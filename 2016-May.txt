From lordpreetam at gmail.com  Sun May  1 00:34:03 2016
From: lordpreetam at gmail.com (Preetam Pal)
Date: Sun, 1 May 2016 04:04:03 +0530
Subject: [R] Data Issues with ctree/glm and controlling classification
	parameters
Message-ID: <CAHVFrXH0xtnFnQcjUVVeCLCOnW8OLyurpb0OrAp+4t+LYND0Og@mail.gmail.com>

Hi,

I have a dataset obtained as:

mydata <- read.csv("data.csv", header = TRUE) which contains the variable
'y' (y is binary 0 or 1) and also another variable 'weight' (weight is a
numerical variable - taking fractional values between 0 and 1).

1>
I want to first apply ctree() on  mydata, but dont want to use this
'weight' variable in the tree-buiding process. Can you please suggest how
to do this? Please note, I *don't* want to delete/remove this variable from
mydata.


2>
Another question: Say, I split up mydata into train (80%) and test(20%) as:
d<-sort(sample(nrow(mydata), nrow(mydata)*0.8));
train <- mydata[d,];
test < -mydata[-d,];


Then, I perform weighted glm (essentially, logistic regression) on train as:
#Build GLM model on train data
model <-glm(y~., data = train, weights = train$weight, family = binomial);
********************(A)
#Apply model on test
score <-predict(model, type = 'response',test); **************(B)
#Get classification for each observation in test as 'positive' or 'negative'
classify <-performance(score,"tpr","fpr"); **************(C)

My question here is:
2a> Again, how do I proceed if I don't want to use the variable 'weight' as
a regressor in the glm() function in (A) above (but use all other variables
in train)?
2b> In step (B) & (C), how do I control the classification rule, i.e. R
might classify observations with model-fitted probability > 0.5 as a
'positive' and <= 0.5 as a 'negative'. Is there a way I can change this
threshold to say, 0.75 instead of whatever R might be using (I used 0.5 as
example).

Thank you in advance for your help.
-Preetam
-- 
Preetam Pal
(+91)-9432212774
M-Stat 2nd Year,                                             Room No. N-114
Statistics Division,                                           C.V.Raman
Hall
Indian Statistical Institute,                                 B.H.O.S.
Kolkata.

	[[alternative HTML version deleted]]


From lordpreetam at gmail.com  Sun May  1 00:49:36 2016
From: lordpreetam at gmail.com (Preetam Pal)
Date: Sun, 1 May 2016 04:19:36 +0530
Subject: [R] CTree to obtain segmented data
Message-ID: <CAHVFrXHNVfYX1=+ZTFECSz46g=Hv05FQpybdD=ynQ4D-bk5j8A@mail.gmail.com>

Hi guys,

I have a dataset obtained as:
mydata <- read.csv("data.csv", header = TRUE) which contains the variable
'y' (y is binary 0 or 1) and some regressor variables.
I want to apply the ctree technique on this data with the following
requirements:
1> Of course I would need the tree plot (which I can do myself)
2> After that, I would need the segmented subsets of the data (as
determined by running ctree()) in array format, i.e. if ctree partitions
mydata into 6 smaller datasets, I need to output an array 'CTree_Subsets'
with 6 elements, each element being one of these smaller datasets. Note
that I need the actual smaller datasets in the array, and not just their
characteristics/classification rules obtained from the tree. (Context: I'll
need to run separate logistic regression models for each of these smaller
datasets). Would really appreciate your help with this issue

Thanks,
Preetam

-- 
Preetam Pal
(+91)-9432212774
M-Stat 2nd Year,                                             Room No. N-114
Statistics Division,                                           C.V.Raman
Hall
Indian Statistical Institute,                                 B.H.O.S.
Kolkata.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun May  1 01:16:11 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 30 Apr 2016 16:16:11 -0700
Subject: [R] Removing NAs from dataframe  (for use in Vioplot)
In-Reply-To: <142423783.20160430205840@hsm.org.uk>
References: <142423783.20160430205840@hsm.org.uk>
Message-ID: <1D7DB03F-C03B-48E4-B508-6C23406F26A2@comcast.net>


> On Apr 30, 2016, at 12:58 PM, Mike Smith <mike at hsm.org.uk> wrote:
> 
> Hi
> 
> First post and a relative R newbie....
> 
> I am using the vioplot library to produce some violin plots. I have an input CSV with columns off irregular length that contain NAs. I want to strip the NAs out and produce a multiple violin plot automatically labelled using the headers. At the moment I do this
> 
> Code: 
> ds1 = read.csv("http://www.lecturematerials.co.uk/data/spelling.csv")
> library(vioplot)
> y6<-na.omit(ds1$y6)
> y5<-na.omit(ds1$y5)
> y4<-na.omit(ds1$y4)
> y3<-na.omit(ds1$y3)
> y2<-na.omit(ds1$y2)
> y1<-na.omit(ds1$y1)
> vioplot(y6, y5, y4,y3,y2,y1,horizontal=TRUE, names=c("Y6", "Y5","Y4","Y3","Y2","Y1"), col = "lightblue")
> 
> 
> Two queries:
> 
> 1. Is there a more elegant way of automatically stripping the NAs, passing the columns to the function along with the header names??
> 

ds2 <- lapply( ds1, na.omit)


> 2. Can I easily add the sample size to each violin plotted??

> ?violplot
No documentation for ?violplot? in specified packages and libraries:
you could try ???violplot?

> 


> thanks
> 
> mike
> 						
> 
> 
> ---
> Mike Smith
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sun May  1 01:23:43 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 30 Apr 2016 16:23:43 -0700
Subject: [R] Removing NAs from dataframe  (for use in Vioplot)
In-Reply-To: <1D7DB03F-C03B-48E4-B508-6C23406F26A2@comcast.net>
References: <142423783.20160430205840@hsm.org.uk>
	<1D7DB03F-C03B-48E4-B508-6C23406F26A2@comcast.net>
Message-ID: <39FB27E5-65B5-4388-9849-02ABE585BC4D@comcast.net>


> On Apr 30, 2016, at 4:16 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Apr 30, 2016, at 12:58 PM, Mike Smith <mike at hsm.org.uk> wrote:
>> 
>> Hi
>> 
>> First post and a relative R newbie....
>> 
>> I am using the vioplot library to produce some violin plots.

It's a package,  .... not a library.

>> I have an input CSV with columns off irregular length that contain NAs. I want to strip the NAs out and produce a multiple violin plot automatically labelled using the headers. At the moment I do this
>> 
>> Code: 
>> ds1 = read.csv("http://www.lecturematerials.co.uk/data/spelling.csv")
>> library(vioplot)
>> y6<-na.omit(ds1$y6)
>> y5<-na.omit(ds1$y5)
>> y4<-na.omit(ds1$y4)
>> y3<-na.omit(ds1$y3)
>> y2<-na.omit(ds1$y2)
>> y1<-na.omit(ds1$y1)
>> vioplot(y6, y5, y4,y3,y2,y1,horizontal=TRUE, names=c("Y6", "Y5","Y4","Y3","Y2","Y1"), col = "lightblue")
>> 
>> 
>> Two queries:
>> 
>> 1. Is there a more elegant way of automatically stripping the NAs, passing the columns to the function along with the header names??
>> 
> 
> ds2 <- lapply( ds1, na.omit)
> 
> 
>> 2. Can I easily add the sample size to each violin plotted??
> 
>> ?violplot
> No documentation for ?violplot? in specified packages and libraries:
> you could try ???violplot?

I see that I mispled that _package_ name. However, after loading it I realized that I had no way of replicating what you are seeing, because you didn't provide that file (or even something that resembles it. It's rather unclear how you wanted this information presented.

-- 
David.


David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Sun May  1 02:06:12 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 1 May 2016 10:06:12 +1000
Subject: [R] How to print the frequency table (produced by the command
 "table" to Excel
In-Reply-To: <CABcx46AsBxGTurGu9hJ9+XUFg+o0hyQYt6k=qiP4TWJWQc=imQ@mail.gmail.com>
References: <CABcx46D_isFkbjCB_uN-epssdoOsnyx34uu7ey-aQHkkWOkk2Q@mail.gmail.com>
	<CA+8X3fVbX1ptDr_xaaQyCrbskqQNqBS0mN8fm8Utm-y2rnbfwA@mail.gmail.com>
	<CABcx46AsBxGTurGu9hJ9+XUFg+o0hyQYt6k=qiP4TWJWQc=imQ@mail.gmail.com>
Message-ID: <CA+8X3fWC_Uj1oOhmVag=Nh8rorL2Mb=Khq3-JOrDCk8-BvOt1w@mail.gmail.com>

Hi jpm miao,
I think you can get what you want like this:

alpha1<-sample(LETTERS[1:3],50,TRUE)
alpha2<-sample(LETTERS[1:2],50,TRUE)
alphas<-data.frame(alpha1,alpha2)
library(prettyR)
alphatab<-xtab(alpha1~alpha2,alphas)
sink("temp_table3.csv",append=TRUE)
delim.xtab(alphatab,pct=NA,delim=",")
sink()

Jim

On Sun, May 1, 2016 at 4:47 AM, jpm miao <miaojpm at gmail.com> wrote:
> Jim,
>
>    Thanks for creating such a fantastic package "prettyR".
>    I want to print the pretty frequency table (with row total and column
> total) to an excel (or csv ) file. Is it possible?
>>alphatab
>
> A B Total
> A 8 10 18
> B 7 5 12
> C 9 11 20
> Total 24 26 50
>
>    Two issues I encountered (See the attached csv file).
> 1. When I tried to print the above table to csv file, all elements on the
> same row are printed in one cell.
> 2. If I write "delim.table(alpha tab)", the table is distorted (see
> attached). Of course, I can adjust it manually but sometimes the number of
> files is big.
>
>     Thanks!
>
> Miao
>
>> alpha1<-sample(LETTERS[1:3],50,TRUE)
>> alpha2<-sample(LETTERS[1:2],50,TRUE)
>>
>> alphas<-data.frame(alpha1,alpha2)
>> alphatab<-xtab(alpha1~alpha2,alphas)
> Crosstabulation of alpha1 by alpha2
> alpha2
> alpha1      A      B
> A      8     10     18
>    44.44  55.56      -
>    33.33  38.46  36.00
>
> B      7      5     12
>    58.33  41.67      -
>    29.17  19.23  24.00
>
> C      9     11     20
>       45     55      -
>    37.50  42.31  40.00
>
>       24     26     50
>       48     52    100
>> delim.xtab(alphatab,pct=NA,interdigitate=TRUE)
> alphatab
>
> A B Total
> A 8 10 18
> B 7 5 12
> C 9 11 20
> Total 24 26 50
>
>> sink("temp_table3.csv")
>> delim.xtab(alphatab,pct=NA,interdigitate=TRUE)
>> sink()
>> sink("temp_table3.csv", append=TRUE)
>> delim.table(alphatab)
>> sink()
>> sink("temp_table3.csv", append=TRUE)
>> delim.table(alphatab)
>> sink()
>> ?delim.xtab
>
>
> 2016-04-26 16:14 GMT-07:00 Jim Lemon <drjimlemon at gmail.com>:
>>
>> Hi jpm miao,
>> You can get CSV files that can be imported into Excel like this:
>>
>> library(prettyR)
>> sink("excel_table1.csv")
>> delim.table(table(df[,c("y","z")]))
>> sink()
>> sink("excel_table2.csv")
>> delim.table(as.data.frame(table(df[,c("y","z")])),label="")
>> sink()
>> sink("excel_table3.csv")
>> delim.table(as.matrix(table(df[,c("y","z")])),label="")
>> sink()
>>
>> Jim
>>
>> On Wed, Apr 27, 2016 at 8:35 AM, jpm miao <miaojpm at gmail.com> wrote:
>> > Hi,
>> >
>> >    How could we print the frequency table (produced by "table") to an
>> > Excel
>> > file?
>> >    Is there an easy way to do so? Thanks,
>> >
>> > Miao
>> >
>> >> df <- data.frame(x = 1:3, y = 3:1, z = letters[1:3])
>> >
>> >> table(df[,c("y","z")])
>> >    z
>> > y   a b c
>> >   1 0 0 1
>> >   2 0 1 0
>> >   3 1 0 0
>> >> test<-table(df[,c("y","z")])
>> >> as.data.frame(test)
>> >   y z Freq
>> > 1 1 a    0
>> > 2 2 a    0
>> > 3 3 a    1
>> > 4 1 b    0
>> > 5 2 b    1
>> > 6 3 b    0
>> > 7 1 c    1
>> > 8 2 c    0
>> > 9 3 c    0
>> >> as.matrix(test)
>> >    z
>> > y   a b c
>> >   1 0 0 1
>> >   2 0 1 0
>> >   3 1 0 0
>> >> testm<-as.matrix(test)
>> >> testm
>> >    z
>> > y   a b c
>> >   1 0 0 1
>> >   2 0 1 0
>> >   3 1 0 0
>> >> typeof(testm)
>> > [1] "integer"
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From drjimlemon at gmail.com  Sun May  1 02:08:53 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 1 May 2016 10:08:53 +1000
Subject: [R] Issue installing packages - Linux
In-Reply-To: <CAO7OmOhi1Pag3funkd9UOv7QxkWjOPmYjcEQX_QBeSTdOAvK4Q@mail.gmail.com>
References: <CAO7OmOhi1Pag3funkd9UOv7QxkWjOPmYjcEQX_QBeSTdOAvK4Q@mail.gmail.com>
Message-ID: <CA+8X3fVVCA1-ZpVt9b9cegqf7=UGcci0NxastVFGi3GSttO4Rg@mail.gmail.com>

Hi Lars,
A mystery, but for the bodgy characters in your error message. Perhaps
there is a problem with R trying to read a different character set
from that used in the package.

Jim

On Sat, Apr 30, 2016 at 8:22 PM, Lars Bishop <lars52r at gmail.com> wrote:
> Hello,
>
> I can?t seem to be able to install packages on a redhat-linux-gnu. For
> instance, this is what happens when I try to install ?bitops?. Any hint on
> what might be the issue would be much appreciated.
>
>> sessionInfo()
> R version 3.2.3 (2015-12-10)
> Platform: x86_64-redhat-linux-gnu (64-bit)
> Running under: Red Hat Enterprise Linux
>
>> Sys.setenv(https_proxy="https://labproxy.com:8080")
>> install.packages("bitops", lib="mypath ")
>
> Here I choose: 22: (HTTP mirrors) and then a mirror 16:Canada(ON)
>
> * installing *source* package ?bitops? ...
> ** package ?bitops? successfully unpacked and MD5 sums checked
> Error in readRDS(pfile) : error reading from connection
> ERROR: lazy loading failed for package ?bitops?
>
> I?ve also tried from the shell (after downloading the package source)
>
> $  R CMD INSTALL bitops_1.0-6.tar.gz
> ERROR: cannot extract package from bitops_1.0-6.tar.gz
>
> Thank you,
> Lars.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From btupper at bigelow.org  Sun May  1 02:33:14 2016
From: btupper at bigelow.org (Ben Tupper)
Date: Sat, 30 Apr 2016 20:33:14 -0400
Subject: [R] Could not find function "pointsToRaster"
In-Reply-To: <CAC8ss33c8=K_-t-uM3pt62csn_BDpv6d2ZAhdJ35ifD7uYCY7A@mail.gmail.com>
References: <CAC8ss30OF5jHDmvMrXLw0NJt68Ect9FsxYWK+56aH=q0bL7JFw@mail.gmail.com>
	<9D970500-C4F5-47B1-AA9C-3447D50A8E02@bigelow.org>
	<CAC8ss33c8=K_-t-uM3pt62csn_BDpv6d2ZAhdJ35ifD7uYCY7A@mail.gmail.com>
Message-ID: <5F0DE1C6-4D0D-495B-9F00-247C275AF10F@bigelow.org>

Hi,

I think you need to check the order of your arguments to rasterize().  See the documentation with ?rasterize and compare to what you did below.

Cheers,
Ben

 
> On Apr 30, 2016, at 9:55 AM, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
> 
> Dear All,
> Thanks for your inputs. I did replace pointsToRaster () with
> raster::rasterize(). Below is part of my script.
> 
> But I got another error:
> Error in (function (classes, fdef, mtable)  :
>  unable to find an inherited method for function ?rasterize? for
> signature ?"RasterLayer", "matrix"?
> 
> Thank you for more inputs.
> Ogbos
> 
> k<-read.table("Lat05w3.txt")
> colnames(k)<-c("y","x")
> xy<-cbind(k$x,k$y)
> library(raster)
> r<-raster()
> #library(sp)
> pr<-raster::rasterize(r,xy)
> 
> #pr<-pointsToRaster(r,xy)
> 
> library(maps)
> w = map("world")
> wc = cbind(w$x, w$y)
> wc=wc[!is.na(wc[,1]),]
> write.table(wc, file = "my.fileb", sep=" ",row=FALSE,col=FALSE)
> my<-read.table("my.out",col.names=c("a","b"))
> rena = function(X,Z){
> Y=rep(NA,length(X))
> Y[!is.na(X)]=Z
> Y
> }
> 
> 
> 
> 
> On 4/30/16, Ben Tupper <btupper at bigelow.org> wrote:
>> Hi,
>> 
>> A terrific resource for this type of issue (and pretty much anything related
>> to R) is http://rseek.org/  I'm sure I use it at least daily.  Check out
>> ...
>> 
>> http://rseek.org/?q=pointsToRaster
>> 
>> The first hit is about pointsToRaster() - it has been replaced by
>> raster::rasterize()
>> 
>> Cheers,
>> Ben
>> 
>>> On Apr 30, 2016, at 4:28 AM, Ogbos Okike <giftedlife2014 at gmail.com>
>>> wrote:
>>> 
>>> Dear All,
>>> I have a script that draws longitude and latitude of lightning
>>> occurrence. This script was running fine before. But when I changed my
>>> system and do a fresh install on another laptop, this error persist.
>>> source("script")
>>> Error in eval(expr, envir, enclos) :
>>> could not find function "pointsToRaster"
>>> 
>>> I have tried to see if  there is any other package I need to install
>>> to take of the problem, I could not see. Already, when I installed
>>> raster, it installed its dependencies such as sp.
>>> Can any body please bail me out.
>>> 
>>> Thanks
>>> Ogbos
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> Ben Tupper
>> Bigelow Laboratory for Ocean Sciences
>> 60 Bigelow Drive, P.O. Box 380
>> East Boothbay, Maine 04544
>> http://www.bigelow.org
>> 
>> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From miaojpm at gmail.com  Sun May  1 03:19:00 2016
From: miaojpm at gmail.com (jpm miao)
Date: Sat, 30 Apr 2016 18:19:00 -0700
Subject: [R] How to print the frequency table (produced by the command
 "table" to Excel
In-Reply-To: <CA+8X3fWC_Uj1oOhmVag=Nh8rorL2Mb=Khq3-JOrDCk8-BvOt1w@mail.gmail.com>
References: <CABcx46D_isFkbjCB_uN-epssdoOsnyx34uu7ey-aQHkkWOkk2Q@mail.gmail.com>
	<CA+8X3fVbX1ptDr_xaaQyCrbskqQNqBS0mN8fm8Utm-y2rnbfwA@mail.gmail.com>
	<CABcx46AsBxGTurGu9hJ9+XUFg+o0hyQYt6k=qiP4TWJWQc=imQ@mail.gmail.com>
	<CA+8X3fWC_Uj1oOhmVag=Nh8rorL2Mb=Khq3-JOrDCk8-BvOt1w@mail.gmail.com>
Message-ID: <CABcx46CwPnejdpYYYxpuPh-71hPv1Zf0noiTW3tZ_qwou_4Qzw@mail.gmail.com>

Thanks.
Could we print the row/column names, "alpha1" and "alpha2" to the csv file?

2016-04-30 17:06 GMT-07:00 Jim Lemon <drjimlemon at gmail.com>:

> Hi jpm miao,
> I think you can get what you want like this:
>
> alpha1<-sample(LETTERS[1:3],50,TRUE)
> alpha2<-sample(LETTERS[1:2],50,TRUE)
> alphas<-data.frame(alpha1,alpha2)
> library(prettyR)
> alphatab<-xtab(alpha1~alpha2,alphas)
> sink("temp_table3.csv",append=TRUE)
> delim.xtab(alphatab,pct=NA,delim=",")
> sink()
>
> Jim
>
> On Sun, May 1, 2016 at 4:47 AM, jpm miao <miaojpm at gmail.com> wrote:
> > Jim,
> >
> >    Thanks for creating such a fantastic package "prettyR".
> >    I want to print the pretty frequency table (with row total and column
> > total) to an excel (or csv ) file. Is it possible?
> >>alphatab
> >
> > A B Total
> > A 8 10 18
> > B 7 5 12
> > C 9 11 20
> > Total 24 26 50
> >
> >    Two issues I encountered (See the attached csv file).
> > 1. When I tried to print the above table to csv file, all elements on the
> > same row are printed in one cell.
> > 2. If I write "delim.table(alpha tab)", the table is distorted (see
> > attached). Of course, I can adjust it manually but sometimes the number
> of
> > files is big.
> >
> >     Thanks!
> >
> > Miao
> >
> >> alpha1<-sample(LETTERS[1:3],50,TRUE)
> >> alpha2<-sample(LETTERS[1:2],50,TRUE)
> >>
> >> alphas<-data.frame(alpha1,alpha2)
> >> alphatab<-xtab(alpha1~alpha2,alphas)
> > Crosstabulation of alpha1 by alpha2
> > alpha2
> > alpha1      A      B
> > A      8     10     18
> >    44.44  55.56      -
> >    33.33  38.46  36.00
> >
> > B      7      5     12
> >    58.33  41.67      -
> >    29.17  19.23  24.00
> >
> > C      9     11     20
> >       45     55      -
> >    37.50  42.31  40.00
> >
> >       24     26     50
> >       48     52    100
> >> delim.xtab(alphatab,pct=NA,interdigitate=TRUE)
> > alphatab
> >
> > A B Total
> > A 8 10 18
> > B 7 5 12
> > C 9 11 20
> > Total 24 26 50
> >
> >> sink("temp_table3.csv")
> >> delim.xtab(alphatab,pct=NA,interdigitate=TRUE)
> >> sink()
> >> sink("temp_table3.csv", append=TRUE)
> >> delim.table(alphatab)
> >> sink()
> >> sink("temp_table3.csv", append=TRUE)
> >> delim.table(alphatab)
> >> sink()
> >> ?delim.xtab
> >
> >
> > 2016-04-26 16:14 GMT-07:00 Jim Lemon <drjimlemon at gmail.com>:
> >>
> >> Hi jpm miao,
> >> You can get CSV files that can be imported into Excel like this:
> >>
> >> library(prettyR)
> >> sink("excel_table1.csv")
> >> delim.table(table(df[,c("y","z")]))
> >> sink()
> >> sink("excel_table2.csv")
> >> delim.table(as.data.frame(table(df[,c("y","z")])),label="")
> >> sink()
> >> sink("excel_table3.csv")
> >> delim.table(as.matrix(table(df[,c("y","z")])),label="")
> >> sink()
> >>
> >> Jim
> >>
> >> On Wed, Apr 27, 2016 at 8:35 AM, jpm miao <miaojpm at gmail.com> wrote:
> >> > Hi,
> >> >
> >> >    How could we print the frequency table (produced by "table") to an
> >> > Excel
> >> > file?
> >> >    Is there an easy way to do so? Thanks,
> >> >
> >> > Miao
> >> >
> >> >> df <- data.frame(x = 1:3, y = 3:1, z = letters[1:3])
> >> >
> >> >> table(df[,c("y","z")])
> >> >    z
> >> > y   a b c
> >> >   1 0 0 1
> >> >   2 0 1 0
> >> >   3 1 0 0
> >> >> test<-table(df[,c("y","z")])
> >> >> as.data.frame(test)
> >> >   y z Freq
> >> > 1 1 a    0
> >> > 2 2 a    0
> >> > 3 3 a    1
> >> > 4 1 b    0
> >> > 5 2 b    1
> >> > 6 3 b    0
> >> > 7 1 c    1
> >> > 8 2 c    0
> >> > 9 3 c    0
> >> >> as.matrix(test)
> >> >    z
> >> > y   a b c
> >> >   1 0 0 1
> >> >   2 0 1 0
> >> >   3 1 0 0
> >> >> testm<-as.matrix(test)
> >> >> testm
> >> >    z
> >> > y   a b c
> >> >   1 0 0 1
> >> >   2 0 1 0
> >> >   3 1 0 0
> >> >> typeof(testm)
> >> > [1] "integer"
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>

	[[alternative HTML version deleted]]


From tom at maladmin.com  Sun May  1 04:03:59 2016
From: tom at maladmin.com (Tom Wright)
Date: Sat, 30 Apr 2016 19:03:59 -0700
Subject: [R] Removing NAs from dataframe (for use in Vioplot)
In-Reply-To: <142423783.20160430205840@hsm.org.uk>
References: <142423783.20160430205840@hsm.org.uk>
Message-ID: <CAKmUXV_M+gWRfHqoLLsxiD6r47W7gX6t7NHxxO36F7foyesUcA@mail.gmail.com>

Never let it be said there's only one way to do a thing:

require(ggplot2)
require(dplyr)

#create a sample dataset
dat <- data.frame(y1=sample(c(1:10,NA),20,replace=TRUE),
                          y2=sample(c(1:10,NA),20,replace=TRUE),
                          y3=sample(c(1:10,NA),20,replace=TRUE))

# convert from wide to long
dat <- melt(dat)

# add the counts as a label
dat <- merge(dat,
          group_by(dat,variable) %>%
               summarise(lab=paste0('n=',length(na.omit(value)))))

# do the plot
ggplot(dat,aes(x=variable,y=value)) +
    geom_violin() +
    geom_text(aes(y=max(value,na.rm=TRUE)/2,label=lab))


# apologies to David Winsemius for directing this answer to him, I'll work
out how to use email one day.

On Sat, Apr 30, 2016 at 12:58 PM, Mike Smith <mike at hsm.org.uk> wrote:

> Hi
>
> First post and a relative R newbie....
>
> I am using the vioplot library to produce some violin plots. I have an
> input CSV with columns off irregular length that contain NAs. I want to
> strip the NAs out and produce a multiple violin plot automatically labelled
> using the headers. At the moment I do this
>
> Code:
> ds1 = read.csv("http://www.lecturematerials.co.uk/data/spelling.csv")
> library(vioplot)
> y6<-na.omit(ds1$y6)
> y5<-na.omit(ds1$y5)
> y4<-na.omit(ds1$y4)
> y3<-na.omit(ds1$y3)
> y2<-na.omit(ds1$y2)
> y1<-na.omit(ds1$y1)
> vioplot(y6, y5, y4,y3,y2,y1,horizontal=TRUE, names=c("Y6",
> "Y5","Y4","Y3","Y2","Y1"), col = "lightblue")
>
>
> Two queries:
>
> 1. Is there a more elegant way of automatically stripping the NAs, passing
> the columns to the function along with the header names??
>
> 2. Can I easily add the sample size to each violin plotted??
>
> thanks
>
> mike
>
>
>
> ---
> Mike Smith
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tom at maladmin.com  Sun May  1 04:07:34 2016
From: tom at maladmin.com (Tom Wright)
Date: Sat, 30 Apr 2016 19:07:34 -0700
Subject: [R] how to use AND in grepl
In-Reply-To: <1930216316.8287881.1462052327296.JavaMail.yahoo@mail.yahoo.com>
References: <1930216316.8287881.1462052327296.JavaMail.yahoo.ref@mail.yahoo.com>
	<1930216316.8287881.1462052327296.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAKmUXV9KC+hn6kKT=yEJTehyVgLhCdjiqR-OEumWavHgU=2wCg@mail.gmail.com>

subset(df,grepl("t2|pd",x$Command))


On Sat, Apr 30, 2016 at 2:38 PM, ch.elahe via R-help <r-help at r-project.org>
wrote:

> Hi all,
>
> I have one factor variable in my df and I want to extract the names from
> it which contain both "t2" and "pd":
>
>   'data.frame': 36919 obs. of 162 variables
>    $TE                :int 38,41,11,52,48,75,.....
>    $TR                :int 100,210,548,546,.....
>    $Command          :factor W/2229 levels
> "_localize_PD","_localize_tre_t2","_abdomen_t1_seq","knee_pd_t1_localize","pd_local_abdomen_t2"...
>
> I have tried this but I did not get result:
>
>   t2pd=subset(df,grepl("t2",Command) & grepl("pd",Command))
>
>
> does anyone know how to apply AND in grepl?
>
> Thanks
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tom at maladmin.com  Sun May  1 04:35:12 2016
From: tom at maladmin.com (Tom Wright)
Date: Sun, 01 May 2016 02:35:12 +0000
Subject: [R] how to use AND in grepl
In-Reply-To: <CAKmUXV9KC+hn6kKT=yEJTehyVgLhCdjiqR-OEumWavHgU=2wCg@mail.gmail.com>
References: <1930216316.8287881.1462052327296.JavaMail.yahoo.ref@mail.yahoo.com>
	<1930216316.8287881.1462052327296.JavaMail.yahoo@mail.yahoo.com>
	<CAKmUXV9KC+hn6kKT=yEJTehyVgLhCdjiqR-OEumWavHgU=2wCg@mail.gmail.com>
Message-ID: <CAKmUXV_nabMZpm_Q4RxvZayamwko+40shFdYv=P-ag5N8rsP+w@mail.gmail.com>

Actually not sure my previous answer does what you wanted. Using your
approach:

 t2pd=subset(df,grepl("t2",df$Command) & grepl("pd",df$Command))

Should work.

I think the regex pattern you are looking for is:

 Subset(df,grepl("(.* t2.*pd.* )|(.* pd.* t2.*)",df$Command)

On Sat, Apr 30, 2016, 7:07 PM Tom Wright <tom at maladmin.com> wrote:

> subset(df,grepl("t2|pd",x$Command))
>
>
> On Sat, Apr 30, 2016 at 2:38 PM, ch.elahe via R-help <r-help at r-project.org
> > wrote:
>
>> Hi all,
>>
>> I have one factor variable in my df and I want to extract the names from
>> it which contain both "t2" and "pd":
>>
>>   'data.frame': 36919 obs. of 162 variables
>>    $TE                :int 38,41,11,52,48,75,.....
>>    $TR                :int 100,210,548,546,.....
>>    $Command          :factor W/2229 levels
>> "_localize_PD","_localize_tre_t2","_abdomen_t1_seq","knee_pd_t1_localize","pd_local_abdomen_t2"...
>>
>> I have tried this but I did not get result:
>>
>>   t2pd=subset(df,grepl("t2",Command) & grepl("pd",Command))
>>
>>
>> does anyone know how to apply AND in grepl?
>>
>> Thanks
>> Elahe
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun May  1 04:59:28 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 01 May 2016 03:59:28 +0100
Subject: [R] Removing NAs from dataframe (for use in Vioplot)
In-Reply-To: <CAKmUXV_M+gWRfHqoLLsxiD6r47W7gX6t7NHxxO36F7foyesUcA@mail.gmail.com>
References: <142423783.20160430205840@hsm.org.uk>
	<CAKmUXV_M+gWRfHqoLLsxiD6r47W7gX6t7NHxxO36F7foyesUcA@mail.gmail.com>
Message-ID: <146A5AE9-CCF2-40FF-AFA9-9CC791028E8A@dcn.davis.ca.us>

But require() should not be used interchangeably with library()... the return value from require() should always be tested. 
-- 
Sent from my phone. Please excuse my brevity.

On May 1, 2016 3:03:59 AM GMT+01:00, Tom Wright <tom at maladmin.com> wrote:
>Never let it be said there's only one way to do a thing:
>
>require(ggplot2)
>require(dplyr)
>
>#create a sample dataset
>dat <- data.frame(y1=sample(c(1:10,NA),20,replace=TRUE),
>                          y2=sample(c(1:10,NA),20,replace=TRUE),
>                          y3=sample(c(1:10,NA),20,replace=TRUE))
>
># convert from wide to long
>dat <- melt(dat)
>
># add the counts as a label
>dat <- merge(dat,
>          group_by(dat,variable) %>%
>               summarise(lab=paste0('n=',length(na.omit(value)))))
>
># do the plot
>ggplot(dat,aes(x=variable,y=value)) +
>    geom_violin() +
>    geom_text(aes(y=max(value,na.rm=TRUE)/2,label=lab))
>
>
># apologies to David Winsemius for directing this answer to him, I'll
>work
>out how to use email one day.
>
>On Sat, Apr 30, 2016 at 12:58 PM, Mike Smith <mike at hsm.org.uk> wrote:
>
>> Hi
>>
>> First post and a relative R newbie....
>>
>> I am using the vioplot library to produce some violin plots. I have
>an
>> input CSV with columns off irregular length that contain NAs. I want
>to
>> strip the NAs out and produce a multiple violin plot automatically
>labelled
>> using the headers. At the moment I do this
>>
>> Code:
>> ds1 = read.csv("http://www.lecturematerials.co.uk/data/spelling.csv")
>> library(vioplot)
>> y6<-na.omit(ds1$y6)
>> y5<-na.omit(ds1$y5)
>> y4<-na.omit(ds1$y4)
>> y3<-na.omit(ds1$y3)
>> y2<-na.omit(ds1$y2)
>> y1<-na.omit(ds1$y1)
>> vioplot(y6, y5, y4,y3,y2,y1,horizontal=TRUE, names=c("Y6",
>> "Y5","Y4","Y3","Y2","Y1"), col = "lightblue")
>>
>>
>> Two queries:
>>
>> 1. Is there a more elegant way of automatically stripping the NAs,
>passing
>> the columns to the function along with the header names??
>>
>> 2. Can I easily add the sample size to each violin plotted??
>>
>> thanks
>>
>> mike
>>
>>
>>
>> ---
>> Mike Smith
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From mike at hsm.org.uk  Sun May  1 09:15:44 2016
From: mike at hsm.org.uk (Mike Smith)
Date: Sun, 1 May 2016 08:15:44 +0100
Subject: [R] Removing NAs from dataframe  (for use in Vioplot)
In-Reply-To: <39FB27E5-65B5-4388-9849-02ABE585BC4D@comcast.net>
References: <142423783.20160430205840@hsm.org.uk> 
	<1D7DB03F-C03B-48E4-B508-6C23406F26A2@comcast.net>
	<39FB27E5-65B5-4388-9849-02ABE585BC4D@comcast.net>
Message-ID: <1805593311.20160501081544@hsm.org.uk>

>>> On Apr 30, 2016, at 12:58 PM, Mike Smith <mike at hsm.org.uk> wrote:

>>> Hi

>>> First post and a relative R newbie....

>>> I am using the vioplot library to produce some violin plots.

DW> It's a package,  .... not a library.

>>> I have an input CSV with columns off irregular length that contain NAs. I want to strip the NAs out and produce a multiple violin plot automatically labelled using the headers. At the moment I do this

>>> Code: 
>>> ds1 = read.csv("http://www.lecturematerials.co.uk/data/spelling.csv")
>>> library(vioplot)
>>> y6<-na.omit(ds1$y6)
>>> y5<-na.omit(ds1$y5)
>>> y4<-na.omit(ds1$y4)
>>> y3<-na.omit(ds1$y3)
>>> y2<-na.omit(ds1$y2)
>>> y1<-na.omit(ds1$y1)
>>> vioplot(y6, y5, y4,y3,y2,y1,horizontal=TRUE, names=c("Y6", "Y5","Y4","Y3","Y2","Y1"), col = "lightblue")


>>> Two queries:

>>> 1. Is there a more elegant way of automatically stripping the NAs, passing the columns to the function along with the header names??


>> ds2 <- lapply( ds1, na.omit)


Fantastic - that does the trick! Easy when you know how!! 

Follow-on: is there a way feed all the lists from ds2 to vioplot? It is now a series of lists (rather than a dataframe - is that right?). So this works, 

library(vioplot)
ds1 = read.csv("http://www.lecturematerials.co.uk/data/spelling.csv")
ds2 <- lapply( ds1, na.omit)
vioplot(ds2$y1,ds2$y2)

but this doesnt

library(vioplot)
ds1 = read.csv("http://www.lecturematerials.co.uk/data/spelling.csv")
ds2 <- lapply( ds1, na.omit)
vioplot(ds2)

>>> 2. Can I easily add the sample size to each violin plotted??

>>> ?violplot
>> No documentation for ?violplot? in specified packages and libraries:
>> you could try ???violplot?

DW> I see that I mispled that _package_ name. However, after loading
DW> it I realized that I had no way of replicating what you are
DW> seeing, because you didn't provide that file (or even something
DW> that resembles it. It's rather unclear how you wanted this information presented.

The original code *should* have worked as the csv was online. There doesnt seem to be any option in vioplot to add the sample size (these are all small samples which I wanted to highlight) so I dont know if this is easily done elsewhere.

Thanks again!!
---
Mike Smith


From milujisb at gmail.com  Sun May  1 17:30:56 2016
From: milujisb at gmail.com (Miluji Sb)
Date: Sun, 1 May 2016 17:30:56 +0200
Subject: [R] Aggregate FIPS data to State and Census divisions
Message-ID: <CAMLwc7MYVXhg6f_PpheHTrjecp7BbiiW_3RBAVTEaJoGyme81A@mail.gmail.com>

Dear all,

I have the following data by US FIPS code. Is there a package to aggregate
the data by State and Census divisions?

temp <- dput(head(pop1,5))
structure(list(FIPS = c("01001", "01003", "01005", "01007", "01009"
), death_2050A1 = c(18.19158, 101.63088, 13.18896, 10.30068,
131.91798), death_2050A2 = c(22.16349, 116.58387, 15.85324, 12.78564,
155.20506), death_2050B1 = c(21.38906, 76.23018, 21.38218, 17.14269,
151.64466), death_2050B2 = c(23.43543, 81.39378, 22.96802, 18.76926,
161.86404), death_2050BC = c(21.89947, 93.88002, 18.60352, 15.1032,
152.43414)), .Names = c("FIPS", "death_2050A1", "death_2050A2",
"death_2050B1", "death_2050B2", "death_2050BC"), row.names = c(NA,
5L), class = "data.frame")

Thank you!

Sincerely,

Milu

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun May  1 17:43:12 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 1 May 2016 08:43:12 -0700
Subject: [R] Removing NAs from dataframe  (for use in Vioplot)
In-Reply-To: <1805593311.20160501081544@hsm.org.uk>
References: <142423783.20160430205840@hsm.org.uk>
	<1D7DB03F-C03B-48E4-B508-6C23406F26A2@comcast.net>
	<39FB27E5-65B5-4388-9849-02ABE585BC4D@comcast.net>
	<1805593311.20160501081544@hsm.org.uk>
Message-ID: <1A3977BC-6BCC-4D93-A245-343DD302EFA3@comcast.net>


> On May 1, 2016, at 12:15 AM, Mike Smith <mike at hsm.org.uk> wrote:
> 
>>>> On Apr 30, 2016, at 12:58 PM, Mike Smith <mike at hsm.org.uk> wrote:
> 
>>>> Hi
> 
>>>> First post and a relative R newbie....
> 
>>>> I am using the vioplot library to produce some violin plots.
> 
> DW> It's a package,  .... not a library.
> 
>>>> I have an input CSV with columns off irregular length that contain NAs. I want to strip the NAs out and produce a multiple violin plot automatically labelled using the headers. At the moment I do this
> 
>>>> Code: 
>>>> ds1 = read.csv("http://www.lecturematerials.co.uk/data/spelling.csv")
>>>> library(vioplot)
>>>> y6<-na.omit(ds1$y6)
>>>> y5<-na.omit(ds1$y5)
>>>> y4<-na.omit(ds1$y4)
>>>> y3<-na.omit(ds1$y3)
>>>> y2<-na.omit(ds1$y2)
>>>> y1<-na.omit(ds1$y1)
>>>> vioplot(y6, y5, y4,y3,y2,y1,horizontal=TRUE, names=c("Y6", "Y5","Y4","Y3","Y2","Y1"), col = "lightblue")
> 
> 
>>>> Two queries:
> 
>>>> 1. Is there a more elegant way of automatically stripping the NAs, passing the columns to the function along with the header names??
> 
> 
>>> ds2 <- lapply( ds1, na.omit)
> 
> 
> Fantastic - that does the trick! Easy when you know how!! 
> 
> Follow-on: is there a way feed all the lists from ds2 to vioplot? It is now a series of lists (rather than a dataframe - is that right?). So this works, 
> 
> library(vioplot)
> ds1 = read.csv("http://www.lecturematerials.co.uk/data/spelling.csv")
> ds2 <- lapply( ds1, na.omit)
> vioplot(ds2$y1,ds2$y2)
> 
> but this doesnt
> 
> library(vioplot)
> ds1 = read.csv("http://www.lecturematerials.co.uk/data/spelling.csv")
> ds2 <- lapply( ds1, na.omit)
> vioplot(ds2)
> 
Error in min(data) : invalid 'type' (list) of argument


I had trouble, too. I thought, "Oh, this is easy, just use `do.call`", but I failed in getting any successful argument passing that way. 

> do.call('vioplot', list(x=ds2[[6]], ds2[-6]) )
Error in min(data) : invalid 'type' (list) of argument
> do.call('vioplot', c(x=ds2[[6]], ds2[-6]) )
Error in vioplot(x1 = 5L, x2 = 10L, x3 = 6L, x4 = 7L, x5 = 7L, x6 = 6L,  : 
  argument "x" is missing, with no default

Eventually I re-wrote the first line of vioplot's body to behave the way I thought made the most sense:

 vioplot <- 
function (x, ..., range = 1.5, h = NULL, ylim = NULL, names = NULL, 
    horizontal = FALSE, col = "magenta", border = "black", lty = 1, 
    lwd = 1, rectCol = "black", colMed = "white", pchMed = 19, 
    at, add = FALSE, wex = 1, drawRect = TRUE) 
{
    datas <- c(list(x), ...)
# .... but keep the rest the same.

# I then get success with:

vioplot(ds2[['y1']], ds2[-6])  # success

do.call('vioplot', list(x=ds2[[6]], ds2[-6]) ) # also successes
do.call('vioplot', list(x=ds2[['y1']], ds2[-6]) )

This is retracing a route explored 8 years ago:

http://markmail.org/search/?q=list%3Aorg.r-project.r-help+list+argument+to+vioplot#query:list%3Aorg.r-project.r-help%20list%20argument%20to%20vioplot+page:1+mid:j6lapgri46utcod7+state:results


It's probably easier to use that helper-function approach than my efforts at hacking.

Best of luck;

David


>>>> 2. Can I easily add the sample size to each violin plotted??
> 
>>>> ?violplot
>>> No documentation for ?violplot? in specified packages and libraries:
>>> you could try ???violplot?
> 
> DW> I see that I mispled that _package_ name. However, after loading
> DW> it I realized that I had no way of replicating what you are
> DW> seeing, because you didn't provide that file (or even something
> DW> that resembles it. It's rather unclear how you wanted this information presented.
> 
> The original code *should* have worked as the csv was online. There doesnt seem to be any option in vioplot to add the sample size (these are all small samples which I wanted to highlight) so I dont know if this is easily done elsewhere.
> 
> Thanks again!!
> ---
> Mike Smith
> 

David Winsemius
Alameda, CA, USA


From milujisb at gmail.com  Sun May  1 18:30:21 2016
From: milujisb at gmail.com (Miluji Sb)
Date: Sun, 1 May 2016 18:30:21 +0200
Subject: [R] Aggregate FIPS data to State and Census divisions
In-Reply-To: <CADv2QyGqrxc5Spfvvzs0fC4tJhkwmT57cyYXyqGQifDh+W5soA@mail.gmail.com>
References: <CAMLwc7MYVXhg6f_PpheHTrjecp7BbiiW_3RBAVTEaJoGyme81A@mail.gmail.com>
	<CADv2QyGqrxc5Spfvvzs0fC4tJhkwmT57cyYXyqGQifDh+W5soA@mail.gmail.com>
Message-ID: <CAMLwc7Ne4xd78O53S28_sLnQQKBUdBh90FPQXVqrGjhBHR886g@mail.gmail.com>

Dear Dennis,

Thank you for your reply. I can use the dplyr/data.table packages to
aggregate - its the matching FIPS codes to their states that I am having
trouble. Thanks again.

Sincerely,

Milu

On Sun, May 1, 2016 at 6:20 PM, Dennis Murphy <djmuser at gmail.com> wrote:

> Hi:
>
> Several such packages exist. Given the size of your data, it's likely
> that the dplyr and data.table packages would be worth investigating.
> Both are well documented.
>
> Dennis
>
> On Sun, May 1, 2016 at 8:30 AM, Miluji Sb <milujisb at gmail.com> wrote:
> > Dear all,
> >
> > I have the following data by US FIPS code. Is there a package to
> aggregate
> > the data by State and Census divisions?
> >
> > temp <- dput(head(pop1,5))
> > structure(list(FIPS = c("01001", "01003", "01005", "01007", "01009"
> > ), death_2050A1 = c(18.19158, 101.63088, 13.18896, 10.30068,
> > 131.91798), death_2050A2 = c(22.16349, 116.58387, 15.85324, 12.78564,
> > 155.20506), death_2050B1 = c(21.38906, 76.23018, 21.38218, 17.14269,
> > 151.64466), death_2050B2 = c(23.43543, 81.39378, 22.96802, 18.76926,
> > 161.86404), death_2050BC = c(21.89947, 93.88002, 18.60352, 15.1032,
> > 152.43414)), .Names = c("FIPS", "death_2050A1", "death_2050A2",
> > "death_2050B1", "death_2050B2", "death_2050BC"), row.names = c(NA,
> > 5L), class = "data.frame")
> >
> > Thank you!
> >
> > Sincerely,
> >
> > Milu
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jan.kacaba at gmail.com  Sun May  1 19:53:48 2016
From: jan.kacaba at gmail.com (Jan Kacaba)
Date: Sun, 1 May 2016 19:53:48 +0200
Subject: [R] inserting row(column) in array or dataframe at specified
	row(column)
Message-ID: <CAHby=D2x+7FKocM4gSpwks3_0PZN16pjMz4rz3v6cqN76_w1Qg@mail.gmail.com>

Hello dear R users,

Is there a function or package which can insert row, column or array in
another array at specified place (row or column)?

I have made several attempts at this function optimizing both speed, code
readability and ease of use. The functions are of following format:

appcol=function(original_array, inserted_object, column_number,
overwrite=FALSE)

# If overwrite=TRUE the columns after column_number are ovewritten by
inserted_object else the columns after column_number are shifted.

Now I have started using package dplyr and it seams that there is no
inserting function either. One can only append at the end or at the
beginning of tbl_df. Is it true?

	[[alternative HTML version deleted]]


From jan.kacaba at gmail.com  Sun May  1 20:09:32 2016
From: jan.kacaba at gmail.com (Jan Kacaba)
Date: Sun, 1 May 2016 20:09:32 +0200
Subject: [R] row names, coulmn names
Message-ID: <CAHby=D1mkfZnsWd_bZyfsfgfbCQcbimNRSF4U1TUrLB4XNqrwA@mail.gmail.com>

Hello dear R helpers,

Is it possible to have more than 1 row for column names in data.frame,
array, tbl_df? I would like to have column numbers in the first row, string
names in the second row, physical unit in third row.
How would I do it?

Derek

	[[alternative HTML version deleted]]


From tom at maladmin.com  Sun May  1 20:56:48 2016
From: tom at maladmin.com (Tom Wright)
Date: Sun, 01 May 2016 18:56:48 +0000
Subject: [R] row names, coulmn names
In-Reply-To: <CAHby=D1mkfZnsWd_bZyfsfgfbCQcbimNRSF4U1TUrLB4XNqrwA@mail.gmail.com>
References: <CAHby=D1mkfZnsWd_bZyfsfgfbCQcbimNRSF4U1TUrLB4XNqrwA@mail.gmail.com>
Message-ID: <CAKmUXV_N61friB7RqB0UUh023e=R_8PgJYHfRVkb=pqnvSA_Yg@mail.gmail.com>

I think what you ask isn't ideal.Each column in a dataframe should be the
same data type. While column names are stored in the first row when the df
is exported to CSV, they are not stored as columns in the data frame.
Instead the column names are stored as a separate attribute of the df. This
is why you need to use names(df) to access them, not df[1,]. I don't have
access to R right now, but I think ?attributes or ??"attributes" should
point you in the correct direction.

On Sun, May 1, 2016, 11:11 AM Jan Kacaba <jan.kacaba at gmail.com> wrote:

> Hello dear R helpers,
>
> Is it possible to have more than 1 row for column names in data.frame,
> array, tbl_df? I would like to have column numbers in the first row, string
> names in the second row, physical unit in third row.
> How would I do it?
>
> Derek
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tom at maladmin.com  Sun May  1 20:59:45 2016
From: tom at maladmin.com (Tom Wright)
Date: Sun, 01 May 2016 18:59:45 +0000
Subject: [R] inserting row(column) in array or dataframe at specified
	row(column)
In-Reply-To: <CAHby=D2x+7FKocM4gSpwks3_0PZN16pjMz4rz3v6cqN76_w1Qg@mail.gmail.com>
References: <CAHby=D2x+7FKocM4gSpwks3_0PZN16pjMz4rz3v6cqN76_w1Qg@mail.gmail.com>
Message-ID: <CAKmUXV_JSt8=y2mAE2b-fcNc7kcUX7=sNEv7kvz37tW5bWXuqg@mail.gmail.com>

If you can address your columns by name then order shouldn't matter. If the
column order does matter, perhaps a matrix is a better structure to use?

On Sun, May 1, 2016, 10:56 AM Jan Kacaba <jan.kacaba at gmail.com> wrote:

> Hello dear R users,
>
> Is there a function or package which can insert row, column or array in
> another array at specified place (row or column)?
>
> I have made several attempts at this function optimizing both speed, code
> readability and ease of use. The functions are of following format:
>
> appcol=function(original_array, inserted_object, column_number,
> overwrite=FALSE)
>
> # If overwrite=TRUE the columns after column_number are ovewritten by
> inserted_object else the columns after column_number are shifted.
>
> Now I have started using package dplyr and it seams that there is no
> inserting function either. One can only append at the end or at the
> beginning of tbl_df. Is it true?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun May  1 21:52:27 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 1 May 2016 12:52:27 -0700
Subject: [R] Aggregate FIPS data to State and Census divisions
In-Reply-To: <CAMLwc7Ne4xd78O53S28_sLnQQKBUdBh90FPQXVqrGjhBHR886g@mail.gmail.com>
References: <CAMLwc7MYVXhg6f_PpheHTrjecp7BbiiW_3RBAVTEaJoGyme81A@mail.gmail.com>
	<CADv2QyGqrxc5Spfvvzs0fC4tJhkwmT57cyYXyqGQifDh+W5soA@mail.gmail.com>
	<CAMLwc7Ne4xd78O53S28_sLnQQKBUdBh90FPQXVqrGjhBHR886g@mail.gmail.com>
Message-ID: <65938938-CE71-44C9-AC60-A3C305113873@comcast.net>


> On May 1, 2016, at 9:30 AM, Miluji Sb <milujisb at gmail.com> wrote:
> 
> Dear Dennis,
> 
> Thank you for your reply. I can use the dplyr/data.table packages to
> aggregate - its the matching FIPS codes to their states that I am having
> trouble. Thanks again.

So post some example code that demonstrate you paid attention to the answer given. Both dplyr and data.table not limited for aggregation. They do several versions of matching. So does the base function `merge`. We do not yet know what sort of efforts you have made. r-help at r-project.org is not an online code-writing service.

-- 
David
> 
> Sincerely,
> 
> Milu
> 
> On Sun, May 1, 2016 at 6:20 PM, Dennis Murphy <djmuser at gmail.com> wrote:
> 
>> Hi:
>> 
>> Several such packages exist. Given the size of your data, it's likely
>> that the dplyr and data.table packages would be worth investigating.
>> Both are well documented.
>> 
>> Dennis
>> 
>> On Sun, May 1, 2016 at 8:30 AM, Miluji Sb <milujisb at gmail.com> wrote:
>>> Dear all,
>>> 
>>> I have the following data by US FIPS code. Is there a package to
>> aggregate
>>> the data by State and Census divisions?
>>> 
>>> temp <- dput(head(pop1,5))
>>> structure(list(FIPS = c("01001", "01003", "01005", "01007", "01009"
>>> ), death_2050A1 = c(18.19158, 101.63088, 13.18896, 10.30068,
>>> 131.91798), death_2050A2 = c(22.16349, 116.58387, 15.85324, 12.78564,
>>> 155.20506), death_2050B1 = c(21.38906, 76.23018, 21.38218, 17.14269,
>>> 151.64466), death_2050B2 = c(23.43543, 81.39378, 22.96802, 18.76926,
>>> 161.86404), death_2050BC = c(21.89947, 93.88002, 18.60352, 15.1032,
>>> 152.43414)), .Names = c("FIPS", "death_2050A1", "death_2050A2",
>>> "death_2050B1", "death_2050B2", "death_2050BC"), row.names = c(NA,
>>> 5L), class = "data.frame")
>>> 
>>> Thank you!
>>> 
>>> Sincerely,
>>> 
>>> Milu
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sun May  1 21:55:31 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 1 May 2016 12:55:31 -0700
Subject: [R] row names, coulmn names
In-Reply-To: <CAHby=D1mkfZnsWd_bZyfsfgfbCQcbimNRSF4U1TUrLB4XNqrwA@mail.gmail.com>
References: <CAHby=D1mkfZnsWd_bZyfsfgfbCQcbimNRSF4U1TUrLB4XNqrwA@mail.gmail.com>
Message-ID: <52830DE1-A9CE-42F7-9DC3-3388681FBAB5@comcast.net>


> On May 1, 2016, at 11:09 AM, Jan Kacaba <jan.kacaba at gmail.com> wrote:
> 
> Hello dear R helpers,
> 
> Is it possible to have more than 1 row for column names in data.frame,
> array, tbl_df? I would like to have column numbers in the first row, string
> names in the second row, physical unit in third row.

It's possible to embed "\n" in names but whether that will deliver desired results with plotting and printing functions may be another matter. You would always  need to quote names, even when using "$".


> How would I do it?
> 
> Derek
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sun May  1 22:02:01 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 1 May 2016 13:02:01 -0700
Subject: [R] inserting row(column) in array or dataframe at specified
	row(column)
In-Reply-To: <CAHby=D2x+7FKocM4gSpwks3_0PZN16pjMz4rz3v6cqN76_w1Qg@mail.gmail.com>
References: <CAHby=D2x+7FKocM4gSpwks3_0PZN16pjMz4rz3v6cqN76_w1Qg@mail.gmail.com>
Message-ID: <ED63BC47-30DB-430E-8CD4-9D7ECD6E76F5@comcast.net>


> On May 1, 2016, at 10:53 AM, Jan Kacaba <jan.kacaba at gmail.com> wrote:
> 
> Hello dear R users,
> 
> Is there a function or package which can insert row, column or array in
> another array at specified place (row or column)?
> 
> I have made several attempts at this function optimizing both speed, code
> readability and ease of use. The functions are of following format:
> 
> appcol=function(original_array, inserted_object, column_number,
> overwrite=FALSE)

This does not offer code, only the list of formals. If you want help with coding, then you should provide some. I remember a posting by Gabor Grothendieck on StackOverflow (where he cited another blogger) where he demonstrated how to implement a postfix "+" function like that of C, that I _think_ might address this question but without a MWE and desired result I cannot do any testing.

> 
>  If overwrite=TRUE the columns after column_number are ovewritten by
> inserted_object else the columns after column_number are shifted.
> 
> Now I have started using package dplyr and it seams that there is no
> inserting function either. One can only append at the end or at the
> beginning of tbl_df. Is it true?

Probably not. There's always:

> fortunes::fortune("Yoda")

Evelyn Hall: I would like to know how (if) I can extract some of the
information from the summary of my nlme.
Simon Blomberg: This is R. There is no if. Only how.
   -- Evelyn Hall and Simon 'Yoda' Blomberg
      R-help (April 2005)

> 	[[alternative HTML version deleted]]

One of _your_ tasks is now to learn "how" to tell gmail to post in plaintext.

-- 

David Winsemius
Alameda, CA, USA


From sidoti.23 at buckeyemail.osu.edu  Sun May  1 16:32:30 2016
From: sidoti.23 at buckeyemail.osu.edu (Sidoti, Salvatore A.)
Date: Sun, 1 May 2016 14:32:30 +0000
Subject: [R]  Spicing Up Native Circular Plot Using ggplot2
Message-ID: <CY1PR0101MB10040BAC4F5D45201E70C539AB780@CY1PR0101MB1004.prod.exchangelabs.com>

I have some angle data from an animal behavior study that I would like to plot for publication using ggplot2. What follows is my current workflow with some example data.

### BEGIN SCRIPT ###

### Create two data frames of random Cartesian coordinates ###
df1 <- data.frame(
x = sample(10, 11, replace = TRUE),
y = sample(10, 11, replace = TRUE))

df2 <- data.frame(
x = sample(10, 11, replace = TRUE),
y = sample(10, 11, replace = TRUE))

### Write a function that converts continuous Cartesian coordinates to velocities ###
get.polar <- function(df)
{
x <- diff(df$x)
y <- diff(df$y)
d <- complex(real = x, imaginary = y)
steps <- data.frame(speed = Mod(d), angle = Arg(d))
steps[-1,] # Deletes the first row as it does not contain an angle measurement
steps$time <- (1:nrow(steps))/30 # generates a time column in seconds (1 data point = 1/30 of a second)
return(steps)
}

df1_polar <- get.polar(df1)
df2_polar <- get.polar(df2)

require(circular)

### Convert angles into an object of type 'circular' ###
df1_rad <- circular(df1_polar$angle, type = 'angles', units = 'radians', zero=0, rotation = "counter")
df2_rad <- circular(df2_polar$angle, type = 'angles', units = 'radians', zero=0, rotation = "counter")

### Convert radians to degrees with a clockwise rotation and zero at "north" ###
df1_deg <- conversion.circular(df1_rad, type = "angles", units = "degrees", zero = pi/2, rotation = "clock")
df2_deg <- conversion.circular(df2_rad, type = "angles", units = "degrees", zero = pi/2, rotation = "clock")

### Convert negative rotations to positive ###
df1_deg[df1_deg < 0] <- df1_deg[df1_deg < 0] + 360 
df2_deg[df2_deg < 0] <- df2_deg[df2_deg < 0] + 360

par(pty = "s")
plot(df1_deg, units = "degrees")
ticks.circular(circular(seq(0,(11/6)*pi, pi/6)), zero = pi/2, rotation = "clock", tcl  = 0.075)
points(df2_deg, zero = pi/2, rotation = "clock", pch = 16, col = "darkgrey", next.points = -0.2)

### END SCRIPT ###

Some suggestions for turning this rough plot into something publishable using ggplot2?

Thank you!
Salvatore A. Sidoti


From syen04 at gmail.com  Mon May  2 00:01:26 2016
From: syen04 at gmail.com (Steven Yen)
Date: Sun, 1 May 2016 18:01:26 -0400
Subject: [R] Retrieving response variable in the probit
Message-ID: <CAKTtY6TXEW8c1M0oTNVgfeP-_uqVrVP9e06u+QFmoZrBdyTphQ@mail.gmail.com>

Can anyone tell me how to retrieve the response (dependent) variable
from a probit regression object (as much as model.matrix(obj)
retrieves the data matrix). Below is a self-runnable set of codes.
Thank you!

library(sampleSelection)
data<-read.csv("https://dl.dropboxusercontent.com/u/220037024/Yen/data/pta.csv")
eq1<-d~sex+age+educ
p1<-probit(eq1,data=data)
summary(p1)
attributes(p1)


From parsifalblake at gmail.com  Mon May  2 01:59:23 2016
From: parsifalblake at gmail.com (Judson Blake)
Date: Sun, 1 May 2016 19:59:23 -0400
Subject: [R] Order of bars w geom_errorbarh ??
Message-ID: <CAOrp6CfNCNXBYLyVgUC1-qB6M9KHKbXZ96wbCCNuqZDRpE7T_w@mail.gmail.com>

Using geom_errorbarh with ggplot, my plot has several error bars.   For my
presentation, the order of these bars from top to bottom is important.
But errorbarh seems to put these in a random order I can't change.  ( It
does not follow the order in the data.frame. )    How can I specify the
order of the bars?   Could I also specify the thickness of the bar lines?

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon May  2 10:34:47 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 2 May 2016 08:34:47 +0000
Subject: [R] inserting row(column) in array or dataframe at
	specified	row(column)
In-Reply-To: <CAHby=D2x+7FKocM4gSpwks3_0PZN16pjMz4rz3v6cqN76_w1Qg@mail.gmail.com>
References: <CAHby=D2x+7FKocM4gSpwks3_0PZN16pjMz4rz3v6cqN76_w1Qg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C502A00A@SRVEXCHMBX.precheza.cz>

Hi

You can use rbind, cbind but you need to be aware of what objects you are binding together.

mm<-matrix(rnorm(12), 3,4)
> rbind(mm[1:2,], 1:4, mm[3,])
           [,1]       [,2]       [,3]       [,4]
[1,] -0.2029407 -1.5910628 -0.2582281 -0.1649921
[2,] -0.6913951  0.3591561  0.8236836 -0.3592203
[3,]  1.0000000  2.0000000  3.0000000  4.0000000
[4,] -0.2096650 -2.3671913 -0.4444438  0.3846274

Anyway, you can append rows/columns and perform sort/order afterwards if you consider ordering important.

Cheers
Petr




> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jan Kacaba
> Sent: Sunday, May 1, 2016 7:54 PM
> To: r-help at r-project.org
> Subject: [R] inserting row(column) in array or dataframe at specified
> row(column)
>
> Hello dear R users,
>
> Is there a function or package which can insert row, column or array in
> another array at specified place (row or column)?
>
> I have made several attempts at this function optimizing both speed, code
> readability and ease of use. The functions are of following format:
>
> appcol=function(original_array, inserted_object, column_number,
> overwrite=FALSE)
>
> # If overwrite=TRUE the columns after column_number are ovewritten by
> inserted_object else the columns after column_number are shifted.
>
> Now I have started using package dplyr and it seams that there is no inserting
> function either. One can only append at the end or at the beginning of
> tbl_df. Is it true?
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From maechler at stat.math.ethz.ch  Mon May  2 10:49:20 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 2 May 2016 10:49:20 +0200
Subject: [R] Removing NAs from dataframe  (for use in Vioplot)
In-Reply-To: <1805593311.20160501081544@hsm.org.uk>
References: <142423783.20160430205840@hsm.org.uk>
	<1D7DB03F-C03B-48E4-B508-6C23406F26A2@comcast.net>
	<39FB27E5-65B5-4388-9849-02ABE585BC4D@comcast.net>
	<1805593311.20160501081544@hsm.org.uk>
Message-ID: <22311.5264.327599.172488@stat.math.ethz.ch>

>>>>> Mike Smith <mike at hsm.org.uk>
>>>>>     on Sun, 1 May 2016 08:15:44 +0100 writes:

    >>>> On Apr 30, 2016, at 12:58 PM, Mike Smith
    >>>> <mike at hsm.org.uk> wrote: Hi

    >>>> First post and a relative R newbie....

    >>>> I am using the vioplot library to produce some violin
    >>>> plots.

    DW> It's a package, .... not a library.

[yes!]


    >>>> 1. Is there a more elegant way of automatically
    >>>> stripping the NAs, passing the columns to the function
    >>>> along with the header names??

    >>> ds2 <- lapply( ds1, na.omit)


    > Fantastic - that does the trick! Easy when you know how!!

    > Follow-on: is there a way feed all the lists from ds2 to
    > vioplot? It is now a series of lists (rather than a
    > dataframe - is that right?).

Yes, that's right.  So after all the above was not really
perfect :

  na.omit() has been designed as a generic function and has always
  had a method for "data.frame"; so, really

    ds.noNA <- na.omit(ds1)
or  ds0NA   <- na.omit(ds1)

(choosing "expressive names")

is what you want.


From Achim.Zeileis at uibk.ac.at  Mon May  2 11:14:09 2016
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Mon, 2 May 2016 11:14:09 +0200 (CEST)
Subject: [R] Retrieving response variable in the probit
In-Reply-To: <CAKTtY6TXEW8c1M0oTNVgfeP-_uqVrVP9e06u+QFmoZrBdyTphQ@mail.gmail.com>
References: <CAKTtY6TXEW8c1M0oTNVgfeP-_uqVrVP9e06u+QFmoZrBdyTphQ@mail.gmail.com>
Message-ID: <alpine.DEB.2.20.1605021113190.9929@paninaro>

On Mon, 2 May 2016, Steven Yen wrote:

> Can anyone tell me how to retrieve the response (dependent) variable
> from a probit regression object (as much as model.matrix(obj)
> retrieves the data matrix). Below is a self-runnable set of codes.
> Thank you!
>
> library(sampleSelection)
> data<-read.csv("https://dl.dropboxusercontent.com/u/220037024/Yen/data/pta.csv")
> eq1<-d~sex+age+educ
> p1<-probit(eq1,data=data)
> summary(p1)
> attributes(p1)

model.frame(p1)

recovers the (possibly transformed) data employed for fitting the model 
and

model.response(model.frame(p1))

extracts the response variable from that model frame.

> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From drjimlemon at gmail.com  Mon May  2 11:58:13 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 2 May 2016 19:58:13 +1000
Subject: [R] How to print the frequency table (produced by the command
 "table" to Excel
In-Reply-To: <CABcx46CwPnejdpYYYxpuPh-71hPv1Zf0noiTW3tZ_qwou_4Qzw@mail.gmail.com>
References: <CABcx46D_isFkbjCB_uN-epssdoOsnyx34uu7ey-aQHkkWOkk2Q@mail.gmail.com>
	<CA+8X3fVbX1ptDr_xaaQyCrbskqQNqBS0mN8fm8Utm-y2rnbfwA@mail.gmail.com>
	<CABcx46AsBxGTurGu9hJ9+XUFg+o0hyQYt6k=qiP4TWJWQc=imQ@mail.gmail.com>
	<CA+8X3fWC_Uj1oOhmVag=Nh8rorL2Mb=Khq3-JOrDCk8-BvOt1w@mail.gmail.com>
	<CABcx46CwPnejdpYYYxpuPh-71hPv1Zf0noiTW3tZ_qwou_4Qzw@mail.gmail.com>
Message-ID: <CA+8X3fWOn=y8DmD0T96Uw=dT8doBiDfuLz2=K71RnBVMShDcJA@mail.gmail.com>

Hi jpm miao,
After a fair stretch of fooling around with it, I can't see any way to
add the variable names ("varnames") to the output of delim.table
without breaking it for things other than table objects. You can
probably do this as a one-off hack by setting the names of the
dimnames of the "counts" element in alphatab like this:

names(dimnames(alphatab$counts))<-alphatab$varnames

You can then shoehorn these into the output by adding a line to
display the second varname above the table and add the first varname
to the row of value labels. That's the best I can do at the moment.

Jim


On Sun, May 1, 2016 at 11:19 AM, jpm miao <miaojpm at gmail.com> wrote:
> Thanks.
> Could we print the row/column names, "alpha1" and "alpha2" to the csv file?
>
> 2016-04-30 17:06 GMT-07:00 Jim Lemon <drjimlemon at gmail.com>:
>>
>> Hi jpm miao,
>> I think you can get what you want like this:
>>
>> alpha1<-sample(LETTERS[1:3],50,TRUE)
>> alpha2<-sample(LETTERS[1:2],50,TRUE)
>> alphas<-data.frame(alpha1,alpha2)
>> library(prettyR)
>> alphatab<-xtab(alpha1~alpha2,alphas)
>> sink("temp_table3.csv",append=TRUE)
>> delim.xtab(alphatab,pct=NA,delim=",")
>> sink()
>>
>> Jim
>>
>> On Sun, May 1, 2016 at 4:47 AM, jpm miao <miaojpm at gmail.com> wrote:
>> > Jim,
>> >
>> >    Thanks for creating such a fantastic package "prettyR".
>> >    I want to print the pretty frequency table (with row total and column
>> > total) to an excel (or csv ) file. Is it possible?
>> >>alphatab
>> >
>> > A B Total
>> > A 8 10 18
>> > B 7 5 12
>> > C 9 11 20
>> > Total 24 26 50
>> >
>> >    Two issues I encountered (See the attached csv file).
>> > 1. When I tried to print the above table to csv file, all elements on
>> > the
>> > same row are printed in one cell.
>> > 2. If I write "delim.table(alpha tab)", the table is distorted (see
>> > attached). Of course, I can adjust it manually but sometimes the number
>> > of
>> > files is big.
>> >
>> >     Thanks!
>> >
>> > Miao
>> >
>> >> alpha1<-sample(LETTERS[1:3],50,TRUE)
>> >> alpha2<-sample(LETTERS[1:2],50,TRUE)
>> >>
>> >> alphas<-data.frame(alpha1,alpha2)
>> >> alphatab<-xtab(alpha1~alpha2,alphas)
>> > Crosstabulation of alpha1 by alpha2
>> > alpha2
>> > alpha1      A      B
>> > A      8     10     18
>> >    44.44  55.56      -
>> >    33.33  38.46  36.00
>> >
>> > B      7      5     12
>> >    58.33  41.67      -
>> >    29.17  19.23  24.00
>> >
>> > C      9     11     20
>> >       45     55      -
>> >    37.50  42.31  40.00
>> >
>> >       24     26     50
>> >       48     52    100
>> >> delim.xtab(alphatab,pct=NA,interdigitate=TRUE)
>> > alphatab
>> >
>> > A B Total
>> > A 8 10 18
>> > B 7 5 12
>> > C 9 11 20
>> > Total 24 26 50
>> >
>> >> sink("temp_table3.csv")
>> >> delim.xtab(alphatab,pct=NA,interdigitate=TRUE)
>> >> sink()
>> >> sink("temp_table3.csv", append=TRUE)
>> >> delim.table(alphatab)
>> >> sink()
>> >> sink("temp_table3.csv", append=TRUE)
>> >> delim.table(alphatab)
>> >> sink()
>> >> ?delim.xtab
>> >
>> >
>> > 2016-04-26 16:14 GMT-07:00 Jim Lemon <drjimlemon at gmail.com>:
>> >>
>> >> Hi jpm miao,
>> >> You can get CSV files that can be imported into Excel like this:
>> >>
>> >> library(prettyR)
>> >> sink("excel_table1.csv")
>> >> delim.table(table(df[,c("y","z")]))
>> >> sink()
>> >> sink("excel_table2.csv")
>> >> delim.table(as.data.frame(table(df[,c("y","z")])),label="")
>> >> sink()
>> >> sink("excel_table3.csv")
>> >> delim.table(as.matrix(table(df[,c("y","z")])),label="")
>> >> sink()
>> >>
>> >> Jim
>> >>
>> >> On Wed, Apr 27, 2016 at 8:35 AM, jpm miao <miaojpm at gmail.com> wrote:
>> >> > Hi,
>> >> >
>> >> >    How could we print the frequency table (produced by "table") to an
>> >> > Excel
>> >> > file?
>> >> >    Is there an easy way to do so? Thanks,
>> >> >
>> >> > Miao
>> >> >
>> >> >> df <- data.frame(x = 1:3, y = 3:1, z = letters[1:3])
>> >> >
>> >> >> table(df[,c("y","z")])
>> >> >    z
>> >> > y   a b c
>> >> >   1 0 0 1
>> >> >   2 0 1 0
>> >> >   3 1 0 0
>> >> >> test<-table(df[,c("y","z")])
>> >> >> as.data.frame(test)
>> >> >   y z Freq
>> >> > 1 1 a    0
>> >> > 2 2 a    0
>> >> > 3 3 a    1
>> >> > 4 1 b    0
>> >> > 5 2 b    1
>> >> > 6 3 b    0
>> >> > 7 1 c    1
>> >> > 8 2 c    0
>> >> > 9 3 c    0
>> >> >> as.matrix(test)
>> >> >    z
>> >> > y   a b c
>> >> >   1 0 0 1
>> >> >   2 0 1 0
>> >> >   3 1 0 0
>> >> >> testm<-as.matrix(test)
>> >> >> testm
>> >> >    z
>> >> > y   a b c
>> >> >   1 0 0 1
>> >> >   2 0 1 0
>> >> >   3 1 0 0
>> >> >> typeof(testm)
>> >> > [1] "integer"
>> >> >
>> >> >         [[alternative HTML version deleted]]
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide
>> >> > http://www.R-project.org/posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>
>


From chalabi.elahe at yahoo.de  Mon May  2 12:43:25 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Mon, 2 May 2016 10:43:25 +0000 (UTC)
Subject: [R] how to use AND in grepl
In-Reply-To: <CAKmUXV_nabMZpm_Q4RxvZayamwko+40shFdYv=P-ag5N8rsP+w@mail.gmail.com>
References: <CAKmUXV_nabMZpm_Q4RxvZayamwko+40shFdYv=P-ag5N8rsP+w@mail.gmail.com>
Message-ID: <1327157538.9214923.1462185805140.JavaMail.yahoo@mail.yahoo.com>

Thanks for your reply tom. After using  Subset(df,grepl("(.*t2.*pd.*)|(.*pd.*t2.*)"),df$Command)  I get this error: Argument "x" is missing, with no default. Actually I don't know how to fix this. Do you have any idea?
Thanks,
Elahe 


On Saturday, April 30, 2016 7:35 PM, Tom Wright <tom at maladmin.com> wrote:



Actually not sure my previous answer does what you wanted. Using your approach:
 t2pd=subset(df,grepl("t2",df$Command) & grepl("pd",df$Command))
Should work.
I think the regex pattern you are looking for is:
 Subset(df,grepl("(.* t2.*pd.* )|(.* pd.* t2.*)",df$Command)

On Sat, Apr 30, 2016, 7:07 PM Tom Wright <tom at maladmin.com> wrote:

subset(df,grepl("t2|pd",x$Command))
>
>
>
>
>On Sat, Apr 30, 2016 at 2:38 PM, ch.elahe via R-help <r-help at r-project.org> wrote:
>
>Hi all,
>>
>>I have one factor variable in my df and I want to extract the names from it which contain both "t2" and "pd":
>>
>>  'data.frame': 36919 obs. of 162 variables
>>   $TE                :int 38,41,11,52,48,75,.....
>>   $TR                :int 100,210,548,546,.....
>>   $Command          :factor W/2229 levels "_localize_PD","_localize_tre_t2","_abdomen_t1_seq","knee_pd_t1_localize","pd_local_abdomen_t2"...
>>
>>I have tried this but I did not get result:
>>
>>  t2pd=subset(df,grepl("t2",Command) & grepl("pd",Command))
>>
>>
>>does anyone know how to apply AND in grepl?
>>
>>Thanks
>>Elahe
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>>.


From pdalgd at gmail.com  Mon May  2 14:03:09 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 2 May 2016 14:03:09 +0200
Subject: [R] how to use AND in grepl
In-Reply-To: <1327157538.9214923.1462185805140.JavaMail.yahoo@mail.yahoo.com>
References: <CAKmUXV_nabMZpm_Q4RxvZayamwko+40shFdYv=P-ag5N8rsP+w@mail.gmail.com>
	<1327157538.9214923.1462185805140.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <C9BAD7E6-7E7E-472A-9512-A68E55738602@gmail.com>


On 02 May 2016, at 12:43 , ch.elahe via R-help <r-help at r-project.org> wrote:

> Thanks for your reply tom. After using  Subset(df,grepl("(.*t2.*pd.*)|(.*pd.*t2.*)"),df$Command)  I get this error: Argument "x" is missing, with no default. Actually I don't know how to fix this. Do you have any idea?

Tom's code was missing a ")" but not where you put one. He probably also didn't intend to capitalize "subset".

-pd

> Thanks,
> Elahe 
> 
> 
> On Saturday, April 30, 2016 7:35 PM, Tom Wright <tom at maladmin.com> wrote:
> 
> 
> 
> Actually not sure my previous answer does what you wanted. Using your approach:
> t2pd=subset(df,grepl("t2",df$Command) & grepl("pd",df$Command))
> Should work.
> I think the regex pattern you are looking for is:
> Subset(df,grepl("(.* t2.*pd.* )|(.* pd.* t2.*)",df$Command)
> 
> On Sat, Apr 30, 2016, 7:07 PM Tom Wright <tom at maladmin.com> wrote:
> 
> subset(df,grepl("t2|pd",x$Command))
>> 
>> 
>> 
>> 
>> On Sat, Apr 30, 2016 at 2:38 PM, ch.elahe via R-help <r-help at r-project.org> wrote:
>> 
>> Hi all,
>>> 
>>> I have one factor variable in my df and I want to extract the names from it which contain both "t2" and "pd":
>>> 
>>> 'data.frame': 36919 obs. of 162 variables
>>>  $TE                :int 38,41,11,52,48,75,.....
>>>  $TR                :int 100,210,548,546,.....
>>>  $Command          :factor W/2229 levels "_localize_PD","_localize_tre_t2","_abdomen_t1_seq","knee_pd_t1_localize","pd_local_abdomen_t2"...
>>> 
>>> I have tried this but I did not get result:
>>> 
>>> t2pd=subset(df,grepl("t2",Command) & grepl("pd",Command))
>>> 
>>> 
>>> does anyone know how to apply AND in grepl?
>>> 
>>> Thanks
>>> Elahe
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> .
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jdnewmil at dcn.davis.ca.us  Mon May  2 14:42:42 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 02 May 2016 05:42:42 -0700
Subject: [R] Order of bars w geom_errorbarh ??
In-Reply-To: <CAOrp6CfNCNXBYLyVgUC1-qB6M9KHKbXZ96wbCCNuqZDRpE7T_w@mail.gmail.com>
References: <CAOrp6CfNCNXBYLyVgUC1-qB6M9KHKbXZ96wbCCNuqZDRpE7T_w@mail.gmail.com>
Message-ID: <EA413B8F-C778-40D0-B1D9-3B115BC463A5@dcn.davis.ca.us>

Ordering of any discrete values in ggplot goes according to the levels of the factor. As a convenience, ggplot will convert character values into factor for you according to the default order alphabetical). To take control of this you have to convert your discrete columns to factors yourself before giving the data to ggplot, e.g.

DF$somecol  <- factor( DF$somecol, levels=c("level1","level2",...) )

However, if you pull data from different factors in different input tables, ggplot has to combine them internally, and you will lose your specified ordering. With no minimum reproducible example I cannot tell whether that is a problem for you,  but the solution would be to combine them yourself before you give them to ggplot.
-- 
Sent from my phone. Please excuse my brevity.

On May 1, 2016 4:59:23 PM PDT, Judson Blake <parsifalblake at gmail.com> wrote:
>Using geom_errorbarh with ggplot, my plot has several error bars.   For
>my
>presentation, the order of these bars from top to bottom is important.
>But errorbarh seems to put these in a random order I can't change.  (
>It
>does not follow the order in the data.frame. )    How can I specify the
>order of the bars?   Could I also specify the thickness of the bar
>lines?
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon May  2 15:20:52 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 2 May 2016 06:20:52 -0700
Subject: [R] Removing NAs from dataframe (for use in Vioplot)
In-Reply-To: <22311.5264.327599.172488@stat.math.ethz.ch>
References: <142423783.20160430205840@hsm.org.uk>
	<1D7DB03F-C03B-48E4-B508-6C23406F26A2@comcast.net>
	<39FB27E5-65B5-4388-9849-02ABE585BC4D@comcast.net>
	<1805593311.20160501081544@hsm.org.uk>
	<22311.5264.327599.172488@stat.math.ethz.ch>
Message-ID: <CAGxFJbSGO6TBFip_c+KfnRtYs=boTH1UhPAOB+qGoa4arUAUXg@mail.gmail.com>

Martin et. al.:

na.omit(frame) will remove all rows/cases in which an NA occurs.  I'm
not sure that this is what the OP wanted, which seemed to be to
separately remove NA's from each column and plot the resulting column.
This is what the lapply (and the OP's provided code) does, anyway.

Also, lapply() produces a single list (of vectors), not a "series of lists" .

Corrections happily accepted if I'm in error.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, May 2, 2016 at 1:49 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Mike Smith <mike at hsm.org.uk>
>>>>>>     on Sun, 1 May 2016 08:15:44 +0100 writes:
>
>     >>>> On Apr 30, 2016, at 12:58 PM, Mike Smith
>     >>>> <mike at hsm.org.uk> wrote: Hi
>
>     >>>> First post and a relative R newbie....
>
>     >>>> I am using the vioplot library to produce some violin
>     >>>> plots.
>
>     DW> It's a package, .... not a library.
>
> [yes!]
>
>
>     >>>> 1. Is there a more elegant way of automatically
>     >>>> stripping the NAs, passing the columns to the function
>     >>>> along with the header names??
>
>     >>> ds2 <- lapply( ds1, na.omit)
>
>
>     > Fantastic - that does the trick! Easy when you know how!!
>
>     > Follow-on: is there a way feed all the lists from ds2 to
>     > vioplot? It is now a series of lists (rather than a
>     > dataframe - is that right?).
>
> Yes, that's right.  So after all the above was not really
> perfect :
>
>   na.omit() has been designed as a generic function and has always
>   had a method for "data.frame"; so, really
>
>     ds.noNA <- na.omit(ds1)
> or  ds0NA   <- na.omit(ds1)
>
> (choosing "expressive names")
>
> is what you want.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon May  2 15:30:24 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 2 May 2016 06:30:24 -0700
Subject: [R] How to print the frequency table (produced by the command
 "table" to Excel
In-Reply-To: <CA+8X3fWOn=y8DmD0T96Uw=dT8doBiDfuLz2=K71RnBVMShDcJA@mail.gmail.com>
References: <CABcx46D_isFkbjCB_uN-epssdoOsnyx34uu7ey-aQHkkWOkk2Q@mail.gmail.com>
	<CA+8X3fVbX1ptDr_xaaQyCrbskqQNqBS0mN8fm8Utm-y2rnbfwA@mail.gmail.com>
	<CABcx46AsBxGTurGu9hJ9+XUFg+o0hyQYt6k=qiP4TWJWQc=imQ@mail.gmail.com>
	<CA+8X3fWC_Uj1oOhmVag=Nh8rorL2Mb=Khq3-JOrDCk8-BvOt1w@mail.gmail.com>
	<CABcx46CwPnejdpYYYxpuPh-71hPv1Zf0noiTW3tZ_qwou_4Qzw@mail.gmail.com>
	<CA+8X3fWOn=y8DmD0T96Uw=dT8doBiDfuLz2=K71RnBVMShDcJA@mail.gmail.com>
Message-ID: <CAGxFJbRfZKRhFdOsN03d1gzJi+fqFOLztB7=51Hp8+a3SjcLOA@mail.gmail.com>

Don't know if this would help, but you could always set an attribute
of alphatab to be the dimnames. See ?attrib . Of course you would then
have to write a custom print() function, possibly along the lines you
indicated.

You could also do this via S3 (or whatever) classes, of course. But
again, none of this may be the sort of thing the OP could handle.
Maybe my point is by improving her(?) R programming skills, she would
gain the ability to do all sorts of such "customizations".

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, May 2, 2016 at 2:58 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi jpm miao,
> After a fair stretch of fooling around with it, I can't see any way to
> add the variable names ("varnames") to the output of delim.table
> without breaking it for things other than table objects. You can
> probably do this as a one-off hack by setting the names of the
> dimnames of the "counts" element in alphatab like this:
>
> names(dimnames(alphatab$counts))<-alphatab$varnames
>
> You can then shoehorn these into the output by adding a line to
> display the second varname above the table and add the first varname
> to the row of value labels. That's the best I can do at the moment.
>
> Jim
>
>
> On Sun, May 1, 2016 at 11:19 AM, jpm miao <miaojpm at gmail.com> wrote:
>> Thanks.
>> Could we print the row/column names, "alpha1" and "alpha2" to the csv file?
>>
>> 2016-04-30 17:06 GMT-07:00 Jim Lemon <drjimlemon at gmail.com>:
>>>
>>> Hi jpm miao,
>>> I think you can get what you want like this:
>>>
>>> alpha1<-sample(LETTERS[1:3],50,TRUE)
>>> alpha2<-sample(LETTERS[1:2],50,TRUE)
>>> alphas<-data.frame(alpha1,alpha2)
>>> library(prettyR)
>>> alphatab<-xtab(alpha1~alpha2,alphas)
>>> sink("temp_table3.csv",append=TRUE)
>>> delim.xtab(alphatab,pct=NA,delim=",")
>>> sink()
>>>
>>> Jim
>>>
>>> On Sun, May 1, 2016 at 4:47 AM, jpm miao <miaojpm at gmail.com> wrote:
>>> > Jim,
>>> >
>>> >    Thanks for creating such a fantastic package "prettyR".
>>> >    I want to print the pretty frequency table (with row total and column
>>> > total) to an excel (or csv ) file. Is it possible?
>>> >>alphatab
>>> >
>>> > A B Total
>>> > A 8 10 18
>>> > B 7 5 12
>>> > C 9 11 20
>>> > Total 24 26 50
>>> >
>>> >    Two issues I encountered (See the attached csv file).
>>> > 1. When I tried to print the above table to csv file, all elements on
>>> > the
>>> > same row are printed in one cell.
>>> > 2. If I write "delim.table(alpha tab)", the table is distorted (see
>>> > attached). Of course, I can adjust it manually but sometimes the number
>>> > of
>>> > files is big.
>>> >
>>> >     Thanks!
>>> >
>>> > Miao
>>> >
>>> >> alpha1<-sample(LETTERS[1:3],50,TRUE)
>>> >> alpha2<-sample(LETTERS[1:2],50,TRUE)
>>> >>
>>> >> alphas<-data.frame(alpha1,alpha2)
>>> >> alphatab<-xtab(alpha1~alpha2,alphas)
>>> > Crosstabulation of alpha1 by alpha2
>>> > alpha2
>>> > alpha1      A      B
>>> > A      8     10     18
>>> >    44.44  55.56      -
>>> >    33.33  38.46  36.00
>>> >
>>> > B      7      5     12
>>> >    58.33  41.67      -
>>> >    29.17  19.23  24.00
>>> >
>>> > C      9     11     20
>>> >       45     55      -
>>> >    37.50  42.31  40.00
>>> >
>>> >       24     26     50
>>> >       48     52    100
>>> >> delim.xtab(alphatab,pct=NA,interdigitate=TRUE)
>>> > alphatab
>>> >
>>> > A B Total
>>> > A 8 10 18
>>> > B 7 5 12
>>> > C 9 11 20
>>> > Total 24 26 50
>>> >
>>> >> sink("temp_table3.csv")
>>> >> delim.xtab(alphatab,pct=NA,interdigitate=TRUE)
>>> >> sink()
>>> >> sink("temp_table3.csv", append=TRUE)
>>> >> delim.table(alphatab)
>>> >> sink()
>>> >> sink("temp_table3.csv", append=TRUE)
>>> >> delim.table(alphatab)
>>> >> sink()
>>> >> ?delim.xtab
>>> >
>>> >
>>> > 2016-04-26 16:14 GMT-07:00 Jim Lemon <drjimlemon at gmail.com>:
>>> >>
>>> >> Hi jpm miao,
>>> >> You can get CSV files that can be imported into Excel like this:
>>> >>
>>> >> library(prettyR)
>>> >> sink("excel_table1.csv")
>>> >> delim.table(table(df[,c("y","z")]))
>>> >> sink()
>>> >> sink("excel_table2.csv")
>>> >> delim.table(as.data.frame(table(df[,c("y","z")])),label="")
>>> >> sink()
>>> >> sink("excel_table3.csv")
>>> >> delim.table(as.matrix(table(df[,c("y","z")])),label="")
>>> >> sink()
>>> >>
>>> >> Jim
>>> >>
>>> >> On Wed, Apr 27, 2016 at 8:35 AM, jpm miao <miaojpm at gmail.com> wrote:
>>> >> > Hi,
>>> >> >
>>> >> >    How could we print the frequency table (produced by "table") to an
>>> >> > Excel
>>> >> > file?
>>> >> >    Is there an easy way to do so? Thanks,
>>> >> >
>>> >> > Miao
>>> >> >
>>> >> >> df <- data.frame(x = 1:3, y = 3:1, z = letters[1:3])
>>> >> >
>>> >> >> table(df[,c("y","z")])
>>> >> >    z
>>> >> > y   a b c
>>> >> >   1 0 0 1
>>> >> >   2 0 1 0
>>> >> >   3 1 0 0
>>> >> >> test<-table(df[,c("y","z")])
>>> >> >> as.data.frame(test)
>>> >> >   y z Freq
>>> >> > 1 1 a    0
>>> >> > 2 2 a    0
>>> >> > 3 3 a    1
>>> >> > 4 1 b    0
>>> >> > 5 2 b    1
>>> >> > 6 3 b    0
>>> >> > 7 1 c    1
>>> >> > 8 2 c    0
>>> >> > 9 3 c    0
>>> >> >> as.matrix(test)
>>> >> >    z
>>> >> > y   a b c
>>> >> >   1 0 0 1
>>> >> >   2 0 1 0
>>> >> >   3 1 0 0
>>> >> >> testm<-as.matrix(test)
>>> >> >> testm
>>> >> >    z
>>> >> > y   a b c
>>> >> >   1 0 0 1
>>> >> >   2 0 1 0
>>> >> >   3 1 0 0
>>> >> >> typeof(testm)
>>> >> > [1] "integer"
>>> >> >
>>> >> >         [[alternative HTML version deleted]]
>>> >> >
>>> >> > ______________________________________________
>>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> > PLEASE do read the posting guide
>>> >> > http://www.R-project.org/posting-guide.html
>>> >> > and provide commented, minimal, self-contained, reproducible code.
>>> >
>>> >
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From swagatam1987 at gmail.com  Mon May  2 10:55:20 2016
From: swagatam1987 at gmail.com (Swagatam Basu)
Date: Mon, 2 May 2016 14:25:20 +0530
Subject: [R] Help regarding Community Detection Algorithm in R (like
	Propagation, Walktrap)
Message-ID: <CALk0NBuADj9Jc44tPNBS3WKyHxmG4pqF5WajDNpQ0F1rfU6gdQ@mail.gmail.com>

Hi

I am very new to R studio and R language. I have installed the R studio in
my machine.

I need to do a community detection of a set of message. I have a Matrix for
that.

Is there any sample code /Package/ website is present which will help me to
understand/do this community Detection (like Propagation, Walk trap
Algorithm) in R-language by using R-studio.

Please help.

Please revert back in case of any discrepencies.

Thanks
S Basu

	[[alternative HTML version deleted]]


From purvakulkarni7 at gmail.com  Mon May  2 13:48:30 2016
From: purvakulkarni7 at gmail.com (Purva Kulkarni)
Date: Mon, 2 May 2016 13:48:30 +0200
Subject: [R] Rserve() error in the first instance of running a Java
	application
Message-ID: <C32C152F-ED73-4B77-A4C1-4D0BBABC0BC5@gmail.com>

Hi, 

I am writing a Java GUI application which uses Rserve(). I have a java script which sends a command to the shell to start Rserve(). When I run the Java main method for the very first time, it calls this script to invoke Rserve() and starts Rserve(). But, in this first run the Java GUI application is not launched. But, when I run the main method for the second time, I get the following message and the GUI application is launched. 

##> SOCK_ERROR: bind error #48(address already in use)

I do not understand this behaviour. From what I can understand, in the first run, the script just establishes the Rserve() connection and then in the second run it works. Can someone help me fix this, so that program connects to Rserve() in the first instance and also launches the GUI?

Here my Java class containing the method to invoke Rserve():

public class InvokeRserve {
    public static int invoke() {
        String s;

        try {

            // run the Unix "ps -ef" command
            // using the Runtime exec method:
            Process p = Runtime.getRuntime().exec("R CMD RServe --vanilla");

            BufferedReader stdInput = new BufferedReader(new
                    InputStreamReader(p.getInputStream()));

            BufferedReader stdError = new BufferedReader(new
                    InputStreamReader(p.getErrorStream()));

            // read the output from the command
            System.out.println("Here is the standard output of the command:\n");
            while ((s = stdInput.readLine()) != null) {
                System.out.println(s);
            }

            // read any errors from the attempted command
            System.out.println("Here is the standard error of the command (if any):\n");
            while ((s = stdError.readLine()) != null) {
                System.out.println(s);
            }

            //  System.exit(0);

        }
        catch (IOException e) {
            System.out.println("exception happened - here's what I know: ");
            e.printStackTrace();
            System.exit(-1);
        }
        return 1;
    }


Here is the main method which calls the invoke() method:

public class Application {
    /**
     * Main method for the Swing application
     *
     * @param args
     * @throws Exception
     */
    public static void main(String[] args) throws Exception {

        // Start Rserve()
        int value = InvokeRserve.invoke();

        if(value == 1) {
            // Run the GUI construction in the Event-Dispatching thread for thread-safety
            SwingUtilities.invokeLater(new Runnable() {

                /**
                 * run method which create a new GUIMain object
                 */
                @Override
                public void run() {
                    new GUIMain(?Data Analysis Application?); // Let the constructor do the job
                }
            });
        }
    }
}


From Kushank.chhabra at iontrading.com  Mon May  2 14:36:54 2016
From: Kushank.chhabra at iontrading.com (Kushank Chhabra)
Date: Mon, 2 May 2016 18:06:54 +0530
Subject: [R] Network Layouting in R
Message-ID: <4b8726c399d1f4fbd4ed916623cd2def@mail.gmail.com>

Hi,



I am trying to plot a network diagram of around 1500 component (as nodes)
and many connections (as edges) within them.



I tried igraph package, however unable to create a layout where there is no
overlap of nodes or edges.



More or less tried all the things mentioned in this link -

http://kateto.net/network-visualization



Can you please suggest how to do it in R ?



Output expected ? A good layout of the network diagram (of around 1500
nodes) with no overlaps of nodes or even edges and possibly it can be
screened as a picture, or on a browser or on a pdf.



With Best Regards,

Kushank

	[[alternative HTML version deleted]]


From chalabi.elahe at yahoo.de  Mon May  2 16:42:29 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Mon, 2 May 2016 14:42:29 +0000 (UTC)
Subject: [R] how to use AND in grepl
In-Reply-To: <C9BAD7E6-7E7E-472A-9512-A68E55738602@gmail.com>
References: <C9BAD7E6-7E7E-472A-9512-A68E55738602@gmail.com>
Message-ID: <1066416646.9317980.1462200149389.JavaMail.yahoo@mail.yahoo.com>

Thanks Peter, you were right, the exact grepl is grepl("(.*t2.*pd.*)|(.*pd.*t2.*)",df$Command), but it does not change anything in Command, when I check the size of it by sum(grepl("(.*t2.*pd.*)|(.*pd.*t2.*)",df$Command))  the result is 0, but I am sure that the size is not 0. It seems that this AND does not work.
 

On Monday, May 2, 2016 5:05 AM, peter dalgaard <pdalgd at gmail.com> wrote:

On 02 May 2016, at 12:43 , ch.elahe via R-help <r-help at r-project.org> wrote:

> Thanks for your reply tom. After using  Subset(df,grepl("(.*t2.*pd.*)|(.*pd.*t2.*)"),df$Command)  I get this error: Argument "x" is missing, with no default. Actually I don't know how to fix this. Do you have any idea?

Tom's code was missing a ")" but not where you put one. He probably also didn't intend to capitalize "subset".


-pd

> Thanks,
> Elahe 
> 
> 
> On Saturday, April 30, 2016 7:35 PM, Tom Wright <tom at maladmin.com> wrote:
> 
> 
> 
> Actually not sure my previous answer does what you wanted. Using your approach:
> t2pd=subset(df,grepl("t2",df$Command) & grepl("pd",df$Command))
> Should work.
> I think the regex pattern you are looking for is:
> Subset(df,grepl("(.* t2.*pd.* )|(.* pd.* t2.*)",df$Command)
> 
> On Sat, Apr 30, 2016, 7:07 PM Tom Wright <tom at maladmin.com> wrote:
> 
> subset(df,grepl("t2|pd",x$Command))
>> 
>> 
>> 
>> 
>> On Sat, Apr 30, 2016 at 2:38 PM, ch.elahe via R-help <r-help at r-project.org> wrote:
>> 
>> Hi all,
>>> 
>>> I have one factor variable in my df and I want to extract the names from it which contain both "t2" and "pd":
>>> 
>>> 'data.frame': 36919 obs. of 162 variables
>>>  $TE                :int 38,41,11,52,48,75,.....
>>>  $TR                :int 100,210,548,546,.....
>>>  $Command          :factor W/2229 levels "_localize_PD","_localize_tre_t2","_abdomen_t1_seq","knee_pd_t1_localize","pd_local_abdomen_t2"...
>>> 
>>> I have tried this but I did not get result:
>>> 
>>> t2pd=subset(df,grepl("t2",Command) & grepl("pd",Command))
>>> 
>>> 
>>> does anyone know how to apply AND in grepl?
>>> 
>>> Thanks
>>> Elahe
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> .
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From sarah.goslee at gmail.com  Mon May  2 16:49:40 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 2 May 2016 10:49:40 -0400
Subject: [R] Network Layouting in R
In-Reply-To: <4b8726c399d1f4fbd4ed916623cd2def@mail.gmail.com>
References: <4b8726c399d1f4fbd4ed916623cd2def@mail.gmail.com>
Message-ID: <CAM_vjukZ+kEaYDgHpsGLbwRjC=1JEvqmTZXKc0CvDeHkVwW_RQ@mail.gmail.com>

Hi,

On Mon, May 2, 2016 at 8:36 AM, Kushank Chhabra
<Kushank.chhabra at iontrading.com> wrote:
> Hi,
>
>
>
> I am trying to plot a network diagram of around 1500 component (as nodes)
> and many connections (as edges) within them.

> I tried igraph package, however unable to create a layout where there is no
> overlap of nodes or edges.

How do you know it's physically possible to create a 2D layout with no overlap?
1500 nodes is a lot.

What did you try? What did you get? Did you produce a diagram, just
with more overlap than you were expecting? That may be the best you
can do.

> More or less tried all the things mentioned in this link -
>
> http://kateto.net/network-visualization

Again, what did you try? What did you get that doesn't meet your
needs? Just the overlap? Again, that may be unavoidable. Note the
comment from that link:
"One thing to emphasize though is that in many cases, visualizing
larger networks as giant hairballs is less helpful than providing
charts that show key characteristics of the graph."

> Can you please suggest how to do it in R ?

For working with largish graph layouts, I've had more success with
gephi than R, although I believe you can duplicate most of the gephi
functionality in R.

Sarah


>
>
> Output expected ? A good layout of the network diagram (of around 1500
> nodes) with no overlaps of nodes or even edges and possibly it can be
> screened as a picture, or on a browser or on a pdf.
>
>
>
> With Best Regards,
>
> Kushank


From lars52r at gmail.com  Mon May  2 17:17:10 2016
From: lars52r at gmail.com (Lars Bishop)
Date: Mon, 2 May 2016 11:17:10 -0400
Subject: [R] Issue installing packages - Linux
In-Reply-To: <CA+8X3fVVCA1-ZpVt9b9cegqf7=UGcci0NxastVFGi3GSttO4Rg@mail.gmail.com>
References: <CAO7OmOhi1Pag3funkd9UOv7QxkWjOPmYjcEQX_QBeSTdOAvK4Q@mail.gmail.com>
	<CA+8X3fVVCA1-ZpVt9b9cegqf7=UGcci0NxastVFGi3GSttO4Rg@mail.gmail.com>
Message-ID: <CAO7OmOh6yBV88VPj+yMB0=YeRcsJL05qWphcxd27_YCeTWWitg@mail.gmail.com>

Thanks Jim. I don't think that is the issue...if anyone else can shed some
light here, that would be much appreciated.

Regards
Lars.

On Saturday, 30 April 2016, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Lars,
> A mystery, but for the bodgy characters in your error message. Perhaps
> there is a problem with R trying to read a different character set
> from that used in the package.
>
> Jim
>
> On Sat, Apr 30, 2016 at 8:22 PM, Lars Bishop <lars52r at gmail.com
> <javascript:;>> wrote:
> > Hello,
> >
> > I can?t seem to be able to install packages on a redhat-linux-gnu. For
> > instance, this is what happens when I try to install ?bitops?. Any hint
> on
> > what might be the issue would be much appreciated.
> >
> >> sessionInfo()
> > R version 3.2.3 (2015-12-10)
> > Platform: x86_64-redhat-linux-gnu (64-bit)
> > Running under: Red Hat Enterprise Linux
> >
> >> Sys.setenv(https_proxy="https://labproxy.com:8080")
> >> install.packages("bitops", lib="mypath ")
> >
> > Here I choose: 22: (HTTP mirrors) and then a mirror 16:Canada(ON)
> >
> > * installing *source* package ?bitops? ...
> > ** package ?bitops? successfully unpacked and MD5 sums checked
> > Error in readRDS(pfile) : error reading from connection
> > ERROR: lazy loading failed for package ?bitops?
> >
> > I?ve also tried from the shell (after downloading the package source)
> >
> > $  R CMD INSTALL bitops_1.0-6.tar.gz
> > ERROR: cannot extract package from bitops_1.0-6.tar.gz
> >
> > Thank you,
> > Lars.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tom at maladmin.com  Mon May  2 17:18:32 2016
From: tom at maladmin.com (Tom Wright)
Date: Mon, 2 May 2016 08:18:32 -0700
Subject: [R] how to use AND in grepl
In-Reply-To: <1066416646.9317980.1462200149389.JavaMail.yahoo@mail.yahoo.com>
References: <C9BAD7E6-7E7E-472A-9512-A68E55738602@gmail.com>
	<1066416646.9317980.1462200149389.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAKmUXV9qkt-L0OYDyPdMmo44EMsbZPhc5SQK1yv7BSb4TpMdDQ@mail.gmail.com>

Sorry for the missed braces earlier. I was typing on a phone, not the best
place to conjugate regular expressions.
Using the example you provided:

> df=data.frame(Command=c("_localize_PD", "_localize_tre_t2",
"_abdomen_t1_seq", "knee_pd_t1_localize", "pd_local_abdomen_t2"))

> grepl("(.*t2.*pd.*)|(.*pd.*t2.*)",df$Command)
[1] FALSE FALSE FALSE FALSE  TRUE

> subset(df,grepl("(.*t2.*pd.*)|(.*pd.*t2.*)",df$Command))
              Command
5 pd_local_abdomen_t2


On Mon, May 2, 2016 at 7:42 AM, <chalabi.elahe at yahoo.de> wrote:

> Thanks Peter, you were right, the exact grepl is
> grepl("(.*t2.*pd.*)|(.*pd.*t2.*)",df$Command), but it does not change
> anything in Command, when I check the size of it by
> sum(grepl("(.*t2.*pd.*)|(.*pd.*t2.*)",df$Command))  the result is 0, but I
> am sure that the size is not 0. It seems that this AND does not work.
>
>
> On Monday, May 2, 2016 5:05 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>
> On 02 May 2016, at 12:43 , ch.elahe via R-help <r-help at r-project.org>
> wrote:
>
> > Thanks for your reply tom. After using
> Subset(df,grepl("(.*t2.*pd.*)|(.*pd.*t2.*)"),df$Command)  I get this error:
> Argument "x" is missing, with no default. Actually I don't know how to fix
> this. Do you have any idea?
>
> Tom's code was missing a ")" but not where you put one. He probably also
> didn't intend to capitalize "subset".
>
>
> -pd
>
> > Thanks,
> > Elahe
> >
> >
> > On Saturday, April 30, 2016 7:35 PM, Tom Wright <tom at maladmin.com>
> wrote:
> >
> >
> >
> > Actually not sure my previous answer does what you wanted. Using your
> approach:
> > t2pd=subset(df,grepl("t2",df$Command) & grepl("pd",df$Command))
> > Should work.
> > I think the regex pattern you are looking for is:
> > Subset(df,grepl("(.* t2.*pd.* )|(.* pd.* t2.*)",df$Command)
> >
> > On Sat, Apr 30, 2016, 7:07 PM Tom Wright <tom at maladmin.com> wrote:
> >
> > subset(df,grepl("t2|pd",x$Command))
> >>
> >>
> >>
> >>
> >> On Sat, Apr 30, 2016 at 2:38 PM, ch.elahe via R-help <
> r-help at r-project.org> wrote:
> >>
> >> Hi all,
> >>>
> >>> I have one factor variable in my df and I want to extract the names
> from it which contain both "t2" and "pd":
> >>>
> >>> 'data.frame': 36919 obs. of 162 variables
> >>>  $TE                :int 38,41,11,52,48,75,.....
> >>>  $TR                :int 100,210,548,546,.....
> >>>  $Command          :factor W/2229 levels
> "_localize_PD","_localize_tre_t2","_abdomen_t1_seq","knee_pd_t1_localize","pd_local_abdomen_t2"...
> >>>
> >>> I have tried this but I did not get result:
> >>>
> >>> t2pd=subset(df,grepl("t2",Command) & grepl("pd",Command))
> >>>
> >>>
> >>> does anyone know how to apply AND in grepl?
> >>>
> >>> Thanks
> >>> Elahe
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>> .
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>

	[[alternative HTML version deleted]]


From shouro at gmail.com  Mon May  2 17:32:29 2016
From: shouro at gmail.com (Shouro Dasgupta)
Date: Mon, 2 May 2016 17:32:29 +0200
Subject: [R] Issue installing packages - Linux
In-Reply-To: <CAO7OmOh6yBV88VPj+yMB0=YeRcsJL05qWphcxd27_YCeTWWitg@mail.gmail.com>
References: <CAO7OmOhi1Pag3funkd9UOv7QxkWjOPmYjcEQX_QBeSTdOAvK4Q@mail.gmail.com>
	<CA+8X3fVVCA1-ZpVt9b9cegqf7=UGcci0NxastVFGi3GSttO4Rg@mail.gmail.com>
	<CAO7OmOh6yBV88VPj+yMB0=YeRcsJL05qWphcxd27_YCeTWWitg@mail.gmail.com>
Message-ID: <CAMx+UYf0+1dsDix=uAtSQEKu3SE6=f1w4d0JrodN5jkbD26d7Q@mail.gmail.com>

Hello Lara,

I recently installed a number of packages through compiling. After
downloading the package using 'wget', running R CMD INSTALL package.tar.gz
should work.

Sincerely,

Shouro

On Mon, May 2, 2016 at 5:17 PM, Lars Bishop <lars52r at gmail.com> wrote:

> Thanks Jim. I don't think that is the issue...if anyone else can shed some
> light here, that would be much appreciated.
>
> Regards
> Lars.
>
> On Saturday, 30 April 2016, Jim Lemon <drjimlemon at gmail.com> wrote:
>
> > Hi Lars,
> > A mystery, but for the bodgy characters in your error message. Perhaps
> > there is a problem with R trying to read a different character set
> > from that used in the package.
> >
> > Jim
> >
> > On Sat, Apr 30, 2016 at 8:22 PM, Lars Bishop <lars52r at gmail.com
> > <javascript:;>> wrote:
> > > Hello,
> > >
> > > I can?t seem to be able to install packages on a redhat-linux-gnu. For
> > > instance, this is what happens when I try to install ?bitops?. Any hint
> > on
> > > what might be the issue would be much appreciated.
> > >
> > >> sessionInfo()
> > > R version 3.2.3 (2015-12-10)
> > > Platform: x86_64-redhat-linux-gnu (64-bit)
> > > Running under: Red Hat Enterprise Linux
> > >
> > >> Sys.setenv(https_proxy="https://labproxy.com:8080")
> > >> install.packages("bitops", lib="mypath ")
> > >
> > > Here I choose: 22: (HTTP mirrors) and then a mirror 16:Canada(ON)
> > >
> > > * installing *source* package ?bitops? ...
> > > ** package ?bitops? successfully unpacked and MD5 sums checked
> > > Error in readRDS(pfile) : error reading from connection
> > > ERROR: lazy loading failed for package ?bitops?
> > >
> > > I?ve also tried from the shell (after downloading the package source)
> > >
> > > $  R CMD INSTALL bitops_1.0-6.tar.gz
> > > ERROR: cannot extract package from bitops_1.0-6.tar.gz
> > >
> > > Thank you,
> > > Lars.
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> > more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




-- 

Shouro Dasgupta, PhD
Junior Researcher
Fondazione Eni Enrico Mattei (FEEM) |
Centro Euro-Mediterraneo per i Cambiamenti Climatici (CMCC)
Isola di San Giorgio Maggiore, 8
30124 Venezia
Phone: +39 041 2700 436

	[[alternative HTML version deleted]]


From giorgio.garziano at ericsson.com  Mon May  2 17:40:39 2016
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Mon, 2 May 2016 15:40:39 +0000
Subject: [R] Help regarding Community Detection Algorithm in R (like
 Propagation, Walktrap)
Message-ID: <248E6FA047A8C746BA491485764190F53D3B1359@ESESSMB207.ericsson.se>

You may look at:

http://rseek.org/?q=community%20detection


--

Best,

GG

	[[alternative HTML version deleted]]


From chalabi.elahe at yahoo.de  Mon May  2 17:46:36 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Mon, 2 May 2016 15:46:36 +0000 (UTC)
Subject: [R] how to use AND in grepl
In-Reply-To: <CAKmUXV9qkt-L0OYDyPdMmo44EMsbZPhc5SQK1yv7BSb4TpMdDQ@mail.gmail.com>
References: <CAKmUXV9qkt-L0OYDyPdMmo44EMsbZPhc5SQK1yv7BSb4TpMdDQ@mail.gmail.com>
Message-ID: <125133071.9385292.1462203997074.JavaMail.yahoo@mail.yahoo.com>

Yes it works, but let me explain what I am going to do. I extract all the names I want and then create a new column out of them for my plot. This is he whole thing I do:
  PD=subset(df,grepl("pd",Command)) //extract names in Command with only "pd"
  t2=subset(df,grepl("t2",Command)) //extract names with only "t2"
  PDT2=subset(df,grepl("(.*t2.*pd.*)|(.*pd.*t2.*)",df$Command) // extract names which contain both "pd" and "t2"
  v1=c('PD','t2','PDT2')// I create a vector with these conditions
  str_extract(df$Command,paste(v1,collaps='|')) //returning patterns, using stringr library

here I see no pattern named PDT2 but there are only PD and t2 patterns.
On Monday, May 2, 2016 8:18 AM, Tom Wright <tom at maladmin.com> wrote:



Sorry for the missed braces earlier. I was typing on a phone, not the best place to conjugate regular expressions.
Using the example you provided:

> df=data.frame(Command=c("_localize_PD", "_localize_tre_t2", "_abdomen_t1_seq", "knee_pd_t1_localize", "pd_local_abdomen_t2"))

> grepl("(.*t2.*pd.*)|(.*pd.*t2.*)",df$Command)
[1] FALSE FALSE FALSE FALSE  TRUE

> subset(df,grepl("(.*t2.*pd.*)|(.*pd.*t2.*)",df$Command))
              Command
5 pd_local_abdomen_t2



On Mon, May 2, 2016 at 7:42 AM, <chalabi.elahe at yahoo.de> wrote:

Thanks Peter, you were right, the exact grepl is grepl("(.*t2.*pd.*)|(.*pd.*t2.*)",df$Command), but it does not change anything in Command, when I check the size of it by sum(grepl("(.*t2.*pd.*)|(.*pd.*t2.*)",df$Command))  the result is 0, but I am sure that the size is not 0. It seems that this AND does not work.
>
>
>
>On Monday, May 2, 2016 5:05 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>
>On 02 May 2016, at 12:43 , ch.elahe via R-help <r-help at r-project.org> wrote:
>
>> Thanks for your reply tom. After using  Subset(df,grepl("(.*t2.*pd.*)|(.*pd.*t2.*)"),df$Command)  I get this error: Argument "x" is missing, with no default. Actually I don't know how to fix this. Do you have any idea?
>
>Tom's code was missing a ")" but not where you put one. He probably also didn't intend to capitalize "subset".
>
>
>-pd
>
>> Thanks,
>> Elahe
>>
>>
>> On Saturday, April 30, 2016 7:35 PM, Tom Wright <tom at maladmin.com> wrote:
>>
>>
>>
>> Actually not sure my previous answer does what you wanted. Using your approach:
>> t2pd=subset(df,grepl("t2",df$Command) & grepl("pd",df$Command))
>> Should work.
>> I think the regex pattern you are looking for is:
>> Subset(df,grepl("(.* t2.*pd.* )|(.* pd.* t2.*)",df$Command)
>>
>> On Sat, Apr 30, 2016, 7:07 PM Tom Wright <tom at maladmin.com> wrote:
>>
>> subset(df,grepl("t2|pd",x$Command))
>>>
>>>
>>>
>>>
>>> On Sat, Apr 30, 2016 at 2:38 PM, ch.elahe via R-help <r-help at r-project.org> wrote:
>>>
>>> Hi all,
>>>>
>>>> I have one factor variable in my df and I want to extract the names from it which contain both "t2" and "pd":
>>>>
>>>> 'data.frame': 36919 obs. of 162 variables
>>>>  $TE                :int 38,41,11,52,48,75,.....
>>>>  $TR                :int 100,210,548,546,.....
>>>>  $Command          :factor W/2229 levels "_localize_PD","_localize_tre_t2","_abdomen_t1_seq","knee_pd_t1_localize","pd_local_abdomen_t2"...
>>>>
>>>> I have tried this but I did not get result:
>>>>
>>>> t2pd=subset(df,grepl("t2",Command) & grepl("pd",Command))
>>>>
>>>>
>>>> does anyone know how to apply AND in grepl?
>>>>
>>>> Thanks
>>>> Elahe
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> .
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>--
>Peter Dalgaard, Professor,
>Center for Statistics, Copenhagen Business School
>Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>Phone: (+45)38153501
>Office: A 4.23
>Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>


From tom at maladmin.com  Mon May  2 18:16:09 2016
From: tom at maladmin.com (Tom Wright)
Date: Mon, 02 May 2016 16:16:09 +0000
Subject: [R] how to use AND in grepl
In-Reply-To: <125133071.9385292.1462203997074.JavaMail.yahoo@mail.yahoo.com>
References: <CAKmUXV9qkt-L0OYDyPdMmo44EMsbZPhc5SQK1yv7BSb4TpMdDQ@mail.gmail.com>
	<125133071.9385292.1462203997074.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAKmUXV-jq74NNqV7fai9HBZ3eNAT2eu4hBcA4VqW3BPFEnOS=w@mail.gmail.com>

The first thing I notice here is that your first two subset statements are
searching in an object named Command, not the column df$Command. I'm not at
all sure what you are trying to achieve with the str_extract process but it
is looking for the exact string 'PDT2' the vectors / dataframe formed in
your previous commands are not being used at all.
Moving forward I think you need to pay attention to case "PD" != "pd". Also
the set PDT2 is going to be a subset of both  sets PD and t2, I don't think
this is what you are after.

On Mon, May 2, 2016, 8:49 AM <chalabi.elahe at yahoo.de> wrote:

> Yes it works, but let me explain what I am going to do. I extract all the
> names I want and then create a new column out of them for my plot. This is
> he whole thing I do:
>   PD=subset(df,grepl("pd",Command)) //extract names in Command with only
> "pd"
>   t2=subset(df,grepl("t2",Command)) //extract names with only "t2"
>   PDT2=subset(df,grepl("(.*t2.*pd.*)|(.*pd.*t2.*)",df$Command) // extract
> names which contain both "pd" and "t2"
>   v1=c('PD','t2','PDT2')// I create a vector with these conditions
>   str_extract(df$Command,paste(v1,collaps='|')) //returning patterns,
> using stringr library
>
> here I see no pattern named PDT2 but there are only PD and t2 patterns.
> On Monday, May 2, 2016 8:18 AM, Tom Wright <tom at maladmin.com> wrote:
>
>
>
> Sorry for the missed braces earlier. I was typing on a phone, not the best
> place to conjugate regular expressions.
> Using the example you provided:
>
> > df=data.frame(Command=c("_localize_PD", "_localize_tre_t2",
> "_abdomen_t1_seq", "knee_pd_t1_localize", "pd_local_abdomen_t2"))
>
> > grepl("(.*t2.*pd.*)|(.*pd.*t2.*)",df$Command)
> [1] FALSE FALSE FALSE FALSE  TRUE
>
> > subset(df,grepl("(.*t2.*pd.*)|(.*pd.*t2.*)",df$Command))
>               Command
> 5 pd_local_abdomen_t2
>
>
>
> On Mon, May 2, 2016 at 7:42 AM, <chalabi.elahe at yahoo.de> wrote:
>
> Thanks Peter, you were right, the exact grepl is
> grepl("(.*t2.*pd.*)|(.*pd.*t2.*)",df$Command), but it does not change
> anything in Command, when I check the size of it by
> sum(grepl("(.*t2.*pd.*)|(.*pd.*t2.*)",df$Command))  the result is 0, but I
> am sure that the size is not 0. It seems that this AND does not work.
> >
> >
> >
> >On Monday, May 2, 2016 5:05 AM, peter dalgaard <pdalgd at gmail.com> wrote:
> >
> >On 02 May 2016, at 12:43 , ch.elahe via R-help <r-help at r-project.org>
> wrote:
> >
> >> Thanks for your reply tom. After using
> Subset(df,grepl("(.*t2.*pd.*)|(.*pd.*t2.*)"),df$Command)  I get this error:
> Argument "x" is missing, with no default. Actually I don't know how to fix
> this. Do you have any idea?
> >
> >Tom's code was missing a ")" but not where you put one. He probably also
> didn't intend to capitalize "subset".
> >
> >
> >-pd
> >
> >> Thanks,
> >> Elahe
> >>
> >>
> >> On Saturday, April 30, 2016 7:35 PM, Tom Wright <tom at maladmin.com>
> wrote:
> >>
> >>
> >>
> >> Actually not sure my previous answer does what you wanted. Using your
> approach:
> >> t2pd=subset(df,grepl("t2",df$Command) & grepl("pd",df$Command))
> >> Should work.
> >> I think the regex pattern you are looking for is:
> >> Subset(df,grepl("(.* t2.*pd.* )|(.* pd.* t2.*)",df$Command)
> >>
> >> On Sat, Apr 30, 2016, 7:07 PM Tom Wright <tom at maladmin.com> wrote:
> >>
> >> subset(df,grepl("t2|pd",x$Command))
> >>>
> >>>
> >>>
> >>>
> >>> On Sat, Apr 30, 2016 at 2:38 PM, ch.elahe via R-help <
> r-help at r-project.org> wrote:
> >>>
> >>> Hi all,
> >>>>
> >>>> I have one factor variable in my df and I want to extract the names
> from it which contain both "t2" and "pd":
> >>>>
> >>>> 'data.frame': 36919 obs. of 162 variables
> >>>>  $TE                :int 38,41,11,52,48,75,.....
> >>>>  $TR                :int 100,210,548,546,.....
> >>>>  $Command          :factor W/2229 levels
> "_localize_PD","_localize_tre_t2","_abdomen_t1_seq","knee_pd_t1_localize","pd_local_abdomen_t2"...
> >>>>
> >>>> I have tried this but I did not get result:
> >>>>
> >>>> t2pd=subset(df,grepl("t2",Command) & grepl("pd",Command))
> >>>>
> >>>>
> >>>> does anyone know how to apply AND in grepl?
> >>>>
> >>>> Thanks
> >>>> Elahe
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>> .
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >--
> >Peter Dalgaard, Professor,
> >Center for Statistics, Copenhagen Business School
> >Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> >Phone: (+45)38153501
> >Office: A 4.23
> >Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> >
>

	[[alternative HTML version deleted]]


From ddalthorp at usgs.gov  Mon May  2 18:20:09 2016
From: ddalthorp at usgs.gov (Dalthorp, Daniel)
Date: Mon, 2 May 2016 09:20:09 -0700
Subject: [R] tcltk: click and return table cell index
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC810F8B8A0@FHSDB2D11-2.csu.mcmaster.ca>
References: <CAJeYpE_G=eTLTmOxtOTFhUNQ3LJusrGbwecpu1yXGBg3T47S4g@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F8B8A0@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CAJeYpE8JnptLy_sNz7wnMpkw7tuNL6nbJCGKGQJ8-RG=Ebo3mw@mail.gmail.com>

Thanks, John.

The trouble with that solution is that it gives the index for where the
cursor was before clicking rather than the cell that was clicked. The
solution is that the <Button-1> binding gives the x, y pixel coordinates of
the click to the callback, and the pixel coordinates can be translated to
cell index via:

tkindex(table1, as.tclObj(paste0("@",x, ",", y)))

Or, showing the whole example:

# create table
tt<-tktoplevel()
table1<-tkwidget(tt,"table", rows=3,cols=3)
tkgrid(table1)

# bind the mouse click to printing out cell index:
tkbind(table1, "<Button-1>", function(x, y) print(tcl(table1, "index",
as.tclObj(paste0("@",x, ",", y)))))

Thanks again!

-Dan

On Sat, Apr 30, 2016 at 6:43 AM, Fox, John <jfox at mcmaster.ca> wrote:

> Dear Daniel,
>
> Try
>
> tkbind(table1, "<Button-1>", function(){
>      res <- try(tclvalue(tkindex(table1, "active")), silent=TRUE)
>    if (inherits(res, "try-error")) print (NULL)
>    else print(res)
> })
>
> I put in the calls to print() so that you could see how it works.
>
> I hope this helps,
>  John
>
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> Web: socserv.mcmaster.ca/jfox
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Dalthorp,
> > Daniel
> > Sent: April 29, 2016 1:42 PM
> > To: r-help at R-project.org (r-help at r-project.org) <r-help at r-project.org>
> > Subject: [R] tcltk: click and return table cell index
> >
> > I'm struggling mightily with what should be a simple task...when a user
> clicks
> > on a cell in a tcltk table widget, I need to know which cell was clicked.
> >
> > One idea that gives a cryptic error:
> > tkbind(table1, "<Button-1>", function(x, y){
> >   tcl(table1, "index", x, y)
> > }
> >
> > # x, y give pixel coordinates; "index" should give cell coordinates, but
> format
> > must be correct
> >
> > I get an error message:
> >
> > wrong # args: should be ".25.1 index <index> ?row|col?".
> >
> > To which I respond, "Yes, I know I have the format wrong, but how can I
> make
> > sense of THAT?"
> >
> > Does anyone know a simple fix?
> >
> > Much appreciated!
> >
> > -Dan
> >
> > --
> > Dan Dalthorp, PhD
> > USGS Forest and Rangeland Ecosystem Science Center Forest Sciences Lab,
> Rm
> > 189
> > 3200 SW Jefferson Way
> > Corvallis, OR 97331
> > ph: 541-750-0953
> > ddalthorp at usgs.gov
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
Dan Dalthorp, PhD
USGS Forest and Rangeland Ecosystem Science Center
Forest Sciences Lab, Rm 189
3200 SW Jefferson Way
Corvallis, OR 97331
ph: 541-750-0953
ddalthorp at usgs.gov

	[[alternative HTML version deleted]]


From miaojpm at gmail.com  Mon May  2 19:27:38 2016
From: miaojpm at gmail.com (jpm miao)
Date: Mon, 2 May 2016 10:27:38 -0700
Subject: [R] Can't rename a data frame column
Message-ID: <CABcx46CBgeTjJpiD1cCz_rTnFLP49ukwxJ4ip-n+Rcwzq2wRwQ@mail.gmail.com>

Hi,

   Could someone suggest a way to rename a data frame column? For example,
I want to rename the column beta, but I can't do it this way

> d <- data.frame(alpha=1:3, beta=4:6, gamma=7:9)
> mm<-"beta"
> rename(d, c(mm="two", "gamma"="three"))
The following `from` values were not present in `x`: mm
  alpha beta three
1     1    4     7
2     2    5     8
3     3    6     9

********
     Of course this would work

> rename(d, c("beta"="two", "gamma"="three"))
  alpha two three
1     1   4     7
2     2   5     8
3     3   6     9

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Mon May  2 19:28:22 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 2 May 2016 19:28:22 +0200
Subject: [R] Removing NAs from dataframe (for use in Vioplot)
In-Reply-To: <CAGxFJbSGO6TBFip_c+KfnRtYs=boTH1UhPAOB+qGoa4arUAUXg@mail.gmail.com>
References: <142423783.20160430205840@hsm.org.uk>
	<1D7DB03F-C03B-48E4-B508-6C23406F26A2@comcast.net>
	<39FB27E5-65B5-4388-9849-02ABE585BC4D@comcast.net>
	<1805593311.20160501081544@hsm.org.uk>
	<22311.5264.327599.172488@stat.math.ethz.ch>
	<CAGxFJbSGO6TBFip_c+KfnRtYs=boTH1UhPAOB+qGoa4arUAUXg@mail.gmail.com>
Message-ID: <22311.36406.854015.253804@stat.math.ethz.ch>

>>>>> Bert Gunter <bgunter.4567 at gmail.com>
>>>>>     on Mon, 2 May 2016 06:20:52 -0700 writes:

    > Martin et. al.:
    > na.omit(frame) will remove all rows/cases in which an NA occurs.  I'm
    > not sure that this is what the OP wanted, which seemed to be to
    > separately remove NA's from each column and plot the resulting column.
    > This is what the lapply (and the OP's provided code) does, anyway.

    > Also, lapply() produces a single list (of vectors), not a "series of lists" .

    > Corrections happily accepted if I'm in error.

No corrections needed.  You were right ... and indeed I was
wrong in assuming that "one would want"  a complete  na.omit()
here.

Martin



    > Cheers,
    > Bert

    > Bert Gunter

    > "The trouble with having an open mind is that people keep coming along
    > and sticking things into it."
    > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


    > On Mon, May 2, 2016 at 1:49 AM, Martin Maechler
    > <maechler at stat.math.ethz.ch> wrote:
    >>>>>>> Mike Smith <mike at hsm.org.uk>
    >>>>>>> on Sun, 1 May 2016 08:15:44 +0100 writes:
    >> 
    >> >>>> On Apr 30, 2016, at 12:58 PM, Mike Smith
    >> >>>> <mike at hsm.org.uk> wrote: Hi
    >> 
    >> >>>> First post and a relative R newbie....
    >> 
    >> >>>> I am using the vioplot library to produce some violin
    >> >>>> plots.
    >> 
    DW> It's a package, .... not a library.
    >> 
    >> [yes!]
    >> 
    >> 
    >> >>>> 1. Is there a more elegant way of automatically
    >> >>>> stripping the NAs, passing the columns to the function
    >> >>>> along with the header names??
    >> 
    >> >>> ds2 <- lapply( ds1, na.omit)
    >> 
    >> 
    >> > Fantastic - that does the trick! Easy when you know how!!
    >> 
    >> > Follow-on: is there a way feed all the lists from ds2 to
    >> > vioplot? It is now a series of lists (rather than a
    >> > dataframe - is that right?).
    >> 
    >> Yes, that's right.  So after all the above was not really
    >> perfect :
    >> 
    >> na.omit() has been designed as a generic function and has always
    >> had a method for "data.frame"; so, really
    >> 
    >> ds.noNA <- na.omit(ds1)
    >> or  ds0NA   <- na.omit(ds1)
    >> 
    >> (choosing "expressive names")
    >> 
    >> is what you want.
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.


From alaios at yahoo.com  Mon May  2 19:32:34 2016
From: alaios at yahoo.com (Alaios)
Date: Mon, 2 May 2016 17:32:34 +0000 (UTC)
Subject: [R] greek characters in Figures
References: <1770895494.4876101.1462210354831.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1770895494.4876101.1462210354831.JavaMail.yahoo@mail.yahoo.com>

Dear all,I am trying to write in my Figure labels short equations that contain greek characters

For example:??C(h) = sigma^2 * rho(h). ??

I am googling it and there are many packages available but unfortunately they do not look available for my 3.2.4 latex version

install.packages("latex2expr")Installiere Paket nach ?/home/apa/R/x86_64-pc-linux-gnu-library/3.2?(da ?lib? nicht spezifiziert)Warnung: kann nicht auf den Index f?r das Repository https://cran.cnr.Berkeley.edu/src/contrib zugreifen:? nicht unterst?tztes URL SchemaWarnmeldung:Paket ?latex2expr? ist nicht verf?gbar (for R version 3.2.4 Revised)?

Any ideas what else I can try?I would like to thank you in advance for your replyRegardsAlex
	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Mon May  2 19:38:54 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 2 May 2016 19:38:54 +0200
Subject: [R] greek characters in Figures
In-Reply-To: <1770895494.4876101.1462210354831.JavaMail.yahoo@mail.yahoo.com>
References: <1770895494.4876101.1462210354831.JavaMail.yahoo.ref@mail.yahoo.com>
	<1770895494.4876101.1462210354831.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <22311.37038.797313.484845@stat.math.ethz.ch>

>>>>> Alaios via R-help <r-help at r-project.org>
>>>>>     on Mon, 2 May 2016 17:32:34 +0000 writes:

    > Dear all,I am trying to write in my Figure labels short equations that contain greek characters
    > For example:??C(h) = sigma^2 * rho(h). ??

    > I am googling it and there are many packages available ......

Googling about R problems often does not lead to the best
solutions.

In this case do

   ?plotmath

and see that you do *NOT* need to install any extra packages.
You do have 29 R packages installed with your R installation,
you already have several 1000s R functions at your
disposition....

Martin Maechler,
ETH Zurich


    > Any ideas what else I can try?I would like to thank you in advance for your replyRegardsAlex


From boris.steipe at utoronto.ca  Mon May  2 19:49:26 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 2 May 2016 13:49:26 -0400
Subject: [R] Can't rename a data frame column
In-Reply-To: <CABcx46CBgeTjJpiD1cCz_rTnFLP49ukwxJ4ip-n+Rcwzq2wRwQ@mail.gmail.com>
References: <CABcx46CBgeTjJpiD1cCz_rTnFLP49ukwxJ4ip-n+Rcwzq2wRwQ@mail.gmail.com>
Message-ID: <52A853FC-0A96-4D72-9AE0-5BB44191D2B7@utoronto.ca>

You need to learn about proper subsetting, and the names() function. Consider the following:

R > d <- data.frame(alpha=1:3, beta=4:6, gamma=7:9)
R > d
  alpha beta gamma
1     1    4     7
2     2    5     8
3     3    6     9
R > names(d)
[1] "alpha" "beta"  "gamma"
R > names(d) == "beta"
[1] FALSE  TRUE FALSE
R > names(d)[names(d) == "beta"] <- "two"
R > d
  alpha two gamma
1     1   4     7
2     2   5     8
3     3   6     9

R > names(d)[3] <- "three"
R > d
  alpha two three
1     1   4     7
2     2   5     8
3     3   6     9



B.
(I can't even ...)




On May 2, 2016, at 1:27 PM, jpm miao <miaojpm at gmail.com> wrote:

> Hi,
> 
>   Could someone suggest a way to rename a data frame column? For example,
> I want to rename the column beta, but I can't do it this way
> 
>> d <- data.frame(alpha=1:3, beta=4:6, gamma=7:9)
>> mm<-"beta"
>> rename(d, c(mm="two", "gamma"="three"))
> The following `from` values were not present in `x`: mm
>  alpha beta three
> 1     1    4     7
> 2     2    5     8
> 3     3    6     9
> 
> ********
>     Of course this would work
> 
>> rename(d, c("beta"="two", "gamma"="three"))
>  alpha two three
> 1     1   4     7
> 2     2   5     8
> 3     3   6     9
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chalabi.elahe at yahoo.de  Mon May  2 20:01:32 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Mon, 2 May 2016 18:01:32 +0000 (UTC)
Subject: [R] how to use AND in grepl
In-Reply-To: <CAKmUXV-jq74NNqV7fai9HBZ3eNAT2eu4hBcA4VqW3BPFEnOS=w@mail.gmail.com>
References: <CAKmUXV-jq74NNqV7fai9HBZ3eNAT2eu4hBcA4VqW3BPFEnOS=w@mail.gmail.com>
Message-ID: <1224913045.9583904.1462212092443.JavaMail.yahoo@mail.yahoo.com>

I just changed all the names in Command to lowercase, then this str_extract works fine for "pd" and "t2", but not for "PDT2". Do you have any idea how I can bring PDT2  also in str_extract?  


On Monday, May 2, 2016 9:16 AM, Tom Wright <tom at maladmin.com> wrote:



The first thing I notice here is that your first two subset statements are searching in an object named Command, not the column df$Command. I'm not at all sure what you are trying to achieve with the str_extract process but it is looking for the exact string 'PDT2' the vectors / dataframe formed in your previous commands are not being used at all. 
Moving forward I think you need to pay attention to case "PD" != "pd". Also the set PDT2 is going to be a subset of both  sets PD and t2, I don't think this is what you are after.

On Mon, May 2, 2016, 8:49 AM  <chalabi.elahe at yahoo.de> wrote:

Yes it works, but let me explain what I am going to do. I extract all the names I want and then create a new column out of them for my plot. This is he whole thing I do:
>  PD=subset(df,grepl("pd",Command)) //extract names in Command with only "pd"
>  t2=subset(df,grepl("t2",Command)) //extract names with only "t2"
>  PDT2=subset(df,grepl("(.*t2.*pd.*)|(.*pd.*t2.*)",df$Command) // extract names which contain both "pd" and "t2"
>  v1=c('PD','t2','PDT2')// I create a vector with these conditions
>  str_extract(df$Command,paste(v1,collaps='|')) //returning patterns, using stringr library
>
>here I see no pattern named PDT2 but there are only PD and t2 patterns.
>On Monday, May 2, 2016 8:18 AM, Tom Wright <tom at maladmin.com> wrote:
>
>
>
>Sorry for the missed braces earlier. I was typing on a phone, not the best place to conjugate regular expressions.
>Using the example you provided:
>
>> df=data.frame(Command=c("_localize_PD", "_localize_tre_t2", "_abdomen_t1_seq", "knee_pd_t1_localize", "pd_local_abdomen_t2"))
>
>> grepl("(.*t2.*pd.*)|(.*pd.*t2.*)",df$Command)
>[1] FALSE FALSE FALSE FALSE  TRUE
>
>> subset(df,grepl("(.*t2.*pd.*)|(.*pd.*t2.*)",df$Command))
>              Command
>5 pd_local_abdomen_t2
>
>
>
>On Mon, May 2, 2016 at 7:42 AM, <chalabi.elahe at yahoo.de> wrote:
>
>Thanks Peter, you were right, the exact grepl is grepl("(.*t2.*pd.*)|(.*pd.*t2.*)",df$Command), but it does not change anything in Command, when I check the size of it by sum(grepl("(.*t2.*pd.*)|(.*pd.*t2.*)",df$Command))  the result is 0, but I am sure that the size is not 0. It seems that this AND does not work.
>>
>>
>>
>>On Monday, May 2, 2016 5:05 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>>
>>On 02 May 2016, at 12:43 , ch.elahe via R-help <r-help at r-project.org> wrote:
>>
>>> Thanks for your reply tom. After using  Subset(df,grepl("(.*t2.*pd.*)|(.*pd.*t2.*)"),df$Command)  I get this error: Argument "x" is missing, with no default. Actually I don't know how to fix this. Do you have any idea?
>>
>>Tom's code was missing a ")" but not where you put one. He probably also didn't intend to capitalize "subset".
>>
>>
>>-pd
>>
>>> Thanks,
>>> Elahe
>>>
>>>
>>> On Saturday, April 30, 2016 7:35 PM, Tom Wright <tom at maladmin.com> wrote:
>>>
>>>
>>>
>>> Actually not sure my previous answer does what you wanted. Using your approach:
>>> t2pd=subset(df,grepl("t2",df$Command) & grepl("pd",df$Command))
>>> Should work.
>>> I think the regex pattern you are looking for is:
>>> Subset(df,grepl("(.* t2.*pd.* )|(.* pd.* t2.*)",df$Command)
>>>
>>> On Sat, Apr 30, 2016, 7:07 PM Tom Wright <tom at maladmin.com> wrote:
>>>
>>> subset(df,grepl("t2|pd",x$Command))
>>>>
>>>>
>>>>
>>>>
>>>> On Sat, Apr 30, 2016 at 2:38 PM, ch.elahe via R-help <r-help at r-project.org> wrote:
>>>>
>>>> Hi all,
>>>>>
>>>>> I have one factor variable in my df and I want to extract the names from it which contain both "t2" and "pd":
>>>>>
>>>>> 'data.frame': 36919 obs. of 162 variables
>>>>>  $TE                :int 38,41,11,52,48,75,.....
>>>>>  $TR                :int 100,210,548,546,.....
>>>>>  $Command          :factor W/2229 levels "_localize_PD","_localize_tre_t2","_abdomen_t1_seq","knee_pd_t1_localize","pd_local_abdomen_t2"...
>>>>>
>>>>> I have tried this but I did not get result:
>>>>>
>>>>> t2pd=subset(df,grepl("t2",Command) & grepl("pd",Command))
>>>>>
>>>>>
>>>>> does anyone know how to apply AND in grepl?
>>>>>
>>>>> Thanks
>>>>> Elahe
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> .
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>--
>>Peter Dalgaard, Professor,
>>Center for Statistics, Copenhagen Business School
>>Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>Phone: (+45)38153501
>>Office: A 4.23
>>Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>


From john.archie.mckown at gmail.com  Mon May  2 20:10:59 2016
From: john.archie.mckown at gmail.com (John McKown)
Date: Mon, 2 May 2016 13:10:59 -0500
Subject: [R] how to use AND in grepl
In-Reply-To: <1224913045.9583904.1462212092443.JavaMail.yahoo@mail.yahoo.com>
References: <CAKmUXV-jq74NNqV7fai9HBZ3eNAT2eu4hBcA4VqW3BPFEnOS=w@mail.gmail.com>
	<1224913045.9583904.1462212092443.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAAJSdjiJNHEgTf5akwNPo3=cRfTZ9fcP8sCn_Fb2yZcj_Rv=ow@mail.gmail.com>

On Mon, May 2, 2016 at 1:01 PM, ch.elahe via R-help <r-help at r-project.org>
wrote:

> I just changed all the names in Command to lowercase, then this
> str_extract works fine for "pd" and "t2", but not for "PDT2". Do you have
> any idea how I can bring PDT2  also in str_extract?
>

Looking at ??grepl, I see the option: ignore.case=TRUE?

 PDT2=subset(df,grepl("(.*t2.*pd.*)|(.*pd.*t2.*)",df$
Command,ignore.case=TRUE)

Perhaps this will do the trick.

-- 
The unfacts, did we have them, are too imprecisely few to warrant our
certitude.

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From tr206 at kent.ac.uk  Mon May  2 20:31:47 2016
From: tr206 at kent.ac.uk (T.Riedle)
Date: Mon, 2 May 2016 18:31:47 +0000
Subject: [R] Generating 3Dplot in lattice package
Message-ID: <c2426a26544549429a2424c5a05c65c9@ex13-live-mbn1.ad.kent.ac.uk>

Dear R users,

I am trying to generate a 3D plot using the wireframe() function in the lattice package.

The corresponding formula in Excel looks as follows and is applied to the wireframe() function:

MIN(psi/K14,EXP(((ABS(H14)/peak)^omega)*LN(psi/K14)))

I tried to "translate" this formula in R and the code looks as follows


min(psi/VaR,exp(((abs(B)/Bmax)^w2)*log((psi/VaR),2.718182)))



In this case I get only one value which is NAN but I should get a time series with 13000 values. Hence, I deleted the min() function and tried the wireframe() function:


wireframe(inflator~exp((abs(B)/Bmax)^w2)*log((psi/VaR),base=2.718182),data=data_3Dplot)

However, it doesn't work as the formula for the inflator is incorrect. It produces NANs although it shouldn't do that and actually doesn't do that in Excel. Furthermore, the results are totally different to those calculated by Excel.

Can anyone help me with the formula and translate it correctly in terms of R? How do I get the time series? How do I get the values I get in Excel?

I have attached the data as csv file to this email.

Thank you very much for your help.


From tr206 at kent.ac.uk  Mon May  2 20:41:26 2016
From: tr206 at kent.ac.uk (T.Riedle)
Date: Mon, 2 May 2016 18:41:26 +0000
Subject: [R] Backtesting VaR using rugarch package
Message-ID: <92d822ff5cf54a48bf399540959ee90a@ex13-live-mbn1.ad.kent.ac.uk>

Dear R users,
I am trying to backtest VaR using the rugarch package. My code looks as follows

VaRTest(alpha=0.025,Backtesting_BuVaR$Log.return,Backtesting_BuVaR$VaR,conf.level = 0.975)

R returns following output. I don't understand why I get NAs except for the critical values.
Does anyone have an idea what I am doing wrong and why R returns only NAs? The corresponding data are in the csv file.

Many thanks for your support.

$expected.exceed
[1] 117

$actual.exceed
[1] NA

$uc.H0
[1] "Correct Exceedances"

$uc.LRstat
[1] NA

$uc.critical
[1] 5.023886

$uc.LRp
[1] NA

$uc.Decision
[1] NA

$cc.H0
[1] "Correct Exceedances & Independent"

$cc.LRstat
[1] NA

$cc.critical
[1] 7.377759

$cc.LRp
[1] NA

$cc.Decision
[1] NA

Warning message:
In Ops.factor(actual, VaR) : '<' not meaningful for factors




From thierry.onkelinx at inbo.be  Mon May  2 20:49:31 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 2 May 2016 20:49:31 +0200
Subject: [R] Can't rename a data frame column
In-Reply-To: <52A853FC-0A96-4D72-9AE0-5BB44191D2B7@utoronto.ca>
References: <CABcx46CBgeTjJpiD1cCz_rTnFLP49ukwxJ4ip-n+Rcwzq2wRwQ@mail.gmail.com>
	<52A853FC-0A96-4D72-9AE0-5BB44191D2B7@utoronto.ca>
Message-ID: <CAJuCY5xZFQ2KvGnbusQJx+f5Cj6zg_1f4TNq4+WZ+vYkYV9jVg@mail.gmail.com>

Or you dplyr

library(dplyr)
d <- data.frame(alpha=1:3, beta=4:6, gamma=7:9)
mm <- "beta"
rename_(d, "two" = mm, "three" = "gamma")


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-05-02 19:49 GMT+02:00 Boris Steipe <boris.steipe at utoronto.ca>:

> You need to learn about proper subsetting, and the names() function.
> Consider the following:
>
> R > d <- data.frame(alpha=1:3, beta=4:6, gamma=7:9)
> R > d
>   alpha beta gamma
> 1     1    4     7
> 2     2    5     8
> 3     3    6     9
> R > names(d)
> [1] "alpha" "beta"  "gamma"
> R > names(d) == "beta"
> [1] FALSE  TRUE FALSE
> R > names(d)[names(d) == "beta"] <- "two"
> R > d
>   alpha two gamma
> 1     1   4     7
> 2     2   5     8
> 3     3   6     9
>
> R > names(d)[3] <- "three"
> R > d
>   alpha two three
> 1     1   4     7
> 2     2   5     8
> 3     3   6     9
>
>
>
> B.
> (I can't even ...)
>
>
>
>
> On May 2, 2016, at 1:27 PM, jpm miao <miaojpm at gmail.com> wrote:
>
> > Hi,
> >
> >   Could someone suggest a way to rename a data frame column? For example,
> > I want to rename the column beta, but I can't do it this way
> >
> >> d <- data.frame(alpha=1:3, beta=4:6, gamma=7:9)
> >> mm<-"beta"
> >> rename(d, c(mm="two", "gamma"="three"))
> > The following `from` values were not present in `x`: mm
> >  alpha beta three
> > 1     1    4     7
> > 2     2    5     8
> > 3     3    6     9
> >
> > ********
> >     Of course this would work
> >
> >> rename(d, c("beta"="two", "gamma"="three"))
> >  alpha two three
> > 1     1   4     7
> > 2     2   5     8
> > 3     3   6     9
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Mon May  2 21:04:43 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 2 May 2016 12:04:43 -0700
Subject: [R] Generating 3Dplot in lattice package
In-Reply-To: <c2426a26544549429a2424c5a05c65c9@ex13-live-mbn1.ad.kent.ac.uk>
References: <c2426a26544549429a2424c5a05c65c9@ex13-live-mbn1.ad.kent.ac.uk>
Message-ID: <CAF8bMcZA8G1d=8akY1vX1tZBbV2at2cghTu4x19H-ze_JLvv0g@mail.gmail.com>

For starters, use 'pmin' (parallel min) instead of 'min'.

substitute(MIN(psi/K14,EXP(((ABS(H14)/peak)^omega)*LN(psi/K14))),
     list(MIN=quote(pmin), K14=quote(VaR), ABS=quote(abs),
          EXP=quote(exp), LN=quote(log), H14=quote(Bmax),
          omega=quote(w2)))
# pmin(psi/VaR, exp(((abs(Bmax)/peak)^w2) * log(psi/VaR)))


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, May 2, 2016 at 11:31 AM, T.Riedle <tr206 at kent.ac.uk> wrote:

> Dear R users,
>
> I am trying to generate a 3D plot using the wireframe() function in the
> lattice package.
>
> The corresponding formula in Excel looks as follows and is applied to the
> wireframe() function:
>
> MIN(psi/K14,EXP(((ABS(H14)/peak)^omega)*LN(psi/K14)))
>
> I tried to "translate" this formula in R and the code looks as follows
>
>
> min(psi/VaR,exp(((abs(B)/Bmax)^w2)*log((psi/VaR),2.718182)))
>
>
>
> In this case I get only one value which is NAN but I should get a time
> series with 13000 values. Hence, I deleted the min() function and tried the
> wireframe() function:
>
>
>
> wireframe(inflator~exp((abs(B)/Bmax)^w2)*log((psi/VaR),base=2.718182),data=data_3Dplot)
>
> However, it doesn't work as the formula for the inflator is incorrect. It
> produces NANs although it shouldn't do that and actually doesn't do that in
> Excel. Furthermore, the results are totally different to those calculated
> by Excel.
>
> Can anyone help me with the formula and translate it correctly in terms of
> R? How do I get the time series? How do I get the values I get in Excel?
>
> I have attached the data as csv file to this email.
>
> Thank you very much for your help.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tom at maladmin.com  Mon May  2 21:08:20 2016
From: tom at maladmin.com (Tom Wright)
Date: Mon, 2 May 2016 12:08:20 -0700
Subject: [R] how to use AND in grepl
In-Reply-To: <1224913045.9583904.1462212092443.JavaMail.yahoo@mail.yahoo.com>
References: <CAKmUXV-jq74NNqV7fai9HBZ3eNAT2eu4hBcA4VqW3BPFEnOS=w@mail.gmail.com>
	<1224913045.9583904.1462212092443.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAKmUXV8H54sysCw9nYpDq-fLj-sRMgPQT089nHojeyDU1gUFkg@mail.gmail.com>

Please try to read my earlier comments.
In the absence of a proper example with expected output I think what you
are trying to achieve is:

# create a sample dataframe
df <- data.frame(Command=c("_localize_PD", "_localize_tre_t2",
"_abdomen_t1_seq", "knee_pd_t1_localize", "pd_local_abdomen_t2"))

# identify which rows in the dataframe set match the patterns
# note, the vectors PD, T2 and PDT2 are booleans indicating if a match was
made
PD <- grepl("pd", df$Command)
T2 <- grepl('t2', df$Command)
PDT2 <- grepl("(.*t2.*pd.*)|(.*pd.*t2.*)", df$Command)

# create the new column to hold the new names
df$new_name <- NA

df[PD,'new_name'] <- 'pd'
df[T2,'new_name'] <- 't2'
df[PDT2,'new_name'] <- 'pdt2'


# note 1: the order of these command is important, if the last command is
run first all matches will be overwritten by the single matches for 't2'
and 'pd'.
# note 2: There is no match for row 1 as "PD" != "pd", as suggested by John
McKown the ignore.case parameter for grepl can be used to change this
behaviour.

On Mon, May 2, 2016 at 11:01 AM, <chalabi.elahe at yahoo.de> wrote:

> I just changed all the names in Command to lowercase, then this
> str_extract works fine for "pd" and "t2", but not for "PDT2". Do you have
> any idea how I can bring PDT2  also in str_extract?
>
>
> On Monday, May 2, 2016 9:16 AM, Tom Wright <tom at maladmin.com> wrote:
>
>
>
> The first thing I notice here is that your first two subset statements are
> searching in an object named Command, not the column df$Command. I'm not at
> all sure what you are trying to achieve with the str_extract process but it
> is looking for the exact string 'PDT2' the vectors / dataframe formed in
> your previous commands are not being used at all.
> Moving forward I think you need to pay attention to case "PD" != "pd".
> Also the set PDT2 is going to be a subset of both  sets PD and t2, I don't
> think this is what you are after.
>
> On Mon, May 2, 2016, 8:49 AM  <chalabi.elahe at yahoo.de> wrote:
>
> Yes it works, but let me explain what I am going to do. I extract all the
> names I want and then create a new column out of them for my plot. This is
> he whole thing I do:
> >  PD=subset(df,grepl("pd",Command)) //extract names in Command with only
> "pd"
> >  t2=subset(df,grepl("t2",Command)) //extract names with only "t2"
> >  PDT2=subset(df,grepl("(.*t2.*pd.*)|(.*pd.*t2.*)",df$Command) // extract
> names which contain both "pd" and "t2"
> >  v1=c('PD','t2','PDT2')// I create a vector with these conditions
> >  str_extract(df$Command,paste(v1,collaps='|')) //returning patterns,
> using stringr library
> >
> >here I see no pattern named PDT2 but there are only PD and t2 patterns.
> >On Monday, May 2, 2016 8:18 AM, Tom Wright <tom at maladmin.com> wrote:
> >
> >
> >
> >Sorry for the missed braces earlier. I was typing on a phone, not the
> best place to conjugate regular expressions.
> >Using the example you provided:
> >
> >> df=data.frame(Command=c("_localize_PD", "_localize_tre_t2",
> "_abdomen_t1_seq", "knee_pd_t1_localize", "pd_local_abdomen_t2"))
> >
> >> grepl("(.*t2.*pd.*)|(.*pd.*t2.*)",df$Command)
> >[1] FALSE FALSE FALSE FALSE  TRUE
> >
> >> subset(df,grepl("(.*t2.*pd.*)|(.*pd.*t2.*)",df$Command))
> >              Command
> >5 pd_local_abdomen_t2
> >
> >
> >
> >On Mon, May 2, 2016 at 7:42 AM, <chalabi.elahe at yahoo.de> wrote:
> >
> >Thanks Peter, you were right, the exact grepl is
> grepl("(.*t2.*pd.*)|(.*pd.*t2.*)",df$Command), but it does not change
> anything in Command, when I check the size of it by
> sum(grepl("(.*t2.*pd.*)|(.*pd.*t2.*)",df$Command))  the result is 0, but I
> am sure that the size is not 0. It seems that this AND does not work.
> >>
> >>
> >>
> >>On Monday, May 2, 2016 5:05 AM, peter dalgaard <pdalgd at gmail.com> wrote:
> >>
> >>On 02 May 2016, at 12:43 , ch.elahe via R-help <r-help at r-project.org>
> wrote:
> >>
> >>> Thanks for your reply tom. After using
> Subset(df,grepl("(.*t2.*pd.*)|(.*pd.*t2.*)"),df$Command)  I get this error:
> Argument "x" is missing, with no default. Actually I don't know how to fix
> this. Do you have any idea?
> >>
> >>Tom's code was missing a ")" but not where you put one. He probably also
> didn't intend to capitalize "subset".
> >>
> >>
> >>-pd
> >>
> >>> Thanks,
> >>> Elahe
> >>>
> >>>
> >>> On Saturday, April 30, 2016 7:35 PM, Tom Wright <tom at maladmin.com>
> wrote:
> >>>
> >>>
> >>>
> >>> Actually not sure my previous answer does what you wanted. Using your
> approach:
> >>> t2pd=subset(df,grepl("t2",df$Command) & grepl("pd",df$Command))
> >>> Should work.
> >>> I think the regex pattern you are looking for is:
> >>> Subset(df,grepl("(.* t2.*pd.* )|(.* pd.* t2.*)",df$Command)
> >>>
> >>> On Sat, Apr 30, 2016, 7:07 PM Tom Wright <tom at maladmin.com> wrote:
> >>>
> >>> subset(df,grepl("t2|pd",x$Command))
> >>>>
> >>>>
> >>>>
> >>>>
> >>>> On Sat, Apr 30, 2016 at 2:38 PM, ch.elahe via R-help <
> r-help at r-project.org> wrote:
> >>>>
> >>>> Hi all,
> >>>>>
> >>>>> I have one factor variable in my df and I want to extract the names
> from it which contain both "t2" and "pd":
> >>>>>
> >>>>> 'data.frame': 36919 obs. of 162 variables
> >>>>>  $TE                :int 38,41,11,52,48,75,.....
> >>>>>  $TR                :int 100,210,548,546,.....
> >>>>>  $Command          :factor W/2229 levels
> "_localize_PD","_localize_tre_t2","_abdomen_t1_seq","knee_pd_t1_localize","pd_local_abdomen_t2"...
> >>>>>
> >>>>> I have tried this but I did not get result:
> >>>>>
> >>>>> t2pd=subset(df,grepl("t2",Command) & grepl("pd",Command))
> >>>>>
> >>>>>
> >>>>> does anyone know how to apply AND in grepl?
> >>>>>
> >>>>> Thanks
> >>>>> Elahe
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>> .
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>--
> >>Peter Dalgaard, Professor,
> >>Center for Statistics, Copenhagen Business School
> >>Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> >>Phone: (+45)38153501
> >>Office: A 4.23
> >>Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> >>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon May  2 21:39:46 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 2 May 2016 12:39:46 -0700
Subject: [R] greek characters in Figures
In-Reply-To: <1770895494.4876101.1462210354831.JavaMail.yahoo@mail.yahoo.com>
References: <1770895494.4876101.1462210354831.JavaMail.yahoo.ref@mail.yahoo.com>
	<1770895494.4876101.1462210354831.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <F132CF86-8EDD-4E21-85B0-E429E86586FA@comcast.net>


> On May 2, 2016, at 10:32 AM, Alaios via R-help <r-help at r-project.org> wrote:
> 
> Dear all,I am trying to write in my Figure labels short equations that contain greek characters
> 
> For example:  C(h) = sigma^2 * rho(h).   
> 
> I am googling it and there are many packages available but unfortunately they do not look available for my 3.2.4 latex version
> 
> install.packages("latex2expr")

My efforts found a 'latex2exp' but no 'latex2expr'. Are you sure you are not missplelling the package name?


> Installiere Paket nach ?/home/apa/R/x86_64-pc-linux-gnu-library/3.2?(da ?lib? nicht spezifiziert)Warnung: kann nicht auf den Index f?r das Repository https://cran.cnr.Berkeley.edu/src/contrib zugreifen:  nicht unterst?tztes URL SchemaWarnmeldung:Paket ?latex2expr? ist nicht verf?gbar (for R version 3.2.4 Revised) 
> 
> Any ideas what else I can try?I would like to thank you in advance for your replyRegardsAlex
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From lordpreetam at gmail.com  Mon May  2 23:25:38 2016
From: lordpreetam at gmail.com (Preetam Pal)
Date: Tue, 3 May 2016 02:55:38 +0530
Subject: [R] Accessing terminal datasets in Ctree()
Message-ID: <CAHVFrXEc7azk6F5+qpNQVHkTGQ_NSj1OUFaDkxHdLMqkZh4iJQ@mail.gmail.com>

Hi guys,

If I am applying ctree() on a data (specifying some control parameters like
maxdepth), is there a way I can programmatically access the (smaller)
datasets corresponding to the terminal nodes in the tree? Say, if there are
7 terminal nodes, I need those 7 datasets (of course, I can look at the
respective node-splitting attributes and write out a filtering function -
but clearly too much to ask for if I have a large number of terminal
nodes). Intention is to perform regression on each of these terminal
datasets.

Regards,
Preetam

-- 
Preetam Pal
(+91)-9432212774
M-Stat 2nd Year,                                             Room No. N-114
Statistics Division,                                           C.V.Raman
Hall
Indian Statistical Institute,                                 B.H.O.S.
Kolkata.

	[[alternative HTML version deleted]]


From Achim.Zeileis at uibk.ac.at  Mon May  2 23:38:18 2016
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Mon, 2 May 2016 23:38:18 +0200 (CEST)
Subject: [R] Accessing terminal datasets in Ctree()
In-Reply-To: <CAHVFrXEc7azk6F5+qpNQVHkTGQ_NSj1OUFaDkxHdLMqkZh4iJQ@mail.gmail.com>
References: <CAHVFrXEc7azk6F5+qpNQVHkTGQ_NSj1OUFaDkxHdLMqkZh4iJQ@mail.gmail.com>
Message-ID: <alpine.DEB.2.20.1605022333310.21730@paninaro>

On Mon, 2 May 2016, Preetam Pal wrote:

> Hi guys,
>
> If I am applying ctree() on a data (specifying some control parameters like
> maxdepth), is there a way I can programmatically access the (smaller)
> datasets corresponding to the terminal nodes in the tree? Say, if there are
> 7 terminal nodes, I need those 7 datasets (of course, I can look at the
> respective node-splitting attributes and write out a filtering function -
> but clearly too much to ask for if I have a large number of terminal
> nodes). Intention is to perform regression on each of these terminal
> datasets.

If you use the "partykit" implementation you can do:

library("partykit")
ct <- ctree(Species ~ ., data = iris)
data_party(ct, id = 6)

to obtain the data associated with node 6 for example. You can also use 
ct[6] to obtain the subtree and ct[6]$data for its associated data.

For setting up a factor with the terminal node IDs, you can also use 
predict(ct, type = "node") and then use that in lm() etc.

Finally, note that there is also lmtree() and glmtree() for trees with 
(generalized) linear models in their nodes.

> Regards,
> Preetam
>
> -- 
> Preetam Pal
> (+91)-9432212774
> M-Stat 2nd Year,                                             Room No. N-114
> Statistics Division,                                           C.V.Raman
> Hall
> Indian Statistical Institute,                                 B.H.O.S.
> Kolkata.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From lordpreetam at gmail.com  Mon May  2 23:46:20 2016
From: lordpreetam at gmail.com (Preetam Pal)
Date: Tue, 3 May 2016 03:16:20 +0530
Subject: [R] Accessing terminal datasets in Ctree()
In-Reply-To: <alpine.DEB.2.20.1605022333310.21730@paninaro>
References: <CAHVFrXEc7azk6F5+qpNQVHkTGQ_NSj1OUFaDkxHdLMqkZh4iJQ@mail.gmail.com>
	<alpine.DEB.2.20.1605022333310.21730@paninaro>
Message-ID: <CAHVFrXGsLGg4JdePfDwpuVRh2W8xFvD9KebJOt04NHkQRaNHaA@mail.gmail.com>

Great, thank you so much Achim.
But one issue, in case I do not know how many terminal nodes would be
there, what do I do? Note that I do not need the datasets corresponding to
the intermediate nodes only need the terminal datasets.
Regards,
Preetam

On Tue, May 3, 2016 at 3:08 AM, Achim Zeileis <Achim.Zeileis at uibk.ac.at>
wrote:

> On Mon, 2 May 2016, Preetam Pal wrote:
>
> Hi guys,
>>
>> If I am applying ctree() on a data (specifying some control parameters
>> like
>> maxdepth), is there a way I can programmatically access the (smaller)
>> datasets corresponding to the terminal nodes in the tree? Say, if there
>> are
>> 7 terminal nodes, I need those 7 datasets (of course, I can look at the
>> respective node-splitting attributes and write out a filtering function -
>> but clearly too much to ask for if I have a large number of terminal
>> nodes). Intention is to perform regression on each of these terminal
>> datasets.
>>
>
> If you use the "partykit" implementation you can do:
>
> library("partykit")
> ct <- ctree(Species ~ ., data = iris)
> data_party(ct, id = 6)
>
> to obtain the data associated with node 6 for example. You can also use
> ct[6] to obtain the subtree and ct[6]$data for its associated data.
>
> For setting up a factor with the terminal node IDs, you can also use
> predict(ct, type = "node") and then use that in lm() etc.
>
> Finally, note that there is also lmtree() and glmtree() for trees with
> (generalized) linear models in their nodes.
>
> Regards,
>> Preetam
>>
>> --
>> Preetam Pal
>> (+91)-9432212774
>> M-Stat 2nd Year,                                             Room No.
>> N-114
>> Statistics Division,                                           C.V.Raman
>> Hall
>> Indian Statistical Institute,                                 B.H.O.S.
>> Kolkata.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>


-- 
Preetam Pal
(+91)-9432212774
M-Stat 2nd Year,                                             Room No. N-114
Statistics Division,                                           C.V.Raman
Hall
Indian Statistical Institute,                                 B.H.O.S.
Kolkata.

	[[alternative HTML version deleted]]


From Achim.Zeileis at uibk.ac.at  Mon May  2 23:52:38 2016
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Mon, 2 May 2016 23:52:38 +0200 (CEST)
Subject: [R] Accessing terminal datasets in Ctree()
In-Reply-To: <CAHVFrXGsLGg4JdePfDwpuVRh2W8xFvD9KebJOt04NHkQRaNHaA@mail.gmail.com>
References: <CAHVFrXEc7azk6F5+qpNQVHkTGQ_NSj1OUFaDkxHdLMqkZh4iJQ@mail.gmail.com>
	<alpine.DEB.2.20.1605022333310.21730@paninaro>
	<CAHVFrXGsLGg4JdePfDwpuVRh2W8xFvD9KebJOt04NHkQRaNHaA@mail.gmail.com>
Message-ID: <alpine.DEB.2.20.1605022351190.21730@paninaro>

On Mon, 2 May 2016, Preetam Pal wrote:

> Great, thank you so much Achim.But one issue, in case I do not know how many
> terminal nodes would be there, what do I do? Note that I do not need the
> datasets corresponding to the intermediate nodes only need the terminal
> datasets.

With predict(ct, type = "node") you can set up a new variable, e.g.,

iris$node <- factor(predict(ct, type = "node"))

and then use this to obtain the subset corresponding to each of the 
terminal nodes.

> Regards,
> Preetam?
> 
> On Tue, May 3, 2016 at 3:08 AM, Achim Zeileis <Achim.Zeileis at uibk.ac.at>
> wrote:
>       On Mon, 2 May 2016, Preetam Pal wrote:
>
>             Hi guys,
>
>             If I am applying ctree() on a data (specifying some
>             control parameters like
>             maxdepth), is there a way I can programmatically
>             access the (smaller)
>             datasets corresponding to the terminal nodes in the
>             tree? Say, if there are
>             7 terminal nodes, I need those 7 datasets (of
>             course, I can look at the
>             respective node-splitting attributes and write out a
>             filtering function -
>             but clearly too much to ask for if I have a large
>             number of terminal
>             nodes). Intention is to perform regression on each
>             of these terminal
>             datasets.
> 
>
>       If you use the "partykit" implementation you can do:
>
>       library("partykit")
>       ct <- ctree(Species ~ ., data = iris)
>       data_party(ct, id = 6)
>
>       to obtain the data associated with node 6 for example. You can
>       also use ct[6] to obtain the subtree and ct[6]$data for its
>       associated data.
>
>       For setting up a factor with the terminal node IDs, you can also
>       use predict(ct, type = "node") and then use that in lm() etc.
>
>       Finally, note that there is also lmtree() and glmtree() for
>       trees with (generalized) linear models in their nodes.
>
>             Regards,
>             Preetam
>
>             --
>             Preetam Pal
>             (+91)-9432212774
>             M-Stat 2nd Year,? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
>             ? ? ? ? ?Room No. N-114
>             Statistics Division,? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
>             ? ? ? ? ? ?C.V.Raman
>             Hall
>             Indian Statistical Institute,? ? ? ? ? ? ? ? ? ? ? ?
>             ? ? ? ? ?B.H.O.S.
>             Kolkata.
>
>             ? ? ? ? [[alternative HTML version deleted]]
>
>             ______________________________________________
>             R-help at r-project.org mailing list -- To UNSUBSCRIBE
>             and more, see
>             https://stat.ethz.ch/mailman/listinfo/r-help
>             PLEASE do read the posting guide
>             http://www.R-project.org/posting-guide.html
>             and provide commented, minimal, self-contained,
>             reproducible code.
> 
> 
> 
> 
> --
> Preetam Pal ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
> (+91)-9432212774
> M-Stat 2nd Year, ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Room No. N-114
> Statistics Division, ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? C.V.Raman
> HallIndian Statistical Institute, ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? B.H.O.S.
> Kolkata.
> 
>

From lordpreetam at gmail.com  Mon May  2 23:56:30 2016
From: lordpreetam at gmail.com (Preetam Pal)
Date: Tue, 3 May 2016 03:26:30 +0530
Subject: [R] Accessing terminal datasets in Ctree()
In-Reply-To: <alpine.DEB.2.20.1605022351190.21730@paninaro>
References: <CAHVFrXEc7azk6F5+qpNQVHkTGQ_NSj1OUFaDkxHdLMqkZh4iJQ@mail.gmail.com>
	<alpine.DEB.2.20.1605022333310.21730@paninaro>
	<CAHVFrXGsLGg4JdePfDwpuVRh2W8xFvD9KebJOt04NHkQRaNHaA@mail.gmail.com>
	<alpine.DEB.2.20.1605022351190.21730@paninaro>
Message-ID: <CAHVFrXFE6FC-rV5z+XEJhLaYytE8aftCHgQgNm++TaJGzj3qdw@mail.gmail.com>

Again, really appreciate your help on this. Thanks, Achim.
-Preetam

On Tue, May 3, 2016 at 3:22 AM, Achim Zeileis <Achim.Zeileis at uibk.ac.at>
wrote:

> On Mon, 2 May 2016, Preetam Pal wrote:
>
> Great, thank you so much Achim.But one issue, in case I do not know how
>> many
>> terminal nodes would be there, what do I do? Note that I do not need the
>> datasets corresponding to the intermediate nodes only need the terminal
>> datasets.
>>
>
> With predict(ct, type = "node") you can set up a new variable, e.g.,
>
> iris$node <- factor(predict(ct, type = "node"))
>
> and then use this to obtain the subset corresponding to each of the
> terminal nodes.
>
>
> Regards,
>> Preetam
>>
>> On Tue, May 3, 2016 at 3:08 AM, Achim Zeileis <Achim.Zeileis at uibk.ac.at>
>> wrote:
>>       On Mon, 2 May 2016, Preetam Pal wrote:
>>
>>             Hi guys,
>>
>>             If I am applying ctree() on a data (specifying some
>>             control parameters like
>>             maxdepth), is there a way I can programmatically
>>             access the (smaller)
>>             datasets corresponding to the terminal nodes in the
>>             tree? Say, if there are
>>             7 terminal nodes, I need those 7 datasets (of
>>             course, I can look at the
>>             respective node-splitting attributes and write out a
>>             filtering function -
>>             but clearly too much to ask for if I have a large
>>             number of terminal
>>             nodes). Intention is to perform regression on each
>>             of these terminal
>>             datasets.
>>
>>
>>       If you use the "partykit" implementation you can do:
>>
>>       library("partykit")
>>       ct <- ctree(Species ~ ., data = iris)
>>       data_party(ct, id = 6)
>>
>>       to obtain the data associated with node 6 for example. You can
>>       also use ct[6] to obtain the subtree and ct[6]$data for its
>>       associated data.
>>
>>       For setting up a factor with the terminal node IDs, you can also
>>       use predict(ct, type = "node") and then use that in lm() etc.
>>
>>       Finally, note that there is also lmtree() and glmtree() for
>>       trees with (generalized) linear models in their nodes.
>>
>>             Regards,
>>             Preetam
>>
>>             --
>>             Preetam Pal
>>             (+91)-9432212774
>>             M-Stat 2nd Year,
>>                      Room No. N-114
>>             Statistics Division,
>>                        C.V.Raman
>>             Hall
>>             Indian Statistical Institute,
>>                      B.H.O.S.
>>             Kolkata.
>>
>>                     [[alternative HTML version deleted]]
>>
>>             ______________________________________________
>>             R-help at r-project.org mailing list -- To UNSUBSCRIBE
>>             and more, see
>>             https://stat.ethz.ch/mailman/listinfo/r-help
>>             PLEASE do read the posting guide
>>             http://www.R-project.org/posting-guide.html
>>             and provide commented, minimal, self-contained,
>>             reproducible code.
>>
>>
>>
>>
>> --
>> Preetam Pal
>> (+91)-9432212774
>> M-Stat 2nd Year,                                             Room No.
>> N-114
>> Statistics Division,                                           C.V.Raman
>> HallIndian Statistical Institute,                                 B.H.O.S.
>> Kolkata.
>>
>>


-- 
Preetam Pal
(+91)-9432212774
M-Stat 2nd Year,                                             Room No. N-114
Statistics Division,                                           C.V.Raman
Hall
Indian Statistical Institute,                                 B.H.O.S.
Kolkata.

	[[alternative HTML version deleted]]


From richard_raubertas at merck.com  Tue May  3 00:00:48 2016
From: richard_raubertas at merck.com (Raubertas, Richard)
Date: Mon, 2 May 2016 18:00:48 -0400
Subject: [R] Create a new variable and concatenation inside a "for" loop
In-Reply-To: <094A4DD5-947E-4A20-B543-045F1036B915@dcn.davis.ca.us>
References: <VI1PR06MB116560D3E0A1EDB3E872DA20B2640@VI1PR06MB1165.eurprd06.prod.outlook.com>
	<094A4DD5-947E-4A20-B543-045F1036B915@dcn.davis.ca.us>
Message-ID: <1D693EC430D9BA40A64CB59875BED8CF017DC4196E8D@USCTMXP51004.merck.com>

What nonsense.  There is a group of finger-waggers on this list who jump on every poster who uses the name of an R function as a variable name.  R is perfectly capable of distinguishing the two, so if 'c' (or 'data' or 'df', etc.) is the natural name for a variable then go ahead and use it.  Mr. Newmiller provides an excellent example of this:  he recommends 'C' instead of 'c', apparently without realizing that 'C' is also a built-in R function--because there is "no such problem".

Richard Raubertas

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jeff Newmiller
Sent: Wednesday, April 27, 2016 3:58 PM
To: Gordon, Fabiana; 'r-help at R-project.org'
Subject: Re: [R] Create a new variable and concatenation inside a "for" loop

"c" an extremely commonly-used function. Functions are first-class objects that occupy the same namespaces that variables do, so they can obscure each other. In short, don't use variables called "c" (R is case sensitive, so "C" has no such problem).

Wherever possible, avoid incremental concatenation like the plague. If you feel you must use it, at least concatenate in lists and then use functions like unlist, do.call, or pre-allocate vectors or matrix-like objects with unuseful values like NA and then overwrite each element in the vector or matrix-type object in a loop like your first one. 
-- 
Sent from my phone. Please excuse my brevity.

On April 27, 2016 3:25:14 PM GMT+01:00, "Gordon, Fabiana" <fabiana.gordon at imperial.ac.uk> wrote:
>Hello,
>
>Suppose the you need a loop to create a new variable , i.e., you are
>not reading data from outside the loop. This is a simple example in
>Matlab code,
>
>for i=1:5
>r1=randn
>r2=randn
>r=[r1 r2]
>c(i,:)=r;   % creation of each row of c , % the ":" symbol indicates
>all columns. In R this would be [i,]
>end
>
>The output of interest is c which I'm creating inside the "for" loop
>-also the index used in the loop is used to create c. In R I had to
>create c as an  empty vector (numeric() ) outside the loop, otherwise I
>get an error message saying that c doesn't exit.
>
>The other issue is the concatenation. In each iteration I'm creating
>the rows of c by placing the new row  (r) below the previous one so
>that c becomes a 5 x 2 matrix.
>In R, it seems that I have no choice but use the function "rbind". I
>managed to write this code in R . However, I'm not sure that if instead
>of creating a new variable  using  the index in the "for" loop , I
>wanted to use the index to read data, e.g.  suppose I have a 2 X 10
>matrix X and suppose I want to calculate the sin () for each 2 x 2
>sub-matrix of and stored in a matrix A. Then the code would be
>something like this,
>
>for i=1:5
>A(:, 2*i-1:2*i)= sin(X(:, 2*i-1:2*i))   % the ":" symbol indicates all
>rows
>end
>
>Many Thanks,
>
>Fabiana
>
>
>Dr Fabiana Gordon
>
>Senior Statistical Consultant
>Statistical Advisory Service, School Of Public Health,
>Imperial College London
>1st Floor, Stadium House, 68 Wood Lane,
>London W12 7RH.
>
>Tel: 020 7594 1749
>Email:
>fabiana.gordon at imperial.ac.uk<mailto:fabiana.gordon at imperial.ac.uk>
>Web: 
>www.imperial.ac.uk/research-and-innovation/support-for-staff/stats-advice-service/<http://www.imperial.ac.uk/research-and-innovation/support-for-staff/stats-advice-service/>
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
Notice:  This e-mail message, together with any attachme...{{dropped:11}}


From tom at maladmin.com  Tue May  3 01:45:01 2016
From: tom at maladmin.com (Tom Wright)
Date: Mon, 02 May 2016 23:45:01 +0000
Subject: [R] Create a new variable and concatenation inside a "for" loop
In-Reply-To: <VI1PR06MB116560D3E0A1EDB3E872DA20B2640@VI1PR06MB1165.eurprd06.prod.outlook.com>
References: <VI1PR06MB116560D3E0A1EDB3E872DA20B2640@VI1PR06MB1165.eurprd06.prod.outlook.com>
Message-ID: <CAKmUXV9XQ6yFYYXGvpQUoenwOa6Zts8rWrTbN-MvCoje16GBfw@mail.gmail.com>

As pointed out somewhere in the replies to this you can always use the
exists() function.
for(i in 1:5){
    if(exists(output)){
        output <- c(output, i )
    }else{
       output <- i
   }
}

On Wed, Apr 27, 2016, 11:15 AM Gordon, Fabiana <
fabiana.gordon at imperial.ac.uk> wrote:

> Hello,
>
> Suppose the you need a loop to create a new variable , i.e., you are not
> reading data from outside the loop. This is a simple example in Matlab code,
>
> for i=1:5
> r1=randn
> r2=randn
> r=[r1 r2]
> c(i,:)=r;   % creation of each row of c , % the ":" symbol indicates all
> columns. In R this would be [i,]
> end
>
> The output of interest is c which I'm creating inside the "for" loop -also
> the index used in the loop is used to create c. In R I had to create c as
> an  empty vector (numeric() ) outside the loop, otherwise I get an error
> message saying that c doesn't exit.
>
> The other issue is the concatenation. In each iteration I'm creating the
> rows of c by placing the new row  (r) below the previous one so that c
> becomes a 5 x 2 matrix.
> In R, it seems that I have no choice but use the function "rbind". I
> managed to write this code in R . However, I'm not sure that if instead of
> creating a new variable  using  the index in the "for" loop , I wanted to
> use the index to read data, e.g.  suppose I have a 2 X 10 matrix X and
> suppose I want to calculate the sin () for each 2 x 2 sub-matrix of and
> stored in a matrix A. Then the code would be something like this,
>
> for i=1:5
> A(:, 2*i-1:2*i)= sin(X(:, 2*i-1:2*i))   % the ":" symbol indicates all rows
> end
>
> Many Thanks,
>
> Fabiana
>
>
> Dr Fabiana Gordon
>
> Senior Statistical Consultant
> Statistical Advisory Service, School Of Public Health,
> Imperial College London
> 1st Floor, Stadium House, 68 Wood Lane,
> London W12 7RH.
>
> Tel: 020 7594 1749
> Email: fabiana.gordon at imperial.ac.uk<mailto:fabiana.gordon at imperial.ac.uk>
> Web:
> www.imperial.ac.uk/research-and-innovation/support-for-staff/stats-advice-service/
> <
> http://www.imperial.ac.uk/research-and-innovation/support-for-staff/stats-advice-service/
> >
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Tue May  3 01:54:49 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 3 May 2016 11:54:49 +1200
Subject: [R] Create a new variable and concatenation inside a "for" loop
In-Reply-To: <1D693EC430D9BA40A64CB59875BED8CF017DC4196E8D@USCTMXP51004.merck.com>
References: <VI1PR06MB116560D3E0A1EDB3E872DA20B2640@VI1PR06MB1165.eurprd06.prod.outlook.com>
	<094A4DD5-947E-4A20-B543-045F1036B915@dcn.davis.ca.us>
	<1D693EC430D9BA40A64CB59875BED8CF017DC4196E8D@USCTMXP51004.merck.com>
Message-ID: <2931e739-1796-01f9-8514-a842d328cc57@auckland.ac.nz>



You are quite wrong.  This is not "nonsense"; it is sound advice.  It is 
true that R is capable of distinguishing between a function and a 
non-function object with the same name.  However there are many 
circumstances in which using a function's name for the name of a data 
object will lead to errors in function calls and the resulting error 
messages will be difficult to interpret.  (Things like "object of type 
'builtin' is not subsettable".)

Indulging in using "c" (e.g.) for the name of a data object is bad 
practice and mental laziness.

I would suggest that you restrain your presumptuousness and arrogance, 
and refrain from telling experienced and wise R gurus, like Jeff 
Newmiller, that their ideas are "nonsense" until you have a little more 
experience with and knowledge of R.

I am sure that you will insist on arguing about this and that you will 
continue to claim that black is white, but the fact remains that you are 
wrong.  Others should pay no attention to your ranting.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

On 03/05/16 10:00, Raubertas, Richard wrote:
> What nonsense. There is a group of finger-waggers on this list who
> jump on every poster who uses the name of an R function as a variable
> name. R is perfectly capable of distinguishing the two, so if 'c' (or
> 'data' or 'df', etc.) is the natural name for a variable then go ahead
> and use it. Mr. Newmiller provides an excellent example of this: he
> recommends 'C' instead of 'c', apparently without realizing that 'C' is
> also a built-in R function--because there is "no such problem".
>
> Richard Raubertas
>
> -----Original Message----- From: R-help
> [mailto:r-help-bounces at r-project.org] On Behalf Of JeffNewmiller
> Sent: Wednesday, April 27, 2016 3:58 PM To: Gordon, Fabiana;
> 'r-help at R-project.org' Subject: Re: [R] Create a new variable and
> concatenation inside a  "for" loop
> "c" an extremely commonly-used function. Functions are first-class
> objects that occupy the same namespaces that variables do, so they can
> obscure each other. In short, don't use variables called "c" (R is case
> sensitive, so "C" has no such problem).
>
> Wherever possible, avoid incremental concatenation like the plague.
> If  you feel you must use it, at least concatenate in lists and then use
> functions like unlist, do.call, or pre-allocate vectors or matrix-like
> objects with unuseful values like NA and then overwrite each element in
> the vector or matrix-type object in a loop like your first one.


From miaojpm at gmail.com  Tue May  3 04:56:04 2016
From: miaojpm at gmail.com (jpm miao)
Date: Mon, 2 May 2016 19:56:04 -0700
Subject: [R] Extracting rows of a data.frame by "identical"
Message-ID: <CABcx46CkjM4abpMv2sJeYEC6BRnaa61rn5rOHKs9pfXuQMXsBA@mail.gmail.com>

Is it possible? I am expecting the result to be the second row of the data
frame ...


d<-data.frame(a=1:3, b=3:5,c=9:11)
> d
  a b  c
1 1 3  9
2 2 4 10
3 3 5 11
> d[identical(d[c("b","c")],c(4,10)),]
[1] a b c
<0 rows> (or 0-length row.names)

	[[alternative HTML version deleted]]


From miaojpm at gmail.com  Tue May  3 05:21:20 2016
From: miaojpm at gmail.com (jpm miao)
Date: Mon, 2 May 2016 20:21:20 -0700
Subject: [R] Use "append" in the function write.xlsx2 or write.xlsx
	(openxlsx package)
Message-ID: <CABcx46DWgBJ6qNZ87gOLYz5-t9fUNPUeb9m_b1oQnB1T+Ktdqg@mail.gmail.com>

Hi,

   I am trying to print several dataset in several different sheets of the
same xlsx file.
I sometimes run the codes more than once, and I need to erase all things in
the target file, and I do not use "append" in the first function call.
However I want to write it in a loop. Is there a way to initiate a blank
xlsx file so that I can use "append = TRUE" whenever I call the function
write.xlsx2?

output_file2<-"data_xx.xlsx"
write.xlsx2(x= df_all2[["a"]], file = output_file2, sheetName = "a")
write.xlsx2(x= df_all2[["b"]], file = output_file2, sheetName = "b",
append=TRUE)
write.xlsx2(x= df_all2[["c"]], file = output_file2, sheetName = "c",
append= TRUE)

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Tue May  3 05:40:51 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Tue, 03 May 2016 03:40:51 +0000
Subject: [R] Extracting rows of a data.frame by "identical"
In-Reply-To: <CABcx46CkjM4abpMv2sJeYEC6BRnaa61rn5rOHKs9pfXuQMXsBA@mail.gmail.com>
References: <CABcx46CkjM4abpMv2sJeYEC6BRnaa61rn5rOHKs9pfXuQMXsBA@mail.gmail.com>
Message-ID: <CAKVAULOqjeOdte562sB7deYTHTP3nT2=D3=buzW58gNRzzMGqQ@mail.gmail.com>

Can you use subset?

subset(d, b == 4 & c == 10)

Best
Ulrik

On Tue, 3 May 2016 04:58 jpm miao, <miaojpm at gmail.com> wrote:

> Is it possible? I am expecting the result to be the second row of the data
> frame ...
>
>
> d<-data.frame(a=1:3, b=3:5,c=9:11)
> > d
>   a b  c
> 1 1 3  9
> 2 2 4 10
> 3 3 5 11
> > d[identical(d[c("b","c")],c(4,10)),]
> [1] a b c
> <0 rows> (or 0-length row.names)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ivan.calandra at univ-reims.fr  Tue May  3 09:13:28 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Tue, 3 May 2016 09:13:28 +0200
Subject: [R] Extracting rows of a data.frame by "identical"
In-Reply-To: <CABcx46CkjM4abpMv2sJeYEC6BRnaa61rn5rOHKs9pfXuQMXsBA@mail.gmail.com>
References: <CABcx46CkjM4abpMv2sJeYEC6BRnaa61rn5rOHKs9pfXuQMXsBA@mail.gmail.com>
Message-ID: <89c5c025-6b14-7576-8dfb-c67e84fe5db2@univ-reims.fr>

I'm not sure what you are trying to do...

Have you checked what the output of d[c("b","c")] is? And what about the 
output of identical(d[c("b","c")],c(4,10)) ? As is, I don't see the 
point of going through identical(). Maybe you're looking for which() or 
"%in%"?

If you just want to subset the second row, and second and third columns, 
then just do it! In your code, you forgot to subset for the rows... Here 
is an idea:
d[2, c("b","c")]
You can also use the function subset() as Ulrik has shown you.

HTH,
Ivan

--
Ivan Calandra, PhD
Scientific Mediator
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 03/05/2016 ? 04:56, jpm miao a ?crit :
> Is it possible? I am expecting the result to be the second row of the data
> frame ...
>
>
> d<-data.frame(a=1:3, b=3:5,c=9:11)
>> d
>    a b  c
> 1 1 3  9
> 2 2 4 10
> 3 3 5 11
>> d[identical(d[c("b","c")],c(4,10)),]
> [1] a b c
> <0 rows> (or 0-length row.names)
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ivan.calandra at univ-reims.fr  Tue May  3 09:32:12 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Tue, 3 May 2016 09:32:12 +0200
Subject: [R] Use "append" in the function write.xlsx2 or write.xlsx
 (openxlsx package)
In-Reply-To: <CABcx46DWgBJ6qNZ87gOLYz5-t9fUNPUeb9m_b1oQnB1T+Ktdqg@mail.gmail.com>
References: <CABcx46DWgBJ6qNZ87gOLYz5-t9fUNPUeb9m_b1oQnB1T+Ktdqg@mail.gmail.com>
Message-ID: <a205d82f-fc81-6e72-fbde-cf3624e53fca@univ-reims.fr>

Not sure this is what you need or the best way to do it, but you could 
do something along these lines:

#first create a file name that depends on which file names already 
exist. The big thing here is list.files() but you probably need to adapt 
the rest to your needs:
fileNumber <- list.files(pattern="xxx")
fileName <- paste0("xxx", length(fileNumber)+1 , ".xlsx")

#then write to xlsx in a loop:
for(i in ...){
   write.xlsx2(df_all2[[i]], file=fileName, sheetName=i, append=TRUE)
}

This works at least with xlsx::write.xlsx2(), with no error or warning 
even for when the file does not exist (first iteration)

HTH,
Ivan

--
Ivan Calandra, PhD
Scientific Mediator
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 03/05/2016 ? 05:21, jpm miao a ?crit :
> Hi,
>
>     I am trying to print several dataset in several different sheets of the
> same xlsx file.
> I sometimes run the codes more than once, and I need to erase all things in
> the target file, and I do not use "append" in the first function call.
> However I want to write it in a loop. Is there a way to initiate a blank
> xlsx file so that I can use "append = TRUE" whenever I call the function
> write.xlsx2?
>
> output_file2<-"data_xx.xlsx"
> write.xlsx2(x= df_all2[["a"]], file = output_file2, sheetName = "a")
> write.xlsx2(x= df_all2[["b"]], file = output_file2, sheetName = "b",
> append=TRUE)
> write.xlsx2(x= df_all2[["c"]], file = output_file2, sheetName = "c",
> append= TRUE)
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From pd.mes at cbs.dk  Tue May  3 10:37:56 2016
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Tue, 3 May 2016 08:37:56 +0000
Subject: [R]  R 3.3.0 is released
Message-ID: <4DC7E51C-2C95-4B9E-8A33-1094B7754736@cbs.dk>

The build system rolled up R-3.3.0.tar.gz (codename "Supposedly Educational") this morning.

The list below details the changes in this release.

You can get the source code from

http://cran.r-project.org/src/base/R-3/R-3.3.0.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard


These are the md5sums for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = eb97a5cd38acb1cfc6408988bffef765
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 76774c732435b189f155a8b2841c1221
MD5 (INSTALL) = 3964b9119adeaab9ceb633773fc94aac
MD5 (NEWS) = 37f3315e19326b206a062faade8751d9
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = 8e2f4d1d5228663ae598a09bf1e2bc6b
MD5 (R-latest.tar.gz) = 5a7506c8813432d1621c9725e86baf7a
MD5 (README) = aece1dfbd18c1760128c3787f5456af6
MD5 (RESOURCES) = 529223fd3ffef95731d0a87353108435
MD5 (THANKS) = f80d02e7ba9729a927e1c9cf7b435b32
MD5 (VERSION-INFO.dcf) = a3b0ab07e2e8209fb81fbe97a114a1a2
MD5 (R-3/R-3.3.0.tar.gz) = 5a7506c8813432d1621c9725e86baf7a


This is the relevant part of the NEWS file

CHANGES IN R 3.3.0:

  SIGNIFICANT USER-VISIBLE CHANGES:

    * nchar(x, *)'s argument keepNA governing how the result for NAs in
      x is determined, gets a new default keepNA = NA which returns NA
      where x is NA, except for type = "width" which still returns 2,
      the formatting / printing width of NA.

    * All builds have support for https: URLs in the default methods
      for download.file(), url() and code making use of them.

      Unfortunately that cannot guarantee that any particular https:
      URL can be accessed.  For example, server and client have to
      successfully negotiate a cryptographic protocol (TLS/SSL, ...)
      and the server's identity has to be verifiable _via_ the
      available certificates.  Different access methods may allow
      different protocols or use private certificate bundles: we
      encountered a https: CRAN mirror which could be accessed by one
      browser but not by another nor by download.file() on the same
      Linux machine.

  NEW FEATURES:

    * The print method for methods() gains a byclass argument.

    * New functions validEnc() and validUTF8() to give access to the
      validity checks for inputs used by grep() and friends.

    * Experimental new functionality for S3 method checking, notably
      isS3method().

      Also, the names of the R 'language elements' are exported as
      character vector tools::langElts.

    * str(x) now displays "Time-Series" also for matrix (multivariate)
      time-series, i.e. when is.ts(x) is true.

    * (Windows only) The GUI menu item to install local packages now
      accepts *.tar.gz files as well as *.zip files (but defaults to
      the latter).

    * New programmeR's utility function chkDots().

    * D() now signals an error when given invalid input, rather than
      silently returning NA.  (Request of John Nash.)

    * formula objects are slightly more "first class": e.g., formula()
      or new("formula", y ~ x) are now valid.  Similarly, for "table",
      "ordered" and "summary.table".  Packages defining S4 classes with
      the above S3/S4 classes as slots should be reinstalled.

    * New function strrep() for repeating the elements of a character
      vector.

    * rapply() preserves attributes on the list when how = "replace".

    * New S3 generic function sigma() with methods for extracting the
      estimated standard deviation aka "residual standard deviation"
      from a fitted model.

    * news() now displays R and package news files within the HTML help
      system if it is available.  If no news file is found, a visible
      NULL is returned to the console.

    * as.raster(x) now also accepts raw arrays x assuming values in
      0:255.

    * Subscripting of matrix/array objects of type "expression" is now
      supported.

    * type.convert("i") now returns a factor instead of a complex value
      with zero real part and missing imaginary part.

    * Graphics devices cairo_pdf() and cairo_ps() now allow non-default
      values of the cairographics 'fallback resolution' to be set.

      This now defaults to 300 on all platforms: that is the default
      documented by cairographics, but apparently was not used by all
      system installations.

    * file() gains an explicit method argument rather than implicitly
      using getOption("url.method", "default").

    * Thanks to a patch from Tomas Kalibera, x[x != 0] is now typically
      faster than x[which(x != 0)] (in the case where x has no NAs, the
      two are equivalent).

    * read.table() now always uses the names for a named colClasses
      argument (previously names were only used when colClasses was too
      short). (In part, wish of PR#16478.)

    * (Windows only) download.file() with default method = "auto" and a
      ftps:// URL chooses "libcurl" if that is available.

    * The out-of-the box Bioconductor mirror has been changed to one
      using https://: use chooseBioCmirror() to choose a http:// mirror
      if required.

    * The data frame and formula methods for aggregate() gain a drop
      argument.

    * available.packages() gains a repos argument.

    * The undocumented switching of methods for url() on https: and
      ftps: URLs is confined to method = "default" (and documented).

    * smoothScatter() gains a ret.selection argument.

    * qr() no longer has a ... argument to pass additional arguments to
      methods.

    * [ has a method for class "table".

    * It is now possible (again) to replayPlot() a display list
      snapshot that was created by recordPlot() in a different R
      session.

      It is still not a good idea to use snapshots as a persistent
      storage format for R plots, but it is now not completely silly to
      use a snapshot as a format for transferring an R plot between two
      R sessions.

      The underlying changes mean that packages providing graphics
      devices (e.g., Cairo, RSvgDevice, cairoDevice, tikzDevice) will
      need to be reinstalled.

      Code for restoring snapshots was contributed by Jeroen Ooms and
      JJ Allaire.

      Some testing code is available at <URL:
      https://github.com/pmur002/R-display-list>.

    * tools::undoc(dir = D) and codoc(dir = D) now also work when D is
      a directory whose normalizePath()ed version does not end in the
      package name, e.g. from a symlink.

    * abbreviate() has more support for multi-byte character sets - it
      no longer removes bytes within characters and knows about Latin
      vowels with accents.  It is still only really suitable for (most)
      European languages, and still warns on non-ASCII input.

      abbreviate(use.classes = FALSE) is now implemented, and that is
      more suitable for non-European languages.

    * match(x, table) is faster (sometimes by an order of magnitude)
      when x is of length one and incomparables is unchanged, thanks to
      Peter Haverty (PR#16491).

    * More consistent, partly not back-compatible behavior of NA and
      NaN coercion to complex numbers, operations less often resulting
      in complex NA (NA_complex_).

    * lengths() considers methods for length and [[ on x, so it should
      work automatically on any objects for which appropriate methods
      on those generics are defined.

    * The logic for selecting the default screen device on OS X has
      been simplified: it is now quartz() if that is available even if
      environment variable DISPLAY has been set by the user.

      The choice can easily be overridden _via_ environment variable
      R_INTERACTIVE_DEVICE.

    * On Unix-like platforms which support the getline C library
      function, system(*,intern = TRUE) no longer truncates (output)
      lines longer than 8192 characters, thanks to Karl Millar.
      (PR#16544)

    * rank() gains a ties.method = "last" option, for convenience (and
      symmetry).

    * regmatches(invert = NA) can now be used to extract both
      non-matched and matched substrings.

    * data.frame() gains argument fix.empty.names; as.data.frame.list()
      gets new cut.names, col.names and fix.empty.names.

    * plot(x ~ x, *) now warns that it is the same as plot(x ~ 1, *).

    * recordPlot() has new arguments load and attach to allow package
      names to be stored as part of a recorded plot.  replayPlot() has
      new argument reloadPkgs to load/attach any package names that
      were stored as part of a recorded plot.

    * S4 dispatch works within calls to .Internal(). This means
      explicit S4 generics are no longer needed for unlist() and
      as.vector().

    * Only font family names starting with "Hershey" (and not "Her" as
      before) are given special treatment by the graphics engine.

    * S4 values are automatically coerced to vector (via as.vector)
      when subassigned into atomic vectors.

    * findInterval() gets a left.open option.

    * The version of LAPACK included in the sources has been updated to
      3.6.0, including those 'deprecated' routines which were
      previously included.  _Ca_ 40 double-complex routines have been
      added at the request of a package maintainer.

      As before, the details of what is included are in
      src/modules/lapack/README and this now gives information on
      earlier additions.

    * tapply() has been made considerably more efficient without
      changing functionality, thanks to proposals from Peter Haverty
      and Suharto Anggono.  (PR#16640)

    * match.arg(arg) (the one-argument case) is faster; so is
      sort.int().  (PR#16640)

    * The format method for object_size objects now also accepts
      "binary" units such as "KiB" and e.g., "Tb".  (Partly from
      PR#16649.)

    * Profiling now records calls of the form foo::bar and some similar
      cases directly rather than as calls to <Anonymous>.  Contributed
      by Winston Chang.

    * New string utilities startsWith(x, prefix) and endsWith(x,
      suffix).  Also provide speedups for some grepl("^...",*) uses
      (related to proposals in PR#16490).

    * Reference class finalizers run at exit, as well as on garbage
      collection.

    * Avoid parallel dependency on stats for port choice and random
      number seeds.  (PR#16668)

    * The radix sort algorithm and implementation from data.table
      (forder) replaces the previous radix (counting) sort and adds a
      new method for order().  Contributed by Matt Dowle and Arun
      Srinivasan, the new algorithm supports logical, integer (even
      with large values), real, and character vectors.  It outperforms
      all other methods, but there are some caveats (see ?sort).

    * The order() function gains a method argument for choosing between
      "shell" and "radix".

    * New function grouping() returns a permutation that stably
      rearranges data so that identical values are adjacent.  The
      return value includes extra partitioning information on the
      groups.  The implementation came included with the new radix
      sort.

    * rhyper(nn, m, n, k) no longer returns NA when one of the three
      parameters exceeds the maximal integer.

    * switch() now warns when no alternatives are provided.

    * parallel::detectCores() now has default logical = TRUE on all
      platforms - as this was the default on Windows, this change only
      affects Sparc Solaris.

      Option logical = FALSE is now supported on Linux and recent
      versions of OS X (for the latter, thanks to a suggestion of Kyaw
      Sint).

    * hist() for "Date" or "POSIXt" objects would sometimes give
      misleading labels on the breaks, as they were set to the day
      before the start of the period being displayed.  The display
      format has been changed, and the shift of the start day has been
      made conditional on right = TRUE (the default).  (PR#16679)

    * R now uses a new version of the logo (donated to the R Foundation
      by RStudio).  It is defined in .svg format, so will resize
      without unnecessary degradation when displayed on HTML
      pages-there is also a vector PDF version.  Thanks to Dirk
      Eddelbuettel for producing the corresponding X11 icon.

    * New function .traceback() returns the stack trace which
      traceback() prints.

    * lengths() dispatches internally.

    * dotchart() gains a pt.cex argument to control the size of points
      separately from the size of plot labels.  Thanks to Michael
      Friendly and Milan Bouchet-Valat for ideas and patches.

    * as.roman(ch) now correctly deals with more diverse character
      vectors ch; also arithmetic with the resulting roman numbers
      works in more cases.  (PR#16779)

    * prcomp() gains a new option rank. allowing to directly aim for
      less than min(n,p) PC's.  The summary() and its print() method
      have been amended, notably for this case.

    * gzcon() gains a new option text, which marks the connection as
      text-oriented (so e.g. pushBack() works).  It is still always
      opened in binary mode.

    * The import() namespace directive now accepts an argument except
      which names symbols to exclude from the imports. The except
      expression should evaluate to a character vector (after
      substituting symbols for strings). See Writing R Extensions.

    * New convenience function Rcmd() in package tools for invoking R
      CMD tools from within R.

    * New functions makevars_user() and makevars_site() in package
      tools to determine the location of the user and site specific
      Makevars files for customizing package compilation.

  UTILITIES:

    * R CMD check has a new option --ignore-vignettes for use with
      non-Sweave vignettes whose VignetteBuilder package is not
      available.

    * R CMD check now by default checks code usage (_via_ codetools)
      with only the base package attached.  Functions from default
      packages other than base which are used in the package code but
      not imported are reported as undefined globals, with a suggested
      addition to the NAMESPACE file.

    * R CMD check --as-cran now also checks DOIs in package CITATION
      and Rd files.

    * R CMD Rdconv and R CMD Rd2pdf each have a new option
      --RdMacros=pkglist which allows Rd macros to be specified before
      processing.

  DEPRECATED AND DEFUNCT:

    * The previously included versions of zlib, bzip2, xz and PCRE have
      been removed, so suitable external (usually system) versions are
      required (see the 'R Installation and Administration' manual).

    * The unexported and undocumented Windows-only devices cairo_bmp(),
      cairo_png() and cairo_tiff() have been removed.  (These devices
      should be used as e.g. bmp(type = "cairo").)

    * (Windows only) Function setInternet2() has no effect and will be
      removed in due course.  The choice between methods "internal" and
      "wininet" is now made by the method arguments of url() and
      download.file() and their defaults can be set _via_ options.  The
      out-of-the-box default remains "wininet" (as it has been since R
      3.2.2).

    * [<- with an S4 value into a list currently embeds the S4 object
      into its own list such that the end result is roughly equivalent
      to using [[<-.  That behavior is deprecated.  In the future, the
      S4 value will be coerced to a list with as.list().

    * Package tools' functions package.dependencies(), pkgDepends(),
      etc are deprecated now, mostly in favor of package_dependencies()
      which is both more flexible and efficient.

  INSTALLATION and INCLUDED SOFTWARE:

    * Support for very old versions of valgrind (e.g., 3.3.0) has been
      removed.

    * The included libtool script (generated by configure) has been
      updated to version 2.4.6 (from 2.2.6a).

    * libcurl version 7.28.0 or later with support for the https
      protocol is required for installation (except on Windows).

    * BSD networking is now required (except on Windows) and so
      capabilities("http/ftp") is always true.

    * configure uses pkg-config for PNG, TIFF and JPEG where this is
      available.  This should work better with multiple installs and
      with those using static libraries.

    * The minimum supported version of OS X is 10.6 ('Snow Leopard'):
      even that has been unsupported by Apple since 2012.

    * The configure default on OS X is --disable-R-framework: enable
      this if you intend to install under /Library/Frameworks and use
      with R.app.

    * The minimum preferred version of PCRE has since R 3.0.0 been 8.32
      (released in Nov 2012).  Versions 8.10 to 8.31 are now deprecated
      (with warnings from configure), but will still be accepted until
      R 3.4.0.

    * configure looks for C functions __cospi, __sinpi and __tanpi and
      uses these if cospi _etc_ are not found.  (OS X is the main
      instance.)

    * (Windows) R is now built using gcc 4.9.3.  This build will
      require recompilation of at least those packages that include C++
      code, and possibly others.  A build of R-devel using the older
      toolchain will be temporarily available for comparison purposes.

      During the transition, the environment variable R_COMPILED_BY has
      been defined to indicate which toolchain was used to compile R
      (and hence, which should be used to compile code in packages).
      The COMPILED_BY variable described below will be a permanent
      replacement for this.

    * (Windows) A make and R CMD config variable named COMPILED_BY has
      been added.  This indicates which toolchain was used to compile R
      (and hence, which should be used to compile code in packages).

  PACKAGE INSTALLATION:

    * The make macro AWK which used to be made available to files such
      as src/Makefile is no longer set.

  C-LEVEL FACILITIES:

    * The API call logspace_sum introduced in R 3.2.0 is now remapped
      as an entry point to Rf_logspace_sum, and its first argument has
      gained a const qualifier.  (PR#16470)

      Code using it will need to be reinstalled.

      Similarly, entry point log1pexp also defined in Rmath.h is
      remapped there to Rf_log1pexp

    * R_GE_version has been increased to 11.

    * New API call R_orderVector1, a faster one-argument version of
      R_orderVector.

    * When R headers such as R.h and Rmath.h are called from C++ code
      in packages they include the C++ versions of system headers such
      as <cmath> rather than the legacy headers such as <math.h>.
      (Headers Rinternals.h and Rinterface.h already did, and inclusion
      of system headers can still be circumvented by defining
      NO_C_HEADERS, including as from this version for those two
      headers.)

      The manual has long said that R headers should *not* be included
      within an extern "C" block, and almost all the packages affected
      by this change were doing so.

    * Including header S.h from C++ code would fail on some platforms,
      and so gives a compilation error on all.

    * The deprecated header Rdefines.h is now compatible with defining
      R_NO_REMAP.

    * The connections API now includes a function R_GetConnection()
      which allows packages implementing connections to convert R
      connection objects to Rconnection handles used in the API. Code
      which previously used the low-level R-internal getConnection()
      entry point should switch to the official API.

  BUG FIXES:

    * C-level asChar(x) is fixed for when x is not a vector, and it
      returns "TRUE"/"FALSE" instead of "T"/"F" for logical vectors.

    * The first arguments of .colSums() etc (with an initial dot) are
      now named x rather than X (matching colSums()): thus error
      messages are corrected.

    * A coef() method for class "maov" has been added to allow vcov()
      to work with multivariate results. (PR#16380)

    * method = "libcurl" connections signal errors rather than
      retrieving HTTP error pages (where the ISP reports the error).

    * xpdrows.data.frame() was not checking for unique row names; in
      particular, this affected assignment to non-existing rows via
      numerical indexing. (PR#16570)

    * tail.matrix() did not work for zero rows matrices, and could
      produce row "labels" such as "[1e+05,]".

    * Data frames with a column named "stringsAsFactors" now format and
      print correctly.  (PR#16580)

    * cor() is now guaranteed to return a value with absolute value
      less than or equal to 1. (PR#16638)

    * Array subsetting now keeps names(dim(.)).

    * Blocking socket connection selection recovers more gracefully on
      signal interrupts.

    * The data.frame method of rbind() construction row.names works
      better in borderline integer cases, but may change the names
      assigned.  (PR#16666)

    * (X11 only) getGraphicsEvent() miscoded buttons and missed mouse
      motion events.  (PR#16700)

    * methods(round) now also lists round.POSIXt.

    * tar() now works with the default files = NULL.  (PR#16716)

    * Jumps to outer contexts, for example in error recovery, now make
      intermediate jumps to contexts where on.exit() actions are
      established instead of trying to run all on.exit() actions before
      jumping to the final target. This unwinds the stack gradually,
      releases resources held on the stack, and significantly reduces
      the chance of a segfault when running out of C stack space. Error
      handlers established using withCallingHandlers() and
      options("error") specifications are ignored when handling a C
      stack overflow error as attempting one of these would trigger a
      cascade of C stack overflow errors.  (These changes resolve
      PR#16753.)

    * The spacing could be wrong when printing a complex array.
      (Report and patch by Lukas Stadler.)

    * pretty(d, n, min.n, *) for date-time objects d works again in
      border cases with large min.n, returns a labels attribute also
      for small-range dates and in such cases its returned length is
      closer to the desired n.  (PR#16761) Additionally, it finally
      does cover the range of d, as it always claimed.

    * tsp(x) <- NULL did not handle correctly objects inheriting from
      both "ts" and "mts".  (PR#16769)

    * install.packages() could give false errors when
      options("pkgType") was "binary".  (Reported by Jose Claudio
      Faria.)

    * A bug fix in R 3.0.2 fixed problems with locator() in X11, but
      introduced problems in Windows.  Now both should be fixed.
      (PR#15700)

    * download.file() with method = "wininet" incorrectly warned of
      download file length difference when reported length was unknown.
      (PR#16805)

    * diag(NULL, 1) crashed because of missed type checking.
      (PR#16853)
_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From syen04 at gmail.com  Tue May  3 12:38:32 2016
From: syen04 at gmail.com (Steven Yen)
Date: Tue, 3 May 2016 06:38:32 -0400
Subject: [R] grep command
Message-ID: <CAKTtY6R2a68kAimsGOEggQgUR8jC0sn1zQaf_9E9ptn2hrYsag@mail.gmail.com>

Dear all
In the grep command below, is there a way to identify only "age" and
not "age2"? Thanks.

> x<-c("abc","def","rst","xyz","age","age2")
> x
[1] "abc"  "def"  "rst"  "xyz"  "age"  "age2"
> grep("age2",x)
[1] 6
> grep("age",x) # I need to grab "age" only, not "age2"
[1] 5 6

Also, I post message to r-help at r-project.org and that's subject to
approval by the list moderator. Am I sending it to the wrong address?


From tr206 at kent.ac.uk  Tue May  3 12:54:20 2016
From: tr206 at kent.ac.uk (T.Riedle)
Date: Tue, 3 May 2016 10:54:20 +0000
Subject: [R] Fw:  Generating 3Dplot in lattice package
In-Reply-To: <CAF8bMcZA8G1d=8akY1vX1tZBbV2at2cghTu4x19H-ze_JLvv0g@mail.gmail.com>
References: <c2426a26544549429a2424c5a05c65c9@ex13-live-mbn1.ad.kent.ac.uk>,
	<CAF8bMcZA8G1d=8akY1vX1tZBbV2at2cghTu4x19H-ze_JLvv0g@mail.gmail.com>
Message-ID: <1462272860683.89268@kent.ac.uk>

Something is wrong here. The formula

pmin(psi/VaR,exp(((abs(B)/Bmax)^w2)*log((psi/VaR),2.718182)))


provides a time series. Nevertheless, the returned values are incorrect and it produces NANs.



________________________________
From: William Dunlap <wdunlap at tibco.com>
Sent: 02 May 2016 20:04
To: T.Riedle
Cc: r-help at r-project.org
Subject: Re: [R] Generating 3Dplot in lattice package

For starters, use 'pmin' (parallel min) instead of 'min'.

substitute(MIN(psi/K14,EXP(((ABS(H14)/peak)^omega)*LN(psi/K14))),
     list(MIN=quote(pmin), K14=quote(VaR), ABS=quote(abs),
          EXP=quote(exp), LN=quote(log), H14=quote(Bmax),
          omega=quote(w2)))
# pmin(psi/VaR, exp(((abs(Bmax)/peak)^w2) * log(psi/VaR)))


Bill Dunlap
TIBCO Software
wdunlap tibco.com<http://tibco.com>

On Mon, May 2, 2016 at 11:31 AM, T.Riedle <tr206 at kent.ac.uk<mailto:tr206 at kent.ac.uk>> wrote:
Dear R users,

I am trying to generate a 3D plot using the wireframe() function in the lattice package.

The corresponding formula in Excel looks as follows and is applied to the wireframe() function:

MIN(psi/K14,EXP(((ABS(H14)/peak)^omega)*LN(psi/K14)))

I tried to "translate" this formula in R and the code looks as follows


min(psi/VaR,exp(((abs(B)/Bmax)^w2)*log((psi/VaR),2.718182)))



In this case I get only one value which is NAN but I should get a time series with 13000 values. Hence, I deleted the min() function and tried the wireframe() function:


wireframe(inflator~exp((abs(B)/Bmax)^w2)*log((psi/VaR),base=2.718182),data=data_3Dplot)

However, it doesn't work as the formula for the inflator is incorrect. It produces NANs although it shouldn't do that and actually doesn't do that in Excel. Furthermore, the results are totally different to those calculated by Excel.

Can anyone help me with the formula and translate it correctly in terms of R? How do I get the time series? How do I get the values I get in Excel?

I have attached the data as csv file to this email.

Thank you very much for your help.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From ivan.calandra at univ-reims.fr  Tue May  3 12:57:05 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Tue, 3 May 2016 12:57:05 +0200
Subject: [R] grep command
In-Reply-To: <CAKTtY6R2a68kAimsGOEggQgUR8jC0sn1zQaf_9E9ptn2hrYsag@mail.gmail.com>
References: <CAKTtY6R2a68kAimsGOEggQgUR8jC0sn1zQaf_9E9ptn2hrYsag@mail.gmail.com>
Message-ID: <abff865c-4bb1-9c24-e000-705b5fc5a4fa@univ-reims.fr>

What about?

grep("^age$", x)

Ivan

--
Ivan Calandra, PhD
Scientific Mediator
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 03/05/2016 ? 12:38, Steven Yen a ?crit :
> Dear all
> In the grep command below, is there a way to identify only "age" and
> not "age2"? Thanks.
>
>> x<-c("abc","def","rst","xyz","age","age2")
>> x
> [1] "abc"  "def"  "rst"  "xyz"  "age"  "age2"
>> grep("age2",x)
> [1] 6
>> grep("age",x) # I need to grab "age" only, not "age2"
> [1] 5 6
>
> Also, I post message to r-help at r-project.org and that's subject to
> approval by the list moderator. Am I sending it to the wrong address?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ivan.calandra at univ-reims.fr  Tue May  3 12:57:52 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Tue, 3 May 2016 12:57:52 +0200
Subject: [R] grep command
In-Reply-To: <CAKTtY6R2a68kAimsGOEggQgUR8jC0sn1zQaf_9E9ptn2hrYsag@mail.gmail.com>
References: <CAKTtY6R2a68kAimsGOEggQgUR8jC0sn1zQaf_9E9ptn2hrYsag@mail.gmail.com>
Message-ID: <837d8d29-cfe9-18dc-559d-4d78be28908b@univ-reims.fr>

Oh, and regarding the moderator approval, I guess it's because you're a 
new user to the list.

Ivan

--
Ivan Calandra, PhD
Scientific Mediator
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 03/05/2016 ? 12:38, Steven Yen a ?crit :
> Dear all
> In the grep command below, is there a way to identify only "age" and
> not "age2"? Thanks.
>
>> x<-c("abc","def","rst","xyz","age","age2")
>> x
> [1] "abc"  "def"  "rst"  "xyz"  "age"  "age2"
>> grep("age2",x)
> [1] 6
>> grep("age",x) # I need to grab "age" only, not "age2"
> [1] 5 6
>
> Also, I post message to r-help at r-project.org and that's subject to
> approval by the list moderator. Am I sending it to the wrong address?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.ca.us  Tue May  3 15:05:27 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 03 May 2016 06:05:27 -0700
Subject: [R] grep command
In-Reply-To: <abff865c-4bb1-9c24-e000-705b5fc5a4fa@univ-reims.fr>
References: <CAKTtY6R2a68kAimsGOEggQgUR8jC0sn1zQaf_9E9ptn2hrYsag@mail.gmail.com>
	<abff865c-4bb1-9c24-e000-705b5fc5a4fa@univ-reims.fr>
Message-ID: <2C2258EE-489B-4980-9AC5-23D0C0C1395F@dcn.davis.ca.us>

Isn't that just an inefficient way to do

"age" == x

?
-- 
Sent from my phone. Please excuse my brevity.

On May 3, 2016 3:57:05 AM PDT, Ivan Calandra <ivan.calandra at univ-reims.fr> wrote:
>What about?
>
>grep("^age$", x)
>
>Ivan
>
>--
>Ivan Calandra, PhD
>Scientific Mediator
>University of Reims Champagne-Ardenne
>GEGENAA - EA 3795
>CREA - 2 esplanade Roland Garros
>51100 Reims, France
>+33(0)3 26 77 36 89
>ivan.calandra at univ-reims.fr
>--
>https://www.researchgate.net/profile/Ivan_Calandra
>https://publons.com/author/705639/
>
>Le 03/05/2016 ? 12:38, Steven Yen a ?crit :
>> Dear all
>> In the grep command below, is there a way to identify only "age" and
>> not "age2"? Thanks.
>>
>>> x<-c("abc","def","rst","xyz","age","age2")
>>> x
>> [1] "abc"  "def"  "rst"  "xyz"  "age"  "age2"
>>> grep("age2",x)
>> [1] 6
>>> grep("age",x) # I need to grab "age" only, not "age2"
>> [1] 5 6
>>
>> Also, I post message to r-help at r-project.org and that's subject to
>> approval by the list moderator. Am I sending it to the wrong address?
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From erum at konf.ue.poznan.pl  Tue May  3 16:17:51 2016
From: erum at konf.ue.poznan.pl (eRum)
Date: Tue, 3 May 2016 16:17:51 +0200
Subject: [R] eRum 2016 conference - call for papers
Message-ID: <2FF8ECE9-0331-41A0-990B-C83DFEDA8B19@konf.ue.poznan.pl>

Dear R Users,

Poznan University of Economics and Business, Poznan University of Life Sciences and Polish R Users groups are organising international conference European R Users Meeting (eRum 2016)!

eRum 2016 will take place between October 12th and 14th, and we already have confirmed invited speakers such as Rasmus B??th, Romain Fran?ois, Ulrike Gr?mping, Matthias Templ, and Heather Turner, as well as top level local R users. It will be a meeting of useRs from all across Europe working in different areas of the industry, academy, and government. 

We are looking for speakers and the call for papers is open until 15th of June. 

More information about the conference can be found at our webpage www.erum.ue.poznan.pl.

Looking forward to seeing you in Poznan!

Best regards,
Maciej Ber?sewicz

Chair of the Organising Committee
European R Users Meeting 2016
www.erum.ue.poznan.pl
www.twitter.com/erum2016

Department of Statistics
Faculty of Informatics and Electronic Economy
Pozna? University of Economics and Business
al. Niepodleg?o?ci 10
61 ? 875 Pozna?
tel. + 48 61 854 39 43?




	[[alternative HTML version deleted]]


From mark.fingerle at brainlab.com  Tue May  3 16:45:29 2016
From: mark.fingerle at brainlab.com (Mark Fingerle)
Date: Tue, 3 May 2016 14:45:29 +0000
Subject: [R] Reading multiple tables from one .txt doc
Message-ID: <afdd8c079a604eb0bf18a3f67ef29d48@despmsx02.brainlab.net>

Dear all,
I have a .txt file which contains multiple tables and I would like to read these tables separately in order to create graphs for each one.
The tables are separated by a blank line, have a variable number of lines, fixed nr. Of rows, have a header and a comment above the header (#) which contains a specific word that identifies each table. (see example below). It would be possible to change the layout of the .txt data a bit (Add a word, remove comment etc..)
I would be extremely grateful if anyone could help me with this daunting task :-)
Example:
# CoordA
Image    X             Y             Z             MeasuredMove MachineMove
vf_36.png            -114.345475       -89.043448         556.073402         0             0
vf_37.png            -111.118715       -89.978534         606.040764         50.080172           50.000000
vf_38.png            -107.911209       -90.901958         656.025557         50.096111           50.000000
vf_39.png            -104.693931       -91.814392         705.982620         50.068868           50.000000
vf_40.png            -101.459549       -92.730113         755.983835         50.114082           50.000000

# CoordB
Image    X             Y             Z             MeasuredMove MachineMove
vf_36.png            -115.345475       -89.043448         556.073402         0             0
vf_37.png            -115.118715       -89.978534         606.040764         50.080172           50.000000
vf_38.png            -134.911209       -90.901958         656.025557         50.096111           50.000000
vf_39.png            -164.693931       -91.814392         705.982620         50.068868           50.000000
vf_40.png            -134.459549       -92.730113         755.983835         50.114082           50.000000

# CoordC
Image    X             Y             Z             MeasuredMove MachineMove
vf_36.png            -168.345475       -89.043448         556.073402         0             0
vf_37.png            -115.118715       -89.978534         606.040764         50.080172           50.000000
vf_38.png            -146.911209       -90.901958         656.025557         50.096111           50.000000
vf_39.png            -187.693931       -91.814392         705.982620         50.068868           50.000000
vf_40.png            -185.459549       -92.730113         755.983835         50.114082           50.000000

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue May  3 17:23:56 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 3 May 2016 08:23:56 -0700
Subject: [R] Fw:  Generating 3Dplot in lattice package
In-Reply-To: <1462272860683.89268@kent.ac.uk>
References: <c2426a26544549429a2424c5a05c65c9@ex13-live-mbn1.ad.kent.ac.uk>
	<CAF8bMcZA8G1d=8akY1vX1tZBbV2at2cghTu4x19H-ze_JLvv0g@mail.gmail.com>
	<1462272860683.89268@kent.ac.uk>
Message-ID: <1192EF08-F3FF-4B77-A613-919192B44CFD@comcast.net>


> On May 3, 2016, at 3:54 AM, T.Riedle <tr206 at kent.ac.uk> wrote:
> 
> Something is wrong here. The formula
> 
> pmin(psi/VaR,exp(((abs(B)/Bmax)^w2)*log((psi/VaR),2.718182)))
> 
> 
> provides a time series. Nevertheless, the returned values are incorrect and it produces NANs.

The only thing we can conclude at the moment is that you have not provided sufficient information. The standard mailing list "sig" is there in an effort to prevent just this situation.

> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
David.
> 
> 
> 
> ________________________________
> From: William Dunlap <wdunlap at tibco.com>
> Sent: 02 May 2016 20:04
> To: T.Riedle
> Cc: r-help at r-project.org
> Subject: Re: [R] Generating 3Dplot in lattice package
> 
> For starters, use 'pmin' (parallel min) instead of 'min'.
> 
> substitute(MIN(psi/K14,EXP(((ABS(H14)/peak)^omega)*LN(psi/K14))),
>     list(MIN=quote(pmin), K14=quote(VaR), ABS=quote(abs),
>          EXP=quote(exp), LN=quote(log), H14=quote(Bmax),
>          omega=quote(w2)))
> # pmin(psi/VaR, exp(((abs(Bmax)/peak)^w2) * log(psi/VaR)))
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com<http://tibco.com>
> 
> On Mon, May 2, 2016 at 11:31 AM, T.Riedle <tr206 at kent.ac.uk<mailto:tr206 at kent.ac.uk>> wrote:
> Dear R users,
> 
> I am trying to generate a 3D plot using the wireframe() function in the lattice package.
> 
> The corresponding formula in Excel looks as follows and is applied to the wireframe() function:
> 
> MIN(psi/K14,EXP(((ABS(H14)/peak)^omega)*LN(psi/K14)))
> 
> I tried to "translate" this formula in R and the code looks as follows
> 
> 
> min(psi/VaR,exp(((abs(B)/Bmax)^w2)*log((psi/VaR),2.718182)))
> 
> 
> 
> In this case I get only one value which is NAN but I should get a time series with 13000 values. Hence, I deleted the min() function and tried the wireframe() function:
> 
> 
> wireframe(inflator~exp((abs(B)/Bmax)^w2)*log((psi/VaR),base=2.718182),data=data_3Dplot)
> 
> However, it doesn't work as the formula for the inflator is incorrect. It produces NANs although it shouldn't do that and actually doesn't do that in Excel. Furthermore, the results are totally different to those calculated by Excel.
> 
> Can anyone help me with the formula and translate it correctly in terms of R? How do I get the time series? How do I get the values I get in Excel?
> 
> I have attached the data as csv file to this email.
> 
> Thank you very much for your help.
> 
> 
> https://stat.ethz.ch/mailman/listinfo/r-help

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Tue May  3 17:41:03 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 3 May 2016 08:41:03 -0700
Subject: [R] Reading multiple tables from one .txt doc
In-Reply-To: <afdd8c079a604eb0bf18a3f67ef29d48@despmsx02.brainlab.net>
References: <afdd8c079a604eb0bf18a3f67ef29d48@despmsx02.brainlab.net>
Message-ID: <CAGxFJbT5bLBp=ukSS4q-_PSCatsggNzrQecDqTKG5MWb1rDvbA@mail.gmail.com>

One approach would be to use ?readLines to read the lines into a
character vector. You could then use indexing to remove all the blank
and header (lines beginning with "image") lines. You can now find the
indices of where the separate data blocks begin (they all begin with
"#", right?) and then sequentially read them into a list of data
frames, using ?strsplit to delineate columns and ?as.numeric to
convert the numeric columns. I leave it to you to work out what I
think are the straightforward details.

Do note, however, that there may be better ways to do this, especially
using some of the text manipulation packages and functions.  Have a
look at the "stringr" package or any others that searching might bring
up (rseek.org is a good search site for R; as is google of course).
And wait a bit for better suggestions before proceeding, as my brute
force approach should probably be considered a last resort.


Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, May 3, 2016 at 7:45 AM, Mark Fingerle
<mark.fingerle at brainlab.com> wrote:
> Dear all,
> I have a .txt file which contains multiple tables and I would like to read these tables separately in order to create graphs for each one.
> The tables are separated by a blank line, have a variable number of lines, fixed nr. Of rows, have a header and a comment above the header (#) which contains a specific word that identifies each table. (see example below). It would be possible to change the layout of the .txt data a bit (Add a word, remove comment etc..)
> I would be extremely grateful if anyone could help me with this daunting task :-)
> Example:
> # CoordA
> Image    X             Y             Z             MeasuredMove MachineMove
> vf_36.png            -114.345475       -89.043448         556.073402         0             0
> vf_37.png            -111.118715       -89.978534         606.040764         50.080172           50.000000
> vf_38.png            -107.911209       -90.901958         656.025557         50.096111           50.000000
> vf_39.png            -104.693931       -91.814392         705.982620         50.068868           50.000000
> vf_40.png            -101.459549       -92.730113         755.983835         50.114082           50.000000
>
> # CoordB
> Image    X             Y             Z             MeasuredMove MachineMove
> vf_36.png            -115.345475       -89.043448         556.073402         0             0
> vf_37.png            -115.118715       -89.978534         606.040764         50.080172           50.000000
> vf_38.png            -134.911209       -90.901958         656.025557         50.096111           50.000000
> vf_39.png            -164.693931       -91.814392         705.982620         50.068868           50.000000
> vf_40.png            -134.459549       -92.730113         755.983835         50.114082           50.000000
>
> # CoordC
> Image    X             Y             Z             MeasuredMove MachineMove
> vf_36.png            -168.345475       -89.043448         556.073402         0             0
> vf_37.png            -115.118715       -89.978534         606.040764         50.080172           50.000000
> vf_38.png            -146.911209       -90.901958         656.025557         50.096111           50.000000
> vf_39.png            -187.693931       -91.814392         705.982620         50.068868           50.000000
> vf_40.png            -185.459549       -92.730113         755.983835         50.114082           50.000000
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Tue May  3 18:05:05 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 3 May 2016 09:05:05 -0700
Subject: [R] Fw: Generating 3Dplot in lattice package
In-Reply-To: <1462272860683.89268@kent.ac.uk>
References: <c2426a26544549429a2424c5a05c65c9@ex13-live-mbn1.ad.kent.ac.uk>
	<CAF8bMcZA8G1d=8akY1vX1tZBbV2at2cghTu4x19H-ze_JLvv0g@mail.gmail.com>
	<1462272860683.89268@kent.ac.uk>
Message-ID: <CAF8bMcZs=HacfLOR3NGFMNEAD=sbieyrHhCCGU7Ws2nSPRQd9A@mail.gmail.com>

See if you can use is.nan() to figure out which values of B, Bmax, ...,
cause
the result to be NaN (not a number).  One possibility is if B were always
negative so abs(B)/max(B) could be negative: (negative)^(non-integer power)
is NaN.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, May 3, 2016 at 3:54 AM, T.Riedle <tr206 at kent.ac.uk> wrote:

> Something is wrong here. The formula
>
> pmin(psi/VaR,exp(((abs(B)/Bmax)^w2)*log((psi/VaR),2.718182)))
>
>
> provides a time series. Nevertheless, the returned values are incorrect
> and it produces NANs.
>
>
>
> ________________________________
> From: William Dunlap <wdunlap at tibco.com>
> Sent: 02 May 2016 20:04
> To: T.Riedle
> Cc: r-help at r-project.org
> Subject: Re: [R] Generating 3Dplot in lattice package
>
> For starters, use 'pmin' (parallel min) instead of 'min'.
>
> substitute(MIN(psi/K14,EXP(((ABS(H14)/peak)^omega)*LN(psi/K14))),
>      list(MIN=quote(pmin), K14=quote(VaR), ABS=quote(abs),
>           EXP=quote(exp), LN=quote(log), H14=quote(Bmax),
>           omega=quote(w2)))
> # pmin(psi/VaR, exp(((abs(Bmax)/peak)^w2) * log(psi/VaR)))
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com<http://tibco.com>
>
> On Mon, May 2, 2016 at 11:31 AM, T.Riedle <tr206 at kent.ac.uk<mailto:
> tr206 at kent.ac.uk>> wrote:
> Dear R users,
>
> I am trying to generate a 3D plot using the wireframe() function in the
> lattice package.
>
> The corresponding formula in Excel looks as follows and is applied to the
> wireframe() function:
>
> MIN(psi/K14,EXP(((ABS(H14)/peak)^omega)*LN(psi/K14)))
>
> I tried to "translate" this formula in R and the code looks as follows
>
>
> min(psi/VaR,exp(((abs(B)/Bmax)^w2)*log((psi/VaR),2.718182)))
>
>
>
> In this case I get only one value which is NAN but I should get a time
> series with 13000 values. Hence, I deleted the min() function and tried the
> wireframe() function:
>
>
>
> wireframe(inflator~exp((abs(B)/Bmax)^w2)*log((psi/VaR),base=2.718182),data=data_3Dplot)
>
> However, it doesn't work as the formula for the inflator is incorrect. It
> produces NANs although it shouldn't do that and actually doesn't do that in
> Excel. Furthermore, the results are totally different to those calculated
> by Excel.
>
> Can anyone help me with the formula and translate it correctly in terms of
> R? How do I get the time series? How do I get the values I get in Excel?
>
> I have attached the data as csv file to this email.
>
> Thank you very much for your help.
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Tue May  3 18:20:16 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 3 May 2016 09:20:16 -0700
Subject: [R] Reading multiple tables from one .txt doc
In-Reply-To: <CAGxFJbT5bLBp=ukSS4q-_PSCatsggNzrQecDqTKG5MWb1rDvbA@mail.gmail.com>
References: <afdd8c079a604eb0bf18a3f67ef29d48@despmsx02.brainlab.net>
	<CAGxFJbT5bLBp=ukSS4q-_PSCatsggNzrQecDqTKG5MWb1rDvbA@mail.gmail.com>
Message-ID: <CAF8bMcYKh8thuy-dX1rDaY9eFqumNcf6Q6tGy0zeg2A3_w0Tcg@mail.gmail.com>

The following base R code does roughly what Bert suggests.  It does
no checking that the data is in the format you describe.  The
split-by-cumsum
trick is a handy idiom.

# lines <- readLines(yourFile), or, for this example:
lines <- c("#One","X Y Z","1 2 3","4 5 6","",
                "#Two", "X Y Z", "11 12 13", "",
                "#Three", "X Y Z", "21 22 23")
tables <- split(lines, cumsum( grepl("^#", lines)))
names(tables) <- vapply(tables, function(table)sub("^#", "", table[1]), "")
lapply(tables, function(text)read.table(text=text, header=TRUE, skip=1))
#$One
#  X Y Z
#1 1 2 3
#2 4 5 6
#
#$Two
#   X  Y  Z
#1 11 12 13
#
#$Three
#   X  Y  Z
#1 21 22 23


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, May 3, 2016 at 8:41 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> One approach would be to use ?readLines to read the lines into a
> character vector. You could then use indexing to remove all the blank
> and header (lines beginning with "image") lines. You can now find the
> indices of where the separate data blocks begin (they all begin with
> "#", right?) and then sequentially read them into a list of data
> frames, using ?strsplit to delineate columns and ?as.numeric to
> convert the numeric columns. I leave it to you to work out what I
> think are the straightforward details.
>
> Do note, however, that there may be better ways to do this, especially
> using some of the text manipulation packages and functions.  Have a
> look at the "stringr" package or any others that searching might bring
> up (rseek.org is a good search site for R; as is google of course).
> And wait a bit for better suggestions before proceeding, as my brute
> force approach should probably be considered a last resort.
>
>
> Cheers,
> Bert
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, May 3, 2016 at 7:45 AM, Mark Fingerle
> <mark.fingerle at brainlab.com> wrote:
> > Dear all,
> > I have a .txt file which contains multiple tables and I would like to
> read these tables separately in order to create graphs for each one.
> > The tables are separated by a blank line, have a variable number of
> lines, fixed nr. Of rows, have a header and a comment above the header (#)
> which contains a specific word that identifies each table. (see example
> below). It would be possible to change the layout of the .txt data a bit
> (Add a word, remove comment etc..)
> > I would be extremely grateful if anyone could help me with this daunting
> task :-)
> > Example:
> > # CoordA
> > Image    X             Y             Z             MeasuredMove
> MachineMove
> > vf_36.png            -114.345475       -89.043448         556.073402
>      0             0
> > vf_37.png            -111.118715       -89.978534         606.040764
>      50.080172           50.000000
> > vf_38.png            -107.911209       -90.901958         656.025557
>      50.096111           50.000000
> > vf_39.png            -104.693931       -91.814392         705.982620
>      50.068868           50.000000
> > vf_40.png            -101.459549       -92.730113         755.983835
>      50.114082           50.000000
> >
> > # CoordB
> > Image    X             Y             Z             MeasuredMove
> MachineMove
> > vf_36.png            -115.345475       -89.043448         556.073402
>      0             0
> > vf_37.png            -115.118715       -89.978534         606.040764
>      50.080172           50.000000
> > vf_38.png            -134.911209       -90.901958         656.025557
>      50.096111           50.000000
> > vf_39.png            -164.693931       -91.814392         705.982620
>      50.068868           50.000000
> > vf_40.png            -134.459549       -92.730113         755.983835
>      50.114082           50.000000
> >
> > # CoordC
> > Image    X             Y             Z             MeasuredMove
> MachineMove
> > vf_36.png            -168.345475       -89.043448         556.073402
>      0             0
> > vf_37.png            -115.118715       -89.978534         606.040764
>      50.080172           50.000000
> > vf_38.png            -146.911209       -90.901958         656.025557
>      50.096111           50.000000
> > vf_39.png            -187.693931       -91.814392         705.982620
>      50.068868           50.000000
> > vf_40.png            -185.459549       -92.730113         755.983835
>      50.114082           50.000000
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From hpages at fredhutch.org  Tue May  3 19:09:55 2016
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Tue, 3 May 2016 10:09:55 -0700
Subject: [R] grep command
In-Reply-To: <2C2258EE-489B-4980-9AC5-23D0C0C1395F@dcn.davis.ca.us>
References: <CAKTtY6R2a68kAimsGOEggQgUR8jC0sn1zQaf_9E9ptn2hrYsag@mail.gmail.com>
	<abff865c-4bb1-9c24-e000-705b5fc5a4fa@univ-reims.fr>
	<2C2258EE-489B-4980-9AC5-23D0C0C1395F@dcn.davis.ca.us>
Message-ID: <5728DB63.1080007@fredhutch.org>

On 05/03/2016 06:05 AM, Jeff Newmiller wrote:
> Isn't that just an inefficient way to do
>
> "age" == x

Yep, it's an inefficient way to do which(x == "age").

H.

>
> ?
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From adriens_cachan at yahoo.fr  Tue May  3 18:26:58 2016
From: adriens_cachan at yahoo.fr (BONACHE Adrien)
Date: Tue, 3 May 2016 16:26:58 +0000 (UTC)
Subject: [R] Is my simulation to compute power of a multiple ordinal
 logistic regression right?
References: <610430437.10536538.1462292818161.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <610430437.10536538.1462292818161.JavaMail.yahoo@mail.yahoo.com>

Good day,
I was performing a power analysis of articles published in a journal of management using the pwr package in R. However, it seemed to be impossible to compute power for small, medium and large Effect Size for multiple ordinal logistic regression output. I have tried using G*power, but it seemed to be just useful when we have simple logistic regression output. Thus, I have tried to simulate to calculate the power based on Greg Snow and Gung answers.    library(rms)

    tmpfun <- function(n, beta1,beta2,beta3,beta4,beta5,beta6,beta7,
    beta8,beta9,beta10,beta11,beta12,beta13,beta14) {   
    var1=log(runif(n,3,33))
    var2=rbinom(n,1,0.4502)
    x=1
    while (x>0.96) {var3=rbinom(n,1,0.9474); x=mean(var3)}
    var4=rbinom(n,1,0.2749)
    var5=rbinom(n,1,0.6199)
    var6=rbinom(n,1,0.4327)
    var7=rnorm(n,1.11,0.29)
    var8=rnorm(n,0.06,0.07)
    var9=runif(n,106,536804)
    var10=runif(n,0.08,3.7)
    var11=runif(n,0.08,0.92)
    var12=rnorm(n,96.24,113.11)
    for (i in 1:n) {if (var12[i]<=0) {var12[i]=runif(1)} else   
    {var12[i]=log(var12[i])}}
    var13=runif(n,0.05,0.88)
    var14=runif(n,-1.06,0.03)
    eta1 <- beta1*var1+beta2*var2+beta3*var3+beta4*var4+beta5*var5+
    beta6*var6
    eta2=eta1+beta7*var7+beta8*var8+beta9*var9+beta10*var10
    +beta11*var11+beta12*var12+beta13*var13+beta14*var14
    p1 <- exp(eta1)/(1+exp(eta1))
    p1=replace(p1,is.na(p1),1)
    p2 <- exp(eta2)/(1+exp(eta2))
    p2=replace(p2,is.na(p2),1)
    tmp <- runif(n)
    y <- (tmp < p1)+(tmp<p2)
    fit <- lrm(y~var1+var2+var3+var4+var5+var6)
    fit$stats[5]
    }
    out <- replicate(10000, tmpfun(n=112,0.582,-0.176,-0.413,
    -0.138,0.861,-0.942,3.481,4.542,1.059,0.322,-2.562,0.599,2.4,0.732))
    mean( out < 0.05 )
Is my simulation right? How can I get power for small, medium and large ES? Those are the questions... Thank for your time and your help.
Regards,
Adrien. 
	[[alternative HTML version deleted]]


From 538280 at gmail.com  Tue May  3 23:26:40 2016
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 3 May 2016 15:26:40 -0600
Subject: [R] row names, coulmn names
In-Reply-To: <52830DE1-A9CE-42F7-9DC3-3388681FBAB5@comcast.net>
References: <CAHby=D1mkfZnsWd_bZyfsfgfbCQcbimNRSF4U1TUrLB4XNqrwA@mail.gmail.com>
	<52830DE1-A9CE-42F7-9DC3-3388681FBAB5@comcast.net>
Message-ID: <CAFEqCdxLSsNnfj54UsqEekNTUBj-EJeif-UPRisBVhtWTYNK+w@mail.gmail.com>

There are some packages that add labels or other attributes (units) to
columns of data frames and have methods to display the labels, units,
etc.  One of these packages is Hmisc, see the label and unit
functions.  I believe that there are other packages as well.  This may
provide what the original poster desires.

On Sun, May 1, 2016 at 1:55 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On May 1, 2016, at 11:09 AM, Jan Kacaba <jan.kacaba at gmail.com> wrote:
>>
>> Hello dear R helpers,
>>
>> Is it possible to have more than 1 row for column names in data.frame,
>> array, tbl_df? I would like to have column numbers in the first row, string
>> names in the second row, physical unit in third row.
>
> It's possible to embed "\n" in names but whether that will deliver desired results with plotting and printing functions may be another matter. You would always  need to quote names, even when using "$".
>
>
>> How would I do it?
>>
>> Derek
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From leonardof at leonardof.med.br  Wed May  4 00:34:15 2016
From: leonardof at leonardof.med.br (Leonardo Ferreira Fontenelle)
Date: Tue, 03 May 2016 19:34:15 -0300
Subject: [R] Unexpected scores from weighted PCA with svyprcomp()
In-Reply-To: <1461984011.3962650.593973745.101FB110@webmail.messagingengine.com>
References: <1461984011.3962650.593973745.101FB110@webmail.messagingengine.com>
Message-ID: <1462314855.4060942.597284897.4BC3F344@webmail.messagingengine.com>

Is there something I could do to improve my chances of getting an
answer?

Leonardo Ferreira Fontenelle
http://lattes.cnpq.br/9234772336296638

Em Sex 29 abr. 2016, ?s 23:40, Leonardo Ferreira Fontenelle escreveu:
> Hello!
> 
> I'd like to create an assets-based economic indicator using data from a
> national household survey. The economic indicator is to be the first
> principal component from a principal components analysis, which (given
> the source of the data) I believe should take in consideration the
> sampling weights of the observations. After running the PCA with
> svyprcomp(), from the survey package, I wanted to list the loading (with
> regard to the first principal component) and the scale of the variables,
> so that I can tell people how to "reconstitute" the economic indicator
> from the variables without any knowledge of PCA. This reconstituted
> indicator wouldn't be centered, but that's OK because the important
> thing for the application is the relative position of the observations.
> The unexpected (at least for me) behavior was that the principal
> component returned by svyprcomp() was very different from from the
> reconstituted indicator as well as from the indicator returned by
> predict(). "Different" here means weak correlation and different
> distributions.
> 
> I hope the following code illustrates what I mean:
> 
> =====
> 
> svycor <- function(formula, design) {
>   # https://stat.ethz.ch/pipermail/r-help/2003-July/036645.html
>   stopifnot(require(survey))
>   covariance.matrix <- svyvar(formula, design)
>   variables <- diag(covariance.matrix)
>   correlation.matrix <- covariance.matrix / sqrt(variables %*%
>   t(variables))
>   return(correlation.matrix)
> }
> 
> library(survey)
> data(api)
> dclus2 <- svydesign(ids = ~ dnum + snum, fpc = ~ fpc1 + fpc2, data =
> apiclus2)
> pc <- svyprcomp( ~ api99 + api00, design = dclus2, scale = TRUE, scores
> = TRUE)
> dclus2$variables$pc1 <- pc$x[, "PC1"]
> dclus2$variables$pc2 <- predict(pc, apiclus2)[, "PC1"]
> mycoef <- pc$rotation[, "PC1"] / pc$scale
> dclus2$variables$pc3 <- with(apiclus2, api99 * mycoef["api99"] + api00 *
> mycoef["api00"])
> svycor(~ pc1 + pc2 + pc3, dclus2)[, ]
> #           pc1       pc2       pc3
> # pc1 1.0000000 0.2078789 0.2078789
> # pc2 0.2078789 1.0000000 1.0000000
> # pc3 0.2078789 1.0000000 1.0000000
> plot(svysmooth(~ pc1, dclus2), xlim = c(-2.5, 5), ylim = 0:1)
> lines(svysmooth(~ pc2, dclus2), col = 2)
> lines(svysmooth(~ pc3, dclus2), col = 3)
> legend("topright", legend = c('pc$x[, "PC1"]', 'predict(pc, apiclus2)[,
> "PC1"]', 'Reconstituted indicator'), col = 1:3, lty = 1)
> 
> sessionInfo()
> # R version 3.2.4 Revised (2016-03-16 r70336)
> # Platform: x86_64-pc-linux-gnu (64-bit)
> # Running under: Arch Linux
> # 
> #  locale:
> #  [1] LC_CTYPE=pt_BR.UTF-8       LC_NUMERIC=C              
> #  [3] LC_TIME=pt_BR.UTF-8        LC_COLLATE=pt_BR.UTF-8    
> #  [5] LC_MONETARY=pt_BR.UTF-8    LC_MESSAGES=pt_BR.UTF-8   
> #  [7] LC_PAPER=pt_BR.UTF-8       LC_NAME=C                 
> #  [9] LC_ADDRESS=C               LC_TELEPHONE=C            
> # [11] LC_MEASUREMENT=pt_BR.UTF-8 LC_IDENTIFICATION=C       
> # 
> # attached base packages:
> # [1] grid      stats     graphics  utils     datasets  grDevices
> # [7] methods   base     
> # 
> # other attached packages:
> # [1] KernSmooth_2.23-15 survey_3.30-3     
> # 
> # loaded via a namespace (and not attached):
> # [1] tools_3.2.4
> 
> =====
> 
> This lack of correlation doesn't happen if the survey design object has
> uniform sampling weights or if the the data is analyzed with prcomp().
> 
> Why does the returned principal component is so different from the
> predicted and the reconstituted ones? Are predict() and my
> "reconstitution" missing something? Are the three methods equally valid
> but with different interpretations? Is there a bug in svyprcomp() ??
> 
> Thanks in advance,
> 
> Leonardo Ferreira Fontenelle
> http://lattes.cnpq.br/9234772336296638
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Wed May  4 02:10:32 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 3 May 2016 20:10:32 -0400
Subject: [R] 3D surface plot
In-Reply-To: <57782dcbd9f0427b878f48a7d93fec85@ex13-live-mbn1.ad.kent.ac.uk>
References: <57782dcbd9f0427b878f48a7d93fec85@ex13-live-mbn1.ad.kent.ac.uk>
Message-ID: <57293DF8.1050702@gmail.com>

On 30/04/2016 1:48 PM, T.Riedle wrote:
> Dear R users,
>
> I am trying to generate a 3D surface plot given the inflator formula in the attached file.
>
> Now, I want to create a 3D plot showing how Delta changes with the values of Abs(B) and sigma. The other variables in the formula are constant. Delta is calculated daily therefore the subscript t which denotes the day. I have used different functions and different packages but I get either wrong results or an error in R.
>
> Does anyone have an idea which function I should use?

One way is to create a function of two arguments, e.g.

f <- function(x, y) x^2 + y^2

This function needs to be "vectorized", i.e. if x and y are vectors, it 
needs to pair the values and produce a vector as an answer.  Then

library(rgl)
persp3d(f)

will do a perspective plot of it.  There are a lot of optional arguments 
to set the range of x, y, labels, colours, etc.

Duncan Murdoch

>
> Furthermore, I think I have to create a matrix using the formula above but I do not know how to do that in this connection. Can any body help me with the code for this purpose?
>
> Thanks a lot in advance.
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.ca.us  Wed May  4 02:16:06 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 03 May 2016 17:16:06 -0700
Subject: [R] Unexpected scores from weighted PCA with svyprcomp()
In-Reply-To: <1462314855.4060942.597284897.4BC3F344@webmail.messagingengine.com>
References: <1461984011.3962650.593973745.101FB110@webmail.messagingengine.com>
	<1462314855.4060942.597284897.4BC3F344@webmail.messagingengine.com>
Message-ID: <55AEC308-2B16-4FCE-AB97-CE55E63FEB84@dcn.davis.ca.us>

Your question is a mixture of statistical and implementation (package) issues. This isn't really the right forum for "what is the statistically-correct answer" questions, and as to whether the package is correct or you are using it right would require someone familiar with that particular CONTRIBUTED package to be reading this list. (While this is probably one of the more widely used contributed packages,  there are over 8000 contributed packages so far and I for one don't use it...)

You could ask on stats.stackexchange.com where theory is more on topic, or you could try to get the maintainer to chime in (use the maintainer() function to find out who to cc), or you could just be patient. 
-- 
Sent from my phone. Please excuse my brevity.

On May 3, 2016 3:34:15 PM PDT, Leonardo Ferreira Fontenelle <leonardof at leonardof.med.br> wrote:
>Is there something I could do to improve my chances of getting an
>answer?
>
>Leonardo Ferreira Fontenelle
>http://lattes.cnpq.br/9234772336296638
>
>Em Sex 29 abr. 2016, ?s 23:40, Leonardo Ferreira Fontenelle escreveu:
>> Hello!
>> 
>> I'd like to create an assets-based economic indicator using data from
>a
>> national household survey. The economic indicator is to be the first
>> principal component from a principal components analysis, which
>(given
>> the source of the data) I believe should take in consideration the
>> sampling weights of the observations. After running the PCA with
>> svyprcomp(), from the survey package, I wanted to list the loading
>(with
>> regard to the first principal component) and the scale of the
>variables,
>> so that I can tell people how to "reconstitute" the economic
>indicator
>> from the variables without any knowledge of PCA. This reconstituted
>> indicator wouldn't be centered, but that's OK because the important
>> thing for the application is the relative position of the
>observations.
>> The unexpected (at least for me) behavior was that the principal
>> component returned by svyprcomp() was very different from from the
>> reconstituted indicator as well as from the indicator returned by
>> predict(). "Different" here means weak correlation and different
>> distributions.
>> 
>> I hope the following code illustrates what I mean:
>> 
>> =====
>> 
>> svycor <- function(formula, design) {
>>   # https://stat.ethz.ch/pipermail/r-help/2003-July/036645.html
>>   stopifnot(require(survey))
>>   covariance.matrix <- svyvar(formula, design)
>>   variables <- diag(covariance.matrix)
>>   correlation.matrix <- covariance.matrix / sqrt(variables %*%
>>   t(variables))
>>   return(correlation.matrix)
>> }
>> 
>> library(survey)
>> data(api)
>> dclus2 <- svydesign(ids = ~ dnum + snum, fpc = ~ fpc1 + fpc2, data =
>> apiclus2)
>> pc <- svyprcomp( ~ api99 + api00, design = dclus2, scale = TRUE,
>scores
>> = TRUE)
>> dclus2$variables$pc1 <- pc$x[, "PC1"]
>> dclus2$variables$pc2 <- predict(pc, apiclus2)[, "PC1"]
>> mycoef <- pc$rotation[, "PC1"] / pc$scale
>> dclus2$variables$pc3 <- with(apiclus2, api99 * mycoef["api99"] +
>api00 *
>> mycoef["api00"])
>> svycor(~ pc1 + pc2 + pc3, dclus2)[, ]
>> #           pc1       pc2       pc3
>> # pc1 1.0000000 0.2078789 0.2078789
>> # pc2 0.2078789 1.0000000 1.0000000
>> # pc3 0.2078789 1.0000000 1.0000000
>> plot(svysmooth(~ pc1, dclus2), xlim = c(-2.5, 5), ylim = 0:1)
>> lines(svysmooth(~ pc2, dclus2), col = 2)
>> lines(svysmooth(~ pc3, dclus2), col = 3)
>> legend("topright", legend = c('pc$x[, "PC1"]', 'predict(pc,
>apiclus2)[,
>> "PC1"]', 'Reconstituted indicator'), col = 1:3, lty = 1)
>> 
>> sessionInfo()
>> # R version 3.2.4 Revised (2016-03-16 r70336)
>> # Platform: x86_64-pc-linux-gnu (64-bit)
>> # Running under: Arch Linux
>> # 
>> #  locale:
>> #  [1] LC_CTYPE=pt_BR.UTF-8       LC_NUMERIC=C              
>> #  [3] LC_TIME=pt_BR.UTF-8        LC_COLLATE=pt_BR.UTF-8    
>> #  [5] LC_MONETARY=pt_BR.UTF-8    LC_MESSAGES=pt_BR.UTF-8   
>> #  [7] LC_PAPER=pt_BR.UTF-8       LC_NAME=C                 
>> #  [9] LC_ADDRESS=C               LC_TELEPHONE=C            
>> # [11] LC_MEASUREMENT=pt_BR.UTF-8 LC_IDENTIFICATION=C       
>> # 
>> # attached base packages:
>> # [1] grid      stats     graphics  utils     datasets  grDevices
>> # [7] methods   base     
>> # 
>> # other attached packages:
>> # [1] KernSmooth_2.23-15 survey_3.30-3     
>> # 
>> # loaded via a namespace (and not attached):
>> # [1] tools_3.2.4
>> 
>> =====
>> 
>> This lack of correlation doesn't happen if the survey design object
>has
>> uniform sampling weights or if the the data is analyzed with
>prcomp().
>> 
>> Why does the returned principal component is so different from the
>> predicted and the reconstituted ones? Are predict() and my
>> "reconstitution" missing something? Are the three methods equally
>valid
>> but with different interpretations? Is there a bug in svyprcomp() ??
>> 
>> Thanks in advance,
>> 
>> Leonardo Ferreira Fontenelle
>> http://lattes.cnpq.br/9234772336296638
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From yasir.suhail at gmail.com  Wed May  4 01:13:31 2016
From: yasir.suhail at gmail.com (Yasir Suhail)
Date: Tue, 3 May 2016 19:13:31 -0400
Subject: [R] R column assignment fails for lists
Message-ID: <CADrG32Teg5oo+ZzjSdBSrFS6BVnH1vMgUkZDKVz25QSZD7a0Zw@mail.gmail.com>

Dear R developers and users,

Consider the object :

> a <- data.frame(a=c(1,2), b=c(2,3), c=c("a,b","c,d"), stringsAsFactors = F)
> a$c <- strsplit(a$c, ",")

Re-assignment works fine for columns 1 and 2, but fails for column 3. If a
is a valid object, the assignment should work.

> a[,1] <- a[,1]
> a[,2] <- a[,2]
> a[,3] <- a[,3]
Warning message:
In `[<-.data.frame`(`*tmp*`, , 3, value = list(c("a", "b"), c("c",  :
  provided 2 variables to replace 1 variables

	[[alternative HTML version deleted]]


From leonardof at leonardof.med.br  Wed May  4 02:43:36 2016
From: leonardof at leonardof.med.br (Leonardo Ferreira Fontenelle)
Date: Tue, 03 May 2016 21:43:36 -0300
Subject: [R] Unexpected scores from weighted PCA with svyprcomp()
In-Reply-To: <55AEC308-2B16-4FCE-AB97-CE55E63FEB84@dcn.davis.ca.us>
References: <1461984011.3962650.593973745.101FB110@webmail.messagingengine.com>
	<1462314855.4060942.597284897.4BC3F344@webmail.messagingengine.com>
	<55AEC308-2B16-4FCE-AB97-CE55E63FEB84@dcn.davis.ca.us>
Message-ID: <1462322616.4086590.597368177.01F6BF3C@webmail.messagingengine.com>

Thanks for remembering me to cc him!

Thomas Lumley is the package maintainer, and he frequently answers
questions in this list, but it is obviously hard for anyone to keep up
with so many emails.

Att,

Leonardo Ferreira Fontenelle
http://lattes.cnpq.br/9234772336296638


Em Ter 3 mai. 2016, ?s 21:16, Jeff Newmiller escreveu:
> Your question is a mixture of statistical and implementation (package) issues. This isn't really the right forum for "what is the statistically-correct answer" questions, and as to whether the package is correct or you are using it right would require someone familiar with that particular CONTRIBUTED package to be reading this list. (While this is probably one of the more widely used contributed packages,  there are over 8000 contributed packages so far and I for one don't use it...)
>  
>  You could ask on stats.stackexchange.com where theory is more on topic, or you could try to get the maintainer to chime in (use the maintainer() function to find out who to cc), or you could just be patient. 
>  -- 
>  Sent from my phone. Please excuse my brevity.
> 
> On May 3, 2016 3:34:15 PM PDT, Leonardo Ferreira Fontenelle <leonardof at leonardof.med.br> wrote:
>> Is there something I could do to improve my chances of getting an
>> answer?
>> 
>> Leonardo Ferreira Fontenelle
>> http://lattes.cnpq.br/9234772336296638
>> 
>> Em Sex 29 abr. 2016, ?s 23:40, Leonardo Ferreira Fontenelle escreveu:
>>>  Hello!
>>>  
>>>  I'd like to create an assets-based economic indicator using data from a
>>>  national household survey. The economic indicator is to be the first
>>>  principal component from a principal components analysis, which (given
>>>  the source of the data) I believe should take in consideration the
>>>  sampling weights of the observations. After running the PCA with
>>>  svyprcomp(), from the survey package, I wanted to list the loading (with
>>>  regard to the first principal component) and the scale of the variables,
>>>  so
that I can tell people how to "reconstitute" the economic indicator
>>>  from the variables without any knowledge of PCA. This reconstituted
>>>  indicator wouldn't be centered, but that's OK because the important
>>>  thing for the application is the relative position of the observations.
>>>  The unexpected (at least for me) behavior was that the principal
>>>  component returned by svyprcomp() was very different from from the
>>>  reconstituted indicator as well as from the indicator returned by
>>>  predict(). "Different" here means weak correlation and different
>>>  distributions.
>>>  
>>>  I hope the following code illustrates what I mean:
>>>  
>>>  =====
>>>  
>>>  svycor <- function(formula, design) {
>>>    # https://stat.ethz.ch/pipermail/r-help/2003-July/036645.html
>>>    stopifnot(require(survey))
>>>    covariance.matrix <- svyvar(formula, design)
>>>    variables <-
diag(covariance.matrix)
>>>    correlation.matrix <- covariance.matrix / sqrt(variables %*%
>>>    t(variables))
>>>    return(correlation.matrix)
>>>  }
>>>  
>>>  library(survey)
>>>  data(api)
>>>  dclus2 <- svydesign(ids = ~ dnum + snum, fpc = ~ fpc1 + fpc2, data =
>>>  apiclus2)
>>>  pc <- svyprcomp( ~ api99 + api00, design = dclus2, scale = TRUE, scores
>>>  = TRUE)
>>>  dclus2$variables$pc1 <- pc$x[, "PC1"]
>>>  dclus2$variables$pc2 <- predict(pc, apiclus2)[, "PC1"]
>>>  mycoef <- pc$rotation[, "PC1"] / pc$scale
>>>  dclus2$variables$pc3 <- with(apiclus2, api99 * mycoef["api99"] + api00 *
>>>  mycoef["api00"])
>>>  svycor(~ pc1 + pc2 + pc3, dclus2)[, ]
>>>  #           pc1       pc2       pc3
>>>  # pc1 1.0000000 0.2078789 0.2078789
>>>  # pc2 0.2078789 1.0000000 1.0000000
>>>  # pc3 0.2078789 1.0000000 1.0000000
>>>  plot(svysmooth(~ pc1, dclus2), xlim = c(-2.5, 5), ylim = 0:1)
>>>  lines(svysmooth(~ pc2, dclus2), col = 2)
>>> 
lines(svysmooth(~ pc3, dclus2), col = 3)
>>>  legend("topright", legend = c('pc$x[, "PC1"]', 'predict(pc, apiclus2)[,
>>>  "PC1"]', 'Reconstituted indicator'), col = 1:3, lty = 1)
>>>  
>>>  sessionInfo()
>>>  # R version 3.2.4 Revised (2016-03-16 r70336)
>>>  # Platform: x86_64-pc-linux-gnu (64-bit)
>>>  # Running under: Arch Linux
>>>  # 
>>>  #  locale:
>>>  #  [1] LC_CTYPE=pt_BR.UTF-8       LC_NUMERIC=C              
>>>  #  [3] LC_TIME=pt_BR.UTF-8        LC_COLLATE=pt_BR.UTF-8    
>>>  #  [5] LC_MONETARY=pt_BR.UTF-8    LC_MESSAGES=pt_BR.UTF-8   
>>>  #  [7] LC_PAPER=pt_BR.UTF-8       LC_NAME=C                 
>>>  #  [9] LC_ADDRESS=C               LC_TELEPHONE=C            
>>>  # [11] LC_MEASUREMENT=pt_BR.UTF-8 LC_IDENTIFICATION=C       
>>>  # 
>>>  # attached base packages:
>>>  # [1] grid      stats     graphics  utils     datasets  grDevices
>>>  # [7] methods   base     
>>>  # 
>>>  # other attached packages:
>>>  # [1] KernSmooth_2.23-15
survey_3.30-3     
>>>  # 
>>>  # loaded via a namespace (and not attached):
>>>  # [1] tools_3.2.4
>>>  
>>>  =====
>>>  
>>>  This lack of correlation doesn't happen if the survey design object has
>>>  uniform sampling weights or if the the data is analyzed with prcomp().
>>>  
>>>  Why does the returned principal component is so different from the
>>>  predicted and the reconstituted ones? Are predict() and my
>>>  "reconstitution" missing something? Are the three methods equally valid
>>>  but with different interpretations? Is there a bug in svyprcomp() ??
>>>  
>>>  Thanks in advance,
>>>  
>>>  Leonardo Ferreira Fontenelle
>>>  http://lattes.cnpq.br/9234772336296638
>>>  
>>> 
>>>  R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>  https://stat.ethz.ch/mailman/listinfo/r-help
>>>  PLEASE do read the posting guide
>>>  http://www.R-project.org/posting-guide.html[http://www.r-project.org/posting-guide.html]
>>>  and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html[http://www.r-project.org/posting-guide.html]
>> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed May  4 03:48:13 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 3 May 2016 18:48:13 -0700
Subject: [R] R column assignment fails for lists
In-Reply-To: <CADrG32Teg5oo+ZzjSdBSrFS6BVnH1vMgUkZDKVz25QSZD7a0Zw@mail.gmail.com>
References: <CADrG32Teg5oo+ZzjSdBSrFS6BVnH1vMgUkZDKVz25QSZD7a0Zw@mail.gmail.com>
Message-ID: <73802C04-561B-400A-9EA1-1149DA41DF79@comcast.net>


> On May 3, 2016, at 4:13 PM, Yasir Suhail <yasir.suhail at gmail.com> wrote:
> 
> Dear R developers and users,
> 
> Consider the object :
> 
>> a <- data.frame(a=c(1,2), b=c(2,3), c=c("a,b","c,d"), stringsAsFactors = F)
>> a$c <- strsplit(a$c, ",")

You are the one who should "consider the object". Look at what strsplit(a$c, ",") returns and then perhaps re-consider trying to assign it to a single column.

> 
> Re-assignment works fine for columns 1 and 2, but fails for column 3. If a
> is a valid object, the assignment should work.
> 
>> a[,1] <- a[,1]
>> a[,2] <- a[,2]
>> a[,3] <- a[,3]
> Warning message:
> In `[<-.data.frame`(`*tmp*`, , 3, value = list(c("a", "b"), c("c",  :
>  provided 2 variables to replace 1 variables
> 
> 	[[alternative HTML version deleted]]

And please reconsider also the format of your postings.

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Wed May  4 03:48:13 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 4 May 2016 11:48:13 +1000
Subject: [R] R column assignment fails for lists
In-Reply-To: <CADrG32Teg5oo+ZzjSdBSrFS6BVnH1vMgUkZDKVz25QSZD7a0Zw@mail.gmail.com>
References: <CADrG32Teg5oo+ZzjSdBSrFS6BVnH1vMgUkZDKVz25QSZD7a0Zw@mail.gmail.com>
Message-ID: <CA+8X3fVV2fLCJpjZ38HKiqdQBC9WU-1qs07NvPWfq+sH0-ALTA@mail.gmail.com>

Hi Yasil,
If you look at what happens to a[,3] after the "strsplit" it is easy:

> a[,3]
[1] "a,b" "c,d"

Here a[,3] is two strings

a$c <- strsplit(a$c, ",")
> a[,3]
[[1]]
[1] "a" "b"

[[2]]
[1] "c" "d"

Now a[,3] is a two element list. What R probably did was to take the
first component of a[,3] to replace the existing two values. Now if
you don't try to fool R:

> a[,3]<-list(a[,3])
> a$c
[[1]]
[1] "a" "b"

[[2]]
[1] "c" "d"

Jim


On Wed, May 4, 2016 at 9:13 AM, Yasir Suhail <yasir.suhail at gmail.com> wrote:
> Dear R developers and users,
>
> Consider the object :
>
>> a <- data.frame(a=c(1,2), b=c(2,3), c=c("a,b","c,d"), stringsAsFactors = F)
>> a$c <- strsplit(a$c, ",")
>
> Re-assignment works fine for columns 1 and 2, but fails for column 3. If a
> is a valid object, the assignment should work.
>
>> a[,1] <- a[,1]
>> a[,2] <- a[,2]
>> a[,3] <- a[,3]
> Warning message:
> In `[<-.data.frame`(`*tmp*`, , 3, value = list(c("a", "b"), c("c",  :
>   provided 2 variables to replace 1 variables
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From yoursurrogategod at gmail.com  Wed May  4 03:55:09 2016
From: yoursurrogategod at gmail.com (Yves S. Garret)
Date: Tue, 3 May 2016 21:55:09 -0400
Subject: [R] Custom data structures inside of a hash function
Message-ID: <CAJ=2b073WxEk5Th6AYGWaPnLHMVroBt8T4+eBrcYKYOJndC9Ug@mail.gmail.com>

Hello,

I have the following code:
http://pastebin.ca/3590201

What I'm trying to do is to create a hash map where the key is two
characters and
that maps to a structure of some information.  The problem with the above
example
is that the first two keys match to the first instance of c('hello', 0),
but the second is
completely ignored.  Ideally, I'd like to retrieve the structure with my
values based on
the key at hand and modify it as I see fit.

How can I achieve this?

	[[alternative HTML version deleted]]


From syen04 at gmail.com  Wed May  4 07:45:42 2016
From: syen04 at gmail.com (Steven Yen)
Date: Wed, 4 May 2016 01:45:42 -0400
Subject: [R] Grep command
Message-ID: <CAKTtY6T8riPtpW2t5nvXp_v65j3BMy=3aafD4s1nkkoy5=uKCQ@mail.gmail.com>

Dear all
In the grep command below, is there a way to identify only "age" and
not "age2"? In other words, I like to greb "age" and "age2"
separately, one at a time. Thanks.

x<-c("abc","def","rst","xyz","age","age2")
x

[1] "abc"  "def"  "rst"  "xyz"  "age"  "age2"

grep("age2",x)

[1] 6

grep("age",x) # I need to grab "age" only, not "age2"

[1] 5 6


From drjimlemon at gmail.com  Wed May  4 08:02:15 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 4 May 2016 16:02:15 +1000
Subject: [R] Grep command
In-Reply-To: <CAKTtY6T8riPtpW2t5nvXp_v65j3BMy=3aafD4s1nkkoy5=uKCQ@mail.gmail.com>
References: <CAKTtY6T8riPtpW2t5nvXp_v65j3BMy=3aafD4s1nkkoy5=uKCQ@mail.gmail.com>
Message-ID: <CA+8X3fUqOrv5_tkJAw9StV1PFL40n_uxGj8EVTQits0LJYOs0A@mail.gmail.com>

Hi Steven,
If this is just a one-off, you could do this:

grepl("age",x) & nchar(x)<4

returning a logical vector containing TRUE for "age" but not "age2"

Jim


On Wed, May 4, 2016 at 3:45 PM, Steven Yen <syen04 at gmail.com> wrote:
> Dear all
> In the grep command below, is there a way to identify only "age" and
> not "age2"? In other words, I like to greb "age" and "age2"
> separately, one at a time. Thanks.
>
> x<-c("abc","def","rst","xyz","age","age2")
> x
>
> [1] "abc"  "def"  "rst"  "xyz"  "age"  "age2"
>
> grep("age2",x)
>
> [1] 6
>
> grep("age",x) # I need to grab "age" only, not "age2"
>
> [1] 5 6
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From oma.gonzales at gmail.com  Wed May  4 08:15:55 2016
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Wed, 4 May 2016 01:15:55 -0500
Subject: [R] Grep command
In-Reply-To: <CA+8X3fUqOrv5_tkJAw9StV1PFL40n_uxGj8EVTQits0LJYOs0A@mail.gmail.com>
References: <CAKTtY6T8riPtpW2t5nvXp_v65j3BMy=3aafD4s1nkkoy5=uKCQ@mail.gmail.com>
	<CA+8X3fUqOrv5_tkJAw9StV1PFL40n_uxGj8EVTQits0LJYOs0A@mail.gmail.com>
Message-ID: <CAM-xyZjHgW3bJuggLep9w-uMPaBW7GJDGjjNzNC7VZDKM-Bf8A@mail.gmail.com>

Hi Steven,

grep uses regex... so you can use this:

-grep("age$",x): it says: match "a", then "g", then "e" and stop.  The "$"
menas until here and no more.

> grep("age$",x)
[1] 5

2016-05-04 1:02 GMT-05:00 Jim Lemon <drjimlemon at gmail.com>:

> Hi Steven,
> If this is just a one-off, you could do this:
>
> grepl("age",x) & nchar(x)<4
>
> returning a logical vector containing TRUE for "age" but not "age2"
>
> Jim
>
>
> On Wed, May 4, 2016 at 3:45 PM, Steven Yen <syen04 at gmail.com> wrote:
> > Dear all
> > In the grep command below, is there a way to identify only "age" and
> > not "age2"? In other words, I like to greb "age" and "age2"
> > separately, one at a time. Thanks.
> >
> > x<-c("abc","def","rst","xyz","age","age2")
> > x
> >
> > [1] "abc"  "def"  "rst"  "xyz"  "age"  "age2"
> >
> > grep("age2",x)
> >
> > [1] 6
> >
> > grep("age",x) # I need to grab "age" only, not "age2"
> >
> > [1] 5 6
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed May  4 08:18:51 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 3 May 2016 23:18:51 -0700
Subject: [R] R column assignment fails for lists
In-Reply-To: <CADrG32Teg5oo+ZzjSdBSrFS6BVnH1vMgUkZDKVz25QSZD7a0Zw@mail.gmail.com>
References: <CADrG32Teg5oo+ZzjSdBSrFS6BVnH1vMgUkZDKVz25QSZD7a0Zw@mail.gmail.com>
Message-ID: <623876E5-BF7F-4755-A418-729F8289924B@comcast.net>


> On May 3, 2016, at 4:13 PM, Yasir Suhail <yasir.suhail at gmail.com> wrote:
> 
> Dear R developers and users,
> 
> Consider the object :
> 
>> a <- data.frame(a=c(1,2), b=c(2,3), c=c("a,b","c,d"), stringsAsFactors = F)
>> a$c <- strsplit(a$c, ",")
> 
> Re-assignment works fine for columns 1 and 2, but fails for column 3. If a
> is a valid object, the assignment should work.

Try working with a 3 row dataframe. Then your misconceptions about how this proposed assignment will be more prominent because the dimensions would be wrong.

Here's an alternate approach:

> a <- data.frame(a=c(1,2,3), b=c(2,3,4), c=c("a,b","c,d", "e,f"), stringsAsFactors = F)
> strsplit(a$c, ",")
[[1]]
[1] "a" "b"

[[2]]
[1] "c" "d"

[[3]]
[1] "e" "f"

> do.call(rbind, strsplit(a$c, ",") )
     [,1] [,2]
[1,] "a"  "b" 
[2,] "c"  "d" 
[3,] "e"  "f" 


> str(cbind(a[-3] , do.call(rbind, strsplit(a$c, ",") ) ,stringsAsFactors=FALSE) )
'data.frame':	3 obs. of  4 variables:
 $ a: num  1 2 3
 $ b: num  2 3 4
 $ 1: chr  "a" "c" "e"
 $ 2: chr  "b" "d" "f"

-- 
David.
> 


>> a[,1] <- a[,1]
>> a[,2] <- a[,2]
>> a[,3] <- a[,3]
> Warning message:
> In `[<-.data.frame`(`*tmp*`, , 3, value = list(c("a", "b"), c("c",  :
>  provided 2 variables to replace 1 variables
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Wed May  4 08:25:07 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 3 May 2016 23:25:07 -0700
Subject: [R] R column assignment fails for lists
In-Reply-To: <73802C04-561B-400A-9EA1-1149DA41DF79@comcast.net>
References: <CADrG32Teg5oo+ZzjSdBSrFS6BVnH1vMgUkZDKVz25QSZD7a0Zw@mail.gmail.com>
	<73802C04-561B-400A-9EA1-1149DA41DF79@comcast.net>
Message-ID: <CAGxFJbTh2aDOFC2K3T4uc3333fDxrcVtPPqi6pyw97OJwYpSNQ@mail.gmail.com>

This is actually a bit subtle -- you need to carefully read the Help
pages to see what's happening. Here's the explanation to the best of
my understanding (corrections happily accepted if I've got it wrong!).

First, let's simplify:

> z <- data.frame(a = 1:2, b = list(a = letters[1:2], b = letters[3:4]))

> z
  a b.a b.b
1 1   a   c
2 2   b   d

> ncol(z)
[1] 3


So we ended up with a 3 column data.frame where it seems we should
only have two, with the second being a list with 2 components.

But that's not how it works. ?data.frame says:

"... data.frame converts each of its arguments to a data frame by
calling as.data.frame(optional = TRUE) "

and ?as.data.frame says:

"If a list is supplied, each element is converted to a column in the
data frame."

Hence when as.data.frame() is called on the second column, a 2 element
list, it converts it into a 2 column data frame (of 2 rows each) thus
giving 3 columns in all in the data frame, yielding the error you saw.

Something like this is what also happens in your assignment, I assume.
Jim's solution assigned a 1 element list which yielded what you wanted
when as.data.frame converted it into a single column.

I think....

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, May 3, 2016 at 6:48 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On May 3, 2016, at 4:13 PM, Yasir Suhail <yasir.suhail at gmail.com> wrote:
>>
>> Dear R developers and users,
>>
>> Consider the object :
>>
>>> a <- data.frame(a=c(1,2), b=c(2,3), c=c("a,b","c,d"), stringsAsFactors = F)
>>> a$c <- strsplit(a$c, ",")
>
> You are the one who should "consider the object". Look at what strsplit(a$c, ",") returns and then perhaps re-consider trying to assign it to a single column.
>
>>
>> Re-assignment works fine for columns 1 and 2, but fails for column 3. If a
>> is a valid object, the assignment should work.
>>
>>> a[,1] <- a[,1]
>>> a[,2] <- a[,2]
>>> a[,3] <- a[,3]
>> Warning message:
>> In `[<-.data.frame`(`*tmp*`, , 3, value = list(c("a", "b"), c("c",  :
>>  provided 2 variables to replace 1 variables
>>
>>       [[alternative HTML version deleted]]
>
> And please reconsider also the format of your postings.
>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From G.Maubach at weinwolf.de  Wed May  4 08:30:50 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Wed, 4 May 2016 08:30:50 +0200
Subject: [R] Antwort: Re: selecting columns from a data frame or data table
	by type, ie, numeric, integer
In-Reply-To: <1609303718.5308381.1461960441557.JavaMail.yahoo@mail.yahoo.com>
References: <CAF8bMcZMbPgRfdH0uXY+bHcb8BsrYU+9XMFqpr9czKdzjJmLUg@mail.gmail.com>
	<1609303718.5308381.1461960441557.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <OFCB1BF8EB.1F30305B-ONC1257FA9.0022CB68-C1257FA9.0023C93E@lotus.hawesko.de>

Hi All,
Hi Carl,

I am not sure if this is useful to you, but I followed your conversation 
and thought of you when I read this:

for (i in 1:ncol(dataset)) {
  if(class(dataset) == "character|numeric|factor|or whatsoever") {
    dataset[, i] <- as.factor(dataset[, i])
  }
}
Source: Zumel, Nina / Mount, John: Practical Data Science with R, Manning 
Publications: Shelter Island, 2014, Chapter 2: Loading data into R, p. 25

This way you can select variables of a certain class only and do 
transformations. I found that this approach is not applicable if used with 
statistical functions like head(). Transformations worked fine for me.

I found reading the above given source worthwile.

Kind regards

Georg

PS: I am not related to the above given authors. I am just a reader 
reporting on - at least to me - a valuable ressource.



Von:    Carl Sutton via R-help <r-help at r-project.org>
An:     William Dunlap <wdunlap at tibco.com>, 
Kopie:  "r-help at r-project.org" <r-help at r-project.org>
Datum:  29.04.2016 22:08
Betreff:        Re: [R] selecting columns from a data frame or data table 
by type, ie, numeric, integer
Gesendet von:   "R-help" <r-help-bounces at r-project.org>



Thank you Bill Dunlap.  So simple I never tried that approach. Tried 
dozens of others though, read manuals till I was getting headaches, and of 
course the answer was simple when one is competent.   Learning, its a 
struggle, but slowly getting there.
Thanks again
 Carl Sutton CPA
 

    On Friday, April 29, 2016 10:50 AM, William Dunlap <wdunlap at tibco.com> 
wrote:
 
 

 > dt1[ vapply(dt1, FUN=is.numeric, FUN.VALUE=NA) ]    a   c1   1 1.12   2 
1.0...10 10 0.2


Bill Dunlap
TIBCO Software
wdunlap tibco.com
On Fri, Apr 29, 2016 at 9:19 AM, Carl Sutton via R-help 
<r-help at r-project.org> wrote:

Good morning RGuru's
I have a data frame of 575 columns.  I want to extract only those columns 
that are numeric(double) or integer to do some machine learning with.  I 
have searched the web for a couple of days (off and on) and have not found 
anything that shows how to do this.   Lots of ways to extract rows, but 
not columns.  I have attempted to use "(x == y)" indices extraction method 
but that threw error that == was for atomic vectors and lists, and I was 
doing this on a data frame.

My test code is below

#  a technique to get column classes
library(data.table)
a <- 1:10
b <- c("a","b","c","d","e","f","g","h","i","j")
c <- seq(1.1, .2, length = 10)
dt1 <- data.table(a,b,c)
str(dt1)
col.classes <- sapply(dt1, class)
head(col.classes)
dt2 <- subset(dt1, typeof = "double" | "numeric")
str(dt2)
dt2   #  not subset
dt2 <- dt1[, list(typeof = "double")]
str(dt2)
class_data <- dt1[,sapply(dt1,is.integer) | sapply(dt1, is.numeric)]
class_data
sum(class_data)
typeof(class_data)
names(class_data)
str(class_data)
 Any help is appreciated
Carl Sutton CPA

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




 
                 [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From syen04 at gmail.com  Wed May  4 08:35:42 2016
From: syen04 at gmail.com (Steven Yen)
Date: Wed, 4 May 2016 02:35:42 -0400
Subject: [R] Fwd:  Grep command
In-Reply-To: <CA+8X3fXQq09T+qpJWQ1L-1a59_7Yg7bF4EdKNJPRN4EdoOzC0A@mail.gmail.com>
References: <CAKTtY6T8riPtpW2t5nvXp_v65j3BMy=3aafD4s1nkkoy5=uKCQ@mail.gmail.com>
	<CA+8X3fUqOrv5_tkJAw9StV1PFL40n_uxGj8EVTQits0LJYOs0A@mail.gmail.com>
	<CAKTtY6S85TFdGOFOfKG3Lo-r1PapLnFfB3Ht0nfyGh0B5q6rgQ@mail.gmail.com>
	<CA+8X3fXQq09T+qpJWQ1L-1a59_7Yg7bF4EdKNJPRN4EdoOzC0A@mail.gmail.com>
Message-ID: <CAKTtY6SR8d19WOL-S8bhxK7ju5EXyXEJo8r4ZtLotf2Tiyu4-g@mail.gmail.com>

Hi all
Both \\b and $ do the job. Thanks.

> x<-c("abc","def","rst","xyz","age","age2")
> x
[1] "abc"  "def"  "rst"  "xyz"  "age"  "age2"
> grep("age2\\b",x)
[1] 6
> grep("age\\b",x)
[1] 5
> grep("age2$",x)
[1] 6
> grep("age$",x)
[1]


From: Jim Lemon <drjimlemon at gmail.com>
Date: Wed, May 4, 2016 at 2:19 AM
Subject: Re: [R] Grep command
To: Steven Yen <syen04 at gmail.com>


Does not:

abcplus<-c("zxzxabc","zxzxabc2rst")
grepl("abc",abcplus) & nchar(abcplus)<8

do the job?

Jim

On Wed, May 4, 2016 at 4:15 PM, Steven Yen <syen04 at gmail.com> wrote:
> Thanks but no.
> There will be time when I have
>
> zxzxabc and zxzxabc2rst
>
> and I don't like to grep with the string "abc" and end up with both.
>
>
> On Wed, May 4, 2016 at 2:02 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>> Hi Steven,
>> If this is just a one-off, you could do this:
>>
>> grepl("age",x) & nchar(x)<4
>>
>> returning a logical vector containing TRUE for "age" but not "age2"
>>
>> Jim
>>
>>
>> On Wed, May 4, 2016 at 3:45 PM, Steven Yen <syen04 at gmail.com> wrote:
>>> Dear all
>>> In the grep command below, is there a way to identify only "age" and
>>> not "age2"? In other words, I like to greb "age" and "age2"
>>> separately, one at a time. Thanks.
>>>
>>> x<-c("abc","def","rst","xyz","age","age2")
>>> x
>>>
>>> [1] "abc"  "def"  "rst"  "xyz"  "age"  "age2"
>>>
>>> grep("age2",x)
>>>
>>> [1] 6
>>>
>>> grep("age",x) # I need to grab "age" only, not "age2"
>>>
>>> [1] 5 6
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From loris.bennett at fu-berlin.de  Wed May  4 08:57:37 2016
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Wed, 4 May 2016 08:57:37 +0200
Subject: [R] Reading multiple tables from one .txt doc
References: <afdd8c079a604eb0bf18a3f67ef29d48@despmsx02.brainlab.net>
Message-ID: <87k2jaxqce.fsf@hornfels.zedat.fu-berlin.de>

Mark Fingerle <mark.fingerle at brainlab.com> writes:

> Dear all,

> I have a .txt file which contains multiple tables and I would like to
> read these tables separately in order to create graphs for each one.
> The tables are separated by a blank line, have a variable number of
> lines, fixed nr. Of rows, have a header and a comment above the header
> (#) which contains a specific word that identifies each table. (see
> example below). It would be possible to change the layout of the .txt
> data a bit (Add a word, remove comment etc..)

> I would be extremely grateful if anyone could help me with this daunting task :-)
> Example:
> # CoordA
> Image    X             Y             Z             MeasuredMove MachineMove
> vf_36.png            -114.345475       -89.043448         556.073402         0             0
> vf_37.png            -111.118715       -89.978534         606.040764         50.080172           50.000000
> vf_38.png            -107.911209       -90.901958         656.025557         50.096111           50.000000
> vf_39.png            -104.693931       -91.814392         705.982620         50.068868           50.000000
> vf_40.png            -101.459549       -92.730113         755.983835         50.114082           50.000000
>
> # CoordB
> Image    X             Y             Z             MeasuredMove MachineMove
> vf_36.png            -115.345475       -89.043448         556.073402         0             0
> vf_37.png            -115.118715       -89.978534         606.040764         50.080172           50.000000
> vf_38.png            -134.911209       -90.901958         656.025557         50.096111           50.000000
> vf_39.png            -164.693931       -91.814392         705.982620         50.068868           50.000000
> vf_40.png            -134.459549       -92.730113         755.983835         50.114082           50.000000
>
> # CoordC
> Image    X             Y             Z             MeasuredMove MachineMove
> vf_36.png            -168.345475       -89.043448         556.073402         0             0
> vf_37.png            -115.118715       -89.978534         606.040764         50.080172           50.000000
> vf_38.png            -146.911209       -90.901958         656.025557         50.096111           50.000000
> vf_39.png            -187.693931       -91.814392         705.982620         50.068868           50.000000
> vf_40.png            -185.459549       -92.730113         755.983835         50.114082           50.000000
>
> 	[[alternative HTML version deleted]]
>

This is not a solution if you really want separate graphs of the
individual tables, but you could add column "Coord", roll everything
into a single table and then create one or more facet plots from that.

Cheers,

Loris

-- 
This signature is currently under construction.


From maechler at stat.math.ethz.ch  Wed May  4 09:06:18 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 4 May 2016 09:06:18 +0200
Subject: [R] Antwort: Re: selecting columns from a data frame or data
	table	by type, ie, numeric, integer
In-Reply-To: <OFCB1BF8EB.1F30305B-ONC1257FA9.0022CB68-C1257FA9.0023C93E@lotus.hawesko.de>
References: <CAF8bMcZMbPgRfdH0uXY+bHcb8BsrYU+9XMFqpr9czKdzjJmLUg@mail.gmail.com>
	<1609303718.5308381.1461960441557.JavaMail.yahoo@mail.yahoo.com>
	<OFCB1BF8EB.1F30305B-ONC1257FA9.0022CB68-C1257FA9.0023C93E@lotus.hawesko.de>
Message-ID: <22313.40810.69364.551940@stat.math.ethz.ch>

>>>>>   <G.Maubach at weinwolf.de>
>>>>>     on Wed, 4 May 2016 08:30:50 +0200 writes:

> Hi All,
> Hi Carl,
> 
> I am not sure if this is useful to you, but I followed your conversation 
> and thought of you when I read this:
> 
> for (i in 1:ncol(dataset)) {
>   if(class(dataset) == "character|numeric|factor|or whatsoever") {
>     dataset[, i] <- as.factor(dataset[, i])
>   }
> }

Ouch -- so many problems in such a short piece of R code !!!

> Source: Zumel, Nina / Mount, John: Practical Data Science with R, Manning 
> Publications: Shelter Island, 2014, Chapter 2: Loading data into R, p. 25

Sorry, but after reading the above, I'd strongly recommend getting
better books about R...
       {{maybe do not take those containing "data science" ;-)}}

Compared to the nice and efficient solution of Bill Dunlap,
the above is really bad-bad-bad  in at least four ways :

0) They way you write it above, you cannot use it,
     <string> == "variant1|variant2|..."
   is pseudocode and does not really work

1) Note the missing "[, i]"  in the 2nd line: It should be
     if(class(dataset[, i]) ...

2) A for loop changing each column at a time is really slow for
   largish data sets

3) [last but not at all least!]
   Please ... many of you readers, do learn:
  
 Using checks such as
       if ( class(x) == "numeric" )
 are (almost) always wrong by design !!!

 Instead you really should (almost) always use

 	 if(inherits(x, "numeric"))

Why?  Because classes in R (S3 or S4) can *extend* other classes.
Example: Many of you know that after   fm <- glm(...)
class(fm) is   c("glm", "lm")   and so

    > if(class(fm) == "lm")
    + "yes"
    Warning message:
    In if (class(fm) == "lm") "yes" :
      the condition has length > 1 and only the first element will be used

Similarly, in your case

y <- 1:10
class(y) <- c("myNumber", "numeric")

when that 'y' is a column in your data frame,
the test for  if(class(dataset[,i]) == "numeric")  will *not*
work but actually produce the above warning.

However, one  could als have had

Num <- setClass("Num", contains="numeric")
N <- Num(1:10)

     > Num <- setClass("Num", contains="numeric")
     > N <- Num(1:10)
     > N
     An object of class "Num"
      [1]  1  2  3  4  5  6  7  8  9 10
     > if(class(N) == "numeric") "yes" else "no"
     [1] "no"
     > 

I hope that many of the readers --- including *MANY* authors of
R packages !! --- have understood the above and will fix their R
code -- and even more their books where applicable !!

Martin Maechler,
ETH Zurich & R Core Team 
 
> 


> This way you can select variables of a certain class only and do 
> transformations. I found that this approach is not applicable if used with 
> statistical functions like head(). Transformations worked fine for me.
> 
> I found reading the above given source worthwile.
> 
> Kind regards
> 
> Georg
> 
> PS: I am not related to the above given authors. I am just a reader 
> reporting on - at least to me - a valuable ressource.
> 
> 
> 
> Von:    Carl Sutton via R-help <r-help at r-project.org>
> An:     William Dunlap <wdunlap at tibco.com>, 
> Kopie:  "r-help at r-project.org" <r-help at r-project.org>
> Datum:  29.04.2016 22:08
> Betreff:        Re: [R] selecting columns from a data frame or data table 
> by type, ie, numeric, integer
> Gesendet von:   "R-help" <r-help-bounces at r-project.org>
> 
> 
> 
> Thank you Bill Dunlap.  So simple I never tried that approach. Tried 
> dozens of others though, read manuals till I was getting headaches, and of 
> course the answer was simple when one is competent.   Learning, its a 
> struggle, but slowly getting there.
> Thanks again
>  Carl Sutton CPA
>  
> 
>     On Friday, April 29, 2016 10:50 AM, William Dunlap <wdunlap at tibco.com> 
> wrote:
>  
>  
> 
>  > dt1[ vapply(dt1, FUN=is.numeric, FUN.VALUE=NA) ]    a   c1   1 1.12   2 
> 1.0...10 10 0.2
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> On Fri, Apr 29, 2016 at 9:19 AM, Carl Sutton via R-help 
> <r-help at r-project.org> wrote:
> 
> Good morning RGuru's
> I have a data frame of 575 columns.  I want to extract only those columns 
> that are numeric(double) or integer to do some machine learning with.  I 
> have searched the web for a couple of days (off and on) and have not found 
> anything that shows how to do this.   Lots of ways to extract rows, but 
> not columns.  I have attempted to use "(x == y)" indices extraction method 
> but that threw error that == was for atomic vectors and lists, and I was 
> doing this on a data frame.
> 
> My test code is below
> 
> #  a technique to get column classes
> library(data.table)
> a <- 1:10
> b <- c("a","b","c","d","e","f","g","h","i","j")
> c <- seq(1.1, .2, length = 10)
> dt1 <- data.table(a,b,c)
> str(dt1)
> col.classes <- sapply(dt1, class)
> head(col.classes)
> dt2 <- subset(dt1, typeof = "double" | "numeric")
> str(dt2)
> dt2   #  not subset
> dt2 <- dt1[, list(typeof = "double")]
> str(dt2)
> class_data <- dt1[,sapply(dt1,is.integer) | sapply(dt1, is.numeric)]
> class_data
> sum(class_data)
> typeof(class_data)
> names(class_data)
> str(class_data)
>  Any help is appreciated
> Carl Sutton CPA


From jdnewmil at dcn.davis.ca.us  Wed May  4 08:06:30 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 03 May 2016 23:06:30 -0700
Subject: [R] Custom data structures inside of a hash function
In-Reply-To: <CAJ=2b073WxEk5Th6AYGWaPnLHMVroBt8T4+eBrcYKYOJndC9Ug@mail.gmail.com>
References: <CAJ=2b073WxEk5Th6AYGWaPnLHMVroBt8T4+eBrcYKYOJndC9Ug@mail.gmail.com>
Message-ID: <92F11E1E-0D6C-4888-97E0-86C29B69EFFE@dcn.davis.ca.us>

It is impolite to put such a minor code fragment on a transient website. Also, this is a plain text mailing list... html usually gets stripped, damaging any advantage the HTML might have had and creating confusion for people reading your message, so please learn how to send plain text.

You wrote:

------
keys <- c('AB', 'AC')
values <- c(c('hello', 0), c('world', 0))
names(values) <- keys
cat(length(values))
-----

You seem to think this is Perl. The c function concatenates... it does not make tuples, it makes vectors, which must have all elements of the same type (unless the vector is of list type). And while vectors can have named elements, those names are not hashes. And since this is R, not Perl, you should use data structures that can be operated on in vectorized fashion, or you will have horrible performance.

So,  the unhelpful but literal answer to your question is

-----
values <- list( list( 'hello', 0 ), list( 'world', 0 ))
names( values ) <- c( "AB", "AC" )
values[[ "AC" ]]
values[[ "AC" ]][[ 2 ]] <- 1
-----

but if you want a scalable solution then you need something like

-----
values <- data.frame( string=c( "hello", "world" ), num=c( 0, 0 ) )
rownames( values ) <- c( "AB", "AC" )
values[ "AC", ]
values[ "AC", 2 ] <- 1
----

though often as not the names get stuffed into another column in the data frame and rows are simply accessed using integer or logical vector indexing.

Note that data frames are column oriented.  This is fundamental to the way R works... embrace it. 

If you absolutely must have a hash then you need environments, but they are tricky animals and are remarkably (if you come from a Perl background) rarely needed. 

A long time ago I came to R with similar thoughts of writing Perl in R... but eventually I read the actual words in the Introduction to R document instead of trying to reframe them in the Perl mind set and only then did I start to make progress with R.

-- 
Sent from my phone. Please excuse my brevity.

On May 3, 2016 6:55:09 PM PDT, "Yves S. Garret" <yoursurrogategod at gmail.com> wrote:
>Hello,
>
>I have the following code:
>http://pastebin.ca/3590201
>
>What I'm trying to do is to create a hash map where the key is two
>characters and
>that maps to a structure of some information.  The problem with the
>above
>example
>is that the first two keys match to the first instance of c('hello',
>0),
>but the second is
>completely ignored.  Ideally, I'd like to retrieve the structure with
>my
>values based on
>the key at hand and modify it as I see fit.
>
>How can I achieve this?
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed May  4 08:16:48 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 03 May 2016 23:16:48 -0700
Subject: [R] Grep command
In-Reply-To: <CAKTtY6T8riPtpW2t5nvXp_v65j3BMy=3aafD4s1nkkoy5=uKCQ@mail.gmail.com>
References: <CAKTtY6T8riPtpW2t5nvXp_v65j3BMy=3aafD4s1nkkoy5=uKCQ@mail.gmail.com>
Message-ID: <80027C86-A3AA-49E9-85C5-8CDD82E77306@dcn.davis.ca.us>

Yes, but the answer is likely to depend on the actual patterns of strings in your real data, so the sooner you go find a book or tutorial on regular expressions the better.  This is decidedly not R specific and there are already lots of resources out there.

Given the example you provide,  the pattern "age$" should work. However, that is probably not sufficiently selective for a practical data set so start learning to fish (design regex patterns) yourself. 
-- 
Sent from my phone. Please excuse my brevity.

On May 3, 2016 10:45:42 PM PDT, Steven Yen <syen04 at gmail.com> wrote:
>Dear all
>In the grep command below, is there a way to identify only "age" and
>not "age2"? In other words, I like to greb "age" and "age2"
>separately, one at a time. Thanks.
>
>x<-c("abc","def","rst","xyz","age","age2")
>x
>
>[1] "abc"  "def"  "rst"  "xyz"  "age"  "age2"
>
>grep("age2",x)
>
>[1] 6
>
>grep("age",x) # I need to grab "age" only, not "age2"
>
>[1] 5 6
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From G.Maubach at weinwolf.de  Wed May  4 10:05:54 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Wed, 4 May 2016 10:05:54 +0200
Subject: [R] Antwort: Antwort: Re: selecting columns from a data frame or
	data table	by type, ie, numeric, integer
In-Reply-To: <22313.40810.69364.551940@stat.math.ethz.ch>
References: <CAF8bMcZMbPgRfdH0uXY+bHcb8BsrYU+9XMFqpr9czKdzjJmLUg@mail.gmail.com>	<1609303718.5308381.1461960441557.JavaMail.yahoo@mail.yahoo.com>
	<OFCB1BF8EB.1F30305B-ONC1257FA9.0022CB68-C1257FA9.0023C93E@lotus.hawesko.de>
	<22313.40810.69364.551940@stat.math.ethz.ch>
Message-ID: <OF7DA48A32.03F37908-ONC1257FA9.002B15FF-C1257FA9.002C7D5C@lotus.hawesko.de>

Hi Martin,

many thanks for your answer and your broad explanation. 

I am a newbie to "R" and got help on this list and thought I could give 
something back what looked OK to me.

regarding 0)
You're right, it's pseudo code. I assumed that anybody on the list would 
be able to adapt the code to their needs so that it worked. Next time I 
will post runnable code.

regarding 1)
Your right: "[, i]" is missing. My fault. Sorry.

regarding 3)
I got your point and will do better in the future.

One question: What books do you recommend to read to get to know "R" 
better?

Kind regards

Georg




Von:    Martin Maechler <maechler at stat.math.ethz.ch>
An:     <G.Maubach at weinwolf.de>, 
Kopie:  Carl Sutton <suttoncarl at ymail.com>, "r-help at r-project.org" 
<r-help at r-project.org>
Datum:  04.05.2016 09:05
Betreff:        [R] Antwort: Re: selecting columns from a data frame or 
data table      by type, ie, numeric, integer



>>>>>   <G.Maubach at weinwolf.de>
>>>>>     on Wed, 4 May 2016 08:30:50 +0200 writes:

> Hi All,
> Hi Carl,
> 
> I am not sure if this is useful to you, but I followed your conversation 

> and thought of you when I read this:
> 
> for (i in 1:ncol(dataset)) {
>   if(class(dataset) == "character|numeric|factor|or whatsoever") {
>     dataset[, i] <- as.factor(dataset[, i])
>   }
> }

Ouch -- so many problems in such a short piece of R code !!!

> Source: Zumel, Nina / Mount, John: Practical Data Science with R, 
Manning 
> Publications: Shelter Island, 2014, Chapter 2: Loading data into R, p. 
25

Sorry, but after reading the above, I'd strongly recommend getting
better books about R...
       {{maybe do not take those containing "data science" ;-)}}

Compared to the nice and efficient solution of Bill Dunlap,
the above is really bad-bad-bad  in at least four ways :

0) They way you write it above, you cannot use it,
     <string> == "variant1|variant2|..."
   is pseudocode and does not really work

1) Note the missing "[, i]"  in the 2nd line: It should be
     if(class(dataset[, i]) ...

2) A for loop changing each column at a time is really slow for
   largish data sets

3) [last but not at all least!]
   Please ... many of you readers, do learn:
 
 Using checks such as
       if ( class(x) == "numeric" )
 are (almost) always wrong by design !!!

 Instead you really should (almost) always use

                  if(inherits(x, "numeric"))

Why?  Because classes in R (S3 or S4) can *extend* other classes.
Example: Many of you know that after   fm <- glm(...)
class(fm) is   c("glm", "lm")   and so

    > if(class(fm) == "lm")
    + "yes"
    Warning message:
    In if (class(fm) == "lm") "yes" :
      the condition has length > 1 and only the first element will be used

Similarly, in your case

y <- 1:10
class(y) <- c("myNumber", "numeric")

when that 'y' is a column in your data frame,
the test for  if(class(dataset[,i]) == "numeric")  will *not*
work but actually produce the above warning.

However, one  could als have had

Num <- setClass("Num", contains="numeric")
N <- Num(1:10)

     > Num <- setClass("Num", contains="numeric")
     > N <- Num(1:10)
     > N
     An object of class "Num"
      [1]  1  2  3  4  5  6  7  8  9 10
     > if(class(N) == "numeric") "yes" else "no"
     [1] "no"
     > 

I hope that many of the readers --- including *MANY* authors of
R packages !! --- have understood the above and will fix their R
code -- and even more their books where applicable !!

Martin Maechler,
ETH Zurich & R Core Team 
 
> 


> This way you can select variables of a certain class only and do 
> transformations. I found that this approach is not applicable if used 
with 
> statistical functions like head(). Transformations worked fine for me.
> 
> I found reading the above given source worthwile.
> 
> Kind regards
> 
> Georg
> 
> PS: I am not related to the above given authors. I am just a reader 
> reporting on - at least to me - a valuable ressource.
> 
> 
> 
> Von:    Carl Sutton via R-help <r-help at r-project.org>
> An:     William Dunlap <wdunlap at tibco.com>, 
> Kopie:  "r-help at r-project.org" <r-help at r-project.org>
> Datum:  29.04.2016 22:08
> Betreff:        Re: [R] selecting columns from a data frame or data 
table 
> by type, ie, numeric, integer
> Gesendet von:   "R-help" <r-help-bounces at r-project.org>
> 
> 
> 
> Thank you Bill Dunlap.  So simple I never tried that approach. Tried 
> dozens of others though, read manuals till I was getting headaches, and 
of 
> course the answer was simple when one is competent.   Learning, its a 
> struggle, but slowly getting there.
> Thanks again
>  Carl Sutton CPA
> 
> 
>     On Friday, April 29, 2016 10:50 AM, William Dunlap 
<wdunlap at tibco.com> 
> wrote:
> 
> 
> 
>  > dt1[ vapply(dt1, FUN=is.numeric, FUN.VALUE=NA) ]    a   c1   1 1.12 2 

> 1.0...10 10 0.2
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> On Fri, Apr 29, 2016 at 9:19 AM, Carl Sutton via R-help 
> <r-help at r-project.org> wrote:
> 
> Good morning RGuru's
> I have a data frame of 575 columns.  I want to extract only those 
columns 
> that are numeric(double) or integer to do some machine learning with.  I 

> have searched the web for a couple of days (off and on) and have not 
found 
> anything that shows how to do this.   Lots of ways to extract rows, but 
> not columns.  I have attempted to use "(x == y)" indices extraction 
method 
> but that threw error that == was for atomic vectors and lists, and I was 

> doing this on a data frame.
> 
> My test code is below
> 
> #  a technique to get column classes
> library(data.table)
> a <- 1:10
> b <- c("a","b","c","d","e","f","g","h","i","j")
> c <- seq(1.1, .2, length = 10)
> dt1 <- data.table(a,b,c)
> str(dt1)
> col.classes <- sapply(dt1, class)
> head(col.classes)
> dt2 <- subset(dt1, typeof = "double" | "numeric")
> str(dt2)
> dt2   #  not subset
> dt2 <- dt1[, list(typeof = "double")]
> str(dt2)
> class_data <- dt1[,sapply(dt1,is.integer) | sapply(dt1, is.numeric)]
> class_data
> sum(class_data)
> typeof(class_data)
> names(class_data)
> str(class_data)
>  Any help is appreciated
> Carl Sutton CPA


From petr.pikal at precheza.cz  Wed May  4 10:32:00 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 4 May 2016 08:32:00 +0000
Subject: [R] Antwort: Antwort: Re: selecting columns from a data frame
 or	data table	by type, ie, numeric, integer
In-Reply-To: <OF7DA48A32.03F37908-ONC1257FA9.002B15FF-C1257FA9.002C7D5C@lotus.hawesko.de>
References: <CAF8bMcZMbPgRfdH0uXY+bHcb8BsrYU+9XMFqpr9czKdzjJmLUg@mail.gmail.com>
	<1609303718.5308381.1461960441557.JavaMail.yahoo@mail.yahoo.com>
	<OFCB1BF8EB.1F30305B-ONC1257FA9.0022CB68-C1257FA9.0023C93E@lotus.hawesko.de>
	<22313.40810.69364.551940@stat.math.ethz.ch>
	<OF7DA48A32.03F37908-ONC1257FA9.002B15FF-C1257FA9.002C7D5C@lotus.hawesko.de>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C502A6E4@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> G.Maubach at weinwolf.de
> Sent: Wednesday, May 4, 2016 10:06 AM
> To: Martin Maechler <maechler at stat.math.ethz.ch>
> Cc: r-help at r-project.org
> Subject: [R] Antwort: Antwort: Re: selecting columns from a data frame or
> data table by type, ie, numeric, integer
>
> Hi Martin,
>
> many thanks for your answer and your broad explanation.
>
> I am a newbie to "R" and got help on this list and thought I could give
> something back what looked OK to me.
>
> regarding 0)
> You're right, it's pseudo code. I assumed that anybody on the list would be
> able to adapt the code to their needs so that it worked. Next time I will post
> runnable code.
>
> regarding 1)
> Your right: "[, i]" is missing. My fault. Sorry.
>
> regarding 3)
> I got your point and will do better in the future.
>
> One question: What books do you recommend to read to get to know "R"
> better?

Freely available from CRAN

These I can recommend as I went through them

?A Guide for the Unwilling S User? by Patrick Burns
?Using R for Data Analysis and Graphics - Introduction, Examples and Commentary?  by John Maindonald (PDF, data sets and scripts are available at JM's homepage).
?Practical Regression and Anova using R? by Julian Faraway (PDF, data sets and scripts are available at the book homepage).

There are also some German books but I do not have experience with them.

Books from bookstores
Modern Applied Statistics with S. Fourth Edition, by W. N. Venables and B. D. Ripley
Introductory Statistics with R, Authors: Dalgaard, Peter

Cheers
Petr

>
> Kind regards
>
> Georg
>
>
>
>
> Von:    Martin Maechler <maechler at stat.math.ethz.ch>
> An:     <G.Maubach at weinwolf.de>,
> Kopie:  Carl Sutton <suttoncarl at ymail.com>, "r-help at r-project.org"
> <r-help at r-project.org>
> Datum:  04.05.2016 09:05
> Betreff:        [R] Antwort: Re: selecting columns from a data frame or
> data table      by type, ie, numeric, integer
>
>
>
> >>>>>   <G.Maubach at weinwolf.de>
> >>>>>     on Wed, 4 May 2016 08:30:50 +0200 writes:
>
> > Hi All,
> > Hi Carl,
> >
> > I am not sure if this is useful to you, but I followed your
> > conversation
>
> > and thought of you when I read this:
> >
> > for (i in 1:ncol(dataset)) {
> >   if(class(dataset) == "character|numeric|factor|or whatsoever") {
> >     dataset[, i] <- as.factor(dataset[, i])
> >   }
> > }
>
> Ouch -- so many problems in such a short piece of R code !!!
>
> > Source: Zumel, Nina / Mount, John: Practical Data Science with R,
> Manning
> > Publications: Shelter Island, 2014, Chapter 2: Loading data into R, p.
> 25
>
> Sorry, but after reading the above, I'd strongly recommend getting better
> books about R...
>        {{maybe do not take those containing "data science" ;-)}}
>
> Compared to the nice and efficient solution of Bill Dunlap, the above is really
> bad-bad-bad  in at least four ways :
>
> 0) They way you write it above, you cannot use it,
>      <string> == "variant1|variant2|..."
>    is pseudocode and does not really work
>
> 1) Note the missing "[, i]"  in the 2nd line: It should be
>      if(class(dataset[, i]) ...
>
> 2) A for loop changing each column at a time is really slow for
>    largish data sets
>
> 3) [last but not at all least!]
>    Please ... many of you readers, do learn:
>
>  Using checks such as
>        if ( class(x) == "numeric" )
>  are (almost) always wrong by design !!!
>
>  Instead you really should (almost) always use
>
>                   if(inherits(x, "numeric"))
>
> Why?  Because classes in R (S3 or S4) can *extend* other classes.
> Example: Many of you know that after   fm <- glm(...)
> class(fm) is   c("glm", "lm")   and so
>
>     > if(class(fm) == "lm")
>     + "yes"
>     Warning message:
>     In if (class(fm) == "lm") "yes" :
>       the condition has length > 1 and only the first element will be used
>
> Similarly, in your case
>
> y <- 1:10
> class(y) <- c("myNumber", "numeric")
>
> when that 'y' is a column in your data frame, the test for  if(class(dataset[,i])
> == "numeric")  will *not* work but actually produce the above warning.
>
> However, one  could als have had
>
> Num <- setClass("Num", contains="numeric") N <- Num(1:10)
>
>      > Num <- setClass("Num", contains="numeric")
>      > N <- Num(1:10)
>      > N
>      An object of class "Num"
>       [1]  1  2  3  4  5  6  7  8  9 10
>      > if(class(N) == "numeric") "yes" else "no"
>      [1] "no"
>      >
>
> I hope that many of the readers --- including *MANY* authors of R packages
> !! --- have understood the above and will fix their R code -- and even more
> their books where applicable !!
>
> Martin Maechler,
> ETH Zurich & R Core Team
>
> >
>
>
> > This way you can select variables of a certain class only and do
> > transformations. I found that this approach is not applicable if used
> with
> > statistical functions like head(). Transformations worked fine for me.
> >
> > I found reading the above given source worthwile.
> >
> > Kind regards
> >
> > Georg
> >
> > PS: I am not related to the above given authors. I am just a reader
> > reporting on - at least to me - a valuable ressource.
> >
> >
> >
> > Von:    Carl Sutton via R-help <r-help at r-project.org>
> > An:     William Dunlap <wdunlap at tibco.com>,
> > Kopie:  "r-help at r-project.org" <r-help at r-project.org>
> > Datum:  29.04.2016 22:08
> > Betreff:        Re: [R] selecting columns from a data frame or data
> table
> > by type, ie, numeric, integer
> > Gesendet von:   "R-help" <r-help-bounces at r-project.org>
> >
> >
> >
> > Thank you Bill Dunlap.  So simple I never tried that approach. Tried
> > dozens of others though, read manuals till I was getting headaches,
> > and
> of
> > course the answer was simple when one is competent.   Learning, its a
> > struggle, but slowly getting there.
> > Thanks again
> >  Carl Sutton CPA
> >
> >
> >     On Friday, April 29, 2016 10:50 AM, William Dunlap
> <wdunlap at tibco.com>
> > wrote:
> >
> >
> >
> >  > dt1[ vapply(dt1, FUN=is.numeric, FUN.VALUE=NA) ]    a   c1   1 1.12 2
>
> > 1.0...10 10 0.2
> >
> >
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com
> > On Fri, Apr 29, 2016 at 9:19 AM, Carl Sutton via R-help
> > <r-help at r-project.org> wrote:
> >
> > Good morning RGuru's
> > I have a data frame of 575 columns.  I want to extract only those
> columns
> > that are numeric(double) or integer to do some machine learning with.
> > I
>
> > have searched the web for a couple of days (off and on) and have not
> found
> > anything that shows how to do this.   Lots of ways to extract rows, but
> > not columns.  I have attempted to use "(x == y)" indices extraction
> method
> > but that threw error that == was for atomic vectors and lists, and I
> > was
>
> > doing this on a data frame.
> >
> > My test code is below
> >
> > #  a technique to get column classes
> > library(data.table)
> > a <- 1:10
> > b <- c("a","b","c","d","e","f","g","h","i","j")
> > c <- seq(1.1, .2, length = 10)
> > dt1 <- data.table(a,b,c)
> > str(dt1)
> > col.classes <- sapply(dt1, class)
> > head(col.classes)
> > dt2 <- subset(dt1, typeof = "double" | "numeric")
> > str(dt2)
> > dt2   #  not subset
> > dt2 <- dt1[, list(typeof = "double")]
> > str(dt2)
> > class_data <- dt1[,sapply(dt1,is.integer) | sapply(dt1, is.numeric)]
> > class_data
> > sum(class_data)
> > typeof(class_data)
> > names(class_data)
> > str(class_data)
> >  Any help is appreciated
> > Carl Sutton CPA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From NJN at dst.dk  Wed May  4 08:22:39 2016
From: NJN at dst.dk (Niels Jespersen)
Date: Wed, 4 May 2016 06:22:39 +0000
Subject: [R] Grep command
Message-ID: <3967181ED595B445B1E39718204FD4BD9F740947@SRVEXC5.dst.local>

> x <- c("abc","def","rst","xyz","age","age2")
> grep("^age$", x)
[1] 5
> grep("^age2$", x)
[1] 6
> 
>

-----Oprindelig meddelelse-----
Fra: R-help [mailto:r-help-bounces at r-project.org] P? vegne af Steven Yen
Sendt: 4. maj 2016 07:46
Til: r-help
Emne: [R] Grep command

Dear all
In the grep command below, is there a way to identify only "age" and not "age2"? In other words, I like to greb "age" and "age2"
separately, one at a time. Thanks.

x<-c("abc","def","rst","xyz","age","age2")
x

[1] "abc"  "def"  "rst"  "xyz"  "age"  "age2"

grep("age2",x)

[1] 6

grep("age",x) # I need to grab "age" only, not "age2"

[1] 5 6

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From yasir.suhail at gmail.com  Wed May  4 05:58:26 2016
From: yasir.suhail at gmail.com (Yasir Suhail)
Date: Tue, 3 May 2016 23:58:26 -0400
Subject: [R] R column assignment fails for lists
In-Reply-To: <73802C04-561B-400A-9EA1-1149DA41DF79@comcast.net>
References: <CADrG32Teg5oo+ZzjSdBSrFS6BVnH1vMgUkZDKVz25QSZD7a0Zw@mail.gmail.com>
	<73802C04-561B-400A-9EA1-1149DA41DF79@comcast.net>
Message-ID: <CADrG32QxDjvkrs8avKG-+vBCaNkdebD2PQbKO0MhyyTM9QRa9w@mail.gmail.com>

Dear Jim and David,

Thank you very much for your reply. I guess my question is whether it is
legal to store vectors in the elements of a data.frame. These are useful
for storing things like neighbors of a graph vertex, orthologs of a gene
etc. I have been using data frames of this sort and they are very useful,
so I am hoping this is a feature, rather than a bug. The weird code in my
email to form a was just one quick way of making such an object for a toy
example. These sort of data frames were doing fine for a number of analysis
pipelines until I used a function on them that had code of the sort
df[, j] <- sapply(df[, j], fun)

The interesting thing is that while
a[,3] <- a[,3] changes the object and gives the warning
a$c <- a$c works "correctly". leaving a to what it was and doesn't give a
warning.

If elements of a data frame are supposed to be able to store vectors, then
shouldn't
a[,3] <- a[,3] work?

Best regards,
yasir


On Tue, May 3, 2016 at 9:48 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On May 3, 2016, at 4:13 PM, Yasir Suhail <yasir.suhail at gmail.com> wrote:
> >
> > Dear R developers and users,
> >
> > Consider the object :
> >
> >> a <- data.frame(a=c(1,2), b=c(2,3), c=c("a,b","c,d"), stringsAsFactors
> = F)
> >> a$c <- strsplit(a$c, ",")
>
> You are the one who should "consider the object". Look at what
> strsplit(a$c, ",") returns and then perhaps re-consider trying to assign it
> to a single column.
>
> >
> > Re-assignment works fine for columns 1 and 2, but fails for column 3. If
> a
> > is a valid object, the assignment should work.
> >
> >> a[,1] <- a[,1]
> >> a[,2] <- a[,2]
> >> a[,3] <- a[,3]
> > Warning message:
> > In `[<-.data.frame`(`*tmp*`, , 3, value = list(c("a", "b"), c("c",  :
> >  provided 2 variables to replace 1 variables
> >
> >       [[alternative HTML version deleted]]
>
> And please reconsider also the format of your postings.
>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From naresh_gurbuxani at hotmail.com  Wed May  4 13:11:01 2016
From: naresh_gurbuxani at hotmail.com (Naresh Gurbuxani)
Date: Wed, 4 May 2016 11:11:01 +0000
Subject: [R] expression input to a function
Message-ID: <BN3PR07MB2577DCDD05AA808F324B55DEFA7B0@BN3PR07MB2577.namprd07.prod.outlook.com>

I am trying to write a function, which can be made very general if one of the inputs can be an expression. ?How can this be done?


For example, to find root of a function, I would like to say

my.func <- function(x) {x^3 + 2 * (x^2) - 7}

x.left <- 0
x.right <- 2
n.iterations <- 0

find.root <- function(my.func, x.left, x.right) {
 # code here
return(c(x.mid, n.iterations))
}

The above method clearly does not work.  

Thanks,
Naresh

From murdoch.duncan at gmail.com  Wed May  4 14:13:57 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 4 May 2016 08:13:57 -0400
Subject: [R] expression input to a function
In-Reply-To: <BN3PR07MB2577DCDD05AA808F324B55DEFA7B0@BN3PR07MB2577.namprd07.prod.outlook.com>
References: <BN3PR07MB2577DCDD05AA808F324B55DEFA7B0@BN3PR07MB2577.namprd07.prod.outlook.com>
Message-ID: <5729E785.9020503@gmail.com>

On 04/05/2016 7:11 AM, Naresh Gurbuxani wrote:
> I am trying to write a function, which can be made very general if one of the inputs can be an expression.  How can this be done?
>
>
> For example, to find root of a function, I would like to say
>
> my.func <- function(x) {x^3 + 2 * (x^2) - 7}
>
> x.left <- 0
> x.right <- 2
> n.iterations <- 0
>
> find.root <- function(my.func, x.left, x.right) {
>   # code here
> return(c(x.mid, n.iterations))
> }
>
> The above method clearly does not work.

You are taking the right approach.  You can pass functions as arguments 
to other functions; they are "first class objects".  For example:

evaluate <- function(f, x) f(x)

evaluate(my.func, 3)

would give the same result as my.func(3).

For your find.root function, just write the search in find.root using 
the name of the argument (which for didactic purposes I'd recommend be 
different from the actual function name, but it'll be fine in practice).

It is also possible to pass expressions that aren't in functions, but it 
gets tricky, and you shouldn't do that in your first attempt.

Duncan Murdoch


From erich.neuwirth at univie.ac.at  Wed May  4 14:22:43 2016
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Wed, 4 May 2016 14:22:43 +0200
Subject: [R] Install on Xenial
Message-ID: <5D60EDD9-54A6-4A2A-987C-ABF86BE53695@univie.ac.at>

I am trying to install R-3.3.0 on Xenial.
I followed the instructions on the corresponding CRAN page, and I added the GPG key.
But after adding
deb https://cran.at.r-project.org//bin/linux/ubuntu xenial/
to /etc/apt/sources.list
and
sudo apt-get update
I get the following error:

Err:7 https://cran.at.r-project.org//bin/linux/ubuntu xenial/ Packages
  SSL: certificate subject name (*.r-project.org) does not match target host name 'cran.at.r-project.org?

What do I need to do to get rid of this error


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 670 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160504/1ee535d0/attachment.bin>

From jdnewmil at dcn.davis.ca.us  Wed May  4 14:36:18 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 04 May 2016 05:36:18 -0700
Subject: [R] Install on Xenial
In-Reply-To: <5D60EDD9-54A6-4A2A-987C-ABF86BE53695@univie.ac.at>
References: <5D60EDD9-54A6-4A2A-987C-ABF86BE53695@univie.ac.at>
Message-ID: <D2206D3D-F024-4290-907B-8DC68C2B4998@dcn.davis.ca.us>

Pick different mirror. 
-- 
Sent from my phone. Please excuse my brevity.

On May 4, 2016 5:22:43 AM PDT, Erich Neuwirth <erich.neuwirth at univie.ac.at> wrote:
>I am trying to install R-3.3.0 on Xenial.
>I followed the instructions on the corresponding CRAN page, and I added
>the GPG key.
>But after adding
>deb https://cran.at.r-project.org//bin/linux/ubuntu xenial/
>to /etc/apt/sources.list
>and
>sudo apt-get update
>I get the following error:
>
>Err:7 https://cran.at.r-project.org//bin/linux/ubuntu xenial/ Packages
>SSL: certificate subject name (*.r-project.org) does not match target
>host name 'cran.at.r-project.org?
>
>What do I need to do to get rid of this error
>
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From chalabi.elahe at yahoo.de  Wed May  4 15:05:26 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Wed, 4 May 2016 13:05:26 +0000 (UTC)
Subject: [R] undefined columns selected!
References: <1645119024.648807.1462367126434.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1645119024.648807.1462367126434.JavaMail.yahoo@mail.yahoo.com>


Hi all,
I know it seems simple but I am trying to copy a code and I don't know what is the problem with this command!

    msubsub=msub[,cn]

the error I get is : error in '[.data.frame '(msub, ,cn) : undefined columns selected 
 
Thanks for any help,
Elahe


From john.archie.mckown at gmail.com  Wed May  4 15:14:46 2016
From: john.archie.mckown at gmail.com (John McKown)
Date: Wed, 4 May 2016 08:14:46 -0500
Subject: [R] undefined columns selected!
In-Reply-To: <1645119024.648807.1462367126434.JavaMail.yahoo@mail.yahoo.com>
References: <1645119024.648807.1462367126434.JavaMail.yahoo.ref@mail.yahoo.com>
	<1645119024.648807.1462367126434.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAAJSdjjWZ-TKFNOPBiqoJ1Dr7E5=B2FX+sPJq-TdtkW+whci-A@mail.gmail.com>

On Wed, May 4, 2016 at 8:05 AM, ch.elahe via R-help <r-help at r-project.org>
wrote:

>
> Hi all,
> I know it seems simple but I am trying to copy a code and I don't know
> what is the problem with this command!
>
>     msubsub=msub[,cn]
>
> the error I get is : error in '[.data.frame '(msub, ,cn) : undefined
> columns selected
>

?First - very important - please change from HTML posting to plain text.
This forum doesn't handle HTML well and its use very often results in
?unreadable and thus unusable messages.

?TLI (Too Little Information). I would probably help if you would post the
information from things like:

dput(head(msub))

dput(head(cn)?)


Most want "dput(msub)" and "dput(cn)", but I use the "head()" to subset
that to examples which are usually easier to post. It depends on the
problem and the size of the data involved. Oh, please don't just
cut'n'paste the output from simply listing "msub" or "cn", that produces
output which cannot be cut and pasted easily into an R session. Thanks.


>
> Thanks for any help,
> Elahe
>
>

-- 
The unfacts, did we have them, are too imprecisely few to warrant our
certitude.

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From varinsacha at yahoo.fr  Wed May  4 16:53:12 2016
From: varinsacha at yahoo.fr (varin sacha)
Date: Wed, 4 May 2016 14:53:12 +0000 (UTC)
Subject: [R] Robust MARS regression with R ?
References: <1440627439.828408.1462373592494.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1440627439.828408.1462373592494.JavaMail.yahoo@mail.yahoo.com>

Dear R-helpers,

I would like to know if it is possible using R (earth packages or another one) to realize robust MARS regression RMARS or RCMARS (C mean "conic").

Some authors have done it using MOSEK combined with Salford-MARS and special MATLAB programs.

Best Regards,

Sacha


From bgunter.4567 at gmail.com  Wed May  4 16:55:51 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 4 May 2016 07:55:51 -0700
Subject: [R] undefined columns selected!
In-Reply-To: <1645119024.648807.1462367126434.JavaMail.yahoo@mail.yahoo.com>
References: <1645119024.648807.1462367126434.JavaMail.yahoo.ref@mail.yahoo.com>
	<1645119024.648807.1462367126434.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAGxFJbR_gwojCPowBcw_B9JYyqR6VE1gyQRLcWaqMvRVuefieg@mail.gmail.com>

The the column name must be quoted in the index:

msubsub=msub[,"cn"]


Please go through a basic R tutorial  or two if you want to learn to use R.


Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, May 4, 2016 at 6:05 AM, ch.elahe via R-help
<r-help at r-project.org> wrote:
>
> Hi all,
> I know it seems simple but I am trying to copy a code and I don't know what is the problem with this command!
>
>     msubsub=msub[,cn]
>
> the error I get is : error in '[.data.frame '(msub, ,cn) : undefined columns selected
>
> Thanks for any help,
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Wed May  4 17:08:08 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 4 May 2016 15:08:08 +0000
Subject: [R] undefined columns selected!
In-Reply-To: <1645119024.648807.1462367126434.JavaMail.yahoo@mail.yahoo.com>
References: <1645119024.648807.1462367126434.JavaMail.yahoo.ref@mail.yahoo.com>
	<1645119024.648807.1462367126434.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <D34F5D27.1725D2%macqueen1@llnl.gov>

First, type
   names(msub)
and then type
   cn
and compare the output.

Probably, you will find a name in cn that is not among the names of msub.

To maybe make it easier to see the missing column(s), you can type

  setdiff(cn, names(msub))

The expression
  msub[,cn]
is intended to select columns from msub. That error message means that you
are trying to select one or more columns that are not there.

Or perhaps Bert Gunter is correct, and it should be
  msub[,'cn']
but I believe that if that were the case the error message would likely be
different. Without more information we can't be sure.

-Don



-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 5/4/16, 6:05 AM, "R-help on behalf of ch.elahe via R-help"
<r-help-bounces at r-project.org on behalf of r-help at r-project.org> wrote:

>
>Hi all,
>I know it seems simple but I am trying to copy a code and I don't know
>what is the problem with this command!
>
>    msubsub=msub[,cn]
>
>the error I get is : error in '[.data.frame '(msub, ,cn) : undefined
>columns selected 
> 
>Thanks for any help,
>Elahe
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://secure-web.cisco.com/17LbfsJ6l1TxAGGDaZPJaqSjzCIWn5E9CwPSSMrKL6TmF
>nzxq4NMk2_I5ZoRND9U7-DVdKRI4gQq-ksFm42c_Y4YLWER6RjmX7KA43TlJE090H6BW03h2ch
>R-AjcGVBd7OkbsupK4ILVvkOhZEs4oearHg3fxw5eGd1HheF2ZmV23Gk8iUz73qq3xABMYDqRs
>MimloONz77mr0nVciORpjobMGuDvIH69DttdwbXnkLyVgrlscdiOjTp_LjcdJMSFKqMjepMDxH
>iQGQfThQ4q3l5ZjSUts8soTR8Bg5R722f-4WJkevdYYreIEU3i0aH64_AdN7Hhn9lHL1MUOm0K
>Mg0IV4twClhcRjs7Bf5Qf9M/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2F
>r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>


From E.M.A.Hensor at leeds.ac.uk  Wed May  4 12:43:53 2016
From: E.M.A.Hensor at leeds.ac.uk (Elizabeth Hensor)
Date: Wed, 4 May 2016 10:43:53 +0000
Subject: [R] Changing transformations in mi package
Message-ID: <VI1PR03MB145502589EEB2F0193B83472D77B0@VI1PR03MB1455.eurprd03.prod.outlook.com>

Dear all,
I am an R beginner and new to the list. In preparation for using mi to impute missing values I am setting up the missing data frame and would like to specify the transformation types for some of my variables, as I will be using these transformations in my analysis models. According to the documentation the available options are "standardize" (the default), "identity", "log", "logshift" and "sqrt". I can successfully change the transformation types to "log" and "logshift", but when I attempt to change to "sqrt", this changes the type to "log" instead. I'd appreciate your help, please.
Below are details of my system and some code which replicates the issue.

> sessionInfo()
R version 3.2.5 (2016-04-14)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United Kingdom.1252   
[3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C                           
[5] LC_TIME=English_United Kingdom.1252    

attached base packages:
[1] stats4    stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] lmerTest_2.0-30 truncnorm_1.0-7 mi_1.0          lme4_1.1-12     Matrix_1.2-4   
[6] pls_2.5-0      

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.4         Formula_1.2-1       cluster_2.0.3       splines_3.2.5      
 [5] MASS_7.3-45         munsell_0.4.3       colorspace_1.2-6    arm_1.8-6          
 [9] lattice_0.20-33     minqa_1.2.4         plyr_1.8.3          nnet_7.3-12        
[13] grid_3.2.5          nlme_3.1-126        gtable_0.2.0        latticeExtra_0.6-28
[17] coda_0.18-1         abind_1.4-3         survival_2.38-3     gridExtra_2.2.1    
[21] RColorBrewer_1.1-2  nloptr_1.0.4        ggplot2_2.1.0       acepack_1.3-3.3    
[25] rpart_4.1-10        scales_0.4.0        Hmisc_3.17-3        foreign_0.8-66

data <- data.frame(a=c(NA,2.1,3.3,4.5,5.9,6.2),b=c(2.2,NA,6.1,8.3,10.2,12.13),c=c(4.2,7.9,NA,16.1,19.9,23))
data

    a     b    c
1  NA  2.20  4.2
2 2.1    NA  7.9
3 3.3  6.10   NA
4 4.5  8.30 16.1
5 5.9 10.20 19.9
6 6.2 12.13 23.0

data.missingdf <- missing_data.frame(data)
show(data.missingdf)

Object of class missing_data.frame with 6 observations on 3 variables

There are 4 missing data patterns

Append '@patterns' to this missing_data.frame to access the corresponding pattern for every observation or perhaps use table()

        type missing method  model
a continuous       1    ppd linear
b continuous       1    ppd linear
c continuous       1    ppd linear

    family     link transformation
a gaussian identity    standardize
b gaussian identity    standardize
c gaussian identity    standardize

#Let's say I'd like to change transformation for a, b and c to "log", "logshift" and "sqrt" respectively

data.missingdf <- change(data.missingdf, y="a", what="transformation", to="logshift")
data.missingdf <- change(data.missingdf, y="b", what="transformation", to="log")
data.missingdf <- change(data.missingdf, y="c", what="transformation", to="sqrt")
show(data.missingdf)

Object of class missing_data.frame with 6 observations on 3 variables

There are 4 missing data patterns

Append '@patterns' to this missing_data.frame to access the corresponding pattern for every observation or perhaps use table()

        type missing method  model
a continuous       1    ppd linear
b continuous       1    ppd linear
c continuous       1    ppd linear

    family     link transformation
a gaussian identity       logshift
b gaussian identity            log
c gaussian identity            log

#Transformation has been successfully changed for a and b, but for c has been changed to "log" instead of "sqrt"

Thanks in advance for your assistance,
Liz Hensor

Biostatistician
Leeds Institute of Rheumatic and Musculoskeletal Medicine &
NIHR Leeds Musculoskeletal Biomedical Research Unit


From jeremiejuste at gmail.com  Wed May  4 14:34:05 2016
From: jeremiejuste at gmail.com (=?UTF-8?B?SsOpcsOpbWllIEp1c3Rl?=)
Date: Wed, 4 May 2016 14:34:05 +0200
Subject: [R] copula package error when gumbel parameter is close to bound.
Message-ID: <CAPHJcdBagMQFn_ieZs4n9DhmF2LXVgQqVQnpszNLptPEM6XbxA@mail.gmail.com>

Hello,

In a situation where the dimension is high and the parameter is close to
the bound computing the density of the gumbel copula throws the following
error.

library(copula)
dCopula(rep(0.5,127),gumbelCopula(1.19,127),log=TRUE)

Loading required namespace: Rmpfr
Failed with error:  ?there is no package called ?Rmpfr??
Error: requireNamespace("Rmpfr") is not TRUE


It does not seem to be a ploblem with lower dimension though

dCopula(rep(0.5,17),gumbelCopula(1.19,17),log=TRUE)

[1] 2.402906

I'm I missing something about the computation?

Best regards
-- 
Jeremie Juste

	[[alternative HTML version deleted]]


From desolator88 at 163.com  Wed May  4 16:45:27 2016
From: desolator88 at 163.com (super)
Date: Wed, 4 May 2016 22:45:27 +0800 (CST)
Subject: [R]  how to compute Bonferroni, Tukey's,
 Sheffe 95%-condence intervals for coefficients B1, B2,
 B3 in linear regression?
Message-ID: <3b331b67.8b6b.1547c3b1432.Coremail.desolator88@163.com>


Dear experts,?
? ?I have a problem in compute?Bonferroni,Tukey's,Sheffe 95%-condence intervals for coefficients B1,B2,B3 in linear regression using R? how can i do it? I only know how to compute these three cofindence intervals in multicomparsion by using multcomp package, and i am search a lot for how to comupte the three CIs for linear regression coefficients but without any useful information, so, plz help me ~

From HDoran at air.org  Wed May  4 17:51:13 2016
From: HDoran at air.org (Doran, Harold)
Date: Wed, 4 May 2016 15:51:13 +0000
Subject: [R] Grep command
In-Reply-To: <CAKTtY6T8riPtpW2t5nvXp_v65j3BMy=3aafD4s1nkkoy5=uKCQ@mail.gmail.com>
References: <CAKTtY6T8riPtpW2t5nvXp_v65j3BMy=3aafD4s1nkkoy5=uKCQ@mail.gmail.com>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD686012BC0E02B@DC1VEX10MB01.air.org>

You asked this question yesterday, and received responses on this same response. Is there a reason this is reposted?



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Steven Yen
Sent: Wednesday, May 04, 2016 1:46 AM
To: r-help <r-help at r-project.org>
Subject: [R] Grep command

Dear all
In the grep command below, is there a way to identify only "age" and not "age2"? In other words, I like to greb "age" and "age2"
separately, one at a time. Thanks.

x<-c("abc","def","rst","xyz","age","age2")
x

[1] "abc"  "def"  "rst"  "xyz"  "age"  "age2"

grep("age2",x)

[1] 6

grep("age",x) # I need to grab "age" only, not "age2"

[1] 5 6

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed May  4 18:59:48 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 4 May 2016 09:59:48 -0700
Subject: [R] Grep command
In-Reply-To: <80027C86-A3AA-49E9-85C5-8CDD82E77306@dcn.davis.ca.us>
References: <CAKTtY6T8riPtpW2t5nvXp_v65j3BMy=3aafD4s1nkkoy5=uKCQ@mail.gmail.com>
	<80027C86-A3AA-49E9-85C5-8CDD82E77306@dcn.davis.ca.us>
Message-ID: <3FF34864-6C1A-4958-A71E-88631D33F10F@comcast.net>


> On May 3, 2016, at 11:16 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> Yes, but the answer is likely to depend on the actual patterns of strings in your real data, so the sooner you go find a book or tutorial on regular expressions the better.  This is decidedly not R specific and there are already lots of resources out there.
> 
> Given the example you provide,  the pattern "age$" should work. However, that is probably not sufficiently selective for a practical data set so start learning to fish (design regex patterns) yourself. 

@ Steven;

As is almost always the case I agree with Jeff. I found that reading Rhelp and attempting to answer regex-questions was the best method to learn them. In particular I found the postings by Gabor Grothendieck very helpful in getting some degree of competence in this area. I see that his grep-related postings still exceed my grep postings and I assure you that his will be more sophisticated than my efforts. I recommend the MarkMail Rhelp mirror interface as very useful in "mining" Rhelp for knowledge:

Gabor Grothendieck answers with either 'grep' pr 'regex' in their body:

http://markmail.org/search/?q=list%3Aorg.r-project.r-help+list%3Agrep+list%3Aregex+from%3A%22Gabor+Grothendieck

-- 
Happy searching;
David.


> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On May 3, 2016 10:45:42 PM PDT, Steven Yen <syen04 at gmail.com> wrote:
>> Dear all
>> In the grep command below, is there a way to identify only "age" and
>> not "age2"? In other words, I like to greb "age" and "age2"
>> separately, one at a time. Thanks.
>> 
>> x<-c("abc","def","rst","xyz","age","age2")
>> x
>> 
>> [1] "abc"  "def"  "rst"  "xyz"  "age"  "age2"
>> 
>> grep("age2",x)
>> 
>> [1] 6
>> 
>> grep("age",x) # I need to grab "age" only, not "age2"
>> 
>> [1] 5 6
>> 

David Winsemius
Alameda, CA, USA


From suttoncarl at ymail.com  Wed May  4 19:08:02 2016
From: suttoncarl at ymail.com (Carl Sutton)
Date: Wed, 4 May 2016 17:08:02 +0000 (UTC)
Subject: [R] Antwort: Re: selecting columns from a data frame or data
 table	by type, ie, numeric, integer
In-Reply-To: <22313.40810.69364.551940@stat.math.ethz.ch>
References: <22313.40810.69364.551940@stat.math.ethz.ch>
Message-ID: <1321078026.8205902.1462381682972.JavaMail.yahoo@mail.yahoo.com>

Hi Martin and list:
First let me thank you for thinking of me.?? It is probably apparent that my programming experience is limited, and the vector aspect of R has taken some getting used to.?? A very very long time ago I did some programming in Fortran and for loops and if statements were ordinary, useful, and used frequently.?? Now if I see a for loop and if statement together then it is flatly apparent that I need to rework that code to take advantage of R's strengths using vectoized functions on whatever object I am working on.??
It has also become apparent that one should read manuals, experiment with some code to firmly cement the knowledge, and build a solid foundation.?? My natural inclination is the opposite.? I am anxious to produce some code to solve a problem or satisfy curiosity or ....? R is not something one can learn and use productively in a few weeks or months.?? It is powerful, subtle, and takes some thinking.?? I started this trek into R with Jared Lander's book "R for Everyone",? progressed to Prof Norman Matloff's "The Art of R Programming" (which was way beyond my comprehension at the beginning) and Hadley Wickham's "ggplot2" book, and several courses with Data Camp and Couresra.? One day I will be at the point where I do know what I don't know about R and at that time I will almost be competent with the language.

I have taken the work from Bill Dunlap and Giorgio Garziano and have applied it to my little project and am just amazed that so little code can do so much.? I have also followed Bert Gunter's advice and taken that code and dissected it item by item to comprehend what each element is doing.?? 

The knowledge and help on this list is just amazing and I do appreciate the efforts of all involved.? I read the digest daily .
Carl Sutton CPA
 

    On Wednesday, May 4, 2016 12:06 AM, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
 
 

 >>>>>? <G.Maubach at weinwolf.de>
>>>>>? ? on Wed, 4 May 2016 08:30:50 +0200 writes:

> Hi All,
> Hi Carl,
> 
> I am not sure if this is useful to you, but I followed your conversation 
> and thought of you when I read this:
> 
> for (i in 1:ncol(dataset)) {
>? if(class(dataset) == "character|numeric|factor|or whatsoever") {
>? ? dataset[, i] <- as.factor(dataset[, i])
>? }
> }

Ouch -- so many problems in such a short piece of R code !!!

> Source: Zumel, Nina / Mount, John: Practical Data Science with R, Manning 
> Publications: Shelter Island, 2014, Chapter 2: Loading data into R, p. 25

Sorry, but after reading the above, I'd strongly recommend getting
better books about R...
? ? ? {{maybe do not take those containing "data science" ;-)}}

Compared to the nice and efficient solution of Bill Dunlap,
the above is really bad-bad-bad? in at least four ways :

0) They way you write it above, you cannot use it,
? ? <string> == "variant1|variant2|..."
? is pseudocode and does not really work

1) Note the missing "[, i]"? in the 2nd line: It should be
? ? if(class(dataset[, i]) ...

2) A for loop changing each column at a time is really slow for
? largish data sets

3) [last but not at all least!]
? Please ... many of you readers, do learn:
? 
 Using checks such as
? ? ? if ( class(x) == "numeric" )
 are (almost) always wrong by design !!!

 Instead you really should (almost) always use

 ??? if(inherits(x, "numeric"))

Why?? Because classes in R (S3 or S4) can *extend* other classes.
Example: Many of you know that after? fm <- glm(...)
class(fm) is? c("glm", "lm")? and so

? ? > if(class(fm) == "lm")
? ? + "yes"
? ? Warning message:
? ? In if (class(fm) == "lm") "yes" :
? ? ? the condition has length > 1 and only the first element will be used

Similarly, in your case

y <- 1:10
class(y) <- c("myNumber", "numeric")

when that 'y' is a column in your data frame,
the test for? if(class(dataset[,i]) == "numeric")? will *not*
work but actually produce the above warning.

However, one? could als have had

Num <- setClass("Num", contains="numeric")
N <- Num(1:10)

? ? > Num <- setClass("Num", contains="numeric")
? ? > N <- Num(1:10)
? ? > N
? ? An object of class "Num"
? ? ? [1]? 1? 2? 3? 4? 5? 6? 7? 8? 9 10
? ? > if(class(N) == "numeric") "yes" else "no"
? ? [1] "no"
? ? > 

I hope that many of the readers --- including *MANY* authors of
R packages !! --- have understood the above and will fix their R
code -- and even more their books where applicable !!

Martin Maechler,
ETH Zurich & R Core Team 
 
> 


> This way you can select variables of a certain class only and do 
> transformations. I found that this approach is not applicable if used with 
> statistical functions like head(). Transformations worked fine for me.
> 
> I found reading the above given source worthwile.
> 
> Kind regards
> 
> Georg
> 
> PS: I am not related to the above given authors. I am just a reader 
> reporting on - at least to me - a valuable ressource.
> 
> 
> 
> Von:? ? Carl Sutton via R-help <r-help at r-project.org>
> An:? ? William Dunlap <wdunlap at tibco.com>, 
> Kopie:? "r-help at r-project.org" <r-help at r-project.org>
> Datum:? 29.04.2016 22:08
> Betreff:? ? ? ? Re: [R] selecting columns from a data frame or data table 
> by type, ie, numeric, integer
> Gesendet von:? "R-help" <r-help-bounces at r-project.org>
> 
> 
> 
> Thank you Bill Dunlap.? So simple I never tried that approach. Tried 
> dozens of others though, read manuals till I was getting headaches, and of 
> course the answer was simple when one is competent.? Learning, its a 
> struggle, but slowly getting there.
> Thanks again
>? Carl Sutton CPA
>? 
> 
>? ? On Friday, April 29, 2016 10:50 AM, William Dunlap <wdunlap at tibco.com> 
> wrote:
>? 
>? 
> 
>? > dt1[ vapply(dt1, FUN=is.numeric, FUN.VALUE=NA) ]? ? a? c1? 1 1.12? 2 
> 1.0...10 10 0.2
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> On Fri, Apr 29, 2016 at 9:19 AM, Carl Sutton via R-help 
> <r-help at r-project.org> wrote:
> 
> Good morning RGuru's
> I have a data frame of 575 columns.? I want to extract only those columns 
> that are numeric(double) or integer to do some machine learning with.? I 
> have searched the web for a couple of days (off and on) and have not found 
> anything that shows how to do this.? Lots of ways to extract rows, but 
> not columns.? I have attempted to use "(x == y)" indices extraction method 
> but that threw error that == was for atomic vectors and lists, and I was 
> doing this on a data frame.
> 
> My test code is below
> 
> #? a technique to get column classes
> library(data.table)
> a <- 1:10
> b <- c("a","b","c","d","e","f","g","h","i","j")
> c <- seq(1.1, .2, length = 10)
> dt1 <- data.table(a,b,c)
> str(dt1)
> col.classes <- sapply(dt1, class)
> head(col.classes)
> dt2 <- subset(dt1, typeof = "double" | "numeric")
> str(dt2)
> dt2? #? not subset
> dt2 <- dt1[, list(typeof = "double")]
> str(dt2)
> class_data <- dt1[,sapply(dt1,is.integer) | sapply(dt1, is.numeric)]
> class_data
> sum(class_data)
> typeof(class_data)
> names(class_data)
> str(class_data)
>? Any help is appreciated
> Carl Sutton CPA


 
  
	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Wed May  4 19:23:01 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 4 May 2016 10:23:01 -0700
Subject: [R] Grep command
In-Reply-To: <3FF34864-6C1A-4958-A71E-88631D33F10F@comcast.net>
References: <CAKTtY6T8riPtpW2t5nvXp_v65j3BMy=3aafD4s1nkkoy5=uKCQ@mail.gmail.com>
	<80027C86-A3AA-49E9-85C5-8CDD82E77306@dcn.davis.ca.us>
	<3FF34864-6C1A-4958-A71E-88631D33F10F@comcast.net>
Message-ID: <CAF8bMca7WUV4cvXkKbAZN6qLAzJoq-7aSq=W1or9-n89gwQbYA@mail.gmail.com>

No matter how expert you are at writing regular expressions,
it is important to list which sorts of strings you want matched
and which you do not want matched.  Saying you want to match
"age" but not "age2" leads to lots of possibilities.  Saying how
you want to categorize each string in a vector of stirngs like
the following would narrow things down.
   c("age", "ages ago", "age 60", "An aged man", "page", "Age", "age1",
      "age2",  "dark age", "the aGE")
>From such a list, make a good verbal description of the rule you
are thinking of and someone will be able to translate that into a regular
expression (or say that regular expressions cannot do the job).


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, May 4, 2016 at 9:59 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On May 3, 2016, at 11:16 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> >
> > Yes, but the answer is likely to depend on the actual patterns of
> strings in your real data, so the sooner you go find a book or tutorial on
> regular expressions the better.  This is decidedly not R specific and there
> are already lots of resources out there.
> >
> > Given the example you provide,  the pattern "age$" should work. However,
> that is probably not sufficiently selective for a practical data set so
> start learning to fish (design regex patterns) yourself.
>
> @ Steven;
>
> As is almost always the case I agree with Jeff. I found that reading Rhelp
> and attempting to answer regex-questions was the best method to learn them.
> In particular I found the postings by Gabor Grothendieck very helpful in
> getting some degree of competence in this area. I see that his grep-related
> postings still exceed my grep postings and I assure you that his will be
> more sophisticated than my efforts. I recommend the MarkMail Rhelp mirror
> interface as very useful in "mining" Rhelp for knowledge:
>
> Gabor Grothendieck answers with either 'grep' pr 'regex' in their body:
>
>
> http://markmail.org/search/?q=list%3Aorg.r-project.r-help+list%3Agrep+list%3Aregex+from%3A%22Gabor+Grothendieck
>
> --
> Happy searching;
> David.
>
>
> > --
> > Sent from my phone. Please excuse my brevity.
> >
> > On May 3, 2016 10:45:42 PM PDT, Steven Yen <syen04 at gmail.com> wrote:
> >> Dear all
> >> In the grep command below, is there a way to identify only "age" and
> >> not "age2"? In other words, I like to greb "age" and "age2"
> >> separately, one at a time. Thanks.
> >>
> >> x<-c("abc","def","rst","xyz","age","age2")
> >> x
> >>
> >> [1] "abc"  "def"  "rst"  "xyz"  "age"  "age2"
> >>
> >> grep("age2",x)
> >>
> >> [1] 6
> >>
> >> grep("age",x) # I need to grab "age" only, not "age2"
> >>
> >> [1] 5 6
> >>
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From alaios at yahoo.com  Wed May  4 19:53:04 2016
From: alaios at yahoo.com (Alaios)
Date: Wed, 4 May 2016 17:53:04 +0000 (UTC)
Subject: [R] greek characters in Figures
In-Reply-To: <F132CF86-8EDD-4E21-85B0-E429E86586FA@comcast.net>
References: <F132CF86-8EDD-4E21-85B0-E429E86586FA@comcast.net>
Message-ID: <1816955105.6118956.1462384384750.JavaMail.yahoo@mail.yahoo.com>

> install.packages("latex2exp")Installiere Paket nach ?/home/apa/R/x86_64-pc-linux-gnu-library/3.2?(da ?lib? nicht spezifiziert)Warnung: kann nicht auf den Index f?r das Repository https://cran.cnr.Berkeley.edu/src/contrib zugreifen:? nicht unterst?tztes URL SchemaWarnmeldung:Paket ?latex2exp? ist nicht verf?gbar (for R version 3.2.4 Revised)?> install.packages("latex2expr")Installiere Paket nach ?/home/apa/R/x86_64-pc-linux-gnu-library/3.2?(da ?lib? nicht spezifiziert)Warnung: kann nicht auf den Index f?r das Repository https://cran.cnr.Berkeley.edu/src/contrib zugreifen:? nicht unterst?tztes URL SchemaWarnmeldung:Paket ?latex2expr? ist nicht verf?gbar (for R version 3.2.4 Revised)?
 

    On Monday, May 2, 2016 9:39 PM, David Winsemius <dwinsemius at comcast.net> wrote:
 

 
> On May 2, 2016, at 10:32 AM, Alaios via R-help <r-help at r-project.org> wrote:
> 
> Dear all,I am trying to write in my Figure labels short equations that contain greek characters
> 
> For example:? C(h) = sigma^2 * rho(h).? 
> 
> I am googling it and there are many packages available but unfortunately they do not look available for my 3.2.4 latex version
> 
> install.packages("latex2expr")

My efforts found a 'latex2exp' but no 'latex2expr'. Are you sure you are not missplelling the package name?


> Installiere Paket nach ?/home/apa/R/x86_64-pc-linux-gnu-library/3.2?(da ?lib? nicht spezifiziert)Warnung: kann nicht auf den Index f?r das Repository https://cran.cnr.Berkeley.edu/src/contrib zugreifen:? nicht unterst?tztes URL SchemaWarnmeldung:Paket ?latex2expr? ist nicht verf?gbar (for R version 3.2.4 Revised) 
> 
> Any ideas what else I can try?I would like to thank you in advance for your replyRegardsAlex
> ??? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


  
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed May  4 21:35:14 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 4 May 2016 12:35:14 -0700
Subject: [R] greek characters in Figures
In-Reply-To: <1816955105.6118956.1462384384750.JavaMail.yahoo@mail.yahoo.com>
References: <F132CF86-8EDD-4E21-85B0-E429E86586FA@comcast.net>
	<1816955105.6118956.1462384384750.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <8405B3ED-0DEC-4779-A9C0-DC276B5B029E@comcast.net>


> On May 4, 2016, at 10:53 AM, Alaios <alaios at yahoo.com> wrote:
> 
> > install.packages("latex2exp")
> Installiere Paket nach ?/home/apa/R/x86_64-pc-linux-gnu-library/3.2?
> (da ?lib? nicht spezifiziert)
> Warnung: kann nicht auf den Index f?r das Repository https://cran.cnr.Berkeley.edu/src/contrib zugreifen:
>   nicht unterst?tztes URL Schema

You seem to have difficulties with your Internet connection/setup:

> Warnmeldung:
> Paket ?latex2exp? ist nicht verf?gbar (for R version 3.2.4 Revised) 
> > install.packages("latex2expr")
> Installiere Paket nach ?/home/apa/R/x86_64-pc-linux-gnu-library/3.2?
> (da ?lib? nicht spezifiziert)
> Warnung: kann nicht auf den Index f?r das Repository https://cran.cnr.Berkeley.edu/src/contrib zugreifen:
>   nicht unterst?tztes URL Schema
> Warnmeldung:
> Paket ?latex2expr? ist nicht verf?gbar (for R version 3.2.4 Revised) 

I just installed from source from that repository into an R 3.2.5 library. (I first needed to reinstall that version since I had moved to 3.3.0. Admittedly I was doing this on a Mac but since the package does not require any C/Fortran level compiling, my experience should mimic that of a Linux user using a source package.


-- 
David


> 
> 
> 
> On Monday, May 2, 2016 9:39 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
> 
> > On May 2, 2016, at 10:32 AM, Alaios via R-help <r-help at r-project.org> wrote:
> > 
> > Dear all,I am trying to write in my Figure labels short equations that contain greek characters
> > 
> > For example:  C(h) = sigma^2 * rho(h).  
> > 
> > I am googling it and there are many packages available but unfortunately they do not look available for my 3.2.4 latex version
> > 
> > install.packages("latex2expr")
> 
> My efforts found a 'latex2exp' but no 'latex2expr'. Are you sure you are not missplelling the package name?
> 
> 
> 
> > Installiere Paket nach ?/home/apa/R/x86_64-pc-linux-gnu-library/3.2?(da ?lib? nicht spezifiziert)Warnung: kann nicht auf den Index f?r das Repository https://cran.cnr.Berkeley.edu/src/contrib zugreifen:  nicht unterst?tztes URL SchemaWarnmeldung:Paket ?latex2expr? ist nicht verf?gbar (for R version 3.2.4 Revised) 
> > 
> > Any ideas what else I can try?I would like to thank you in advance for your replyRegardsAlex
> >     [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 
> David Winsemius
> Alameda, CA, USA
> 
> 
> 

David Winsemius
Alameda, CA, USA


From jeremiejuste at gmail.com  Wed May  4 17:59:57 2016
From: jeremiejuste at gmail.com (Jeremie Juste)
Date: Wed, 4 May 2016 17:59:57 +0200 (CEST)
Subject: [R] copula package error when gumbel parameter is close to
	bound.
In-Reply-To: <20160504233611.114a8f2a@bossiaea> (Berwin A. Turlach's message
	of "Wed, 4 May 2016 23:36:11 +0800")
References: <CAPHJcdBagMQFn_ieZs4n9DhmF2LXVgQqVQnpszNLptPEM6XbxA@mail.gmail.com>
	<20160504233611.114a8f2a@bossiaea>
Message-ID: <87eg9holtw.fsf@oldgnu.org>

Hello 

> Berwin A Turlach <Berwin.Turlach at gmail.com> writes:

> That you don't have the package Rmpfr installed?  And it seems to be
> needed for the higher dimension.  On my machine it works:
>


Thanks for the lead,

Best regards,
Jeremie


From saegerei at t-online.de  Wed May  4 20:51:27 2016
From: saegerei at t-online.de (=?UTF-8?Q?C&A_S=c3=a4ger?=)
Date: Wed, 4 May 2016 20:51:27 +0200
Subject: [R] Can't resolve dependency problems with package "sem"
Message-ID: <572A44AF.8060008@t-online.de>

Hello,

First time user on Ubuntu 14.4 with Ubuntus R Commander and

> $ R --version
> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
> Copyright (C) 2013 The R Foundation for Statistical Computing
> Platform: x86_64-pc-linux-gnu (64-bit)

The program icon of the commander executes

> sh -c 'R_DEFAULT_PACKAGES="$R_DEFAULT_PACKAGES Rcmdr" R "$@"'

On first run it started downloading, compiling and installing various
packages. One of them fails:

> 
>> install.packages("sem",dependencies=TRUE)
> Installing package into ?/home/andreas/R/x86_64-pc-linux-gnu-library/3.0?
> (as ?lib? is unspecified)
> Warnung: dependencies ?MBESS?, ?arm?, ?plyr? are not available
> also installing the dependencies ?scales?, ?mi?, ?DiagrammeR?
> 
> versuche URL 'http://ftp5.gwdg.de/pub/misc/cran/src/contrib/scales_0.4.0.tar.gz'
> Content type 'application/x-gzip' length 57358 bytes (56 Kb)
> URL ge?ffnet
> ==================================================
> downloaded 56 Kb
> 
> versuche URL 'http://ftp5.gwdg.de/pub/misc/cran/src/contrib/mi_1.0.tar.gz'
> Content type 'application/x-gzip' length 793313 bytes (774 Kb)
> URL ge?ffnet
> ==================================================
> downloaded 774 Kb
> 
> versuche URL 'http://ftp5.gwdg.de/pub/misc/cran/src/contrib/DiagrammeR_0.8.2.tar.gz'
> Content type 'application/x-gzip' length 3532835 bytes (3.4 Mb)
> URL ge?ffnet
> ==================================================
> downloaded 3.4 Mb
> 
> versuche URL 'http://ftp5.gwdg.de/pub/misc/cran/src/contrib/sem_3.1-7.tar.gz'
> Content type 'application/x-gzip' length 154654 bytes (151 Kb)
> URL ge?ffnet
> ==================================================
> downloaded 151 Kb
> 
> ERROR: dependency ?plyr? is not available for package ?scales?
> * removing ?/home/andreas/R/x86_64-pc-linux-gnu-library/3.0/scales?
> ERROR: dependency ?arm? is not available for package ?mi?
> * removing ?/home/andreas/R/x86_64-pc-linux-gnu-library/3.0/mi?
> ERROR: dependency ?scales? is not available for package ?DiagrammeR?
> * removing ?/home/andreas/R/x86_64-pc-linux-gnu-library/3.0/DiagrammeR?
> ERROR: dependency ?mi? is not available for package ?sem?
> * removing ?/home/andreas/R/x86_64-pc-linux-gnu-library/3.0/sem?
> 
> Die heruntergeladenen Quellpakete sind in
> ?/tmp/RtmplEqHDo/downloaded_packages?
> Warnmeldungen:
> 1: In install.packages("sem", dependencies = TRUE) :
> Installation des Pakets ?scales? hatte Exit-Status ungleich 0
> 2: In install.packages("sem", dependencies = TRUE) :
> Installation des Pakets ?mi? hatte Exit-Status ungleich 0
> 3: In install.packages("sem", dependencies = TRUE) :
> Installation des Pakets ?DiagrammeR? hatte Exit-Status ungleich 0
> 4: In install.packages("sem", dependencies = TRUE) :
> Installation des Pakets ?sem? hatte Exit-Status ungleich 0

How can I resolve the dependencies?
Should I replace the Ubuntu version with something fresh?

Thanks in advance,
Andreas

From swagatam1987 at gmail.com  Wed May  4 21:01:39 2016
From: swagatam1987 at gmail.com (Swagatam Basu)
Date: Thu, 5 May 2016 00:31:39 +0530
Subject: [R] Help regarding Community Detection Algorithm in R (like
 Propagation, Walktrap)
In-Reply-To: <CALk0NBuADj9Jc44tPNBS3WKyHxmG4pqF5WajDNpQ0F1rfU6gdQ@mail.gmail.com>
References: <CALk0NBuADj9Jc44tPNBS3WKyHxmG4pqF5WajDNpQ0F1rfU6gdQ@mail.gmail.com>
Message-ID: <CALk0NBuuTuV_mQ08H3axAqesXov1Wg7K=pTktjk5Vj_+dTb3pw@mail.gmail.com>

kindly help me ..from where do i get sample code and details about
community detection...

Thanks
Swagatam Basu


On Mon, May 2, 2016 at 2:25 PM, Swagatam Basu <swagatam1987 at gmail.com>
wrote:

> Hi
>
> I am very new to R studio and R language. I have installed the R studio in
> my machine.
>
> I need to do a community detection of a set of message. I have a Matrix
> for that.
>
> Is there any sample code /Package/ website is present which will help me
> to understand/do this community Detection (like Propagation, Walk trap
> Algorithm) in R-language by using R-studio.
>
> Please help.
>
> Please revert back in case of any discrepencies.
>
> Thanks
> S Basu
>
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed May  4 21:49:10 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 4 May 2016 12:49:10 -0700
Subject: [R] Help regarding Community Detection Algorithm in R (like
 Propagation, Walktrap)
In-Reply-To: <CALk0NBuuTuV_mQ08H3axAqesXov1Wg7K=pTktjk5Vj_+dTb3pw@mail.gmail.com>
References: <CALk0NBuADj9Jc44tPNBS3WKyHxmG4pqF5WajDNpQ0F1rfU6gdQ@mail.gmail.com>
	<CALk0NBuuTuV_mQ08H3axAqesXov1Wg7K=pTktjk5Vj_+dTb3pw@mail.gmail.com>
Message-ID: <CAGxFJbRES=TOnepF9chRyYMFYdRPrQHkb6==KBwszjr6u3Ey+w@mail.gmail.com>

Please do not re-post. Search on your own. Entering "community
detection" at the rseek.org R search site brought up many hits,
especially from the igraph package.

Cheers,

Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, May 4, 2016 at 12:01 PM, Swagatam Basu <swagatam1987 at gmail.com> wrote:
> kindly help me ..from where do i get sample code and details about
> community detection...
>
> Thanks
> Swagatam Basu
>
>
> On Mon, May 2, 2016 at 2:25 PM, Swagatam Basu <swagatam1987 at gmail.com>
> wrote:
>
>> Hi
>>
>> I am very new to R studio and R language. I have installed the R studio in
>> my machine.
>>
>> I need to do a community detection of a set of message. I have a Matrix
>> for that.
>>
>> Is there any sample code /Package/ website is present which will help me
>> to understand/do this community Detection (like Propagation, Walk trap
>> Algorithm) in R-language by using R-studio.
>>
>> Please help.
>>
>> Please revert back in case of any discrepencies.
>>
>> Thanks
>> S Basu
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed May  4 21:55:45 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 4 May 2016 12:55:45 -0700
Subject: [R] how to compute Bonferroni, Tukey's,
	Sheffe 95%-condence intervals for coefficients B1, B2,
	B3 in linear regression?
In-Reply-To: <3b331b67.8b6b.1547c3b1432.Coremail.desolator88@163.com>
References: <3b331b67.8b6b.1547c3b1432.Coremail.desolator88@163.com>
Message-ID: <81BC802D-481C-4D71-8947-4EB5C9C79C4D@comcast.net>


> On May 4, 2016, at 7:45 AM, super <desolator88 at 163.com> wrote:
> 
> 
> Dear experts, 
>    I have a problem in compute Bonferroni,Tukey's,Sheffe 95%-condence intervals for coefficients B1,B2,B3 in linear regression using R? how can i do it? I only know how to compute these three cofindence intervals in multicomparsion by using multcomp package, and i am search a lot for how to comupte the three CIs for linear regression coefficients but without any useful information, so, plz help me ~

Your question does not detail where the 'confint' function in pkg:multcop is letting you down. After the first few lines of the first example I type:

confint(wht)

#---------------
And get:

	 Simultaneous Confidence Intervals

Multiple Comparisons of Means: Tukey Contrasts


Fit: aov(formula = breaks ~ wool + tension, data = warpbreaks)

Quantile = 2.4155
95% family-wise confidence level
 

Linear Hypotheses:
           Estimate lwr      upr     
M - L == 0 -10.0000 -19.3536  -0.6464
H - L == 0 -14.7222 -24.0758  -5.3687
H - M == 0  -4.7222 -14.0758   4.6313


Subsequent examples on that page use linear regression models as there starting point.

-- 

David Winsemius
Alameda, CA, USA


From dcarlson at tamu.edu  Wed May  4 23:23:35 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 4 May 2016 21:23:35 +0000
Subject: [R] Changing transformations in mi package
In-Reply-To: <VI1PR03MB145502589EEB2F0193B83472D77B0@VI1PR03MB1455.eurprd03.prod.outlook.com>
References: <VI1PR03MB145502589EEB2F0193B83472D77B0@VI1PR03MB1455.eurprd03.prod.outlook.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D730B06@mb02.ads.tamu.edu>

Thank you for providing a working example. I think you need to contact the package maintainer:

> maintainer("mi")
[1] "Ben Goodrich <benjamin.goodrich at columbia.edu>"

When I run your code it appears that the c column is correctly transformed to square roots, but the show() function is incorrectly indicating a log transform:

> data.missingdf at variables$c at raw_data # The raw data
[1]  4.2  7.9   NA 16.1 19.9 23.0
> sqrt(data.missingdf at variables$c at raw_data) # The square root of the raw data
[1] 2.049390 2.810694       NA 4.012481 4.460942 4.795832
> data.missingdf at variables$c at data # The transformed data - square roots, not logs
[1] 2.049390 2.810694       NA 4.012481 4.460942 4.795832

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Elizabeth Hensor
Sent: Wednesday, May 4, 2016 5:44 AM
To: 'r-help at r-project.org'
Subject: [R] Changing transformations in mi package

Dear all,
I am an R beginner and new to the list. In preparation for using mi to impute missing values I am setting up the missing data frame and would like to specify the transformation types for some of my variables, as I will be using these transformations in my analysis models. According to the documentation the available options are "standardize" (the default), "identity", "log", "logshift" and "sqrt". I can successfully change the transformation types to "log" and "logshift", but when I attempt to change to "sqrt", this changes the type to "log" instead. I'd appreciate your help, please.
Below are details of my system and some code which replicates the issue.

> sessionInfo()
R version 3.2.5 (2016-04-14)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United Kingdom.1252   
[3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C                           
[5] LC_TIME=English_United Kingdom.1252    

attached base packages:
[1] stats4    stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] lmerTest_2.0-30 truncnorm_1.0-7 mi_1.0          lme4_1.1-12     Matrix_1.2-4   
[6] pls_2.5-0      

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.4         Formula_1.2-1       cluster_2.0.3       splines_3.2.5      
 [5] MASS_7.3-45         munsell_0.4.3       colorspace_1.2-6    arm_1.8-6          
 [9] lattice_0.20-33     minqa_1.2.4         plyr_1.8.3          nnet_7.3-12        
[13] grid_3.2.5          nlme_3.1-126        gtable_0.2.0        latticeExtra_0.6-28
[17] coda_0.18-1         abind_1.4-3         survival_2.38-3     gridExtra_2.2.1    
[21] RColorBrewer_1.1-2  nloptr_1.0.4        ggplot2_2.1.0       acepack_1.3-3.3    
[25] rpart_4.1-10        scales_0.4.0        Hmisc_3.17-3        foreign_0.8-66

data <- data.frame(a=c(NA,2.1,3.3,4.5,5.9,6.2),b=c(2.2,NA,6.1,8.3,10.2,12.13),c=c(4.2,7.9,NA,16.1,19.9,23))
data

    a     b    c
1  NA  2.20  4.2
2 2.1    NA  7.9
3 3.3  6.10   NA
4 4.5  8.30 16.1
5 5.9 10.20 19.9
6 6.2 12.13 23.0

data.missingdf <- missing_data.frame(data)
show(data.missingdf)

Object of class missing_data.frame with 6 observations on 3 variables

There are 4 missing data patterns

Append '@patterns' to this missing_data.frame to access the corresponding pattern for every observation or perhaps use table()

        type missing method  model
a continuous       1    ppd linear
b continuous       1    ppd linear
c continuous       1    ppd linear

    family     link transformation
a gaussian identity    standardize
b gaussian identity    standardize
c gaussian identity    standardize

#Let's say I'd like to change transformation for a, b and c to "log", "logshift" and "sqrt" respectively

data.missingdf <- change(data.missingdf, y="a", what="transformation", to="logshift")
data.missingdf <- change(data.missingdf, y="b", what="transformation", to="log")
data.missingdf <- change(data.missingdf, y="c", what="transformation", to="sqrt")
show(data.missingdf)

Object of class missing_data.frame with 6 observations on 3 variables

There are 4 missing data patterns

Append '@patterns' to this missing_data.frame to access the corresponding pattern for every observation or perhaps use table()

        type missing method  model
a continuous       1    ppd linear
b continuous       1    ppd linear
c continuous       1    ppd linear

    family     link transformation
a gaussian identity       logshift
b gaussian identity            log
c gaussian identity            log

#Transformation has been successfully changed for a and b, but for c has been changed to "log" instead of "sqrt"

Thanks in advance for your assistance,
Liz Hensor

Biostatistician
Leeds Institute of Rheumatic and Musculoskeletal Medicine &
NIHR Leeds Musculoskeletal Biomedical Research Unit

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Thu May  5 00:17:47 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 5 May 2016 08:17:47 +1000
Subject: [R] Can't resolve dependency problems with package "sem"
In-Reply-To: <572A44AF.8060008@t-online.de>
References: <572A44AF.8060008@t-online.de>
Message-ID: <CA+8X3fU5rkkJAPq_0BV4zh4EX6Z80n0bFD4_s8260cg3xvg2Fw@mail.gmail.com>

Hi Andreas,
Try installing plyr, arm, scales and mi separately. If you get an
error message about a version mismatch, that's where your problem is.
_Sometimes_ upgrading R will fix it, if the problem is that the
version you are downloading is too new for your R version.

Jim

On Thu, May 5, 2016 at 4:51 AM, C&A S?ger <saegerei at t-online.de> wrote:
> Hello,
>
> First time user on Ubuntu 14.4 with Ubuntus R Commander and
>
>> $ R --version
>> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
>> Copyright (C) 2013 The R Foundation for Statistical Computing
>> Platform: x86_64-pc-linux-gnu (64-bit)
>
> The program icon of the commander executes
>
>> sh -c 'R_DEFAULT_PACKAGES="$R_DEFAULT_PACKAGES Rcmdr" R "$@"'
>
> On first run it started downloading, compiling and installing various
> packages. One of them fails:
>
>>
>>> install.packages("sem",dependencies=TRUE)
>> Installing package into ?/home/andreas/R/x86_64-pc-linux-gnu-library/3.0?
>> (as ?lib? is unspecified)
>> Warnung: dependencies ?MBESS?, ?arm?, ?plyr? are not available
>> also installing the dependencies ?scales?, ?mi?, ?DiagrammeR?
>>
>> versuche URL 'http://ftp5.gwdg.de/pub/misc/cran/src/contrib/scales_0.4.0.tar.gz'
>> Content type 'application/x-gzip' length 57358 bytes (56 Kb)
>> URL ge?ffnet
>> ==================================================
>> downloaded 56 Kb
>>
>> versuche URL 'http://ftp5.gwdg.de/pub/misc/cran/src/contrib/mi_1.0.tar.gz'
>> Content type 'application/x-gzip' length 793313 bytes (774 Kb)
>> URL ge?ffnet
>> ==================================================
>> downloaded 774 Kb
>>
>> versuche URL 'http://ftp5.gwdg.de/pub/misc/cran/src/contrib/DiagrammeR_0.8.2.tar.gz'
>> Content type 'application/x-gzip' length 3532835 bytes (3.4 Mb)
>> URL ge?ffnet
>> ==================================================
>> downloaded 3.4 Mb
>>
>> versuche URL 'http://ftp5.gwdg.de/pub/misc/cran/src/contrib/sem_3.1-7.tar.gz'
>> Content type 'application/x-gzip' length 154654 bytes (151 Kb)
>> URL ge?ffnet
>> ==================================================
>> downloaded 151 Kb
>>
>> ERROR: dependency ?plyr? is not available for package ?scales?
>> * removing ?/home/andreas/R/x86_64-pc-linux-gnu-library/3.0/scales?
>> ERROR: dependency ?arm? is not available for package ?mi?
>> * removing ?/home/andreas/R/x86_64-pc-linux-gnu-library/3.0/mi?
>> ERROR: dependency ?scales? is not available for package ?DiagrammeR?
>> * removing ?/home/andreas/R/x86_64-pc-linux-gnu-library/3.0/DiagrammeR?
>> ERROR: dependency ?mi? is not available for package ?sem?
>> * removing ?/home/andreas/R/x86_64-pc-linux-gnu-library/3.0/sem?
>>
>> Die heruntergeladenen Quellpakete sind in
>> ?/tmp/RtmplEqHDo/downloaded_packages?
>> Warnmeldungen:
>> 1: In install.packages("sem", dependencies = TRUE) :
>> Installation des Pakets ?scales? hatte Exit-Status ungleich 0
>> 2: In install.packages("sem", dependencies = TRUE) :
>> Installation des Pakets ?mi? hatte Exit-Status ungleich 0
>> 3: In install.packages("sem", dependencies = TRUE) :
>> Installation des Pakets ?DiagrammeR? hatte Exit-Status ungleich 0
>> 4: In install.packages("sem", dependencies = TRUE) :
>> Installation des Pakets ?sem? hatte Exit-Status ungleich 0
>
> How can I resolve the dependencies?
> Should I replace the Ubuntu version with something fresh?
>
> Thanks in advance,
> Andreas
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Thu May  5 01:41:43 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 04 May 2016 16:41:43 -0700
Subject: [R] Can't resolve dependency problems with package "sem"
In-Reply-To: <572A44AF.8060008@t-online.de>
References: <572A44AF.8060008@t-online.de>
Message-ID: <2B75862B-6BAC-444E-9D7D-60B8A538D6B6@dcn.davis.ca.us>

Did you follow the instructions for setting up apt to pull recent versions of R, as described in CRAN? I suspect not, since your version is old. 
-- 
Sent from my phone. Please excuse my brevity.

On May 4, 2016 11:51:27 AM PDT, "C&A S?ger" <saegerei at t-online.de> wrote:
>Hello,
>
>First time user on Ubuntu 14.4 with Ubuntus R Commander and
>
>> $ R --version
>> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
>> Copyright (C) 2013 The R Foundation for Statistical Computing
>> Platform: x86_64-pc-linux-gnu (64-bit)
>
>The program icon of the commander executes
>
>> sh -c 'R_DEFAULT_PACKAGES="$R_DEFAULT_PACKAGES Rcmdr" R "$@"'
>
>On first run it started downloading, compiling and installing various
>packages. One of them fails:
>
>> 
>>> install.packages("sem",dependencies=TRUE)
>> Installing package into
>?/home/andreas/R/x86_64-pc-linux-gnu-library/3.0?
>> (as ?lib? is unspecified)
>> Warnung: dependencies ?MBESS?, ?arm?, ?plyr? are not available
>> also installing the dependencies ?scales?, ?mi?, ?DiagrammeR?
>> 
>> versuche URL
>'http://ftp5.gwdg.de/pub/misc/cran/src/contrib/scales_0.4.0.tar.gz'
>> Content type 'application/x-gzip' length 57358 bytes (56 Kb)
>> URL ge?ffnet
>> ==================================================
>> downloaded 56 Kb
>> 
>> versuche URL
>'http://ftp5.gwdg.de/pub/misc/cran/src/contrib/mi_1.0.tar.gz'
>> Content type 'application/x-gzip' length 793313 bytes (774 Kb)
>> URL ge?ffnet
>> ==================================================
>> downloaded 774 Kb
>> 
>> versuche URL
>'http://ftp5.gwdg.de/pub/misc/cran/src/contrib/DiagrammeR_0.8.2.tar.gz'
>> Content type 'application/x-gzip' length 3532835 bytes (3.4 Mb)
>> URL ge?ffnet
>> ==================================================
>> downloaded 3.4 Mb
>> 
>> versuche URL
>'http://ftp5.gwdg.de/pub/misc/cran/src/contrib/sem_3.1-7.tar.gz'
>> Content type 'application/x-gzip' length 154654 bytes (151 Kb)
>> URL ge?ffnet
>> ==================================================
>> downloaded 151 Kb
>> 
>> ERROR: dependency ?plyr? is not available for package ?scales?
>> * removing ?/home/andreas/R/x86_64-pc-linux-gnu-library/3.0/scales?
>> ERROR: dependency ?arm? is not available for package ?mi?
>> * removing ?/home/andreas/R/x86_64-pc-linux-gnu-library/3.0/mi?
>> ERROR: dependency ?scales? is not available for package ?DiagrammeR?
>> * removing
>?/home/andreas/R/x86_64-pc-linux-gnu-library/3.0/DiagrammeR?
>> ERROR: dependency ?mi? is not available for package ?sem?
>> * removing ?/home/andreas/R/x86_64-pc-linux-gnu-library/3.0/sem?
>> 
>> Die heruntergeladenen Quellpakete sind in
>> ?/tmp/RtmplEqHDo/downloaded_packages?
>> Warnmeldungen:
>> 1: In install.packages("sem", dependencies = TRUE) :
>> Installation des Pakets ?scales? hatte Exit-Status ungleich 0
>> 2: In install.packages("sem", dependencies = TRUE) :
>> Installation des Pakets ?mi? hatte Exit-Status ungleich 0
>> 3: In install.packages("sem", dependencies = TRUE) :
>> Installation des Pakets ?DiagrammeR? hatte Exit-Status ungleich 0
>> 4: In install.packages("sem", dependencies = TRUE) :
>> Installation des Pakets ?sem? hatte Exit-Status ungleich 0
>
>How can I resolve the dependencies?
>Should I replace the Ubuntu version with something fresh?
>
>Thanks in advance,
>Andreas
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From saegerei at t-online.de  Thu May  5 02:27:56 2016
From: saegerei at t-online.de (=?UTF-8?Q?C&A_S=c3=a4ger?=)
Date: Thu, 5 May 2016 02:27:56 +0200
Subject: [R] Can't resolve dependency problems with package "sem"
In-Reply-To: <CA+8X3fU5rkkJAPq_0BV4zh4EX6Z80n0bFD4_s8260cg3xvg2Fw@mail.gmail.com>
References: <572A44AF.8060008@t-online.de>
	<CA+8X3fU5rkkJAPq_0BV4zh4EX6Z80n0bFD4_s8260cg3xvg2Fw@mail.gmail.com>
Message-ID: <572A938C.80302@t-online.de>

Am 05.05.2016 um 00:17 schrieb Jim Lemon:
> Hi Andreas,
> Try installing plyr, arm, scales and mi separately. If you get an
> error message about a version mismatch, that's where your problem is.
> _Sometimes_ upgrading R will fix it, if the problem is that the
> version you are downloading is too new for your R version.
> 
> Jim
> 

Hello Jim,

Indeed, this might be the problem. When I try to install plyr, I get
something like this:
"Package xxx is not availlable (not for this version 3.0.x)"

I was hoping that any old version from the Ubuntu repositories would be
good enough for an absolute beginner.

Thank you very much,
Andreas

From jfox at mcmaster.ca  Thu May  5 02:35:20 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Thu, 5 May 2016 00:35:20 +0000
Subject: [R] Can't resolve dependency problems with package "sem"
In-Reply-To: <572A938C.80302@t-online.de>
References: <572A44AF.8060008@t-online.de>
	<CA+8X3fU5rkkJAPq_0BV4zh4EX6Z80n0bFD4_s8260cg3xvg2Fw@mail.gmail.com>
	<572A938C.80302@t-online.de>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F8CF00@FHSDB2D11-2.csu.mcmaster.ca>

Dear Andreas,

As has been suggested, you're probably better off using an up-to-date version of R and corresponding up-to-date packages, but if the only issue is that sem can't be installed, the Rcmdr package should still work. The menu item for confirmatory factor analysis will be missing, and unless you tell it to suppress checking for missing packages on start-up, the Rcmdr will continue to ask you whether you want to install the sem package, but everything else should work.

To suppress the start-up package check, issue the R command options(Rcmdr=list(check.packages=FALSE)) before library(Rcmdr).

I hope this helps,
 John

-----------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.socsci.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of C&A
> S?ger
> Sent: Wednesday, May 4, 2016 8:28 PM
> To: Jim Lemon; r-help at r-project.org
> Subject: Re: [R] Can't resolve dependency problems with package "sem"
> 
> Am 05.05.2016 um 00:17 schrieb Jim Lemon:
> > Hi Andreas,
> > Try installing plyr, arm, scales and mi separately. If you get an
> > error message about a version mismatch, that's where your problem is.
> > _Sometimes_ upgrading R will fix it, if the problem is that the
> > version you are downloading is too new for your R version.
> >
> > Jim
> >
> 
> Hello Jim,
> 
> Indeed, this might be the problem. When I try to install plyr, I get
> something like this:
> "Package xxx is not availlable (not for this version 3.0.x)"
> 
> I was hoping that any old version from the Ubuntu repositories would be
> good enough for an absolute beginner.
> 
> Thank you very much,
> Andreas
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From saegerei at t-online.de  Thu May  5 04:06:24 2016
From: saegerei at t-online.de (=?UTF-8?Q?C&A_S=c3=a4ger?=)
Date: Thu, 5 May 2016 04:06:24 +0200
Subject: [R] Can't resolve dependency problems with package "sem"
In-Reply-To: <2B75862B-6BAC-444E-9D7D-60B8A538D6B6@dcn.davis.ca.us>
References: <572A44AF.8060008@t-online.de>
	<2B75862B-6BAC-444E-9D7D-60B8A538D6B6@dcn.davis.ca.us>
Message-ID: <572AAAA0.5040001@t-online.de>

Am 05.05.2016 um 01:41 schrieb Jeff Newmiller:
> Did you follow the instructions for setting up apt to pull recent
> versions of R, as described in CRAN? I suspect not, since your version
> is old.
> -- 

Hello Jeff,

Thank you very much for taking notice.

I was hoping that any old version which used to be the best of breed 3
years ago would be just fine for absolute beginners.
I did not even know that CRAN exists until I actually installed the
software. I use Ubuntu because compiling software is a major annoyance
to me. Since 2002 I use to compile something every now and then when it
is the only way to get something installed.

Right now I try to follow the R installation guide carefully but dumb
because I don't really understand what I'm doing. configure, make, make
check, everything runs OK so far but sudo make install fails anyway.
What a horrible waste of time and electricity!

Actually, I'm trying to help my daughter who needs to learn some R
basics. The installation on a Windows PC is a matter of minutes by
following a tiny instructional PDF from her tutor. But she does not have
the time nor knowledge to install R successfully on her Ubuntu PC which
is the same as mine. While she has some real work to do, I'm trying to
get this darn thing onto our computers. Even if I manage to compile a
working R program on my computer, this will not be of any help for my
daughter who does not have the compilers installed and I don't know
which packages make it happen on my PC. I'd have to build my first
Debian package which might take another day of reading and testing.

[...]

Meanwhile the installation of R out of debian packages from a CRAN
server did the job and I managed to ...

>  install.packages("Rcmdr",dependencies=TRUE)

... which finished with ...

> ** testing if installed package can be loaded
> * DONE (Rcmdr)

... but also with warnings ...

> 1: In install.packages("Rcmdr", dependencies = TRUE) :
>   Installation des Pakets ?rgl? hatte Exit-Status ungleich 0
> 2: In install.packages("Rcmdr", dependencies = TRUE) :
>   Installation des Pakets ?rglwidget? hatte Exit-Status ungleich 0

.. due to these errors:

> configure: error: missing required header GL/gl.h
> ERROR: configuration failed for package ?rgl?

> ERROR: dependency ?rgl? is not available for package ?rglwidget?


Thank you very much for the pointer to this instructive page:

> http://ftp5.gwdg.de/pub/misc/cran/

May be we can live without GL support for now.

Greetings,
Andreas


From jdnewmil at dcn.davis.ca.us  Thu May  5 05:36:00 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 04 May 2016 20:36:00 -0700
Subject: [R] Can't resolve dependency problems with package "sem"
In-Reply-To: <572AAAA0.5040001@t-online.de>
References: <572A44AF.8060008@t-online.de>
	<2B75862B-6BAC-444E-9D7D-60B8A538D6B6@dcn.davis.ca.us>
	<572AAAA0.5040001@t-online.de>
Message-ID: <2DB0C0E8-4A46-418B-B04B-63B5FAEBCDD6@dcn.davis.ca.us>

An old version of R would be fine if that was all you wanted, but no, you want all the latest contributed packages as well. I can't blame you for that, but don't blame R for difficulties with contributed packages that have external dependencies and depend on recent versions of R.

You might find

http://trestletech.com/2012/10/install-rgl-in-ubuntu/

helpful with your RGL package issue. 

I very rarely configure/compile since apt is so powerful. IMHO you should always start with apt on Debian derivatives before falling back to compiling. 
-- 
Sent from my phone. Please excuse my brevity.

On May 4, 2016 7:06:24 PM PDT, "C&A S?ger" <saegerei at t-online.de> wrote:
>Am 05.05.2016 um 01:41 schrieb Jeff Newmiller:
>> Did you follow the instructions for setting up apt to pull recent
>> versions of R, as described in CRAN? I suspect not, since your
>version
>> is old.
>> -- 
>
>Hello Jeff,
>
>Thank you very much for taking notice.
>
>I was hoping that any old version which used to be the best of breed 3
>years ago would be just fine for absolute beginners.
>I did not even know that CRAN exists until I actually installed the
>software. I use Ubuntu because compiling software is a major annoyance
>to me. Since 2002 I use to compile something every now and then when it
>is the only way to get something installed.
>
>Right now I try to follow the R installation guide carefully but dumb
>because I don't really understand what I'm doing. configure, make, make
>check, everything runs OK so far but sudo make install fails anyway.
>What a horrible waste of time and electricity!
>
>Actually, I'm trying to help my daughter who needs to learn some R
>basics. The installation on a Windows PC is a matter of minutes by
>following a tiny instructional PDF from her tutor. But she does not
>have
>the time nor knowledge to install R successfully on her Ubuntu PC which
>is the same as mine. While she has some real work to do, I'm trying to
>get this darn thing onto our computers. Even if I manage to compile a
>working R program on my computer, this will not be of any help for my
>daughter who does not have the compilers installed and I don't know
>which packages make it happen on my PC. I'd have to build my first
>Debian package which might take another day of reading and testing.
>
>[...]
>
>Meanwhile the installation of R out of debian packages from a CRAN
>server did the job and I managed to ...
>
>>  install.packages("Rcmdr",dependencies=TRUE)
>
>... which finished with ...
>
>> ** testing if installed package can be loaded
>> * DONE (Rcmdr)
>
>... but also with warnings ...
>
>> 1: In install.packages("Rcmdr", dependencies = TRUE) :
>>   Installation des Pakets ?rgl? hatte Exit-Status ungleich 0
>> 2: In install.packages("Rcmdr", dependencies = TRUE) :
>>   Installation des Pakets ?rglwidget? hatte Exit-Status ungleich 0
>
>.. due to these errors:
>
>> configure: error: missing required header GL/gl.h
>> ERROR: configuration failed for package ?rgl?
>
>> ERROR: dependency ?rgl? is not available for package ?rglwidget?
>
>
>Thank you very much for the pointer to this instructive page:
>
>> http://ftp5.gwdg.de/pub/misc/cran/
>
>May be we can live without GL support for now.
>
>Greetings,
>Andreas

	[[alternative HTML version deleted]]


From profjcnash at gmail.com  Thu May  5 15:59:21 2016
From: profjcnash at gmail.com (ProfJCNash)
Date: Thu, 5 May 2016 09:59:21 -0400
Subject: [R] request for collaborator for animation of optimization
	computations
Message-ID: <572B51B9.3000206@gmail.com>

In an email exchange with Hans Werner Borchers, two optimization
problems were mentioned where the optimization parameters define
positions that can be graphed. One is a chain hanging problem (catenary)
and the other the largest area polygon where the vertices cannot be more
than one unit apart. Three decades ago I used the latter with very
positive reactions to demonstrate optimization to semi-technical
audiences, and I have found that the program will still run. However, it
would be very useful to have a modern R implementation, possibly as a
Web app, that can be used to illustrate optimization problems in a way
that is accessible to non-technical audiences, as well as demonstrating
R capabilities. If possible, I'd like to find a collaborator with skills
in coding the graphics, which "update" steadily as the area in the
polygon increases, as my expertise is weak in graphics. Please contact
me off-list if interested.

For those who are not familiar with the polygon problem, the best known
case is that the largest constrained (or small) hexagon is NOT a regular
hexagon, but almost a pentagon with one edge slightly dented.

For those wanting to see the idea, the MSDOS executable, which still
runs (clunkily) in my Windows XP virtual machine or under DOSBOX for
Linux is at

https://www.dropbox.com/s/8l8dalpp9v03qf8/VMPOLY2A.EXE?dl=0

There is also an approximation to the BASIC source code (I seem to have
lost the exact version) at

https://www.dropbox.com/s/n0zldgufkn2jie4/VMPOLY2Y.BAS?dl=0

This can be run under GWBASIC in DOSBOX or under the PC-BASIC emulator from

https://sourceforge.net/projects/pcbasic/

Cheers, John Nash


From rosita21 at gmail.com  Wed May  4 21:47:34 2016
From: rosita21 at gmail.com (Rosa Oliveira)
Date: Wed, 4 May 2016 20:47:34 +0100
Subject: [R] boostrap - not converging cycles
Message-ID: <EB6D324B-F529-4148-811C-FDEC7407BFC4@gmail.com>

Dear all, 

I have a problem, rather serious and I am not being able to resolve it.

I started working with R a few time ago :( 

I?m running a bootstrap analyses for 2 different methods and It was expected that I get the same coefficients and standard errors for both, consequently the same coverage - but I?m not getting the same values.

With the estimates obtained in bootstrap we don?t get that, which means that there are resampling cycles that are different, even more, as the coverage is different, it leads me to think that there are bootstrap cycles that do not converge and therefore left out of coverage.

A. Is there a way of knowing which were the cycles that did not converge and correct the estimates?
B. For this I have the "results? saved - 

save.image("~/Documents/phd_april_v16.RData?) will this be useful for something?

Best,
RO



Atenciosamente,
Rosa Oliveira

-- 
____________________________________________________________________________



Rosa Celeste dos Santos Oliveira, 

E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
Tlm: +351 939355143 
Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
____________________________________________________________________________
"Many admire, few know"
Hippocrates


From desolator88 at 163.com  Thu May  5 06:44:34 2016
From: desolator88 at 163.com (super)
Date: Thu, 5 May 2016 12:44:34 +0800 (CST)
Subject: [R] how to compute Bonferroni, Tukey's,
 Sheffe 95%-condence intervals for coefficients B1, B2,
 B3 in linear regression?
In-Reply-To: <81BC802D-481C-4D71-8947-4EB5C9C79C4D@comcast.net>
References: <3b331b67.8b6b.1547c3b1432.Coremail.desolator88@163.com>
	<81BC802D-481C-4D71-8947-4EB5C9C79C4D@comcast.net>
Message-ID: <4ff25b89.4f07.1547f3b5097.Coremail.desolator88@163.com>



Tks for you attention, i want to know?Bonferroni, Tukey's, Sheffe 95%-condence intervals for coefficients in linear regression, for example,
fit <- lm(y ~ x1 + x2)
confint(fit) would give b0,b1,b2 95%CIs, but i want to get?Bonferroni, Tukey's, Sheffe 95%-condence intervals for these coefficients. Do anyone happen to know it?







At 2016-05-05 03:55:45, "David Winsemius" <dwinsemius at comcast.net> wrote:
>
>> On May 4, 2016, at 7:45 AM, super <desolator88 at 163.com> wrote:
>> 
>> 
>> Dear experts, 
>>    I have a problem in compute Bonferroni,Tukey's,Sheffe 95%-condence intervals for coefficients B1,B2,B3 in linear regression using R? how can i do it? I only know how to compute these three cofindence intervals in multicomparsion by using multcomp package, and i am search a lot for how to comupte the three CIs for linear regression coefficients but without any useful information, so, plz help me ~
>
>Your question does not detail where the 'confint' function in pkg:multcop is letting you down. After the first few lines of the first example I type:
>
>confint(wht)
>
>#---------------
>And get:
>
>	 Simultaneous Confidence Intervals
>
>Multiple Comparisons of Means: Tukey Contrasts
>
>
>Fit: aov(formula = breaks ~ wool + tension, data = warpbreaks)
>
>Quantile = 2.4155
>95% family-wise confidence level
> 
>
>Linear Hypotheses:
>           Estimate lwr      upr     
>M - L == 0 -10.0000 -19.3536  -0.6464
>H - L == 0 -14.7222 -24.0758  -5.3687
>H - M == 0  -4.7222 -14.0758   4.6313
>
>
>Subsequent examples on that page use linear regression models as there starting point.
>
>-- 
>
>David Winsemius
>Alameda, CA, USA
>

From E.M.A.Hensor at leeds.ac.uk  Thu May  5 09:54:43 2016
From: E.M.A.Hensor at leeds.ac.uk (Elizabeth Hensor)
Date: Thu, 5 May 2016 07:54:43 +0000
Subject: [R] Changing transformations in mi package
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D730B06@mb02.ads.tamu.edu>
References: <VI1PR03MB145502589EEB2F0193B83472D77B0@VI1PR03MB1455.eurprd03.prod.outlook.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D730B06@mb02.ads.tamu.edu>
Message-ID: <VI1PR03MB14555A4ED5DF33F283ABF814D77C0@VI1PR03MB1455.eurprd03.prod.outlook.com>

Thanks very much for your help David. I'll contact Ben Goodrich.

-----Original Message-----
From: David L Carlson [mailto:dcarlson at tamu.edu] 
Sent: 04 May 2016 22:24
To: Elizabeth Hensor; 'r-help at r-project.org'
Subject: RE: Changing transformations in mi package

Thank you for providing a working example. I think you need to contact the package maintainer:

> maintainer("mi")
[1] "Ben Goodrich <benjamin.goodrich at columbia.edu>"

When I run your code it appears that the c column is correctly transformed to square roots, but the show() function is incorrectly indicating a log transform:

> data.missingdf at variables$c at raw_data # The raw data
[1]  4.2  7.9   NA 16.1 19.9 23.0
> sqrt(data.missingdf at variables$c at raw_data) # The square root of the raw 
> data
[1] 2.049390 2.810694       NA 4.012481 4.460942 4.795832
> data.missingdf at variables$c at data # The transformed data - square roots, 
> not logs
[1] 2.049390 2.810694       NA 4.012481 4.460942 4.795832

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Elizabeth Hensor
Sent: Wednesday, May 4, 2016 5:44 AM
To: 'r-help at r-project.org'
Subject: [R] Changing transformations in mi package

Dear all,
I am an R beginner and new to the list. In preparation for using mi to impute missing values I am setting up the missing data frame and would like to specify the transformation types for some of my variables, as I will be using these transformations in my analysis models. According to the documentation the available options are "standardize" (the default), "identity", "log", "logshift" and "sqrt". I can successfully change the transformation types to "log" and "logshift", but when I attempt to change to "sqrt", this changes the type to "log" instead. I'd appreciate your help, please.
Below are details of my system and some code which replicates the issue.

> sessionInfo()
R version 3.2.5 (2016-04-14)
Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United Kingdom.1252   
[3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C                           
[5] LC_TIME=English_United Kingdom.1252    

attached base packages:
[1] stats4    stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] lmerTest_2.0-30 truncnorm_1.0-7 mi_1.0          lme4_1.1-12     Matrix_1.2-4   
[6] pls_2.5-0      

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.4         Formula_1.2-1       cluster_2.0.3       splines_3.2.5      
 [5] MASS_7.3-45         munsell_0.4.3       colorspace_1.2-6    arm_1.8-6          
 [9] lattice_0.20-33     minqa_1.2.4         plyr_1.8.3          nnet_7.3-12        
[13] grid_3.2.5          nlme_3.1-126        gtable_0.2.0        latticeExtra_0.6-28
[17] coda_0.18-1         abind_1.4-3         survival_2.38-3     gridExtra_2.2.1    
[21] RColorBrewer_1.1-2  nloptr_1.0.4        ggplot2_2.1.0       acepack_1.3-3.3    
[25] rpart_4.1-10        scales_0.4.0        Hmisc_3.17-3        foreign_0.8-66

data <- data.frame(a=c(NA,2.1,3.3,4.5,5.9,6.2),b=c(2.2,NA,6.1,8.3,10.2,12.13),c=c(4.2,7.9,NA,16.1,19.9,23))
data

    a     b    c
1  NA  2.20  4.2
2 2.1    NA  7.9
3 3.3  6.10   NA
4 4.5  8.30 16.1
5 5.9 10.20 19.9
6 6.2 12.13 23.0

data.missingdf <- missing_data.frame(data)
show(data.missingdf)

Object of class missing_data.frame with 6 observations on 3 variables

There are 4 missing data patterns

Append '@patterns' to this missing_data.frame to access the corresponding pattern for every observation or perhaps use table()

        type missing method  model
a continuous       1    ppd linear
b continuous       1    ppd linear
c continuous       1    ppd linear

    family     link transformation
a gaussian identity    standardize
b gaussian identity    standardize
c gaussian identity    standardize

#Let's say I'd like to change transformation for a, b and c to "log", "logshift" and "sqrt" respectively

data.missingdf <- change(data.missingdf, y="a", what="transformation", to="logshift") data.missingdf <- change(data.missingdf, y="b", what="transformation", to="log") data.missingdf <- change(data.missingdf, y="c", what="transformation", to="sqrt")
show(data.missingdf)

Object of class missing_data.frame with 6 observations on 3 variables

There are 4 missing data patterns

Append '@patterns' to this missing_data.frame to access the corresponding pattern for every observation or perhaps use table()

        type missing method  model
a continuous       1    ppd linear
b continuous       1    ppd linear
c continuous       1    ppd linear

    family     link transformation
a gaussian identity       logshift
b gaussian identity            log
c gaussian identity            log

#Transformation has been successfully changed for a and b, but for c has been changed to "log" instead of "sqrt"

Thanks in advance for your assistance,
Liz Hensor

Biostatistician
Leeds Institute of Rheumatic and Musculoskeletal Medicine & NIHR Leeds Musculoskeletal Biomedical Research Unit

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Thu May  5 17:27:54 2016
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 5 May 2016 09:27:54 -0600
Subject: [R] how to compute Bonferroni, Tukey's,
 Sheffe 95%-condence intervals for coefficients B1, B2,
 B3 in linear regression?
In-Reply-To: <4ff25b89.4f07.1547f3b5097.Coremail.desolator88@163.com>
References: <3b331b67.8b6b.1547c3b1432.Coremail.desolator88@163.com>
	<81BC802D-481C-4D71-8947-4EB5C9C79C4D@comcast.net>
	<4ff25b89.4f07.1547f3b5097.Coremail.desolator88@163.com>
Message-ID: <CAFEqCdz4ZM6pRs+y92M1u9fUxWsh+EgznibWgWzr9Ur_VkhyOQ@mail.gmail.com>

Super,

Are you just interested in having the final intervals computed for
you?  Or are you trying to compute them yourself so that you can learn
more about what they do?  Or something else?

If the first is the case then you can just use the multicomp package
as you have mentioned.  David was assuming that this was your approach
and wanted to know why that was not good enough, what you did with
multicomp and why you were not satisfied with the results.  If you are
happy using multicomp and just are not seeing a piece that you are
expecting, then show us what you have tried,  what the results are,
what you expect the results to be, and how the last 2 differ.  Then we
can better help you.

If your goal is to learn, then re-inventing the wheel can be a good
thing, but make it clear that learning is the important part, not just
getting an answer.  Also show us what you have done so far, what
references you are using for the formulas, and where you are stuck.

If your goal is something else, then give us more details.

On Wed, May 4, 2016 at 10:44 PM, super <desolator88 at 163.com> wrote:
>
>
> Tks for you attention, i want to know Bonferroni, Tukey's, Sheffe 95%-condence intervals for coefficients in linear regression, for example,
> fit <- lm(y ~ x1 + x2)
> confint(fit) would give b0,b1,b2 95%CIs, but i want to get Bonferroni, Tukey's, Sheffe 95%-condence intervals for these coefficients. Do anyone happen to know it?
>
>
>
>
>
>
>
> At 2016-05-05 03:55:45, "David Winsemius" <dwinsemius at comcast.net> wrote:
>>
>>> On May 4, 2016, at 7:45 AM, super <desolator88 at 163.com> wrote:
>>>
>>>
>>> Dear experts,
>>>    I have a problem in compute Bonferroni,Tukey's,Sheffe 95%-condence intervals for coefficients B1,B2,B3 in linear regression using R? how can i do it? I only know how to compute these three cofindence intervals in multicomparsion by using multcomp package, and i am search a lot for how to comupte the three CIs for linear regression coefficients but without any useful information, so, plz help me ~
>>
>>Your question does not detail where the 'confint' function in pkg:multcop is letting you down. After the first few lines of the first example I type:
>>
>>confint(wht)
>>
>>#---------------
>>And get:
>>
>>        Simultaneous Confidence Intervals
>>
>>Multiple Comparisons of Means: Tukey Contrasts
>>
>>
>>Fit: aov(formula = breaks ~ wool + tension, data = warpbreaks)
>>
>>Quantile = 2.4155
>>95% family-wise confidence level
>>
>>
>>Linear Hypotheses:
>>           Estimate lwr      upr
>>M - L == 0 -10.0000 -19.3536  -0.6464
>>H - L == 0 -14.7222 -24.0758  -5.3687
>>H - M == 0  -4.7222 -14.0758   4.6313
>>
>>
>>Subsequent examples on that page use linear regression models as there starting point.
>>
>>--
>>
>>David Winsemius
>>Alameda, CA, USA
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From alaios at yahoo.com  Thu May  5 18:52:12 2016
From: alaios at yahoo.com (Alaios)
Date: Thu, 5 May 2016 16:52:12 +0000 (UTC)
Subject: [R] moran's I visualization example
References: <545210371.6561203.1462467132171.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <545210371.6561203.1462467132171.JavaMail.yahoo@mail.yahoo.com>

Hi there,in case one has found a nice and easy reproducible example of a Morans'I example where neighborhoods are depicted and their calculated correlations are visible as well.Point is to make some examples that I can share with students that want to understand fast what is the notion about.
RegardsAlex
	[[alternative HTML version deleted]]


From saegerei at t-online.de  Thu May  5 19:07:44 2016
From: saegerei at t-online.de (=?UTF-8?Q?C&A_S=c3=a4ger?=)
Date: Thu, 5 May 2016 19:07:44 +0200
Subject: [R] Can't resolve ... [Solved] Thanks everybody
In-Reply-To: <572A44AF.8060008@t-online.de>
References: <572A44AF.8060008@t-online.de>
Message-ID: <572B7DE0.7010805@t-online.de>

Thank you Jim, John and Jeff.

From 538280 at gmail.com  Thu May  5 20:43:13 2016
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 5 May 2016 12:43:13 -0600
Subject: [R] how to compute Bonferroni, Tukey's,
 Sheffe 95%-condence intervals for coefficients B1, B2,
 B3 in linear regression?
In-Reply-To: <6ef57c46.9508.15481c56878.Coremail.desolator88@163.com>
References: <3b331b67.8b6b.1547c3b1432.Coremail.desolator88@163.com>
	<81BC802D-481C-4D71-8947-4EB5C9C79C4D@comcast.net>
	<4ff25b89.4f07.1547f3b5097.Coremail.desolator88@163.com>
	<CAFEqCdz4ZM6pRs+y92M1u9fUxWsh+EgznibWgWzr9Ur_VkhyOQ@mail.gmail.com>
	<6ef57c46.9508.15481c56878.Coremail.desolator88@163.com>
Message-ID: <CAFEqCdwXn=3aFWVo_N+UcqAN6ZbN9x_o9Y6=8U8A6TLpmwkRbw@mail.gmail.com>

OK, I think that I understand better.  In your original post it
appeared that you already had used the multcomp package.  But now it
looks like you have heard that multcomp is the tool to use, but you
don't know how to use it, is that correct?

p.s.  It is best to keep these discussions on the list, others may be
quicker to respond and/or have better answers.

On Thu, May 5, 2016 at 10:34 AM, super <desolator88 at 163.com> wrote:
>
> OK, Let me show u an example:
>
>
>
>> fit <- lm( mpg ~ disp, data = mtcars)
>> confint(fit)
>                   2.5 %      97.5 %
> (Intercept) 27.08843246 32.11127705
> disp        -0.05083797 -0.03159227
> Now i have a 95% CI for b0 and b1,  and i don't what the name for this CI, may be default CI. Now I want to get some other CIs for b0 and b1, the CIs are Bonferroni,  Tukey's and Sheffe CIs,   Have i explained clearly? And I don't know at all how to do it.... I only heard these CIs in Multcomp package, but i totally don't understand how to compute these CIs for coefficients of linear regression. So i asked u for help, i hope u can understand me. Any help can be useful whether you show me related  package, code or  how to compute the CIs.  Note that, my question is how to compute these CIs for coefficients not the difference in means for different groups.
>
>
>
>
>
>
> At 2016-05-05 23:27:54, "Greg Snow" <538280 at gmail.com> wrote:
>>Super,
>>
>>Are you just interested in having the final intervals computed for
>>you?  Or are you trying to compute them yourself so that you can learn
>>more about what they do?  Or something else?
>>
>>If the first is the case then you can just use the multicomp package
>>as you have mentioned.  David was assuming that this was your approach
>>and wanted to know why that was not good enough, what you did with
>>multicomp and why you were not satisfied with the results.  If you are
>>happy using multicomp and just are not seeing a piece that you are
>>expecting, then show us what you have tried,  what the results are,
>>what you expect the results to be, and how the last 2 differ.  Then we
>>can better help you.
>>
>>If your goal is to learn, then re-inventing the wheel can be a good
>>thing, but make it clear that learning is the important part, not just
>>getting an answer.  Also show us what you have done so far, what
>>references you are using for the formulas, and where you are stuck.
>>
>>If your goal is something else, then give us more details.
>>
>>On Wed, May 4, 2016 at 10:44 PM, super <desolator88 at 163.com> wrote:
>>>
>>>
>>> Tks for you attention, i want to know Bonferroni, Tukey's, Sheffe 95%-condence intervals for coefficients in linear regression, for example,
>>> fit <- lm(y ~ x1 + x2)
>>> confint(fit) would give b0,b1,b2 95%CIs, but i want to get Bonferroni, Tukey's, Sheffe 95%-condence intervals for these coefficients. Do anyone happen to know it?
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> At 2016-05-05 03:55:45, "David Winsemius" <dwinsemius at comcast.net> wrote:
>>>>
>>>>> On May 4, 2016, at 7:45 AM, super <desolator88 at 163.com> wrote:
>>>>>
>>>>>
>>>>> Dear experts,
>>>>>    I have a problem in compute Bonferroni,Tukey's,Sheffe 95%-condence intervals for coefficients B1,B2,B3 in linear regression using R? how can i do it? I only know how to compute these three cofindence intervals in multicomparsion by using multcomp package, and i am search a lot for how to comupte the three CIs for linear regression coefficients but without any useful information, so, plz help me ~
>>>>
>>>>Your question does not detail where the 'confint' function in pkg:multcop is letting you down. After the first few lines of the first example I type:
>>>>
>>>>confint(wht)
>>>>
>>>>#---------------
>>>>And get:
>>>>
>>>>        Simultaneous Confidence Intervals
>>>>
>>>>Multiple Comparisons of Means: Tukey Contrasts
>>>>
>>>>
>>>>Fit: aov(formula = breaks ~ wool + tension, data = warpbreaks)
>>>>
>>>>Quantile = 2.4155
>>>>95% family-wise confidence level
>>>>
>>>>
>>>>Linear Hypotheses:
>>>>           Estimate lwr      upr
>>>>M - L == 0 -10.0000 -19.3536  -0.6464
>>>>H - L == 0 -14.7222 -24.0758  -5.3687
>>>>H - M == 0  -4.7222 -14.0758   4.6313
>>>>
>>>>
>>>>Subsequent examples on that page use linear regression models as there starting point.
>>>>
>>>>--
>>>>
>>>>David Winsemius
>>>>Alameda, CA, USA
>>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>>--
>>Gregory (Greg) L. Snow Ph.D.
>>538280 at gmail.com



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From bolseiro.raiz.csilva at thenavigatorcompany.com  Thu May  5 18:06:00 2016
From: bolseiro.raiz.csilva at thenavigatorcompany.com (Catarina Silva)
Date: Thu, 5 May 2016 17:06:00 +0100
Subject: [R] How to access to an created array with a cicle for
Message-ID: <003601d1a6e8$04d338b0$0e79aa10$@thenavigatorcompany.com>

Hi,

I'm organizing one data base in array's (matrix of positions and for each
position I have a vector with 5 variables). And I have approximately 600
array's.

To construct these array's I've used a for cicle and after construct the
array I named it like: E_1_1_1.1, and I've done the same for the others
array's, like: E_2_1_4, .

 

After, I need to access these constructed array's to compare them. But when
I try to call them, in a for cicle, like noquote(paste(E,x,y,z,sep="_")) or
simply E_x_y_z (varying x, y and z) R assume the name of the array as a
"string" but don't associate the name to the array object created.  How can
I call the array created before with a for cicle varying the index's
"x","y","z" ?

 

Ty,

 

Catarina Silva 

 

 

 


	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Thu May  5 22:17:05 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 5 May 2016 16:17:05 -0400
Subject: [R] How to access to an created array with a cicle for
In-Reply-To: <003601d1a6e8$04d338b0$0e79aa10$@thenavigatorcompany.com>
References: <003601d1a6e8$04d338b0$0e79aa10$@thenavigatorcompany.com>
Message-ID: <CAM_vju=9rYUn4yoA5ob0WX7gg31qp1hf5HD55OPYRxUHTp0piA@mail.gmail.com>

You can use get(), but a more R-like way is to make a list of these
matrices instead of 600 separate objects.

thismat <- get(paste(E,x,y,z,sep="_"))

Sarah

On Thu, May 5, 2016 at 12:06 PM, Catarina Silva
<bolseiro.raiz.csilva at thenavigatorcompany.com> wrote:
> Hi,
>
> I'm organizing one data base in array's (matrix of positions and for each
> position I have a vector with 5 variables). And I have approximately 600
> array's.
>
> To construct these array's I've used a for cicle and after construct the
> array I named it like: E_1_1_1.1, and I've done the same for the others
> array's, like: E_2_1_4, .
>
>
>
> After, I need to access these constructed array's to compare them. But when
> I try to call them, in a for cicle, like noquote(paste(E,x,y,z,sep="_")) or
> simply E_x_y_z (varying x, y and z) R assume the name of the array as a
> "string" but don't associate the name to the array object created.  How can
> I call the array created before with a for cicle varying the index's
> "x","y","z" ?
>
>
>
> Ty,
>
>
>
> Catarina Silva
>
>
>
>


From spencer.graves at effectivedefense.org  Fri May  6 02:12:48 2016
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Thu, 5 May 2016 19:12:48 -0500
Subject: [R] with vs. attach
Message-ID: <901fd028-5e60-cf67-906d-c29e43d8762b@effectivedefense.org>

I want a function to evaluate one argument
in the environment of a data.frame supplied
as another argument.  "attach" works for
this, but "with" does not.  Is there a way
to make "with" work?  I'd rather not attach
the data.frame.


With the following two functions "eval.w.attach"
works but "eval.w.with" fails:


dat <- data.frame(a=1:2)
eval.w.attach <- function(x, dat){
   attach(dat)
   X <- x
   detach()
   X
}

eval.w.with <- function(x, dat){
   with(dat, x)
}

eval.w.attach(a/2, dat) # returns c(.5, 1)

eval.w.with(a/2, dat) # Error ... 'a' not found


Thanks, Spencer Graves

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri May  6 02:43:47 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 5 May 2016 17:43:47 -0700
Subject: [R] with vs. attach
In-Reply-To: <901fd028-5e60-cf67-906d-c29e43d8762b@effectivedefense.org>
References: <901fd028-5e60-cf67-906d-c29e43d8762b@effectivedefense.org>
Message-ID: <4808B356-E233-4859-A15E-745D26D4B85C@comcast.net>


> On May 5, 2016, at 5:12 PM, Spencer Graves <spencer.graves at effectivedefense.org> wrote:
> 
> I want a function to evaluate one argument
> in the environment of a data.frame supplied
> as another argument.  "attach" works for
> this, but "with" does not.  Is there a way
> to make "with" work?  I'd rather not attach
> the data.frame.
> 
> 
> With the following two functions "eval.w.attach"
> works but "eval.w.with" fails:
> 
> 
> dat <- data.frame(a=1:2)
> eval.w.attach <- function(x, dat){
>   attach(dat)
>   X <- x
>   detach()
>   X
> }
> 
> eval.w.with <- function(x, dat){
>   with(dat, x)
> }
> 
> eval.w.attach(a/2, dat) # returns c(.5, 1)

How about using eval( substitute( ...))?

 eval.w.sub <- function(expr, datt){
   eval( substitute(expr), env=datt)
                         }
 eval.w.sub(a/2, dat)
#[1] 0.5 1.0


-- 
David.


> 
> eval.w.with(a/2, dat) # Error ... 'a' not found
> 
> 
> Thanks, Spencer Graves
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From spencer.graves at effectivedefense.org  Fri May  6 04:38:38 2016
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Thu, 5 May 2016 21:38:38 -0500
Subject: [R] with vs. attach
In-Reply-To: <4808B356-E233-4859-A15E-745D26D4B85C@comcast.net>
References: <901fd028-5e60-cf67-906d-c29e43d8762b@effectivedefense.org>
	<4808B356-E233-4859-A15E-745D26D4B85C@comcast.net>
Message-ID: <70d0e27b-4bfd-1b61-8d69-6e93dc6d6235@effectivedefense.org>

Hi, David:  That works.  Thanks very much.  Spencer Graves



On 5/5/2016 7:43 PM, David Winsemius wrote:
>> On May 5, 2016, at 5:12 PM, Spencer Graves <spencer.graves at effectivedefense.org> wrote:
>>
>> I want a function to evaluate one argument
>> in the environment of a data.frame supplied
>> as another argument.  "attach" works for
>> this, but "with" does not.  Is there a way
>> to make "with" work?  I'd rather not attach
>> the data.frame.
>>
>>
>> With the following two functions "eval.w.attach"
>> works but "eval.w.with" fails:
>>
>>
>> dat <- data.frame(a=1:2)
>> eval.w.attach <- function(x, dat){
>>    attach(dat)
>>    X <- x
>>    detach()
>>    X
>> }
>>
>> eval.w.with <- function(x, dat){
>>    with(dat, x)
>> }
>>
>> eval.w.attach(a/2, dat) # returns c(.5, 1)
> How about using eval( substitute( ...))?
>
>   eval.w.sub <- function(expr, datt){
>     eval( substitute(expr), env=datt)
>                           }
>   eval.w.sub(a/2, dat)
> #[1] 0.5 1.0
>
>


From bgunter.4567 at gmail.com  Fri May  6 06:17:12 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 5 May 2016 21:17:12 -0700
Subject: [R] with vs. attach
In-Reply-To: <70d0e27b-4bfd-1b61-8d69-6e93dc6d6235@effectivedefense.org>
References: <901fd028-5e60-cf67-906d-c29e43d8762b@effectivedefense.org>
	<4808B356-E233-4859-A15E-745D26D4B85C@comcast.net>
	<70d0e27b-4bfd-1b61-8d69-6e93dc6d6235@effectivedefense.org>
Message-ID: <CAGxFJbSY+17Zb+dTNO-EZLOnPvKC7j22V2XNut8OVrEz6ejS2w@mail.gmail.com>

... and it's exactly with.default's code !

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, May 5, 2016 at 7:38 PM, Spencer Graves
<spencer.graves at effectivedefense.org> wrote:
> Hi, David:  That works.  Thanks very much.  Spencer Graves
>
>
>
> On 5/5/2016 7:43 PM, David Winsemius wrote:
>>>
>>> On May 5, 2016, at 5:12 PM, Spencer Graves
>>> <spencer.graves at effectivedefense.org> wrote:
>>>
>>> I want a function to evaluate one argument
>>> in the environment of a data.frame supplied
>>> as another argument.  "attach" works for
>>> this, but "with" does not.  Is there a way
>>> to make "with" work?  I'd rather not attach
>>> the data.frame.
>>>
>>>
>>> With the following two functions "eval.w.attach"
>>> works but "eval.w.with" fails:
>>>
>>>
>>> dat <- data.frame(a=1:2)
>>> eval.w.attach <- function(x, dat){
>>>    attach(dat)
>>>    X <- x
>>>    detach()
>>>    X
>>> }
>>>
>>> eval.w.with <- function(x, dat){
>>>    with(dat, x)
>>> }
>>>
>>> eval.w.attach(a/2, dat) # returns c(.5, 1)
>>
>> How about using eval( substitute( ...))?
>>
>>   eval.w.sub <- function(expr, datt){
>>     eval( substitute(expr), env=datt)
>>                           }
>>   eval.w.sub(a/2, dat)
>> #[1] 0.5 1.0
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From spencer.graves at effectivedefense.org  Fri May  6 11:37:00 2016
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Fri, 6 May 2016 04:37:00 -0500
Subject: [R] with vs. attach
In-Reply-To: <CAGxFJbSY+17Zb+dTNO-EZLOnPvKC7j22V2XNut8OVrEz6ejS2w@mail.gmail.com>
References: <901fd028-5e60-cf67-906d-c29e43d8762b@effectivedefense.org>
	<4808B356-E233-4859-A15E-745D26D4B85C@comcast.net>
	<70d0e27b-4bfd-1b61-8d69-6e93dc6d6235@effectivedefense.org>
	<CAGxFJbSY+17Zb+dTNO-EZLOnPvKC7j22V2XNut8OVrEz6ejS2w@mail.gmail.com>
Message-ID: <f8d11e28-dc44-9fb8-7ba7-19d8f3de019d@effectivedefense.org>



On 5/5/2016 11:17 PM, Bert Gunter wrote:
> ... and it's exactly with.default's code !


Thanks for pointing that out.  Unfortunately, it didn't work inside 
another function.  However, if I had looked at it, I might have been 
able to thought to try it.  Spencer
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, May 5, 2016 at 7:38 PM, Spencer Graves
> <spencer.graves at effectivedefense.org> wrote:
>> Hi, David:  That works.  Thanks very much.  Spencer Graves
>>
>>
>>
>> On 5/5/2016 7:43 PM, David Winsemius wrote:
>>>> On May 5, 2016, at 5:12 PM, Spencer Graves
>>>> <spencer.graves at effectivedefense.org> wrote:
>>>>
>>>> I want a function to evaluate one argument
>>>> in the environment of a data.frame supplied
>>>> as another argument.  "attach" works for
>>>> this, but "with" does not.  Is there a way
>>>> to make "with" work?  I'd rather not attach
>>>> the data.frame.
>>>>
>>>>
>>>> With the following two functions "eval.w.attach"
>>>> works but "eval.w.with" fails:
>>>>
>>>>
>>>> dat <- data.frame(a=1:2)
>>>> eval.w.attach <- function(x, dat){
>>>>     attach(dat)
>>>>     X <- x
>>>>     detach()
>>>>     X
>>>> }
>>>>
>>>> eval.w.with <- function(x, dat){
>>>>     with(dat, x)
>>>> }
>>>>
>>>> eval.w.attach(a/2, dat) # returns c(.5, 1)
>>> How about using eval( substitute( ...))?
>>>
>>>    eval.w.sub <- function(expr, datt){
>>>      eval( substitute(expr), env=datt)
>>>                            }
>>>    eval.w.sub(a/2, dat)
>>> #[1] 0.5 1.0
>>>
>>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From kendejan at yahoo.fr  Fri May  6 11:20:00 2016
From: kendejan at yahoo.fr (kende jan)
Date: Fri, 6 May 2016 09:20:00 +0000 (UTC)
Subject: [R] svyciprop object
References: <1729178949.363594.1462526400131.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1729178949.363594.1462526400131.JavaMail.yahoo@mail.yahoo.com>

Hi,?I'd like to access to the different elements in a svyciprop object (to the confidence intervals in particular...). But none of the functions I know works.Thank you for your help !
> grr <- svyciprop(~temp==bzz, dclus1)> grr? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?2.5% ? 97.5%temp == bzz 0.040719697 0.027622756 0.05965> attributes(grr)$names[1] "temp == bzz"
$var? ? ? ? ? ? ? ? ? ? ? ? as.numeric(temp == bzz)as.numeric(temp == bzz) ? ? ? 6.42377038236e-05
$ci? ? ? ? ? ?2.5% ? ? ? ? ? 97.5%?0.0276227559667 0.0596454643748?
$class[1] "svyciprop"
> grr$ciErreur dans grr$ci : $ operator is invalid for atomic vectors> grr["ci"]<NA>?? NA?> ci(grr)Erreur : impossible de trouver la fonction "ci"


	[[alternative HTML version deleted]]


From philipp.schaper at unisg.ch  Fri May  6 08:40:10 2016
From: philipp.schaper at unisg.ch (Philipp Schaper)
Date: Fri, 6 May 2016 08:40:10 +0200
Subject: [R] Truncreg package help
Message-ID: <OFFAAF6EAC.0DEF1A65-ONC1257FAB.0023970D-C1257FAB.0024A2FF@unisg.ch>

Dear R userers,

I am running truncated regressions with the 'truncreg' package. My sample 
is large (6,000 observations), the data is left-truncated at 1 and the 
left tail of the data is heavily centered at 1. When I am running the 
regression I receive the following error message: 

  Error in optim(par = start[!fixed], fn = logLikFunc, control = control, 
: 
  initial value in 'vmmin' is not finite

>From a previous discussion (
http://r.789695.n4.nabble.com/betareg-help-td3350129.html) on a similar 
issue in the betareg function I assume that the error message stems from 
that the estimate of the starting value of the precision parameter is 
negative. However, I do not know how I can take care of this. Thus I would 
be very thankful for any help.

Best regards,
Philipp 
	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri May  6 13:46:21 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 6 May 2016 13:46:21 +0200
Subject: [R] with vs. attach
In-Reply-To: <4808B356-E233-4859-A15E-745D26D4B85C@comcast.net>
References: <901fd028-5e60-cf67-906d-c29e43d8762b@effectivedefense.org>
	<4808B356-E233-4859-A15E-745D26D4B85C@comcast.net>
Message-ID: <CD4AB490-E960-44E9-BAC0-D30E96518922@gmail.com>


On 06 May 2016, at 02:43 , David Winsemius <dwinsemius at comcast.net> wrote:

> 
>> On May 5, 2016, at 5:12 PM, Spencer Graves <spencer.graves at effectivedefense.org> wrote:
>> 
>> I want a function to evaluate one argument
>> in the environment of a data.frame supplied
>> as another argument.  "attach" works for
>> this, but "with" does not.  Is there a way
>> to make "with" work?  I'd rather not attach
>> the data.frame.
>> 
>> 
>> With the following two functions "eval.w.attach"
>> works but "eval.w.with" fails:
>> 
>> 
>> dat <- data.frame(a=1:2)
>> eval.w.attach <- function(x, dat){
>>  attach(dat)
>>  X <- x
>>  detach()
>>  X
>> }
>> 
>> eval.w.with <- function(x, dat){
>>  with(dat, x)
>> }
>> 
>> eval.w.attach(a/2, dat) # returns c(.5, 1)
> 
> How about using eval( substitute( ...))?
> 
> eval.w.sub <- function(expr, datt){
>   eval( substitute(expr), env=datt)
>                         }
> eval.w.sub(a/2, dat)
> #[1] 0.5 1.0
> 
> 

Actually, I think a better overall strategy is to say that if you want to pass an expression to a function, then pass an expression object (or a call object or maybe a formula object). 

Once you figure out _how_ your eval.w.attach works (sort of), you'll get the creeps: 

Lazy evaluation causes the argument x to be evaluated after the attach(), hence the evaluation environment of an actual argument is being temporarily modified from inside a function. 

Apart from upsetting computer science purists, there could be hidden problems: One major issue is that  values in "dat" could be masked by values in the global environment, another issue is that an error in evaluating the expression will leave dat attached. So at a minimum, you need to recode using on.exit() magic.

So my preferences go along these lines:

> dat <- data.frame(a=1:2)
> eval.expression <- function(e, dat) eval(e, dat)
> eval.expression(quote(a/2), dat)
[1] 0.5 1.0
> eval.expression(expression(a/2), dat)
[1] 0.5 1.0

> eval.formula <- function(f, dat) eval(f[[2]], dat)
> eval.formula(~a/2, dat)
[1] 0.5 1.0

Peter D.



> -- 
> David.
> 
> 
>> 
>> eval.w.with(a/2, dat) # Error ... 'a' not found
>> 
>> 
>> Thanks, Spencer Graves
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jdnewmil at dcn.davis.ca.us  Fri May  6 14:00:09 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 06 May 2016 05:00:09 -0700
Subject: [R] svyciprop object
In-Reply-To: <1729178949.363594.1462526400131.JavaMail.yahoo@mail.yahoo.com>
References: <1729178949.363594.1462526400131.JavaMail.yahoo.ref@mail.yahoo.com>
	<1729178949.363594.1462526400131.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <C21FF7CB-E18F-4069-B74A-B925DDF1CAEF@dcn.davis.ca.us>

Your post in HTML format came through garbled.  Please post plain text email on this list. 

Your question is unclear as well.  Perhaps you are not familiar with using the str() function preview what is in an object? 
-- 
Sent from my phone. Please excuse my brevity.

On May 6, 2016 2:20:00 AM PDT, kende jan via R-help <r-help at r-project.org> wrote:
>Hi,?I'd like to access to the different elements in a svyciprop object
>(to the confidence intervals in particular...). But none of the
>functions I know works.Thank you for your help !
>> grr <- svyciprop(~temp==bzz, dclus1)> grr? ? ? ? ? ? ? ? ? ? ? ? ? ?
>? ?2.5% ? 97.5%temp == bzz 0.040719697 0.027622756 0.05965>
>attributes(grr)$names[1] "temp == bzz"
>$var? ? ? ? ? ? ? ? ? ? ? ? as.numeric(temp == bzz)as.numeric(temp ==
>bzz) ? ? ? 6.42377038236e-05
>$ci? ? ? ? ? ?2.5% ? ? ? ? ? 97.5%?0.0276227559667 0.0596454643748?
>$class[1] "svyciprop"
>> grr$ciErreur dans grr$ci : $ operator is invalid for atomic vectors>
>grr["ci"]<NA>?? NA?> ci(grr)Erreur : impossible de trouver la fonction
>"ci"
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From leonardof at leonardof.med.br  Fri May  6 14:01:18 2016
From: leonardof at leonardof.med.br (Leonardo Ferreira Fontenelle)
Date: Fri, 06 May 2016 09:01:18 -0300
Subject: [R] svyciprop object
In-Reply-To: <1729178949.363594.1462526400131.JavaMail.yahoo@mail.yahoo.com>
References: <1729178949.363594.1462526400131.JavaMail.yahoo.ref@mail.yahoo.com>
	<1729178949.363594.1462526400131.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1462536078.353637.599990985.5F763393@webmail.messagingengine.com>

Em Sex 6 mai. 2016, ?s 06:20, kende jan via R-help escreveu:
> Hi,?I'd like to access to the different elements in a svyciprop object
> (to the confidence intervals in particular...). But none of the functions
> I know works.Thank you for your help !

I don't know what data set you are using, so for reproducibility I'm
using the data set from the example in the function documentation.

=====
library(survey)
data(api)
dclus1 <- svydesign(ids = ~ dnum, fpc = ~ fpc, data = apiclus1)
grr <- svyciprop(~ I(ell == 0), dclus1, method = "likelihood")
attr(grr, "ci")
#         2.5%        97.5% 
# 0.0006639212 0.1077784084
=====

HTH,

Leonardo Ferreira Fontenelle
PhD candidate in epidemiology, Federal University of Pelotas
Professor of medicine, Vila Velha University
Legislative analyst in health, Municipal Chamber of Vit?ria


From spencer.graves at effectivedefense.org  Fri May  6 14:47:18 2016
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Fri, 6 May 2016 07:47:18 -0500
Subject: [R] with vs. attach
In-Reply-To: <CD4AB490-E960-44E9-BAC0-D30E96518922@gmail.com>
References: <901fd028-5e60-cf67-906d-c29e43d8762b@effectivedefense.org>
	<4808B356-E233-4859-A15E-745D26D4B85C@comcast.net>
	<CD4AB490-E960-44E9-BAC0-D30E96518922@gmail.com>
Message-ID: <02d73d7c-2699-dc24-8552-048491dc21fa@effectivedefense.org>



On 5/6/2016 6:46 AM, peter dalgaard wrote:
> On 06 May 2016, at 02:43 , David Winsemius <dwinsemius at comcast.net> wrote:
>
>>> On May 5, 2016, at 5:12 PM, Spencer Graves <spencer.graves at effectivedefense.org> wrote:
>>>
>>> I want a function to evaluate one argument
>>> in the environment of a data.frame supplied
>>> as another argument.  "attach" works for
>>> this, but "with" does not.  Is there a way
>>> to make "with" work?  I'd rather not attach
>>> the data.frame.
>>>
>>>
>>> With the following two functions "eval.w.attach"
>>> works but "eval.w.with" fails:
>>>
>>>
>>> dat <- data.frame(a=1:2)
>>> eval.w.attach <- function(x, dat){
>>>   attach(dat)
>>>   X <- x
>>>   detach()
>>>   X
>>> }
>>>
>>> eval.w.with <- function(x, dat){
>>>   with(dat, x)
>>> }
>>>
>>> eval.w.attach(a/2, dat) # returns c(.5, 1)
>> How about using eval( substitute( ...))?
>>
>> eval.w.sub <- function(expr, datt){
>>    eval( substitute(expr), env=datt)
>>                          }
>> eval.w.sub(a/2, dat)
>> #[1] 0.5 1.0
>>
>>
> Actually, I think a better overall strategy is to say that if you want to pass an expression to a function, then pass an expression object (or a call object or maybe a formula object).
>
> Once you figure out _how_ your eval.w.attach works (sort of), you'll get the creeps:
>
> Lazy evaluation causes the argument x to be evaluated after the attach(), hence the evaluation environment of an actual argument is being temporarily modified from inside a function.
>
> Apart from upsetting computer science purists, there could be hidden problems: One major issue is that  values in "dat" could be masked by values in the global environment, another issue is that an error in evaluating the expression will leave dat attached. So at a minimum, you need to recode using on.exit() magic.
>
> So my preferences go along these lines:
>
>> dat <- data.frame(a=1:2)
>> eval.expression <- function(e, dat) eval(e, dat)
>> eval.expression(quote(a/2), dat)
> [1] 0.5 1.0
>> eval.expression(expression(a/2), dat)
> [1] 0.5 1.0
>
>> eval.formula <- function(f, dat) eval(f[[2]], dat)
>> eval.formula(~a/2, dat)
> [1] 0.5 1.0

Hi, Peter:


       I don't like eval.expression or eval.formula, because they don't 
automatically accept what I naively thought should work and require more 
knowledge of the user.  What about David's eval.w.sub:


a <- pi
dat <- data.frame(a=1:2)
eval.w.sub <- function(a, Dat){
   eval( substitute(a), env=Dat)
}
 > eval.w.sub(a/2, dat)
[1] 0.5 1.0


       This produces what's desired in a way that seems simpler to me.


       By the way, I really appreciate Peter's insightful comments:


eval.w.attachOops <- function(x, Dat){
   attach(Dat)
   X <- x
   detach()
   X
}
 > eval.w.attachOops(a/2, dat)
The following object is masked _by_ .GlobalEnv:

     a

[1] 1.570796
 > eval.w.attachOops(b/2, dat)
The following object is masked _by_ .GlobalEnv:

     a

Error in eval.w.attachOops(b/2, dat) : object 'b' not found
 > search()
[1] ".GlobalEnv"        "Dat"               "package:graphics"
[4] "package:grDevices" "package:utils"     "package:datasets"
[7] "package:methods"   "Autoloads"         "package:base"
 > objects(2)
[1] "a"

*** NOTES:


       1.  This gives a likely wrong answer with a warning if "a" exists 
in .GlobalEnv, and leaves "Dat" (NOT "dat") attached upon exit.



       2.  A stray "detach()" [not shown here] detached 
"package:stats".  oops.


*** Using "on.exit" fixes the problem with failure to detach but not the 
likely wrong answer:


detach()
search()
eval.w.attachStillWrong <- function(x, dat){
   attach(dat)
   on.exit(detach(dat))
   X <- x
   X
}
The following object is masked _by_ .GlobalEnv:

     a

[1] 1.570796
 > eval.w.attachStillWrong(b/2, dat)
The following object is masked _by_ .GlobalEnv:

     a

Error in eval.w.attachStillWrong(b/2, dat) : object 'b' not found
 > search()
[1] ".GlobalEnv"        "package:grDevices" "package:utils"
[4] "package:datasets"  "package:methods"   "Autoloads"
[7] "package:base"


       Thanks again to Peter and David.  Spencer

> Peter D.
>
>
>
>> -- 
>> David.
>>
>>
>>> eval.w.with(a/2, dat) # Error ... 'a' not found
>>>
>>>
>>> Thanks, Spencer Graves
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> David Winsemius
>> Alameda, CA, USA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From thanoon.younis80 at gmail.com  Fri May  6 15:45:41 2016
From: thanoon.younis80 at gmail.com (thanoon younis)
Date: Fri, 6 May 2016 16:45:41 +0300
Subject: [R] bootstrapping code with ordered categorical data(five
	categories)
Message-ID: <CABLo8nG6mM4BKcjbPfTj5PTv3GLnR=Cj1tFH16w0K0juVakNAQ@mail.gmail.com>

Hi

I need a bootstrapping code with ordered categorical data(five categories)
to re-samplling a real data with 16 variables and 200 sample size.


Any help please




-- 
Thanoon Y. Thanoon
PhD
Department of Mathematical Sciences
Faculty of Science
University Technology Malaysia, UTM
E.Mail: Thanoon.younis80 at gmail.com
E.Mail: dawn_prayer80 at yahoo.com
Facebook:Thanoon Younis AL-Shakerchy
Twitter: Thanoon Alshakerchy
H.P:00601127550205

	[[alternative HTML version deleted]]


From cdetermanjr at gmail.com  Fri May  6 17:15:28 2016
From: cdetermanjr at gmail.com (Charles Determan)
Date: Fri, 6 May 2016 10:15:28 -0500
Subject: [R] openssl package install error
Message-ID: <CAKxd1KMx89TXYE6gsy+8XKSUKqonMO614rc8Vsf4h9bOL11ydw@mail.gmail.com>

I am trying to install 'openssl' on ubuntu 14.04.  I already of libssl-dev
and libcurl4-openssl-dev installed.  But when I try to install I get a
bunch of errors complaining about 'unknown type 'u_char''.

Thoughts?

Excerpt of output:

Found pkg-config cflags and libs!
Using PKG_CFLAGS=
Using PKG_LIBS=-lssl -lcrypto
** libs
ccache gcc-4.8 -I/usr/share/R/include -DNDEBUG      -fpic  -std=c99 -c
aes.c -o aes.o
ccache gcc-4.8 -I/usr/share/R/include -DNDEBUG      -fpic  -std=c99 -c
base64.c -o base64.o
ccache gcc-4.8 -I/usr/share/R/include -DNDEBUG      -fpic  -std=c99 -c
bignum.c -o bignum.o
ccache gcc-4.8 -I/usr/share/R/include -DNDEBUG      -fpic  -std=c99 -c
cert.c -o cert.o
ccache gcc-4.8 -I/usr/share/R/include -DNDEBUG      -fpic  -std=c99 -c
diffie.c -o diffie.o
ccache gcc-4.8 -I/usr/share/R/include -DNDEBUG      -fpic  -std=c99 -c
envelope.c -o envelope.o
ccache gcc-4.8 -I/usr/share/R/include -DNDEBUG      -fpic  -std=c99 -c
error.c -o error.o
ccache gcc-4.8 -I/usr/share/R/include -DNDEBUG      -fpic  -std=c99 -c
hash.c -o hash.o
ccache gcc-4.8 -I/usr/share/R/include -DNDEBUG      -fpic  -std=c99 -c
info.c -o info.o
ccache gcc-4.8 -I/usr/share/R/include -DNDEBUG      -fpic  -std=c99 -c
keygen.c -o keygen.o
ccache gcc-4.8 -I/usr/share/R/include -DNDEBUG      -fpic  -std=c99 -c
onload.c -o onload.o
ccache gcc-4.8 -I/usr/share/R/include -DNDEBUG      -fpic  -std=c99 -c
openssh.c -o openssh.o
ccache gcc-4.8 -I/usr/share/R/include -DNDEBUG      -fpic  -std=c99 -c
rand.c -o rand.o
ccache gcc-4.8 -I/usr/share/R/include -DNDEBUG      -fpic  -std=c99 -c
read.c -o read.o
ccache gcc-4.8 -I/usr/share/R/include -DNDEBUG      -fpic  -std=c99 -c
rsa.c -o rsa.o
ccache gcc-4.8 -I/usr/share/R/include -DNDEBUG      -fpic  -std=c99 -c
signing.c -o signing.o
ccache gcc-4.8 -I/usr/share/R/include -DNDEBUG      -fpic  -std=c99 -c
ssl.c -o ssl.o
In file included from /usr/include/resolv.h:65:0,
                 from ssl.c:15:
/usr/include/arpa/nameser.h:115:2: error: unknown type name ?u_char?
  const u_char *_msg, *_eom;
  ^
/usr/include/arpa/nameser.h:117:2: error: unknown type name ?u_char?
  const u_char *_sections[ns_s_max];
  ^
/usr/include/arpa/nameser.h:120:2: error: unknown type name ?u_char?
  const u_char *_msg_ptr;

	[[alternative HTML version deleted]]


From adamsanders11 at gmail.com  Fri May  6 17:46:56 2016
From: adamsanders11 at gmail.com (Adam Sanders)
Date: Fri, 6 May 2016 09:46:56 -0600
Subject: [R] RandomForest-question about split point and GetTree function
Message-ID: <CAOBKCDcVGjkci8kH-SKf=h2H=w0yLr4s41Vr89BMhVmpk6peiQ@mail.gmail.com>

I am looking at results of a random forest. In the documentation, it says
the following for categorical variables:

"For categorical predictors, the splitting point is represented by an
integer, whose binary expansion gives the identities of the categories that
goes to left or right. For example, if a predictor has four categories, and
the split point is 13. The binary expansion of 13 is (1, 0, 1, 1) (because
13 = 1 ? 2 0 + 0 ? 2 1 + 1 ? 2 2 + 1 ? 2 3 ), so cases with categories 1,
3, or 4 in this predictor get sent to the left, and the rest to the right. "

I am unsure how to interpret this when the splitting point is 0. I was
thinking it means all categories would be to the right. Is this correct?

	[[alternative HTML version deleted]]


From pnsinha68 at gmail.com  Fri May  6 18:40:17 2016
From: pnsinha68 at gmail.com (Partha Sinha)
Date: Fri, 6 May 2016 22:10:17 +0530
Subject: [R] Freq table
Message-ID: <CADcgpJeXbcYyiRpuw-MEfSFpEhE6=D=G6qttGHhGgNvQuqEMhw@mail.gmail.com>

M1 M2 M4
60 86 48
72 90 86
66 86 62
69 60 48
66 86     58
I  want to frequency table by binning the data in 0-60, 61-80,80-100
and want output as
           M1   M2   M3
0-60
61-80
80-100

How to do

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri May  6 18:48:35 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 6 May 2016 09:48:35 -0700
Subject: [R] Freq table
In-Reply-To: <CADcgpJeXbcYyiRpuw-MEfSFpEhE6=D=G6qttGHhGgNvQuqEMhw@mail.gmail.com>
References: <CADcgpJeXbcYyiRpuw-MEfSFpEhE6=D=G6qttGHhGgNvQuqEMhw@mail.gmail.com>
Message-ID: <CAGxFJbQkqGGuU-iK0HxQeoCyrcGXaE6xf2h+drncFZt5jKC46g@mail.gmail.com>

This is not a code writing service. Posters are expected to first make
an honest effort and show us their code as part of their post. Please
read the posting guide to learn what is expected.

However, a hint to get you started: see ?cut

If you have not already gone through an R tutorial or two, please do
so before posting further. There are many good ones on the web.

Cheers,
Bert Gunter
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, May 6, 2016 at 9:40 AM, Partha Sinha <pnsinha68 at gmail.com> wrote:
> M1 M2 M4
> 60 86 48
> 72 90 86
> 66 86 62
> 69 60 48
> 66 86     58
> I  want to frequency table by binning the data in 0-60, 61-80,80-100
> and want output as
>            M1   M2   M3
> 0-60
> 61-80
> 80-100
>
> How to do
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dal64372 at ufl.edu  Fri May  6 18:35:13 2016
From: dal64372 at ufl.edu (Phillips,Douglas A)
Date: Fri, 6 May 2016 16:35:13 +0000
Subject: [R] Help needed with successfully downloading and opening Agricolae
 package
Message-ID: <96C3B1CA-BAD7-4129-B20A-890F2D28D934@ufl.edu>

Hi, I just downloaded the Agricolae package and tried to access it using the commands listed below (and received the error messages in red).  Any suggestions on resolving these errors?

Thanks for your assistance.

Doug



> install.packages("agricolae")
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100  896k  100  896k    0     0   900k      0 --:--:-- --:--:-- --:--:--  900k

The downloaded binary packages are in
/var/folders/qn/8tc0v1m971d361gv0mwsmxj80000gn/T//RtmpYMZ97k/downloaded_packages
>
>
> library(agricolae)
Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
  there is no package called ?sp?
Error: package or namespace load failed for ?agricolae?

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri May  6 21:14:27 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 6 May 2016 12:14:27 -0700
Subject: [R] with vs. attach
In-Reply-To: <02d73d7c-2699-dc24-8552-048491dc21fa@effectivedefense.org>
References: <901fd028-5e60-cf67-906d-c29e43d8762b@effectivedefense.org>
	<4808B356-E233-4859-A15E-745D26D4B85C@comcast.net>
	<CD4AB490-E960-44E9-BAC0-D30E96518922@gmail.com>
	<02d73d7c-2699-dc24-8552-048491dc21fa@effectivedefense.org>
Message-ID: <FAC95CBE-8E91-4ED3-B3AE-DF6568354D7B@comcast.net>


> On May 6, 2016, at 5:47 AM, Spencer Graves <spencer.graves at effectivedefense.org> wrote:
> 
> 
> 
> On 5/6/2016 6:46 AM, peter dalgaard wrote:
>> On 06 May 2016, at 02:43 , David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>>>> On May 5, 2016, at 5:12 PM, Spencer Graves <spencer.graves at effectivedefense.org> wrote:
>>>> 
>>>> I want a function to evaluate one argument
>>>> in the environment of a data.frame supplied
>>>> as another argument.  "attach" works for
>>>> this, but "with" does not.  Is there a way
>>>> to make "with" work?  I'd rather not attach
>>>> the data.frame.
>>>> 
>>>> 
>>>> With the following two functions "eval.w.attach"
>>>> works but "eval.w.with" fails:
>>>> 
>>>> 
>>>> dat <- data.frame(a=1:2)
>>>> eval.w.attach <- function(x, dat){
>>>>  attach(dat)
>>>>  X <- x
>>>>  detach()
>>>>  X
>>>> }
>>>> 
>>>> eval.w.with <- function(x, dat){
>>>>  with(dat, x)
>>>> }
>>>> 
>>>> eval.w.attach(a/2, dat) # returns c(.5, 1)
>>> How about using eval( substitute( ...))?
>>> 
>>> eval.w.sub <- function(expr, datt){
>>>   eval( substitute(expr), env=datt)
>>>                         }
>>> eval.w.sub(a/2, dat)
>>> #[1] 0.5 1.0
>>> 
>>> 
>> Actually, I think a better overall strategy is to say that if you want to pass an expression to a function, then pass an expression object (or a call object or maybe a formula object).
>> 
>> Once you figure out _how_ your eval.w.attach works (sort of), you'll get the creeps:
>> 
>> Lazy evaluation causes the argument x to be evaluated after the attach(), hence the evaluation environment of an actual argument is being temporarily modified from inside a function.
>> 
>> Apart from upsetting computer science purists, there could be hidden problems: One major issue is that  values in "dat" could be masked by values in the global environment, another issue is that an error in evaluating the expression will leave dat attached. So at a minimum, you need to recode using on.exit() magic.
>> 
>> So my preferences go along these lines:
>> 
>>> dat <- data.frame(a=1:2)
>>> eval.expression <- function(e, dat) eval(e, dat)
>>> eval.expression(quote(a/2), dat)
>> [1] 0.5 1.0
>>> eval.expression(expression(a/2), dat)
>> [1] 0.5 1.0
>> 
>>> eval.formula <- function(f, dat) eval(f[[2]], dat)
>>> eval.formula(~a/2, dat)
>> [1] 0.5 1.0
> 
> Hi, Peter:
> 
> 
>      I don't like eval.expression or eval.formula, because they don't automatically accept what I naively thought should work and require more knowledge of the user.  What about David's eval.w.sub:
> 
> 
> a <- pi
> dat <- data.frame(a=1:2)
> eval.w.sub <- function(a, Dat){
>  eval( substitute(a), env=Dat)
> }
> > eval.w.sub(a/2, dat)
> [1] 0.5 1.0

I liked eval.expression and tested it with a bquote(...) argument to see if that would succeed. It did, but it didn't return what you wanted for `a/2`, so I tried seeing if a "double eval wuold deliver both yours and my desired results:

 eval.w.sub <- function(a, Dat){
  eval( eval(substitute(a),Dat), env=Dat)
 }
x=2
 eval.w.sub( a/2, dat)
[1] 0.5 1.0
 eval.w.sub( bquote(2*a*.(x) ), dat)
[1] 4 8

We are here retracing the path the Hadley took in some of his ggplot2 design decsions. Unfortunately for me those NSE rules often left me confused about what should and shouldn't be 'quoted' in the as-character sense and what should be quote()-ed or "unquoted" in the bquote() sense.
-- 

> 
> 
> 
>      This produces what's desired in a way that seems simpler to me.
> 
> 
>      By the way, I really appreciate Peter's insightful comments:
> 
> 
> eval.w.attachOops <- function(x, Dat){
>  attach(Dat)
>  X <- x
>  detach()
>  X
> }
> > eval.w.attachOops(a/2, dat)
> The following object is masked _by_ .GlobalEnv:
> 
>    a
> 
> [1] 1.570796
> > eval.w.attachOops(b/2, dat)
> The following object is masked _by_ .GlobalEnv:
> 
>    a
> 
> Error in eval.w.attachOops(b/2, dat) : object 'b' not found
> > search()
> [1] ".GlobalEnv"        "Dat"               "package:graphics"
> [4] "package:grDevices" "package:utils"     "package:datasets"
> [7] "package:methods"   "Autoloads"         "package:base"
> > objects(2)
> [1] "a"
> 
> *** NOTES:
> 
> 
>      1.  This gives a likely wrong answer with a warning if "a" exists in .GlobalEnv, and leaves "Dat" (NOT "dat") attached upon exit.
> 
> 
> 
>      2.  A stray "detach()" [not shown here] detached "package:stats".  oops.
> 
> 
> *** Using "on.exit" fixes the problem with failure to detach but not the likely wrong answer:
> 
> 
> detach()
> search()
> eval.w.attachStillWrong <- function(x, dat){
>  attach(dat)
>  on.exit(detach(dat))
>  X <- x
>  X
> }
> The following object is masked _by_ .GlobalEnv:
> 
>    a
> 
> [1] 1.570796
> > eval.w.attachStillWrong(b/2, dat)
> The following object is masked _by_ .GlobalEnv:
> 
>    a
> 
> Error in eval.w.attachStillWrong(b/2, dat) : object 'b' not found
> > search()
> [1] ".GlobalEnv"        "package:grDevices" "package:utils"
> [4] "package:datasets"  "package:methods"   "Autoloads"
> [7] "package:base"
> 
> 
>      Thanks again to Peter and David.  Spencer
> 
>> Peter D.
>> 
>> 
>> 
>>> -- 
>>> David.
>>> 
>>> 
>>>> eval.w.with(a/2, dat) # Error ... 'a' not found
>>>> 
>>>> 
>>>> Thanks, Spencer Graves
>>>> 
>>>> 	[[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> David Winsemius
>>> Alameda, CA, USA
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From sarah.goslee at gmail.com  Fri May  6 21:47:44 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 6 May 2016 15:47:44 -0400
Subject: [R] Help needed with successfully downloading and opening
 Agricolae package
In-Reply-To: <96C3B1CA-BAD7-4129-B20A-890F2D28D934@ufl.edu>
References: <96C3B1CA-BAD7-4129-B20A-890F2D28D934@ufl.edu>
Message-ID: <CAM_vjukT439quv9DUiD+p0Ab5MET6GANmOsjuBJvOKZEaoD5CQ@mail.gmail.com>

This is a plain-text email list, so your red doesn't show up, but
since the error message said that the installer couldn't find the sp
package, I'd start by installing that.

Sarah

On Fri, May 6, 2016 at 12:35 PM, Phillips,Douglas A <dal64372 at ufl.edu> wrote:
> Hi, I just downloaded the Agricolae package and tried to access it using the commands listed below (and received the error messages in red).  Any suggestions on resolving these errors?
>
> Thanks for your assistance.
>
> Doug
>
>
>
>> install.packages("agricolae")
>   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
>                                  Dload  Upload   Total   Spent    Left  Speed
>   0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100  896k  100  896k    0     0   900k      0 --:--:-- --:--:-- --:--:--  900k
>
> The downloaded binary packages are in
> /var/folders/qn/8tc0v1m971d361gv0mwsmxj80000gn/T//RtmpYMZ97k/downloaded_packages
>>
>>
>> library(agricolae)
> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
>   there is no package called ?sp?
> Error: package or namespace load failed for ?agricolae?
>
>         [[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri May  6 22:33:55 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 06 May 2016 13:33:55 -0700
Subject: [R] Help needed with successfully downloading and opening
	Agricolae package
In-Reply-To: <CAM_vjukT439quv9DUiD+p0Ab5MET6GANmOsjuBJvOKZEaoD5CQ@mail.gmail.com>
References: <96C3B1CA-BAD7-4129-B20A-890F2D28D934@ufl.edu>
	<CAM_vjukT439quv9DUiD+p0Ab5MET6GANmOsjuBJvOKZEaoD5CQ@mail.gmail.com>
Message-ID: <448DB0A8-E598-4747-A432-124F367BE1D5@dcn.davis.ca.us>

I am puzzled why the original install.packages call did not also download the sp package, since the default argument dependencies = NA should have triggered installation of imports including spDep, which should in turn have installed the dependencies including the sp package. Anyone have a theory? 
-- 
Sent from my phone. Please excuse my brevity.

On May 6, 2016 12:47:44 PM PDT, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>This is a plain-text email list, so your red doesn't show up, but
>since the error message said that the installer couldn't find the sp
>package, I'd start by installing that.
>
>Sarah
>
>On Fri, May 6, 2016 at 12:35 PM, Phillips,Douglas A <dal64372 at ufl.edu>
>wrote:
>> Hi, I just downloaded the Agricolae package and tried to access it
>using the commands listed below (and received the error messages in
>red).  Any suggestions on resolving these errors?
>>
>> Thanks for your assistance.
>>
>> Doug
>>
>>
>>
>>> install.packages("agricolae")
>>   % Total    % Received % Xferd  Average Speed   Time    Time    
>Time  Current
>>                                  Dload  Upload   Total   Spent   
>Left  Speed
>>   0     0    0     0    0     0      0      0 --:--:-- --:--:--
>--:--:--     0  0     0    0     0    0     0      0      0 --:--:--
>--:--:-- --:--:--     0100  896k  100  896k    0     0   900k      0
>--:--:-- --:--:-- --:--:--  900k
>>
>> The downloaded binary packages are in
>>
>/var/folders/qn/8tc0v1m971d361gv0mwsmxj80000gn/T//RtmpYMZ97k/downloaded_packages
>>>
>>>
>>> library(agricolae)
>> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck =
>vI[[i]]) :
>>   there is no package called ?sp?
>> Error: package or namespace load failed for ?agricolae?
>>
>>         [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Fri May  6 22:41:34 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 6 May 2016 16:41:34 -0400
Subject: [R] Help needed with successfully downloading and opening
 Agricolae package
In-Reply-To: <448DB0A8-E598-4747-A432-124F367BE1D5@dcn.davis.ca.us>
References: <96C3B1CA-BAD7-4129-B20A-890F2D28D934@ufl.edu>
	<CAM_vjukT439quv9DUiD+p0Ab5MET6GANmOsjuBJvOKZEaoD5CQ@mail.gmail.com>
	<448DB0A8-E598-4747-A432-124F367BE1D5@dcn.davis.ca.us>
Message-ID: <CAM_vjumHXXrdiNHeTHzP8XtrtAstJ3rGOd3Y9JAnu+eSbC+BBw@mail.gmail.com>

On Fri, May 6, 2016 at 4:33 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> I am puzzled why the original install.packages call did not also download
> the sp package, since the default argument dependencies = NA should have
> triggered installation of imports including spDep, which should in turn have
> installed the dependencies including the sp package. Anyone have a theory?

Any hypothesis would require more information, sessionInfo() at a very minimum.


> --
> Sent from my phone. Please excuse my brevity.
>
> On May 6, 2016 12:47:44 PM PDT, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>>
>> This is a plain-text email list, so your red doesn't show up, but
>> since the error message said that the installer couldn't find the sp
>> package, I'd start by installing that.
>>
>> Sarah
>>
>> On Fri, May 6, 2016 at 12:35 PM, Phillips,Douglas A <dal64372 at ufl.edu>
>> wrote:
>>>
>>>  Hi, I just downloaded the Agricolae package and tried to access it using
>>> the commands listed below (and received the error messages in red).  Any
>>> suggestions on resolving these errors?
>>>
>>>  Thanks for your assistance.
>>>
>>>  Doug
>>>
>>>
>>>
>>>>  install.packages("agricolae")
>>>
>>>    % Total    % Received % Xferd  Average Speed   Time    Time     Time
>>> Current
>>>                                   Dload
>>>  Upload   Total   Spent    Left  Speed
>>>    0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--
>>> 0  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--
>>> 0100  896k  100  896k    0     0   900k      0 --:--:-- --:--:-- --:--:--
>>> 900k
>>>
>>>  The downloaded binary packages are in
>>>
>>> /var/folders/qn/8tc0v1m971d361gv0mwsmxj80000gn/T//RtmpYMZ97k/downloaded_packages
>>>>
>>>>
>>>>
>>>>  library(agricolae)
>>>
>>>  Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck =
>>> vI[[i]]) :
>>>    there is no package called ?sp?
>>>  Error: package or namespace load failed for ?agricolae?
>>>
>>>          [[alternative HTML version deleted]]
>>
>>


From lid.zigh at gmail.com  Fri May  6 23:12:33 2016
From: lid.zigh at gmail.com (Lida Zeighami)
Date: Fri, 6 May 2016 16:12:33 -0500
Subject: [R] find high correlated variables in a big matrix
In-Reply-To: <CAMqbV1B7toZ5E7Vpd6sJMwh4CvWHncdnrPzK1D6k8FQFqmUXaA@mail.gmail.com>
References: <CAMqbV1CD+Faty1PY3Z7N=NUpjSpRZ+BNQLw+CJVNsRzCL+Dpgg@mail.gmail.com>
	<CAMqbV1BVXKHt7B72UVO-HMQbqZyziogMx7JEih-TLyZ6jydC-Q@mail.gmail.com>
	<CAMqbV1B38tTDVXEkdKOgGjLf1TMyU0Cq1YaL=uLSfXM7WYkSbA@mail.gmail.com>
	<CAMqbV1Aoa4YxqffpmSG1rh3N4XwG-kTfqOanc=qiffw2+riFmw@mail.gmail.com>
	<CAMqbV1B40YOU84mSVBp=u8NEdtewkt1WBW2h8yLDYU+0MYQ8aw@mail.gmail.com>
	<CAMqbV1B7toZ5E7Vpd6sJMwh4CvWHncdnrPzK1D6k8FQFqmUXaA@mail.gmail.com>
Message-ID: <CAMqbV1CrhBAksjxE-UC1fyz7yKxZyc9DiWVfvwbi=rSTCwCb-w@mail.gmail.com>

Hi there,

Is there any way to find out high correlated variables among a big matrix?
for example I have a matrix called data= 2000*5000 and I need to find the
high correlated variables between the variables in the columns! (Need 100
high correlated variables from 5000 variables in column)

I could calculate the correlation matrix and pick the high correlated ones
but my problem is, I just can pick pairs of variables with high correlation
and may be we have low correlation across the pairs! Means, in my 100*100
correlation matrix, there are some pairs with low correlation and I
couldn't find the 100 variables which they all have high correlation
together!!!
Would you please ley me know if there is any way?

Thanks

	[[alternative HTML version deleted]]


From clint at ecy.wa.gov  Fri May  6 23:25:46 2016
From: clint at ecy.wa.gov (Clint Bowman)
Date: Fri, 6 May 2016 14:25:46 -0700 (PDT)
Subject: [R] find high correlated variables in a big matrix
In-Reply-To: <CAMqbV1CrhBAksjxE-UC1fyz7yKxZyc9DiWVfvwbi=rSTCwCb-w@mail.gmail.com>
References: <CAMqbV1CD+Faty1PY3Z7N=NUpjSpRZ+BNQLw+CJVNsRzCL+Dpgg@mail.gmail.com>
	<CAMqbV1BVXKHt7B72UVO-HMQbqZyziogMx7JEih-TLyZ6jydC-Q@mail.gmail.com>
	<CAMqbV1B38tTDVXEkdKOgGjLf1TMyU0Cq1YaL=uLSfXM7WYkSbA@mail.gmail.com>
	<CAMqbV1Aoa4YxqffpmSG1rh3N4XwG-kTfqOanc=qiffw2+riFmw@mail.gmail.com>
	<CAMqbV1B40YOU84mSVBp=u8NEdtewkt1WBW2h8yLDYU+0MYQ8aw@mail.gmail.com>
	<CAMqbV1B7toZ5E7Vpd6sJMwh4CvWHncdnrPzK1D6k8FQFqmUXaA@mail.gmail.com>
	<CAMqbV1CrhBAksjxE-UC1fyz7yKxZyc9DiWVfvwbi=rSTCwCb-w@mail.gmail.com>
Message-ID: <alpine.LRH.2.20.1605061424570.6311@aeolus.ecy.wa.gov>

Are you rying to find clusters of variables according to some distance 
metric?

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Fri, 6 May 2016, Lida Zeighami wrote:

> Hi there,
>
> Is there any way to find out high correlated variables among a big matrix?
> for example I have a matrix called data= 2000*5000 and I need to find the
> high correlated variables between the variables in the columns! (Need 100
> high correlated variables from 5000 variables in column)
>
> I could calculate the correlation matrix and pick the high correlated ones
> but my problem is, I just can pick pairs of variables with high correlation
> and may be we have low correlation across the pairs! Means, in my 100*100
> correlation matrix, there are some pairs with low correlation and I
> couldn't find the 100 variables which they all have high correlation
> together!!!
> Would you please ley me know if there is any way?
>
> Thanks
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Fri May  6 23:32:20 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 6 May 2016 14:32:20 -0700
Subject: [R] find high correlated variables in a big matrix
In-Reply-To: <CAMqbV1CrhBAksjxE-UC1fyz7yKxZyc9DiWVfvwbi=rSTCwCb-w@mail.gmail.com>
References: <CAMqbV1CD+Faty1PY3Z7N=NUpjSpRZ+BNQLw+CJVNsRzCL+Dpgg@mail.gmail.com>
	<CAMqbV1BVXKHt7B72UVO-HMQbqZyziogMx7JEih-TLyZ6jydC-Q@mail.gmail.com>
	<CAMqbV1B38tTDVXEkdKOgGjLf1TMyU0Cq1YaL=uLSfXM7WYkSbA@mail.gmail.com>
	<CAMqbV1Aoa4YxqffpmSG1rh3N4XwG-kTfqOanc=qiffw2+riFmw@mail.gmail.com>
	<CAMqbV1B40YOU84mSVBp=u8NEdtewkt1WBW2h8yLDYU+0MYQ8aw@mail.gmail.com>
	<CAMqbV1B7toZ5E7Vpd6sJMwh4CvWHncdnrPzK1D6k8FQFqmUXaA@mail.gmail.com>
	<CAMqbV1CrhBAksjxE-UC1fyz7yKxZyc9DiWVfvwbi=rSTCwCb-w@mail.gmail.com>
Message-ID: <41931FF7-BD24-43E4-A436-F2FA73913FE2@comcast.net>


> On May 6, 2016, at 2:12 PM, Lida Zeighami <lid.zigh at gmail.com> wrote:
> 
> Hi there,
> 
> Is there any way to find out high correlated variables among a big matrix?
> for example I have a matrix called data= 2000*5000 and I need to find the
> high correlated variables between the variables in the columns! (Need 100
> high correlated variables from 5000 variables in column)
> 
> I could calculate the correlation matrix and pick the high correlated ones
> but my problem is, I just can pick pairs of variables with high correlation
> and may be we have low correlation across the pairs! Means, in my 100*100
> correlation matrix, there are some pairs with low correlation and I
> couldn't find the 100 variables which they all have high correlation
> together!!!
> Would you please ley me know if there is any way?

The rcorr function in Hmisc will return a list whose first element is a correlation matrix

> base <- rnorm(100)

> test <- matrix(base+0.2*rnorm(300), 100)

> rcorr(test)[[1]]
          [,1]      [,2]      [,3]
[1,] 1.0000000 0.9631220 0.9721688
[2,] 0.9631220 1.0000000 0.9666564
[3,] 0.9721688 0.9666564 1.0000000

You can use which to to find the locations meeting a criterion (or two):

> mycorr <- .Last.value

> which(mycorr > 0.97 & mycorr != 1, arr.ind=TRUE)
     row col
[1,]   3   1
[2,]   1   3



-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Fri May  6 23:42:28 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 6 May 2016 14:42:28 -0700
Subject: [R] Help needed with successfully downloading and opening
	Agricolae package
In-Reply-To: <CAM_vjumHXXrdiNHeTHzP8XtrtAstJ3rGOd3Y9JAnu+eSbC+BBw@mail.gmail.com>
References: <96C3B1CA-BAD7-4129-B20A-890F2D28D934@ufl.edu>
	<CAM_vjukT439quv9DUiD+p0Ab5MET6GANmOsjuBJvOKZEaoD5CQ@mail.gmail.com>
	<448DB0A8-E598-4747-A432-124F367BE1D5@dcn.davis.ca.us>
	<CAM_vjumHXXrdiNHeTHzP8XtrtAstJ3rGOd3Y9JAnu+eSbC+BBw@mail.gmail.com>
Message-ID: <35FE589A-1D6A-40C2-B404-77E4A2FC9C2D@comcast.net>


> On May 6, 2016, at 1:41 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> 
> On Fri, May 6, 2016 at 4:33 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>> I am puzzled why the original install.packages call did not also download
>> the sp package, since the default argument dependencies = NA should have
>> triggered installation of imports including spDep, which should in turn have
>> installed the dependencies including the sp package. Anyone have a theory?

I think you need to set dependencies=TRUE to make the checks recursive.

-- 
David.

> 
> Any hypothesis would require more information, sessionInfo() at a very minimum.
> 
> 
>> --
>> Sent from my phone. Please excuse my brevity.
>> 
>> On May 6, 2016 12:47:44 PM PDT, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>>> 
>>> This is a plain-text email list, so your red doesn't show up, but
>>> since the error message said that the installer couldn't find the sp
>>> package, I'd start by installing that.
>>> 
>>> Sarah
>>> 
>>> On Fri, May 6, 2016 at 12:35 PM, Phillips,Douglas A <dal64372 at ufl.edu>
>>> wrote:
>>>> 
>>>> Hi, I just downloaded the Agricolae package and tried to access it using
>>>> the commands listed below (and received the error messages in red).  Any
>>>> suggestions on resolving these errors?
>>>> 
>>>> Thanks for your assistance.
>>>> 
>>>> Doug
>>>> 
>>>> 
>>>> 
>>>>> install.packages("agricolae")
>>>> 
>>>>   % Total    % Received % Xferd  Average Speed   Time    Time     Time
>>>> Current
>>>>                                  Dload
>>>> Upload   Total   Spent    Left  Speed
>>>>   0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--
>>>> 0  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--
>>>> 0100  896k  100  896k    0     0   900k      0 --:--:-- --:--:-- --:--:--
>>>> 900k
>>>> 
>>>> The downloaded binary packages are in
>>>> 
>>>> /var/folders/qn/8tc0v1m971d361gv0mwsmxj80000gn/T//RtmpYMZ97k/downloaded_packages
>>>>> 
>>>>> 
>>>>> 
>>>>> library(agricolae)
>>>> 
>>>> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck =
>>>> vI[[i]]) :
>>>>   there is no package called ?sp?
>>>> Error: package or namespace load failed for ?agricolae?
>>>> 
>>>>         [[alternative HTML version deleted]]
>>> 
>>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dal64372 at ufl.edu  Sat May  7 00:02:37 2016
From: dal64372 at ufl.edu (Phillips,Douglas A)
Date: Fri, 6 May 2016 22:02:37 +0000
Subject: [R] Help needed with successfully downloading and
	opening	Agricolae package
In-Reply-To: <35FE589A-1D6A-40C2-B404-77E4A2FC9C2D@comcast.net>
References: <96C3B1CA-BAD7-4129-B20A-890F2D28D934@ufl.edu>
	<CAM_vjukT439quv9DUiD+p0Ab5MET6GANmOsjuBJvOKZEaoD5CQ@mail.gmail.com>
	<448DB0A8-E598-4747-A432-124F367BE1D5@dcn.davis.ca.us>
	<CAM_vjumHXXrdiNHeTHzP8XtrtAstJ3rGOd3Y9JAnu+eSbC+BBw@mail.gmail.com>
	<35FE589A-1D6A-40C2-B404-77E4A2FC9C2D@comcast.net>
Message-ID: <495B54F9-8299-49EE-8165-A19F5BB09528@ufl.edu>

Thanks Sarah, downloaded the sp package separately and that resolved the error. 

> On May 6, 2016, at 5:43 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On May 6, 2016, at 1:41 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>> 
>> On Fri, May 6, 2016 at 4:33 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>> I am puzzled why the original install.packages call did not also download
>>> the sp package, since the default argument dependencies = NA should have
>>> triggered installation of imports including spDep, which should in turn have
>>> installed the dependencies including the sp package. Anyone have a theory?
> 
> I think you need to set dependencies=TRUE to make the checks recursive.
> 
> -- 
> David.
> 
>> 
>> Any hypothesis would require more information, sessionInfo() at a very minimum.
>> 
>> 
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>> 
>>>> On May 6, 2016 12:47:44 PM PDT, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>>>> 
>>>> This is a plain-text email list, so your red doesn't show up, but
>>>> since the error message said that the installer couldn't find the sp
>>>> package, I'd start by installing that.
>>>> 
>>>> Sarah
>>>> 
>>>> On Fri, May 6, 2016 at 12:35 PM, Phillips,Douglas A <dal64372 at ufl.edu>
>>>> wrote:
>>>>> 
>>>>> Hi, I just downloaded the Agricolae package and tried to access it using
>>>>> the commands listed below (and received the error messages in red).  Any
>>>>> suggestions on resolving these errors?
>>>>> 
>>>>> Thanks for your assistance.
>>>>> 
>>>>> Doug
>>>>> 
>>>>> 
>>>>> 
>>>>>> install.packages("agricolae")
>>>>> 
>>>>>  % Total    % Received % Xferd  Average Speed   Time    Time     Time
>>>>> Current
>>>>>                                 Dload
>>>>> Upload   Total   Spent    Left  Speed
>>>>>  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--
>>>>> 0  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--
>>>>> 0100  896k  100  896k    0     0   900k      0 --:--:-- --:--:-- --:--:--
>>>>> 900k
>>>>> 
>>>>> The downloaded binary packages are in
>>>>> 
>>>>> /var/folders/qn/8tc0v1m971d361gv0mwsmxj80000gn/T//RtmpYMZ97k/downloaded_packages
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> library(agricolae)
>>>>> 
>>>>> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck =
>>>>> vI[[i]]) :
>>>>>  there is no package called ?sp?
>>>>> Error: package or namespace load failed for ?agricolae?
>>>>> 
>>>>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From h.wickham at gmail.com  Sat May  7 00:08:54 2016
From: h.wickham at gmail.com (Hadley Wickham)
Date: Fri, 6 May 2016 17:08:54 -0500
Subject: [R] with vs. attach
In-Reply-To: <FAC95CBE-8E91-4ED3-B3AE-DF6568354D7B@comcast.net>
References: <901fd028-5e60-cf67-906d-c29e43d8762b@effectivedefense.org>
	<4808B356-E233-4859-A15E-745D26D4B85C@comcast.net>
	<CD4AB490-E960-44E9-BAC0-D30E96518922@gmail.com>
	<02d73d7c-2699-dc24-8552-048491dc21fa@effectivedefense.org>
	<FAC95CBE-8E91-4ED3-B3AE-DF6568354D7B@comcast.net>
Message-ID: <CABdHhvELpD3+JA2TkFz1OfTXSy5HvWRZJ4d0m_03hMnrtFeboA@mail.gmail.com>

You may want to read http://rpubs.com/hadley/157957, which captures my
latest thinking (and tooling) around this problem. Feedback is much
appreciated.

Hadley

On Fri, May 6, 2016 at 2:14 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On May 6, 2016, at 5:47 AM, Spencer Graves <spencer.graves at effectivedefense.org> wrote:
>>
>>
>>
>> On 5/6/2016 6:46 AM, peter dalgaard wrote:
>>> On 06 May 2016, at 02:43 , David Winsemius <dwinsemius at comcast.net> wrote:
>>>
>>>>> On May 5, 2016, at 5:12 PM, Spencer Graves <spencer.graves at effectivedefense.org> wrote:
>>>>>
>>>>> I want a function to evaluate one argument
>>>>> in the environment of a data.frame supplied
>>>>> as another argument.  "attach" works for
>>>>> this, but "with" does not.  Is there a way
>>>>> to make "with" work?  I'd rather not attach
>>>>> the data.frame.
>>>>>
>>>>>
>>>>> With the following two functions "eval.w.attach"
>>>>> works but "eval.w.with" fails:
>>>>>
>>>>>
>>>>> dat <- data.frame(a=1:2)
>>>>> eval.w.attach <- function(x, dat){
>>>>>  attach(dat)
>>>>>  X <- x
>>>>>  detach()
>>>>>  X
>>>>> }
>>>>>
>>>>> eval.w.with <- function(x, dat){
>>>>>  with(dat, x)
>>>>> }
>>>>>
>>>>> eval.w.attach(a/2, dat) # returns c(.5, 1)
>>>> How about using eval( substitute( ...))?
>>>>
>>>> eval.w.sub <- function(expr, datt){
>>>>   eval( substitute(expr), env=datt)
>>>>                         }
>>>> eval.w.sub(a/2, dat)
>>>> #[1] 0.5 1.0
>>>>
>>>>
>>> Actually, I think a better overall strategy is to say that if you want to pass an expression to a function, then pass an expression object (or a call object or maybe a formula object).
>>>
>>> Once you figure out _how_ your eval.w.attach works (sort of), you'll get the creeps:
>>>
>>> Lazy evaluation causes the argument x to be evaluated after the attach(), hence the evaluation environment of an actual argument is being temporarily modified from inside a function.
>>>
>>> Apart from upsetting computer science purists, there could be hidden problems: One major issue is that  values in "dat" could be masked by values in the global environment, another issue is that an error in evaluating the expression will leave dat attached. So at a minimum, you need to recode using on.exit() magic.
>>>
>>> So my preferences go along these lines:
>>>
>>>> dat <- data.frame(a=1:2)
>>>> eval.expression <- function(e, dat) eval(e, dat)
>>>> eval.expression(quote(a/2), dat)
>>> [1] 0.5 1.0
>>>> eval.expression(expression(a/2), dat)
>>> [1] 0.5 1.0
>>>
>>>> eval.formula <- function(f, dat) eval(f[[2]], dat)
>>>> eval.formula(~a/2, dat)
>>> [1] 0.5 1.0
>>
>> Hi, Peter:
>>
>>
>>      I don't like eval.expression or eval.formula, because they don't automatically accept what I naively thought should work and require more knowledge of the user.  What about David's eval.w.sub:
>>
>>
>> a <- pi
>> dat <- data.frame(a=1:2)
>> eval.w.sub <- function(a, Dat){
>>  eval( substitute(a), env=Dat)
>> }
>> > eval.w.sub(a/2, dat)
>> [1] 0.5 1.0
>
> I liked eval.expression and tested it with a bquote(...) argument to see if that would succeed. It did, but it didn't return what you wanted for `a/2`, so I tried seeing if a "double eval wuold deliver both yours and my desired results:
>
>  eval.w.sub <- function(a, Dat){
>   eval( eval(substitute(a),Dat), env=Dat)
>  }
> x=2
>  eval.w.sub( a/2, dat)
> [1] 0.5 1.0
>  eval.w.sub( bquote(2*a*.(x) ), dat)
> [1] 4 8
>
> We are here retracing the path the Hadley took in some of his ggplot2 design decsions. Unfortunately for me those NSE rules often left me confused about what should and shouldn't be 'quoted' in the as-character sense and what should be quote()-ed or "unquoted" in the bquote() sense.
> --
>
>>
>>
>>
>>      This produces what's desired in a way that seems simpler to me.
>>
>>
>>      By the way, I really appreciate Peter's insightful comments:
>>
>>
>> eval.w.attachOops <- function(x, Dat){
>>  attach(Dat)
>>  X <- x
>>  detach()
>>  X
>> }
>> > eval.w.attachOops(a/2, dat)
>> The following object is masked _by_ .GlobalEnv:
>>
>>    a
>>
>> [1] 1.570796
>> > eval.w.attachOops(b/2, dat)
>> The following object is masked _by_ .GlobalEnv:
>>
>>    a
>>
>> Error in eval.w.attachOops(b/2, dat) : object 'b' not found
>> > search()
>> [1] ".GlobalEnv"        "Dat"               "package:graphics"
>> [4] "package:grDevices" "package:utils"     "package:datasets"
>> [7] "package:methods"   "Autoloads"         "package:base"
>> > objects(2)
>> [1] "a"
>>
>> *** NOTES:
>>
>>
>>      1.  This gives a likely wrong answer with a warning if "a" exists in .GlobalEnv, and leaves "Dat" (NOT "dat") attached upon exit.
>>
>>
>>
>>      2.  A stray "detach()" [not shown here] detached "package:stats".  oops.
>>
>>
>> *** Using "on.exit" fixes the problem with failure to detach but not the likely wrong answer:
>>
>>
>> detach()
>> search()
>> eval.w.attachStillWrong <- function(x, dat){
>>  attach(dat)
>>  on.exit(detach(dat))
>>  X <- x
>>  X
>> }
>> The following object is masked _by_ .GlobalEnv:
>>
>>    a
>>
>> [1] 1.570796
>> > eval.w.attachStillWrong(b/2, dat)
>> The following object is masked _by_ .GlobalEnv:
>>
>>    a
>>
>> Error in eval.w.attachStillWrong(b/2, dat) : object 'b' not found
>> > search()
>> [1] ".GlobalEnv"        "package:grDevices" "package:utils"
>> [4] "package:datasets"  "package:methods"   "Autoloads"
>> [7] "package:base"
>>
>>
>>      Thanks again to Peter and David.  Spencer
>>
>>> Peter D.
>>>
>>>
>>>
>>>> --
>>>> David.
>>>>
>>>>
>>>>> eval.w.with(a/2, dat) # Error ... 'a' not found
>>>>>
>>>>>
>>>>> Thanks, Spencer Graves
>>>>>
>>>>>    [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> David Winsemius
>>>> Alameda, CA, USA
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://hadley.nz


From sewashm at gmail.com  Sat May  7 01:11:04 2016
From: sewashm at gmail.com (Ashta)
Date: Fri, 6 May 2016 18:11:04 -0500
Subject: [R] month and output
Message-ID: <CADDFq30xBMGdJ1hvm_a=iohrG6KWdM6ddU3fd98-ue7cEDDWUw@mail.gmail.com>

Hi all,

I am trying to ge get the next month of the year.

today <- Sys.Date()
xx<- format(today, format="%B%Y")

I got  "May2016",  but I want  Jun2016. How do I do that?

My other question is that, I read a data  and do some analysis  and I
want to send all the results of the analysis to a pdf file

Example
x5 <- runif(15, 5.0, 7.5)
x5


I tried this one

 pdf(file=" test.pdf")
 x5
dev.off()

I found the file is empty. I would appreciate if you help me out.

Thanks in advance


From sabasehrish at yahoo.com  Sat May  7 01:15:09 2016
From: sabasehrish at yahoo.com (Saba Sehrish)
Date: Fri, 6 May 2016 23:15:09 +0000 (UTC)
Subject: [R] replacing values of rows with identical row names in two
	dataframes
In-Reply-To: <1341444334.82975.1462576283168.JavaMail.yahoo@mail.yahoo.com>
References: <1341444334.82975.1462576283168.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1871012002.68309.1462576509880.JavaMail.yahoo@mail.yahoo.com>



Hi 

I have two dataframes(df1, df2) with equal number of columns (1566) but lesser rows in df2 (2772 in df1 and 40 in df2). Row names are 
identical in both dataframes (date). I want to replace NAs of df1 with the values of df2 for all those rows having identical row names (date) but 
without affecting already existing values in those rows of df1. 

Please see below: 

df1: 
date     11A  11A   21B   3CC   3CC 
20040101  100   150   NA   NA   140 
20040115   200   NA   200   NA   NA 
20040131   NA   165   180   190   190 
20040205   NA   NA   NA   NA   NA 
20040228   NA   NA   NA   NA   NA 
20040301  150   155   170   150   160 
20040315   NA   NA   180   190   200 
20040331   NA   NA   NA   175   180 

df2: 
date     11A  11A   21B   3CC   3CC 
20040131   170   NA   NA   NA   NA 
20040228   140   145   165   150   155 
20040331   NA   145   160   NA   NA 

I want the resulting dataframe to be: 

df3: 
date         11A  11A   21B   3CC   3CC 
20040101      100   150   NA   NA   140 
20040115      200   NA   200   NA   NA 
20040131      170   165   180   190   190 
20040205      NA   NA   NA   NA   NA 
20040228      140   145   165   150   155 
20040301      150   155   170   150   160 
20040315      NA   NA   180   190   200 
20040331      NA   145   160   175   180 

If it is possible, I would prefer to use "for loop" and "which" function to achieve the result. 

Please guide me in this regard. 

Thanks 
Saba


From dwinsemius at comcast.net  Sat May  7 01:30:05 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 6 May 2016 16:30:05 -0700
Subject: [R] month and output
In-Reply-To: <CADDFq30xBMGdJ1hvm_a=iohrG6KWdM6ddU3fd98-ue7cEDDWUw@mail.gmail.com>
References: <CADDFq30xBMGdJ1hvm_a=iohrG6KWdM6ddU3fd98-ue7cEDDWUw@mail.gmail.com>
Message-ID: <F2D315DA-4A2B-471F-A626-5FC0F1F15BF4@comcast.net>


> On May 6, 2016, at 4:11 PM, Ashta <sewashm at gmail.com> wrote:
> 
> Hi all,
> 
> I am trying to ge get the next month of the year.
> 
> today <- Sys.Date()
> xx<- format(today, format="%B%Y")
> 
> I got  "May2016",  but I want  Jun2016. How do I do that?

today <- Sys.Date()
nextmo<- paste0( month.abb[ as.numeric(format(today, format="%m"))+1] ,
                 format(today,"%Y") )
[1] "Jun2016"

> 
> My other question is that, I read a data  and do some analysis  and I
> want to send all the results of the analysis to a pdf file
> 
> Example
> x5 <- runif(15, 5.0, 7.5)
> x5
> 
> 
> I tried this one
> 
> pdf(file=" test.pdf")
> x5
> dev.off()

pdf() opens a graphics device, so you need a function that establishes a coordinate system:

x5 <- runif(15, 5.0, 7.5)
pdf(file=" test.pdf"); 
plot(1,1,type="n")
text(1, 1, paste(round(x5, 2), collapse="\n") )
dev.off()

I doubt that this is what you really want, and suspect you really need to be studying the capabilities supported by the knitr package. If I'm wrong about that and you want a system that supports drawing and text on a blank page, then first study:

> library(grid)
> help(pac=grid)

If you choose that route then the text "R Graphics" by Paul Murrell will be indispensable.

-- 
David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.ca.us  Sat May  7 01:30:41 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 06 May 2016 16:30:41 -0700
Subject: [R] replacing values of rows with identical row names in
	two	dataframes
In-Reply-To: <1871012002.68309.1462576509880.JavaMail.yahoo@mail.yahoo.com>
References: <1341444334.82975.1462576283168.JavaMail.yahoo@mail.yahoo.com>
	<1871012002.68309.1462576509880.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <23E13C6E-62D2-4BDE-8C17-D67E94A7AFAC@dcn.davis.ca.us>

Why would you want to use a for loop?  Is this homework? 
-- 
Sent from my phone. Please excuse my brevity.

On May 6, 2016 4:15:09 PM PDT, Saba Sehrish via R-help <r-help at r-project.org> wrote:
>
>
>Hi 
>
>I have two dataframes(df1, df2) with equal number of columns (1566) but
>lesser rows in df2 (2772 in df1 and 40 in df2). Row names are 
>identical in both dataframes (date). I want to replace NAs of df1 with
>the values of df2 for all those rows having identical row names (date)
>but 
>without affecting already existing values in those rows of df1. 
>
>Please see below: 
>
>df1: 
>date     11A  11A   21B   3CC   3CC 
>20040101  100   150   NA   NA   140 
>20040115   200   NA   200   NA   NA 
>20040131   NA   165   180   190   190 
>20040205   NA   NA   NA   NA   NA 
>20040228   NA   NA   NA   NA   NA 
>20040301  150   155   170   150   160 
>20040315   NA   NA   180   190   200 
>20040331   NA   NA   NA   175   180 
>
>df2: 
>date     11A  11A   21B   3CC   3CC 
>20040131   170   NA   NA   NA   NA 
>20040228   140   145   165   150   155 
>20040331   NA   145   160   NA   NA 
>
>I want the resulting dataframe to be: 
>
>df3: 
>date         11A  11A   21B   3CC   3CC 
>20040101      100   150   NA   NA   140 
>20040115      200   NA   200   NA   NA 
>20040131      170   165   180   190   190 
>20040205      NA   NA   NA   NA   NA 
>20040228      140   145   165   150   155 
>20040301      150   155   170   150   160 
>20040315      NA   NA   180   190   200 
>20040331      NA   145   160   175   180 
>
>If it is possible, I would prefer to use "for loop" and "which"
>function to achieve the result. 
>
>Please guide me in this regard. 
>
>Thanks 
>Saba
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ddalthorp at usgs.gov  Sat May  7 01:35:24 2016
From: ddalthorp at usgs.gov (Dalthorp, Daniel)
Date: Fri, 6 May 2016 16:35:24 -0700
Subject: [R] Fwd:  tcltk: click and return table cell index
In-Reply-To: <CAJeYpE9E_BK75=ZS8+5Snaz5u2EyZHQDbvmZ13b+fVgu-gkTtg@mail.gmail.com>
References: <CAJeYpE_G=eTLTmOxtOTFhUNQ3LJusrGbwecpu1yXGBg3T47S4g@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F8B8A0@FHSDB2D11-2.csu.mcmaster.ca>
	<CAJeYpE9E_BK75=ZS8+5Snaz5u2EyZHQDbvmZ13b+fVgu-gkTtg@mail.gmail.com>
Message-ID: <CAJeYpE9KuY7cDbr+4KhT5fGX2T9YCFUxYGGxcNVf7YYdC5cSBw@mail.gmail.com>

Thanks, John.

The trouble with that solution is that it gives the index for where the
cursor was before clicking rather than the cell that was clicked. The
solution is that the <Button-1> binding gives the x, y pixel coordinates of
the click to the callback, and those just need to be translated to cell
index via tkindex ( My (almost) solution gives the pixel coordinates of the
mouse click. There is a function that converts the coords to cell index,
but I was having trouble figuring out the format of parameters, but the
following works:

tcl(table1, "index", as.tclObj(paste0("@",x, ",", y)))

I.e., to retrieve the index of the cell that is clicked on:

# create table
tt<-tktoplevel()
tclRequire("Tktable")
table1<-tkwidget(tt,"table",rows=3,cols=3)
tkgrid(table1)

tkbind(table1, "<Button-1>", function(x, y){
  cellIndex<-tcl(table1, "index", as.tclObj(paste0("@",x, ",", y)))
  print(tclvalue(cellIndex))
})

Thanks again!

-Dan


On Sat, Apr 30, 2016 at 6:43 AM, Fox, John <jfox at mcmaster.ca> wrote:

> Dear Daniel,
>
> Try
>
> tkbind(table1, "<Button-1>", function(){
>      res <- try(tclvalue(tkindex(table1, "active")), silent=TRUE)
>    if (inherits(res, "try-error")) print (NULL)
>    else print(res)
> })
>
> I put in the calls to print() so that you could see how it works.
>
> I hope this helps,
>  John
>
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> Web: socserv.mcmaster.ca/jfox
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Dalthorp,
> > Daniel
> > Sent: April 29, 2016 1:42 PM
> > To: r-help at R-project.org (r-help at r-project.org) <r-help at r-project.org>
> > Subject: [R] tcltk: click and return table cell index
> >
> > I'm struggling mightily with what should be a simple task...when a user
> clicks
> > on a cell in a tcltk table widget, I need to know which cell was clicked.
> >
> > One idea that gives a cryptic error:
> > tkbind(table1, "<Button-1>", function(x, y){
> >   tcl(table1, "index", x, y)
> > }
> >
> > # x, y give pixel coordinates; "index" should give cell coordinates, but
> format
> > must be correct
> >
> > I get an error message:
> >
> > wrong # args: should be ".25.1 index <index> ?row|col?".
> >
> > To which I respond, "Yes, I know I have the format wrong, but how can I
> make
> > sense of THAT?"
> >
> > Does anyone know a simple fix?
> >
> > Much appreciated!
> >
> > -Dan
> >
> > --
> > Dan Dalthorp, PhD
> > USGS Forest and Rangeland Ecosystem Science Center Forest Sciences Lab,
> Rm
> > 189
> > 3200 SW Jefferson Way
> > Corvallis, OR 97331
> > ph: 541-750-0953
> > ddalthorp at usgs.gov
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
Dan Dalthorp, PhD
USGS Forest and Rangeland Ecosystem Science Center
Forest Sciences Lab, Rm 189
3200 SW Jefferson Way
Corvallis, OR 97331
ph: 541-750-0953
ddalthorp at usgs.gov




-- 
Dan Dalthorp, PhD
USGS Forest and Rangeland Ecosystem Science Center
Forest Sciences Lab, Rm 189
3200 SW Jefferson Way
Corvallis, OR 97331
ph: 541-750-0953
ddalthorp at usgs.gov

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat May  7 01:40:40 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 6 May 2016 16:40:40 -0700
Subject: [R] month and output
In-Reply-To: <F2D315DA-4A2B-471F-A626-5FC0F1F15BF4@comcast.net>
References: <CADDFq30xBMGdJ1hvm_a=iohrG6KWdM6ddU3fd98-ue7cEDDWUw@mail.gmail.com>
	<F2D315DA-4A2B-471F-A626-5FC0F1F15BF4@comcast.net>
Message-ID: <36D919EB-2191-427B-9523-13FEC021FC79@comcast.net>


> On May 6, 2016, at 4:30 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On May 6, 2016, at 4:11 PM, Ashta <sewashm at gmail.com> wrote:
>> 
>> Hi all,
>> 
>> I am trying to ge get the next month of the year.
>> 
>> today <- Sys.Date()
>> xx<- format(today, format="%B%Y")
>> 
>> I got  "May2016",  but I want  Jun2016. How do I do that?
> 
> today <- Sys.Date()
> nextmo<- paste0( month.abb[ as.numeric(format(today, format="%m"))+1] ,
>                 format(today,"%Y") )
> [1] "Jun2016"

It occurred to me that at the end of the year you would want to increment the year as well. This calculates the next month and increments the year value if needed:

 today <- as.Date("2008-12-01")
 nextmo<- paste0(m <- month.abb[(as.numeric(format(today, format="%m"))+1) %/% 12] , 
                  as.numeric( format(today,"%Y") ) + (m == "Jan") )
 nextmo
#[1] "Jan2009"
> 
>> 
>> My other question is that, I read a data  and do some analysis  and I
>> want to send all the results of the analysis to a pdf file
>> 
>> Example
>> x5 <- runif(15, 5.0, 7.5)
>> x5
>> 
>> 
>> I tried this one
>> 
>> pdf(file=" test.pdf")
>> x5
>> dev.off()
> 
> pdf() opens a graphics device, so you need a function that establishes a coordinate system:
> 
> x5 <- runif(15, 5.0, 7.5)
> pdf(file=" test.pdf"); 
> plot(1,1,type="n")
> text(1, 1, paste(round(x5, 2), collapse="\n") )
> dev.off()
> 

If you need to suppress the axes and their labels:

 pdf(file=" test.pdf"); plot(1,1, type="n", axes=FALSE, xlab="", ylab="")
 text(1, 1, paste(round(x5, 2), collapse="\n") )
 dev.off()

> I doubt that this is what you really want, and suspect you really need to be studying the capabilities supported by the knitr package. If I'm wrong about that and you want a system that supports drawing and text on a blank page, then first study:
> 
>> library(grid)
>> help(pac=grid)
> 
> If you choose that route then the text "R Graphics" by Paul Murrell will be indispensable.
> 
> -- 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Sat May  7 01:41:54 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 6 May 2016 16:41:54 -0700
Subject: [R] month and output
In-Reply-To: <CADDFq30xBMGdJ1hvm_a=iohrG6KWdM6ddU3fd98-ue7cEDDWUw@mail.gmail.com>
References: <CADDFq30xBMGdJ1hvm_a=iohrG6KWdM6ddU3fd98-ue7cEDDWUw@mail.gmail.com>
Message-ID: <CAGxFJbSQjKtUOLL2CAsHuUr3FZRNP3eR1zps6FuY9XBPXiox_Q@mail.gmail.com>

To add to what David said, maybe you want ?sink or ?capture.output  .

If you're really looking to combine your own text and R output, than
knitr is probably what you want. The RStudio ide integrates this
stuff, so you may want to look at that, too.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, May 6, 2016 at 4:11 PM, Ashta <sewashm at gmail.com> wrote:
> Hi all,
>
> I am trying to ge get the next month of the year.
>
> today <- Sys.Date()
> xx<- format(today, format="%B%Y")
>
> I got  "May2016",  but I want  Jun2016. How do I do that?
>
> My other question is that, I read a data  and do some analysis  and I
> want to send all the results of the analysis to a pdf file
>
> Example
> x5 <- runif(15, 5.0, 7.5)
> x5
>
>
> I tried this one
>
>  pdf(file=" test.pdf")
>  x5
> dev.off()
>
> I found the file is empty. I would appreciate if you help me out.
>
> Thanks in advance
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sewashm at gmail.com  Sat May  7 02:15:59 2016
From: sewashm at gmail.com (Ashta)
Date: Fri, 6 May 2016 19:15:59 -0500
Subject: [R] month and output
In-Reply-To: <36D919EB-2191-427B-9523-13FEC021FC79@comcast.net>
References: <CADDFq30xBMGdJ1hvm_a=iohrG6KWdM6ddU3fd98-ue7cEDDWUw@mail.gmail.com>
	<F2D315DA-4A2B-471F-A626-5FC0F1F15BF4@comcast.net>
	<36D919EB-2191-427B-9523-13FEC021FC79@comcast.net>
Message-ID: <CADDFq31ESRVfVogOfhv+2aLiBA4O0gRnGaFvFz7w4Lxys+obHQ@mail.gmail.com>

Thank you very much David.

So there is no general formal that works year all round.

The first one work only Jan to Nov
today <- Sys.Date()
nextmo<- paste0( month.abb[ as.numeric(format(today, format="%m"))+1] ,
                 format(today,"%Y") )
[1] "Jun2016"

The second one works only  for the last month of the year.
today <- as.Date("2008-12-01")
 nextmo<- paste0(m <- month.abb[(as.numeric(format(today,
format="%m"))+1) %/% 12] ,
                  as.numeric( format(today,"%Y") ) + (m == "Jan") )
 nextmo


Many thanks





On Fri, May 6, 2016 at 6:40 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On May 6, 2016, at 4:30 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>>
>>> On May 6, 2016, at 4:11 PM, Ashta <sewashm at gmail.com> wrote:
>>>
>>> Hi all,
>>>
>>> I am trying to ge get the next month of the year.
>>>
>>> today <- Sys.Date()
>>> xx<- format(today, format="%B%Y")
>>>
>>> I got  "May2016",  but I want  Jun2016. How do I do that?
>>
>> today <- Sys.Date()
>> nextmo<- paste0( month.abb[ as.numeric(format(today, format="%m"))+1] ,
>>                 format(today,"%Y") )
>> [1] "Jun2016"
>
> It occurred to me that at the end of the year you would want to increment the year as well. This calculates the next month and increments the year value if needed:
>
>  today <- as.Date("2008-12-01")
>  nextmo<- paste0(m <- month.abb[(as.numeric(format(today, format="%m"))+1) %/% 12] ,
>                   as.numeric( format(today,"%Y") ) + (m == "Jan") )
>  nextmo
> #[1] "Jan2009"
>>
>>>
>>> My other question is that, I read a data  and do some analysis  and I
>>> want to send all the results of the analysis to a pdf file
>>>
>>> Example
>>> x5 <- runif(15, 5.0, 7.5)
>>> x5
>>>
>>>
>>> I tried this one
>>>
>>> pdf(file=" test.pdf")
>>> x5
>>> dev.off()
>>
>> pdf() opens a graphics device, so you need a function that establishes a coordinate system:
>>
>> x5 <- runif(15, 5.0, 7.5)
>> pdf(file=" test.pdf");
>> plot(1,1,type="n")
>> text(1, 1, paste(round(x5, 2), collapse="\n") )
>> dev.off()
>>
>
> If you need to suppress the axes and their labels:
>
>  pdf(file=" test.pdf"); plot(1,1, type="n", axes=FALSE, xlab="", ylab="")
>  text(1, 1, paste(round(x5, 2), collapse="\n") )
>  dev.off()
>
>> I doubt that this is what you really want, and suspect you really need to be studying the capabilities supported by the knitr package. If I'm wrong about that and you want a system that supports drawing and text on a blank page, then first study:
>>
>>> library(grid)
>>> help(pac=grid)
>>
>> If you choose that route then the text "R Graphics" by Paul Murrell will be indispensable.
>>
>> --
>> David Winsemius
>> Alameda, CA, USA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>


From wdunlap at tibco.com  Sat May  7 02:27:13 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 6 May 2016 17:27:13 -0700
Subject: [R] month and output
In-Reply-To: <CADDFq31ESRVfVogOfhv+2aLiBA4O0gRnGaFvFz7w4Lxys+obHQ@mail.gmail.com>
References: <CADDFq30xBMGdJ1hvm_a=iohrG6KWdM6ddU3fd98-ue7cEDDWUw@mail.gmail.com>
	<F2D315DA-4A2B-471F-A626-5FC0F1F15BF4@comcast.net>
	<36D919EB-2191-427B-9523-13FEC021FC79@comcast.net>
	<CADDFq31ESRVfVogOfhv+2aLiBA4O0gRnGaFvFz7w4Lxys+obHQ@mail.gmail.com>
Message-ID: <CAF8bMcZwwHGuz6Vp9mT+5gsLg-ZvcFttvc5B7FBUTPXfbpXS9g@mail.gmail.com>

You could install and load the 'lubridate' package, which has month()
and month<-() functions so you can do the following:

> z <- as.Date(c("2015-01-29", "2016-01-29", "2016-05-07", "2016-12-25"))
> z
[1] "2015-01-29" "2016-01-29" "2016-05-07" "2016-12-25"
> month(z) <- month(z) + 1
> z
[1] NA           "2016-02-29" "2016-06-07" "2017-01-25"



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, May 6, 2016 at 5:15 PM, Ashta <sewashm at gmail.com> wrote:

> Thank you very much David.
>
> So there is no general formal that works year all round.
>
> The first one work only Jan to Nov
> today <- Sys.Date()
> nextmo<- paste0( month.abb[ as.numeric(format(today, format="%m"))+1] ,
>                  format(today,"%Y") )
> [1] "Jun2016"
>
> The second one works only  for the last month of the year.
> today <- as.Date("2008-12-01")
>  nextmo<- paste0(m <- month.abb[(as.numeric(format(today,
> format="%m"))+1) %/% 12] ,
>                   as.numeric( format(today,"%Y") ) + (m == "Jan") )
>  nextmo
>
>
> Many thanks
>
>
>
>
>
> On Fri, May 6, 2016 at 6:40 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> >> On May 6, 2016, at 4:30 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >>
> >>
> >>> On May 6, 2016, at 4:11 PM, Ashta <sewashm at gmail.com> wrote:
> >>>
> >>> Hi all,
> >>>
> >>> I am trying to ge get the next month of the year.
> >>>
> >>> today <- Sys.Date()
> >>> xx<- format(today, format="%B%Y")
> >>>
> >>> I got  "May2016",  but I want  Jun2016. How do I do that?
> >>
> >> today <- Sys.Date()
> >> nextmo<- paste0( month.abb[ as.numeric(format(today, format="%m"))+1] ,
> >>                 format(today,"%Y") )
> >> [1] "Jun2016"
> >
> > It occurred to me that at the end of the year you would want to
> increment the year as well. This calculates the next month and increments
> the year value if needed:
> >
> >  today <- as.Date("2008-12-01")
> >  nextmo<- paste0(m <- month.abb[(as.numeric(format(today,
> format="%m"))+1) %/% 12] ,
> >                   as.numeric( format(today,"%Y") ) + (m == "Jan") )
> >  nextmo
> > #[1] "Jan2009"
> >>
> >>>
> >>> My other question is that, I read a data  and do some analysis  and I
> >>> want to send all the results of the analysis to a pdf file
> >>>
> >>> Example
> >>> x5 <- runif(15, 5.0, 7.5)
> >>> x5
> >>>
> >>>
> >>> I tried this one
> >>>
> >>> pdf(file=" test.pdf")
> >>> x5
> >>> dev.off()
> >>
> >> pdf() opens a graphics device, so you need a function that establishes
> a coordinate system:
> >>
> >> x5 <- runif(15, 5.0, 7.5)
> >> pdf(file=" test.pdf");
> >> plot(1,1,type="n")
> >> text(1, 1, paste(round(x5, 2), collapse="\n") )
> >> dev.off()
> >>
> >
> > If you need to suppress the axes and their labels:
> >
> >  pdf(file=" test.pdf"); plot(1,1, type="n", axes=FALSE, xlab="", ylab="")
> >  text(1, 1, paste(round(x5, 2), collapse="\n") )
> >  dev.off()
> >
> >> I doubt that this is what you really want, and suspect you really need
> to be studying the capabilities supported by the knitr package. If I'm
> wrong about that and you want a system that supports drawing and text on a
> blank page, then first study:
> >>
> >>> library(grid)
> >>> help(pac=grid)
> >>
> >> If you choose that route then the text "R Graphics" by Paul Murrell
> will be indispensable.
> >>
> >> --
> >> David Winsemius
> >> Alameda, CA, USA
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Emily.Chang2 at ucsf.edu  Sat May  7 00:19:13 2016
From: Emily.Chang2 at ucsf.edu (Chang, Emily)
Date: Fri, 6 May 2016 22:19:13 +0000
Subject: [R] Issue replacing dataset values from read data
Message-ID: <E8628E91E7FC33438D6681B3341266E2016A170E@ex09.net.ucsf.edu>

Dear all,

I am reading a modest dataset (2297 x 644) with specific values I want to change. The code is inelegant but looks like this:

df <- read.csv("mydata.csv", header = TRUE, stringsAsFactors = FALSE)

# yrsquit, packyrs missing for following IDs. Manually change.
for(myid in c(2165, 2534, 2553, 2611, 2983, 3233)){
     temp <- subset(df, id == myid)
     df[df$id == myid , "yrsquit"] <- 0
     temp.yrssmoke <- temp$age-(temp$agesmoke+temp$yrsquit)
     df[df$id == myid , "yrssmoke"]  <- temp.yrssmoke
     df[df$id == myid , "packyrs"] <- (temp$cigsdaytotal/20)*(temp.yrssmoke)
}

If I run just the first line and then the for loop, it works.
If I run the first line and for loop together, yrsquit is properly replaced to == 0, but packyrs is NA still.

Obviously there's many ways around this specific problem, but I was wondering what the issue is here, so as to look out for and avoid it in the future.

Apologies for the lack of reproducible code; I haven't yet reproduced the problem with generated data.

Much thanks in advance.

Best regards,
Emily

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat May  7 04:20:11 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 06 May 2016 19:20:11 -0700
Subject: [R] replacing values of rows with identical row names in
	two	dataframes
In-Reply-To: <1091902258.66284.1462577535995.JavaMail.yahoo@mail.yahoo.com>
References: <23E13C6E-62D2-4BDE-8C17-D67E94A7AFAC@dcn.davis.ca.us>
	<1091902258.66284.1462577535995.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <43A80E82-4302-4441-A414-617964E84E36@dcn.davis.ca.us>

Please use reply-all to keep the mailing list in the loop,  and use plain text rather than HTML to make sure the your message gets through uncorrupted. 

?merge
?lapply

# untested
# align rows by date
df1a <- merge( df1, df2, by="date", all.x=TRUE )
# like-named columns have .x or .y appended
df1an0  <- grep( "\\.x$", names( df1a ), values=TRUE )
df1an <- substr( df1an0, 1, nchar( df1an0 ) - 2 )
# make a list of updated columns
df1b <- lapply( df1an, function(nm) { 
   nmx  <- paste0( nm, ".x" )
   nmy  <- paste0( nm, ".y" )
   ifelse( is.na( df1a[[ nmx ]] ), df1a[[ nmy ]], df1a[[ nmx ]] )
 }
# set the names of the fixed columns
df1b <- setNames( df1b, df1an )
# figure out the names of the non-duped columns
df1an1 <- grep( "\\.[xy]$", names( df1a ), invert =TRUE )
# make a new data frame
df1c  <- data.frame( df1a[ , df1an1, drop=FALSE ], df1b )

-- 
Sent from my phone. Please excuse my brevity.

On May 6, 2016 4:32:15 PM PDT, Saba Sehrish <sabasehrish at yahoo.com> wrote:
>No. If there is some other way, i would like to go for it.
>RegardsSaba 
>
>On Saturday, 7 May 2016, 11:30, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
> 
>
> Why would you want to use a for loop? Is this homework? 
>-- 
>Sent from my phone. Please excuse my brevity.
>
>On May 6, 2016 4:15:09 PM PDT, Saba Sehrish via R-help
><r-help at r-project.org> wrote:
>
>
>Hi 
>
>I have two dataframes(df1, df2) with equal number of columns (1566) but
>lesser rows in df2 (2772 in df1 and 40 in df2). Row names are 
>identical in both dataframes (date). I want to replace NAs of df1 with
>the values of df2 for all those rows having identical row names (date)
>but 
>without affecting already existing values in those rows of df1. 
>
>Please see below: 
>
>df1: 
>date     11A  11A   21B   3CC   3CC 
>20040101  100   150   NA   NA   140 
>20040115   200   NA   200   NA   NA 
>20040131   NA   165   180   190   190 
>20040205   NA   NA   NA   NA   NA 
>20040228   NA   NA   NA   NA   NA 
>20040301  150   155   170   150   160 
>20040315   NA   NA   180   190   200 
>20040331   NA   NA   NA   175   180 
>
>df2: 
>date     11A  11A   21B   3CC   3CC 
>20040131   170   NA   NA   NA   NA 
>20040228   140   145   165   150   155 
>20040331   NA  
>145   160   NA   NA 
>
>I want the resulting dataframe to be: 
>
>df3: 
>date         11A  11A   21B   3CC   3CC 
>20040101      100   150   NA   NA   140 
>20040115      200   NA   200   NA   NA 
>20040131      170   165   180   190   190 
>20040205      NA   NA   NA   NA   NA 
>20040228      140   145   165   150   155 
>20040301      150   155   170   150   160 
>20040315      NA   NA   180   190   200 
>20040331      NA   145   160   175   180 
>
>If it is possible, I would prefer to use "for loop" and "which"
>function to achieve the result. 
>
>Please guide me in this regard. 
>
>Thanks 
>Saba
>
>
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>
>
>   

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat May  7 07:18:05 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 6 May 2016 22:18:05 -0700
Subject: [R] month and output
In-Reply-To: <CADDFq31ESRVfVogOfhv+2aLiBA4O0gRnGaFvFz7w4Lxys+obHQ@mail.gmail.com>
References: <CADDFq30xBMGdJ1hvm_a=iohrG6KWdM6ddU3fd98-ue7cEDDWUw@mail.gmail.com>
	<F2D315DA-4A2B-471F-A626-5FC0F1F15BF4@comcast.net>
	<36D919EB-2191-427B-9523-13FEC021FC79@comcast.net>
	<CADDFq31ESRVfVogOfhv+2aLiBA4O0gRnGaFvFz7w4Lxys+obHQ@mail.gmail.com>
Message-ID: <0CD6C454-AEC4-4F47-846D-1BEF90B43E0E@comcast.net>


> On May 6, 2016, at 5:15 PM, Ashta <sewashm at gmail.com> wrote:
> 
> Thank you very much David.
> 
> So there is no general formal that works year all round.
> 
> The first one work only Jan to Nov
> today <- Sys.Date()
> nextmo<- paste0( month.abb[ as.numeric(format(today, format="%m"))+1] ,
>                 format(today,"%Y") )
> [1] "Jun2016"
> 
> The second one works only  for the last month of the year.
> today <- as.Date("2008-12-01")
> nextmo<- paste0(m <- month.abb[(as.numeric(format(today,
> format="%m"))+1) %/% 12] ,
>                  as.numeric( format(today,"%Y") ) + (m == "Jan") )

Sorry;

This works as intended:

> today <- seq( from=as.Date("2008-1-01"), length=13, by="1 mo" )
> 
> nextmo<- paste0( m <- month.abb[ as.numeric(format(today, format="%m")) %% 12+1] ,
+                as.numeric( format(today,"%Y") ) + (m=="Jan") ); nextmo
 [1] "Feb2008" "Mar2008" "Apr2008" "May2008" "Jun2008" "Jul2008" "Aug2008" "Sep2008"
 [9] "Oct2008" "Nov2008" "Dec2008" "Jan2009" "Feb2009"



> nextmo
> 
> 
> Many thanks
> 
> 
> 
> 
> 
> On Fri, May 6, 2016 at 6:40 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>>> On May 6, 2016, at 4:30 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>> 
>>> 
>>>> On May 6, 2016, at 4:11 PM, Ashta <sewashm at gmail.com> wrote:
>>>> 
>>>> Hi all,
>>>> 
>>>> I am trying to ge get the next month of the year.
>>>> 
>>>> today <- Sys.Date()
>>>> xx<- format(today, format="%B%Y")
>>>> 
>>>> I got  "May2016",  but I want  Jun2016. How do I do that?
>>> 
>>> today <- Sys.Date()
>>> nextmo<- paste0( month.abb[ as.numeric(format(today, format="%m"))+1] ,
>>>                format(today,"%Y") )
>>> [1] "Jun2016"
>> 
>> It occurred to me that at the end of the year you would want to increment the year as well. This calculates the next month and increments the year value if needed:
>> 
>> today <- as.Date("2008-12-01")
>> nextmo<- paste0(m <- month.abb[(as.numeric(format(today, format="%m"))+1) %/% 12] ,
>>                  as.numeric( format(today,"%Y") ) + (m == "Jan") )
>> nextmo
>> #[1] "Jan2009"
>>> 
>>>> 
>>>> My other question is that, I read a data  and do some analysis  and I
>>>> want to send all the results of the analysis to a pdf file
>>>> 
>>>> Example
>>>> x5 <- runif(15, 5.0, 7.5)
>>>> x5
>>>> 
>>>> 
>>>> I tried this one
>>>> 
>>>> pdf(file=" test.pdf")
>>>> x5
>>>> dev.off()
>>> 
>>> pdf() opens a graphics device, so you need a function that establishes a coordinate system:
>>> 
>>> x5 <- runif(15, 5.0, 7.5)
>>> pdf(file=" test.pdf");
>>> plot(1,1,type="n")
>>> text(1, 1, paste(round(x5, 2), collapse="\n") )
>>> dev.off()
>>> 
>> 
>> If you need to suppress the axes and their labels:
>> 
>> pdf(file=" test.pdf"); plot(1,1, type="n", axes=FALSE, xlab="", ylab="")
>> text(1, 1, paste(round(x5, 2), collapse="\n") )
>> dev.off()
>> 
>>> I doubt that this is what you really want, and suspect you really need to be studying the capabilities supported by the knitr package. If I'm wrong about that and you want a system that supports drawing and text on a blank page, then first study:
>>> 
>>>> library(grid)
>>>> help(pac=grid)
>>> 
>>> If you choose that route then the text "R Graphics" by Paul Murrell will be indispensable.
>>> 
>>> --
>>> David Winsemius
>>> Alameda, CA, USA
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Sat May  7 08:07:45 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 7 May 2016 16:07:45 +1000
Subject: [R] Issue replacing dataset values from read data
In-Reply-To: <E8628E91E7FC33438D6681B3341266E2016A170E@ex09.net.ucsf.edu>
References: <E8628E91E7FC33438D6681B3341266E2016A170E@ex09.net.ucsf.edu>
Message-ID: <CA+8X3fXEmtR8xqa4F0Ek61E1cD-dPrUpaAwniiug2TgdTYq9hw@mail.gmail.com>

Hi Emily,
I haven't tested this exhaustively, but it seems to work:

df<-data.frame(id=2001:3300,yrssmoke=sample(1:40,1300,TRUE),
 cigsdaytotal=sample(1:60,1300,TRUE),yrsquit=sample(1:20,1300,TRUE))
dfNA<-sapply(df$id,"%in%",c(2165,2534,2553,2611,2983,3233))
# create your NA values
df[dfNA,c("yrsquit","packyrs")]<-NA
# since you know the NA id values
df[dfNA,"yrsquit"]<-0
df[dfNA,"packyrs"]<-df[dfNA,"yrssmoke"]*df[dfNA,"cigsdaytotal"]/20

Jim


On Sat, May 7, 2016 at 8:19 AM, Chang, Emily <Emily.Chang2 at ucsf.edu> wrote:
> Dear all,
>
> I am reading a modest dataset (2297 x 644) with specific values I want to change. The code is inelegant but looks like this:
>
> df <- read.csv("mydata.csv", header = TRUE, stringsAsFactors = FALSE)
>
> # yrsquit, packyrs missing for following IDs. Manually change.
> for(myid in c(2165, 2534, 2553, 2611, 2983, 3233)){
>      temp <- subset(df, id == myid)
>      df[df$id == myid , "yrsquit"] <- 0
>      temp.yrssmoke <- temp$age-(temp$agesmoke+temp$yrsquit)
>      df[df$id == myid , "yrssmoke"]  <- temp.yrssmoke
>      df[df$id == myid , "packyrs"] <- (temp$cigsdaytotal/20)*(temp.yrssmoke)
> }
>
> If I run just the first line and then the for loop, it works.
> If I run the first line and for loop together, yrsquit is properly replaced to == 0, but packyrs is NA still.
>
> Obviously there's many ways around this specific problem, but I was wondering what the issue is here, so as to look out for and avoid it in the future.
>
> Apologies for the lack of reproducible code; I haven't yet reproduced the problem with generated data.
>
> Much thanks in advance.
>
> Best regards,
> Emily
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wjm1 at caa.columbia.edu  Sat May  7 13:13:25 2016
From: wjm1 at caa.columbia.edu (William Michels)
Date: Sat, 7 May 2016 04:13:25 -0700
Subject: [R] Issue replacing dataset values from read data
In-Reply-To: <E8628E91E7FC33438D6681B3341266E2016A170E@ex09.net.ucsf.edu>
References: <E8628E91E7FC33438D6681B3341266E2016A170E@ex09.net.ucsf.edu>
Message-ID: <CAA99HCwQFdaeE+gQiBMjiCAcA__a0NNJWSg+rk9CCc-2=i6h3g@mail.gmail.com>

1. It's not immediately clear why you need the line "temp <- subset(df, id
== myid)"

2. The objects described by "temp$age", temp$agesmoke, and temp$yrsquit are
all vectors. So temp.yrssmoke is also a vector. This means that when you
replace, it should be with "<- temp.yrssmoke[i]", where "i" is the (row)
 number you're looping over (note "temp" re-numbers rows to 1 through 6,
another reason to remove the "temp" line).

3. Ditto for " <- (temp$cigsdaytotal[i]/20)*(temp.yrssmoke[i]) "

Hope this helps!

Bill

W. Michels, Ph.D.



On Fri, May 6, 2016 at 3:19 PM, Chang, Emily <Emily.Chang2 at ucsf.edu> wrote:

> Dear all,
>
> I am reading a modest dataset (2297 x 644) with specific values I want to
> change. The code is inelegant but looks like this:
>
> df <- read.csv("mydata.csv", header = TRUE, stringsAsFactors = FALSE)
>
> # yrsquit, packyrs missing for following IDs. Manually change.
> for(myid in c(2165, 2534, 2553, 2611, 2983, 3233)){
>      temp <- subset(df, id == myid)
>      df[df$id == myid , "yrsquit"] <- 0
>      temp.yrssmoke <- temp$age-(temp$agesmoke+temp$yrsquit)
>      df[df$id == myid , "yrssmoke"]  <- temp.yrssmoke
>      df[df$id == myid , "packyrs"] <-
> (temp$cigsdaytotal/20)*(temp.yrssmoke)
> }
>
> If I run just the first line and then the for loop, it works.
> If I run the first line and for loop together, yrsquit is properly
> replaced to == 0, but packyrs is NA still.
>
> Obviously there's many ways around this specific problem, but I was
> wondering what the issue is here, so as to look out for and avoid it in the
> future.
>
> Apologies for the lack of reproducible code; I haven't yet reproduced the
> problem with generated data.
>
> Much thanks in advance.
>
> Best regards,
> Emily
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From marco.prado.bs at gmail.com  Sat May  7 18:31:25 2016
From: marco.prado.bs at gmail.com (Marco Silva)
Date: Sat, 07 May 2016 13:31:25 -0300
Subject: [R] Expand 80 columns terminal output
Message-ID: <1462638683-sup-4036@ubatuba>

Hi R'ers,

I noted that R breaks lines for any output greater than 80 chars,
Is there a way to expand this limit ?

Thks

-- 
Marco Arthur @ (M)arco Creatives


From dwinsemius at comcast.net  Sat May  7 18:38:59 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 7 May 2016 09:38:59 -0700
Subject: [R] Expand 80 columns terminal output
In-Reply-To: <1462638683-sup-4036@ubatuba>
References: <1462638683-sup-4036@ubatuba>
Message-ID: <DB903625-901C-45F8-8070-F662E192C459@comcast.net>


> On May 7, 2016, at 9:31 AM, Marco Silva <marco.prado.bs at gmail.com> wrote:
> 
> Hi R'ers,
> 
> I noted that R breaks lines for any output greater than 80 chars,
> Is there a way to expand this limit ?

?options

options(width=120)

-- 

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Sat May  7 20:31:13 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 7 May 2016 11:31:13 -0700
Subject: [R] Expand 80 columns terminal output
In-Reply-To: <DB903625-901C-45F8-8070-F662E192C459@comcast.net>
References: <1462638683-sup-4036@ubatuba>
	<DB903625-901C-45F8-8070-F662E192C459@comcast.net>
Message-ID: <CAGxFJbSfzNHoUv7xr8D5WbY68TM1niBaavhr5u-S=_riocd1eQ@mail.gmail.com>

Actually, I think this may depend on context. options(width =...)
directly controls only what is described in it's Help file. It does
not necessarily control the width of lines in the console or whatever
GUI you might be interacting with, nor necessarily the width at which
many objects are printed, which is under the control of their print()
methods, including defaults. Note, however, many such defaults default
to the options value, which may or may not be what you want for them.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, May 7, 2016 at 9:38 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On May 7, 2016, at 9:31 AM, Marco Silva <marco.prado.bs at gmail.com> wrote:
>>
>> Hi R'ers,
>>
>> I noted that R breaks lines for any output greater than 80 chars,
>> Is there a way to expand this limit ?
>
> ?options
>
> options(width=120)
>
> --
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Achim.Zeileis at uibk.ac.at  Sat May  7 21:18:14 2016
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Sat, 7 May 2016 21:18:14 +0200 (CEST)
Subject: [R] Truncreg package help
In-Reply-To: <OFFAAF6EAC.0DEF1A65-ONC1257FAB.0023970D-C1257FAB.0024A2FF@unisg.ch>
References: <OFFAAF6EAC.0DEF1A65-ONC1257FAB.0023970D-C1257FAB.0024A2FF@unisg.ch>
Message-ID: <alpine.DEB.2.20.1605072112450.29313@paninaro>

On Fri, 6 May 2016, Philipp Schaper wrote:

> Dear R userers,
>
> I am running truncated regressions with the 'truncreg' package. My sample
> is large (6,000 observations), the data is left-truncated at 1 and the
> left tail of the data is heavily centered at 1. When I am running the
> regression I receive the following error message:
>
>  Error in optim(par = start[!fixed], fn = logLikFunc, control = control,
> :
>  initial value in 'vmmin' is not finite
>
>> From a previous discussion (
> http://r.789695.n4.nabble.com/betareg-help-td3350129.html) on a similar
> issue in the betareg function I assume that the error message stems from
> that the estimate of the starting value of the precision parameter is
> negative. However, I do not know how I can take care of this. Thus I would
> be very thankful for any help.

As in the thread you quote above, it is hard to say what is going on 
without a reproducible example. It is possible that the problem is caused 
by some problem of (almost) degenerate data (as was the case with the 
betareg example). With a reproducible example we might be able to say 
more.

As an alternative to truncreg() you might try the function trch() from 
package "crch": trch(y ~ x1 + x2 + ... | 1, data = mydata, left = 0). This 
is a different implementation of the same model so possibly this avoids 
the problem - but maybe not.

> Best regards,
> Philipp
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From marc_grt at yahoo.fr  Sat May  7 21:49:05 2016
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Sat, 7 May 2016 21:49:05 +0200
Subject: [R] error.crosses
In-Reply-To: <CAHskWAVDZgkMPeZ7kuUVBXxjpOMrgr6FCOJGi+X_dTbS1azo+Q@mail.gmail.com>
References: <CAHskWAVDZgkMPeZ7kuUVBXxjpOMrgr6FCOJGi+X_dTbS1azo+Q@mail.gmail.com>
Message-ID: <572E46B1.8060905@yahoo.fr>

Following the message of Bert Gunter, you should explain better what you 
have done (not everyone know that describeBy is a function of psych 
package) and what you want. You said "error bars"... but what "error 
bar"? (I don't like the term "error bars". Most often they are not 
errors but dispersion bar; if you read French, you can check this ppt 
from a conference I gave : Myths and legends in statistics : 
http://max2.ese.u-psud.fr/epc/conservation/Publi/Mythes.pdf

Here is a reproducible example, and it works:
 > library("psych")
 > df <- data.frame(A=rnorm(10, 10, 2), B=rnorm(10, 9, 3), 
C=sample(c("G", "H"), 10, replace=TRUE))
 > d <- describeBy(df[, c("A", "B")], group=df$C)
 > error.crosses(d$G, d$H)

Sincerely

Marc Girondot


Le 27/04/2016 20:54, Marlin Keith Cox a ?crit :
> Hello all, I have used describeBy to generate the following summary
> statistics.  I simply need x and y error bars on a plot that has CQN
> (xaxis) and Price (yaxis).  There should be four total points on the graph
> (one for each supplier).
>
> Using "error.crosses(desc$CQN, desc$Price)" does not work.
>
>
>
> group: a
>            vars  n  mean    sd median trimmed   mad   min   max range skew
> CQN          1 65 48.22 11.12  49.61   47.86 13.79 31.30 72.71 41.41  0.1
> Price        2 65  6.65  0.06   6.69    6.66  0.01  6.48  6.70  0.22 -1.2
> Supplier*    3 65   NaN    NA     NA     NaN    NA   Inf  -Inf  -Inf   NA
>            kurtosis   se
> CQN          -1.01 1.38
> Price         0.70 0.01
> Supplier*       NA   NA
> ------------------------------------------------------------
> group: b
>            vars n  mean sd median trimmed mad   min   max range skew
> kurtosis se
> CQN          1 1 91.93 NA  91.93   91.93   0 91.93 91.93     0   NA
> NA NA
> Price        2 1  6.95 NA   6.95    6.95   0  6.95  6.95     0   NA
> NA NA
> Supplier*    3 1   NaN NA     NA     NaN  NA   Inf  -Inf  -Inf   NA
> NA NA
> ------------------------------------------------------------
> group: c
>            vars n  mean   sd median trimmed  mad   min   max range skew
> kurtosis
> CQN          1 6 63.11 2.58  62.04   63.11 1.53 60.66 67.19  6.53 0.55
>   -1.68
> Price        2 6  8.92 0.00   8.92    8.92 0.00  8.92  8.92  0.00  NaN
>   NaN
> Supplier*    3 6   NaN   NA     NA     NaN   NA   Inf  -Inf  -Inf   NA
>    NA
>              se
> CQN       1.05
> Price     0.00
> Supplier*   NA
> ------------------------------------------------------------
> group: d
>            vars n  mean  sd median trimmed  mad   min   max range skew
> kurtosis
> CQN          1 6 47.20 5.7  46.31   47.20 7.17 39.52 54.45 14.93 0.08
>   -1.79
> Price        2 6  7.17 0.0   7.17    7.17 0.00  7.17  7.17  0.00  NaN
>   NaN
> Supplier*    3 6   NaN  NA     NA     NaN   NA   Inf  -Inf  -Inf   NA
> NA
>              se
> CQN       2.33
> Price     0.00
> Supplier*   NA
>
> M. Keith Cox, Ph.D.
> Principal
> MKConsulting
> 17415 Christine Ave.
> Juneau, AK 99801
> U.S. 907.957.4606
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From sewashm at gmail.com  Sun May  8 01:48:11 2016
From: sewashm at gmail.com (Ashta)
Date: Sat, 7 May 2016 18:48:11 -0500
Subject: [R] month and output
In-Reply-To: <0CD6C454-AEC4-4F47-846D-1BEF90B43E0E@comcast.net>
References: <CADDFq30xBMGdJ1hvm_a=iohrG6KWdM6ddU3fd98-ue7cEDDWUw@mail.gmail.com>
	<F2D315DA-4A2B-471F-A626-5FC0F1F15BF4@comcast.net>
	<36D919EB-2191-427B-9523-13FEC021FC79@comcast.net>
	<CADDFq31ESRVfVogOfhv+2aLiBA4O0gRnGaFvFz7w4Lxys+obHQ@mail.gmail.com>
	<0CD6C454-AEC4-4F47-846D-1BEF90B43E0E@comcast.net>
Message-ID: <CADDFq302gWg7+vTrfiG=D2hiHk5BGYc9UqFXsMpJ+rfA9WDk+w@mail.gmail.com>

Thank you David!

On Sat, May 7, 2016 at 12:18 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On May 6, 2016, at 5:15 PM, Ashta <sewashm at gmail.com> wrote:
>>
>> Thank you very much David.
>>
>> So there is no general formal that works year all round.
>>
>> The first one work only Jan to Nov
>> today <- Sys.Date()
>> nextmo<- paste0( month.abb[ as.numeric(format(today, format="%m"))+1] ,
>>                 format(today,"%Y") )
>> [1] "Jun2016"
>>
>> The second one works only  for the last month of the year.
>> today <- as.Date("2008-12-01")
>> nextmo<- paste0(m <- month.abb[(as.numeric(format(today,
>> format="%m"))+1) %/% 12] ,
>>                  as.numeric( format(today,"%Y") ) + (m == "Jan") )
>
> Sorry;
>
> This works as intended:
>
>> today <- seq( from=as.Date("2008-1-01"), length=13, by="1 mo" )
>>
>> nextmo<- paste0( m <- month.abb[ as.numeric(format(today, format="%m")) %% 12+1] ,
> +                as.numeric( format(today,"%Y") ) + (m=="Jan") ); nextmo
>  [1] "Feb2008" "Mar2008" "Apr2008" "May2008" "Jun2008" "Jul2008" "Aug2008" "Sep2008"
>  [9] "Oct2008" "Nov2008" "Dec2008" "Jan2009" "Feb2009"
>
>
>
>> nextmo
>>
>>
>> Many thanks
>>
>>
>>
>>
>>
>> On Fri, May 6, 2016 at 6:40 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>>
>>>> On May 6, 2016, at 4:30 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>>>
>>>>
>>>>> On May 6, 2016, at 4:11 PM, Ashta <sewashm at gmail.com> wrote:
>>>>>
>>>>> Hi all,
>>>>>
>>>>> I am trying to ge get the next month of the year.
>>>>>
>>>>> today <- Sys.Date()
>>>>> xx<- format(today, format="%B%Y")
>>>>>
>>>>> I got  "May2016",  but I want  Jun2016. How do I do that?
>>>>
>>>> today <- Sys.Date()
>>>> nextmo<- paste0( month.abb[ as.numeric(format(today, format="%m"))+1] ,
>>>>                format(today,"%Y") )
>>>> [1] "Jun2016"
>>>
>>> It occurred to me that at the end of the year you would want to increment the year as well. This calculates the next month and increments the year value if needed:
>>>
>>> today <- as.Date("2008-12-01")
>>> nextmo<- paste0(m <- month.abb[(as.numeric(format(today, format="%m"))+1) %/% 12] ,
>>>                  as.numeric( format(today,"%Y") ) + (m == "Jan") )
>>> nextmo
>>> #[1] "Jan2009"
>>>>
>>>>>
>>>>> My other question is that, I read a data  and do some analysis  and I
>>>>> want to send all the results of the analysis to a pdf file
>>>>>
>>>>> Example
>>>>> x5 <- runif(15, 5.0, 7.5)
>>>>> x5
>>>>>
>>>>>
>>>>> I tried this one
>>>>>
>>>>> pdf(file=" test.pdf")
>>>>> x5
>>>>> dev.off()
>>>>
>>>> pdf() opens a graphics device, so you need a function that establishes a coordinate system:
>>>>
>>>> x5 <- runif(15, 5.0, 7.5)
>>>> pdf(file=" test.pdf");
>>>> plot(1,1,type="n")
>>>> text(1, 1, paste(round(x5, 2), collapse="\n") )
>>>> dev.off()
>>>>
>>>
>>> If you need to suppress the axes and their labels:
>>>
>>> pdf(file=" test.pdf"); plot(1,1, type="n", axes=FALSE, xlab="", ylab="")
>>> text(1, 1, paste(round(x5, 2), collapse="\n") )
>>> dev.off()
>>>
>>>> I doubt that this is what you really want, and suspect you really need to be studying the capabilities supported by the knitr package. If I'm wrong about that and you want a system that supports drawing and text on a blank page, then first study:
>>>>
>>>>> library(grid)
>>>>> help(pac=grid)
>>>>
>>>> If you choose that route then the text "R Graphics" by Paul Murrell will be indispensable.
>>>>
>>>> --
>>>> David Winsemius
>>>> Alameda, CA, USA
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> David Winsemius
>>> Alameda, CA, USA
>>>
>
> David Winsemius
> Alameda, CA, USA
>


From Muhammad2.Bilal at live.uwe.ac.uk  Sun May  8 02:40:26 2016
From: Muhammad2.Bilal at live.uwe.ac.uk (Muhammad Bilal)
Date: Sun, 8 May 2016 00:40:26 +0000
Subject: [R] trainControl and train functions are not found in caret package
Message-ID: <DB5PR07MB1109B1DC0DB19077FDD39ED6DB7F0@DB5PR07MB1109.eurprd07.prod.outlook.com>

Hi All,


Whilst using 'trainControl' and 'train' functions in R studio, an error is raised stating that the functions are not found.


I tried installing the caret function a few times, but the error persists.


Can anyone guide me how to access these functions.


Many Thanks and


Kind Regards

--
Muhammad Bilal
Research Fellow and Doctoral Researcher,
Bristol Enterprise, Research, and Innovation Centre (BERIC),
University of the West of England (UWE),
Frenchay Campus,
Bristol,
BS16 1QY

muhammad2.bilal at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun May  8 03:37:52 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 07 May 2016 18:37:52 -0700
Subject: [R] trainControl and train functions are not found in caret
	package
In-Reply-To: <DB5PR07MB1109B1DC0DB19077FDD39ED6DB7F0@DB5PR07MB1109.eurprd07.prod.outlook.com>
References: <DB5PR07MB1109B1DC0DB19077FDD39ED6DB7F0@DB5PR07MB1109.eurprd07.prod.outlook.com>
Message-ID: <0863609E-884B-4720-A7BC-6E4237B443D6@dcn.davis.ca.us>

Reproducible example?  At least whatever you did... and the output of sessionInfo().

Did you use library function to load it into memory? 
-- 
Sent from my phone. Please excuse my brevity.

On May 7, 2016 5:40:26 PM PDT, Muhammad Bilal <Muhammad2.Bilal at live.uwe.ac.uk> wrote:
>Hi All,
>
>
>Whilst using 'trainControl' and 'train' functions in R studio, an error
>is raised stating that the functions are not found.
>
>
>I tried installing the caret function a few times, but the error
>persists.
>
>
>Can anyone guide me how to access these functions.
>
>
>Many Thanks and
>
>
>Kind Regards
>
>--
>Muhammad Bilal
>Research Fellow and Doctoral Researcher,
>Bristol Enterprise, Research, and Innovation Centre (BERIC),
>University of the West of England (UWE),
>Frenchay Campus,
>Bristol,
>BS16 1QY
>
>muhammad2.bilal at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From Muhammad2.Bilal at live.uwe.ac.uk  Sun May  8 12:36:31 2016
From: Muhammad2.Bilal at live.uwe.ac.uk (Muhammad Bilal)
Date: Sun, 8 May 2016 10:36:31 +0000
Subject: [R] trainControl and train functions are not found in caret
 package
In-Reply-To: <0863609E-884B-4720-A7BC-6E4237B443D6@dcn.davis.ca.us>
References: <DB5PR07MB1109B1DC0DB19077FDD39ED6DB7F0@DB5PR07MB1109.eurprd07.prod.outlook.com>,
	<0863609E-884B-4720-A7BC-6E4237B443D6@dcn.davis.ca.us>
Message-ID: <DB5PR07MB1109808B0E62C3853C80A7A5DB7F0@DB5PR07MB1109.eurprd07.prod.outlook.com>

Firstly, many thanks for kind consideration.

***I wrote the following R code:
install.packages("caret")
install.packages("e1071")

library(caret)
library(e1071)

set.seed(100)

tr.control <- trainControl(method="cv", number=10)
Error: could not find function "trainControl"

cp.grid <- expand.grid(.cp = (0:10)*0.001)

tr_m <- train(project_delay ~ project_lon + project_lat + project_duration + sector + contract_type + capital_value, data = trainPFI, method="rpart", trControl=tr.control, tuneGrid = cp.grid)
Error: could not find function "train"

I hope this will explain the situation I am facing right now.

***Below are the details of session info:
> sessionInfo()
R version 3.2.0 (2015-04-16)
Platform: i386-w64-mingw32/i386 (32-bit)
Running under: Windows 7 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] tcltk     stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
 [1] e1071_1.6-7      lattice_0.20-31  caTools_1.17.1   rpart.plot_1.5.3 rpart_4.1-10
 [6] XML_3.98-1.4     maps_3.1.0       plotrix_3.6-1    xlsx_0.5.7       xlsxjars_0.6.1
[11] rJava_0.9-8      sqldf_0.4-10     RSQLite_1.0.0    DBI_0.3.1        gsubfn_0.6-6
[16] proto_0.3-10     ggplot2_2.1.0

loaded via a namespace (and not attached):
 [1] codetools_0.2-11 digest_0.6.9     scales_0.4.0     grid_3.2.0       bitops_1.0-6
 [6] stringr_1.0.0    munsell_0.4.3    nnet_7.3-9       labeling_0.3     foreach_1.4.3
[11] iterators_1.0.8  chron_2.3-47     MASS_7.3-40      plyr_1.8.3       stringi_1.0-1
[16] magrittr_1.5     reshape2_1.4.1   gtable_0.2.0     colorspace_1.2-6 tools_3.2.0
[21] nlme_3.1-120     class_7.3-12     Rcpp_0.11.6



I even tried loading the caret package using require() function but no success.

Many Thanks and

Kind Regards


--
Muhammad Bilal
Research Fellow and Doctoral Researcher,
Bristol Enterprise, Research, and Innovation Centre (BERIC),
University of the West of England (UWE),
Frenchay Campus,
Bristol,
BS16 1QY

muhammad2.bilal at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>


________________________________
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: 08 May 2016 02:37:52
To: Muhammad Bilal; r-help at r-project.org
Subject: Re: [R] trainControl and train functions are not found in caret package

Reproducible example? At least whatever you did... and the output of sessionInfo().

Did you use library function to load it into memory?
--
Sent from my phone. Please excuse my brevity.

On May 7, 2016 5:40:26 PM PDT, Muhammad Bilal <Muhammad2.Bilal at live.uwe.ac.uk> wrote:

Hi All,


Whilst using 'trainControl' and 'train' functions in R studio, an error is raised stating that the functions are not found.


I tried installing the caret function a few times, but the error persists.


Can anyone guide me how to access these functions.


Many Thanks and


Kind Regards

--
Muhammad Bilal
Research Fellow and Doctoral Researcher,
Bristol Enterprise, Research, and Innovation Centre (BERIC),
University of the West of England (UWE),
Frenchay Campus,
Bristol,
BS16 1QY

muhammad2.bilal at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>


 [[alternative HTML version deleted]]

________________________________

R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read
the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Sun May  8 12:57:22 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Sun, 08 May 2016 11:57:22 +0100
Subject: [R] trainControl and train functions are not found in caret
 package
In-Reply-To: <DB5PR07MB1109808B0E62C3853C80A7A5DB7F0@DB5PR07MB1109.eurprd07.prod.outlook.com>
References: <DB5PR07MB1109B1DC0DB19077FDD39ED6DB7F0@DB5PR07MB1109.eurprd07.prod.outlook.com>
	<0863609E-884B-4720-A7BC-6E4237B443D6@dcn.davis.ca.us>
	<DB5PR07MB1109808B0E62C3853C80A7A5DB7F0@DB5PR07MB1109.eurprd07.prod.outlook.com>
Message-ID: <20160508115722.Horde.67GBax6d0wpoT-1o4grCRQv@mail.sapo.pt>

Hello,

Works with me, but I'm using R v 3.3.0. Note that your version of R is  
over 1 year old, try updating it.

install.packages("caret")
install.packages("e1071")

library(caret)
library(e1071)

set.seed(100)

tr.control <- trainControl(method="cv", number=10)

class(tr.control)
[1] "list"

Hope this helps,

Rui Barradas

?

Citando Muhammad Bilal <Muhammad2.Bilal at live.uwe.ac.uk>:

> Firstly, many thanks for kind consideration.
>
> ***I wrote the following R code:
> install.packages("caret")
> install.packages("e1071")
>
> library(caret)
> library(e1071)
>
> set.seed(100)
>
> tr.control <- trainControl(method="cv", number=10)
> Error: could not find function "trainControl"
>
> cp.grid <- expand.grid(.cp = (0:10)*0.001)
>
> tr_m <- train(project_delay ~ project_lon + project_lat +  
> project_duration + sector + contract_type + capital_value, data =  
> trainPFI, method="rpart", trControl=tr.control, tuneGrid = cp.grid)
> Error: could not find function "train"
>
> I hope this will explain the situation I am facing right now.
>
> ***Below are the details of session info:
>> sessionInfo()
>
> R version 3.2.0 (2015-04-16)
> Platform: i386-w64-mingw32/i386 (32-bit)
> Running under: Windows 7 (build 7601) Service Pack 1
>
> locale:
> [1] LC_COLLATE=English_United States.1252? LC_CTYPE=English_United  
> States.1252
> [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] tcltk? ? ?stats? ? ?graphics? grDevices utils? ? ?datasets?  
> methods? ?base
>
> other attached packages:
> [1] e1071_1.6-7? ? ? lattice_0.20-31? caTools_1.17.1?  
> ?rpart.plot_1.5.3 rpart_4.1-10
> [6] XML_3.98-1.4? ? ?maps_3.1.0? ? ? ?plotrix_3.6-1? ? xlsx_0.5.7? ?  
> ? ?xlsxjars_0.6.1
> [11] rJava_0.9-8? ? ? sqldf_0.4-10? ? ?RSQLite_1.0.0? ? DBI_0.3.1? ?  
> ? ? gsubfn_0.6-6
> [16] proto_0.3-10? ? ?ggplot2_2.1.0
>
> loaded via a namespace (and not attached):
> [1] codetools_0.2-11 digest_0.6.9? ? ?scales_0.4.0? ? ?grid_3.2.0? ?  
> ? ?bitops_1.0-6
> [6] stringr_1.0.0? ? munsell_0.4.3? ? nnet_7.3-9? ? ? ?labeling_0.3?  
> ? ?foreach_1.4.3
> [11] iterators_1.0.8? chron_2.3-47? ? ?MASS_7.3-40? ? ? plyr_1.8.3?  
> ? ? ?stringi_1.0-1
> [16] magrittr_1.5? ? ?reshape2_1.4.1? ?gtable_0.2.0? ?  
> ?colorspace_1.2-6 tools_3.2.0
> [21] nlme_3.1-120? ? ?class_7.3-12? ? ?Rcpp_0.11.6
>
> I even tried loading the caret package using require() function but  
> no success.
>
> Many Thanks and
>
> Kind Regards
>
> --
> Muhammad Bilal
> Research Fellow and Doctoral Researcher,
> Bristol Enterprise, Research, and Innovation Centre (BERIC),
> University of the West of England (UWE),
> Frenchay Campus,
> Bristol,
> BS16 1QY
>
> muhammad2.bilal at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>
>
> ________________________________
> From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> Sent: 08 May 2016 02:37:52
> To: Muhammad Bilal; r-help at r-project.org
> Subject: Re: [R] trainControl and train functions are not found in  
> caret package
>
> Reproducible example? At least whatever you did... and the output of  
> sessionInfo().
>
> Did you use library function to load it into memory?
> --
> Sent from my phone. Please excuse my brevity.
>
> On May 7, 2016 5:40:26 PM PDT, Muhammad Bilal  
> <Muhammad2.Bilal at live.uwe.ac.uk> wrote:
>
> Hi All,
>
> Whilst using 'trainControl' and 'train' functions in R studio, an  
> error is raised stating that the functions are not found.
>
> I tried installing the caret function a few times, but the error persists.
>
> Can anyone guide me how to access these functions.
>
> Many Thanks and
>
> Kind Regards
>
> --
> Muhammad Bilal
> Research Fellow and Doctoral Researcher,
> Bristol Enterprise, Research, and Innovation Centre (BERIC),
> University of the West of England (UWE),
> Frenchay Campus,
> Bristol,
> BS16 1QY
>
> muhammad2.bilal at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>
>
> [[alternative HTML version deleted]]
>
> ________________________________
>
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read
> the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide  
> http://www.R-project.org/posting-guide.htmland provide commented,  
> minimal, self-contained, reproducible code.

?

	[[alternative HTML version deleted]]


From prasad.prasad.kale at gmail.com  Sun May  8 14:24:41 2016
From: prasad.prasad.kale at gmail.com (Prasad Kale)
Date: Sun, 8 May 2016 17:54:41 +0530
Subject: [R] Pl help with code and graph
Message-ID: <CAHKdztX9o4FuzjqFS=x8U_+NOSGwhrNND2X=CPGG=zp7oXK4aA@mail.gmail.com>

Hi,

I am very new to R-studio data modelling so can anyone help me with a
detail code which provides a graph which will provides information in which
year my company i.e. A will reaches 1 lacs crs. milestone and by that time
where my competitors i.e. B and C will stands.

I am attaching a excel in which I have given Year on Year profits as well
as % growth over last year..

Thanks in Advance.

From bgunter.4567 at gmail.com  Sun May  8 17:07:01 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 8 May 2016 08:07:01 -0700
Subject: [R] Pl help with code and graph
In-Reply-To: <CAHKdztX9o4FuzjqFS=x8U_+NOSGwhrNND2X=CPGG=zp7oXK4aA@mail.gmail.com>
References: <CAHKdztX9o4FuzjqFS=x8U_+NOSGwhrNND2X=CPGG=zp7oXK4aA@mail.gmail.com>
Message-ID: <CAGxFJbTMONtj41Mk9Eq9uxpnWf9qJKrDDZ+Fj779m7Z238dhkQ@mail.gmail.com>

This is not a code writing service. Posters are expected to first make
an honest effort and show us their code as part of their post. Please
read the posting guide to learn more. Most attachments, including
Excel files, are stripped by the mail server. Use ?dput to include
example data in a post.

If you have not already gone through an R tutorial or two, please do
so before posting further. There are many good ones on the web.


Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, May 8, 2016 at 5:24 AM, Prasad Kale
<prasad.prasad.kale at gmail.com> wrote:
> Hi,
>
> I am very new to R-studio data modelling so can anyone help me with a
> detail code which provides a graph which will provides information in which
> year my company i.e. A will reaches 1 lacs crs. milestone and by that time
> where my competitors i.e. B and C will stands.
>
> I am attaching a excel in which I have given Year on Year profits as well
> as % growth over last year..
>
> Thanks in Advance.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Muhammad2.Bilal at live.uwe.ac.uk  Sun May  8 17:31:01 2016
From: Muhammad2.Bilal at live.uwe.ac.uk (Muhammad Bilal)
Date: Sun, 8 May 2016 15:31:01 +0000
Subject: [R] trainControl and train functions are not found in caret
 package
In-Reply-To: <20160508115722.Horde.67GBax6d0wpoT-1o4grCRQv@mail.sapo.pt>
References: <DB5PR07MB1109B1DC0DB19077FDD39ED6DB7F0@DB5PR07MB1109.eurprd07.prod.outlook.com>
	<0863609E-884B-4720-A7BC-6E4237B443D6@dcn.davis.ca.us>
	<DB5PR07MB1109808B0E62C3853C80A7A5DB7F0@DB5PR07MB1109.eurprd07.prod.outlook.com>,
	<20160508115722.Horde.67GBax6d0wpoT-1o4grCRQv@mail.sapo.pt>
Message-ID: <DB5PR07MB11098723016BA6FAB1373A76DB7F0@DB5PR07MB1109.eurprd07.prod.outlook.com>

Thanks you very much.


The issue resolved by just upgrading the R and R studio to their latest versions. All the packages are now successfully installed. Henceforth, the code runs absolutely okay.


--
Muhammad Bilal
Research Fellow and Doctoral Researcher,
Bristol Enterprise, Research, and Innovation Centre (BERIC),
University of the West of England (UWE),
Frenchay Campus,
Bristol,
BS16 1QY

muhammad2.bilal at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>


________________________________
From: ruipbarradas at sapo.pt <ruipbarradas at sapo.pt>
Sent: 08 May 2016 11:57:22
To: Muhammad Bilal
Cc: Jeff Newmiller; r-help at r-project.org
Subject: Re: [R] trainControl and train functions are not found in caret package


Hello,

Works with me, but I'm using R v 3.3.0. Note that your version of R is over 1 year old, try updating it.

install.packages("caret")
install.packages("e1071")

library(caret)
library(e1071)

set.seed(100)

tr.control <- trainControl(method="cv", number=10)

class(tr.control)
[1] "list"

Hope this helps,

Rui Barradas



Citando Muhammad Bilal <Muhammad2.Bilal at live.uwe.ac.uk<mailto:Muhammad2.Bilal at live.uwe.ac.uk>>:

Firstly, many thanks for kind consideration.

***I wrote the following R code:
install.packages("caret")
install.packages("e1071")

library(caret)
library(e1071)

set.seed(100)

tr.control <- trainControl(method="cv", number=10)
Error: could not find function "trainControl"

cp.grid <- expand.grid(.cp = (0:10)*0.001)

tr_m <- train(project_delay ~ project_lon + project_lat + project_duration + sector + contract_type + capital_value, data = trainPFI, method="rpart", trControl=tr.control, tuneGrid = cp.grid)
Error: could not find function "train"

I hope this will explain the situation I am facing right now.

***Below are the details of session info:

sessionInfo()

R version 3.2.0 (2015-04-16)
Platform: i386-w64-mingw32/i386 (32-bit)
Running under: Windows 7 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] tcltk     stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] e1071_1.6-7      lattice_0.20-31  caTools_1.17.1   rpart.plot_1.5.3 rpart_4.1-10
[6] XML_3.98-1.4     maps_3.1.0       plotrix_3.6-1    xlsx_0.5.7       xlsxjars_0.6.1
[11] rJava_0.9-8      sqldf_0.4-10     RSQLite_1.0.0    DBI_0.3.1        gsubfn_0.6-6
[16] proto_0.3-10     ggplot2_2.1.0

loaded via a namespace (and not attached):
[1] codetools_0.2-11 digest_0.6.9     scales_0.4.0     grid_3.2.0       bitops_1.0-6
[6] stringr_1.0.0    munsell_0.4.3    nnet_7.3-9       labeling_0.3     foreach_1.4.3
[11] iterators_1.0.8  chron_2.3-47     MASS_7.3-40      plyr_1.8.3       stringi_1.0-1
[16] magrittr_1.5     reshape2_1.4.1   gtable_0.2.0     colorspace_1.2-6 tools_3.2.0
[21] nlme_3.1-120     class_7.3-12     Rcpp_0.11.6



I even tried loading the caret package using require() function but no success.

Many Thanks and

Kind Regards


--
Muhammad Bilal
Research Fellow and Doctoral Researcher,
Bristol Enterprise, Research, and Innovation Centre (BERIC),
University of the West of England (UWE),
Frenchay Campus,
Bristol,
BS16 1QY

muhammad2.bilal at live.uwe.ac.uk<mailto:muhammad2.bilal at live.uwe.ac.uk><mailto:olugbenga2.akinade at live.uwe.ac.uk><mailto:olugbenga2.akinade at live.uwe.ac.uk>>


________________________________
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us<mailto:jdnewmil at dcn.davis.ca.us>>
Sent: 08 May 2016 02:37:52
To: Muhammad Bilal; r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] trainControl and train functions are not found in caret package

Reproducible example? At least whatever you did... and the output of sessionInfo().

Did you use library function to load it into memory?
--
Sent from my phone. Please excuse my brevity.

On May 7, 2016 5:40:26 PM PDT, Muhammad Bilal <Muhammad2.Bilal at live.uwe.ac.uk<mailto:Muhammad2.Bilal at live.uwe.ac.uk>> wrote:

Hi All,


Whilst using 'trainControl' and 'train' functions in R studio, an error is raised stating that the functions are not found.


I tried installing the caret function a few times, but the error persists.


Can anyone guide me how to access these functions.


Many Thanks and


Kind Regards

--
Muhammad Bilal
Research Fellow and Doctoral Researcher,
Bristol Enterprise, Research, and Innovation Centre (BERIC),
University of the West of England (UWE),
Frenchay Campus,
Bristol,
BS16 1QY

muhammad2.bilal at live.uwe.ac.uk<mailto:muhammad2.bilal at live.uwe.ac.uk><mailto:olugbenga2.akinade at live.uwe.ac.uk><mailto:olugbenga2.akinade at live.uwe.ac.uk>>


[[alternative HTML version deleted]]

________________________________

R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read
the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.htmland provide commented, minimal, self-contained, reproducible code.



	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon May  9 00:29:51 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 9 May 2016 08:29:51 +1000
Subject: [R] Pl help with code and graph
In-Reply-To: <CAHKdztX9o4FuzjqFS=x8U_+NOSGwhrNND2X=CPGG=zp7oXK4aA@mail.gmail.com>
References: <CAHKdztX9o4FuzjqFS=x8U_+NOSGwhrNND2X=CPGG=zp7oXK4aA@mail.gmail.com>
Message-ID: <CA+8X3fX0xQXDRjXddh1_fpbyK_2_hWWKvQxVJ5GzzL5EDauVOg@mail.gmail.com>

Hi Prasad,
You are probably looking for linear modelling of some sort. The first
thing to do is to read the data into R (if you haven't already done
so). You will almost invariably have a _data frame_ in which the
columns will contain values for at least year and profit.

Then plot the profits of A B and C against years. You can do that
using a function like "matplot" (graphics).

Finally, add linear regression lines by getting the result of the "lm"
(stats) function and add them to your plot using "lines" (graphics).
Look at it. Are the letters close to the corresponding lines for each
company or are they scattered all over the plot? If you are lucky,
they will be the former. If not, you will probably have learned enough
about R to inquire what you can do next.

Jim

On Sun, May 8, 2016 at 10:24 PM, Prasad Kale
<prasad.prasad.kale at gmail.com> wrote:
> Hi,
>
> I am very new to R-studio data modelling so can anyone help me with a
> detail code which provides a graph which will provides information in which
> year my company i.e. A will reaches 1 lacs crs. milestone and by that time
> where my competitors i.e. B and C will stands.
>
> I am attaching a excel in which I have given Year on Year profits as well
> as % growth over last year..
>
> Thanks in Advance.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From spencer.graves at effectivedefense.org  Mon May  9 00:30:16 2016
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Sun, 8 May 2016 17:30:16 -0500
Subject: [R] with vs. attach
In-Reply-To: <CABdHhvELpD3+JA2TkFz1OfTXSy5HvWRZJ4d0m_03hMnrtFeboA@mail.gmail.com>
References: <901fd028-5e60-cf67-906d-c29e43d8762b@effectivedefense.org>
	<4808B356-E233-4859-A15E-745D26D4B85C@comcast.net>
	<CD4AB490-E960-44E9-BAC0-D30E96518922@gmail.com>
	<02d73d7c-2699-dc24-8552-048491dc21fa@effectivedefense.org>
	<FAC95CBE-8E91-4ED3-B3AE-DF6568354D7B@comcast.net>
	<CABdHhvELpD3+JA2TkFz1OfTXSy5HvWRZJ4d0m_03hMnrtFeboA@mail.gmail.com>
Message-ID: <bdcc1ca4-4af5-22c0-0678-50f8739f321b@effectivedefense.org>

Hi, Hadley et al.:


       Hadley's link requires his development version of "lazyeval", 
which can be obtained as follows:


library(devtools)
install_github("hadley/lazyeval")


       Hadley's link describes real problems with elegant solutions.


       However, David's solution solved my immediate problem, and it's 
not immediately obvious to me how his "expr_text" function (or other 
functions in "lazyevel") to produce a better solution.


       Thanks again to David, Peter and Hadley for their replies.


       Spencer Graves


On 5/6/2016 5:08 PM, Hadley Wickham wrote:
> You may want to read http://rpubs.com/hadley/157957, which captures my
> latest thinking (and tooling) around this problem. Feedback is much
> appreciated.
>
> Hadley
>
> On Fri, May 6, 2016 at 2:14 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>> On May 6, 2016, at 5:47 AM, Spencer Graves <spencer.graves at effectivedefense.org> wrote:
>>>
>>>
>>>
>>> On 5/6/2016 6:46 AM, peter dalgaard wrote:
>>>> On 06 May 2016, at 02:43 , David Winsemius <dwinsemius at comcast.net> wrote:
>>>>
>>>>>> On May 5, 2016, at 5:12 PM, Spencer Graves <spencer.graves at effectivedefense.org> wrote:
>>>>>>
>>>>>> I want a function to evaluate one argument
>>>>>> in the environment of a data.frame supplied
>>>>>> as another argument.  "attach" works for
>>>>>> this, but "with" does not.  Is there a way
>>>>>> to make "with" work?  I'd rather not attach
>>>>>> the data.frame.
>>>>>>
>>>>>>
>>>>>> With the following two functions "eval.w.attach"
>>>>>> works but "eval.w.with" fails:
>>>>>>
>>>>>>
>>>>>> dat <- data.frame(a=1:2)
>>>>>> eval.w.attach <- function(x, dat){
>>>>>>   attach(dat)
>>>>>>   X <- x
>>>>>>   detach()
>>>>>>   X
>>>>>> }
>>>>>>
>>>>>> eval.w.with <- function(x, dat){
>>>>>>   with(dat, x)
>>>>>> }
>>>>>>
>>>>>> eval.w.attach(a/2, dat) # returns c(.5, 1)
>>>>> How about using eval( substitute( ...))?
>>>>>
>>>>> eval.w.sub <- function(expr, datt){
>>>>>    eval( substitute(expr), env=datt)
>>>>>                          }
>>>>> eval.w.sub(a/2, dat)
>>>>> #[1] 0.5 1.0
>>>>>
>>>>>
>>>> Actually, I think a better overall strategy is to say that if you want to pass an expression to a function, then pass an expression object (or a call object or maybe a formula object).
>>>>
>>>> Once you figure out _how_ your eval.w.attach works (sort of), you'll get the creeps:
>>>>
>>>> Lazy evaluation causes the argument x to be evaluated after the attach(), hence the evaluation environment of an actual argument is being temporarily modified from inside a function.
>>>>
>>>> Apart from upsetting computer science purists, there could be hidden problems: One major issue is that  values in "dat" could be masked by values in the global environment, another issue is that an error in evaluating the expression will leave dat attached. So at a minimum, you need to recode using on.exit() magic.
>>>>
>>>> So my preferences go along these lines:
>>>>
>>>>> dat <- data.frame(a=1:2)
>>>>> eval.expression <- function(e, dat) eval(e, dat)
>>>>> eval.expression(quote(a/2), dat)
>>>> [1] 0.5 1.0
>>>>> eval.expression(expression(a/2), dat)
>>>> [1] 0.5 1.0
>>>>
>>>>> eval.formula <- function(f, dat) eval(f[[2]], dat)
>>>>> eval.formula(~a/2, dat)
>>>> [1] 0.5 1.0
>>> Hi, Peter:
>>>
>>>
>>>       I don't like eval.expression or eval.formula, because they don't automatically accept what I naively thought should work and require more knowledge of the user.  What about David's eval.w.sub:
>>>
>>>
>>> a <- pi
>>> dat <- data.frame(a=1:2)
>>> eval.w.sub <- function(a, Dat){
>>>   eval( substitute(a), env=Dat)
>>> }
>>>> eval.w.sub(a/2, dat)
>>> [1] 0.5 1.0
>> I liked eval.expression and tested it with a bquote(...) argument to see if that would succeed. It did, but it didn't return what you wanted for `a/2`, so I tried seeing if a "double eval wuold deliver both yours and my desired results:
>>
>>   eval.w.sub <- function(a, Dat){
>>    eval( eval(substitute(a),Dat), env=Dat)
>>   }
>> x=2
>>   eval.w.sub( a/2, dat)
>> [1] 0.5 1.0
>>   eval.w.sub( bquote(2*a*.(x) ), dat)
>> [1] 4 8
>>
>> We are here retracing the path the Hadley took in some of his ggplot2 design decsions. Unfortunately for me those NSE rules often left me confused about what should and shouldn't be 'quoted' in the as-character sense and what should be quote()-ed or "unquoted" in the bquote() sense.
>> --
>>
>>>
>>>
>>>       This produces what's desired in a way that seems simpler to me.
>>>
>>>
>>>       By the way, I really appreciate Peter's insightful comments:
>>>
>>>
>>> eval.w.attachOops <- function(x, Dat){
>>>   attach(Dat)
>>>   X <- x
>>>   detach()
>>>   X
>>> }
>>>> eval.w.attachOops(a/2, dat)
>>> The following object is masked _by_ .GlobalEnv:
>>>
>>>     a
>>>
>>> [1] 1.570796
>>>> eval.w.attachOops(b/2, dat)
>>> The following object is masked _by_ .GlobalEnv:
>>>
>>>     a
>>>
>>> Error in eval.w.attachOops(b/2, dat) : object 'b' not found
>>>> search()
>>> [1] ".GlobalEnv"        "Dat"               "package:graphics"
>>> [4] "package:grDevices" "package:utils"     "package:datasets"
>>> [7] "package:methods"   "Autoloads"         "package:base"
>>>> objects(2)
>>> [1] "a"
>>>
>>> *** NOTES:
>>>
>>>
>>>       1.  This gives a likely wrong answer with a warning if "a" exists in .GlobalEnv, and leaves "Dat" (NOT "dat") attached upon exit.
>>>
>>>
>>>
>>>       2.  A stray "detach()" [not shown here] detached "package:stats".  oops.
>>>
>>>
>>> *** Using "on.exit" fixes the problem with failure to detach but not the likely wrong answer:
>>>
>>>
>>> detach()
>>> search()
>>> eval.w.attachStillWrong <- function(x, dat){
>>>   attach(dat)
>>>   on.exit(detach(dat))
>>>   X <- x
>>>   X
>>> }
>>> The following object is masked _by_ .GlobalEnv:
>>>
>>>     a
>>>
>>> [1] 1.570796
>>>> eval.w.attachStillWrong(b/2, dat)
>>> The following object is masked _by_ .GlobalEnv:
>>>
>>>     a
>>>
>>> Error in eval.w.attachStillWrong(b/2, dat) : object 'b' not found
>>>> search()
>>> [1] ".GlobalEnv"        "package:grDevices" "package:utils"
>>> [4] "package:datasets"  "package:methods"   "Autoloads"
>>> [7] "package:base"
>>>
>>>
>>>       Thanks again to Peter and David.  Spencer
>>>
>>>> Peter D.
>>>>
>>>>
>>>>
>>>>> --
>>>>> David.
>>>>>
>>>>>
>>>>>> eval.w.with(a/2, dat) # Error ... 'a' not found
>>>>>>
>>>>>>
>>>>>> Thanks, Spencer Graves
>>>>>>
>>>>>>     [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> David Winsemius
>>>>> Alameda, CA, USA
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>> David Winsemius
>> Alameda, CA, USA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From jdnewmil at dcn.davis.ca.us  Mon May  9 01:02:22 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 08 May 2016 16:02:22 -0700
Subject: [R] with vs. attach
In-Reply-To: <bdcc1ca4-4af5-22c0-0678-50f8739f321b@effectivedefense.org>
References: <901fd028-5e60-cf67-906d-c29e43d8762b@effectivedefense.org>
	<4808B356-E233-4859-A15E-745D26D4B85C@comcast.net>
	<CD4AB490-E960-44E9-BAC0-D30E96518922@gmail.com>
	<02d73d7c-2699-dc24-8552-048491dc21fa@effectivedefense.org>
	<FAC95CBE-8E91-4ED3-B3AE-DF6568354D7B@comcast.net>
	<CABdHhvELpD3+JA2TkFz1OfTXSy5HvWRZJ4d0m_03hMnrtFeboA@mail.gmail.com>
	<bdcc1ca4-4af5-22c0-0678-50f8739f321b@effectivedefense.org>
Message-ID: <AC401D99-DFB4-4206-B164-68CA1F62F93F@dcn.davis.ca.us>

The lazyeval package addresses the problem of how to delay evaluation even when the function you want to do the evaluation in is buried two or more function calls below where the original call was made. If you are not building nested function calls with delayed evaluation then you probably don't need that package. 
-- 
Sent from my phone. Please excuse my brevity.

On May 8, 2016 3:30:16 PM PDT, Spencer Graves <spencer.graves at effectivedefense.org> wrote:
>Hi, Hadley et al.:
>
>
>       Hadley's link requires his development version of "lazyeval", 
>which can be obtained as follows:
>
>
>library(devtools)
>install_github("hadley/lazyeval")
>
>
>       Hadley's link describes real problems with elegant solutions.
>
>
>       However, David's solution solved my immediate problem, and it's 
>not immediately obvious to me how his "expr_text" function (or other 
>functions in "lazyevel") to produce a better solution.
>
>
>       Thanks again to David, Peter and Hadley for their replies.
>
>
>       Spencer Graves
>
>
>On 5/6/2016 5:08 PM, Hadley Wickham wrote:
>> You may want to read http://rpubs.com/hadley/157957, which captures
>my
>> latest thinking (and tooling) around this problem. Feedback is much
>> appreciated.
>>
>> Hadley
>>
>> On Fri, May 6, 2016 at 2:14 PM, David Winsemius
><dwinsemius at comcast.net> wrote:
>>>> On May 6, 2016, at 5:47 AM, Spencer Graves
><spencer.graves at effectivedefense.org> wrote:
>>>>
>>>>
>>>>
>>>> On 5/6/2016 6:46 AM, peter dalgaard wrote:
>>>>> On 06 May 2016, at 02:43 , David Winsemius
><dwinsemius at comcast.net> wrote:
>>>>>
>>>>>>> On May 5, 2016, at 5:12 PM, Spencer Graves
><spencer.graves at effectivedefense.org> wrote:
>>>>>>>
>>>>>>> I want a function to evaluate one argument
>>>>>>> in the environment of a data.frame supplied
>>>>>>> as another argument.  "attach" works for
>>>>>>> this, but "with" does not.  Is there a way
>>>>>>> to make "with" work?  I'd rather not attach
>>>>>>> the data.frame.
>>>>>>>
>>>>>>>
>>>>>>> With the following two functions "eval.w.attach"
>>>>>>> works but "eval.w.with" fails:
>>>>>>>
>>>>>>>
>>>>>>> dat <- data.frame(a=1:2)
>>>>>>> eval.w.attach <- function(x, dat){
>>>>>>>   attach(dat)
>>>>>>>   X <- x
>>>>>>>   detach()
>>>>>>>   X
>>>>>>> }
>>>>>>>
>>>>>>> eval.w.with <- function(x, dat){
>>>>>>>   with(dat, x)
>>>>>>> }
>>>>>>>
>>>>>>> eval.w.attach(a/2, dat) # returns c(.5, 1)
>>>>>> How about using eval( substitute( ...))?
>>>>>>
>>>>>> eval.w.sub <- function(expr, datt){
>>>>>>    eval( substitute(expr), env=datt)
>>>>>>                          }
>>>>>> eval.w.sub(a/2, dat)
>>>>>> #[1] 0.5 1.0
>>>>>>
>>>>>>
>>>>> Actually, I think a better overall strategy is to say that if you
>want to pass an expression to a function, then pass an expression
>object (or a call object or maybe a formula object).
>>>>>
>>>>> Once you figure out _how_ your eval.w.attach works (sort of),
>you'll get the creeps:
>>>>>
>>>>> Lazy evaluation causes the argument x to be evaluated after the
>attach(), hence the evaluation environment of an actual argument is
>being temporarily modified from inside a function.
>>>>>
>>>>> Apart from upsetting computer science purists, there could be
>hidden problems: One major issue is that  values in "dat" could be
>masked by values in the global environment, another issue is that an
>error in evaluating the expression will leave dat attached. So at a
>minimum, you need to recode using on.exit() magic.
>>>>>
>>>>> So my preferences go along these lines:
>>>>>
>>>>>> dat <- data.frame(a=1:2)
>>>>>> eval.expression <- function(e, dat) eval(e, dat)
>>>>>> eval.expression(quote(a/2), dat)
>>>>> [1] 0.5 1.0
>>>>>> eval.expression(expression(a/2), dat)
>>>>> [1] 0.5 1.0
>>>>>
>>>>>> eval.formula <- function(f, dat) eval(f[[2]], dat)
>>>>>> eval.formula(~a/2, dat)
>>>>> [1] 0.5 1.0
>>>> Hi, Peter:
>>>>
>>>>
>>>>       I don't like eval.expression or eval.formula, because they
>don't automatically accept what I naively thought should work and
>require more knowledge of the user.  What about David's eval.w.sub:
>>>>
>>>>
>>>> a <- pi
>>>> dat <- data.frame(a=1:2)
>>>> eval.w.sub <- function(a, Dat){
>>>>   eval( substitute(a), env=Dat)
>>>> }
>>>>> eval.w.sub(a/2, dat)
>>>> [1] 0.5 1.0
>>> I liked eval.expression and tested it with a bquote(...) argument to
>see if that would succeed. It did, but it didn't return what you wanted
>for `a/2`, so I tried seeing if a "double eval wuold deliver both yours
>and my desired results:
>>>
>>>   eval.w.sub <- function(a, Dat){
>>>    eval( eval(substitute(a),Dat), env=Dat)
>>>   }
>>> x=2
>>>   eval.w.sub( a/2, dat)
>>> [1] 0.5 1.0
>>>   eval.w.sub( bquote(2*a*.(x) ), dat)
>>> [1] 4 8
>>>
>>> We are here retracing the path the Hadley took in some of his
>ggplot2 design decsions. Unfortunately for me those NSE rules often
>left me confused about what should and shouldn't be 'quoted' in the
>as-character sense and what should be quote()-ed or "unquoted" in the
>bquote() sense.
>>> --
>>>
>>>>
>>>>
>>>>       This produces what's desired in a way that seems simpler to
>me.
>>>>
>>>>
>>>>       By the way, I really appreciate Peter's insightful comments:
>>>>
>>>>
>>>> eval.w.attachOops <- function(x, Dat){
>>>>   attach(Dat)
>>>>   X <- x
>>>>   detach()
>>>>   X
>>>> }
>>>>> eval.w.attachOops(a/2, dat)
>>>> The following object is masked _by_ .GlobalEnv:
>>>>
>>>>     a
>>>>
>>>> [1] 1.570796
>>>>> eval.w.attachOops(b/2, dat)
>>>> The following object is masked _by_ .GlobalEnv:
>>>>
>>>>     a
>>>>
>>>> Error in eval.w.attachOops(b/2, dat) : object 'b' not found
>>>>> search()
>>>> [1] ".GlobalEnv"        "Dat"               "package:graphics"
>>>> [4] "package:grDevices" "package:utils"     "package:datasets"
>>>> [7] "package:methods"   "Autoloads"         "package:base"
>>>>> objects(2)
>>>> [1] "a"
>>>>
>>>> *** NOTES:
>>>>
>>>>
>>>>       1.  This gives a likely wrong answer with a warning if "a"
>exists in .GlobalEnv, and leaves "Dat" (NOT "dat") attached upon exit.
>>>>
>>>>
>>>>
>>>>       2.  A stray "detach()" [not shown here] detached
>"package:stats".  oops.
>>>>
>>>>
>>>> *** Using "on.exit" fixes the problem with failure to detach but
>not the likely wrong answer:
>>>>
>>>>
>>>> detach()
>>>> search()
>>>> eval.w.attachStillWrong <- function(x, dat){
>>>>   attach(dat)
>>>>   on.exit(detach(dat))
>>>>   X <- x
>>>>   X
>>>> }
>>>> The following object is masked _by_ .GlobalEnv:
>>>>
>>>>     a
>>>>
>>>> [1] 1.570796
>>>>> eval.w.attachStillWrong(b/2, dat)
>>>> The following object is masked _by_ .GlobalEnv:
>>>>
>>>>     a
>>>>
>>>> Error in eval.w.attachStillWrong(b/2, dat) : object 'b' not found
>>>>> search()
>>>> [1] ".GlobalEnv"        "package:grDevices" "package:utils"
>>>> [4] "package:datasets"  "package:methods"   "Autoloads"
>>>> [7] "package:base"
>>>>
>>>>
>>>>       Thanks again to Peter and David.  Spencer
>>>>
>>>>> Peter D.
>>>>>
>>>>>
>>>>>
>>>>>> --
>>>>>> David.
>>>>>>
>>>>>>
>>>>>>> eval.w.with(a/2, dat) # Error ... 'a' not found
>>>>>>>
>>>>>>>
>>>>>>> Thanks, Spencer Graves
>>>>>>>
>>>>>>>     [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible
>code.
>>>>>> David Winsemius
>>>>>> Alameda, CA, USA
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible
>code.
>>> David Winsemius
>>> Alameda, CA, USA
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From Muhammad2.Bilal at live.uwe.ac.uk  Mon May  9 01:14:27 2016
From: Muhammad2.Bilal at live.uwe.ac.uk (Muhammad Bilal)
Date: Sun, 8 May 2016 23:14:27 +0000
Subject: [R] Problem while predicting in regression trees
Message-ID: <DB5PR07MB1109CA40FD696496736EAD5ADB7F0@DB5PR07MB1109.eurprd07.prod.outlook.com>

Hi All,

I have the following script, that raises error at the last command. I am new to R and require some clarification on what is going wrong.

#Creating the training and testing data sets
splitFlag <- sample.split(pfi_v3, SplitRatio = 0.7)
trainPFI <- subset(pfi_v3, splitFlag==TRUE)
testPFI <- subset(pfi_v3, splitFlag==FALSE)


#Structure of the trainPFI data frame
> str(trainPFI)
*******
'data.frame': 491 obs. of  16 variables:
 $ project_id             : int  1 2 3 6 7 9 10 12 13 14 ...
 $ project_lat            : num  51.4 51.5 52.2 51.9 52.5 ...
 $ project_lon            : num  -0.642 -1.85 0.08 -0.401 -1.888 ...
 $ sector                 : Factor w/ 9 levels "Defense","Hospitals",..: 4 4 4 6 6 6 6 6 6 6 ...
 $ contract_type          : chr  "Turnkey" "Turnkey" "Turnkey" "Turnkey" ...
 $ project_duration       : int  1826 3652 121 730 730 790 522 819 998 372 ...
 $ project_delay          : int  -323 0 -60 0 0 0 -91 0 0 7 ...
 $ capital_value          : num  6.7 5.8 21.8 24.2 40.7 10.7 70 24.5 60.5 78 ...
 $ project_delay_pct      : num  -17.7 0 -49.6 0 0 0 -17.4 0 0 1.9 ...
 $ delay_type             : Ord.factor w/ 9 levels "7 months early & beyond"<..: 1 5 3 5 5 5 2 5 5 6 ...

library(caret)
library(e1071)

set.seed(100)

tr.control <- trainControl(method="cv", number=10)
cp.grid <- expand.grid(.cp = (0:10)*0.001)

#Fitting the model using regression tree
tr_m <- train(project_delay ~ project_lon + project_lat + project_duration + sector + contract_type + capital_value, data = trainPFI, method="rpart", trControl=tr.control, tuneGrid = cp.grid)

tr_m

CART
491 samples
15 predictor
No pre-processing
Resampling: Cross-Validated (10 fold)
Summary of sample sizes: 443, 442, 441, 442, 441, 442, ...
Resampling results across tuning parameters:
  cp     RMSE      Rsquared
  0.000  441.1524  0.5417064
  0.001  439.6319  0.5451104
  0.002  437.4039  0.5487203
  0.003  432.3675  0.5566661
  0.004  434.2138  0.5519964
  0.005  431.6635  0.5577771
  0.006  436.6163  0.5474135
  0.007  440.5473  0.5407240
  0.008  441.0876  0.5399614
  0.009  441.5715  0.5401718
  0.010  441.1401  0.5407121
RMSE was used to select the optimal model using  the smallest value.
The final value used for the model was cp = 0.005.

#Fetching the best tree
best_tree <- tr_m$finalModel

Alright, all the aforementioned commands worked fine.

Except the subsequent command raises error, when the developed model is used to make predictions:
best_tree_pred <- predict(best_tree, newdata = testPFI)
Error in eval(expr, envir, enclos) : object 'sectorHospitals' not found

Can someone guide me what to do to resolve this issue.

Any help will be highly appreciated.

Many Thanks and

Kind Regards

--
Muhammad Bilal
Research Fellow and Doctoral Researcher,
Bristol Enterprise, Research, and Innovation Centre (BERIC),
University of the West of England (UWE),
Frenchay Campus,
Bristol,
BS16 1QY

muhammad2.bilal at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon May  9 02:28:04 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 8 May 2016 17:28:04 -0700
Subject: [R] with vs. attach
In-Reply-To: <AC401D99-DFB4-4206-B164-68CA1F62F93F@dcn.davis.ca.us>
References: <901fd028-5e60-cf67-906d-c29e43d8762b@effectivedefense.org>
	<4808B356-E233-4859-A15E-745D26D4B85C@comcast.net>
	<CD4AB490-E960-44E9-BAC0-D30E96518922@gmail.com>
	<02d73d7c-2699-dc24-8552-048491dc21fa@effectivedefense.org>
	<FAC95CBE-8E91-4ED3-B3AE-DF6568354D7B@comcast.net>
	<CABdHhvELpD3+JA2TkFz1OfTXSy5HvWRZJ4d0m_03hMnrtFeboA@mail.gmail.com>
	<bdcc1ca4-4af5-22c0-0678-50f8739f321b@effectivedefense.org>
	<AC401D99-DFB4-4206-B164-68CA1F62F93F@dcn.davis.ca.us>
Message-ID: <CAGxFJbQc1C90c45ChKP_dmz4kZ1MKayGrFt5QKMXgqxC9LHReg@mail.gmail.com>

Jeff:

That's easy to do already with substitute(), since you can pass around
an unevaluated expression (a parse tree) however you like. As I read
it, (admittedly quickly) what it's main feature is that it allows you
more control over the environment in which the expression is finally
evaluated -- as well as permitting nested expression evaluation fairly
easily.

But maybe we're saying the same thing ...  IMHO I think Hadley has
gone overboard here, worrying about rarely important issues, as you
seem to be intimating also.

Feel free to set me straight... or ignore.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, May 8, 2016 at 4:02 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> The lazyeval package addresses the problem of how to delay evaluation even when the function you want to do the evaluation in is buried two or more function calls below where the original call was made. If you are not building nested function calls with delayed evaluation then you probably don't need that package.
> --
> Sent from my phone. Please excuse my brevity.
>
> On May 8, 2016 3:30:16 PM PDT, Spencer Graves <spencer.graves at effectivedefense.org> wrote:
>>Hi, Hadley et al.:
>>
>>
>>       Hadley's link requires his development version of "lazyeval",
>>which can be obtained as follows:
>>
>>
>>library(devtools)
>>install_github("hadley/lazyeval")
>>
>>
>>       Hadley's link describes real problems with elegant solutions.
>>
>>
>>       However, David's solution solved my immediate problem, and it's
>>not immediately obvious to me how his "expr_text" function (or other
>>functions in "lazyevel") to produce a better solution.
>>
>>
>>       Thanks again to David, Peter and Hadley for their replies.
>>
>>
>>       Spencer Graves
>>
>>
>>On 5/6/2016 5:08 PM, Hadley Wickham wrote:
>>> You may want to read http://rpubs.com/hadley/157957, which captures
>>my
>>> latest thinking (and tooling) around this problem. Feedback is much
>>> appreciated.
>>>
>>> Hadley
>>>
>>> On Fri, May 6, 2016 at 2:14 PM, David Winsemius
>><dwinsemius at comcast.net> wrote:
>>>>> On May 6, 2016, at 5:47 AM, Spencer Graves
>><spencer.graves at effectivedefense.org> wrote:
>>>>>
>>>>>
>>>>>
>>>>> On 5/6/2016 6:46 AM, peter dalgaard wrote:
>>>>>> On 06 May 2016, at 02:43 , David Winsemius
>><dwinsemius at comcast.net> wrote:
>>>>>>
>>>>>>>> On May 5, 2016, at 5:12 PM, Spencer Graves
>><spencer.graves at effectivedefense.org> wrote:
>>>>>>>>
>>>>>>>> I want a function to evaluate one argument
>>>>>>>> in the environment of a data.frame supplied
>>>>>>>> as another argument.  "attach" works for
>>>>>>>> this, but "with" does not.  Is there a way
>>>>>>>> to make "with" work?  I'd rather not attach
>>>>>>>> the data.frame.
>>>>>>>>
>>>>>>>>
>>>>>>>> With the following two functions "eval.w.attach"
>>>>>>>> works but "eval.w.with" fails:
>>>>>>>>
>>>>>>>>
>>>>>>>> dat <- data.frame(a=1:2)
>>>>>>>> eval.w.attach <- function(x, dat){
>>>>>>>>   attach(dat)
>>>>>>>>   X <- x
>>>>>>>>   detach()
>>>>>>>>   X
>>>>>>>> }
>>>>>>>>
>>>>>>>> eval.w.with <- function(x, dat){
>>>>>>>>   with(dat, x)
>>>>>>>> }
>>>>>>>>
>>>>>>>> eval.w.attach(a/2, dat) # returns c(.5, 1)
>>>>>>> How about using eval( substitute( ...))?
>>>>>>>
>>>>>>> eval.w.sub <- function(expr, datt){
>>>>>>>    eval( substitute(expr), env=datt)
>>>>>>>                          }
>>>>>>> eval.w.sub(a/2, dat)
>>>>>>> #[1] 0.5 1.0
>>>>>>>
>>>>>>>
>>>>>> Actually, I think a better overall strategy is to say that if you
>>want to pass an expression to a function, then pass an expression
>>object (or a call object or maybe a formula object).
>>>>>>
>>>>>> Once you figure out _how_ your eval.w.attach works (sort of),
>>you'll get the creeps:
>>>>>>
>>>>>> Lazy evaluation causes the argument x to be evaluated after the
>>attach(), hence the evaluation environment of an actual argument is
>>being temporarily modified from inside a function.
>>>>>>
>>>>>> Apart from upsetting computer science purists, there could be
>>hidden problems: One major issue is that  values in "dat" could be
>>masked by values in the global environment, another issue is that an
>>error in evaluating the expression will leave dat attached. So at a
>>minimum, you need to recode using on.exit() magic.
>>>>>>
>>>>>> So my preferences go along these lines:
>>>>>>
>>>>>>> dat <- data.frame(a=1:2)
>>>>>>> eval.expression <- function(e, dat) eval(e, dat)
>>>>>>> eval.expression(quote(a/2), dat)
>>>>>> [1] 0.5 1.0
>>>>>>> eval.expression(expression(a/2), dat)
>>>>>> [1] 0.5 1.0
>>>>>>
>>>>>>> eval.formula <- function(f, dat) eval(f[[2]], dat)
>>>>>>> eval.formula(~a/2, dat)
>>>>>> [1] 0.5 1.0
>>>>> Hi, Peter:
>>>>>
>>>>>
>>>>>       I don't like eval.expression or eval.formula, because they
>>don't automatically accept what I naively thought should work and
>>require more knowledge of the user.  What about David's eval.w.sub:
>>>>>
>>>>>
>>>>> a <- pi
>>>>> dat <- data.frame(a=1:2)
>>>>> eval.w.sub <- function(a, Dat){
>>>>>   eval( substitute(a), env=Dat)
>>>>> }
>>>>>> eval.w.sub(a/2, dat)
>>>>> [1] 0.5 1.0
>>>> I liked eval.expression and tested it with a bquote(...) argument to
>>see if that would succeed. It did, but it didn't return what you wanted
>>for `a/2`, so I tried seeing if a "double eval wuold deliver both yours
>>and my desired results:
>>>>
>>>>   eval.w.sub <- function(a, Dat){
>>>>    eval( eval(substitute(a),Dat), env=Dat)
>>>>   }
>>>> x=2
>>>>   eval.w.sub( a/2, dat)
>>>> [1] 0.5 1.0
>>>>   eval.w.sub( bquote(2*a*.(x) ), dat)
>>>> [1] 4 8
>>>>
>>>> We are here retracing the path the Hadley took in some of his
>>ggplot2 design decsions. Unfortunately for me those NSE rules often
>>left me confused about what should and shouldn't be 'quoted' in the
>>as-character sense and what should be quote()-ed or "unquoted" in the
>>bquote() sense.
>>>> --
>>>>
>>>>>
>>>>>
>>>>>       This produces what's desired in a way that seems simpler to
>>me.
>>>>>
>>>>>
>>>>>       By the way, I really appreciate Peter's insightful comments:
>>>>>
>>>>>
>>>>> eval.w.attachOops <- function(x, Dat){
>>>>>   attach(Dat)
>>>>>   X <- x
>>>>>   detach()
>>>>>   X
>>>>> }
>>>>>> eval.w.attachOops(a/2, dat)
>>>>> The following object is masked _by_ .GlobalEnv:
>>>>>
>>>>>     a
>>>>>
>>>>> [1] 1.570796
>>>>>> eval.w.attachOops(b/2, dat)
>>>>> The following object is masked _by_ .GlobalEnv:
>>>>>
>>>>>     a
>>>>>
>>>>> Error in eval.w.attachOops(b/2, dat) : object 'b' not found
>>>>>> search()
>>>>> [1] ".GlobalEnv"        "Dat"               "package:graphics"
>>>>> [4] "package:grDevices" "package:utils"     "package:datasets"
>>>>> [7] "package:methods"   "Autoloads"         "package:base"
>>>>>> objects(2)
>>>>> [1] "a"
>>>>>
>>>>> *** NOTES:
>>>>>
>>>>>
>>>>>       1.  This gives a likely wrong answer with a warning if "a"
>>exists in .GlobalEnv, and leaves "Dat" (NOT "dat") attached upon exit.
>>>>>
>>>>>
>>>>>
>>>>>       2.  A stray "detach()" [not shown here] detached
>>"package:stats".  oops.
>>>>>
>>>>>
>>>>> *** Using "on.exit" fixes the problem with failure to detach but
>>not the likely wrong answer:
>>>>>
>>>>>
>>>>> detach()
>>>>> search()
>>>>> eval.w.attachStillWrong <- function(x, dat){
>>>>>   attach(dat)
>>>>>   on.exit(detach(dat))
>>>>>   X <- x
>>>>>   X
>>>>> }
>>>>> The following object is masked _by_ .GlobalEnv:
>>>>>
>>>>>     a
>>>>>
>>>>> [1] 1.570796
>>>>>> eval.w.attachStillWrong(b/2, dat)
>>>>> The following object is masked _by_ .GlobalEnv:
>>>>>
>>>>>     a
>>>>>
>>>>> Error in eval.w.attachStillWrong(b/2, dat) : object 'b' not found
>>>>>> search()
>>>>> [1] ".GlobalEnv"        "package:grDevices" "package:utils"
>>>>> [4] "package:datasets"  "package:methods"   "Autoloads"
>>>>> [7] "package:base"
>>>>>
>>>>>
>>>>>       Thanks again to Peter and David.  Spencer
>>>>>
>>>>>> Peter D.
>>>>>>
>>>>>>
>>>>>>
>>>>>>> --
>>>>>>> David.
>>>>>>>
>>>>>>>
>>>>>>>> eval.w.with(a/2, dat) # Error ... 'a' not found
>>>>>>>>
>>>>>>>>
>>>>>>>> Thanks, Spencer Graves
>>>>>>>>
>>>>>>>>     [[alternative HTML version deleted]]
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible
>>code.
>>>>>>> David Winsemius
>>>>>>> Alameda, CA, USA
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible
>>code.
>>>> David Winsemius
>>>> Alameda, CA, USA
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon May  9 02:42:39 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 8 May 2016 17:42:39 -0700
Subject: [R] Problem while predicting in regression trees
In-Reply-To: <DB5PR07MB1109CA40FD696496736EAD5ADB7F0@DB5PR07MB1109.eurprd07.prod.outlook.com>
References: <DB5PR07MB1109CA40FD696496736EAD5ADB7F0@DB5PR07MB1109.eurprd07.prod.outlook.com>
Message-ID: <CAGxFJbS8m1b8gjzU9kZbmo+upcz1KbymXt594XpKVLS1rbyTNQ@mail.gmail.com>

It seems that the data that you used for prediction contained a level
"Hospitals" for the sector factor that did not appear in the training
data (or maybe it's the other way round). Check this.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, May 8, 2016 at 4:14 PM, Muhammad Bilal
<Muhammad2.Bilal at live.uwe.ac.uk> wrote:
> Hi All,
>
> I have the following script, that raises error at the last command. I am new to R and require some clarification on what is going wrong.
>
> #Creating the training and testing data sets
> splitFlag <- sample.split(pfi_v3, SplitRatio = 0.7)
> trainPFI <- subset(pfi_v3, splitFlag==TRUE)
> testPFI <- subset(pfi_v3, splitFlag==FALSE)
>
>
> #Structure of the trainPFI data frame
>> str(trainPFI)
> *******
> 'data.frame': 491 obs. of  16 variables:
>  $ project_id             : int  1 2 3 6 7 9 10 12 13 14 ...
>  $ project_lat            : num  51.4 51.5 52.2 51.9 52.5 ...
>  $ project_lon            : num  -0.642 -1.85 0.08 -0.401 -1.888 ...
>  $ sector                 : Factor w/ 9 levels "Defense","Hospitals",..: 4 4 4 6 6 6 6 6 6 6 ...
>  $ contract_type          : chr  "Turnkey" "Turnkey" "Turnkey" "Turnkey" ...
>  $ project_duration       : int  1826 3652 121 730 730 790 522 819 998 372 ...
>  $ project_delay          : int  -323 0 -60 0 0 0 -91 0 0 7 ...
>  $ capital_value          : num  6.7 5.8 21.8 24.2 40.7 10.7 70 24.5 60.5 78 ...
>  $ project_delay_pct      : num  -17.7 0 -49.6 0 0 0 -17.4 0 0 1.9 ...
>  $ delay_type             : Ord.factor w/ 9 levels "7 months early & beyond"<..: 1 5 3 5 5 5 2 5 5 6 ...
>
> library(caret)
> library(e1071)
>
> set.seed(100)
>
> tr.control <- trainControl(method="cv", number=10)
> cp.grid <- expand.grid(.cp = (0:10)*0.001)
>
> #Fitting the model using regression tree
> tr_m <- train(project_delay ~ project_lon + project_lat + project_duration + sector + contract_type + capital_value, data = trainPFI, method="rpart", trControl=tr.control, tuneGrid = cp.grid)
>
> tr_m
>
> CART
> 491 samples
> 15 predictor
> No pre-processing
> Resampling: Cross-Validated (10 fold)
> Summary of sample sizes: 443, 442, 441, 442, 441, 442, ...
> Resampling results across tuning parameters:
>   cp     RMSE      Rsquared
>   0.000  441.1524  0.5417064
>   0.001  439.6319  0.5451104
>   0.002  437.4039  0.5487203
>   0.003  432.3675  0.5566661
>   0.004  434.2138  0.5519964
>   0.005  431.6635  0.5577771
>   0.006  436.6163  0.5474135
>   0.007  440.5473  0.5407240
>   0.008  441.0876  0.5399614
>   0.009  441.5715  0.5401718
>   0.010  441.1401  0.5407121
> RMSE was used to select the optimal model using  the smallest value.
> The final value used for the model was cp = 0.005.
>
> #Fetching the best tree
> best_tree <- tr_m$finalModel
>
> Alright, all the aforementioned commands worked fine.
>
> Except the subsequent command raises error, when the developed model is used to make predictions:
> best_tree_pred <- predict(best_tree, newdata = testPFI)
> Error in eval(expr, envir, enclos) : object 'sectorHospitals' not found
>
> Can someone guide me what to do to resolve this issue.
>
> Any help will be highly appreciated.
>
> Many Thanks and
>
> Kind Regards
>
> --
> Muhammad Bilal
> Research Fellow and Doctoral Researcher,
> Bristol Enterprise, Research, and Innovation Centre (BERIC),
> University of the West of England (UWE),
> Frenchay Campus,
> Bristol,
> BS16 1QY
>
> muhammad2.bilal at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon May  9 02:46:35 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 8 May 2016 17:46:35 -0700
Subject: [R] with vs. attach
In-Reply-To: <CAGxFJbQc1C90c45ChKP_dmz4kZ1MKayGrFt5QKMXgqxC9LHReg@mail.gmail.com>
References: <901fd028-5e60-cf67-906d-c29e43d8762b@effectivedefense.org>
	<4808B356-E233-4859-A15E-745D26D4B85C@comcast.net>
	<CD4AB490-E960-44E9-BAC0-D30E96518922@gmail.com>
	<02d73d7c-2699-dc24-8552-048491dc21fa@effectivedefense.org>
	<FAC95CBE-8E91-4ED3-B3AE-DF6568354D7B@comcast.net>
	<CABdHhvELpD3+JA2TkFz1OfTXSy5HvWRZJ4d0m_03hMnrtFeboA@mail.gmail.com>
	<bdcc1ca4-4af5-22c0-0678-50f8739f321b@effectivedefense.org>
	<AC401D99-DFB4-4206-B164-68CA1F62F93F@dcn.davis.ca.us>
	<CAGxFJbQc1C90c45ChKP_dmz4kZ1MKayGrFt5QKMXgqxC9LHReg@mail.gmail.com>
Message-ID: <CAGxFJbR0YXWhsbvDm7HoviOZC92VC3K57WtinqeVsJ+nWGuzCQ@mail.gmail.com>

... To be clear, Hadley or anyone else should also feel free to set me
straight, preferably publicly, but privately if you prefer.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, May 8, 2016 at 5:28 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Jeff:
>
> That's easy to do already with substitute(), since you can pass around
> an unevaluated expression (a parse tree) however you like. As I read
> it, (admittedly quickly) what it's main feature is that it allows you
> more control over the environment in which the expression is finally
> evaluated -- as well as permitting nested expression evaluation fairly
> easily.
>
> But maybe we're saying the same thing ...  IMHO I think Hadley has
> gone overboard here, worrying about rarely important issues, as you
> seem to be intimating also.
>
> Feel free to set me straight... or ignore.
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, May 8, 2016 at 4:02 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>> The lazyeval package addresses the problem of how to delay evaluation even when the function you want to do the evaluation in is buried two or more function calls below where the original call was made. If you are not building nested function calls with delayed evaluation then you probably don't need that package.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On May 8, 2016 3:30:16 PM PDT, Spencer Graves <spencer.graves at effectivedefense.org> wrote:
>>>Hi, Hadley et al.:
>>>
>>>
>>>       Hadley's link requires his development version of "lazyeval",
>>>which can be obtained as follows:
>>>
>>>
>>>library(devtools)
>>>install_github("hadley/lazyeval")
>>>
>>>
>>>       Hadley's link describes real problems with elegant solutions.
>>>
>>>
>>>       However, David's solution solved my immediate problem, and it's
>>>not immediately obvious to me how his "expr_text" function (or other
>>>functions in "lazyevel") to produce a better solution.
>>>
>>>
>>>       Thanks again to David, Peter and Hadley for their replies.
>>>
>>>
>>>       Spencer Graves
>>>
>>>
>>>On 5/6/2016 5:08 PM, Hadley Wickham wrote:
>>>> You may want to read http://rpubs.com/hadley/157957, which captures
>>>my
>>>> latest thinking (and tooling) around this problem. Feedback is much
>>>> appreciated.
>>>>
>>>> Hadley
>>>>
>>>> On Fri, May 6, 2016 at 2:14 PM, David Winsemius
>>><dwinsemius at comcast.net> wrote:
>>>>>> On May 6, 2016, at 5:47 AM, Spencer Graves
>>><spencer.graves at effectivedefense.org> wrote:
>>>>>>
>>>>>>
>>>>>>
>>>>>> On 5/6/2016 6:46 AM, peter dalgaard wrote:
>>>>>>> On 06 May 2016, at 02:43 , David Winsemius
>>><dwinsemius at comcast.net> wrote:
>>>>>>>
>>>>>>>>> On May 5, 2016, at 5:12 PM, Spencer Graves
>>><spencer.graves at effectivedefense.org> wrote:
>>>>>>>>>
>>>>>>>>> I want a function to evaluate one argument
>>>>>>>>> in the environment of a data.frame supplied
>>>>>>>>> as another argument.  "attach" works for
>>>>>>>>> this, but "with" does not.  Is there a way
>>>>>>>>> to make "with" work?  I'd rather not attach
>>>>>>>>> the data.frame.
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> With the following two functions "eval.w.attach"
>>>>>>>>> works but "eval.w.with" fails:
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> dat <- data.frame(a=1:2)
>>>>>>>>> eval.w.attach <- function(x, dat){
>>>>>>>>>   attach(dat)
>>>>>>>>>   X <- x
>>>>>>>>>   detach()
>>>>>>>>>   X
>>>>>>>>> }
>>>>>>>>>
>>>>>>>>> eval.w.with <- function(x, dat){
>>>>>>>>>   with(dat, x)
>>>>>>>>> }
>>>>>>>>>
>>>>>>>>> eval.w.attach(a/2, dat) # returns c(.5, 1)
>>>>>>>> How about using eval( substitute( ...))?
>>>>>>>>
>>>>>>>> eval.w.sub <- function(expr, datt){
>>>>>>>>    eval( substitute(expr), env=datt)
>>>>>>>>                          }
>>>>>>>> eval.w.sub(a/2, dat)
>>>>>>>> #[1] 0.5 1.0
>>>>>>>>
>>>>>>>>
>>>>>>> Actually, I think a better overall strategy is to say that if you
>>>want to pass an expression to a function, then pass an expression
>>>object (or a call object or maybe a formula object).
>>>>>>>
>>>>>>> Once you figure out _how_ your eval.w.attach works (sort of),
>>>you'll get the creeps:
>>>>>>>
>>>>>>> Lazy evaluation causes the argument x to be evaluated after the
>>>attach(), hence the evaluation environment of an actual argument is
>>>being temporarily modified from inside a function.
>>>>>>>
>>>>>>> Apart from upsetting computer science purists, there could be
>>>hidden problems: One major issue is that  values in "dat" could be
>>>masked by values in the global environment, another issue is that an
>>>error in evaluating the expression will leave dat attached. So at a
>>>minimum, you need to recode using on.exit() magic.
>>>>>>>
>>>>>>> So my preferences go along these lines:
>>>>>>>
>>>>>>>> dat <- data.frame(a=1:2)
>>>>>>>> eval.expression <- function(e, dat) eval(e, dat)
>>>>>>>> eval.expression(quote(a/2), dat)
>>>>>>> [1] 0.5 1.0
>>>>>>>> eval.expression(expression(a/2), dat)
>>>>>>> [1] 0.5 1.0
>>>>>>>
>>>>>>>> eval.formula <- function(f, dat) eval(f[[2]], dat)
>>>>>>>> eval.formula(~a/2, dat)
>>>>>>> [1] 0.5 1.0
>>>>>> Hi, Peter:
>>>>>>
>>>>>>
>>>>>>       I don't like eval.expression or eval.formula, because they
>>>don't automatically accept what I naively thought should work and
>>>require more knowledge of the user.  What about David's eval.w.sub:
>>>>>>
>>>>>>
>>>>>> a <- pi
>>>>>> dat <- data.frame(a=1:2)
>>>>>> eval.w.sub <- function(a, Dat){
>>>>>>   eval( substitute(a), env=Dat)
>>>>>> }
>>>>>>> eval.w.sub(a/2, dat)
>>>>>> [1] 0.5 1.0
>>>>> I liked eval.expression and tested it with a bquote(...) argument to
>>>see if that would succeed. It did, but it didn't return what you wanted
>>>for `a/2`, so I tried seeing if a "double eval wuold deliver both yours
>>>and my desired results:
>>>>>
>>>>>   eval.w.sub <- function(a, Dat){
>>>>>    eval( eval(substitute(a),Dat), env=Dat)
>>>>>   }
>>>>> x=2
>>>>>   eval.w.sub( a/2, dat)
>>>>> [1] 0.5 1.0
>>>>>   eval.w.sub( bquote(2*a*.(x) ), dat)
>>>>> [1] 4 8
>>>>>
>>>>> We are here retracing the path the Hadley took in some of his
>>>ggplot2 design decsions. Unfortunately for me those NSE rules often
>>>left me confused about what should and shouldn't be 'quoted' in the
>>>as-character sense and what should be quote()-ed or "unquoted" in the
>>>bquote() sense.
>>>>> --
>>>>>
>>>>>>
>>>>>>
>>>>>>       This produces what's desired in a way that seems simpler to
>>>me.
>>>>>>
>>>>>>
>>>>>>       By the way, I really appreciate Peter's insightful comments:
>>>>>>
>>>>>>
>>>>>> eval.w.attachOops <- function(x, Dat){
>>>>>>   attach(Dat)
>>>>>>   X <- x
>>>>>>   detach()
>>>>>>   X
>>>>>> }
>>>>>>> eval.w.attachOops(a/2, dat)
>>>>>> The following object is masked _by_ .GlobalEnv:
>>>>>>
>>>>>>     a
>>>>>>
>>>>>> [1] 1.570796
>>>>>>> eval.w.attachOops(b/2, dat)
>>>>>> The following object is masked _by_ .GlobalEnv:
>>>>>>
>>>>>>     a
>>>>>>
>>>>>> Error in eval.w.attachOops(b/2, dat) : object 'b' not found
>>>>>>> search()
>>>>>> [1] ".GlobalEnv"        "Dat"               "package:graphics"
>>>>>> [4] "package:grDevices" "package:utils"     "package:datasets"
>>>>>> [7] "package:methods"   "Autoloads"         "package:base"
>>>>>>> objects(2)
>>>>>> [1] "a"
>>>>>>
>>>>>> *** NOTES:
>>>>>>
>>>>>>
>>>>>>       1.  This gives a likely wrong answer with a warning if "a"
>>>exists in .GlobalEnv, and leaves "Dat" (NOT "dat") attached upon exit.
>>>>>>
>>>>>>
>>>>>>
>>>>>>       2.  A stray "detach()" [not shown here] detached
>>>"package:stats".  oops.
>>>>>>
>>>>>>
>>>>>> *** Using "on.exit" fixes the problem with failure to detach but
>>>not the likely wrong answer:
>>>>>>
>>>>>>
>>>>>> detach()
>>>>>> search()
>>>>>> eval.w.attachStillWrong <- function(x, dat){
>>>>>>   attach(dat)
>>>>>>   on.exit(detach(dat))
>>>>>>   X <- x
>>>>>>   X
>>>>>> }
>>>>>> The following object is masked _by_ .GlobalEnv:
>>>>>>
>>>>>>     a
>>>>>>
>>>>>> [1] 1.570796
>>>>>>> eval.w.attachStillWrong(b/2, dat)
>>>>>> The following object is masked _by_ .GlobalEnv:
>>>>>>
>>>>>>     a
>>>>>>
>>>>>> Error in eval.w.attachStillWrong(b/2, dat) : object 'b' not found
>>>>>>> search()
>>>>>> [1] ".GlobalEnv"        "package:grDevices" "package:utils"
>>>>>> [4] "package:datasets"  "package:methods"   "Autoloads"
>>>>>> [7] "package:base"
>>>>>>
>>>>>>
>>>>>>       Thanks again to Peter and David.  Spencer
>>>>>>
>>>>>>> Peter D.
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>> --
>>>>>>>> David.
>>>>>>>>
>>>>>>>>
>>>>>>>>> eval.w.with(a/2, dat) # Error ... 'a' not found
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> Thanks, Spencer Graves
>>>>>>>>>
>>>>>>>>>     [[alternative HTML version deleted]]
>>>>>>>>>
>>>>>>>>> ______________________________________________
>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>>see
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>> PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>>>>>>> and provide commented, minimal, self-contained, reproducible
>>>code.
>>>>>>>> David Winsemius
>>>>>>>> Alameda, CA, USA
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible
>>>code.
>>>>> David Winsemius
>>>>> Alameda, CA, USA
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Mon May  9 14:12:51 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 9 May 2016 14:12:51 +0200
Subject: [R] with vs. attach
In-Reply-To: <CAGxFJbR0YXWhsbvDm7HoviOZC92VC3K57WtinqeVsJ+nWGuzCQ@mail.gmail.com>
References: <901fd028-5e60-cf67-906d-c29e43d8762b@effectivedefense.org>
	<4808B356-E233-4859-A15E-745D26D4B85C@comcast.net>
	<CD4AB490-E960-44E9-BAC0-D30E96518922@gmail.com>
	<02d73d7c-2699-dc24-8552-048491dc21fa@effectivedefense.org>
	<FAC95CBE-8E91-4ED3-B3AE-DF6568354D7B@comcast.net>
	<CABdHhvELpD3+JA2TkFz1OfTXSy5HvWRZJ4d0m_03hMnrtFeboA@mail.gmail.com>
	<bdcc1ca4-4af5-22c0-0678-50f8739f321b@effectivedefense.org>
	<AC401D99-DFB4-4206-B164-68CA1F62F93F@dcn.davis.ca.us>
	<CAGxFJbQc1C90c45ChKP_dmz4kZ1MKayGrFt5QKMXgqxC9LHReg@mail.gmail.com>
	<CAGxFJbR0YXWhsbvDm7HoviOZC92VC3K57WtinqeVsJ+nWGuzCQ@mail.gmail.com>
Message-ID: <E5668628-4D62-451A-AB99-BA52D2C3BD09@gmail.com>


On 09 May 2016, at 02:46 , Bert Gunter <bgunter.4567 at gmail.com> wrote:

> ... To be clear, Hadley or anyone else should also feel free to set me
> straight, preferably publicly, but privately if you prefer.

Not really to "set anyone straight", but there are some subtleties with mode call objects versus expression objects and formulas to be aware of. 

E.g.,

> a <- 2
> do.call("print", list(a*pi))
[1] 6.283185
> do.call("print", list(quote(a*pi)))
[1] 6.283185
> do.call("print", list(expression(a*pi)))
expression(a * pi)
> do.call("print", list(~a*pi))
~a * pi

Thing is, if you insert a call object into a parse tree, nothing is there to preserve its nature as an unevaluated expression. Similarly, in

> call("print", quote(a*pi))
print(a * pi)

the result is identical to quote(print(a * pi)), so when evaluated, quoting is not seen by print().

As far as I understand, this is also the reason that for math in ggplot, you may need as.expression(bquote(....)).

In general, I think that a number of things in R had been more cleanly implemented using formulas/expression objects than using substitution and lazy evaluation, notably subset and offset arguments in lm/glm. It would have been so much cleaner to have

lm(math ~ age, data = foo, subset = ~ sex=="1")

than the current situation where lm internally chops its own head off and substitutes with model.frame, then evaluates the call to model.frame() which in turn does eval(substitute(subset), data, env). Of course, at the time, ~ was intended specifically for Wilkinson Rogers type formulas; "abusing" it for other kinds of expressions is something of an afterthought. 

-pd

> 
> Cheers,
> Bert
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Sun, May 8, 2016 at 5:28 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> Jeff:
>> 
>> That's easy to do already with substitute(), since you can pass around
>> an unevaluated expression (a parse tree) however you like. As I read
>> it, (admittedly quickly) what it's main feature is that it allows you
>> more control over the environment in which the expression is finally
>> evaluated -- as well as permitting nested expression evaluation fairly
>> easily.
>> 
>> But maybe we're saying the same thing ...  IMHO I think Hadley has
>> gone overboard here, worrying about rarely important issues, as you
>> seem to be intimating also.
>> 
>> Feel free to set me straight... or ignore.
>> 
>> Cheers,
>> Bert
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Sun, May 8, 2016 at 4:02 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>> The lazyeval package addresses the problem of how to delay evaluation even when the function you want to do the evaluation in is buried two or more function calls below where the original call was made. If you are not building nested function calls with delayed evaluation then you probably don't need that package.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>> 
>>> On May 8, 2016 3:30:16 PM PDT, Spencer Graves <spencer.graves at effectivedefense.org> wrote:
>>>> Hi, Hadley et al.:
>>>> 
>>>> 
>>>>      Hadley's link requires his development version of "lazyeval",
>>>> which can be obtained as follows:
>>>> 
>>>> 
>>>> library(devtools)
>>>> install_github("hadley/lazyeval")
>>>> 
>>>> 
>>>>      Hadley's link describes real problems with elegant solutions.
>>>> 
>>>> 
>>>>      However, David's solution solved my immediate problem, and it's
>>>> not immediately obvious to me how his "expr_text" function (or other
>>>> functions in "lazyevel") to produce a better solution.
>>>> 
>>>> 
>>>>      Thanks again to David, Peter and Hadley for their replies.
>>>> 
>>>> 
>>>>      Spencer Graves
>>>> 
>>>> 
>>>> On 5/6/2016 5:08 PM, Hadley Wickham wrote:
>>>>> You may want to read http://rpubs.com/hadley/157957, which captures
>>>> my
>>>>> latest thinking (and tooling) around this problem. Feedback is much
>>>>> appreciated.
>>>>> 
>>>>> Hadley
>>>>> 
>>>>> On Fri, May 6, 2016 at 2:14 PM, David Winsemius
>>>> <dwinsemius at comcast.net> wrote:
>>>>>>> On May 6, 2016, at 5:47 AM, Spencer Graves
>>>> <spencer.graves at effectivedefense.org> wrote:
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> On 5/6/2016 6:46 AM, peter dalgaard wrote:
>>>>>>>> On 06 May 2016, at 02:43 , David Winsemius
>>>> <dwinsemius at comcast.net> wrote:
>>>>>>>> 
>>>>>>>>>> On May 5, 2016, at 5:12 PM, Spencer Graves
>>>> <spencer.graves at effectivedefense.org> wrote:
>>>>>>>>>> 
>>>>>>>>>> I want a function to evaluate one argument
>>>>>>>>>> in the environment of a data.frame supplied
>>>>>>>>>> as another argument.  "attach" works for
>>>>>>>>>> this, but "with" does not.  Is there a way
>>>>>>>>>> to make "with" work?  I'd rather not attach
>>>>>>>>>> the data.frame.
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> With the following two functions "eval.w.attach"
>>>>>>>>>> works but "eval.w.with" fails:
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> dat <- data.frame(a=1:2)
>>>>>>>>>> eval.w.attach <- function(x, dat){
>>>>>>>>>>  attach(dat)
>>>>>>>>>>  X <- x
>>>>>>>>>>  detach()
>>>>>>>>>>  X
>>>>>>>>>> }
>>>>>>>>>> 
>>>>>>>>>> eval.w.with <- function(x, dat){
>>>>>>>>>>  with(dat, x)
>>>>>>>>>> }
>>>>>>>>>> 
>>>>>>>>>> eval.w.attach(a/2, dat) # returns c(.5, 1)
>>>>>>>>> How about using eval( substitute( ...))?
>>>>>>>>> 
>>>>>>>>> eval.w.sub <- function(expr, datt){
>>>>>>>>>   eval( substitute(expr), env=datt)
>>>>>>>>>                         }
>>>>>>>>> eval.w.sub(a/2, dat)
>>>>>>>>> #[1] 0.5 1.0
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>> Actually, I think a better overall strategy is to say that if you
>>>> want to pass an expression to a function, then pass an expression
>>>> object (or a call object or maybe a formula object).
>>>>>>>> 
>>>>>>>> Once you figure out _how_ your eval.w.attach works (sort of),
>>>> you'll get the creeps:
>>>>>>>> 
>>>>>>>> Lazy evaluation causes the argument x to be evaluated after the
>>>> attach(), hence the evaluation environment of an actual argument is
>>>> being temporarily modified from inside a function.
>>>>>>>> 
>>>>>>>> Apart from upsetting computer science purists, there could be
>>>> hidden problems: One major issue is that  values in "dat" could be
>>>> masked by values in the global environment, another issue is that an
>>>> error in evaluating the expression will leave dat attached. So at a
>>>> minimum, you need to recode using on.exit() magic.
>>>>>>>> 
>>>>>>>> So my preferences go along these lines:
>>>>>>>> 
>>>>>>>>> dat <- data.frame(a=1:2)
>>>>>>>>> eval.expression <- function(e, dat) eval(e, dat)
>>>>>>>>> eval.expression(quote(a/2), dat)
>>>>>>>> [1] 0.5 1.0
>>>>>>>>> eval.expression(expression(a/2), dat)
>>>>>>>> [1] 0.5 1.0
>>>>>>>> 
>>>>>>>>> eval.formula <- function(f, dat) eval(f[[2]], dat)
>>>>>>>>> eval.formula(~a/2, dat)
>>>>>>>> [1] 0.5 1.0
>>>>>>> Hi, Peter:
>>>>>>> 
>>>>>>> 
>>>>>>>      I don't like eval.expression or eval.formula, because they
>>>> don't automatically accept what I naively thought should work and
>>>> require more knowledge of the user.  What about David's eval.w.sub:
>>>>>>> 
>>>>>>> 
>>>>>>> a <- pi
>>>>>>> dat <- data.frame(a=1:2)
>>>>>>> eval.w.sub <- function(a, Dat){
>>>>>>>  eval( substitute(a), env=Dat)
>>>>>>> }
>>>>>>>> eval.w.sub(a/2, dat)
>>>>>>> [1] 0.5 1.0
>>>>>> I liked eval.expression and tested it with a bquote(...) argument to
>>>> see if that would succeed. It did, but it didn't return what you wanted
>>>> for `a/2`, so I tried seeing if a "double eval wuold deliver both yours
>>>> and my desired results:
>>>>>> 
>>>>>>  eval.w.sub <- function(a, Dat){
>>>>>>   eval( eval(substitute(a),Dat), env=Dat)
>>>>>>  }
>>>>>> x=2
>>>>>>  eval.w.sub( a/2, dat)
>>>>>> [1] 0.5 1.0
>>>>>>  eval.w.sub( bquote(2*a*.(x) ), dat)
>>>>>> [1] 4 8
>>>>>> 
>>>>>> We are here retracing the path the Hadley took in some of his
>>>> ggplot2 design decsions. Unfortunately for me those NSE rules often
>>>> left me confused about what should and shouldn't be 'quoted' in the
>>>> as-character sense and what should be quote()-ed or "unquoted" in the
>>>> bquote() sense.
>>>>>> --
>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>>      This produces what's desired in a way that seems simpler to
>>>> me.
>>>>>>> 
>>>>>>> 
>>>>>>>      By the way, I really appreciate Peter's insightful comments:
>>>>>>> 
>>>>>>> 
>>>>>>> eval.w.attachOops <- function(x, Dat){
>>>>>>>  attach(Dat)
>>>>>>>  X <- x
>>>>>>>  detach()
>>>>>>>  X
>>>>>>> }
>>>>>>>> eval.w.attachOops(a/2, dat)
>>>>>>> The following object is masked _by_ .GlobalEnv:
>>>>>>> 
>>>>>>>    a
>>>>>>> 
>>>>>>> [1] 1.570796
>>>>>>>> eval.w.attachOops(b/2, dat)
>>>>>>> The following object is masked _by_ .GlobalEnv:
>>>>>>> 
>>>>>>>    a
>>>>>>> 
>>>>>>> Error in eval.w.attachOops(b/2, dat) : object 'b' not found
>>>>>>>> search()
>>>>>>> [1] ".GlobalEnv"        "Dat"               "package:graphics"
>>>>>>> [4] "package:grDevices" "package:utils"     "package:datasets"
>>>>>>> [7] "package:methods"   "Autoloads"         "package:base"
>>>>>>>> objects(2)
>>>>>>> [1] "a"
>>>>>>> 
>>>>>>> *** NOTES:
>>>>>>> 
>>>>>>> 
>>>>>>>      1.  This gives a likely wrong answer with a warning if "a"
>>>> exists in .GlobalEnv, and leaves "Dat" (NOT "dat") attached upon exit.
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>>      2.  A stray "detach()" [not shown here] detached
>>>> "package:stats".  oops.
>>>>>>> 
>>>>>>> 
>>>>>>> *** Using "on.exit" fixes the problem with failure to detach but
>>>> not the likely wrong answer:
>>>>>>> 
>>>>>>> 
>>>>>>> detach()
>>>>>>> search()
>>>>>>> eval.w.attachStillWrong <- function(x, dat){
>>>>>>>  attach(dat)
>>>>>>>  on.exit(detach(dat))
>>>>>>>  X <- x
>>>>>>>  X
>>>>>>> }
>>>>>>> The following object is masked _by_ .GlobalEnv:
>>>>>>> 
>>>>>>>    a
>>>>>>> 
>>>>>>> [1] 1.570796
>>>>>>>> eval.w.attachStillWrong(b/2, dat)
>>>>>>> The following object is masked _by_ .GlobalEnv:
>>>>>>> 
>>>>>>>    a
>>>>>>> 
>>>>>>> Error in eval.w.attachStillWrong(b/2, dat) : object 'b' not found
>>>>>>>> search()
>>>>>>> [1] ".GlobalEnv"        "package:grDevices" "package:utils"
>>>>>>> [4] "package:datasets"  "package:methods"   "Autoloads"
>>>>>>> [7] "package:base"
>>>>>>> 
>>>>>>> 
>>>>>>>      Thanks again to Peter and David.  Spencer
>>>>>>> 
>>>>>>>> Peter D.
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>>> --
>>>>>>>>> David.
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>>> eval.w.with(a/2, dat) # Error ... 'a' not found
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> Thanks, Spencer Graves
>>>>>>>>>> 
>>>>>>>>>>    [[alternative HTML version deleted]]
>>>>>>>>>> 
>>>>>>>>>> ______________________________________________
>>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>>> see
>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>>> and provide commented, minimal, self-contained, reproducible
>>>> code.
>>>>>>>>> David Winsemius
>>>>>>>>> Alameda, CA, USA
>>>>>>>>> 
>>>>>>>>> ______________________________________________
>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>> and provide commented, minimal, self-contained, reproducible
>>>> code.
>>>>>> David Winsemius
>>>>>> Alameda, CA, USA
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>>> 
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From h.wickham at gmail.com  Mon May  9 14:29:10 2016
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 9 May 2016 07:29:10 -0500
Subject: [R] with vs. attach
In-Reply-To: <CAGxFJbQc1C90c45ChKP_dmz4kZ1MKayGrFt5QKMXgqxC9LHReg@mail.gmail.com>
References: <901fd028-5e60-cf67-906d-c29e43d8762b@effectivedefense.org>
	<4808B356-E233-4859-A15E-745D26D4B85C@comcast.net>
	<CD4AB490-E960-44E9-BAC0-D30E96518922@gmail.com>
	<02d73d7c-2699-dc24-8552-048491dc21fa@effectivedefense.org>
	<FAC95CBE-8E91-4ED3-B3AE-DF6568354D7B@comcast.net>
	<CABdHhvELpD3+JA2TkFz1OfTXSy5HvWRZJ4d0m_03hMnrtFeboA@mail.gmail.com>
	<bdcc1ca4-4af5-22c0-0678-50f8739f321b@effectivedefense.org>
	<AC401D99-DFB4-4206-B164-68CA1F62F93F@dcn.davis.ca.us>
	<CAGxFJbQc1C90c45ChKP_dmz4kZ1MKayGrFt5QKMXgqxC9LHReg@mail.gmail.com>
Message-ID: <CABdHhvFUWAFHMXNCGv8o8aNy7zMdPNwWOsMuhKqm77ez2=TuqQ@mail.gmail.com>

On Sun, May 8, 2016 at 7:28 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Jeff:
>
> That's easy to do already with substitute(), since you can pass around
> an unevaluated expression (a parse tree) however you like. As I read
> it, (admittedly quickly) what it's main feature is that it allows you
> more control over the environment in which the expression is finally
> evaluated -- as well as permitting nested expression evaluation fairly
> easily.
>
> But maybe we're saying the same thing ...  IMHO I think Hadley has
> gone overboard here, worrying about rarely important issues, as you
> seem to be intimating also.

These are absolutely critical issues that crop up as soon as other
people want to write functions that use your functions that use NSE.

Hadley

-- 
http://hadley.nz


From h.wickham at gmail.com  Mon May  9 14:31:39 2016
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 9 May 2016 07:31:39 -0500
Subject: [R] with vs. attach
In-Reply-To: <E5668628-4D62-451A-AB99-BA52D2C3BD09@gmail.com>
References: <901fd028-5e60-cf67-906d-c29e43d8762b@effectivedefense.org>
	<4808B356-E233-4859-A15E-745D26D4B85C@comcast.net>
	<CD4AB490-E960-44E9-BAC0-D30E96518922@gmail.com>
	<02d73d7c-2699-dc24-8552-048491dc21fa@effectivedefense.org>
	<FAC95CBE-8E91-4ED3-B3AE-DF6568354D7B@comcast.net>
	<CABdHhvELpD3+JA2TkFz1OfTXSy5HvWRZJ4d0m_03hMnrtFeboA@mail.gmail.com>
	<bdcc1ca4-4af5-22c0-0678-50f8739f321b@effectivedefense.org>
	<AC401D99-DFB4-4206-B164-68CA1F62F93F@dcn.davis.ca.us>
	<CAGxFJbQc1C90c45ChKP_dmz4kZ1MKayGrFt5QKMXgqxC9LHReg@mail.gmail.com>
	<CAGxFJbR0YXWhsbvDm7HoviOZC92VC3K57WtinqeVsJ+nWGuzCQ@mail.gmail.com>
	<E5668628-4D62-451A-AB99-BA52D2C3BD09@gmail.com>
Message-ID: <CABdHhvEeLyxP=Tz82zU8dKXFXrOPwkshyMkqhc7ykTBsxS8ofQ@mail.gmail.com>

On Mon, May 9, 2016 at 7:12 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>
> On 09 May 2016, at 02:46 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
>> ... To be clear, Hadley or anyone else should also feel free to set me
>> straight, preferably publicly, but privately if you prefer.
>
> Not really to "set anyone straight", but there are some subtleties with mode call objects versus expression objects and formulas to be aware of.
>
> E.g.,
>
>> a <- 2
>> do.call("print", list(a*pi))
> [1] 6.283185
>> do.call("print", list(quote(a*pi)))
> [1] 6.283185
>> do.call("print", list(expression(a*pi)))
> expression(a * pi)
>> do.call("print", list(~a*pi))
> ~a * pi
>
> Thing is, if you insert a call object into a parse tree, nothing is there to preserve its nature as an unevaluated expression. Similarly, in
>
>> call("print", quote(a*pi))
> print(a * pi)
>
> the result is identical to quote(print(a * pi)), so when evaluated, quoting is not seen by print().
>
> As far as I understand, this is also the reason that for math in ggplot, you may need as.expression(bquote(....)).
>
> In general, I think that a number of things in R had been more cleanly implemented using formulas/expression objects than using substitution and lazy evaluation, notably subset and offset arguments in lm/glm. It would have been so much cleaner to have
>
> lm(math ~ age, data = foo, subset = ~ sex=="1")
>
> than the current situation where lm internally chops its own head off and substitutes with model.frame, then evaluates the call to model.frame() which in turn does eval(substitute(subset), data, env). Of course, at the time, ~ was intended specifically for Wilkinson Rogers type formulas; "abusing" it for other kinds of expressions is something of an afterthought.

Yeah, to my mind, the cool thing about formulas is that they provide a
concise way to capture an environment and an expression, and then
Wilkinson Rogers are just a special case.

It's obvious impossible to go back and change how lm() etc works now,
but I'm reasonably confident that lazyeval provides a strong
foundation going forward. The quasiquotation stuff is particularly
important - and unquote-splice makes it possible to do things that are
impossible with bquote().  (Of course, unquote-splice could be added
to bquote(), but I think you'll still run into issues with
environments)

Hadley


-- 
http://hadley.nz


From a.mosnier at gmail.com  Mon May  9 15:24:11 2016
From: a.mosnier at gmail.com (Arnaud Mosnier)
Date: Mon, 9 May 2016 09:24:11 -0400
Subject: [R] Clean method to convert date and time between time zones
 keeping it in POSIXct format
Message-ID: <CANkFkEfj36sr2z2chemtcEm=mGW6AHWHgiA29zQ0bG95LJsDLw@mail.gmail.com>

Dear UseRs,

I know two ways to convert dates and time from on time zone to another but
I am pretty sure that there is a better (cleaner) way to do that.


Here are the methods I know:


## The longest way ...

T1 <- as.POSIXct("2016-05-09 10:00:00", format="%Y-%m-%d %H:%M:%S",
tz="America/New_York")

print(T1)

T2 <- as.POSIXct(format(T1, tz="UTC"), tz="UTC") # format convert it to
character, so I have to convert it back to POSIXct afterward.

print(T2)



## The shortest but probably not the cleanest ...

attributes(T1)$tzone <- "UTC"

print(T1)

	[[alternative HTML version deleted]]


From ivan.calandra at univ-reims.fr  Mon May  9 15:37:44 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Mon, 9 May 2016 15:37:44 +0200
Subject: [R] Clean method to convert date and time between time zones
 keeping it in POSIXct format
In-Reply-To: <CANkFkEfj36sr2z2chemtcEm=mGW6AHWHgiA29zQ0bG95LJsDLw@mail.gmail.com>
References: <CANkFkEfj36sr2z2chemtcEm=mGW6AHWHgiA29zQ0bG95LJsDLw@mail.gmail.com>
Message-ID: <2d25a3f1-9ec0-6db7-e21a-e98bef5bb989@univ-reims.fr>

I don't have an answer, but actually, I would have expected
as.POSIXct(T1, tz="UTC")
to work...

Looks like as.POSIXct cannot convert from class "POSIXct"

Ivan

--
Ivan Calandra, PhD
Scientific Mediator
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 09/05/2016 ? 15:24, Arnaud Mosnier a ?crit :
> Dear UseRs,
>
> I know two ways to convert dates and time from on time zone to another but
> I am pretty sure that there is a better (cleaner) way to do that.
>
>
> Here are the methods I know:
>
>
> ## The longest way ...
>
> T1 <- as.POSIXct("2016-05-09 10:00:00", format="%Y-%m-%d %H:%M:%S",
> tz="America/New_York")
>
> print(T1)
>
> T2 <- as.POSIXct(format(T1, tz="UTC"), tz="UTC") # format convert it to
> character, so I have to convert it back to POSIXct afterward.
>
> print(T2)
>
>
>
> ## The shortest but probably not the cleanest ...
>
> attributes(T1)$tzone <- "UTC"
>
> print(T1)
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ggrothendieck at gmail.com  Mon May  9 15:46:28 2016
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 9 May 2016 09:46:28 -0400
Subject: [R] Clean method to convert date and time between time zones
 keeping it in POSIXct format
In-Reply-To: <CANkFkEfj36sr2z2chemtcEm=mGW6AHWHgiA29zQ0bG95LJsDLw@mail.gmail.com>
References: <CANkFkEfj36sr2z2chemtcEm=mGW6AHWHgiA29zQ0bG95LJsDLw@mail.gmail.com>
Message-ID: <CAP01uRmVG0tzottgQjpT2YsVgYfagrkV+an1HDwWyWbtWX2qhQ@mail.gmail.com>

This involves mucking with the internals as well but it is short:

   structure(T1, tzone = "UTC")

On Mon, May 9, 2016 at 9:24 AM, Arnaud Mosnier <a.mosnier at gmail.com> wrote:
> Dear UseRs,
>
> I know two ways to convert dates and time from on time zone to another but
> I am pretty sure that there is a better (cleaner) way to do that.
>
>
> Here are the methods I know:
>
>
> ## The longest way ...
>
> T1 <- as.POSIXct("2016-05-09 10:00:00", format="%Y-%m-%d %H:%M:%S",
> tz="America/New_York")
>
> print(T1)
>
> T2 <- as.POSIXct(format(T1, tz="UTC"), tz="UTC") # format convert it to
> character, so I have to convert it back to POSIXct afterward.
>
> print(T2)
>
>
>
> ## The shortest but probably not the cleanest ...
>
> attributes(T1)$tzone <- "UTC"
>
> print(T1)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From wdunlap at tibco.com  Mon May  9 16:36:07 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 9 May 2016 07:36:07 -0700
Subject: [R] Clean method to convert date and time between time zones
 keeping it in POSIXct format
In-Reply-To: <2d25a3f1-9ec0-6db7-e21a-e98bef5bb989@univ-reims.fr>
References: <CANkFkEfj36sr2z2chemtcEm=mGW6AHWHgiA29zQ0bG95LJsDLw@mail.gmail.com>
	<2d25a3f1-9ec0-6db7-e21a-e98bef5bb989@univ-reims.fr>
Message-ID: <CAF8bMcZC-Ja=t9+qfehpXyZhB2s0KFF7GFuy=uVg9RkXa9dcjw@mail.gmail.com>

I think as.POSIXct will just pass through a POSIXct object without any
changes.  E.g.,
  > dput(as.POSIXct( structure( list(quote(foo)),
class=c("POSIXct","POSIXt"))))
  structure(list(foo), class = c("POSIXct", "POSIXt"))

If as.POSIXct( POSIXctObject, tz="ZONE") changed the time zone then a fair
bit of code would have to be changed from
    t <- as.POSIXct(t)
to
    if (!is.POSIXct(t)) {
        t <- as.POSIXct(t)
    }
so that existing POSIXct objects would not have their time zones changed.

Having a tzone<- or tz<- function could be handy.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, May 9, 2016 at 6:37 AM, Ivan Calandra <ivan.calandra at univ-reims.fr>
wrote:

> I don't have an answer, but actually, I would have expected
> as.POSIXct(T1, tz="UTC")
> to work...
>
> Looks like as.POSIXct cannot convert from class "POSIXct"
>
> Ivan
>
> --
> Ivan Calandra, PhD
> Scientific Mediator
> University of Reims Champagne-Ardenne
> GEGENAA - EA 3795
> CREA - 2 esplanade Roland Garros
> 51100 Reims, France
> +33(0)3 26 77 36 89
> ivan.calandra at univ-reims.fr
> --
> https://www.researchgate.net/profile/Ivan_Calandra
> https://publons.com/author/705639/
>
>
> Le 09/05/2016 ? 15:24, Arnaud Mosnier a ?crit :
>
>> Dear UseRs,
>>
>> I know two ways to convert dates and time from on time zone to another but
>> I am pretty sure that there is a better (cleaner) way to do that.
>>
>>
>> Here are the methods I know:
>>
>>
>> ## The longest way ...
>>
>> T1 <- as.POSIXct("2016-05-09 10:00:00", format="%Y-%m-%d %H:%M:%S",
>> tz="America/New_York")
>>
>> print(T1)
>>
>> T2 <- as.POSIXct(format(T1, tz="UTC"), tz="UTC") # format convert it to
>> character, so I have to convert it back to POSIXct afterward.
>>
>> print(T2)
>>
>>
>>
>> ## The shortest but probably not the cleanest ...
>>
>> attributes(T1)$tzone <- "UTC"
>>
>> print(T1)
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Muhammad2.Bilal at live.uwe.ac.uk  Mon May  9 17:23:45 2016
From: Muhammad2.Bilal at live.uwe.ac.uk (Muhammad Bilal)
Date: Mon, 9 May 2016 15:23:45 +0000
Subject: [R] Problem while predicting in regression trees
In-Reply-To: <CAGxFJbS8m1b8gjzU9kZbmo+upcz1KbymXt594XpKVLS1rbyTNQ@mail.gmail.com>
References: <DB5PR07MB1109CA40FD696496736EAD5ADB7F0@DB5PR07MB1109.eurprd07.prod.outlook.com>,
	<CAGxFJbS8m1b8gjzU9kZbmo+upcz1KbymXt594XpKVLS1rbyTNQ@mail.gmail.com>
Message-ID: <DB5PR07MB1109E99CC2AD0AF465F18048DB700@DB5PR07MB1109.eurprd07.prod.outlook.com>

Hi Bert,

Thanks for the response.

I checked the datasets, however, the Hospitals level appears in both of them. See the output below:

> sqldf("SELECT sector, count(*) FROM trainPFI GROUP BY sector")
            sector count(*)
1          Defense        9
2        Hospitals      101
3          Housing       32
4           Others       99
5 Public Buildings       39
6          Schools      148
7      Social Care       10
8      Transportation       27
9            Waste       26
> sqldf("SELECT sector, count(*) FROM testPFI GROUP BY sector")
            sector count(*)
1          Defense        5
2        Hospitals       47
3          Housing       11
4           Others       44
5 Public Buildings       18
6          Schools       69
7      Social Care        9
8   Transportation        8
9            Waste       12

Any thing else to try?

--
Muhammad Bilal
Research Fellow and Doctoral Researcher,
Bristol Enterprise, Research, and Innovation Centre (BERIC),
University of the West of England (UWE),
Frenchay Campus,
Bristol,
BS16 1QY

muhammad2.bilal at live.uwe.ac.uk


________________________________________
From: Bert Gunter <bgunter.4567 at gmail.com>
Sent: 09 May 2016 01:42:39
To: Muhammad Bilal
Cc: r-help at r-project.org
Subject: Re: [R] Problem while predicting in regression trees

It seems that the data that you used for prediction contained a level
"Hospitals" for the sector factor that did not appear in the training
data (or maybe it's the other way round). Check this.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, May 8, 2016 at 4:14 PM, Muhammad Bilal
<Muhammad2.Bilal at live.uwe.ac.uk> wrote:
> Hi All,
>
> I have the following script, that raises error at the last command. I am new to R and require some clarification on what is going wrong.
>
> #Creating the training and testing data sets
> splitFlag <- sample.split(pfi_v3, SplitRatio = 0.7)
> trainPFI <- subset(pfi_v3, splitFlag==TRUE)
> testPFI <- subset(pfi_v3, splitFlag==FALSE)
>
>
> #Structure of the trainPFI data frame
>> str(trainPFI)
> *******
> 'data.frame': 491 obs. of  16 variables:
>  $ project_id             : int  1 2 3 6 7 9 10 12 13 14 ...
>  $ project_lat            : num  51.4 51.5 52.2 51.9 52.5 ...
>  $ project_lon            : num  -0.642 -1.85 0.08 -0.401 -1.888 ...
>  $ sector                 : Factor w/ 9 levels "Defense","Hospitals",..: 4 4 4 6 6 6 6 6 6 6 ...
>  $ contract_type          : chr  "Turnkey" "Turnkey" "Turnkey" "Turnkey" ...
>  $ project_duration       : int  1826 3652 121 730 730 790 522 819 998 372 ...
>  $ project_delay          : int  -323 0 -60 0 0 0 -91 0 0 7 ...
>  $ capital_value          : num  6.7 5.8 21.8 24.2 40.7 10.7 70 24.5 60.5 78 ...
>  $ project_delay_pct      : num  -17.7 0 -49.6 0 0 0 -17.4 0 0 1.9 ...
>  $ delay_type             : Ord.factor w/ 9 levels "7 months early & beyond"<..: 1 5 3 5 5 5 2 5 5 6 ...
>
> library(caret)
> library(e1071)
>
> set.seed(100)
>
> tr.control <- trainControl(method="cv", number=10)
> cp.grid <- expand.grid(.cp = (0:10)*0.001)
>
> #Fitting the model using regression tree
> tr_m <- train(project_delay ~ project_lon + project_lat + project_duration + sector + contract_type + capital_value, data = trainPFI, method="rpart", trControl=tr.control, tuneGrid = cp.grid)
>
> tr_m
>
> CART
> 491 samples
> 15 predictor
> No pre-processing
> Resampling: Cross-Validated (10 fold)
> Summary of sample sizes: 443, 442, 441, 442, 441, 442, ...
> Resampling results across tuning parameters:
>   cp     RMSE      Rsquared
>   0.000  441.1524  0.5417064
>   0.001  439.6319  0.5451104
>   0.002  437.4039  0.5487203
>   0.003  432.3675  0.5566661
>   0.004  434.2138  0.5519964
>   0.005  431.6635  0.5577771
>   0.006  436.6163  0.5474135
>   0.007  440.5473  0.5407240
>   0.008  441.0876  0.5399614
>   0.009  441.5715  0.5401718
>   0.010  441.1401  0.5407121
> RMSE was used to select the optimal model using  the smallest value.
> The final value used for the model was cp = 0.005.
>
> #Fetching the best tree
> best_tree <- tr_m$finalModel
>
> Alright, all the aforementioned commands worked fine.
>
> Except the subsequent command raises error, when the developed model is used to make predictions:
> best_tree_pred <- predict(best_tree, newdata = testPFI)
> Error in eval(expr, envir, enclos) : object 'sectorHospitals' not found
>
> Can someone guide me what to do to resolve this issue.
>
> Any help will be highly appreciated.
>
> Many Thanks and
>
> Kind Regards
>
> --
> Muhammad Bilal
> Research Fellow and Doctoral Researcher,
> Bristol Enterprise, Research, and Innovation Centre (BERIC),
> University of the West of England (UWE),
> Frenchay Campus,
> Bristol,
> BS16 1QY
>
> muhammad2.bilal at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mxkuhn at gmail.com  Mon May  9 18:22:22 2016
From: mxkuhn at gmail.com (Max Kuhn)
Date: Mon, 9 May 2016 12:22:22 -0400
Subject: [R] Problem while predicting in regression trees
In-Reply-To: <DB5PR07MB1109E99CC2AD0AF465F18048DB700@DB5PR07MB1109.eurprd07.prod.outlook.com>
References: <DB5PR07MB1109CA40FD696496736EAD5ADB7F0@DB5PR07MB1109.eurprd07.prod.outlook.com>
	<CAGxFJbS8m1b8gjzU9kZbmo+upcz1KbymXt594XpKVLS1rbyTNQ@mail.gmail.com>
	<DB5PR07MB1109E99CC2AD0AF465F18048DB700@DB5PR07MB1109.eurprd07.prod.outlook.com>
Message-ID: <CAJ9CoWkawwB+9ESAgzs+un90goKifCWza6RegRe_W5GNAtBpBA@mail.gmail.com>

It is extremely difficult to tell what the issue might be without a
reproducible example.

The only thing that I can suggest is to use the non-formula interface to
`train` so that you can avoid creating dummy variables.

On Mon, May 9, 2016 at 11:23 AM, Muhammad Bilal <
Muhammad2.Bilal at live.uwe.ac.uk> wrote:

> Hi Bert,
>
> Thanks for the response.
>
> I checked the datasets, however, the Hospitals level appears in both of
> them. See the output below:
>
> > sqldf("SELECT sector, count(*) FROM trainPFI GROUP BY sector")
>             sector count(*)
> 1          Defense        9
> 2        Hospitals      101
> 3          Housing       32
> 4           Others       99
> 5 Public Buildings       39
> 6          Schools      148
> 7      Social Care       10
> 8      Transportation       27
> 9            Waste       26
> > sqldf("SELECT sector, count(*) FROM testPFI GROUP BY sector")
>             sector count(*)
> 1          Defense        5
> 2        Hospitals       47
> 3          Housing       11
> 4           Others       44
> 5 Public Buildings       18
> 6          Schools       69
> 7      Social Care        9
> 8   Transportation        8
> 9            Waste       12
>
> Any thing else to try?
>
> --
> Muhammad Bilal
> Research Fellow and Doctoral Researcher,
> Bristol Enterprise, Research, and Innovation Centre (BERIC),
> University of the West of England (UWE),
> Frenchay Campus,
> Bristol,
> BS16 1QY
>
> muhammad2.bilal at live.uwe.ac.uk
>
>
> ________________________________________
> From: Bert Gunter <bgunter.4567 at gmail.com>
> Sent: 09 May 2016 01:42:39
> To: Muhammad Bilal
> Cc: r-help at r-project.org
> Subject: Re: [R] Problem while predicting in regression trees
>
> It seems that the data that you used for prediction contained a level
> "Hospitals" for the sector factor that did not appear in the training
> data (or maybe it's the other way round). Check this.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, May 8, 2016 at 4:14 PM, Muhammad Bilal
> <Muhammad2.Bilal at live.uwe.ac.uk> wrote:
> > Hi All,
> >
> > I have the following script, that raises error at the last command. I am
> new to R and require some clarification on what is going wrong.
> >
> > #Creating the training and testing data sets
> > splitFlag <- sample.split(pfi_v3, SplitRatio = 0.7)
> > trainPFI <- subset(pfi_v3, splitFlag==TRUE)
> > testPFI <- subset(pfi_v3, splitFlag==FALSE)
> >
> >
> > #Structure of the trainPFI data frame
> >> str(trainPFI)
> > *******
> > 'data.frame': 491 obs. of  16 variables:
> >  $ project_id             : int  1 2 3 6 7 9 10 12 13 14 ...
> >  $ project_lat            : num  51.4 51.5 52.2 51.9 52.5 ...
> >  $ project_lon            : num  -0.642 -1.85 0.08 -0.401 -1.888 ...
> >  $ sector                 : Factor w/ 9 levels "Defense","Hospitals",..:
> 4 4 4 6 6 6 6 6 6 6 ...
> >  $ contract_type          : chr  "Turnkey" "Turnkey" "Turnkey" "Turnkey"
> ...
> >  $ project_duration       : int  1826 3652 121 730 730 790 522 819 998
> 372 ...
> >  $ project_delay          : int  -323 0 -60 0 0 0 -91 0 0 7 ...
> >  $ capital_value          : num  6.7 5.8 21.8 24.2 40.7 10.7 70 24.5
> 60.5 78 ...
> >  $ project_delay_pct      : num  -17.7 0 -49.6 0 0 0 -17.4 0 0 1.9 ...
> >  $ delay_type             : Ord.factor w/ 9 levels "7 months early &
> beyond"<..: 1 5 3 5 5 5 2 5 5 6 ...
> >
> > library(caret)
> > library(e1071)
> >
> > set.seed(100)
> >
> > tr.control <- trainControl(method="cv", number=10)
> > cp.grid <- expand.grid(.cp = (0:10)*0.001)
> >
> > #Fitting the model using regression tree
> > tr_m <- train(project_delay ~ project_lon + project_lat +
> project_duration + sector + contract_type + capital_value, data = trainPFI,
> method="rpart", trControl=tr.control, tuneGrid = cp.grid)
> >
> > tr_m
> >
> > CART
> > 491 samples
> > 15 predictor
> > No pre-processing
> > Resampling: Cross-Validated (10 fold)
> > Summary of sample sizes: 443, 442, 441, 442, 441, 442, ...
> > Resampling results across tuning parameters:
> >   cp     RMSE      Rsquared
> >   0.000  441.1524  0.5417064
> >   0.001  439.6319  0.5451104
> >   0.002  437.4039  0.5487203
> >   0.003  432.3675  0.5566661
> >   0.004  434.2138  0.5519964
> >   0.005  431.6635  0.5577771
> >   0.006  436.6163  0.5474135
> >   0.007  440.5473  0.5407240
> >   0.008  441.0876  0.5399614
> >   0.009  441.5715  0.5401718
> >   0.010  441.1401  0.5407121
> > RMSE was used to select the optimal model using  the smallest value.
> > The final value used for the model was cp = 0.005.
> >
> > #Fetching the best tree
> > best_tree <- tr_m$finalModel
> >
> > Alright, all the aforementioned commands worked fine.
> >
> > Except the subsequent command raises error, when the developed model is
> used to make predictions:
> > best_tree_pred <- predict(best_tree, newdata = testPFI)
> > Error in eval(expr, envir, enclos) : object 'sectorHospitals' not found
> >
> > Can someone guide me what to do to resolve this issue.
> >
> > Any help will be highly appreciated.
> >
> > Many Thanks and
> >
> > Kind Regards
> >
> > --
> > Muhammad Bilal
> > Research Fellow and Doctoral Researcher,
> > Bristol Enterprise, Research, and Innovation Centre (BERIC),
> > University of the West of England (UWE),
> > Frenchay Campus,
> > Bristol,
> > BS16 1QY
> >
> > muhammad2.bilal at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From davidsmi at microsoft.com  Mon May  9 18:49:30 2016
From: davidsmi at microsoft.com (David Smith)
Date: Mon, 9 May 2016 16:49:30 +0000
Subject: [R] Revolutions blog: April 2016 roundup
Message-ID: <DM2PR0301MB08480DE1DF9EEC4468A47348C8700@DM2PR0301MB0848.namprd03.prod.outlook.com>

Since 2008, Microsoft (formerly Revolution Analytics) staff and guests have written about R every weekday at the
Revolutions blog: http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month of particular interest to readers of r-help.

And in case you missed them, here are some articles related to R from the month of April:

Lukasz Piwek recreates classic graphs from Tufte's 'The Visual Display of Quantitative Information' in R:
http://blog.revolutionanalytics.com/2016/04/tufte-style-graphics-in-r.html

A preview of upcoming R conferences in Europe:
http://blog.revolutionanalytics.com/2016/04/r-conferences-europe-2016.html

Andrie de Vries updates the data on R package growth on CRAN,
http://blog.revolutionanalytics.com/2016/04/cran-package-growth.html and finds a segmented regression model with
break-points in 2007 and 2011 fits the data well:
http://blog.revolutionanalytics.com/2016/04/a-segmented-model-of-cran-package-growth.html

A Microsoft data scientist compares R, Microsoft R Open and Microsoft R Server:
http://blog.revolutionanalytics.com/2016/04/data-scientist-perspective.html

A webinar on data visualization with Microsoft R Open, presented by Naomi and Joyce Robbins:
http://blog.revolutionanalytics.com/2016/04/webinar-april-28-effective-graphs.html

Microsoft R Open 3.2.4 now available for Windows, Mac and Linux:
http://blog.revolutionanalytics.com/2016/04/mro-324-available.html

A preview of R/Finance 2016, May 20-21 in Chicago:
http://blog.revolutionanalytics.com/2016/04/get-ready-for-rfinance-2016.html

Julia Silge releases a CRAN package with the text of Jane Austin's novels, and uses the syuzhet package to map 
sentiment in the narratives: http://blog.revolutionanalytics.com/2016/04/pride-and-prejudice-and-z-scores.html

Modeling tips paid to taxi drivers in NYC with Microsoft R Server running on HDInsight Hadoop:
http://blog.revolutionanalytics.com/2016/04/mrs-nyc-taxi.html

A webinar recording (with slides) shows how to scale Microsoft R Server to very large data sets on HDInsight with Apache
Spark: http://blog.revolutionanalytics.com/2016/04/scalable-ds-platform.html

News on recent grants to community projects by the R Consortium (proposals for the next round are due July 10):
http://blog.revolutionanalytics.com/2016/04/get-involved-with-the-r-consortium.html

The Microsoft Data Science Virtual Machine, which packages many data science tools including R, is now available as a
Linux VM: http://blog.revolutionanalytics.com/2016/04/microsoft-ds-vm-linux.html

Buzzfeed used R to visualize the activity of surveillance aircraft used by the US government:
http://blog.revolutionanalytics.com/2016/04/the-fbis-aerial-surveillance-program-visualized-with-r.html

Using Azure ML and R to predict the quality of wine:
http://blog.revolutionanalytics.com/2016/04/predicting-wine-quality.html

A review of the book 'Graphical Data Analysis with R' by Antony Unwin:
http://blog.revolutionanalytics.com/2016/04/graphical-data-analysis-with-r.html

Montgomery County, MD opened its traffic violation data, and Srini Kumar used SQL Server and R to visualize it:
http://blog.revolutionanalytics.com/2016/04/an-analysis-of-traffic-violation-data-with-sql-server-and-r.html

80% of Airbnb's data scientists use R, and share methods and tools via an internal R package:
http://blog.revolutionanalytics.com/2016/04/airbnb-uses-r.html 

Microsoft sponsors a competition using R to evaluate a treatment for brain injury and infer vision from brain waves:
http://blog.revolutionanalytics.com/2016/04/connected-brains.html

General interest stories (not related to R) in the past month included stories about: the new Thunderbirds
(http://blog.revolutionanalytics.com/2016/04/thunderbirds-are-go.html), Australian abbreviations
(http://blog.revolutionanalytics.com/2016/04/abbreviated-discource.html), anamorphic illusions
(http://blog.revolutionanalytics.com/2016/04/witness-brusspup-illusions.html), the jet streams of Earth and Jupiter
(http://blog.revolutionanalytics.com/2016/04/because-its-friday-jet-stream.html), and never-seen YouTube videos
(http://blog.revolutionanalytics.com/2016/04/petit-tube.html).

Meeting times for local R user groups (http://blog.revolutionanalytics.com/local-r-groups.html) can be found on the
updated R Community Calendar at: http://blog.revolutionanalytics.com/calendar.html .
If you're looking for more articles about R, you can find summaries from previous months at
http://blog.revolutionanalytics.com/roundups/. You can receive daily blog posts via email using services like
blogtrottr.com.

As always, thanks for the comments and please keep sending suggestions to me at davidsmi at microsoft.com or via Twitter
(I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
R Community Lead, Microsoft? 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com


From macqueen1 at llnl.gov  Mon May  9 20:38:34 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 9 May 2016 18:38:34 +0000
Subject: [R] Clean method to convert date and time between time zones
 keeping it in POSIXct format
In-Reply-To: <CANkFkEfj36sr2z2chemtcEm=mGW6AHWHgiA29zQ0bG95LJsDLw@mail.gmail.com>
References: <CANkFkEfj36sr2z2chemtcEm=mGW6AHWHgiA29zQ0bG95LJsDLw@mail.gmail.com>
Message-ID: <D3561022.172CBC%macqueen1@llnl.gov>

I think setting the attribute is the best way to "convert", and the
following will hopefully explain why. (And I would tend to agree with
William Dunlap that a function to set the attribute might help userRs.)



R always stores POSIXct objects internally in seconds since an origin in
UTC. I would not think in terms of converting; I would think in terms of
displaying.


t1 <- as.POSIXct("2016-05-09 10:00:00", tz="America/New_York")
t2 <- t1
attributes(t2)$tzone <- 'UTC'

> print(t1)
[1] "2016-05-09 10:00:00 EDT"
> print(t2)
[1] "2016-05-09 14:00:00 UTC"

> as.numeric(t1)
[1] 1462802400
> as.numeric(t2)
[1] 1462802400



The actual value of t2 is the same as t1, it has not been "converted"
(because to me conversion implies change, and there has been no change in
the value of t2). R has been merely been told to display it in UTC when
printed.


Similarly, when a character string is converted to POSIXct, R has to be
told what timezone to use to convert it to seconds since the origin in
UTC. If a timezone is not specified, the user's local (default) timezone
is used.

> t3 <- as.POSIXct("2016-05-09 10:00:00")
> t3
[1] "2016-05-09 10:00:00 PDT"
> as.numeric(t3)
[1] 1462813200


The number of seconds for t3 is different than for t1 and t2, and this is
because I am not in the America/New_York timezone

And, in fact,

> (as.numeric(t3) - as.numeric(t1))/3600
[1] 3


Indicating that PDT and America/New_York are three hours apart, as indeed
they are.

To me, this version
  t4 <- as.POSIXct(format(t1, tz="UTC"), tz="UTC")
doesn't recognize the distinction between internal storage and display,
and the fact that there is no real conversion.

> identical(t2, t4)
[1] TRUE




To go a little further,

> attributes(t3)
$class
[1] "POSIXct" "POSIXt"

$tzone
[1] ""


If a timezone is not specified when the object is created, then the tzone
attribute is set to "" and R displays using the local timezone.

> t3
[1] "2016-05-09 10:00:00 PDT"

I can change the local timezone:

> Sys.setenv(TZ='UTC')
> t3
[1] "2016-05-09 17:00:00 UTC"

t3 has not changed, but how it is displayed has changed.

Given all this, it's helpful that the format() function for POSIXt objects
has a tz argument.

> format(t3, tz='US/Pacific')
[1] "2016-05-09 10:00:00"


Indicating again that t3 has not changed; I've just manipulated to rules
for how it is displayed.


-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 5/9/16, 6:24 AM, "R-help on behalf of Arnaud Mosnier"
<r-help-bounces at r-project.org on behalf of a.mosnier at gmail.com> wrote:

>Dear UseRs,
>
>I know two ways to convert dates and time from on time zone to another but
>I am pretty sure that there is a better (cleaner) way to do that.
>
>
>Here are the methods I know:
>
>
>## The longest way ...
>
>T1 <- as.POSIXct("2016-05-09 10:00:00", format="%Y-%m-%d %H:%M:%S",
>tz="America/New_York")
>
>print(T1)
>
>T2 <- as.POSIXct(format(T1, tz="UTC"), tz="UTC") # format convert it to
>character, so I have to convert it back to POSIXct afterward.
>
>print(T2)
>
>
>
>## The shortest but probably not the cleanest ...
>
>attributes(T1)$tzone <- "UTC"
>
>print(T1)
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://secure-web.cisco.com/1nvZKqHLPcK9TOXimc8J5movKns8BiTyuMWcZyyxtloFp
>axMIqoeoukSrVfSV5mZWIt9iP1hZc8xp4qpTd4myFmgBNUpWkT0GA8U1sEDLLDrqq4f6rBRi8l
>XA8AZCvehwZW9JmJOjsfBUHIciqVRyN2jDW3WmSTnM6vZP_pc2W1B_DxINMQlrH6d8IveSoEVz
>x5Ie8aC104HM-D5z1qkGhkmTZBDtAkwyRfij_jTlVGsYXCgM3f8umyU0J6rr0zlsQyTFAdzqmi
>rfZsH0CvNtISZVnx_h3_ErJhp7onwLO-9l4UvGOe9y7j0thranjcVCJ45UFTgaP8Jp0lEZ1XjJ
>QnrRiRwQ9m8IHckFxPXutNY/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2F
>r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>


From Muhammad2.Bilal at live.uwe.ac.uk  Mon May  9 20:46:03 2016
From: Muhammad2.Bilal at live.uwe.ac.uk (Muhammad Bilal)
Date: Mon, 9 May 2016 18:46:03 +0000
Subject: [R] Problem while predicting in regression trees
In-Reply-To: <CAJ9CoWkawwB+9ESAgzs+un90goKifCWza6RegRe_W5GNAtBpBA@mail.gmail.com>
References: <DB5PR07MB1109CA40FD696496736EAD5ADB7F0@DB5PR07MB1109.eurprd07.prod.outlook.com>
	<CAGxFJbS8m1b8gjzU9kZbmo+upcz1KbymXt594XpKVLS1rbyTNQ@mail.gmail.com>
	<DB5PR07MB1109E99CC2AD0AF465F18048DB700@DB5PR07MB1109.eurprd07.prod.outlook.com>,
	<CAJ9CoWkawwB+9ESAgzs+un90goKifCWza6RegRe_W5GNAtBpBA@mail.gmail.com>
Message-ID: <DB5PR07MB1109395C945654381052CFC5DB700@DB5PR07MB1109.eurprd07.prod.outlook.com>

Please find the sample dataset attached along with R code pasted below to reproduce the issue.


#Loading the data frame

pfi <- read.csv("pfi_data.csv")

#Splitting the data into training and test sets
split <- sample.split(pfi, SplitRatio = 0.7)
trainPFI <- subset(pfi, split == TRUE)
testPFI <- subset(pfi, split == FALSE)

#Cross validating the decision trees
tr.control <- trainControl(method="repeatedcv", number=20)
cp.grid <- expand.grid(.cp = (0:10)*0.001)
tr_m <- train(project_delay ~ project_lon + project_lat + project_duration + sector + contract_type + capital_value, data = trainPFI, method="rpart", trControl=tr.control, tuneGrid = cp.grid)

#Displaying the train results
tr_m

#Fetching the best tree
best_tree <- tr_m$finalModel

#Plotting the best tree
prp(best_tree)

#Using the best tree to make predictions [This command raises the error]
best_tree_pred <- predict(best_tree, newdata = testPFI)

#Calculating the SSE
best_tree_pred.sse <- sum((best_tree_pred - testPFI$project_delay)^2)

#
tree_pred.sse

...


Many Thanks and


Kind Regards



--
Muhammad Bilal
Research Fellow and Doctoral Researcher,
Bristol Enterprise, Research, and Innovation Centre (BERIC),
University of the West of England (UWE),
Frenchay Campus,
Bristol,
BS16 1QY

muhammad2.bilal at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>


________________________________
From: Max Kuhn <mxkuhn at gmail.com>
Sent: 09 May 2016 17:22:22
To: Muhammad Bilal
Cc: Bert Gunter; r-help at r-project.org
Subject: Re: [R] Problem while predicting in regression trees

It is extremely difficult to tell what the issue might be without a reproducible example.

The only thing that I can suggest is to use the non-formula interface to `train` so that you can avoid creating dummy variables.

On Mon, May 9, 2016 at 11:23 AM, Muhammad Bilal <Muhammad2.Bilal at live.uwe.ac.uk<mailto:Muhammad2.Bilal at live.uwe.ac.uk>> wrote:
Hi Bert,

Thanks for the response.

I checked the datasets, however, the Hospitals level appears in both of them. See the output below:

> sqldf("SELECT sector, count(*) FROM trainPFI GROUP BY sector")
            sector count(*)
1          Defense        9
2        Hospitals      101
3          Housing       32
4           Others       99
5 Public Buildings       39
6          Schools      148
7      Social Care       10
8      Transportation       27
9            Waste       26
> sqldf("SELECT sector, count(*) FROM testPFI GROUP BY sector")
            sector count(*)
1          Defense        5
2        Hospitals       47
3          Housing       11
4           Others       44
5 Public Buildings       18
6          Schools       69
7      Social Care        9
8   Transportation        8
9            Waste       12

Any thing else to try?

--
Muhammad Bilal
Research Fellow and Doctoral Researcher,
Bristol Enterprise, Research, and Innovation Centre (BERIC),
University of the West of England (UWE),
Frenchay Campus,
Bristol,
BS16 1QY

muhammad2.bilal at live.uwe.ac.uk<mailto:muhammad2.bilal at live.uwe.ac.uk>


________________________________________
From: Bert Gunter <bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>>
Sent: 09 May 2016 01:42:39
To: Muhammad Bilal
Cc: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] Problem while predicting in regression trees

It seems that the data that you used for prediction contained a level
"Hospitals" for the sector factor that did not appear in the training
data (or maybe it's the other way round). Check this.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, May 8, 2016 at 4:14 PM, Muhammad Bilal
<Muhammad2.Bilal at live.uwe.ac.uk<mailto:Muhammad2.Bilal at live.uwe.ac.uk>> wrote:
> Hi All,
>
> I have the following script, that raises error at the last command. I am new to R and require some clarification on what is going wrong.
>
> #Creating the training and testing data sets
> splitFlag <- sample.split(pfi_v3, SplitRatio = 0.7)
> trainPFI <- subset(pfi_v3, splitFlag==TRUE)
> testPFI <- subset(pfi_v3, splitFlag==FALSE)
>
>
> #Structure of the trainPFI data frame
>> str(trainPFI)
> *******
> 'data.frame': 491 obs. of  16 variables:
>  $ project_id             : int  1 2 3 6 7 9 10 12 13 14 ...
>  $ project_lat            : num  51.4 51.5 52.2 51.9 52.5 ...
>  $ project_lon            : num  -0.642 -1.85 0.08 -0.401 -1.888 ...
>  $ sector                 : Factor w/ 9 levels "Defense","Hospitals",..: 4 4 4 6 6 6 6 6 6 6 ...
>  $ contract_type          : chr  "Turnkey" "Turnkey" "Turnkey" "Turnkey" ...
>  $ project_duration       : int  1826 3652 121 730 730 790 522 819 998 372 ...
>  $ project_delay          : int  -323 0 -60 0 0 0 -91 0 0 7 ...
>  $ capital_value          : num  6.7 5.8 21.8 24.2 40.7 10.7 70 24.5 60.5 78 ...
>  $ project_delay_pct      : num  -17.7 0 -49.6 0 0 0 -17.4 0 0 1.9 ...
>  $ delay_type             : Ord.factor w/ 9 levels "7 months early & beyond"<..: 1 5 3 5 5 5 2 5 5 6 ...
>
> library(caret)
> library(e1071)
>
> set.seed(100)
>
> tr.control <- trainControl(method="cv", number=10)
> cp.grid <- expand.grid(.cp = (0:10)*0.001)
>
> #Fitting the model using regression tree
> tr_m <- train(project_delay ~ project_lon + project_lat + project_duration + sector + contract_type + capital_value, data = trainPFI, method="rpart", trControl=tr.control, tuneGrid = cp.grid)
>
> tr_m
>
> CART
> 491 samples
> 15 predictor
> No pre-processing
> Resampling: Cross-Validated (10 fold)
> Summary of sample sizes: 443, 442, 441, 442, 441, 442, ...
> Resampling results across tuning parameters:
>   cp     RMSE      Rsquared
>   0.000  441.1524  0.5417064
>   0.001  439.6319  0.5451104
>   0.002  437.4039  0.5487203
>   0.003  432.3675  0.5566661
>   0.004  434.2138  0.5519964
>   0.005  431.6635  0.5577771
>   0.006  436.6163  0.5474135
>   0.007  440.5473  0.5407240
>   0.008  441.0876  0.5399614
>   0.009  441.5715  0.5401718
>   0.010  441.1401  0.5407121
> RMSE was used to select the optimal model using  the smallest value.
> The final value used for the model was cp = 0.005.
>
> #Fetching the best tree
> best_tree <- tr_m$finalModel
>
> Alright, all the aforementioned commands worked fine.
>
> Except the subsequent command raises error, when the developed model is used to make predictions:
> best_tree_pred <- predict(best_tree, newdata = testPFI)
> Error in eval(expr, envir, enclos) : object 'sectorHospitals' not found
>
> Can someone guide me what to do to resolve this issue.
>
> Any help will be highly appreciated.
>
> Many Thanks and
>
> Kind Regards
>
> --
> Muhammad Bilal
> Research Fellow and Doctoral Researcher,
> Bristol Enterprise, Research, and Innovation Centre (BERIC),
> University of the West of England (UWE),
> Frenchay Campus,
> Bristol,
> BS16 1QY
>
> muhammad2.bilal at live.uwe.ac.uk<mailto:muhammad2.bilal at live.uwe.ac.uk><mailto:olugbenga2.akinade at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Muhammad2.Bilal at live.uwe.ac.uk  Mon May  9 21:15:40 2016
From: Muhammad2.Bilal at live.uwe.ac.uk (Muhammad Bilal)
Date: Mon, 9 May 2016 19:15:40 +0000
Subject: [R] Problem while predicting in regression trees
In-Reply-To: <CAJ9CoWkawwB+9ESAgzs+un90goKifCWza6RegRe_W5GNAtBpBA@mail.gmail.com>
References: <DB5PR07MB1109CA40FD696496736EAD5ADB7F0@DB5PR07MB1109.eurprd07.prod.outlook.com>
	<CAGxFJbS8m1b8gjzU9kZbmo+upcz1KbymXt594XpKVLS1rbyTNQ@mail.gmail.com>
	<DB5PR07MB1109E99CC2AD0AF465F18048DB700@DB5PR07MB1109.eurprd07.prod.outlook.com>,
	<CAJ9CoWkawwB+9ESAgzs+un90goKifCWza6RegRe_W5GNAtBpBA@mail.gmail.com>
Message-ID: <DB5PR07MB1109694D46B6F4E7FA4C96FADB700@DB5PR07MB1109.eurprd07.prod.outlook.com>

The dataset could also be downloaded from the following link:

https://www.dropbox.com/s/kkiwm32jxfk7jac/pfi_data.csv?dl=0

[https://cf.dropboxstatic.com/static/images/icons128/page_white_excel.png]<https://www.dropbox.com/s/kkiwm32jxfk7jac/pfi_data.csv?dl=0>

pfi_data.csv<https://www.dropbox.com/s/kkiwm32jxfk7jac/pfi_data.csv?dl=0>
www.dropbox.com
Shared with Dropbox





--
Muhammad Bilal
Research Fellow and Doctoral Researcher,
Bristol Enterprise, Research, and Innovation Centre (BERIC),
University of the West of England (UWE),
Frenchay Campus,
Bristol,
BS16 1QY

muhammad2.bilal at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>


________________________________
From: Max Kuhn <mxkuhn at gmail.com>
Sent: 09 May 2016 17:22:22
To: Muhammad Bilal
Cc: Bert Gunter; r-help at r-project.org
Subject: Re: [R] Problem while predicting in regression trees

It is extremely difficult to tell what the issue might be without a reproducible example.

The only thing that I can suggest is to use the non-formula interface to `train` so that you can avoid creating dummy variables.

On Mon, May 9, 2016 at 11:23 AM, Muhammad Bilal <Muhammad2.Bilal at live.uwe.ac.uk<mailto:Muhammad2.Bilal at live.uwe.ac.uk>> wrote:
Hi Bert,

Thanks for the response.

I checked the datasets, however, the Hospitals level appears in both of them. See the output below:

> sqldf("SELECT sector, count(*) FROM trainPFI GROUP BY sector")
            sector count(*)
1          Defense        9
2        Hospitals      101
3          Housing       32
4           Others       99
5 Public Buildings       39
6          Schools      148
7      Social Care       10
8      Transportation       27
9            Waste       26
> sqldf("SELECT sector, count(*) FROM testPFI GROUP BY sector")
            sector count(*)
1          Defense        5
2        Hospitals       47
3          Housing       11
4           Others       44
5 Public Buildings       18
6          Schools       69
7      Social Care        9
8   Transportation        8
9            Waste       12

Any thing else to try?

--
Muhammad Bilal
Research Fellow and Doctoral Researcher,
Bristol Enterprise, Research, and Innovation Centre (BERIC),
University of the West of England (UWE),
Frenchay Campus,
Bristol,
BS16 1QY

muhammad2.bilal at live.uwe.ac.uk<mailto:muhammad2.bilal at live.uwe.ac.uk>


________________________________________
From: Bert Gunter <bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>>
Sent: 09 May 2016 01:42:39
To: Muhammad Bilal
Cc: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] Problem while predicting in regression trees

It seems that the data that you used for prediction contained a level
"Hospitals" for the sector factor that did not appear in the training
data (or maybe it's the other way round). Check this.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, May 8, 2016 at 4:14 PM, Muhammad Bilal
<Muhammad2.Bilal at live.uwe.ac.uk<mailto:Muhammad2.Bilal at live.uwe.ac.uk>> wrote:
> Hi All,
>
> I have the following script, that raises error at the last command. I am new to R and require some clarification on what is going wrong.
>
> #Creating the training and testing data sets
> splitFlag <- sample.split(pfi_v3, SplitRatio = 0.7)
> trainPFI <- subset(pfi_v3, splitFlag==TRUE)
> testPFI <- subset(pfi_v3, splitFlag==FALSE)
>
>
> #Structure of the trainPFI data frame
>> str(trainPFI)
> *******
> 'data.frame': 491 obs. of  16 variables:
>  $ project_id             : int  1 2 3 6 7 9 10 12 13 14 ...
>  $ project_lat            : num  51.4 51.5 52.2 51.9 52.5 ...
>  $ project_lon            : num  -0.642 -1.85 0.08 -0.401 -1.888 ...
>  $ sector                 : Factor w/ 9 levels "Defense","Hospitals",..: 4 4 4 6 6 6 6 6 6 6 ...
>  $ contract_type          : chr  "Turnkey" "Turnkey" "Turnkey" "Turnkey" ...
>  $ project_duration       : int  1826 3652 121 730 730 790 522 819 998 372 ...
>  $ project_delay          : int  -323 0 -60 0 0 0 -91 0 0 7 ...
>  $ capital_value          : num  6.7 5.8 21.8 24.2 40.7 10.7 70 24.5 60.5 78 ...
>  $ project_delay_pct      : num  -17.7 0 -49.6 0 0 0 -17.4 0 0 1.9 ...
>  $ delay_type             : Ord.factor w/ 9 levels "7 months early & beyond"<..: 1 5 3 5 5 5 2 5 5 6 ...
>
> library(caret)
> library(e1071)
>
> set.seed(100)
>
> tr.control <- trainControl(method="cv", number=10)
> cp.grid <- expand.grid(.cp = (0:10)*0.001)
>
> #Fitting the model using regression tree
> tr_m <- train(project_delay ~ project_lon + project_lat + project_duration + sector + contract_type + capital_value, data = trainPFI, method="rpart", trControl=tr.control, tuneGrid = cp.grid)
>
> tr_m
>
> CART
> 491 samples
> 15 predictor
> No pre-processing
> Resampling: Cross-Validated (10 fold)
> Summary of sample sizes: 443, 442, 441, 442, 441, 442, ...
> Resampling results across tuning parameters:
>   cp     RMSE      Rsquared
>   0.000  441.1524  0.5417064
>   0.001  439.6319  0.5451104
>   0.002  437.4039  0.5487203
>   0.003  432.3675  0.5566661
>   0.004  434.2138  0.5519964
>   0.005  431.6635  0.5577771
>   0.006  436.6163  0.5474135
>   0.007  440.5473  0.5407240
>   0.008  441.0876  0.5399614
>   0.009  441.5715  0.5401718
>   0.010  441.1401  0.5407121
> RMSE was used to select the optimal model using  the smallest value.
> The final value used for the model was cp = 0.005.
>
> #Fetching the best tree
> best_tree <- tr_m$finalModel
>
> Alright, all the aforementioned commands worked fine.
>
> Except the subsequent command raises error, when the developed model is used to make predictions:
> best_tree_pred <- predict(best_tree, newdata = testPFI)
> Error in eval(expr, envir, enclos) : object 'sectorHospitals' not found
>
> Can someone guide me what to do to resolve this issue.
>
> Any help will be highly appreciated.
>
> Many Thanks and
>
> Kind Regards
>
> --
> Muhammad Bilal
> Research Fellow and Doctoral Researcher,
> Bristol Enterprise, Research, and Innovation Centre (BERIC),
> University of the West of England (UWE),
> Frenchay Campus,
> Bristol,
> BS16 1QY
>
> muhammad2.bilal at live.uwe.ac.uk<mailto:muhammad2.bilal at live.uwe.ac.uk><mailto:olugbenga2.akinade at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Mon May  9 21:27:14 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 9 May 2016 12:27:14 -0700
Subject: [R] Problem while predicting in regression trees
In-Reply-To: <DB5PR07MB1109395C945654381052CFC5DB700@DB5PR07MB1109.eurprd07.prod.outlook.com>
References: <DB5PR07MB1109CA40FD696496736EAD5ADB7F0@DB5PR07MB1109.eurprd07.prod.outlook.com>
	<CAGxFJbS8m1b8gjzU9kZbmo+upcz1KbymXt594XpKVLS1rbyTNQ@mail.gmail.com>
	<DB5PR07MB1109E99CC2AD0AF465F18048DB700@DB5PR07MB1109.eurprd07.prod.outlook.com>
	<CAJ9CoWkawwB+9ESAgzs+un90goKifCWza6RegRe_W5GNAtBpBA@mail.gmail.com>
	<DB5PR07MB1109395C945654381052CFC5DB700@DB5PR07MB1109.eurprd07.prod.outlook.com>
Message-ID: <CAF8bMca3jd0qfMM5fg+npOTh-5vrcvY9JJK22pADXcac6bsFeA@mail.gmail.com>

Why are you predicting from tr_m$finalModel instead of from tr_m?

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, May 9, 2016 at 11:46 AM, Muhammad Bilal <
Muhammad2.Bilal at live.uwe.ac.uk> wrote:

> Please find the sample dataset attached along with R code pasted below to
> reproduce the issue.
>
>
> #Loading the data frame
>
> pfi <- read.csv("pfi_data.csv")
>
> #Splitting the data into training and test sets
> split <- sample.split(pfi, SplitRatio = 0.7)
> trainPFI <- subset(pfi, split == TRUE)
> testPFI <- subset(pfi, split == FALSE)
>
> #Cross validating the decision trees
> tr.control <- trainControl(method="repeatedcv", number=20)
> cp.grid <- expand.grid(.cp = (0:10)*0.001)
> tr_m <- train(project_delay ~ project_lon + project_lat + project_duration
> + sector + contract_type + capital_value, data = trainPFI, method="rpart",
> trControl=tr.control, tuneGrid = cp.grid)
>
> #Displaying the train results
> tr_m
>
> #Fetching the best tree
> best_tree <- tr_m$finalModel
>
> #Plotting the best tree
> prp(best_tree)
>
> #Using the best tree to make predictions [This command raises the error]
> best_tree_pred <- predict(best_tree, newdata = testPFI)
>
> #Calculating the SSE
> best_tree_pred.sse <- sum((best_tree_pred - testPFI$project_delay)^2)
>
> #
> tree_pred.sse
>
> ...
>
>
> Many Thanks and
>
>
> Kind Regards
>
>
>
> --
> Muhammad Bilal
> Research Fellow and Doctoral Researcher,
> Bristol Enterprise, Research, and Innovation Centre (BERIC),
> University of the West of England (UWE),
> Frenchay Campus,
> Bristol,
> BS16 1QY
>
> muhammad2.bilal at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>
>
>
> ________________________________
> From: Max Kuhn <mxkuhn at gmail.com>
> Sent: 09 May 2016 17:22:22
> To: Muhammad Bilal
> Cc: Bert Gunter; r-help at r-project.org
> Subject: Re: [R] Problem while predicting in regression trees
>
> It is extremely difficult to tell what the issue might be without a
> reproducible example.
>
> The only thing that I can suggest is to use the non-formula interface to
> `train` so that you can avoid creating dummy variables.
>
> On Mon, May 9, 2016 at 11:23 AM, Muhammad Bilal <
> Muhammad2.Bilal at live.uwe.ac.uk<mailto:Muhammad2.Bilal at live.uwe.ac.uk>>
> wrote:
> Hi Bert,
>
> Thanks for the response.
>
> I checked the datasets, however, the Hospitals level appears in both of
> them. See the output below:
>
> > sqldf("SELECT sector, count(*) FROM trainPFI GROUP BY sector")
>             sector count(*)
> 1          Defense        9
> 2        Hospitals      101
> 3          Housing       32
> 4           Others       99
> 5 Public Buildings       39
> 6          Schools      148
> 7      Social Care       10
> 8      Transportation       27
> 9            Waste       26
> > sqldf("SELECT sector, count(*) FROM testPFI GROUP BY sector")
>             sector count(*)
> 1          Defense        5
> 2        Hospitals       47
> 3          Housing       11
> 4           Others       44
> 5 Public Buildings       18
> 6          Schools       69
> 7      Social Care        9
> 8   Transportation        8
> 9            Waste       12
>
> Any thing else to try?
>
> --
> Muhammad Bilal
> Research Fellow and Doctoral Researcher,
> Bristol Enterprise, Research, and Innovation Centre (BERIC),
> University of the West of England (UWE),
> Frenchay Campus,
> Bristol,
> BS16 1QY
>
> muhammad2.bilal at live.uwe.ac.uk<mailto:muhammad2.bilal at live.uwe.ac.uk>
>
>
> ________________________________________
> From: Bert Gunter <bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>>
> Sent: 09 May 2016 01:42:39
> To: Muhammad Bilal
> Cc: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: Re: [R] Problem while predicting in regression trees
>
> It seems that the data that you used for prediction contained a level
> "Hospitals" for the sector factor that did not appear in the training
> data (or maybe it's the other way round). Check this.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, May 8, 2016 at 4:14 PM, Muhammad Bilal
> <Muhammad2.Bilal at live.uwe.ac.uk<mailto:Muhammad2.Bilal at live.uwe.ac.uk>>
> wrote:
> > Hi All,
> >
> > I have the following script, that raises error at the last command. I am
> new to R and require some clarification on what is going wrong.
> >
> > #Creating the training and testing data sets
> > splitFlag <- sample.split(pfi_v3, SplitRatio = 0.7)
> > trainPFI <- subset(pfi_v3, splitFlag==TRUE)
> > testPFI <- subset(pfi_v3, splitFlag==FALSE)
> >
> >
> > #Structure of the trainPFI data frame
> >> str(trainPFI)
> > *******
> > 'data.frame': 491 obs. of  16 variables:
> >  $ project_id             : int  1 2 3 6 7 9 10 12 13 14 ...
> >  $ project_lat            : num  51.4 51.5 52.2 51.9 52.5 ...
> >  $ project_lon            : num  -0.642 -1.85 0.08 -0.401 -1.888 ...
> >  $ sector                 : Factor w/ 9 levels "Defense","Hospitals",..:
> 4 4 4 6 6 6 6 6 6 6 ...
> >  $ contract_type          : chr  "Turnkey" "Turnkey" "Turnkey" "Turnkey"
> ...
> >  $ project_duration       : int  1826 3652 121 730 730 790 522 819 998
> 372 ...
> >  $ project_delay          : int  -323 0 -60 0 0 0 -91 0 0 7 ...
> >  $ capital_value          : num  6.7 5.8 21.8 24.2 40.7 10.7 70 24.5
> 60.5 78 ...
> >  $ project_delay_pct      : num  -17.7 0 -49.6 0 0 0 -17.4 0 0 1.9 ...
> >  $ delay_type             : Ord.factor w/ 9 levels "7 months early &
> beyond"<..: 1 5 3 5 5 5 2 5 5 6 ...
> >
> > library(caret)
> > library(e1071)
> >
> > set.seed(100)
> >
> > tr.control <- trainControl(method="cv", number=10)
> > cp.grid <- expand.grid(.cp = (0:10)*0.001)
> >
> > #Fitting the model using regression tree
> > tr_m <- train(project_delay ~ project_lon + project_lat +
> project_duration + sector + contract_type + capital_value, data = trainPFI,
> method="rpart", trControl=tr.control, tuneGrid = cp.grid)
> >
> > tr_m
> >
> > CART
> > 491 samples
> > 15 predictor
> > No pre-processing
> > Resampling: Cross-Validated (10 fold)
> > Summary of sample sizes: 443, 442, 441, 442, 441, 442, ...
> > Resampling results across tuning parameters:
> >   cp     RMSE      Rsquared
> >   0.000  441.1524  0.5417064
> >   0.001  439.6319  0.5451104
> >   0.002  437.4039  0.5487203
> >   0.003  432.3675  0.5566661
> >   0.004  434.2138  0.5519964
> >   0.005  431.6635  0.5577771
> >   0.006  436.6163  0.5474135
> >   0.007  440.5473  0.5407240
> >   0.008  441.0876  0.5399614
> >   0.009  441.5715  0.5401718
> >   0.010  441.1401  0.5407121
> > RMSE was used to select the optimal model using  the smallest value.
> > The final value used for the model was cp = 0.005.
> >
> > #Fetching the best tree
> > best_tree <- tr_m$finalModel
> >
> > Alright, all the aforementioned commands worked fine.
> >
> > Except the subsequent command raises error, when the developed model is
> used to make predictions:
> > best_tree_pred <- predict(best_tree, newdata = testPFI)
> > Error in eval(expr, envir, enclos) : object 'sectorHospitals' not found
> >
> > Can someone guide me what to do to resolve this issue.
> >
> > Any help will be highly appreciated.
> >
> > Many Thanks and
> >
> > Kind Regards
> >
> > --
> > Muhammad Bilal
> > Research Fellow and Doctoral Researcher,
> > Bristol Enterprise, Research, and Innovation Centre (BERIC),
> > University of the West of England (UWE),
> > Frenchay Campus,
> > Bristol,
> > BS16 1QY
> >
> > muhammad2.bilal at live.uwe.ac.uk<mailto:muhammad2.bilal at live.uwe.ac.uk
> ><mailto:olugbenga2.akinade at live.uwe.ac.uk<mailto:
> olugbenga2.akinade at live.uwe.ac.uk>>
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Muhammad2.Bilal at live.uwe.ac.uk  Mon May  9 21:32:46 2016
From: Muhammad2.Bilal at live.uwe.ac.uk (Muhammad Bilal)
Date: Mon, 9 May 2016 19:32:46 +0000
Subject: [R] Problem while predicting in regression trees
In-Reply-To: <CAF8bMca3jd0qfMM5fg+npOTh-5vrcvY9JJK22pADXcac6bsFeA@mail.gmail.com>
References: <DB5PR07MB1109CA40FD696496736EAD5ADB7F0@DB5PR07MB1109.eurprd07.prod.outlook.com>
	<CAGxFJbS8m1b8gjzU9kZbmo+upcz1KbymXt594XpKVLS1rbyTNQ@mail.gmail.com>
	<DB5PR07MB1109E99CC2AD0AF465F18048DB700@DB5PR07MB1109.eurprd07.prod.outlook.com>
	<CAJ9CoWkawwB+9ESAgzs+un90goKifCWza6RegRe_W5GNAtBpBA@mail.gmail.com>
	<DB5PR07MB1109395C945654381052CFC5DB700@DB5PR07MB1109.eurprd07.prod.outlook.com>,
	<CAF8bMca3jd0qfMM5fg+npOTh-5vrcvY9JJK22pADXcac6bsFeA@mail.gmail.com>
Message-ID: <DB5PR07MB1109CD6D7D56437E74D54B98DB700@DB5PR07MB1109.eurprd07.prod.outlook.com>

Hi Bill,


Many thanks for highlighting the issue. It worked as I predicted using the tr_m. I'm extremely grateful for the insight.


Thanks for all who gave me prior guidance as well.


--
Muhammad Bilal
Research Fellow and Doctoral Researcher,
Bristol Enterprise, Research, and Innovation Centre (BERIC),
University of the West of England (UWE),
Frenchay Campus,
Bristol,
BS16 1QY

muhammad2.bilal at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>


________________________________
From: William Dunlap <wdunlap at tibco.com>
Sent: 09 May 2016 20:27:14
To: Muhammad Bilal
Cc: Max Kuhn; r-help at r-project.org
Subject: Re: [R] Problem while predicting in regression trees

Why are you predicting from tr_m$finalModel instead of from tr_m?

Bill Dunlap
TIBCO Software
wdunlap tibco.com<http://tibco.com>

On Mon, May 9, 2016 at 11:46 AM, Muhammad Bilal <Muhammad2.Bilal at live.uwe.ac.uk<mailto:Muhammad2.Bilal at live.uwe.ac.uk>> wrote:
Please find the sample dataset attached along with R code pasted below to reproduce the issue.


#Loading the data frame

pfi <- read.csv("pfi_data.csv")

#Splitting the data into training and test sets
split <- sample.split(pfi, SplitRatio = 0.7)
trainPFI <- subset(pfi, split == TRUE)
testPFI <- subset(pfi, split == FALSE)

#Cross validating the decision trees
tr.control <- trainControl(method="repeatedcv", number=20)
cp.grid <- expand.grid(.cp = (0:10)*0.001)
tr_m <- train(project_delay ~ project_lon + project_lat + project_duration + sector + contract_type + capital_value, data = trainPFI, method="rpart", trControl=tr.control, tuneGrid = cp.grid)

#Displaying the train results
tr_m

#Fetching the best tree
best_tree <- tr_m$finalModel

#Plotting the best tree
prp(best_tree)

#Using the best tree to make predictions [This command raises the error]
best_tree_pred <- predict(best_tree, newdata = testPFI)

#Calculating the SSE
best_tree_pred.sse <- sum((best_tree_pred - testPFI$project_delay)^2)

#
tree_pred.sse

...


Many Thanks and


Kind Regards



--
Muhammad Bilal
Research Fellow and Doctoral Researcher,
Bristol Enterprise, Research, and Innovation Centre (BERIC),
University of the West of England (UWE),
Frenchay Campus,
Bristol,
BS16 1QY

muhammad2.bilal at live.uwe.ac.uk<mailto:muhammad2.bilal at live.uwe.ac.uk><mailto:olugbenga2.akinade at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>>


________________________________
From: Max Kuhn <mxkuhn at gmail.com<mailto:mxkuhn at gmail.com>>
Sent: 09 May 2016 17:22:22
To: Muhammad Bilal
Cc: Bert Gunter; r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] Problem while predicting in regression trees

It is extremely difficult to tell what the issue might be without a reproducible example.

The only thing that I can suggest is to use the non-formula interface to `train` so that you can avoid creating dummy variables.

On Mon, May 9, 2016 at 11:23 AM, Muhammad Bilal <Muhammad2.Bilal at live.uwe.ac.uk<mailto:Muhammad2.Bilal at live.uwe.ac.uk><mailto:Muhammad2.Bilal at live.uwe.ac.uk<mailto:Muhammad2.Bilal at live.uwe.ac.uk>>> wrote:
Hi Bert,

Thanks for the response.

I checked the datasets, however, the Hospitals level appears in both of them. See the output below:

> sqldf("SELECT sector, count(*) FROM trainPFI GROUP BY sector")
            sector count(*)
1          Defense        9
2        Hospitals      101
3          Housing       32
4           Others       99
5 Public Buildings       39
6          Schools      148
7      Social Care       10
8      Transportation       27
9            Waste       26
> sqldf("SELECT sector, count(*) FROM testPFI GROUP BY sector")
            sector count(*)
1          Defense        5
2        Hospitals       47
3          Housing       11
4           Others       44
5 Public Buildings       18
6          Schools       69
7      Social Care        9
8   Transportation        8
9            Waste       12

Any thing else to try?

--
Muhammad Bilal
Research Fellow and Doctoral Researcher,
Bristol Enterprise, Research, and Innovation Centre (BERIC),
University of the West of England (UWE),
Frenchay Campus,
Bristol,
BS16 1QY

muhammad2.bilal at live.uwe.ac.uk<mailto:muhammad2.bilal at live.uwe.ac.uk><mailto:muhammad2.bilal at live.uwe.ac.uk<mailto:muhammad2.bilal at live.uwe.ac.uk>>


________________________________________
From: Bert Gunter <bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com><mailto:bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>>>
Sent: 09 May 2016 01:42:39
To: Muhammad Bilal
Cc: r-help at r-project.org<mailto:r-help at r-project.org><mailto:r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: Re: [R] Problem while predicting in regression trees

It seems that the data that you used for prediction contained a level
"Hospitals" for the sector factor that did not appear in the training
data (or maybe it's the other way round). Check this.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, May 8, 2016 at 4:14 PM, Muhammad Bilal
<Muhammad2.Bilal at live.uwe.ac.uk<mailto:Muhammad2.Bilal at live.uwe.ac.uk><mailto:Muhammad2.Bilal at live.uwe.ac.uk<mailto:Muhammad2.Bilal at live.uwe.ac.uk>>> wrote:
> Hi All,
>
> I have the following script, that raises error at the last command. I am new to R and require some clarification on what is going wrong.
>
> #Creating the training and testing data sets
> splitFlag <- sample.split(pfi_v3, SplitRatio = 0.7)
> trainPFI <- subset(pfi_v3, splitFlag==TRUE)
> testPFI <- subset(pfi_v3, splitFlag==FALSE)
>
>
> #Structure of the trainPFI data frame
>> str(trainPFI)
> *******
> 'data.frame': 491 obs. of  16 variables:
>  $ project_id             : int  1 2 3 6 7 9 10 12 13 14 ...
>  $ project_lat            : num  51.4 51.5 52.2 51.9 52.5 ...
>  $ project_lon            : num  -0.642 -1.85 0.08 -0.401 -1.888 ...
>  $ sector                 : Factor w/ 9 levels "Defense","Hospitals",..: 4 4 4 6 6 6 6 6 6 6 ...
>  $ contract_type          : chr  "Turnkey" "Turnkey" "Turnkey" "Turnkey" ...
>  $ project_duration       : int  1826 3652 121 730 730 790 522 819 998 372 ...
>  $ project_delay          : int  -323 0 -60 0 0 0 -91 0 0 7 ...
>  $ capital_value          : num  6.7 5.8 21.8 24.2 40.7 10.7 70 24.5 60.5 78 ...
>  $ project_delay_pct      : num  -17.7 0 -49.6 0 0 0 -17.4 0 0 1.9 ...
>  $ delay_type             : Ord.factor w/ 9 levels "7 months early & beyond"<..: 1 5 3 5 5 5 2 5 5 6 ...
>
> library(caret)
> library(e1071)
>
> set.seed(100)
>
> tr.control <- trainControl(method="cv", number=10)
> cp.grid <- expand.grid(.cp = (0:10)*0.001)
>
> #Fitting the model using regression tree
> tr_m <- train(project_delay ~ project_lon + project_lat + project_duration + sector + contract_type + capital_value, data = trainPFI, method="rpart", trControl=tr.control, tuneGrid = cp.grid)
>
> tr_m
>
> CART
> 491 samples
> 15 predictor
> No pre-processing
> Resampling: Cross-Validated (10 fold)
> Summary of sample sizes: 443, 442, 441, 442, 441, 442, ...
> Resampling results across tuning parameters:
>   cp     RMSE      Rsquared
>   0.000  441.1524  0.5417064
>   0.001  439.6319  0.5451104
>   0.002  437.4039  0.5487203
>   0.003  432.3675  0.5566661
>   0.004  434.2138  0.5519964
>   0.005  431.6635  0.5577771
>   0.006  436.6163  0.5474135
>   0.007  440.5473  0.5407240
>   0.008  441.0876  0.5399614
>   0.009  441.5715  0.5401718
>   0.010  441.1401  0.5407121
> RMSE was used to select the optimal model using  the smallest value.
> The final value used for the model was cp = 0.005.
>
> #Fetching the best tree
> best_tree <- tr_m$finalModel
>
> Alright, all the aforementioned commands worked fine.
>
> Except the subsequent command raises error, when the developed model is used to make predictions:
> best_tree_pred <- predict(best_tree, newdata = testPFI)
> Error in eval(expr, envir, enclos) : object 'sectorHospitals' not found
>
> Can someone guide me what to do to resolve this issue.
>
> Any help will be highly appreciated.
>
> Many Thanks and
>
> Kind Regards
>
> --
> Muhammad Bilal
> Research Fellow and Doctoral Researcher,
> Bristol Enterprise, Research, and Innovation Centre (BERIC),
> University of the West of England (UWE),
> Frenchay Campus,
> Bristol,
> BS16 1QY
>
> muhammad2.bilal at live.uwe.ac.uk<mailto:muhammad2.bilal at live.uwe.ac.uk><mailto:muhammad2.bilal at live.uwe.ac.uk<mailto:muhammad2.bilal at live.uwe.ac.uk>><mailto:olugbenga2.akinade at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk><mailto:olugbenga2.akinade at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>>>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org><mailto:R-help at r-project.org<mailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org><mailto:R-help at r-project.org<mailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From mike at hsm.org.uk  Mon May  9 23:24:19 2016
From: mike at hsm.org.uk (Mike Smith)
Date: Mon, 9 May 2016 22:24:19 +0100
Subject: [R] ggplot scale_colour_distiller  legend to display all values?
Message-ID: <372231884.20160509222419@hsm.org.uk>

Is there a way to get ggplot scale_colour_distiller to display all values in the legend? 

Currently using this code.

thanks!

mike

library(ggplot2)
#Input data: insert the filename for raw data
data <- read.csv("http://www.lecturematerials.co.uk/data/learning_bands.csv",header=T)

ggplot(data,aes(x=multiplier,y=factor)) +
  geom_point(aes(colour=band), size=8, shape=15) +
  scale_colour_distiller(palette = "Spectral", direction=-1, guide="legend", name="Order") +
  ggtitle("Times Tables Learning Bands") +
  scale_x_continuous(name="Multiplier", limits=c(2, 12), breaks=c(2,4,6,8,10,12)) +
  scale_y_continuous(name="Factor", limits=c(2, 12), breaks=c(2,4,6,8,10,12)) + 
  geom_abline(intercept = 0, slope = 1, size=1) +
  coord_fixed() 




---
Mike Smith


From mxkuhn at gmail.com  Tue May 10 00:22:30 2016
From: mxkuhn at gmail.com (Max Kuhn)
Date: Mon, 9 May 2016 18:22:30 -0400
Subject: [R] Problem while predicting in regression trees
In-Reply-To: <DB5PR07MB1109395C945654381052CFC5DB700@DB5PR07MB1109.eurprd07.prod.outlook.com>
References: <DB5PR07MB1109CA40FD696496736EAD5ADB7F0@DB5PR07MB1109.eurprd07.prod.outlook.com>
	<CAGxFJbS8m1b8gjzU9kZbmo+upcz1KbymXt594XpKVLS1rbyTNQ@mail.gmail.com>
	<DB5PR07MB1109E99CC2AD0AF465F18048DB700@DB5PR07MB1109.eurprd07.prod.outlook.com>
	<CAJ9CoWkawwB+9ESAgzs+un90goKifCWza6RegRe_W5GNAtBpBA@mail.gmail.com>
	<DB5PR07MB1109395C945654381052CFC5DB700@DB5PR07MB1109.eurprd07.prod.outlook.com>
Message-ID: <CAJ9CoWkeWtBXVmdRm-Ec5kCa=0G=ENzfYHf-L5-8nwgfDEDJrQ@mail.gmail.com>

I've brought this up numerous times... you shouldn't use `predict.rpart`
(or whatever modeling function) from the `finalModel` object. That object
has no idea what was done to the data prior to its invocation.

The issue here is that `train(formula)` converts the factors to dummy
variables. `rpart` does not require that and the `finalModel` object has no
idea that that happened. Using `predict.train` works just fine so why not
use it?

> table(predict(tr_m, newdata = testPFI))

-2617.42857142857 -1786.76923076923 -1777.58333333333           -1217.3
                3                 3                 6                 3
-886.666666666667          -408.375            -375.7 -240.307692307692
                5                 1                 4                 5
-201.612903225806 -19.6071428571429  30.8083333333333              43.9
               30                72                66                 9
            151.5  209.647058823529
                6                28

On Mon, May 9, 2016 at 2:46 PM, Muhammad Bilal <
Muhammad2.Bilal at live.uwe.ac.uk> wrote:

> Please find the sample dataset attached along with R code pasted below to
> reproduce the issue.
>
>
> #Loading the data frame
>
> pfi <- read.csv("pfi_data.csv")
>
> #Splitting the data into training and test sets
> split <- sample.split(pfi, SplitRatio = 0.7)
> trainPFI <- subset(pfi, split == TRUE)
> testPFI <- subset(pfi, split == FALSE)
>
> #Cross validating the decision trees
> tr.control <- trainControl(method="repeatedcv", number=20)
> cp.grid <- expand.grid(.cp = (0:10)*0.001)
> tr_m <- train(project_delay ~ project_lon + project_lat + project_duration
> + sector + contract_type + capital_value, data = trainPFI, method="rpart",
> trControl=tr.control, tuneGrid = cp.grid)
>
> #Displaying the train results
> tr_m
>
> #Fetching the best tree
> best_tree <- tr_m$finalModel
>
> #Plotting the best tree
> prp(best_tree)
>
> #Using the best tree to make predictions *[This command raises the error]*
> best_tree_pred <- predict(best_tree, newdata = testPFI)
>
> #Calculating the SSE
> best_tree_pred.sse <- sum((best_tree_pred - testPFI$project_delay)^2)
>
> #
> tree_pred.sse
>
> ...
>
> Many Thanks and
>
>
> Kind Regards
>
>
>
> --
> Muhammad Bilal
> Research Fellow and Doctoral Researcher,
> Bristol Enterprise, Research, and Innovation Centre (BERIC),
> University of the West of England (UWE),
> Frenchay Campus,
> Bristol,
> BS16 1QY
>
> *muhammad2.bilal at live.uwe.ac.uk* <olugbenga2.akinade at live.uwe.ac.uk>
>
>
> ------------------------------
> *From:* Max Kuhn <mxkuhn at gmail.com>
> *Sent:* 09 May 2016 17:22:22
> *To:* Muhammad Bilal
> *Cc:* Bert Gunter; r-help at r-project.org
>
> *Subject:* Re: [R] Problem while predicting in regression trees
>
> It is extremely difficult to tell what the issue might be without a
> reproducible example.
>
> The only thing that I can suggest is to use the non-formula interface to
> `train` so that you can avoid creating dummy variables.
>
> On Mon, May 9, 2016 at 11:23 AM, Muhammad Bilal <
> Muhammad2.Bilal at live.uwe.ac.uk> wrote:
>
>> Hi Bert,
>>
>> Thanks for the response.
>>
>> I checked the datasets, however, the Hospitals level appears in both of
>> them. See the output below:
>>
>> > sqldf("SELECT sector, count(*) FROM trainPFI GROUP BY sector")
>>             sector count(*)
>> 1          Defense        9
>> 2        Hospitals      101
>> 3          Housing       32
>> 4           Others       99
>> 5 Public Buildings       39
>> 6          Schools      148
>> 7      Social Care       10
>> 8      Transportation       27
>> 9            Waste       26
>> > sqldf("SELECT sector, count(*) FROM testPFI GROUP BY sector")
>>             sector count(*)
>> 1          Defense        5
>> 2        Hospitals       47
>> 3          Housing       11
>> 4           Others       44
>> 5 Public Buildings       18
>> 6          Schools       69
>> 7      Social Care        9
>> 8   Transportation        8
>> 9            Waste       12
>>
>> Any thing else to try?
>>
>> --
>> Muhammad Bilal
>> Research Fellow and Doctoral Researcher,
>> Bristol Enterprise, Research, and Innovation Centre (BERIC),
>> University of the West of England (UWE),
>> Frenchay Campus,
>> Bristol,
>> BS16 1QY
>>
>> muhammad2.bilal at live.uwe.ac.uk
>>
>>
>> ________________________________________
>> From: Bert Gunter <bgunter.4567 at gmail.com>
>> Sent: 09 May 2016 01:42:39
>> To: Muhammad Bilal
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Problem while predicting in regression trees
>>
>> It seems that the data that you used for prediction contained a level
>> "Hospitals" for the sector factor that did not appear in the training
>> data (or maybe it's the other way round). Check this.
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sun, May 8, 2016 at 4:14 PM, Muhammad Bilal
>> <Muhammad2.Bilal at live.uwe.ac.uk> wrote:
>> > Hi All,
>> >
>> > I have the following script, that raises error at the last command. I
>> am new to R and require some clarification on what is going wrong.
>> >
>> > #Creating the training and testing data sets
>> > splitFlag <- sample.split(pfi_v3, SplitRatio = 0.7)
>> > trainPFI <- subset(pfi_v3, splitFlag==TRUE)
>> > testPFI <- subset(pfi_v3, splitFlag==FALSE)
>> >
>> >
>> > #Structure of the trainPFI data frame
>> >> str(trainPFI)
>> > *******
>> > 'data.frame': 491 obs. of  16 variables:
>> >  $ project_id             : int  1 2 3 6 7 9 10 12 13 14 ...
>> >  $ project_lat            : num  51.4 51.5 52.2 51.9 52.5 ...
>> >  $ project_lon            : num  -0.642 -1.85 0.08 -0.401 -1.888 ...
>> >  $ sector                 : Factor w/ 9 levels
>> "Defense","Hospitals",..: 4 4 4 6 6 6 6 6 6 6 ...
>> >  $ contract_type          : chr  "Turnkey" "Turnkey" "Turnkey"
>> "Turnkey" ...
>> >  $ project_duration       : int  1826 3652 121 730 730 790 522 819 998
>> 372 ...
>> >  $ project_delay          : int  -323 0 -60 0 0 0 -91 0 0 7 ...
>> >  $ capital_value          : num  6.7 5.8 21.8 24.2 40.7 10.7 70 24.5
>> 60.5 78 ...
>> >  $ project_delay_pct      : num  -17.7 0 -49.6 0 0 0 -17.4 0 0 1.9 ...
>> >  $ delay_type             : Ord.factor w/ 9 levels "7 months early &
>> beyond"<..: 1 5 3 5 5 5 2 5 5 6 ...
>> >
>> > library(caret)
>> > library(e1071)
>> >
>> > set.seed(100)
>> >
>> > tr.control <- trainControl(method="cv", number=10)
>> > cp.grid <- expand.grid(.cp = (0:10)*0.001)
>> >
>> > #Fitting the model using regression tree
>> > tr_m <- train(project_delay ~ project_lon + project_lat +
>> project_duration + sector + contract_type + capital_value, data = trainPFI,
>> method="rpart", trControl=tr.control, tuneGrid = cp.grid)
>> >
>> > tr_m
>> >
>> > CART
>> > 491 samples
>> > 15 predictor
>> > No pre-processing
>> > Resampling: Cross-Validated (10 fold)
>> > Summary of sample sizes: 443, 442, 441, 442, 441, 442, ...
>> > Resampling results across tuning parameters:
>> >   cp     RMSE      Rsquared
>> >   0.000  441.1524  0.5417064
>> >   0.001  439.6319  0.5451104
>> >   0.002  437.4039  0.5487203
>> >   0.003  432.3675  0.5566661
>> >   0.004  434.2138  0.5519964
>> >   0.005  431.6635  0.5577771
>> >   0.006  436.6163  0.5474135
>> >   0.007  440.5473  0.5407240
>> >   0.008  441.0876  0.5399614
>> >   0.009  441.5715  0.5401718
>> >   0.010  441.1401  0.5407121
>> > RMSE was used to select the optimal model using  the smallest value.
>> > The final value used for the model was cp = 0.005.
>> >
>> > #Fetching the best tree
>> > best_tree <- tr_m$finalModel
>> >
>> > Alright, all the aforementioned commands worked fine.
>> >
>> > Except the subsequent command raises error, when the developed model is
>> used to make predictions:
>> > best_tree_pred <- predict(best_tree, newdata = testPFI)
>> > Error in eval(expr, envir, enclos) : object 'sectorHospitals' not found
>> >
>> > Can someone guide me what to do to resolve this issue.
>> >
>> > Any help will be highly appreciated.
>> >
>> > Many Thanks and
>> >
>> > Kind Regards
>> >
>> > --
>> > Muhammad Bilal
>> > Research Fellow and Doctoral Researcher,
>> > Bristol Enterprise, Research, and Innovation Centre (BERIC),
>> > University of the West of England (UWE),
>> > Frenchay Campus,
>> > Bristol,
>> > BS16 1QY
>> >
>> > muhammad2.bilal at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk
>> >
>> >
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From lucam1968 at gmail.com  Tue May 10 06:58:51 2016
From: lucam1968 at gmail.com (Luca Meyer)
Date: Tue, 10 May 2016 06:58:51 +0200
Subject: [R] Assistance with httr package with R version 3.3.0
Message-ID: <CABQyo84PYt+caZgxydaVMEgNm7S=G5HW9jMwSc41R+qtwqcxwQ@mail.gmail.com>

Hello,

I am trying to run a code I have been using for a few years now after
downloading the new R version 3.3.0 and I get the following error:

> rm(list=ls())
> library(httr)
>
> #carico i dati da Google spreadsheets
> url <- "
https://docs.google.com/spreadsheets/d/102-jJ7x1YfIe4Kkvb9olQ4chQ_TS90jxoU0vAbFZewc/pubhtml?gid=0&single=true
"
> readSpreadsheet <- function(url, sheet = 1){
+   r <- GET(url)
+   html <- content(r)
+   sheets <- readHTMLTable(html, header=FALSE, stringsAsFactors=FALSE)
+   df <- sheets[[sheet]]
+   dfClean <- function(df){
+     nms <- t(df[1,])
+     names(df) <- nms
+     df <- df[-1,-1]
+     row.names(df) <- seq(1,nrow(df))
+     df
+   }
+   dfClean(df)
+ }
> dati <- readSpreadsheet(url)
Error in (function (classes, fdef, mtable)  :
  unable to find an inherited method for function ?readHTMLTable? for
signature ?"xml_document"?
> rm(readSpreadsheet,url)

Can anyone suggest a solution to it?

Thanks,

Luca

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue May 10 08:52:38 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 10 May 2016 16:52:38 +1000
Subject: [R] Assistance with httr package with R version 3.3.0
In-Reply-To: <CABQyo84PYt+caZgxydaVMEgNm7S=G5HW9jMwSc41R+qtwqcxwQ@mail.gmail.com>
References: <CABQyo84PYt+caZgxydaVMEgNm7S=G5HW9jMwSc41R+qtwqcxwQ@mail.gmail.com>
Message-ID: <CA+8X3fXk0xnufi4xQzhp47zP_xckkyD-Bo5UA3eLw48iaumYpQ@mail.gmail.com>

Hi Luca,
The function readHTMLtable is in the XML package, not httr. Perhaps
that is the problem as I don't see a dependency in httr for XML
(although xml2 is suggested).

Jim


On Tue, May 10, 2016 at 2:58 PM, Luca Meyer <lucam1968 at gmail.com> wrote:
> Hello,
>
> I am trying to run a code I have been using for a few years now after
> downloading the new R version 3.3.0 and I get the following error:
>
>> rm(list=ls())
>> library(httr)
>>
>> #carico i dati da Google spreadsheets
>> url <- "
> https://docs.google.com/spreadsheets/d/102-jJ7x1YfIe4Kkvb9olQ4chQ_TS90jxoU0vAbFZewc/pubhtml?gid=0&single=true
> "
>> readSpreadsheet <- function(url, sheet = 1){
> +   r <- GET(url)
> +   html <- content(r)
> +   sheets <- readHTMLTable(html, header=FALSE, stringsAsFactors=FALSE)
> +   df <- sheets[[sheet]]
> +   dfClean <- function(df){
> +     nms <- t(df[1,])
> +     names(df) <- nms
> +     df <- df[-1,-1]
> +     row.names(df) <- seq(1,nrow(df))
> +     df
> +   }
> +   dfClean(df)
> + }
>> dati <- readSpreadsheet(url)
> Error in (function (classes, fdef, mtable)  :
>   unable to find an inherited method for function ?readHTMLTable? for
> signature ?"xml_document"?
>> rm(readSpreadsheet,url)
>
> Can anyone suggest a solution to it?
>
> Thanks,
>
> Luca
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From G.Maubach at weinwolf.de  Tue May 10 09:25:57 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 10 May 2016 09:25:57 +0200
Subject: [R] sink(): Cannot open  file
Message-ID: <OF15A2364C.38B38E20-ONC1257FAF.00287156-C1257FAF.0028D3F1@lotus.hawesko.de>

Hi All,

I would like to route the output to a file using sink(). When using the 
example from the ?sink documentation:

sink("sink-examp.txt")
i <- 1:10
outer(i, i, "*")
sink()
unlink("sink-examp.txt")

## capture all the output to a file.
zz <- file("all.Rout", open = "wt")
sink(zz)
sink(zz, type = "message")
try(log("a"))
## back to the console
sink(type = "message")
sink()
file.show("all.Rout")

I can not open the file in Windows Explorer. The error message is:

"Cannot open file. File is in use be another proces."

How can I close the file in a manner that I can open it right after it was 
created?

Kind regards

Georg


From lucam1968 at gmail.com  Tue May 10 09:27:12 2016
From: lucam1968 at gmail.com (Luca Meyer)
Date: Tue, 10 May 2016 09:27:12 +0200
Subject: [R] Assistance with httr package with R version 3.3.0
In-Reply-To: <CA+8X3fXk0xnufi4xQzhp47zP_xckkyD-Bo5UA3eLw48iaumYpQ@mail.gmail.com>
References: <CABQyo84PYt+caZgxydaVMEgNm7S=G5HW9jMwSc41R+qtwqcxwQ@mail.gmail.com>
	<CA+8X3fXk0xnufi4xQzhp47zP_xckkyD-Bo5UA3eLw48iaumYpQ@mail.gmail.com>
Message-ID: <CABQyo84VABvyXxw1fZtVKySxkYZ8cx-qSw9_K+1d-1x1FFVG2w@mail.gmail.com>

Hi Jim,

Thank you for your suggestion. I have actually tried to upload XML and xml2
but nothing changed...any other suggestion?

Kind regards,

Luca

> rm(list=ls())
> library(httr)
> library(XML)
> library(xml2)
>
> #carico i dati da Google spreadsheets
> url <- "
https://docs.google.com/spreadsheets/d/102-jJ7x1YfIe4Kkvb9olQ4chQ_TS90jxoU0vAbFZewc/pubhtml?gid=0&single=true
"
> readSpreadsheet <- function(url, sheet = 1){
+   r <- GET(url)
+   html <- content(r)
+   sheets <- readHTMLTable(html, header=FALSE, stringsAsFactors=FALSE)
+   df <- sheets[[sheet]]
+   dfClean <- function(df){
+     nms <- t(df[1,])
+     names(df) <- nms
+     df <- df[-1,-1]
+     row.names(df) <- seq(1,nrow(df))
+     df
+   }
+   dfClean(df)
+ }
> dati <- readSpreadsheet(url)
Error in (function (classes, fdef, mtable)  :
  unable to find an inherited method for function ?readHTMLTable? for
signature ?"xml_document"?
> rm(readSpreadsheet,url)

2016-05-10 8:52 GMT+02:00 Jim Lemon <drjimlemon at gmail.com>:

> Hi Luca,
> The function readHTMLtable is in the XML package, not httr. Perhaps
> that is the problem as I don't see a dependency in httr for XML
> (although xml2 is suggested).
>
> Jim
>
>
> On Tue, May 10, 2016 at 2:58 PM, Luca Meyer <lucam1968 at gmail.com> wrote:
> > Hello,
> >
> > I am trying to run a code I have been using for a few years now after
> > downloading the new R version 3.3.0 and I get the following error:
> >
> >> rm(list=ls())
> >> library(httr)
> >>
> >> #carico i dati da Google spreadsheets
> >> url <- "
> >
> https://docs.google.com/spreadsheets/d/102-jJ7x1YfIe4Kkvb9olQ4chQ_TS90jxoU0vAbFZewc/pubhtml?gid=0&single=true
> > "
> >> readSpreadsheet <- function(url, sheet = 1){
> > +   r <- GET(url)
> > +   html <- content(r)
> > +   sheets <- readHTMLTable(html, header=FALSE, stringsAsFactors=FALSE)
> > +   df <- sheets[[sheet]]
> > +   dfClean <- function(df){
> > +     nms <- t(df[1,])
> > +     names(df) <- nms
> > +     df <- df[-1,-1]
> > +     row.names(df) <- seq(1,nrow(df))
> > +     df
> > +   }
> > +   dfClean(df)
> > + }
> >> dati <- readSpreadsheet(url)
> > Error in (function (classes, fdef, mtable)  :
> >   unable to find an inherited method for function ?readHTMLTable? for
> > signature ?"xml_document"?
> >> rm(readSpreadsheet,url)
> >
> > Can anyone suggest a solution to it?
> >
> > Thanks,
> >
> > Luca
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bob at rudis.net  Tue May 10 11:08:12 2016
From: bob at rudis.net (boB Rudis)
Date: Tue, 10 May 2016 05:08:12 -0400
Subject: [R] Assistance with httr package with R version 3.3.0
In-Reply-To: <CABQyo84VABvyXxw1fZtVKySxkYZ8cx-qSw9_K+1d-1x1FFVG2w@mail.gmail.com>
References: <CABQyo84PYt+caZgxydaVMEgNm7S=G5HW9jMwSc41R+qtwqcxwQ@mail.gmail.com>
	<CA+8X3fXk0xnufi4xQzhp47zP_xckkyD-Bo5UA3eLw48iaumYpQ@mail.gmail.com>
	<CABQyo84VABvyXxw1fZtVKySxkYZ8cx-qSw9_K+1d-1x1FFVG2w@mail.gmail.com>
Message-ID: <CAJ4QxaOPNvp76-T7WwnvBRYC2Hwnv+t0S1f8PC8wPHLKdcvKeg@mail.gmail.com>

I don't fully remember, but I doubt httr::content() ever returned a
character vector without using the `as="text"` parameter. Try
switching that line to:

    html <- content(r, as="text")



On Tue, May 10, 2016 at 3:27 AM, Luca Meyer <lucam1968 at gmail.com> wrote:
> Hi Jim,
>
> Thank you for your suggestion. I have actually tried to upload XML and xml2
> but nothing changed...any other suggestion?
>
> Kind regards,
>
> Luca
>
>> rm(list=ls())
>> library(httr)
>> library(XML)
>> library(xml2)
>>
>> #carico i dati da Google spreadsheets
>> url <- "
> https://docs.google.com/spreadsheets/d/102-jJ7x1YfIe4Kkvb9olQ4chQ_TS90jxoU0vAbFZewc/pubhtml?gid=0&single=true
> "
>> readSpreadsheet <- function(url, sheet = 1){
> +   r <- GET(url)
> +   html <- content(r)
> +   sheets <- readHTMLTable(html, header=FALSE, stringsAsFactors=FALSE)
> +   df <- sheets[[sheet]]
> +   dfClean <- function(df){
> +     nms <- t(df[1,])
> +     names(df) <- nms
> +     df <- df[-1,-1]
> +     row.names(df) <- seq(1,nrow(df))
> +     df
> +   }
> +   dfClean(df)
> + }
>> dati <- readSpreadsheet(url)
> Error in (function (classes, fdef, mtable)  :
>   unable to find an inherited method for function ?readHTMLTable? for
> signature ?"xml_document"?
>> rm(readSpreadsheet,url)
>
> 2016-05-10 8:52 GMT+02:00 Jim Lemon <drjimlemon at gmail.com>:
>
>> Hi Luca,
>> The function readHTMLtable is in the XML package, not httr. Perhaps
>> that is the problem as I don't see a dependency in httr for XML
>> (although xml2 is suggested).
>>
>> Jim
>>
>>
>> On Tue, May 10, 2016 at 2:58 PM, Luca Meyer <lucam1968 at gmail.com> wrote:
>> > Hello,
>> >
>> > I am trying to run a code I have been using for a few years now after
>> > downloading the new R version 3.3.0 and I get the following error:
>> >
>> >> rm(list=ls())
>> >> library(httr)
>> >>
>> >> #carico i dati da Google spreadsheets
>> >> url <- "
>> >
>> https://docs.google.com/spreadsheets/d/102-jJ7x1YfIe4Kkvb9olQ4chQ_TS90jxoU0vAbFZewc/pubhtml?gid=0&single=true
>> > "
>> >> readSpreadsheet <- function(url, sheet = 1){
>> > +   r <- GET(url)
>> > +   html <- content(r)
>> > +   sheets <- readHTMLTable(html, header=FALSE, stringsAsFactors=FALSE)
>> > +   df <- sheets[[sheet]]
>> > +   dfClean <- function(df){
>> > +     nms <- t(df[1,])
>> > +     names(df) <- nms
>> > +     df <- df[-1,-1]
>> > +     row.names(df) <- seq(1,nrow(df))
>> > +     df
>> > +   }
>> > +   dfClean(df)
>> > + }
>> >> dati <- readSpreadsheet(url)
>> > Error in (function (classes, fdef, mtable)  :
>> >   unable to find an inherited method for function ?readHTMLTable? for
>> > signature ?"xml_document"?
>> >> rm(readSpreadsheet,url)
>> >
>> > Can anyone suggest a solution to it?
>> >
>> > Thanks,
>> >
>> > Luca
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Muhammad2.Bilal at live.uwe.ac.uk  Tue May 10 12:17:26 2016
From: Muhammad2.Bilal at live.uwe.ac.uk (Muhammad Bilal)
Date: Tue, 10 May 2016 10:17:26 +0000
Subject: [R] Problem while predicting in regression trees
In-Reply-To: <CAJ9CoWkeWtBXVmdRm-Ec5kCa=0G=ENzfYHf-L5-8nwgfDEDJrQ@mail.gmail.com>
References: <DB5PR07MB1109CA40FD696496736EAD5ADB7F0@DB5PR07MB1109.eurprd07.prod.outlook.com>
	<CAGxFJbS8m1b8gjzU9kZbmo+upcz1KbymXt594XpKVLS1rbyTNQ@mail.gmail.com>
	<DB5PR07MB1109E99CC2AD0AF465F18048DB700@DB5PR07MB1109.eurprd07.prod.outlook.com>
	<CAJ9CoWkawwB+9ESAgzs+un90goKifCWza6RegRe_W5GNAtBpBA@mail.gmail.com>
	<DB5PR07MB1109395C945654381052CFC5DB700@DB5PR07MB1109.eurprd07.prod.outlook.com>,
	<CAJ9CoWkeWtBXVmdRm-Ec5kCa=0G=ENzfYHf-L5-8nwgfDEDJrQ@mail.gmail.com>
Message-ID: <HE1PR07MB111413432F570BDBB81CDF87DB710@HE1PR07MB1114.eurprd07.prod.outlook.com>

Many thanks Max for these valuable suggestions.


--
Muhammad Bilal
Research Fellow and Doctoral Researcher,
Bristol Enterprise, Research, and Innovation Centre (BERIC),
University of the West of England (UWE),
Frenchay Campus,
Bristol,
BS16 1QY

muhammad2.bilal at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>


________________________________
From: Max Kuhn <mxkuhn at gmail.com>
Sent: 09 May 2016 23:22:30
To: Muhammad Bilal
Cc: Bert Gunter; r-help at r-project.org
Subject: Re: [R] Problem while predicting in regression trees

I've brought this up numerous times... you shouldn't use `predict.rpart` (or whatever modeling function) from the `finalModel` object. That object has no idea what was done to the data prior to its invocation.

The issue here is that `train(formula)` converts the factors to dummy variables. `rpart` does not require that and the `finalModel` object has no idea that that happened. Using `predict.train` works just fine so why not use it?

> table(predict(tr_m, newdata = testPFI))

-2617.42857142857 -1786.76923076923 -1777.58333333333           -1217.3
                3                 3                 6                 3
-886.666666666667          -408.375            -375.7 -240.307692307692
                5                 1                 4                 5
-201.612903225806 -19.6071428571429  30.8083333333333              43.9
               30                72                66                 9
            151.5  209.647058823529
                6                28

On Mon, May 9, 2016 at 2:46 PM, Muhammad Bilal <Muhammad2.Bilal at live.uwe.ac.uk<mailto:Muhammad2.Bilal at live.uwe.ac.uk>> wrote:

Please find the sample dataset attached along with R code pasted below to reproduce the issue.


#Loading the data frame

pfi <- read.csv("pfi_data.csv")

#Splitting the data into training and test sets
split <- sample.split(pfi, SplitRatio = 0.7)
trainPFI <- subset(pfi, split == TRUE)
testPFI <- subset(pfi, split == FALSE)

#Cross validating the decision trees
tr.control <- trainControl(method="repeatedcv", number=20)
cp.grid <- expand.grid(.cp = (0:10)*0.001)
tr_m <- train(project_delay ~ project_lon + project_lat + project_duration + sector + contract_type + capital_value, data = trainPFI, method="rpart", trControl=tr.control, tuneGrid = cp.grid)

#Displaying the train results
tr_m

#Fetching the best tree
best_tree <- tr_m$finalModel

#Plotting the best tree
prp(best_tree)

#Using the best tree to make predictions [This command raises the error]
best_tree_pred <- predict(best_tree, newdata = testPFI)

#Calculating the SSE
best_tree_pred.sse <- sum((best_tree_pred - testPFI$project_delay)^2)

#
tree_pred.sse

...


Many Thanks and


Kind Regards



--
Muhammad Bilal
Research Fellow and Doctoral Researcher,
Bristol Enterprise, Research, and Innovation Centre (BERIC),
University of the West of England (UWE),
Frenchay Campus,
Bristol,
BS16 1QY

muhammad2.bilal at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>


________________________________
From: Max Kuhn <mxkuhn at gmail.com<mailto:mxkuhn at gmail.com>>
Sent: 09 May 2016 17:22:22
To: Muhammad Bilal
Cc: Bert Gunter; r-help at r-project.org<mailto:r-help at r-project.org>

Subject: Re: [R] Problem while predicting in regression trees

It is extremely difficult to tell what the issue might be without a reproducible example.

The only thing that I can suggest is to use the non-formula interface to `train` so that you can avoid creating dummy variables.

On Mon, May 9, 2016 at 11:23 AM, Muhammad Bilal <Muhammad2.Bilal at live.uwe.ac.uk<mailto:Muhammad2.Bilal at live.uwe.ac.uk>> wrote:
Hi Bert,

Thanks for the response.

I checked the datasets, however, the Hospitals level appears in both of them. See the output below:

> sqldf("SELECT sector, count(*) FROM trainPFI GROUP BY sector")
            sector count(*)
1          Defense        9
2        Hospitals      101
3          Housing       32
4           Others       99
5 Public Buildings       39
6          Schools      148
7      Social Care       10
8      Transportation       27
9            Waste       26
> sqldf("SELECT sector, count(*) FROM testPFI GROUP BY sector")
            sector count(*)
1          Defense        5
2        Hospitals       47
3          Housing       11
4           Others       44
5 Public Buildings       18
6          Schools       69
7      Social Care        9
8   Transportation        8
9            Waste       12

Any thing else to try?

--
Muhammad Bilal
Research Fellow and Doctoral Researcher,
Bristol Enterprise, Research, and Innovation Centre (BERIC),
University of the West of England (UWE),
Frenchay Campus,
Bristol,
BS16 1QY

muhammad2.bilal at live.uwe.ac.uk<mailto:muhammad2.bilal at live.uwe.ac.uk>


________________________________________
From: Bert Gunter <bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>>
Sent: 09 May 2016 01:42:39
To: Muhammad Bilal
Cc: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] Problem while predicting in regression trees

It seems that the data that you used for prediction contained a level
"Hospitals" for the sector factor that did not appear in the training
data (or maybe it's the other way round). Check this.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, May 8, 2016 at 4:14 PM, Muhammad Bilal
<Muhammad2.Bilal at live.uwe.ac.uk<mailto:Muhammad2.Bilal at live.uwe.ac.uk>> wrote:
> Hi All,
>
> I have the following script, that raises error at the last command. I am new to R and require some clarification on what is going wrong.
>
> #Creating the training and testing data sets
> splitFlag <- sample.split(pfi_v3, SplitRatio = 0.7)
> trainPFI <- subset(pfi_v3, splitFlag==TRUE)
> testPFI <- subset(pfi_v3, splitFlag==FALSE)
>
>
> #Structure of the trainPFI data frame
>> str(trainPFI)
> *******
> 'data.frame': 491 obs. of  16 variables:
>  $ project_id             : int  1 2 3 6 7 9 10 12 13 14 ...
>  $ project_lat            : num  51.4 51.5 52.2 51.9 52.5 ...
>  $ project_lon            : num  -0.642 -1.85 0.08 -0.401 -1.888 ...
>  $ sector                 : Factor w/ 9 levels "Defense","Hospitals",..: 4 4 4 6 6 6 6 6 6 6 ...
>  $ contract_type          : chr  "Turnkey" "Turnkey" "Turnkey" "Turnkey" ...
>  $ project_duration       : int  1826 3652 121 730 730 790 522 819 998 372 ...
>  $ project_delay          : int  -323 0 -60 0 0 0 -91 0 0 7 ...
>  $ capital_value          : num  6.7 5.8 21.8 24.2 40.7 10.7 70 24.5 60.5 78 ...
>  $ project_delay_pct      : num  -17.7 0 -49.6 0 0 0 -17.4 0 0 1.9 ...
>  $ delay_type             : Ord.factor w/ 9 levels "7 months early & beyond"<..: 1 5 3 5 5 5 2 5 5 6 ...
>
> library(caret)
> library(e1071)
>
> set.seed(100)
>
> tr.control <- trainControl(method="cv", number=10)
> cp.grid <- expand.grid(.cp = (0:10)*0.001)
>
> #Fitting the model using regression tree
> tr_m <- train(project_delay ~ project_lon + project_lat + project_duration + sector + contract_type + capital_value, data = trainPFI, method="rpart", trControl=tr.control, tuneGrid = cp.grid)
>
> tr_m
>
> CART
> 491 samples
> 15 predictor
> No pre-processing
> Resampling: Cross-Validated (10 fold)
> Summary of sample sizes: 443, 442, 441, 442, 441, 442, ...
> Resampling results across tuning parameters:
>   cp     RMSE      Rsquared
>   0.000  441.1524  0.5417064
>   0.001  439.6319  0.5451104
>   0.002  437.4039  0.5487203
>   0.003  432.3675  0.5566661
>   0.004  434.2138  0.5519964
>   0.005  431.6635  0.5577771
>   0.006  436.6163  0.5474135
>   0.007  440.5473  0.5407240
>   0.008  441.0876  0.5399614
>   0.009  441.5715  0.5401718
>   0.010  441.1401  0.5407121
> RMSE was used to select the optimal model using  the smallest value.
> The final value used for the model was cp = 0.005.
>
> #Fetching the best tree
> best_tree <- tr_m$finalModel
>
> Alright, all the aforementioned commands worked fine.
>
> Except the subsequent command raises error, when the developed model is used to make predictions:
> best_tree_pred <- predict(best_tree, newdata = testPFI)
> Error in eval(expr, envir, enclos) : object 'sectorHospitals' not found
>
> Can someone guide me what to do to resolve this issue.
>
> Any help will be highly appreciated.
>
> Many Thanks and
>
> Kind Regards
>
> --
> Muhammad Bilal
> Research Fellow and Doctoral Researcher,
> Bristol Enterprise, Research, and Innovation Centre (BERIC),
> University of the West of England (UWE),
> Frenchay Campus,
> Bristol,
> BS16 1QY
>
> muhammad2.bilal at live.uwe.ac.uk<mailto:muhammad2.bilal at live.uwe.ac.uk><mailto:olugbenga2.akinade at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue May 10 12:50:54 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 10 May 2016 20:50:54 +1000
Subject: [R] sink(): Cannot open file
In-Reply-To: <OF15A2364C.38B38E20-ONC1257FAF.00287156-C1257FAF.0028D3F1@lotus.hawesko.de>
References: <OF15A2364C.38B38E20-ONC1257FAF.00287156-C1257FAF.0028D3F1@lotus.hawesko.de>
Message-ID: <CA+8X3fWKAJysbwP+whoDrSnT8W3njAUq5LwmjTp3qq-AOdanzg@mail.gmail.com>

Hi Georg,
I don't suppose that you have:

1) checked that the file "all.Rout" exists somewhere?

2) if so, looked at the file with Notepad, perhaps?

3) let us in on the secret by pasting the contents of "all.Rout" into
your message if it is not too big?

At a guess, trying:

 close(zz)

might get you there.

Jim

On Tue, May 10, 2016 at 5:25 PM,  <G.Maubach at weinwolf.de> wrote:
> Hi All,
>
> I would like to route the output to a file using sink(). When using the
> example from the ?sink documentation:
>
> sink("sink-examp.txt")
> i <- 1:10
> outer(i, i, "*")
> sink()
> unlink("sink-examp.txt")
>
> ## capture all the output to a file.
> zz <- file("all.Rout", open = "wt")
> sink(zz)
> sink(zz, type = "message")
> try(log("a"))
> ## back to the console
> sink(type = "message")
> sink()
> file.show("all.Rout")
>
> I can not open the file in Windows Explorer. The error message is:
>
> "Cannot open file. File is in use be another proces."
>
> How can I close the file in a manner that I can open it right after it was
> created?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From G.Maubach at weinwolf.de  Tue May 10 13:05:44 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 10 May 2016 13:05:44 +0200
Subject: [R] Antwort: Re:  sink(): Cannot open file
In-Reply-To: <CA+8X3fWKAJysbwP+whoDrSnT8W3njAUq5LwmjTp3qq-AOdanzg@mail.gmail.com>
References: <OF15A2364C.38B38E20-ONC1257FAF.00287156-C1257FAF.0028D3F1@lotus.hawesko.de>
	<CA+8X3fWKAJysbwP+whoDrSnT8W3njAUq5LwmjTp3qq-AOdanzg@mail.gmail.com>
Message-ID: <OF680609C9.B98EF9B5-ONC1257FAF.003C5B6B-C1257FAF.003CF31F@lotus.hawesko.de>

Hi Jim,

thanks for your reply.

ad 1)
"all.Rout" was created in the correct directory. It exists properly with 
correct file properties on Windows, e.g. creation date and time and file 
size information.

ad 2)
I can not access the file with Notepad.exe directly after it was created 
by R.  The error message is (translated):

"Cannot access file "all.Rout". The file is opened by another process."

ad 3)
If I close R completely the file access is released. Then I can read the 
file using Notepad.exe. The contents is:

Error in log("a") : non-numeric argument to mathematical function

I tried

close(zz)

but the error persists.

To me it looks like R is still accessing the file and not releasing the 
connection for other programs. close(zz) should have solved the problem 
but unfortantely it doesn't.

What else could I try?

Kind regards

Georg




Von:    Jim Lemon <drjimlemon at gmail.com>
An:     G.Maubach at weinwolf.de, 
Kopie:  r-help mailing list <r-help at r-project.org>
Datum:  10.05.2016 12:50
Betreff:        Re: [R] sink(): Cannot open file



Hi Georg,
I don't suppose that you have:

1) checked that the file "all.Rout" exists somewhere?

2) if so, looked at the file with Notepad, perhaps?

3) let us in on the secret by pasting the contents of "all.Rout" into
your message if it is not too big?

At a guess, trying:

 close(zz)

might get you there.

Jim

On Tue, May 10, 2016 at 5:25 PM,  <G.Maubach at weinwolf.de> wrote:
> Hi All,
>
> I would like to route the output to a file using sink(). When using the
> example from the ?sink documentation:
>
> sink("sink-examp.txt")
> i <- 1:10
> outer(i, i, "*")
> sink()
> unlink("sink-examp.txt")
>
> ## capture all the output to a file.
> zz <- file("all.Rout", open = "wt")
> sink(zz)
> sink(zz, type = "message")
> try(log("a"))
> ## back to the console
> sink(type = "message")
> sink()
> file.show("all.Rout")
>
> I can not open the file in Windows Explorer. The error message is:
>
> "Cannot open file. File is in use be another proces."
>
> How can I close the file in a manner that I can open it right after it 
was
> created?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mkashif at uaf.edu.pk  Tue May 10 13:15:42 2016
From: mkashif at uaf.edu.pk (Muhammad  Kashif)
Date: Tue, 10 May 2016 11:15:42 +0000
Subject: [R] Coverage Probability
Message-ID: <VI1PR07MB132544F2B6DB27B3068C603294710@VI1PR07MB1325.eurprd07.prod.outlook.com>

Dears
Can anyone help me to solve the issue.

By using" boot" and "boot.ci" package in R we can construct bootstrap confidence intervals. How we calculate the coverage probability of these intervals.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue May 10 13:16:55 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 10 May 2016 21:16:55 +1000
Subject: [R] sink(): Cannot open file
In-Reply-To: <OF680609C9.B98EF9B5-ONC1257FAF.003C5B6B-C1257FAF.003CF31F@lotus.hawesko.de>
References: <OF15A2364C.38B38E20-ONC1257FAF.00287156-C1257FAF.0028D3F1@lotus.hawesko.de>
	<CA+8X3fWKAJysbwP+whoDrSnT8W3njAUq5LwmjTp3qq-AOdanzg@mail.gmail.com>
	<OF680609C9.B98EF9B5-ONC1257FAF.003C5B6B-C1257FAF.003CF31F@lotus.hawesko.de>
Message-ID: <CA+8X3fV=Cc8n0WBk6JjobbHm0E+R4ss+7is233o9HYVwGaiQ8Q@mail.gmail.com>

Have you tried:

sink("all.Rout")
try(log("a"))
sink()

Jim

On Tue, May 10, 2016 at 9:05 PM,  <G.Maubach at weinwolf.de> wrote:
> Hi Jim,
>
> thanks for your reply.
>
> ad 1)
> "all.Rout" was created in the correct directory. It exists properly with
> correct file properties on Windows, e.g. creation date and time and file
> size information.
>
> ad 2)
> I can not access the file with Notepad.exe directly after it was created
> by R.  The error message is (translated):
>
> "Cannot access file "all.Rout". The file is opened by another process."
>
> ad 3)
> If I close R completely the file access is released. Then I can read the
> file using Notepad.exe. The contents is:
>
> Error in log("a") : non-numeric argument to mathematical function
>
> I tried
>
> close(zz)
>
> but the error persists.
>
> To me it looks like R is still accessing the file and not releasing the
> connection for other programs. close(zz) should have solved the problem
> but unfortantely it doesn't.
>
> What else could I try?
>
> Kind regards
>
> Georg
>
>
>
>
> Von:    Jim Lemon <drjimlemon at gmail.com>
> An:     G.Maubach at weinwolf.de,
> Kopie:  r-help mailing list <r-help at r-project.org>
> Datum:  10.05.2016 12:50
> Betreff:        Re: [R] sink(): Cannot open file
>
>
>
> Hi Georg,
> I don't suppose that you have:
>
> 1) checked that the file "all.Rout" exists somewhere?
>
> 2) if so, looked at the file with Notepad, perhaps?
>
> 3) let us in on the secret by pasting the contents of "all.Rout" into
> your message if it is not too big?
>
> At a guess, trying:
>
>  close(zz)
>
> might get you there.
>
> Jim
>
> On Tue, May 10, 2016 at 5:25 PM,  <G.Maubach at weinwolf.de> wrote:
>> Hi All,
>>
>> I would like to route the output to a file using sink(). When using the
>> example from the ?sink documentation:
>>
>> sink("sink-examp.txt")
>> i <- 1:10
>> outer(i, i, "*")
>> sink()
>> unlink("sink-examp.txt")
>>
>> ## capture all the output to a file.
>> zz <- file("all.Rout", open = "wt")
>> sink(zz)
>> sink(zz, type = "message")
>> try(log("a"))
>> ## back to the console
>> sink(type = "message")
>> sink()
>> file.show("all.Rout")
>>
>> I can not open the file in Windows Explorer. The error message is:
>>
>> "Cannot open file. File is in use be another proces."
>>
>> How can I close the file in a manner that I can open it right after it
> was
>> created?
>>
>> Kind regards
>>
>> Georg
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From nite at achren.org  Mon May  9 23:39:27 2016
From: nite at achren.org (Andrew Clancy)
Date: Mon, 9 May 2016 22:39:27 +0100
Subject: [R] Ensure parameter is a string when passed within an lapply &
 called function runs a 'substitute' on it
Message-ID: <57310388.e873c20a.284cd.062d@mx.google.com>

Hi, 

I?m trying to solve what looks like the same issue as stack overflow article, but within an lapply:
http://stackoverflow.com/questions/18939254/cant-use-a-variable-as-an-argument-but-can-use-its-value

I?ve replicated the issue with partialPlot below in ?testFunc?. The lines up to the final print can?t change (including the substitute). In the first call it prints out ?X1? correctly, in the second it prints out ?var?. I?ve tried eval, quote etc as the article suggests. Any ideas?

numObs ?<- 10
numVars <- 6
dataSet ? ?<- data.frame(replicate(numVars,rnorm(numObs)))
# partialPlot(x = model, pred.data = dataSet, x.var = 'X1', plot = F)?

testFunc <- function(x, pred.data, x.var, plot=F) {
? x.var <- substitute(x.var)
? # print(paste('is.character(x.var)', is.character(x.var), 'is.name(x.var)',?is.name(x.var)))
? xname <- if (is.character(x.var)) x.var else {
? ? if (is.name(x.var)) deparse(x.var) else {
? ? ? eval(x.var)
? ? }
? }
? print(xname)
? # print(head(pred.data[,xname]))
}

vars <- names(dataSet)[[1]]
testFunc(x = model, pred.data = dataSet, x.var = local(vars), plot = F)

lapply(vars, function(var) {
? # print(paste('var', var))
? testFunc(x = model, pred.data = dataSet, x.var = var, plot = F)
})

	[[alternative HTML version deleted]]


From G.Maubach at weinwolf.de  Tue May 10 17:05:00 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 10 May 2016 17:05:00 +0200
Subject: [R] Antwort: Re: Re:  sink(): Cannot open file
In-Reply-To: <CA+8X3fV=Cc8n0WBk6JjobbHm0E+R4ss+7is233o9HYVwGaiQ8Q@mail.gmail.com>
References: <OF15A2364C.38B38E20-ONC1257FAF.00287156-C1257FAF.0028D3F1@lotus.hawesko.de>
	<CA+8X3fWKAJysbwP+whoDrSnT8W3njAUq5LwmjTp3qq-AOdanzg@mail.gmail.com>	<OF680609C9.B98EF9B5-ONC1257FAF.003C5B6B-C1257FAF.003CF31F@lotus.hawesko.de>
	<CA+8X3fV=Cc8n0WBk6JjobbHm0E+R4ss+7is233o9HYVwGaiQ8Q@mail.gmail.com>
Message-ID: <OFF8B5EC26.08CB1CFC-ONC1257FAF.00526FBA-C1257FAF.0052DAB9@lotus.hawesko.de>

Hi Jim,

I tried:

sink("all.Rout")
try(log("a"))
sink()

The program executes without warning or error. The file "all.Rout" is 
begin created. Nothing will be written to it. The file is accessable 
rights after the execution of the program by notepad.exe.

The program

zz <- file("all.Rout", open = "wt")
sink(zz, type = "message")
try(log("a"))
sink()
close(zz)
unlink(zz)

creates the file, does not write anything to it and is not accessable 
after program execution in R with notepad.exe.

Any ideas what happens behind the szenes?

Kind regards

Georg




Von:    Jim Lemon <drjimlemon at gmail.com>
An:     G.Maubach at weinwolf.de, 
Kopie:  r-help mailing list <r-help at r-project.org>
Datum:  10.05.2016 13:16
Betreff:        Re: Re: [R] sink(): Cannot open file



Have you tried:

sink("all.Rout")
try(log("a"))
sink()

Jim

On Tue, May 10, 2016 at 9:05 PM,  <G.Maubach at weinwolf.de> wrote:
> Hi Jim,
>
> thanks for your reply.
>
> ad 1)
> "all.Rout" was created in the correct directory. It exists properly with
> correct file properties on Windows, e.g. creation date and time and file
> size information.
>
> ad 2)
> I can not access the file with Notepad.exe directly after it was created
> by R.  The error message is (translated):
>
> "Cannot access file "all.Rout". The file is opened by another process."
>
> ad 3)
> If I close R completely the file access is released. Then I can read the
> file using Notepad.exe. The contents is:
>
> Error in log("a") : non-numeric argument to mathematical function
>
> I tried
>
> close(zz)
>
> but the error persists.
>
> To me it looks like R is still accessing the file and not releasing the
> connection for other programs. close(zz) should have solved the problem
> but unfortantely it doesn't.
>
> What else could I try?
>
> Kind regards
>
> Georg
>
>
>
>
> Von:    Jim Lemon <drjimlemon at gmail.com>
> An:     G.Maubach at weinwolf.de,
> Kopie:  r-help mailing list <r-help at r-project.org>
> Datum:  10.05.2016 12:50
> Betreff:        Re: [R] sink(): Cannot open file
>
>
>
> Hi Georg,
> I don't suppose that you have:
>
> 1) checked that the file "all.Rout" exists somewhere?
>
> 2) if so, looked at the file with Notepad, perhaps?
>
> 3) let us in on the secret by pasting the contents of "all.Rout" into
> your message if it is not too big?
>
> At a guess, trying:
>
>  close(zz)
>
> might get you there.
>
> Jim
>
> On Tue, May 10, 2016 at 5:25 PM,  <G.Maubach at weinwolf.de> wrote:
>> Hi All,
>>
>> I would like to route the output to a file using sink(). When using the
>> example from the ?sink documentation:
>>
>> sink("sink-examp.txt")
>> i <- 1:10
>> outer(i, i, "*")
>> sink()
>> unlink("sink-examp.txt")
>>
>> ## capture all the output to a file.
>> zz <- file("all.Rout", open = "wt")
>> sink(zz)
>> sink(zz, type = "message")
>> try(log("a"))
>> ## back to the console
>> sink(type = "message")
>> sink()
>> file.show("all.Rout")
>>
>> I can not open the file in Windows Explorer. The error message is:
>>
>> "Cannot open file. File is in use be another proces."
>>
>> How can I close the file in a manner that I can open it right after it
> was
>> created?
>>
>> Kind regards
>>
>> Georg
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From jsorkin at grecc.umaryland.edu  Tue May 10 17:15:08 2016
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Tue, 10 May 2016 11:15:08 -0400
Subject: [R] Antwort: Re: Re: sink(): Cannot open file
In-Reply-To: <OFF8B5EC26.08CB1CFC-ONC1257FAF.00526FBA-C1257FAF.0052DAB9@lotus.hawesko.de>
References: <OF15A2364C.38B38E20-ONC1257FAF.00287156-C1257FAF.0028D3F1@lotus.hawesko.de>
	<CA+8X3fWKAJysbwP+whoDrSnT8W3njAUq5LwmjTp3qq-AOdanzg@mail.gmail.com>
	<OF680609C9.B98EF9B5-ONC1257FAF.003C5B6B-C1257FAF.003CF31F@lotus.hawesko.de>
	<CA+8X3fV=Cc8n0WBk6JjobbHm0E+R4ss+7is233o9HYVwGaiQ8Q@mail.gmail.com>
	<OFF8B5EC26.08CB1CFC-ONC1257FAF.00526FBA-C1257FAF.0052DAB9@lotus.hawesko.de>
Message-ID: <5731C2BC020000CB001536F4@smtp.medicine.umaryland.edu>

George,
I do not know what operating system you are working with, but when I use sink() under windows, I need to specify a valid path which I don't see in your code. I might, for example specify:

sink("c:\myfile.txt")
 R code goes here
sink()

with the expectation that I would create a file myfile.txt that would contain the output of my R program.
 
John


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>>> <G.Maubach at weinwolf.de> 05/10/16 11:10 AM >>>
Hi Jim,

I tried:

sink("all.Rout")
try(log("a"))
sink()

The program executes without warning or error. The file "all.Rout" is 
begin created. Nothing will be written to it. The file is accessable 
rights after the execution of the program by notepad.exe.

The program

zz <- file("all.Rout", open = "wt")
sink(zz, type = "message")
try(log("a"))
sink()
close(zz)
unlink(zz)

creates the file, does not write anything to it and is not accessable 
after program execution in R with notepad.exe.

Any ideas what happens behind the szenes?

Kind regards

Georg




Von: Jim Lemon <drjimlemon at gmail.com>
An: G.Maubach at weinwolf.de, 
Kopie: r-help mailing list <r-help at r-project.org>
Datum: 10.05.2016 13:16
Betreff: Re: Re: [R] sink(): Cannot open file



Have you tried:

sink("all.Rout")
try(log("a"))
sink()

Jim

On Tue, May 10, 2016 at 9:05 PM, <G.Maubach at weinwolf.de> wrote:
> Hi Jim,
>
> thanks for your reply.
>
> ad 1)
> "all.Rout" was created in the correct directory. It exists properly with
> correct file properties on Windows, e.g. creation date and time and file
> size information.
>
> ad 2)
> I can not access the file with Notepad.exe directly after it was created
> by R. The error message is (translated):
>
> "Cannot access file "all.Rout". The file is opened by another process."
>
> ad 3)
> If I close R completely the file access is released. Then I can read the
> file using Notepad.exe. The contents is:
>
> Error in log("a") : non-numeric argument to mathematical function
>
> I tried
>
> close(zz)
>
> but the error persists.
>
> To me it looks like R is still accessing the file and not releasing the
> connection for other programs. close(zz) should have solved the problem
> but unfortantely it doesn't.
>
> What else could I try?
>
> Kind regards
>
> Georg
>
>
>
>
> Von: Jim Lemon <drjimlemon at gmail.com>
> An: G.Maubach at weinwolf.de,
> Kopie: r-help mailing list <r-help at r-project.org>
> Datum: 10.05.2016 12:50
> Betreff: Re: [R] sink(): Cannot open file
>
>
>
> Hi Georg,
> I don't suppose that you have:
>
> 1) checked that the file "all.Rout" exists somewhere?
>
> 2) if so, looked at the file with Notepad, perhaps?
>
> 3) let us in on the secret by pasting the contents of "all.Rout" into
> your message if it is not too big?
>
> At a guess, trying:
>
> close(zz)
>
> might get you there.
>
> Jim
>
> On Tue, May 10, 2016 at 5:25 PM, <G.Maubach at weinwolf.de> wrote:
>> Hi All,
>>
>> I would like to route the output to a file using sink(). When using the
>> example from the ?sink documentation:
>>
>> sink("sink-examp.txt")
>> i <- 1:10
>> outer(i, i, "*")
>> sink()
>> unlink("sink-examp.txt")
>>
>> ## capture all the output to a file.
>> zz <- file("all.Rout", open = "wt")
>> sink(zz)
>> sink(zz, type = "message")
>> try(log("a"))
>> ## back to the console
>> sink(type = "message")
>> sink()
>> file.show("all.Rout")
>>
>> I can not open the file in Windows Explorer. The error message is:
>>
>> "Cannot open file. File is in use be another proces."
>>
>> How can I close the file in a manner that I can open it right after it
> was
>> created?
>>
>> Kind regards
>>
>> Georg
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From sarah.goslee at gmail.com  Tue May 10 17:17:36 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 10 May 2016 11:17:36 -0400
Subject: [R] Antwort: Re: Re: sink(): Cannot open file
In-Reply-To: <OFF8B5EC26.08CB1CFC-ONC1257FAF.00526FBA-C1257FAF.0052DAB9@lotus.hawesko.de>
References: <OF15A2364C.38B38E20-ONC1257FAF.00287156-C1257FAF.0028D3F1@lotus.hawesko.de>
	<CA+8X3fWKAJysbwP+whoDrSnT8W3njAUq5LwmjTp3qq-AOdanzg@mail.gmail.com>
	<OF680609C9.B98EF9B5-ONC1257FAF.003C5B6B-C1257FAF.003CF31F@lotus.hawesko.de>
	<CA+8X3fV=Cc8n0WBk6JjobbHm0E+R4ss+7is233o9HYVwGaiQ8Q@mail.gmail.com>
	<OFF8B5EC26.08CB1CFC-ONC1257FAF.00526FBA-C1257FAF.0052DAB9@lotus.hawesko.de>
Message-ID: <CAM_vjukn65HMyvUVWcNATyb660xPa-GYkxJV81_witEFxeFHhQ@mail.gmail.com>

Try closing the type of sink you're actually opening:


zz <- file("all.Rout", open = "wt")
sink(zz, type = "message")
try(log("a"))
sink(type = "message")
close(zz)
unlink(zz)


If you look carefully at the example in?sink, there are two close
statements, one for each stream being sent to that file.

Sarah

On Tue, May 10, 2016 at 11:05 AM,  <G.Maubach at weinwolf.de> wrote:
> Hi Jim,
>
> I tried:
>
> sink("all.Rout")
> try(log("a"))
> sink()
>
> The program executes without warning or error. The file "all.Rout" is
> begin created. Nothing will be written to it. The file is accessable
> rights after the execution of the program by notepad.exe.
>
> The program
>
> zz <- file("all.Rout", open = "wt")
> sink(zz, type = "message")
> try(log("a"))
> sink()
> close(zz)
> unlink(zz)
>
> creates the file, does not write anything to it and is not accessable
> after program execution in R with notepad.exe.
>
> Any ideas what happens behind the szenes?
>
> Kind regards
>
> Georg
>
>
>


From christopher.clarkson15 at imperial.ac.uk  Tue May 10 15:23:27 2016
From: christopher.clarkson15 at imperial.ac.uk (Clarkson, Christopher)
Date: Tue, 10 May 2016 13:23:27 +0000
Subject: [R] intermediate action button necessary to update graph-not
	responding
Message-ID: <VI1PR06MB1102AE0CEAFE4ADB58AEBC49B9710@VI1PR06MB1102.eurprd06.prod.outlook.com>

Hello,
I'm aware that this is not a suitable question for this resource but neither Stackoverflow nor shiny help forum could help with the problem I'm having- is it possible that you could point me in the right direction?
thanks
Chris

I have a command from a particular package that outputs a graph. The command requires preliminary processed input via a different command that is defined in the same package. Hence my plan is to create an app whereby the user can interactively update the map. This as far as I can see will require 2 action buttons: "actionbutton A" will re-run the preliminary processing command with input from a "checkboxGroupInput". "actionbutton B" will then update the graph with the new input from the preliminary processing command.

#ui.R
checkboxGroupInput("column_choices", "column choice", colnames(data), selected=c("column1", "column2"....)),
actionButton(inputId="choices", label="Update tag"))

actionButton(inputId="replot", label="Update plot")),
plotOutput("graph")

#server.R
servercell <- function(input, output) {
  dataInput<-observeEvent(input$choices, {
    isolate(tagData(IRIS[, input$column_choices]))
  })
  output$SPV<-renderPlot({
    input$replot
    isolate(package_defined_plot_function(data=data, dataTag=dataInput()))
    })
}

The buttons work when tested independent of each other: the checkbox input seems to update fine, after clicking "Update tag"/actionbutton A and the graph seems to work fine after clicking "Update plot"/actionbutton B (when dataInput() is not an argument in the plot function).

My problem is that dataInput<-observeEvent(input$choices, {..... does not allow the graph to display. When dataInput() is made an argument of the plotting function- instead of the graph displaying on the app page- in place of that I get the error: could not find dataInput function

As I said buttons A and B work fine when independent of each other..... however their coexistence conflicts... and having two action buttons is the only way I can think of to update the graph interactively... if anyone can think of how to do it with one button that would be great.

When I do this with one output command, :
output$SPV<-renderPlot({
dataInput<-
package_defined_plot_function(data=data, dataTag=tagData(runif(input$cell_choices(isolate())))
})
I try some variation(cannot remember the actual syntax) of the above but it forces me to shut down my R session as the data handling seems to go on an infinite loop (I can not show you the exact error for this as in order to get it I have to crash the R session- it looks some thing like: "cannot compute -Inf"). hence I would be much more comfortable with tow buttons.
I am quite stuck as I don't know what to do... any tips?

	[[alternative HTML version deleted]]


From shuklashweta33 at gmail.com  Tue May 10 12:10:23 2016
From: shuklashweta33 at gmail.com (shweta shukla)
Date: Tue, 10 May 2016 15:40:23 +0530
Subject: [R] Regarding to R
Message-ID: <CAHLtvOKfneoLddrPh35cZdCqN=yF6XsowFdkLJRyeV-41d_OyA@mail.gmail.com>

Dear,
I recently started R for my analysis but still not clear concept.
please guide me with some informative mterial to learn R.

Iam also confuse that which one I should prefer R or R studio and what
differences in between.




Thank you.

	[[alternative HTML version deleted]]


From lid.zigh at gmail.com  Tue May 10 18:30:22 2016
From: lid.zigh at gmail.com (Lida Zeighami)
Date: Tue, 10 May 2016 11:30:22 -0500
Subject: [R] find high correlated variables in a big matrix
In-Reply-To: <41931FF7-BD24-43E4-A436-F2FA73913FE2@comcast.net>
References: <CAMqbV1CD+Faty1PY3Z7N=NUpjSpRZ+BNQLw+CJVNsRzCL+Dpgg@mail.gmail.com>
	<CAMqbV1BVXKHt7B72UVO-HMQbqZyziogMx7JEih-TLyZ6jydC-Q@mail.gmail.com>
	<CAMqbV1B38tTDVXEkdKOgGjLf1TMyU0Cq1YaL=uLSfXM7WYkSbA@mail.gmail.com>
	<CAMqbV1Aoa4YxqffpmSG1rh3N4XwG-kTfqOanc=qiffw2+riFmw@mail.gmail.com>
	<CAMqbV1B40YOU84mSVBp=u8NEdtewkt1WBW2h8yLDYU+0MYQ8aw@mail.gmail.com>
	<CAMqbV1B7toZ5E7Vpd6sJMwh4CvWHncdnrPzK1D6k8FQFqmUXaA@mail.gmail.com>
	<CAMqbV1CrhBAksjxE-UC1fyz7yKxZyc9DiWVfvwbi=rSTCwCb-w@mail.gmail.com>
	<41931FF7-BD24-43E4-A436-F2FA73913FE2@comcast.net>
Message-ID: <CAMqbV1B4VQUAMrgyNk3pGqHgZkFsr2nsdBRJP0trGOFzY1Oqig@mail.gmail.com>

Thank you David for your reply,

But still couldn't get my answer.
I've already used the rcorr and created the correlation matrix and found
the high correlated variables but just among the two variables, it means I
could find the pairs of variables with high correlation.
So I couldn't get for example 100 variables that all of them are high
correlated together.

Dear Clint, I think you are right! It's better to tell that I'm  trying to
find clusters of variables according to some distance metric! would you
please let me know how I can solve it?

Thanks


On Fri, May 6, 2016 at 4:32 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On May 6, 2016, at 2:12 PM, Lida Zeighami <lid.zigh at gmail.com> wrote:
> >
> > Hi there,
> >
> > Is there any way to find out high correlated variables among a big
> matrix?
> > for example I have a matrix called data= 2000*5000 and I need to find the
> > high correlated variables between the variables in the columns! (Need 100
> > high correlated variables from 5000 variables in column)
> >
> > I could calculate the correlation matrix and pick the high correlated
> ones
> > but my problem is, I just can pick pairs of variables with high
> correlation
> > and may be we have low correlation across the pairs! Means, in my 100*100
> > correlation matrix, there are some pairs with low correlation and I
> > couldn't find the 100 variables which they all have high correlation
> > together!!!
> > Would you please ley me know if there is any way?
>
> The rcorr function in Hmisc will return a list whose first element is a
> correlation matrix
>
> > base <- rnorm(100)
>
> > test <- matrix(base+0.2*rnorm(300), 100)
>
> > rcorr(test)[[1]]
>           [,1]      [,2]      [,3]
> [1,] 1.0000000 0.9631220 0.9721688
> [2,] 0.9631220 1.0000000 0.9666564
> [3,] 0.9721688 0.9666564 1.0000000
>
> You can use which to to find the locations meeting a criterion (or two):
>
> > mycorr <- .Last.value
>
> > which(mycorr > 0.97 & mycorr != 1, arr.ind=TRUE)
>      row col
> [1,]   3   1
> [2,]   1   3
>
>
>
> --
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From G.Maubach at weinwolf.de  Tue May 10 18:34:26 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 10 May 2016 18:34:26 +0200
Subject: [R] Antwort: Re:  Antwort: Re: Re: sink(): Cannot open file
In-Reply-To: <CAM_vjukn65HMyvUVWcNATyb660xPa-GYkxJV81_witEFxeFHhQ@mail.gmail.com>
References: <OF15A2364C.38B38E20-ONC1257FAF.00287156-C1257FAF.0028D3F1@lotus.hawesko.de>
	<CA+8X3fWKAJysbwP+whoDrSnT8W3njAUq5LwmjTp3qq-AOdanzg@mail.gmail.com>	<OF680609C9.B98EF9B5-ONC1257FAF.003C5B6B-C1257FAF.003CF31F@lotus.hawesko.de>
	<CA+8X3fV=Cc8n0WBk6JjobbHm0E+R4ss+7is233o9HYVwGaiQ8Q@mail.gmail.com>	<OFF8B5EC26.08CB1CFC-ONC1257FAF.00526FBA-C1257FAF.0052DAB9@lotus.hawesko.de>
	<CAM_vjukn65HMyvUVWcNATyb660xPa-GYkxJV81_witEFxeFHhQ@mail.gmail.com>
Message-ID: <OFB1F950C2.FF819EF7-ONC1257FAF.005A9AE4-C1257FAF.005B0ACB@lotus.hawesko.de>

Hi Sarah, John, Jim,
Hi All,

I have set my envrionment variable 

path <- file.path("H:", "2016", "Analysis")
setwd(dir = path)

This works well cause the file is created in that directory.

I have tried

close(zz)
unlink(zz)

and neither worked nor did it work out using them together.

I had this before when working with IBM SPSS Statistics. There was a 
workaround for the problem in SPSS.

Is there one for R?

Kind regards

Georg





Von:    Sarah Goslee <sarah.goslee at gmail.com>
An:     G.Maubach at weinwolf.de, 
Kopie:  r-help mailing list <r-help at r-project.org>
Datum:  10.05.2016 17:17
Betreff:        Re: [R] Antwort: Re: Re: sink(): Cannot open file



Try closing the type of sink you're actually opening:


zz <- file("all.Rout", open = "wt")
sink(zz, type = "message")
try(log("a"))
sink(type = "message")
close(zz)
unlink(zz)


If you look carefully at the example in?sink, there are two close
statements, one for each stream being sent to that file.

Sarah

----- Weitergeleitet von Georg Maubach/WWBO/WW/HAW am 10.05.2016 18:29 
-----

Von:    "John Sorkin" <jsorkin at grecc.umaryland.edu>
An:     <drjimlemon at gmail.com>, <G.Maubach at weinwolf.de>, 
Kopie:  <r-help at r-project.org>
Datum:  10.05.2016 17:20
Betreff:        Re: [R] Antwort: Re: Re: sink(): Cannot open file



George,
I do not know what operating system you are working with, but when I use 
sink() under windows, I need to specify a valid path which I don't see in 
your code. I might, for example specify:

sink("c:\myfile.txt")
 R code goes here
sink()
with the expectation that I would create a file myfile.txt that would 
contain the output of my R program.
 
John


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and 
Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 



On Tue, May 10, 2016 at 11:05 AM,  <G.Maubach at weinwolf.de> wrote:
> Hi Jim,
>
> I tried:
>
> sink("all.Rout")
> try(log("a"))
> sink()
>
> The program executes without warning or error. The file "all.Rout" is
> begin created. Nothing will be written to it. The file is accessable
> rights after the execution of the program by notepad.exe.
>
> The program
>
> zz <- file("all.Rout", open = "wt")
> sink(zz, type = "message")
> try(log("a"))
> sink()
> close(zz)
> unlink(zz)
>
> creates the file, does not write anything to it and is not accessable
> after program execution in R with notepad.exe.
>
> Any ideas what happens behind the szenes?
>
> Kind regards
>
> Georg
>
>
>


From dcarlson at tamu.edu  Tue May 10 18:46:33 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 10 May 2016 16:46:33 +0000
Subject: [R] find high correlated variables in a big matrix
In-Reply-To: <CAMqbV1B4VQUAMrgyNk3pGqHgZkFsr2nsdBRJP0trGOFzY1Oqig@mail.gmail.com>
References: <CAMqbV1CD+Faty1PY3Z7N=NUpjSpRZ+BNQLw+CJVNsRzCL+Dpgg@mail.gmail.com>
	<CAMqbV1BVXKHt7B72UVO-HMQbqZyziogMx7JEih-TLyZ6jydC-Q@mail.gmail.com>
	<CAMqbV1B38tTDVXEkdKOgGjLf1TMyU0Cq1YaL=uLSfXM7WYkSbA@mail.gmail.com>
	<CAMqbV1Aoa4YxqffpmSG1rh3N4XwG-kTfqOanc=qiffw2+riFmw@mail.gmail.com>
	<CAMqbV1B40YOU84mSVBp=u8NEdtewkt1WBW2h8yLDYU+0MYQ8aw@mail.gmail.com>
	<CAMqbV1B7toZ5E7Vpd6sJMwh4CvWHncdnrPzK1D6k8FQFqmUXaA@mail.gmail.com>
	<CAMqbV1CrhBAksjxE-UC1fyz7yKxZyc9DiWVfvwbi=rSTCwCb-w@mail.gmail.com>
	<41931FF7-BD24-43E4-A436-F2FA73913FE2@comcast.net>
	<CAMqbV1B4VQUAMrgyNk3pGqHgZkFsr2nsdBRJP0trGOFzY1Oqig@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D731A16@mb02.ads.tamu.edu>

Look at varclus() in package Hmisc or package ClustOfVar.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Lida Zeighami
Sent: Tuesday, May 10, 2016 11:30 AM
To: David Winsemius; clint at ecy.wa.gov
Cc: r-help
Subject: Re: [R] find high correlated variables in a big matrix

Thank you David for your reply,

But still couldn't get my answer.
I've already used the rcorr and created the correlation matrix and found
the high correlated variables but just among the two variables, it means I
could find the pairs of variables with high correlation.
So I couldn't get for example 100 variables that all of them are high
correlated together.

Dear Clint, I think you are right! It's better to tell that I'm  trying to
find clusters of variables according to some distance metric! would you
please let me know how I can solve it?

Thanks


On Fri, May 6, 2016 at 4:32 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On May 6, 2016, at 2:12 PM, Lida Zeighami <lid.zigh at gmail.com> wrote:
> >
> > Hi there,
> >
> > Is there any way to find out high correlated variables among a big
> matrix?
> > for example I have a matrix called data= 2000*5000 and I need to find the
> > high correlated variables between the variables in the columns! (Need 100
> > high correlated variables from 5000 variables in column)
> >
> > I could calculate the correlation matrix and pick the high correlated
> ones
> > but my problem is, I just can pick pairs of variables with high
> correlation
> > and may be we have low correlation across the pairs! Means, in my 100*100
> > correlation matrix, there are some pairs with low correlation and I
> > couldn't find the 100 variables which they all have high correlation
> > together!!!
> > Would you please ley me know if there is any way?
>
> The rcorr function in Hmisc will return a list whose first element is a
> correlation matrix
>
> > base <- rnorm(100)
>
> > test <- matrix(base+0.2*rnorm(300), 100)
>
> > rcorr(test)[[1]]
>           [,1]      [,2]      [,3]
> [1,] 1.0000000 0.9631220 0.9721688
> [2,] 0.9631220 1.0000000 0.9666564
> [3,] 0.9721688 0.9666564 1.0000000
>
> You can use which to to find the locations meeting a criterion (or two):
>
> > mycorr <- .Last.value
>
> > which(mycorr > 0.97 & mycorr != 1, arr.ind=TRUE)
>      row col
> [1,]   3   1
> [2,]   1   3
>
>
>
> --
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Tue May 10 18:53:35 2016
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 10 May 2016 10:53:35 -0600
Subject: [R] Regarding to R
In-Reply-To: <CAHLtvOKfneoLddrPh35cZdCqN=yF6XsowFdkLJRyeV-41d_OyA@mail.gmail.com>
References: <CAHLtvOKfneoLddrPh35cZdCqN=yF6XsowFdkLJRyeV-41d_OyA@mail.gmail.com>
Message-ID: <CAFEqCdx4rUNK=FdyGZ5ucQ1T9OAyhrWpS74n2GBq+tTc7AuGwg@mail.gmail.com>

Please help us help you.  Tell us what you have tried and where you
have looked (otherwise we may just point you to things you already
know about).  Also what is your focus (simple analysis, learning,
programming, ...)?

The best place to start is with "An Introduction to R" which Installs
with R.  Then there are a lot of tutorials pointed to from the main R
website.


Comparing R and Rstudio is not an either/or question.  R is the
statistical package, Rstudio is an interface to R (Rstudio by itself
is not very useful, it passes the commands to R).

Think of R as being a car with only a few options, it can take you
anywhere and for many it is good enough.  Rstudio is a nice options
package (power steering, a GPS navigation system, etc.)  Things that
make driving the car easier and more enjoyable, but would not help
much without the car to add them to.

On Tue, May 10, 2016 at 4:10 AM, shweta shukla <shuklashweta33 at gmail.com> wrote:
> Dear,
> I recently started R for my analysis but still not clear concept.
> please guide me with some informative mterial to learn R.
>
> Iam also confuse that which one I should prefer R or R studio and what
> differences in between.
>
>
>
>
> Thank you.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From bbolker at gmail.com  Tue May 10 18:55:08 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 10 May 2016 16:55:08 +0000
Subject: [R] Regarding to R
References: <CAHLtvOKfneoLddrPh35cZdCqN=yF6XsowFdkLJRyeV-41d_OyA@mail.gmail.com>
Message-ID: <loom.20160510T185035-810@post.gmane.org>

shweta shukla <shuklashweta33 <at> gmail.com> writes:

> 
> Dear,
> I recently started R for my analysis but still not clear concept.
> please guide me with some informative mterial to learn R.
> 
> Iam also confuse that which one I should prefer R or R studio and what
> differences in between.
> 

R and RStudio are two different types of thing; it's not a question of
"which one to use".  RStudio is a front-end (interface) for R. You
probably *should* use RStudio (rather than the standard "R console"
interface that comes with R), it's well supported and has lots of
useful features.  Most of the time when you're asking questions,
though, they will be questions about R (unless they are specific
issues about the *interface*, they won't be RStudio-specific).

  It's hard to tell you where to start with "informative material".
What is most useful will depend on your background; your field/desired
type of analyses; language; personality; etc. etc..  There are literally
thousands of R tutorials and books, many available for free on the
internet.  I'd suggest you google "learning R programming", inspect
a dozen or so of the top hits, and see which ones seem to suit you
best.

  good luck,
    Ben Bolker


From dwinsemius at comcast.net  Tue May 10 19:02:41 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 10 May 2016 10:02:41 -0700
Subject: [R] Assistance with httr package with R version 3.3.0
In-Reply-To: <CAJ4QxaOPNvp76-T7WwnvBRYC2Hwnv+t0S1f8PC8wPHLKdcvKeg@mail.gmail.com>
References: <CABQyo84PYt+caZgxydaVMEgNm7S=G5HW9jMwSc41R+qtwqcxwQ@mail.gmail.com>
	<CA+8X3fXk0xnufi4xQzhp47zP_xckkyD-Bo5UA3eLw48iaumYpQ@mail.gmail.com>
	<CABQyo84VABvyXxw1fZtVKySxkYZ8cx-qSw9_K+1d-1x1FFVG2w@mail.gmail.com>
	<CAJ4QxaOPNvp76-T7WwnvBRYC2Hwnv+t0S1f8PC8wPHLKdcvKeg@mail.gmail.com>
Message-ID: <51B6C732-6DEA-4F9E-85D9-998CE536EF74@comcast.net>


> On May 10, 2016, at 2:08 AM, boB Rudis <bob at rudis.net> wrote:
> 
> I don't fully remember, but I doubt httr::content() ever returned a
> character vector without using the `as="text"` parameter. Try
> switching that line to:
> 
>    html <- content(r, as="text")
> 
> 
> 
> On Tue, May 10, 2016 at 3:27 AM, Luca Meyer <lucam1968 at gmail.com> wrote:
>> Hi Jim,
>> 
>> Thank you for your suggestion. I have actually tried to upload XML and xml2
>> but nothing changed...any other suggestion?
>> 
>> Kind regards,
>> 
>> Luca
>> 
>>> rm(list=ls())
>>> library(httr)
>>> library(XML)
>>> library(xml2)
>>> 
>>> #carico i dati da Google spreadsheets
>>> url <- "
>> https://docs.google.com/spreadsheets/d/102-jJ7x1YfIe4Kkvb9olQ4chQ_TS90jxoU0vAbFZewc/pubhtml?gid=0&single=true
>> "
>>> readSpreadsheet <- function(url, sheet = 1){
>> +   r <- GET(url)
>> +   html <- content(r)
>> +   sheets <- readHTMLTable(html, header=FALSE, stringsAsFactors=FALSE)
>> +   df <- sheets[[sheet]]
>> +   dfClean <- function(df){
>> +     nms <- t(df[1,])
>> +     names(df) <- nms
>> +     df <- df[-1,-1]
>> +     row.names(df) <- seq(1,nrow(df))
>> +     df
>> +   }
>> +   dfClean(df)
>> + }
>>> dati <- readSpreadsheet(url)
>> Error in (function (classes, fdef, mtable)  :
>>  unable to find an inherited method for function ?readHTMLTable? for
>> signature ?"xml_document"?
>>> rm(readSpreadsheet,url)
>> 
>> 2016-05-10 8:52 GMT+02:00 Jim Lemon <drjimlemon at gmail.com>:
>> 
>>> Hi Luca,
>>> The function readHTMLtable is in the XML package, not httr. Perhaps
>>> that is the problem as I don't see a dependency in httr for XML
>>> (although xml2 is suggested).
>>> 
>>> Jim
>>> 
>>> 
>>> On Tue, May 10, 2016 at 2:58 PM, Luca Meyer <lucam1968 at gmail.com> wrote:
>>>> Hello,
>>>> 
>>>> I am trying to run a code I have been using for a few years now after
>>>> downloading the new R version 3.3.0 and I get the following error:
>>>> 
>>>>> rm(list=ls())
>>>>> library(httr)
>>>>> 
>>>>> #carico i dati da Google spreadsheets
>>>>> url <- "
>>>> 
>>> https://docs.google.com/spreadsheets/d/102-jJ7x1YfIe4Kkvb9olQ4chQ_TS90jxoU0vAbFZewc/pubhtml?gid=0&single=true
>>>> "
>>>>> readSpreadsheet <- function(url, sheet = 1){
>>>> +   r <- GET(url)
>>>> +   html <- content(r)
>>>> +   sheets <- readHTMLTable(html, header=FALSE, stringsAsFactors=FALSE)
>>>> +   df <- sheets[[sheet]]
>>>> +   dfClean <- function(df){
>>>> +     nms <- t(df[1,])
>>>> +     names(df) <- nms
>>>> +     df <- df[-1,-1]
>>>> +     row.names(df) <- seq(1,nrow(df))
>>>> +     df
>>>> +   }
>>>> +   dfClean(df)
>>>> + }
>>>>> dati <- readSpreadsheet(url)
>>>> Error in (function (classes, fdef, mtable)  :
>>>>  unable to find an inherited method for function ?readHTMLTable? for
>>>> signature ?"xml_document"?
>>>>> rm(readSpreadsheet,url)
>>>> 
>>>> Can anyone suggest a solution to it?
>>>> 
>>>> Thanks,
>>>> 
>>>> Luca
>>>> 
>>>>        [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From murdoch.duncan at gmail.com  Tue May 10 19:04:26 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 10 May 2016 13:04:26 -0400
Subject: [R] Antwort: Re: Re: sink(): Cannot open file
In-Reply-To: <5731C2BC020000CB001536F4@smtp.medicine.umaryland.edu>
References: <OF15A2364C.38B38E20-ONC1257FAF.00287156-C1257FAF.0028D3F1@lotus.hawesko.de>
	<CA+8X3fWKAJysbwP+whoDrSnT8W3njAUq5LwmjTp3qq-AOdanzg@mail.gmail.com>
	<OF680609C9.B98EF9B5-ONC1257FAF.003C5B6B-C1257FAF.003CF31F@lotus.hawesko.de>
	<CA+8X3fV=Cc8n0WBk6JjobbHm0E+R4ss+7is233o9HYVwGaiQ8Q@mail.gmail.com>
	<OFF8B5EC26.08CB1CFC-ONC1257FAF.00526FBA-C1257FAF.0052DAB9@lotus.hawesko.de>
	<5731C2BC020000CB001536F4@smtp.medicine.umaryland.edu>
Message-ID: <5732149A.7080203@gmail.com>

On 10/05/2016 11:15 AM, John Sorkin wrote:
> George,
> I do not know what operating system you are working with, but when I use sink() under windows, I need to specify a valid path which I don't see in your code. I might, for example specify:
>
> sink("c:\myfile.txt")

Note that the backslash should be doubled (so it isn't interpreted as an 
escape for the "m" that follows it), or replaced with a forward slash.

Duncan Murdoch

>   R code goes here
> sink()
>
> with the expectation that I would create a file myfile.txt that would contain the output of my R program.
>   
> John
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> >>> <G.Maubach at weinwolf.de> 05/10/16 11:10 AM >>>
> Hi Jim,
>
> I tried:
>
> sink("all.Rout")
> try(log("a"))
> sink()
>
> The program executes without warning or error. The file "all.Rout" is
> begin created. Nothing will be written to it. The file is accessable
> rights after the execution of the program by notepad.exe.
>
> The program
>
> zz <- file("all.Rout", open = "wt")
> sink(zz, type = "message")
> try(log("a"))
> sink()
> close(zz)
> unlink(zz)
>
> creates the file, does not write anything to it and is not accessable
> after program execution in R with notepad.exe.
>
> Any ideas what happens behind the szenes?
>
> Kind regards
>
> Georg
>
>
>
>
> Von: Jim Lemon <drjimlemon at gmail.com>
> An: G.Maubach at weinwolf.de,
> Kopie: r-help mailing list <r-help at r-project.org>
> Datum: 10.05.2016 13:16
> Betreff: Re: Re: [R] sink(): Cannot open file
>
>
>
> Have you tried:
>
> sink("all.Rout")
> try(log("a"))
> sink()
>
> Jim
>
> On Tue, May 10, 2016 at 9:05 PM, <G.Maubach at weinwolf.de> wrote:
> > Hi Jim,
> >
> > thanks for your reply.
> >
> > ad 1)
> > "all.Rout" was created in the correct directory. It exists properly with
> > correct file properties on Windows, e.g. creation date and time and file
> > size information.
> >
> > ad 2)
> > I can not access the file with Notepad.exe directly after it was created
> > by R. The error message is (translated):
> >
> > "Cannot access file "all.Rout". The file is opened by another process."
> >
> > ad 3)
> > If I close R completely the file access is released. Then I can read the
> > file using Notepad.exe. The contents is:
> >
> > Error in log("a") : non-numeric argument to mathematical function
> >
> > I tried
> >
> > close(zz)
> >
> > but the error persists.
> >
> > To me it looks like R is still accessing the file and not releasing the
> > connection for other programs. close(zz) should have solved the problem
> > but unfortantely it doesn't.
> >
> > What else could I try?
> >
> > Kind regards
> >
> > Georg
> >
> >
> >
> >
> > Von: Jim Lemon <drjimlemon at gmail.com>
> > An: G.Maubach at weinwolf.de,
> > Kopie: r-help mailing list <r-help at r-project.org>
> > Datum: 10.05.2016 12:50
> > Betreff: Re: [R] sink(): Cannot open file
> >
> >
> >
> > Hi Georg,
> > I don't suppose that you have:
> >
> > 1) checked that the file "all.Rout" exists somewhere?
> >
> > 2) if so, looked at the file with Notepad, perhaps?
> >
> > 3) let us in on the secret by pasting the contents of "all.Rout" into
> > your message if it is not too big?
> >
> > At a guess, trying:
> >
> > close(zz)
> >
> > might get you there.
> >
> > Jim
> >
> > On Tue, May 10, 2016 at 5:25 PM, <G.Maubach at weinwolf.de> wrote:
> >> Hi All,
> >>
> >> I would like to route the output to a file using sink(). When using the
> >> example from the ?sink documentation:
> >>
> >> sink("sink-examp.txt")
> >> i <- 1:10
> >> outer(i, i, "*")
> >> sink()
> >> unlink("sink-examp.txt")
> >>
> >> ## capture all the output to a file.
> >> zz <- file("all.Rout", open = "wt")
> >> sink(zz)
> >> sink(zz, type = "message")
> >> try(log("a"))
> >> ## back to the console
> >> sink(type = "message")
> >> sink()
> >> file.show("all.Rout")
> >>
> >> I can not open the file in Windows Explorer. The error message is:
> >>
> >> "Cannot open file. File is in use be another proces."
> >>
> >> How can I close the file in a manner that I can open it right after it
> > was
> >> created?
> >>
> >> Kind regards
> >>
> >> Georg
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:7}}


From bbolker at gmail.com  Tue May 10 18:59:57 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 10 May 2016 16:59:57 +0000
Subject: [R] Coverage Probability
References: <VI1PR07MB132544F2B6DB27B3068C603294710@VI1PR07MB1325.eurprd07.prod.outlook.com>
Message-ID: <loom.20160510T185536-587@post.gmane.org>

Muhammad  Kashif <mkashif <at> uaf.edu.pk> writes:

> 
> Dears
> Can anyone help me to solve the issue.
> 
> By using" boot" and "boot.ci" package in R we can construct bootstrap
confidence intervals. How we
> calculate the coverage probability of these intervals.

  Calculating coverage probability for any but the simplest
cases requires simulations.  You need to simulate a particular
scenario; for each simulation, use your estimation and confidence-interval
calculation procedure; and then score the particular simulation
as 1 (estimated CI included the true parameter value) or 0
(true parameter value fell outside the estimated CI). Across
a large number of simulations, the proportion of ones is
an estimate of the coverage.

This is discussed more here:

http://ms.mcmaster.ca/~bolker/emdbook/chap5A.pdf


From dwinsemius at comcast.net  Tue May 10 19:07:02 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 10 May 2016 10:07:02 -0700
Subject: [R] Assistance with httr package with R version 3.3.0
In-Reply-To: <51B6C732-6DEA-4F9E-85D9-998CE536EF74@comcast.net>
References: <CABQyo84PYt+caZgxydaVMEgNm7S=G5HW9jMwSc41R+qtwqcxwQ@mail.gmail.com>
	<CA+8X3fXk0xnufi4xQzhp47zP_xckkyD-Bo5UA3eLw48iaumYpQ@mail.gmail.com>
	<CABQyo84VABvyXxw1fZtVKySxkYZ8cx-qSw9_K+1d-1x1FFVG2w@mail.gmail.com>
	<CAJ4QxaOPNvp76-T7WwnvBRYC2Hwnv+t0S1f8PC8wPHLKdcvKeg@mail.gmail.com>
	<51B6C732-6DEA-4F9E-85D9-998CE536EF74@comcast.net>
Message-ID: <9B4DD7DB-D759-495C-9792-51DCBE88CC97@comcast.net>


> On May 10, 2016, at 10:02 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On May 10, 2016, at 2:08 AM, boB Rudis <bob at rudis.net> wrote:
>> 
>> I don't fully remember, but I doubt httr::content() ever returned a
>> character vector without using the `as="text"` parameter. Try
>> switching that line to:
>> 
>>   html <- content(r, as="text")
>> 

Wrapping as.character around it also retrieves a version, although the first line was interpreted as a header and the the data was all character:

> str(dati)
'data.frame':	3 obs. of  6 variables:
 $ 91   : chr  "0,9" "" "34"
 $ 90,2 : chr  "16,7" "" "-96"
 $ 0,8  : chr  "9,018" "" "-66"
 $ 0,008: chr  "" "" "-128"
 $ 10,2 : chr  "" "" ""
 $ 4,896: chr  "" "" ""



>> 
>> 
>> On Tue, May 10, 2016 at 3:27 AM, Luca Meyer <lucam1968 at gmail.com> wrote:
>>> Hi Jim,
>>> 
>>> Thank you for your suggestion. I have actually tried to upload XML and xml2
>>> but nothing changed...any other suggestion?
>>> 
>>> Kind regards,
>>> 
>>> Luca
>>> 
>>>> rm(list=ls())
>>>> library(httr)
>>>> library(XML)
>>>> library(xml2)
>>>> 
>>>> #carico i dati da Google spreadsheets
>>>> url <- "
>>> https://docs.google.com/spreadsheets/d/102-jJ7x1YfIe4Kkvb9olQ4chQ_TS90jxoU0vAbFZewc/pubhtml?gid=0&single=true
>>> "
>>>> readSpreadsheet <- function(url, sheet = 1){
>>> +   r <- GET(url)
>>> +   html <- content(r)
>>> +   sheets <- readHTMLTable(html, header=FALSE, stringsAsFactors=FALSE)
>>> +   df <- sheets[[sheet]]
>>> +   dfClean <- function(df){
>>> +     nms <- t(df[1,])
>>> +     names(df) <- nms
>>> +     df <- df[-1,-1]
>>> +     row.names(df) <- seq(1,nrow(df))
>>> +     df
>>> +   }
>>> +   dfClean(df)
>>> + }
>>>> dati <- readSpreadsheet(url)
>>> Error in (function (classes, fdef, mtable)  :
>>> unable to find an inherited method for function ?readHTMLTable? for
>>> signature ?"xml_document"?
>>>> rm(readSpreadsheet,url)
>>> 
>>> 2016-05-10 8:52 GMT+02:00 Jim Lemon <drjimlemon at gmail.com>:
>>> 
>>>> Hi Luca,
>>>> The function readHTMLtable is in the XML package, not httr. Perhaps
>>>> that is the problem as I don't see a dependency in httr for XML
>>>> (although xml2 is suggested).
>>>> 
>>>> Jim
>>>> 
>>>> 
>>>> On Tue, May 10, 2016 at 2:58 PM, Luca Meyer <lucam1968 at gmail.com> wrote:
>>>>> Hello,
>>>>> 
>>>>> I am trying to run a code I have been using for a few years now after
>>>>> downloading the new R version 3.3.0 and I get the following error:
>>>>> 
>>>>>> rm(list=ls())
>>>>>> library(httr)
>>>>>> 
>>>>>> #carico i dati da Google spreadsheets
>>>>>> url <- "
>>>>> 
>>>> https://docs.google.com/spreadsheets/d/102-jJ7x1YfIe4Kkvb9olQ4chQ_TS90jxoU0vAbFZewc/pubhtml?gid=0&single=true
>>>>> "
>>>>>> readSpreadsheet <- function(url, sheet = 1){
>>>>> +   r <- GET(url)
>>>>> +   html <- content(r)
>>>>> +   sheets <- readHTMLTable(html, header=FALSE, stringsAsFactors=FALSE)
>>>>> +   df <- sheets[[sheet]]
>>>>> +   dfClean <- function(df){
>>>>> +     nms <- t(df[1,])
>>>>> +     names(df) <- nms
>>>>> +     df <- df[-1,-1]
>>>>> +     row.names(df) <- seq(1,nrow(df))
>>>>> +     df
>>>>> +   }
>>>>> +   dfClean(df)
>>>>> + }
>>>>>> dati <- readSpreadsheet(url)
>>>>> Error in (function (classes, fdef, mtable)  :
>>>>> unable to find an inherited method for function ?readHTMLTable? for
>>>>> signature ?"xml_document"?
>>>>>> rm(readSpreadsheet,url)
>>>>> 
>>>>> Can anyone suggest a solution to it?
>>>>> 
>>>>> Thanks,
>>>>> 
>>>>> Luca
>>>>> 
>>>>>       [[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>>       [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 

David Winsemius
Alameda, CA, USA


From jason.hernandez74 at yahoo.com  Tue May 10 19:14:52 2016
From: jason.hernandez74 at yahoo.com (Jason Hernandez)
Date: Tue, 10 May 2016 17:14:52 +0000 (UTC)
Subject: [R] Cannot Install Packages
References: <2107261304.1608099.1462900492113.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <2107261304.1608099.1462900492113.JavaMail.yahoo@mail.yahoo.com>

I have been trying to install the package "reshape2" using the code:
> install.packages("reshape2")
I get the following return:

Installing package into ?C:/Users/Jason/Documents/R/win-library/3.0?
(as ?lib? is unspecified)
Warning: unable to access index for repository http://cran.cs.wwu.edu/bin/windows/contrib/3.0
Warning message:
package ?reshape2? is not available (for R version 3.0.2)
When I went to the list of packages to look up reshape2, it said this package needs compilation. I did not see an indication of which R versions it is available for.
I went to the R for Windows FAQ, but it did not seem very helpful. The relevant sentences seemed to be:
"For packages with code that needscompilation you will need to collect and install several tools: you candownload them via the portal athttp://www.murdoch-sutherland.com/Rtools/. Once you have doneso, just run R CMD INSTALL pkgname at a Windows commandprompt."
I did the download, but I do not understand the meaning of the last sentence, since R does not recognize R CMD INSTALL as a valid code line, and the usual install.packages("reshape2") still returns the same error. What did I miss?
Jason Hernandez

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Tue May 10 19:27:46 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 10 May 2016 19:27:46 +0200
Subject: [R] Cannot Install Packages
In-Reply-To: <2107261304.1608099.1462900492113.JavaMail.yahoo@mail.yahoo.com>
References: <2107261304.1608099.1462900492113.JavaMail.yahoo.ref@mail.yahoo.com>
	<2107261304.1608099.1462900492113.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <da660a94-6003-09f4-bd8d-c8db760f192f@statistik.tu-dortmund.de>



On 10.05.2016 19:14, Jason Hernandez via R-help wrote:
> I have been trying to install the package "reshape2" using the code:
>> install.packages("reshape2")
> I get the following return:
>
> Installing package into ?C:/Users/Jason/Documents/R/win-library/3.0?
> (as ?lib? is unspecified)
> Warning: unable to access index for repository http://cran.cs.wwu.edu/bin/windows/contrib/3.0

The mirror does not exist, perhaps choose another one?


Best,
Uwe Ligges


> Warning message:
> package ?reshape2? is not available (for R version 3.0.2)
> When I went to the list of packages to look up reshape2, it said this package needs compilation. I did not see an indication of which R versions it is available for.
> I went to the R for Windows FAQ, but it did not seem very helpful. The relevant sentences seemed to be:
> "For packages with code that needscompilation you will need to collect and install several tools: you candownload them via the portal athttp://www.murdoch-sutherland.com/Rtools/. Once you have doneso, just run R CMD INSTALL pkgname at a Windows commandprompt."
> I did the download, but I do not understand the meaning of the last sentence, since R does not recognize R CMD INSTALL as a valid code line, and the usual install.packages("reshape2") still returns the same error. What did I miss?
> Jason Hernandez
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From sethshashi at rediffmail.com  Tue May 10 18:24:36 2016
From: sethshashi at rediffmail.com (SHASHI SETH)
Date: 10 May 2016 16:24:36 -0000
Subject: [R] =?utf-8?q?very_long_processing_time?=
Message-ID: <20160510162436.341.qmail@f5mail-224-118.rediffmail.com>

Hi,



 I have implemented following program in R, that reads data from the "dtm_mydata.csv". file size is 

114,029 kB, saved document Term matrix. Prog. performing some calculation and writing in a file. my 

computer RAM is 16 GB. To execute this program its taking around 25 hours. can any body help me what is 

wrong, why this much time is taken. Although it is doing the job what is required

                fitness_1_data 
	[[alternative HTML version deleted]]


From mike at hsm.org.uk  Tue May 10 19:40:47 2016
From: mike at hsm.org.uk (Mike Smith)
Date: Tue, 10 May 2016 18:40:47 +0100
Subject: [R] Left align plot_grid titles?
Message-ID: <1079482433.20160510184047@hsm.org.uk>

Is there any way to left align titles automatically in plot_grid?? Currently using this code which centre aligns the whole plot title

thanks!

library(ggplot2)
library(cowplot)

data <- read.csv("http://www.lecturematerials.co.uk/data/times_tables.csv",header=T)

gg1<-ggplot(data,aes(x=multiplier,y=factor)) +
  geom_point(aes(colour=incorrect), size=8, shape=15) +
  scale_colour_distiller(palette = "Spectral", direction=-1, guide="colourbar", name="Incorrect (%)") +
  scale_x_continuous(name="Multiplier", limits=c(1, 12), breaks=seq(2,12,by=2)) +
  scale_y_continuous(name="Factor", limits=c(1, 12), breaks=seq(2,12,by=2)) +
  geom_abline(intercept = 0, slope = 1, size=1) +
  coord_fixed()

gg2<-ggplot(data,aes(x=multiplier,y=factor)) +
  geom_point(aes(colour=incorrect), size=8, shape=15) +
  scale_colour_distiller(palette = "Spectral", direction=-1, guide="colourbar", name="Incorrect (%)") +
  scale_x_continuous(name="Multiplier", limits=c(1, 12), breaks=seq(2,12,by=2)) +
  scale_y_continuous(name="Factor", limits=c(1, 12), breaks=seq(2,12,by=2)) +
  geom_abline(intercept = 0, slope = 1, size=1) +
  coord_fixed()

p<-plot_grid(gg1,gg2,labels=c("A", "B"), nrow = 2)
title <- ggdraw() + draw_label("A Title", fontface='bold')
plot_grid(title, p, ncol=1, rel_heights=c(0.1, 1), align=c("h")) # rel_heights values control title margins

---
Mike Smith


From bgunter.4567 at gmail.com  Tue May 10 20:17:03 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 10 May 2016 11:17:03 -0700
Subject: [R] Ensure parameter is a string when passed within an lapply &
 called function runs a 'substitute' on it
In-Reply-To: <57310388.e873c20a.284cd.062d@mx.google.com>
References: <57310388.e873c20a.284cd.062d@mx.google.com>
Message-ID: <CAGxFJbTQsh9Jt-1a05oJAQn6Za6oPqC3cGmhp_cMVFiGMFzmXw@mail.gmail.com>

Well, here's a very bad way of doing this:

vars <- names(dataSet)

lapply(vars, function(var) {
  assign("y",var,pos=parent.frame(2))
  testFunc(x = model, pred.data = dataSet,
x.var=eval(y,parent.frame(2)), plot = F)
} )

## results in

[1] "X1"
[1] "X2"
[1] "X3"
[1] "X4"
[1] "X5"
[1] "X6"
[[1]]
[1] "X1"

[[2]]
[1] "X2"

[[3]]
[1] "X3"

[[4]]
[1] "X4"

[[5]]
[1] "X5"

[[6]]
[1] "X6"


Assigning to the calling environment is a bad idea, but I have not
figured out a better way to go about this.


Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, May 9, 2016 at 2:39 PM, Andrew Clancy <nite at achren.org> wrote:
> Hi,
>
> I?m trying to solve what looks like the same issue as stack overflow article, but within an lapply:
> http://stackoverflow.com/questions/18939254/cant-use-a-variable-as-an-argument-but-can-use-its-value
>
> I?ve replicated the issue with partialPlot below in ?testFunc?. The lines up to the final print can?t change (including the substitute). In the first call it prints out ?X1? correctly, in the second it prints out ?var?. I?ve tried eval, quote etc as the article suggests. Any ideas?
>
> numObs  <- 10
> numVars <- 6
> dataSet    <- data.frame(replicate(numVars,rnorm(numObs)))
> # partialPlot(x = model, pred.data = dataSet, x.var = 'X1', plot = F)
>
> testFunc <- function(x, pred.data, x.var, plot=F) {
>   x.var <- substitute(x.var)
>   # print(paste('is.character(x.var)', is.character(x.var), 'is.name(x.var)', is.name(x.var)))
>   xname <- if (is.character(x.var)) x.var else {
>     if (is.name(x.var)) deparse(x.var) else {
>       eval(x.var)
>     }
>   }
>   print(xname)
>   # print(head(pred.data[,xname]))
> }
>
> vars <- names(dataSet)[[1]]
> testFunc(x = model, pred.data = dataSet, x.var = local(vars), plot = F)
>
> lapply(vars, function(var) {
>   # print(paste('var', var))
>   testFunc(x = model, pred.data = dataSet, x.var = var, plot = F)
> })
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From friendly at yorku.ca  Tue May 10 20:45:28 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Tue, 10 May 2016 14:45:28 -0400
Subject: [R] web scraping tables generated in multiple server pages
Message-ID: <ff65b860-65aa-35b0-546b-646380e7ec37@yorku.ca>

This is my first attempt to try R web scraping tools, for a project my 
daughter is working on.  It concerns a data base of projects in Sao 
Paulo, Brazil, listed at 
http://outorgaonerosa.prefeitura.sp.gov.br/relatorios/RelSituacaoGeralProcessos.aspx, 
but spread out over 69 pages accessed through a javascript menu at the 
bottom of the page.

Each web page contains 3 HTML tables, of which only the last contains 
the relevant data.  In this, only a subset of columns are of interest.  
I tried using the XML package as illustrated on several tutorial pages, 
as shown below.  I have no idea how to automate this to extract these 
tables from multiple web pages.  Is there some other package better 
suited to this task?  Can someone help me solve this and other issues?

# Goal: read the data tables contained on 69 pages generated by the link 
below, where
# each page is generated by a javascript link in the menu of the bottom 
of the page.
#
# Each "page" contains 3 html tables, with names "Table 1", "Table 2", 
and the only one
# of interest with the data, "grdRelSitGeralProcessos"
#
# From each such table, extract the following columns:
#- Processo
#- Endere?o
#- Distrito
#- Area terreno (m2)
#- Valor contrapartida ($)
#- Area excedente (m2)

# NB: All of the numeric fields use "." as comma-separator and "," as 
the decimal separator,
#   but because of this are read in as character


library(XML)
link <- 
"http://outorgaonerosa.prefeitura.sp.gov.br/relatorios/RelSituacaoGeralProcessos.aspx"

saopaulo <- htmlParse(link)
saopaulo.tables <- readHTMLTable(saopaulo, stringsAsFactors = FALSE)
length(saopaulo.tables)

# its the third table on this page we want
sp.tab <- saopaulo.tables[[3]]

# columns wanted
wanted <- c(1, 2, 5, 7, 8, 13, 14)
head(sp.tab[, wanted])

 > head(sp.tab[, wanted])
   Proposta Processo Endere??o        Distrito
1        1 2002-0.148.242-4 R. DOMINGOS LOPES DA SILVA X R. CORN??LIO 
VAN CLEVE    VILA ANDRADE
2        2 2003-0.129.667-3                      AV. DR. JOS?? HIGINO, 
200 E 216       AGUA RASA
3        3 2003-0.065.011-2                       R. ALIAN??A LIBERAL, 
980 E 990 VILA LEOPOLDINA
4        4 2003-0.165.806-0                       R. ALIAN??A LIBERAL, 
880 E 886 VILA LEOPOLDINA
5        5 2003-0.139.053-0                R. DR. JOS?? DE ANDRADE 
FIGUEIRA, 111    VILA ANDRADE
6        6 2003-0.200.692-0                                R. JOS?? DE 
JESUS, 66      VILA SONIA
   ??rea Terreno (m2) ??rea Excedente (m2) Valor Contrapartida (R$)
1               0,00             1.551,14 127.875,98
2               0,00             3.552,13 267.075,77
3               0,00               624,99 70.212,93
4               0,00               395,64 44.447,18
5               0,00               719,68 41.764,46
6               0,00               446,52 85.152,92

thanks,


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue May 10 21:55:54 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 10 May 2016 12:55:54 -0700
Subject: [R] Ensure parameter is a string when passed within an lapply &
 called function runs a 'substitute' on it
In-Reply-To: <CAGxFJbTQsh9Jt-1a05oJAQn6Za6oPqC3cGmhp_cMVFiGMFzmXw@mail.gmail.com>
References: <57310388.e873c20a.284cd.062d@mx.google.com>
	<CAGxFJbTQsh9Jt-1a05oJAQn6Za6oPqC3cGmhp_cMVFiGMFzmXw@mail.gmail.com>
Message-ID: <CAGxFJbS=y=g5ob+F-b4513ufj2c7xAdRTVX_QufGdox7M7OpUQ@mail.gmail.com>

Andrew:

Actually, thinking about it a bit more, I think my "solution" is not
really a solution either; that is, it will fail in use. My
understanding, which may be wrong and which others may correct, is
this: in the lapply call, x.var = ... will result in substitute(...)
in testFunc yielding an unevaluated call with my eval() "solution".
The problem is: when this call gets evaluated in testFunc() **where**
does it get evaluated? The answer is: in the testFunc environment
(lexical scoping); if not found there in the parent of testFunc, which
is the environment in which testFunc **was defined**, not called, and
so on up through the tree of frames. My solution works only because I
stuck "var" in the global environment, which happened to be where
testFunc was defined. This will not be true in general, and almost
certainly will fail for your actual use case.

I see no clean solution for this issue -- it's the nature of lexical
scoping. A simple way to make it work is just to stick var in the
.GlobalEnv or baseenv(), depending on where the function with
substitute comes from (but probably the latter). Then var will be
found by lexical scoping. e.g., for your example:

vars <- names(dataSet)

lapply(vars, function(var) {
  # print(paste('var', var))
  assign("somename",var,globalenv())
  testFunc(x = model, pred.data = dataSet, x.var =
eval(somename,globalenv()), plot = F)
})

I would hope someone else may offer a better approach.


Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, May 10, 2016 at 11:17 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Well, here's a very bad way of doing this:
>
> vars <- names(dataSet)
>
> lapply(vars, function(var) {
>   assign("y",var,pos=parent.frame(2))
>   testFunc(x = model, pred.data = dataSet,
> x.var=eval(y,parent.frame(2)), plot = F)
> } )
>
> ## results in
>
> [1] "X1"
> [1] "X2"
> [1] "X3"
> [1] "X4"
> [1] "X5"
> [1] "X6"
> [[1]]
> [1] "X1"
>
> [[2]]
> [1] "X2"
>
> [[3]]
> [1] "X3"
>
> [[4]]
> [1] "X4"
>
> [[5]]
> [1] "X5"
>
> [[6]]
> [1] "X6"
>
>
> Assigning to the calling environment is a bad idea, but I have not
> figured out a better way to go about this.
>
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, May 9, 2016 at 2:39 PM, Andrew Clancy <nite at achren.org> wrote:
>> Hi,
>>
>> I?m trying to solve what looks like the same issue as stack overflow article, but within an lapply:
>> http://stackoverflow.com/questions/18939254/cant-use-a-variable-as-an-argument-but-can-use-its-value
>>
>> I?ve replicated the issue with partialPlot below in ?testFunc?. The lines up to the final print can?t change (including the substitute). In the first call it prints out ?X1? correctly, in the second it prints out ?var?. I?ve tried eval, quote etc as the article suggests. Any ideas?
>>
>> numObs  <- 10
>> numVars <- 6
>> dataSet    <- data.frame(replicate(numVars,rnorm(numObs)))
>> # partialPlot(x = model, pred.data = dataSet, x.var = 'X1', plot = F)
>>
>> testFunc <- function(x, pred.data, x.var, plot=F) {
>>   x.var <- substitute(x.var)
>>   # print(paste('is.character(x.var)', is.character(x.var), 'is.name(x.var)', is.name(x.var)))
>>   xname <- if (is.character(x.var)) x.var else {
>>     if (is.name(x.var)) deparse(x.var) else {
>>       eval(x.var)
>>     }
>>   }
>>   print(xname)
>>   # print(head(pred.data[,xname]))
>> }
>>
>> vars <- names(dataSet)[[1]]
>> testFunc(x = model, pred.data = dataSet, x.var = local(vars), plot = F)
>>
>> lapply(vars, function(var) {
>>   # print(paste('var', var))
>>   testFunc(x = model, pred.data = dataSet, x.var = var, plot = F)
>> })
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From pascal.niklaus at ieu.uzh.ch  Tue May 10 20:37:51 2016
From: pascal.niklaus at ieu.uzh.ch (Pascal A. Niklaus)
Date: Tue, 10 May 2016 20:37:51 +0200
Subject: [R] error in lmerTest after updating to R 3.3.0
Message-ID: <57322A7F.1000609@ieu.uzh.ch>

Dear all,

After updating to R 3.3.0 (inadvertently, via apt-get), I get an error 
when using lmerTest. Here is an example:

library(lmerTest)
library(MASS)
data(oats)
m <- lmer(Y ~ N*V + (1|B/V), data=oats)
summary(m)

summary from lme4 is returned
some computational error has occurred in lmerTest

I have removed all old libraries and tried to have as clean an 
installation as possible, but this did not fix the problem.

Is this an incompatibility or a problem with my installation?

Thanks for your help

Pascal


From marco.prado.bs at gmail.com  Tue May 10 22:08:56 2016
From: marco.prado.bs at gmail.com (Marco Silva)
Date: Tue, 10 May 2016 17:08:56 -0300
Subject: [R] web scraping tables generated in multiple server pages
In-Reply-To: <ff65b860-65aa-35b0-546b-646380e7ec37@yorku.ca>
References: <ff65b860-65aa-35b0-546b-646380e7ec37@yorku.ca>
Message-ID: <1462910218-sup-8869@ubatuba>

Excerpts from Michael Friendly's message of 2016-05-10 14:45:28 -0400:
> This is my first attempt to try R web scraping tools, for a project my 
> daughter is working on.  It concerns a data base of projects in Sao 
> Paulo, Brazil, listed at 
> http://outorgaonerosa.prefeitura.sp.gov.br/relatorios/RelSituacaoGeralProcessos.aspx, 
> but spread out over 69 pages accessed through a javascript menu at the 
> bottom of the page.
> 
> Each web page contains 3 HTML tables, of which only the last contains 
> the relevant data.  In this, only a subset of columns are of interest.  
> I tried using the XML package as illustrated on several tutorial pages, 
> as shown below.  I have no idea how to automate this to extract these 
> tables from multiple web pages.  Is there some other package better 
> suited to this task?  Can someone help me solve this and other issues?
> 
> # Goal: read the data tables contained on 69 pages generated by the link 
> below, where
> # each page is generated by a javascript link in the menu of the bottom 
> of the page.
> #
> # Each "page" contains 3 html tables, with names "Table 1", "Table 2", 
> and the only one
> # of interest with the data, "grdRelSitGeralProcessos"
> #
> # From each such table, extract the following columns:
> #- Processo
> #- Endere?o
> #- Distrito
> #- Area terreno (m2)
> #- Valor contrapartida ($)
> #- Area excedente (m2)
> 
> # NB: All of the numeric fields use "." as comma-separator and "," as 
> the decimal separator,
> #   but because of this are read in as character
> 
> 
> library(XML)
> link <- 
> "http://outorgaonerosa.prefeitura.sp.gov.br/relatorios/RelSituacaoGeralProcessos.aspx"
> 
> saopaulo <- htmlParse(link)
> saopaulo.tables <- readHTMLTable(saopaulo, stringsAsFactors = FALSE)
> length(saopaulo.tables)
> 
> # its the third table on this page we want
> sp.tab <- saopaulo.tables[[3]]
> 
> # columns wanted
> wanted <- c(1, 2, 5, 7, 8, 13, 14)
> head(sp.tab[, wanted])
> 
>  > head(sp.tab[, wanted])
>    Proposta Processo Endere??o        Distrito
> 1        1 2002-0.148.242-4 R. DOMINGOS LOPES DA SILVA X R. CORN??LIO 
> VAN CLEVE    VILA ANDRADE
> 2        2 2003-0.129.667-3                      AV. DR. JOS?? HIGINO, 
> 200 E 216       AGUA RASA
> 3        3 2003-0.065.011-2                       R. ALIAN??A LIBERAL, 
> 980 E 990 VILA LEOPOLDINA
> 4        4 2003-0.165.806-0                       R. ALIAN??A LIBERAL, 
> 880 E 886 VILA LEOPOLDINA
> 5        5 2003-0.139.053-0                R. DR. JOS?? DE ANDRADE 
> FIGUEIRA, 111    VILA ANDRADE
> 6        6 2003-0.200.692-0                                R. JOS?? DE 
> JESUS, 66      VILA SONIA
>    ??rea Terreno (m2) ??rea Excedente (m2) Valor Contrapartida (R$)
> 1               0,00             1.551,14 127.875,98
> 2               0,00             3.552,13 267.075,77
> 3               0,00               624,99 70.212,93
> 4               0,00               395,64 44.447,18
> 5               0,00               719,68 41.764,46
> 6               0,00               446,52 85.152,92
> 
> thanks,
> 
> 
> -- 
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
> 
> 
# what is missing to you
?gsub
# aliasing
df <- sp.tab[, wanted]

# convert to double
as.double(                                      # convert to double
    gsub(',', '.',                              # makes the ',' to become '.'
    gsub('\\.', '', df$"?rea Excedente (m2)"))  # get rid of the dot

You can easily put the names of the columns and use lapply on them to
convert all of them in same manner, that is left as an exercise.


-- 
Marco Arthur @ (M)arco Creatives


From bob at rudis.net  Tue May 10 22:11:07 2016
From: bob at rudis.net (boB Rudis)
Date: Tue, 10 May 2016 16:11:07 -0400
Subject: [R] web scraping tables generated in multiple server pages
In-Reply-To: <ff65b860-65aa-35b0-546b-646380e7ec37@yorku.ca>
References: <ff65b860-65aa-35b0-546b-646380e7ec37@yorku.ca>
Message-ID: <CAJ4QxaPmGG3mOMV-27JCK+BR_c9GUZu8fnZmN_XRp6=FnYgYOg@mail.gmail.com>

Unfortunately, it's a wretched, vile, SharePoint-based site. That
means it doesn't use traditional encoding methods to do the pagination
and one of the only ways to do this effectively is going to be to use
RSelenium:

    library(RSelenium)
    library(rvest)
    library(dplyr)
    library(pbapply)

    URL <- "http://outorgaonerosa.prefeitura.sp.gov.br/relatorios/RelSituacaoGeralProcessos.aspx"

    checkForServer()
    startServer()
    remDr <- remoteDriver$new()
    remDr$open()

    remDr$navigate(URL)

    pblapply(1:69, function(i) {

      if (i %in% seq(1, 69, 10)) {

        # the first item on the page is not a link but we can just grab the page

        pg <- read_html(remDr$getPageSource()[[1]])
        ret <- html_table(html_nodes(pg, "table")[[3]], header=TRUE)

      } else {

        # we can get the rest of them by the link text directly

        ref <- remDr$findElements("xpath",
sprintf(".//a[contains(@href, 'javascript:__doPostBack') and .='%s']",
i))
        ref[[1]]$clickElement()
        pg <- read_html(remDr$getPageSource()[[1]])
        ret <- html_table(html_nodes(pg, "table")[[3]], header=TRUE)

      }

      # we have to move to the next actual page of data after every 10 links

      if ((i %% 10) == 0) {
        ref <- remDr$findElements("xpath", ".//a[.='...']")
        ref[[length(ref)]]$clickElement()
      }

      ret

    }) -> tabs

    final_dat <- bind_rows(tabs)
    final_dat <- final_dat[, c(1, 2, 5, 7, 8, 13, 14)] # the cols you want
    final_dat <- final_dat[complete.cases(final_dat),] # take care of NAs

    remDr$quit()


Prbly good ref code to have around, but you can grab the data & code
here: https://gist.github.com/hrbrmstr/ec35ebb32c3cf0aba95f7bad28df1e98

(anything to help a fellow parent out :-)

-Bob

On Tue, May 10, 2016 at 2:45 PM, Michael Friendly <friendly at yorku.ca> wrote:
> This is my first attempt to try R web scraping tools, for a project my
> daughter is working on.  It concerns a data base of projects in Sao
> Paulo, Brazil, listed at
> http://outorgaonerosa.prefeitura.sp.gov.br/relatorios/RelSituacaoGeralProcessos.aspx,
> but spread out over 69 pages accessed through a javascript menu at the
> bottom of the page.
>
> Each web page contains 3 HTML tables, of which only the last contains
> the relevant data.  In this, only a subset of columns are of interest.
> I tried using the XML package as illustrated on several tutorial pages,
> as shown below.  I have no idea how to automate this to extract these
> tables from multiple web pages.  Is there some other package better
> suited to this task?  Can someone help me solve this and other issues?
>
> # Goal: read the data tables contained on 69 pages generated by the link
> below, where
> # each page is generated by a javascript link in the menu of the bottom
> of the page.
> #
> # Each "page" contains 3 html tables, with names "Table 1", "Table 2",
> and the only one
> # of interest with the data, "grdRelSitGeralProcessos"
> #
> # From each such table, extract the following columns:
> #- Processo
> #- Endere?o
> #- Distrito
> #- Area terreno (m2)
> #- Valor contrapartida ($)
> #- Area excedente (m2)
>
> # NB: All of the numeric fields use "." as comma-separator and "," as
> the decimal separator,
> #   but because of this are read in as character
>
>
> library(XML)
> link <-
> "http://outorgaonerosa.prefeitura.sp.gov.br/relatorios/RelSituacaoGeralProcessos.aspx"
>
> saopaulo <- htmlParse(link)
> saopaulo.tables <- readHTMLTable(saopaulo, stringsAsFactors = FALSE)
> length(saopaulo.tables)
>
> # its the third table on this page we want
> sp.tab <- saopaulo.tables[[3]]
>
> # columns wanted
> wanted <- c(1, 2, 5, 7, 8, 13, 14)
> head(sp.tab[, wanted])
>
>  > head(sp.tab[, wanted])
>    Proposta Processo Endere??o        Distrito
> 1        1 2002-0.148.242-4 R. DOMINGOS LOPES DA SILVA X R. CORN??LIO
> VAN CLEVE    VILA ANDRADE
> 2        2 2003-0.129.667-3                      AV. DR. JOS?? HIGINO,
> 200 E 216       AGUA RASA
> 3        3 2003-0.065.011-2                       R. ALIAN??A LIBERAL,
> 980 E 990 VILA LEOPOLDINA
> 4        4 2003-0.165.806-0                       R. ALIAN??A LIBERAL,
> 880 E 886 VILA LEOPOLDINA
> 5        5 2003-0.139.053-0                R. DR. JOS?? DE ANDRADE
> FIGUEIRA, 111    VILA ANDRADE
> 6        6 2003-0.200.692-0                                R. JOS?? DE
> JESUS, 66      VILA SONIA
>    ? rea Terreno (m2) ? rea Excedente (m2) Valor Contrapartida (R$)
> 1               0,00             1.551,14 127.875,98
> 2               0,00             3.552,13 267.075,77
> 3               0,00               624,99 70.212,93
> 4               0,00               395,64 44.447,18
> 5               0,00               719,68 41.764,46
> 6               0,00               446,52 85.152,92
>
> thanks,
>
>
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From abichteler at toxstrategies.com  Tue May 10 22:33:17 2016
From: abichteler at toxstrategies.com (Anne Bichteler)
Date: Tue, 10 May 2016 20:33:17 +0000
Subject: [R] Quantiles on multiply imputed survey data - mitools
Message-ID: <F29237C5-CDD2-4215-B516-B37D066D0678@toxstrategies.com>

Hello, and thank you for considering this question:

The svystat object created with multiply imputed NHANES data files is failing on calling survey::svyquantile. I'm wondering if I'm diagnosing the issue correctly, whether the behavior is expected, and whether y'all might have any ideas for workarounds.

I'm following T. Lumley's general method outlined here: http://faculty.washington.edu/tlumley/old-survey/svymi.html, but with data files I've imputed myself on the 2001/2002 biennial. Each file has 1081 observations and no missing values.

### Create the survey design object with list of imputed data files ImputedList0102.
des <- svydesign(id=~SDMVPSU, strat=~SDMVSTRA, weight=~WTSPO2YR, data=imputationList(ImputedList0102), nest=TRUE)


### Blood analyte of interest
var_name <- "LBXTCD" # analyte in blood serum

### All is well calculating the mean:
M <- with(des, svymean(make.formula(get('var_name'))))
summary(M)
Result <- MIcombine(M)
Result$coefficients
# LBXTCD 
# 17.41635


### but svystat object fails to calculate a 50th percentile:
### it fails when hard-coding the name rather than using make.formula;
### it fails regardless of number of files or choices in handling ties or interval type.
### There are 16 ties in each data file.
M1 <- with(des, svyquantile(make.formula(get('var_name')), quantiles = c(.5)))
summary(M1)

#     Length Class  Mode   
#[1,] 1      -none- numeric
#[2,] 1      -none- numeric
#[3,] 1      -none- numeric


### The quantile is successfully calculated on one file at a time, however, and is different for each file.
### (had thought perhaps there was a lack-of-variance issue). The quantile calculated on each file
### is the same regardless of interval.type.
des_single1 <- svydesign(id=~SDMVPSU, strat=~SDMVSTRA, weight=~WTSPO2YR, data=ImputedList0102[[1]], nest=TRUE)
svyquantile(make.formula(get('var_name')), des_single1, c(.5))
# 0.5
# LBXTCD 13.5554


des_single2 <- svydesign(id=~SDMVPSU, strat=~SDMVSTRA, weight=~WTSPO2YR, data=ImputedList0102[[2]], nest=TRUE)
svyquantile(make.formula(get('var_name')), des_single2, c(.5))
# 0.5
# LBXTCD 14.06154

# The number of observations exceeding the 50th percentile differs for each file, which I can't claim to understand.

# I removed the 16 ties, but no help. Do the ties and/or different number of observations above/below prevent the svydesigns from being combined?
nrow(subset(ImputedList0102[[1]], LBXTCD > 13.5554))
# [1] 516
nrow(subset(ImputedList0102[[2]], LBXTCD > 14.06154))
# [1] 512


I'm hoping someone can point me to some gross error I'm making or another function parameter or data manipulation or another survey-savvy method altogether to calculate a 50th percentile across multiply imputed data files. Thanks for any advice,

Brennan

www.toxstrategies.com

From drjimlemon at gmail.com  Wed May 11 00:21:20 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 11 May 2016 08:21:20 +1000
Subject: [R] very long processing time
In-Reply-To: <20160510162436.341.qmail@f5mail-224-118.rediffmail.com>
References: <20160510162436.341.qmail@f5mail-224-118.rediffmail.com>
Message-ID: <CA+8X3fX7UHG4NjOh_6moJhSCxp99Ht6iuLtRjWF1__0M6dZfeQ@mail.gmail.com>

Hi Shashi,
The assumption that anyone on the list apart from yourself knows what
"some calculation" involves is incorrect. I suspect that "what is
wrong" may be one of two things:

1) "some calculation" includes a very large number of operations,
perhaps leading to "disk-thrashing" when your 16GB of memory is full
of intermediate values. There is no software problem, buy more
hardware.

2) "some calculation" is a very inefficient method of getting the
result you want. If this method is revealed to us, we may be able to
help you.

Jim


On Wed, May 11, 2016 at 2:24 AM, SHASHI SETH <sethshashi at rediffmail.com> wrote:
> Hi,
>
>
>
>  I have implemented following program in R, that reads data from the "dtm_mydata.csv". file size is
>
> 114,029 kB, saved document Term matrix. Prog. performing some calculation and writing in a file. my
>
> computer RAM is 16 GB. To execute this program its taking around 25 hours. can any body help me what is
>
> wrong, why this much time is taken. Although it is doing the job what is required
>
>                 fitness_1_data
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bbolker at gmail.com  Wed May 11 01:37:43 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 10 May 2016 23:37:43 +0000
Subject: [R] error in lmerTest after updating to R 3.3.0
References: <57322A7F.1000609@ieu.uzh.ch>
Message-ID: <loom.20160511T012601-962@post.gmane.org>

Pascal A. Niklaus <pascal.niklaus <at> ieu.uzh.ch> writes:

> 
> Dear all,
> 
> After updating to R 3.3.0 (inadvertently, via apt-get), I get an error 
> when using lmerTest. Here is an example:
> 
> library(lmerTest)
> library(MASS)
> data(oats)
> m <- lmer(Y ~ N*V + (1|B/V), data=oats)
> summary(m)
> 
> summary from lme4 is returned
> some computational error has occurred in lmerTest
> 
> I have removed all old libraries and tried to have as clean an 
> installation as possible, but this did not fix the problem.
> 
> Is this an incompatibility or a problem with my installation?
> 

 Hard to say.  Works for me on a clean MacOS install of R 3.3/lme4/
lmerTest.

  You might want to send followups to r-sig-mixed-models at r-project.org



Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.9.5 (Mavericks)

locale:
[1] en_CA.UTF-8/en_CA.UTF-8/en_CA.UTF-8/C/en_CA.UTF-8/en_CA.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods  
[7] base     

other attached packages:
[1] MASS_7.3-45     lmerTest_2.0-30 lme4_1.1-12     Matrix_1.2-6   

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.4         Formula_1.2-1       cluster_2.0.4      
 [4] splines_3.3.0       munsell_0.4.3       colorspace_1.2-6   
 [7] lattice_0.20-33     minqa_1.2.4         plyr_1.8.3         
[10] tools_3.3.0         nnet_7.3-12         grid_3.3.0         
[13] data.table_1.9.6    gtable_0.2.0        nlme_3.1-127       
[16] latticeExtra_0.6-28 survival_2.39-3     gridExtra_2.2.1    
[19] RColorBrewer_1.1-2  nloptr_1.0.4        ggplot2_2.1.0      
[22] acepack_1.3-3.3     rpart_4.1-10        scales_0.4.0       
[25] Hmisc_3.17-4        chron_2.3-47        foreign_0.8-66


From Muhammad2.Bilal at live.uwe.ac.uk  Wed May 11 01:45:50 2016
From: Muhammad2.Bilal at live.uwe.ac.uk (Muhammad Bilal)
Date: Tue, 10 May 2016 23:45:50 +0000
Subject: [R] Creating data frame of predicted and actual values in R for
	plotting
Message-ID: <DB5PR07MB11093B491F3E5F50B22CA461DB710@DB5PR07MB1109.eurprd07.prod.outlook.com>

Hi All,


I have the following dataset:


> str(pfi_v3)
'data.frame': 714 obs. of  8 variables:
 $ project_id             : int  1 2 3 4 5 6 7 8 9 10 ...
 $ project_lat            : num  51.4 51.5 52.2 51.5 53.5 ...
 $ project_lon            : num  -0.642 -1.85 0.08 0.126 -1.392 ...
 $ sector                 : Factor w/ 9 levels "Defense","Hospitals",..: 4 4 4 6 6 6 6 6 6 6 ...
 $ project_duration       : int  1826 3652 121 520 1087 730 730 730 790 522 ...
 $ project_delay          : int  -323 0 -60 0 0 0 0 0 0 -91 ...
 $ capital_value          : num  6.7 5.8 21.8 47.3 47 24.2 40.7 71.9 10.7 70 ...
 $ contract_type          : Factor w/ 2 levels "Lumpsum","Turnkey": 2 2 2 2 2 2 2 2 2 2 ...


I'm using following commands to create training and test sets:

split <- sample.split(pfi_v3, SplitRatio = 0.8)
trainPFI <- subset(pfi_v3, split == TRUE)
testPFI <- subset(pfi_v3, split == FALSE)


I am using several predictive models to estimate delay in projects.


The commands are given as below:


1. Simple linear regression

lm_m <- lm(project_delay ~ project_lon +

                                                     project_lat +

                                                     project_duration +

                                                     sector +

                                                     contract_type +

                                                     capital_value,

                         data = trainPFI)

lm_pred <- predict(lm_m2, newdata = testPFI)


2. Regression tree

tree_m <- rpart(project_delay ~ project_lon +
                                                          project_lat +
                                                          project_duration +
                                                          sector +
                                                          contract_type +
                                                          capital_value,
                                data = trainPFI)

tree_pred <- predict(tree_m2, newdata = testPFI)

3. Cp optimsed regression tree

train_m <- train(project_delay ~ project_lon +
                                                           project_lat +
                                                           project_duration +
                                                           sector +
                                                           contract_type +
                                                           capital_value,
                     data = trainPFI,
                     method="rpart",
                     trControl=tr.control, tuneGrid = cp.grid)


train_pred <- predict(tr_m, newdata = testPFI)


4. Random Forest

rf_m <- randomForest(project_delay ~ project_lon +
                       project_lat +
                       project_duration +
                       sector +
                       contract_type +
                       capital_value,
                     data = trainPFI,
                     importance=TRUE,
                     ntree = 2000)

rf_pred <- predict(rf_m, newdata = testPFI)

5. Conditional Forest
cf_m <- cforest(project_delay ~ project_lon +
                       project_lat +
                       project_duration +
                       sector +
                       contract_type +
                       capital_value,
                     data = trainPFI,
                     controls=cforest_unbiased(ntree=2000, mtry=3))

cf_pred <- predict(cf_m, testPFI, OOB=TRUE, type = "response")

That is it.


Now I want to create a new data frame to combine the actual and predicted values such that the new frame has the following columns:

$project_id

$actual_delay

$lm_predicted_delay

$tree_predicted_delay

$train_predicted_delay

$rf_predicted_delay

$cf_predicted_delay


I want to use this dataframe to draw the line chart to compare predictions.


How to achieve this?


Any help will be highly appreciated.


Many Thanks and


Kind Regards

--
Muhammad Bilal
Research Fellow and Doctoral Researcher,
Bristol Enterprise, Research, and Innovation Centre (BERIC),
University of the West of England (UWE),
Frenchay Campus,
Bristol,
BS16 1QY

muhammad2.bilal at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>


	[[alternative HTML version deleted]]


From Muhammad2.Bilal at live.uwe.ac.uk  Wed May 11 02:06:32 2016
From: Muhammad2.Bilal at live.uwe.ac.uk (Muhammad Bilal)
Date: Wed, 11 May 2016 00:06:32 +0000
Subject: [R] Creating data frame of predicted and actual values in R
	for	plotting
In-Reply-To: <DB5PR07MB11093B491F3E5F50B22CA461DB710@DB5PR07MB1109.eurprd07.prod.outlook.com>
References: <DB5PR07MB11093B491F3E5F50B22CA461DB710@DB5PR07MB1109.eurprd07.prod.outlook.com>
Message-ID: <71991361-B4E1-4A53-931B-811866AC6E1C@live.uwe.ac.uk>

Pls don't mind the typo in predict() functions for some of the models. 

Sent from my iPhone

> On 11 May 2016, at 12:47 am, Muhammad Bilal <Muhammad2.Bilal at live.uwe.ac.uk> wrote:
> 
> Hi All,
> 
> 
> I have the following dataset:
> 
> 
>> str(pfi_v3)
> 'data.frame': 714 obs. of  8 variables:
> $ project_id             : int  1 2 3 4 5 6 7 8 9 10 ...
> $ project_lat            : num  51.4 51.5 52.2 51.5 53.5 ...
> $ project_lon            : num  -0.642 -1.85 0.08 0.126 -1.392 ...
> $ sector                 : Factor w/ 9 levels "Defense","Hospitals",..: 4 4 4 6 6 6 6 6 6 6 ...
> $ project_duration       : int  1826 3652 121 520 1087 730 730 730 790 522 ...
> $ project_delay          : int  -323 0 -60 0 0 0 0 0 0 -91 ...
> $ capital_value          : num  6.7 5.8 21.8 47.3 47 24.2 40.7 71.9 10.7 70 ...
> $ contract_type          : Factor w/ 2 levels "Lumpsum","Turnkey": 2 2 2 2 2 2 2 2 2 2 ...
> 
> 
> I'm using following commands to create training and test sets:
> 
> split <- sample.split(pfi_v3, SplitRatio = 0.8)
> trainPFI <- subset(pfi_v3, split == TRUE)
> testPFI <- subset(pfi_v3, split == FALSE)
> 
> 
> I am using several predictive models to estimate delay in projects.
> 
> 
> The commands are given as below:
> 
> 
> 1. Simple linear regression
> 
> lm_m <- lm(project_delay ~ project_lon +
> 
>                                                     project_lat +
> 
>                                                     project_duration +
> 
>                                                     sector +
> 
>                                                     contract_type +
> 
>                                                     capital_value,
> 
>                         data = trainPFI)
> 
> lm_pred <- predict(lm_m2, newdata = testPFI)
> 
> 
> 2. Regression tree
> 
> tree_m <- rpart(project_delay ~ project_lon +
>                                                          project_lat +
>                                                          project_duration +
>                                                          sector +
>                                                          contract_type +
>                                                          capital_value,
>                                data = trainPFI)
> 
> tree_pred <- predict(tree_m2, newdata = testPFI)
> 
> 3. Cp optimsed regression tree
> 
> train_m <- train(project_delay ~ project_lon +
>                                                           project_lat +
>                                                           project_duration +
>                                                           sector +
>                                                           contract_type +
>                                                           capital_value,
>                     data = trainPFI,
>                     method="rpart",
>                     trControl=tr.control, tuneGrid = cp.grid)
> 
> 
> train_pred <- predict(tr_m, newdata = testPFI)
> 
> 
> 4. Random Forest
> 
> rf_m <- randomForest(project_delay ~ project_lon +
>                       project_lat +
>                       project_duration +
>                       sector +
>                       contract_type +
>                       capital_value,
>                     data = trainPFI,
>                     importance=TRUE,
>                     ntree = 2000)
> 
> rf_pred <- predict(rf_m, newdata = testPFI)
> 
> 5. Conditional Forest
> cf_m <- cforest(project_delay ~ project_lon +
>                       project_lat +
>                       project_duration +
>                       sector +
>                       contract_type +
>                       capital_value,
>                     data = trainPFI,
>                     controls=cforest_unbiased(ntree=2000, mtry=3))
> 
> cf_pred <- predict(cf_m, testPFI, OOB=TRUE, type = "response")
> 
> That is it.
> 
> 
> Now I want to create a new data frame to combine the actual and predicted values such that the new frame has the following columns:
> 
> $project_id
> 
> $actual_delay
> 
> $lm_predicted_delay
> 
> $tree_predicted_delay
> 
> $train_predicted_delay
> 
> $rf_predicted_delay
> 
> $cf_predicted_delay
> 
> 
> I want to use this dataframe to draw the line chart to compare predictions.
> 
> 
> How to achieve this?
> 
> 
> Any help will be highly appreciated.
> 
> 
> Many Thanks and
> 
> 
> Kind Regards
> 
> --
> Muhammad Bilal
> Research Fellow and Doctoral Researcher,
> Bristol Enterprise, Research, and Innovation Centre (BERIC),
> University of the West of England (UWE),
> Frenchay Campus,
> Bristol,
> BS16 1QY
> 
> muhammad2.bilal at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>
> 
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed May 11 03:07:21 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 11 May 2016 11:07:21 +1000
Subject: [R] very long processing time
In-Reply-To: <1462918759.S.4696.27197.f5-224-103.1462925771.8927@webmail.rediffmail.com>
References: <CA+8X3fX7UHG4NjOh_6moJhSCxp99Ht6iuLtRjWF1__0M6dZfeQ@mail.gmail.com>
	<1462918759.S.4696.27197.f5-224-103.1462925771.8927@webmail.rediffmail.com>
Message-ID: <CA+8X3fUG3OCw8TSs05kXtJE22UP+g34Euupagj0HsPpFpE+Ayw@mail.gmail.com>

Hi Shashi,
First off, keep the thread on the list. Compare the two statements below:

Jim:  If this method is revealed to us, we may be able to help you.

Shashi: "if this method reveal to me i can help"

Regardless, I will attempt to help. This looks like number 2 - inefficient
code

You appear to be forming a very large vector bit by bit. This is _very_
inefficient. If you want to get the data frame "matrixdata" as a vector:

# this may work
fitness_1_data<-unlist(matrixdata)
# if not, try this
fitness_1_data<-as.vector(as.matrix(matrixdata))

This is written to a file and the file is read and again reformatted into
vectors for processing. If you are able, try to create a _small_ data set
that will be processed in the same way as "matrixdata" (e.g. a 10x10 data
frame):

smalldata<-as.data.frame(matrix(sample(1:100,100,nrow=10))
names(smalldata)<-paste("Col",1:10,sep="")

This will allow you to try out your code without spending a day on each
run. For instance, you can probably substitute:

matrixdata2<-matrixdata[,-1]

for a lot of the code in the second half of your script.

Jim

On Wed, May 11, 2016 at 10:16 AM, SHASHI SETH <sethshashi at rediffmail.com>
wrote:

>
> Hi Jim,
>
> Thanks a lot.. I could not understand what do u mean by "if this method
> reveal to me i can help" I am
> giving full program again and putting comment at calculation part. When I
> execute it, I can see after
> every one minute 29 kb is written in the file. Pls see.
>
>
> fitness_1_data <- c();
> src="dtm_mydata.csv"
> matrixdata <- read.csv(src)
> #get no vector/column from file/matrix
> noofvec <- length(matrixdata)
>
> #set no of records/rows/document
> noofrecords <- length(matrixdata[,1])
> #set row index
> rindex<-1;
> #preapare header
> colindex<-1;
> colList <- colnames(matrixdata)
>
> combine<-"";
>
> vec_fitness_data<- c();
>
> while(colindex <= length(colList))
> {
> fitness_1_data <- append(fitness_1_data,colList[colindex])
>
> colindex<- colindex+1
> }
> #add two additional vector for percentage and cluster
> fitness_1_data <- append(fitness_1_data,"percentage")
> fitness_1_data <- append(fitness_1_data,"Cluster")
> #write.csv(matrix(fitness_1_data, nrow=1), file ="myfile.csv",
> row.names=FALSE)
> write.table(as.list(fitness_1_data), file ="Res_mydata_cycle1.csv",append
> = TRUE,
> row.names=FALSE, col.names=FALSE, sep=",")
>
> #end header record
>
> #while (rindex < 2) #fitness will apply for first record everytime (first
> record will
> be compare with all below records)
>
> nestedloopindex <- 2
>
>
> while( nestedloopindex <= noofrecords )
> {
>
> #init of temperory variables
> sums1 <- 0;
> sums2 <- 0;
> sum <- 0;
>
> #set initial index of column 2 , coloumn one hold document no not
> actual data
> colindex <- 3;
>
> # combine <-"";
>
> vec1 <- c();
> vec2 <- c();
>
> #add document number in vector
> vec1 <- append(vec1,matrixdata[rindex,1]);
> vec2 <- append(vec2,matrixdata[nestedloopindex,1]);
> vec1 <- append(vec1,matrixdata$ID[rindex]);
> vec2 <- append(vec2,matrixdata$ID[nestedloopindex]);
>
>
> baseSum <- 0;
>
> ##############################################Calculation
> Part#######################################
> while(colindex <= noofvec )
> {
>
> baseSum <- baseSum + matrixdata[rindex,colindex]
>
> vec1 <- append(vec1,matrixdata[rindex,colindex]);
> vec2 <- append(vec2,matrixdata[nestedloopindex,colindex]);
>
> sum = sum +
> matrixdata[rindex,colindex]*matrixdata[nestedloopindex,colindex]
>
> sums1 <- sums1 + matrixdata[rindex,colindex]^2;
>
> sums2 <- sums2 + matrixdata[nestedloopindex,colindex]^2;
>
> colindex <- colindex+1
> }
>
> if(sum > 0 && sums1 > 0 && sums2 > 0)
> {
> out <- sum / ((sqrt(sums1) * sqrt(sums2)))
> }else
> {
> out <-0
> }
> #################################### End Calculation
> ################################################
> vec1 <- append(vec1,out);
> vec1 <-append(vec1, "1")
> vec2 <- append(vec2, out);
>
> if(nestedloopindex==2)
> {
> write.table(as.list(vec1), file ="Res_mydata_cycle1.csv",append =
> TRUE, row.names=FALSE, col.names=FALSE, sep=",")
> write.table(as.list(vec2), file ="Res_mydata_cycle1.csv",append =
> TRUE, row.names=FALSE, col.names=FALSE, sep=",")
> nestedloopindex<- nestedloopindex+1
> } else
> {
> write.table(as.list(vec2), file ="Res_mydata_cycle1.csv",append =
> TRUE, row.names=FALSE, col.names=FALSE, sep=",")
> nestedloopindex<- nestedloopindex+1
> }
> }
>
> Thanks,
> Shashi
>
>
>
>
> On Wed, 11 May 2016 03:49:19 +0530 Jim Lemon wrote
> >Hi Shashi,
>
> The assumption that anyone on the list apart from yourself knows what
>
> "some calculation" involves is incorrect. I suspect that "what is
>
> wrong" may be one of two things:
>
>
> 1) "some calculation" includes a very large number of operations,
>
> perhaps leading to "disk-thrashing" when your 16GB of memory is full
>
> of intermediate values. There is no software problem, buy more
>
> hardware.
>
>
>
> 2) "some calculation" is a very inefficient method of getting the
>
> result you want. If this method is revealed to us, we may be able to
>
> help you.
>
>
>
> Jim
>
>
>
>
>
> On Wed, May 11, 2016 at 2:24 AM, SHASHI SETH wrote:
>
> > Hi,
>
> >
>
> >
>
> >
>
> > I have implemented following program in R, that reads data from the
> "dtm_mydata.csv". file size is
>
> >
>
> > 114,029 kB, saved document Term matrix. Prog. performing some
> calculation and writing in a file. my
>
> >
>
> > computer RAM is 16 GB. To execute this program its taking around 25
> hours. can any body help me what
> is
>
> >
>
> > wrong, why this much time is taken. Although it is doing the job what is
> required
>
> >
>
> > fitness_1_data
>
> > [[alternative HTML version deleted]]
>
> >
>
> > ______________________________________________
>
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> > https://stat.ethz.ch/mailman/listinfo/r-help
>
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> <https://sigads.rediff.com/RealMedia/ads/click_nx.ads/www.rediffmail.com/signatureline.htm at Middle?>
>
> Get your own *FREE* website, *FREE* domain & *FREE* mobile app with
> Company email.
> *Know More >*
> <http://track.rediff.com/click?url=___http://businessemail.rediff.com?sc_cid=sign-1-10-13___&cmp=host&lnk=sign-1-10-13&nsrv1=host>

	[[alternative HTML version deleted]]


From ajdamico at gmail.com  Wed May 11 05:37:05 2016
From: ajdamico at gmail.com (Anthony Damico)
Date: Tue, 10 May 2016 23:37:05 -0400
Subject: [R] Quantiles on multiply imputed survey data - mitools
In-Reply-To: <F29237C5-CDD2-4215-B516-B37D066D0678@toxstrategies.com>
References: <F29237C5-CDD2-4215-B516-B37D066D0678@toxstrategies.com>
Message-ID: <CAOwvMDx+rrxz1BUFOFdgAHdBguPvsUpu2TF_3Vusun4bPS+SuQ@mail.gmail.com>

is the `with` not passing make.formula( get( 'var_name' ) ) through to
svyquantile for some reason?  does this work?

MIcombine( with(des, svyquantile(~LBXTCD, .5)))


if that's not it, could you make a minimal reproducible example that
includes the data download?  code to download and import nhanes here

https://github.com/ajdamico/asdfree/tree/master/National%20Health%20and%20Nutrition%20Examination%20Survey



On Tue, May 10, 2016 at 4:33 PM, Anne Bichteler <
abichteler at toxstrategies.com> wrote:

> Hello, and thank you for considering this question:
>
> The svystat object created with multiply imputed NHANES data files is
> failing on calling survey::svyquantile. I'm wondering if I'm diagnosing the
> issue correctly, whether the behavior is expected, and whether y'all might
> have any ideas for workarounds.
>
> I'm following T. Lumley's general method outlined here:
> http://faculty.washington.edu/tlumley/old-survey/svymi.html, but with
> data files I've imputed myself on the 2001/2002 biennial. Each file has
> 1081 observations and no missing values.
>
> ### Create the survey design object with list of imputed data files
> ImputedList0102.
> des <- svydesign(id=~SDMVPSU, strat=~SDMVSTRA, weight=~WTSPO2YR,
> data=imputationList(ImputedList0102), nest=TRUE)
>
>
> ### Blood analyte of interest
> var_name <- "LBXTCD" # analyte in blood serum
>
> ### All is well calculating the mean:
> M <- with(des, svymean(make.formula(get('var_name'))))
> summary(M)
> Result <- MIcombine(M)
> Result$coefficients
> # LBXTCD
> # 17.41635
>
>
> ### but svystat object fails to calculate a 50th percentile:
> ### it fails when hard-coding the name rather than using make.formula;
> ### it fails regardless of number of files or choices in handling ties or
> interval type.
> ### There are 16 ties in each data file.
> M1 <- with(des, svyquantile(make.formula(get('var_name')), quantiles =
> c(.5)))
> summary(M1)
>
> #     Length Class  Mode
> #[1,] 1      -none- numeric
> #[2,] 1      -none- numeric
> #[3,] 1      -none- numeric
>
>
> ### The quantile is successfully calculated on one file at a time,
> however, and is different for each file.
> ### (had thought perhaps there was a lack-of-variance issue). The quantile
> calculated on each file
> ### is the same regardless of interval.type.
> des_single1 <- svydesign(id=~SDMVPSU, strat=~SDMVSTRA, weight=~WTSPO2YR,
> data=ImputedList0102[[1]], nest=TRUE)
> svyquantile(make.formula(get('var_name')), des_single1, c(.5))
> # 0.5
> # LBXTCD 13.5554
>
>
> des_single2 <- svydesign(id=~SDMVPSU, strat=~SDMVSTRA, weight=~WTSPO2YR,
> data=ImputedList0102[[2]], nest=TRUE)
> svyquantile(make.formula(get('var_name')), des_single2, c(.5))
> # 0.5
> # LBXTCD 14.06154
>
> # The number of observations exceeding the 50th percentile differs for
> each file, which I can't claim to understand.
>
> # I removed the 16 ties, but no help. Do the ties and/or different number
> of observations above/below prevent the svydesigns from being combined?
> nrow(subset(ImputedList0102[[1]], LBXTCD > 13.5554))
> # [1] 516
> nrow(subset(ImputedList0102[[2]], LBXTCD > 14.06154))
> # [1] 512
>
>
> I'm hoping someone can point me to some gross error I'm making or another
> function parameter or data manipulation or another survey-savvy method
> altogether to calculate a 50th percentile across multiply imputed data
> files. Thanks for any advice,
>
> Brennan
>
> www.toxstrategies.com
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Dominik.Schneider at colorado.edu  Wed May 11 02:30:58 2016
From: Dominik.Schneider at colorado.edu (Dominik Schneider)
Date: Tue, 10 May 2016 18:30:58 -0600
Subject: [R] physical constraint with gam
Message-ID: <CAF1jk_=312-4GEwpeJM2UaOojnSE_6PxLo6YU2ysjGdHKBt3UQ@mail.gmail.com>

Hi,
Just getting into using GAM using the mgcv package. I've generated some
models and extracted the splines for each of the variables and started
visualizing them. I'm noticing that one of my variables is physically
unrealistic.

In the example below, my interpretation of the following plot is that the
y-axis is basically the equivalent of a "parameter" value of a GLM; in GAM
this value can change as the functional relationship changes between x and
y. In my case, I am predicting snowdepth based on the fractional snow
covered area. In no case will snowdepth realistically decrease for a unit
increase in fsca so my question is: *Is there a way to constrain the spline
to positive values? *

Thanks
Dominik

library(mgcv)
library(dplyr)
library(ggplot2)
extract_splines=function(mdl){
  sterms=predict(mdl,type='terms')
  datplot=cbind(sterms,mdl$model) %>% tbl_df
  datplot$intercept=attr(sterms,'constant')
  datplot$yhat=rowSums(sterms)+attr(sterms,'constant')
  return(datplot)
}
dat=data_frame(snowdepth=runif(100,min =
0.001,max=6.7),fsca=runif(100,0.01,.99))
mdl=gam(snowdepth~s(fsca),data=dat)
termdF=extract_splines(mdl)
ggplot(termdF)+
  geom_line(aes(x=fsca,y=`s(fsca)`))

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed May 11 09:48:25 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 11 May 2016 00:48:25 -0700
Subject: [R] Ensure parameter is a string when passed within an lapply &
	called function runs a 'substitute' on it
In-Reply-To: <57310388.e873c20a.284cd.062d@mx.google.com>
References: <57310388.e873c20a.284cd.062d@mx.google.com>
Message-ID: <ACA108A3-73DA-455C-B769-B1A01C6BEE9F@comcast.net>


> On May 9, 2016, at 2:39 PM, Andrew Clancy <nite at achren.org> wrote:
> 
> Hi, 
> 
> I?m trying to solve what looks like the same issue as stack overflow article, but within an lapply:
> http://stackoverflow.com/questions/18939254/cant-use-a-variable-as-an-argument-but-can-use-its-value


It would be helpful if you could articulate the issue.

> 
> I?ve replicated the issue with partialPlot below in ?testFunc?. The lines up to the final print can?t change (including the substitute). In the first call it prints out ?X1? correctly, in the second it prints out ?var?. I?ve tried eval, quote etc as the article suggests. Any ideas?
> 
> numObs  <- 10
> numVars <- 6
> dataSet    <- data.frame(replicate(numVars,rnorm(numObs)))
> # partialPlot(x = model, pred.data = dataSet, x.var = 'X1', plot = F) 

I'm assuming that the comment character is actually something that was inserted in hte process of stripping hte HTML from this posting.

It throws an error when removed:

Error in partialPlot(x = model, pred.data = dataSet, x.var = "X1", plot = F) : 
  object 'model' not found

> 

> testFunc <- function(x, pred.data, x.var, plot=F) {
>   x.var <- substitute(x.var)

Try changing to eval(x.bar)

>   # print(paste('is.character(x.var)', is.character(x.var), 'is.name(x.var)', is.name(x.var)))

>   xname <- if (is.character(x.var)) x.var else {
>     if (is.name(x.var)) deparse(x.var) else {
>       eval(x.var)
>     }
>   }
>   print(xname)
>   # print(head(pred.data[,xname]))
> }
> 
> vars <- names(dataSet)[[1]]
> testFunc(x = model, pred.data = dataSet, x.var = local(vars), plot = F)

Returns:
[1] "is.character(x.var) TRUE is.name(x.var) FALSE"
[1] "X1"
[1]  0.8704543 -0.4421564 -0.6725336 -1.3096399 -1.0531335 -0.4979650


> 
> lapply(vars, function(var) {
>   # print(paste('var', var))
>   testFunc(x = model, pred.data = dataSet, x.var = var, plot = F)
> })

Retruns:
[1] "var X1"
[1] "is.character(x.var) TRUE is.name(x.var) FALSE"
[1] "X1"
[1]  0.8704543 -0.4421564 -0.6725336 -1.3096399 -1.0531335 -0.4979650
[[1]]
[1]  0.8704543 -0.4421564 -0.6725336 -1.3096399 -1.0531335 -0.4979650


> 
> 	[[alternative HTML version deleted]]

Please learn to post in plain text for this mailing list.

-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Wed May 11 09:52:35 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 11 May 2016 00:52:35 -0700
Subject: [R] physical constraint with gam
In-Reply-To: <CAF1jk_=312-4GEwpeJM2UaOojnSE_6PxLo6YU2ysjGdHKBt3UQ@mail.gmail.com>
References: <CAF1jk_=312-4GEwpeJM2UaOojnSE_6PxLo6YU2ysjGdHKBt3UQ@mail.gmail.com>
Message-ID: <B28C1145-6290-43D0-B8CB-CE11E6AD845C@comcast.net>


> On May 10, 2016, at 5:30 PM, Dominik Schneider <Dominik.Schneider at colorado.edu> wrote:
> 
> Hi,
> Just getting into using GAM using the mgcv package. I've generated some
> models and extracted the splines for each of the variables and started
> visualizing them. I'm noticing that one of my variables is physically
> unrealistic.
> 
> In the example below, my interpretation of the following plot is that the
> y-axis is basically the equivalent of a "parameter" value of a GLM; in GAM
> this value can change as the functional relationship changes between x and
> y. In my case, I am predicting snowdepth based on the fractional snow
> covered area. In no case will snowdepth realistically decrease for a unit
> increase in fsca so my question is: *Is there a way to constrain the spline
> to positive values? *
> 

I would think that the mass or volume of snow might not realistically decrease with increase in area but I see no reason why increasing the area might not be associated with an decrease in mean depth. Depth would be "orthogonal" to area.



> Thanks
> Dominik
> 
> library(mgcv)
> library(dplyr)
> library(ggplot2)
> extract_splines=function(mdl){
>  sterms=predict(mdl,type='terms')
>  datplot=cbind(sterms,mdl$model) %>% tbl_df
>  datplot$intercept=attr(sterms,'constant')
>  datplot$yhat=rowSums(sterms)+attr(sterms,'constant')
>  return(datplot)
> }
> dat=data_frame(snowdepth=runif(100,min =
> 0.001,max=6.7),fsca=runif(100,0.01,.99))
> mdl=gam(snowdepth~s(fsca),data=dat)
> termdF=extract_splines(mdl)
> ggplot(termdF)+
>  geom_line(aes(x=fsca,y=`s(fsca)`))
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From wewolski at gmail.com  Wed May 11 10:45:03 2016
From: wewolski at gmail.com (Witold E Wolski)
Date: Wed, 11 May 2016 10:45:03 +0200
Subject: [R] how to manipulate ... in the argument list
Message-ID: <CAAjnpdg3XrWjagscn7shX1TWm8TEY0=VcWvUy29j_ai_+NmdOA@mail.gmail.com>

Hi,

I am looking for a documentation describing how to manipulate the
"..." . Searching R-intro.html gives to many not relevant hits for
"..."

What I want to do is something like this :


image.2 <- function(x, col , ...){
 # function is manipulating colors (adding a few)
 # since it changes colors it needs to update breaks if defined.

  breaks <- list(...)$breaks

 if( !is.null( list(...)$breaks ) ){
    #manipulate breaks

   image(x, col, breaks = breaks ,...)

  }else{
     image(x,col ,...)
  }
}

but in order to get it working I will need to remove breaks from ...
since otherwise I am getting multiple defined argument for breaks.

So how to manipulate the "..." argument? Or should I use a different pattern

best



-- 
Witold Eryk Wolski


From simon.wood at bath.edu  Wed May 11 11:11:12 2016
From: simon.wood at bath.edu (Simon Wood)
Date: Wed, 11 May 2016 10:11:12 +0100
Subject: [R] physical constraint with gam
In-Reply-To: <CAF1jk_=312-4GEwpeJM2UaOojnSE_6PxLo6YU2ysjGdHKBt3UQ@mail.gmail.com>
References: <CAF1jk_=312-4GEwpeJM2UaOojnSE_6PxLo6YU2ysjGdHKBt3UQ@mail.gmail.com>
Message-ID: <5732F730.9000800@bath.edu>

The spline having a positive value is not the same as a glm coefficient 
having a positive value. When you plot a smooth, say s(x), that is 
equivalent to plotting the line 'beta * x' in a GLM. It is not 
equivalent to plotting 'beta'. The smooths in a gam are (usually) 
subject to `sum-to-zero' identifiability constraints to avoid 
confounding via the intercept, so they are bound to be negative over 
some part of the covariate range. For example, if I have a model y ~ 
s(x) + s(z), I can't estimate the mean level for s(x) and the mean level 
for s(z) as they are completely confounded, and confounded with the 
model intercept term.

I suppose that if you want to interpret the smooths as glm parameters 
varying with the covariate they relate to then you can do, by setting 
the model up as a varying coefficient model, using the `by' argument to 
's'...

gam(snowdepth~s(fsca,by=fsca),data=dat)


this model is `snowdepth_i = f(fsca_i) * fsca_i + e_i' . s(fsca,by=fsca) 
is not confounded with the intercept, so no constraint is needed or 
applied, and you can now interpret the smooth like a local GLM coefficient.

best,
Simon




On 11/05/16 01:30, Dominik Schneider wrote:
> Hi,
> Just getting into using GAM using the mgcv package. I've generated some
> models and extracted the splines for each of the variables and started
> visualizing them. I'm noticing that one of my variables is physically
> unrealistic.
>
> In the example below, my interpretation of the following plot is that the
> y-axis is basically the equivalent of a "parameter" value of a GLM; in GAM
> this value can change as the functional relationship changes between x and
> y. In my case, I am predicting snowdepth based on the fractional snow
> covered area. In no case will snowdepth realistically decrease for a unit
> increase in fsca so my question is: *Is there a way to constrain the spline
> to positive values? *
>
> Thanks
> Dominik
>
> library(mgcv)
> library(dplyr)
> library(ggplot2)
> extract_splines=function(mdl){
>    sterms=predict(mdl,type='terms')
>    datplot=cbind(sterms,mdl$model) %>% tbl_df
>    datplot$intercept=attr(sterms,'constant')
>    datplot$yhat=rowSums(sterms)+attr(sterms,'constant')
>    return(datplot)
> }
> dat=data_frame(snowdepth=runif(100,min =
> 0.001,max=6.7),fsca=runif(100,0.01,.99))
> mdl=gam(snowdepth~s(fsca),data=dat)
> termdF=extract_splines(mdl)
> ggplot(termdF)+
>    geom_line(aes(x=fsca,y=`s(fsca)`))
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Simon Wood, School of Mathematics, University of Bristol BS8 1TW UK
+44 (0)117 33 18273     http://www.maths.bris.ac.uk/~sw15190


From drjimlemon at gmail.com  Wed May 11 11:29:19 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 11 May 2016 19:29:19 +1000
Subject: [R] how to manipulate ... in the argument list
In-Reply-To: <CAAjnpdg3XrWjagscn7shX1TWm8TEY0=VcWvUy29j_ai_+NmdOA@mail.gmail.com>
References: <CAAjnpdg3XrWjagscn7shX1TWm8TEY0=VcWvUy29j_ai_+NmdOA@mail.gmail.com>
Message-ID: <CA+8X3fWUjtYjkGfu_Cvp_8vuuZYcDxnfDV_V9Xjez+6NRtcAqw@mail.gmail.com>

Hi Witold,
You could try Ben Bolker's "clean.args" function in the plotrix package.

Jim


On Wed, May 11, 2016 at 6:45 PM, Witold E Wolski <wewolski at gmail.com> wrote:
> Hi,
>
> I am looking for a documentation describing how to manipulate the
> "..." . Searching R-intro.html gives to many not relevant hits for
> "..."
>
> What I want to do is something like this :
>
>
> image.2 <- function(x, col , ...){
>  # function is manipulating colors (adding a few)
>  # since it changes colors it needs to update breaks if defined.
>
>   breaks <- list(...)$breaks
>
>  if( !is.null( list(...)$breaks ) ){
>     #manipulate breaks
>
>    image(x, col, breaks = breaks ,...)
>
>   }else{
>      image(x,col ,...)
>   }
> }
>
> but in order to get it working I will need to remove breaks from ...
> since otherwise I am getting multiple defined argument for breaks.
>
> So how to manipulate the "..." argument? Or should I use a different pattern
>
> best
>
>
>
> --
> Witold Eryk Wolski
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Muhammad2.Bilal at live.uwe.ac.uk  Wed May 11 12:36:04 2016
From: Muhammad2.Bilal at live.uwe.ac.uk (Muhammad Bilal)
Date: Wed, 11 May 2016 10:36:04 +0000
Subject: [R] Creating data frame of predicted and actual values in R
	for	plotting
In-Reply-To: <71991361-B4E1-4A53-931B-811866AC6E1C@live.uwe.ac.uk>
References: <DB5PR07MB11093B491F3E5F50B22CA461DB710@DB5PR07MB1109.eurprd07.prod.outlook.com>,
	<71991361-B4E1-4A53-931B-811866AC6E1C@live.uwe.ac.uk>
Message-ID: <DB5PR07MB11090256E72DDD7A01A41D75DB720@DB5PR07MB1109.eurprd07.prod.outlook.com>

I have achieved this use case by writing the following commands:

all_predictions <- data.frame(pid = testPFI$project_id, actual_delay = testPFI$project_delay,lm_pred, tree_pred, best_tree_pred, rf_pred)

str(all_predictions)

all_pred <- sqldf("SELECT pid, actual_delay, ROUND(lm_pred,2) lm_pred,
                               ROUND(tree_pred,2) tree_pred,
                               ROUND(best_tree_pred,2) train_pred,
                               ROUND(rf_pred,2) rf_pred
                     FROM all_predictions
                      ORDER BY actual_delay")
all_pred

#Plotting all the predictions on the graph
ggplot(all_pred, aes(x=pid)) + geom_line(aes(y=actual_delay), colour="blue") +
  geom_line(aes(y=lm_pred), colour="red", size=1)  +
  geom_line(aes(y=tree_pred), colour="green", size=1)  +
  geom_line(aes(y=train_pred), colour="yellow", size=1)  +
  geom_line(aes(y=rf_pred), colour="black", size=1)

So I am done.

Many Thanks and

Kind Regards
--
Muhammad Bilal
Research Fellow and Doctoral Researcher,
Bristol Enterprise, Research, and Innovation Centre (BERIC),
University of the West of England (UWE),
Frenchay Campus,
Bristol,
BS16 1QY

muhammad2.bilal at live.uwe.ac.uk


________________________________________
From: Muhammad Bilal
Sent: 11 May 2016 01:06:32
To: r-help at r-project.org
Subject: Re: [R] Creating data frame of predicted and actual values in R for    plotting

Pls don't mind the typo in predict() functions for some of the models.

Sent from my iPhone

> On 11 May 2016, at 12:47 am, Muhammad Bilal <Muhammad2.Bilal at live.uwe.ac.uk> wrote:
>
> Hi All,
>
>
> I have the following dataset:
>
>
>> str(pfi_v3)
> 'data.frame': 714 obs. of  8 variables:
> $ project_id             : int  1 2 3 4 5 6 7 8 9 10 ...
> $ project_lat            : num  51.4 51.5 52.2 51.5 53.5 ...
> $ project_lon            : num  -0.642 -1.85 0.08 0.126 -1.392 ...
> $ sector                 : Factor w/ 9 levels "Defense","Hospitals",..: 4 4 4 6 6 6 6 6 6 6 ...
> $ project_duration       : int  1826 3652 121 520 1087 730 730 730 790 522 ...
> $ project_delay          : int  -323 0 -60 0 0 0 0 0 0 -91 ...
> $ capital_value          : num  6.7 5.8 21.8 47.3 47 24.2 40.7 71.9 10.7 70 ...
> $ contract_type          : Factor w/ 2 levels "Lumpsum","Turnkey": 2 2 2 2 2 2 2 2 2 2 ...
>
>
> I'm using following commands to create training and test sets:
>
> split <- sample.split(pfi_v3, SplitRatio = 0.8)
> trainPFI <- subset(pfi_v3, split == TRUE)
> testPFI <- subset(pfi_v3, split == FALSE)
>
>
> I am using several predictive models to estimate delay in projects.
>
>
> The commands are given as below:
>
>
> 1. Simple linear regression
>
> lm_m <- lm(project_delay ~ project_lon +
>
>                                                     project_lat +
>
>                                                     project_duration +
>
>                                                     sector +
>
>                                                     contract_type +
>
>                                                     capital_value,
>
>                         data = trainPFI)
>
> lm_pred <- predict(lm_m2, newdata = testPFI)
>
>
> 2. Regression tree
>
> tree_m <- rpart(project_delay ~ project_lon +
>                                                          project_lat +
>                                                          project_duration +
>                                                          sector +
>                                                          contract_type +
>                                                          capital_value,
>                                data = trainPFI)
>
> tree_pred <- predict(tree_m2, newdata = testPFI)
>
> 3. Cp optimsed regression tree
>
> train_m <- train(project_delay ~ project_lon +
>                                                           project_lat +
>                                                           project_duration +
>                                                           sector +
>                                                           contract_type +
>                                                           capital_value,
>                     data = trainPFI,
>                     method="rpart",
>                     trControl=tr.control, tuneGrid = cp.grid)
>
>
> train_pred <- predict(tr_m, newdata = testPFI)
>
>
> 4. Random Forest
>
> rf_m <- randomForest(project_delay ~ project_lon +
>                       project_lat +
>                       project_duration +
>                       sector +
>                       contract_type +
>                       capital_value,
>                     data = trainPFI,
>                     importance=TRUE,
>                     ntree = 2000)
>
> rf_pred <- predict(rf_m, newdata = testPFI)
>
> 5. Conditional Forest
> cf_m <- cforest(project_delay ~ project_lon +
>                       project_lat +
>                       project_duration +
>                       sector +
>                       contract_type +
>                       capital_value,
>                     data = trainPFI,
>                     controls=cforest_unbiased(ntree=2000, mtry=3))
>
> cf_pred <- predict(cf_m, testPFI, OOB=TRUE, type = "response")
>
> That is it.
>
>
> Now I want to create a new data frame to combine the actual and predicted values such that the new frame has the following columns:
>
> $project_id
>
> $actual_delay
>
> $lm_predicted_delay
>
> $tree_predicted_delay
>
> $train_predicted_delay
>
> $rf_predicted_delay
>
> $cf_predicted_delay
>
>
> I want to use this dataframe to draw the line chart to compare predictions.
>
>
> How to achieve this?
>
>
> Any help will be highly appreciated.
>
>
> Many Thanks and
>
>
> Kind Regards
>
> --
> Muhammad Bilal
> Research Fellow and Doctoral Researcher,
> Bristol Enterprise, Research, and Innovation Centre (BERIC),
> University of the West of England (UWE),
> Frenchay Campus,
> Bristol,
> BS16 1QY
>
> muhammad2.bilal at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>
>
>
>    [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Wed May 11 12:45:42 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 11 May 2016 06:45:42 -0400
Subject: [R] how to manipulate ... in the argument list
In-Reply-To: <CAAjnpdg3XrWjagscn7shX1TWm8TEY0=VcWvUy29j_ai_+NmdOA@mail.gmail.com>
References: <CAAjnpdg3XrWjagscn7shX1TWm8TEY0=VcWvUy29j_ai_+NmdOA@mail.gmail.com>
Message-ID: <57330D56.5090600@gmail.com>

On 11/05/2016 4:45 AM, Witold E Wolski wrote:
> Hi,
>
> I am looking for a documentation describing how to manipulate the
> "..." . Searching R-intro.html gives to many not relevant hits for
> "..."
>
> What I want to do is something like this :
>
>
> image.2 <- function(x, col , ...){
>   # function is manipulating colors (adding a few)
>   # since it changes colors it needs to update breaks if defined.
>
>    breaks <- list(...)$breaks
>
>   if( !is.null( list(...)$breaks ) ){
>      #manipulate breaks
>
>     image(x, col, breaks = breaks ,...)
>
>    }else{
>       image(x,col ,...)
>    }
> }
>
> but in order to get it working I will need to remove breaks from ...
> since otherwise I am getting multiple defined argument for breaks.

If breaks is an argument that image.2 uses, you should just list it 
explicitly, and it won't become part of ... .

However, if you really want to do what you describe, you can do it using 
do.call.  Replace

image(x, col, breaks = breaks, ...)

with

dots <- list(...)
dots$breaks <- NULL
do.call(image, c(list(x, col, breaks = breaks), dots))

>
> So how to manipulate the "..." argument? Or should I use a different pattern

I'd recommend a different pattern, i.e. include breaks as an argument, 
and possibly use is.missing(breaks) to determine when it has not been used.

Duncan Murdoch


From chalabi.elahe at yahoo.de  Wed May 11 14:00:55 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Wed, 11 May 2016 12:00:55 +0000 (UTC)
Subject: [R] factor variables in logistic regression
References: <183701246.538353.1462968055608.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <183701246.538353.1462968055608.JavaMail.yahoo@mail.yahoo.com>

Hi all,

I have a plot for TSTMean vs. SNRMean and both of these variables are factors. How can I use Logistic Regression for factor variables?
Currently I use model=lm(TSTMean~SNRMean,data=df) but when I check summary(model) I get this error: r error in quartile.default (resid) factors are not allowed
 
thanks for any help,
Elahe


From nite at achren.org  Wed May 11 13:02:06 2016
From: nite at achren.org (Andrew Clancy)
Date: Wed, 11 May 2016 12:02:06 +0100
Subject: [R] Ensure parameter is a string when passed within an lapply &
 called function runs a 'substitute' on it
In-Reply-To: <ACA108A3-73DA-455C-B769-B1A01C6BEE9F@comcast.net>
References: <57310388.e873c20a.284cd.062d@mx.google.com>
	<ACA108A3-73DA-455C-B769-B1A01C6BEE9F@comcast.net>
Message-ID: <CA+brG2C8_bsTPZ6B7Q_25nAQddfF+00t=Vv7Ao+28mQ73u_jEg@mail.gmail.com>

Thanks David - my earlier response to Bert contains the resolution.
partialPlot was commented out deliberately as it was the target function
who's behaviour I was replicating in testFunc. The original behaviour, ie.
printing 'X1' was correct, and the do.call fix yields this same response
when testFunc is called within lapply. As I'm replicating partialPlot, no
changes can be made to testFunc (eg. your removal of 'substitute')
otherwise I'd need to patch the randomForest::partialPlot package &
function. The correct patch would be to change the eval to use the parent
environment, the subtitue should remain.

See the resolution here (jcheng beat r-help to it this time!)
https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!topic/shiny-discuss/cIZJzQmw8tQ


On 11 May 2016 at 08:48, David Winsemius <dwinsemius at comcast.net> wrote:

>
> > On May 9, 2016, at 2:39 PM, Andrew Clancy <nite at achren.org> wrote:
> >
> > Hi,
> >
> > I?m trying to solve what looks like the same issue as stack overflow
> article, but within an lapply:
> >
> http://stackoverflow.com/questions/18939254/cant-use-a-variable-as-an-argument-but-can-use-its-value
>
>
> It would be helpful if you could articulate the issue.
>
> >
> > I?ve replicated the issue with partialPlot below in ?testFunc?. The
> lines up to the final print can?t change (including the substitute). In the
> first call it prints out ?X1? correctly, in the second it prints out ?var?.
> I?ve tried eval, quote etc as the article suggests. Any ideas?
> >
> > numObs  <- 10
> > numVars <- 6
> > dataSet    <- data.frame(replicate(numVars,rnorm(numObs)))
> > # partialPlot(x = model, pred.data = dataSet, x.var = 'X1', plot = F)
>
> I'm assuming that the comment character is actually something that was
> inserted in hte process of stripping hte HTML from this posting.
>
> It throws an error when removed:
>
> Error in partialPlot(x = model, pred.data = dataSet, x.var = "X1", plot =
> F) :
>   object 'model' not found
>
> >
>
> > testFunc <- function(x, pred.data, x.var, plot=F) {
> >   x.var <- substitute(x.var)
>
> Try changing to eval(x.bar)
>
> >   # print(paste('is.character(x.var)', is.character(x.var), 'is.name(x.var)',
> is.name(x.var)))
>
> >   xname <- if (is.character(x.var)) x.var else {
> >     if (is.name(x.var)) deparse(x.var) else {
> >       eval(x.var)
> >     }
> >   }
> >   print(xname)
> >   # print(head(pred.data[,xname]))
> > }
> >
> > vars <- names(dataSet)[[1]]
> > testFunc(x = model, pred.data = dataSet, x.var = local(vars), plot = F)
>
> Returns:
> [1] "is.character(x.var) TRUE is.name(x.var) FALSE"
> [1] "X1"
> [1]  0.8704543 -0.4421564 -0.6725336 -1.3096399 -1.0531335 -0.4979650
>
>
> >
> > lapply(vars, function(var) {
> >   # print(paste('var', var))
> >   testFunc(x = model, pred.data = dataSet, x.var = var, plot = F)
> > })
>
> Retruns:
> [1] "var X1"
> [1] "is.character(x.var) TRUE is.name(x.var) FALSE"
> [1] "X1"
> [1]  0.8704543 -0.4421564 -0.6725336 -1.3096399 -1.0531335 -0.4979650
> [[1]]
> [1]  0.8704543 -0.4421564 -0.6725336 -1.3096399 -1.0531335 -0.4979650
>
>
> >
> >       [[alternative HTML version deleted]]
>
> Please learn to post in plain text for this mailing list.
>
> --
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From kevin.thorpe at utoronto.ca  Wed May 11 14:44:22 2016
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Wed, 11 May 2016 08:44:22 -0400
Subject: [R] factor variables in logistic regression
In-Reply-To: <183701246.538353.1462968055608.JavaMail.yahoo@mail.yahoo.com>
References: <183701246.538353.1462968055608.JavaMail.yahoo.ref@mail.yahoo.com>
	<183701246.538353.1462968055608.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <57332926.60304@utoronto.ca>

On 05/11/2016 08:00 AM, ch.elahe via R-help wrote:
> Hi all,
>
> I have a plot for TSTMean vs. SNRMean and both of these variables are factors. How can I use Logistic Regression for factor variables?
> Currently I use model=lm(TSTMean~SNRMean,data=df) but when I check summary(model) I get this error: r error in quartile.default (resid) factors are not allowed
>
> thanks for any help,
> Elahe
>

First of all, lm() is for linear regression, not logistic regression. 
For logistic regression you need to use glm() and make sure you set the 
correct family (see ?glm). I don't recall if glm() accepts a factor 
outcome but if not, you would need to re-code it to 0/1.

Kevin

-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's Hospital
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From friendly at yorku.ca  Wed May 11 14:45:03 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 11 May 2016 08:45:03 -0400
Subject: [R] web scraping tables generated in multiple server pages /
 Best of R-help
In-Reply-To: <CAJ4QxaPmGG3mOMV-27JCK+BR_c9GUZu8fnZmN_XRp6=FnYgYOg@mail.gmail.com>
References: <ff65b860-65aa-35b0-546b-646380e7ec37@yorku.ca>
	<CAJ4QxaPmGG3mOMV-27JCK+BR_c9GUZu8fnZmN_XRp6=FnYgYOg@mail.gmail.com>
Message-ID: <69304fd1-2e4a-a364-3832-c55e6281bf3b@yorku.ca>

On 5/10/2016 4:11 PM, boB Rudis wrote:
> Unfortunately, it's a wretched, vile, SharePoint-based site. That
> means it doesn't use traditional encoding methods to do the pagination
> and one of the only ways to do this effectively is going to be to use
> RSelenium:
>
R-help is not stack exchange, where people get "reputation" points for 
good answers,
and R-help often sees a lot of unhelpful and sometimes unkind answers.
So, when someone is exceptionally helpful, it is worthwhile 
acknowledging it
in public, as I do now, with my "Best of R-help" award to Bob Rudis.

Not only did he point me to RSelenium, but he wrote a complete solution
to the problem, and gave me the generated data on a github link.
It was slick, and I learned a lot from it.

best,
-Michael

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


	[[alternative HTML version deleted]]


From vito.muggeo at unipa.it  Wed May 11 15:45:09 2016
From: vito.muggeo at unipa.it (Vito M. R. Muggeo)
Date: Wed, 11 May 2016 15:45:09 +0200
Subject: [R] how to manipulate ... in the argument list
In-Reply-To: <CAAjnpdg3XrWjagscn7shX1TWm8TEY0=VcWvUy29j_ai_+NmdOA@mail.gmail.com>
References: <CAAjnpdg3XrWjagscn7shX1TWm8TEY0=VcWvUy29j_ai_+NmdOA@mail.gmail.com>
Message-ID: <57333765.2040806@unipa.it>

Hi Witold,
use do.call()

list.args<-list(...)

#modify 'list.args' (add/delete/modify)

do.call(image, list.args)

best,
vito


Il 11/05/2016 10.45, Witold E Wolski ha scritto:
> Hi,
>
> I am looking for a documentation describing how to manipulate the
> "..." . Searching R-intro.html gives to many not relevant hits for
> "..."
>
> What I want to do is something like this :
>
>
> image.2 <- function(x, col , ...){
>   # function is manipulating colors (adding a few)
>   # since it changes colors it needs to update breaks if defined.
>
>    breaks <- list(...)$breaks
>
>   if( !is.null( list(...)$breaks ) ){
>      #manipulate breaks
>
>     image(x, col, breaks = breaks ,...)
>
>    }else{
>       image(x,col ,...)
>    }
> }
>
> but in order to get it working I will need to remove breaks from ...
> since otherwise I am getting multiple defined argument for breaks.
>
> So how to manipulate the "..." argument? Or should I use a different pattern
>
> best
>
>
>

-- 
==============================================
Vito M.R. Muggeo
Dip.to Sc Statist e Matem `Vianelli'
Universit? di Palermo
viale delle Scienze, edificio 13
90128 Palermo - ITALY
tel: 091 23895240
fax: 091 485726
http://dssm.unipa.it/vmuggeo
Associate Editor, Statistical Modelling


From abichteler at toxstrategies.com  Wed May 11 18:09:23 2016
From: abichteler at toxstrategies.com (Anne Bichteler)
Date: Wed, 11 May 2016 16:09:23 +0000
Subject: [R] Quantiles on multiply imputed survey data - mitools
In-Reply-To: <CAOwvMDx+rrxz1BUFOFdgAHdBguPvsUpu2TF_3Vusun4bPS+SuQ@mail.gmail.com>
References: <F29237C5-CDD2-4215-B516-B37D066D0678@toxstrategies.com>
	<CAOwvMDx+rrxz1BUFOFdgAHdBguPvsUpu2TF_3Vusun4bPS+SuQ@mail.gmail.com>
Message-ID: <C37FA28B-FA49-45D8-9DD9-6E90426AABF1@toxstrategies.com>

Thanks for looking. No, for the quantiles it fails to instantiate the collection of designs correctly, whether hard-coding the variable name or using make.formula. 'with' passes make.formula correctly when calculating the mean, e.g. this works:

MIcombine( with(des, svymean(make.formula(get('var_name')))))

# Here's a reproducible example.

DF1 <- data.frame(SDMVPSU = c(1,1,1,1,1,2,2,2,2,2), 
                  SDMVSTRA = c(22, 20, 24, 18, 20, 22, 20, 24, 18, 20),
                  WTSPO2YR = c(252605, 82199, 24946, 147236, 3679, 294959, 65085, 21765, 197775, 49931),
                  LBXTCD = c(20.4, 29.7, 8.8, 18.0, 22.2, 10.4, 43.9, 15.3, 13.8, 84.5))

DF2 <- data.frame(SDMVPSU = c(1,1,1,1,1,2,2,2,2,2), 
                  SDMVSTRA = c(22, 20, 24, 18, 20, 22, 20, 24, 18, 20),
                  WTSPO2YR = c(252605, 82199, 24946, 147236, 3679, 294959, 65085, 21765, 197775, 49931),
                  LBXTCD = c(21.9, 29.7, 9.2, 5.9, 32.8, 8.9, 43.9, 7.4, 10.5, 84.5))

var_name <- "LBXTCD"

# Individually svyquantile (and svymean) work:
des_single1 <- svydesign(id=~SDMVPSU, strat=~SDMVSTRA, weight=~WTSPO2YR, data=Df1_red, nest=TRUE)
svyquantile(make.formula(get('var_name')), des_single1, c(.5), na.rm = FALSE)

des_single2 <- svydesign(id=~SDMVPSU, strat=~SDMVSTRA, weight=~WTSPO2YR, data=Df2_red, nest=TRUE)
svyquantile(make.formula(get('var_name')), des_single2, c(.5), na.rm = FALSE)

Imputed_list <- c()
Imputed_list[[1]] <- DF1
Imputed_list[[2]] <- DF2

# svymean works (so the svydesign object is fine?) but svyquantile doesn't:
des_mult <- svydesign(id=~SDMVPSU, strat=~SDMVSTRA, weight=~WTSPO2YR, data=imputationList(Imputed_list), nest=TRUE)
M_mean <- with(des_mult, svymean(make.formula(get('var_name'))))
summary(M_mean)
M_quantile <- with(des_mult, svyquantile(make.formula(get('var_name')), quantiles = c(.5)))
summary(M_quantile)


Thanks again,

Brennan

www.toxstrategies.com


From:  Anthony Damico <ajdamico at gmail.com>
Date:  Tuesday, May 10, 2016 at 10:37 PM
To:  Anne Bichteler <abichteler at toxstrategies.com>
Cc:  "r-help at r-project.org" <r-help at r-project.org>
Subject:  Re: [R] Quantiles on multiply imputed survey data - mitools


is the `with` not passing make.formula( get( 'var_name' ) ) through to svyquantile for some reason?  does this work?

MIcombine( with(des, svyquantile(~LBXTCD, .5)))



if that's not it, could you make a minimal reproducible example that includes the data download?  code to download and import nhanes here

https://github.com/ajdamico/asdfree/tree/master/National%20Health%20and%20Nutrition%20Examination%20Survey





On Tue, May 10, 2016 at 4:33 PM, Anne Bichteler 
<abichteler at toxstrategies.com> wrote:

Hello, and thank you for considering this question:

The svystat object created with multiply imputed NHANES data files is failing on calling survey::svyquantile. I'm wondering if I'm diagnosing the issue correctly, whether the behavior is expected, and whether y'all might have any ideas for workarounds.

I'm following T. Lumley's general method outlined here: 
http://faculty.washington.edu/tlumley/old-survey/svymi.html <http://faculty.washington.edu/tlumley/old-survey/svymi.html>, but with data files I've imputed myself on the 2001/2002 biennial. Each file has 1081 observations and no missing values.

### Create the survey design object with list of imputed data files ImputedList0102.
des <- svydesign(id=~SDMVPSU, strat=~SDMVSTRA, weight=~WTSPO2YR, data=imputationList(ImputedList0102), nest=TRUE)


### Blood analyte of interest
var_name <- "LBXTCD" # analyte in blood serum

### All is well calculating the mean:
M <- with(des, svymean(make.formula(get('var_name'))))
summary(M)
Result <- MIcombine(M)
Result$coefficients
# LBXTCD
# 17.41635


### but svystat object fails to calculate a 50th percentile:
### it fails when hard-coding the name rather than using make.formula;
### it fails regardless of number of files or choices in handling ties or interval type.
### There are 16 ties in each data file.
M1 <- with(des, svyquantile(make.formula(get('var_name')), quantiles = c(.5)))
summary(M1)

#     Length Class  Mode
#[1,] 1      -none- numeric
#[2,] 1      -none- numeric
#[3,] 1      -none- numeric


### The quantile is successfully calculated on one file at a time, however, and is different for each file.
### (had thought perhaps there was a lack-of-variance issue). The quantile calculated on each file
### is the same regardless of interval.type.
des_single1 <- svydesign(id=~SDMVPSU, strat=~SDMVSTRA, weight=~WTSPO2YR, data=ImputedList0102[[1]], nest=TRUE)
svyquantile(make.formula(get('var_name')), des_single1, c(.5))
# 0.5
# LBXTCD 13.5554


des_single2 <- svydesign(id=~SDMVPSU, strat=~SDMVSTRA, weight=~WTSPO2YR, data=ImputedList0102[[2]], nest=TRUE)
svyquantile(make.formula(get('var_name')), des_single2, c(.5))
# 0.5
# LBXTCD 14.06154

# The number of observations exceeding the 50th percentile differs for each file, which I can't claim to understand.

# I removed the 16 ties, but no help. Do the ties and/or different number of observations above/below prevent the svydesigns from being combined?
nrow(subset(ImputedList0102[[1]], LBXTCD > 13.5554))
# [1] 516
nrow(subset(ImputedList0102[[2]], LBXTCD > 14.06154))
# [1] 512


I'm hoping someone can point me to some gross error I'm making or another function parameter or data manipulation or another survey-savvy method altogether to calculate a 50th percentile across multiply imputed data files. Thanks for any advice,

Brennan

www.toxstrategies.com <http://www.toxstrategies.com>
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html <http://www.R-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.






From ajdamico at gmail.com  Wed May 11 18:17:08 2016
From: ajdamico at gmail.com (Anthony Damico)
Date: Wed, 11 May 2016 12:17:08 -0400
Subject: [R] Quantiles on multiply imputed survey data - mitools
In-Reply-To: <C37FA28B-FA49-45D8-9DD9-6E90426AABF1@toxstrategies.com>
References: <F29237C5-CDD2-4215-B516-B37D066D0678@toxstrategies.com>
	<CAOwvMDx+rrxz1BUFOFdgAHdBguPvsUpu2TF_3Vusun4bPS+SuQ@mail.gmail.com>
	<C37FA28B-FA49-45D8-9DD9-6E90426AABF1@toxstrategies.com>
Message-ID: <CAOwvMDymH4EUFYNuJYQwdnPp8L3U13xVeJxHVthnHRmDxvs6bQ@mail.gmail.com>

hi, you want   se=T

M_quantile <- with(des_mult, svyquantile(make.formula(get('var_name')),
quantiles = c(.5),se=T))
MIcombine(M_quantile)



Multiple imputation results:
      with(des_mult, svyquantile(make.formula(get("var_name")), quantiles =
c(0.5),
    se = T))
      MIcombine.default(M_quantile)
       results       se
LBXTCD 12.7978 6.917285






On Wed, May 11, 2016 at 12:09 PM, Anne Bichteler <
abichteler at toxstrategies.com> wrote:

> Thanks for looking. No, for the quantiles it fails to instantiate the
> collection of designs correctly, whether hard-coding the variable name or
> using make.formula. 'with' passes make.formula correctly when calculating
> the mean, e.g. this works:
>
> MIcombine( with(des, svymean(make.formula(get('var_name')))))
>
> # Here's a reproducible example.
>
> DF1 <- data.frame(SDMVPSU = c(1,1,1,1,1,2,2,2,2,2),
>                   SDMVSTRA = c(22, 20, 24, 18, 20, 22, 20, 24, 18, 20),
>                   WTSPO2YR = c(252605, 82199, 24946, 147236, 3679, 294959,
> 65085, 21765, 197775, 49931),
>                   LBXTCD = c(20.4, 29.7, 8.8, 18.0, 22.2, 10.4, 43.9,
> 15.3, 13.8, 84.5))
>
> DF2 <- data.frame(SDMVPSU = c(1,1,1,1,1,2,2,2,2,2),
>                   SDMVSTRA = c(22, 20, 24, 18, 20, 22, 20, 24, 18, 20),
>                   WTSPO2YR = c(252605, 82199, 24946, 147236, 3679, 294959,
> 65085, 21765, 197775, 49931),
>                   LBXTCD = c(21.9, 29.7, 9.2, 5.9, 32.8, 8.9, 43.9, 7.4,
> 10.5, 84.5))
>
> var_name <- "LBXTCD"
>
> # Individually svyquantile (and svymean) work:
> des_single1 <- svydesign(id=~SDMVPSU, strat=~SDMVSTRA, weight=~WTSPO2YR,
> data=Df1_red, nest=TRUE)
> svyquantile(make.formula(get('var_name')), des_single1, c(.5), na.rm =
> FALSE)
>
> des_single2 <- svydesign(id=~SDMVPSU, strat=~SDMVSTRA, weight=~WTSPO2YR,
> data=Df2_red, nest=TRUE)
> svyquantile(make.formula(get('var_name')), des_single2, c(.5), na.rm =
> FALSE)
>
> Imputed_list <- c()
> Imputed_list[[1]] <- DF1
> Imputed_list[[2]] <- DF2
>
> # svymean works (so the svydesign object is fine?) but svyquantile doesn't:
> des_mult <- svydesign(id=~SDMVPSU, strat=~SDMVSTRA, weight=~WTSPO2YR,
> data=imputationList(Imputed_list), nest=TRUE)
> M_mean <- with(des_mult, svymean(make.formula(get('var_name'))))
> summary(M_mean)
> M_quantile <- with(des_mult, svyquantile(make.formula(get('var_name')),
> quantiles = c(.5)))
> summary(M_quantile)
>
>
> Thanks again,
>
> Brennan
>
> www.toxstrategies.com
>
>
> From:  Anthony Damico <ajdamico at gmail.com>
> Date:  Tuesday, May 10, 2016 at 10:37 PM
> To:  Anne Bichteler <abichteler at toxstrategies.com>
> Cc:  "r-help at r-project.org" <r-help at r-project.org>
> Subject:  Re: [R] Quantiles on multiply imputed survey data - mitools
>
>
> is the `with` not passing make.formula( get( 'var_name' ) ) through to
> svyquantile for some reason?  does this work?
>
> MIcombine( with(des, svyquantile(~LBXTCD, .5)))
>
>
>
> if that's not it, could you make a minimal reproducible example that
> includes the data download?  code to download and import nhanes here
>
>
> https://github.com/ajdamico/asdfree/tree/master/National%20Health%20and%20Nutrition%20Examination%20Survey
>
>
>
>
>
> On Tue, May 10, 2016 at 4:33 PM, Anne Bichteler
> <abichteler at toxstrategies.com> wrote:
>
> Hello, and thank you for considering this question:
>
> The svystat object created with multiply imputed NHANES data files is
> failing on calling survey::svyquantile. I'm wondering if I'm diagnosing the
> issue correctly, whether the behavior is expected, and whether y'all might
> have any ideas for workarounds.
>
> I'm following T. Lumley's general method outlined here:
> http://faculty.washington.edu/tlumley/old-survey/svymi.html <
> http://faculty.washington.edu/tlumley/old-survey/svymi.html>, but with
> data files I've imputed myself on the 2001/2002 biennial. Each file has
> 1081 observations and no missing values.
>
> ### Create the survey design object with list of imputed data files
> ImputedList0102.
> des <- svydesign(id=~SDMVPSU, strat=~SDMVSTRA, weight=~WTSPO2YR,
> data=imputationList(ImputedList0102), nest=TRUE)
>
>
> ### Blood analyte of interest
> var_name <- "LBXTCD" # analyte in blood serum
>
> ### All is well calculating the mean:
> M <- with(des, svymean(make.formula(get('var_name'))))
> summary(M)
> Result <- MIcombine(M)
> Result$coefficients
> # LBXTCD
> # 17.41635
>
>
> ### but svystat object fails to calculate a 50th percentile:
> ### it fails when hard-coding the name rather than using make.formula;
> ### it fails regardless of number of files or choices in handling ties or
> interval type.
> ### There are 16 ties in each data file.
> M1 <- with(des, svyquantile(make.formula(get('var_name')), quantiles =
> c(.5)))
> summary(M1)
>
> #     Length Class  Mode
> #[1,] 1      -none- numeric
> #[2,] 1      -none- numeric
> #[3,] 1      -none- numeric
>
>
> ### The quantile is successfully calculated on one file at a time,
> however, and is different for each file.
> ### (had thought perhaps there was a lack-of-variance issue). The quantile
> calculated on each file
> ### is the same regardless of interval.type.
> des_single1 <- svydesign(id=~SDMVPSU, strat=~SDMVSTRA, weight=~WTSPO2YR,
> data=ImputedList0102[[1]], nest=TRUE)
> svyquantile(make.formula(get('var_name')), des_single1, c(.5))
> # 0.5
> # LBXTCD 13.5554
>
>
> des_single2 <- svydesign(id=~SDMVPSU, strat=~SDMVSTRA, weight=~WTSPO2YR,
> data=ImputedList0102[[2]], nest=TRUE)
> svyquantile(make.formula(get('var_name')), des_single2, c(.5))
> # 0.5
> # LBXTCD 14.06154
>
> # The number of observations exceeding the 50th percentile differs for
> each file, which I can't claim to understand.
>
> # I removed the 16 ties, but no help. Do the ties and/or different number
> of observations above/below prevent the svydesigns from being combined?
> nrow(subset(ImputedList0102[[1]], LBXTCD > 13.5554))
> # [1] 516
> nrow(subset(ImputedList0102[[2]], LBXTCD > 14.06154))
> # [1] 512
>
>
> I'm hoping someone can point me to some gross error I'm making or another
> function parameter or data manipulation or another survey-savvy method
> altogether to calculate a 50th percentile across multiply imputed data
> files. Thanks for any advice,
>
> Brennan
>
> www.toxstrategies.com <http://www.toxstrategies.com>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html <
> http://www.R-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From abichteler at toxstrategies.com  Wed May 11 18:30:47 2016
From: abichteler at toxstrategies.com (Anne Bichteler)
Date: Wed, 11 May 2016 16:30:47 +0000
Subject: [R] Quantiles on multiply imputed survey data - mitools
In-Reply-To: <CAOwvMDymH4EUFYNuJYQwdnPp8L3U13xVeJxHVthnHRmDxvs6bQ@mail.gmail.com>
References: <F29237C5-CDD2-4215-B516-B37D066D0678@toxstrategies.com>
	<CAOwvMDx+rrxz1BUFOFdgAHdBguPvsUpu2TF_3Vusun4bPS+SuQ@mail.gmail.com>
	<C37FA28B-FA49-45D8-9DD9-6E90426AABF1@toxstrategies.com>
	<CAOwvMDymH4EUFYNuJYQwdnPp8L3U13xVeJxHVthnHRmDxvs6bQ@mail.gmail.com>
Message-ID: <4A5DE2DA-221D-4A9E-8FBE-A6D72EFD0DF4@toxstrategies.com>

Thanks so SO much.

Brennan

www.toxstrategies.com




From:  Anthony Damico <ajdamico at gmail.com>
Date:  Wednesday, May 11, 2016 at 11:17 AM
To:  Anne Bichteler <abichteler at toxstrategies.com>
Cc:  "r-help at r-project.org" <r-help at r-project.org>
Subject:  Re: [R] Quantiles on multiply imputed survey data - mitools


hi, you want   se=T

M_quantile <- with(des_mult, svyquantile(make.formula(get('var_name')), quantiles = c(.5),se=T))
MIcombine(M_quantile)



Multiple imputation results:
      with(des_mult, svyquantile(make.formula(get("var_name")), quantiles = c(0.5),

    se = T))
      MIcombine.default(M_quantile)
       results       se
LBXTCD 12.7978 6.917285








On Wed, May 11, 2016 at 12:09 PM, Anne Bichteler 
<abichteler at toxstrategies.com> wrote:

Thanks for looking. No, for the quantiles it fails to instantiate the collection of designs correctly, whether hard-coding the variable name or using make.formula. 'with' passes make.formula correctly when calculating the mean, e.g. this works:

MIcombine( with(des, svymean(make.formula(get('var_name')))))

# Here's a reproducible example.

DF1 <- data.frame(SDMVPSU = c(1,1,1,1,1,2,2,2,2,2),
                  SDMVSTRA = c(22, 20, 24, 18, 20, 22, 20, 24, 18, 20),
                  WTSPO2YR = c(252605, 82199, 24946, 147236, 3679, 294959, 65085, 21765, 197775, 49931),
                  LBXTCD = c(20.4, 29.7, 8.8, 18.0, 22.2, 10.4, 43.9, 15.3, 13.8, 84.5))

DF2 <- data.frame(SDMVPSU = c(1,1,1,1,1,2,2,2,2,2),
                  SDMVSTRA = c(22, 20, 24, 18, 20, 22, 20, 24, 18, 20),
                  WTSPO2YR = c(252605, 82199, 24946, 147236, 3679, 294959, 65085, 21765, 197775, 49931),
                  LBXTCD = c(21.9, 29.7, 9.2, 5.9, 32.8, 8.9, 43.9, 7.4, 10.5, 84.5))

var_name <- "LBXTCD"

# Individually svyquantile (and svymean) work:
des_single1 <- svydesign(id=~SDMVPSU, strat=~SDMVSTRA, weight=~WTSPO2YR, data=Df1_red, nest=TRUE)
svyquantile(make.formula(get('var_name')), des_single1, c(.5), na.rm = FALSE)

des_single2 <- svydesign(id=~SDMVPSU, strat=~SDMVSTRA, weight=~WTSPO2YR, data=Df2_red, nest=TRUE)
svyquantile(make.formula(get('var_name')), des_single2, c(.5), na.rm = FALSE)

Imputed_list <- c()
Imputed_list[[1]] <- DF1
Imputed_list[[2]] <- DF2

# svymean works (so the svydesign object is fine?) but svyquantile doesn't:
des_mult <- svydesign(id=~SDMVPSU, strat=~SDMVSTRA, weight=~WTSPO2YR, data=imputationList(Imputed_list), nest=TRUE)
M_mean <- with(des_mult, svymean(make.formula(get('var_name'))))
summary(M_mean)
M_quantile <- with(des_mult, svyquantile(make.formula(get('var_name')), quantiles = c(.5)))
summary(M_quantile)


Thanks again,

Brennan

www.toxstrategies.com <http://www.toxstrategies.com>


From:  Anthony Damico <ajdamico at gmail.com>
Date:  Tuesday, May 10, 2016 at 10:37 PM
To:  Anne Bichteler <abichteler at toxstrategies.com>
Cc:  "r-help at r-project.org" <r-help at r-project.org>
Subject:  Re: [R] Quantiles on multiply imputed survey data - mitools


is the `with` not passing make.formula( get( 'var_name' ) ) through to svyquantile for some reason?  does this work?

MIcombine( with(des, svyquantile(~LBXTCD, .5)))



if that's not it, could you make a minimal reproducible example that includes the data download?  code to download and import nhanes here

https://github.com/ajdamico/asdfree/tree/master/National%20Health%20and%20Nutrition%20Examination%20Survey





On Tue, May 10, 2016 at 4:33 PM, Anne Bichteler
<abichteler at toxstrategies.com> wrote:

Hello, and thank you for considering this question:

The svystat object created with multiply imputed NHANES data files is failing on calling survey::svyquantile. I'm wondering if I'm diagnosing the issue correctly, whether the behavior is expected, and whether y'all might have any ideas for workarounds.

I'm following T. Lumley's general method outlined here:
http://faculty.washington.edu/tlumley/old-survey/svymi.html <http://faculty.washington.edu/tlumley/old-survey/svymi.html>,
 but with data files I've imputed myself on the 2001/2002 biennial. Each file has 1081 observations and no missing values.

### Create the survey design object with list of imputed data files ImputedList0102.
des <- svydesign(id=~SDMVPSU, strat=~SDMVSTRA, weight=~WTSPO2YR, data=imputationList(ImputedList0102), nest=TRUE)


### Blood analyte of interest
var_name <- "LBXTCD" # analyte in blood serum

### All is well calculating the mean:
M <- with(des, svymean(make.formula(get('var_name'))))
summary(M)
Result <- MIcombine(M)
Result$coefficients
# LBXTCD
# 17.41635


### but svystat object fails to calculate a 50th percentile:
### it fails when hard-coding the name rather than using make.formula;
### it fails regardless of number of files or choices in handling ties or interval type.
### There are 16 ties in each data file.
M1 <- with(des, svyquantile(make.formula(get('var_name')), quantiles = c(.5)))
summary(M1)

#     Length Class  Mode
#[1,] 1      -none- numeric
#[2,] 1      -none- numeric
#[3,] 1      -none- numeric


### The quantile is successfully calculated on one file at a time, however, and is different for each file.
### (had thought perhaps there was a lack-of-variance issue). The quantile calculated on each file
### is the same regardless of interval.type.
des_single1 <- svydesign(id=~SDMVPSU, strat=~SDMVSTRA, weight=~WTSPO2YR, data=ImputedList0102[[1]], nest=TRUE)
svyquantile(make.formula(get('var_name')), des_single1, c(.5))
# 0.5
# LBXTCD 13.5554


des_single2 <- svydesign(id=~SDMVPSU, strat=~SDMVSTRA, weight=~WTSPO2YR, data=ImputedList0102[[2]], nest=TRUE)
svyquantile(make.formula(get('var_name')), des_single2, c(.5))
# 0.5
# LBXTCD 14.06154

# The number of observations exceeding the 50th percentile differs for each file, which I can't claim to understand.

# I removed the 16 ties, but no help. Do the ties and/or different number of observations above/below prevent the svydesigns from being combined?
nrow(subset(ImputedList0102[[1]], LBXTCD > 13.5554))
# [1] 516
nrow(subset(ImputedList0102[[2]], LBXTCD > 14.06154))
# [1] 512


I'm hoping someone can point me to some gross error I'm making or another function parameter or data manipulation or another survey-savvy method altogether to calculate a 50th percentile across multiply imputed data files. Thanks for any advice,

Brennan



www.toxstrategies.com <http://www.toxstrategies.com> <http://www.toxstrategies.com>
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html <http://www.R-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.













From G.Maubach at weinwolf.de  Wed May 11 18:45:39 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Wed, 11 May 2016 18:45:39 +0200
Subject: [R] Antwort: Re: Re:  Antwort: Re: Re: sink(): Cannot open file
In-Reply-To: <CAM_vjukqpe_wUvsycbGM-4_CAGeG2Qu+bkvQe=53hkSN+zQt9A@mail.gmail.com>
References: <OF15A2364C.38B38E20-ONC1257FAF.00287156-C1257FAF.0028D3F1@lotus.hawesko.de>
	<CA+8X3fWKAJysbwP+whoDrSnT8W3njAUq5LwmjTp3qq-AOdanzg@mail.gmail.com>	<OF680609C9.B98EF9B5-ONC1257FAF.003C5B6B-C1257FAF.003CF31F@lotus.hawesko.de>
	<CA+8X3fV=Cc8n0WBk6JjobbHm0E+R4ss+7is233o9HYVwGaiQ8Q@mail.gmail.com>	<OFF8B5EC26.08CB1CFC-ONC1257FAF.00526FBA-C1257FAF.0052DAB9@lotus.hawesko.de>
	<CAM_vjukn65HMyvUVWcNATyb660xPa-GYkxJV81_witEFxeFHhQ@mail.gmail.com>	<OFB1F950C2.FF819EF7-ONC1257FAF.005A9AE4-C1257FAF.005B0ACB@lotus.hawesko.de>
	<CAM_vjukqpe_wUvsycbGM-4_CAGeG2Qu+bkvQe=53hkSN+zQt9A@mail.gmail.com>
Message-ID: <OFE75E365B.FBDCB581-ONC1257FB0.005B5E6B-C1257FB0.005C1243@lotus.hawesko.de>

Hi Sarah,

yes, I followed your suggestion.

If I do exactly what is in the example of the documentation:

sink("C:/Temp/sink-examp.txt")
i <- 1:10
outer(i, i, "*")
sink()
unlink("C:/Temp/sink-examp.txt")

it does not write anything, i. e. no file is created in "C:/Temp/". The 
script is executed without an error or warning message.

If I run

## capture all the output to a file.
zz <- file("C:/Temp/all.Rout", open = "wt")
sink(zz)
sink(zz, type = "message")
try(log("a"))
## back to the console
sink(type = "message")  # I think ,this was your suggestion
sink()
unlink("C:/Temp/all.Rout")

the script is executed without error or warning message, the file is 
created in "C:/Temp/" but if I try to open it right away after the script 
is done the message

DE: "Auf das Dokument "C:\Temp\all.Rout" kann nicht zugegriffen werden, da 
es von einer anderen Anwendung verwendet wird."
EN: "Cannot access the document "C:\Temp\all.Rout" cause it is used by 
another application."

What do I do wrong?

Kind regards

Georg




Von:    Sarah Goslee <sarah.goslee at gmail.com>
An:     G.Maubach at weinwolf.de, 
Datum:  10.05.2016 18:46
Betreff:        Re: Re: [R] Antwort: Re: Re: sink(): Cannot open file



On Tue, May 10, 2016 at 12:34 PM,  <G.Maubach at weinwolf.de> wrote:
> sink(type = "message")


But did you do that ^^ as I suggested?


If you start a message sink with
sink(zz, type="message")
as you did, you need to explicitly close that stream. Just using
sink()
doesn't do it.


From G.Maubach at weinwolf.de  Wed May 11 18:47:18 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Wed, 11 May 2016 18:47:18 +0200
Subject: [R] Antwort: Re:  Antwort: Re: Re: sink(): Cannot open file
In-Reply-To: <5732149A.7080203@gmail.com>
References: <OF15A2364C.38B38E20-ONC1257FAF.00287156-C1257FAF.0028D3F1@lotus.hawesko.de>
	<CA+8X3fWKAJysbwP+whoDrSnT8W3njAUq5LwmjTp3qq-AOdanzg@mail.gmail.com>
	<OF680609C9.B98EF9B5-ONC1257FAF.003C5B6B-C1257FAF.003CF31F@lotus.hawesko.de>
	<CA+8X3fV=Cc8n0WBk6JjobbHm0E+R4ss+7is233o9HYVwGaiQ8Q@mail.gmail.com>
	<OFF8B5EC26.08CB1CFC-ONC1257FAF.00526FBA-C1257FAF.0052DAB9@lotus.hawesko.de>
	<5731C2BC020000CB001536F4@smtp.medicine.umaryland.edu>
	<5732149A.7080203@gmail.com>
Message-ID: <OFBC7434F2.0E57B1FE-ONC1257FB0.005C1753-C1257FB0.005C38DA@lotus.hawesko.de>

Duncan,

thanks for the hint.

I have done it correctly in R fashion

## capture all the output to a file.
zz <- file("C:/Temp/all.Rout", open = "wt")
sink(zz)
sink(zz, type = "message")
try(log("a"))
## back to the console
sink(type = "message")
sink()
unlink("C:/Temp/all.Rout")

But the error persits.

Kind regards

Georg




Von:    Duncan Murdoch <murdoch.duncan at gmail.com>
An:     John Sorkin <jsorkin at grecc.umaryland.edu>, drjimlemon at gmail.com, 
G.Maubach at weinwolf.de, 
Kopie:  r-help at r-project.org
Datum:  10.05.2016 19:03
Betreff:        Re: [R] Antwort: Re: Re: sink(): Cannot open file



On 10/05/2016 11:15 AM, John Sorkin wrote:
> George,
> I do not know what operating system you are working with, but when I use 
sink() under windows, I need to specify a valid path which I don't see in 
your code. I might, for example specify:
>
> sink("c:\myfile.txt")

Note that the backslash should be doubled (so it isn't interpreted as an 
escape for the "m" that follows it), or replaced with a forward slash.

Duncan Murdoch

>   R code goes here
> sink()
>
> with the expectation that I would create a file myfile.txt that would 
contain the output of my R program.
> 
> John
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and 
Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> >>> <G.Maubach at weinwolf.de> 05/10/16 11:10 AM >>>
> Hi Jim,
>
> I tried:
>
> sink("all.Rout")
> try(log("a"))
> sink()
>
> The program executes without warning or error. The file "all.Rout" is
> begin created. Nothing will be written to it. The file is accessable
> rights after the execution of the program by notepad.exe.
>
> The program
>
> zz <- file("all.Rout", open = "wt")
> sink(zz, type = "message")
> try(log("a"))
> sink()
> close(zz)
> unlink(zz)
>
> creates the file, does not write anything to it and is not accessable
> after program execution in R with notepad.exe.
>
> Any ideas what happens behind the szenes?
>
> Kind regards
>
> Georg
>
>
>
>
> Von: Jim Lemon <drjimlemon at gmail.com>
> An: G.Maubach at weinwolf.de,
> Kopie: r-help mailing list <r-help at r-project.org>
> Datum: 10.05.2016 13:16
> Betreff: Re: Re: [R] sink(): Cannot open file
>
>
>
> Have you tried:
>
> sink("all.Rout")
> try(log("a"))
> sink()
>
> Jim
>
> On Tue, May 10, 2016 at 9:05 PM, <G.Maubach at weinwolf.de> wrote:
> > Hi Jim,
> >
> > thanks for your reply.
> >
> > ad 1)
> > "all.Rout" was created in the correct directory. It exists properly 
with
> > correct file properties on Windows, e.g. creation date and time and 
file
> > size information.
> >
> > ad 2)
> > I can not access the file with Notepad.exe directly after it was 
created
> > by R. The error message is (translated):
> >
> > "Cannot access file "all.Rout". The file is opened by another 
process."
> >
> > ad 3)
> > If I close R completely the file access is released. Then I can read 
the
> > file using Notepad.exe. The contents is:
> >
> > Error in log("a") : non-numeric argument to mathematical function
> >
> > I tried
> >
> > close(zz)
> >
> > but the error persists.
> >
> > To me it looks like R is still accessing the file and not releasing 
the
> > connection for other programs. close(zz) should have solved the 
problem
> > but unfortantely it doesn't.
> >
> > What else could I try?
> >
> > Kind regards
> >
> > Georg
> >
> >
> >
> >
> > Von: Jim Lemon <drjimlemon at gmail.com>
> > An: G.Maubach at weinwolf.de,
> > Kopie: r-help mailing list <r-help at r-project.org>
> > Datum: 10.05.2016 12:50
> > Betreff: Re: [R] sink(): Cannot open file
> >
> >
> >
> > Hi Georg,
> > I don't suppose that you have:
> >
> > 1) checked that the file "all.Rout" exists somewhere?
> >
> > 2) if so, looked at the file with Notepad, perhaps?
> >
> > 3) let us in on the secret by pasting the contents of "all.Rout" into
> > your message if it is not too big?
> >
> > At a guess, trying:
> >
> > close(zz)
> >
> > might get you there.
> >
> > Jim
> >
> > On Tue, May 10, 2016 at 5:25 PM, <G.Maubach at weinwolf.de> wrote:
> >> Hi All,
> >>
> >> I would like to route the output to a file using sink(). When using 
the
> >> example from the ?sink documentation:
> >>
> >> sink("sink-examp.txt")
> >> i <- 1:10
> >> outer(i, i, "*")
> >> sink()
> >> unlink("sink-examp.txt")
> >>
> >> ## capture all the output to a file.
> >> zz <- file("all.Rout", open = "wt")
> >> sink(zz)
> >> sink(zz, type = "message")
> >> try(log("a"))
> >> ## back to the console
> >> sink(type = "message")
> >> sink()
> >> file.show("all.Rout")
> >>
> >> I can not open the file in Windows Explorer. The error message is:
> >>
> >> "Cannot open file. File is in use be another proces."
> >>
> >> How can I close the file in a manner that I can open it right after 
it
> > was
> >> created?
> >>
> >> Kind regards
> >>
> >> Georg
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:14}}


From Dominik.Schneider at colorado.edu  Wed May 11 18:11:17 2016
From: Dominik.Schneider at colorado.edu (Dominik Schneider)
Date: Wed, 11 May 2016 10:11:17 -0600
Subject: [R] physical constraint with gam
In-Reply-To: <5732F730.9000800@bath.edu>
References: <CAF1jk_=312-4GEwpeJM2UaOojnSE_6PxLo6YU2ysjGdHKBt3UQ@mail.gmail.com>
	<5732F730.9000800@bath.edu>
Message-ID: <CAF1jk_=Yk6ruWTyDZ_aZnDTAmSZi6=7eSM5CoL0x=jF=JVqm4w@mail.gmail.com>

Hi Simon, Thanks for this explanation.
To make sure I understand, another way of explaining the y axis in my
original example is that it is the contribution to snowdepth relative to
the other variables (the example only had fsca, but my actual case has a
couple others). i.e. a negative s(fsca) of -0.5 simply means snowdepth 0.5
units below the intercept+s(x_i), where s(x_i) could also be negative in
the case where total snowdepth is less than the intercept value.

The use of by=fsca is really useful for interpreting the marginal impact of
the different variables. With my actual data, the term s(fsca):fsca is
never negative, which is much more intuitive. Is it appropriate to compare
magnitudes of e.g. s(x2):x2 / mean(x2) and s(x2):x2 / mean(x2)  where
mean(x_i) are the mean of the actual data?

Lastly, how would these two differ: s(x1,by=x2); or s(x1,by=x1)*s(x2,by=x2)
since interactions are surely present and i'm not sure if a linear
combination is enough.

Thanks!
Dominik


On Wed, May 11, 2016 at 3:11 AM, Simon Wood <simon.wood at bath.edu> wrote:

> The spline having a positive value is not the same as a glm coefficient
> having a positive value. When you plot a smooth, say s(x), that is
> equivalent to plotting the line 'beta * x' in a GLM. It is not equivalent
> to plotting 'beta'. The smooths in a gam are (usually) subject to
> `sum-to-zero' identifiability constraints to avoid confounding via the
> intercept, so they are bound to be negative over some part of the covariate
> range. For example, if I have a model y ~ s(x) + s(z), I can't estimate the
> mean level for s(x) and the mean level for s(z) as they are completely
> confounded, and confounded with the model intercept term.
>
> I suppose that if you want to interpret the smooths as glm parameters
> varying with the covariate they relate to then you can do, by setting the
> model up as a varying coefficient model, using the `by' argument to 's'...
>
> gam(snowdepth~s(fsca,by=fsca),data=dat)
>
>
> this model is `snowdepth_i = f(fsca_i) * fsca_i + e_i' . s(fsca,by=fsca)
> is not confounded with the intercept, so no constraint is needed or
> applied, and you can now interpret the smooth like a local GLM coefficient.
>
> best,
> Simon
>
>
>
>
> On 11/05/16 01:30, Dominik Schneider wrote:
>
>> Hi,
>> Just getting into using GAM using the mgcv package. I've generated some
>> models and extracted the splines for each of the variables and started
>> visualizing them. I'm noticing that one of my variables is physically
>> unrealistic.
>>
>> In the example below, my interpretation of the following plot is that the
>> y-axis is basically the equivalent of a "parameter" value of a GLM; in GAM
>> this value can change as the functional relationship changes between x and
>> y. In my case, I am predicting snowdepth based on the fractional snow
>> covered area. In no case will snowdepth realistically decrease for a unit
>> increase in fsca so my question is: *Is there a way to constrain the
>> spline
>> to positive values? *
>>
>> Thanks
>> Dominik
>>
>> library(mgcv)
>> library(dplyr)
>> library(ggplot2)
>> extract_splines=function(mdl){
>>    sterms=predict(mdl,type='terms')
>>    datplot=cbind(sterms,mdl$model) %>% tbl_df
>>    datplot$intercept=attr(sterms,'constant')
>>    datplot$yhat=rowSums(sterms)+attr(sterms,'constant')
>>    return(datplot)
>> }
>> dat=data_frame(snowdepth=runif(100,min =
>> 0.001,max=6.7),fsca=runif(100,0.01,.99))
>> mdl=gam(snowdepth~s(fsca),data=dat)
>> termdF=extract_splines(mdl)
>> ggplot(termdF)+
>>    geom_line(aes(x=fsca,y=`s(fsca)`))
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> --
> Simon Wood, School of Mathematics, University of Bristol BS8 1TW UK
> +44 (0)117 33 18273     http://www.maths.bris.ac.uk/~sw15190
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed May 11 19:48:23 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 11 May 2016 10:48:23 -0700
Subject: [R] web scraping tables generated in multiple server pages
In-Reply-To: <CAJ4QxaPmGG3mOMV-27JCK+BR_c9GUZu8fnZmN_XRp6=FnYgYOg@mail.gmail.com>
References: <ff65b860-65aa-35b0-546b-646380e7ec37@yorku.ca>
	<CAJ4QxaPmGG3mOMV-27JCK+BR_c9GUZu8fnZmN_XRp6=FnYgYOg@mail.gmail.com>
Message-ID: <657EFDF4-4B42-4ABA-9E0A-DAD22FEF0551@comcast.net>


> On May 10, 2016, at 1:11 PM, boB Rudis <bob at rudis.net> wrote:
> 
> Unfortunately, it's a wretched, vile, SharePoint-based site. That
> means it doesn't use traditional encoding methods to do the pagination
> and one of the only ways to do this effectively is going to be to use
> RSelenium:
> 
>    library(RSelenium)
>    library(rvest)
>    library(dplyr)
>    library(pbapply)
> 
>    URL <- "http://outorgaonerosa.prefeitura.sp.gov.br/relatorios/RelSituacaoGeralProcessos.aspx"
> 
>    checkForServer()
>    startServer()
>    remDr <- remoteDriver$new()
>    remDr$open()

Thanks Bob/hrbrmstr;

At this point I got an error:

>    startServer()
>    remDr <- remoteDriver$new()
>    remDr$open()
[1] "Connecting to remote server"
Undefined error in RCurl call.Error in queryRD(paste0(serverURL, "/session"), "POST", qdata = toJSON(serverOpts)) : 

Running R 3.0.0 on a Mac (El Cap) in the R.app GUI. 
$ java -version
java version "1.8.0_65"
Java(TM) SE Runtime Environment (build 1.8.0_65-b17)
Java HotSpot(TM) 64-Bit Server VM (build 25.65-b01, mixed mode)

I asked myself: What additional information is needed to debug this? But then I thought I had a responsibility to search for earlier reports of this error on a Mac, and there were many. After reading this thread: https://github.com/ropensci/RSelenium/issues/54  I decided to try creating an "alias", mac-speak for a symlink, and put that symlink in my working directory (with no further chmod security efforts). I restarted R and re-ran the code which opened a Firefox browser window and then proceeded to page through many pages. Eventually, however it errors out with this message:

>    pblapply(1:69, function(i) {
+ 
+      if (i %in% seq(1, 69, 10)) {
+        pg <- read_html(remDr$getPageSource()[[1]])
+        ret <- html_table(html_nodes(pg, "table")[[3]], header=TRUE)
+ 
+      } else {
+        ref <- remDr$findElements("xpath",
+ sprintf(".//a[contains(@href, 'javascript:__doPostBack') and .='%s']",
+ i))
+        ref[[1]]$clickElement()
+        pg <- read_html(remDr$getPageSource()[[1]])
+        ret <- html_table(html_nodes(pg, "table")[[3]], header=TRUE)
+ 
+      }
+      if ((i %% 10) == 0) {
+        ref <- remDr$findElements("xpath", ".//a[.='...']")
+        ref[[length(ref)]]$clickElement()
+      }
+ 
+      ret
+ 
+    }) -> tabs
   |+++++++++++                                       | 22% ~54s          Error in html_nodes(pg, "table")[[3]] : subscript out of bounds
> 
>    final_dat <- bind_rows(tabs)
Error in bind_rows(tabs) : object 'tabs' not found


There doesn't seem to be any trace of objects from all the downloading efforts that I could find. When I changed both instances of '69' to '30' it no longer errors out. Is there supposed to be an initial step of finding out how many pages are actually there befor setting the two iteration limits? I'm wondering if that code could be modified to return some intermediate values that would be amenable to further assembly efforts in the event of errors?

Sincerely;
David.


>    remDr$navigate(URL)
> 
>    pblapply(1:69, function(i) {
> 
>      if (i %in% seq(1, 69, 10)) {
> 
>        # the first item on the page is not a link but we can just grab the page
> 
>        pg <- read_html(remDr$getPageSource()[[1]])
>        ret <- html_table(html_nodes(pg, "table")[[3]], header=TRUE)
> 
>      } else {
> 
>        # we can get the rest of them by the link text directly
> 
>        ref <- remDr$findElements("xpath",
> sprintf(".//a[contains(@href, 'javascript:__doPostBack') and .='%s']",
> i))
>        ref[[1]]$clickElement()
>        pg <- read_html(remDr$getPageSource()[[1]])
>        ret <- html_table(html_nodes(pg, "table")[[3]], header=TRUE)
> 
>      }
> 
>      # we have to move to the next actual page of data after every 10 links
> 
>      if ((i %% 10) == 0) {
>        ref <- remDr$findElements("xpath", ".//a[.='...']")
>        ref[[length(ref)]]$clickElement()
>      }
> 
>      ret
> 
>    }) -> tabs
> 
>    final_dat <- bind_rows(tabs)
>    final_dat <- final_dat[, c(1, 2, 5, 7, 8, 13, 14)] # the cols you want
>    final_dat <- final_dat[complete.cases(final_dat),] # take care of NAs
> 
>    remDr$quit()
> 
> 
> Prbly good ref code to have around, but you can grab the data & code
> here: https://gist.github.com/hrbrmstr/ec35ebb32c3cf0aba95f7bad28df1e98
> 
> (anything to help a fellow parent out :-)
> 
> -Bob
> 
> On Tue, May 10, 2016 at 2:45 PM, Michael Friendly <friendly at yorku.ca> wrote:
>> This is my first attempt to try R web scraping tools, for a project my
>> daughter is working on.  It concerns a data base of projects in Sao
>> Paulo, Brazil, listed at
>> http://outorgaonerosa.prefeitura.sp.gov.br/relatorios/RelSituacaoGeralProcessos.aspx,
>> but spread out over 69 pages accessed through a javascript menu at the
>> bottom of the page.
>> 
>> Each web page contains 3 HTML tables, of which only the last contains
>> the relevant data.  In this, only a subset of columns are of interest.
>> I tried using the XML package as illustrated on several tutorial pages,
>> as shown below.  I have no idea how to automate this to extract these
>> tables from multiple web pages.  Is there some other package better
>> suited to this task?  Can someone help me solve this and other issues?
>> 
>> # Goal: read the data tables contained on 69 pages generated by the link
>> below, where
>> # each page is generated by a javascript link in the menu of the bottom
>> of the page.
>> #
>> # Each "page" contains 3 html tables, with names "Table 1", "Table 2",
>> and the only one
>> # of interest with the data, "grdRelSitGeralProcessos"
>> #
>> # From each such table, extract the following columns:
>> #- Processo
>> #- Endere?o
>> #- Distrito
>> #- Area terreno (m2)
>> #- Valor contrapartida ($)
>> #- Area excedente (m2)
>> 
>> # NB: All of the numeric fields use "." as comma-separator and "," as
>> the decimal separator,
>> #   but because of this are read in as character
>> 
>> 
>> library(XML)
>> link <-
>> "http://outorgaonerosa.prefeitura.sp.gov.br/relatorios/RelSituacaoGeralProcessos.aspx"
>> 
>> saopaulo <- htmlParse(link)
>> saopaulo.tables <- readHTMLTable(saopaulo, stringsAsFactors = FALSE)
>> length(saopaulo.tables)
>> 
>> # its the third table on this page we want
>> sp.tab <- saopaulo.tables[[3]]
>> 
>> # columns wanted
>> wanted <- c(1, 2, 5, 7, 8, 13, 14)
>> head(sp.tab[, wanted])
>> 
>>> head(sp.tab[, wanted])
>>   Proposta Processo Endere??o        Distrito
>> 1        1 2002-0.148.242-4 R. DOMINGOS LOPES DA SILVA X R. CORN??LIO
>> VAN CLEVE    VILA ANDRADE
>> 2        2 2003-0.129.667-3                      AV. DR. JOS?? HIGINO,
>> 200 E 216       AGUA RASA
>> 3        3 2003-0.065.011-2                       R. ALIAN??A LIBERAL,
>> 980 E 990 VILA LEOPOLDINA
>> 4        4 2003-0.165.806-0                       R. ALIAN??A LIBERAL,
>> 880 E 886 VILA LEOPOLDINA
>> 5        5 2003-0.139.053-0                R. DR. JOS?? DE ANDRADE
>> FIGUEIRA, 111    VILA ANDRADE
>> 6        6 2003-0.200.692-0                                R. JOS?? DE
>> JESUS, 66      VILA SONIA
>>   ? rea Terreno (m2) ? rea Excedente (m2) Valor Contrapartida (R$)
>> 1               0,00             1.551,14 127.875,98
>> 2               0,00             3.552,13 267.075,77
>> 3               0,00               624,99 70.212,93
>> 4               0,00               395,64 44.447,18
>> 5               0,00               719,68 41.764,46
>> 6               0,00               446,52 85.152,92
>> 
>> thanks,
>> 
>> 
>> --
>> Michael Friendly     Email: friendly AT yorku DOT ca
>> Professor, Psychology Dept. & Chair, Quantitative Methods
>> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
>> 4700 Keele Street    Web:http://www.datavis.ca
>> Toronto, ONT  M3J 1P3 CANADA
>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bob at rudis.net  Wed May 11 20:00:43 2016
From: bob at rudis.net (boB Rudis)
Date: Wed, 11 May 2016 14:00:43 -0400
Subject: [R] web scraping tables generated in multiple server pages
In-Reply-To: <657EFDF4-4B42-4ABA-9E0A-DAD22FEF0551@comcast.net>
References: <ff65b860-65aa-35b0-546b-646380e7ec37@yorku.ca>
	<CAJ4QxaPmGG3mOMV-27JCK+BR_c9GUZu8fnZmN_XRp6=FnYgYOg@mail.gmail.com>
	<657EFDF4-4B42-4ABA-9E0A-DAD22FEF0551@comcast.net>
Message-ID: <CAJ4QxaNm07Z85v0RVHQQuMXYhoAyN09eZjEg4xOWr3vN3f_6hQ@mail.gmail.com>

Hey David,

I'm on a Mac as well but have never had to tweak anything to get
[R]Selenium to work (but this is one reason I try to avoid solutions
involving RSelenium as they are pretty fragile IMO).

The site itself has "P?gina 1 de 69" at the top which is where i got
the "69" from and I just re-ran the code in a 100% clean env (on a
completely different Mac) and it worked fine.

I did neglect to put my session info up before (apologies):

    Session info
------------------------------------------------------------------------------------
     setting  value
     version  R version 3.3.0 RC (2016-05-01 r70572)
     system   x86_64, darwin13.4.0
     ui       RStudio (0.99.1172)
     language (EN)
     collate  en_US.UTF-8
     tz       America/New_York
     date     2016-05-11

    Packages ----------------------------------------------------------------------------------------
     package    * version  date       source
     assertthat   0.1      2013-12-06 CRAN (R 3.3.0)
     bitops     * 1.0-6    2013-08-17 CRAN (R 3.3.0)
     caTools      1.17.1   2014-09-10 CRAN (R 3.3.0)
     DBI          0.4      2016-05-02 CRAN (R 3.3.0)
     devtools   * 1.11.1   2016-04-21 CRAN (R 3.3.0)
     digest       0.6.9    2016-01-08 CRAN (R 3.3.0)
     dplyr      * 0.4.3    2015-09-01 CRAN (R 3.3.0)
     httr         1.1.0    2016-01-28 CRAN (R 3.3.0)
     magrittr     1.5      2014-11-22 CRAN (R 3.3.0)
     memoise      1.0.0    2016-01-29 CRAN (R 3.3.0)
     pbapply    * 1.2-1    2016-04-19 CRAN (R 3.3.0)
     R6           2.1.2    2016-01-26 CRAN (R 3.3.0)
     Rcpp         0.12.4   2016-03-26 CRAN (R 3.3.0)
     RCurl      * 1.95-4.8 2016-03-01 CRAN (R 3.3.0)
     RJSONIO    * 1.3-0    2014-07-28 CRAN (R 3.3.0)
     RSelenium  * 1.3.5    2014-10-26 CRAN (R 3.3.0)
     rvest      * 0.3.1    2015-11-11 CRAN (R 3.3.0)
     selectr      0.2-3    2014-12-24 CRAN (R 3.3.0)
     stringi      1.0-1    2015-10-22 CRAN (R 3.3.0)
     stringr      1.0.0    2015-04-30 CRAN (R 3.3.0)
     withr        1.0.1    2016-02-04 CRAN (R 3.3.0)
     XML        * 3.98-1.4 2016-03-01 CRAN (R 3.3.0)
     xml2       * 0.1.2    2015-09-01 CRAN (R 3.3.0)

(and, wow, does that tiny snippet of code end up using alot of pkgs)

I had actually started with smaller snippets to test. The code got
uglier due to the way the site paginates (it loads 10-entries worth of
data on to a single page but requires a server call for the next 10).

I also keep firefox scarily out-of-date (back in the 33's rev) b/c I
only use it with RSelenium (not a big fan of the browser). Let me
update to the 46-series and see if I can replicate.

-Bob

On Wed, May 11, 2016 at 1:48 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On May 10, 2016, at 1:11 PM, boB Rudis <bob at rudis.net> wrote:
>>
>> Unfortunately, it's a wretched, vile, SharePoint-based site. That
>> means it doesn't use traditional encoding methods to do the pagination
>> and one of the only ways to do this effectively is going to be to use
>> RSelenium:
>>
>>    library(RSelenium)
>>    library(rvest)
>>    library(dplyr)
>>    library(pbapply)
>>
>>    URL <- "http://outorgaonerosa.prefeitura.sp.gov.br/relatorios/RelSituacaoGeralProcessos.aspx"
>>
>>    checkForServer()
>>    startServer()
>>    remDr <- remoteDriver$new()
>>    remDr$open()
>
> Thanks Bob/hrbrmstr;
>
> At this point I got an error:
>
>>    startServer()
>>    remDr <- remoteDriver$new()
>>    remDr$open()
> [1] "Connecting to remote server"
> Undefined error in RCurl call.Error in queryRD(paste0(serverURL, "/session"), "POST", qdata = toJSON(serverOpts)) :
>
> Running R 3.0.0 on a Mac (El Cap) in the R.app GUI.
> $ java -version
> java version "1.8.0_65"
> Java(TM) SE Runtime Environment (build 1.8.0_65-b17)
> Java HotSpot(TM) 64-Bit Server VM (build 25.65-b01, mixed mode)
>
> I asked myself: What additional information is needed to debug this? But then I thought I had a responsibility to search for earlier reports of this error on a Mac, and there were many. After reading this thread: https://github.com/ropensci/RSelenium/issues/54  I decided to try creating an "alias", mac-speak for a symlink, and put that symlink in my working directory (with no further chmod security efforts). I restarted R and re-ran the code which opened a Firefox browser window and then proceeded to page through many pages. Eventually, however it errors out with this message:
>
>>    pblapply(1:69, function(i) {
> +
> +      if (i %in% seq(1, 69, 10)) {
> +        pg <- read_html(remDr$getPageSource()[[1]])
> +        ret <- html_table(html_nodes(pg, "table")[[3]], header=TRUE)
> +
> +      } else {
> +        ref <- remDr$findElements("xpath",
> + sprintf(".//a[contains(@href, 'javascript:__doPostBack') and .='%s']",
> + i))
> +        ref[[1]]$clickElement()
> +        pg <- read_html(remDr$getPageSource()[[1]])
> +        ret <- html_table(html_nodes(pg, "table")[[3]], header=TRUE)
> +
> +      }
> +      if ((i %% 10) == 0) {
> +        ref <- remDr$findElements("xpath", ".//a[.='...']")
> +        ref[[length(ref)]]$clickElement()
> +      }
> +
> +      ret
> +
> +    }) -> tabs
>    |+++++++++++                                       | 22% ~54s          Error in html_nodes(pg, "table")[[3]] : subscript out of bounds
>>
>>    final_dat <- bind_rows(tabs)
> Error in bind_rows(tabs) : object 'tabs' not found
>
>
> There doesn't seem to be any trace of objects from all the downloading efforts that I could find. When I changed both instances of '69' to '30' it no longer errors out. Is there supposed to be an initial step of finding out how many pages are actually there befor setting the two iteration limits? I'm wondering if that code could be modified to return some intermediate values that would be amenable to further assembly efforts in the event of errors?
>
> Sincerely;
> David.
>
>
>>    remDr$navigate(URL)
>>
>>    pblapply(1:69, function(i) {
>>
>>      if (i %in% seq(1, 69, 10)) {
>>
>>        # the first item on the page is not a link but we can just grab the page
>>
>>        pg <- read_html(remDr$getPageSource()[[1]])
>>        ret <- html_table(html_nodes(pg, "table")[[3]], header=TRUE)
>>
>>      } else {
>>
>>        # we can get the rest of them by the link text directly
>>
>>        ref <- remDr$findElements("xpath",
>> sprintf(".//a[contains(@href, 'javascript:__doPostBack') and .='%s']",
>> i))
>>        ref[[1]]$clickElement()
>>        pg <- read_html(remDr$getPageSource()[[1]])
>>        ret <- html_table(html_nodes(pg, "table")[[3]], header=TRUE)
>>
>>      }
>>
>>      # we have to move to the next actual page of data after every 10 links
>>
>>      if ((i %% 10) == 0) {
>>        ref <- remDr$findElements("xpath", ".//a[.='...']")
>>        ref[[length(ref)]]$clickElement()
>>      }
>>
>>      ret
>>
>>    }) -> tabs
>>
>>    final_dat <- bind_rows(tabs)
>>    final_dat <- final_dat[, c(1, 2, 5, 7, 8, 13, 14)] # the cols you want
>>    final_dat <- final_dat[complete.cases(final_dat),] # take care of NAs
>>
>>    remDr$quit()
>>
>>
>> Prbly good ref code to have around, but you can grab the data & code
>> here: https://gist.github.com/hrbrmstr/ec35ebb32c3cf0aba95f7bad28df1e98
>>
>> (anything to help a fellow parent out :-)
>>
>> -Bob
>>
>> On Tue, May 10, 2016 at 2:45 PM, Michael Friendly <friendly at yorku.ca> wrote:
>>> This is my first attempt to try R web scraping tools, for a project my
>>> daughter is working on.  It concerns a data base of projects in Sao
>>> Paulo, Brazil, listed at
>>> http://outorgaonerosa.prefeitura.sp.gov.br/relatorios/RelSituacaoGeralProcessos.aspx,
>>> but spread out over 69 pages accessed through a javascript menu at the
>>> bottom of the page.
>>>
>>> Each web page contains 3 HTML tables, of which only the last contains
>>> the relevant data.  In this, only a subset of columns are of interest.
>>> I tried using the XML package as illustrated on several tutorial pages,
>>> as shown below.  I have no idea how to automate this to extract these
>>> tables from multiple web pages.  Is there some other package better
>>> suited to this task?  Can someone help me solve this and other issues?
>>>
>>> # Goal: read the data tables contained on 69 pages generated by the link
>>> below, where
>>> # each page is generated by a javascript link in the menu of the bottom
>>> of the page.
>>> #
>>> # Each "page" contains 3 html tables, with names "Table 1", "Table 2",
>>> and the only one
>>> # of interest with the data, "grdRelSitGeralProcessos"
>>> #
>>> # From each such table, extract the following columns:
>>> #- Processo
>>> #- Endere?o
>>> #- Distrito
>>> #- Area terreno (m2)
>>> #- Valor contrapartida ($)
>>> #- Area excedente (m2)
>>>
>>> # NB: All of the numeric fields use "." as comma-separator and "," as
>>> the decimal separator,
>>> #   but because of this are read in as character
>>>
>>>
>>> library(XML)
>>> link <-
>>> "http://outorgaonerosa.prefeitura.sp.gov.br/relatorios/RelSituacaoGeralProcessos.aspx"
>>>
>>> saopaulo <- htmlParse(link)
>>> saopaulo.tables <- readHTMLTable(saopaulo, stringsAsFactors = FALSE)
>>> length(saopaulo.tables)
>>>
>>> # its the third table on this page we want
>>> sp.tab <- saopaulo.tables[[3]]
>>>
>>> # columns wanted
>>> wanted <- c(1, 2, 5, 7, 8, 13, 14)
>>> head(sp.tab[, wanted])
>>>
>>>> head(sp.tab[, wanted])
>>>   Proposta Processo Endere??o        Distrito
>>> 1        1 2002-0.148.242-4 R. DOMINGOS LOPES DA SILVA X R. CORN??LIO
>>> VAN CLEVE    VILA ANDRADE
>>> 2        2 2003-0.129.667-3                      AV. DR. JOS?? HIGINO,
>>> 200 E 216       AGUA RASA
>>> 3        3 2003-0.065.011-2                       R. ALIAN??A LIBERAL,
>>> 980 E 990 VILA LEOPOLDINA
>>> 4        4 2003-0.165.806-0                       R. ALIAN??A LIBERAL,
>>> 880 E 886 VILA LEOPOLDINA
>>> 5        5 2003-0.139.053-0                R. DR. JOS?? DE ANDRADE
>>> FIGUEIRA, 111    VILA ANDRADE
>>> 6        6 2003-0.200.692-0                                R. JOS?? DE
>>> JESUS, 66      VILA SONIA
>>>   ? rea Terreno (m2) ? rea Excedente (m2) Valor Contrapartida (R$)
>>> 1               0,00             1.551,14 127.875,98
>>> 2               0,00             3.552,13 267.075,77
>>> 3               0,00               624,99 70.212,93
>>> 4               0,00               395,64 44.447,18
>>> 5               0,00               719,68 41.764,46
>>> 6               0,00               446,52 85.152,92
>>>
>>> thanks,
>>>
>>>
>>> --
>>> Michael Friendly     Email: friendly AT yorku DOT ca
>>> Professor, Psychology Dept. & Chair, Quantitative Methods
>>> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
>>> 4700 Keele Street    Web:http://www.datavis.ca
>>> Toronto, ONT  M3J 1P3 CANADA
>>>
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>


From bob at rudis.net  Wed May 11 20:26:55 2016
From: bob at rudis.net (boB Rudis)
Date: Wed, 11 May 2016 14:26:55 -0400
Subject: [R] web scraping tables generated in multiple server pages
In-Reply-To: <CAJ4QxaNm07Z85v0RVHQQuMXYhoAyN09eZjEg4xOWr3vN3f_6hQ@mail.gmail.com>
References: <ff65b860-65aa-35b0-546b-646380e7ec37@yorku.ca>
	<CAJ4QxaPmGG3mOMV-27JCK+BR_c9GUZu8fnZmN_XRp6=FnYgYOg@mail.gmail.com>
	<657EFDF4-4B42-4ABA-9E0A-DAD22FEF0551@comcast.net>
	<CAJ4QxaNm07Z85v0RVHQQuMXYhoAyN09eZjEg4xOWr3vN3f_6hQ@mail.gmail.com>
Message-ID: <CAJ4QxaORU9arewdkc-ZpNodi6ooBSSVcPEB5=Y5iDevGLJyf6A@mail.gmail.com>

I upgraded ffox to the 46-series and intermittently received the same
error. But by adding a `Sys.sleep(1)` to the final `if`:

  if ((i %% 10) == 0) {
    ref <- remDr$findElements("xpath", ".//a[.='...']")
    ref[[length(ref)]]$clickElement()
    Sys.sleep(1)
  }

I was able to reproduce my original, successful outcome. I think it
has something to do with the page not being fully loaded when the the
driver tries to get the page content. Go multithreading! My choice of
1s was arbitrary. Longer == better chance of it working more often.

This <http://stackoverflow.com/questions/27080920/how-to-check-if-page-finished-loading-in-rselenium>
would probably also be better (waiting for a full page load signal),
but I try to not use [R]Selenium at all if it can be helped.

-Bob



On Wed, May 11, 2016 at 2:00 PM, boB Rudis <bob at rudis.net> wrote:
> Hey David,
>
> I'm on a Mac as well but have never had to tweak anything to get
> [R]Selenium to work (but this is one reason I try to avoid solutions
> involving RSelenium as they are pretty fragile IMO).
>
> The site itself has "P?gina 1 de 69" at the top which is where i got
> the "69" from and I just re-ran the code in a 100% clean env (on a
> completely different Mac) and it worked fine.
>
> I did neglect to put my session info up before (apologies):
>
>     Session info
> ------------------------------------------------------------------------------------
>      setting  value
>      version  R version 3.3.0 RC (2016-05-01 r70572)
>      system   x86_64, darwin13.4.0
>      ui       RStudio (0.99.1172)
>      language (EN)
>      collate  en_US.UTF-8
>      tz       America/New_York
>      date     2016-05-11
>
>     Packages ----------------------------------------------------------------------------------------
>      package    * version  date       source
>      assertthat   0.1      2013-12-06 CRAN (R 3.3.0)
>      bitops     * 1.0-6    2013-08-17 CRAN (R 3.3.0)
>      caTools      1.17.1   2014-09-10 CRAN (R 3.3.0)
>      DBI          0.4      2016-05-02 CRAN (R 3.3.0)
>      devtools   * 1.11.1   2016-04-21 CRAN (R 3.3.0)
>      digest       0.6.9    2016-01-08 CRAN (R 3.3.0)
>      dplyr      * 0.4.3    2015-09-01 CRAN (R 3.3.0)
>      httr         1.1.0    2016-01-28 CRAN (R 3.3.0)
>      magrittr     1.5      2014-11-22 CRAN (R 3.3.0)
>      memoise      1.0.0    2016-01-29 CRAN (R 3.3.0)
>      pbapply    * 1.2-1    2016-04-19 CRAN (R 3.3.0)
>      R6           2.1.2    2016-01-26 CRAN (R 3.3.0)
>      Rcpp         0.12.4   2016-03-26 CRAN (R 3.3.0)
>      RCurl      * 1.95-4.8 2016-03-01 CRAN (R 3.3.0)
>      RJSONIO    * 1.3-0    2014-07-28 CRAN (R 3.3.0)
>      RSelenium  * 1.3.5    2014-10-26 CRAN (R 3.3.0)
>      rvest      * 0.3.1    2015-11-11 CRAN (R 3.3.0)
>      selectr      0.2-3    2014-12-24 CRAN (R 3.3.0)
>      stringi      1.0-1    2015-10-22 CRAN (R 3.3.0)
>      stringr      1.0.0    2015-04-30 CRAN (R 3.3.0)
>      withr        1.0.1    2016-02-04 CRAN (R 3.3.0)
>      XML        * 3.98-1.4 2016-03-01 CRAN (R 3.3.0)
>      xml2       * 0.1.2    2015-09-01 CRAN (R 3.3.0)
>
> (and, wow, does that tiny snippet of code end up using alot of pkgs)
>
> I had actually started with smaller snippets to test. The code got
> uglier due to the way the site paginates (it loads 10-entries worth of
> data on to a single page but requires a server call for the next 10).
>
> I also keep firefox scarily out-of-date (back in the 33's rev) b/c I
> only use it with RSelenium (not a big fan of the browser). Let me
> update to the 46-series and see if I can replicate.
>
> -Bob
>
> On Wed, May 11, 2016 at 1:48 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>>> On May 10, 2016, at 1:11 PM, boB Rudis <bob at rudis.net> wrote:
>>>
>>> Unfortunately, it's a wretched, vile, SharePoint-based site. That
>>> means it doesn't use traditional encoding methods to do the pagination
>>> and one of the only ways to do this effectively is going to be to use
>>> RSelenium:
>>>
>>>    library(RSelenium)
>>>    library(rvest)
>>>    library(dplyr)
>>>    library(pbapply)
>>>
>>>    URL <- "http://outorgaonerosa.prefeitura.sp.gov.br/relatorios/RelSituacaoGeralProcessos.aspx"
>>>
>>>    checkForServer()
>>>    startServer()
>>>    remDr <- remoteDriver$new()
>>>    remDr$open()
>>
>> Thanks Bob/hrbrmstr;
>>
>> At this point I got an error:
>>
>>>    startServer()
>>>    remDr <- remoteDriver$new()
>>>    remDr$open()
>> [1] "Connecting to remote server"
>> Undefined error in RCurl call.Error in queryRD(paste0(serverURL, "/session"), "POST", qdata = toJSON(serverOpts)) :
>>
>> Running R 3.0.0 on a Mac (El Cap) in the R.app GUI.
>> $ java -version
>> java version "1.8.0_65"
>> Java(TM) SE Runtime Environment (build 1.8.0_65-b17)
>> Java HotSpot(TM) 64-Bit Server VM (build 25.65-b01, mixed mode)
>>
>> I asked myself: What additional information is needed to debug this? But then I thought I had a responsibility to search for earlier reports of this error on a Mac, and there were many. After reading this thread: https://github.com/ropensci/RSelenium/issues/54  I decided to try creating an "alias", mac-speak for a symlink, and put that symlink in my working directory (with no further chmod security efforts). I restarted R and re-ran the code which opened a Firefox browser window and then proceeded to page through many pages. Eventually, however it errors out with this message:
>>
>>>    pblapply(1:69, function(i) {
>> +
>> +      if (i %in% seq(1, 69, 10)) {
>> +        pg <- read_html(remDr$getPageSource()[[1]])
>> +        ret <- html_table(html_nodes(pg, "table")[[3]], header=TRUE)
>> +
>> +      } else {
>> +        ref <- remDr$findElements("xpath",
>> + sprintf(".//a[contains(@href, 'javascript:__doPostBack') and .='%s']",
>> + i))
>> +        ref[[1]]$clickElement()
>> +        pg <- read_html(remDr$getPageSource()[[1]])
>> +        ret <- html_table(html_nodes(pg, "table")[[3]], header=TRUE)
>> +
>> +      }
>> +      if ((i %% 10) == 0) {
>> +        ref <- remDr$findElements("xpath", ".//a[.='...']")
>> +        ref[[length(ref)]]$clickElement()
>> +      }
>> +
>> +      ret
>> +
>> +    }) -> tabs
>>    |+++++++++++                                       | 22% ~54s          Error in html_nodes(pg, "table")[[3]] : subscript out of bounds
>>>
>>>    final_dat <- bind_rows(tabs)
>> Error in bind_rows(tabs) : object 'tabs' not found
>>
>>
>> There doesn't seem to be any trace of objects from all the downloading efforts that I could find. When I changed both instances of '69' to '30' it no longer errors out. Is there supposed to be an initial step of finding out how many pages are actually there befor setting the two iteration limits? I'm wondering if that code could be modified to return some intermediate values that would be amenable to further assembly efforts in the event of errors?
>>
>> Sincerely;
>> David.
>>
>>
>>>    remDr$navigate(URL)
>>>
>>>    pblapply(1:69, function(i) {
>>>
>>>      if (i %in% seq(1, 69, 10)) {
>>>
>>>        # the first item on the page is not a link but we can just grab the page
>>>
>>>        pg <- read_html(remDr$getPageSource()[[1]])
>>>        ret <- html_table(html_nodes(pg, "table")[[3]], header=TRUE)
>>>
>>>      } else {
>>>
>>>        # we can get the rest of them by the link text directly
>>>
>>>        ref <- remDr$findElements("xpath",
>>> sprintf(".//a[contains(@href, 'javascript:__doPostBack') and .='%s']",
>>> i))
>>>        ref[[1]]$clickElement()
>>>        pg <- read_html(remDr$getPageSource()[[1]])
>>>        ret <- html_table(html_nodes(pg, "table")[[3]], header=TRUE)
>>>
>>>      }
>>>
>>>      # we have to move to the next actual page of data after every 10 links
>>>
>>>      if ((i %% 10) == 0) {
>>>        ref <- remDr$findElements("xpath", ".//a[.='...']")
>>>        ref[[length(ref)]]$clickElement()
>>>      }
>>>
>>>      ret
>>>
>>>    }) -> tabs
>>>
>>>    final_dat <- bind_rows(tabs)
>>>    final_dat <- final_dat[, c(1, 2, 5, 7, 8, 13, 14)] # the cols you want
>>>    final_dat <- final_dat[complete.cases(final_dat),] # take care of NAs
>>>
>>>    remDr$quit()
>>>
>>>
>>> Prbly good ref code to have around, but you can grab the data & code
>>> here: https://gist.github.com/hrbrmstr/ec35ebb32c3cf0aba95f7bad28df1e98
>>>
>>> (anything to help a fellow parent out :-)
>>>
>>> -Bob
>>>
>>> On Tue, May 10, 2016 at 2:45 PM, Michael Friendly <friendly at yorku.ca> wrote:
>>>> This is my first attempt to try R web scraping tools, for a project my
>>>> daughter is working on.  It concerns a data base of projects in Sao
>>>> Paulo, Brazil, listed at
>>>> http://outorgaonerosa.prefeitura.sp.gov.br/relatorios/RelSituacaoGeralProcessos.aspx,
>>>> but spread out over 69 pages accessed through a javascript menu at the
>>>> bottom of the page.
>>>>
>>>> Each web page contains 3 HTML tables, of which only the last contains
>>>> the relevant data.  In this, only a subset of columns are of interest.
>>>> I tried using the XML package as illustrated on several tutorial pages,
>>>> as shown below.  I have no idea how to automate this to extract these
>>>> tables from multiple web pages.  Is there some other package better
>>>> suited to this task?  Can someone help me solve this and other issues?
>>>>
>>>> # Goal: read the data tables contained on 69 pages generated by the link
>>>> below, where
>>>> # each page is generated by a javascript link in the menu of the bottom
>>>> of the page.
>>>> #
>>>> # Each "page" contains 3 html tables, with names "Table 1", "Table 2",
>>>> and the only one
>>>> # of interest with the data, "grdRelSitGeralProcessos"
>>>> #
>>>> # From each such table, extract the following columns:
>>>> #- Processo
>>>> #- Endere?o
>>>> #- Distrito
>>>> #- Area terreno (m2)
>>>> #- Valor contrapartida ($)
>>>> #- Area excedente (m2)
>>>>
>>>> # NB: All of the numeric fields use "." as comma-separator and "," as
>>>> the decimal separator,
>>>> #   but because of this are read in as character
>>>>
>>>>
>>>> library(XML)
>>>> link <-
>>>> "http://outorgaonerosa.prefeitura.sp.gov.br/relatorios/RelSituacaoGeralProcessos.aspx"
>>>>
>>>> saopaulo <- htmlParse(link)
>>>> saopaulo.tables <- readHTMLTable(saopaulo, stringsAsFactors = FALSE)
>>>> length(saopaulo.tables)
>>>>
>>>> # its the third table on this page we want
>>>> sp.tab <- saopaulo.tables[[3]]
>>>>
>>>> # columns wanted
>>>> wanted <- c(1, 2, 5, 7, 8, 13, 14)
>>>> head(sp.tab[, wanted])
>>>>
>>>>> head(sp.tab[, wanted])
>>>>   Proposta Processo Endere??o        Distrito
>>>> 1        1 2002-0.148.242-4 R. DOMINGOS LOPES DA SILVA X R. CORN??LIO
>>>> VAN CLEVE    VILA ANDRADE
>>>> 2        2 2003-0.129.667-3                      AV. DR. JOS?? HIGINO,
>>>> 200 E 216       AGUA RASA
>>>> 3        3 2003-0.065.011-2                       R. ALIAN??A LIBERAL,
>>>> 980 E 990 VILA LEOPOLDINA
>>>> 4        4 2003-0.165.806-0                       R. ALIAN??A LIBERAL,
>>>> 880 E 886 VILA LEOPOLDINA
>>>> 5        5 2003-0.139.053-0                R. DR. JOS?? DE ANDRADE
>>>> FIGUEIRA, 111    VILA ANDRADE
>>>> 6        6 2003-0.200.692-0                                R. JOS?? DE
>>>> JESUS, 66      VILA SONIA
>>>>   ? rea Terreno (m2) ? rea Excedente (m2) Valor Contrapartida (R$)
>>>> 1               0,00             1.551,14 127.875,98
>>>> 2               0,00             3.552,13 267.075,77
>>>> 3               0,00               624,99 70.212,93
>>>> 4               0,00               395,64 44.447,18
>>>> 5               0,00               719,68 41.764,46
>>>> 6               0,00               446,52 85.152,92
>>>>
>>>> thanks,
>>>>
>>>>
>>>> --
>>>> Michael Friendly     Email: friendly AT yorku DOT ca
>>>> Professor, Psychology Dept. & Chair, Quantitative Methods
>>>> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
>>>> 4700 Keele Street    Web:http://www.datavis.ca
>>>> Toronto, ONT  M3J 1P3 CANADA
>>>>
>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>


From henrik.bengtsson at gmail.com  Wed May 11 21:49:08 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Wed, 11 May 2016 12:49:08 -0700
Subject: [R] Antwort: Re: Antwort: Re: Re: sink(): Cannot open file
In-Reply-To: <OFBC7434F2.0E57B1FE-ONC1257FB0.005C1753-C1257FB0.005C38DA@lotus.hawesko.de>
References: <OF15A2364C.38B38E20-ONC1257FAF.00287156-C1257FAF.0028D3F1@lotus.hawesko.de>
	<CA+8X3fWKAJysbwP+whoDrSnT8W3njAUq5LwmjTp3qq-AOdanzg@mail.gmail.com>
	<OF680609C9.B98EF9B5-ONC1257FAF.003C5B6B-C1257FAF.003CF31F@lotus.hawesko.de>
	<CA+8X3fV=Cc8n0WBk6JjobbHm0E+R4ss+7is233o9HYVwGaiQ8Q@mail.gmail.com>
	<OFF8B5EC26.08CB1CFC-ONC1257FAF.00526FBA-C1257FAF.0052DAB9@lotus.hawesko.de>
	<5731C2BC020000CB001536F4@smtp.medicine.umaryland.edu>
	<5732149A.7080203@gmail.com>
	<OFBC7434F2.0E57B1FE-ONC1257FB0.005C1753-C1257FB0.005C38DA@lotus.hawesko.de>
Message-ID: <CAFDcVCTksQ9EmqH_O5GGd1ubOq9M+SDmV2NSHRp0X2i=vNbpnw@mail.gmail.com>

Sounds like it would be helpful to find out exactly which process is
holding on to the file in order to figure out what's going on. From a
quick look, it seems that

  http://superuser.com/questions/117902/find-out-which-process-is-locking-a-file-or-folder-in-windows

gives some useful info on how to track down the process that looks the file.

/Henrik

On Wed, May 11, 2016 at 9:47 AM,  <G.Maubach at weinwolf.de> wrote:
> Duncan,
>
> thanks for the hint.
>
> I have done it correctly in R fashion
>
> ## capture all the output to a file.
> zz <- file("C:/Temp/all.Rout", open = "wt")
> sink(zz)
> sink(zz, type = "message")
> try(log("a"))
> ## back to the console
> sink(type = "message")
> sink()
> unlink("C:/Temp/all.Rout")
>
> But the error persits.
>
> Kind regards
>
> Georg
>
>
>
>
> Von:    Duncan Murdoch <murdoch.duncan at gmail.com>
> An:     John Sorkin <jsorkin at grecc.umaryland.edu>, drjimlemon at gmail.com,
> G.Maubach at weinwolf.de,
> Kopie:  r-help at r-project.org
> Datum:  10.05.2016 19:03
> Betreff:        Re: [R] Antwort: Re: Re: sink(): Cannot open file
>
>
>
> On 10/05/2016 11:15 AM, John Sorkin wrote:
>> George,
>> I do not know what operating system you are working with, but when I use
> sink() under windows, I need to specify a valid path which I don't see in
> your code. I might, for example specify:
>>
>> sink("c:\myfile.txt")
>
> Note that the backslash should be doubled (so it isn't interpreted as an
> escape for the "m" that follows it), or replaced with a forward slash.
>
> Duncan Murdoch
>
>>   R code goes here
>> sink()
>>
>> with the expectation that I would create a file myfile.txt that would
> contain the output of my R program.
>>
>> John
>>
>>
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>> >>> <G.Maubach at weinwolf.de> 05/10/16 11:10 AM >>>
>> Hi Jim,
>>
>> I tried:
>>
>> sink("all.Rout")
>> try(log("a"))
>> sink()
>>
>> The program executes without warning or error. The file "all.Rout" is
>> begin created. Nothing will be written to it. The file is accessable
>> rights after the execution of the program by notepad.exe.
>>
>> The program
>>
>> zz <- file("all.Rout", open = "wt")
>> sink(zz, type = "message")
>> try(log("a"))
>> sink()
>> close(zz)
>> unlink(zz)
>>
>> creates the file, does not write anything to it and is not accessable
>> after program execution in R with notepad.exe.
>>
>> Any ideas what happens behind the szenes?
>>
>> Kind regards
>>
>> Georg
>>
>>
>>
>>
>> Von: Jim Lemon <drjimlemon at gmail.com>
>> An: G.Maubach at weinwolf.de,
>> Kopie: r-help mailing list <r-help at r-project.org>
>> Datum: 10.05.2016 13:16
>> Betreff: Re: Re: [R] sink(): Cannot open file
>>
>>
>>
>> Have you tried:
>>
>> sink("all.Rout")
>> try(log("a"))
>> sink()
>>
>> Jim
>>
>> On Tue, May 10, 2016 at 9:05 PM, <G.Maubach at weinwolf.de> wrote:
>> > Hi Jim,
>> >
>> > thanks for your reply.
>> >
>> > ad 1)
>> > "all.Rout" was created in the correct directory. It exists properly
> with
>> > correct file properties on Windows, e.g. creation date and time and
> file
>> > size information.
>> >
>> > ad 2)
>> > I can not access the file with Notepad.exe directly after it was
> created
>> > by R. The error message is (translated):
>> >
>> > "Cannot access file "all.Rout". The file is opened by another
> process."
>> >
>> > ad 3)
>> > If I close R completely the file access is released. Then I can read
> the
>> > file using Notepad.exe. The contents is:
>> >
>> > Error in log("a") : non-numeric argument to mathematical function
>> >
>> > I tried
>> >
>> > close(zz)
>> >
>> > but the error persists.
>> >
>> > To me it looks like R is still accessing the file and not releasing
> the
>> > connection for other programs. close(zz) should have solved the
> problem
>> > but unfortantely it doesn't.
>> >
>> > What else could I try?
>> >
>> > Kind regards
>> >
>> > Georg
>> >
>> >
>> >
>> >
>> > Von: Jim Lemon <drjimlemon at gmail.com>
>> > An: G.Maubach at weinwolf.de,
>> > Kopie: r-help mailing list <r-help at r-project.org>
>> > Datum: 10.05.2016 12:50
>> > Betreff: Re: [R] sink(): Cannot open file
>> >
>> >
>> >
>> > Hi Georg,
>> > I don't suppose that you have:
>> >
>> > 1) checked that the file "all.Rout" exists somewhere?
>> >
>> > 2) if so, looked at the file with Notepad, perhaps?
>> >
>> > 3) let us in on the secret by pasting the contents of "all.Rout" into
>> > your message if it is not too big?
>> >
>> > At a guess, trying:
>> >
>> > close(zz)
>> >
>> > might get you there.
>> >
>> > Jim
>> >
>> > On Tue, May 10, 2016 at 5:25 PM, <G.Maubach at weinwolf.de> wrote:
>> >> Hi All,
>> >>
>> >> I would like to route the output to a file using sink(). When using
> the
>> >> example from the ?sink documentation:
>> >>
>> >> sink("sink-examp.txt")
>> >> i <- 1:10
>> >> outer(i, i, "*")
>> >> sink()
>> >> unlink("sink-examp.txt")
>> >>
>> >> ## capture all the output to a file.
>> >> zz <- file("all.Rout", open = "wt")
>> >> sink(zz)
>> >> sink(zz, type = "message")
>> >> try(log("a"))
>> >> ## back to the console
>> >> sink(type = "message")
>> >> sink()
>> >> file.show("all.Rout")
>> >>
>> >> I can not open the file in Windows Explorer. The error message is:
>> >>
>> >> "Cannot open file. File is in use be another proces."
>> >>
>> >> How can I close the file in a manner that I can open it right after
> it
>> > was
>> >> created?
>> >>
>> >> Kind regards
>> >>
>> >> Georg
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> Confidentiality Statement:
>> This email message, including any attachments, is for ...{{dropped:14}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jan.kacaba at gmail.com  Wed May 11 22:12:34 2016
From: jan.kacaba at gmail.com (Jan Kacaba)
Date: Wed, 11 May 2016 22:12:34 +0200
Subject: [R] break string at specified possitions
Message-ID: <CAHby=D1UYkGp-L_hVgy8Xus=_wVjDmV=6_x39Dyd0Pt38-H02w@mail.gmail.com>

Dear R-help

I would like to split long string at specified precomputed positions.
'substring' needs beginings and ends. Is there a native function which
accepts positions so I don't have to count second argument?

For example I have vector of possitions pos<-c(5,10,19). Substring
needs input first=c(1,6,11) and last=c(5,10,19). There is no problem
to write my own function. Just asking.

Derek


From bgunter.4567 at gmail.com  Wed May 11 23:12:00 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 11 May 2016 14:12:00 -0700
Subject: [R] break string at specified possitions
In-Reply-To: <CAHby=D1UYkGp-L_hVgy8Xus=_wVjDmV=6_x39Dyd0Pt38-H02w@mail.gmail.com>
References: <CAHby=D1UYkGp-L_hVgy8Xus=_wVjDmV=6_x39Dyd0Pt38-H02w@mail.gmail.com>
Message-ID: <CAGxFJbTi0SPb9STcFwu1DaGA2Ynd5K6v6KWNe7=ubh_Nc3uo+g@mail.gmail.com>

Dunno -- but you might have a look at Hadley Wickham's 'stringr' package:
https://cran.r-project.org/web/packages/stringr/stringr.pdf

Cheers,

Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, May 11, 2016 at 1:12 PM, Jan Kacaba <jan.kacaba at gmail.com> wrote:
> Dear R-help
>
> I would like to split long string at specified precomputed positions.
> 'substring' needs beginings and ends. Is there a native function which
> accepts positions so I don't have to count second argument?
>
> For example I have vector of possitions pos<-c(5,10,19). Substring
> needs input first=c(1,6,11) and last=c(5,10,19). There is no problem
> to write my own function. Just asking.
>
> Derek
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jan.kacaba at gmail.com  Wed May 11 23:23:31 2016
From: jan.kacaba at gmail.com (Jan Kacaba)
Date: Wed, 11 May 2016 23:23:31 +0200
Subject: [R] break string at specified possitions
In-Reply-To: <CAGxFJbTi0SPb9STcFwu1DaGA2Ynd5K6v6KWNe7=ubh_Nc3uo+g@mail.gmail.com>
References: <CAHby=D1UYkGp-L_hVgy8Xus=_wVjDmV=6_x39Dyd0Pt38-H02w@mail.gmail.com>
	<CAGxFJbTi0SPb9STcFwu1DaGA2Ynd5K6v6KWNe7=ubh_Nc3uo+g@mail.gmail.com>
Message-ID: <CAHby=D3aXQ6WF3wWWkYob1+a5wPhB0+yTGrVTJ9tzpcQz8i4kw@mail.gmail.com>

Here is my attempt at function which computes margins from positions.

require("stringr")
require("dplyr")

ends<-seq(10,100,8)  # end margins
test_string<-"Lorem ipsum dolor sit amet, consectetuer adipiscing
elit. Aliquam in lorem sit amet leo accumsan lacinia."

sekoj=function(ends){
  l_ends<-length(ends)
  begs=vector(mode="integer",l_ends)
  begs[1]=1
  for (i in 2:(l_ends)){
    begs[i]<-ends[i-1]+1
  }
  margs<-rbind(begs,ends)
  margs<-cbind(margs,c(ends[l_ends]+1,-1))
  #rownames(margs)<-c("beg","end")
  return(margs)
}
margins<-sekoj(ends)
str_sub(test_string,margins[1,],margins[2,]) %>% print

Code to run in browser:
http://www.r-fiddle.org/#/fiddle?id=rVmNVxDV

2016-05-11 23:12 GMT+02:00 Bert Gunter <bgunter.4567 at gmail.com>:
> Dunno -- but you might have a look at Hadley Wickham's 'stringr' package:
> https://cran.r-project.org/web/packages/stringr/stringr.pdf
>
> Cheers,
>
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, May 11, 2016 at 1:12 PM, Jan Kacaba <jan.kacaba at gmail.com> wrote:
>> Dear R-help
>>
>> I would like to split long string at specified precomputed positions.
>> 'substring' needs beginings and ends. Is there a native function which
>> accepts positions so I don't have to count second argument?
>>
>> For example I have vector of possitions pos<-c(5,10,19). Substring
>> needs input first=c(1,6,11) and last=c(5,10,19). There is no problem
>> to write my own function. Just asking.
>>
>> Derek
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Thu May 12 02:05:47 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 12 May 2016 10:05:47 +1000
Subject: [R] break string at specified possitions
In-Reply-To: <CAHby=D3aXQ6WF3wWWkYob1+a5wPhB0+yTGrVTJ9tzpcQz8i4kw@mail.gmail.com>
References: <CAHby=D1UYkGp-L_hVgy8Xus=_wVjDmV=6_x39Dyd0Pt38-H02w@mail.gmail.com>
	<CAGxFJbTi0SPb9STcFwu1DaGA2Ynd5K6v6KWNe7=ubh_Nc3uo+g@mail.gmail.com>
	<CAHby=D3aXQ6WF3wWWkYob1+a5wPhB0+yTGrVTJ9tzpcQz8i4kw@mail.gmail.com>
Message-ID: <CA+8X3fUpTkyJiyq=nLmYa-ogLiwYXPjcxFgZdgWz32aD6Vy7uA@mail.gmail.com>

Hi Jan,
This might be helpful:

chop_string<-function(x,ends) {
 starts<-c(1,ends[-length(ends)]-1)
 return(substring(x,starts,ends))
}

Jim


On Thu, May 12, 2016 at 7:23 AM, Jan Kacaba <jan.kacaba at gmail.com> wrote:
> Here is my attempt at function which computes margins from positions.
>
> require("stringr")
> require("dplyr")
>
> ends<-seq(10,100,8)  # end margins
> test_string<-"Lorem ipsum dolor sit amet, consectetuer adipiscing
> elit. Aliquam in lorem sit amet leo accumsan lacinia."
>
> sekoj=function(ends){
>   l_ends<-length(ends)
>   begs=vector(mode="integer",l_ends)
>   begs[1]=1
>   for (i in 2:(l_ends)){
>     begs[i]<-ends[i-1]+1
>   }
>   margs<-rbind(begs,ends)
>   margs<-cbind(margs,c(ends[l_ends]+1,-1))
>   #rownames(margs)<-c("beg","end")
>   return(margs)
> }
> margins<-sekoj(ends)
> str_sub(test_string,margins[1,],margins[2,]) %>% print
>
> Code to run in browser:
> http://www.r-fiddle.org/#/fiddle?id=rVmNVxDV
>
> 2016-05-11 23:12 GMT+02:00 Bert Gunter <bgunter.4567 at gmail.com>:
>> Dunno -- but you might have a look at Hadley Wickham's 'stringr' package:
>> https://cran.r-project.org/web/packages/stringr/stringr.pdf
>>
>> Cheers,
>>
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Wed, May 11, 2016 at 1:12 PM, Jan Kacaba <jan.kacaba at gmail.com> wrote:
>>> Dear R-help
>>>
>>> I would like to split long string at specified precomputed positions.
>>> 'substring' needs beginings and ends. Is there a native function which
>>> accepts positions so I don't have to count second argument?
>>>
>>> For example I have vector of possitions pos<-c(5,10,19). Substring
>>> needs input first=c(1,6,11) and last=c(5,10,19). There is no problem
>>> to write my own function. Just asking.
>>>
>>> Derek
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Thu May 12 02:45:31 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 12 May 2016 10:45:31 +1000
Subject: [R] break string at specified possitions
In-Reply-To: <CA+8X3fUpTkyJiyq=nLmYa-ogLiwYXPjcxFgZdgWz32aD6Vy7uA@mail.gmail.com>
References: <CAHby=D1UYkGp-L_hVgy8Xus=_wVjDmV=6_x39Dyd0Pt38-H02w@mail.gmail.com>
	<CAGxFJbTi0SPb9STcFwu1DaGA2Ynd5K6v6KWNe7=ubh_Nc3uo+g@mail.gmail.com>
	<CAHby=D3aXQ6WF3wWWkYob1+a5wPhB0+yTGrVTJ9tzpcQz8i4kw@mail.gmail.com>
	<CA+8X3fUpTkyJiyq=nLmYa-ogLiwYXPjcxFgZdgWz32aD6Vy7uA@mail.gmail.com>
Message-ID: <CA+8X3fU8mGykM++TSU-LDZRKxL3oUs0KFaS10P3mkoDU1z2gUA@mail.gmail.com>

Hi again,
Sorry, that should be:

chop_string<-function(x,ends) {
 starts<-c(1,ends[-length(ends)]+1)
 return(substring(x,starts,ends))
}

Jim

On Thu, May 12, 2016 at 10:05 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Jan,
> This might be helpful:
>
> chop_string<-function(x,ends) {
>  starts<-c(1,ends[-length(ends)]-1)
>  return(substring(x,starts,ends))
> }
>
> Jim
>
>
> On Thu, May 12, 2016 at 7:23 AM, Jan Kacaba <jan.kacaba at gmail.com> wrote:
>> Here is my attempt at function which computes margins from positions.
>>
>> require("stringr")
>> require("dplyr")
>>
>> ends<-seq(10,100,8)  # end margins
>> test_string<-"Lorem ipsum dolor sit amet, consectetuer adipiscing
>> elit. Aliquam in lorem sit amet leo accumsan lacinia."
>>
>> sekoj=function(ends){
>>   l_ends<-length(ends)
>>   begs=vector(mode="integer",l_ends)
>>   begs[1]=1
>>   for (i in 2:(l_ends)){
>>     begs[i]<-ends[i-1]+1
>>   }
>>   margs<-rbind(begs,ends)
>>   margs<-cbind(margs,c(ends[l_ends]+1,-1))
>>   #rownames(margs)<-c("beg","end")
>>   return(margs)
>> }
>> margins<-sekoj(ends)
>> str_sub(test_string,margins[1,],margins[2,]) %>% print
>>
>> Code to run in browser:
>> http://www.r-fiddle.org/#/fiddle?id=rVmNVxDV
>>
>> 2016-05-11 23:12 GMT+02:00 Bert Gunter <bgunter.4567 at gmail.com>:
>>> Dunno -- but you might have a look at Hadley Wickham's 'stringr' package:
>>> https://cran.r-project.org/web/packages/stringr/stringr.pdf
>>>
>>> Cheers,
>>>
>>> Bert
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Wed, May 11, 2016 at 1:12 PM, Jan Kacaba <jan.kacaba at gmail.com> wrote:
>>>> Dear R-help
>>>>
>>>> I would like to split long string at specified precomputed positions.
>>>> 'substring' needs beginings and ends. Is there a native function which
>>>> accepts positions so I don't have to count second argument?
>>>>
>>>> For example I have vector of possitions pos<-c(5,10,19). Substring
>>>> needs input first=c(1,6,11) and last=c(5,10,19). There is no problem
>>>> to write my own function. Just asking.
>>>>
>>>> Derek
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From djnordlund at gmail.com  Thu May 12 00:43:37 2016
From: djnordlund at gmail.com (Daniel Nordlund)
Date: Wed, 11 May 2016 15:43:37 -0700
Subject: [R] break string at specified possitions
In-Reply-To: <CAHby=D3aXQ6WF3wWWkYob1+a5wPhB0+yTGrVTJ9tzpcQz8i4kw@mail.gmail.com>
References: <CAHby=D1UYkGp-L_hVgy8Xus=_wVjDmV=6_x39Dyd0Pt38-H02w@mail.gmail.com>
	<CAGxFJbTi0SPb9STcFwu1DaGA2Ynd5K6v6KWNe7=ubh_Nc3uo+g@mail.gmail.com>
	<CAHby=D3aXQ6WF3wWWkYob1+a5wPhB0+yTGrVTJ9tzpcQz8i4kw@mail.gmail.com>
Message-ID: <fdbd774e-c9cf-009a-1518-6108120f833b@gmail.com>

On 5/11/2016 2:23 PM, Jan Kacaba wrote:
> Here is my attempt at function which computes margins from positions.
>
> require("stringr")
> require("dplyr")
>
> ends<-seq(10,100,8)  # end margins
> test_string<-"Lorem ipsum dolor sit amet, consectetuer adipiscing
> elit. Aliquam in lorem sit amet leo accumsan lacinia."
>
> sekoj=function(ends){
>   l_ends<-length(ends)
>   begs=vector(mode="integer",l_ends)
>   begs[1]=1
>   for (i in 2:(l_ends)){
>     begs[i]<-ends[i-1]+1
>   }
>   margs<-rbind(begs,ends)
>   margs<-cbind(margs,c(ends[l_ends]+1,-1))
>   #rownames(margs)<-c("beg","end")
>   return(margs)
> }
> margins<-sekoj(ends)
> str_sub(test_string,margins[1,],margins[2,]) %>% print
>
> Code to run in browser:
> http://www.r-fiddle.org/#/fiddle?id=rVmNVxDV
>
> 2016-05-11 23:12 GMT+02:00 Bert Gunter <bgunter.4567 at gmail.com>:
>> Dunno -- but you might have a look at Hadley Wickham's 'stringr' package:
>> https://cran.r-project.org/web/packages/stringr/stringr.pdf
>>
>> Cheers,
>>
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Wed, May 11, 2016 at 1:12 PM, Jan Kacaba <jan.kacaba at gmail.com> wrote:
>>> Dear R-help
>>>
>>> I would like to split long string at specified precomputed positions.
>>> 'substring' needs beginings and ends. Is there a native function which
>>> accepts positions so I don't have to count second argument?
>>>
>>> For example I have vector of possitions pos<-c(5,10,19). Substring
>>> needs input first=c(1,6,11) and last=c(5,10,19). There is no problem
>>> to write my own function. Just asking.
>>>
>>> Derek
>>>

I think you can simply this. just create a function (I'll call it begs) 
to compute the beginning positions.

     begs <- function(x) c(0,x[-length(x)])+1

Then, then use that function in your call to str_sub

     str_sub(test_string,begs(ends),ends) %>% print


Hope this is helpful,

Dan

Daniel Nordlund
Bothell, WA USA


From Dominik.Schneider at colorado.edu  Thu May 12 03:29:40 2016
From: Dominik.Schneider at colorado.edu (Dominik Schneider)
Date: Wed, 11 May 2016 19:29:40 -0600
Subject: [R] physical constraint with gam
In-Reply-To: <CAF1jk_=Yk6ruWTyDZ_aZnDTAmSZi6=7eSM5CoL0x=jF=JVqm4w@mail.gmail.com>
References: <CAF1jk_=312-4GEwpeJM2UaOojnSE_6PxLo6YU2ysjGdHKBt3UQ@mail.gmail.com>
	<5732F730.9000800@bath.edu>
	<CAF1jk_=Yk6ruWTyDZ_aZnDTAmSZi6=7eSM5CoL0x=jF=JVqm4w@mail.gmail.com>
Message-ID: <CAF1jk_k=v1-FhTRRrq54Ry_SixdMsAKV+YKaLZmBNwy6uF77yg@mail.gmail.com>

Hi again,
I'm looking for some clarification on 2 things.
1. On that last note, I realize that s(x1,x2) would be the other obvious
interaction to compare with - and I see that you recommend te(x1,x2) if
they are not on the same scale.
2. If s(x1,by=x1) gives you a "parameter" value similar to a GLM when you
plot s(x1):x1, why does my function above return the same yhat as
predict(mdl,type='response') ?  Shouldn't each of the terms need to be
multiplied by the variable value before applying
rowSums()+attr(sterms,'constant') ??
Thanks again
Dominik

On Wed, May 11, 2016 at 10:11 AM, Dominik Schneider <
Dominik.Schneider at colorado.edu> wrote:

> Hi Simon, Thanks for this explanation.
> To make sure I understand, another way of explaining the y axis in my
> original example is that it is the contribution to snowdepth relative to
> the other variables (the example only had fsca, but my actual case has a
> couple others). i.e. a negative s(fsca) of -0.5 simply means snowdepth 0.5
> units below the intercept+s(x_i), where s(x_i) could also be negative in
> the case where total snowdepth is less than the intercept value.
>
> The use of by=fsca is really useful for interpreting the marginal impact
> of the different variables. With my actual data, the term s(fsca):fsca is
> never negative, which is much more intuitive. Is it appropriate to compare
> magnitudes of e.g. s(x2):x2 / mean(x2) and s(x2):x2 / mean(x2)  where
> mean(x_i) are the mean of the actual data?
>
> Lastly, how would these two differ: s(x1,by=x2); or
> s(x1,by=x1)*s(x2,by=x2) since interactions are surely present and i'm not
> sure if a linear combination is enough.
>
> Thanks!
> Dominik
>
>
> On Wed, May 11, 2016 at 3:11 AM, Simon Wood <simon.wood at bath.edu> wrote:
>
>> The spline having a positive value is not the same as a glm coefficient
>> having a positive value. When you plot a smooth, say s(x), that is
>> equivalent to plotting the line 'beta * x' in a GLM. It is not equivalent
>> to plotting 'beta'. The smooths in a gam are (usually) subject to
>> `sum-to-zero' identifiability constraints to avoid confounding via the
>> intercept, so they are bound to be negative over some part of the covariate
>> range. For example, if I have a model y ~ s(x) + s(z), I can't estimate the
>> mean level for s(x) and the mean level for s(z) as they are completely
>> confounded, and confounded with the model intercept term.
>>
>> I suppose that if you want to interpret the smooths as glm parameters
>> varying with the covariate they relate to then you can do, by setting the
>> model up as a varying coefficient model, using the `by' argument to 's'...
>>
>> gam(snowdepth~s(fsca,by=fsca),data=dat)
>>
>>
>> this model is `snowdepth_i = f(fsca_i) * fsca_i + e_i' . s(fsca,by=fsca)
>> is not confounded with the intercept, so no constraint is needed or
>> applied, and you can now interpret the smooth like a local GLM coefficient.
>>
>> best,
>> Simon
>>
>>
>>
>>
>> On 11/05/16 01:30, Dominik Schneider wrote:
>>
>>> Hi,
>>> Just getting into using GAM using the mgcv package. I've generated some
>>> models and extracted the splines for each of the variables and started
>>> visualizing them. I'm noticing that one of my variables is physically
>>> unrealistic.
>>>
>>> In the example below, my interpretation of the following plot is that the
>>> y-axis is basically the equivalent of a "parameter" value of a GLM; in
>>> GAM
>>> this value can change as the functional relationship changes between x
>>> and
>>> y. In my case, I am predicting snowdepth based on the fractional snow
>>> covered area. In no case will snowdepth realistically decrease for a unit
>>> increase in fsca so my question is: *Is there a way to constrain the
>>> spline
>>> to positive values? *
>>>
>>> Thanks
>>> Dominik
>>>
>>> library(mgcv)
>>> library(dplyr)
>>> library(ggplot2)
>>> extract_splines=function(mdl){
>>>    sterms=predict(mdl,type='terms')
>>>    datplot=cbind(sterms,mdl$model) %>% tbl_df
>>>    datplot$intercept=attr(sterms,'constant')
>>>    datplot$yhat=rowSums(sterms)+attr(sterms,'constant')
>>>    return(datplot)
>>> }
>>> dat=data_frame(snowdepth=runif(100,min =
>>> 0.001,max=6.7),fsca=runif(100,0.01,.99))
>>> mdl=gam(snowdepth~s(fsca),data=dat)
>>> termdF=extract_splines(mdl)
>>> ggplot(termdF)+
>>>    geom_line(aes(x=fsca,y=`s(fsca)`))
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>> --
>> Simon Wood, School of Mathematics, University of Bristol BS8 1TW UK
>> +44 (0)117 33 18273     http://www.maths.bris.ac.uk/~sw15190
>>
>>
>

	[[alternative HTML version deleted]]


From btyner at gmail.com  Thu May 12 04:39:21 2016
From: btyner at gmail.com (Benjamin Tyner)
Date: Wed, 11 May 2016 22:39:21 -0400
Subject: [R] R_DirtyImage and Rprof
Message-ID: <5733ECD9.3000509@gmail.com>

Hello,

I have some code which was running in interactive mode while Rprof(..., 
line.profiling = TRUE). Near the end of my script, it opens up a 
pipe(..., open = "w") to a perl script, and at that point the execution 
gets stuck using 100% cpu.

(The perl script itself never showed up in pstree, as far as I can tell).

I did a "tail -f" on the file being written to by Rprof, and it was 
reporting "sys.save.image" over and over, and in fact an ".RData" file 
appeared when I had not asked for one, and I was able to load it later.

This got me curious, as nowhere in my code do I directly use that 
function. Looking through the source code for R, it appears that 
"sys.save.image" is called whenever an R_DirtyImage condition is triggered.

This was using R version 3.2.2 under RHEL. My efforts to create a 
reproducible example of this behavior have thus far been unsuccessful.

My questions: is there any documentation for R_DirtyImage, and how 
plausible is it that the R_DirtyImage condition was triggered by 
something Rprof did? The reason for my conjecture is that 
sys.save.image() calls closeAllConnections(), which I imagine might have 
interfered with the pipe that was open for writing, thus causing the 
stuck execution at that point.

If so, any advice for avoiding the R_DirtyImage condition while profiling?

If not, any conjectures for what might actually be going on? For what 
it's worth, I have observed a similar situation when using Rprof + 
system() instead of pipe(); for example:

    https://stat.ethz.ch/pipermail/r-help/2015-August/431286.html

Regards
Ben


From friendly at yorku.ca  Thu May 12 04:40:33 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 11 May 2016 22:40:33 -0400
Subject: [R] R simulation help pls
In-Reply-To: <KL1PR01MB0887B3D3585826A65B7D41F4B59F0@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>
References: <KL1PR01MB0887B3D3585826A65B7D41F4B59F0@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>
Message-ID: <5733ED21.1040502@yorku.ca>

On 4/06/16 11:54 AM, tan sj wrote:
>
> Hi, i am student from malaysia, i am new in r programming field, now i am trying to conduct a robustness study on 2 sample test under several combination of factors such as sample sizes ,standard deviation ratio and  also distribution..
>
> but now i am stucking in how to use for loop or apply function to conduct the simulation ?
> Then how can i test the test in the combined combination of factors?
>
Look for the SimDesign package.  Makes this easy to do.  No loops, no 
pain.  There are some good examples on the wiki for this.

https://github.com/philchalmers/SimDesign
https://github.com/philchalmers/SimDesign/wiki


From marcelolaia at gmail.com  Thu May 12 05:45:29 2016
From: marcelolaia at gmail.com (Marcelo Laia)
Date: Thu, 12 May 2016 00:45:29 -0300
Subject: [R] To compare and filter text (mining data)
Message-ID: <20160512034529.GK2731@localhost>

Hi, I have a experiment like this:

Trat Rep Peak CAS
1    1   1    123-92-2
1    1   2    109-21-7
1    1   3    2867-05-2
1    1   ...  ...
1    1   33   99-86-5
1    2   1    562-74-3
1    2   2    123-92-2
1    2   3    109-21-7
1    2   ...  ...
1    2   45   2867-05-2
...
14   3   18   2867-05-2

Trat = Treatment - range from 1 to 14
Rep = Biological Replicate - range from 1 to 3
Peak = Peak from GC/MS chromatogram - range from 1 to n (n>1)
CAS = oil CAS Number [1]

I would like to compare all 14 treatments (3 replicates) and print only Trat
and Rep and Peak that have exclusive CAS, and the CAS number, off course. In
fact, I would like to know if there are exclusive CAS in a specific 
treatment. 

Is it possible to do it inside R?

Could you share a code ou paper ou tutorial to do that? Or point me out a
R package/library?

Thank you very much!

1. https://www.cas.org/content/chemical-substances/faqs

-- 
Marcelo


From wewolski at gmail.com  Thu May 12 09:12:12 2016
From: wewolski at gmail.com (Witold E Wolski)
Date: Thu, 12 May 2016 09:12:12 +0200
Subject: [R] how to manipulate ... in the argument list
In-Reply-To: <57333765.2040806@unipa.it>
References: <CAAjnpdg3XrWjagscn7shX1TWm8TEY0=VcWvUy29j_ai_+NmdOA@mail.gmail.com>
	<57333765.2040806@unipa.it>
Message-ID: <CAAjnpdjz5ecQGVW0bB1aiNdcZoHmm4Kx0ZCABoDRPaKAiTc7Xw@mail.gmail.com>

Duncan suggested to use the argument explicitly and combine it with
the missing function which is for this problem also my preferred
solution:


image.2 <- function(x, col , breaks, ...){
  # function is manipulating colors (adding a few)
  # since it changes colors it needs to update breaks if defined.

  if( !missing(breaks) ){
     #manipulate breaks

    image(x, col, breaks  ,...)

   }else{
      image(x,col ,...)
   }
}

It is good to know that I also could have used do.call.

I also learned yesterday that it is better to search for dot dot dot
argument or for elipsis instead of  ...

best





On 11 May 2016 at 15:45, Vito M. R. Muggeo <vito.muggeo at unipa.it> wrote:
> Hi Witold,
> use do.call()
>
> list.args<-list(...)
>
> #modify 'list.args' (add/delete/modify)
>
> do.call(image, list.args)
>
> best,
> vito
>
>
> Il 11/05/2016 10.45, Witold E Wolski ha scritto:
>>
>> Hi,
>>
>> I am looking for a documentation describing how to manipulate the
>> "..." . Searching R-intro.html gives to many not relevant hits for
>> "..."
>>
>> What I want to do is something like this :
>>
>>
>> image.2 <- function(x, col , ...){
>>   # function is manipulating colors (adding a few)
>>   # since it changes colors it needs to update breaks if defined.
>>
>>    breaks <- list(...)$breaks
>>
>>   if( !is.null( list(...)$breaks ) ){
>>      #manipulate breaks
>>
>>     image(x, col, breaks = breaks ,...)
>>
>>    }else{
>>       image(x,col ,...)
>>    }
>> }
>>
>> but in order to get it working I will need to remove breaks from ...
>> since otherwise I am getting multiple defined argument for breaks.
>>
>> So how to manipulate the "..." argument? Or should I use a different
>> pattern
>>
>> best
>>
>>
>>
>
> --
> ==============================================
> Vito M.R. Muggeo
> Dip.to Sc Statist e Matem `Vianelli'
> Universit? di Palermo
> viale delle Scienze, edificio 13
> 90128 Palermo - ITALY
> tel: 091 23895240
> fax: 091 485726
> http://dssm.unipa.it/vmuggeo
> Associate Editor, Statistical Modelling
> ===============================================



-- 
Witold Eryk Wolski


From G.Maubach at weinwolf.de  Thu May 12 10:13:59 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Thu, 12 May 2016 10:13:59 +0200
Subject: [R] Antwort: Re: Antwort: Re: Antwort: Re: Re: sink(): Cannot open
	file (SOLVED)
In-Reply-To: <CAFDcVCTksQ9EmqH_O5GGd1ubOq9M+SDmV2NSHRp0X2i=vNbpnw@mail.gmail.com>
References: <OF15A2364C.38B38E20-ONC1257FAF.00287156-C1257FAF.0028D3F1@lotus.hawesko.de>
	<CA+8X3fWKAJysbwP+whoDrSnT8W3njAUq5LwmjTp3qq-AOdanzg@mail.gmail.com>
	<OF680609C9.B98EF9B5-ONC1257FAF.003C5B6B-C1257FAF.003CF31F@lotus.hawesko.de>
	<CA+8X3fV=Cc8n0WBk6JjobbHm0E+R4ss+7is233o9HYVwGaiQ8Q@mail.gmail.com>
	<OFF8B5EC26.08CB1CFC-ONC1257FAF.00526FBA-C1257FAF.0052DAB9@lotus.hawesko.de>
	<5731C2BC020000CB001536F4@smtp.medicine.umaryland.edu>
	<5732149A.7080203@gmail.com>
	<OFBC7434F2.0E57B1FE-ONC1257FB0.005C1753-C1257FB0.005C38DA@lotus.hawesko.de>
	<CAFDcVCTksQ9EmqH_O5GGd1ubOq9M+SDmV2NSHRp0X2i=vNbpnw@mail.gmail.com>
Message-ID: <OFA229D574.A03C2E31-ONC1257FB1.0027B67C-C1257FB1.002D39CA@lotus.hawesko.de>

Hi Henrik, Jim, Sarah, Duncan,
Hi All,

I have tried the built-in solution using PowerShell:

$lockedFile="C:\Windows\System32\wshtcpip.dll" 
Get-Process | foreach{$processVar = $_;$_.Modules | foreach{if($_.FileName 
-eq $lockedFile){$processVar.Name + " PID:" + $processVar.id}}}

It did not show any processes.

Then I tried the solution using "RessourceMonitor". There I found two 
processes:

rstudio.exe
rsession.exe

Right-clicking on rstudio.exe and selecting "Warteschlange analysieren" (= 
analyse queue?) showed nothing. Right-clicking on rsession.exe and 
selecting "Warteschlage" said:

"Mindestens ein Thread von rsession.exe wartet auf die Fertigstellung von 
Netzwerk E/A". (= "At least one thread of "rsession.exe" is waiting for 
finishing a network i/o operation").

Putting rsession.exe into the search field of the handles tap of 
RessourceMonitor gave no results. No handles were identified.

I can not follow the suggestions where installation of software is 
required due to security rules of the company I work for.

I had a look at different R versions on my machine:

1) R i386 3.2.2
2) R i386 3.2.4 (revised)
3) R i386 3.2.5
4) R x54 3.2.2
5) R x64 3.2.4 (revised)
6) R x64 3.2.5

I did 

## capture all the output to a file.
zz <- file("C:/Temp/all.Rout", open = "wt")
sink(zz)
sink(zz, type = "message")
try(log("a"))
## back to the console
sink(type = "message")
sink()
unlink("C:/Temp/all.Rout")

on R i386 3.2.2 and R x64 3.2.2 directly without RStudio. In both cases 
the file was locked.

Adding

close(zz)

solved the problem in both versions.

Encouraged by this I tired (successivly refered to as "complete code")

## capture all the output to a file.
zz <- file("C:/Temp/all.Rout", open = "wt")
sink(zz)
sink(zz, type = "message")
try(log("a"))
## back to the console
sink(type = "message")
sink()
unlink("C:/Temp/all.Rout")
close(zz)

on R i386 3.2.4 (revised) and R x64 3.2.4 (revised) without RStudio. Works 
in both cases. The same with R i386 3.2.5 and R x64 3.2.5 each without 
RStudio.

It did the same with RStudio altering the R version in the RStudio session 
using "complete code". The results are:

R i386 3.2.2: OK
R. x64 3.2.2: OK
R i386 3.2.4 (revised): OK
R x64 3.2.4 (revised): OK
R i386 3.2.5: OK
R x64 3.2.5: OK

This got me lost. I had tried the complete code the last days a hundred 
times. It never worked.

Then I restarted my machine powering up RStudio x64 3.2.5 using the 
"complete code" and ... it worked.

I have no idea what was wrong the last days.

As far as I can say today the documentation of ?sink in R is currently

## capture all the output to a file.
zz <- file("all.Rout", open = "wt")
sink(zz)
sink(zz, type = "message")
try(log("a"))
## back to the console
sink(type = "message")
sink()
file.show("all.Rout")

and should be - in my opinion  - supplemented with

close(zz).

Any thoughts?

Kind regards

Georg




Von:    Henrik Bengtsson <henrik.bengtsson at gmail.com>
An:     G.Maubach at weinwolf.de, 
Kopie:  Duncan Murdoch <murdoch.duncan at gmail.com>, "r-help at r-project.org" 
<r-help at r-project.org>
Datum:  11.05.2016 21:48
Betreff:        Re: [R] Antwort: Re: Antwort: Re: Re: sink(): Cannot open 
file



Sounds like it would be helpful to find out exactly which process is
holding on to the file in order to figure out what's going on. From a
quick look, it seems that

  
http://superuser.com/questions/117902/find-out-which-process-is-locking-a-file-or-folder-in-windows


gives some useful info on how to track down the process that looks the 
file.

/Henrik

On Wed, May 11, 2016 at 9:47 AM,  <G.Maubach at weinwolf.de> wrote:
> Duncan,
>
> thanks for the hint.
>
> I have done it correctly in R fashion
>
> ## capture all the output to a file.
> zz <- file("C:/Temp/all.Rout", open = "wt")
> sink(zz)
> sink(zz, type = "message")
> try(log("a"))
> ## back to the console
> sink(type = "message")
> sink()
> unlink("C:/Temp/all.Rout")
>
> But the error persits.
>
> Kind regards
>
> Georg
>
>
>
>
> Von:    Duncan Murdoch <murdoch.duncan at gmail.com>
> An:     John Sorkin <jsorkin at grecc.umaryland.edu>, drjimlemon at gmail.com,
> G.Maubach at weinwolf.de,
> Kopie:  r-help at r-project.org
> Datum:  10.05.2016 19:03
> Betreff:        Re: [R] Antwort: Re: Re: sink(): Cannot open file
>
>
>
> On 10/05/2016 11:15 AM, John Sorkin wrote:
>> George,
>> I do not know what operating system you are working with, but when I 
use
> sink() under windows, I need to specify a valid path which I don't see 
in
> your code. I might, for example specify:
>>
>> sink("c:\myfile.txt")
>
> Note that the backslash should be doubled (so it isn't interpreted as an
> escape for the "m" that follows it), or replaced with a forward slash.
>
> Duncan Murdoch
>
>>   R code goes here
>> sink()
>>
>> with the expectation that I would create a file myfile.txt that would
> contain the output of my R program.
>>
>> John
>>
>>
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>> >>> <G.Maubach at weinwolf.de> 05/10/16 11:10 AM >>>
>> Hi Jim,
>>
>> I tried:
>>
>> sink("all.Rout")
>> try(log("a"))
>> sink()
>>
>> The program executes without warning or error. The file "all.Rout" is
>> begin created. Nothing will be written to it. The file is accessable
>> rights after the execution of the program by notepad.exe.
>>
>> The program
>>
>> zz <- file("all.Rout", open = "wt")
>> sink(zz, type = "message")
>> try(log("a"))
>> sink()
>> close(zz)
>> unlink(zz)
>>
>> creates the file, does not write anything to it and is not accessable
>> after program execution in R with notepad.exe.
>>
>> Any ideas what happens behind the szenes?
>>
>> Kind regards
>>
>> Georg
>>
>>
>>
>>
>> Von: Jim Lemon <drjimlemon at gmail.com>
>> An: G.Maubach at weinwolf.de,
>> Kopie: r-help mailing list <r-help at r-project.org>
>> Datum: 10.05.2016 13:16
>> Betreff: Re: Re: [R] sink(): Cannot open file
>>
>>
>>
>> Have you tried:
>>
>> sink("all.Rout")
>> try(log("a"))
>> sink()
>>
>> Jim
>>
>> On Tue, May 10, 2016 at 9:05 PM, <G.Maubach at weinwolf.de> wrote:
>> > Hi Jim,
>> >
>> > thanks for your reply.
>> >
>> > ad 1)
>> > "all.Rout" was created in the correct directory. It exists properly
> with
>> > correct file properties on Windows, e.g. creation date and time and
> file
>> > size information.
>> >
>> > ad 2)
>> > I can not access the file with Notepad.exe directly after it was
> created
>> > by R. The error message is (translated):
>> >
>> > "Cannot access file "all.Rout". The file is opened by another
> process."
>> >
>> > ad 3)
>> > If I close R completely the file access is released. Then I can read
> the
>> > file using Notepad.exe. The contents is:
>> >
>> > Error in log("a") : non-numeric argument to mathematical function
>> >
>> > I tried
>> >
>> > close(zz)
>> >
>> > but the error persists.
>> >
>> > To me it looks like R is still accessing the file and not releasing
> the
>> > connection for other programs. close(zz) should have solved the
> problem
>> > but unfortantely it doesn't.
>> >
>> > What else could I try?
>> >
>> > Kind regards
>> >
>> > Georg
>> >
>> >
>> >
>> >
>> > Von: Jim Lemon <drjimlemon at gmail.com>
>> > An: G.Maubach at weinwolf.de,
>> > Kopie: r-help mailing list <r-help at r-project.org>
>> > Datum: 10.05.2016 12:50
>> > Betreff: Re: [R] sink(): Cannot open file
>> >
>> >
>> >
>> > Hi Georg,
>> > I don't suppose that you have:
>> >
>> > 1) checked that the file "all.Rout" exists somewhere?
>> >
>> > 2) if so, looked at the file with Notepad, perhaps?
>> >
>> > 3) let us in on the secret by pasting the contents of "all.Rout" into
>> > your message if it is not too big?
>> >
>> > At a guess, trying:
>> >
>> > close(zz)
>> >
>> > might get you there.
>> >
>> > Jim
>> >
>> > On Tue, May 10, 2016 at 5:25 PM, <G.Maubach at weinwolf.de> wrote:
>> >> Hi All,
>> >>
>> >> I would like to route the output to a file using sink(). When using
> the
>> >> example from the ?sink documentation:
>> >>
>> >> sink("sink-examp.txt")
>> >> i <- 1:10
>> >> outer(i, i, "*")
>> >> sink()
>> >> unlink("sink-examp.txt")
>> >>
>> >> ## capture all the output to a file.
>> >> zz <- file("all.Rout", open = "wt")
>> >> sink(zz)
>> >> sink(zz, type = "message")
>> >> try(log("a"))
>> >> ## back to the console
>> >> sink(type = "message")
>> >> sink()
>> >> file.show("all.Rout")
>> >>
>> >> I can not open the file in Windows Explorer. The error message is:
>> >>
>> >> "Cannot open file. File is in use be another proces."
>> >>
>> >> How can I close the file in a manner that I can open it right after
> it
>> > was
>> >> created?
>> >>
>> >> Kind regards
>> >>
>> >> Georg
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> Confidentiality Statement:
>> This email message, including any attachments, is for ...{{dropped:14}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jan.kacaba at gmail.com  Thu May 12 10:18:44 2016
From: jan.kacaba at gmail.com (Jan Kacaba)
Date: Thu, 12 May 2016 10:18:44 +0200
Subject: [R] break string at specified possitions
In-Reply-To: <CA+8X3fU8mGykM++TSU-LDZRKxL3oUs0KFaS10P3mkoDU1z2gUA@mail.gmail.com>
References: <CAHby=D1UYkGp-L_hVgy8Xus=_wVjDmV=6_x39Dyd0Pt38-H02w@mail.gmail.com>
	<CAGxFJbTi0SPb9STcFwu1DaGA2Ynd5K6v6KWNe7=ubh_Nc3uo+g@mail.gmail.com>
	<CAHby=D3aXQ6WF3wWWkYob1+a5wPhB0+yTGrVTJ9tzpcQz8i4kw@mail.gmail.com>
	<CA+8X3fUpTkyJiyq=nLmYa-ogLiwYXPjcxFgZdgWz32aD6Vy7uA@mail.gmail.com>
	<CA+8X3fU8mGykM++TSU-LDZRKxL3oUs0KFaS10P3mkoDU1z2gUA@mail.gmail.com>
Message-ID: <CAHby=D0MJEWRaX_UH9Q1UU2rT0QORF-rQdxhQ=KWHt8R7sK80g@mail.gmail.com>

Nice solution Jim, thank you.



2016-05-12 2:45 GMT+02:00 Jim Lemon <drjimlemon at gmail.com>:
> Hi again,
> Sorry, that should be:
>
> chop_string<-function(x,ends) {
>  starts<-c(1,ends[-length(ends)]+1)
>  return(substring(x,starts,ends))
> }
>
> Jim
>
> On Thu, May 12, 2016 at 10:05 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>> Hi Jan,
>> This might be helpful:
>>
>> chop_string<-function(x,ends) {
>>  starts<-c(1,ends[-length(ends)]-1)
>>  return(substring(x,starts,ends))
>> }
>>
>> Jim
>>
>>
>> On Thu, May 12, 2016 at 7:23 AM, Jan Kacaba <jan.kacaba at gmail.com> wrote:
>>> Here is my attempt at function which computes margins from positions.
>>>
>>> require("stringr")
>>> require("dplyr")
>>>
>>> ends<-seq(10,100,8)  # end margins
>>> test_string<-"Lorem ipsum dolor sit amet, consectetuer adipiscing
>>> elit. Aliquam in lorem sit amet leo accumsan lacinia."
>>>
>>> sekoj=function(ends){
>>>   l_ends<-length(ends)
>>>   begs=vector(mode="integer",l_ends)
>>>   begs[1]=1
>>>   for (i in 2:(l_ends)){
>>>     begs[i]<-ends[i-1]+1
>>>   }
>>>   margs<-rbind(begs,ends)
>>>   margs<-cbind(margs,c(ends[l_ends]+1,-1))
>>>   #rownames(margs)<-c("beg","end")
>>>   return(margs)
>>> }
>>> margins<-sekoj(ends)
>>> str_sub(test_string,margins[1,],margins[2,]) %>% print
>>>
>>> Code to run in browser:
>>> http://www.r-fiddle.org/#/fiddle?id=rVmNVxDV
>>>
>>> 2016-05-11 23:12 GMT+02:00 Bert Gunter <bgunter.4567 at gmail.com>:
>>>> Dunno -- but you might have a look at Hadley Wickham's 'stringr' package:
>>>> https://cran.r-project.org/web/packages/stringr/stringr.pdf
>>>>
>>>> Cheers,
>>>>
>>>> Bert
>>>>
>>>>
>>>> Bert Gunter
>>>>
>>>> "The trouble with having an open mind is that people keep coming along
>>>> and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>
>>>>
>>>> On Wed, May 11, 2016 at 1:12 PM, Jan Kacaba <jan.kacaba at gmail.com> wrote:
>>>>> Dear R-help
>>>>>
>>>>> I would like to split long string at specified precomputed positions.
>>>>> 'substring' needs beginings and ends. Is there a native function which
>>>>> accepts positions so I don't have to count second argument?
>>>>>
>>>>> For example I have vector of possitions pos<-c(5,10,19). Substring
>>>>> needs input first=c(1,6,11) and last=c(5,10,19). There is no problem
>>>>> to write my own function. Just asking.
>>>>>
>>>>> Derek
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From maechler at stat.math.ethz.ch  Thu May 12 10:36:52 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 12 May 2016 10:36:52 +0200
Subject: [R] break string at specified possitions
In-Reply-To: <fdbd774e-c9cf-009a-1518-6108120f833b@gmail.com>
References: <CAHby=D1UYkGp-L_hVgy8Xus=_wVjDmV=6_x39Dyd0Pt38-H02w@mail.gmail.com>
	<CAGxFJbTi0SPb9STcFwu1DaGA2Ynd5K6v6KWNe7=ubh_Nc3uo+g@mail.gmail.com>
	<CAHby=D3aXQ6WF3wWWkYob1+a5wPhB0+yTGrVTJ9tzpcQz8i4kw@mail.gmail.com>
	<fdbd774e-c9cf-009a-1518-6108120f833b@gmail.com>
Message-ID: <22324.16548.65736.260367@stat.math.ethz.ch>


> On 5/11/2016 2:23 PM, Jan Kacaba wrote:
> > Here is my attempt at function which computes margins from positions.
> >
> > require("stringr")
> > require("dplyr")
> >
> > ends<-seq(10,100,8)  # end margins
> > test_string<-"Lorem ipsum dolor sit amet, consectetuer adipiscing
> > elit. Aliquam in lorem sit amet leo accumsan lacinia."
> >
> > sekoj=function(ends){
> >   l_ends<-length(ends)
> >   begs=vector(mode="integer",l_ends)
> >   begs[1]=1
> >   for (i in 2:(l_ends)){
> >     begs[i]<-ends[i-1]+1
> >   }
> >   margs<-rbind(begs,ends)
> >   margs<-cbind(margs,c(ends[l_ends]+1,-1))
> >   #rownames(margs)<-c("beg","end")
> >   return(margs)
> > }
> > margins<-sekoj(ends)
> > str_sub(test_string,margins[1,],margins[2,]) %>% print
> >
> > Code to run in browser:
> > http://www.r-fiddle.org/#/fiddle?id=rVmNVxDV
> >
> > 2016-05-11 23:12 GMT+02:00 Bert Gunter <bgunter.4567 at gmail.com>:
> >> Dunno -- but you might have a look at Hadley Wickham's 'stringr' package:
> >> https://cran.r-project.org/web/packages/stringr/stringr.pdf
> >>
> >> Cheers,
> >>
> >> Bert
> >>
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> >> and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Wed, May 11, 2016 at 1:12 PM, Jan Kacaba <jan.kacaba at gmail.com> wrote:
> >>> Dear R-help
> >>>
> >>> I would like to split long string at specified precomputed positions.
> >>> 'substring' needs beginings and ends. Is there a native function which
> >>> accepts positions so I don't have to count second argument?
> >>>
> >>> For example I have vector of possitions pos<-c(5,10,19). Substring
> >>> needs input first=c(1,6,11) and last=c(5,10,19). There is no problem
> >>> to write my own function. Just asking.
> >>>
> >>> Derek
> >>>
> 
> I think you can simply this. just create a function (I'll call it begs) 
> to compute the beginning positions.
> 
>      begs <- function(x) c(0,x[-length(x)])+1
> 
> Then, then use that function in your call to str_sub
> 
>      str_sub(test_string,begs(ends),ends) %>% print
> 

and why can't you simply use base R's  substr() function ?
Packages (such as 'stringr' in this case) have their uses and
great merits, but using base R seems more sensical to me (also
slightly more future-proof).


> Hope this is helpful,

Yes, I'd think so , because that was also my quick thought when
I read the OP's question.

Martin


--
Martin Maechler, ETH Zurich & R Core


From maechler at stat.math.ethz.ch  Thu May 12 10:41:28 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 12 May 2016 10:41:28 +0200
Subject: [R]  Antwort: Re: Re:  Antwort: Re: Re: sink(): Cannot open file
In-Reply-To: <OFE75E365B.FBDCB581-ONC1257FB0.005B5E6B-C1257FB0.005C1243@lotus.hawesko.de>
References: <OF15A2364C.38B38E20-ONC1257FAF.00287156-C1257FAF.0028D3F1@lotus.hawesko.de>
	<CA+8X3fWKAJysbwP+whoDrSnT8W3njAUq5LwmjTp3qq-AOdanzg@mail.gmail.com>
	<OF680609C9.B98EF9B5-ONC1257FAF.003C5B6B-C1257FAF.003CF31F@lotus.hawesko.de>
	<CA+8X3fV=Cc8n0WBk6JjobbHm0E+R4ss+7is233o9HYVwGaiQ8Q@mail.gmail.com>
	<OFF8B5EC26.08CB1CFC-ONC1257FAF.00526FBA-C1257FAF.0052DAB9@lotus.hawesko.de>
	<CAM_vjukn65HMyvUVWcNATyb660xPa-GYkxJV81_witEFxeFHhQ@mail.gmail.com>
	<OFB1F950C2.FF819EF7-ONC1257FAF.005A9AE4-C1257FAF.005B0ACB@lotus.hawesko.de>
	<CAM_vjukqpe_wUvsycbGM-4_CAGeG2Qu+bkvQe=53hkSN+zQt9A@mail.gmail.com>
	<OFE75E365B.FBDCB581-ONC1257FB0.005B5E6B-C1257FB0.005C1243@lotus.hawesko.de>
Message-ID: <22324.16824.223426.299672@stat.math.ethz.ch>


> Hi Sarah,
> yes, I followed your suggestion.

I doubt that you followed it correctly. Sarah's advise is
usually really very sound -- and your code below is *not* :

> If I do exactly what is in the example of the documentation:

> sink("C:/Temp/sink-examp.txt")
> i <- 1:10
> outer(i, i, "*")
> sink()
> unlink("C:/Temp/sink-examp.txt")

> it does not write anything, i. e. no file is created in "C:/Temp/". The 
> script is executed without an error or warning message.

Well, did you ever lookup what unlink() does ?
I save you the time : it does *REMOVE* a file.

So no wonder that you don't see any result after executing the
above R code block..

Martin


From G.Maubach at weinwolf.de  Thu May 12 11:10:08 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Thu, 12 May 2016 11:10:08 +0200
Subject: [R] Antwort: Antwort: Re: Re: Antwort: Re: Re: sink(): Cannot open
	file
In-Reply-To: <22324.16824.223426.299672@stat.math.ethz.ch>
References: <OF15A2364C.38B38E20-ONC1257FAF.00287156-C1257FAF.0028D3F1@lotus.hawesko.de>
	<CA+8X3fWKAJysbwP+whoDrSnT8W3njAUq5LwmjTp3qq-AOdanzg@mail.gmail.com>	<OF680609C9.B98EF9B5-ONC1257FAF.003C5B6B-C1257FAF.003CF31F@lotus.hawesko.de>
	<CA+8X3fV=Cc8n0WBk6JjobbHm0E+R4ss+7is233o9HYVwGaiQ8Q@mail.gmail.com>	<OFF8B5EC26.08CB1CFC-ONC1257FAF.00526FBA-C1257FAF.0052DAB9@lotus.hawesko.de>
	<CAM_vjukn65HMyvUVWcNATyb660xPa-GYkxJV81_witEFxeFHhQ@mail.gmail.com>	<OFB1F950C2.FF819EF7-ONC1257FAF.005A9AE4-C1257FAF.005B0ACB@lotus.hawesko.de>
	<CAM_vjukqpe_wUvsycbGM-4_CAGeG2Qu+bkvQe=53hkSN+zQt9A@mail.gmail.com>	<OFE75E365B.FBDCB581-ONC1257FB0.005B5E6B-C1257FB0.005C1243@lotus.hawesko.de>
	<22324.16824.223426.299672@stat.math.ethz.ch>
Message-ID: <OF762E6963.8C44272D-ONC1257FB1.00313E4A-C1257FB1.00325E02@lotus.hawesko.de>

Hi Martin,

many thanks for following-up on my question.

I did it again:

## capture all the output to a file.
zz <- file("C:/Temp/all.Rout", open = "wt")
sink(zz)
sink(zz, type = "message")
try(log("a"))
## back to the console
sink(type = "message")
sink()
close(zz)

This works.

I tried several other combinations of the commands, e.g.

## capture all the output to a file.
zz <- file("C:/Temp/all.Rout", open = "wt")
sink(zz)
sink(zz, type = "message")
try(log("a"))
close(zz)

Does not work.

As far as I have understood right now, I have to loosen the connection of 
the streams with sink(zz, type = "message") and sink() before I can close 
the file connection itself.

If I did it like in the last example the connection to the file is lost 
and then the connection to the streams of sink() can not be recovered. 
This will last until the R session is closed and opened again.

To me it looks like I need to learn more about the operation of R under 
the hood.

Kind regards

Georg




Von:    Martin Maechler <maechler at stat.math.ethz.ch>
An:     <G.Maubach at weinwolf.de>, 
Kopie:  Sarah Goslee <sarah.goslee at gmail.com>, <r-help at r-project.org>
Datum:  12.05.2016 10:40
Betreff:        [R] Antwort: Re: Re:  Antwort: Re: Re: sink(): Cannot open 
file




> Hi Sarah,
> yes, I followed your suggestion.

I doubt that you followed it correctly. Sarah's advise is
usually really very sound -- and your code below is *not* :

> If I do exactly what is in the example of the documentation:

> sink("C:/Temp/sink-examp.txt")
> i <- 1:10
> outer(i, i, "*")
> sink()
> unlink("C:/Temp/sink-examp.txt")

> it does not write anything, i. e. no file is created in "C:/Temp/". The 
> script is executed without an error or warning message.

Well, did you ever lookup what unlink() does ?
I save you the time : it does *REMOVE* a file.

So no wonder that you don't see any result after executing the
above R code block..

Martin


From mario.lavezzi at unipa.it  Thu May 12 11:26:23 2016
From: mario.lavezzi at unipa.it (A M Lavezzi)
Date: Thu, 12 May 2016 10:26:23 +0100
Subject: [R] building a spatial matrix
Message-ID: <CAOZPQW7DOicT9pS8H2BA3gxnJLg0wYTu9UhinwpgywcSDGoKFw@mail.gmail.com>

Hello,

I have a sample of 1327  locations, each one idetified by an id and a
numerical code.

I need to build a spatial matrix, say, M, i.e. a 1327x1327 matrix
collecting distances among the locations.

M(i,i) should be 0, M(i,j) should contain the distance among location i and
j

I shoud use data organized in the following way:

1) id_cell contains the identifier (id) of each location (1...1327) and the
numerical code of the location (f_cell) (see head of id_cell below)

> head(id_cell)
     id  f_cell
1    1   2120
12  2     204
22  3   2546
24  4   1327
34  5   1729
43  6   2293

2) censDist contains, for each location identified by its numerical code,
the distance to other locations (censDist has 1.5 million rows). The
head(consist) below, for example, reads like this:

location 2924 has a distance to 2732 of 1309.7525
location 2924 has a distance to 2875 of 696.2891,
etc.

> head(censDist)
  f_cell f  _cell_neigh  distance
1   2924         2732   1309.7525
2   2924         2875     696.2891
3   2924         2351   1346.0561
4   2924         2350   1296.9804
5   2924         2725   1278.1877
6   2924         2721   1346.9126


Basically, for every location in  id_cell I should pick up the distance to
other locations in id_cell from censDist, and allocate it in M

I have not come up with a satisfactory vectorizion of this problem and
using a loop is out of question.

Thanks for your help
Mario


-- 
Andrea Mario Lavezzi
DiGi,Sezione Diritto e Societ?
Universit? di Palermo
Piazza Bologni 8
90134 Palermo, Italy
tel. ++39 091 23892208
fax ++39 091 6111268
skype: lavezzimario
email: mario.lavezzi (at) unipa.it
web: http://www.unipa.it/~mario.lavezzi

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Thu May 12 15:51:13 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 12 May 2016 09:51:13 -0400
Subject: [R] building a spatial matrix
In-Reply-To: <CAOZPQW7DOicT9pS8H2BA3gxnJLg0wYTu9UhinwpgywcSDGoKFw@mail.gmail.com>
References: <CAOZPQW7DOicT9pS8H2BA3gxnJLg0wYTu9UhinwpgywcSDGoKFw@mail.gmail.com>
Message-ID: <CAM_vjuk8hVY6F67behO+YQ1R5gSxb5xTxQgysSwZmigmPoQXow@mail.gmail.com>

I don't see any reason why a loop is out of the question, and
answering would have been much easier if you'd included the requested
reproducible data, but what about this?

This solution is robust to pairs from idcell being absent in censDist,
and to the difference from A to B being different than the distance
from B to A, but not to A-B appearing twice. If that's possible,
you'll need to figure out how to manage it.

# create some fake data

idcell <- data.frame(
  id = seq_len(5),
  fcell = sample(1:100, 5))

censDist <- expand.grid(fcell=seq_len(100), cellneigh=seq_len(100))
censDist$distance <- runif(nrow(censDist))

# assemble the non-symmetric distance matrix
result <- subset(censDist, fcell %in% idcell$fcell & cellneigh %in%
idcell$fcell)
result.m <- matrix(NA, nrow=nrow(idcell), ncol=nrow(idcell))
result.m[factor(result$fcell), factor(result$cellneigh)] <- result$distance

Sarah

On Thu, May 12, 2016 at 5:26 AM, A M Lavezzi <mario.lavezzi at unipa.it> wrote:
> Hello,
>
> I have a sample of 1327  locations, each one idetified by an id and a
> numerical code.
>
> I need to build a spatial matrix, say, M, i.e. a 1327x1327 matrix
> collecting distances among the locations.
>
> M(i,i) should be 0, M(i,j) should contain the distance among location i and
> j
>
> I shoud use data organized in the following way:
>
> 1) id_cell contains the identifier (id) of each location (1...1327) and the
> numerical code of the location (f_cell) (see head of id_cell below)
>
>> head(id_cell)
>      id  f_cell
> 1    1   2120
> 12  2     204
> 22  3   2546
> 24  4   1327
> 34  5   1729
> 43  6   2293
>
> 2) censDist contains, for each location identified by its numerical code,
> the distance to other locations (censDist has 1.5 million rows). The
> head(consist) below, for example, reads like this:
>
> location 2924 has a distance to 2732 of 1309.7525
> location 2924 has a distance to 2875 of 696.2891,
> etc.
>
>> head(censDist)
>   f_cell f  _cell_neigh  distance
> 1   2924         2732   1309.7525
> 2   2924         2875     696.2891
> 3   2924         2351   1346.0561
> 4   2924         2350   1296.9804
> 5   2924         2725   1278.1877
> 6   2924         2721   1346.9126
>
>
> Basically, for every location in  id_cell I should pick up the distance to
> other locations in id_cell from censDist, and allocate it in M
>
> I have not come up with a satisfactory vectorizion of this problem and
> using a loop is out of question.
>
> Thanks for your help
> Mario
>
>


From albapompeo at gmail.com  Thu May 12 13:45:40 2016
From: albapompeo at gmail.com (Alba Pompeo)
Date: Thu, 12 May 2016 08:45:40 -0300
Subject: [R] Warning when running R - can't install packages either
Message-ID: <CAJDAfTBMYFH0PcRG7scf+g5GAbkPC2yz4UF+1w+d5=xssipaHQ@mail.gmail.com>

Hello.

I've tried to run R, but I receive many warnings and can't do simple
stuff such as installing packages.

Here's the full log when I run it.

http://pastebin.com/raw/2BkNpTte

Does anyone know what could be wrong here?

Thanks a lot.


From lorenzo.isella at gmail.com  Thu May 12 16:49:52 2016
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Thu, 12 May 2016 16:49:52 +0200
Subject: [R] Bootstrap Methods for Confidence Intervals -- glmnet
Message-ID: <20160512144952.GA3271@localhost.localdomain>

Dear All,
Please have a look at the code at the end of the email.
It is just an example of regression based on glmnet with some
artificial data.
My question is how I can evaluate the uncertainty of the prediction
yhat.

It looks like there are some reasons for not providing a standard
error estimate, see e.g.



http://stackoverflow.com/questions/12937331/how-to-get-statistical-summary-information-from-glmnet-model
and
https://www.reddit.com/r/statistics/comments/1vg8k0/standard_errors_in_glmnet/

However, from what I read in this thesis

https://air.unimi.it/retrieve/handle/2434/153099/133417/phd_unimi_R07738.pdf

(see sections 3.2 and 3.3)

and in the quoted papers

http://www.stat.cmu.edu/~fienberg/Statistics36-756/Efron1979.pdf
and
http://www.ams.org/journals/proc/2010-138-12/S0002-9939-2010-10474-4/S0002-9939-2010-10474-4.pdf

there are some bootstrap methods that are quite general and applicable
well beyond the case of glmnet.
Is there anything already implemented to help me out? Is anybody aware
of this?
Cheers

Lorenzo

#########################################################################
#########################################################################
#########################################################################
#########################################################################
#########################################################################


library(glmnet)


# Generate data
set.seed(19875)  # Set seed for reproducibility
n <- 1000  # Number of observations
p <- 5000  # Number of predictors included in model
real_p <- 15  # Number of true predictors
x <- matrix(rnorm(n*p), nrow=n, ncol=p)
y <- apply(x[,1:real_p], 1, sum) + rnorm(n)

# Split data into train (2/3) and test (1/3) sets
train_rows <- sample(1:n, .66*n)
x.train <- x[train_rows, ]
x.test <- x[-train_rows, ]

y.train <- y[train_rows]
y.test <- y[-train_rows]



fit.elnet <- glmnet(x.train, y.train, family="gaussian", alpha=.5)

yhat <- predict(fit.elnet, s=fit.elnet$lambda, newx=x.test)


From jdnewmil at dcn.davis.ca.us  Thu May 12 17:02:02 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 12 May 2016 08:02:02 -0700
Subject: [R] Warning when running R - can't install packages either
In-Reply-To: <CAJDAfTBMYFH0PcRG7scf+g5GAbkPC2yz4UF+1w+d5=xssipaHQ@mail.gmail.com>
References: <CAJDAfTBMYFH0PcRG7scf+g5GAbkPC2yz4UF+1w+d5=xssipaHQ@mail.gmail.com>
Message-ID: <AE224EFA-FE50-4B6A-90C6-09D690EC5622@dcn.davis.ca.us>

Looks to me like something outside of R is blocking network access by R. That could be anything from you don't have networking setup to some security policy or firewall configuration. I doubt this will be the right place to resolve those issues. 
-- 
Sent from my phone. Please excuse my brevity.

On May 12, 2016 4:45:40 AM PDT, Alba Pompeo <albapompeo at gmail.com> wrote:
>Hello.
>
>I've tried to run R, but I receive many warnings and can't do simple
>stuff such as installing packages.
>
>Here's the full log when I run it.
>
>http://pastebin.com/raw/2BkNpTte
>
>Does anyone know what could be wrong here?
>
>Thanks a lot.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu May 12 17:02:13 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 12 May 2016 08:02:13 -0700
Subject: [R] Bootstrap Methods for Confidence Intervals -- glmnet
In-Reply-To: <20160512144952.GA3271@localhost.localdomain>
References: <20160512144952.GA3271@localhost.localdomain>
Message-ID: <CAGxFJbTOnfrO=eWNaOAwX_gQ7FMY0woLD0hOgX2+ta3mcmXAow@mail.gmail.com>

Lorenzo:

This is a complicated and subtle question that I believe is mostly
about statistical methodology, not R. I would suggest that you post
your query to stats.stackexchange.com rather than here in order to
determine *what* you should do. Then, if necessary, you can come back
here to ask about *how* to do it in R (with code from your failed
attempts, etc.).

Better yet, you might wish to have this discussion with a local
expert, if you can find one.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, May 12, 2016 at 7:49 AM, Lorenzo Isella
<lorenzo.isella at gmail.com> wrote:
> Dear All,
> Please have a look at the code at the end of the email.
> It is just an example of regression based on glmnet with some
> artificial data.
> My question is how I can evaluate the uncertainty of the prediction
> yhat.
>
> It looks like there are some reasons for not providing a standard
> error estimate, see e.g.
>
>
>
> http://stackoverflow.com/questions/12937331/how-to-get-statistical-summary-information-from-glmnet-model
> and
> https://www.reddit.com/r/statistics/comments/1vg8k0/standard_errors_in_glmnet/
>
> However, from what I read in this thesis
>
> https://air.unimi.it/retrieve/handle/2434/153099/133417/phd_unimi_R07738.pdf
>
> (see sections 3.2 and 3.3)
>
> and in the quoted papers
>
> http://www.stat.cmu.edu/~fienberg/Statistics36-756/Efron1979.pdf
> and
> http://www.ams.org/journals/proc/2010-138-12/S0002-9939-2010-10474-4/S0002-9939-2010-10474-4.pdf
>
> there are some bootstrap methods that are quite general and applicable
> well beyond the case of glmnet.
> Is there anything already implemented to help me out? Is anybody aware
> of this?
> Cheers
>
> Lorenzo
>
> #########################################################################
> #########################################################################
> #########################################################################
> #########################################################################
> #########################################################################
>
>
> library(glmnet)
>
>
> # Generate data
> set.seed(19875)  # Set seed for reproducibility
> n <- 1000  # Number of observations
> p <- 5000  # Number of predictors included in model
> real_p <- 15  # Number of true predictors
> x <- matrix(rnorm(n*p), nrow=n, ncol=p)
> y <- apply(x[,1:real_p], 1, sum) + rnorm(n)
>
> # Split data into train (2/3) and test (1/3) sets
> train_rows <- sample(1:n, .66*n)
> x.train <- x[train_rows, ]
> x.test <- x[-train_rows, ]
>
> y.train <- y[train_rows]
> y.test <- y[-train_rows]
>
>
>
> fit.elnet <- glmnet(x.train, y.train, family="gaussian", alpha=.5)
>
> yhat <- predict(fit.elnet, s=fit.elnet$lambda, newx=x.test)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From martin.morgan at roswellpark.org  Thu May 12 17:12:23 2016
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Thu, 12 May 2016 11:12:23 -0400
Subject: [R] Warning when running R - can't install packages either
In-Reply-To: <CAJDAfTBMYFH0PcRG7scf+g5GAbkPC2yz4UF+1w+d5=xssipaHQ@mail.gmail.com>
References: <CAJDAfTBMYFH0PcRG7scf+g5GAbkPC2yz4UF+1w+d5=xssipaHQ@mail.gmail.com>
Message-ID: <57349D57.6030301@roswellpark.org>



On 05/12/2016 07:45 AM, Alba Pompeo wrote:
> Hello.
>
> I've tried to run R, but I receive many warnings and can't do simple
> stuff such as installing packages.
>
> Here's the full log when I run it.
>
> http://pastebin.com/raw/2BkNpTte
>
> Does anyone know what could be wrong here?

do you have any success when choosing a non-https mirror, #28 in your 
screenshot?

Martin Morgan

>
> Thanks a lot.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


This email message may contain legally privileged and/or...{{dropped:2}}


From yoursurrogategod at gmail.com  Thu May 12 19:19:54 2016
From: yoursurrogategod at gmail.com (yoursurrogategod at gmail.com)
Date: Thu, 12 May 2016 13:19:54 -0400
Subject: [R] What is the easiest way to turn a dataframe into a barplot?
Message-ID: <056474CC-7FCD-48FF-8D21-CDE4A83F66A5@gmail.com>

Hello, I can't post my code since it's on a work computer.

But basically, I have a dataframe that has two columns, one is a string and the other is an integer.  I want to turn this into a vertival barplot where on the x-axis I have the string in the first columb and then the plot will display the integer count.

I have found many examples online and most of those matched either odd edge cases or putting the data into a format that strips out some of the data and I can't use it later.

This should be a breeze, what am I missing?

From wdunlap at tibco.com  Thu May 12 19:31:42 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 12 May 2016 10:31:42 -0700
Subject: [R] What is the easiest way to turn a dataframe into a barplot?
In-Reply-To: <056474CC-7FCD-48FF-8D21-CDE4A83F66A5@gmail.com>
References: <056474CC-7FCD-48FF-8D21-CDE4A83F66A5@gmail.com>
Message-ID: <CAF8bMcb7PKaQj5x39V9X3c6JgOP=T5oBJotf-rWr1BsbrvT=2Q@mail.gmail.com>

Does this do what you want?

z <- data.frame(Name=c("One","Three","Twelve","Eleven"), Count=c(1,3,12,11))
with(z, barplot(Count, names=Name, horiz=TRUE))
with(z, barplot(Count, names=Name, horiz=TRUE, las=1))


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, May 12, 2016 at 10:19 AM, yoursurrogategod at gmail.com <
yoursurrogategod at gmail.com> wrote:

> Hello, I can't post my code since it's on a work computer.
>
> But basically, I have a dataframe that has two columns, one is a string
> and the other is an integer.  I want to turn this into a vertival barplot
> where on the x-axis I have the string in the first columb and then the plot
> will display the integer count.
>
> I have found many examples online and most of those matched either odd
> edge cases or putting the data into a format that strips out some of the
> data and I can't use it later.
>
> This should be a breeze, what am I missing?
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu May 12 19:56:18 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 12 May 2016 10:56:18 -0700
Subject: [R] What is the easiest way to turn a dataframe into a barplot?
In-Reply-To: <056474CC-7FCD-48FF-8D21-CDE4A83F66A5@gmail.com>
References: <056474CC-7FCD-48FF-8D21-CDE4A83F66A5@gmail.com>
Message-ID: <EC2EFEB0-F17C-4D6D-831D-7D77B1B707AA@dcn.davis.ca.us>

You are missing a reproducible example. We don't care what is on your home or work computer... we just need to have clear communication, so make up some data that shows the problem and some  code to go with it. You MIGHT have to show some data that does not have the problem in order to highlight the problem for us.
-- 
Sent from my phone. Please excuse my brevity.

On May 12, 2016 10:19:54 AM PDT, "yoursurrogategod at gmail.com" <yoursurrogategod at gmail.com> wrote:
>Hello, I can't post my code since it's on a work computer.
>
>But basically, I have a dataframe that has two columns, one is a string
>and the other is an integer.  I want to turn this into a vertival
>barplot where on the x-axis I have the string in the first columb and
>then the plot will display the integer count.
>
>I have found many examples online and most of those matched either odd
>edge cases or putting the data into a format that strips out some of
>the data and I can't use it later.
>
>This should be a breeze, what am I missing?
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From yoursurrogategod at gmail.com  Thu May 12 20:13:37 2016
From: yoursurrogategod at gmail.com (yoursurrogategod at gmail.com)
Date: Thu, 12 May 2016 14:13:37 -0400
Subject: [R] What is the easiest way to turn a dataframe into a barplot?
In-Reply-To: <CAF8bMcb7PKaQj5x39V9X3c6JgOP=T5oBJotf-rWr1BsbrvT=2Q@mail.gmail.com>
References: <056474CC-7FCD-48FF-8D21-CDE4A83F66A5@gmail.com>
	<CAF8bMcb7PKaQj5x39V9X3c6JgOP=T5oBJotf-rWr1BsbrvT=2Q@mail.gmail.com>
Message-ID: <D8AB947C-F5C7-4392-9052-489C09ABF66D@gmail.com>

Ok, the horizontal names work here.  Thanks.

> On May 12, 2016, at 1:31 PM, William Dunlap <wdunlap at tibco.com> wrote:
> 
> Does this do what you want?
> 
> z <- data.frame(Name=c("One","Three","Twelve","Eleven"), Count=c(1,3,12,11))
> with(z, barplot(Count, names=Name, horiz=TRUE))
> with(z, barplot(Count, names=Name, horiz=TRUE, las=1))
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
>> On Thu, May 12, 2016 at 10:19 AM, yoursurrogategod at gmail.com <yoursurrogategod at gmail.com> wrote:
>> Hello, I can't post my code since it's on a work computer.
>> 
>> But basically, I have a dataframe that has two columns, one is a string and the other is an integer.  I want to turn this into a vertival barplot where on the x-axis I have the string in the first columb and then the plot will display the integer count.
>> 
>> I have found many examples online and most of those matched either odd edge cases or putting the data into a format that strips out some of the data and I can't use it later.
>> 
>> This should be a breeze, what am I missing?
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 

	[[alternative HTML version deleted]]


From tomhopper at gmail.com  Thu May 12 22:59:45 2016
From: tomhopper at gmail.com (Tom Hopper)
Date: Thu, 12 May 2016 16:59:45 -0400
Subject: [R] Warning when running R - can't install packages either
In-Reply-To: <CAJDAfTBMYFH0PcRG7scf+g5GAbkPC2yz4UF+1w+d5=xssipaHQ@mail.gmail.com>
References: <CAJDAfTBMYFH0PcRG7scf+g5GAbkPC2yz4UF+1w+d5=xssipaHQ@mail.gmail.com>
Message-ID: <238A333C-AE09-4131-94CE-E4688A6814D3@gmail.com>

setInternet2() first thing after launching R might fix that.


> On May 12, 2016, at 07:45, Alba Pompeo <albapompeo at gmail.com> wrote:
> 
> Hello.
> 
> I've tried to run R, but I receive many warnings and can't do simple
> stuff such as installing packages.
> 
> Here's the full log when I run it.
> 
> http://pastebin.com/raw/2BkNpTte
> 
> Does anyone know what could be wrong here?
> 
> Thanks a lot.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From albapompeo at gmail.com  Fri May 13 04:25:44 2016
From: albapompeo at gmail.com (Alba Pompeo)
Date: Thu, 12 May 2016 23:25:44 -0300
Subject: [R] Warning when running R - can't install packages either
In-Reply-To: <238A333C-AE09-4131-94CE-E4688A6814D3@gmail.com>
References: <CAJDAfTBMYFH0PcRG7scf+g5GAbkPC2yz4UF+1w+d5=xssipaHQ@mail.gmail.com>
	<238A333C-AE09-4131-94CE-E4688A6814D3@gmail.com>
Message-ID: <CAJDAfTAa0RuZ+CjO0kX-zFaxzVfb2XsBZ_cpA2G-GCoq0qeteA@mail.gmail.com>

Martin Morgan, I tried an HTTP mirror and it worked.
What could be the problem and how to fix?
Also, should I ignore the warning about ignoring environment value of R_HOME?
Thanks.

On Thu, May 12, 2016 at 5:59 PM, Tom Hopper <tomhopper at gmail.com> wrote:
> setInternet2() first thing after launching R might fix that.
>
>
>> On May 12, 2016, at 07:45, Alba Pompeo <albapompeo at gmail.com> wrote:
>>
>> Hello.
>>
>> I've tried to run R, but I receive many warnings and can't do simple
>> stuff such as installing packages.
>>
>> Here's the full log when I run it.
>>
>> http://pastebin.com/raw/2BkNpTte
>>
>> Does anyone know what could be wrong here?
>>
>> Thanks a lot.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jwd at surewest.net  Fri May 13 05:47:32 2016
From: jwd at surewest.net (John Dougherty)
Date: Thu, 12 May 2016 20:47:32 -0700
Subject: [R] What is the easiest way to turn a dataframe into a barplot?
In-Reply-To: <056474CC-7FCD-48FF-8D21-CDE4A83F66A5@gmail.com>
References: <056474CC-7FCD-48FF-8D21-CDE4A83F66A5@gmail.com>
Message-ID: <20160512204732.765bb624@draco>

On Thu, 12 May 2016 13:19:54 -0400
"yoursurrogategod at gmail.com" <yoursurrogategod at gmail.com> wrote:

> Hello, I can't post my code since it's on a work computer.
> 
> But basically, I have a dataframe that has two columns, one is a
> string and the other is an integer.  I want to turn this into a
> vertival barplot where on the x-axis I have the string in the first
> columb and then the plot will display the integer count.
> 
> I have found many examples online and most of those matched either
> odd edge cases or putting the data into a format that strips out some
> of the data and I can't use it later.
> 
> This should be a breeze, what am I missing?

Without showing a data sample, no one can really do more than guess
what you are asking.  Among other things, no one "turns" a
dataframe "into" a barplot, ever.  It would defeat the purpose of
collecting the data to begin with.  It is also unclear what data the
process could strip out, or why you can't use the data again, unless
you are attempting to overwrite the dataframe with the bar plot.  

A barplot is a visual summary of data. So, best to bite the bullet and
supply an example. That way we can understand what you are attempting to
summarize.  As long as it has a similar structure and data types, you
can make it up. You would also benefit a great deal from reading up on
R and communicating in a manner that the community can follow. Sadly, no
specialized community exists without its own specialized jargon and
R-help is an intersection of at least two such communities.

JWDougherty


From mikko.t.hurme at gmail.com  Fri May 13 06:45:02 2016
From: mikko.t.hurme at gmail.com (Mikko Hurme)
Date: Fri, 13 May 2016 07:45:02 +0300
Subject: [R] Packages problems
Message-ID: <CAErdP=CyDaJ0=9Q+=LHJGWkp1mOdJ6GGMhnDQqencgdT245oyQ@mail.gmail.com>

Hi!

I also have problems when I try to install packages. I use R (v. 3.3.0) on
iMac (v. 10.11.4).
For instance:

> install.packages("doBy")
Warning: unable to access index for repository
http://ftp.sunet.se/pub/lang/CRAN/src/contrib:
  cannot open URL 'http://ftp.sunet.se/pub/lang/CRAN/src/contrib/PACKAGES'
Warning: unable to access index for repository
http://ftp.sunet.se/pub/lang/CRAN/bin/macosx/mavericks/contrib/3.3:
  cannot open URL '
http://ftp.sunet.se/pub/lang/CRAN/bin/macosx/mavericks/contrib/3.3/PACKAGES'
Warning message:
package ?doBy? is not available (for R version 3.3.0)
>

But when I give the same command using RStudio, everything works just fine

> install.packages("doBy")
trying URL '
https://cran.rstudio.com/bin/macosx/mavericks/contrib/3.3/doBy_4.5-15.tgz'
Content type 'application/x-gzip' length 3429051 bytes (3.3 MB)
==================================================
downloaded 3.3 MB

Also, the Get list button on the R Package Intaller window generates an
error message

Warning: unable to access index for repository
http://ftp.sunet.se/pub/lang/CRAN/bin/macosx/mavericks/contrib/3.3:
  cannot open URL '
http://ftp.sunet.se/pub/lang/CRAN/bin/macosx/mavericks/contrib/3.3/PACKAGES'

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri May 13 08:27:33 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 12 May 2016 23:27:33 -0700
Subject: [R] Packages problems
In-Reply-To: <CAErdP=CyDaJ0=9Q+=LHJGWkp1mOdJ6GGMhnDQqencgdT245oyQ@mail.gmail.com>
References: <CAErdP=CyDaJ0=9Q+=LHJGWkp1mOdJ6GGMhnDQqencgdT245oyQ@mail.gmail.com>
Message-ID: <1D58C7BC-C907-487C-B7BD-0B0F9921D9C9@dcn.davis.ca.us>

Try a different mirror. 
-- 
Sent from my phone. Please excuse my brevity.

On May 12, 2016 9:45:02 PM PDT, Mikko Hurme <mikko.t.hurme at gmail.com> wrote:
>Hi!
>
>I also have problems when I try to install packages. I use R (v. 3.3.0)
>on
>iMac (v. 10.11.4).
>For instance:
>
>> install.packages("doBy")
>Warning: unable to access index for repository
>http://ftp.sunet.se/pub/lang/CRAN/src/contrib:
>cannot open URL
>'http://ftp.sunet.se/pub/lang/CRAN/src/contrib/PACKAGES'
>Warning: unable to access index for repository
>http://ftp.sunet.se/pub/lang/CRAN/bin/macosx/mavericks/contrib/3.3:
>  cannot open URL '
>http://ftp.sunet.se/pub/lang/CRAN/bin/macosx/mavericks/contrib/3.3/PACKAGES'
>Warning message:
>package ?doBy? is not available (for R version 3.3.0)
>>
>
>But when I give the same command using RStudio, everything works just
>fine
>
>> install.packages("doBy")
>trying URL '
>https://cran.rstudio.com/bin/macosx/mavericks/contrib/3.3/doBy_4.5-15.tgz'
>Content type 'application/x-gzip' length 3429051 bytes (3.3 MB)
>==================================================
>downloaded 3.3 MB
>
>Also, the Get list button on the R Package Intaller window generates an
>error message
>
>Warning: unable to access index for repository
>http://ftp.sunet.se/pub/lang/CRAN/bin/macosx/mavericks/contrib/3.3:
>  cannot open URL '
>http://ftp.sunet.se/pub/lang/CRAN/bin/macosx/mavericks/contrib/3.3/PACKAGES'
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From martin.morgan at roswellpark.org  Fri May 13 11:20:22 2016
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Fri, 13 May 2016 05:20:22 -0400
Subject: [R] Warning when running R - can't install packages either
In-Reply-To: <CAJDAfTAa0RuZ+CjO0kX-zFaxzVfb2XsBZ_cpA2G-GCoq0qeteA@mail.gmail.com>
References: <CAJDAfTBMYFH0PcRG7scf+g5GAbkPC2yz4UF+1w+d5=xssipaHQ@mail.gmail.com>
	<238A333C-AE09-4131-94CE-E4688A6814D3@gmail.com>
	<CAJDAfTAa0RuZ+CjO0kX-zFaxzVfb2XsBZ_cpA2G-GCoq0qeteA@mail.gmail.com>
Message-ID: <57359C56.2010001@roswellpark.org>



On 05/12/2016 10:25 PM, Alba Pompeo wrote:
> Martin Morgan, I tried an HTTP mirror and it worked.
> What could be the problem and how to fix?

The problem is in the warning message

1: In download.file(url, destfile = f, quiet = TRUE) :
URL 'https://cran.r-project.org/CRAN_mirrors.csv': status was 'Problem 
with the SSL CA cert (path? access rights?)'

and an easier way to reproduce / troubleshoot the problem is

     download.file("https://cran.r-project.org/CRAN_mirrors.csv", 
tempfile())

The details of this process are described in ?download.file. My guess 
would be that you have 'libcurl' available

 > capabilities()["libcurl"]
libcurl
    TRUE

that it supports https (mine does, in the protocol attribute):

 > libcurlVersion()
[1] "7.35.0"
attr(,"ssl_version")
[1] "OpenSSL/1.0.1f"
attr(,"libssh_version")
[1] ""
attr(,"protocols")
  [1] "dict"   "file"   "ftp"    "ftps"   "gopher" "http"   "https" 
"imap"
  [9] "imaps"  "ldap"   "ldaps"  "pop3"   "pop3s"  "rtmp"   "rtsp" 
"smtp"
[17] "smtps"  "telnet" "tftp"

and that you have outdated or other CA certificates problem, with some 
hints for troubleshooting in the first and subsequent paragraphs of the 
'Secure URL' section.

Martin Morgan


> Also, should I ignore the warning about ignoring environment value of R_HOME?
> Thanks.
>
> On Thu, May 12, 2016 at 5:59 PM, Tom Hopper <tomhopper at gmail.com> wrote:
>> setInternet2() first thing after launching R might fix that.
>>
>>
>>> On May 12, 2016, at 07:45, Alba Pompeo <albapompeo at gmail.com> wrote:
>>>
>>> Hello.
>>>
>>> I've tried to run R, but I receive many warnings and can't do simple
>>> stuff such as installing packages.
>>>
>>> Here's the full log when I run it.
>>>
>>> http://pastebin.com/raw/2BkNpTte
>>>
>>> Does anyone know what could be wrong here?
>>>
>>> Thanks a lot.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


This email message may contain legally privileged and/or...{{dropped:2}}


From martin.morgan at roswellpark.org  Fri May 13 11:31:52 2016
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Fri, 13 May 2016 05:31:52 -0400
Subject: [R] Warning when running R - can't install packages either
In-Reply-To: <CAJDAfTAa0RuZ+CjO0kX-zFaxzVfb2XsBZ_cpA2G-GCoq0qeteA@mail.gmail.com>
References: <CAJDAfTBMYFH0PcRG7scf+g5GAbkPC2yz4UF+1w+d5=xssipaHQ@mail.gmail.com>
	<238A333C-AE09-4131-94CE-E4688A6814D3@gmail.com>
	<CAJDAfTAa0RuZ+CjO0kX-zFaxzVfb2XsBZ_cpA2G-GCoq0qeteA@mail.gmail.com>
Message-ID: <57359F08.8090307@roswellpark.org>



On 05/12/2016 10:25 PM, Alba Pompeo wrote:
> Martin Morgan, I tried an HTTP mirror and it worked.
> What could be the problem and how to fix?
> Also, should I ignore the warning about ignoring environment value of R_HOME?

It depends on why you set the value in your environment in the first 
place; maybe you were trying to use a particular installation of R, but 
setting R_HOME is not the way to do that (I use an alias, e.g., 
R-3.3='~/bin/R-3-3-branch/bin/R --no-save --no-restore --silent')

Martin

> Thanks.
>
> On Thu, May 12, 2016 at 5:59 PM, Tom Hopper <tomhopper at gmail.com> wrote:
>> setInternet2() first thing after launching R might fix that.
>>
>>
>>> On May 12, 2016, at 07:45, Alba Pompeo <albapompeo at gmail.com> wrote:
>>>
>>> Hello.
>>>
>>> I've tried to run R, but I receive many warnings and can't do simple
>>> stuff such as installing packages.
>>>
>>> Here's the full log when I run it.
>>>
>>> http://pastebin.com/raw/2BkNpTte
>>>
>>> Does anyone know what could be wrong here?
>>>
>>> Thanks a lot.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


This email message may contain legally privileged and/or...{{dropped:2}}


From hpages at fredhutch.org  Fri May 13 11:48:21 2016
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Fri, 13 May 2016 02:48:21 -0700
Subject: [R] break string at specified possitions
In-Reply-To: <CAHby=D0MJEWRaX_UH9Q1UU2rT0QORF-rQdxhQ=KWHt8R7sK80g@mail.gmail.com>
References: <CAHby=D1UYkGp-L_hVgy8Xus=_wVjDmV=6_x39Dyd0Pt38-H02w@mail.gmail.com>
	<CAGxFJbTi0SPb9STcFwu1DaGA2Ynd5K6v6KWNe7=ubh_Nc3uo+g@mail.gmail.com>
	<CAHby=D3aXQ6WF3wWWkYob1+a5wPhB0+yTGrVTJ9tzpcQz8i4kw@mail.gmail.com>
	<CA+8X3fUpTkyJiyq=nLmYa-ogLiwYXPjcxFgZdgWz32aD6Vy7uA@mail.gmail.com>
	<CA+8X3fU8mGykM++TSU-LDZRKxL3oUs0KFaS10P3mkoDU1z2gUA@mail.gmail.com>
	<CAHby=D0MJEWRaX_UH9Q1UU2rT0QORF-rQdxhQ=KWHt8R7sK80g@mail.gmail.com>
Message-ID: <5735A2E5.1010700@fredhutch.org>

Hi,

Here is the Biostrings solution in case you need to chop a long
string into hundreds or thousands of fragments (a situation where
base::substring() is very inefficient):

   library(Biostrings)

   ## Call as.character() on the result if you want it back as
   ## a character vector.
   fast_chop_string <- function(x, ends)
   {
     if (!is(x, "XString"))
         x <- as(x, "XString")
     extractAt(x, at=PartitioningByEnd(ends))
   }

Will be much faster than substring (e.g. 100x or 1000x) when
chopping a string like a Human chromosome into hundreds or
thousands of fragments.

Biostrings is a Bioconductor package:

   https://bioconductor.org/packages/Biostrings

Cheers,
H.


On 05/12/2016 01:18 AM, Jan Kacaba wrote:
> Nice solution Jim, thank you.
>
>
>
> 2016-05-12 2:45 GMT+02:00 Jim Lemon <drjimlemon at gmail.com>:
>> Hi again,
>> Sorry, that should be:
>>
>> chop_string<-function(x,ends) {
>>   starts<-c(1,ends[-length(ends)]+1)
>>   return(substring(x,starts,ends))
>> }
>>
>> Jim
>>
>> On Thu, May 12, 2016 at 10:05 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>> Hi Jan,
>>> This might be helpful:
>>>
>>> chop_string<-function(x,ends) {
>>>   starts<-c(1,ends[-length(ends)]-1)
>>>   return(substring(x,starts,ends))
>>> }
>>>
>>> Jim
>>>
>>>
>>> On Thu, May 12, 2016 at 7:23 AM, Jan Kacaba <jan.kacaba at gmail.com> wrote:
>>>> Here is my attempt at function which computes margins from positions.
>>>>
>>>> require("stringr")
>>>> require("dplyr")
>>>>
>>>> ends<-seq(10,100,8)  # end margins
>>>> test_string<-"Lorem ipsum dolor sit amet, consectetuer adipiscing
>>>> elit. Aliquam in lorem sit amet leo accumsan lacinia."
>>>>
>>>> sekoj=function(ends){
>>>>    l_ends<-length(ends)
>>>>    begs=vector(mode="integer",l_ends)
>>>>    begs[1]=1
>>>>    for (i in 2:(l_ends)){
>>>>      begs[i]<-ends[i-1]+1
>>>>    }
>>>>    margs<-rbind(begs,ends)
>>>>    margs<-cbind(margs,c(ends[l_ends]+1,-1))
>>>>    #rownames(margs)<-c("beg","end")
>>>>    return(margs)
>>>> }
>>>> margins<-sekoj(ends)
>>>> str_sub(test_string,margins[1,],margins[2,]) %>% print
>>>>
>>>> Code to run in browser:
>>>> http://www.r-fiddle.org/#/fiddle?id=rVmNVxDV
>>>>
>>>> 2016-05-11 23:12 GMT+02:00 Bert Gunter <bgunter.4567 at gmail.com>:
>>>>> Dunno -- but you might have a look at Hadley Wickham's 'stringr' package:
>>>>> https://cran.r-project.org/web/packages/stringr/stringr.pdf
>>>>>
>>>>> Cheers,
>>>>>
>>>>> Bert
>>>>>
>>>>>
>>>>> Bert Gunter
>>>>>
>>>>> "The trouble with having an open mind is that people keep coming along
>>>>> and sticking things into it."
>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>
>>>>>
>>>>> On Wed, May 11, 2016 at 1:12 PM, Jan Kacaba <jan.kacaba at gmail.com> wrote:
>>>>>> Dear R-help
>>>>>>
>>>>>> I would like to split long string at specified precomputed positions.
>>>>>> 'substring' needs beginings and ends. Is there a native function which
>>>>>> accepts positions so I don't have to count second argument?
>>>>>>
>>>>>> For example I have vector of possitions pos<-c(5,10,19). Substring
>>>>>> needs input first=c(1,6,11) and last=c(5,10,19). There is no problem
>>>>>> to write my own function. Just asking.
>>>>>>
>>>>>> Derek
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From simon.wood at bath.edu  Fri May 13 12:32:18 2016
From: simon.wood at bath.edu (Simon Wood)
Date: Fri, 13 May 2016 11:32:18 +0100
Subject: [R] physical constraint with gam
In-Reply-To: <CAF1jk_=Yk6ruWTyDZ_aZnDTAmSZi6=7eSM5CoL0x=jF=JVqm4w@mail.gmail.com>
References: <CAF1jk_=312-4GEwpeJM2UaOojnSE_6PxLo6YU2ysjGdHKBt3UQ@mail.gmail.com>
	<5732F730.9000800@bath.edu>
	<CAF1jk_=Yk6ruWTyDZ_aZnDTAmSZi6=7eSM5CoL0x=jF=JVqm4w@mail.gmail.com>
Message-ID: <5735AD32.4060204@bath.edu>

On 11/05/16 17:11, Dominik Schneider wrote:
> Hi Simon, Thanks for this explanation.
> To make sure I understand, another way of explaining the y axis in my 
> original example is that it is the contribution to snowdepth relative 
> to the other variables (the example only had fsca, but my actual case 
> has a couple others). i.e. a negative s(fsca) of -0.5 simply means 
> snowdepth 0.5 units below the intercept+s(x_i), where s(x_i) could 
> also be negative in the case where total snowdepth is less than the 
> intercept value.
>
- Yes, this looks right.

> The use of by=fsca is really useful for interpreting the marginal 
> impact of the different variables. With my actual data, the term 
> s(fsca):fsca is never negative, which is much more intuitive. Is it 
> appropriate to compare magnitudes of e.g. s(x2):x2 / mean(x2) and 
> s(x2):x2 / mean(x2)  where mean(x_i) are the mean of the actual data?
>
- I guess so (similarly to lm/glm).

> Lastly, how would these two differ: s(x1,by=x2); or 
> s(x1,by=x1)*s(x2,by=x2) since interactions are surely present and i'm 
> not sure if a linear combination is enough.
>
- you'd probably use te(x1,x2) unless x1 and x2 are really on the same 
scale, in which case s(x1,x2) might be appropriate. The `by' variable 
trick is probably not going to work so well for interactions, however 
(it's not so clear what the by variable should be).


-- 
Simon Wood, School of Mathematics, University of Bristol BS8 1TW UK
+44 (0)117 33 18273     http://www.maths.bris.ac.uk/~sw15190


	[[alternative HTML version deleted]]


From at.ouchen at gmail.com  Fri May 13 13:50:05 2016
From: at.ouchen at gmail.com (Amatoallah Ouchen)
Date: Fri, 13 May 2016 11:50:05 +0000
Subject: [R] How to program friction model(kind of cencored regression )
Message-ID: <CAF=n1M3vXU52bF-OhacxGqysjX0WEOP4mZsb=UUurLWL91trAQ@mail.gmail.com>

Hi,

I am going to program (what is called) the ?friction model? in economics
and statistics. This model can be used for analysing the government
intervention. It looks like tobit but different. I can not deal with this
model by any R library. This model assume that government intervenes in the
market only when a certain condition is fulfilled.

For example, INT is the amount of government intervention in the market.
The equation to be estimated is:
(1) *INT = a + b*X +e*  where INT indicates (actual) intervention amount
and X is control variable.

Let INT* denote the desirable intervention amount ? this is the same as the
right hand side of equation (1) excluding error terms. Then the acutal
value, i.e., INT, have a differnt value depending on whether INT* reach the
threshold. That is, government is assumed to intervene only when INT* is
larger than the upper positive threshold(p>0) or less than the lower
negative threshold(n<0).

That is, there are 3 cases.
(2)
INT = INT* - p + e             if INT*>p : intervention
INT= 0 if n<=INT*<=p        no intervention
INT= INT* + n +e               if INT*<n : intervention

The parameters(a,b, p, n) in (1) and (2) can be estimated by maximum
likelihood.

does  anyone  knows how to program this model or has complete code of this
model ?
Many thanks in advance !!
Ama

	[[alternative HTML version deleted]]


From chalabi.elahe at yahoo.de  Fri May 13 13:56:08 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Fri, 13 May 2016 11:56:08 +0000 (UTC)
Subject: [R] changing factor to numbers without getting NAs
References: <9850584.2788372.1463140568884.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <9850584.2788372.1463140568884.JavaMail.yahoo@mail.yahoo.com>

Hi all,
I have a df which a part of this is:
 
   TSTMax     :int 213 228 227 281
   TSTMin     :int 149 167 158 176 
   TSTMean    :Factor w/94 levels "100,2" , "104,3" , ...
I want to change the TSTMean into numeric but by using as.numeric(as.character(df$TSTMean)) I get too many NAs.
Is there a way to change TSTMean into numeric without those NAs?
I want TSTMean to be at the end like:
 
   TSTMean  :int 100.2 104.3 .....
 
Thanks for any help
Elahe


From murdoch.duncan at gmail.com  Fri May 13 14:09:26 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 13 May 2016 08:09:26 -0400
Subject: [R] changing factor to numbers without getting NAs
In-Reply-To: <9850584.2788372.1463140568884.JavaMail.yahoo@mail.yahoo.com>
References: <9850584.2788372.1463140568884.JavaMail.yahoo.ref@mail.yahoo.com>
	<9850584.2788372.1463140568884.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <5735C3F6.7060900@gmail.com>

On 13/05/2016 7:56 AM, ch.elahe via R-help wrote:
> Hi all,
> I have a df which a part of this is:
>
>     TSTMax     :int 213 228 227 281
>     TSTMin     :int 149 167 158 176
>     TSTMean    :Factor w/94 levels "100,2" , "104,3" , ...
> I want to change the TSTMean into numeric but by using as.numeric(as.character(df$TSTMean)) I get too many NAs.
> Is there a way to change TSTMean into numeric without those NAs?
> I want TSTMean to be at the end like:
>
>     TSTMean  :int 100.2 104.3 .....

You appear to have a comma as the decimal marker, so you can use 
type.convert(as.character(df$TSTMean), dec = ",", as.is = TRUE) instead 
of as.numeric().

A simpler approach might be to avoid getting the factor in the first 
place; if you read this data using read.table, there is the dec option 
to recognize a comma as the decimal separator.

Duncan Murdoch


From marc_schwartz at me.com  Fri May 13 14:12:47 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 13 May 2016 07:12:47 -0500
Subject: [R] changing factor to numbers without getting NAs
In-Reply-To: <9850584.2788372.1463140568884.JavaMail.yahoo@mail.yahoo.com>
References: <9850584.2788372.1463140568884.JavaMail.yahoo.ref@mail.yahoo.com>
	<9850584.2788372.1463140568884.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <D926FB0C-9C03-4465-B460-042C2541B501@me.com>


> On May 13, 2016, at 6:56 AM, ch.elahe via R-help <r-help at r-project.org> wrote:
> 
> Hi all,
> I have a df which a part of this is:
> 
>   TSTMax     :int 213 228 227 281
>   TSTMin     :int 149 167 158 176 
>   TSTMean    :Factor w/94 levels "100,2" , "104,3" , ...
> I want to change the TSTMean into numeric but by using as.numeric(as.character(df$TSTMean)) I get too many NAs.
> Is there a way to change TSTMean into numeric without those NAs?
> I want TSTMean to be at the end like:
> 
>   TSTMean  :int 100.2 104.3 .....
> 
> Thanks for any help
> Elahe

Hi,

First, how did you get the data into R? 

I am going to guess that you used ?read.table or ?read.csv, which by default, will convert character values into factors (see the 'as.is' argument).

Second, by default, the decimal character in R is a period ('.') and you appear to be importing European values where the decimal character is a comma (','). Thus, take note of the 'dec' argument in read.table/read.csv and modify that to dec = "," in your function call.

The NA values are the result of converting character values that cannot be coerced to numeric due to the commas:

> as.numeric("100,2")
[1] NA
Warning message:
NAs introduced by coercion 

> as.numeric("100.2")
[1] 100.2

Regards,

Marc Schwartz


From chalabi.elahe at yahoo.de  Fri May 13 14:28:56 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Fri, 13 May 2016 12:28:56 +0000 (UTC)
Subject: [R] changing factor to numbers without getting NAs
In-Reply-To: <5735C3F6.7060900@gmail.com>
References: <9850584.2788372.1463140568884.JavaMail.yahoo.ref@mail.yahoo.com>
	<9850584.2788372.1463140568884.JavaMail.yahoo@mail.yahoo.com>
	<5735C3F6.7060900@gmail.com>
Message-ID: <608832488.2893495.1463142536759.JavaMail.yahoo@mail.yahoo.com>

Thanks Duncan,
This type.convert works fine for me and gives me TSTMean with decimal, but I want to add this result as a new column to my df as int or num, how can I do this?
 
Thanks,
Elahe



On Friday, May 13, 2016 2:15 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
On 13/05/2016 7:56 AM, ch.elahe via R-help wrote:

> Hi all,
> I have a df which a part of this is:
>
>     TSTMax     :int 213 228 227 281
>     TSTMin     :int 149 167 158 176
>     TSTMean    :Factor w/94 levels "100,2" , "104,3" , ...
> I want to change the TSTMean into numeric but by using as.numeric(as.character(df$TSTMean)) I get too many NAs.
> Is there a way to change TSTMean into numeric without those NAs?
> I want TSTMean to be at the end like:
>
>     TSTMean  :int 100.2 104.3 .....

You appear to have a comma as the decimal marker, so you can use 
type.convert(as.character(df$TSTMean), dec = ",", as.is = TRUE) instead 
of as.numeric().

A simpler approach might be to avoid getting the factor in the first 
place; if you read this data using read.table, there is the dec option 
to recognize a comma as the decimal separator.

Duncan Murdoch


From cryan at binghamton.edu  Thu May 12 22:06:25 2016
From: cryan at binghamton.edu (Christopher W Ryan)
Date: Thu, 12 May 2016 16:06:25 -0400
Subject: [R] anonymizing subject identifiers for survival analysis
Message-ID: <CAM+rpY=HgsQwPsfP9bXfK=0QGe_Lfi87PYNHv27BSwVoRA56ow@mail.gmail.com>

I would like to conduct a survival analysis, examining a subject's
time to *next* appearance in a database, after their first appearance.
It is a database of dated events.

I need to obfuscate or anonymize or mask the subject identifiers (a
combination of name and birthdate). And obviously any given subject
should have the same anonymous code ever time he/she appears in the
database.  I'm not talking "safe from the NSA" here. And I won't be
releasing it. It's just sensitive data and I don't want to be working
every day with cleartext versions of it.

I've looked at packages digest, anonymizer, and anonymize.  What do
you think of this approach:

# running R 3.1.1 on Windows 7 Enterprise
library(digest)
dd <- data.frame(id=1:6, name = c("Harry", "Ron", "Hermione", "Luna",
"Ginny", "Harry"), dob = c("1990-01-01", "1990-06-15", "1990-04-08",
"1999-11-26", "1990-07-21", "1990-01-01"))
dd.2 <- transform(dd, code=paste0(tolower(name), tolower(dob), sep=""))
library(digest)
anonymize <- function(x, algo="sha256"){
  unq_hashes <- vapply(x, function(object) digest(object, algo=algo),
FUN.VALUE="", USE.NAMES=TRUE)
  unname(unq_hashes[x])
}
dd.2$codex <- anonymize(dd.2$code)
dd.2
table(duplicated(dd.2$codex))

Thanks.

--Chris Ryan
Broome County Health Department


From cryan at binghamton.edu  Thu May 12 19:29:47 2016
From: cryan at binghamton.edu (Christopher W. Ryan)
Date: Thu, 12 May 2016 13:29:47 -0400
Subject: [R] What is the easiest way to turn a dataframe into a barplot?
In-Reply-To: <056474CC-7FCD-48FF-8D21-CDE4A83F66A5@gmail.com>
References: <056474CC-7FCD-48FF-8D21-CDE4A83F66A5@gmail.com>
Message-ID: <5734BD8B.60906@binghamton.edu>

Here is one way:

dd <- data.frame(var1=c("string1", "string2", "string3"), var2=c(3,7,4))
dd
with(dd, barplot(var2, names.arg=var1))

--Chris Ryan
Binghamton, NY

yoursurrogategod at gmail.com wrote:
> Hello, I can't post my code since it's on a work computer.
> 
> But basically, I have a dataframe that has two columns, one is a string and the other is an integer.  I want to turn this into a vertival barplot where on the x-axis I have the string in the first columb and then the plot will display the integer count.
> 
> I have found many examples online and most of those matched either odd edge cases or putting the data into a format that strips out some of the data and I can't use it later.
> 
> This should be a breeze, what am I missing?
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From massimo.bressan at arpa.veneto.it  Fri May 13 13:55:39 2016
From: massimo.bressan at arpa.veneto.it (Massimo Bressan)
Date: Fri, 13 May 2016 13:55:39 +0200 (CEST)
Subject: [R] apply formula over columns by subset of rows in a dataframe (to
 get a new dataframe)
Message-ID: <1274186074.11911782.1463140539471.JavaMail.zimbra@arpa.veneto.it>

hi 

I need to apply a user defined formula over some selected columns of a dataframe by subsetting group of rows (blocks) and get back a new dataframe 

I?ve been managed to get the the calculations right but I?m not satisfied at all by the form of the results 

please refer to my reproducible example 

########## 
# my user function (an example) 
mynorm <- function(x) {(x - min(x, na.rm=TRUE))/(max(x, na.rm=TRUE) - min(x, na.rm=TRUE))} 

# my dataframe to apply the formula by blocks 
mydf<-data.frame(blocks=rep(c("a","b","c"),each=5), v1=round(runif(15,10,25),0), v2=round(rnorm(15,30,5),0)) 


#my attempts (not satisfied by final output) 

tapply(mydf$v1, mydf$blocks, mynorm) 

byf<-factor(mydf$blocks) 
aggregate(mydf[2:3], list(byf), mynorm) 
aggregate(mydf[2:3], list(mydf$blocks), mynorm, simplify = FALSE) 

########### 

please can anyone give me some hints on how to properly proceed? 

I need a dataframe with all variables as final result 
sorry but I?m sort of definitely stuck with this? 

thanks 


	[[alternative HTML version deleted]]


From HLiao at odu.edu  Fri May 13 15:24:05 2016
From: HLiao at odu.edu (Liao, Hongsheng)
Date: Fri, 13 May 2016 13:24:05 +0000
Subject: [R] Equation with double quotes from R to Excel?
Message-ID: <BL2PR17MB0724E3B8ABADA0FDA97E20E6BD740@BL2PR17MB0724.namprd17.prod.outlook.com>

I am trying to add an equation with ?? from R to an Excel workbook.  However, I have found that the Function ?setCellFormula? doesn?t take the ?? well while a ?? in Excel equation stands for a blank cell.  I have tried NA(), EMPTY(), etc, and none of them are what I want.  Does anyone have other ways to put an equation with ?? from R to Excel workbook?  Thanks in advance.

Following is simple codes just for the demonstration, and the error is highlighted in red.

#load package "XLConnect" to add functions from R to Excel
library(XLConnect)

# Load workbook (create if not existing)
wb <- loadWorkbook("try adding an equation.xlsx", create = TRUE)

# Create a sheet named 'data'
createSheet(wb, name = 'data')

#the formula contains no double quotes which works well
formula.without.double.quote <- "IF(A2>95, 1, 0)"
setCellFormula(wb, 'data', 2, 10, formula=formula.without.double.quote)

#the formula contains double quotes which doesn?t work with the function ?setCellFormula?
formula.with.double.quote <- paste("IF(A2=", dQuote(""), ",", dQuote(""), ",1)", sep="")
setCellFormula(wb, 'data', 3, 10, formula=formula.with.double.quote)
Error: FormulaParseException (Java): Parse error near char 6 '???' in specified formula 'IF(A2=??????,??????,1)'. Expected cell ref or constant literal

#save the workbook
saveWorkbook(wb, file="C:\\Users\\try adding an equation.xlsx")

Hank

Hongsheng (Hank) Liao, PhD.
Lab Manager
Center for Quantitative  Fisheries Ecology
Old Dominion University
757-683-4571




	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Fri May 13 15:40:41 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 13 May 2016 09:40:41 -0400
Subject: [R] Equation with double quotes from R to Excel?
In-Reply-To: <BL2PR17MB0724E3B8ABADA0FDA97E20E6BD740@BL2PR17MB0724.namprd17.prod.outlook.com>
References: <BL2PR17MB0724E3B8ABADA0FDA97E20E6BD740@BL2PR17MB0724.namprd17.prod.outlook.com>
Message-ID: <CAM_vjun_uQQbOEbW3EgFHc4pRtiSv0kuvLC5M68mM5Se-rrbpw@mail.gmail.com>

This doesn't answer your actual question, but isn't it better practice
to use ISBLANK instead of ""?

As for your actual question, a check of the parts of your command at
the R prompt would probably reveal something interesting:

> paste("IF(A2=", dQuote(""), ",", dQuote(""), ",1)", sep="")
[1] "IF(A2=??,??,1)"
> options(useFancyQuotes=FALSE)
> paste("IF(A2=", dQuote(""), ",", dQuote(""), ",1)", sep="")
[1] "IF(A2=\"\",\"\",1)"

This bit of your output should have been a hint:
IF(A2=????? ,????? ,1)

Sarah

On Fri, May 13, 2016 at 9:24 AM, Liao, Hongsheng <HLiao at odu.edu> wrote:
> I am trying to add an equation with ?? from R to an Excel workbook.  However, I have found that the Function ?setCellFormula? doesn?t take the ?? well while a ?? in Excel equation stands for a blank cell.  I have tried NA(), EMPTY(), etc, and none of them are what I want.  Does anyone have other ways to put an equation with ?? from R to Excel workbook?  Thanks in advance.
>
> Following is simple codes just for the demonstration, and the error is highlighted in red.
>
> #load package "XLConnect" to add functions from R to Excel
> library(XLConnect)
>
> # Load workbook (create if not existing)
> wb <- loadWorkbook("try adding an equation.xlsx", create = TRUE)
>
> # Create a sheet named 'data'
> createSheet(wb, name = 'data')
>
> #the formula contains no double quotes which works well
> formula.without.double.quote <- "IF(A2>95, 1, 0)"
> setCellFormula(wb, 'data', 2, 10, formula=formula.without.double.quote)
>
> #the formula contains double quotes which doesn?t work with the function ?setCellFormula?
> formula.with.double.quote <- paste("IF(A2=", dQuote(""), ",", dQuote(""), ",1)", sep="")
> setCellFormula(wb, 'data', 3, 10, formula=formula.with.double.quote)
> Error: FormulaParseException (Java): Parse error near char 6 '???' in specified formula 'IF(A2=????? ,????? ,1)'. Expected cell ref or constant literal
>
> #save the workbook
> saveWorkbook(wb, file="C:\\Users\\try adding an equation.xlsx")
>
> Hank
>
> Hongsheng (Hank) Liao, PhD.
> Lab Manager
> Center for Quantitative  Fisheries Ecology
> Old Dominion University
> 757-683-4571
>
>
>
>


From dcarlson at tamu.edu  Fri May 13 15:59:04 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 13 May 2016 13:59:04 +0000
Subject: [R] apply formula over columns by subset of rows in a dataframe
 (to get a new dataframe)
In-Reply-To: <1274186074.11911782.1463140539471.JavaMail.zimbra@arpa.veneto.it>
References: <1274186074.11911782.1463140539471.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D732474@mb02.ads.tamu.edu>

You can do this with split/unsplit:

> mydf.split <- split(mydf, mydf$blocks)
> str(mydf.split)
List of 3
 $ a:'data.frame':      5 obs. of  3 variables:
  ..$ blocks: Factor w/ 3 levels "a","b","c": 1 1 1 1 1
  ..$ v1    : num [1:5] 19 15 17 22 16
  ..$ v2    : num [1:5] 35 31 35 31 39
 $ b:'data.frame':      5 obs. of  3 variables:
  ..$ blocks: Factor w/ 3 levels "a","b","c": 2 2 2 2 2
  ..$ v1    : num [1:5] 12 24 25 22 18
  ..$ v2    : num [1:5] 31 19 35 32 38
 $ c:'data.frame':      5 obs. of  3 variables:
  ..$ blocks: Factor w/ 3 levels "a","b","c": 3 3 3 3 3
  ..$ v1    : num [1:5] 17 14 21 21 22
  ..$ v2    : num [1:5] 27 25 23 23 27
> mydf.split2 <- lapply(mydf.split, function(x) data.frame(x, 
+      v1mod=mynorm(x$v1)))
> str(mydf.split2)
List of 3
 $ a:'data.frame':      5 obs. of  4 variables:
  ..$ blocks: Factor w/ 3 levels "a","b","c": 1 1 1 1 1
  ..$ v1    : num [1:5] 19 15 17 22 16
  ..$ v2    : num [1:5] 35 31 35 31 39
  ..$ v1mod : num [1:5] 0.571 0 0.286 1 0.143
 $ b:'data.frame':      5 obs. of  4 variables:
  ..$ blocks: Factor w/ 3 levels "a","b","c": 2 2 2 2 2
  ..$ v1    : num [1:5] 12 24 25 22 18
  ..$ v2    : num [1:5] 31 19 35 32 38
  ..$ v1mod : num [1:5] 0 0.923 1 0.769 0.462
 $ c:'data.frame':      5 obs. of  4 variables:
  ..$ blocks: Factor w/ 3 levels "a","b","c": 3 3 3 3 3
  ..$ v1    : num [1:5] 17 14 21 21 22
  ..$ v2    : num [1:5] 27 25 23 23 27
  ..$ v1mod : num [1:5] 0.375 0 0.875 0.875 1
> mydf2 <- unsplit(mydf.split2, mydf$blocks)
> str(mydf2)
'data.frame':   15 obs. of  4 variables:
 $ blocks: Factor w/ 3 levels "a","b","c": 1 1 1 1 1 2 2 2 2 2 ...
 $ v1    : num  19 15 17 22 16 12 24 25 22 18 ...
 $ v2    : num  35 31 35 31 39 31 19 35 32 38 ...
 $ v1mod : num  0.571 0 0.286 1 0.143 ...

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Massimo Bressan
Sent: Friday, May 13, 2016 6:56 AM
To: r-help at r-project.org
Subject: [R] apply formula over columns by subset of rows in a dataframe (to get a new dataframe)

hi 

I need to apply a user defined formula over some selected columns of a dataframe by subsetting group of rows (blocks) and get back a new dataframe 

I?ve been managed to get the the calculations right but I?m not satisfied at all by the form of the results 

please refer to my reproducible example 

########## 
# my user function (an example) 
mynorm <- function(x) {(x - min(x, na.rm=TRUE))/(max(x, na.rm=TRUE) - min(x, na.rm=TRUE))} 

# my dataframe to apply the formula by blocks 
mydf<-data.frame(blocks=rep(c("a","b","c"),each=5), v1=round(runif(15,10,25),0), v2=round(rnorm(15,30,5),0)) 


#my attempts (not satisfied by final output) 

tapply(mydf$v1, mydf$blocks, mynorm) 

byf<-factor(mydf$blocks) 
aggregate(mydf[2:3], list(byf), mynorm) 
aggregate(mydf[2:3], list(mydf$blocks), mynorm, simplify = FALSE) 

########### 

please can anyone give me some hints on how to properly proceed? 

I need a dataframe with all variables as final result 
sorry but I?m sort of definitely stuck with this? 

thanks 


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From dcarlson at tamu.edu  Fri May 13 16:09:04 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 13 May 2016 14:09:04 +0000
Subject: [R] What is the easiest way to turn a dataframe into a barplot?
In-Reply-To: <D8AB947C-F5C7-4392-9052-489C09ABF66D@gmail.com>
References: <056474CC-7FCD-48FF-8D21-CDE4A83F66A5@gmail.com>
	<CAF8bMcb7PKaQj5x39V9X3c6JgOP=T5oBJotf-rWr1BsbrvT=2Q@mail.gmail.com>
	<D8AB947C-F5C7-4392-9052-489C09ABF66D@gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D732490@mb02.ads.tamu.edu>

If you want to stay with vertical bars, the barp() function in package plotrix lets you stagger or rotate the labels:

> set.seed(42)
> Name=c("One","Two", "Three","Four", "Five", "Six", "Seven", 
+      "Eight", "Nine", "Ten", "Eleven", "Twelve", "Thirteen", 
+      "Fourteen", "Fifteen")
> Count=sample.int(15, 15, replace=TRUE)
> z <- data.frame(Name, Count)
> with(z, barp(Count, names=Name))   # Some labels suppressed by the plot device
# Note that if you drag the plot window to be wider, the labels will eventually appear
> with(z, barp(Count, names=Name, staxx=TRUE))  # Stagger the labels
> with(z, barp(Count, names=Name, staxx=TRUE, srt=60))  # Slant the labels

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of yoursurrogategod at gmail.com
Sent: Thursday, May 12, 2016 1:14 PM
To: William Dunlap
Cc: r-help at r-project.org
Subject: Re: [R] What is the easiest way to turn a dataframe into a barplot?

Ok, the horizontal names work here.  Thanks.

> On May 12, 2016, at 1:31 PM, William Dunlap <wdunlap at tibco.com> wrote:
> 
> Does this do what you want?
> 
> z <- data.frame(Name=c("One","Three","Twelve","Eleven"), Count=c(1,3,12,11))
> with(z, barplot(Count, names=Name, horiz=TRUE))
> with(z, barplot(Count, names=Name, horiz=TRUE, las=1))
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
>> On Thu, May 12, 2016 at 10:19 AM, yoursurrogategod at gmail.com <yoursurrogategod at gmail.com> wrote:
>> Hello, I can't post my code since it's on a work computer.
>> 
>> But basically, I have a dataframe that has two columns, one is a string and the other is an integer.  I want to turn this into a vertival barplot where on the x-axis I have the string in the first columb and then the plot will display the integer count.
>> 
>> I have found many examples online and most of those matched either odd edge cases or putting the data into a format that strips out some of the data and I can't use it later.
>> 
>> This should be a breeze, what am I missing?
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From HLiao at odu.edu  Fri May 13 16:23:58 2016
From: HLiao at odu.edu (Liao, Hongsheng)
Date: Fri, 13 May 2016 14:23:58 +0000
Subject: [R] Equation with double quotes from R to Excel?
In-Reply-To: <CAM_vjun_uQQbOEbW3EgFHc4pRtiSv0kuvLC5M68mM5Se-rrbpw@mail.gmail.com>
References: <BL2PR17MB0724E3B8ABADA0FDA97E20E6BD740@BL2PR17MB0724.namprd17.prod.outlook.com>
	<CAM_vjun_uQQbOEbW3EgFHc4pRtiSv0kuvLC5M68mM5Se-rrbpw@mail.gmail.com>
Message-ID: <BL2PR17MB072478C1796DE8F02397E20CBD740@BL2PR17MB0724.namprd17.prod.outlook.com>

Sarah,
Thank you very much.  The following codes you sent to me work perfectly.  "IF(A2=\"\",\"\",1)" in R becomes "IF(A2="","",1)" in Excel.  Wonderful!

Hank

Hongsheng (Hank) Liao, PhD.
Lab Manager
Center for Quantitative  Fisheries Ecology
Old Dominion University
757-683-4571




> options(useFancyQuotes=FALSE)
> paste("IF(A2=", dQuote(""), ",", dQuote(""), ",1)", sep="")

-----Original Message-----
From: Sarah Goslee [mailto:sarah.goslee at gmail.com] 
Sent: Friday, May 13, 2016 9:41 AM
To: Liao, Hongsheng
Cc: R-help Mailing List
Subject: Re: [R] Equation with double quotes from R to Excel?

This doesn't answer your actual question, but isn't it better practice to use ISBLANK instead of ""?

As for your actual question, a check of the parts of your command at the R prompt would probably reveal something interesting:

> paste("IF(A2=", dQuote(""), ",", dQuote(""), ",1)", sep="")
[1] "IF(A2=??,??,1)"
> options(useFancyQuotes=FALSE)
> paste("IF(A2=", dQuote(""), ",", dQuote(""), ",1)", sep="")
[1] "IF(A2=\"\",\"\",1)"

This bit of your output should have been a hint:
IF(A2=????? ,????? ,1)

Sarah

On Fri, May 13, 2016 at 9:24 AM, Liao, Hongsheng <HLiao at odu.edu> wrote:
> I am trying to add an equation with ?? from R to an Excel workbook.  However, I have found that the Function ?setCellFormula? doesn?t take the ?? well while a ?? in Excel equation stands for a blank cell.  I have tried NA(), EMPTY(), etc, and none of them are what I want.  Does anyone have other ways to put an equation with ?? from R to Excel workbook?  Thanks in advance.
>
> Following is simple codes just for the demonstration, and the error is highlighted in red.
>
> #load package "XLConnect" to add functions from R to Excel
> library(XLConnect)
>
> # Load workbook (create if not existing) wb <- loadWorkbook("try 
> adding an equation.xlsx", create = TRUE)
>
> # Create a sheet named 'data'
> createSheet(wb, name = 'data')
>
> #the formula contains no double quotes which works well 
> formula.without.double.quote <- "IF(A2>95, 1, 0)"
> setCellFormula(wb, 'data', 2, 10, 
> formula=formula.without.double.quote)
>
> #the formula contains double quotes which doesn?t work with the function ?setCellFormula?
> formula.with.double.quote <- paste("IF(A2=", dQuote(""), ",", 
> dQuote(""), ",1)", sep="") setCellFormula(wb, 'data', 3, 10, 
> formula=formula.with.double.quote)
> Error: FormulaParseException (Java): Parse error near char 6 '???' in 
> specified formula 'IF(A2=????? ,????? ,1)'. Expected cell ref or 
> constant literal
>
> #save the workbook
> saveWorkbook(wb, file="C:\\Users\\try adding an equation.xlsx")
>
> Hank
>
> Hongsheng (Hank) Liao, PhD.
> Lab Manager
> Center for Quantitative  Fisheries Ecology Old Dominion University
> 757-683-4571
>
>
>
>

From mario.lavezzi at unipa.it  Fri May 13 16:26:41 2016
From: mario.lavezzi at unipa.it (A M Lavezzi)
Date: Fri, 13 May 2016 15:26:41 +0100
Subject: [R] building a spatial matrix
In-Reply-To: <CAM_vjuk8hVY6F67behO+YQ1R5gSxb5xTxQgysSwZmigmPoQXow@mail.gmail.com>
References: <CAOZPQW7DOicT9pS8H2BA3gxnJLg0wYTu9UhinwpgywcSDGoKFw@mail.gmail.com>
	<CAM_vjuk8hVY6F67behO+YQ1R5gSxb5xTxQgysSwZmigmPoQXow@mail.gmail.com>
Message-ID: <CAOZPQW4zO7EaF3KTaDGgBStoycEvyMyKJFz1MwCRjMUk7zfDug@mail.gmail.com>

Hello Sarah
thanks a lot for your advice.

I followed your suggestions unitl the creation of "result"

The allocation of the values of result$distance to the matrix result.m,
however ,does not seem to work: it produces a matrix with identical columns
corresponding to the last values of result$distance. Maybe my description
of the dataset was not clear enough.

I produced the final matrix with a loop, that I report below (it takes
about 1 hour on my macbook pro),

set_i = -1   # create a variable to store the i values already examined

for(i in unique(result$id)){

  set_i=c(set_i,i) # store the value of the i

  set_neigh = result$id_neigh[result$id==i & !result$id_neigh %in% set_i] #
identify the locations connected to i. Exclude                  those

  for(j in set_neigh){
    if(i!=j){
      spat_dist[i,j] = result$distance[result$id==i &  result$id_neigh==j]
      spat_dist[j,i] = spat_dist[i,j]
    }
    else{
      spat_dist[i,j]=0
    }
  }
}

It not the most elegant and efficient solution in the world, that's for sure



On Thu, May 12, 2016 at 2:51 PM, Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> I don't see any reason why a loop is out of the question, and
> answering would have been much easier if you'd included the requested
> reproducible data, but what about this?
>
> This solution is robust to pairs from idcell being absent in censDist,
> and to the difference from A to B being different than the distance
> from B to A, but not to A-B appearing twice. If that's possible,
> you'll need to figure out how to manage it.
>
> # create some fake data
>
> idcell <- data.frame(
>   id = seq_len(5),
>   fcell = sample(1:100, 5))
>
> censDist <- expand.grid(fcell=seq_len(100), cellneigh=seq_len(100))
> censDist$distance <- runif(nrow(censDist))
>
> # assemble the non-symmetric distance matrix
> result <- subset(censDist, fcell %in% idcell$fcell & cellneigh %in%
> idcell$fcell)
> result.m <- matrix(NA, nrow=nrow(idcell), ncol=nrow(idcell))
> result.m[factor(result$fcell), factor(result$cellneigh)] <- result$distance
>
> Sarah
>
> On Thu, May 12, 2016 at 5:26 AM, A M Lavezzi <mario.lavezzi at unipa.it>
> wrote:
> > Hello,
> >
> > I have a sample of 1327  locations, each one idetified by an id and a
> > numerical code.
> >
> > I need to build a spatial matrix, say, M, i.e. a 1327x1327 matrix
> > collecting distances among the locations.
> >
> > M(i,i) should be 0, M(i,j) should contain the distance among location i
> and
> > j
> >
> > I shoud use data organized in the following way:
> >
> > 1) id_cell contains the identifier (id) of each location (1...1327) and
> the
> > numerical code of the location (f_cell) (see head of id_cell below)
> >
> >> head(id_cell)
> >      id  f_cell
> > 1    1   2120
> > 12  2     204
> > 22  3   2546
> > 24  4   1327
> > 34  5   1729
> > 43  6   2293
> >
> > 2) censDist contains, for each location identified by its numerical code,
> > the distance to other locations (censDist has 1.5 million rows). The
> > head(consist) below, for example, reads like this:
> >
> > location 2924 has a distance to 2732 of 1309.7525
> > location 2924 has a distance to 2875 of 696.2891,
> > etc.
> >
> >> head(censDist)
> >   f_cell f  _cell_neigh  distance
> > 1   2924         2732   1309.7525
> > 2   2924         2875     696.2891
> > 3   2924         2351   1346.0561
> > 4   2924         2350   1296.9804
> > 5   2924         2725   1278.1877
> > 6   2924         2721   1346.9126
> >
> >
> > Basically, for every location in  id_cell I should pick up the distance
> to
> > other locations in id_cell from censDist, and allocate it in M
> >
> > I have not come up with a satisfactory vectorizion of this problem and
> > using a loop is out of question.
> >
> > Thanks for your help
> > Mario
> >
> >
>



-- 
Andrea Mario Lavezzi
DiGi,Sezione Diritto e Societ?
Universit? di Palermo
Piazza Bologni 8
90134 Palermo, Italy
tel. ++39 091 23892208
fax ++39 091 6111268
skype: lavezzimario
email: mario.lavezzi (at) unipa.it
web: http://www.unipa.it/~mario.lavezzi

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri May 13 16:27:46 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 13 May 2016 07:27:46 -0700
Subject: [R] anonymizing subject identifiers for survival analysis
In-Reply-To: <CAM+rpY=HgsQwPsfP9bXfK=0QGe_Lfi87PYNHv27BSwVoRA56ow@mail.gmail.com>
References: <CAM+rpY=HgsQwPsfP9bXfK=0QGe_Lfi87PYNHv27BSwVoRA56ow@mail.gmail.com>
Message-ID: <CAF8bMcZ52svT0q-2wy2=xnigCbwJYw1wUQ+94fe4UHzo_dSsrA@mail.gmail.com>

You can also use match(code, unique(code)), as in
  transform(dd.2, codex2 = paste0("Person", match(code, unique(code))))
It is not guaranteed that x!=y implies digest(x)!=digest(y), but it is
extremely
unlikely to fail.  This match idiom guarantees that.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, May 12, 2016 at 1:06 PM, Christopher W Ryan <cryan at binghamton.edu>
wrote:

> I would like to conduct a survival analysis, examining a subject's
> time to *next* appearance in a database, after their first appearance.
> It is a database of dated events.
>
> I need to obfuscate or anonymize or mask the subject identifiers (a
> combination of name and birthdate). And obviously any given subject
> should have the same anonymous code ever time he/she appears in the
> database.  I'm not talking "safe from the NSA" here. And I won't be
> releasing it. It's just sensitive data and I don't want to be working
> every day with cleartext versions of it.
>
> I've looked at packages digest, anonymizer, and anonymize.  What do
> you think of this approach:
>
> # running R 3.1.1 on Windows 7 Enterprise
> library(digest)
> dd <- data.frame(id=1:6, name = c("Harry", "Ron", "Hermione", "Luna",
> "Ginny", "Harry"), dob = c("1990-01-01", "1990-06-15", "1990-04-08",
> "1999-11-26", "1990-07-21", "1990-01-01"))
> dd.2 <- transform(dd, code=paste0(tolower(name), tolower(dob), sep=""))
> library(digest)
> anonymize <- function(x, algo="sha256"){
>   unq_hashes <- vapply(x, function(object) digest(object, algo=algo),
> FUN.VALUE="", USE.NAMES=TRUE)
>   unname(unq_hashes[x])
> }
> dd.2$codex <- anonymize(dd.2$code)
> dd.2
> table(duplicated(dd.2$codex))
>
> Thanks.
>
> --Chris Ryan
> Broome County Health Department
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Fri May 13 18:45:08 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 13 May 2016 12:45:08 -0400
Subject: [R] building a spatial matrix
In-Reply-To: <CAOZPQW6kGycyZ-a1-nZVu1_YjFtDb+qLcgcxvjiE-vS=6O5wZQ@mail.gmail.com>
References: <CAOZPQW7DOicT9pS8H2BA3gxnJLg0wYTu9UhinwpgywcSDGoKFw@mail.gmail.com>
	<CAM_vjuk8hVY6F67behO+YQ1R5gSxb5xTxQgysSwZmigmPoQXow@mail.gmail.com>
	<CAOZPQW4zO7EaF3KTaDGgBStoycEvyMyKJFz1MwCRjMUk7zfDug@mail.gmail.com>
	<CAOZPQW6kGycyZ-a1-nZVu1_YjFtDb+qLcgcxvjiE-vS=6O5wZQ@mail.gmail.com>
Message-ID: <CAM_vju=CtoOn9a3tb5U407no7t5E7tXgPxbvHEbDwihODbTJdA@mail.gmail.com>

Sorry, you're right.

The result line should be:

result.m[cbind(factor(result$fcell), factor(result$cellneigh))]  <-
result$distance


idcell <- data.frame(
  id = seq_len(5),
  fcell = sample(1:100, 5))

censDist <- expand.grid(fcell=seq_len(100), cellneigh=seq_len(100))
censDist$distance <- runif(nrow(censDist))

# assemble the non-symmetric distance matrix
result <- subset(censDist, fcell %in% idcell$fcell & cellneigh %in%
idcell$fcell)
result.m <- matrix(NA, nrow=nrow(idcell), ncol=nrow(idcell))
result.m[cbind(factor(result$fcell), factor(result$cellneigh))]  <-
result$distance

It's just about instantaneous on the dataset you sent me:


system.time({
result <- subset(censDist, f_cell %in% id_cell$f_cell & f_cell_neigh %in%
id_cell$f_cell)
result.m <- matrix(NA, nrow=nrow(id_cell), ncol=nrow(id_cell))
result.m[cbind(factor(result$f_cell), factor(result$f_cell_neigh))] <-
result$distance
})

  user  system elapsed
  0.361   0.007   0.368




Sarah

On Fri, May 13, 2016 at 10:36 AM, A M Lavezzi <mario.lavezzi at unipa.it>
wrote:
> PLEASE IGNORE THE PREVIOUS EMAIL, IT WAS SENT BY MISTAKE
>
> Hello Sarah
> thanks a lot for your advice.
>
> I followed your suggestions unitil the creation of "result"
>
> The allocation of the values of result$distance to the matrix result.m,
> however ,does not seem to work: it produces a matrix with identical
columns
> corresponding to the last values of result$distance. Maybe my description
of
> the dataset was not clear enough.
>
> I produced the final matrix spat_dist with a loop, that I report below (it
> takes about 1 hour on my macbook pro),
>
> set_i = -1   # create a variable to store the i values already examined
>
> for(i in unique(result$id)){
>
>   set_i=c(set_i,i) # store the value of the i
>
>   set_neigh = result$id_neigh[result$id==i & !result$id_neigh %in% set_i]
#
> identify the locations connected to i. If the distance between i and j was
> examined before, don't look for the distance between j and i
>
>   for(j in set_neigh){
>     if(i!=j){
>       spat_dist[i,j] = result$distance[result$id==i &  result$id_neigh==j]
>       spat_dist[j,i] = spat_dist[i,j]
>     }
>     else{
>       spat_dist[i,j]=0
>     }
>   }
> }
>
> It is not the most elegant and efficient solution in the world, that's for
> sure.
>
> I would be grateful, if you could suggest an alternative instruction to:
>
> result.m[factor(result$fcell), factor(result$cellneigh)] <-
result$distance
>
> so I will learn a faster procedure (I tried many times but to modify this
> structure but I did not make it). I don't want to abuse of your time, so
> forget it if you are busy
>
> Thank you so much anyway,
> Mario
>
> ps I attach the data. Notice that the 1327 units in id_cell are firms,
> indexed by id, located in location f_cell. Different firms can be located
in
> the same f_cell. With respect to your suggestion, I added two columns to
> "result" with the id of the firms.
>
> On Fri, May 13, 2016 at 3:26 PM, A M Lavezzi <mario.lavezzi at unipa.it>
wrote:
>>
>>
>> Hello Sarah
>> thanks a lot for your advice.
>>
>> I followed your suggestions unitl the creation of "result"
>>
>> The allocation of the values of result$distance to the matrix result.m,
>> however ,does not seem to work: it produces a matrix with identical
columns
>> corresponding to the last values of result$distance. Maybe my
description of
>> the dataset was not clear enough.
>>
>> I produced the final matrix with a loop, that I report below (it takes
>> about 1 hour on my macbook pro),
>>
>> set_i = -1   # create a variable to store the i values already examined
>>
>> for(i in unique(result$id)){
>>
>>   set_i=c(set_i,i) # store the value of the i
>>
>>   set_neigh = result$id_neigh[result$id==i & !result$id_neigh %in% set_i]
>> # identify the locations connected to i. Exclude                  those
>>
>>   for(j in set_neigh){
>>     if(i!=j){
>>       spat_dist[i,j] = result$distance[result$id==i &
 result$id_neigh==j]
>>       spat_dist[j,i] = spat_dist[i,j]
>>     }
>>     else{
>>       spat_dist[i,j]=0
>>     }
>>   }
>> }
>>
>> It not the most elegant and efficient solution in the world, that's for
>> sure
>>
>>
>>
>> On Thu, May 12, 2016 at 2:51 PM, Sarah Goslee <sarah.goslee at gmail.com>
>> wrote:
>>>
>>> I don't see any reason why a loop is out of the question, and
>>> answering would have been much easier if you'd included the requested
>>> reproducible data, but what about this?
>>>
>>> This solution is robust to pairs from idcell being absent in censDist,
>>> and to the difference from A to B being different than the distance
>>> from B to A, but not to A-B appearing twice. If that's possible,
>>> you'll need to figure out how to manage it.
>>>
>>> # create some fake data
>>>
>>> idcell <- data.frame(
>>>   id = seq_len(5),
>>>   fcell = sample(1:100, 5))
>>>
>>> censDist <- expand.grid(fcell=seq_len(100), cellneigh=seq_len(100))
>>> censDist$distance <- runif(nrow(censDist))
>>>
>>> # assemble the non-symmetric distance matrix
>>> result <- subset(censDist, fcell %in% idcell$fcell & cellneigh %in%
>>> idcell$fcell)
>>> result.m <- matrix(NA, nrow=nrow(idcell), ncol=nrow(idcell))
>>> result.m[factor(result$fcell), factor(result$cellneigh)] <-
>>> result$distance
>>>
>>> Sarah
>>>
>>> On Thu, May 12, 2016 at 5:26 AM, A M Lavezzi <mario.lavezzi at unipa.it>
>>> wrote:
>>> > Hello,
>>> >
>>> > I have a sample of 1327  locations, each one idetified by an id and a
>>> > numerical code.
>>> >
>>> > I need to build a spatial matrix, say, M, i.e. a 1327x1327 matrix
>>> > collecting distances among the locations.
>>> >
>>> > M(i,i) should be 0, M(i,j) should contain the distance among location
i
>>> > and
>>> > j
>>> >
>>> > I shoud use data organized in the following way:
>>> >
>>> > 1) id_cell contains the identifier (id) of each location (1...1327)
and
>>> > the
>>> > numerical code of the location (f_cell) (see head of id_cell below)
>>> >
>>> >> head(id_cell)
>>> >      id  f_cell
>>> > 1    1   2120
>>> > 12  2     204
>>> > 22  3   2546
>>> > 24  4   1327
>>> > 34  5   1729
>>> > 43  6   2293
>>> >
>>> > 2) censDist contains, for each location identified by its numerical
>>> > code,
>>> > the distance to other locations (censDist has 1.5 million rows). The
>>> > head(consist) below, for example, reads like this:
>>> >
>>> > location 2924 has a distance to 2732 of 1309.7525
>>> > location 2924 has a distance to 2875 of 696.2891,
>>> > etc.
>>> >
>>> >> head(censDist)
>>> >   f_cell f  _cell_neigh  distance
>>> > 1   2924         2732   1309.7525
>>> > 2   2924         2875     696.2891
>>> > 3   2924         2351   1346.0561
>>> > 4   2924         2350   1296.9804
>>> > 5   2924         2725   1278.1877
>>> > 6   2924         2721   1346.9126
>>> >
>>> >
>>> > Basically, for every location in  id_cell I should pick up the
distance
>>> > to
>>> > other locations in id_cell from censDist, and allocate it in M
>>> >
>>> > I have not come up with a satisfactory vectorizion of this problem and
>>> > using a loop is out of question.
>>> >
>>> > Thanks for your help
>>> > Mario
>>> >
>>> >
>>

	[[alternative HTML version deleted]]


From mario.lavezzi at unipa.it  Fri May 13 16:36:26 2016
From: mario.lavezzi at unipa.it (A M Lavezzi)
Date: Fri, 13 May 2016 15:36:26 +0100
Subject: [R] building a spatial matrix
In-Reply-To: <CAOZPQW4zO7EaF3KTaDGgBStoycEvyMyKJFz1MwCRjMUk7zfDug@mail.gmail.com>
References: <CAOZPQW7DOicT9pS8H2BA3gxnJLg0wYTu9UhinwpgywcSDGoKFw@mail.gmail.com>
	<CAM_vjuk8hVY6F67behO+YQ1R5gSxb5xTxQgysSwZmigmPoQXow@mail.gmail.com>
	<CAOZPQW4zO7EaF3KTaDGgBStoycEvyMyKJFz1MwCRjMUk7zfDug@mail.gmail.com>
Message-ID: <CAOZPQW6kGycyZ-a1-nZVu1_YjFtDb+qLcgcxvjiE-vS=6O5wZQ@mail.gmail.com>

*PLEASE IGNORE THE PREVIOUS EMAIL, IT WAS SENT BY MISTAKE*

Hello Sarah
thanks a lot for your advice.

I followed your suggestions unitil the creation of "result"

The allocation of the values of result$distance to the matrix result.m,
however ,does not seem to work: it produces a matrix with identical columns
corresponding to the last values of result$distance. Maybe my description
of the dataset was not clear enough.

I produced the final matrix spat_dist with a loop, that I report below (it
takes about 1 hour on my macbook pro),

set_i = -1   # create a variable to store the i values already examined

for(i in unique(result$id)){

  set_i=c(set_i,i) # store the value of the i

  set_neigh = result$id_neigh[result$id==i & !result$id_neigh %in% set_i] #
identify the locations connected to i. If the distance between i and j was
examined before, don't look for the distance between j and i

  for(j in set_neigh){
    if(i!=j){
      spat_dist[i,j] = result$distance[result$id==i &  result$id_neigh==j]
      spat_dist[j,i] = spat_dist[i,j]
    }
    else{
      spat_dist[i,j]=0
    }
  }
}

It is not the most elegant and efficient solution in the world, that's for
sure.

I would be grateful, if you could suggest an alternative instruction to:

result.m[factor(result$fcell), factor(result$cellneigh)] <- result$distance

so I will learn a faster procedure (I tried many times but to modify this
structure but I did not make it). I don't want to abuse of your time, so
forget it if you are busy

Thank you so much anyway,
Mario

ps I attach the data. Notice that the 1327 units in id_cell are firms,
indexed by id, located in location f_cell. Different firms can be located
in the same f_cell. With respect to your suggestion, I added two columns to
"result" with the id of the firms.

On Fri, May 13, 2016 at 3:26 PM, A M Lavezzi <mario.lavezzi at unipa.it> wrote:

>
> Hello Sarah
> thanks a lot for your advice.
>
> I followed your suggestions unitl the creation of "result"
>
> The allocation of the values of result$distance to the matrix result.m,
> however ,does not seem to work: it produces a matrix with identical columns
> corresponding to the last values of result$distance. Maybe my description
> of the dataset was not clear enough.
>
> I produced the final matrix with a loop, that I report below (it takes
> about 1 hour on my macbook pro),
>
> set_i = -1   # create a variable to store the i values already examined
>
> for(i in unique(result$id)){
>
>   set_i=c(set_i,i) # store the value of the i
>
>   set_neigh = result$id_neigh[result$id==i & !result$id_neigh %in% set_i]
> # identify the locations connected to i. Exclude                  those
>
>   for(j in set_neigh){
>     if(i!=j){
>       spat_dist[i,j] = result$distance[result$id==i &  result$id_neigh==j]
>       spat_dist[j,i] = spat_dist[i,j]
>     }
>     else{
>       spat_dist[i,j]=0
>     }
>   }
> }
>
> It not the most elegant and efficient solution in the world, that's for
> sure
>
>
>
> On Thu, May 12, 2016 at 2:51 PM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
>
>> I don't see any reason why a loop is out of the question, and
>> answering would have been much easier if you'd included the requested
>> reproducible data, but what about this?
>>
>> This solution is robust to pairs from idcell being absent in censDist,
>> and to the difference from A to B being different than the distance
>> from B to A, but not to A-B appearing twice. If that's possible,
>> you'll need to figure out how to manage it.
>>
>> # create some fake data
>>
>> idcell <- data.frame(
>>   id = seq_len(5),
>>   fcell = sample(1:100, 5))
>>
>> censDist <- expand.grid(fcell=seq_len(100), cellneigh=seq_len(100))
>> censDist$distance <- runif(nrow(censDist))
>>
>> # assemble the non-symmetric distance matrix
>> result <- subset(censDist, fcell %in% idcell$fcell & cellneigh %in%
>> idcell$fcell)
>> result.m <- matrix(NA, nrow=nrow(idcell), ncol=nrow(idcell))
>> result.m[factor(result$fcell), factor(result$cellneigh)] <-
>> result$distance
>>
>> Sarah
>>
>> On Thu, May 12, 2016 at 5:26 AM, A M Lavezzi <mario.lavezzi at unipa.it>
>> wrote:
>> > Hello,
>> >
>> > I have a sample of 1327  locations, each one idetified by an id and a
>> > numerical code.
>> >
>> > I need to build a spatial matrix, say, M, i.e. a 1327x1327 matrix
>> > collecting distances among the locations.
>> >
>> > M(i,i) should be 0, M(i,j) should contain the distance among location i
>> and
>> > j
>> >
>> > I shoud use data organized in the following way:
>> >
>> > 1) id_cell contains the identifier (id) of each location (1...1327) and
>> the
>> > numerical code of the location (f_cell) (see head of id_cell below)
>> >
>> >> head(id_cell)
>> >      id  f_cell
>> > 1    1   2120
>> > 12  2     204
>> > 22  3   2546
>> > 24  4   1327
>> > 34  5   1729
>> > 43  6   2293
>> >
>> > 2) censDist contains, for each location identified by its numerical
>> code,
>> > the distance to other locations (censDist has 1.5 million rows). The
>> > head(consist) below, for example, reads like this:
>> >
>> > location 2924 has a distance to 2732 of 1309.7525
>> > location 2924 has a distance to 2875 of 696.2891,
>> > etc.
>> >
>> >> head(censDist)
>> >   f_cell f  _cell_neigh  distance
>> > 1   2924         2732   1309.7525
>> > 2   2924         2875     696.2891
>> > 3   2924         2351   1346.0561
>> > 4   2924         2350   1296.9804
>> > 5   2924         2725   1278.1877
>> > 6   2924         2721   1346.9126
>> >
>> >
>> > Basically, for every location in  id_cell I should pick up the distance
>> to
>> > other locations in id_cell from censDist, and allocate it in M
>> >
>> > I have not come up with a satisfactory vectorizion of this problem and
>> > using a loop is out of question.
>> >
>> > Thanks for your help
>> > Mario
>> >
>> >
>>
>
>
>
> --
> Andrea Mario Lavezzi
> DiGi,Sezione Diritto e Societ?
> Universit? di Palermo
> Piazza Bologni 8
> 90134 Palermo, Italy
> tel. ++39 091 23892208
> fax ++39 091 6111268
> skype: lavezzimario
> email: mario.lavezzi (at) unipa.it
> web: http://www.unipa.it/~mario.lavezzi
>



-- 
Andrea Mario Lavezzi
DiGi,Sezione Diritto e Societ?
Universit? di Palermo
Piazza Bologni 8
90134 Palermo, Italy
tel. ++39 091 23892208
fax ++39 091 6111268
skype: lavezzimario
email: mario.lavezzi (at) unipa.it
web: http://www.unipa.it/~mario.lavezzi

From massimo.bressan at arpa.veneto.it  Fri May 13 16:44:55 2016
From: massimo.bressan at arpa.veneto.it (Massimo Bressan)
Date: Fri, 13 May 2016 16:44:55 +0200 (CEST)
Subject: [R] apply formula over columns by subset of rows in a dataframe
 (to get a new dataframe)
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D732474@mb02.ads.tamu.edu>
References: <1274186074.11911782.1463140539471.JavaMail.zimbra@arpa.veneto.it>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D732474@mb02.ads.tamu.edu>
Message-ID: <2059033841.11937030.1463150695746.JavaMail.zimbra@arpa.veneto.it>

yes, thanks

you pointed me in the right direction: split/unplist was the trick 

I completely left behind that possibility!

here the final version

############

mynorm <- function(x) {(x - min(x, na.rm=TRUE))/(max(x, na.rm=TRUE) - min(x, na.rm=TRUE))} 

mydf<-data.frame(blocks=rep(c("a","b","c"),each=5), v1=round(runif(15,10,25),0), v2=round(rnorm(15,30,5),0)) 

g <- mydf$blocks
l <- split(mydf, g)
l <- lapply(l, transform, v1.mod = mynorm(v1))
mydf_new <- unsplit(l, g)

############

thanks again

massimo


From wdunlap at tibco.com  Fri May 13 19:22:21 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 13 May 2016 10:22:21 -0700
Subject: [R] apply formula over columns by subset of rows in a dataframe
 (to get a new dataframe)
In-Reply-To: <2059033841.11937030.1463150695746.JavaMail.zimbra@arpa.veneto.it>
References: <1274186074.11911782.1463140539471.JavaMail.zimbra@arpa.veneto.it>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D732474@mb02.ads.tamu.edu>
	<2059033841.11937030.1463150695746.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <CAF8bMcYL+jOx4VA6cZmaU-spFOZ9cJ4UCscT_jv-2rWT_txUcA@mail.gmail.com>

ave() encapsulates the split/lapply/unsplit stuff so
   transform(mydf, v1.mod = ave(v1, blocks, FUN=mynorm))
also gives what you got above.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, May 13, 2016 at 7:44 AM, Massimo Bressan <
massimo.bressan at arpa.veneto.it> wrote:

> yes, thanks
>
> you pointed me in the right direction: split/unplist was the trick
>
> I completely left behind that possibility!
>
> here the final version
>
> ############
>
> mynorm <- function(x) {(x - min(x, na.rm=TRUE))/(max(x, na.rm=TRUE) -
> min(x, na.rm=TRUE))}
>
> mydf<-data.frame(blocks=rep(c("a","b","c"),each=5),
> v1=round(runif(15,10,25),0), v2=round(rnorm(15,30,5),0))
>
> g <- mydf$blocks
> l <- split(mydf, g)
> l <- lapply(l, transform, v1.mod = mynorm(v1))
> mydf_new <- unsplit(l, g)
>
> ############
>
> thanks again
>
> massimo
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jakub at jirutka.cz  Fri May 13 21:55:47 2016
From: jakub at jirutka.cz (Jakub Jirutka)
Date: Fri, 13 May 2016 21:55:47 +0200
Subject: [R] Warning when running R - can't install packages either
In-Reply-To: <57359F08.8090307@roswellpark.org>
References: <CAJDAfTBMYFH0PcRG7scf+g5GAbkPC2yz4UF+1w+d5=xssipaHQ@mail.gmail.com>
	<238A333C-AE09-4131-94CE-E4688A6814D3@gmail.com>
	<CAJDAfTAa0RuZ+CjO0kX-zFaxzVfb2XsBZ_cpA2G-GCoq0qeteA@mail.gmail.com>
	<57359F08.8090307@roswellpark.org>
Message-ID: <986689C7-EA25-4724-9D98-2939E1A5831B@jirutka.cz>

Hi,

I?m maintainer of the R package in Alpine Linux.

I read on multiple places that some packages needs R_HOME variable set to the location where is R installed, so I?ve added it to the system-wide profile. Is this correct, or a misinformation?

What system dependencies does R need to compile modules from CRAN? On Alpine the following dependencies are needed to build R: bzip2-dev curl-dev gfortran lapack-dev pcre-dev perl readline-dev xz-dev zlib-dev. Are all of these dependencies needed for compiling modules?

Jakub

On 13. May 2016, at 11:31, Martin Morgan <martin.morgan at roswellpark.org> wrote:

> 
> 
> On 05/12/2016 10:25 PM, Alba Pompeo wrote:
>> Martin Morgan, I tried an HTTP mirror and it worked.
>> What could be the problem and how to fix?
>> Also, should I ignore the warning about ignoring environment value of R_HOME?
> 
> It depends on why you set the value in your environment in the first place; maybe you were trying to use a particular installation of R, but setting R_HOME is not the way to do that (I use an alias, e.g., R-3.3='~/bin/R-3-3-branch/bin/R --no-save --no-restore --silent')
> 
> Martin
> 
>> Thanks.
>> 
>> On Thu, May 12, 2016 at 5:59 PM, Tom Hopper <tomhopper at gmail.com> wrote:
>>> setInternet2() first thing after launching R might fix that.
>>> 
>>> 
>>>> On May 12, 2016, at 07:45, Alba Pompeo <albapompeo at gmail.com> wrote:
>>>> 
>>>> Hello.
>>>> 
>>>> I've tried to run R, but I receive many warnings and can't do simple
>>>> stuff such as installing packages.
>>>> 
>>>> Here's the full log when I run it.
>>>> 
>>>> http://pastebin.com/raw/2BkNpTte
>>>> 
>>>> Does anyone know what could be wrong here?
>>>> 
>>>> Thanks a lot.
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> This email message may contain legally privileged and/or confidential information.  If you are not the intended recipient(s), or the employee or agent responsible for the delivery of this message to the intended recipient(s), you are hereby notified that any disclosure, copying, distribution, or use of this email message is prohibited.  If you have received this message in error, please notify the sender immediately by e-mail and delete this email message from your computer. Thank you.


From martin.morgan at roswellpark.org  Sat May 14 00:57:09 2016
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Fri, 13 May 2016 18:57:09 -0400
Subject: [R] Warning when running R - can't install packages either
In-Reply-To: <986689C7-EA25-4724-9D98-2939E1A5831B@jirutka.cz>
References: <CAJDAfTBMYFH0PcRG7scf+g5GAbkPC2yz4UF+1w+d5=xssipaHQ@mail.gmail.com>
	<238A333C-AE09-4131-94CE-E4688A6814D3@gmail.com>
	<CAJDAfTAa0RuZ+CjO0kX-zFaxzVfb2XsBZ_cpA2G-GCoq0qeteA@mail.gmail.com>
	<57359F08.8090307@roswellpark.org>
	<986689C7-EA25-4724-9D98-2939E1A5831B@jirutka.cz>
Message-ID: <57365BC5.1040101@roswellpark.org>

Hi Jakub,

This is really a separate question. It is not really end-user related, 
and should be asked on the R-devel mailing list. Nonetheless, some 
answers below.

On 05/13/2016 03:55 PM, Jakub Jirutka wrote:
> Hi,
>
> I?m maintainer of the R package in Alpine Linux.
>
> I read on multiple places that some packages needs R_HOME variable
> set to the location where is R installed, so I?ve added it to the
> system-wide profile. Is this correct, or a misinformation?

R_HOME is set when R starts

~$ env|grep R_HOME
~$ R --vanilla -e "Sys.getenv('R_HOME')"
 > Sys.getenv('R_HOME')
[1] "/home/mtmorgan/bin/R-3-3-branch"

and (after reading the documentation in ?R_HOME it the R help system)

~$ R RHOME
/home/mtmorgan/bin/R-3-3-branch

so there is no need to set it in a system-wide profile. It is sometimes 
referenced inside an R package source tree that uses C or other compiled 
code in a Makevars file, as described in the 'Writing R Extensions' manual

https://cran.r-project.org/doc/manuals/r-release/R-exts.html
e.g., the section on configure and cleanup

https://cran.r-project.org/doc/manuals/r-release/R-exts.html#Configure-and-cleanup

In these circumstances it has been set by the R process that is 
compiling the source code.

>
> What system dependencies does R need to compile modules from CRAN? On
> Alpine the following dependencies are needed to build R: bzip2-dev
> curl-dev gfortran lapack-dev pcre-dev perl readline-dev xz-dev
> zlib-dev. Are all of these dependencies needed for compiling
> modules?

As you say, those look like dependencies required to build R itself.

Individual packages may have dependencies on these or other system 
libraries, but many packages do not have system dependencies. It is up 
to the package maintainer to ensure that appropriate checks are made to 
discover the system resource; there are probably dozens or even hundreds 
of system dependencies amongst all of the CRAN packages. Typically the 
task of satisfying those dependencies is left to the user (or to those 
creating distributions of R packages, e.g., 
https://cran.r-project.org/bin/linux/debian/)

Martin Morgan

>
> Jakub
>
> On 13. May 2016, at 11:31, Martin Morgan
> <martin.morgan at roswellpark.org> wrote:
>
>>
>>
>> On 05/12/2016 10:25 PM, Alba Pompeo wrote:
>>> Martin Morgan, I tried an HTTP mirror and it worked. What could
>>> be the problem and how to fix? Also, should I ignore the warning
>>> about ignoring environment value of R_HOME?
>>
>> It depends on why you set the value in your environment in the
>> first place; maybe you were trying to use a particular installation
>> of R, but setting R_HOME is not the way to do that (I use an alias,
>> e.g., R-3.3='~/bin/R-3-3-branch/bin/R --no-save --no-restore
>> --silent')
>>
>> Martin
>>
>>> Thanks.
>>>
>>> On Thu, May 12, 2016 at 5:59 PM, Tom Hopper <tomhopper at gmail.com>
>>> wrote:
>>>> setInternet2() first thing after launching R might fix that.
>>>>
>>>>
>>>>> On May 12, 2016, at 07:45, Alba Pompeo <albapompeo at gmail.com>
>>>>> wrote:
>>>>>
>>>>> Hello.
>>>>>
>>>>> I've tried to run R, but I receive many warnings and can't do
>>>>> simple stuff such as installing packages.
>>>>>
>>>>> Here's the full log when I run it.
>>>>>
>>>>> http://pastebin.com/raw/2BkNpTte
>>>>>
>>>>> Does anyone know what could be wrong here?
>>>>>
>>>>> Thanks a lot.
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>>>> see https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do
>>>>> read the posting guide
>>>>> http://www.R-project.org/posting-guide.html and provide
>>>>> commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>> see https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read
>>> the posting guide http://www.R-project.org/posting-guide.html and
>>> provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>> This email message may contain legally privileged and/or
>> confidential information.  If you are not the intended
>> recipient(s), or the employee or agent responsible for the delivery
>> of this message to the intended recipient(s), you are hereby
>> notified that any disclosure, copying, distribution, or use of this
>> email message is prohibited.  If you have received this message in
>> error, please notify the sender immediately by e-mail and delete
>> this email message from your computer. Thank you.
>


This email message may contain legally privileged and/or...{{dropped:2}}


From simon.wood at bath.edu  Sat May 14 09:24:36 2016
From: simon.wood at bath.edu (Simon Wood)
Date: Sat, 14 May 2016 08:24:36 +0100
Subject: [R] physical constraint with gam
In-Reply-To: <CAF1jk_k=v1-FhTRRrq54Ry_SixdMsAKV+YKaLZmBNwy6uF77yg@mail.gmail.com>
References: <CAF1jk_=312-4GEwpeJM2UaOojnSE_6PxLo6YU2ysjGdHKBt3UQ@mail.gmail.com>
	<5732F730.9000800@bath.edu>
	<CAF1jk_=Yk6ruWTyDZ_aZnDTAmSZi6=7eSM5CoL0x=jF=JVqm4w@mail.gmail.com>
	<CAF1jk_k=v1-FhTRRrq54Ry_SixdMsAKV+YKaLZmBNwy6uF77yg@mail.gmail.com>
Message-ID: <5736D2B4.3030305@bath.edu>

On 12/05/16 02:29, Dominik Schneider wrote:
> Hi again,
> I'm looking for some clarification on 2 things.
> 1. On that last note, I realize that s(x1,x2) would be the other 
> obvious interaction to compare with - and I see that you recommend 
> te(x1,x2) if they are not on the same scale.
- yes that's right, s(x1,x2) gives an isotropic smooth, which is usually 
only appropriate if x1 and x2 are naturally on the same scale.

> 2. If s(x1,by=x1) gives you a "parameter" value similar to a GLM when 
> you plot s(x1):x1, why does my function above return the same yhat as 
> predict(mdl,type='response') ? Shouldn't each of the terms need to be 
> multiplied by the variable value before applying 
> rowSums()+attr(sterms,'constant') ??
predict returns s(x1)*x1 (plot.gam just plots s(x1), because in general 
s(x1,by=x2) is not smooth). If you want to get s(x1) on its own you need 
to do something like this:

x2 <- x1 ## copy x1
m <- gam(y~s(x1,by=x2)) ## model implementing s(x1,by=x1) using copy of x1
predict(m,data.frame(x1=x1,x2=rep(1,length(x2))),type="terms") ## now 
predicted s(x1)*x2 = s(x1)

best,
Simon

> Thanks again
> Dominik
>
> On Wed, May 11, 2016 at 10:11 AM, Dominik Schneider 
> <Dominik.Schneider at colorado.edu 
> <mailto:Dominik.Schneider at colorado.edu>> wrote:
>
>     Hi Simon, Thanks for this explanation.
>     To make sure I understand, another way of explaining the y axis in
>     my original example is that it is the contribution to snowdepth
>     relative to the other variables (the example only had fsca, but my
>     actual case has a couple others). i.e. a negative s(fsca) of -0.5
>     simply means snowdepth 0.5 units below the intercept+s(x_i), where
>     s(x_i) could also be negative in the case where total snowdepth is
>     less than the intercept value.
>
>     The use of by=fsca is really useful for interpreting the marginal
>     impact of the different variables. With my actual data, the term
>     s(fsca):fsca is never negative, which is much more intuitive. Is
>     it appropriate to compare magnitudes of e.g. s(x2):x2 / mean(x2)
>     and s(x2):x2 / mean(x2)  where mean(x_i) are the mean of the
>     actual data?
>
>     Lastly, how would these two differ: s(x1,by=x2); or
>     s(x1,by=x1)*s(x2,by=x2) since interactions are surely present and
>     i'm not sure if a linear combination is enough.
>
>     Thanks!
>     Dominik
>
>
>     On Wed, May 11, 2016 at 3:11 AM, Simon Wood <simon.wood at bath.edu
>     <mailto:simon.wood at bath.edu>> wrote:
>
>         The spline having a positive value is not the same as a glm
>         coefficient having a positive value. When you plot a smooth,
>         say s(x), that is equivalent to plotting the line 'beta * x'
>         in a GLM. It is not equivalent to plotting 'beta'. The smooths
>         in a gam are (usually) subject to `sum-to-zero'
>         identifiability constraints to avoid confounding via the
>         intercept, so they are bound to be negative over some part of
>         the covariate range. For example, if I have a model y ~ s(x) +
>         s(z), I can't estimate the mean level for s(x) and the mean
>         level for s(z) as they are completely confounded, and
>         confounded with the model intercept term.
>
>         I suppose that if you want to interpret the smooths as glm
>         parameters varying with the covariate they relate to then you
>         can do, by setting the model up as a varying coefficient
>         model, using the `by' argument to 's'...
>
>         gam(snowdepth~s(fsca,by=fsca),data=dat)
>
>
>         this model is `snowdepth_i = f(fsca_i) * fsca_i + e_i' .
>         s(fsca,by=fsca) is not confounded with the intercept, so no
>         constraint is needed or applied, and you can now interpret the
>         smooth like a local GLM coefficient.
>
>         best,
>         Simon
>
>
>
>
>         On 11/05/16 01:30, Dominik Schneider wrote:
>
>             Hi,
>             Just getting into using GAM using the mgcv package. I've
>             generated some
>             models and extracted the splines for each of the variables
>             and started
>             visualizing them. I'm noticing that one of my variables is
>             physically
>             unrealistic.
>
>             In the example below, my interpretation of the following
>             plot is that the
>             y-axis is basically the equivalent of a "parameter" value
>             of a GLM; in GAM
>             this value can change as the functional relationship
>             changes between x and
>             y. In my case, I am predicting snowdepth based on the
>             fractional snow
>             covered area. In no case will snowdepth realistically
>             decrease for a unit
>             increase in fsca so my question is: *Is there a way to
>             constrain the spline
>             to positive values? *
>
>             Thanks
>             Dominik
>
>             library(mgcv)
>             library(dplyr)
>             library(ggplot2)
>             extract_splines=function(mdl){
>                sterms=predict(mdl,type='terms')
>                datplot=cbind(sterms,mdl$model) %>% tbl_df
>                datplot$intercept=attr(sterms,'constant')
>              datplot$yhat=rowSums(sterms)+attr(sterms,'constant')
>                return(datplot)
>             }
>             dat=data_frame(snowdepth=runif(100,min =
>             0.001,max=6.7),fsca=runif(100,0.01,.99))
>             mdl=gam(snowdepth~s(fsca),data=dat)
>             termdF=extract_splines(mdl)
>             ggplot(termdF)+
>                geom_line(aes(x=fsca,y=`s(fsca)`))
>
>                     [[alternative HTML version deleted]]
>
>             ______________________________________________
>             R-help at r-project.org <mailto:R-help at r-project.org> mailing
>             list -- To UNSUBSCRIBE and more, see
>             https://stat.ethz.ch/mailman/listinfo/r-help
>             PLEASE do read the posting guide
>             http://www.R-project.org/posting-guide.html
>             and provide commented, minimal, self-contained,
>             reproducible code.
>
>
>
>         -- 
>         Simon Wood, School of Mathematics, University of Bristol BS8
>         1TW UK
>         +44 (0)117 33 18273 <tel:%2B44%20%280%29117%2033%2018273>
>         http://www.maths.bris.ac.uk/~sw15190
>         <http://www.maths.bris.ac.uk/%7Esw15190>
>
>
>


-- 
Simon Wood, School of Mathematics, University of Bristol BS8 1TW UK
+44 (0)117 33 18273     http://www.maths.bris.ac.uk/~sw15190


	[[alternative HTML version deleted]]


From suharto_anggono at yahoo.com  Sat May 14 08:38:54 2016
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Sat, 14 May 2016 06:38:54 +0000 (UTC)
Subject: [R] aggregate.data.frame(drop=FALSE) in R 3.3.0
References: <1680235.1952922.1463207934486.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1680235.1952922.1463207934486.JavaMail.yahoo@mail.yahoo.com>

>From NEWS: The data frame and formula methods for aggregate() gain a drop argument.

Here, I highlight behavior of 'aggregate.data.frame' with drop=FALSE in R 3.3.0.

Example 1, modified from "example with character variables and NAs" in "Example" in R help on 'aggregate':
> testDF <- data.frame(v1 = c(1,3,5,7,8,3,5,NA,4,5,7,9),
+                      v2 = c(11,33,55,77,88,33,55,NA,44,55,77,99) )
> by1 <- c("red", "blue", 1, 2, NA, "big", 1, 2, "red", 1, NA, 12)
> by2 <- c("wet", "dry", 99, 95, NA, "damp", 95, 99, "red", 99, NA, NA)
> str(aggregate(x = testDF, by = list(by1, by2), FUN = "mean", drop = FALSE))
'data.frame':   30 obs. of  4 variables:
 $ Group.1: Factor w/ 5 levels "1","2","big",..: 1 2 3 4 5 1 2 3 4 5 ...
 $ Group.2: Factor w/ 6 levels "95","99","damp",..: 1 1 1 1 1 2 2 2 2 2 ...
 $ v1     : num  5 7 NaN NaN NaN 5 NA NaN NaN NaN ...
 $ v2     : num  55 77 NaN NaN NaN 55 NA NaN NaN NaN ...
 - attr(*, "out.attrs")=List of 2
  ..$ dim     : Named int  5 6
  .. ..- attr(*, "names")= chr  "Group.1" "Group.2"
  ..$ dimnames:List of 2
  .. ..$ Group.1: chr  "Group.1=1" "Group.1=2" "Group.1=big" "Group.1=blue" ...
  .. ..$ Group.2: chr  "Group.2=95" "Group.2=99" "Group.2=damp" "Group.2=dry" ..
.
> str(aggregate(x = testDF, by = list(by1, by2), FUN = "mean"))
'data.frame':   8 obs. of  4 variables:
 $ Group.1: chr  "1" "2" "1" "2" ...
 $ Group.2: chr  "95" "95" "99" "99" ...
 $ v1     : num  5 7 5 NA 3 3 4 1
 $ v2     : num  55 77 55 NA 33 33 44 11

The result of 'aggregate.data.frame' with drop=FALSE has attribute "out.attrs"; the result of default 'aggregate.data.frame' (drop=TRUE) doesn't.
Character grouping variable becomes a factor in the result of 'aggregate.data.frame' with drop=FALSE; stays as character in the result of default 'aggregate.data.frame' (drop=TRUE).

Example 2, modified from "Compute the averages according to region and the occurrence of more than 130 days of frost" in "Examples" in R help on 'aggregate':
> aggregate(state.x77,
+           list(Region = state.region,
+                Cold = state.x77[,"Frost"] > 130),
+           mean, drop = FALSE)
         Region  Cold Population   Income Illiteracy Life Exp    Murder
1     Northeast FALSE  8802.8000 4780.400  1.1800000 71.12800  5.580000
2         South FALSE  4208.1250 4011.938  1.7375000 69.70625 10.581250
3 North Central FALSE  7233.8333 4633.333  0.7833333 70.95667  8.283333
4          West FALSE  4582.5714 4550.143  1.2571429 71.70000  6.828571
5     Northeast  TRUE  1360.5000 4307.500  0.7750000 71.43500  3.650000
6         South  TRUE        NaN      NaN        NaN      NaN       NaN
7 North Central  TRUE  2372.1667 4588.833  0.6166667 72.57667  2.266667
8          West  TRUE   970.1667 4880.500  0.7500000 70.69167  7.666667
   HS Grad    Frost      Area
1 52.06000 110.6000  21838.60
2 44.34375  64.6250  54605.12
3 53.36667 120.0000  56736.50
4 60.11429  51.0000  91863.71
5 56.35000 160.5000  13519.00
6      NaN      NaN       NaN
7 55.66667 157.6667  68567.50
8 64.20000 161.8333 184162.17
> aggregate(state.x77,
+           list(Region = state.region,
+                Cold = state.x77[,"Frost"] > 130),
+           mean)
         Region  Cold Population   Income Illiteracy Life Exp    Murder
1     Northeast FALSE  8802.8000 4780.400  1.1800000 71.12800  5.580000
2         South FALSE  4208.1250 4011.938  1.7375000 69.70625 10.581250
3 North Central FALSE  7233.8333 4633.333  0.7833333 70.95667  8.283333
4          West FALSE  4582.5714 4550.143  1.2571429 71.70000  6.828571
5     Northeast  TRUE  1360.5000 4307.500  0.7750000 71.43500  3.650000
6 North Central  TRUE  2372.1667 4588.833  0.6166667 72.57667  2.266667
7          West  TRUE   970.1667 4880.500  0.7500000 70.69167  7.666667
   HS Grad    Frost      Area
1 52.06000 110.6000  21838.60
2 44.34375  64.6250  54605.12
3 53.36667 120.0000  56736.50
4 60.11429  51.0000  91863.71
5 56.35000 160.5000  13519.00
6 55.66667 157.6667  68567.50
7 64.20000 161.8333 184162.17

Unlike 'tapply', in 'aggregate.data.frame' with drop=FALSE, the function (mean in example 2 above) is also applied to subset corresponding to combination of grouping variables that doesn't appear in the data.

Example 3, modified from http://stackoverflow.com/questions/22523131/dplyr-summarise-equivalent-of-drop-false-to-keep-groups-with-zero-length-in :
> DF <- data.frame(a=rep(1:3,4), b=factor(rep(1:2,6), levels=1:3))
> aggregate(DF["a"], DF["b"], length, drop=FALSE)
  b a
1 1 6
2 2 6

Unlike 'interaction' with drop=FALSE, or 'tapply', for factor grouping variable, levels that never appear in the data (in example 3 above, "3" in 'b') don't appear in the result of 'aggregate.data.frame' with drop=FALSE.


From amitmukh2 at gmail.com  Sat May 14 08:53:05 2016
From: amitmukh2 at gmail.com (Amitava Mukherjee)
Date: Sat, 14 May 2016 12:23:05 +0530
Subject: [R] R 3.3.0 Crashing: Error in readRDS(nsInfoFilePath) : unknown
	input format
Message-ID: <CALWkyWu=OTkdSjrRmqvrborfdMcpV5cc_sWQc+fjwDocYdGoOg@mail.gmail.com>

Dear All,

Greetings. I hope you will be able to provide kind help with the following:

I am facing a strange problem ever since I have started working with R
3.3.0.

I download and work with it, it was fine. Then when I shut down and reopen,
it is not working properly.

I am getting following message:

Error in readRDS(nsInfoFilePath) : unknown input format

R version 3.3.0 (2016-05-03) -- "Supposedly Educational"
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

Warning message:
package "methods" in options("defaultPackages") was not found
[Previously saved workspace restored]

Error in readRDS(nsInfoFilePath) : unknown input format
During startup - Warning message:
package ?methods? in options("defaultPackages") was not found
> ?mean
Error in readRDS(nsInfoFilePath) : unknown input format
>


I have uninstall it three times and reinstall -- Every time after first
installation it is working perfectly.

Then when I am closing R window and reopening it, the problem starts.

Kindly suggest what should I do. Looking forward to hear from you,

Best regards,
Amitava





Dr. Amitava Mukherjee, Ph.D.
Associate Professor,
Production, Operations and Decision Sciences Area,
XLRI-Xavier School of Management, India.

	[[alternative HTML version deleted]]


From mike at hsm.org.uk  Sat May 14 10:18:07 2016
From: mike at hsm.org.uk (Mike Smith)
Date: Sat, 14 May 2016 09:18:07 +0100
Subject: [R] Plot trajectories using ggplot?
Message-ID: <156819244.20160514091807@hsm.org.uk>

Hi

Ive got stuck using the code below to try to plot trajectories - columns are data recorded at time points, rows are cases. Ive used melt to turn the data long allowing me to group by time point and then plot using geom_point but I now need to join the points based upon the correct case (i.e. the first row in the original dataset). geo_segment allows me to specify start-end but I need to do this over multiple time periods....

Any help much appreciated

thanks

mike


library(reshape2)
library(ggplot2)
library(ggthemes)
library(cowplot)

#Read raw data
df = read.table("http://www.lecturematerials.co.uk/data/sample.csv", header=TRUE, sep=",", dec=".", na.strings=c("NA"))
names(df)<-c("1","2","3","4")

#Turn data from wide to long
ds<-melt(df)

ggplot(ds, aes(x = variable, y = value)) +
       geom_point (shape=19, size=5, fill="black")



---
Mike Smith


From massimo.bressan at arpa.veneto.it  Sat May 14 10:44:54 2016
From: massimo.bressan at arpa.veneto.it (Massimo Bressan)
Date: Sat, 14 May 2016 10:44:54 +0200 (CEST)
Subject: [R] apply formula over columns by subset of rows in a dataframe
 (to get a new dataframe)
In-Reply-To: <CAF8bMcYL+jOx4VA6cZmaU-spFOZ9cJ4UCscT_jv-2rWT_txUcA@mail.gmail.com>
References: <1274186074.11911782.1463140539471.JavaMail.zimbra@arpa.veneto.it>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D732474@mb02.ads.tamu.edu>
	<2059033841.11937030.1463150695746.JavaMail.zimbra@arpa.veneto.it>
	<CAF8bMcYL+jOx4VA6cZmaU-spFOZ9cJ4UCscT_jv-2rWT_txUcA@mail.gmail.com>
Message-ID: <326636511.11957426.1463215494976.JavaMail.zimbra@arpa.veneto.it>

thank you, what a nice compact solution with ave() 

I learned something new about the subtleties of R 

let me here summarize the alternative solutions, just in case someonelse might be interested... 

thanks, bye 

# 

# my user function (an example) 
mynorm <- function(x) {(x - min(x, na.rm=TRUE))/(max(x, na.rm=TRUE) - min(x, na.rm=TRUE))} 

# my dataframe to apply the formula by blocks 
mydf<-data.frame(blocks=rep(c("a","b","c"),each=5), v1=round(runif(15,10,25),0), v2=round(rnorm(15,30,5),0)) 

# blocks (factors) to be used for splitting 
b <- mydf$blocks 

# 1 - split-lapply-unsplit with anonimous function to return a new df 
s <- split(mydf, b) 
l<- lapply(s, function(x) data.frame(x, v1mod=mynorm(x$v1))) 
mydf_new <- unsplit(l, mydf$blocks) 

# 2 - split-lapply-unsplit with function trasnform to return a new df 
l <- split(mydf, b) 
l <- lapply(l, transform, v1.mod = mynorm(v1)) 
mydf_new <- unsplit(l, b) 

# 3 - ave() encapsulating split-lapply-unsplit approach 
mydf_new<-transform(mydf, v1.mod = ave(v1, blocks, FUN=mynorm)) 

# 





Da: "William Dunlap" <wdunlap at tibco.com> 
A: "Massimo Bressan" <massimo.bressan at arpa.veneto.it> 
Cc: "David L Carlson" <dcarlson at tamu.edu>, "r-help" <r-help at r-project.org> 
Inviato: Venerd?, 13 maggio 2016 19:22:21 
Oggetto: Re: [R] apply formula over columns by subset of rows in a dataframe (to get a new dataframe) 

ave() encapsulates the split/lapply/unsplit stuff so 
transform(mydf, v1.mod = ave(v1, blocks, FUN=mynorm)) 
also gives what you got above. 

Bill Dunlap 
TIBCO Software 
wdunlap tibco.com 

On Fri, May 13, 2016 at 7:44 AM, Massimo Bressan < massimo.bressan at arpa.veneto.it > wrote: 


yes, thanks 

you pointed me in the right direction: split/unplist was the trick 

I completely left behind that possibility! 

here the final version 

############ 

mynorm <- function(x) {(x - min(x, na.rm=TRUE))/(max(x, na.rm=TRUE) - min(x, na.rm=TRUE))} 

mydf<-data.frame(blocks=rep(c("a","b","c"),each=5), v1=round(runif(15,10,25),0), v2=round(rnorm(15,30,5),0)) 

g <- mydf$blocks 
l <- split(mydf, g) 
l <- lapply(l, transform, v1.mod = mynorm(v1)) 
mydf_new <- unsplit(l, g) 

############ 

thanks again 

massimo 

______________________________________________ 
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
and provide commented, minimal, self-contained, reproducible code. 





-- 

------------------------------------------------------------ 
Massimo Bressan 

ARPAV 
Agenzia Regionale per la Prevenzione e 
Protezione Ambientale del Veneto 

Dipartimento Provinciale di Treviso 
Via Santa Barbara, 5/a 
31100 Treviso, Italy 

tel: +39 0422 558545 
fax: +39 0422 558516 
e-mail: massimo.bressan at arpa.veneto.it 
------------------------------------------------------------ 

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Sat May 14 11:13:15 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Sat, 14 May 2016 09:13:15 +0000
Subject: [R] Plot trajectories using ggplot?
In-Reply-To: <156819244.20160514091807@hsm.org.uk>
References: <156819244.20160514091807@hsm.org.uk>
Message-ID: <CAKVAULP2OAjDEOcQZOcAEhFdymDbJk6Ty1YaDMsqtwuerMQCCw@mail.gmail.com>

You can introduce the row number as a  case number, you can group by case
and plot the connecting lines

#Read raw data
df = read.table("http://www.lecturematerials.co.uk/data/sample.csv",
header=TRUE, sep=",", dec=".", na.strings=c("NA"))
names(df)<-c("1","2","3","4")
df$case <- rownames(df)

#Turn data from wide to long
ds<-melt(df, id.vars = "case")

ggplot(ds, aes(x = variable, y = value, group = case)) +
  geom_point () + geom_line()

Hope this helps,
Ulrik

On Sat, 14 May 2016 at 10:20 Mike Smith <mike at hsm.org.uk> wrote:

> Hi
>
> Ive got stuck using the code below to try to plot trajectories - columns
> are data recorded at time points, rows are cases. Ive used melt to turn the
> data long allowing me to group by time point and then plot using geom_point
> but I now need to join the points based upon the correct case (i.e. the
> first row in the original dataset). geo_segment allows me to specify
> start-end but I need to do this over multiple time periods....
>
> Any help much appreciated
>
> thanks
>
> mike
>
>
> library(reshape2)
> library(ggplot2)
> library(ggthemes)
> library(cowplot)
>
> #Read raw data
> df = read.table("http://www.lecturematerials.co.uk/data/sample.csv",
> header=TRUE, sep=",", dec=".", na.strings=c("NA"))
> names(df)<-c("1","2","3","4")
>
> #Turn data from wide to long
> ds<-melt(df)
>
> ggplot(ds, aes(x = variable, y = value)) +
>        geom_point (shape=19, size=5, fill="black")
>
>
>
> ---
> Mike Smith
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From fisher at plessthan.com  Sat May 14 17:46:39 2016
From: fisher at plessthan.com (Fisher Dennis)
Date: Sat, 14 May 2016 08:46:39 -0700
Subject: [R] Accessing objects manipulated in a function
Message-ID: <B89A8021-90BD-41EF-A2EA-6D42EF8BBE27@plessthan.com>

R 3.2.4
OS X and Windows

Colleagues,

I distribute some code to co-workers and I am trying to simplify their task.  The issue is as follows:

1.  The code automates an extensive set of processes.  Many of the steps are standardized.  However, some of the steps may require that users write snippets of code, stored in R scripts.

2.  If users write their own code, it might appear in files named UserCode1.R, UserCode2.R, etc..  The master code checks for the existence of this code, then executes
	source(?/path/to/UserCode1.R?)
This can occur at many different points in the master code (each time sourcing a different file).  
In addition to the command above, there are a variety of other commands testing whether the file exists and whether it contains certain commands that I don?t allow the user to execute.
In order to simplify the code, these commands are embedded in a function (which I will call MODIFYCODE for the moment).

3.  Assume that an object within the master code is named TEMP.  The user might add a column to TEMP.  Since this occurs within a function, there are two ways to get this modification back to the original environment:
	a.  within the function:	TEMP	<<- TEMP
	b.  use the return value from the function:
		TEMP	<-   MODIFYCODE()

4.  There are disadvantages to each of these:
	a.  The user needs to know that the ?<<-? command must be invoked.  If they don?t do so, the changes within the function are not available in the master environment
	b.  I don?t know what code will be written by the user, i.e., they might manipulate TEMP or they might create a new object or something else.  So, I don?t know a priori what to return.

So, my question is: is there some way to manipulate environments such that the changes within the function are AUTOMATICALLY transferred to the environment outside the function?

Dennis

Dennis Fisher MD
P < (The "P Less Than" Company)
Phone / Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com <http://www.plessthan.com/>





	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat May 14 18:45:42 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 14 May 2016 09:45:42 -0700
Subject: [R] Accessing objects manipulated in a function
In-Reply-To: <B89A8021-90BD-41EF-A2EA-6D42EF8BBE27@plessthan.com>
References: <B89A8021-90BD-41EF-A2EA-6D42EF8BBE27@plessthan.com>
Message-ID: <alpine.BSF.2.00.1605140920230.79844@pedal.dcn.davis.ca.us>

I think you have boxed yourself into a corner, much like someone painting 
the floor and failing to work their way toward an exit.

The whole premise that you will call "unknown code" that does "unknown 
things" that change the global environment is a maintenance disaster. Give 
up on at least one of these requirements.

Think of the "lm" function. It returns a list of related results, 
augmented with a "class" attribute so that methods like "print.lm" and 
"summary.lm" will work. The actions performed need not be reviewed in 
detail if the user knows what to do with the returned object. The "class" 
attribute is a bit of syntactic sugar, but the concept of putting your 
results into a list that the caller doesn't have to mix items in with 
their own is critical.

Using <<- has to be handled in a very controlled manner... wonton (as in 
"users will change my variables this way") use of that operator will 
inevitably lead to surprises and puzzlement later.

I also happen to think that standardizing on calling "source" inside 
functions is a big mistake... the functions defined by the user should be 
setup and handed off to your "master architecture" code as parameters or 
elements within lists that are parameters.

On Sat, 14 May 2016, Fisher Dennis wrote:

> R 3.2.4
> OS X and Windows
>
> Colleagues,
>
> I distribute some code to co-workers and I am trying to simplify their task.  The issue is as follows:
>
> 1.  The code automates an extensive set of processes.  Many of the steps are standardized.  However, some of the steps may require that users write snippets of code, stored in R scripts.
>
> 2.  If users write their own code, it might appear in files named UserCode1.R, UserCode2.R, etc..  The master code checks for the existence of this code, then executes
> 	source(?/path/to/UserCode1.R?)
> This can occur at many different points in the master code (each time sourcing a different file). 
> In addition to the command above, there are a variety of other commands testing whether the file exists and whether it contains certain commands that I don?t allow the user to execute.
> In order to simplify the code, these commands are embedded in a function (which I will call MODIFYCODE for the moment).
>
> 3.  Assume that an object within the master code is named TEMP.  The user might add a column to TEMP.  Since this occurs within a function, there are two ways to get this modification back to the original environment:
> 	a.  within the function:	TEMP	<<- TEMP
> 	b.  use the return value from the function:
> 		TEMP	<-   MODIFYCODE()
>
> 4.  There are disadvantages to each of these:
> 	a.  The user needs to know that the ?<<-? command must be invoked.  If they don?t do so, the changes within the function are not available in the master environment
> 	b.  I don?t know what code will be written by the user, i.e., they might manipulate TEMP or they might create a new object or something else.  So, I don?t know a priori what to return.
>
> So, my question is: is there some way to manipulate environments such that the changes within the function are AUTOMATICALLY transferred to the environment outside the function?
>
> Dennis
>
> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone / Fax: 1-866-PLessThan (1-866-753-7784)
> www.PLessThan.com <http://www.plessthan.com/>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From mike at hsm.org.uk  Sat May 14 19:29:05 2016
From: mike at hsm.org.uk (Mike Smith)
Date: Sat, 14 May 2016 18:29:05 +0100
Subject: [R] Plot trajectories using ggplot?
In-Reply-To: <CAKVAULP2OAjDEOcQZOcAEhFdymDbJk6Ty1YaDMsqtwuerMQCCw@mail.gmail.com>
References: <156819244.20160514091807@hsm.org.uk> 
	<CAKVAULP2OAjDEOcQZOcAEhFdymDbJk6Ty1YaDMsqtwuerMQCCw@mail.gmail.com>
Message-ID: <775711876.20160514182905@hsm.org.uk>

Thanks very much for the pointer - that was spot on. The key thing was to add

df$case <- rownames(df)

to generate the row by row case for when I melted the columns. As Ive since found out either of these will work

ggplot(ds, aes(x = as.numeric(variable), y = value, colour = case)) +
  geom_point () + geom_line()

ggplot(ds, aes(x = variable, y = value, group = case)) +
  geom_point () + geom_line()

Much appreciated!

Saturday, May 14, 2016, 10:13:15 AM, you wrote:

US> You can introduce the row number as a  case number, you can group
US> by case and plot the connecting lines


US> #Read raw data
US> df =
US> read.table("http://www.lecturematerials.co.uk/data/sample.csv",
US> header=TRUE, sep=",", dec=".", na.strings=c("NA"))
US> names(df)<-c("1","2","3","4")
US> df$case <- rownames(df)


US> #Turn data from wide to long
US> ds<-melt(df, id.vars = "case")


US> ggplot(ds, aes(x = variable, y = value, group = case)) +
US>   geom_point () + geom_line()


US> Hope this helps,
US> Ulrik
US> On Sat, 14 May 2016 at 10:20 Mike Smith <mike at hsm.org.uk> wrote:

US> Hi
US>  
US>  Ive got stuck using the code below to try to plot trajectories -
US> columns are data recorded at time points, rows are cases. Ive used
US> melt to turn the data long allowing me to group by time point and
US> then plot using geom_point but I now need to join the points based
US> upon the correct case (i.e. the first row in the original
US> dataset). geo_segment allows me to specify start-end but I need to
US> do this over multiple time periods....
US>  
US>  Any help much appreciated
US>  
US>  thanks
US>  
US>  mike
US>  
US>  
US>  library(reshape2)
US>  library(ggplot2)
US>  library(ggthemes)
US>  library(cowplot)
US>  
US>  #Read raw data
US>  df =
US> read.table("http://www.lecturematerials.co.uk/data/sample.csv",
US> header=TRUE, sep=",", dec=".", na.strings=c("NA"))
US>  names(df)<-c("1","2","3","4")
US>  
US>  #Turn data from wide to long
US>  ds<-melt(df)
US>  
US>  ggplot(ds, aes(x = variable, y = value)) +
US>         geom_point (shape=19, size=5, fill="black")
US>  
US>  
US>  
US>  ---
US>  Mike Smith
US>  
US>  ______________________________________________
US>  R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
US>  https://stat.ethz.ch/mailman/listinfo/r-help
US>  PLEASE do read the posting guide
US> http://www.R-project.org/posting-guide.html
US>  and provide commented, minimal, self-contained, reproducible code.
US>  


---
Mike Smith


From fisher at plessthan.com  Sat May 14 20:06:30 2016
From: fisher at plessthan.com (Dennis Fisher)
Date: Sat, 14 May 2016 11:06:30 -0700
Subject: [R] Accessing objects manipulated in a function
In-Reply-To: <alpine.BSF.2.00.1605140920230.79844@pedal.dcn.davis.ca.us>
References: <B89A8021-90BD-41EF-A2EA-6D42EF8BBE27@plessthan.com>
	<alpine.BSF.2.00.1605140920230.79844@pedal.dcn.davis.ca.us>
Message-ID: <6EAECA34-A9D0-4D1B-87D5-6C8021F0F070@plessthan.com>

Jeff

Thanks for your insights.  I suspected that this was the case but I was hoping for a work-around.  Regardless, I have modified the code so that the source() command is no longer in a function ? all the pre- and post-commands are now in two functions, executed before and after the source command.  Problem solved.

Dennis

Dennis Fisher MD
P < (The "P Less Than" Company)
Phone / Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com




> On May 14, 2016, at 9:45 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> I think you have boxed yourself into a corner, much like someone painting the floor and failing to work their way toward an exit.
> 
> The whole premise that you will call "unknown code" that does "unknown things" that change the global environment is a maintenance disaster. Give up on at least one of these requirements.
> 
> Think of the "lm" function. It returns a list of related results, augmented with a "class" attribute so that methods like "print.lm" and "summary.lm" will work. The actions performed need not be reviewed in detail if the user knows what to do with the returned object. The "class" attribute is a bit of syntactic sugar, but the concept of putting your results into a list that the caller doesn't have to mix items in with their own is critical.
> 
> Using <<- has to be handled in a very controlled manner... wonton (as in "users will change my variables this way") use of that operator will inevitably lead to surprises and puzzlement later.
> 
> I also happen to think that standardizing on calling "source" inside functions is a big mistake... the functions defined by the user should be setup and handed off to your "master architecture" code as parameters or elements within lists that are parameters.
> 
> On Sat, 14 May 2016, Fisher Dennis wrote:
> 
>> R 3.2.4
>> OS X and Windows
>> 
>> Colleagues,
>> 
>> I distribute some code to co-workers and I am trying to simplify their task.  The issue is as follows:
>> 
>> 1.  The code automates an extensive set of processes.  Many of the steps are standardized.  However, some of the steps may require that users write snippets of code, stored in R scripts.
>> 
>> 2.  If users write their own code, it might appear in files named UserCode1.R, UserCode2.R, etc..  The master code checks for the existence of this code, then executes
>> 	source(?/path/to/UserCode1.R?)
>> This can occur at many different points in the master code (each time sourcing a different file). In addition to the command above, there are a variety of other commands testing whether the file exists and whether it contains certain commands that I don?t allow the user to execute.
>> In order to simplify the code, these commands are embedded in a function (which I will call MODIFYCODE for the moment).
>> 
>> 3.  Assume that an object within the master code is named TEMP.  The user might add a column to TEMP.  Since this occurs within a function, there are two ways to get this modification back to the original environment:
>> 	a.  within the function:	TEMP	<<- TEMP
>> 	b.  use the return value from the function:
>> 		TEMP	<-   MODIFYCODE()
>> 
>> 4.  There are disadvantages to each of these:
>> 	a.  The user needs to know that the ?<<-? command must be invoked.  If they don?t do so, the changes within the function are not available in the master environment
>> 	b.  I don?t know what code will be written by the user, i.e., they might manipulate TEMP or they might create a new object or something else.  So, I don?t know a priori what to return.
>> 
>> So, my question is: is there some way to manipulate environments such that the changes within the function are AUTOMATICALLY transferred to the environment outside the function?
>> 
>> Dennis
>> 
>> Dennis Fisher MD
>> P < (The "P Less Than" Company)
>> Phone / Fax: 1-866-PLessThan (1-866-753-7784)
>> www.PLessThan.com <http://www.plessthan.com/>
>> 
>> 
>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------


From bgunter.4567 at gmail.com  Sat May 14 21:39:30 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 14 May 2016 12:39:30 -0700
Subject: [R] Accessing objects manipulated in a function
In-Reply-To: <alpine.BSF.2.00.1605140920230.79844@pedal.dcn.davis.ca.us>
References: <B89A8021-90BD-41EF-A2EA-6D42EF8BBE27@plessthan.com>
	<alpine.BSF.2.00.1605140920230.79844@pedal.dcn.davis.ca.us>
Message-ID: <CAGxFJbTA_iJe7V2=L4i5Z_wO3p4hJUsEp5z3MAkYNkwjv68DQw@mail.gmail.com>

"... wonton (as in "users will change my variables this way") use of
that operator will inevitably lead to surprises and puzzlement later.
"

Is this related to the myriad of choices in a Chinese menu? ;-)

(The spelling is "wanton" -- ah the joys of English!)


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, May 14, 2016 at 9:45 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> I think you have boxed yourself into a corner, much like someone painting
> the floor and failing to work their way toward an exit.
>
> The whole premise that you will call "unknown code" that does "unknown
> things" that change the global environment is a maintenance disaster. Give
> up on at least one of these requirements.
>
> Think of the "lm" function. It returns a list of related results, augmented
> with a "class" attribute so that methods like "print.lm" and "summary.lm"
> will work. The actions performed need not be reviewed in detail if the user
> knows what to do with the returned object. The "class" attribute is a bit of
> syntactic sugar, but the concept of putting your results into a list that
> the caller doesn't have to mix items in with their own is critical.
>
> Using <<- has to be handled in a very controlled manner... wonton (as in
> "users will change my variables this way") use of that operator will
> inevitably lead to surprises and puzzlement later.
>
> I also happen to think that standardizing on calling "source" inside
> functions is a big mistake... the functions defined by the user should be
> setup and handed off to your "master architecture" code as parameters or
> elements within lists that are parameters.
>
> On Sat, 14 May 2016, Fisher Dennis wrote:
>
>> R 3.2.4
>> OS X and Windows
>>
>> Colleagues,
>>
>> I distribute some code to co-workers and I am trying to simplify their
>> task.  The issue is as follows:
>>
>> 1.  The code automates an extensive set of processes.  Many of the steps
>> are standardized.  However, some of the steps may require that users write
>> snippets of code, stored in R scripts.
>>
>> 2.  If users write their own code, it might appear in files named
>> UserCode1.R, UserCode2.R, etc..  The master code checks for the existence of
>> this code, then executes
>>         source(?/path/to/UserCode1.R?)
>> This can occur at many different points in the master code (each time
>> sourcing a different file). In addition to the command above, there are a
>> variety of other commands testing whether the file exists and whether it
>> contains certain commands that I don?t allow the user to execute.
>> In order to simplify the code, these commands are embedded in a function
>> (which I will call MODIFYCODE for the moment).
>>
>> 3.  Assume that an object within the master code is named TEMP.  The user
>> might add a column to TEMP.  Since this occurs within a function, there are
>> two ways to get this modification back to the original environment:
>>         a.  within the function:        TEMP    <<- TEMP
>>         b.  use the return value from the function:
>>                 TEMP    <-   MODIFYCODE()
>>
>> 4.  There are disadvantages to each of these:
>>         a.  The user needs to know that the ?<<-? command must be invoked.
>> If they don?t do so, the changes within the function are not available in
>> the master environment
>>         b.  I don?t know what code will be written by the user, i.e., they
>> might manipulate TEMP or they might create a new object or something else.
>> So, I don?t know a priori what to return.
>>
>> So, my question is: is there some way to manipulate environments such that
>> the changes within the function are AUTOMATICALLY transferred to the
>> environment outside the function?
>>
>> Dennis
>>
>> Dennis Fisher MD
>> P < (The "P Less Than" Company)
>> Phone / Fax: 1-866-PLessThan (1-866-753-7784)
>> www.PLessThan.com <http://www.plessthan.com/>
>>
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From klebyn at yahoo.com.br  Sun May 15 00:27:30 2016
From: klebyn at yahoo.com.br (Cleber N.Borges)
Date: Sat, 14 May 2016 19:27:30 -0300
Subject: [R] help with use of the Linear Programming - constrOptim
Message-ID: <356ef8cc-2994-9ab4-3fda-1a7157dee9c5@yahoo.com.br>

Dears,
I imagine that the LP method should be the solution to find the
parameters of one objective function ...
I known there are the constrOptim command for this.

but I don't know how to elaborate the contour condictions  in matricial
forms
that the way like constrOptim works

I show below one function example to be optimized

I appreciate much if somebody can help me
responding if I really am right imagining LP like ideal tool in my case
and indicate basic material (introduction) about the subject

below

Thanks in advanced

Cleber Borges

#####################
fobjective <- function( x = 0.1 ){
# Constants
k1 <- 0.007585776
k2 <- 6.16595e-08
k3 <- 2.137962e-13
k4 <- 1e-14
# Determine all the 6 variables:
# a, b, c, d, e, f
###################
# 6 Contour Condictions: ( Igualities )
###################
k1 == a * d / c            # 1
k2 == a * e / d            # 2
k3 == a * f / e            # 3
k4 == a * b                # 4
4 * a == b + d + e + f    # 5
x     == c + d + e + f    # 6
return( c( a, b, c, d, e, f ) )
}











---
Este email foi escaneado pelo Avast antiv?rus.
https://www.avast.com/antivirus

	[[alternative HTML version deleted]]


From jonathanreardon at outlook.com  Sun May 15 21:06:15 2016
From: jonathanreardon at outlook.com (Jonathan Reardon)
Date: Sun, 15 May 2016 20:06:15 +0100
Subject: [R] 2x2x2 rm ANOVA, varying results
Message-ID: <DUB125-W67F7E1B0E4DE1B927A3899A4760@phx.gbl>

Hello,

I ran a 2x2x2 repeated measures ANOVA which turned out fine:
                                     Df                Sum Sq       Mean Sq   F value     Pr(>F)  Attend                        1                   0.5540      0.55402     7.0374    0.01079 *PercGrp                      1                   0.0058      0.00580     0.0737    0.78719  Pres                             1                   0.1794      0.17944     2.2794    0.13766  Attend:PercGrp         1                   0.0017      0.00172     0.0218    0.88324  Attend:Pres                 1                 0.0189      0.01894    0.2406      0.62598  PercGrp:Pres              1                  0.0534      0.05344    0.6789     0.41405  Attend:PercGrp:Pres  1                 0.0046     0.00464    0.0590      0.80912  Residuals                      48                3.7788  0.07872    
However, when I run the interactions alone (from the same dataset), I get a different set of results than what was originally shown e.g.
> anova(lm(main~Attend+PercGrp+Pres))Analysis of Variance Table
Response: main                  Df       Sum Sq    Mean Sq    F value      Pr(>F)   Attend     1        0.5540       0.55402    7.4682     0.008561 **PercGrp   1       0.0058        0.00580    0.0782     0.780849   Pres         1        0.1794        0.17944    2.4189     0.125942   Residuals 52     3.8575        0.07418  
I also get different results when i run the interactions alone too. Curious to know why this is.
Thanks,Jon




 		 	   		  
	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Sun May 15 22:52:52 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 15 May 2016 22:52:52 +0200
Subject: [R] 2x2x2 rm ANOVA, varying results
In-Reply-To: <DUB125-W67F7E1B0E4DE1B927A3899A4760@phx.gbl>
References: <DUB125-W67F7E1B0E4DE1B927A3899A4760@phx.gbl>
Message-ID: <37AF4E27-8107-416A-97CA-FBDEB8088CB8@gmail.com>

Sorry, but this is close to unreadable. Please retry, and not in HTML this time. 

However AFAICT, the only difference between the two sets of results (re. main effects present in both) is that the residual df differs, hence so does F and p-value.

-pd


> On 15 May 2016, at 21:06 , Jonathan Reardon <jonathanreardon at outlook.com> wrote:
> 
> Hello,
> 
> I ran a 2x2x2 repeated measures ANOVA which turned out fine:
>                                     Df                Sum Sq       Mean Sq   F value     Pr(>F)  Attend                        1                   0.5540      0.55402     7.0374    0.01079 *PercGrp                      1                   0.0058      0.00580     0.0737    0.78719  Pres                             1                   0.1794      0.17944     2.2794    0.13766  Attend:PercGrp         1                   0.0017      0.00172     0.0218    0.88324  Attend:Pres                 1                 0.0189      0.01894    0.2406      0.62598  PercGrp:Pres              1                  0.0534      0.05344    0.6789     0.41405  Attend:PercGrp:Pres  1                 0.0046     0.00464    0.0590      0.80912  Residuals                      48                3.7788  0.07872    
> However, when I run the interactions alone (from the same dataset), I get a different set of results than what was originally shown e.g.
>> anova(lm(main~Attend+PercGrp+Pres))Analysis of Variance Table
> Response: main                  Df       Sum Sq    Mean Sq    F value      Pr(>F)   Attend     1        0.5540       0.55402    7.4682     0.008561 **PercGrp   1       0.0058        0.00580    0.0782     0.780849   Pres         1        0.1794        0.17944    2.4189     0.125942   Residuals 52     3.8575        0.07418  
> I also get different results when i run the interactions alone too. Curious to know why this is.
> Thanks,Jon
> 
> 
> 
> 
> 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jdnewmil at dcn.davis.ca.us  Mon May 16 00:27:40 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 15 May 2016 15:27:40 -0700
Subject: [R] help with use of the Linear Programming - constrOptim
In-Reply-To: <356ef8cc-2994-9ab4-3fda-1a7157dee9c5@yahoo.com.br>
References: <356ef8cc-2994-9ab4-3fda-1a7157dee9c5@yahoo.com.br>
Message-ID: <B08F648E-3545-457D-8EDA-4E48BD4A33F4@dcn.davis.ca.us>

You have an overactive imagination... these equations are nonlinear. 
-- 
Sent from my phone. Please excuse my brevity.

On May 14, 2016 3:27:30 PM PDT, "Cleber N.Borges" <klebyn at yahoo.com.br> wrote:
>Dears,
>I imagine that the LP method should be the solution to find the
>parameters of one objective function ...
>I known there are the constrOptim command for this.
>
>but I don't know how to elaborate the contour condictions  in matricial
>forms
>that the way like constrOptim works
>
>I show below one function example to be optimized
>
>I appreciate much if somebody can help me
>responding if I really am right imagining LP like ideal tool in my case
>and indicate basic material (introduction) about the subject
>
>below
>
>Thanks in advanced
>
>Cleber Borges
>
>#####################
>fobjective <- function( x = 0.1 ){
># Constants
>k1 <- 0.007585776
>k2 <- 6.16595e-08
>k3 <- 2.137962e-13
>k4 <- 1e-14
># Determine all the 6 variables:
># a, b, c, d, e, f
>###################
># 6 Contour Condictions: ( Igualities )
>###################
>k1 == a * d / c            # 1
>k2 == a * e / d            # 2
>k3 == a * f / e            # 3
>k4 == a * b                # 4
>4 * a == b + d + e + f    # 5
>x     == c + d + e + f    # 6
>return( c( a, b, c, d, e, f ) )
>}
>
>
>
>
>
>
>
>
>
>
>
>---
>Este email foi escaneado pelo Avast antiv?rus.
>https://www.avast.com/antivirus
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From highstat at highstat.com  Mon May 16 08:50:39 2016
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Mon, 16 May 2016 07:50:39 +0100
Subject: [R] Adelaide course: Introduction to mixed modelling
Message-ID: <c5f1d9a9-7078-e016-1786-be27a77a3400@highstat.com>

We would like to announce the following statistics course:

Course: Introduction to Linear Mixed Effects Models and GLMM with R. 
Frequentist and Bayesian approaches.
Where:  University of Adelaide, Adelaide, Australia
When:   20-24 June 2016

Course website: http://www.highstat.com/statscourse.htm
Course flyer: 
http://highstat.com/Courses/Flyers/Flyer2016_06Adelaide_GLMM_V2.pdf

Kind regards,

Alain Zuur


-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


	[[alternative HTML version deleted]]


From carlosbautistaleon at gmail.com  Mon May 16 12:25:23 2016
From: carlosbautistaleon at gmail.com (=?UTF-8?Q?Carlos_Bautista_Le=C3=B3n?=)
Date: Mon, 16 May 2016 12:25:23 +0200
Subject: [R] clm function in ordinal package: "Hessian is numerically
	singular"
Message-ID: <CALTLwxCSpkOWJC7YNE7we6iv-6kUcAtf24v6B_H+rd+_42SnNA@mail.gmail.com>

Dear list,

I'm modeling ordinal data using the clm function from the ordinal package
in R. For that I have 4 variables, 2 ordinal and 2 continuous (O1, O2, C1,
C2).

O1 <- c(2,2,1,2,2,1,3,2,2,3,3,2,1,3,2,2,2)
O2 <- c(2,2,3,2,2,1,2,2,2,1,1,2,3,2,2,2,2)
C1 <- C(49,25,1000,19,61,700,25,375,35,46,105,437,3300,31,203,34,800)
C2 <- c(25350,25050,14925,25050,14325,16300,26425,22250,22250,44650,44650,21400,30125,25350,25050,14325,17525)
data <- data.frame (O1, O2, C1, C2)
data <- within(data, {
O1 <- factor ((O1), ordered =TRUE,
              levels = c("1", "2", "3"))
O2 <- factor ((O2), ordered =TRUE,
              levels = c("1", "2", "3"))})

In a first step I want to model O1 as response variable and O2, C1 and C2
as predictors (3 different models) and second, use O2 as response and O1,
C1 and C2 as predictors (another 3 different models).

m1 <- clm(O1 ~ O2, data = data)
m2 <- clm(O1 ~ C1, data = data)
m3 <- clm(O1 ~ log(C2), data = data)
m4 <- clm(O2 ~ O1, data = data)
m5 <- clm(O2 ~ C1, data = data)
m6 <- clm(O2 ~ log(C2), data = data)

As you can see all models run without problem except for the first one (m1)
which gives as a warning message:

(1) Hessian is numerically singular: parameters are not uniquely determined
In addition: Absolute convergence criterion was met, but relative criterion
was not met

and do not report any standard error or wald z test.

I do not have this problem when simulating data

 data$x1 <- sample(c(1,2,3), 17, replace = TRUE)

What confuses me is that, unlike with m1 (O1 ~ O2), the model which uses O2
as response and O1 as predictor works perfectly fine. In addition I have
tried replacing some values in O1 and it happened that when substituting 1
by 2 or 3 I do not get any warning message and I obtain all the
coefficients of the model.

I made some research and it seems and this can be due to low representation
of certain values in the response, as well as to a small sample size. Is
that right or can it be a bug? Can someone help me please?

Thanks a lot!
Carlos Bautista

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Mon May 16 12:48:15 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Mon, 16 May 2016 11:48:15 +0100
Subject: [R] clm function in ordinal package: "Hessian is numerically
 singular"
In-Reply-To: <CALTLwxCSpkOWJC7YNE7we6iv-6kUcAtf24v6B_H+rd+_42SnNA@mail.gmail.com>
References: <CALTLwxCSpkOWJC7YNE7we6iv-6kUcAtf24v6B_H+rd+_42SnNA@mail.gmail.com>
Message-ID: <a5c8d9cd-b836-b0cc-f244-1cc730a10472@dewey.myzen.co.uk>

Dear Carlos

I think the issue is that you have some zeroes.

 > table(O1, O2)
    O2
O1   1  2  3
   1  1  0  2
   2  0 10  0
   3  2  2  0
 >

Note that when you predict O1 from O2 level 3 of O2 gives a perfect 
prediction.

When you predict O2 from O1 level 2 gives a perfect prediction but I 
think you are saved here because the order constraint means that only 
zeroes at the extreme categories are fatal.

Try experimenting with zeroes in different places, perhaps using more 
levels with artificial data and see what happens and if I am right. 
Warning, I may be wrong.

On 16/05/2016 11:25, Carlos Bautista Le?n wrote:
> Dear list,
>
> I'm modeling ordinal data using the clm function from the ordinal package
> in R. For that I have 4 variables, 2 ordinal and 2 continuous (O1, O2, C1,
> C2).
>
> O1 <- c(2,2,1,2,2,1,3,2,2,3,3,2,1,3,2,2,2)
> O2 <- c(2,2,3,2,2,1,2,2,2,1,1,2,3,2,2,2,2)
> C1 <- C(49,25,1000,19,61,700,25,375,35,46,105,437,3300,31,203,34,800)
> C2 <- c(25350,25050,14925,25050,14325,16300,26425,22250,22250,44650,44650,21400,30125,25350,25050,14325,17525)
> data <- data.frame (O1, O2, C1, C2)
> data <- within(data, {
> O1 <- factor ((O1), ordered =TRUE,
>               levels = c("1", "2", "3"))
> O2 <- factor ((O2), ordered =TRUE,
>               levels = c("1", "2", "3"))})
>
> In a first step I want to model O1 as response variable and O2, C1 and C2
> as predictors (3 different models) and second, use O2 as response and O1,
> C1 and C2 as predictors (another 3 different models).
>
> m1 <- clm(O1 ~ O2, data = data)
> m2 <- clm(O1 ~ C1, data = data)
> m3 <- clm(O1 ~ log(C2), data = data)
> m4 <- clm(O2 ~ O1, data = data)
> m5 <- clm(O2 ~ C1, data = data)
> m6 <- clm(O2 ~ log(C2), data = data)
>
> As you can see all models run without problem except for the first one (m1)
> which gives as a warning message:
>
> (1) Hessian is numerically singular: parameters are not uniquely determined
> In addition: Absolute convergence criterion was met, but relative criterion
> was not met
>
> and do not report any standard error or wald z test.
>
> I do not have this problem when simulating data
>
>  data$x1 <- sample(c(1,2,3), 17, replace = TRUE)
>
> What confuses me is that, unlike with m1 (O1 ~ O2), the model which uses O2
> as response and O1 as predictor works perfectly fine. In addition I have
> tried replacing some values in O1 and it happened that when substituting 1
> by 2 or 3 I do not get any warning message and I obtain all the
> coefficients of the model.
>
> I made some research and it seems and this can be due to low representation
> of certain values in the response, as well as to a small sample size. Is
> that right or can it be a bug? Can someone help me please?
>
> Thanks a lot!
> Carlos Bautista
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From chalabi.elahe at yahoo.de  Mon May 16 14:31:06 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Mon, 16 May 2016 12:31:06 +0000 (UTC)
Subject: [R] mean for every quartile
References: <1944625760.4735063.1463401866904.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1944625760.4735063.1463401866904.JavaMail.yahoo@mail.yahoo.com>

Hi all,
I have a column in my df and I want to get quartiles for this column and then calculate mean for each and every quartile, here is my column:


    df$BR 
    [1] 384 384 384 384 512 384 384 320 320 320 320 320 320 320 320 320 320 384 
    [19] 384 384 320 320 320 320 384 384 256 320 320 320 384 320 320 320 384 384 
    [37] 320 320 320 320 320 320 320 320 320 384 320 320 320 320 320 320 384 320 
    [55] 320 320 320 320 320 320 384 512 320 320 320 320 320 320 320 384 384 320 
    [73] 320 320 384 320 320 320 320 256 320 320 384 320 384 320 384 320 320 320 
    [91] 384 320 320 320 320 320 320 320 320 320 320 320 

I do the following to get the quartiles:

    
    quantile(m$BR) 
    0%  25%  50%  75% 100% 
    256  320  320  368  512

now how can I get mean for each quartile?
Thnaks for any help,
Elahe


From lists at dewey.myzen.co.uk  Mon May 16 15:29:39 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Mon, 16 May 2016 14:29:39 +0100
Subject: [R] mean for every quartile
In-Reply-To: <1944625760.4735063.1463401866904.JavaMail.yahoo@mail.yahoo.com>
References: <1944625760.4735063.1463401866904.JavaMail.yahoo.ref@mail.yahoo.com>
	<1944625760.4735063.1463401866904.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <62494ee7-4474-1d20-a49e-f401c63ea7a5@dewey.myzen.co.uk>

Dear Elahe

In line

On 16/05/2016 13:31, ch.elahe via R-help wrote:
> Hi all,
> I have a column in my df and I want to get quartiles for this column and then calculate mean for each and every quartile, here is my column:
>

The quartiles are strictly speaking the boundaries but if you really 
meant that the problem is trivial so i assume you want to cut the 
variable at the quartiles.

>
>     df$BR
>     [1] 384 384 384 384 512 384 384 320 320 320 320 320 320 320 320 320 320 384
>     [19] 384 384 320 320 320 320 384 384 256 320 320 320 384 320 320 320 384 384
>     [37] 320 320 320 320 320 320 320 320 320 384 320 320 320 320 320 320 384 320
>     [55] 320 320 320 320 320 320 384 512 320 320 320 320 320 320 320 384 384 320
>     [73] 320 320 384 320 320 320 320 256 320 320 384 320 384 320 384 320 320 320
>     [91] 384 320 320 320 320 320 320 320 320 320 320 320
>
> I do the following to get the quartiles:
>
>
>     quantile(m$BR)
>     0%  25%  50%  75% 100%
>     256  320  320  368  512
>
> now how can I get mean for each quartile?

How about setting up a vector which takes the values 1, 2, 3, 4 
depending on the values of BR with cutpoints defined by 
quantile(BR)(using ifelse) and then using tapply?

> Thnaks for any help,
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From ulrik.stervbo at gmail.com  Mon May 16 15:41:10 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Mon, 16 May 2016 13:41:10 +0000
Subject: [R] mean for every quartile
In-Reply-To: <62494ee7-4474-1d20-a49e-f401c63ea7a5@dewey.myzen.co.uk>
References: <1944625760.4735063.1463401866904.JavaMail.yahoo.ref@mail.yahoo.com>
	<1944625760.4735063.1463401866904.JavaMail.yahoo@mail.yahoo.com>
	<62494ee7-4474-1d20-a49e-f401c63ea7a5@dewey.myzen.co.uk>
Message-ID: <CAKVAULMu8i9TKcv7fgZJ23ox-eo5zuBnaX7Xyk+LabBULqWEXQ@mail.gmail.com>

Hi Elahe,

you can create a matrix of ranges and loop over each row:

m <- c(384, 384, 384, 384, 512, 384, 384, 320, 320, 320, 320, 320, 320,
320, 320, 320, 320, 384,
384, 384, 320, 320, 320, 320, 384, 384, 256, 320, 320, 320, 384, 320, 320,
320, 384, 384,
320, 320, 320, 320, 320, 320, 320, 320, 320, 384, 320, 320, 320, 320, 320,
320, 384, 320,
320, 320, 320, 320, 320, 320, 384, 512, 320, 320, 320, 320, 320, 320, 320,
384, 384, 320,
320, 320, 384, 320, 320, 320, 320, 256, 320, 320, 384, 320, 384, 320, 384,
320, 320, 320,
384, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320)

qm <- quantile(m)

q.ranges <- matrix(c(0, qm[1:(length(qm) - 1)], qm), ncol = 2)

apply(q.ranges, MARGIN = 1, function(cr){
  mean(m[m > cr[1] & m <= cr[2]])
})

Hope this helps
Ulrik

On Mon, 16 May 2016 at 15:32 Michael Dewey <lists at dewey.myzen.co.uk> wrote:

> Dear Elahe
>
> In line
>
> On 16/05/2016 13:31, ch.elahe via R-help wrote:
> > Hi all,
> > I have a column in my df and I want to get quartiles for this column and
> then calculate mean for each and every quartile, here is my column:
> >
>
> The quartiles are strictly speaking the boundaries but if you really
> meant that the problem is trivial so i assume you want to cut the
> variable at the quartiles.
>
> >
> >     df$BR
> >     [1] 384 384 384 384 512 384 384 320 320 320 320 320 320 320 320 320
> 320 384
> >     [19] 384 384 320 320 320 320 384 384 256 320 320 320 384 320 320 320
> 384 384
> >     [37] 320 320 320 320 320 320 320 320 320 384 320 320 320 320 320 320
> 384 320
> >     [55] 320 320 320 320 320 320 384 512 320 320 320 320 320 320 320 384
> 384 320
> >     [73] 320 320 384 320 320 320 320 256 320 320 384 320 384 320 384 320
> 320 320
> >     [91] 384 320 320 320 320 320 320 320 320 320 320 320
> >
> > I do the following to get the quartiles:
> >
> >
> >     quantile(m$BR)
> >     0%  25%  50%  75% 100%
> >     256  320  320  368  512
> >
> > now how can I get mean for each quartile?
>
> How about setting up a vector which takes the values 1, 2, 3, 4
> depending on the values of BR with cutpoints defined by
> quantile(BR)(using ifelse) and then using tapply?
>
> > Thnaks for any help,
> > Elahe
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From chalabi.elahe at yahoo.de  Mon May 16 15:46:06 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Mon, 16 May 2016 13:46:06 +0000 (UTC)
Subject: [R] mean for every quartile
In-Reply-To: <62494ee7-4474-1d20-a49e-f401c63ea7a5@dewey.myzen.co.uk>
References: <1944625760.4735063.1463401866904.JavaMail.yahoo.ref@mail.yahoo.com>
	<1944625760.4735063.1463401866904.JavaMail.yahoo@mail.yahoo.com>
	<62494ee7-4474-1d20-a49e-f401c63ea7a5@dewey.myzen.co.uk>
Message-ID: <2037386161.4974253.1463406366945.JavaMail.yahoo@mail.yahoo.com>

Thnaks for your reply,

By using tapply I get this result:

    
    tapply(df$BR, findInterval(df$BR, quantile(df$BR)), mean) 
    1   3   4   5 
    256 320 384 512

But I think this is not true,cause I have to get 5 means but here I get four numbers!




On Monday, May 16, 2016 6:29 AM, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
Dear Elahe

In line

On 16/05/2016 13:31, ch.elahe via R-help wrote:
> Hi all,
> I have a column in my df and I want to get quartiles for this column and then calculate mean for each and every quartile, here is my column:
>

The quartiles are strictly speaking the boundaries but if you really 
meant that the problem is trivial so i assume you want to cut the 
variable at the quartiles.

>
>     df$BR
>     [1] 384 384 384 384 512 384 384 320 320 320 320 320 320 320 320 320 320 384
>     [19] 384 384 320 320 320 320 384 384 256 320 320 320 384 320 320 320 384 384
>     [37] 320 320 320 320 320 320 320 320 320 384 320 320 320 320 320 320 384 320
>     [55] 320 320 320 320 320 320 384 512 320 320 320 320 320 320 320 384 384 320
>     [73] 320 320 384 320 320 320 320 256 320 320 384 320 384 320 384 320 320 320
>     [91] 384 320 320 320 320 320 320 320 320 320 320 320
>
> I do the following to get the quartiles:
>
>
>     quantile(m$BR)
>     0%  25%  50%  75% 100%
>     256  320  320  368  512
>
> now how can I get mean for each quartile?

How about setting up a vector which takes the values 1, 2, 3, 4 
depending on the values of BR with cutpoints defined by 
quantile(BR)(using ifelse) and then using tapply?


> Thnaks for any help,
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From dcarlson at tamu.edu  Mon May 16 16:07:02 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 16 May 2016 14:07:02 +0000
Subject: [R] mean for every quartile
In-Reply-To: <2037386161.4974253.1463406366945.JavaMail.yahoo@mail.yahoo.com>
References: <1944625760.4735063.1463401866904.JavaMail.yahoo.ref@mail.yahoo.com>
	<1944625760.4735063.1463401866904.JavaMail.yahoo@mail.yahoo.com>
	<62494ee7-4474-1d20-a49e-f401c63ea7a5@dewey.myzen.co.uk>
	<2037386161.4974253.1463406366945.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D7329FB@mb02.ads.tamu.edu>

Do you understand that quartiles divide the data into 4 groups?

Min (group 1) 1st quartile (group 2) median (group3) 3rd quartile (group4) max

But in your case df$BR has only 4 unique values:

> table(df$BR)

256 320 384 512 
  2  74  24   2

So the first quartile is equal to the median:

> quantile(df$BR)
  0%  25%  50%  75% 100% 
 256  320  320  368  512

You need to use the argument rightmost.closed=TRUE with findInterval(). If you do not, the 5th group consists of only those values that are equal to the maximum:

> df$quant <- findInterval(df$BR, quantile(df$BR), rightmost.closed=TRUE)
> tapply(df$BR, df$quant, mean)
       1        3        4 
256.0000 320.0000 393.8462

Using values that are more variable:

> set.seed(42)
> df <- data.frame(BR=sample.int(100, 100, replace=TRUE))
> df$quant <- findInterval(df$BR, quantile(df$BR), rightmost.closed=TRUE)
> tapply(df$BR, df$quant, mean)
    1     2     3     4 
12.48 41.24 67.24 90.64

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of ch.elahe via R-help
Sent: Monday, May 16, 2016 8:46 AM
To: Michael Dewey; ulrik.stervbo at gmail.com
Cc: R-help Mailing List
Subject: Re: [R] mean for every quartile

Thnaks for your reply,

By using tapply I get this result:

    
    tapply(df$BR, findInterval(df$BR, quantile(df$BR)), mean) 
    1   3   4   5 
    256 320 384 512

But I think this is not true,cause I have to get 5 means but here I get four numbers!




On Monday, May 16, 2016 6:29 AM, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
Dear Elahe

In line

On 16/05/2016 13:31, ch.elahe via R-help wrote:
> Hi all,
> I have a column in my df and I want to get quartiles for this column and then calculate mean for each and every quartile, here is my column:
>

The quartiles are strictly speaking the boundaries but if you really 
meant that the problem is trivial so i assume you want to cut the 
variable at the quartiles.

>
>     df$BR
>     [1] 384 384 384 384 512 384 384 320 320 320 320 320 320 320 320 320 320 384
>     [19] 384 384 320 320 320 320 384 384 256 320 320 320 384 320 320 320 384 384
>     [37] 320 320 320 320 320 320 320 320 320 384 320 320 320 320 320 320 384 320
>     [55] 320 320 320 320 320 320 384 512 320 320 320 320 320 320 320 384 384 320
>     [73] 320 320 384 320 320 320 320 256 320 320 384 320 384 320 384 320 320 320
>     [91] 384 320 320 320 320 320 320 320 320 320 320 320
>
> I do the following to get the quartiles:
>
>
>     quantile(m$BR)
>     0%  25%  50%  75% 100%
>     256  320  320  368  512
>
> now how can I get mean for each quartile?

How about setting up a vector which takes the values 1, 2, 3, 4 
depending on the values of BR with cutpoints defined by 
quantile(BR)(using ifelse) and then using tapply?


> Thnaks for any help,
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From faliyev2001 at yahoo.com  Mon May 16 16:08:40 2016
From: faliyev2001 at yahoo.com (Fuzuli Aliyev)
Date: Mon, 16 May 2016 14:08:40 +0000 (UTC)
Subject: [R] MR-STAR
References: <580094847.3242093.1463407720451.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <580094847.3242093.1463407720451.JavaMail.yahoo@mail.yahoo.com>

Dear friends, I apologize to take your time.I used STAR model (LSTAR) at my paper. My residuals suffer from remaining linearity. So I plan to use multiple regime (MR-STAR) model.?Can you please help me if there is library for this type of STAR model and coding example? Thank you
	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon May 16 17:08:45 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 16 May 2016 08:08:45 -0700
Subject: [R] MR-STAR
In-Reply-To: <580094847.3242093.1463407720451.JavaMail.yahoo@mail.yahoo.com>
References: <580094847.3242093.1463407720451.JavaMail.yahoo.ref@mail.yahoo.com>
	<580094847.3242093.1463407720451.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAGxFJbSZqvcYG7d6V3oh1ztfKyjBFX2qVYT9XcYGCWRHdA_2sA@mail.gmail.com>

Please use search facilities before posting here. One such very good
one for R searches is rseek.org. I typed in "STAR models" to its
search bar (I have no idea what they are) and got this, among others:

http://www.r-bloggers.com/twinkletwinkle-little-star-2/

This also came up in a google search on "STAR models R"  .

If your search fails to find hits that meet your needs, please tells
us this and why in your posts so that you may be perhaps guided to
more pertinent resources.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, May 16, 2016 at 7:08 AM, Fuzuli Aliyev via R-help
<r-help at r-project.org> wrote:
> Dear friends, I apologize to take your time.I used STAR model (LSTAR) at my paper. My residuals suffer from remaining linearity. So I plan to use multiple regime (MR-STAR) model. Can you please help me if there is library for this type of STAR model and coding example? Thank you
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Mon May 16 17:38:56 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 16 May 2016 08:38:56 -0700
Subject: [R] R 3.3.0 Crashing: Error in readRDS(nsInfoFilePath) :
	unknown	input format
In-Reply-To: <CALWkyWu=OTkdSjrRmqvrborfdMcpV5cc_sWQc+fjwDocYdGoOg@mail.gmail.com>
References: <CALWkyWu=OTkdSjrRmqvrborfdMcpV5cc_sWQc+fjwDocYdGoOg@mail.gmail.com>
Message-ID: <31A25DE7-1BA5-4277-B366-C31A490E9190@dcn.davis.ca.us>

I don't know why this is happening, but the nsInfo.rds file is part of every installed package (see Section 4.1 of the R Internals documentation) and it sounds like one or more of them are getting corrupted.  This could be because you or your .Rprofile or an .RData file are triggering a bug in one of your packages. 

You might try
* posting the output of the sessionInfo function, 
* looking in your .Rprofile file with a text editor, 
* deleting/renaming any RData files in your working directory,  and perhaps
* clearing/renaming your personal 3.3 package library and re-installing one package at a time to see which one triggers the error. 
-- 
Sent from my phone. Please excuse my brevity.

On May 13, 2016 11:53:05 PM PDT, Amitava Mukherjee <amitmukh2 at gmail.com> wrote:
>Dear All,
>
>Greetings. I hope you will be able to provide kind help with the
>following:
>
>I am facing a strange problem ever since I have started working with R
>3.3.0.
>
>I download and work with it, it was fine. Then when I shut down and
>reopen,
>it is not working properly.
>
>I am getting following message:
>
>Error in readRDS(nsInfoFilePath) : unknown input format
>
>R version 3.3.0 (2016-05-03) -- "Supposedly Educational"
>Copyright (C) 2016 The R Foundation for Statistical Computing
>Platform: x86_64-w64-mingw32/x64 (64-bit)
>
>R is free software and comes with ABSOLUTELY NO WARRANTY.
>You are welcome to redistribute it under certain conditions.
>Type 'license()' or 'licence()' for distribution details.
>
>  Natural language support but running in an English locale
>
>R is a collaborative project with many contributors.
>Type 'contributors()' for more information and
>'citation()' on how to cite R or R packages in publications.
>
>Type 'demo()' for some demos, 'help()' for on-line help, or
>'help.start()' for an HTML browser interface to help.
>Type 'q()' to quit R.
>
>Warning message:
>package "methods" in options("defaultPackages") was not found
>[Previously saved workspace restored]
>
>Error in readRDS(nsInfoFilePath) : unknown input format
>During startup - Warning message:
>package ?methods? in options("defaultPackages") was not found
>> ?mean
>Error in readRDS(nsInfoFilePath) : unknown input format
>>
>
>
>I have uninstall it three times and reinstall -- Every time after first
>installation it is working perfectly.
>
>Then when I am closing R window and reopening it, the problem starts.
>
>Kindly suggest what should I do. Looking forward to hear from you,
>
>Best regards,
>Amitava
>
>
>
>
>
>Dr. Amitava Mukherjee, Ph.D.
>Associate Professor,
>Production, Operations and Decision Sciences Area,
>XLRI-Xavier School of Management, India.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From denis.francisci at gmail.com  Mon May 16 18:10:47 2016
From: denis.francisci at gmail.com (Denis Francisci)
Date: Mon, 16 May 2016 18:10:47 +0200
Subject: [R] problem with matrix
Message-ID: <CAJMcJMD6LvxStVWwh4Kuj_gmy5rd-RBvZmXubYk6nCdw+gRjCQ@mail.gmail.com>

Hi all,
I've a simple question.
I have a matrix with same values over and under the diagonal. That's an
example:
  [,1] [,2]     [,3]
[1,]      NaN   45 63.43495
[2,] 45.00000  NaN 90.00000
[3,] 63.43495   90      NaN
How can I extract just the three values over (or under) the diagonal and
convert them in a  vector like this: 45, 63.43495, 90 ?

Thank's in advance

	[[alternative HTML version deleted]]


From iluwinga at yahoo.com  Mon May 16 17:54:41 2016
From: iluwinga at yahoo.com (Isaac Singini)
Date: Mon, 16 May 2016 17:54:41 +0200
Subject: [R] Error when running a basic joint model
Message-ID: <98DA5508-040B-40EF-BCE7-75D7EE1BAB67@yahoo.com>

Dear All
I have the following two datasets for joint modeling the survival and longitudinal data. However when I run the joint model I get the following error. I am new to R, may someone assist

Error in `[.data.frame`(lmeObject$data, all.vars(TermsX)) :  undefined columns selected

Data structure  for the longitudinal analysis is: 
str(cd4long)
'data.frame':	464 obs. of  6 variables:
 $ id1       : int  1011555 1011555 1011555 1011555 1011558 1011558 1011558 1011558 1011568 1011568 ...
 $ week      : int  2 4 6 12 2 4 6 12 2 4 ...
 $ cd4countwk: int  241 137 325 283 235 219 634 465 111 316 ...
 $ pred      : Factor w/ 2 levels "Placebo","Prednisolone": 2 2 2 2 2 2 2 2 2 2 ...
 $ outcome   : int  0 0 0 0 0 0 0 0 0 0 ...
 $ surv4     : int  1137 1137 1137 1137 1097 1097 1097 1097 1129 1129 ..

Data structure  for the survival analysis is as 
'data.frame':	116 obs. of  6 variables:
 $ id1       : int  1011555 1011558 1011568 1011575 1011577 1011581 1011592 1011957 1011961 1011964 ...
 $ week      : int  0 0 0 0 0 0 0 0 0 0 ...
 $ cd4countwk: int  241 235 111 68 146 516 150 64 13 220 ...
 $ outcome   : int  0 0 0 0 0 0 0 0 0 0 ...
 $ surv4     : int  1137 1097 1129 1099 634 1137 1100 729 731 736 ...
 $ pred      : int  1 1 1 0 1 1 0 1 0 0 ?


Thanks
Isaac

From sarah.goslee at gmail.com  Mon May 16 18:23:50 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 16 May 2016 12:23:50 -0400
Subject: [R] problem with matrix
In-Reply-To: <CAJMcJMD6LvxStVWwh4Kuj_gmy5rd-RBvZmXubYk6nCdw+gRjCQ@mail.gmail.com>
References: <CAJMcJMD6LvxStVWwh4Kuj_gmy5rd-RBvZmXubYk6nCdw+gRjCQ@mail.gmail.com>
Message-ID: <CAM_vju=3xpyS4mm3JnWVHoy2nQN8jsGZ6pR+ozD7+4=Q-p_O4A@mail.gmail.com>

How about:

> mymat <- matrix(c(NA, 45, 63, 45, NA, 90, 63, 90, NA), byrow=TRUE, nrow=3)
> mymat
     [,1] [,2] [,3]
[1,]   NA   45   63
[2,]   45   NA   90
[3,]   63   90   NA
> mymat[row(mymat) < col(mymat)]
[1] 45 63 90


On Mon, May 16, 2016 at 12:10 PM, Denis Francisci <denis.francisci at gmail.com
> wrote:

> Hi all,
> I've a simple question.
> I have a matrix with same values over and under the diagonal. That's an
> example:
>   [,1] [,2]     [,3]
> [1,]      NaN   45 63.43495
> [2,] 45.00000  NaN 90.00000
> [3,] 63.43495   90      NaN
> How can I extract just the three values over (or under) the diagonal and
> convert them in a  vector like this: 45, 63.43495, 90 ?
>
> Thank's in advance
>
>

	[[alternative HTML version deleted]]


From rmh at temple.edu  Mon May 16 18:23:48 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Mon, 16 May 2016 12:23:48 -0400
Subject: [R] problem with matrix
In-Reply-To: <CAJMcJMD6LvxStVWwh4Kuj_gmy5rd-RBvZmXubYk6nCdw+gRjCQ@mail.gmail.com>
References: <CAJMcJMD6LvxStVWwh4Kuj_gmy5rd-RBvZmXubYk6nCdw+gRjCQ@mail.gmail.com>
Message-ID: <CAGx1TMCBNSuh7-1XWsX1Qg-a9YYV+ATq+rBCzMkt+n0GWRaQ-w@mail.gmail.com>

?lower.tri

> tmp <- matrix(scan(text="     NaN   45 63.43495
+ 45.00000  NaN 90.00000
+ 63.43495   90      NaN"), 3, 3)
Read 9 items
> tmp
         [,1] [,2]     [,3]
[1,]      NaN   45 63.43495
[2,] 45.00000  NaN 90.00000
[3,] 63.43495   90      NaN
> lower.tri(tmp)
      [,1]  [,2]  [,3]
[1,] FALSE FALSE FALSE
[2,]  TRUE FALSE FALSE
[3,]  TRUE  TRUE FALSE
> tmp[lower.tri(tmp)]
[1] 45.00000 63.43495 90.00000

On Mon, May 16, 2016 at 12:10 PM, Denis Francisci
<denis.francisci at gmail.com> wrote:
> Hi all,
> I've a simple question.
> I have a matrix with same values over and under the diagonal. That's an
> example:
>   [,1] [,2]     [,3]
> [1,]      NaN   45 63.43495
> [2,] 45.00000  NaN 90.00000
> [3,] 63.43495   90      NaN
> How can I extract just the three values over (or under) the diagonal and
> convert them in a  vector like this: 45, 63.43495, 90 ?
>
> Thank's in advance
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Mon May 16 18:25:00 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 16 May 2016 12:25:00 -0400
Subject: [R] problem with matrix
In-Reply-To: <CAJMcJMD6LvxStVWwh4Kuj_gmy5rd-RBvZmXubYk6nCdw+gRjCQ@mail.gmail.com>
References: <CAJMcJMD6LvxStVWwh4Kuj_gmy5rd-RBvZmXubYk6nCdw+gRjCQ@mail.gmail.com>
Message-ID: <5739F45C.3010404@gmail.com>

On 16/05/2016 12:10 PM, Denis Francisci wrote:
> Hi all,
> I've a simple question.
> I have a matrix with same values over and under the diagonal. That's an
> example:
>    [,1] [,2]     [,3]
> [1,]      NaN   45 63.43495
> [2,] 45.00000  NaN 90.00000
> [3,] 63.43495   90      NaN
> How can I extract just the three values over (or under) the diagonal and
> convert them in a  vector like this: 45, 63.43495, 90 ?
>
> Thank's in advance
>

See ?upper.tri.

Duncan Murdoch


From denis.francisci at gmail.com  Mon May 16 18:30:16 2016
From: denis.francisci at gmail.com (Denis Francisci)
Date: Mon, 16 May 2016 18:30:16 +0200
Subject: [R] problem with matrix
In-Reply-To: <5739F45C.3010404@gmail.com>
References: <CAJMcJMD6LvxStVWwh4Kuj_gmy5rd-RBvZmXubYk6nCdw+gRjCQ@mail.gmail.com>
	<5739F45C.3010404@gmail.com>
Message-ID: <CAJMcJMBcnVRyZmOqmdPtFPg_EeitDPdHUxWY_Obf9yGAfYFpdw@mail.gmail.com>

Thank you very much,
just what I needed!!

2016-05-16 18:25 GMT+02:00 Duncan Murdoch <murdoch.duncan at gmail.com>:

> On 16/05/2016 12:10 PM, Denis Francisci wrote:
>
>> Hi all,
>> I've a simple question.
>> I have a matrix with same values over and under the diagonal. That's an
>> example:
>>    [,1] [,2]     [,3]
>> [1,]      NaN   45 63.43495
>> [2,] 45.00000  NaN 90.00000
>> [3,] 63.43495   90      NaN
>> How can I extract just the three values over (or under) the diagonal and
>> convert them in a  vector like this: 45, 63.43495, 90 ?
>>
>> Thank's in advance
>>
>>
> See ?upper.tri.
>
> Duncan Murdoch
>

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Mon May 16 18:39:29 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Mon, 16 May 2016 17:39:29 +0100
Subject: [R] problem with matrix
In-Reply-To: <CAJMcJMD6LvxStVWwh4Kuj_gmy5rd-RBvZmXubYk6nCdw+gRjCQ@mail.gmail.com>
Message-ID: <20160516173929.Horde._gw-zHkMdQET4Co0s8C8FN4@mail.sapo.pt>

Hello,

See the help page for ?lower.tri.
If your matrix is named 'x', something like

x[upper.tri(x)]

Hope this helps,

Rui Barradas
?

Citando Denis Francisci <denis.francisci at gmail.com>:

> Hi all,
> I've a simple question.
> I have a matrix with same values over and under the diagonal. That's an
> example:
> [,1] [,2]? ? ?[,3]
> [1,]? ? ? NaN? ?45 63.43495
> [2,] 45.00000? NaN 90.00000
> [3,] 63.43495? ?90? ? ? NaN
> How can I extract just the three values over (or under) the diagonal and
> convert them in a? vector like this: 45, 63.43495, 90 ?
>
> Thank's in advance
>
> ? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide  
> http://www.R-project.org/posting-guide.htmland provide commented,  
> minimal, self-contained, reproducible code.

?

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon May 16 18:52:17 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 16 May 2016 09:52:17 -0700
Subject: [R] Error when running a basic joint model
In-Reply-To: <98DA5508-040B-40EF-BCE7-75D7EE1BAB67@yahoo.com>
References: <98DA5508-040B-40EF-BCE7-75D7EE1BAB67@yahoo.com>
Message-ID: <CAGxFJbSJ6EsrMdo8d_7GDn79HecYp8TUswE_no2sqJMPGE9dgg@mail.gmail.com>

Suggestion: When new, seek out and follow guides -- in this case, the
posting guide (below), which asks that you post your code that failed.
In this case, an obvious guess is that you have mis-specified or maybe
misspelled one or more of your modeling variables in the call, but
without the code, one can't tell.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, May 16, 2016 at 8:54 AM, Isaac Singini via R-help
<r-help at r-project.org> wrote:
> Dear All
> I have the following two datasets for joint modeling the survival and longitudinal data. However when I run the joint model I get the following error. I am new to R, may someone assist
>
> Error in `[.data.frame`(lmeObject$data, all.vars(TermsX)) :  undefined columns selected
>
> Data structure  for the longitudinal analysis is:
> str(cd4long)
> 'data.frame':   464 obs. of  6 variables:
>  $ id1       : int  1011555 1011555 1011555 1011555 1011558 1011558 1011558 1011558 1011568 1011568 ...
>  $ week      : int  2 4 6 12 2 4 6 12 2 4 ...
>  $ cd4countwk: int  241 137 325 283 235 219 634 465 111 316 ...
>  $ pred      : Factor w/ 2 levels "Placebo","Prednisolone": 2 2 2 2 2 2 2 2 2 2 ...
>  $ outcome   : int  0 0 0 0 0 0 0 0 0 0 ...
>  $ surv4     : int  1137 1137 1137 1137 1097 1097 1097 1097 1129 1129 ..
>
> Data structure  for the survival analysis is as
> 'data.frame':   116 obs. of  6 variables:
>  $ id1       : int  1011555 1011558 1011568 1011575 1011577 1011581 1011592 1011957 1011961 1011964 ...
>  $ week      : int  0 0 0 0 0 0 0 0 0 0 ...
>  $ cd4countwk: int  241 235 111 68 146 516 150 64 13 220 ...
>  $ outcome   : int  0 0 0 0 0 0 0 0 0 0 ...
>  $ surv4     : int  1137 1097 1129 1099 634 1137 1100 729 731 736 ...
>  $ pred      : int  1 1 1 0 1 1 0 1 0 0 ?
>
>
> Thanks
> Isaac
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mario.lavezzi at unipa.it  Mon May 16 18:53:56 2016
From: mario.lavezzi at unipa.it (A M Lavezzi)
Date: Mon, 16 May 2016 17:53:56 +0100
Subject: [R] building a spatial matrix
In-Reply-To: <CAM_vju=CtoOn9a3tb5U407no7t5E7tXgPxbvHEbDwihODbTJdA@mail.gmail.com>
References: <CAOZPQW7DOicT9pS8H2BA3gxnJLg0wYTu9UhinwpgywcSDGoKFw@mail.gmail.com>
	<CAM_vjuk8hVY6F67behO+YQ1R5gSxb5xTxQgysSwZmigmPoQXow@mail.gmail.com>
	<CAOZPQW4zO7EaF3KTaDGgBStoycEvyMyKJFz1MwCRjMUk7zfDug@mail.gmail.com>
	<CAOZPQW6kGycyZ-a1-nZVu1_YjFtDb+qLcgcxvjiE-vS=6O5wZQ@mail.gmail.com>
	<CAM_vju=CtoOn9a3tb5U407no7t5E7tXgPxbvHEbDwihODbTJdA@mail.gmail.com>
Message-ID: <CAOZPQW6tKx=3E4Mkefbo04c9vmV=JFo-QEtGo2cVLWVanziTWw@mail.gmail.com>

Hi Sarah,
thanks a lot. In this line:

result.m[cbind(factor(result$f_cell), factor(result$f_cell_neigh))] <-
result$distance

I had a problem with cbind(factor .. : the assignement to the [i,j] element
of the matrix did not work.

I solved in this manner:

- I modified censDist, so for every couple of location codes (f_cell,
f_cell_neigh), I added the corresponding id from id_cell (they are directly
interpretable as the coordinates of the 1327x1327 result.m matrix). So
censDist looks like this:

head(censDist)
   f_cell f_cell_neigh  distance id id_neigh
1   2924         2732 1309.7525 NA       NA
2   2924         2875  696.2891 NA       NA
3   2924         2351 1346.0561 NA      975
4   2924         2350 1296.9804 NA      758
5   2924         2725 1278.1877 NA       NA
6   2924         2721 1346.9126 NA       NA

Then I run your code with a slight modification of the last row:

resultS <- subset(censDist, f_cell %in% id_cell$f_cell & f_cell_neigh %in%
id_cell$f_cell)
resultS.m <- matrix(NA, nrow=nrow(id_cell), ncol=nrow(id_cell))
resultS.m[cbind(resultS$id, resultS$id_neigh)] <- resultS$distance

and it worked!

thank you so much,
Mario


On Fri, May 13, 2016 at 5:45 PM, Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> Sorry, you're right.
>
> The result line should be:
>
> result.m[cbind(factor(result$fcell), factor(result$cellneigh))]  <-
> result$distance
>
>
> idcell <- data.frame(
>   id = seq_len(5),
>   fcell = sample(1:100, 5))
>
> censDist <- expand.grid(fcell=seq_len(100), cellneigh=seq_len(100))
> censDist$distance <- runif(nrow(censDist))
>
> # assemble the non-symmetric distance matrix
> result <- subset(censDist, fcell %in% idcell$fcell & cellneigh %in%
> idcell$fcell)
> result.m <- matrix(NA, nrow=nrow(idcell), ncol=nrow(idcell))
> result.m[cbind(factor(result$fcell), factor(result$cellneigh))]  <-
> result$distance
>
> It's just about instantaneous on the dataset you sent me:
>
>
> system.time({
> result <- subset(censDist, f_cell %in% id_cell$f_cell & f_cell_neigh %in%
> id_cell$f_cell)
> result.m <- matrix(NA, nrow=nrow(id_cell), ncol=nrow(id_cell))
> result.m[cbind(factor(result$f_cell), factor(result$f_cell_neigh))] <-
> result$distance
> })
>
>   user  system elapsed
>   0.361   0.007   0.368
>
>
>
>
> Sarah
>
>
> On Fri, May 13, 2016 at 10:36 AM, A M Lavezzi <mario.lavezzi at unipa.it>
> wrote:
> > PLEASE IGNORE THE PREVIOUS EMAIL, IT WAS SENT BY MISTAKE
> >
> > Hello Sarah
> > thanks a lot for your advice.
> >
> > I followed your suggestions unitil the creation of "result"
> >
> > The allocation of the values of result$distance to the matrix result.m,
> > however ,does not seem to work: it produces a matrix with identical
> columns
> > corresponding to the last values of result$distance. Maybe my
> description of
> > the dataset was not clear enough.
> >
> > I produced the final matrix spat_dist with a loop, that I report below
> (it
> > takes about 1 hour on my macbook pro),
> >
> > set_i = -1   # create a variable to store the i values already examined
> >
> > for(i in unique(result$id)){
> >
> >   set_i=c(set_i,i) # store the value of the i
> >
> >   set_neigh = result$id_neigh[result$id==i & !result$id_neigh %in%
> set_i] #
> > identify the locations connected to i. If the distance between i and j
> was
> > examined before, don't look for the distance between j and i
> >
> >   for(j in set_neigh){
> >     if(i!=j){
> >       spat_dist[i,j] = result$distance[result$id==i &
>  result$id_neigh==j]
> >       spat_dist[j,i] = spat_dist[i,j]
> >     }
> >     else{
> >       spat_dist[i,j]=0
> >     }
> >   }
> > }
> >
> > It is not the most elegant and efficient solution in the world, that's
> for
> > sure.
> >
> > I would be grateful, if you could suggest an alternative instruction to:
> >
> > result.m[factor(result$fcell), factor(result$cellneigh)] <-
> result$distance
> >
> > so I will learn a faster procedure (I tried many times but to modify this
> > structure but I did not make it). I don't want to abuse of your time, so
> > forget it if you are busy
> >
> > Thank you so much anyway,
> > Mario
> >
> > ps I attach the data. Notice that the 1327 units in id_cell are firms,
> > indexed by id, located in location f_cell. Different firms can be
> located in
> > the same f_cell. With respect to your suggestion, I added two columns to
> > "result" with the id of the firms.
> >
> > On Fri, May 13, 2016 at 3:26 PM, A M Lavezzi <mario.lavezzi at unipa.it>
> wrote:
> >>
> >>
> >> Hello Sarah
> >> thanks a lot for your advice.
> >>
> >> I followed your suggestions unitl the creation of "result"
> >>
> >> The allocation of the values of result$distance to the matrix result.m,
> >> however ,does not seem to work: it produces a matrix with identical
> columns
> >> corresponding to the last values of result$distance. Maybe my
> description of
> >> the dataset was not clear enough.
> >>
> >> I produced the final matrix with a loop, that I report below (it takes
> >> about 1 hour on my macbook pro),
> >>
> >> set_i = -1   # create a variable to store the i values already examined
> >>
> >> for(i in unique(result$id)){
> >>
> >>   set_i=c(set_i,i) # store the value of the i
> >>
> >>   set_neigh = result$id_neigh[result$id==i & !result$id_neigh %in%
> set_i]
> >> # identify the locations connected to i. Exclude                  those
> >>
> >>   for(j in set_neigh){
> >>     if(i!=j){
> >>       spat_dist[i,j] = result$distance[result$id==i &
>  result$id_neigh==j]
> >>       spat_dist[j,i] = spat_dist[i,j]
> >>     }
> >>     else{
> >>       spat_dist[i,j]=0
> >>     }
> >>   }
> >> }
> >>
> >> It not the most elegant and efficient solution in the world, that's for
> >> sure
> >>
> >>
> >>
> >> On Thu, May 12, 2016 at 2:51 PM, Sarah Goslee <sarah.goslee at gmail.com>
> >> wrote:
> >>>
> >>> I don't see any reason why a loop is out of the question, and
> >>> answering would have been much easier if you'd included the requested
> >>> reproducible data, but what about this?
> >>>
> >>> This solution is robust to pairs from idcell being absent in censDist,
> >>> and to the difference from A to B being different than the distance
> >>> from B to A, but not to A-B appearing twice. If that's possible,
> >>> you'll need to figure out how to manage it.
> >>>
> >>> # create some fake data
> >>>
> >>> idcell <- data.frame(
> >>>   id = seq_len(5),
> >>>   fcell = sample(1:100, 5))
> >>>
> >>> censDist <- expand.grid(fcell=seq_len(100), cellneigh=seq_len(100))
> >>> censDist$distance <- runif(nrow(censDist))
> >>>
> >>> # assemble the non-symmetric distance matrix
> >>> result <- subset(censDist, fcell %in% idcell$fcell & cellneigh %in%
> >>> idcell$fcell)
> >>> result.m <- matrix(NA, nrow=nrow(idcell), ncol=nrow(idcell))
> >>> result.m[factor(result$fcell), factor(result$cellneigh)] <-
> >>> result$distance
> >>>
> >>> Sarah
> >>>
> >>> On Thu, May 12, 2016 at 5:26 AM, A M Lavezzi <mario.lavezzi at unipa.it>
> >>> wrote:
> >>> > Hello,
> >>> >
> >>> > I have a sample of 1327  locations, each one idetified by an id and a
> >>> > numerical code.
> >>> >
> >>> > I need to build a spatial matrix, say, M, i.e. a 1327x1327 matrix
> >>> > collecting distances among the locations.
> >>> >
> >>> > M(i,i) should be 0, M(i,j) should contain the distance among
> location i
> >>> > and
> >>> > j
> >>> >
> >>> > I shoud use data organized in the following way:
> >>> >
> >>> > 1) id_cell contains the identifier (id) of each location (1...1327)
> and
> >>> > the
> >>> > numerical code of the location (f_cell) (see head of id_cell below)
> >>> >
> >>> >> head(id_cell)
> >>> >      id  f_cell
> >>> > 1    1   2120
> >>> > 12  2     204
> >>> > 22  3   2546
> >>> > 24  4   1327
> >>> > 34  5   1729
> >>> > 43  6   2293
> >>> >
> >>> > 2) censDist contains, for each location identified by its numerical
> >>> > code,
> >>> > the distance to other locations (censDist has 1.5 million rows). The
> >>> > head(consist) below, for example, reads like this:
> >>> >
> >>> > location 2924 has a distance to 2732 of 1309.7525
> >>> > location 2924 has a distance to 2875 of 696.2891,
> >>> > etc.
> >>> >
> >>> >> head(censDist)
> >>> >   f_cell f  _cell_neigh  distance
> >>> > 1   2924         2732   1309.7525
> >>> > 2   2924         2875     696.2891
> >>> > 3   2924         2351   1346.0561
> >>> > 4   2924         2350   1296.9804
> >>> > 5   2924         2725   1278.1877
> >>> > 6   2924         2721   1346.9126
> >>> >
> >>> >
> >>> > Basically, for every location in  id_cell I should pick up the
> distance
> >>> > to
> >>> > other locations in id_cell from censDist, and allocate it in M
> >>> >
> >>> > I have not come up with a satisfactory vectorizion of this problem
> and
> >>> > using a loop is out of question.
> >>> >
> >>> > Thanks for your help
> >>> > Mario
> >>> >
> >>> >
> >>
>



-- 
Andrea Mario Lavezzi
DiGi,Sezione Diritto e Societ?
Universit? di Palermo
Piazza Bologni 8
90134 Palermo, Italy
tel. ++39 091 23892208
fax ++39 091 6111268
skype: lavezzimario
email: mario.lavezzi (at) unipa.it
web: http://www.unipa.it/~mario.lavezzi

	[[alternative HTML version deleted]]


From iluwinga at yahoo.com  Mon May 16 19:43:57 2016
From: iluwinga at yahoo.com (Isaac Singini)
Date: Mon, 16 May 2016 17:43:57 +0000 (UTC)
Subject: [R] Error when running a basic joint model
References: <1102733061.2853494.1463420637032.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1102733061.2853494.1463420637032.JavaMail.yahoo@mail.yahoo.com>

Thanks Bert,?I will re-check the code and send the accordingly ?as soon as I have access to the laptop
Isaac

Sent from Yahoo Mail on Android 
 
  On Mon, 16 May, 2016 at 6:52 pm, Bert Gunter<bgunter.4567 at gmail.com> wrote:ge?   Suggestion: When new, seek out and follow guides -- in this case, the
posting guide (below), which asks that you post your code that failed.
In this case, an obvious guess is that you have mis-specified or maybe
misspelled one or more of your modeling variables in the call, but
without the code, one can't tell.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, May 16, 2016 at 8:54 AM, Isaac Singini via R-help
<r-help at r-project.org> wrote:
> Dear All
> I have the following two datasets for joint modeling the survival and longitudinal data. However when I run the joint model I get the following error. I am new to R, may someone assist
>
> Error in `[.data.frame`(lmeObject$data, all.vars(TermsX)) :? undefined columns selected
>
> Data structure? for the longitudinal analysis is:
> str(cd4long)
> 'data.frame':? 464 obs. of? 6 variables:
>? $ id1? ? ? : int? 1011555 1011555 1011555 1011555 1011558 1011558 1011558 1011558 1011568 1011568 ...
>? $ week? ? ? : int? 2 4 6 12 2 4 6 12 2 4 ...
>? $ cd4countwk: int? 241 137 325 283 235 219 634 465 111 316 ...
>? $ pred? ? ? : Factor w/ 2 levels "Placebo","Prednisolone": 2 2 2 2 2 2 2 2 2 2 ...
>? $ outcome? : int? 0 0 0 0 0 0 0 0 0 0 ...
>? $ surv4? ? : int? 1137 1137 1137 1137 1097 1097 1097 1097 1129 1129 ..
>
> Data structure? for the survival analysis is as
> 'data.frame':? 116 obs. of? 6 variables:
>? $ id1? ? ? : int? 1011555 1011558 1011568 1011575 1011577 1011581 1011592 1011957 1011961 1011964 ...
>? $ week? ? ? : int? 0 0 0 0 0 0 0 0 0 0 ...
>? $ cd4countwk: int? 241 235 111 68 146 516 150 64 13 220 ...
>? $ outcome? : int? 0 0 0 0 0 0 0 0 0 0 ...
>? $ surv4? ? : int? 1137 1097 1129 1099 634 1137 1100 729 731 736 ...
>? $ pred? ? ? : int? 1 1 1 0 1 1 0 1 0 0 ?
>
>
> Thanks
> Isaac
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.  

	[[alternative HTML version deleted]]


From dosc3612 at colorado.edu  Mon May 16 22:23:01 2016
From: dosc3612 at colorado.edu (Dominik Schneider)
Date: Mon, 16 May 2016 14:23:01 -0600
Subject: [R] physical constraint with gam
In-Reply-To: <5736D2B4.3030305@bath.edu>
References: <CAF1jk_=312-4GEwpeJM2UaOojnSE_6PxLo6YU2ysjGdHKBt3UQ@mail.gmail.com>
	<5732F730.9000800@bath.edu>
	<CAF1jk_=Yk6ruWTyDZ_aZnDTAmSZi6=7eSM5CoL0x=jF=JVqm4w@mail.gmail.com>
	<CAF1jk_k=v1-FhTRRrq54Ry_SixdMsAKV+YKaLZmBNwy6uF77yg@mail.gmail.com>
	<5736D2B4.3030305@bath.edu>
Message-ID: <CAF1jk_mCYSv_M94R_n3kZUf=XB0O_cZPhToVpKW2_FeuNpH_AQ@mail.gmail.com>

Thanks for the clarification!

On Sat, May 14, 2016 at 1:24 AM, Simon Wood <simon.wood at bath.edu> wrote:

> On 12/05/16 02:29, Dominik Schneider wrote:
>
> Hi again,
> I'm looking for some clarification on 2 things.
> 1. On that last note, I realize that s(x1,x2) would be the other obvious
> interaction to compare with - and I see that you recommend te(x1,x2) if
> they are not on the same scale.
>
> - yes that's right, s(x1,x2) gives an isotropic smooth, which is usually
> only appropriate if x1 and x2 are naturally on the same scale.
>
> 2. If s(x1,by=x1) gives you a "parameter" value similar to a GLM when you
> plot s(x1):x1, why does my function above return the same yhat as
> predict(mdl,type='response') ?  Shouldn't each of the terms need to be
> multiplied by the variable value before applying
> rowSums()+attr(sterms,'constant') ??
>
> predict returns s(x1)*x1 (plot.gam just plots s(x1), because in general
> s(x1,by=x2) is not smooth). If you want to get s(x1) on its own you need to
> do something like this:
>
> x2 <- x1 ## copy x1
> m <- gam(y~s(x1,by=x2)) ## model implementing s(x1,by=x1) using copy of x1
> predict(m,data.frame(x1=x1,x2=rep(1,length(x2))),type="terms") ## now
> predicted s(x1)*x2 = s(x1)
>
> best,
> Simon
>
>
> Thanks again
> Dominik
>
> On Wed, May 11, 2016 at 10:11 AM, Dominik Schneider <
> <Dominik.Schneider at colorado.edu>Dominik.Schneider at colorado.edu> wrote:
>
>> Hi Simon, Thanks for this explanation.
>> To make sure I understand, another way of explaining the y axis in my
>> original example is that it is the contribution to snowdepth relative to
>> the other variables (the example only had fsca, but my actual case has a
>> couple others). i.e. a negative s(fsca) of -0.5 simply means snowdepth 0.5
>> units below the intercept+s(x_i), where s(x_i) could also be negative in
>> the case where total snowdepth is less than the intercept value.
>>
>> The use of by=fsca is really useful for interpreting the marginal impact
>> of the different variables. With my actual data, the term s(fsca):fsca is
>> never negative, which is much more intuitive. Is it appropriate to compare
>> magnitudes of e.g. s(x2):x2 / mean(x2) and s(x2):x2 / mean(x2)  where
>> mean(x_i) are the mean of the actual data?
>>
>> Lastly, how would these two differ: s(x1,by=x2); or
>> s(x1,by=x1)*s(x2,by=x2) since interactions are surely present and i'm not
>> sure if a linear combination is enough.
>>
>> Thanks!
>> Dominik
>>
>>
>> On Wed, May 11, 2016 at 3:11 AM, Simon Wood < <simon.wood at bath.edu>
>> simon.wood at bath.edu> wrote:
>>
>>> The spline having a positive value is not the same as a glm coefficient
>>> having a positive value. When you plot a smooth, say s(x), that is
>>> equivalent to plotting the line 'beta * x' in a GLM. It is not equivalent
>>> to plotting 'beta'. The smooths in a gam are (usually) subject to
>>> `sum-to-zero' identifiability constraints to avoid confounding via the
>>> intercept, so they are bound to be negative over some part of the covariate
>>> range. For example, if I have a model y ~ s(x) + s(z), I can't estimate the
>>> mean level for s(x) and the mean level for s(z) as they are completely
>>> confounded, and confounded with the model intercept term.
>>>
>>> I suppose that if you want to interpret the smooths as glm parameters
>>> varying with the covariate they relate to then you can do, by setting the
>>> model up as a varying coefficient model, using the `by' argument to 's'...
>>>
>>> gam(snowdepth~s(fsca,by=fsca),data=dat)
>>>
>>>
>>> this model is `snowdepth_i = f(fsca_i) * fsca_i + e_i' . s(fsca,by=fsca)
>>> is not confounded with the intercept, so no constraint is needed or
>>> applied, and you can now interpret the smooth like a local GLM coefficient.
>>>
>>> best,
>>> Simon
>>>
>>>
>>>
>>>
>>> On 11/05/16 01:30, Dominik Schneider wrote:
>>>
>>>> Hi,
>>>> Just getting into using GAM using the mgcv package. I've generated some
>>>> models and extracted the splines for each of the variables and started
>>>> visualizing them. I'm noticing that one of my variables is physically
>>>> unrealistic.
>>>>
>>>> In the example below, my interpretation of the following plot is that
>>>> the
>>>> y-axis is basically the equivalent of a "parameter" value of a GLM; in
>>>> GAM
>>>> this value can change as the functional relationship changes between x
>>>> and
>>>> y. In my case, I am predicting snowdepth based on the fractional snow
>>>> covered area. In no case will snowdepth realistically decrease for a
>>>> unit
>>>> increase in fsca so my question is: *Is there a way to constrain the
>>>> spline
>>>> to positive values? *
>>>>
>>>> Thanks
>>>> Dominik
>>>>
>>>> library(mgcv)
>>>> library(dplyr)
>>>> library(ggplot2)
>>>> extract_splines=function(mdl){
>>>>    sterms=predict(mdl,type='terms')
>>>>    datplot=cbind(sterms,mdl$model) %>% tbl_df
>>>>    datplot$intercept=attr(sterms,'constant')
>>>>    datplot$yhat=rowSums(sterms)+attr(sterms,'constant')
>>>>    return(datplot)
>>>> }
>>>> dat=data_frame(snowdepth=runif(100,min =
>>>> 0.001,max=6.7),fsca=runif(100,0.01,.99))
>>>> mdl=gam(snowdepth~s(fsca),data=dat)
>>>> termdF=extract_splines(mdl)
>>>> ggplot(termdF)+
>>>>    geom_line(aes(x=fsca,y=`s(fsca)`))
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> <http://www.R-project.org/posting-guide.html>
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>> --
>>> Simon Wood, School of Mathematics, University of Bristol BS8 1TW UK
>>> +44 (0)117 33 18273 <%2B44%20%280%29117%2033%2018273>
>>> <http://www.maths.bris.ac.uk/%7Esw15190>
>>> http://www.maths.bris.ac.uk/~sw15190
>>>
>>>
>>
>
>
> --
> Simon Wood, School of Mathematics, University of Bristol BS8 1TW UK
> +44 (0)117 33 18273     http://www.maths.bris.ac.uk/~sw15190
>
>

	[[alternative HTML version deleted]]


From jennifer.s.lyon at gmail.com  Tue May 17 01:33:51 2016
From: jennifer.s.lyon at gmail.com (Jennifer Lyon)
Date: Mon, 16 May 2016 17:33:51 -0600
Subject: [R] Error in structure(.External(.C_dotTclObjv, objv),
 class = "tclObj") when selecting (HTTP mirrors) in update.packages()
Message-ID: <CAKstpn5EiMRfc722yZvrX55LmypMdaJkN2vxCoUJJZ-sdxn1Fw@mail.gmail.com>

Hi:

When I try to run update.packages() and double click on the last
option (HTTP mirrors), I receive the error message:
 Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj")

While I can reliably reproduce the error, if I double click quickly
enough (decreased time between the two clicks) the error doesn't
appear, so it may be that the menu is receiving two clicks, very close
together instead of a double click causing it to fail.

update.packages()
--- Please select a CRAN mirror for use in this session ---
Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
  [tcl] grab failed: window not viewable.
> traceback()
12: structure(.External(.C_dotTclObjv, objv), class = "tclObj")
11: .Tcl.objv(.Tcl.args.objv(...))
10: tcl("grab", "set", ...)
9: tkgrab.set(dlg)
8: tcltk::tk_select.list(choices, preselect, multiple, title)
7: select.list(choices, multiple = FALSE, title = title, graphics = TRUE)
6: menu(m[, 1L], graphics, httpLabel)
5: .chooseMirror(m, "CRAN", graphics, ind, useHTTPS)
4: chooseCRANmirror()
3: contrib.url(repos, type)
2: available.packages(contriburl = contriburl, method = method)
1: update.packages()

Additional information:
If I run update.packages() in the same R session after receiving the
above error, in addition to the normal menu with title "HTTPS CRAN
mirror", a smaller, empty menu appears with the title "HTTP CRAN
mirror".

Thanks.

Jen

> sessionInfo()
R version 3.3.0 (2016-05-03)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.4 LTS

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.3.0 tcltk_3.3.0
>

	[[alternative HTML version deleted]]


From venkat.architect at gmail.com  Tue May 17 05:32:09 2016
From: venkat.architect at gmail.com (Venkat Ramakrishnan)
Date: Tue, 17 May 2016 09:02:09 +0530
Subject: [R] R-3.3.0 Base: Windows compilation fails while building 'base'
	package
Message-ID: <CAErxogEB9ZKcz5j4Wgr8f+3+OxDg+X+U1TiimsF5YECrc1k1FA@mail.gmail.com>

Hi,

I'm trying to builda  R-3.3.0 base package on Windows 8.1, and it fails
while building 'base' package with an error about unable to create a
directory
under /tmp.

I am running the make from my D:\ partition, and I have created a \TMP
directory
under both C:\ and D:\.  I have also modified my environment variables TEMP
and TMP both point to C:\TMP.

Error messages below:

gfortran -m64 -O3 -mtune=core2  -c cmplx.f -o cmplx.o
gcc -std=gnu99 -m64 -I../../include -DHAVE_CONFIG_H  -O3 -Wall -pedantic
-mtune=
core2   -c init_win.c -o init_win.o
windres -F pe-x86-64   -i Rlapackrc.rc -o Rlapackrc.o
gcc -std=gnu99 -m64 -shared -s -o ../../../bin/x64/Rlapack.dll dlamch.o
dlapack.
o cmplx.o init_win.o Rlapackrc.o -L../../../bin/x64 -lR -lRblas -lgfortran
-lqua
dmath
gcc -std=gnu99 -m64 -I../../include -DHAVE_CONFIG_H  -O3 -Wall -pedantic
-mtune=
core2   -c Lapack.c -o Lapack.o
windres -F pe-x86-64   -i dllversion.rc -o dllversion.o
gcc -std=gnu99 -m64 -shared -s  -o lapack.dll lapack.def Lapack.o
dllversion.o -
L../../../bin/x64 -lRlapack -lRblas -lR
cp lapack.dll ../../../modules/x64/lapack.dll
building package 'base'
cannot create /tmp/R15756: directory nonexistent     <-------------------
mv: cannot stat '/tmp/R15756': No such file or directory <---------------
make[3]: *** [mkR1] Error 1
make[2]: *** [all] Error 2
make[1]: *** [R] Error 1
make: *** [all] Error 2

I'm not sure what else I need to do. Please help.

Thanks & Best Regards,
Venkat.

	[[alternative HTML version deleted]]


From kristi.glover at hotmail.com  Tue May 17 12:09:56 2016
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Tue, 17 May 2016 10:09:56 +0000
Subject: [R] can I calculate Standard deviation or variance?
Message-ID: <BY2PR13MB0454FF85DBCD3286E9D040F0FA480@BY2PR13MB0454.namprd13.prod.outlook.com>

Dear R User,

I have a data with a mean and Standard Error (SE) but no sample size, I am wondering whether I can compute the standard deviation (SD) with these information. if possible, how much would be for the given example?

> mean<-0.098

> SE<-0.0006


Thanks,



	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue May 17 12:48:02 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 17 May 2016 20:48:02 +1000
Subject: [R] can I calculate Standard deviation or variance?
In-Reply-To: <BY2PR13MB0454FF85DBCD3286E9D040F0FA480@BY2PR13MB0454.namprd13.prod.outlook.com>
References: <BY2PR13MB0454FF85DBCD3286E9D040F0FA480@BY2PR13MB0454.namprd13.prod.outlook.com>
Message-ID: <CA+8X3fX_ae2_2PSda-Gy8tB50xhVbUvA9QWsREcu-LG3OtJZGw@mail.gmail.com>

Hi Kristi,
Multiply the standard error by the square root of the sample size.

Jim


On Tue, May 17, 2016 at 8:09 PM, Kristi Glover
<kristi.glover at hotmail.com> wrote:
> Dear R User,
>
> I have a data with a mean and Standard Error (SE) but no sample size, I am wondering whether I can compute the standard deviation (SD) with these information. if possible, how much would be for the given example?
>
>> mean<-0.098
>
>> SE<-0.0006
>
>
> Thanks,
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Tue May 17 12:48:48 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 17 May 2016 20:48:48 +1000
Subject: [R] can I calculate Standard deviation or variance?
In-Reply-To: <CA+8X3fX_ae2_2PSda-Gy8tB50xhVbUvA9QWsREcu-LG3OtJZGw@mail.gmail.com>
References: <BY2PR13MB0454FF85DBCD3286E9D040F0FA480@BY2PR13MB0454.namprd13.prod.outlook.com>
	<CA+8X3fX_ae2_2PSda-Gy8tB50xhVbUvA9QWsREcu-LG3OtJZGw@mail.gmail.com>
Message-ID: <CA+8X3fXYq-qok2WUdJ1bb681pt10dzuDdXHrFs=CVOMdAeSgOQ@mail.gmail.com>

Hi again,
Sorry, didn't read that correctly.  No.

Jim

On Tue, May 17, 2016 at 8:48 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Kristi,
> Multiply the standard error by the square root of the sample size.
>
> Jim
>
>
> On Tue, May 17, 2016 at 8:09 PM, Kristi Glover
> <kristi.glover at hotmail.com> wrote:
>> Dear R User,
>>
>> I have a data with a mean and Standard Error (SE) but no sample size, I am wondering whether I can compute the standard deviation (SD) with these information. if possible, how much would be for the given example?
>>
>>> mean<-0.098
>>
>>> SE<-0.0006
>>
>>
>> Thanks,
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From Muhammad2.Bilal at live.uwe.ac.uk  Tue May 17 12:56:56 2016
From: Muhammad2.Bilal at live.uwe.ac.uk (Muhammad Bilal)
Date: Tue, 17 May 2016 10:56:56 +0000
Subject: [R] Evaluating statistical models and describing coefficients for
 non-parametric models
Message-ID: <DB5PR07MB11097B567822D62EC2046841DB480@DB5PR07MB1109.eurprd07.prod.outlook.com>

Hi All,


I'm using number of models such as lm(), tree, randomForest, svm, and nnet for predicting the delays in projects. Also, I computed the sum of  squared error for all these models for comparison purposes. However, I want to use other related evaluation criteria such as root mean sum of square error (RMSE) and R Squared for evaluation of these models.


My question is that is it possible to compute these criteria (RMSE or R2) for all above-mentioned statistical models.


Second, for the lm() we can see the co-efficient values by checking model summary. Is it possible to see the co-efficient for other models such as SVM and neural network?


Thanks in advance for the help and support.


Many Thanks and


Kind Regards

--
Muhammad Bilal
Research Fellow and Doctoral Researcher,
Bristol Enterprise, Research, and Innovation Centre (BERIC),
University of the West of England (UWE),
Frenchay Campus,
Bristol,
BS16 1QY

muhammad2.bilal at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>


	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Tue May 17 13:01:47 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 17 May 2016 13:01:47 +0200
Subject: [R] Warning when running R - can't install packages either
In-Reply-To: <57365BC5.1040101@roswellpark.org>
References: <CAJDAfTBMYFH0PcRG7scf+g5GAbkPC2yz4UF+1w+d5=xssipaHQ@mail.gmail.com>
	<238A333C-AE09-4131-94CE-E4688A6814D3@gmail.com>
	<CAJDAfTAa0RuZ+CjO0kX-zFaxzVfb2XsBZ_cpA2G-GCoq0qeteA@mail.gmail.com>
	<57359F08.8090307@roswellpark.org>
	<986689C7-EA25-4724-9D98-2939E1A5831B@jirutka.cz>
	<57365BC5.1040101@roswellpark.org>
Message-ID: <22330.64027.194971.440739@stat.math.ethz.ch>

>>>>> Martin Morgan <martin.morgan at roswellpark.org>
>>>>>     on Fri, 13 May 2016 18:57:09 -0400 writes:

> Hi Jakub,
> 
> This is really a separate question. It is not really end-user related, 
> and should be asked on the R-devel mailing list. Nonetheless, some 
> answers below.
> 
> On 05/13/2016 03:55 PM, Jakub Jirutka wrote:
> > Hi,
> >
> > I?m maintainer of the R package in Alpine Linux.
> >
> > I read on multiple places that some packages needs R_HOME variable
> > set to the location where is R installed, so I?ve added it to the
> > system-wide profile. Is this correct, or a misinformation?

Short executive summary to all the nice explanations and
examples (by the other Martin M) below:

  Yes, this is misinformation.
  You should *NOT* set R_HOME in a (system wide /  user) profile.

Martin Maechler

> R_HOME is set when R starts
> 
> ~$ env|grep R_HOME
> ~$ R --vanilla -e "Sys.getenv('R_HOME')"
>  > Sys.getenv('R_HOME')
> [1] "/home/mtmorgan/bin/R-3-3-branch"
> 
> and (after reading the documentation in ?R_HOME it the R help system)
> 
> ~$ R RHOME
> /home/mtmorgan/bin/R-3-3-branch
> 
> so there is no need to set it in a system-wide profile. It is sometimes 
> referenced inside an R package source tree that uses C or other compiled 
> code in a Makevars file, as described in the 'Writing R Extensions' manual
> 
> https://cran.r-project.org/doc/manuals/r-release/R-exts.html
> e.g., the section on configure and cleanup
> 
> https://cran.r-project.org/doc/manuals/r-release/R-exts.html#Configure-and-cleanup
> 
> In these circumstances it has been set by the R process that is 
> compiling the source code.
> 
> >
> > What system dependencies does R need to compile modules from CRAN? On
> > Alpine the following dependencies are needed to build R: bzip2-dev
> > curl-dev gfortran lapack-dev pcre-dev perl readline-dev xz-dev
> > zlib-dev. Are all of these dependencies needed for compiling
> > modules?
> 
> As you say, those look like dependencies required to build R itself.
> 
> Individual packages may have dependencies on these or other system 
> libraries, but many packages do not have system dependencies. It is up 
> to the package maintainer to ensure that appropriate checks are made to 
> discover the system resource; there are probably dozens or even hundreds 
> of system dependencies amongst all of the CRAN packages. Typically the 
> task of satisfying those dependencies is left to the user (or to those 
> creating distributions of R packages, e.g., 
> https://cran.r-project.org/bin/linux/debian/)
> 
> Martin Morgan
> 
> >
> > Jakub
> >
> > On 13. May 2016, at 11:31, Martin Morgan
> > <martin.morgan at roswellpark.org> wrote:
> >
> >>
> >>
> >> On 05/12/2016 10:25 PM, Alba Pompeo wrote:
> >>> Martin Morgan, I tried an HTTP mirror and it worked. What could
> >>> be the problem and how to fix? Also, should I ignore the warning
> >>> about ignoring environment value of R_HOME?
> >>
> >> It depends on why you set the value in your environment in the
> >> first place; maybe you were trying to use a particular installation
> >> of R, but setting R_HOME is not the way to do that (I use an alias,
> >> e.g., R-3.3='~/bin/R-3-3-branch/bin/R --no-save --no-restore
> >> --silent')
> >>
> >> Martin
> >>
> >>> Thanks.
> >>>
> >>> On Thu, May 12, 2016 at 5:59 PM, Tom Hopper <tomhopper at gmail.com>
> >>> wrote:
> >>>> setInternet2() first thing after launching R might fix that.
> >>>>
> >>>>
> >>>>> On May 12, 2016, at 07:45, Alba Pompeo <albapompeo at gmail.com>
> >>>>> wrote:
> >>>>>
> >>>>> Hello.
> >>>>>
> >>>>> I've tried to run R, but I receive many warnings and can't do
> >>>>> simple stuff such as installing packages.
> >>>>>
> >>>>> Here's the full log when I run it.
> >>>>>
> >>>>> http://pastebin.com/raw/2BkNpTte
> >>>>>
> >>>>> Does anyone know what could be wrong here?
> >>>>>
> >>>>> Thanks a lot.


From shaila_jm at rediffmail.com  Tue May 17 13:09:43 2016
From: shaila_jm at rediffmail.com (shaila  shailaja)
Date: 17 May 2016 11:09:43 -0000
Subject: [R] =?utf-8?q?Placement_of_words_in_a_word_cloud_as_per_its_occur?=
	=?utf-8?q?ance=2E?=
Message-ID: <20160517110943.4853.qmail@f5mail-224-153.rediffmail.com>

Dear R help subscribers,




I am working on a word cloud where in I want the words to appear in the same order as in the sentence/text. 

I only know&nbsp;the random.order -&nbsp;which plots words in random order. If false, they will be plotted in decreasing frequency.

&nbsp;

Any help is most welcome.

&nbsp;

Regards

Shailaja
	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Tue May 17 14:15:22 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Tue, 17 May 2016 13:15:22 +0100
Subject: [R] can I calculate Standard deviation or variance?
In-Reply-To: <BY2PR13MB0454FF85DBCD3286E9D040F0FA480@BY2PR13MB0454.namprd13.prod.outlook.com>
References: <BY2PR13MB0454FF85DBCD3286E9D040F0FA480@BY2PR13MB0454.namprd13.prod.outlook.com>
Message-ID: <3fc81326-7a50-71fb-6e77-3a86c09b029f@dewey.myzen.co.uk>

Dear Kristi

You will doubtless soon receive a reply telling you this is a 
statistical question and off-topic here but in the meantime, do you have 
any other information like a value of a test statistic or a p-value? 
Sometimes they can be used.

And please set your mailer to send plain text not HTML as it scrambles 
messages.

On 17/05/2016 11:09, Kristi Glover wrote:
> Dear R User,
>
> I have a data with a mean and Standard Error (SE) but no sample size, I am wondering whether I can compute the standard deviation (SD) with these information. if possible, how much would be for the given example?
>
>> mean<-0.098
>
>> SE<-0.0006
>
>
> Thanks,
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From jdnewmil at dcn.davis.ca.us  Tue May 17 15:55:20 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 17 May 2016 06:55:20 -0700
Subject: [R] R 3.3.0 Crashing: Error in readRDS(nsInfoFilePath) :
	unknown input format
In-Reply-To: <CALWkyWuaRON1tVi70J4rTUpXyhFFK2tKCaFd=xd5xiu4iht=cg@mail.gmail.com>
References: <CALWkyWu=OTkdSjrRmqvrborfdMcpV5cc_sWQc+fjwDocYdGoOg@mail.gmail.com>
	<31A25DE7-1BA5-4277-B366-C31A490E9190@dcn.davis.ca.us>
	<CALWkyWuaRON1tVi70J4rTUpXyhFFK2tKCaFd=xd5xiu4iht=cg@mail.gmail.com>
Message-ID: <772C4477-6135-4A30-9743-B12E36941DFD@dcn.davis.ca.us>

A) I am not a Dr. I am just someone who has been using R for awhile. Since the install process usually works for me, I might not even be the best person to identify your problem, but I will help if I can. 

B) sessionInfo is a function.  You have to invoke functions by including argument parentheses,  like so:

sessionInfo()

Looking at how that function is implemented when you ask the interpreter to print the function definition doesn't help us differentiate your setup from anyone else's.

C) you have not addressed the question of what might be in your .Rprofile. That is a file by that name in your home directory (My Documents?) If it does not exist, it can't be a problem, but you need to confirm. 

D) You have not addressed what might be corrupted in your personal package library (typically My Documents\R\win-lib\3.3). Confirm that you have renamed or deleted it. 

E) It might be relevant to ask how you are installing the package. What was the exact URL of the installation file?  Did you make the mistake of using the "Run As Administrator" option when you started that install file? (If so,  that can make it quite difficult to clean up bad file permissions. I am not even sure how to fix that, so you would need someone else to help if so.)

F) What commands are you giving to R during your first run?
-- 
Sent from my phone. Please excuse my brevity.

On May 17, 2016 6:18:45 AM PDT, Amitava Mukherjee <amitmukh2 at gmail.com> wrote:
>Dear Dr. Jeff,
>
>Many thanks for your reply. Here is the output of session info.
>
>I uninstalled all versions of R from my PC and stored R files, then
>reinstall.
>
>First time, it works smoothly. But crashing once I shut down and
>reopen...
>
>Details appended below...
>
>Thanks and hope you will be able to help and support ...
>
>Best regards,
>Amitava
>
>Error in readRDS(nsInfoFilePath) : unknown input format
>
>R version 3.3.0 (2016-05-03) -- "Supposedly Educational"
>Copyright (C) 2016 The R Foundation for Statistical Computing
>Platform: x86_64-w64-mingw32/x64 (64-bit)
>
>R is free software and comes with ABSOLUTELY NO WARRANTY.
>You are welcome to redistribute it under certain conditions.
>Type 'license()' or 'licence()' for distribution details.
>
>  Natural language support but running in an English locale
>
>R is a collaborative project with many contributors.
>Type 'contributors()' for more information and
>'citation()' on how to cite R or R packages in publications.
>
>Type 'demo()' for some demos, 'help()' for on-line help, or
>'help.start()' for an HTML browser interface to help.
>Type 'q()' to quit R.
>
>Warning message:
>package "methods" in options("defaultPackages") was not found
>Error in readRDS(nsInfoFilePath) : unknown input format
>During startup - Warning message:
>package ?methods? in options("defaultPackages") was not found
>> sessionInfo
>function (package = NULL)
>{
>    z <- list()
>    z$R.version <- R.Version()
>    z$platform <- z$R.version$platform
>    if (nzchar(.Platform$r_arch))
>        z$platform <- paste(z$platform, .Platform$r_arch, sep = "/")
>    z$platform <- paste0(z$platform, " (", 8 * .Machine$sizeof.pointer,
>        "-bit)")
>    z$locale <- Sys.getlocale()
>    if (.Platform$OS.type == "windows") {
>        z$running <- win.version()
>    }
>    else if (nzchar(Sys.which("uname"))) {
>        uname <- system("uname -a", intern = TRUE)
>        os <- sub(" .*", "", uname)
>    z$running <- switch(os, Linux = if (file.exists("/etc/os-release"))
>{
>            tmp <- readLines("/etc/os-release")
>            t2 <- if (any(startsWith(tmp, "PRETTY_NAME=")))
>sub("^PRETTY_NAME=",
>              "", grep("^PRETTY_NAME=", tmp, value = TRUE)[1L]) else if
>(any(startsWith(tmp,
>                "NAME"))) sub("^NAME=", "", grep("^NAME=", tmp,
>                value = TRUE)[1L]) else "Linux (unknown distro)"
>            sub("\"(.*)\"", "\\1", t2)
>        } else if (file.exists("/etc/system-release")) {
>            readLines("/etc/system-release")
>        }, Darwin = {
>            ver <-
>readLines("/System/Library/CoreServices/SystemVersion.plist")
>            ind <- grep("ProductUserVisibleVersion", ver)
>            ver <- ver[ind + 1L]
>            ver <- sub(".*<string>", "", ver)
>            ver <- sub("</string>$", "", ver)
>            ver1 <- strsplit(ver, ".", fixed = TRUE)[[1L]][2L]
>            sprintf("OS X %s (%s)", ver, switch(ver1, `4` = "Tiger",
>                `5` = "Leopard", `6` = "Snow Leopard", `7` = "Lion",
>                `8` = "Mountain Lion", `9` = "Mavericks", `10` =
>"Yosemite",
>                `11` = "El Capitan", "unknown"))
>        }, SunOS = {
>            ver <- system("uname -r", intern = TRUE)
>           paste("Solaris", strsplit(ver, ".", fixed = TRUE)[[1L]][2L])
>        }, uname)
>    }
>    if (is.null(package)) {
>        package <- grep("^package:", search(), value = TRUE)
>        keep <- vapply(package, function(x) x == "package:base" ||
>            !is.null(attr(as.environment(x), "path")), NA)
>        package <- .rmpkg(package[keep])
>    }
>    pkgDesc <- lapply(package, packageDescription, encoding = NA)
>    if (length(package) == 0)
>        stop("no valid packages were specified")
>    basePkgs <- sapply(pkgDesc, function(x) !is.null(x$Priority) &&
>        x$Priority == "base")
>    z$basePkgs <- package[basePkgs]
>    if (any(!basePkgs)) {
>        z$otherPkgs <- pkgDesc[!basePkgs]
>        names(z$otherPkgs) <- package[!basePkgs]
>    }
>    loadedOnly <- loadedNamespaces()
>    loadedOnly <- loadedOnly[!(loadedOnly %in% package)]
>    if (length(loadedOnly)) {
>        names(loadedOnly) <- loadedOnly
>        pkgDesc <- c(pkgDesc, lapply(loadedOnly, packageDescription))
>        z$loadedOnly <- pkgDesc[loadedOnly]
>    }
>    class(z) <- "sessionInfo"
>    z
>}
><bytecode: 0x0000000008a8a8c0>
><environment: namespace:utils>
>>
>
>
>On 16 May 2016 at 21:08, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> I don't know why this is happening, but the nsInfo.rds file is part
>of
>> every installed package (see Section 4.1 of the R Internals
>documentation)
>> and it sounds like one or more of them are getting corrupted. This
>could be
>> because you or your .Rprofile or an .RData file are triggering a bug
>in one
>> of your packages.
>>
>> You might try
>> * posting the output of the sessionInfo function,
>> * looking in your .Rprofile file with a text editor,
>> * deleting/renaming any RData files in your working directory, and
>perhaps
>> * clearing/renaming your personal 3.3 package library and
>re-installing
>> one package at a time to see which one triggers the error.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On May 13, 2016 11:53:05 PM PDT, Amitava Mukherjee
><amitmukh2 at gmail.com>
>> wrote:
>>
>>> Dear All,
>>>
>>> Greetings. I hope you will be able to provide kind help with the
>following:
>>>
>>> I am facing a strange problem ever since I have started working with
>R
>>> 3.3.0.
>>>
>>> I download and work with it, it was fine. Then when I shut down and
>reopen,
>>> it is not working properly.
>>>
>>> I am getting following message:
>>>
>>> Error in readRDS(nsInfoFilePath) : unknown input format
>>>
>>> R version 3.3.0 (2016-05-03) -- "Supposedly Educational"
>>> Copyright (C) 2016 The R Foundation for Statistical Computing
>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>
>>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>>> You are welcome to redistribute it under certain conditions.
>>> Type 'license()' or 'licence()' for distribution details.
>>>
>>>   Natural language support but running in an English locale
>>>
>>> R is a collaborative project with many contributors.
>>> Type 'contributors()' for more
>>> information and
>>> 'citation()' on how to cite R or R packages in publications.
>>>
>>> Type 'demo()' for some demos, 'help()' for on-line help, or
>>> 'help.start()' for an HTML browser interface to help.
>>> Type 'q()' to quit R.
>>>
>>> Warning message:
>>> package "methods" in options("defaultPackages") was not found
>>> [Previously saved workspace restored]
>>>
>>> Error in readRDS(nsInfoFilePath) : unknown input format
>>> During startup - Warning message:
>>> package ?methods? in options("defaultPackages") was not found
>>>
>>>>  ?mean
>>>>
>>> Error in readRDS(nsInfoFilePath) : unknown input format
>>>
>>>>
>>>>
>>>
>>> I have uninstall it three times and reinstall -- Every time after
>first
>>> installation it is working perfectly.
>>>
>>> Then when I am closing R window and reopening it, the problem
>starts.
>>>
>>> Kindly suggest what should I do. Looking forward to hear from you,
>>>
>>> Best regards,
>>> Amitava
>>>
>>>
>>>
>>>
>>>
>>> Dr. Amitava Mukherjee, Ph.D.
>>> Associate Professor,
>>> Production, Operations and Decision Sciences Area,
>>> XLRI-Xavier School of Management, India.
>>>
>>>  [[alternative HTML version deleted]]
>>>
>>> ------------------------------
>>>
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>

	[[alternative HTML version deleted]]


From jan.kacaba at gmail.com  Tue May 17 16:28:19 2016
From: jan.kacaba at gmail.com (Jan Kacaba)
Date: Tue, 17 May 2016 16:28:19 +0200
Subject: [R] break string at specified possitions
In-Reply-To: <5735A2E5.1010700@fredhutch.org>
References: <CAHby=D1UYkGp-L_hVgy8Xus=_wVjDmV=6_x39Dyd0Pt38-H02w@mail.gmail.com>
	<CAGxFJbTi0SPb9STcFwu1DaGA2Ynd5K6v6KWNe7=ubh_Nc3uo+g@mail.gmail.com>
	<CAHby=D3aXQ6WF3wWWkYob1+a5wPhB0+yTGrVTJ9tzpcQz8i4kw@mail.gmail.com>
	<CA+8X3fUpTkyJiyq=nLmYa-ogLiwYXPjcxFgZdgWz32aD6Vy7uA@mail.gmail.com>
	<CA+8X3fU8mGykM++TSU-LDZRKxL3oUs0KFaS10P3mkoDU1z2gUA@mail.gmail.com>
	<CAHby=D0MJEWRaX_UH9Q1UU2rT0QORF-rQdxhQ=KWHt8R7sK80g@mail.gmail.com>
	<5735A2E5.1010700@fredhutch.org>
Message-ID: <CAHby=D3P=a-QZOQMFQsNsyA6VGJMNp+z6mYYZxCtBEe+gq4BMQ@mail.gmail.com>

Excellent Herv?, thank you.

2016-05-13 11:48 GMT+02:00 Herv? Pag?s <hpages at fredhutch.org>:
> Hi,
>
> Here is the Biostrings solution in case you need to chop a long
> string into hundreds or thousands of fragments (a situation where
> base::substring() is very inefficient):
>
>   library(Biostrings)
>
>   ## Call as.character() on the result if you want it back as
>   ## a character vector.
>   fast_chop_string <- function(x, ends)
>   {
>     if (!is(x, "XString"))
>         x <- as(x, "XString")
>     extractAt(x, at=PartitioningByEnd(ends))
>   }
>
> Will be much faster than substring (e.g. 100x or 1000x) when
> chopping a string like a Human chromosome into hundreds or
> thousands of fragments.
>
> Biostrings is a Bioconductor package:
>
>   https://bioconductor.org/packages/Biostrings
>
> Cheers,
> H.
>
>
>
> On 05/12/2016 01:18 AM, Jan Kacaba wrote:
>>
>> Nice solution Jim, thank you.
>>
>>
>>
>> 2016-05-12 2:45 GMT+02:00 Jim Lemon <drjimlemon at gmail.com>:
>>>
>>> Hi again,
>>> Sorry, that should be:
>>>
>>> chop_string<-function(x,ends) {
>>>   starts<-c(1,ends[-length(ends)]+1)
>>>   return(substring(x,starts,ends))
>>> }
>>>
>>> Jim
>>>
>>> On Thu, May 12, 2016 at 10:05 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>>>
>>>> Hi Jan,
>>>> This might be helpful:
>>>>
>>>> chop_string<-function(x,ends) {
>>>>   starts<-c(1,ends[-length(ends)]-1)
>>>>   return(substring(x,starts,ends))
>>>> }
>>>>
>>>> Jim
>>>>
>>>>
>>>> On Thu, May 12, 2016 at 7:23 AM, Jan Kacaba <jan.kacaba at gmail.com>
>>>> wrote:
>>>>>
>>>>> Here is my attempt at function which computes margins from positions.
>>>>>
>>>>> require("stringr")
>>>>> require("dplyr")
>>>>>
>>>>> ends<-seq(10,100,8)  # end margins
>>>>> test_string<-"Lorem ipsum dolor sit amet, consectetuer adipiscing
>>>>> elit. Aliquam in lorem sit amet leo accumsan lacinia."
>>>>>
>>>>> sekoj=function(ends){
>>>>>    l_ends<-length(ends)
>>>>>    begs=vector(mode="integer",l_ends)
>>>>>    begs[1]=1
>>>>>    for (i in 2:(l_ends)){
>>>>>      begs[i]<-ends[i-1]+1
>>>>>    }
>>>>>    margs<-rbind(begs,ends)
>>>>>    margs<-cbind(margs,c(ends[l_ends]+1,-1))
>>>>>    #rownames(margs)<-c("beg","end")
>>>>>    return(margs)
>>>>> }
>>>>> margins<-sekoj(ends)
>>>>> str_sub(test_string,margins[1,],margins[2,]) %>% print
>>>>>
>>>>> Code to run in browser:
>>>>> http://www.r-fiddle.org/#/fiddle?id=rVmNVxDV
>>>>>
>>>>> 2016-05-11 23:12 GMT+02:00 Bert Gunter <bgunter.4567 at gmail.com>:
>>>>>>
>>>>>> Dunno -- but you might have a look at Hadley Wickham's 'stringr'
>>>>>> package:
>>>>>> https://cran.r-project.org/web/packages/stringr/stringr.pdf
>>>>>>
>>>>>> Cheers,
>>>>>>
>>>>>> Bert
>>>>>>
>>>>>>
>>>>>> Bert Gunter
>>>>>>
>>>>>> "The trouble with having an open mind is that people keep coming along
>>>>>> and sticking things into it."
>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>>
>>>>>>
>>>>>> On Wed, May 11, 2016 at 1:12 PM, Jan Kacaba <jan.kacaba at gmail.com>
>>>>>> wrote:
>>>>>>>
>>>>>>> Dear R-help
>>>>>>>
>>>>>>> I would like to split long string at specified precomputed positions.
>>>>>>> 'substring' needs beginings and ends. Is there a native function
>>>>>>> which
>>>>>>> accepts positions so I don't have to count second argument?
>>>>>>>
>>>>>>> For example I have vector of possitions pos<-c(5,10,19). Substring
>>>>>>> needs input first=c(1,6,11) and last=c(5,10,19). There is no problem
>>>>>>> to write my own function. Just asking.
>>>>>>>
>>>>>>> Derek
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> --
> Herv? Pag?s
>
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
>
> E-mail: hpages at fredhutch.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319


From ggrothendieck at gmail.com  Tue May 17 16:35:29 2016
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 17 May 2016 10:35:29 -0400
Subject: [R] break string at specified possitions
In-Reply-To: <CAHby=D1UYkGp-L_hVgy8Xus=_wVjDmV=6_x39Dyd0Pt38-H02w@mail.gmail.com>
References: <CAHby=D1UYkGp-L_hVgy8Xus=_wVjDmV=6_x39Dyd0Pt38-H02w@mail.gmail.com>
Message-ID: <CAP01uRnzqwr0JtKJUqVbV0ba-tn7cwr6DHJzujQez_nrZbUW-w@mail.gmail.com>

Here are two ways that do not use any packages:

s <- paste(letters, collapse = "") # test input

substring(s, first, last)
## [1] "abcde"     "fghij"     "klmnopqrs"


read.fwf(textConnection(s), last - first + 1)
##         V1    V2        V3
## 1 abcde fghij klmnopqrs

On Wed, May 11, 2016 at 4:12 PM, Jan Kacaba <jan.kacaba at gmail.com> wrote:
> Dear R-help
>
> I would like to split long string at specified precomputed positions.
> 'substring' needs beginings and ends. Is there a native function which
> accepts positions so I don't have to count second argument?
>
> For example I have vector of possitions pos<-c(5,10,19). Substring
> needs input first=c(1,6,11) and last=c(5,10,19). There is no problem
> to write my own function. Just asking.
>
> Derek
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From cryan at binghamton.edu  Fri May 13 17:55:13 2016
From: cryan at binghamton.edu (Christopher W. Ryan)
Date: Fri, 13 May 2016 11:55:13 -0400
Subject: [R] anonymizing subject identifiers for survival analysis
In-Reply-To: <CAF8bMcZ52svT0q-2wy2=xnigCbwJYw1wUQ+94fe4UHzo_dSsrA@mail.gmail.com>
References: <CAM+rpY=HgsQwPsfP9bXfK=0QGe_Lfi87PYNHv27BSwVoRA56ow@mail.gmail.com>
	<CAF8bMcZ52svT0q-2wy2=xnigCbwJYw1wUQ+94fe4UHzo_dSsrA@mail.gmail.com>
Message-ID: <5735F8E1.8040606@binghamton.edu>

Excellent, thanks. Much simpler.

--Chris

Christopher W. Ryan, MD, MS
cryanatbinghamtondotedu
https://www.linkedin.com/in/ryancw

Early success is a terrible teacher. You?re essentially being rewarded
for a lack of preparation, so when you find yourself in a situation
where you must prepare, you can?t do it. You don?t know how.
--Chris Hadfield, An Astronaut's Guide to Life on Earth

William Dunlap wrote:
> You can also use match(code, unique(code)), as in
>   transform(dd.2, codex2 = paste0("Person", match(code, unique(code))))
> It is not guaranteed that x!=y implies digest(x)!=digest(y), but it is
> extremely
> unlikely to fail.  This match idiom guarantees that.
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com <http://tibco.com>
> 
> On Thu, May 12, 2016 at 1:06 PM, Christopher W Ryan
> <cryan at binghamton.edu <mailto:cryan at binghamton.edu>> wrote:
> 
>     I would like to conduct a survival analysis, examining a subject's
>     time to *next* appearance in a database, after their first appearance.
>     It is a database of dated events.
> 
>     I need to obfuscate or anonymize or mask the subject identifiers (a
>     combination of name and birthdate). And obviously any given subject
>     should have the same anonymous code ever time he/she appears in the
>     database.  I'm not talking "safe from the NSA" here. And I won't be
>     releasing it. It's just sensitive data and I don't want to be working
>     every day with cleartext versions of it.
> 
>     I've looked at packages digest, anonymizer, and anonymize.  What do
>     you think of this approach:
> 
>     # running R 3.1.1 on Windows 7 Enterprise
>     library(digest)
>     dd <- data.frame(id=1:6, name = c("Harry", "Ron", "Hermione", "Luna",
>     "Ginny", "Harry"), dob = c("1990-01-01", "1990-06-15", "1990-04-08",
>     "1999-11-26", "1990-07-21", "1990-01-01"))
>     dd.2 <- transform(dd, code=paste0(tolower(name), tolower(dob), sep=""))
>     library(digest)
>     anonymize <- function(x, algo="sha256"){
>       unq_hashes <- vapply(x, function(object) digest(object, algo=algo),
>     FUN.VALUE="", USE.NAMES=TRUE)
>       unname(unq_hashes[x])
>     }
>     dd.2$codex <- anonymize(dd.2$code)
>     dd.2
>     table(duplicated(dd.2$codex))
> 
>     Thanks.
> 
>     --Chris Ryan
>     Broome County Health Department
> 
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
> 
>


From amitmukh2 at gmail.com  Tue May 17 15:18:45 2016
From: amitmukh2 at gmail.com (Amitava Mukherjee)
Date: Tue, 17 May 2016 18:48:45 +0530
Subject: [R] R 3.3.0 Crashing: Error in readRDS(nsInfoFilePath) :
 unknown input format
In-Reply-To: <31A25DE7-1BA5-4277-B366-C31A490E9190@dcn.davis.ca.us>
References: <CALWkyWu=OTkdSjrRmqvrborfdMcpV5cc_sWQc+fjwDocYdGoOg@mail.gmail.com>
	<31A25DE7-1BA5-4277-B366-C31A490E9190@dcn.davis.ca.us>
Message-ID: <CALWkyWuaRON1tVi70J4rTUpXyhFFK2tKCaFd=xd5xiu4iht=cg@mail.gmail.com>

Dear Dr. Jeff,

Many thanks for your reply. Here is the output of session info.

I uninstalled all versions of R from my PC and stored R files, then
reinstall.

First time, it works smoothly. But crashing once I shut down and reopen...

Details appended below...

Thanks and hope you will be able to help and support ...

Best regards,
Amitava

Error in readRDS(nsInfoFilePath) : unknown input format

R version 3.3.0 (2016-05-03) -- "Supposedly Educational"
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

Warning message:
package "methods" in options("defaultPackages") was not found
Error in readRDS(nsInfoFilePath) : unknown input format
During startup - Warning message:
package ?methods? in options("defaultPackages") was not found
> sessionInfo
function (package = NULL)
{
    z <- list()
    z$R.version <- R.Version()
    z$platform <- z$R.version$platform
    if (nzchar(.Platform$r_arch))
        z$platform <- paste(z$platform, .Platform$r_arch, sep = "/")
    z$platform <- paste0(z$platform, " (", 8 * .Machine$sizeof.pointer,
        "-bit)")
    z$locale <- Sys.getlocale()
    if (.Platform$OS.type == "windows") {
        z$running <- win.version()
    }
    else if (nzchar(Sys.which("uname"))) {
        uname <- system("uname -a", intern = TRUE)
        os <- sub(" .*", "", uname)
        z$running <- switch(os, Linux = if (file.exists("/etc/os-release"))
{
            tmp <- readLines("/etc/os-release")
            t2 <- if (any(startsWith(tmp, "PRETTY_NAME=")))
sub("^PRETTY_NAME=",
                "", grep("^PRETTY_NAME=", tmp, value = TRUE)[1L]) else if
(any(startsWith(tmp,
                "NAME"))) sub("^NAME=", "", grep("^NAME=", tmp,
                value = TRUE)[1L]) else "Linux (unknown distro)"
            sub("\"(.*)\"", "\\1", t2)
        } else if (file.exists("/etc/system-release")) {
            readLines("/etc/system-release")
        }, Darwin = {
            ver <-
readLines("/System/Library/CoreServices/SystemVersion.plist")
            ind <- grep("ProductUserVisibleVersion", ver)
            ver <- ver[ind + 1L]
            ver <- sub(".*<string>", "", ver)
            ver <- sub("</string>$", "", ver)
            ver1 <- strsplit(ver, ".", fixed = TRUE)[[1L]][2L]
            sprintf("OS X %s (%s)", ver, switch(ver1, `4` = "Tiger",
                `5` = "Leopard", `6` = "Snow Leopard", `7` = "Lion",
                `8` = "Mountain Lion", `9` = "Mavericks", `10` =
"Yosemite",
                `11` = "El Capitan", "unknown"))
        }, SunOS = {
            ver <- system("uname -r", intern = TRUE)
            paste("Solaris", strsplit(ver, ".", fixed = TRUE)[[1L]][2L])
        }, uname)
    }
    if (is.null(package)) {
        package <- grep("^package:", search(), value = TRUE)
        keep <- vapply(package, function(x) x == "package:base" ||
            !is.null(attr(as.environment(x), "path")), NA)
        package <- .rmpkg(package[keep])
    }
    pkgDesc <- lapply(package, packageDescription, encoding = NA)
    if (length(package) == 0)
        stop("no valid packages were specified")
    basePkgs <- sapply(pkgDesc, function(x) !is.null(x$Priority) &&
        x$Priority == "base")
    z$basePkgs <- package[basePkgs]
    if (any(!basePkgs)) {
        z$otherPkgs <- pkgDesc[!basePkgs]
        names(z$otherPkgs) <- package[!basePkgs]
    }
    loadedOnly <- loadedNamespaces()
    loadedOnly <- loadedOnly[!(loadedOnly %in% package)]
    if (length(loadedOnly)) {
        names(loadedOnly) <- loadedOnly
        pkgDesc <- c(pkgDesc, lapply(loadedOnly, packageDescription))
        z$loadedOnly <- pkgDesc[loadedOnly]
    }
    class(z) <- "sessionInfo"
    z
}
<bytecode: 0x0000000008a8a8c0>
<environment: namespace:utils>
>


On 16 May 2016 at 21:08, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> I don't know why this is happening, but the nsInfo.rds file is part of
> every installed package (see Section 4.1 of the R Internals documentation)
> and it sounds like one or more of them are getting corrupted. This could be
> because you or your .Rprofile or an .RData file are triggering a bug in one
> of your packages.
>
> You might try
> * posting the output of the sessionInfo function,
> * looking in your .Rprofile file with a text editor,
> * deleting/renaming any RData files in your working directory, and perhaps
> * clearing/renaming your personal 3.3 package library and re-installing
> one package at a time to see which one triggers the error.
> --
> Sent from my phone. Please excuse my brevity.
>
> On May 13, 2016 11:53:05 PM PDT, Amitava Mukherjee <amitmukh2 at gmail.com>
> wrote:
>
>> Dear All,
>>
>> Greetings. I hope you will be able to provide kind help with the following:
>>
>> I am facing a strange problem ever since I have started working with R
>> 3.3.0.
>>
>> I download and work with it, it was fine. Then when I shut down and reopen,
>> it is not working properly.
>>
>> I am getting following message:
>>
>> Error in readRDS(nsInfoFilePath) : unknown input format
>>
>> R version 3.3.0 (2016-05-03) -- "Supposedly Educational"
>> Copyright (C) 2016 The R Foundation for Statistical Computing
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>
>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>> You are welcome to redistribute it under certain conditions.
>> Type 'license()' or 'licence()' for distribution details.
>>
>>   Natural language support but running in an English locale
>>
>> R is a collaborative project with many contributors.
>> Type 'contributors()' for more
>> information and
>> 'citation()' on how to cite R or R packages in publications.
>>
>> Type 'demo()' for some demos, 'help()' for on-line help, or
>> 'help.start()' for an HTML browser interface to help.
>> Type 'q()' to quit R.
>>
>> Warning message:
>> package "methods" in options("defaultPackages") was not found
>> [Previously saved workspace restored]
>>
>> Error in readRDS(nsInfoFilePath) : unknown input format
>> During startup - Warning message:
>> package ?methods? in options("defaultPackages") was not found
>>
>>>  ?mean
>>>
>> Error in readRDS(nsInfoFilePath) : unknown input format
>>
>>>
>>>
>>
>> I have uninstall it three times and reinstall -- Every time after first
>> installation it is working perfectly.
>>
>> Then when I am closing R window and reopening it, the problem starts.
>>
>> Kindly suggest what should I do. Looking forward to hear from you,
>>
>> Best regards,
>> Amitava
>>
>>
>>
>>
>>
>> Dr. Amitava Mukherjee, Ph.D.
>> Associate Professor,
>> Production, Operations and Decision Sciences Area,
>> XLRI-Xavier School of Management, India.
>>
>>  [[alternative HTML version deleted]]
>>
>> ------------------------------
>>
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue May 17 17:43:12 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 17 May 2016 08:43:12 -0700
Subject: [R] Evaluating statistical models and describing coefficients
	for non-parametric models
In-Reply-To: <DB5PR07MB11097B567822D62EC2046841DB480@DB5PR07MB1109.eurprd07.prod.outlook.com>
References: <DB5PR07MB11097B567822D62EC2046841DB480@DB5PR07MB1109.eurprd07.prod.outlook.com>
Message-ID: <23F3D8EF-FA69-4F9C-8F4B-387E38BD5F00@dcn.davis.ca.us>

If the documentation for those models does not tell you how, then you should ask yourself whether what you are trying to do makes sense statistically. The question of what makes sense statistically is not a good fit for this forum, which is about R.

By the way, root mean square errors are easy to calculate... the hard part is knowing whether doing so is informative per above. 
-- 
Sent from my phone. Please excuse my brevity.

On May 17, 2016 3:56:56 AM PDT, Muhammad Bilal <Muhammad2.Bilal at live.uwe.ac.uk> wrote:
>Hi All,
>
>
>I'm using number of models such as lm(), tree, randomForest, svm, and
>nnet for predicting the delays in projects. Also, I computed the sum of
>squared error for all these models for comparison purposes. However, I
>want to use other related evaluation criteria such as root mean sum of
>square error (RMSE) and R Squared for evaluation of these models.
>
>
>My question is that is it possible to compute these criteria (RMSE or
>R2) for all above-mentioned statistical models.
>
>
>Second, for the lm() we can see the co-efficient values by checking
>model summary. Is it possible to see the co-efficient for other models
>such as SVM and neural network?
>
>
>Thanks in advance for the help and support.
>
>
>Many Thanks and
>
>
>Kind Regards
>
>--
>Muhammad Bilal
>Research Fellow and Doctoral Researcher,
>Bristol Enterprise, Research, and Innovation Centre (BERIC),
>University of the West of England (UWE),
>Frenchay Campus,
>Bristol,
>BS16 1QY
>
>muhammad2.bilal at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From phiroc at free.fr  Tue May 17 17:53:19 2016
From: phiroc at free.fr (phiroc at free.fr)
Date: Tue, 17 May 2016 17:53:19 +0200 (CEST)
Subject: [R] R for RedHat Linux upgrade?
In-Reply-To: <1679442688.243498963.1463500115354.JavaMail.root@zimbra65-e11.priv.proxad.net>
Message-ID: <2145567634.243512909.1463500399658.JavaMail.root@zimbra65-e11.priv.proxad.net>

Hello,

does anyone know when the R 3.3 binary for RH Linux 7 will be available from the RedHat Repository?

One of my R scripts, which uses ggplot2, works fine in RStudio 3.24 on Windows, but doesn't display any graphics in RStudio Server 3.23 on Linux RH 7.

I would like to upgrade the server's R version, but only R v. 3.23 is available from the RH Repository.

Many thanks.

Phiroc


From maitra.mbox.ignored at inbox.com  Tue May 17 18:26:59 2016
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Tue, 17 May 2016 11:26:59 -0500
Subject: [R] R for RedHat Linux upgrade?
In-Reply-To: <2145567634.243512909.1463500399658.JavaMail.root@zimbra65-e11.priv.proxad.net>
References: <1679442688.243498963.1463500115354.JavaMail.root@zimbra65-e11.priv.proxad.net>
	<2145567634.243512909.1463500399658.JavaMail.root@zimbra65-e11.priv.proxad.net>
Message-ID: <20160517112659.35f2f02d96f8e6f59b8efda8@inbox.com>

If I am not mistaken, R is not available from the RH repo. It is available from Fedora's EPEL repo for RH, CentOS and the like. I use Fedora and I have noticed that 3.3 is in testing repo there. You may want to install it and provide feedback on bodhi if you want a faster move to EPEL (and Fedora) repos.

https://bodhi.fedoraproject.org/updates/FEDORA-EPEL-2016-4a34feb770

HTH,
Ranjan

On Tue, 17 May 2016 17:53:19 +0200 <phiroc at free.fr> wrote:

> Hello,
> 
> does anyone know when the R 3.3 binary for RH Linux 7 will be available from the RedHat Repository?
> 
> One of my R scripts, which uses ggplot2, works fine in RStudio 3.24 on Windows, but doesn't display any graphics in RStudio Server 3.23 on Linux RH 7.
> 
> I would like to upgrade the server's R version, but only R v. 3.23 is available from the RH Repository.
> 
> Many thanks.
> 
> Phiroc
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From marc_schwartz at me.com  Tue May 17 18:30:48 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 17 May 2016 11:30:48 -0500
Subject: [R] R for RedHat Linux upgrade?
In-Reply-To: <2145567634.243512909.1463500399658.JavaMail.root@zimbra65-e11.priv.proxad.net>
References: <2145567634.243512909.1463500399658.JavaMail.root@zimbra65-e11.priv.proxad.net>
Message-ID: <14AD3B7F-D3E2-4475-8FE8-BDD1BAF34779@me.com>


> On May 17, 2016, at 10:53 AM, phiroc at free.fr wrote:
> 
> Hello,
> 
> does anyone know when the R 3.3 binary for RH Linux 7 will be available from the RedHat Repository?
> 
> One of my R scripts, which uses ggplot2, works fine in RStudio 3.24 on Windows, but doesn't display any graphics in RStudio Server 3.23 on Linux RH 7.
> 
> I would like to upgrade the server's R version, but only R v. 3.23 is available from the RH Repository.
> 
> Many thanks.
> 
> Phiroc


Hi,

First, RHEL and related distributions (e.g. Fedora), have a dedicated R-SIG list:

  https://stat.ethz.ch/mailman/listinfo/r-sig-fedora

Future queries in this domain should be submitted there, as many of the RH package maintainers (e.g. Tom Callaway, aka Spot) read that list.

Second, as you may be already aware, R is available via the EPEL, not the regular RH repos:

  https://fedoraproject.org/wiki/EPEL

Third, you can check the current status of RH related R builds in two places:

Bodhi, which is the RPM distribution framework - https://bodhi.fedoraproject.org/updates/?packages=R

Koji, which is the build framework - http://koji.fedoraproject.org/koji/packageinfo?packageID=1230


It would appear that Tom is in the process of preparing a 3.3.0 release, but I would defer to him on the time frame for release, which generally requires that testers provide the requisite feedback to increase the "karma" to a pre-specified level.

Regards,

Marc Schwartz


From ulhaqz at gmail.com  Tue May 17 18:44:57 2016
From: ulhaqz at gmail.com (Burhan ul haq)
Date: Tue, 17 May 2016 21:44:57 +0500
Subject: [R] Text Mining in R
Message-ID: <CADw4Cksj-v_Kmo4T2_TU58pmUSm4HT0JjpnM2vDdw5F2qYRDdQ@mail.gmail.com>

Hi,

Wishing you all well.

I am exploring text mining with R. Here is where I need help:

1. The starting point is a data frame

worder1<- c("I am, taking 2","are these the three samples?",
            "He speaks differently to you, aint it !","This is distilled -
my dear, now give me $3","I saved 2500 this month.")
df1 <- data.frame(id=1:5, words=worder1)

here in dput format:

dput(df1)
structure(list(id = 1:5, words = structure(c(3L, 1L, 2L, 5L,
4L), .Label = c("are these the three samples?", "He speaks differently to
you, aint it !",
"I am, taking 2", "I saved 2500 this month.", "This is distilled - my dear,
now give me $3"
), class = "factor")), .Names = c("id", "words"), row.names = c(NA,
-5L), class = "data.frame")


2. The corpus rituals ...

corp1 <- Corpus(VectorSource(df1$words))
inspect(corp1)
class(corp1)

corp1 <- tm_map(corp1, removeNumbers)
corp1 <- tm_map(corp1, removePunctuation)
corp1 <- tm_map(corp1, removeWords, stopwords("english"))
corp1 <- tm_map(corp1, stripWhitespace)
class(corp1)


3. Getting to the analysis

tdm1 <- TermDocumentMatrix(corp1)
inspect(tdm1[1:5,])
dtm1 <- DocumentTermMatrix(corp1)
inspect(dtm1[1:5,])

4. Now here is the problem

If I do a translation, not in getTransformations(), I am unable to convert
to tdm or dtm

corp1 <- tm_map(corp1, tolower)
class(corp1)
tdm1.2 <- TermDocumentMatrix(corp1)
dtm1.2 <- DocumentTermMatrix(corp1)

The error returned is:

Error: inherits(doc, "TextDocument") is not TRUE

5. The explaination on internet suggests either

a) corp1 <- tm_map(corp1, content_transformer(tolower))
which in my case returns error:
Error in UseMethod("content", x) :
  no applicable method for 'content' applied to an object of class
"character"

b) corpus_clean <- tm_map(corp1, PlainTextDocument)
which results in loss of all the meta data

I will appreciate any help. Lastly to keep the doc ids with R corpus,
should the step 2 be changed as:
corp1 <- Corpus(DataframeSource(df1))

from:
corp1 <- Corpus(VectorSource(df1$words))

Thanks /


-----------------------------------------------------------------------------------------------------------------------------

Some of the references I explored:
http://stackoverflow.com/questions/25638503/tm-loses-the-metadata-when-applying-tm-map
http://stackoverflow.com/questions/24191728/documenttermmatrix-error-on-corpus-argument
http://stackoverflow.com/questions/24771165/r-project-no-applicable-method-for-meta-applied-to-an-object-of-class-charact
http://stackoverflow.com/questions/25551514/termdocumentmatrix-errors-in-r
http://stackoverflow.com/questions/20699111/tm-map-error-message-in-r
http://stackoverflow.com/questions/31996891/error-in-usemethodmeta-x-no-applicable-method-for-meta-applied-to-an-ob
http://stackoverflow.com/questions/11876740/r-stemming-a-string-document-corpus

	[[alternative HTML version deleted]]


From amwootte at ncsu.edu  Tue May 17 19:02:02 2016
From: amwootte at ncsu.edu (Adrienne Wootten)
Date: Tue, 17 May 2016 13:02:02 -0400
Subject: [R] projectRaster function no values
Message-ID: <CAOV3wDDD+AxXxFqqnKPUnoNte400u-W2LJhoTSpA30oFL4iizg@mail.gmail.com>

All,

Greetings! Any help with this problem is appreciated!

I'm working to get a netcdf file that has a Lambert Conformal Conic
projection into geographic, but also a smaller area.  Here's the issue I'm
having - essentially it looks like projectRaster is working, but the
resulting raster has no values.

The data itself is massive so I can't include that, but here's what's going
on.


> testvar2 = raster("SE/test.nc",band=t,varname="TAMAX") # pulling first
time slice of my netcdf
> testvar2

class       : RasterLayer
band        : 1  (of  4  bands)
dimensions  : 229, 234, 53586  (nrow, ncol, ncell)
resolution  : 15, 15  (x, y)
extent      : -1747.5, 1762.5, -1710, 1725  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=lcc +lon_0=-77 +lat_0=38 +lat_1=30 +lat_2=60
+ellps=WGS84
data source : /projdata/dcerp/DSdata/regcmdata/SE/test.nc
names       : Avg.Max.Aneom.Temperature
z-value     : 1960-01-01
zvar        : TAMAX

> summary(testvar2) # yes is does have values
Avg.Max.Aneom.Temperature
Min.                   -23.347107
1st Qu.                 -4.706635
Median                   4.347733
3rd Qu.                 16.109032
Max.                    24.556152
NA's                     0.000000

> newlocs <- raster(ncols=length(newlon), nrows=length(newlat)) # dummy
raster with new grid I want
> projection(newlocs)=CRS("+proj=longlat +datum=WGS84")

> newlat=c(25.13511, 25.27025, 25.40538, 25.54052, 25.67565, 25.81079,
25.94592, 26.08106, 26.21619, 26.35133, 26.48646, 26.62160, 26.75673,
26.89187, 27.02700, 27.16214, 27.29727, 27.43241, 27.56754, 27.70268,
27.83781, 27.97295, 28.10808, 28.24322, 28.37835, 28.51349, 28.64862,
28.78376, 28.91889, 29.05403, 29.18916, 29.32430, 29.45943, 29.59457,
29.72970, 29.86484, 29.99997, 30.13511, 30.27024, 30.40538, 30.54051,
30.67565, 30.81078, 30.94592, 31.08105, 31.21619, 31.35132, 31.48646,
31.62159, 31.75673, 31.89186, 32.02700, 32.16213, 32.29727, 32.43240,
32.56754, 32.70267, 32.83781, 32.97294, 33.10808, 33.24321, 33.37835,
33.51348, 33.64862, 33.78375, 33.91889, 34.05402, 34.18916, 34.32429,
34.45943, 34.59456, 34.72970, 34.86483, 34.99997, 35.13510, 35.27024,
35.40537, 35.54051, 35.67564, 35.81078, 35.94591, 36.08105, 36.21618,
36.35132, 36.48645, 36.62159, 36.75672, 36.89186, 37.02699, 37.16213,
37.29726, 37.43240, 37.56753, 37.70267, 37.83780, 37.97294, 38.10807,
38.24321, 38.37834, 38.51348, 38.64861, 38.78375, 38.91888, 39.05402,
39.18915, 39.32429, 39.45942, 39.59456, 39.72969, 39.86483, 39.99996,
40.13510, 40.27023) # the new regular grid in geographic I'd like to work
with

> newlon=c(-102.97288, -102.83774, -102.70261, -102.56747, -102.43234,
-102.29720, -102.16207, -102.02693, -101.89180, -101.75666, -101.62153,
-101.48639, -101.35126, -101.21612, -101.08099, -100.94585, -100.81072,
-100.67558, -100.54045, -100.40531, -100.27018, -100.13504,  -99.99991,
 -99.86477, -99.72964, -99.59450, -99.45937, -99.32423, -99.18910,
-99.05396, -98.91883, -98.78369, -98.64856, -98.51342, -98.37829,
-98.24315, -98.10802, -97.97288, -97.83775, -97.70261, -97.56748,
-97.43234, -97.29721, -97.16207, -97.02694, -96.89180, -96.75667,
-96.62153, -96.48640, -96.35126, -96.21613, -96.08099, -95.94586,
-95.81072, -95.67559, -95.54045, -95.40532, -95.27018, -95.13505,
-94.99991, -94.86478, -94.72964, -94.59451, -94.45937, -94.32424,
-94.18910, -94.05397, -93.91883, -93.78370, -93.64856, -93.51343,
-93.37829, -93.24316, -93.10802, -92.97289, -92.83775, -92.70262,
-92.56748, -92.43235, -92.29721, -92.16208, -92.02694, -91.89181,
-91.75667, -91.62154, -91.48640, -91.35127, -91.21613, -91.08100,
-90.94586, -90.81073, -90.67559, -90.54046, -90.40532, -90.27019,
-90.13505, -89.99992, -89.86478, -89.72965, -89.59451, -89.45938,
-89.32424, -89.18911, -89.05397, -88.91884, -88.78370, -88.64857,
-88.51343, -88.37830, -88.24316, -88.10803, -87.97289, -87.83776,
-87.70262, -87.56749, -87.43235, -87.29722, -87.16208, -87.02695,
-86.89181, -86.75668, -86.62154, -86.48641, -86.35127, -86.21614,
-86.08100, -85.94587, -85.81073, -85.67560, -85.54046, -85.40533,
-85.27019, -85.13506, -84.99992, -84.86479, -84.72965, -84.59452,
-84.45938, -84.32425, -84.18911, -84.05398, -83.91884, -83.78371,
-83.64857, -83.51344, -83.37830, -83.24317, -83.10803, -82.97290,
-82.83776, -82.70263, -82.56749, -82.43236, -82.29722, -82.16209,
-82.02695, -81.89182, -81.75668, -81.62155, -81.48641, -81.35128,
-81.21614, -81.08101, -80.94587, -80.81074, -80.67560, -80.54047,
-80.40533, -80.27020, -80.13506, -79.99993, -79.86479, -79.72966,
-79.59452, -79.45939, -79.32425, -79.18912, -79.05398, -78.91885,
-78.78371, -78.64858, -78.51344, -78.37831, -78.24317, -78.10804,
-77.97290, -77.83777, -77.70263, -77.56750, -77.43236, -77.29723,
-77.16209, -77.02696, -76.89182, -76.75669, -76.62155, -76.48642,
-76.35128, -76.21615, -76.08101, -75.94588, -75.81074, -75.67561,
-75.54047, -75.40534, -75.27020, -75.13507, -74.99993, -74.86480,
-74.72966, -74.59453, -74.45939, -74.32426, -74.18912, -74.05399)

> extent(newlocs) = c(min(newlon),max(newlon),min(newlat),max(newlat)) #
dummy raster put to the right extent

> testproj2 = projectRaster(from=testvar2,to=newlocs,method="bilinear") #
project raster itself

> testproj2 # literally no values.
class       : RasterLayer
dimensions  : 113, 215, 24295  (nrow, ncol, ncell)
resolution  : 0.1345065, 0.1339391  (x, y)
extent      : -102.9729, -74.05399, 25.13511, 40.27023  (xmin, xmax, ymin,
ymax)
coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
data source : in memory
names       : Avg.Max.Aneom.Temperature
values      : NA, NA  (min, max)


I'm quite perplexed with this one, I feel like I'm doing everything right
so I'm not sure what's failing.  The R version is R 3.2.3 in a Linux/Unix
environment.

Many thanks for your help!

Adrienne
-- 
Adrienne Wootten
Ph.D Candidate / Graduate Research Assistant
State Climate Office of North Carolina
Department of Marine, Earth and Atmospheric Sciences
North Carolina State University

	[[alternative HTML version deleted]]


From fotisfotiadis at gmail.com  Tue May 17 21:39:49 2016
From: fotisfotiadis at gmail.com (Fotis Fotiadis)
Date: Tue, 17 May 2016 22:39:49 +0300
Subject: [R] gam.check() NA results (k-index,
 p-value) of a gam logistic regression model
Message-ID: <CAAO1Nnda5xYbA68O6cGi4UmcRrmsXZyGaJF=A62k0uQ75ZCDvw@mail.gmail.com>

Hello all

I am using bam for a mixec-effects logistic regression model:

b0<-bam(acc~ 1 + igc + s(ctrial, by=igc) + s(sbj, bs="re") + s(ctrial, sbj,
bs="re") , data=data, family=binomial)

>summary(b0)

Family: binomial
Link function: logit

Formula:
acc ~ 1 + igc + s(ctrial, by = igc) + s(sbj, bs = "re") + s(ctrial,
    sbj, bs = "re")

Parametric coefficients:
              Estimate Std. Error z value Pr(>|z|)
(Intercept)     2.8334     0.2030  13.955  < 2e-16 ***
igcPA.pseudo    0.4692     0.1285   3.650 0.000262 ***
igcCAT.ideo     0.3276     0.2906   1.127 0.259734
igcCAT.pseudo   0.6701     0.2945   2.275 0.022888 *
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Approximate significance of smooth terms:
                           edf Ref.df Chi.sq  p-value
s(ctrial):igcPA.ideo     3.827  4.733  295.0  < 2e-16 ***
s(ctrial):igcPA.pseudo   3.317  4.110  356.1  < 2e-16 ***
s(ctrial):igcCAT.ideo    3.979  4.911  308.6  < 2e-16 ***
s(ctrial):igcCAT.pseudo  4.937  5.974  383.8  < 2e-16 ***
s(sbj)                  54.326 62.000 3032.8  < 2e-16 ***
s(ctrial,sbj)           43.045 62.000 2706.6 1.31e-08 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

R-sq.(adj) =  0.362   Deviance explained = 38.9%
fREML =  25436  Scale est. = 1         n = 18417


I want to know if the wigglyness of the smooths [s(ctrial, by=igc)] is
appropriate, so I used the gam.check() function. The values though for
k-index and p-value are NAs:

> gam.check(b0)

Method: fREML   Optimizer: perf newton
full convergence after 5 iterations.
Gradient range [-7.60152e-08,8.12795e-06]
(score 25436.12 & scale 1).
Hessian positive definite, eigenvalue range [0.6271375,24.46625].
Model rank =  168 / 168

Basis dimension (k) checking results. Low p-value (k-index<1) may
indicate that k is too low, especially if edf is close to k'.

                           k'   edf k-index p-value
s(ctrial):igcPA.ideo     9.00  3.83      NA      NA
s(ctrial):igcPA.pseudo   9.00  3.32      NA      NA
s(ctrial):igcCAT.ideo    9.00  3.98      NA      NA
s(ctrial):igcCAT.pseudo  9.00  4.94      NA      NA
s(sbj)                  64.00 54.33      NA      NA
s(ctrial,sbj)           64.00 43.04      NA      NA

Does anyone know why is this?

Thank you in advance for your time,
Fotis

P.S. I am using RStudio Version 0.99.896, R 3.3.0, and mgcv package version
1.8.12.
--
PhD Candidate
Department of Philosophy and History of Science
University of Athens, Greece.
http://users.uoa.gr/~aprotopapas/LLL/en/members.html#fotisfotiadis

Notice: Please do not use this account for social networks invitations, for
sending chain-mails to me, or as it were a facebook account. Thank you for
respecting my privacy.

<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
???????????
??? ????. www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DDB4FAA8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed May 18 00:21:19 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 18 May 2016 08:21:19 +1000
Subject: [R] Placement of words in a word cloud as per its occurance.
In-Reply-To: <20160517110943.4853.qmail@f5mail-224-153.rediffmail.com>
References: <20160517110943.4853.qmail@f5mail-224-153.rediffmail.com>
Message-ID: <CA+8X3fXsv2Ly3XxZTPZdS5_Cqw6_iWpio0SXgTukaHmA5zmmaw@mail.gmail.com>

Hi Shailaja,
If you just want a line of words, it's not too difficult if you have
the word frequencies:

# take a common sentence
sentence<-"The quick brown fox jumps over the lazy dog"
words<-unlist(strsplit(sentence," "))
# make up some word frequencies
wordfreq<-c(10,1,2,2,3,4,10,6,5)
library(plotrix)
# scale the frequencies into a convenient range
wordcex<-rescale(wordfreq,c(0.5,2))
x11(height=4)
# a simple function to display a vector of words in different sizes
wordline<-function(words,wordcex,space=0.005) {
 plotxy<-par("usr")
 x<-plotxy[1]
 y<-sum(plotxy[3:4])/2
 space<-diff(plotxy[1:2])*space
 for(i in 1:length(words)) {
  par(cex=wordcex[i])
  text(x,y,words[i],adj=0)
  x<-x+strwidth(words[i])+space
 }
}
# get an empty plot
plot(1:10,type="n",axes=FALSE,xlab="",ylab="")
# display the words
wordline(words,wordcex)

The function can be elaborated to fit the sentence into the available
space, break it into lines, all that sort of thing.

Jim


On Tue, May 17, 2016 at 9:09 PM, shaila  shailaja
<shaila_jm at rediffmail.com> wrote:
> Dear R help subscribers,
>
>
>
>
> I am working on a word cloud where in I want the words to appear in the same order as in the sentence/text.
>
> I only know&nbsp;the random.order -&nbsp;which plots words in random order. If false, they will be plotted in decreasing frequency.
>
> &nbsp;
>
> Any help is most welcome.
>
> &nbsp;
>
> Regards
>
> Shailaja
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From milujisb at gmail.com  Wed May 18 00:26:36 2016
From: milujisb at gmail.com (Miluji Sb)
Date: Wed, 18 May 2016 00:26:36 +0200
Subject: [R] Convert Coordinates to Address - Wikimapia
Message-ID: <CAMLwc7PpRMsNJLChxw3RjnS-vgo4ZX+1YkCFD_8emWU8N=eaTg@mail.gmail.com>

Is it possible to convert latitude and longitude into addresses in R using
Wikimapia mapping instead of Google? The reason being that Wikimapia
addresses have more details.

This is the code I have been using but this obtains the information from
Google.

library(data.table)
library(ggmap)

coords<- structure(list(Lattitude = c(23.8642394, 23.8643628, 23.8645843,
23.8632958, 23.8632859), Longitude = c(90.3981852, 90.3981042,
90.3954784, 90.3940043, 90.3940025)), .Names = c("Lattitude",
"Longitude"), row.names = c(NA, 5L), class = "data.frame")

coords$textAddress <- mapply(FUN = function(lon, lat) revgeocode(c(lon,
lat)), coords$Longitude, coords$Lattitude)

Thank you!

Sincerely,

Milu

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Wed May 18 10:01:35 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 18 May 2016 10:01:35 +0200
Subject: [R] Placement of words in a word cloud as per its occurance.
In-Reply-To: <20160517110943.4853.qmail@f5mail-224-153.rediffmail.com>
References: <20160517110943.4853.qmail@f5mail-224-153.rediffmail.com>
Message-ID: <CCA9E1CF-FCC4-4953-83A2-52E5BEAF1CF1@gmail.com>

A few points of order; you seem to be making a couple of rookie mistakes here. (Don't take it personally, lots of people do).

1) Posting in HTML comes across garbled (and it can get much worse than what you see below), so please configure you mail program to avoid doing that.

2) You seem to assume that we all immediately recognize the task you are working on and that there is a well-known and generally accepted methodology for which we just need to supply some detail that you have overlooked. In fact, the majority will be doing things in hundreds of different directions, and even those who are into wordclouds may be taking different approaches to it, there could be implementations in several packages, etc. Some people might be mildly interested in helping out (perhaps they want to make a wordcloud for themselves one day), but they would need to know what code you are using. As it stands, people are left wondering which function it might be that has an argument called random.order.

- Peter Dalgaard

On 17 May 2016, at 13:09 , shaila shailaja <shaila_jm at rediffmail.com> wrote:

> Dear R help subscribers,
> 
> 
> 
> 
> I am working on a word cloud where in I want the words to appear in the same order as in the sentence/text. 
> 
> I only know&nbsp;the random.order -&nbsp;which plots words in random order. If false, they will be plotted in decreasing frequency.
> 
> &nbsp;
> 
> Any help is most welcome.
> 
> &nbsp;
> 
> Regards
> 
> Shailaja
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From simon.wood at bath.edu  Wed May 18 11:05:56 2016
From: simon.wood at bath.edu (Simon Wood)
Date: Wed, 18 May 2016 10:05:56 +0100
Subject: [R] gam.check() NA results (k-index,
 p-value) of a gam logistic regression model
In-Reply-To: <CAAO1Nnda5xYbA68O6cGi4UmcRrmsXZyGaJF=A62k0uQ75ZCDvw@mail.gmail.com>
References: <CAAO1Nnda5xYbA68O6cGi4UmcRrmsXZyGaJF=A62k0uQ75ZCDvw@mail.gmail.com>
Message-ID: <573C3074.6030800@bath.edu>

Dear Fotis,

The test is a randomization test, based on comparing differences of 
residuals, ordered with respect to the covariate of the smooth, to 
differences of residuals in randomized order. Random effect terms are 
excluded because there is not basis size to choose. Currently smooths 
with factor by variables are also excluded for reasons of maintainer 
laziness, as this would require special case code to exclude the 
covariate values that are irrelevant given the factor level. Sorry about 
that.

My guess is that you don't have a problem here anyway, given the fairly 
low edfs relative to the basis dimension. In general as a double check I 
would plot the residuals against ctrial, colour coded by level of igc, 
just to check that there doesn't seem to be missed pattern in them. 
However with binary residuals you are unlikely to see much.

best,
Simon

On 17/05/16 20:39, Fotis Fotiadis wrote:
> Hello all
>
> I am using bam for a mixec-effects logistic regression model:
>
> b0<-bam(acc~ 1 + igc + s(ctrial, by=igc) + s(sbj, bs="re") + s(ctrial, sbj,
> bs="re") , data=data, family=binomial)
>
>> summary(b0)
> Family: binomial
> Link function: logit
>
> Formula:
> acc ~ 1 + igc + s(ctrial, by = igc) + s(sbj, bs = "re") + s(ctrial,
>      sbj, bs = "re")
>
> Parametric coefficients:
>                Estimate Std. Error z value Pr(>|z|)
> (Intercept)     2.8334     0.2030  13.955  < 2e-16 ***
> igcPA.pseudo    0.4692     0.1285   3.650 0.000262 ***
> igcCAT.ideo     0.3276     0.2906   1.127 0.259734
> igcCAT.pseudo   0.6701     0.2945   2.275 0.022888 *
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Approximate significance of smooth terms:
>                             edf Ref.df Chi.sq  p-value
> s(ctrial):igcPA.ideo     3.827  4.733  295.0  < 2e-16 ***
> s(ctrial):igcPA.pseudo   3.317  4.110  356.1  < 2e-16 ***
> s(ctrial):igcCAT.ideo    3.979  4.911  308.6  < 2e-16 ***
> s(ctrial):igcCAT.pseudo  4.937  5.974  383.8  < 2e-16 ***
> s(sbj)                  54.326 62.000 3032.8  < 2e-16 ***
> s(ctrial,sbj)           43.045 62.000 2706.6 1.31e-08 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> R-sq.(adj) =  0.362   Deviance explained = 38.9%
> fREML =  25436  Scale est. = 1         n = 18417
>
>
> I want to know if the wigglyness of the smooths [s(ctrial, by=igc)] is
> appropriate, so I used the gam.check() function. The values though for
> k-index and p-value are NAs:
>
>> gam.check(b0)
> Method: fREML   Optimizer: perf newton
> full convergence after 5 iterations.
> Gradient range [-7.60152e-08,8.12795e-06]
> (score 25436.12 & scale 1).
> Hessian positive definite, eigenvalue range [0.6271375,24.46625].
> Model rank =  168 / 168
>
> Basis dimension (k) checking results. Low p-value (k-index<1) may
> indicate that k is too low, especially if edf is close to k'.
>
>                             k'   edf k-index p-value
> s(ctrial):igcPA.ideo     9.00  3.83      NA      NA
> s(ctrial):igcPA.pseudo   9.00  3.32      NA      NA
> s(ctrial):igcCAT.ideo    9.00  3.98      NA      NA
> s(ctrial):igcCAT.pseudo  9.00  4.94      NA      NA
> s(sbj)                  64.00 54.33      NA      NA
> s(ctrial,sbj)           64.00 43.04      NA      NA
>
> Does anyone know why is this?
>
> Thank you in advance for your time,
> Fotis
>
> P.S. I am using RStudio Version 0.99.896, R 3.3.0, and mgcv package version
> 1.8.12.
> --
> PhD Candidate
> Department of Philosophy and History of Science
> University of Athens, Greece.
> http://users.uoa.gr/~aprotopapas/LLL/en/members.html#fotisfotiadis
>
> Notice: Please do not use this account for social networks invitations, for
> sending chain-mails to me, or as it were a facebook account. Thank you for
> respecting my privacy.
>
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> ???????????
> ??? ????. www.avast.com
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> <#DDB4FAA8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Simon Wood, School of Mathematics, University of Bristol BS8 1TW UK
+44 (0)117 33 18273     http://www.maths.bris.ac.uk/~sw15190


From phiroc at free.fr  Wed May 18 09:32:47 2016
From: phiroc at free.fr (phiroc at free.fr)
Date: Wed, 18 May 2016 09:32:47 +0200 (CEST)
Subject: [R] ggplot2 not displaying graph in RH7 RStudio Server 3.2.3
In-Reply-To: <708761975.245281298.1463556026062.JavaMail.root@zimbra65-e11.priv.proxad.net>
Message-ID: <1059396733.245332385.1463556767475.JavaMail.root@zimbra65-e11.priv.proxad.net>


Hello,

I have written an R script which displays a bar chart using the ggplot2 library (please refer
to code excerpt at the bottom of this e-mail).

Although the bar chart is displayed OK in the Windows version of RStudio (v. 3.2.4),
nothing appears on Linux RH 7 in Rstudio Server 3.2.3.

I have tried replacing the data frame in the RH-version of the script by 

---------------------------------------------------------------------------

a <- c("ab", "bc", "cd")
b <- c(1, 2, 3)
ds <- data.frame(a,b)
g1 <- ggplot(data = ds, aes(x = a))


----------------------------------------------------------------------------

... but to avail: ggplot doesn't plot anything. No error message are displayed.

Any help with this issue would be much appreciated.

Many thanks.

phiroc


----------------------------- R Code Excerpt -------------------------------


g1 <- ggplot(data = mergedD, aes(x=DESC_TYPE))
g1 + geom_bar(stat="count", fill=rainbow(numberOfDistinctActions), colour="black") +
  xlab("Action & Description") +
  ylab("Count")  +
  ggtitle(paste0(
  "Number of Customer Actions in XXX from ", day0, "/", mon,
  "/", year, " to ", day1, "/", mon, "/", year,
  " in Paris & Hong Kong")) +
  coord_flip()


From shaila_jm at rediffmail.com  Wed May 18 09:06:54 2016
From: shaila_jm at rediffmail.com (shaila  shailaja)
Date: 18 May 2016 07:06:54 -0000
Subject: [R]
	=?utf-8?q?Placement_of_words_in_a_word_cloud_as_per_its_occur?=
	=?utf-8?q?ance=2E?=
Message-ID: <1463523735.S.7038.26467.f5-224-130.1463555213.4698@webmail.rediffmail.com>

Hi Jim,




Thank you for the reply.




Is there a way out to use it with wordcloud package and built a comparative and commonality cloud. 




My usage: 




comparison.cloud(term.matrix,max.words=300)&nbsp;&nbsp; commonality.cloud(term.matrix,random.order=FALSE, rot.per=0)




I am already&nbsp;doing a lot of preprocessing and the sentence is not limited to 1 or 2.




Thanks,

ShailajaFrom: Jim Lemon &lt;drjimlemon at gmail.com&gt;Sent: Wed, 18 May 2016 03:52:15 To: shaila shailaja &lt;shaila_jm at rediffmail.com&gt;Cc: "r-help at r-project.org" &lt;r-help at r-project.org&gt;Subject: Re: [R] Placement of words in a word cloud as per its occurance.Hi Shailaja,If you just want a line of words, it's not too difficult if you havethe word frequencies:# take a common sentencesentence&lt;-"The quick brown fox jumps over the lazy dog"words&lt;-unlist(strsplit(sentence," "))# make up some word frequencieswordfreq&lt;-c(10,1,2,2,3,4,10,6,5)library(plotrix)# scale the frequencies into a convenient rangewordcex&lt;-rescale(wordfreq,c(0.5,2))x11(height=4)# a simple function to display a vector of words in different sizeswordline&lt;-function(words,wordcex,space=0.005) {plotxy&lt;-par("usr")x&lt;-plotxy[1]y&lt;-sum(plotxy[3:4])/2space&lt;-diff(plotxy[1:2])*spacefor(i in 1:length(words)) {&nbsp;par(cex=wordcex[i])&nbsp;text(x,y,words[i],adj=0)&nbsp;x&lt;-x+strwidth(words[i])+space}}# get an empty plotplot(1:10,type="n",axes=FALSE,xlab="",ylab="")# display the wordswordline(words,wordcex)The function can be elaborated to fit the sentence into the availablespace, break it into lines, all that sort of thing.JimOn Tue, May 17, 2016 at 9:09 PM, shaila &nbsp;shailaja&lt;shaila_jm at rediffmail.com&gt; wrote:&gt; Dear R help subscribers,&gt;&gt;&gt;&gt;&gt; I am working on a word cloud where in I want the words to appear in the same order as in the sentence/text.&gt;&gt; I only know&amp;nbsp;the random.order -&amp;nbsp;which plots words in random order. If false, they will be plotted in decreasing frequency.&gt;&gt; &amp;nbsp;&gt;&gt; Any help is most welcome.&gt;&gt; &amp;nbsp;&gt;&gt; Regards&gt;&gt; Shailaja&gt; &nbsp; &nbsp; &nbsp; &nbsp; [[alternative HTML version deleted]]&gt;&gt; ______________________________________________&gt; R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see&gt; https://stat.ethz.ch/mailman/listinfo/r-help&gt; PLEASE do read the posting guide http://www.R-project.org/posting-g
uide.html&gt; and provide commented, minimal, self-contained, reproducible code.______________________________________________R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, seehttps://stat.ethz.ch/mailman/listinfo/r-helpPLEASE do read the posting guide http://www.R-project.org/posting-guide.htmland provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed May 18 14:36:50 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 18 May 2016 05:36:50 -0700
Subject: [R] ggplot2 not displaying graph in RH7 RStudio Server 3.2.3
In-Reply-To: <1059396733.245332385.1463556767475.JavaMail.root@zimbra65-e11.priv.proxad.net>
References: <1059396733.245332385.1463556767475.JavaMail.root@zimbra65-e11.priv.proxad.net>
Message-ID: <10EA9A31-D825-4591-B1C7-904CE0F0672F@dcn.davis.ca.us>

Context is everything.  Please follow the Posting Guide and provide a minimal reproducible example. Also,  if your scripts are literally the same on the two platforms, you should provide the output of the sessionInfo() function for each. 
-- 
Sent from my phone. Please excuse my brevity.

On May 18, 2016 12:32:47 AM PDT, phiroc at free.fr wrote:
>
>Hello,
>
>I have written an R script which displays a bar chart using the ggplot2
>library (please refer
>to code excerpt at the bottom of this e-mail).
>
>Although the bar chart is displayed OK in the Windows version of
>RStudio (v. 3.2.4),
>nothing appears on Linux RH 7 in Rstudio Server 3.2.3.
>
>I have tried replacing the data frame in the RH-version of the script
>by 
>
>---------------------------------------------------------------------------
>
>a <- c("ab", "bc", "cd")
>b <- c(1, 2, 3)
>ds <- data.frame(a,b)
>g1 <- ggplot(data = ds, aes(x = a))
>
>
>----------------------------------------------------------------------------
>
>... but to avail: ggplot doesn't plot anything. No error message are
>displayed.
>
>Any help with this issue would be much appreciated.
>
>Many thanks.
>
>phiroc
>
>
>----------------------------- R Code Excerpt
>-------------------------------
>
>
>g1 <- ggplot(data = mergedD, aes(x=DESC_TYPE))
>g1 + geom_bar(stat="count", fill=rainbow(numberOfDistinctActions),
>colour="black") +
>  xlab("Action & Description") +
>  ylab("Count")  +
>  ggtitle(paste0(
>  "Number of Customer Actions in XXX from ", day0, "/", mon,
>  "/", year, " to ", day1, "/", mon, "/", year,
>  " in Paris & Hong Kong")) +
>  coord_flip()
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From btupper at bigelow.org  Wed May 18 15:05:17 2016
From: btupper at bigelow.org (Ben Tupper)
Date: Wed, 18 May 2016 09:05:17 -0400
Subject: [R] projectRaster function no values
In-Reply-To: <CAOV3wDDD+AxXxFqqnKPUnoNte400u-W2LJhoTSpA30oFL4iizg@mail.gmail.com>
References: <CAOV3wDDD+AxXxFqqnKPUnoNte400u-W2LJhoTSpA30oFL4iizg@mail.gmail.com>
Message-ID: <92F7E069-1DCE-4705-98F8-BB113D0FD8B7@bigelow.org>

Hi Adrienne,

You'll always get great help for these kinds of questions if you subscribe and post to the R-SIG-Geo mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-geo  I highly recommend that you join!

I have encountered this before, and usually it is because I have mistakenly assumed that source and destination data are roughly coincident.  I'm not sure if that is true in your case. I have tried to replicate your steps.  I transformed the coordinates of your source and destination rasters into SpatialPoints objects, and then I reprojected your source coordinates to the projection of your destination coordinates.  Unless I have messed up a step, you can see in the plot generated that there is a significant difference in the extent of the source and destination rasters.  Perhaps your destination coordinates are amiss?

Cheers,
Ben


### Start
library(sp)
library(raster)

nc <- 234
nr <- 229
m <- matrix(runif(nc*nr), ncol = nc, nrow = nr)
r1 <- raster(m, xmn = -1747.5, xmx = 1762.5, ymn = -1710, ymx = 1725,
    crs = CRS('+proj=lcc +lon_0=-77 +lat_0=38 +lat_1=30 +lat_2=60'))

newlon <- c(-102.97288, -74.05399)
newlat <- c(25.13511, 40.27023)
newnr <- 113
newnc <- 215
template <- raster(nrows = newnr, ncol = newnc,
    xmn = newlon[1], xmx = newlon[2],
    ymn = newlat[1], ymx = newlat[2],
    crs = CRS("+proj=longlat +datum=WGS84")) 

r2 <- setValues(template, runif(ncell(template)))    

xy_r1 <- SpatialPoints(coordinates(r1),
    proj4string = CRS('+proj=lcc +lon_0=-77 +lat_0=38 +lat_1=30 +lat_2=60'))
xy_r1_tr <- spTransform(xy_r1, CRS("+proj=longlat +datum=WGS84"))


xy_r2 <- SpatialPoints(coordinates(r2),
    proj4string = CRS("+proj=longlat +datum=WGS84"))

plot(xy_r2, pch = '.', axes = TRUE)
points(xy_r1_tr, pch = 1, col = 'orange')

### END

> On May 17, 2016, at 1:02 PM, Adrienne Wootten <amwootte at ncsu.edu> wrote:
> 
> All,
> 
> Greetings! Any help with this problem is appreciated!
> 
> I'm working to get a netcdf file that has a Lambert Conformal Conic
> projection into geographic, but also a smaller area.  Here's the issue I'm
> having - essentially it looks like projectRaster is working, but the
> resulting raster has no values.
> 
> The data itself is massive so I can't include that, but here's what's going
> on.
> 
> 
>> testvar2 = raster("SE/test.nc",band=t,varname="TAMAX") # pulling first
> time slice of my netcdf
>> testvar2
> 
> class       : RasterLayer
> band        : 1  (of  4  bands)
> dimensions  : 229, 234, 53586  (nrow, ncol, ncell)
> resolution  : 15, 15  (x, y)
> extent      : -1747.5, 1762.5, -1710, 1725  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=lcc +lon_0=-77 +lat_0=38 +lat_1=30 +lat_2=60
> +ellps=WGS84
> data source : /projdata/dcerp/DSdata/regcmdata/SE/test.nc
> names       : Avg.Max.Aneom.Temperature
> z-value     : 1960-01-01
> zvar        : TAMAX
> 
>> summary(testvar2) # yes is does have values
> Avg.Max.Aneom.Temperature
> Min.                   -23.347107
> 1st Qu.                 -4.706635
> Median                   4.347733
> 3rd Qu.                 16.109032
> Max.                    24.556152
> NA's                     0.000000
> 
>> newlocs <- raster(ncols=length(newlon), nrows=length(newlat)) # dummy
> raster with new grid I want
>> projection(newlocs)=CRS("+proj=longlat +datum=WGS84")
> 
>> newlat=c(25.13511, 25.27025, 25.40538, 25.54052, 25.67565, 25.81079,
> 25.94592, 26.08106, 26.21619, 26.35133, 26.48646, 26.62160, 26.75673,
> 26.89187, 27.02700, 27.16214, 27.29727, 27.43241, 27.56754, 27.70268,
> 27.83781, 27.97295, 28.10808, 28.24322, 28.37835, 28.51349, 28.64862,
> 28.78376, 28.91889, 29.05403, 29.18916, 29.32430, 29.45943, 29.59457,
> 29.72970, 29.86484, 29.99997, 30.13511, 30.27024, 30.40538, 30.54051,
> 30.67565, 30.81078, 30.94592, 31.08105, 31.21619, 31.35132, 31.48646,
> 31.62159, 31.75673, 31.89186, 32.02700, 32.16213, 32.29727, 32.43240,
> 32.56754, 32.70267, 32.83781, 32.97294, 33.10808, 33.24321, 33.37835,
> 33.51348, 33.64862, 33.78375, 33.91889, 34.05402, 34.18916, 34.32429,
> 34.45943, 34.59456, 34.72970, 34.86483, 34.99997, 35.13510, 35.27024,
> 35.40537, 35.54051, 35.67564, 35.81078, 35.94591, 36.08105, 36.21618,
> 36.35132, 36.48645, 36.62159, 36.75672, 36.89186, 37.02699, 37.16213,
> 37.29726, 37.43240, 37.56753, 37.70267, 37.83780, 37.97294, 38.10807,
> 38.24321, 38.37834, 38.51348, 38.64861, 38.78375, 38.91888, 39.05402,
> 39.18915, 39.32429, 39.45942, 39.59456, 39.72969, 39.86483, 39.99996,
> 40.13510, 40.27023) # the new regular grid in geographic I'd like to work
> with
> 
>> newlon=c(-102.97288, -102.83774, -102.70261, -102.56747, -102.43234,
> -102.29720, -102.16207, -102.02693, -101.89180, -101.75666, -101.62153,
> -101.48639, -101.35126, -101.21612, -101.08099, -100.94585, -100.81072,
> -100.67558, -100.54045, -100.40531, -100.27018, -100.13504,  -99.99991,
> -99.86477, -99.72964, -99.59450, -99.45937, -99.32423, -99.18910,
> -99.05396, -98.91883, -98.78369, -98.64856, -98.51342, -98.37829,
> -98.24315, -98.10802, -97.97288, -97.83775, -97.70261, -97.56748,
> -97.43234, -97.29721, -97.16207, -97.02694, -96.89180, -96.75667,
> -96.62153, -96.48640, -96.35126, -96.21613, -96.08099, -95.94586,
> -95.81072, -95.67559, -95.54045, -95.40532, -95.27018, -95.13505,
> -94.99991, -94.86478, -94.72964, -94.59451, -94.45937, -94.32424,
> -94.18910, -94.05397, -93.91883, -93.78370, -93.64856, -93.51343,
> -93.37829, -93.24316, -93.10802, -92.97289, -92.83775, -92.70262,
> -92.56748, -92.43235, -92.29721, -92.16208, -92.02694, -91.89181,
> -91.75667, -91.62154, -91.48640, -91.35127, -91.21613, -91.08100,
> -90.94586, -90.81073, -90.67559, -90.54046, -90.40532, -90.27019,
> -90.13505, -89.99992, -89.86478, -89.72965, -89.59451, -89.45938,
> -89.32424, -89.18911, -89.05397, -88.91884, -88.78370, -88.64857,
> -88.51343, -88.37830, -88.24316, -88.10803, -87.97289, -87.83776,
> -87.70262, -87.56749, -87.43235, -87.29722, -87.16208, -87.02695,
> -86.89181, -86.75668, -86.62154, -86.48641, -86.35127, -86.21614,
> -86.08100, -85.94587, -85.81073, -85.67560, -85.54046, -85.40533,
> -85.27019, -85.13506, -84.99992, -84.86479, -84.72965, -84.59452,
> -84.45938, -84.32425, -84.18911, -84.05398, -83.91884, -83.78371,
> -83.64857, -83.51344, -83.37830, -83.24317, -83.10803, -82.97290,
> -82.83776, -82.70263, -82.56749, -82.43236, -82.29722, -82.16209,
> -82.02695, -81.89182, -81.75668, -81.62155, -81.48641, -81.35128,
> -81.21614, -81.08101, -80.94587, -80.81074, -80.67560, -80.54047,
> -80.40533, -80.27020, -80.13506, -79.99993, -79.86479, -79.72966,
> -79.59452, -79.45939, -79.32425, -79.18912, -79.05398, -78.91885,
> -78.78371, -78.64858, -78.51344, -78.37831, -78.24317, -78.10804,
> -77.97290, -77.83777, -77.70263, -77.56750, -77.43236, -77.29723,
> -77.16209, -77.02696, -76.89182, -76.75669, -76.62155, -76.48642,
> -76.35128, -76.21615, -76.08101, -75.94588, -75.81074, -75.67561,
> -75.54047, -75.40534, -75.27020, -75.13507, -74.99993, -74.86480,
> -74.72966, -74.59453, -74.45939, -74.32426, -74.18912, -74.05399)
> 
>> extent(newlocs) = c(min(newlon),max(newlon),min(newlat),max(newlat)) #
> dummy raster put to the right extent
> 
>> testproj2 = projectRaster(from=testvar2,to=newlocs,method="bilinear") #
> project raster itself
> 
>> testproj2 # literally no values.
> class       : RasterLayer
> dimensions  : 113, 215, 24295  (nrow, ncol, ncell)
> resolution  : 0.1345065, 0.1339391  (x, y)
> extent      : -102.9729, -74.05399, 25.13511, 40.27023  (xmin, xmax, ymin,
> ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> data source : in memory
> names       : Avg.Max.Aneom.Temperature
> values      : NA, NA  (min, max)
> 
> 
> I'm quite perplexed with this one, I feel like I'm doing everything right
> so I'm not sure what's failing.  The R version is R 3.2.3 in a Linux/Unix
> environment.
> 
> Many thanks for your help!
> 
> Adrienne
> -- 
> Adrienne Wootten
> Ph.D Candidate / Graduate Research Assistant
> State Climate Office of North Carolina
> Department of Marine, Earth and Atmospheric Sciences
> North Carolina State University
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From j.logsdon at quantex-research.com  Wed May 18 15:32:49 2016
From: j.logsdon at quantex-research.com (John Logsdon)
Date: Wed, 18 May 2016 14:32:49 +0100
Subject: [R] Vectorised operations
Message-ID: <57342100db38c7a9ac572036b30008d8.squirrel@quantex.zedcore.com>

Folks

I have some very long vectors - typically 1 million long - which are
indexed by another vector, same length, with values from 1 to a few
thousand, sp each sub part of the vector may be a few hundred values long.

I want to calculate the cumulative maximum of each sub part the main
vector by the index in an efficient manner.  This can obviously be done in
a loop but the whole calculation is embedded within many other
calculations which would make everything very slow indeed.  All the other
sums are vectorised already.

For example,

A=c(1,2,1,  -3,5,6,7,4,  6,3,7,6,9, ...)
i=c(1,1,1,   2,2,2,2,2,  3,3,3,3,3, ...)

where A has three levels that are not the same but the levels themselves
are all monotonic non-decreasing.

the answer to be a vector of the same length:

R=c(1,2,2,  -3,5,6,7,7,  6,6,7,7,9, ...)

If I could reset the cumulative maximum to -1e6 (eg) at each change of
index, a simple cummax would do but I can't see how to do this.

The best way I have found so far is to use the aggregate command:

as.vector(unlist(aggregate(a,list(i),cummax)[[2]]))

but rarely this fails, returning a shorter vector than expected and seems
rather ugly,  converting to and from lists which may well be an
unnecessary overhead.

I have been trying other approaches using apply() methods but either it
can't be done using them or I can't get my head round them!

Any ideas?

Best wishes

John

John Logsdon
Quantex Research Ltd
+44 161 445 4951/+44 7717758675


From amwootte at ncsu.edu  Wed May 18 16:00:49 2016
From: amwootte at ncsu.edu (Adrienne Wootten)
Date: Wed, 18 May 2016 10:00:49 -0400
Subject: [R] projectRaster function no values
In-Reply-To: <92F7E069-1DCE-4705-98F8-BB113D0FD8B7@bigelow.org>
References: <CAOV3wDDD+AxXxFqqnKPUnoNte400u-W2LJhoTSpA30oFL4iizg@mail.gmail.com>
	<92F7E069-1DCE-4705-98F8-BB113D0FD8B7@bigelow.org>
Message-ID: <CAOV3wDA5MFZuyVgEPmZUaYh6bUHA6sUG-TziBsP3QhS1q0M_7w@mail.gmail.com>

Ben,

Thanks so for much for the heads up on R-sig-geo (totally forgot about that
one myself).  Thank you also for the clue, it gave me a poke in the right
direction to figure it out.  I'll share with the group just in case someone
else runs across this.  It was actually something off with the resolution
and extent in the source data.

> t=1
> testvar2 = raster("SE/test.nc",band=t,varname="TAMAX") # pulling first
time slice of my netcdf
> testvar2

class       : RasterLayer
band        : 1  (of  4  bands)
dimensions  : 229, 234, 53586  (nrow, ncol, ncell)
resolution  : 15, 15  (x, y)
extent      : -1747.5, 1762.5, -1710, 1725  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=lcc +lon_0=-77 +lat_0=38 +lat_1=30 +lat_2=60
+ellps=WGS84
data source : /projdata/dcerp/DSdata/regcmdata/SE/test.nc
names       : Avg.Max.Aneom.Temperature
z-value     : 1960-01-01
zvar        : TAMAX

The CRS in the file was giving the resolution as 15, but in reality this is
a 15km resolution dataset and should cover an area from 20N to 50N and
about 100W to 50W.  R was interpreting the resolution as 15m, which caused
it to have the small extent, instead of what it should have been, which is
covering Eastern North America.   I had to mess with the resolution and
extent a bit, but once I did it worked beautifully with projectRaster.

Thanks again!

Adrienne

-- 
Adrienne Wootten
Ph.D Candidate / Graduate Research Assistant
State Climate Office of North Carolina
Department of Marine, Earth and Atmospheric Sciences
North Carolina State University


On Wed, May 18, 2016 at 9:05 AM, Ben Tupper <btupper at bigelow.org> wrote:

> Hi Adrienne,
>
> You'll always get great help for these kinds of questions if you subscribe
> and post to the R-SIG-Geo mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo  I highly recommend that
> you join!
>
> I have encountered this before, and usually it is because I have
> mistakenly assumed that source and destination data are roughly
> coincident.  I'm not sure if that is true in your case. I have tried to
> replicate your steps.  I transformed the coordinates of your source and
> destination rasters into SpatialPoints objects, and then I reprojected your
> source coordinates to the projection of your destination coordinates.
> Unless I have messed up a step, you can see in the plot generated that
> there is a significant difference in the extent of the source and
> destination rasters.  Perhaps your destination coordinates are amiss?
>
> Cheers,
> Ben
>
>
> ### Start
> library(sp)
> library(raster)
>
> nc <- 234
> nr <- 229
> m <- matrix(runif(nc*nr), ncol = nc, nrow = nr)
> r1 <- raster(m, xmn = -1747.5, xmx = 1762.5, ymn = -1710, ymx = 1725,
>     crs = CRS('+proj=lcc +lon_0=-77 +lat_0=38 +lat_1=30 +lat_2=60'))
>
> newlon <- c(-102.97288, -74.05399)
> newlat <- c(25.13511, 40.27023)
> newnr <- 113
> newnc <- 215
> template <- raster(nrows = newnr, ncol = newnc,
>     xmn = newlon[1], xmx = newlon[2],
>     ymn = newlat[1], ymx = newlat[2],
>     crs = CRS("+proj=longlat +datum=WGS84"))
>
> r2 <- setValues(template, runif(ncell(template)))
>
> xy_r1 <- SpatialPoints(coordinates(r1),
>     proj4string = CRS('+proj=lcc +lon_0=-77 +lat_0=38 +lat_1=30
> +lat_2=60'))
> xy_r1_tr <- spTransform(xy_r1, CRS("+proj=longlat +datum=WGS84"))
>
>
> xy_r2 <- SpatialPoints(coordinates(r2),
>     proj4string = CRS("+proj=longlat +datum=WGS84"))
>
> plot(xy_r2, pch = '.', axes = TRUE)
> points(xy_r1_tr, pch = 1, col = 'orange')
>
> ### END
>
> > On May 17, 2016, at 1:02 PM, Adrienne Wootten <amwootte at ncsu.edu> wrote:
> >
> > All,
> >
> > Greetings! Any help with this problem is appreciated!
> >
> > I'm working to get a netcdf file that has a Lambert Conformal Conic
> > projection into geographic, but also a smaller area.  Here's the issue
> I'm
> > having - essentially it looks like projectRaster is working, but the
> > resulting raster has no values.
> >
> > The data itself is massive so I can't include that, but here's what's
> going
> > on.
> >
> >
> >> testvar2 = raster("SE/test.nc",band=t,varname="TAMAX") # pulling first
> > time slice of my netcdf
> >> testvar2
> >
> > class       : RasterLayer
> > band        : 1  (of  4  bands)
> > dimensions  : 229, 234, 53586  (nrow, ncol, ncell)
> > resolution  : 15, 15  (x, y)
> > extent      : -1747.5, 1762.5, -1710, 1725  (xmin, xmax, ymin, ymax)
> > coord. ref. : +proj=lcc +lon_0=-77 +lat_0=38 +lat_1=30 +lat_2=60
> > +ellps=WGS84
> > data source : /projdata/dcerp/DSdata/regcmdata/SE/test.nc
> > names       : Avg.Max.Aneom.Temperature
> > z-value     : 1960-01-01
> > zvar        : TAMAX
> >
> >> summary(testvar2) # yes is does have values
> > Avg.Max.Aneom.Temperature
> > Min.                   -23.347107
> > 1st Qu.                 -4.706635
> > Median                   4.347733
> > 3rd Qu.                 16.109032
> > Max.                    24.556152
> > NA's                     0.000000
> >
> >> newlocs <- raster(ncols=length(newlon), nrows=length(newlat)) # dummy
> > raster with new grid I want
> >> projection(newlocs)=CRS("+proj=longlat +datum=WGS84")
> >
> >> newlat=c(25.13511, 25.27025, 25.40538, 25.54052, 25.67565, 25.81079,
> > 25.94592, 26.08106, 26.21619, 26.35133, 26.48646, 26.62160, 26.75673,
> > 26.89187, 27.02700, 27.16214, 27.29727, 27.43241, 27.56754, 27.70268,
> > 27.83781, 27.97295, 28.10808, 28.24322, 28.37835, 28.51349, 28.64862,
> > 28.78376, 28.91889, 29.05403, 29.18916, 29.32430, 29.45943, 29.59457,
> > 29.72970, 29.86484, 29.99997, 30.13511, 30.27024, 30.40538, 30.54051,
> > 30.67565, 30.81078, 30.94592, 31.08105, 31.21619, 31.35132, 31.48646,
> > 31.62159, 31.75673, 31.89186, 32.02700, 32.16213, 32.29727, 32.43240,
> > 32.56754, 32.70267, 32.83781, 32.97294, 33.10808, 33.24321, 33.37835,
> > 33.51348, 33.64862, 33.78375, 33.91889, 34.05402, 34.18916, 34.32429,
> > 34.45943, 34.59456, 34.72970, 34.86483, 34.99997, 35.13510, 35.27024,
> > 35.40537, 35.54051, 35.67564, 35.81078, 35.94591, 36.08105, 36.21618,
> > 36.35132, 36.48645, 36.62159, 36.75672, 36.89186, 37.02699, 37.16213,
> > 37.29726, 37.43240, 37.56753, 37.70267, 37.83780, 37.97294, 38.10807,
> > 38.24321, 38.37834, 38.51348, 38.64861, 38.78375, 38.91888, 39.05402,
> > 39.18915, 39.32429, 39.45942, 39.59456, 39.72969, 39.86483, 39.99996,
> > 40.13510, 40.27023) # the new regular grid in geographic I'd like to work
> > with
> >
> >> newlon=c(-102.97288, -102.83774, -102.70261, -102.56747, -102.43234,
> > -102.29720, -102.16207, -102.02693, -101.89180, -101.75666, -101.62153,
> > -101.48639, -101.35126, -101.21612, -101.08099, -100.94585, -100.81072,
> > -100.67558, -100.54045, -100.40531, -100.27018, -100.13504,  -99.99991,
> > -99.86477, -99.72964, -99.59450, -99.45937, -99.32423, -99.18910,
> > -99.05396, -98.91883, -98.78369, -98.64856, -98.51342, -98.37829,
> > -98.24315, -98.10802, -97.97288, -97.83775, -97.70261, -97.56748,
> > -97.43234, -97.29721, -97.16207, -97.02694, -96.89180, -96.75667,
> > -96.62153, -96.48640, -96.35126, -96.21613, -96.08099, -95.94586,
> > -95.81072, -95.67559, -95.54045, -95.40532, -95.27018, -95.13505,
> > -94.99991, -94.86478, -94.72964, -94.59451, -94.45937, -94.32424,
> > -94.18910, -94.05397, -93.91883, -93.78370, -93.64856, -93.51343,
> > -93.37829, -93.24316, -93.10802, -92.97289, -92.83775, -92.70262,
> > -92.56748, -92.43235, -92.29721, -92.16208, -92.02694, -91.89181,
> > -91.75667, -91.62154, -91.48640, -91.35127, -91.21613, -91.08100,
> > -90.94586, -90.81073, -90.67559, -90.54046, -90.40532, -90.27019,
> > -90.13505, -89.99992, -89.86478, -89.72965, -89.59451, -89.45938,
> > -89.32424, -89.18911, -89.05397, -88.91884, -88.78370, -88.64857,
> > -88.51343, -88.37830, -88.24316, -88.10803, -87.97289, -87.83776,
> > -87.70262, -87.56749, -87.43235, -87.29722, -87.16208, -87.02695,
> > -86.89181, -86.75668, -86.62154, -86.48641, -86.35127, -86.21614,
> > -86.08100, -85.94587, -85.81073, -85.67560, -85.54046, -85.40533,
> > -85.27019, -85.13506, -84.99992, -84.86479, -84.72965, -84.59452,
> > -84.45938, -84.32425, -84.18911, -84.05398, -83.91884, -83.78371,
> > -83.64857, -83.51344, -83.37830, -83.24317, -83.10803, -82.97290,
> > -82.83776, -82.70263, -82.56749, -82.43236, -82.29722, -82.16209,
> > -82.02695, -81.89182, -81.75668, -81.62155, -81.48641, -81.35128,
> > -81.21614, -81.08101, -80.94587, -80.81074, -80.67560, -80.54047,
> > -80.40533, -80.27020, -80.13506, -79.99993, -79.86479, -79.72966,
> > -79.59452, -79.45939, -79.32425, -79.18912, -79.05398, -78.91885,
> > -78.78371, -78.64858, -78.51344, -78.37831, -78.24317, -78.10804,
> > -77.97290, -77.83777, -77.70263, -77.56750, -77.43236, -77.29723,
> > -77.16209, -77.02696, -76.89182, -76.75669, -76.62155, -76.48642,
> > -76.35128, -76.21615, -76.08101, -75.94588, -75.81074, -75.67561,
> > -75.54047, -75.40534, -75.27020, -75.13507, -74.99993, -74.86480,
> > -74.72966, -74.59453, -74.45939, -74.32426, -74.18912, -74.05399)
> >
> >> extent(newlocs) = c(min(newlon),max(newlon),min(newlat),max(newlat)) #
> > dummy raster put to the right extent
> >
> >> testproj2 = projectRaster(from=testvar2,to=newlocs,method="bilinear") #
> > project raster itself
> >
> >> testproj2 # literally no values.
> > class       : RasterLayer
> > dimensions  : 113, 215, 24295  (nrow, ncol, ncell)
> > resolution  : 0.1345065, 0.1339391  (x, y)
> > extent      : -102.9729, -74.05399, 25.13511, 40.27023  (xmin, xmax,
> ymin,
> > ymax)
> > coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> > data source : in memory
> > names       : Avg.Max.Aneom.Temperature
> > values      : NA, NA  (min, max)
> >
> >
> > I'm quite perplexed with this one, I feel like I'm doing everything right
> > so I'm not sure what's failing.  The R version is R 3.2.3 in a Linux/Unix
> > environment.
> >
> > Many thanks for your help!
> >
> > Adrienne
> > --
> > Adrienne Wootten
> > Ph.D Candidate / Graduate Research Assistant
> > State Climate Office of North Carolina
> > Department of Marine, Earth and Atmospheric Sciences
> > North Carolina State University
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Wed May 18 16:26:01 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 18 May 2016 07:26:01 -0700
Subject: [R] Vectorised operations
In-Reply-To: <57342100db38c7a9ac572036b30008d8.squirrel@quantex.zedcore.com>
References: <57342100db38c7a9ac572036b30008d8.squirrel@quantex.zedcore.com>
Message-ID: <CAF8bMcZVi1rJv8eTJ0MnxqgQP=8PC4m3mtgryKQC0-Gt23sB3g@mail.gmail.com>

ave(A, i, FUN=cummax) loops but is faster than your aggregate-based
solution.  E.g.,

> i <- rep(1:10000, sample(0:210, replace=TRUE, size=10000))
> length(i)
[1] 1056119
> a <- sample(-50:50, replace=TRUE, size=length(i))
> system.time( vAve <- ave(a, i, FUN=cummax) )
   user  system elapsed
   0.13    0.03    0.16
> system.time( vAggregate <-
as.vector(unlist(aggregate(a,list(i),cummax)[[2]])) )
   user  system elapsed
   1.81    0.13    1.98
> all.equal(vAve, vAggregate)
[1] TRUE



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, May 18, 2016 at 6:32 AM, John Logsdon <
j.logsdon at quantex-research.com> wrote:

> Folks
>
> I have some very long vectors - typically 1 million long - which are
> indexed by another vector, same length, with values from 1 to a few
> thousand, sp each sub part of the vector may be a few hundred values long.
>
> I want to calculate the cumulative maximum of each sub part the main
> vector by the index in an efficient manner.  This can obviously be done in
> a loop but the whole calculation is embedded within many other
> calculations which would make everything very slow indeed.  All the other
> sums are vectorised already.
>
> For example,
>
> A=c(1,2,1,  -3,5,6,7,4,  6,3,7,6,9, ...)
> i=c(1,1,1,   2,2,2,2,2,  3,3,3,3,3, ...)
>
> where A has three levels that are not the same but the levels themselves
> are all monotonic non-decreasing.
>
> the answer to be a vector of the same length:
>
> R=c(1,2,2,  -3,5,6,7,7,  6,6,7,7,9, ...)
>
> If I could reset the cumulative maximum to -1e6 (eg) at each change of
> index, a simple cummax would do but I can't see how to do this.
>
> The best way I have found so far is to use the aggregate command:
>
> as.vector(unlist(aggregate(a,list(i),cummax)[[2]]))
>
> but rarely this fails, returning a shorter vector than expected and seems
> rather ugly,  converting to and from lists which may well be an
> unnecessary overhead.
>
> I have been trying other approaches using apply() methods but either it
> can't be done using them or I can't get my head round them!
>
> Any ideas?
>
> Best wishes
>
> John
>
> John Logsdon
> Quantex Research Ltd
> +44 161 445 4951/+44 7717758675
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed May 18 16:31:49 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 18 May 2016 07:31:49 -0700
Subject: [R] Vectorised operations
In-Reply-To: <57342100db38c7a9ac572036b30008d8.squirrel@quantex.zedcore.com>
References: <57342100db38c7a9ac572036b30008d8.squirrel@quantex.zedcore.com>
Message-ID: <CAGxFJbQBioE2Ob+VO4r5Trj9Ogm1FmRmD+MUUBQr=Dy2HGYBHQ@mail.gmail.com>

Sorry, I can't help, but  wanted to note that "apply methods" are
essentially just loops and rarely much faster or slower than explicit
loops. (Those of us who use them do so for clarity and maintainability
of code reasons).

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, May 18, 2016 at 6:32 AM, John Logsdon
<j.logsdon at quantex-research.com> wrote:
> Folks
>
> I have some very long vectors - typically 1 million long - which are
> indexed by another vector, same length, with values from 1 to a few
> thousand, sp each sub part of the vector may be a few hundred values long.
>
> I want to calculate the cumulative maximum of each sub part the main
> vector by the index in an efficient manner.  This can obviously be done in
> a loop but the whole calculation is embedded within many other
> calculations which would make everything very slow indeed.  All the other
> sums are vectorised already.
>
> For example,
>
> A=c(1,2,1,  -3,5,6,7,4,  6,3,7,6,9, ...)
> i=c(1,1,1,   2,2,2,2,2,  3,3,3,3,3, ...)
>
> where A has three levels that are not the same but the levels themselves
> are all monotonic non-decreasing.
>
> the answer to be a vector of the same length:
>
> R=c(1,2,2,  -3,5,6,7,7,  6,6,7,7,9, ...)
>
> If I could reset the cumulative maximum to -1e6 (eg) at each change of
> index, a simple cummax would do but I can't see how to do this.
>
> The best way I have found so far is to use the aggregate command:
>
> as.vector(unlist(aggregate(a,list(i),cummax)[[2]]))
>
> but rarely this fails, returning a shorter vector than expected and seems
> rather ugly,  converting to and from lists which may well be an
> unnecessary overhead.
>
> I have been trying other approaches using apply() methods but either it
> can't be done using them or I can't get my head round them!
>
> Any ideas?
>
> Best wishes
>
> John
>
> John Logsdon
> Quantex Research Ltd
> +44 161 445 4951/+44 7717758675
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chalabi.elahe at yahoo.de  Wed May 18 16:51:30 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Wed, 18 May 2016 14:51:30 +0000 (UTC)
Subject: [R] 3D plots in R.3.2.3
References: <1977342980.7309080.1463583090535.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1977342980.7309080.1463583090535.JavaMail.yahoo@mail.yahoo.com>


Hi all,
I am using R version 3.2.3 and I want to plot 3D histogram or 3D scatterplot. Does anyone know which packages can be used for this version for 3D plots? I tried plot3d but it's not working for this version.
 
Thanks for any help.
Elahe


From drjimlemon at gmail.com  Thu May 19 00:07:08 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 19 May 2016 08:07:08 +1000
Subject: [R] Vectorised operations
In-Reply-To: <57342100db38c7a9ac572036b30008d8.squirrel@quantex.zedcore.com>
References: <57342100db38c7a9ac572036b30008d8.squirrel@quantex.zedcore.com>
Message-ID: <CA+8X3fVB=139q9972RajYST14D0r7tsfHsZdpKsW5DpkAeKgLA@mail.gmail.com>

Hi John,
I may be misunderstanding what you want, but this seems to produce the
output you specify:

A<-sample(-10:100,100)
i<-rep(1:10,c(5:13,19))
# replace the last value of x with the maximum
max_last<-function(x) return(c(x[-length(x)],max(x)))
as.vector(unlist(by(A,i,max_last)))

and this is what I would expect using the cummax function:

as.vector(unlist(by(A,i,cummax)))

Jim


On Wed, May 18, 2016 at 11:32 PM, John Logsdon
<j.logsdon at quantex-research.com> wrote:
> Folks
>
> I have some very long vectors - typically 1 million long - which are
> indexed by another vector, same length, with values from 1 to a few
> thousand, sp each sub part of the vector may be a few hundred values long.
>
> I want to calculate the cumulative maximum of each sub part the main
> vector by the index in an efficient manner.  This can obviously be done in
> a loop but the whole calculation is embedded within many other
> calculations which would make everything very slow indeed.  All the other
> sums are vectorised already.
>
> For example,
>
> A=c(1,2,1,  -3,5,6,7,4,  6,3,7,6,9, ...)
> i=c(1,1,1,   2,2,2,2,2,  3,3,3,3,3, ...)
>
> where A has three levels that are not the same but the levels themselves
> are all monotonic non-decreasing.
>
> the answer to be a vector of the same length:
>
> R=c(1,2,2,  -3,5,6,7,7,  6,6,7,7,9, ...)
>
> If I could reset the cumulative maximum to -1e6 (eg) at each change of
> index, a simple cummax would do but I can't see how to do this.
>
> The best way I have found so far is to use the aggregate command:
>
> as.vector(unlist(aggregate(a,list(i),cummax)[[2]]))
>
> but rarely this fails, returning a shorter vector than expected and seems
> rather ugly,  converting to and from lists which may well be an
> unnecessary overhead.
>
> I have been trying other approaches using apply() methods but either it
> can't be done using them or I can't get my head round them!
>
> Any ideas?
>
> Best wishes
>
> John
>
> John Logsdon
> Quantex Research Ltd
> +44 161 445 4951/+44 7717758675
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Thu May 19 02:12:45 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 18 May 2016 17:12:45 -0700
Subject: [R] ggplot2 not displaying graph in RH7 RStudio Server 3.2.3
In-Reply-To: <951164527.246400416.1463576231392.JavaMail.root@zimbra65-e11.priv.proxad.net>
References: <951164527.246400416.1463576231392.JavaMail.root@zimbra65-e11.priv.proxad.net>
Message-ID: <DD07E662-9038-4DBC-A384-89086B692694@dcn.davis.ca.us>

Couple of points:
1) this is the R-help mailing list. If there is a problem with RStudio, nice as it is it has its own support area.  If the bug can be reproduced without RStudio then this list or one of its sister lists are appropriate. 
2) I don't have RedHat, but I can try this later at home on Ubuntu. 
3) Posting in HTML causes problems. The Posting Guide warns you to post in plain text.  This may be why your request did not show up on the list, where people with red hat might have already seen it by now. 
4) There is an R-sig-Fedora mailing list that might have people with better answers for your possibly-OS-specific question than this OS-neutral mailing list. 
5) I notice that there are several differences here: OS, R version, RStudio edition, and several packages. You might try to bring these into alignment to narrow the possible sources of the trouble.
-- 
Sent from my phone. Please excuse my brevity.

On May 18, 2016 5:57:11 AM PDT, phiroc at free.fr wrote:
>
>
>Here's a minimal example that displays a bar chart in RStudio 3.2.4 for
>Windows, but not in RStudio Server 3.2.3 on RH Linux 7:
>
>------------------------------------------------------------------- R
>Code
>-------------------------------------------------------------------
>
>library(ggplot2)
>a <- c("ab", "bc", "cd")
>b <- c("de", "fg", "hi")
>ds <- data.frame(a,b)
>g1 <- ggplot(data = ds, aes(x=a))
>g1 + geom_bar(stat="count", fill=rainbow(3), colour="black") +
>xlab("Action & Description") + ylab("Count")  +  ggtitle("test") +
>coord_flip()
>
>----------------------------------------------------------------------------------------------------------------------------------------------
>
>----------------------------------------------------------- sessionInfo
>on Windows ----------------------------------------------------------
>
>R version 3.2.4 Revised (2016-03-16 r70336)
>Platform: x86_64-w64-mingw32/x64 (64-bit)
>Running under: Windows 7 x64 (build 7601) Service Pack 1
>
>locale:
>[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>States.1252   
>[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C                
>         
>[5] LC_TIME=English_United States.1252    
>
>attached base packages:
>[1] stats     graphics  grDevices utils     datasets  methods   base   
> 
>
>other attached packages:
>[1] gridExtra_2.2.1 ggthemes_3.0.2  lubridate_1.5.0 RJDBC_0.2-5    
>rJava_0.9-8    
>[6] DBI_0.3.1       ggplot2_2.1.0  
>
>loaded via a namespace (and not attached):
>[1] Rcpp_0.12.4        assertthat_0.1     grid_3.2.4         plyr_1.8.3
>       
>[5] gtable_0.2.0       magrittr_1.5       scales_0.4.0      
>stringi_1.0-1     
>[9] labeling_0.3       tools_3.2.4        stringr_1.0.0     
>munsell_0.4.3     
>[13] rsconnect_0.4.1.11 colorspace_1.2-6  
>> 
>
>--------------------------------------------------------------------------------------------------------------------------------------------
>
>--------------------------------------------------------- sessionInfo
>on RH Linux 7 -------------------------------------------------------
>
>R version 3.2.3 (2015-12-10)
>Platform: x86_64-redhat-linux-gnu (64-bit)
>Running under: Red Hat Enterprise Linux
>
>locale:
>[1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
>LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
>LC_MONETARY=en_US.UTF-8   
>[6] LC_MESSAGES=en_US.UTF-8    LC_PAPER=en_US.UTF-8       LC_NAME=C    
>             LC_ADDRESS=C               LC_TELEPHONE=C            
>[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       
>
>attached base packages:
>[1] stats     graphics  grDevices utils     datasets  methods   base   
> 
>
>other attached packages:
>[1] gridExtra_2.2.1 ggthemes_3.0.3  ggplot2_2.1.0   lubridate_1.5.6
>RJDBC_0.2-5     rJava_0.9-8     DBI_0.4-1      
>
>loaded via a namespace (and not attached):
>[1] Rcpp_0.12.5      assertthat_0.1   grid_3.2.3       plyr_1.8.3      
>gtable_0.2.0     magrittr_1.5     scales_0.4.0     stringi_1.0-1   
>[9] tools_3.2.3      stringr_1.0.0    munsell_0.4.3    colorspace_1.2-6
>
>------------------------------------------------------------------------------------------------------------------------------------------
>
>
>
>
>
>----- Mail original -----
>De: "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
>?: phiroc at free.fr, r-help at r-project.org
>Envoy?: Mercredi 18 Mai 2016 14:36:50
>Objet: Re: [R] ggplot2 not displaying graph in RH7 RStudio Server 3.2.3
>
>Context is everything. Please follow the Posting Guide and provide a
>minimal reproducible example. Also, if your scripts are literally the
>same on the two platforms, you should provide the output of the
>sessionInfo() function for each. 
>-- 
>Sent from my phone. Please excuse my brevity. 
>
>
>On May 18, 2016 12:32:47 AM PDT, phiroc at free.fr wrote: 
>
>
>Hello, 
>
>I have written an R script which displays a bar chart using the ggplot2
>library (please refer 
>to code excerpt at the bottom of this e-mail). 
>
>Although the bar chart is displayed OK in the Windows version of
>RStudio (v. 3.2.4), 
>nothing appears on Linux RH 7 in Rstudio Server 3.2.3. 
>
>I have tried replacing the data frame in the RH-version of the script
>by 
>
>
>
>
>a <- c("ab", "bc", "cd") 
>b <- c(1, 2, 3) 
>ds <- data.frame(a,b) 
>g1 <- ggplot(data = ds, aes(x = a)) 
>
>
>
>
>
>... but to avail: ggplot doesn't plot anything. No error message are
>displayed. 
>
>Any help with this issue would be much appreciated. 
>
>Many thanks. 
>
>phiroc 
>
>
>----------------------------- R Code Excerpt 
>
>
>
>g1 <- ggplot(data = mergedD, aes(x=DESC_TYPE)) 
>g1 + geom_bar(stat="count",
>fill=rainbow(numberOfDistinctActions), colour="black") + 
>xlab("Action & Description") + 
>ylab("Count")  + 
>ggtitle(paste0( 
>"Number of Customer Actions in XXX from ", day0, "/", mon, 
>"/", year, " to ", day1, "/", mon, "/", year, 
>" in Paris & Hong Kong")) + 
>coord_flip() 
>
>
>
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>https://stat.ethz.ch/mailman/listinfo/r-help 
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html 
>and provide commented, minimal, self-contained, reproducible code. 

	[[alternative HTML version deleted]]


From rezvan.hatami_iut at yahoo.com  Wed May 18 12:37:15 2016
From: rezvan.hatami_iut at yahoo.com (rezvan hatami)
Date: Wed, 18 May 2016 10:37:15 +0000 (UTC)
Subject: [R] R STUDIO crashing
References: <1589762996.4127148.1463567835159.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1589762996.4127148.1463567835159.JavaMail.yahoo@mail.yahoo.com>

Hi there
I have been using R for a while now. I am doing my PhD project with it. Recently, it keeps crashing, mostly when I draw a graph and use XYPLOT code. I even spent some money on cleaning registry, checking ram, deleting unnecessary files from working directory. I used "plot(cars) and?dev.off(). First the">" sign disappears from the console and then if I try to remove the plot or something else, the whole R freezes. When the ">" disappears, R doesn't run the commands anymore. I searched all online questions and answers, but I couldn't fix this. Please help me. PLEASE.
Cheers
Rezvan Hatami
	[[alternative HTML version deleted]]


From rezvan.hatami_iut at yahoo.com  Wed May 18 12:46:02 2016
From: rezvan.hatami_iut at yahoo.com (rezvan hatami)
Date: Wed, 18 May 2016 10:46:02 +0000 (UTC)
Subject: [R] RSTUDIO keeps crashing-please help me
References: <879498341.4156372.1463568362434.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <879498341.4156372.1463568362434.JavaMail.yahoo@mail.yahoo.com>

Hi there
I have been using R for a while now. I am doing my PhD project with it. Recently, it keeps crashing, mostly when I draw a graph and use XYPLOT code. I even spent some money on cleaning registry, checking ram, deleting unnecessary files from working directory. I used "plot(cars) and?dev.off(). First the">" sign disappears from the console and then if I try to remove the plot or something else, the whole R freezes. When the ">" disappears, R doesn't run the commands anymore. I searched all online questions and answers, but I couldn't fix this. I also uninstalled Rstudio and reinstalled it. Would you please help me?Please help me. PLEASE.
Cheers
Rezvan Hatami
	[[alternative HTML version deleted]]


From phiroc at free.fr  Wed May 18 14:57:11 2016
From: phiroc at free.fr (phiroc at free.fr)
Date: Wed, 18 May 2016 14:57:11 +0200 (CEST)
Subject: [R] ggplot2 not displaying graph in RH7 RStudio Server 3.2.3
In-Reply-To: <10EA9A31-D825-4591-B1C7-904CE0F0672F@dcn.davis.ca.us>
Message-ID: <951164527.246400416.1463576231392.JavaMail.root@zimbra65-e11.priv.proxad.net>



Here's a minimal example that displays a bar chart in RStudio 3.2.4 for Windows, but not in RStudio Server 3.2.3 on RH Linux 7:

------------------------------------------------------------------- R Code -------------------------------------------------------------------

library(ggplot2)
a <- c("ab", "bc", "cd")
b <- c("de", "fg", "hi")
ds <- data.frame(a,b)
g1 <- ggplot(data = ds, aes(x=a))
g1 + geom_bar(stat="count", fill=rainbow(3), colour="black") + xlab("Action & Description") + ylab("Count")  +  ggtitle("test") + coord_flip()

----------------------------------------------------------------------------------------------------------------------------------------------

----------------------------------------------------------- sessionInfo on Windows ----------------------------------------------------------

R version 3.2.4 Revised (2016-03-16 r70336)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] gridExtra_2.2.1 ggthemes_3.0.2  lubridate_1.5.0 RJDBC_0.2-5     rJava_0.9-8    
[6] DBI_0.3.1       ggplot2_2.1.0  

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.4        assertthat_0.1     grid_3.2.4         plyr_1.8.3        
 [5] gtable_0.2.0       magrittr_1.5       scales_0.4.0       stringi_1.0-1     
 [9] labeling_0.3       tools_3.2.4        stringr_1.0.0      munsell_0.4.3     
[13] rsconnect_0.4.1.11 colorspace_1.2-6  
> 

--------------------------------------------------------------------------------------------------------------------------------------------

--------------------------------------------------------- sessionInfo on RH Linux 7 -------------------------------------------------------

R version 3.2.3 (2015-12-10)
Platform: x86_64-redhat-linux-gnu (64-bit)
Running under: Red Hat Enterprise Linux

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8  
 [6] LC_MESSAGES=en_US.UTF-8    LC_PAPER=en_US.UTF-8       LC_NAME=C                  LC_ADDRESS=C               LC_TELEPHONE=C           
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] gridExtra_2.2.1 ggthemes_3.0.3  ggplot2_2.1.0   lubridate_1.5.6 RJDBC_0.2-5     rJava_0.9-8     DBI_0.4-1      

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.5      assertthat_0.1   grid_3.2.3       plyr_1.8.3       gtable_0.2.0     magrittr_1.5     scales_0.4.0     stringi_1.0-1   
 [9] tools_3.2.3      stringr_1.0.0    munsell_0.4.3    colorspace_1.2-6

------------------------------------------------------------------------------------------------------------------------------------------





----- Mail original -----
De: "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
?: phiroc at free.fr, r-help at r-project.org
Envoy?: Mercredi 18 Mai 2016 14:36:50
Objet: Re: [R] ggplot2 not displaying graph in RH7 RStudio Server 3.2.3

Context is everything. Please follow the Posting Guide and provide a minimal reproducible example. Also, if your scripts are literally the same on the two platforms, you should provide the output of the sessionInfo() function for each. 
-- 
Sent from my phone. Please excuse my brevity. 


On May 18, 2016 12:32:47 AM PDT, phiroc at free.fr wrote: 


Hello, 

I have written an R script which displays a bar chart using the ggplot2 library (please refer 
to code excerpt at the bottom of this e-mail). 

Although the bar chart is displayed OK in the Windows version of RStudio (v. 3.2.4), 
nothing appears on Linux RH 7 in Rstudio Server 3.2.3. 

I have tried replacing the data frame in the RH-version of the script by 




a <- c("ab", "bc", "cd") 
b <- c(1, 2, 3) 
ds <- data.frame(a,b) 
g1 <- ggplot(data = ds, aes(x = a)) 





... but to avail: ggplot doesn't plot anything. No error message are displayed. 

Any help with this issue would be much appreciated. 

Many thanks. 

phiroc 


----------------------------- R Code Excerpt 



g1 <- ggplot(data = mergedD, aes(x=DESC_TYPE)) 
g1 + geom_bar(stat="count",
fill=rainbow(numberOfDistinctActions), colour="black") + 
xlab("Action & Description") + 
ylab("Count")  + 
ggtitle(paste0( 
"Number of Customer Actions in XXX from ", day0, "/", mon, 
"/", year, " to ", day1, "/", mon, "/", year, 
" in Paris & Hong Kong")) + 
coord_flip() 



R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
and provide commented, minimal, self-contained, reproducible code. 


From fotisfotiadis at gmail.com  Wed May 18 14:57:29 2016
From: fotisfotiadis at gmail.com (Fotis Fotiadis)
Date: Wed, 18 May 2016 15:57:29 +0300
Subject: [R] gam.check() NA results (k-index,
 p-value) of a gam logistic regression model
In-Reply-To: <573C3074.6030800@bath.edu>
References: <CAAO1Nnda5xYbA68O6cGi4UmcRrmsXZyGaJF=A62k0uQ75ZCDvw@mail.gmail.com>
	<573C3074.6030800@bath.edu>
Message-ID: <CAAO1NncN6o-v4eY8Hc5LhLUm5XLwXi8TSz3K3+pPsJiCgXZ7+Q@mail.gmail.com>

Dear Prof. Wood,

Thank you for your reply!

Best,
Fotis

On Wed, May 18, 2016 at 12:05 PM, Simon Wood <simon.wood at bath.edu> wrote:

> Dear Fotis,
>
> The test is a randomization test, based on comparing differences of
> residuals, ordered with respect to the covariate of the smooth, to
> differences of residuals in randomized order. Random effect terms are
> excluded because there is not basis size to choose. Currently smooths with
> factor by variables are also excluded for reasons of maintainer laziness,
> as this would require special case code to exclude the covariate values
> that are irrelevant given the factor level. Sorry about that.
>
> My guess is that you don't have a problem here anyway, given the fairly
> low edfs relative to the basis dimension. In general as a double check I
> would plot the residuals against ctrial, colour coded by level of igc, just
> to check that there doesn't seem to be missed pattern in them. However with
> binary residuals you are unlikely to see much.
>
> best,
> Simon
>
>
> On 17/05/16 20:39, Fotis Fotiadis wrote:
>
>> Hello all
>>
>> I am using bam for a mixec-effects logistic regression model:
>>
>> b0<-bam(acc~ 1 + igc + s(ctrial, by=igc) + s(sbj, bs="re") + s(ctrial,
>> sbj,
>> bs="re") , data=data, family=binomial)
>>
>> summary(b0)
>>>
>> Family: binomial
>> Link function: logit
>>
>> Formula:
>> acc ~ 1 + igc + s(ctrial, by = igc) + s(sbj, bs = "re") + s(ctrial,
>>      sbj, bs = "re")
>>
>> Parametric coefficients:
>>                Estimate Std. Error z value Pr(>|z|)
>> (Intercept)     2.8334     0.2030  13.955  < 2e-16 ***
>> igcPA.pseudo    0.4692     0.1285   3.650 0.000262 ***
>> igcCAT.ideo     0.3276     0.2906   1.127 0.259734
>> igcCAT.pseudo   0.6701     0.2945   2.275 0.022888 *
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Approximate significance of smooth terms:
>>                             edf Ref.df Chi.sq  p-value
>> s(ctrial):igcPA.ideo     3.827  4.733  295.0  < 2e-16 ***
>> s(ctrial):igcPA.pseudo   3.317  4.110  356.1  < 2e-16 ***
>> s(ctrial):igcCAT.ideo    3.979  4.911  308.6  < 2e-16 ***
>> s(ctrial):igcCAT.pseudo  4.937  5.974  383.8  < 2e-16 ***
>> s(sbj)                  54.326 62.000 3032.8  < 2e-16 ***
>> s(ctrial,sbj)           43.045 62.000 2706.6 1.31e-08 ***
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> R-sq.(adj) =  0.362   Deviance explained = 38.9%
>> fREML =  25436  Scale est. = 1         n = 18417
>>
>>
>> I want to know if the wigglyness of the smooths [s(ctrial, by=igc)] is
>> appropriate, so I used the gam.check() function. The values though for
>> k-index and p-value are NAs:
>>
>> gam.check(b0)
>>>
>> Method: fREML   Optimizer: perf newton
>> full convergence after 5 iterations.
>> Gradient range [-7.60152e-08,8.12795e-06]
>> (score 25436.12 & scale 1).
>> Hessian positive definite, eigenvalue range [0.6271375,24.46625].
>> Model rank =  168 / 168
>>
>> Basis dimension (k) checking results. Low p-value (k-index<1) may
>> indicate that k is too low, especially if edf is close to k'.
>>
>>                             k'   edf k-index p-value
>> s(ctrial):igcPA.ideo     9.00  3.83      NA      NA
>> s(ctrial):igcPA.pseudo   9.00  3.32      NA      NA
>> s(ctrial):igcCAT.ideo    9.00  3.98      NA      NA
>> s(ctrial):igcCAT.pseudo  9.00  4.94      NA      NA
>> s(sbj)                  64.00 54.33      NA      NA
>> s(ctrial,sbj)           64.00 43.04      NA      NA
>>
>> Does anyone know why is this?
>>
>> Thank you in advance for your time,
>> Fotis
>>
>> P.S. I am using RStudio Version 0.99.896, R 3.3.0, and mgcv package
>> version
>> 1.8.12.
>> --
>> PhD Candidate
>> Department of Philosophy and History of Science
>> University of Athens, Greece.
>> http://users.uoa.gr/~aprotopapas/LLL/en/members.html#fotisfotiadis
>>
>> Notice: Please do not use this account for social networks invitations,
>> for
>> sending chain-mails to me, or as it were a facebook account. Thank you for
>> respecting my privacy.
>>
>> <
>> https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
>> >
>> ???????????
>> ??? ????. www.avast.com
>> <
>> https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
>> >
>> <#DDB4FAA8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> --
> Simon Wood, School of Mathematics, University of Bristol BS8 1TW UK
> +44 (0)117 33 18273     http://www.maths.bris.ac.uk/~sw15190
>
>


-- 
PhD Candidate
Department of Philosophy and History of Science
University of Athens, Greece.
http://users.uoa.gr/~aprotopapas/LLL/en/members.html#fotisfotiadis

Notice: Please do not use this account for social networks invitations, for
sending chain-mails to me, or as it were a facebook account. Thank you for
respecting my privacy.

<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
???????????
??? ????. www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DDB4FAA8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]


From sabasehrish at yahoo.com  Thu May 19 06:51:34 2016
From: sabasehrish at yahoo.com (Saba Sehrish)
Date: Thu, 19 May 2016 04:51:34 +0000 (UTC)
Subject: [R] Install GARPFRM package
References: <1049908421.4592490.1463633494321.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1049908421.4592490.1463633494321.JavaMail.yahoo@mail.yahoo.com>

Hi

I am trying to install GARPFRM package to R (version: 3.3.0) by following steps:

(a)  install.packages("GARPFRM", repos="http://R-Forge.R-project.org")

It gives following Warning messages:

1: running command '"C:/PROGRA~1/R/R-33~1.0/bin/i386/R" CMD INSTALL -l "C:\Users\ssehrish\Documents\R\win-library\3.3" C:\Users\ssehrish\AppData\Local\Temp\RtmpU3JvBo/downloaded_packages/GARPFRM_0.1.0.tar.gz' had status 1 


2: In install.packages("GARPFRM", repos = "http://R-Forge.R-project.org") :  installation of package ?GARPFRM? had non-zero exit status


(b) library(GARPFRM)

It gives following error :  Error in library(GARPFRM) : there is no package called ?GARPFRM?

Please help me in this regard.

Thanks
Saba


From shigesong at gmail.com  Thu May 19 06:55:14 2016
From: shigesong at gmail.com (Shige Song)
Date: Thu, 19 May 2016 12:55:14 +0800
Subject: [R] R STUDIO crashing
In-Reply-To: <1589762996.4127148.1463567835159.JavaMail.yahoo@mail.yahoo.com>
References: <1589762996.4127148.1463567835159.JavaMail.yahoo.ref@mail.yahoo.com>
	<1589762996.4127148.1463567835159.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAGuGQcwEQR3AqhWe3VzOpTisUGzTnO=JLCMUUSmFfHOGj=1DMA@mail.gmail.com>

One thing for sure: It's not the fault of R nor Rstudio (because they are
doing fine on other people's computers, mine included). You can probably
get some help on the Rstudio support forum.

On Wed, May 18, 2016 at 6:37 PM, rezvan hatami via R-help <
r-help at r-project.org> wrote:

> Hi there
> I have been using R for a while now. I am doing my PhD project with it.
> Recently, it keeps crashing, mostly when I draw a graph and use XYPLOT
> code. I even spent some money on cleaning registry, checking ram, deleting
> unnecessary files from working directory. I used "plot(cars) and dev.off().
> First the">" sign disappears from the console and then if I try to remove
> the plot or something else, the whole R freezes. When the ">" disappears, R
> doesn't run the commands anymore. I searched all online questions and
> answers, but I couldn't fix this. Please help me. PLEASE.
> Cheers
> Rezvan Hatami
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu May 19 08:17:11 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 18 May 2016 23:17:11 -0700
Subject: [R] Install GARPFRM package
In-Reply-To: <1049908421.4592490.1463633494321.JavaMail.yahoo@mail.yahoo.com>
References: <1049908421.4592490.1463633494321.JavaMail.yahoo.ref@mail.yahoo.com>
	<1049908421.4592490.1463633494321.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <A6EE52A1-DC9D-4188-9E15-73F5FB667788@comcast.net>


> On May 18, 2016, at 9:51 PM, Saba Sehrish via R-help <r-help at r-project.org> wrote:
> 
> Hi
> 
> I am trying to install GARPFRM package to R (version: 3.3.0) by following steps:
> 
> (a)  install.packages("GARPFRM", repos="http://R-Forge.R-project.org")
> 
> It gives following Warning messages:
> 
> 1: running command '"C:/PROGRA~1/R/R-33~1.0/bin/i386/R" CMD INSTALL -l "C:\Users\ssehrish\Documents\R\win-library\3.3" C:\Users\ssehrish\AppData\Local\Temp\RtmpU3JvBo/downloaded_packages/GARPFRM_0.1.0.tar.gz' had status 1 
> 

.tar.gz packages are source packages. The default for the install.packages function is for binary packages. (Generally you will not find binary packages on R-Forge.)

You should read the help pages for install.packages.


> 
> 2: In install.packages("GARPFRM", repos = "http://R-Forge.R-project.org") :  installation of package ?GARPFRM? had non-zero exit status
> 
> 
> (b) library(GARPFRM)
> 
> It gives following error :  Error in library(GARPFRM) : there is no package called ?GARPFRM?
> 

Trying to load a package which failed to install should not surprise you.

-- 

David Winsemius
Alameda, CA, USA


From sabasehrish at yahoo.com  Thu May 19 08:28:54 2016
From: sabasehrish at yahoo.com (Saba Sehrish)
Date: Thu, 19 May 2016 06:28:54 +0000 (UTC)
Subject: [R] Install GARPFRM package
References: <920367912.4684059.1463639334840.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <920367912.4684059.1463639334840.JavaMail.yahoo@mail.yahoo.com>

Hi

If a package is not loading, it is a matter of concern. Therefore, I have asked for the assistance or guidance in this regards.

Saba


From dwinsemius at comcast.net  Thu May 19 08:40:08 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 18 May 2016 23:40:08 -0700
Subject: [R] 3D plots in R.3.2.3
In-Reply-To: <1977342980.7309080.1463583090535.JavaMail.yahoo@mail.yahoo.com>
References: <1977342980.7309080.1463583090535.JavaMail.yahoo.ref@mail.yahoo.com>
	<1977342980.7309080.1463583090535.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <71362FA0-BF2E-4C74-A95F-5010CD18364F@comcast.net>


> On May 18, 2016, at 7:51 AM, ch.elahe via R-help <r-help at r-project.org> wrote:
> 
> 
> Hi all,
> I am using R version 3.2.3 and I want to plot 3D histogram or 3D scatterplot. Does anyone know which packages can be used for this version for 3D plots? I tried plot3d but it's not working for this version.

Perhaps you =misspelled the package name. I see no plot3d package. (But there is a plot3D package.)


-- 
David Winsemius
Alameda, CA, USA


From denis.francisci at gmail.com  Thu May 19 10:24:55 2016
From: denis.francisci at gmail.com (Denis Francisci)
Date: Thu, 19 May 2016 10:24:55 +0200
Subject: [R] 3D plots in R.3.2.3
In-Reply-To: <71362FA0-BF2E-4C74-A95F-5010CD18364F@comcast.net>
References: <1977342980.7309080.1463583090535.JavaMail.yahoo.ref@mail.yahoo.com>
	<1977342980.7309080.1463583090535.JavaMail.yahoo@mail.yahoo.com>
	<71362FA0-BF2E-4C74-A95F-5010CD18364F@comcast.net>
Message-ID: <CAJMcJMD8RQ4nNm4KoE8mh5zkUVoeDTCHnnqgyLG+E8s2Mc_BsA@mail.gmail.com>

For 3D scatterplot you can use also "scatterplot3d" package.

2016-05-19 8:40 GMT+02:00 David Winsemius <dwinsemius at comcast.net>:

>
> > On May 18, 2016, at 7:51 AM, ch.elahe via R-help <r-help at r-project.org>
> wrote:
> >
> >
> > Hi all,
> > I am using R version 3.2.3 and I want to plot 3D histogram or 3D
> scatterplot. Does anyone know which packages can be used for this version
> for 3D plots? I tried plot3d but it's not working for this version.
>
> Perhaps you =misspelled the package name. I see no plot3d package. (But
> there is a plot3D package.)
>
>
> --
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu May 19 12:31:28 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 19 May 2016 06:31:28 -0400
Subject: [R] RSTUDIO keeps crashing-please help me
In-Reply-To: <879498341.4156372.1463568362434.JavaMail.yahoo@mail.yahoo.com>
References: <879498341.4156372.1463568362434.JavaMail.yahoo.ref@mail.yahoo.com>
	<879498341.4156372.1463568362434.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <a247d1cf-71bb-129d-384b-bb85782a2e74@gmail.com>

On 18/05/2016 6:46 AM, rezvan hatami via R-help wrote:
> Hi there
> I have been using R for a while now. I am doing my PhD project with it. Recently, it keeps crashing, mostly when I draw a graph and use XYPLOT code. I even spent some money on cleaning registry, checking ram, deleting unnecessary files from working directory. I used "plot(cars) and dev.off(). First the">" sign disappears from the console and then if I try to remove the plot or something else, the whole R freezes. When the ">" disappears, R doesn't run the commands anymore. I searched all online questions and answers, but I couldn't fix this. I also uninstalled Rstudio and reinstalled it. Would you please help me?Please help me. PLEASE.

Do the crashes happen in R if you run it without RStudio?  If not, this 
is something you need to report to the RStudio people, not here.

If they do happen in plain R, try running with the --vanilla option.  If 
that is fine, the problem is probably something you have in your saved 
workspace, or in one of the startup files.

Duncan Murdoch


From jrkrideau at inbox.com  Thu May 19 12:50:52 2016
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 19 May 2016 02:50:52 -0800
Subject: [R] RSTUDIO keeps crashing-please help me
In-Reply-To: <879498341.4156372.1463568362434.JavaMail.yahoo@mail.yahoo.com>
References: <879498341.4156372.1463568362434.javamail.yahoo.ref@mail.yahoo.com>
Message-ID: <F90648CC4D6.00000D3Ejrkrideau@inbox.com>

What happens if you run R in a console or the Windows GUI if you are using Windows

We need to isolate the issue as an R issue or an RStudio one or a local computer one.  My experience is that occasionally RStudio will do something a bit weird but usually rebooting RStudio  cures it.

If it appears to be an RStudio problem you will need to go to the RStudio support. 

For some general suggestions on how to ask questions here have a look at 
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and/or http://adv-r.had.co.nz/Reproducibility.html


John Kane
Kingston ON Canada


> -----Original Message-----
> From: r-help at r-project.org
> Sent: Wed, 18 May 2016 10:46:02 +0000 (UTC)
> To: r-help at r-project.org
> Subject: [R] RSTUDIO keeps crashing-please help me
> 
> Hi there
> I have been using R for a while now. I am doing my PhD project with it.
> Recently, it keeps crashing, mostly when I draw a graph and use XYPLOT
> code. I even spent some money on cleaning registry, checking ram,
> deleting unnecessary files from working directory. I used "plot(cars)
> and?dev.off(). First the">" sign disappears from the console and then if
> I try to remove the plot or something else, the whole R freezes. When the
> ">" disappears, R doesn't run the commands anymore. I searched all online
> questions and answers, but I couldn't fix this. I also uninstalled
> Rstudio and reinstalled it. Would you please help me?Please help me.
> PLEASE.
> Cheers
> Rezvan Hatami
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From joeceradini at gmail.com  Thu May 19 15:27:37 2016
From: joeceradini at gmail.com (Joe Ceradini)
Date: Thu, 19 May 2016 07:27:37 -0600
Subject: [R] R STUDIO crashing
In-Reply-To: <CAGuGQcwEQR3AqhWe3VzOpTisUGzTnO=JLCMUUSmFfHOGj=1DMA@mail.gmail.com>
References: <1589762996.4127148.1463567835159.JavaMail.yahoo.ref@mail.yahoo.com>
	<1589762996.4127148.1463567835159.JavaMail.yahoo@mail.yahoo.com>
	<CAGuGQcwEQR3AqhWe3VzOpTisUGzTnO=JLCMUUSmFfHOGj=1DMA@mail.gmail.com>
Message-ID: <CAKq2vL6=_m+du7SMdWg86xnMjHyvTosbfsPPKS+AVkJqFc_Z8A@mail.gmail.com>

I had this problem as well, a lot, and it was frustrating and I did not
find much reference to it online. I believe it occurs after you run a plot
and then make the plotting window too small for R studio to redraw the
plot. Then when run a line of code, it never runs or appears to be running
indefinitely. The "STOP" sign does not show up either, so you cannot stop
the process that way - I always had to force stop via control alt delete.
After I starting paying attention to either clearing all plots or keeping
the size of the window big enough to draw the plot, the problem totally
stopped. I do not know/understand what the underlying problem is, but
hopefully it is resolved in newer versions.

Joe

On Wed, May 18, 2016 at 10:55 PM, Shige Song <shigesong at gmail.com> wrote:

> One thing for sure: It's not the fault of R nor Rstudio (because they are
> doing fine on other people's computers, mine included). You can probably
> get some help on the Rstudio support forum.
>
> On Wed, May 18, 2016 at 6:37 PM, rezvan hatami via R-help <
> r-help at r-project.org> wrote:
>
> > Hi there
> > I have been using R for a while now. I am doing my PhD project with it.
> > Recently, it keeps crashing, mostly when I draw a graph and use XYPLOT
> > code. I even spent some money on cleaning registry, checking ram,
> deleting
> > unnecessary files from working directory. I used "plot(cars) and
> dev.off().
> > First the">" sign disappears from the console and then if I try to remove
> > the plot or something else, the whole R freezes. When the ">"
> disappears, R
> > doesn't run the commands anymore. I searched all online questions and
> > answers, but I couldn't fix this. Please help me. PLEASE.
> > Cheers
> > Rezvan Hatami
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Cooperative Fish and Wildlife Research Unit
Zoology and Physiology Dept.
University of Wyoming
JoeCeradini at gmail.com / 914.707.8506
wyocoopunit.org

	[[alternative HTML version deleted]]


From joeceradini at gmail.com  Thu May 19 15:31:28 2016
From: joeceradini at gmail.com (Joe Ceradini)
Date: Thu, 19 May 2016 07:31:28 -0600
Subject: [R] R STUDIO crashing
In-Reply-To: <CAKq2vL6=_m+du7SMdWg86xnMjHyvTosbfsPPKS+AVkJqFc_Z8A@mail.gmail.com>
References: <1589762996.4127148.1463567835159.JavaMail.yahoo.ref@mail.yahoo.com>
	<1589762996.4127148.1463567835159.JavaMail.yahoo@mail.yahoo.com>
	<CAGuGQcwEQR3AqhWe3VzOpTisUGzTnO=JLCMUUSmFfHOGj=1DMA@mail.gmail.com>
	<CAKq2vL6=_m+du7SMdWg86xnMjHyvTosbfsPPKS+AVkJqFc_Z8A@mail.gmail.com>
Message-ID: <CAKq2vL7qyF8KUqBK5Ausvx+QcVHOTXu3xJ_HWX-6re-+vEAU0A@mail.gmail.com>

Also, this starting happening for me with R studio 0.99.893, so if you have
a different version, maybe it is a different issue (or maybe it is a
different issue regardless...).

Joe

On Thu, May 19, 2016 at 7:27 AM, Joe Ceradini <joeceradini at gmail.com> wrote:

> I had this problem as well, a lot, and it was frustrating and I did not
> find much reference to it online. I believe it occurs after you run a plot
> and then make the plotting window too small for R studio to redraw the
> plot. Then when run a line of code, it never runs or appears to be running
> indefinitely. The "STOP" sign does not show up either, so you cannot stop
> the process that way - I always had to force stop via control alt delete.
> After I starting paying attention to either clearing all plots or keeping
> the size of the window big enough to draw the plot, the problem totally
> stopped. I do not know/understand what the underlying problem is, but
> hopefully it is resolved in newer versions.
>
> Joe
>
> On Wed, May 18, 2016 at 10:55 PM, Shige Song <shigesong at gmail.com> wrote:
>
>> One thing for sure: It's not the fault of R nor Rstudio (because they are
>> doing fine on other people's computers, mine included). You can probably
>> get some help on the Rstudio support forum.
>>
>> On Wed, May 18, 2016 at 6:37 PM, rezvan hatami via R-help <
>> r-help at r-project.org> wrote:
>>
>> > Hi there
>> > I have been using R for a while now. I am doing my PhD project with it.
>> > Recently, it keeps crashing, mostly when I draw a graph and use XYPLOT
>> > code. I even spent some money on cleaning registry, checking ram,
>> deleting
>> > unnecessary files from working directory. I used "plot(cars) and
>> dev.off().
>> > First the">" sign disappears from the console and then if I try to
>> remove
>> > the plot or something else, the whole R freezes. When the ">"
>> disappears, R
>> > doesn't run the commands anymore. I searched all online questions and
>> > answers, but I couldn't fix this. Please help me. PLEASE.
>> > Cheers
>> > Rezvan Hatami
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> Cooperative Fish and Wildlife Research Unit
> Zoology and Physiology Dept.
> University of Wyoming
> JoeCeradini at gmail.com / 914.707.8506
> wyocoopunit.org
>
>


-- 
Cooperative Fish and Wildlife Research Unit
Zoology and Physiology Dept.
University of Wyoming
JoeCeradini at gmail.com / 914.707.8506
wyocoopunit.org

	[[alternative HTML version deleted]]


From giftedlife2014 at gmail.com  Thu May 19 15:37:09 2016
From: giftedlife2014 at gmail.com (Ogbos Okike)
Date: Thu, 19 May 2016 14:37:09 +0100
Subject: [R] Install GARPFRM package
In-Reply-To: <1049908421.4592490.1463633494321.JavaMail.yahoo@mail.yahoo.com>
References: <1049908421.4592490.1463633494321.JavaMail.yahoo.ref@mail.yahoo.com>
	<1049908421.4592490.1463633494321.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAC8ss32JcLnz6_vyFzzSe8ZpEoD0He4MniSs1piW7zcD8kKmyA@mail.gmail.com>

Hi Saba,
Your main worry may be that of non- zero status and hence your attempt to
load what the system claims you have. I have encountered such problems
severally. You can try two things: run it several times ( network issues
might play a role) or try different crab mirrors.
Ogbos
On May 19, 2016 5:53 AM, "Saba Sehrish via R-help" <r-help at r-project.org>
wrote:

> Hi
>
> I am trying to install GARPFRM package to R (version: 3.3.0) by following
> steps:
>
> (a)  install.packages("GARPFRM", repos="http://R-Forge.R-project.org")
>
> It gives following Warning messages:
>
> 1: running command '"C:/PROGRA~1/R/R-33~1.0/bin/i386/R" CMD INSTALL -l
> "C:\Users\ssehrish\Documents\R\win-library\3.3"
> C:\Users\ssehrish\AppData\Local\Temp\RtmpU3JvBo/downloaded_packages/GARPFRM_0.1.0.tar.gz'
> had status 1
>
>
> 2: In install.packages("GARPFRM", repos = "http://R-Forge.R-project.org")
> :  installation of package ?GARPFRM? had non-zero exit status
>
>
> (b) library(GARPFRM)
>
> It gives following error :  Error in library(GARPFRM) : there is no
> package called ?GARPFRM?
>
> Please help me in this regard.
>
> Thanks
> Saba
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bsmith030465 at gmail.com  Thu May 19 15:40:11 2016
From: bsmith030465 at gmail.com (Brian Smith)
Date: Thu, 19 May 2016 09:40:11 -0400
Subject: [R] x-axis tick marks on log scale plot
Message-ID: <CAEQKoCHSLXiUV=jB_wrhRw9_h9ZAea_p_0Ymto8_CKCmFiHgtg@mail.gmail.com>

Hi,

I have a plot with log scale on the axes. How do I add ticks and labels in
addition to the ones provided by default? Can I specify where I want the
ticks and labels?

For example:

set.seed(12345)
x <- sample(1:10000,10)
y <- sample(1:10000,10)

plot(x,y,log="xy")


For me, this plot has tick marks (and labels) at 2000, 4000, 6000, 8000.
How can I make the axes so that it has marks and labels at 1000 intervals
(i.e. 2000, 3000, 4000, etc.)

thanks!

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu May 19 15:47:48 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 19 May 2016 09:47:48 -0400
Subject: [R] x-axis tick marks on log scale plot
In-Reply-To: <CAEQKoCHSLXiUV=jB_wrhRw9_h9ZAea_p_0Ymto8_CKCmFiHgtg@mail.gmail.com>
References: <CAEQKoCHSLXiUV=jB_wrhRw9_h9ZAea_p_0Ymto8_CKCmFiHgtg@mail.gmail.com>
Message-ID: <0542019d-1168-ab2c-93f5-34b50aae594a@gmail.com>

On 19/05/2016 9:40 AM, Brian Smith wrote:
> Hi,
>
> I have a plot with log scale on the axes. How do I add ticks and labels in
> addition to the ones provided by default? Can I specify where I want the
> ticks and labels?
>
> For example:
>
> set.seed(12345)
> x <- sample(1:10000,10)
> y <- sample(1:10000,10)
>
> plot(x,y,log="xy")
>
>
> For me, this plot has tick marks (and labels) at 2000, 4000, 6000, 8000.
> How can I make the axes so that it has marks and labels at 1000 intervals
> (i.e. 2000, 3000, 4000, etc.)

You'll get ticks on side 1 (the x axis) by using

axis(1, at=1000*(2:10))

You'll get labels at some of those locations; R will leave some out, if 
it looks as though the labels will overlap.  Using las=2 will make them 
perpendicular to the axis, and all should be drawn.

Duncan Murdoch


From ivan.calandra at univ-reims.fr  Thu May 19 15:55:29 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Thu, 19 May 2016 15:55:29 +0200
Subject: [R] x-axis tick marks on log scale plot
In-Reply-To: <CAEQKoCHSLXiUV=jB_wrhRw9_h9ZAea_p_0Ymto8_CKCmFiHgtg@mail.gmail.com>
References: <CAEQKoCHSLXiUV=jB_wrhRw9_h9ZAea_p_0Ymto8_CKCmFiHgtg@mail.gmail.com>
Message-ID: <bedcd4f1-4132-e0d4-a6f3-63b60a0a8b60@univ-reims.fr>

Hi,

You can do it by first plotting your values without the x-axis:
plot(x,y,log="xy", xaxt="n")

and then plotting the x-axis with ticks where you need to:
axis(side=1, at=seq(2000,8000,1000))

HTH,
Ivan

--
Ivan Calandra, PhD
Scientific Mediator
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 19/05/2016 ? 15:40, Brian Smith a ?crit :
> Hi,
>
> I have a plot with log scale on the axes. How do I add ticks and labels in
> addition to the ones provided by default? Can I specify where I want the
> ticks and labels?
>
> For example:
>
> set.seed(12345)
> x <- sample(1:10000,10)
> y <- sample(1:10000,10)
>
> plot(x,y,log="xy")
>
>
> For me, this plot has tick marks (and labels) at 2000, 4000, 6000, 8000.
> How can I make the axes so that it has marks and labels at 1000 intervals
> (i.e. 2000, 3000, 4000, etc.)
>
> thanks!
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bsmith030465 at gmail.com  Thu May 19 17:04:55 2016
From: bsmith030465 at gmail.com (Brian Smith)
Date: Thu, 19 May 2016 11:04:55 -0400
Subject: [R] x-axis tick marks on log scale plot
In-Reply-To: <bedcd4f1-4132-e0d4-a6f3-63b60a0a8b60@univ-reims.fr>
References: <CAEQKoCHSLXiUV=jB_wrhRw9_h9ZAea_p_0Ymto8_CKCmFiHgtg@mail.gmail.com>
	<bedcd4f1-4132-e0d4-a6f3-63b60a0a8b60@univ-reims.fr>
Message-ID: <CAEQKoCHeQG4Grqb+fD326wFSUfVwDD4Pv5-BEJaGPJzBSupumw@mail.gmail.com>

Thanks all !!

On Thu, May 19, 2016 at 9:55 AM, Ivan Calandra <ivan.calandra at univ-reims.fr>
wrote:

> Hi,
>
> You can do it by first plotting your values without the x-axis:
> plot(x,y,log="xy", xaxt="n")
>
> and then plotting the x-axis with ticks where you need to:
> axis(side=1, at=seq(2000,8000,1000))
>
> HTH,
> Ivan
>
> --
> Ivan Calandra, PhD
> Scientific Mediator
> University of Reims Champagne-Ardenne
> GEGENAA - EA 3795
> CREA - 2 esplanade Roland Garros
> 51100 Reims, France
> +33(0)3 26 77 36 89
> ivan.calandra at univ-reims.fr
> --
> https://www.researchgate.net/profile/Ivan_Calandra
> https://publons.com/author/705639/
>
>
> Le 19/05/2016 ? 15:40, Brian Smith a ?crit :
>
>> Hi,
>>
>> I have a plot with log scale on the axes. How do I add ticks and labels in
>> addition to the ones provided by default? Can I specify where I want the
>> ticks and labels?
>>
>> For example:
>>
>> set.seed(12345)
>> x <- sample(1:10000,10)
>> y <- sample(1:10000,10)
>>
>> plot(x,y,log="xy")
>>
>>
>> For me, this plot has tick marks (and labels) at 2000, 4000, 6000, 8000.
>> How can I make the axes so that it has marks and labels at 1000 intervals
>> (i.e. 2000, 3000, 4000, etc.)
>>
>> thanks!
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rezvan.hatami_iut at yahoo.com  Thu May 19 09:47:36 2016
From: rezvan.hatami_iut at yahoo.com (rezvan hatami)
Date: Thu, 19 May 2016 07:47:36 +0000 (UTC)
Subject: [R] Fw:  R STUDIO crashing
In-Reply-To: <1389556561.4834058.1463643490526.JavaMail.yahoo@mail.yahoo.com>
References: <1589762996.4127148.1463567835159.JavaMail.yahoo.ref@mail.yahoo.com>
	<1589762996.4127148.1463567835159.JavaMail.yahoo@mail.yahoo.com>
	<CAGuGQcwEQR3AqhWe3VzOpTisUGzTnO=JLCMUUSmFfHOGj=1DMA@mail.gmail.com>
	<1389556561.4834058.1463643490526.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1699911980.4692349.1463644056726.JavaMail.yahoo@mail.yahoo.com>



     
----- Forwarded Message -----
 From: rezvan hatami <rezvan.hatami_iut at yahoo.com>
 To: Shige Song <shigesong at gmail.com> 
 Sent: Thursday, 19 May 2016, 17:38
 Subject: Re: [R] R STUDIO crashing
   
I didn't say that there is a problem with R or Rstudio. I said, it keeps crashing for whatever reason. If it is not crashing on your computer It doesn't mean that it never might crash. This is not help after keeping me waiting for long time. Such a waste of time corresponding with you.

      From: Shige Song <shigesong at gmail.com>
 To: rezvan hatami <rezvan.hatami_iut at yahoo.com> 
Cc: "r-help at r-project.org" <r-help at r-project.org>
 Sent: Thursday, 19 May 2016, 14:55
 Subject: Re: [R] R STUDIO crashing
  
One thing for sure: It's not the fault of R nor Rstudio (because they are doing fine on other people's computers, mine included). You can probably get some help on the Rstudio support forum. 

On Wed, May 18, 2016 at 6:37 PM, rezvan hatami via R-help <r-help at r-project.org> wrote:

Hi there
I have been using R for a while now. I am doing my PhD project with it. Recently, it keeps crashing, mostly when I draw a graph and use XYPLOT code. I even spent some money on cleaning registry, checking ram, deleting unnecessary files from working directory. I used "plot(cars) and?dev.off(). First the">" sign disappears from the console and then if I try to remove the plot or something else, the whole R freezes. When the ">" disappears, R doesn't run the commands anymore. I searched all online questions and answers, but I couldn't fix this. Please help me. PLEASE.
Cheers
Rezvan Hatami
? ? ? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



   

  
	[[alternative HTML version deleted]]


From lmr6c6 at mail.missouri.edu  Thu May 19 16:16:38 2016
From: lmr6c6 at mail.missouri.edu (Rees, Lisa Marie (MU-Student))
Date: Thu, 19 May 2016 14:16:38 +0000
Subject: [R] error in data.farme--duplicate row.names error
Message-ID: <BN3PR01MB1238DAA8FC88A7C5D2B2CA86924A0@BN3PR01MB1238.prod.exchangelabs.com>

I'm using the "GameTheory" package--- DefineGame(14,values) and values is equal to 16,383 observations.

I keep getting the following error-
[Error in data.frame(rep(0, 2^n - 1), row.names = Bmat) :
  duplicate row.names: 1, 11, 111, 12, 112, 1112, 11112, 13, 113, 1113, 11113, 1213, 11213, 111213, 1111213, 14, 114, 1114, 11114, 1214, 11214, 111214, 1111214, 1314, 11314, 111314, 1111314, 121314, 1121314, 11121314, 111121314]

What can I do to fix this issue?  I would greatly appreciate any help.

Thank you.



	[[alternative HTML version deleted]]


From shaila_jm at rediffmail.com  Thu May 19 16:32:26 2016
From: shaila_jm at rediffmail.com (shaila  shailaja)
Date: 19 May 2016 14:32:26 -0000
Subject: [R]
	=?utf-8?q?Placement_of_words_in_a_word_cloud_as_per_its_occur?=
	=?utf-8?q?ance=2E?=
Message-ID: <1463558645.S.7366.31169.f5-147-232.1463668346.19628@webmail.rediffmail.com>

Thank you Peter for pointing out my errors.

I shall take care of if henceforth.

To keep the mail short I left out the details, sorry about that.

&nbsp;



I am using&nbsp;wordcloud package&nbsp;to built a comparative and commonality cloud. 



My usage: 



comparison.cloud(term.matrix,max.words=300)commonality.cloud(term.matrix,random.order=FALSE, rot.per=0)



I am already&nbsp;doing a lot of preprocessing and the sentence is not limited to 1 or 2.

The words in the word cloud are placed in random order if random.order=FALSE then it is placed according to its frequency.

&nbsp;

I want the same order as the sentence minus the stop words.&nbsp; 

&nbsp;

Thanks,

ShailajaFrom: peter dalgaard &lt;pdalgd at gmail.com&gt;Sent: Wed, 18 May 2016 13:34:05 To: shaila shailaja &lt;shaila_jm at rediffmail.com&gt;Cc: "r-help at r-project.org" &lt;r-help at r-project.org&gt;Subject: Re: [R] Placement of words in a word cloud as per its occurance.A few points of order; you seem to be making a couple of rookie mistakes here. (Don't take it personally, lots of people do).1) Posting in HTML comes across garbled (and it can get much worse than what you see below), so please configure you mail program to avoid doing that.2) You seem to assume that we all immediately recognize the task you are working on and that there is a well-known and generally accepted methodology for which we just need to supply some detail that you have overlooked. In fact, the majority will be doing things in hundreds of different directions, and even those who are into wordclouds may be taking different approaches to it, there could be implementations in several packages, etc. Some people might be mildly interested in helping out (perhaps they want to make a wordcloud for themselves one day), but they would need to know what code you are using. As it stands, people are left wondering which function it might be that has an argument called random.order.- Peter DalgaardOn 17 May 2016, at 13:09 ,&nbsp;shaila shailaja &lt;shaila_jm at rediffmail.com&gt; wrote:&gt; Dear R help subscribers,&gt; &gt; &gt; &gt; &gt; I am working on a word cloud where in I want the words to appear in the same order as in the sentence/text. &gt; &gt; I only know&amp;nbsp;the random.order -&amp;nbsp;which plots words in random order. If false, they will be plotted in decreasing frequency.&gt; &gt; &amp;nbsp;&gt; &gt; Any help is most welcome.&gt; &gt; &amp;nbsp;&gt; &gt; Regards&gt; &gt; Shailaja&gt; &nbsp;&nbsp;&nbsp;[[alternative HTML version deleted]]&gt; &gt; ______________________________________________&gt; R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see&gt; https://stat.ethz.ch/mailman/listinfo/r-help&gt; PLEASE do read the posting
 guide http://www.R-project.org/posting-guide.html&gt; and provide commented, minimal, self-contained, reproducible code.-- Peter Dalgaard, Professor,Center for Statistics, Copenhagen Business SchoolSolbjerg Plads 3, 2000 Frederiksberg, DenmarkPhone: (+45)38153501Office: A 4.23Email: pd.mes at cbs.dk &nbsp;Priv: PDalgd at gmail.com______________________________________________R-help@r-project.org mailing list -- To UNSUBSCRIBE and more, seehttps://stat.ethz.ch/mailman/listinfo/r-helpPLEASE do read the posting guide http://www.R-project.org/posting-guide.htmland provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From marceloperlin at gmail.com  Thu May 19 16:49:48 2016
From: marceloperlin at gmail.com (Marcelo Perlin)
Date: Thu, 19 May 2016 11:49:48 -0300
Subject: [R] Can I use PhantomJS or assume a firefox instalattion for usage
 with RSelenium in CRAN Machines?
Message-ID: <CANMhtdz9bFR+5QaLW8sXxt6upduiayW-xn2xDrHphSkPMfBmPQ@mail.gmail.com>

Hi Guys,

First time posting here.

I have a CRAN package called GetTDData that downloads and reads public data
from a government website (
http://www.tesouro.fazenda.gov.br/tesouro-direto-balanco-e-estatisticas).

Recently (today), the website has changed its structure by removing
permanent links of the files and creating a "random" html address for the
files that really matter. This means that when I download the souce html
code, I don't have the information for the actual links, but just a bunch
of code.

In the past I have dealed with this type of problem by forcing the
renderization of the page using RSelenium with firefox or PhantomJS and
then capturing the desired href locations.

My question is, if integrate my code with RSelenium using firefox or
PhantonJS, will it pass on all arquitectures (win, linux, solaris) of CRAN?

I'm happy to hear any other ideas.

Many thanks!

-- 
Marcelo Perlin
Professor Adjunto | Escola de Administra??o
Universidade Federal do Rio Grande do Sul
Rua Washington Luiz, 855 | 90010-460| Porto Alegre RS| Brasil
Tel.: (51) 3308-3303 | www.ea.ufrgs.br
http://lattes.cnpq.br/3262699324398819
https://sites.google.com/site/marceloperlin/

	[[alternative HTML version deleted]]


From ashenkin at ufl.edu  Thu May 19 17:30:53 2016
From: ashenkin at ufl.edu (Alexander Shenkin)
Date: Thu, 19 May 2016 16:30:53 +0100
Subject: [R] remove fixed effect in predict.merMod
Message-ID: <8c56b6b7-dd52-be72-3e25-b2b8eaf6d17b@ufl.edu>

Hello all,

I've run a model, and now would like to extract residuals.  However, I 
have set sum-to-zero contrasts for the categorical fixed effect 
(contr.sum).  Because I am interested in looking at the variation in the 
residuals associated with that fixed effect (along with other levels), I 
need to calculate residuals setting that fixed effect to zero.  Any 
thoughts on how to do this?

thanks,
allie



contr.sum.keepnames <- function(...) {
     # make deviation contrasts that don't lose the names of the factors 
in the model results
     # from 
https://stackoverflow.com/questions/10808853/why-does-changing-contrast-type-change-row-labels-in-r-lm-summary
     conS <- contr.sum(...)
     colnames(conS) = rownames(conS)[-length(rownames(conS))]
     conS
}

test_df = data.frame(site = rep(LETTERS[1:10], 10), resp = runif(100), 
pred = runif(100))

contrasts(test_df$site) = contr.sum.keepnames(levels(test_df$site))

mod = lmer(resp ~ (1 + pred|site) + pred, data = test_df)

residuals = test_df$resp - predict(mod, REform=NA) # I would like the 
site effect here to be set to zero


From lists at dewey.myzen.co.uk  Thu May 19 18:04:51 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Thu, 19 May 2016 17:04:51 +0100
Subject: [R] error in data.farme--duplicate row.names error
In-Reply-To: <BN3PR01MB1238DAA8FC88A7C5D2B2CA86924A0@BN3PR01MB1238.prod.exchangelabs.com>
References: <BN3PR01MB1238DAA8FC88A7C5D2B2CA86924A0@BN3PR01MB1238.prod.exchangelabs.com>
Message-ID: <d12a1e01-aeaa-0b3c-af8d-fa53082a32cc@dewey.myzen.co.uk>

Dear Lisa

What does Bmat contain? Perhaps try table(table(Bmat)) and see if any 
entries are greater than unity.

On 19/05/2016 15:16, Rees, Lisa Marie (MU-Student) wrote:
> I'm using the "GameTheory" package--- DefineGame(14,values) and values is equal to 16,383 observations.
>
> I keep getting the following error-
> [Error in data.frame(rep(0, 2^n - 1), row.names = Bmat) :
>   duplicate row.names: 1, 11, 111, 12, 112, 1112, 11112, 13, 113, 1113, 11113, 1213, 11213, 111213, 1111213, 14, 114, 1114, 11114, 1214, 11214, 111214, 1111214, 1314, 11314, 111314, 1111314, 121314, 1121314, 11121314, 111121314]
>
> What can I do to fix this issue?  I would greatly appreciate any help.
>
> Thank you.
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From laomeng_3 at 163.com  Thu May 19 17:56:39 2016
From: laomeng_3 at 163.com (laomeng_3)
Date: Thu, 19 May 2016 23:56:39 +0800 (GMT+08:00)
Subject: [R] =?gbk?q?how_to_perform_multiple_comparison=A3=BF?=
Message-ID: <5c16f0c3.5c47.154c9bba8bb.Coremail.laomeng_3@163.com>

Hi all:
As to the anova, we can perform multiple comparison via TukeyHSD.
But as to chi-square test for frequency table,how to perform multiple comparison?

For example, if I want to compare 3 samples' ratio(the data has 3 rows,each row corresponds to 1 sample,and has 2 columns,each column corresponds to positive and negative respectively).


dat<-matrix(c(6,30,8,23,14,3),nrow=3)
dat
      [,1] [,2]
[1,]    6   23
[2,]   30   14
[3,]    8    3



chisq.test(dat)

       Pearson's Chi-squared test

data:  dat
X-squared = 17.9066, df = 2, p-value = 0.0001293


The result shows that the difference between the 3 samples is significant.But if I want to perform multiple comparison to find out which pair of samples is  significantly different,which function should be used?


Many thanks for your help.

My best



???? ????????????
	[[alternative HTML version deleted]]


From lmr6c6 at mail.missouri.edu  Thu May 19 18:16:03 2016
From: lmr6c6 at mail.missouri.edu (Rees, Lisa Marie (MU-Student))
Date: Thu, 19 May 2016 16:16:03 +0000
Subject: [R] error in data.farme--duplicate row.names error
In-Reply-To: <d12a1e01-aeaa-0b3c-af8d-fa53082a32cc@dewey.myzen.co.uk>
References: <BN3PR01MB1238DAA8FC88A7C5D2B2CA86924A0@BN3PR01MB1238.prod.exchangelabs.com>
	<d12a1e01-aeaa-0b3c-af8d-fa53082a32cc@dewey.myzen.co.uk>
Message-ID: <BN3PR01MB1238B46C62470688420A2F90924A0@BN3PR01MB1238.prod.exchangelabs.com>

Michael,

Thanks for your response.  

I tried table(table(Bmat)) and it gave me the following error:
[  Error in table(Bmat) : object 'Bmat' not found]

FYI--
"values" contains 16,383 observations ranging from 0 to less than 1.

Lisa



-----Original Message-----
From: Michael Dewey [mailto:lists at dewey.myzen.co.uk] 
Sent: Thursday, May 19, 2016 11:05 AM
To: Rees, Lisa Marie (MU-Student); r-help at r-project.org
Subject: Re: [R] error in data.farme--duplicate row.names error

Dear Lisa

What does Bmat contain? Perhaps try table(table(Bmat)) and see if any entries are greater than unity.

On 19/05/2016 15:16, Rees, Lisa Marie (MU-Student) wrote:
> I'm using the "GameTheory" package--- DefineGame(14,values) and values is equal to 16,383 observations.
>
> I keep getting the following error-
> [Error in data.frame(rep(0, 2^n - 1), row.names = Bmat) :
>   duplicate row.names: 1, 11, 111, 12, 112, 1112, 11112, 13, 113, 
> 1113, 11113, 1213, 11213, 111213, 1111213, 14, 114, 1114, 11114, 1214, 
> 11214, 111214, 1111214, 1314, 11314, 111314, 1111314, 121314, 1121314, 
> 11121314, 111121314]
>
> What can I do to fix this issue?  I would greatly appreciate any help.
>
> Thank you.
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

--
Michael
http://www.dewey.myzen.co.uk/home.html


From tom at maladmin.com  Thu May 19 21:18:49 2016
From: tom at maladmin.com (Tom Wright)
Date: Thu, 19 May 2016 15:18:49 -0400
Subject: [R] ggplot2 not displaying graph in RH7 RStudio Server 3.2.3
In-Reply-To: <951164527.246400416.1463576231392.JavaMail.root@zimbra65-e11.priv.proxad.net>
References: <10EA9A31-D825-4591-B1C7-904CE0F0672F@dcn.davis.ca.us>
	<951164527.246400416.1463576231392.JavaMail.root@zimbra65-e11.priv.proxad.net>
Message-ID: <CAKmUXV940C449QPnd5qGv1hm_Jqz61MgG6oHAAZ__3m6_sJOFw@mail.gmail.com>

I just tested your code on my debian install with no problems. RStudio
server logs messages to /var/log/messages (on redhat). Does running:

$ cat /var/log/messages |grep rsession

$ cat /var/log/messages |grep rserver

in the shell give any clues?



R version 3.2.5 (2016-04-14)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Debian GNU/Linux 8 (jessie)

locale:
 [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
 [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
LC_PAPER=en_CA.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] ggplot2_2.1.0

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.4        splines_3.2.5      MASS_7.3-45
munsell_0.4.3      colorspace_1.2-6   xtable_1.8-2
 [7] lattice_0.20-33    multcomp_1.4-4     minqa_1.2.4
plyr_1.8.3         tools_3.2.5        pbkrtest_0.4-6
[13] parallel_3.2.5     grid_3.2.5         nlme_3.1-126
gtable_0.2.0       TH.data_1.0-7      coda_0.18-1
[19] survival_2.38-3    lme4_1.1-11        Matrix_1.2-4
nloptr_1.0.4       codetools_0.2-14   labeling_0.3
[25] sandwich_2.3-4     estimability_1.1-1 lsmeans_2.23
scales_0.4.0       mvtnorm_1.0-5      zoo_1.7-12


On Wed, May 18, 2016 at 8:57 AM, <phiroc at free.fr> wrote:

>
>
> Here's a minimal example that displays a bar chart in RStudio 3.2.4 for
> Windows, but not in RStudio Server 3.2.3 on RH Linux 7:
>
> ------------------------------------------------------------------- R Code
> -------------------------------------------------------------------
>
> library(ggplot2)
> a <- c("ab", "bc", "cd")
> b <- c("de", "fg", "hi")
> ds <- data.frame(a,b)
> g1 <- ggplot(data = ds, aes(x=a))
> g1 + geom_bar(stat="count", fill=rainbow(3), colour="black") +
> xlab("Action & Description") + ylab("Count")  +  ggtitle("test") +
> coord_flip()
>
>
> ----------------------------------------------------------------------------------------------------------------------------------------------
>
> ----------------------------------------------------------- sessionInfo on
> Windows ----------------------------------------------------------
>
> R version 3.2.4 Revised (2016-03-16 r70336)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> States.1252
> [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] gridExtra_2.2.1 ggthemes_3.0.2  lubridate_1.5.0 RJDBC_0.2-5
>  rJava_0.9-8
> [6] DBI_0.3.1       ggplot2_2.1.0
>
> loaded via a namespace (and not attached):
>  [1] Rcpp_0.12.4        assertthat_0.1     grid_3.2.4         plyr_1.8.3
>  [5] gtable_0.2.0       magrittr_1.5       scales_0.4.0       stringi_1.0-1
>  [9] labeling_0.3       tools_3.2.4        stringr_1.0.0      munsell_0.4.3
> [13] rsconnect_0.4.1.11 colorspace_1.2-6
> >
>
>
> --------------------------------------------------------------------------------------------------------------------------------------------
>
> --------------------------------------------------------- sessionInfo on
> RH Linux 7 -------------------------------------------------------
>
> R version 3.2.3 (2015-12-10)
> Platform: x86_64-redhat-linux-gnu (64-bit)
> Running under: Red Hat Enterprise Linux
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  LC_MONETARY=en_US.UTF-8
>  [6] LC_MESSAGES=en_US.UTF-8    LC_PAPER=en_US.UTF-8       LC_NAME=C
>             LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] gridExtra_2.2.1 ggthemes_3.0.3  ggplot2_2.1.0   lubridate_1.5.6
> RJDBC_0.2-5     rJava_0.9-8     DBI_0.4-1
>
> loaded via a namespace (and not attached):
>  [1] Rcpp_0.12.5      assertthat_0.1   grid_3.2.3       plyr_1.8.3
>  gtable_0.2.0     magrittr_1.5     scales_0.4.0     stringi_1.0-1
>  [9] tools_3.2.3      stringr_1.0.0    munsell_0.4.3    colorspace_1.2-6
>
>
> ------------------------------------------------------------------------------------------------------------------------------------------
>
>
>
>
>
> ----- Mail original -----
> De: "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
> ?: phiroc at free.fr, r-help at r-project.org
> Envoy?: Mercredi 18 Mai 2016 14:36:50
> Objet: Re: [R] ggplot2 not displaying graph in RH7 RStudio Server 3.2.3
>
> Context is everything. Please follow the Posting Guide and provide a
> minimal reproducible example. Also, if your scripts are literally the same
> on the two platforms, you should provide the output of the sessionInfo()
> function for each.
> --
> Sent from my phone. Please excuse my brevity.
>
>
> On May 18, 2016 12:32:47 AM PDT, phiroc at free.fr wrote:
>
>
> Hello,
>
> I have written an R script which displays a bar chart using the ggplot2
> library (please refer
> to code excerpt at the bottom of this e-mail).
>
> Although the bar chart is displayed OK in the Windows version of RStudio
> (v. 3.2.4),
> nothing appears on Linux RH 7 in Rstudio Server 3.2.3.
>
> I have tried replacing the data frame in the RH-version of the script by
>
>
>
>
> a <- c("ab", "bc", "cd")
> b <- c(1, 2, 3)
> ds <- data.frame(a,b)
> g1 <- ggplot(data = ds, aes(x = a))
>
>
>
>
>
> ... but to avail: ggplot doesn't plot anything. No error message are
> displayed.
>
> Any help with this issue would be much appreciated.
>
> Many thanks.
>
> phiroc
>
>
> ----------------------------- R Code Excerpt
>
>
>
> g1 <- ggplot(data = mergedD, aes(x=DESC_TYPE))
> g1 + geom_bar(stat="count",
> fill=rainbow(numberOfDistinctActions), colour="black") +
> xlab("Action & Description") +
> ylab("Count")  +
> ggtitle(paste0(
> "Number of Customer Actions in XXX from ", day0, "/", mon,
> "/", year, " to ", day1, "/", mon, "/", year,
> " in Paris & Hong Kong")) +
> coord_flip()
>
>
>
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Thu May 19 21:55:13 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 19 May 2016 19:55:13 +0000
Subject: [R] Vectorised operations
In-Reply-To: <CAF8bMcZVi1rJv8eTJ0MnxqgQP=8PC4m3mtgryKQC0-Gt23sB3g@mail.gmail.com>
References: <57342100db38c7a9ac572036b30008d8.squirrel@quantex.zedcore.com>
	<CAF8bMcZVi1rJv8eTJ0MnxqgQP=8PC4m3mtgryKQC0-Gt23sB3g@mail.gmail.com>
Message-ID: <D36365DD.17461B%macqueen1@llnl.gov>

In keeping with the theme of reducing unnecessary overhead
(and using William's example data)

> system.time( vAve <- ave(a, i, FUN=cummax) )
   user  system elapsed
  0.125   0.003   0.127
> system.time( b <- unlist( lapply( split(a,i) , cummax) ) )
   user  system elapsed
  0.320   0.007   0.327
> system.time( b <- unlist( lapply( split(a,i) , cummax) ,
>use.names=FALSE) )
   user  system elapsed
  0.067   0.001   0.068



> all.equal(vAve, b)
[1] TRUE

Apparently, quite a bit of overhead associated with keeping the names when
unlisting.


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 5/18/16, 7:26 AM, "R-help on behalf of William Dunlap via R-help"
<r-help-bounces at r-project.org on behalf of r-help at r-project.org> wrote:

>ave(A, i, FUN=cummax) loops but is faster than your aggregate-based
>solution.  E.g.,
>
>> i <- rep(1:10000, sample(0:210, replace=TRUE, size=10000))
>> length(i)
>[1] 1056119
>> a <- sample(-50:50, replace=TRUE, size=length(i))
>> system.time( vAve <- ave(a, i, FUN=cummax) )
>   user  system elapsed
>   0.13    0.03    0.16
>> system.time( vAggregate <-
>as.vector(unlist(aggregate(a,list(i),cummax)[[2]])) )
>   user  system elapsed
>   1.81    0.13    1.98
>> all.equal(vAve, vAggregate)
>[1] TRUE
>
>
>
>Bill Dunlap
>TIBCO Software
>wdunlap tibco.com
>
>On Wed, May 18, 2016 at 6:32 AM, John Logsdon <
>j.logsdon at quantex-research.com> wrote:
>
>> Folks
>>
>> I have some very long vectors - typically 1 million long - which are
>> indexed by another vector, same length, with values from 1 to a few
>> thousand, sp each sub part of the vector may be a few hundred values
>>long.
>>
>> I want to calculate the cumulative maximum of each sub part the main
>> vector by the index in an efficient manner.  This can obviously be done
>>in
>> a loop but the whole calculation is embedded within many other
>> calculations which would make everything very slow indeed.  All the
>>other
>> sums are vectorised already.
>>
>> For example,
>>
>> A=c(1,2,1,  -3,5,6,7,4,  6,3,7,6,9, ...)
>> i=c(1,1,1,   2,2,2,2,2,  3,3,3,3,3, ...)
>>
>> where A has three levels that are not the same but the levels themselves
>> are all monotonic non-decreasing.
>>
>> the answer to be a vector of the same length:
>>
>> R=c(1,2,2,  -3,5,6,7,7,  6,6,7,7,9, ...)
>>
>> If I could reset the cumulative maximum to -1e6 (eg) at each change of
>> index, a simple cummax would do but I can't see how to do this.
>>
>> The best way I have found so far is to use the aggregate command:
>>
>> as.vector(unlist(aggregate(a,list(i),cummax)[[2]]))
>>
>> but rarely this fails, returning a shorter vector than expected and
>>seems
>> rather ugly,  converting to and from lists which may well be an
>> unnecessary overhead.
>>
>> I have been trying other approaches using apply() methods but either it
>> can't be done using them or I can't get my head round them!
>>
>> Any ideas?
>>
>> Best wishes
>>
>> John
>>
>> John Logsdon
>> Quantex Research Ltd
>> +44 161 445 4951/+44 7717758675
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> 
>>https://secure-web.cisco.com/1db6hsP9YKn27F8A9c3lLtE4FDoYVpnnKmVgP0ZTGuPp
>>rrXWaCCwKPZt-pMgmapmF56MrgngzykSrZV_gXR2fFi1PX6vWBRDFYUhqF2AyuCUF2v4-ZN-8
>>q7fO3mBBnj_2k4lYyx46FqHtq2YNFkc-Hsh3zRxdA0WP8-5LlqRS76CzguBuwflIHhF6RC9n8
>>bi4GGTgNwUAZkfBIBU1Sq2Um1UovWcAe6Su1C7PC6N8LMqOBxCzdIjLT5P_esNZi3t5WiA7U9
>>DdEXxH-RdLJVyrMLmjvyuoCBYponGY4gRxSKSAIB-PuWULy7N1CGCGfMbmeN5tF1NsCnENwLS
>>NH29UinTSrcPwdtvMMh_2PKZ0CjY/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flisti
>>nfo%2Fr-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://secure-web.cisco.com/1db6hsP9YKn27F8A9c3lLtE4FDoYVpnnKmVgP0ZTGuPpr
>rXWaCCwKPZt-pMgmapmF56MrgngzykSrZV_gXR2fFi1PX6vWBRDFYUhqF2AyuCUF2v4-ZN-8q7
>fO3mBBnj_2k4lYyx46FqHtq2YNFkc-Hsh3zRxdA0WP8-5LlqRS76CzguBuwflIHhF6RC9n8bi4
>GGTgNwUAZkfBIBU1Sq2Um1UovWcAe6Su1C7PC6N8LMqOBxCzdIjLT5P_esNZi3t5WiA7U9DdEX
>xH-RdLJVyrMLmjvyuoCBYponGY4gRxSKSAIB-PuWULy7N1CGCGfMbmeN5tF1NsCnENwLSNH29U
>inTSrcPwdtvMMh_2PKZ0CjY/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2F
>r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>


From bgunter.4567 at gmail.com  Thu May 19 22:16:26 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 19 May 2016 13:16:26 -0700
Subject: [R] Fw: R STUDIO crashing
In-Reply-To: <1699911980.4692349.1463644056726.JavaMail.yahoo@mail.yahoo.com>
References: <1589762996.4127148.1463567835159.JavaMail.yahoo.ref@mail.yahoo.com>
	<1589762996.4127148.1463567835159.JavaMail.yahoo@mail.yahoo.com>
	<CAGuGQcwEQR3AqhWe3VzOpTisUGzTnO=JLCMUUSmFfHOGj=1DMA@mail.gmail.com>
	<1389556561.4834058.1463643490526.JavaMail.yahoo@mail.yahoo.com>
	<1699911980.4692349.1463644056726.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAGxFJbTSNXpK6OOk+u30quVuqXaWiRQ3aTHK9VjNxR3ccp3VYw@mail.gmail.com>

Rezvan:

"This is not help after keeping me waiting for long time. Such a waste
of time corresponding with you. "


You do understand that this is entirely a volunteer effort, do you
not? There is no guarantee that you will get any response at all, nor
that any that you do receive is actually helpful -- or even correct!
Caveat Emptor! (and your of getting useful help would probably be
improved by following the posting guide and exhibiting courteous,
respectful behavior to those who are volunteering their time to assist
you).


Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, May 19, 2016 at 12:47 AM, rezvan hatami via R-help
<r-help at r-project.org> wrote:
>
>
>
> ----- Forwarded Message -----
>  From: rezvan hatami <rezvan.hatami_iut at yahoo.com>
>  To: Shige Song <shigesong at gmail.com>
>  Sent: Thursday, 19 May 2016, 17:38
>  Subject: Re: [R] R STUDIO crashing
>
> I didn't say that there is a problem with R or Rstudio. I said, it keeps crashing for whatever reason. If it is not crashing on your computer It doesn't mean that it never might crash. This is not help after keeping me waiting for long time. Such a waste of time corresponding with you.
>
>       From: Shige Song <shigesong at gmail.com>
>  To: rezvan hatami <rezvan.hatami_iut at yahoo.com>
> Cc: "r-help at r-project.org" <r-help at r-project.org>
>  Sent: Thursday, 19 May 2016, 14:55
>  Subject: Re: [R] R STUDIO crashing
>
> One thing for sure: It's not the fault of R nor Rstudio (because they are doing fine on other people's computers, mine included). You can probably get some help on the Rstudio support forum.
>
> On Wed, May 18, 2016 at 6:37 PM, rezvan hatami via R-help <r-help at r-project.org> wrote:
>
> Hi there
> I have been using R for a while now. I am doing my PhD project with it. Recently, it keeps crashing, mostly when I draw a graph and use XYPLOT code. I even spent some money on cleaning registry, checking ram, deleting unnecessary files from working directory. I used "plot(cars) and dev.off(). First the">" sign disappears from the console and then if I try to remove the plot or something else, the whole R freezes. When the ">" disappears, R doesn't run the commands anymore. I searched all online questions and answers, but I couldn't fix this. Please help me. PLEASE.
> Cheers
> Rezvan Hatami
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From YXLL at pge.com  Thu May 19 22:31:10 2016
From: YXLL at pge.com (Lin, Ye)
Date: Thu, 19 May 2016 20:31:10 +0000
Subject: [R] No map background showed up when adding tile in leaflet()
Message-ID: <04555991BCE2934483554C4DD31D51344CC11E48@EXCHMBFF232.Utility.pge.com>

Hey All,

I am learning to create a map with leaflet(), but my default map background won't show up, its just grey.

Here is my code:

leaflet() %>% addTiles()
addCircleMarkers(lng=points$lon,lat=points$lat,
                         radius=6,stroke=FALSE,fillOpacity = 0.5)

When I run the code, the markers show up and interaction of zoom in/out works okay, but background is always solid grey, not sure why. I tried "addProviderTiles("Stamen.TonerLabels")" as well, does not work out.

Thanks for your help in advance.

We respect your privacy. Please review our privacy policy for more information.
http://www.pge.com/en/about/company/privacy/customer/index.page

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Thu May 19 23:26:43 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 19 May 2016 21:26:43 +0000
Subject: [R] error in data.farme--duplicate row.names error
Message-ID: <D3637D0C.174709%macqueen1@llnl.gov>

You will probably have to contact the maintainer of the package, since the
error appears to be generated inside the package's function.

Immediately after the error, type
  traceback()
The results might give you a clue. Or they might not!

There might be some requirements on the second argument of the
DefineGame() function. Check the help page for DefineGame and see if the
object you supplied, value, meets those requirements.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 5/19/16, 7:16 AM, "R-help on behalf of Rees, Lisa Marie (MU-Student)"
<r-help-bounces at r-project.org on behalf of lmr6c6 at mail.missouri.edu> wrote:

>I'm using the "GameTheory" package--- DefineGame(14,values) and values is
>equal to 16,383 observations.
>
>I keep getting the following error-
>[Error in data.frame(rep(0, 2^n - 1), row.names = Bmat) :
>  duplicate row.names: 1, 11, 111, 12, 112, 1112, 11112, 13, 113, 1113,
>11113, 1213, 11213, 111213, 1111213, 14, 114, 1114, 11114, 1214, 11214,
>111214, 1111214, 1314, 11314, 111314, 1111314, 121314, 1121314, 11121314,
>111121314]
>
>What can I do to fix this issue?  I would greatly appreciate any help.
>
>Thank you.
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From syen04 at gmail.com  Fri May 20 01:09:06 2016
From: syen04 at gmail.com (Steven Yen)
Date: Thu, 19 May 2016 19:09:06 -0400
Subject: [R] Grep command
Message-ID: <b988efd2-cacd-60c3-0fd2-af7ed2b33794@gmail.com>

What is a good way to grep multiple strings (say in a vector)? In the 
following, I grep ants, cats, and fox separately and concatenate them, 
is there a way to grep the trio in one action? Thanks.

all<-c("ants","birds","cats","dogs","elks","fox"); all
[1] "ants"  "birds" "cats"  "dogs"  "elks"  "fox"
some<-c("ants","cats","fox"); some
[1] "ants" "cats" "fox"
j<-c(
   grep(some[1],all,value=F),
   grep(some[2],all,value=F),
   grep(some[3],all,value=F)); j; all[j]
[1] 1 3 6
[1] "ants" "cats" "fox"


	[[alternative HTML version deleted]]


From peter.langfelder at gmail.com  Fri May 20 01:47:49 2016
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Thu, 19 May 2016 16:47:49 -0700
Subject: [R] Grep command
In-Reply-To: <b988efd2-cacd-60c3-0fd2-af7ed2b33794@gmail.com>
References: <b988efd2-cacd-60c3-0fd2-af7ed2b33794@gmail.com>
Message-ID: <CA+hbrhU+Aud-qikp-aJDc2Z=GizM2i8wKJqGjo-9BAAdfu9wXg@mail.gmail.com>

I use my own functions multiGrep and multiGrepl:

multiGrep = function(patterns, x, ..., sort = TRUE, invert = FALSE)
{
  if (invert)
  {
    out = multiIntersect(lapply(patterns, grep, x, ..., invert = TRUE))
  } else
    out = unique(unlist(lapply(patterns, grep, x, ..., invert = FALSE)));
  if (sort) out = sort(out);
  out;
}

multiGrepl = function(patterns, x, ...)
{
  mat = do.call(cbind, lapply(patterns, function(p)
as.numeric(grepl(p, x, ...))));
  rowSums(mat)>0;
}

> multiGrep(some, all)
[1] 1 3 6

> multiGrepl(some, all)
[1]  TRUE FALSE  TRUE FALSE FALSE  TRUE

multiGrep(some, all, invert = TRUE)
[1] 2 4 5

Peter


On Thu, May 19, 2016 at 4:09 PM, Steven Yen <syen04 at gmail.com> wrote:
> What is a good way to grep multiple strings (say in a vector)? In the
> following, I grep ants, cats, and fox separately and concatenate them,
> is there a way to grep the trio in one action? Thanks.
>
> all<-c("ants","birds","cats","dogs","elks","fox"); all
> [1] "ants"  "birds" "cats"  "dogs"  "elks"  "fox"
> some<-c("ants","cats","fox"); some
> [1] "ants" "cats" "fox"
> j<-c(
>    grep(some[1],all,value=F),
>    grep(some[2],all,value=F),
>    grep(some[3],all,value=F)); j; all[j]
> [1] 1 3 6
> [1] "ants" "cats" "fox"
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri May 20 01:51:15 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 19 May 2016 16:51:15 -0700
Subject: [R] Can I use PhantomJS or assume a firefox instalattion for
	usage with RSelenium in CRAN Machines?
In-Reply-To: <CANMhtdz9bFR+5QaLW8sXxt6upduiayW-xn2xDrHphSkPMfBmPQ@mail.gmail.com>
References: <CANMhtdz9bFR+5QaLW8sXxt6upduiayW-xn2xDrHphSkPMfBmPQ@mail.gmail.com>
Message-ID: <A7F9F46A-121B-4E75-B13D-447AFDE42255@comcast.net>


> On May 19, 2016, at 7:49 AM, Marcelo Perlin <marceloperlin at gmail.com> wrote:
> 
> Hi Guys,
> 
> First time posting here.
> 
> I have a CRAN package called GetTDData that downloads and reads public data
> from a government website (
> http://www.tesouro.fazenda.gov.br/tesouro-direto-balanco-e-estatisticas).
> 
> Recently (today), the website has changed its structure by removing
> permanent links of the files and creating a "random" html address for the
> files that really matter. This means that when I download the souce html
> code, I don't have the information for the actual links, but just a bunch
> of code.
> 
> In the past I have dealed with this type of problem by forcing the
> renderization of the page using RSelenium with firefox or PhantomJS and
> then capturing the desired href locations.
> 
> My question is, if integrate my code with RSelenium using firefox or
> PhantonJS, will it pass on all arquitectures (win, linux, solaris) of CRAN?

I dn't have a lot of experience at this but I can say that at least one person whose experience I trust recentlyreported in Rhelp that RSelenium tends to be a fragile interface. Nonetheless, he does use it on occasion and it clearly "works" on more than one platform. If your code is not confidential and the website has at least a guest login capacity, you could post it here and ask for trial runs on whatever platform(s) you may not have testing capacities for.

> 
> -- 
> Marcelo Perlin
> Professor Adjunto | Escola de Administra??o

--

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Fri May 20 01:57:22 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 19 May 2016 16:57:22 -0700
Subject: [R] Grep command
In-Reply-To: <b988efd2-cacd-60c3-0fd2-af7ed2b33794@gmail.com>
References: <b988efd2-cacd-60c3-0fd2-af7ed2b33794@gmail.com>
Message-ID: <CA998306-C0F0-474D-855A-4764BF10B977@comcast.net>


> On May 19, 2016, at 4:09 PM, Steven Yen <syen04 at gmail.com> wrote:
> 
> What is a good way to grep multiple strings (say in a vector)? In the 
> following, I grep ants, cats, and fox separately and concatenate them, 
> is there a way to grep the trio in one action? Thanks.
> 
> all<-c("ants","birds","cats","dogs","elks","fox"); all
> [1] "ants"  "birds" "cats"  "dogs"  "elks"  "fox"
> some<-c("ants","cats","fox"); some
> [1] "ants" "cats" "fox"
> j<-c(
>   grep(some[1],all,value=F),
>   grep(some[2],all,value=F),
>   grep(some[3],all,value=F)); j; all[j]
> [1] 1 3 6
> [1] "ants" "cats" "fox"

j <- grep( paste0( some, collapse="|") , all ); j; all[j]
#----------
[1] 1 3 6
[1] "ants" "cats" "fox" 

-- 

David Winsemius
Alameda, CA, USA


From macqueen1 at llnl.gov  Fri May 20 01:58:48 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 19 May 2016 23:58:48 +0000
Subject: [R] Grep command
In-Reply-To: <b988efd2-cacd-60c3-0fd2-af7ed2b33794@gmail.com>
References: <b988efd2-cacd-60c3-0fd2-af7ed2b33794@gmail.com>
Message-ID: <D363A0CE.1747A1%macqueen1@llnl.gov>

Start with:

> all <- c("ants","birds","cats","dogs","elks","fox")
> all[grep('ants|cats|fox',all)]
[1] "ants" "cats" "fox"

Then construct the first arg to grep:

> some <- c("ants","cats","fox")
> all[ grep( paste(some,collapse='|') , all)]
[1] "ants" "cats" "fox"



-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 5/19/16, 4:09 PM, "R-help on behalf of Steven Yen"
<r-help-bounces at r-project.org on behalf of syen04 at gmail.com> wrote:

>What is a good way to grep multiple strings (say in a vector)? In the
>following, I grep ants, cats, and fox separately and concatenate them,
>is there a way to grep the trio in one action? Thanks.
>
>all<-c("ants","birds","cats","dogs","elks","fox"); all
>[1] "ants"  "birds" "cats"  "dogs"  "elks"  "fox"
>some<-c("ants","cats","fox"); some
>[1] "ants" "cats" "fox"
>j<-c(
>   grep(some[1],all,value=F),
>   grep(some[2],all,value=F),
>   grep(some[3],all,value=F)); j; all[j]
>[1] 1 3 6
>[1] "ants" "cats" "fox"
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Fri May 20 02:19:00 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 20 May 2016 10:19:00 +1000
Subject: [R] =?utf-8?q?how_to_perform_multiple_comparison=EF=BC=9F?=
In-Reply-To: <5c16f0c3.5c47.154c9bba8bb.Coremail.laomeng_3@163.com>
References: <5c16f0c3.5c47.154c9bba8bb.Coremail.laomeng_3@163.com>
Message-ID: <CA+8X3fWAe8yV0V-5Wz=CbeXJgD0T-f43UkVJnGb3OJBbXVBmSw@mail.gmail.com>

Hi laomeng_3,
Have a look at the padjust function (stats).

Jim


On Fri, May 20, 2016 at 1:56 AM, laomeng_3 <laomeng_3 at 163.com> wrote:
> Hi all:
> As to the anova, we can perform multiple comparison via TukeyHSD.
> But as to chi-square test for frequency table,how to perform multiple comparison?
>
> For example, if I want to compare 3 samples' ratio(the data has 3 rows,each row corresponds to 1 sample,and has 2 columns,each column corresponds to positive and negative respectively).
>
>
> dat<-matrix(c(6,30,8,23,14,3),nrow=3)
> dat
>       [,1] [,2]
> [1,]    6   23
> [2,]   30   14
> [3,]    8    3
>
>
>
> chisq.test(dat)
>
>        Pearson's Chi-squared test
>
> data:  dat
> X-squared = 17.9066, df = 2, p-value = 0.0001293
>
>
> The result shows that the difference between the 3 samples is significant.But if I want to perform multiple comparison to find out which pair of samples is  significantly different,which function should be used?
>
>
> Many thanks for your help.
>
> My best
>
>
>
> ?? ??????
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri May 20 03:48:26 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 19 May 2016 18:48:26 -0700
Subject: [R] =?utf-8?q?how_to_perform_multiple_comparison=EF=BC=9F?=
In-Reply-To: <CA+8X3fWAe8yV0V-5Wz=CbeXJgD0T-f43UkVJnGb3OJBbXVBmSw@mail.gmail.com>
References: <5c16f0c3.5c47.154c9bba8bb.Coremail.laomeng_3@163.com>
	<CA+8X3fWAe8yV0V-5Wz=CbeXJgD0T-f43UkVJnGb3OJBbXVBmSw@mail.gmail.com>
Message-ID: <F6E32B66-762E-4BC3-946C-93AE36B24BA8@comcast.net>


> On May 19, 2016, at 5:19 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> 
> Hi laomeng_3,
> Have a look at the padjust function (stats).
> 
> Jim
> 
> 
> On Fri, May 20, 2016 at 1:56 AM, laomeng_3 <laomeng_3 at 163.com> wrote:
>> Hi all:
>> As to the anova, we can perform multiple comparison via TukeyHSD.
>> But as to chi-square test for frequency table,how to perform multiple comparison?
>> 
>> For example, if I want to compare 3 samples' ratio(the data has 3 rows,each row corresponds to 1 sample,and has 2 columns,each column corresponds to positive and negative respectively).
>> 
>> 
>> dat<-matrix(c(6,30,8,23,14,3),nrow=3)
>> dat
>>      [,1] [,2]
>> [1,]    6   23
>> [2,]   30   14
>> [3,]    8    3
>> 
>> 
>> 
>> chisq.test(dat)
>> 
>>       Pearson's Chi-squared test
>> 
>> data:  dat
>> X-squared = 17.9066, df = 2, p-value = 0.0001293
>> 
>> 
>> The result shows that the difference between the 3 samples is significant.But if I want to perform multiple comparison to find out which pair of samples is  significantly different,which function should be used?
>> 

It appears your question is which row(s) are contributing most greatly to the overall test of independence. The result of a `chisq.test(.)` (which is not what you see from its print method) has a component named residuals. (Read the help page : ?chisq.test)

x2 <- chisq.test(dat)
x2$residuals
           [,1]       [,2]
[1,] -2.3580463  2.4731398
[2,]  1.4481733 -1.5188569
[3,]  0.9323855 -0.9778942



Those row sums should be distributed as chi-squared statistics with one degree of freedom each, but since you have admittedly inflated the possibility of the type I error, it would be sensible to adjust the "p-statistics" using the function that Jim Lemon misspelled:

> rowSums(x2$residuals^2)
[1] 11.676803  4.404132  1.825620

> p.adjust( 1- pchisq( rowSums(x2$residuals^2), 1) )

[1] 0.001898526 0.071703921 0.176645786

So row 1 represents the only group that is "significantly different at the conventional level" from the expectations based on the overall sample collection. I also seem to remember that there is a function named CrossTable (in a package whose name I'm forgetting) that will deliver a SAS-style tabulation of row and column chi-squared statistics.

-- 
David.

>> 
>> Many thanks for your help.
>> 
>> My best
>> 
>> 
>> 
>> ?? ??????
>>        [[alternative HTML version deleted]]
>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From joycerobbins1 at gmail.com  Fri May 20 02:03:21 2016
From: joycerobbins1 at gmail.com (Joyce Robbins)
Date: Thu, 19 May 2016 20:03:21 -0400
Subject: [R] Grep command
In-Reply-To: <D363A0CE.1747A1%macqueen1@llnl.gov>
References: <b988efd2-cacd-60c3-0fd2-af7ed2b33794@gmail.com>
	<D363A0CE.1747A1%macqueen1@llnl.gov>
Message-ID: <CAM91838jMyGAiywHrWd5kqE9PTpQyGWoUkz0K2TQ7tEtQM-qHg@mail.gmail.com>

I'm not sure you need grep:

> all %in% some
[1]  TRUE FALSE  TRUE FALSE FALSE  TRUE

On Thu, May 19, 2016 at 7:58 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:

> Start with:
>
> > all <- c("ants","birds","cats","dogs","elks","fox")
> > all[grep('ants|cats|fox',all)]
> [1] "ants" "cats" "fox"
>
> Then construct the first arg to grep:
>
> > some <- c("ants","cats","fox")
> > all[ grep( paste(some,collapse='|') , all)]
> [1] "ants" "cats" "fox"
>
>
>
> --
> Don MacQueen
>
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
>
>
>
>
>
> On 5/19/16, 4:09 PM, "R-help on behalf of Steven Yen"
> <r-help-bounces at r-project.org on behalf of syen04 at gmail.com> wrote:
>
> >What is a good way to grep multiple strings (say in a vector)? In the
> >following, I grep ants, cats, and fox separately and concatenate them,
> >is there a way to grep the trio in one action? Thanks.
> >
> >all<-c("ants","birds","cats","dogs","elks","fox"); all
> >[1] "ants"  "birds" "cats"  "dogs"  "elks"  "fox"
> >some<-c("ants","cats","fox"); some
> >[1] "ants" "cats" "fox"
> >j<-c(
> >   grep(some[1],all,value=F),
> >   grep(some[2],all,value=F),
> >   grep(some[3],all,value=F)); j; all[j]
> >[1] 1 3 6
> >[1] "ants" "cats" "fox"
> >
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From michael.eisenring at agroscope.admin.ch  Fri May 20 09:11:37 2016
From: michael.eisenring at agroscope.admin.ch (michael.eisenring at agroscope.admin.ch)
Date: Fri, 20 May 2016 07:11:37 +0000
Subject: [R] Change sum of squares type for ANOVA
Message-ID: <6D5C009FB51EBD41BEE57F4C002350FD09E63F@SB00112A.adb.intra.admin.ch>

Dear R-list members,

I compared my statistics with my supervisor yesterday. He is using STATISTICA, I am using R. We both loaded the same data-file and did a two-way ANOVA with treatment and trial as factors; treatment means were then compared to the untreated control using Dunnett's test. Surprisingly, we got different values, especially the F values differed. In the following Dunnett's test, some treatments were significant in R, but not in STATISTICA. We checked the basic settings of the programs and found out, that STATISTICA is using "sigma-restricted parametrization" and "type VI sum of squares" for the calculations, but so far, I could not find any information about the sum of squares type, which is applied in R. Is it possible, that these settings are the reason for the different values we got? And how can I change in R these settings?

Here the code I used:
bt_assay_devtime_Model <- aov(developmenttime~treatment+run+treatment*run, data=bt_assay)
summary(bt_assay_devtime_Model)
postHocs_bt_assay_devtime <- glht(bt_assay_devtime_Model, linfct=mcp(treatment="Dunnett"), base=1)
summary(postHocs_bt_assay_devtime)
confint(postHocs_bt_assay_devtime)

Thanks a lot for your help!
Simone

Eisenring Michael, Msc.
PhD Student

Federal Department of Economic Affairs, Education and Research
EAER
Institute of Sustainability Sciences ISS
Biosafety

Reckenholzstrasse 191, CH-8046 Z?rich
Tel. +41 44 37 77181
Fax +41 44 37 77201
michael.eisenring at agroscope.admin.ch<mailto:michael.eisenring at agroscope.admin.ch>
www.agroscope.ch<http://www.agroscope.ch/>


	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Fri May 20 11:21:41 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 20 May 2016 11:21:41 +0200
Subject: [R] x-axis tick marks on log scale plot
In-Reply-To: <CAEQKoCHeQG4Grqb+fD326wFSUfVwDD4Pv5-BEJaGPJzBSupumw@mail.gmail.com>
References: <CAEQKoCHSLXiUV=jB_wrhRw9_h9ZAea_p_0Ymto8_CKCmFiHgtg@mail.gmail.com>
	<bedcd4f1-4132-e0d4-a6f3-63b60a0a8b60@univ-reims.fr>
	<CAEQKoCHeQG4Grqb+fD326wFSUfVwDD4Pv5-BEJaGPJzBSupumw@mail.gmail.com>
Message-ID: <22334.55077.655497.177441@stat.math.ethz.ch>

>>>>> Brian Smith <bsmith030465 at gmail.com>
>>>>>     on Thu, 19 May 2016 11:04:55 -0400 writes:

    > Thanks all !!  On Thu, May 19, 2016 at 9:55 AM, Ivan
    > Calandra <ivan.calandra at univ-reims.fr> wrote:

    >> Hi,
    >> 
    >> You can do it by first plotting your values without the
    >> x-axis: plot(x,y,log="xy", xaxt="n")
    >> 
    >> and then plotting the x-axis with ticks where you need to:
    >> axis(side=1, at=seq(2000,8000,1000))

Getting nicer looking axis ticks  for log-scale axes (and
traditional graphics) I have created the function
   eaxis()
and utility function    pretty10exp(.)

and I also created standard R's  axTicks(.)  to help with these.

    if(!require("sfsmisc")) install.packages("sfsmisc")
    require("sfsmisc")

    x <- lseq(1e-10, 0.1, length = 201)
    plot(x, pt(x, df=3), type = "l", xaxt = "n", log = "x")
    eaxis(1)

gives the attached plot

-------------- next part --------------
A non-text attachment was scrubbed...
Name: eaxis-log-example.pdf
Type: application/pdf
Size: 5931 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160520/1a82043a/attachment.pdf>

From Aljosa.Aleksandrovic at man.com  Fri May 20 13:51:36 2016
From: Aljosa.Aleksandrovic at man.com (Aleksandrovic, Aljosa (Pfaeffikon))
Date: Fri, 20 May 2016 11:51:36 +0000
Subject: [R] Linear Regressions with non-negativity constraint
Message-ID: <d04734bb787f416890ea8163f658641f@PLONINEXMS136.maninvestments.ad.man.com>

Hi all,

I hope you are doing well?

I'm currently using lm() to estimate a linear multi-factor (5 factors without intercept) model as follows ...

factor.lm <- lm(y~x1+x2+x3+x4+x5-1, data = data.frame.rbind)

Using nnls(A,b) I estimated the same model, extended by a non-negativity constraint on the 5 independent factors. It works quite well but unfortunately nnls() only returns the x estimates. Is there a way to extract the Std.Errors, t-values, p-valuess and R^2 as well?

Thanks in advance and kind regards, 
Aljosa



Aljosa Aleksandrovic, FRM, CAIA
Senior Quantitative Analyst - Convertibles
aljosa.aleksandrovic at man.com
Tel +41 55 417 76 03

Man Investments (CH) AG
Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Aleksandrovic, Aljosa (Pfaeffikon)
Sent: Donnerstag, 28. April 2016 15:06
To: Gabor Grothendieck
Cc: r-help at r-project.org
Subject: Re: [R] Linear Regressions with constraint coefficients

Thx a lot Gabor!

Aljosa Aleksandrovic, FRM, CAIA
Quantitative Analyst - Convertibles
aljosa.aleksandrovic at man.com
Tel +41 55 417 76 03

Man Investments (CH) AG
Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland


-----Original Message-----
From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com]
Sent: Donnerstag, 28. April 2016 14:48
To: Aleksandrovic, Aljosa (Pfaeffikon)
Cc: r-help at r-project.org
Subject: Re: [R] Linear Regressions with constraint coefficients

The nls2 package can be used to get starting values.

On Thu, Apr 28, 2016 at 8:42 AM, Aleksandrovic, Aljosa (Pfaeffikon) <Aljosa.Aleksandrovic at man.com> wrote:
> Hi Gabor,
>
> Thanks a lot for your help!
>
> I tried to implement your nonlinear least squares solver on my data set. I was just wondering about the argument start. If I would like to force all my coefficients to be inside an interval, let?s say, between 0 and 1, what kind of starting values are normally recommended for the start argument (e.g. Using a 4 factor model with b1, b2, b3 and b4, I tried start = list(b1 = 0.5, b2 = 0.5, b3 = 0.5, b4 = 0.5))? I also tried other starting values ... Hence, the outputs are very sensitive to that start argument?
>
> Thanks a lot for your answer in advance!
>
> Kind regards,
> Aljosa
>
>
>
> Aljosa Aleksandrovic, FRM, CAIA
> Quantitative Analyst - Convertibles
> aljosa.aleksandrovic at man.com
> Tel +41 55 417 76 03
>
> Man Investments (CH) AG
> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>
> -----Original Message-----
> From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com]
> Sent: Dienstag, 26. April 2016 17:59
> To: Aleksandrovic, Aljosa (Pfaeffikon)
> Cc: r-help at r-project.org
> Subject: Re: [R] Linear Regressions with constraint coefficients
>
> This is a quadratic programming problem that you can solve using 
> either a quadratic programming solver with constraints or a general 
> nonlinear solver with constraints.  See 
> https://cran.r-project.org/web/views/Optimization.html
> for more info on what is available.
>
> Here is an example using a nonlinear least squares solver and non-negative bound constraints. The constraint that the coefficients sum to 1 is implied by dividing them by their sum and then dividing the coefficients found by their sum at the end:
>
> # test data
> set.seed(123)
> n <- 1000
> X1 <- rnorm(n)
> X2 <- rnorm(n)
> X3 <- rnorm(n)
> Y <- .2 * X1 + .3 * X2 + .5 * X3 + rnorm(n)
>
> # fit
> library(nlmrt)
> fm <- nlxb(Y ~ (b1 * X1 + b2 * X2 + b3 * X3)/(b1 + b2 + b3),
>      data = list(Y = Y, X1 = X1, X2 = X2, X3 = X3),
>      lower = numeric(3),
>      start = list(b1 = 1, b2 = 2, b3 = 3))
>
> giving the following non-negative coefficients which sum to 1 that are reasonably close to the true values of 0.2, 0.3 and 0.5:
>
>> fm$coefficients / sum(fm$coefficients)
>      b1      b2      b3
> 0.18463 0.27887 0.53650
>
>
> On Tue, Apr 26, 2016 at 8:39 AM, Aleksandrovic, Aljosa (Pfaeffikon) <Aljosa.Aleksandrovic at man.com> wrote:
>> Hi all,
>>
>> I hope you are doing well?
>>
>> I?m currently using the lm() function from the package stats to fit linear multifactor regressions.
>>
>> Unfortunately, I didn?t yet find a way to fit linear multifactor regressions with constraint coefficients? I would like the slope coefficients to be all inside an interval, let?s say, between 0 and 1. Further, if possible, the slope coefficients should add up to 1.
>>
>> Is there an elegant and not too complicated way to do such a constraint regression estimation in R?
>>
>> I would very much appreciate if you could help me with my issue?
>>
>> Thanks a lot in advance and kind regards, Aljosa Aleksandrovic
>>
>>
>>
>> Aljosa Aleksandrovic, FRM, CAIA
>> Quantitative Analyst - Convertibles
>> aljosa.aleksandrovic at man.com
>> Tel +41 55 417 7603
>>
>> Man Investments (CH) AG
>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>
>>
>> -----Original Message-----
>> From: Kevin E. Thorpe [mailto:kevin.thorpe at utoronto.ca]
>> Sent: Dienstag, 26. April 2016 14:35
>> To: Aleksandrovic, Aljosa (Pfaeffikon)
>> Subject: Re: Linear Regressions with constraint coefficients
>>
>> You need to send it to r-help at r-project.org however.
>>
>> Kevin
>>
>> On 04/26/2016 08:32 AM, Aleksandrovic, Aljosa (Pfaeffikon) wrote:
>>> Ok, will do! Thx a lot!
>>>
>>> Please find below my request:
>>>
>>> Hi all,
>>>
>>> I hope you are doing well?
>>>
>>> I?m currently using the lm() function from the package stats to fit linear multifactor regressions.
>>>
>>> Unfortunately, I didn?t yet find a way to fit linear multifactor regressions with constraint coefficients? I would like the slope coefficients to be all inside an interval, let?s say, between 0 and 1. Further, if possible, the slope coefficients should add up to 1.
>>>
>>> Is there an elegant and not too complicated way to do such a constraint regression estimation in R?
>>>
>>> I would very much appreciate if you could help me with my issue?
>>>
>>> Thanks a lot in advance and kind regards, Aljosa Aleksandrovic
>>>
>>>
>>>
>>> Aljosa Aleksandrovic, FRM, CAIA
>>> Quantitative Analyst - Convertibles
>>> aljosa.aleksandrovic at man.com
>>> Tel +41 55 417 7603
>>>
>>> Man Investments (CH) AG
>>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>>
>>>
>>> -----Original Message-----
>>> From: Kevin E. Thorpe [mailto:kevin.thorpe at utoronto.ca]
>>> Sent: Dienstag, 26. April 2016 14:28
>>> To: Aleksandrovic, Aljosa (Pfaeffikon); r-help-owner at r-project.org
>>> Subject: Re: Linear Regressions with constraint coefficients
>>>
>>> I believe I approved a message with such a subject. Perhaps there was another layer that subsequently rejected it after that. I didn't notice any unusual content. Try again, making sure you send the message in plain text only.
>>>
>>> Kevin
>>>
>>> On 04/26/2016 08:16 AM, Aleksandrovic, Aljosa (Pfaeffikon) wrote:
>>>> Do you know where I get help for my issue?
>>>>
>>>> Thanks in advance and kind regards, Aljosa
>>>>
>>>>
>>>> Aljosa Aleksandrovic, FRM, CAIA
>>>> Quantitative Analyst - Convertibles aljosa.aleksandrovic at man.com 
>>>> Tel +41 55 417 7603
>>>>
>>>> Man Investments (CH) AG
>>>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>>>
>>>> -----Original Message-----
>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of 
>>>> r-help-owner at r-project.org
>>>> Sent: Dienstag, 26. April 2016 14:10
>>>> To: Aleksandrovic, Aljosa (Pfaeffikon)
>>>> Subject: Linear Regressions with constraint coefficients
>>>>
>>>> The message's content type was not explicitly allowed
>>>>
>>
>>
>> --
>> Kevin E. Thorpe
>> Head of Biostatistics,  Applied Health Research Centre (AHRC) Li Ka 
>> Shing Knowledge Institute of St. Michael's Hospital Assistant 
>> Professor, Dalla Lana School of Public Health University of Toronto
>> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>>
>> This email has been sent by a member of the Man group (?Man?). Man?s parent company, Man Group plc, is registered in England and Wales (company number 08172396) at Riverbank House, 2 Swan  Lane, London, EC4R 3AD.
>> The contents of this email are for the named addressee(s) only. It 
>> contains information which may be confidential and privileged. If you 
>> are not the intended recipient, please notify the sender immediately, 
>> destroy this email and any attachments and do not otherwise disclose 
>> or use them. Email transmission is not a secure method of 
>> communication and Man cannot accept responsibility for the 
>> completeness or accuracy of this email or any attachments. Whilst Man 
>> makes every effort to keep its network free from viruses, it does not 
>> accept responsibility for any computer virus which might be 
>> transferred by way of this email or any attachments. This email does 
>> not constitute a request, offer, recommendation or solicitation of 
>> any kind to buy, subscribe, sell or redeem any investment instruments 
>> or to perform other such transactions of any kind. Man reserves the 
>> right to monitor, record and retain all electronic and telephone 
>> communications through its network in accordance with applicable laws 
>> and regulations. --UwQe9f5k7pI3vplngP
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com



--
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From vasanthcullen at gmail.com  Fri May 20 10:44:22 2016
From: vasanthcullen at gmail.com (Vasanth Mohan)
Date: Fri, 20 May 2016 14:14:22 +0530
Subject: [R] stopifnot() doesnt work as I expect it to. Are my expectations
	correct?
Message-ID: <CANBHdu_t9KSuX6WiJ_gELSo9_x_Kd681fw1hd4JWe-xijhQwCg@mail.gmail.com>

Hi,

*stopifnot(FALSE, someOtherExpression)*

For the above code I expect stopifnot() to always say that 'FALSE is not
TRUE' regardless of what someOtherExpression is(It may evaluate to TRUE or
FALSE or throw an error). Is my expectation correct? Is that how
stopifnot() is supposed to work?

The present implementation of stopifnot() does not work like that. If
someOtherExpression would throw an error, then stopifnot() throws that
error instead of saying 'FALSE is not TRUE'.

So, I modified the source code of stopifnot() and now it works as I expect
it to.
If that is how stopifnot() is supposed to work, then kindly let me know how
I can contribute my solution

-- 
vAsAnth

The mind, once expanded to the dimensions of larger ideas, never returns to
its original size. - Oliver Wendell Holmes

	[[alternative HTML version deleted]]


From laomeng_3 at 163.com  Fri May 20 13:51:35 2016
From: laomeng_3 at 163.com (laomeng_3)
Date: Fri, 20 May 2016 19:51:35 +0800 (GMT+08:00)
Subject: [R] =?utf-8?q?how_to_perform_multiple_comparison=EF=BC=9F?=
In-Reply-To: <CA+8X3fWAe8yV0V-5Wz=CbeXJgD0T-f43UkVJnGb3OJBbXVBmSw@mail.gmail.com>
References: <5c16f0c3.5c47.154c9bba8bb.Coremail.laomeng_3@163.com>
	<CA+8X3fWAe8yV0V-5Wz=CbeXJgD0T-f43UkVJnGb3OJBbXVBmSw@mail.gmail.com>
Message-ID: <21e60251.a931.154ce01a8a6.Coremail.laomeng_3@163.com>

ok,many thanks.


?? ??????
On 2016-05-20 08:19 , Jim Lemon Wrote:

Hi laomeng_3,
Have a look at the padjust function (stats).

Jim


On Fri, May 20, 2016 at 1:56 AM, laomeng_3 <laomeng_3 at 163.com> wrote:
> Hi all:
> As to the anova, we can perform multiple comparison via TukeyHSD.
> But as to chi-square test for frequency table,how to perform multiple comparison?
>
> For example, if I want to compare 3 samples' ratio(the data has 3 rows,each row corresponds to 1 sample,and has 2 columns,each column corresponds to positive and negative respectively).
>
>
> dat<-matrix(c(6,30,8,23,14,3),nrow=3)
> dat
>       [,1] [,2]
> [1,]    6   23
> [2,]   30   14
> [3,]    8    3
>
>
>
> chisq.test(dat)
>
>        Pearson's Chi-squared test
>
> data:  dat
> X-squared = 17.9066, df = 2, p-value = 0.0001293
>
>
> The result shows that the difference between the 3 samples is significant.But if I want to perform multiple comparison to find out which pair of samples is  significantly different,which function should be used?
>
>
> Many thanks for your help.
>
> My best
>
>
>
> ?? ??????
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From laomeng_3 at 163.com  Fri May 20 13:53:13 2016
From: laomeng_3 at 163.com (laomeng_3)
Date: Fri, 20 May 2016 19:53:13 +0800 (GMT+08:00)
Subject: [R] =?utf-8?q?how_to_perform_multiple_comparison=EF=BC=9F?=
In-Reply-To: <F6E32B66-762E-4BC3-946C-93AE36B24BA8@comcast.net>
References: <5c16f0c3.5c47.154c9bba8bb.Coremail.laomeng_3@163.com>
	<CA+8X3fWAe8yV0V-5Wz=CbeXJgD0T-f43UkVJnGb3OJBbXVBmSw@mail.gmail.com>
	<F6E32B66-762E-4BC3-946C-93AE36B24BA8@comcast.net>
Message-ID: <1604a5a5.a947.154ce032779.Coremail.laomeng_3@163.com>

thanks for your help.


?? ??????
On 2016-05-20 09:48 , David Winsemius Wrote:


> On May 19, 2016, at 5:19 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi laomeng_3,
> Have a look at the padjust function (stats).
>
> Jim
>
>
> On Fri, May 20, 2016 at 1:56 AM, laomeng_3 <laomeng_3 at 163.com> wrote:
>> Hi all:
>> As to the anova, we can perform multiple comparison via TukeyHSD.
>> But as to chi-square test for frequency table,how to perform multiple comparison?
>>
>> For example, if I want to compare 3 samples' ratio(the data has 3 rows,each row corresponds to 1 sample,and has 2 columns,each column corresponds to positive and negative respectively).
>>
>>
>> dat<-matrix(c(6,30,8,23,14,3),nrow=3)
>> dat
>>      [,1] [,2]
>> [1,]    6   23
>> [2,]   30   14
>> [3,]    8    3
>>
>>
>>
>> chisq.test(dat)
>>
>>       Pearson's Chi-squared test
>>
>> data:  dat
>> X-squared = 17.9066, df = 2, p-value = 0.0001293
>>
>>
>> The result shows that the difference between the 3 samples is significant.But if I want to perform multiple comparison to find out which pair of samples is  significantly different,which function should be used?
>>

It appears your question is which row(s) are contributing most greatly to the overall test of independence. The result of a `chisq.test(.)` (which is not what you see from its print method) has a component named residuals. (Read the help page : ?chisq.test)

x2 <- chisq.test(dat)
x2$residuals
          [,1]       [,2]
[1,] -2.3580463  2.4731398
[2,]  1.4481733 -1.5188569
[3,]  0.9323855 -0.9778942



Those row sums should be distributed as chi-squared statistics with one degree of freedom each, but since you have admittedly inflated the possibility of the type I error, it would be sensible to adjust the "p-statistics" using the function that Jim Lemon misspelled:

> rowSums(x2$residuals^2)
[1] 11.676803  4.404132  1.825620

> p.adjust( 1- pchisq( rowSums(x2$residuals^2), 1) )

[1] 0.001898526 0.071703921 0.176645786

So row 1 represents the only group that is "significantly different at the conventional level" from the expectations based on the overall sample collection. I also seem to remember that there is a function named CrossTable (in a package whose name I'm forgetting) that will deliver a SAS-style tabulation of row and column chi-squared statistics.

--
David.

>>
>> Many thanks for your help.
>>
>> My best
>>
>>
>>
>> ?? ??????
>>        [[alternative HTML version deleted]]
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


	[[alternative HTML version deleted]]


From friendly at yorku.ca  Fri May 20 14:49:40 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 20 May 2016 08:49:40 -0400
Subject: [R] Change sum of squares type for ANOVA
In-Reply-To: <6D5C009FB51EBD41BEE57F4C002350FD09E63F@SB00112A.adb.intra.admin.ch>
References: <6D5C009FB51EBD41BEE57F4C002350FD09E63F@SB00112A.adb.intra.admin.ch>
Message-ID: <67975acb-cbfc-0db2-b2af-8166b0943ab4@yorku.ca>

Use car::Anova() for type II and type III sums of squares and F-tests.
The sequential type I tests computed by anova() are rarely sensible

On 5/20/2016 3:11 AM, michael.eisenring at agroscope.admin.ch wrote:
> Dear R-list members,
>
> I compared my statistics with my supervisor yesterday. He is using STATISTICA, I am using R. We both loaded the same data-file and did a two-way ANOVA with treatment and trial as factors; treatment means were then compared to the untreated control using Dunnett's test. Surprisingly, we got different values, especially the F values differed. In the following Dunnett's test, some treatments were significant in R, but not in STATISTICA. We checked the basic settings of the programs and found out, that STATISTICA is using "sigma-restricted parametrization" and "type VI sum of squares" for the calculations, but so far, I could not find any information about the sum of squares type, which is applied in R. Is it possible, that these settings are the reason for the different values we got? And how can I change in R these settings?
>
> Here the code I used:
> bt_assay_devtime_Model <- aov(developmenttime~treatment+run+treatment*run, data=bt_assay)
> summary(bt_assay_devtime_Model)
> postHocs_bt_assay_devtime <- glht(bt_assay_devtime_Model, linfct=mcp(treatment="Dunnett"), base=1)
> summary(postHocs_bt_assay_devtime)
> confint(postHocs_bt_assay_devtime)
>
> Thanks a lot for your help!
> Simone
>
> Eisenring Michael, Msc.
> PhD Student
>
> Federal Department of Economic Affairs, Education and Research
> EAER
> Institute of Sustainability Sciences ISS
> Biosafety
>
> Reckenholzstrasse 191, CH-8046 Z?rich
> Tel. +41 44 37 77181
> Fax +41 44 37 77201
> michael.eisenring at agroscope.admin.ch<mailto:michael.eisenring at agroscope.admin.ch>
> www.agroscope.ch<http://www.agroscope.ch/>
>
>
> 	[[alternative HTML version deleted]]
>
>
>


From friendly at yorku.ca  Fri May 20 14:49:40 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 20 May 2016 08:49:40 -0400
Subject: [R] Change sum of squares type for ANOVA
In-Reply-To: <6D5C009FB51EBD41BEE57F4C002350FD09E63F@SB00112A.adb.intra.admin.ch>
References: <6D5C009FB51EBD41BEE57F4C002350FD09E63F@SB00112A.adb.intra.admin.ch>
Message-ID: <67975acb-cbfc-0db2-b2af-8166b0943ab4@yorku.ca>

Use car::Anova() for type II and type III sums of squares and F-tests.
The sequential type I tests computed by anova() are rarely sensible

On 5/20/2016 3:11 AM, michael.eisenring at agroscope.admin.ch wrote:
> Dear R-list members,
>
> I compared my statistics with my supervisor yesterday. He is using STATISTICA, I am using R. We both loaded the same data-file and did a two-way ANOVA with treatment and trial as factors; treatment means were then compared to the untreated control using Dunnett's test. Surprisingly, we got different values, especially the F values differed. In the following Dunnett's test, some treatments were significant in R, but not in STATISTICA. We checked the basic settings of the programs and found out, that STATISTICA is using "sigma-restricted parametrization" and "type VI sum of squares" for the calculations, but so far, I could not find any information about the sum of squares type, which is applied in R. Is it possible, that these settings are the reason for the different values we got? And how can I change in R these settings?
>
> Here the code I used:
> bt_assay_devtime_Model <- aov(developmenttime~treatment+run+treatment*run, data=bt_assay)
> summary(bt_assay_devtime_Model)
> postHocs_bt_assay_devtime <- glht(bt_assay_devtime_Model, linfct=mcp(treatment="Dunnett"), base=1)
> summary(postHocs_bt_assay_devtime)
> confint(postHocs_bt_assay_devtime)
>
> Thanks a lot for your help!
> Simone
>
> Eisenring Michael, Msc.
> PhD Student
>
> Federal Department of Economic Affairs, Education and Research
> EAER
> Institute of Sustainability Sciences ISS
> Biosafety
>
> Reckenholzstrasse 191, CH-8046 Z?rich
> Tel. +41 44 37 77181
> Fax +41 44 37 77201
> michael.eisenring at agroscope.admin.ch<mailto:michael.eisenring at agroscope.admin.ch>
> www.agroscope.ch<http://www.agroscope.ch/>
>
>
> 	[[alternative HTML version deleted]]
>
>
>


From lmr6c6 at mail.missouri.edu  Fri May 20 14:51:01 2016
From: lmr6c6 at mail.missouri.edu (Rees, Lisa Marie (MU-Student))
Date: Fri, 20 May 2016 12:51:01 +0000
Subject: [R] error in data.farme--duplicate row.names error
In-Reply-To: <D3637D0C.174709%macqueen1@llnl.gov>
References: <D3637D0C.174709%macqueen1@llnl.gov>
Message-ID: <BN3PR01MB123808D3C13075EB079A0802924B0@BN3PR01MB1238.prod.exchangelabs.com>

Don,

Thank you for your helpful response.  At this point, I do believe it is a package error and I have contacted the developer.

Thanks,
Lisa

-----Original Message-----
From: MacQueen, Don [mailto:macqueen1 at llnl.gov] 
Sent: Thursday, May 19, 2016 4:27 PM
To: Rees, Lisa Marie (MU-Student); r-help at r-project.org
Subject: Re: [R] error in data.farme--duplicate row.names error

You will probably have to contact the maintainer of the package, since the error appears to be generated inside the package's function.

Immediately after the error, type
  traceback()
The results might give you a clue. Or they might not!

There might be some requirements on the second argument of the
DefineGame() function. Check the help page for DefineGame and see if the object you supplied, value, meets those requirements.

-Don

--
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 5/19/16, 7:16 AM, "R-help on behalf of Rees, Lisa Marie (MU-Student)"
<r-help-bounces at r-project.org on behalf of lmr6c6 at mail.missouri.edu> wrote:

>I'm using the "GameTheory" package--- DefineGame(14,values) and values 
>is equal to 16,383 observations.
>
>I keep getting the following error-
>[Error in data.frame(rep(0, 2^n - 1), row.names = Bmat) :
>  duplicate row.names: 1, 11, 111, 12, 112, 1112, 11112, 13, 113, 1113, 
>11113, 1213, 11213, 111213, 1111213, 14, 114, 1114, 11114, 1214, 11214, 
>111214, 1111214, 1314, 11314, 111314, 1111314, 121314, 1121314, 
>11121314, 111121314]
>
>What can I do to fix this issue?  I would greatly appreciate any help.
>
>Thank you.
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jfox at mcmaster.ca  Fri May 20 14:58:27 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Fri, 20 May 2016 12:58:27 +0000
Subject: [R] Change sum of squares type for ANOVA
In-Reply-To: <67975acb-cbfc-0db2-b2af-8166b0943ab4@yorku.ca>
References: <6D5C009FB51EBD41BEE57F4C002350FD09E63F@SB00112A.adb.intra.admin.ch>
	<67975acb-cbfc-0db2-b2af-8166b0943ab4@yorku.ca>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F9D40E@FHSDB2D11-2.csu.mcmaster.ca>

Dear Michael and Michael,

I took a quick look at the Statistica website, and their definition of "types" of sums of squares doesn't appear to be the same as the common definition, which originated with SAS. As I read their materials, what they call "Type VI" sums of squares would correspond to the "Type III" tests provided by Anova() in the car package by setting type=3. 

As well, the reference to "sigma-restricted coding" in the Statistica documentation corresponds to contrasts provided by contr.sum() in R. This is important for Type III tests because it produces a row-basis for the model matrix with orthogonal effects. One way to do this is via options(contrasts=c("contr.sum", "contr.poly")). See ?Anova for more information.

I hope this helps,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Michael 
> Friendly
> Sent: May 20, 2016 8:50 AM
> To: michael.eisenring at agroscope.admin.ch; r-help at r-project.org
> Subject: Re: [R] Change sum of squares type for ANOVA
> 
> Use car::Anova() for type II and type III sums of squares and F-tests.
> The sequential type I tests computed by anova() are rarely sensible
> 
> On 5/20/2016 3:11 AM, michael.eisenring at agroscope.admin.ch wrote:
> > Dear R-list members,
> >
> > I compared my statistics with my supervisor yesterday. He is using
> STATISTICA, I am using R. We both loaded the same data-file and did a two-way
> ANOVA with treatment and trial as factors; treatment means were then
> compared to the untreated control using Dunnett's test. Surprisingly, we got
> different values, especially the F values differed. In the following Dunnett's test,
> some treatments were significant in R, but not in STATISTICA. We checked the
> basic settings of the programs and found out, that STATISTICA is using "sigma-
> restricted parametrization" and "type VI sum of squares" for the calculations,
> but so far, I could not find any information about the sum of squares type,
> which is applied in R. Is it possible, that these settings are the reason for the
> different values we got? And how can I change in R these settings?
> >
> > Here the code I used:
> > bt_assay_devtime_Model <-
> > aov(developmenttime~treatment+run+treatment*run, data=bt_assay)
> > summary(bt_assay_devtime_Model)
> > postHocs_bt_assay_devtime <- glht(bt_assay_devtime_Model,
> > linfct=mcp(treatment="Dunnett"), base=1)
> > summary(postHocs_bt_assay_devtime)
> > confint(postHocs_bt_assay_devtime)
> >
> > Thanks a lot for your help!
> > Simone
> >
> > Eisenring Michael, Msc.
> > PhD Student
> >
> > Federal Department of Economic Affairs, Education and Research EAER
> > Institute of Sustainability Sciences ISS Biosafety
> >
> > Reckenholzstrasse 191, CH-8046 Z rich
> > Tel. +41 44 37 77181
> > Fax +41 44 37 77201
> > michael.eisenring at agroscope.admin.ch<mailto:michael.eisenring at agroscop
> > e.admin.ch> www.agroscope.ch<http://www.agroscope.ch/>
> >
> >
> > 	[[alternative HTML version deleted]]
> >
> >
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From lists at dewey.myzen.co.uk  Fri May 20 15:01:53 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Fri, 20 May 2016 14:01:53 +0100
Subject: [R] Change sum of squares type for ANOVA
In-Reply-To: <67975acb-cbfc-0db2-b2af-8166b0943ab4@yorku.ca>
References: <6D5C009FB51EBD41BEE57F4C002350FD09E63F@SB00112A.adb.intra.admin.ch>
	<67975acb-cbfc-0db2-b2af-8166b0943ab4@yorku.ca>
Message-ID: <067fb1ca-50b3-ecb6-8229-b9f28f20f087@dewey.myzen.co.uk>

Dear Michael F

What you say is of course true but Michael E (or possibly Simone) seems 
to be using a function glht from an unnamed package. Since we do not 
have the data or the offending output it is hard to be sure though.

Michael D

On 20/05/2016 13:49, Michael Friendly wrote:
> Use car::Anova() for type II and type III sums of squares and F-tests.
> The sequential type I tests computed by anova() are rarely sensible
>
> On 5/20/2016 3:11 AM, michael.eisenring at agroscope.admin.ch wrote:
>> Dear R-list members,
>>
>> I compared my statistics with my supervisor yesterday. He is using
>> STATISTICA, I am using R. We both loaded the same data-file and did a
>> two-way ANOVA with treatment and trial as factors; treatment means
>> were then compared to the untreated control using Dunnett's test.
>> Surprisingly, we got different values, especially the F values
>> differed. In the following Dunnett's test, some treatments were
>> significant in R, but not in STATISTICA. We checked the basic settings
>> of the programs and found out, that STATISTICA is using
>> "sigma-restricted parametrization" and "type VI sum of squares" for
>> the calculations, but so far, I could not find any information about
>> the sum of squares type, which is applied in R. Is it possible, that
>> these settings are the reason for the different values we got? And how
>> can I change in R these settings?
>>
>> Here the code I used:
>> bt_assay_devtime_Model <-
>> aov(developmenttime~treatment+run+treatment*run, data=bt_assay)
>> summary(bt_assay_devtime_Model)
>> postHocs_bt_assay_devtime <- glht(bt_assay_devtime_Model,
>> linfct=mcp(treatment="Dunnett"), base=1)
>> summary(postHocs_bt_assay_devtime)
>> confint(postHocs_bt_assay_devtime)
>>
>> Thanks a lot for your help!
>> Simone
>>
>> Eisenring Michael, Msc.
>> PhD Student
>>
>> Federal Department of Economic Affairs, Education and Research
>> EAER
>> Institute of Sustainability Sciences ISS
>> Biosafety
>>
>> Reckenholzstrasse 191, CH-8046 Z?rich
>> Tel. +41 44 37 77181
>> Fax +41 44 37 77201
>> michael.eisenring at agroscope.admin.ch<mailto:michael.eisenring at agroscope.admin.ch>
>>
>> www.agroscope.ch<http://www.agroscope.ch/>
>>
>>
>>     [[alternative HTML version deleted]]
>>
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From rbaer at atsu.edu  Fri May 20 15:06:09 2016
From: rbaer at atsu.edu (Robert Baer)
Date: Fri, 20 May 2016 08:06:09 -0500
Subject: [R] x-axis tick marks on log scale plot
In-Reply-To: <22334.55077.655497.177441@stat.math.ethz.ch>
References: <CAEQKoCHSLXiUV=jB_wrhRw9_h9ZAea_p_0Ymto8_CKCmFiHgtg@mail.gmail.com>
	<bedcd4f1-4132-e0d4-a6f3-63b60a0a8b60@univ-reims.fr>
	<CAEQKoCHeQG4Grqb+fD326wFSUfVwDD4Pv5-BEJaGPJzBSupumw@mail.gmail.com>
	<22334.55077.655497.177441@stat.math.ethz.ch>
Message-ID: <c3d0b577-38de-ae3d-c1cc-598a2556272a@atsu.edu>

Very, very nice.  Thanks for sharing.


On 5/20/2016 4:21 AM, Martin Maechler wrote:
>>>>>> Brian Smith <bsmith030465 at gmail.com>
>>>>>>      on Thu, 19 May 2016 11:04:55 -0400 writes:
>      > Thanks all !!  On Thu, May 19, 2016 at 9:55 AM, Ivan
>      > Calandra <ivan.calandra at univ-reims.fr> wrote:
>
>      >> Hi,
>      >>
>      >> You can do it by first plotting your values without the
>      >> x-axis: plot(x,y,log="xy", xaxt="n")
>      >>
>      >> and then plotting the x-axis with ticks where you need to:
>      >> axis(side=1, at=seq(2000,8000,1000))
>
> Getting nicer looking axis ticks  for log-scale axes (and
> traditional graphics) I have created the function
>     eaxis()
> and utility function    pretty10exp(.)
>
> and I also created standard R's  axTicks(.)  to help with these.
>
>      if(!require("sfsmisc")) install.packages("sfsmisc")
>      require("sfsmisc")
>
>      x <- lseq(1e-10, 0.1, length = 201)
>      plot(x, pt(x, df=3), type = "l", xaxt = "n", log = "x")
>      eaxis(1)
>
> gives the attached plot
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri May 20 16:13:27 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 20 May 2016 10:13:27 -0400
Subject: [R] stopifnot() doesnt work as I expect it to. Are my
 expectations correct?
In-Reply-To: <CANBHdu_t9KSuX6WiJ_gELSo9_x_Kd681fw1hd4JWe-xijhQwCg@mail.gmail.com>
References: <CANBHdu_t9KSuX6WiJ_gELSo9_x_Kd681fw1hd4JWe-xijhQwCg@mail.gmail.com>
Message-ID: <bb931523-152d-bf98-af06-021e702f2074@gmail.com>

On 20/05/2016 4:44 AM, Vasanth Mohan wrote:
> Hi,
>
> *stopifnot(FALSE, someOtherExpression)*
>
> For the above code I expect stopifnot() to always say that 'FALSE is not
> TRUE' regardless of what someOtherExpression is(It may evaluate to TRUE or
> FALSE or throw an error). Is my expectation correct? Is that how
> stopifnot() is supposed to work?
>
> The present implementation of stopifnot() does not work like that. If
> someOtherExpression would throw an error, then stopifnot() throws that
> error instead of saying 'FALSE is not TRUE'.
>
> So, I modified the source code of stopifnot() and now it works as I expect
> it to.
> If that is how stopifnot() is supposed to work, then kindly let me know how
> I can contribute my solution
>

The documentation is unclear on that.  First it implies all expressions 
are evaluated:  "If any of the expressions in ... are not all TRUE, stop 
is called, producing an error message indicating the first of the 
elements of ... which were not true."

But then the "conceptually equivalent" code acts the way you expected.

However, it doesn't really make sense to me to put in tests that could 
themselves trigger errors unless you'd be interested in seeing those 
errors, so I don't think I'd change it.

Duncan Murdoch


From wdunlap at tibco.com  Fri May 20 16:33:01 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 20 May 2016 07:33:01 -0700
Subject: [R] stopifnot() doesnt work as I expect it to. Are my
 expectations correct?
In-Reply-To: <bb931523-152d-bf98-af06-021e702f2074@gmail.com>
References: <CANBHdu_t9KSuX6WiJ_gELSo9_x_Kd681fw1hd4JWe-xijhQwCg@mail.gmail.com>
	<bb931523-152d-bf98-af06-021e702f2074@gmail.com>
Message-ID: <CAF8bMcatqH_=M3QZ6JudOiX9nLgSyV__ngEc=dNRb0DUSnQssQ@mail.gmail.com>

The following usage of stopifnot seems reasonable to me and it
would be nice if the 2nd call caused the message 'is.data.frame(df) is not
TRUE'.

f <- function(df) {
    stopifnot(is.data.frame(df), is.integer(df$ID))
    range(df$ID)
}
f(data.frame(ID=4:7))
# [1] 4 7
f(4:7)
# Error in df$ID : $ operator is invalid for atomic vectors


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, May 20, 2016 at 7:13 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 20/05/2016 4:44 AM, Vasanth Mohan wrote:
>
>> Hi,
>>
>> *stopifnot(FALSE, someOtherExpression)*
>>
>> For the above code I expect stopifnot() to always say that 'FALSE is not
>> TRUE' regardless of what someOtherExpression is(It may evaluate to TRUE or
>> FALSE or throw an error). Is my expectation correct? Is that how
>> stopifnot() is supposed to work?
>>
>> The present implementation of stopifnot() does not work like that. If
>> someOtherExpression would throw an error, then stopifnot() throws that
>> error instead of saying 'FALSE is not TRUE'.
>>
>> So, I modified the source code of stopifnot() and now it works as I expect
>> it to.
>> If that is how stopifnot() is supposed to work, then kindly let me know
>> how
>> I can contribute my solution
>>
>>
> The documentation is unclear on that.  First it implies all expressions
> are evaluated:  "If any of the expressions in ... are not all TRUE, stop is
> called, producing an error message indicating the first of the elements of
> ... which were not true."
>
> But then the "conceptually equivalent" code acts the way you expected.
>
> However, it doesn't really make sense to me to put in tests that could
> themselves trigger errors unless you'd be interested in seeing those
> errors, so I don't think I'd change it.
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sukant.iitr at gmail.com  Fri May 20 11:48:13 2016
From: sukant.iitr at gmail.com (Sukant Arora)
Date: Fri, 20 May 2016 15:18:13 +0530
Subject: [R] Instruments for endogenous interaction term in Simultaneous
	Equation Model
Message-ID: <CABwicxgRV-MW6NGEt7y=zv4pVAELFWzFgvFs1oxuSin9oj5QGg@mail.gmail.com>

Hi

I want to estimate the following SEM model:

Y1 = a0 + b0*D + c0* Y3 + d0 * Y3 * D + control variables
Y2 = a1 + b1*D + c1 *Y3 + d1 * Y3 * D + control variables
Y3 = a2 + b2*D + c2 *Y1 + d2 * Y1 * D + e2*Y2 + f2 * Y2* D + control
variables


where, D is dummy variable, Y1,  Y2 and Y3 are endogenous variables and
Y1*D, Y2*D, Y3*D represent the interaction terms.

Suppose I have Z as an instrument for Y2. Then, can I use Z*D as instrument
for Y2*D and similarly for others?


Regards
Sukant

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Fri May 20 17:19:05 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 20 May 2016 17:19:05 +0200
Subject: [R] stopifnot() doesnt work as I expect it to. Are my
 expectations correct?
In-Reply-To: <CAF8bMcatqH_=M3QZ6JudOiX9nLgSyV__ngEc=dNRb0DUSnQssQ@mail.gmail.com>
References: <CANBHdu_t9KSuX6WiJ_gELSo9_x_Kd681fw1hd4JWe-xijhQwCg@mail.gmail.com>
	<bb931523-152d-bf98-af06-021e702f2074@gmail.com>
	<CAF8bMcatqH_=M3QZ6JudOiX9nLgSyV__ngEc=dNRb0DUSnQssQ@mail.gmail.com>
Message-ID: <CAJuCY5y-LXiALNjDVLBUcZr76Xman6C8n4AunObKh7idLuChVA@mail.gmail.com>

Dear Bill,

assertthat has such capabilities

f <- function(df){
  require(assertthat)
  assert_that(is.data.frame(df))
  assert_that(is.integer(df$ID))
  range(df$ID)
}

f(data.frame(ID=4:7))
# [1] 4 7
f(4:7)
# Error: df is not a data frame
f(data.frame(ID=letters))
#  Error: df$ID is not an integer vector

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-05-20 16:33 GMT+02:00 William Dunlap via R-help <r-help at r-project.org>:

> The following usage of stopifnot seems reasonable to me and it
> would be nice if the 2nd call caused the message 'is.data.frame(df) is not
> TRUE'.
>
> f <- function(df) {
>     stopifnot(is.data.frame(df), is.integer(df$ID))
>     range(df$ID)
> }
> f(data.frame(ID=4:7))
> # [1] 4 7
> f(4:7)
> # Error in df$ID : $ operator is invalid for atomic vectors
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Fri, May 20, 2016 at 7:13 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>
> > On 20/05/2016 4:44 AM, Vasanth Mohan wrote:
> >
> >> Hi,
> >>
> >> *stopifnot(FALSE, someOtherExpression)*
> >>
> >> For the above code I expect stopifnot() to always say that 'FALSE is not
> >> TRUE' regardless of what someOtherExpression is(It may evaluate to TRUE
> or
> >> FALSE or throw an error). Is my expectation correct? Is that how
> >> stopifnot() is supposed to work?
> >>
> >> The present implementation of stopifnot() does not work like that. If
> >> someOtherExpression would throw an error, then stopifnot() throws that
> >> error instead of saying 'FALSE is not TRUE'.
> >>
> >> So, I modified the source code of stopifnot() and now it works as I
> expect
> >> it to.
> >> If that is how stopifnot() is supposed to work, then kindly let me know
> >> how
> >> I can contribute my solution
> >>
> >>
> > The documentation is unclear on that.  First it implies all expressions
> > are evaluated:  "If any of the expressions in ... are not all TRUE, stop
> is
> > called, producing an error message indicating the first of the elements
> of
> > ... which were not true."
> >
> > But then the "conceptually equivalent" code acts the way you expected.
> >
> > However, it doesn't really make sense to me to put in tests that could
> > themselves trigger errors unless you'd be interested in seeing those
> > errors, so I don't think I'd change it.
> >
> > Duncan Murdoch
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From varinsacha at yahoo.fr  Fri May 20 17:28:22 2016
From: varinsacha at yahoo.fr (varin sacha)
Date: Fri, 20 May 2016 15:28:22 +0000 (UTC)
Subject: [R] Plots for lmrob function
References: <575281469.9654085.1463758102039.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <575281469.9654085.1463758102039.JavaMail.yahoo@mail.yahoo.com>

Dear R-helpers,

I have fitted a robust regression using lmrob function from robustbase package. I try to get the different plots for diagnostics of residuals and others. I can't get them, a window opens but nothing appears on it (the window remains white, no graph appears) and I get this error messages.


Here is a small reproducible example


a=c(1231,1415,1256,3242,3121,1567)
b=c(12,34.3,43.5,23.5,12,54.3)
c=c(23,56,73,21,34,45)
d=c(43,11,15,65,76,34)
library("robustbase")
fit=lmrob(a~b+c+d)
plot(fit,plot=all)

Erreur dans plot.new() : attempt to plot on null device

I have an open device :
dev.cur()

null device 
1 

How can I solve my problem and finally get the different required plots ?


Best
S


From murdoch.duncan at gmail.com  Fri May 20 17:42:28 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 20 May 2016 11:42:28 -0400
Subject: [R] stopifnot() doesnt work as I expect it to. Are my
 expectations correct?
In-Reply-To: <CAF8bMcatqH_=M3QZ6JudOiX9nLgSyV__ngEc=dNRb0DUSnQssQ@mail.gmail.com>
References: <CANBHdu_t9KSuX6WiJ_gELSo9_x_Kd681fw1hd4JWe-xijhQwCg@mail.gmail.com>
	<bb931523-152d-bf98-af06-021e702f2074@gmail.com>
	<CAF8bMcatqH_=M3QZ6JudOiX9nLgSyV__ngEc=dNRb0DUSnQssQ@mail.gmail.com>
Message-ID: <b6e9405f-4a9b-7145-48d9-48d088662118@gmail.com>

On 20/05/2016 10:33 AM, William Dunlap wrote:
> The following usage of stopifnot seems reasonable to me and it
> would be nice if the 2nd call caused the message 'is.data.frame(df) is
> not TRUE'.
>
> f <- function(df) {
>     stopifnot(is.data.frame(df), is.integer(df$ID))
>     range(df$ID)
> }

Yes, that's an example where the proposed behaviour makes sense.  But

stopifnot(is.data.frame(df)); stopifnot(is.integer(df$ID))

isn't that much harder to type, and it already does what you want.

Duncan Murdoch


> f(data.frame(ID=4:7))
> # [1] 4 7
> f(4:7)
> # Error in df$ID : $ operator is invalid for atomic vectors
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com <http://tibco.com>
>
> On Fri, May 20, 2016 at 7:13 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>
>     On 20/05/2016 4:44 AM, Vasanth Mohan wrote:
>
>         Hi,
>
>         *stopifnot(FALSE, someOtherExpression)*
>
>         For the above code I expect stopifnot() to always say that
>         'FALSE is not
>         TRUE' regardless of what someOtherExpression is(It may evaluate
>         to TRUE or
>         FALSE or throw an error). Is my expectation correct? Is that how
>         stopifnot() is supposed to work?
>
>         The present implementation of stopifnot() does not work like
>         that. If
>         someOtherExpression would throw an error, then stopifnot()
>         throws that
>         error instead of saying 'FALSE is not TRUE'.
>
>         So, I modified the source code of stopifnot() and now it works
>         as I expect
>         it to.
>         If that is how stopifnot() is supposed to work, then kindly let
>         me know how
>         I can contribute my solution
>
>
>     The documentation is unclear on that.  First it implies all
>     expressions are evaluated:  "If any of the expressions in ... are
>     not all TRUE, stop is called, producing an error message indicating
>     the first of the elements of ... which were not true."
>
>     But then the "conceptually equivalent" code acts the way you expected.
>
>     However, it doesn't really make sense to me to put in tests that
>     could themselves trigger errors unless you'd be interested in seeing
>     those errors, so I don't think I'd change it.
>
>     Duncan Murdoch
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>


From utz.ryan at gmail.com  Fri May 20 20:28:36 2016
From: utz.ryan at gmail.com (Ryan Utz)
Date: Fri, 20 May 2016 14:28:36 -0400
Subject: [R] rjags crashes RStudio every time it tries to load
Message-ID: <CAKJ8KVg+Hj0OGMFcakjQ0OtovoAiA=6sSE-Q-+OjUPj7OH-o7w@mail.gmail.com>

Hello,

Every time I try to require(rjags) in Studio, Studio crashes and says that
a fatal error has occurred. This seems to happen when it's trying to
require coda, which I have installed. All of my software is updated. Anyone
else encountered this before? The package does seem to load successfully in
regular R, but I would prefer not to be constrained to that platform if
possible.

-- 

Ryan Utz, Ph.D.
Assistant professor of water resources
*chatham**UNIVERSITY*
Home/Cell: (724) 272-7769

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri May 20 20:46:49 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 20 May 2016 14:46:49 -0400
Subject: [R] rjags crashes RStudio every time it tries to load
In-Reply-To: <CAKJ8KVg+Hj0OGMFcakjQ0OtovoAiA=6sSE-Q-+OjUPj7OH-o7w@mail.gmail.com>
References: <CAKJ8KVg+Hj0OGMFcakjQ0OtovoAiA=6sSE-Q-+OjUPj7OH-o7w@mail.gmail.com>
Message-ID: <ac8d8e41-727b-805a-fefb-ee7ee8b8b05a@gmail.com>

On 20/05/2016 2:28 PM, Ryan Utz wrote:
> Hello,
>
> Every time I try to require(rjags) in Studio, Studio crashes and says that
> a fatal error has occurred. This seems to happen when it's trying to
> require coda, which I have installed. All of my software is updated. Anyone
> else encountered this before? The package does seem to load successfully in
> regular R, but I would prefer not to be constrained to that platform if
> possible.
>

Since this is RStudio-specific, you'll need to ask on one of the RStudio 
forums.

Duncan Murdoch


From dwinsemius at comcast.net  Fri May 20 21:13:16 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 20 May 2016 12:13:16 -0700
Subject: [R] Plots for lmrob function
In-Reply-To: <575281469.9654085.1463758102039.JavaMail.yahoo@mail.yahoo.com>
References: <575281469.9654085.1463758102039.JavaMail.yahoo.ref@mail.yahoo.com>
	<575281469.9654085.1463758102039.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <F6BA11B2-9382-49FD-AA41-AAE68EF6EFBD@comcast.net>


> On May 20, 2016, at 8:28 AM, varin sacha via R-help <r-help at r-project.org> wrote:
> 
> Dear R-helpers,
> 
> I have fitted a robust regression using lmrob function from robustbase package. I try to get the different plots for diagnostics of residuals and others. I can't get them, a window opens but nothing appears on it (the window remains white, no graph appears) and I get this error messages.
> 
> 
> Here is a small reproducible example
> 
> 
> a=c(1231,1415,1256,3242,3121,1567)
> b=c(12,34.3,43.5,23.5,12,54.3)
> c=c(23,56,73,21,34,45)
> d=c(43,11,15,65,76,34)
> library("robustbase")
> fit=lmrob(a~b+c+d)
> plot(fit,plot=all)
> 
> Erreur dans plot.new() : attempt to plot on null device
> 
> I have an open device :
> dev.cur()
> 
> null device 
> 1 
> 
> How can I solve my problem and finally get the different required plots ?
> 
> 
A "null device" is not going to be of much help. Generally one would have an available interactive device. On a Mac this would be the quartz device:

> dev.cur()
quartz 
     2 


That said I also get a different error. I am running with the 'error' option set to `recover`, so I see only a single plot of the "Robust Standardized residuals" before an error is reported. I intially wondered is this is caused by using such a small dataset for a model when requesting three predictors and an outcome.

> plot(fit,plot=all)
recomputing robust Mahalanobis distances
saving the robust distances 'MD' as part of ?fit?
Hit <Return> to see next plot: 
Error in plot.it && missing(ylim) : invalid 'x' type in 'x && y'
In addition: Warning messages:
1: In plot.window(...) : "plot" is not a graphical parameter
2: In plot.xy(xy, type, ...) : "plot" is not a graphical parameter
3: In axis(side = side, at = at, labels = labels, ...) :
  "plot" is not a graphical parameter
4: In axis(side = side, at = at, labels = labels, ...) :
  "plot" is not a graphical parameter
5: In box(...) : "plot" is not a graphical parameter
6: In title(...) : "plot" is not a graphical parameter
7: In plot.xy(xy.coords(x, y), type = type, ...) :
  "plot" is not a graphical parameter
8: In title(sub = sub.caption, ...) : "plot" is not a graphical parameter

But reducing the model did not cure the error. Only removing `plot=all` was sufficient to get plotting of all five plots. The help page for plot.lmrob does not describe a "plot" parameter.

-- 

David Winsemius
Alameda, CA, USA


From kevin.thorpe at utoronto.ca  Fri May 20 21:27:07 2016
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Fri, 20 May 2016 15:27:07 -0400
Subject: [R] Multistate survival models
Message-ID: <573F650B.7050501@utoronto.ca>

A quick (I think) question.

Does the survreg() function in the survival package handle Surv() 
objects of type mstate?

It's not clear from the documentation that it doesn't. The Vignette only 
discusses the Cox model and the Fine-Gray model.

I tried using survreg() on an mstate Surv() object. It did not give an 
error and produced a result but I don't know if it did a competing risk 
analysis or not.

Thanks.

-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's Hospital
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From hokut1 at yahoo.com  Fri May 20 20:46:31 2016
From: hokut1 at yahoo.com (oslo)
Date: Fri, 20 May 2016 18:46:31 +0000 (UTC)
Subject: [R] Choosing subset of data
References: <1598096813.5717732.1463769991582.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1598096813.5717732.1463769991582.JavaMail.yahoo@mail.yahoo.com>

Hi all;
I have a big data set (a small part is given below) and V1 column has repeated info in it. That is rs941873, rs12307687... are repeating many times. I need choose only one SNP (in first column named rs) which has the smallest ?Pvalue withing V1 column. That is I need choose only one SNP for repeated names in V1 which has the smallest Pvalue.
Your helps are truly appreciated,




?rs ? ? ? ? ? ? ? ? ? Chr V6 ? ? ? ? ?? A1? A2 ??Freq ??Effect ?StdErr ? ? ? ? Pvalue? V1 ? ? ? ? ?Gene?rs941873 chr10 81139462 a g 0.4117 -0.0541 0.0103 1.52E-07 rs941873 ? ? ???no_value?rs634552 chr11 75282052 t g 0.3735 0.0159 0.0099 1.08E-01 rs941873 SERPINH1?rs11107175 chr12 94161719 t c 0.0896 -0.0386 0.0176 2.85E-02 rs941873? CRADD?rs12307687 chr12 47175866 a t 0.7379 -0.0208 0.0135 1.23E-01 rs12307687 SLC38A4?rs3917155 chr14 76444685 c g 0.0495 0.0153 0.0371 6.80E-01 rs941873? TGFB3?rs1600640 chr15 84603034 t g 0.1791 -0.0448 0.0123 2.75E-04 rs12307687 ADAMTSL3?rs2871865 chr15 99194896 c g 0.5515 0.0191 0.0106 7.09E-02 rs12307687 IGF1R?rs2955250 chr17 61959740 t c 0.6945 0.0277 0.0129 3.17E-02 rs12307687 GH2?rs228758 chr17 42148205 t c 0.1222 -0.0265 0.015 7.72E-02 rs12307687 G6PC3?rs224333 chr20 34023962 a g 0.8606 0.0568 0.0246 2.10E-02 rs10071837 GDF5?rs4681725 chr3 56692321 t g 0.2362 0.0386 0.011 4.45E-04 rs10071837 C3orf63?rs7652177 chr3 ? 171969077 c g 0.1478 -0.0458 0.0134 6.34E-04 rs10071837 FNDC3B?rs925098 chr4 ? 17919811 a g 0.6529 -0.0563 0.0097 5.55E-09 rs925098 LCORL?rs1662837 chr4? 82168889 t c 0.2728 -0.0411 0.0105 8.66E-05 rs925098? no_value?rs10071837 chr5? 33381581 t c 0.424 -0.0324 0.0094 5.74E-04 rs925098? no_value

	[[alternative HTML version deleted]]


From data_analyst20bhrl at yahoo.com  Fri May 20 23:06:18 2016
From: data_analyst20bhrl at yahoo.com (data_analyst20bhrl at yahoo.com)
Date: Fri, 20 May 2016 21:06:18 +0000 (UTC)
Subject: [R] Inverse normal transformation of ranked data
References: <2046958597.14381.1463778378865.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <2046958597.14381.1463778378865.JavaMail.yahoo@mail.yahoo.com>

I am?using ddply on?a data set that contains 2+ million rows; trying to rank the values of a variable within groups, and then transform the ranks to (approximate) z-scores --- i.e generate quantiles on the normal scale.
Here is some sample data for one group:x <- NA 0.3640951 0.1175880 0.3453916 0.4214050 0.7469022 0.1091423 0.6099482? ? ? ? NA? ? ? ? NA 0.6786140 0.1785854 0.9750262? ? ? ? NA

I have tried the following two alternatives:?
(1) Using the qnorm function from the stats package in conjunction with the percent_rank function from the dplyr? package:For example:
y <- qnorm(percent_rank(x))
This produces -Inf and Inf for the extreme values in the sample data. This issue is resolved if I use the rank function from the stats package instead, for example:y <- qnorm(rank(x, na.last = "keep", ties.method = "average")/length(x))
but if there are no NAs in a certain group, the upper extreme data point is still evaluated to Inf.
(2) Using the ztransform function from the GenABEL package:
For example: 
y <- ztransform(percent_rank(x))
This preserves the extreme values but produces one of the following types of errors when used on my full data set.

Error in ztransform(x) : trait is binary
ORError in ztransform(x) : trait is monomorphic
I suspect these errors may be due to the fact that there are very few observations and/or several missing values (NAs) within certain groups, but I am not sure since there are several hundred groups.? 
Is there a better way?
Sent from Yahoo Mail. Get the app
	[[alternative HTML version deleted]]


From sibasish.saha7 at gmail.com  Fri May 20 20:43:32 2016
From: sibasish.saha7 at gmail.com (Sibasish Saha)
Date: Sat, 21 May 2016 00:13:32 +0530
Subject: [R] (no subject)
Message-ID: <CAE8W_8_xcKWdrTKoqgkDE9CXS1UaWL7dmPVPWVFE_tEW22hdDQ@mail.gmail.com>

What is the code in R to get the goodness of fit in nls?? Please sir...
please help me

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat May 21 03:35:44 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 20 May 2016 18:35:44 -0700
Subject: [R] Choosing subset of data
In-Reply-To: <1598096813.5717732.1463769991582.JavaMail.yahoo@mail.yahoo.com>
References: <1598096813.5717732.1463769991582.JavaMail.yahoo.ref@mail.yahoo.com>
	<1598096813.5717732.1463769991582.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <BBFDCF91-AC6D-411E-8749-7D826DFA1627@comcast.net>


> On May 20, 2016, at 11:46 AM, oslo via R-help <r-help at r-project.org> wrote:
> 
> Hi all;
> I have a big data set (a small part is given below) and V1 column has repeated info in it. That is rs941873, rs12307687... are repeating many times. I need choose only one SNP (in first column named rs) which has the smallest  Pvalue withing V1 column. That is I need choose only one SNP for repeated names in V1 which has the smallest Pvalue.
> Your helps are truly appreciated,
> 
> 
> 
> 
>  rs                   Chr V6            A1  A2   Freq   Effect  StdErr         Pvalue  V1          Gene rs941873 chr10 81139462 a g 0.4117 -0.0541 0.0103 1.52E-07 rs941873        no_value rs634552 chr11 75282052 t g 0.3735 0.0159 0.0099 1.08E-01 rs941873 SERPINH1 rs11107175 chr12 94161719 t c 0.0896 -0.0386 0.0176 2.85E-02 rs941873  CRADD rs12307687 chr12 47175866 a t 0.7379 -0.0208 0.0135 1.23E-01 rs12307687 SLC38A4 rs3917155 chr14 76444685 c g 0.0495 0.0153 0.0371 6.80E-01 rs941873  TGFB3 rs1600640 chr15 84603034 t g 0.1791 -0.0448 0.0123 2.75E-04 rs12307687 ADAMTSL3 rs2871865 chr15 99194896 c g 0.5515 0.0191 0.0106 7.09E-02 rs12307687 IGF1R rs2955250 chr17 61959740 t c 0.6945 0.0277 0.0129 3.17E-02 rs12307687 GH2 rs228758 chr17 42148205 t c 0.1222 -0.0265 0.015 7.72E-02 rs12307687 G6PC3 rs224333 chr20 34023962 a g 0.8606 0.0568 0.0246 2.10E-02 rs10071837 GDF5 rs4681725 chr3 56692321 t g 0.2362 0.0386 0.011 4.45E-04 rs10071837 C3orf63 rs7652177 chr3   171969077 c g 0.1478 -0.0458 0.0134 6.34E-04 rs10071837 FNDC3B rs925098 chr4   17919811 a g 0.6529 -0.0563 0.0097 5.55E-09 rs925098 LCORL rs1662837 chr4  82168889 t c 0.2728 -0.0411 0.0105 8.66E-05 rs925098  no_value rs10071837 chr5  33381581 t c 0.424 -0.0324 0.0094 5.74E-04 rs925098  no_value
> 
> 	[[alternative HTML version deleted]]

The reason your data is garbled is that you failed to configure your email client to post in plain text. Please read the posting guide and the listinfo for r-help. You should also clarify what you want. Do you want only one line per SNP so the result would be another dataframe with a reduced number of lines of data?

______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sat May 21 03:39:16 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 20 May 2016 18:39:16 -0700
Subject: [R] (no subject)
In-Reply-To: <CAE8W_8_xcKWdrTKoqgkDE9CXS1UaWL7dmPVPWVFE_tEW22hdDQ@mail.gmail.com>
References: <CAE8W_8_xcKWdrTKoqgkDE9CXS1UaWL7dmPVPWVFE_tEW22hdDQ@mail.gmail.com>
Message-ID: <2629381A-2BBC-45B9-AE56-02A75C2CC77E@comcast.net>


> On May 20, 2016, at 11:43 AM, Sibasish Saha <sibasish.saha7 at gmail.com> wrote:
> 
> What is the code in R to get the goodness of fit in nls??

Can you "back up" a bit and present the _theory_  you have in mind that lets you assess the GOF?

> Please sir...
> please help me

You should also search the r-help archives because this is a recurring question here.

http://markmail.org/search/?q=list%3Aorg.r-project.r-help+goodness+of+fit+nls


> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From albapompeo at gmail.com  Sat May 21 14:49:24 2016
From: albapompeo at gmail.com (Alba Pompeo)
Date: Sat, 21 May 2016 09:49:24 -0300
Subject: [R] lib default location
Message-ID: <CAJDAfTD9qh1b_5DE029o9xtSy6MqLMCDF9W6XdQyypxL+bscKg@mail.gmail.com>

Everytime I install a package from CRAN I receive this message:

Installing package into ?/home/albap/R/x86_64-pc-linux-gnu-library/3.3?
(as ?lib? is unspecified)

Should I set my lib? If so, what's the recommended path?

Also, everytime I have to choose the mirror. Could I make one of them default?

Thanks!
Ciao.


From ligges at statistik.tu-dortmund.de  Sat May 21 15:54:19 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 21 May 2016 15:54:19 +0200
Subject: [R] lib default location
In-Reply-To: <CAJDAfTD9qh1b_5DE029o9xtSy6MqLMCDF9W6XdQyypxL+bscKg@mail.gmail.com>
References: <CAJDAfTD9qh1b_5DE029o9xtSy6MqLMCDF9W6XdQyypxL+bscKg@mail.gmail.com>
Message-ID: <d1d64b23-7c76-1950-c1ea-0a8a592b266f@statistik.tu-dortmund.de>



On 21.05.2016 14:49, Alba Pompeo wrote:
> Everytime I install a package from CRAN I receive this message:
>
> Installing package into ?/home/albap/R/x86_64-pc-linux-gnu-library/3.3?
> (as ?lib? is unspecified)
>
> Should I set my lib? If so, what's the recommended path?

It is fine to keep this per user default.



> Also, everytime I have to choose the mirror. Could I make one of them default?

Yes, one way is described in the examples of ?Startup.

Best,
Uwe Ligges



> Thanks!
> Ciao.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From chalabi.elahe at yahoo.de  Sat May 21 16:41:47 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Sat, 21 May 2016 14:41:47 +0000 (UTC)
Subject: [R] An averaged model based on Quartile and Mean of Quartiles
References: <713001651.363450.1463841707112.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <713001651.363450.1463841707112.JavaMail.yahoo@mail.yahoo.com>

Hi all,

Here is my df and I want to make an averaged model of my variables based on Time like the following:

    
   $ Protocol   : Factor w/ 48 levels "DP FS QTSE SAG",..: 2 3 43 42 
   $ Time       : num  182 185 189 234 186 ... 

   $ Systemtype   : Factor w/ 2 levels "Aera XJ","AERA XQ": 1 1 1 
   $ ADJ        : Factor w/ 2 levels "auto","manu": 1 1 
   $ BR         : int  384 384 384 384 512 384
   $ TF         : int  10 10 13 7 7 5 5 
I split my df into quartiles for time,

   
   df$quant=findInterval(df$Time, quantile(df$Time), rightmost.closed=TRUE)
by the column df$quant I see quartiles 1 to 4 for time, next I want to create a new column for example for BR and if df$quant==1 then put mean of first quartile of BR in that,if df$quant==2 put mean of second quartile of BR in that and so on. I do the same for every numeric variable. Does anyone know how to that?


Thanks for any help!
Elahe


From dwinsemius at comcast.net  Sat May 21 17:13:57 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 21 May 2016 08:13:57 -0700
Subject: [R] An averaged model based on Quartile and Mean of Quartiles
In-Reply-To: <713001651.363450.1463841707112.JavaMail.yahoo@mail.yahoo.com>
References: <713001651.363450.1463841707112.JavaMail.yahoo.ref@mail.yahoo.com>
	<713001651.363450.1463841707112.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <78CF2E68-E764-44DD-8885-BED6EDD405B9@comcast.net>


> On May 21, 2016, at 7:41 AM, ch.elahe via R-help <r-help at r-project.org> wrote:
> 
> Hi all,
> 
> Here is my df and I want to make an averaged model of my variables based on Time like the following:
> 
> 
>   $ Protocol   : Factor w/ 48 levels "DP FS QTSE SAG",..: 2 3 43 42 
>   $ Time       : num  182 185 189 234 186 ... 
> 
>   $ Systemtype   : Factor w/ 2 levels "Aera XJ","AERA XQ": 1 1 1 
>   $ ADJ        : Factor w/ 2 levels "auto","manu": 1 1 
>   $ BR         : int  384 384 384 384 512 384
>   $ TF         : int  10 10 13 7 7 5 5 
> I split my df into quartiles for time,
> 
> 
>   df$quant=findInterval(df$Time, quantile(df$Time), rightmost.closed=TRUE)
> by the column df$quant I see quartiles 1 to 4 for time, next I want to create a new column for example for BR and if df$quant==1 then put mean of first quartile of BR in that,if df$quant==2 put mean of second quartile of BR in that and so on. I do the same for every numeric variable. Does anyone know how to that?
> 

Perhaps, but untested in the absence of a reproducible example and choosing to instead use a name for the dataframe which is not also a function name:

aggregate( dfrm[ , sapply( dfrm, inherits, "numeric")],   # logical indexing for `[, j]`
           dfrm['quant']      # using "[" keeps it a list
           mean)

-- 

David Winsemius
Alameda, CA, USA


From ulrik.stervbo at gmail.com  Sat May 21 17:59:18 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Sat, 21 May 2016 15:59:18 +0000
Subject: [R] An averaged model based on Quartile and Mean of Quartiles
In-Reply-To: <78CF2E68-E764-44DD-8885-BED6EDD405B9@comcast.net>
References: <713001651.363450.1463841707112.JavaMail.yahoo.ref@mail.yahoo.com>
	<713001651.363450.1463841707112.JavaMail.yahoo@mail.yahoo.com>
	<78CF2E68-E764-44DD-8885-BED6EDD405B9@comcast.net>
Message-ID: <CAKVAULPE2Gz+U56YbXP-jv06bQsx9RmaeVCNwrabBvvSJMU_MQ@mail.gmail.com>

Hi Chalabi,

Maybe you can use ddply to look over the intervals and add the means as new
colum

Best wishes
Ulrik

David Winsemius <dwinsemius at comcast.net> schrieb am Sa., 21. Mai 2016 17:16:

>
> > On May 21, 2016, at 7:41 AM, ch.elahe via R-help <r-help at r-project.org>
> wrote:
> >
> > Hi all,
> >
> > Here is my df and I want to make an averaged model of my variables based
> on Time like the following:
> >
> >
> >   $ Protocol   : Factor w/ 48 levels "DP FS QTSE SAG",..: 2 3 43 42
> >   $ Time       : num  182 185 189 234 186 ...
> >
> >   $ Systemtype   : Factor w/ 2 levels "Aera XJ","AERA XQ": 1 1 1
> >   $ ADJ        : Factor w/ 2 levels "auto","manu": 1 1
> >   $ BR         : int  384 384 384 384 512 384
> >   $ TF         : int  10 10 13 7 7 5 5
> > I split my df into quartiles for time,
> >
> >
> >   df$quant=findInterval(df$Time, quantile(df$Time),
> rightmost.closed=TRUE)
> > by the column df$quant I see quartiles 1 to 4 for time, next I want to
> create a new column for example for BR and if df$quant==1 then put mean of
> first quartile of BR in that,if df$quant==2 put mean of second quartile of
> BR in that and so on. I do the same for every numeric variable. Does anyone
> know how to that?
> >
>
> Perhaps, but untested in the absence of a reproducible example and
> choosing to instead use a name for the dataframe which is not also a
> function name:
>
> aggregate( dfrm[ , sapply( dfrm, inherits, "numeric")],   # logical
> indexing for `[, j]`
>            dfrm['quant']      # using "[" keeps it a list
>            mean)
>
> --
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From george.brida at gmail.com  Sat May 21 21:00:31 2016
From: george.brida at gmail.com (george brida)
Date: Sat, 21 May 2016 21:00:31 +0200
Subject: [R] Matrix multiplications
Message-ID: <CAGsroM2O5yKg3Jyd+2Fs_+UX2F1yiviL2GSAmjGrzRSyoJeKCw@mail.gmail.com>

Dear R users:

I have written the following lines :

>x=c(10,11,12,13,14,17,15,16,10,11,41,25,26,14,12,14,15,20,14,22)
> x=matrix(x,ncol=2)
> a=matrix(1,nrow(x),1)
> X=cbind(a,x)
>y=c(12.00, 11.00, 13.00, 12.50, 14.00, 18.50, 15.00, 12.50, 13.75, 15.00)

>b=solve(t(X)%*% X)%*% t(X)%*% y

when I wrote the following line
>(t(y-X %*% b)%*%(y-X %*% b)/(length(y)-ncol(X)))*solve(t(X)%*% X)
I have obtained an error message, I don't know why namely (t(y-X %*%
b)%*%(y-X %*% b)/(length(y)-ncol(X))) is a scalar:
> (t(y-X %*% b)%*%(y-X %*% b)/(length(y)-ncol(X)))
         [,1]
[1,] 3.620354


Can you please help me.

Thank you

George

	[[alternative HTML version deleted]]


From roy.mendelssohn at noaa.gov  Sat May 21 21:10:57 2016
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Sat, 21 May 2016 12:10:57 -0700
Subject: [R] Matrix multiplications
In-Reply-To: <CAGsroM2O5yKg3Jyd+2Fs_+UX2F1yiviL2GSAmjGrzRSyoJeKCw@mail.gmail.com>
References: <CAGsroM2O5yKg3Jyd+2Fs_+UX2F1yiviL2GSAmjGrzRSyoJeKCw@mail.gmail.com>
Message-ID: <633F5E66-DB21-4764-91E9-2F4BE3EDACF8@noaa.gov>

>  str(t(y-X %*% b))
 num [1, 1:10] 0.595 -1.7538 -0.0498 -1.651 -0.6328 ...
> str((y-X %*% b))
 num [1:10, 1] 0.595 -1.7538 -0.0498 -1.651 -0.6328 ?

-Roy


> On May 21, 2016, at 12:00 PM, george brida <george.brida at gmail.com> wrote:
> 
> Dear R users:
> 
> I have written the following lines :
> 
>> x=c(10,11,12,13,14,17,15,16,10,11,41,25,26,14,12,14,15,20,14,22)
>> x=matrix(x,ncol=2)
>> a=matrix(1,nrow(x),1)
>> X=cbind(a,x)
>> y=c(12.00, 11.00, 13.00, 12.50, 14.00, 18.50, 15.00, 12.50, 13.75, 15.00)
> 
>> b=solve(t(X)%*% X)%*% t(X)%*% y
> 
> when I wrote the following line
>> (t(y-X %*% b)%*%(y-X %*% b)/(length(y)-ncol(X)))*solve(t(X)%*% X)
> I have obtained an error message, I don't know why namely (t(y-X %*%
> b)%*%(y-X %*% b)/(length(y)-ncol(X))) is a scalar:
>> (t(y-X %*% b)%*%(y-X %*% b)/(length(y)-ncol(X)))
>         [,1]
> [1,] 3.620354
> 
> 
> Can you please help me.
> 
> Thank you
> 
> George
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From pdalgd at gmail.com  Sat May 21 21:18:21 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 21 May 2016 21:18:21 +0200
Subject: [R] Matrix multiplications
In-Reply-To: <CAGsroM2O5yKg3Jyd+2Fs_+UX2F1yiviL2GSAmjGrzRSyoJeKCw@mail.gmail.com>
References: <CAGsroM2O5yKg3Jyd+2Fs_+UX2F1yiviL2GSAmjGrzRSyoJeKCw@mail.gmail.com>
Message-ID: <B64CD58C-61C9-4B0F-922F-46EFC924C042@gmail.com>


> On 21 May 2016, at 21:00 , george brida <george.brida at gmail.com> wrote:
> 
> Dear R users:
> 
> I have written the following lines :
> 
>> x=c(10,11,12,13,14,17,15,16,10,11,41,25,26,14,12,14,15,20,14,22)
>> x=matrix(x,ncol=2)
>> a=matrix(1,nrow(x),1)
>> X=cbind(a,x)
>> y=c(12.00, 11.00, 13.00, 12.50, 14.00, 18.50, 15.00, 12.50, 13.75, 15.00)
> 
>> b=solve(t(X)%*% X)%*% t(X)%*% y
> 
> when I wrote the following line
>> (t(y-X %*% b)%*%(y-X %*% b)/(length(y)-ncol(X)))*solve(t(X)%*% X)
> I have obtained an error message, I don't know why namely (t(y-X %*%
> b)%*%(y-X %*% b)/(length(y)-ncol(X))) is a scalar:
>> (t(y-X %*% b)%*%(y-X %*% b)/(length(y)-ncol(X)))
>         [,1]
> [1,] 3.620354
> 
> 
> Can you please help me.

Mistake is that (t(y-X %*% b)%*%(y-X %*% b)/(length(y)-ncol(X))) is NOT a scalar, but a 1 x 1 matrix. 

This works:

as.vector((t(y-X %*% b)%*%(y-X %*% b))/(length(y)-ncol(X)))*solve(t(X)%*% X)

as does recognizing the first term as a sum of squares:

sum((y-X %*% b)^2)/(length(y)-ncol(X))*solve(t(X)%*% X)

(And, for the Illuminati, a Kronecker product works too:

(t(y-X %*% b)%*%(y-X %*% b)/(length(y)-ncol(X))) %x% solve(t(X)%*% X)

This could be useful for multivariate y.)

> 
> Thank you
> 
> George
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From george.brida at gmail.com  Sat May 21 21:26:06 2016
From: george.brida at gmail.com (george brida)
Date: Sat, 21 May 2016 21:26:06 +0200
Subject: [R] Matrix multiplications
In-Reply-To: <633F5E66-DB21-4764-91E9-2F4BE3EDACF8@noaa.gov>
References: <CAGsroM2O5yKg3Jyd+2Fs_+UX2F1yiviL2GSAmjGrzRSyoJeKCw@mail.gmail.com>
	<633F5E66-DB21-4764-91E9-2F4BE3EDACF8@noaa.gov>
Message-ID: <CAGsroM3oTzNYpWJ7JCD0AkoZ6+h02cQuyvKMZ3LJyXaCAAMSqA@mail.gmail.com>

Roy,

Yes, t(y-X %*% b) is the transpose of y-X %*% b. In principle the product
of  t(y-X %*% b) *(y-X %*% b) is a scalar, I don't know why I have an error
message after the following line:

(t(y-X %*% b)%*%(y-X %*% b)/(length(y)-ncol(X)))*solve(t(X)%*% X)

Thanks


On Sat, May 21, 2016 at 9:10 PM, Roy Mendelssohn - NOAA Federal <
roy.mendelssohn at noaa.gov> wrote:

> >  str(t(y-X %*% b))
>  num [1, 1:10] 0.595 -1.7538 -0.0498 -1.651 -0.6328 ...
> > str((y-X %*% b))
>  num [1:10, 1] 0.595 -1.7538 -0.0498 -1.651 -0.6328 ?
>
> -Roy
>
>
> > On May 21, 2016, at 12:00 PM, george brida <george.brida at gmail.com>
> wrote:
> >
> > Dear R users:
> >
> > I have written the following lines :
> >
> >> x=c(10,11,12,13,14,17,15,16,10,11,41,25,26,14,12,14,15,20,14,22)
> >> x=matrix(x,ncol=2)
> >> a=matrix(1,nrow(x),1)
> >> X=cbind(a,x)
> >> y=c(12.00, 11.00, 13.00, 12.50, 14.00, 18.50, 15.00, 12.50, 13.75,
> 15.00)
> >
> >> b=solve(t(X)%*% X)%*% t(X)%*% y
> >
> > when I wrote the following line
> >> (t(y-X %*% b)%*%(y-X %*% b)/(length(y)-ncol(X)))*solve(t(X)%*% X)
> > I have obtained an error message, I don't know why namely (t(y-X %*%
> > b)%*%(y-X %*% b)/(length(y)-ncol(X))) is a scalar:
> >> (t(y-X %*% b)%*%(y-X %*% b)/(length(y)-ncol(X)))
> >         [,1]
> > [1,] 3.620354
> >
> >
> > Can you please help me.
> >
> > Thank you
> >
> > George
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> **********************
> "The contents of this message do not reflect any position of the U.S.
> Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new address and phone***
> 110 Shaffer Road
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK
> Jr.
>
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Sat May 21 22:29:12 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 21 May 2016 22:29:12 +0200
Subject: [R] Matrix multiplications
In-Reply-To: <CAGsroM3oTzNYpWJ7JCD0AkoZ6+h02cQuyvKMZ3LJyXaCAAMSqA@mail.gmail.com>
References: <CAGsroM2O5yKg3Jyd+2Fs_+UX2F1yiviL2GSAmjGrzRSyoJeKCw@mail.gmail.com>
	<633F5E66-DB21-4764-91E9-2F4BE3EDACF8@noaa.gov>
	<CAGsroM3oTzNYpWJ7JCD0AkoZ6+h02cQuyvKMZ3LJyXaCAAMSqA@mail.gmail.com>
Message-ID: <D407CAEB-435B-4BB8-8861-AAD9E62B2420@gmail.com>

I don't know if there is some sort of propagation delay, but the reason has already been given and multiple fixes suggested.

-pd


> On 21 May 2016, at 21:26 , george brida <george.brida at gmail.com> wrote:
> 
> Roy,
> 
> Yes, t(y-X %*% b) is the transpose of y-X %*% b. In principle the product
> of  t(y-X %*% b) *(y-X %*% b) is a scalar, I don't know why I have an error
> message after the following line:
> 
> (t(y-X %*% b)%*%(y-X %*% b)/(length(y)-ncol(X)))*solve(t(X)%*% X)
> 
> Thanks
> 
> 
> On Sat, May 21, 2016 at 9:10 PM, Roy Mendelssohn - NOAA Federal <
> roy.mendelssohn at noaa.gov> wrote:
> 
>>> str(t(y-X %*% b))
>> num [1, 1:10] 0.595 -1.7538 -0.0498 -1.651 -0.6328 ...
>>> str((y-X %*% b))
>> num [1:10, 1] 0.595 -1.7538 -0.0498 -1.651 -0.6328 ?
>> 
>> -Roy
>> 
>> 
>>> On May 21, 2016, at 12:00 PM, george brida <george.brida at gmail.com>
>> wrote:
>>> 
>>> Dear R users:
>>> 
>>> I have written the following lines :
>>> 
>>>> x=c(10,11,12,13,14,17,15,16,10,11,41,25,26,14,12,14,15,20,14,22)
>>>> x=matrix(x,ncol=2)
>>>> a=matrix(1,nrow(x),1)
>>>> X=cbind(a,x)
>>>> y=c(12.00, 11.00, 13.00, 12.50, 14.00, 18.50, 15.00, 12.50, 13.75,
>> 15.00)
>>> 
>>>> b=solve(t(X)%*% X)%*% t(X)%*% y
>>> 
>>> when I wrote the following line
>>>> (t(y-X %*% b)%*%(y-X %*% b)/(length(y)-ncol(X)))*solve(t(X)%*% X)
>>> I have obtained an error message, I don't know why namely (t(y-X %*%
>>> b)%*%(y-X %*% b)/(length(y)-ncol(X))) is a scalar:
>>>> (t(y-X %*% b)%*%(y-X %*% b)/(length(y)-ncol(X)))
>>>        [,1]
>>> [1,] 3.620354
>>> 
>>> 
>>> Can you please help me.
>>> 
>>> Thank you
>>> 
>>> George
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> **********************
>> "The contents of this message do not reflect any position of the U.S.
>> Government or NOAA."
>> **********************
>> Roy Mendelssohn
>> Supervisory Operations Research Analyst
>> NOAA/NMFS
>> Environmental Research Division
>> Southwest Fisheries Science Center
>> ***Note new address and phone***
>> 110 Shaffer Road
>> Santa Cruz, CA 95060
>> Phone: (831)-420-3666
>> Fax: (831) 420-3980
>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>> 
>> "Old age and treachery will overcome youth and skill."
>> "From those who have been given much, much will be expected"
>> "the arc of the moral universe is long, but it bends toward justice" -MLK
>> Jr.
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From r.turner at auckland.ac.nz  Sat May 21 23:30:55 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 22 May 2016 09:30:55 +1200
Subject: [R] lib default location
In-Reply-To: <d1d64b23-7c76-1950-c1ea-0a8a592b266f@statistik.tu-dortmund.de>
References: <CAJDAfTD9qh1b_5DE029o9xtSy6MqLMCDF9W6XdQyypxL+bscKg@mail.gmail.com>
	<d1d64b23-7c76-1950-c1ea-0a8a592b266f@statistik.tu-dortmund.de>
Message-ID: <92b937d5-f89c-f11a-65f0-d2f1d92618b0@auckland.ac.nz>

On 22/05/16 01:54, Uwe Ligges wrote:
>
>
> On 21.05.2016 14:49, Alba Pompeo wrote:
>> Everytime I install a package from CRAN I receive this message:
>>
>> Installing package into ?/home/albap/R/x86_64-pc-linux-gnu-library/3.3?
>> (as ?lib? is unspecified)
>>
>> Should I set my lib? If so, what's the recommended path?
>
> It is fine to keep this per user default.

Note that you can suppress the somewhat redundant message by specifying 
quiet=TRUE in the call to install.packages().

cheers,

Rolf Turner

Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From albapompeo at gmail.com  Sun May 22 00:06:19 2016
From: albapompeo at gmail.com (Alba Pompeo)
Date: Sat, 21 May 2016 19:06:19 -0300
Subject: [R] lib default location
In-Reply-To: <92b937d5-f89c-f11a-65f0-d2f1d92618b0@auckland.ac.nz>
References: <CAJDAfTD9qh1b_5DE029o9xtSy6MqLMCDF9W6XdQyypxL+bscKg@mail.gmail.com>
	<d1d64b23-7c76-1950-c1ea-0a8a592b266f@statistik.tu-dortmund.de>
	<92b937d5-f89c-f11a-65f0-d2f1d92618b0@auckland.ac.nz>
Message-ID: <CAJDAfTDkMvzK9+BrKvYF4U5-TYOo1Kpp+z37a32ciTA3tFnfHg@mail.gmail.com>

Nice alternative solution.
Thanks Rolf.


On Sat, May 21, 2016 at 6:30 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 22/05/16 01:54, Uwe Ligges wrote:
>>
>>
>>
>> On 21.05.2016 14:49, Alba Pompeo wrote:
>>>
>>> Everytime I install a package from CRAN I receive this message:
>>>
>>> Installing package into ?/home/albap/R/x86_64-pc-linux-gnu-library/3.3?
>>> (as ?lib? is unspecified)
>>>
>>> Should I set my lib? If so, what's the recommended path?
>>
>>
>> It is fine to keep this per user default.
>
>
> Note that you can suppress the somewhat redundant message by specifying
> quiet=TRUE in the call to install.packages().
>
> cheers,
>
> Rolf Turner
>
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276


From george.brida at gmail.com  Sat May 21 21:32:59 2016
From: george.brida at gmail.com (george brida)
Date: Sat, 21 May 2016 21:32:59 +0200
Subject: [R] Matrix multiplications
In-Reply-To: <B64CD58C-61C9-4B0F-922F-46EFC924C042@gmail.com>
References: <CAGsroM2O5yKg3Jyd+2Fs_+UX2F1yiviL2GSAmjGrzRSyoJeKCw@mail.gmail.com>
	<B64CD58C-61C9-4B0F-922F-46EFC924C042@gmail.com>
Message-ID: <CAGsroM0nQ3KZG4nTbB+mxjKBhXH0961v6c8U1DwJuNfo9fu77Q@mail.gmail.com>

Thank you very much Peter.

On Sat, May 21, 2016 at 9:18 PM, peter dalgaard <pdalgd at gmail.com> wrote:

>
> > On 21 May 2016, at 21:00 , george brida <george.brida at gmail.com> wrote:
> >
> > Dear R users:
> >
> > I have written the following lines :
> >
> >> x=c(10,11,12,13,14,17,15,16,10,11,41,25,26,14,12,14,15,20,14,22)
> >> x=matrix(x,ncol=2)
> >> a=matrix(1,nrow(x),1)
> >> X=cbind(a,x)
> >> y=c(12.00, 11.00, 13.00, 12.50, 14.00, 18.50, 15.00, 12.50, 13.75,
> 15.00)
> >
> >> b=solve(t(X)%*% X)%*% t(X)%*% y
> >
> > when I wrote the following line
> >> (t(y-X %*% b)%*%(y-X %*% b)/(length(y)-ncol(X)))*solve(t(X)%*% X)
> > I have obtained an error message, I don't know why namely (t(y-X %*%
> > b)%*%(y-X %*% b)/(length(y)-ncol(X))) is a scalar:
> >> (t(y-X %*% b)%*%(y-X %*% b)/(length(y)-ncol(X)))
> >         [,1]
> > [1,] 3.620354
> >
> >
> > Can you please help me.
>
> Mistake is that (t(y-X %*% b)%*%(y-X %*% b)/(length(y)-ncol(X))) is NOT a
> scalar, but a 1 x 1 matrix.
>
> This works:
>
> as.vector((t(y-X %*% b)%*%(y-X %*% b))/(length(y)-ncol(X)))*solve(t(X)%*%
> X)
>
> as does recognizing the first term as a sum of squares:
>
> sum((y-X %*% b)^2)/(length(y)-ncol(X))*solve(t(X)%*% X)
>
> (And, for the Illuminati, a Kronecker product works too:
>
> (t(y-X %*% b)%*%(y-X %*% b)/(length(y)-ncol(X))) %x% solve(t(X)%*% X)
>
> This could be useful for multivariate y.)
>
> >
> > Thank you
> >
> > George
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From hokut1 at yahoo.com  Sun May 22 05:31:12 2016
From: hokut1 at yahoo.com (oslo)
Date: Sun, 22 May 2016 03:31:12 +0000 (UTC)
Subject: [R] Choosing rows
References: <709946481.355864.1463887872593.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <709946481.355864.1463887872593.JavaMail.yahoo@mail.yahoo.com>

Hi all;
I have a big data set (a small part is given below) and V1 column has repeated info in it. That is rs941873, rs12307687... are repeating many times. I need choose only one SNP (in first column named rs) which has the smallest ?Pvalue withing V1 column. That is I need choose only one SNP for repeated names in V1 which has the smallest Pvalue.
Your helps are truly appreciated,Oslo

| ?rs  | n0 | Pvalue | V1 |
|  ?rs941873  | 81139462 | 1.52E-07 | rs941873 |
|  ?rs634552  | 75282052 | 1.08E-01 | rs941873 |
|  ?rs11107175  | 94161719 | 2.85E-02 | rs941873? |
|  ?rs12307687  | 47175866 | 1.23E-01 | rs12307687 |
|  ?rs3917155  | 76444685 | 6.80E-01 | rs941873? |
|  ?rs1600640  | 84603034 | 2.75E-04 | rs12307687 |
|  ?rs2871865  | 99194896 | 7.09E-02 | rs12307687 |
|  ?rs2955250  | 61959740 | 3.17E-02 | rs12307687 |
|  ?rs228758  | 42148205 | 7.72E-02 | rs12307687 |
|  ?rs224333  | 34023962 | 2.10E-02 | rs10071837 |
|  ?rs4681725  | 56692321 | 4.45E-04 | rs10071837 |
|  ?rs7652177  | 171969077 | 6.34E-04 | rs10071837 |
|  ?rs925098  | 17919811 | 5.55E-09 | rs925098 |
|  ?rs1662837  | 82168889 | 8.66E-05 | rs925098? |
|  ?rs10071837  | 33381581 | 5.74E-04 | rs925098? |


	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Sun May 22 13:35:20 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Sun, 22 May 2016 12:35:20 +0100
Subject: [R] Choosing rows
In-Reply-To: <709946481.355864.1463887872593.JavaMail.yahoo@mail.yahoo.com>
References: <709946481.355864.1463887872593.JavaMail.yahoo.ref@mail.yahoo.com>
	<709946481.355864.1463887872593.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <20160522123520.Horde.sAzcaYYDx5NUX5gf6zesx10@mail.sapo.pt>

Hello,

First of all, it's better to post data using ?dput. Below, I give an  
example of that? in the lines structure(...).
dat <-
structure(list(rs = c("?? rs941873? ", "?? rs634552? ", "?? rs11107175? ",
"?? rs12307687? ", "?? rs3917155? ", "?? rs1600640? ", "?? rs2871865? ",
"?? rs2955250? ", "?? rs228758? ", "?? rs224333? ", "?? rs4681725? ",
"?? rs7652177? ", "?? rs925098? ", "?? rs1662837? ", "?? rs10071837? "
), n0 = c(81139462, 75282052, 94161719, 47175866, 76444685, 84603034,
99194896, 61959740, 42148205, 34023962, 56692321, 171969077,
17919811, 82168889, 33381581), Pvalue = c(1.52e-07, 0.108, 0.0285,
0.123, 0.68, 0.000275, 0.0709, 0.0317, 0.0772, 0.021, 0.000445,
0.000634, 5.55e-09, 8.66e-05, 0.000574), V1 = c("rs941873", "rs941873",
"rs941873", "rs12307687", "rs941873", "rs12307687", "rs12307687",
"rs12307687", "rs12307687", "rs10071837", "rs10071837", "rs10071837",
"rs925098", "rs925098", "rs925098")), .Names = c("rs", "n0",
"Pvalue", "V1"), row.names = c(NA, -15L), class = "data.frame")

Now, if I understand correctly, the following might do what you want.

tmp <- split(dat[, "Pvalue"], dat[, "V1"])
idx <- unlist(lapply(tmp, function(x) x == min(x)))[order(order(dat[, "V1"]))]
rm(tmp)
result <- dat[idx, ]
result

Hope this helps,

Rui Barradas
?

Citando oslo via R-help <r-help at r-project.org>:

> Hi all;
> I have a big data set (a small part is given below) and V1 column  
> has repeated info in it. That is rs941873, rs12307687... are  
> repeating many times. I need choose only one SNP (in first column  
> named rs) which has the smallest ?Pvalue withing V1 column. That is  
> I need choose only one SNP for repeated names in V1 which has the  
> smallest Pvalue.
> Your helps are truly appreciated,Oslo
>
> | ?rs? | n0 | Pvalue | V1 |
> |? ?rs941873? | 81139462 | 1.52E-07 | rs941873 |
> |? ?rs634552? | 75282052 | 1.08E-01 | rs941873 |
> |? ?rs11107175? | 94161719 | 2.85E-02 | rs941873? |
> |? ?rs12307687? | 47175866 | 1.23E-01 | rs12307687 |
> |? ?rs3917155? | 76444685 | 6.80E-01 | rs941873? |
> |? ?rs1600640? | 84603034 | 2.75E-04 | rs12307687 |
> |? ?rs2871865? | 99194896 | 7.09E-02 | rs12307687 |
> |? ?rs2955250? | 61959740 | 3.17E-02 | rs12307687 |
> |? ?rs228758? | 42148205 | 7.72E-02 | rs12307687 |
> |? ?rs224333? | 34023962 | 2.10E-02 | rs10071837 |
> |? ?rs4681725? | 56692321 | 4.45E-04 | rs10071837 |
> |? ?rs7652177? | 171969077 | 6.34E-04 | rs10071837 |
> |? ?rs925098? | 17919811 | 5.55E-09 | rs925098 |
> |? ?rs1662837? | 82168889 | 8.66E-05 | rs925098? |
> |? ?rs10071837? | 33381581 | 5.74E-04 | rs925098? |
>
> ? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide  
> http://www.R-project.org/posting-guide.htmland provide commented,  
> minimal, self-contained, reproducible code.

?

	[[alternative HTML version deleted]]


From carlosalvarezroa at hotmail.com  Sun May 22 13:31:16 2016
From: carlosalvarezroa at hotmail.com (Carlos Alvarez Roa)
Date: Sun, 22 May 2016 21:31:16 +1000
Subject: [R] Contrast matrix with a continuous variable
Message-ID: <DUB123-W4451CDC1BC062754278F43C44D0@phx.gbl>





















Hello everyone, 


I was wondering if could help me designing a
contrast matrix when you have a continuous variable (Days).  


 


My model looks like
this: 


 


model<-lme(Y~A*B*Days,
data=data_over_time) 


 


The factor A hast
two levels (A1 and A2) and factor B has three levels (B1, B2, and B3). I
measured the response variable Y every two or three days over 70 days
(Days).  


I need to look at
only a few comparisons over the 70 days such us: 


                                   A1 and B1 vs A2 and B1,  


                                   A2 and B2 vs
A2 and B1,  


                                   A1 and B2 vs
A2 and B2


I could use the
function contrast from the package contrast to design the matrix with the three
comparisons mentioned above for specific days at a time. However, I need to run
the comparison over the 70 days not at individual time points. 


 


I was wondering if
you could help me designing this contrast matrix. 


 


Any help would be
much appreciated.






 		 	   		  
	[[alternative HTML version deleted]]


From michu.kom at gmail.com  Sun May 22 10:49:01 2016
From: michu.kom at gmail.com (Michu Kom)
Date: Sun, 22 May 2016 10:49:01 +0200
Subject: [R] R vs SPSS - simple effects analysis in mixed 2x2 ANOVA scheme -
 same data, different results
Message-ID: <CAEJSOqgsRRV8CKk05u=0vX_JOJWk6Y=dqSR+FtxyQ-APUmS5pg@mail.gmail.com>

down votefavoriteHell
<http://stats.stackexchange.com/questions/213592/r-vs-spss-simple-effects-analysis-in-mixed-2x2-anova-scheme-same-data-diffe#>

Hello,

I prepared a mixed 2x2 ANOVA design analysis both in SPSS and in R. The
SPSS script is correct, but in R script there is a mistake somewhere. To
test that I generated artificial data from a normal distribution to
simulate the interaction between two independent variables. There were no
difference between the results in main effects, but results of simple
effects analysis do not match when comparing between levels of variable
which introduced repeated measures (GROUP A: PRE vs POST ; GROUP B: PRE vs
POST).

I would be very thankful if you can help me. The code below will do
everything for you.

*Here is the code in R which:* - generates the data - calculates mixed
ANOVA - prepares data to csv format to import to SPSS - performs simple
effect analysis (there is probably a mistake)

N <- 100
absMean <- 1
sdCustom <- 5

grA_pre <- data.frame(ID = seq(N), lvl=rnorm(N, mean=absMean,
sd=sdCustom), group=factor('A'), stage = factor('pre'))
grA_post <- data.frame(ID = seq(N), lvl=rnorm(N, mean=-absMean,
sd=sdCustom), group=factor('A'), stage = factor('post'))
grB_pre <- data.frame(ID = seq(N+1,2*N), lvl=rnorm(N, mean=-absMean,
sd=sdCustom), group=factor('B'), stage = factor('pre'))
grB_post <- data.frame(ID = seq(N+1,2*N), lvl=rnorm(N, mean=absMean,
sd=sdCustom), group=factor('B'), stage = factor('post'))

gr <- rbind(grA_pre, grA_post, grB_pre, grB_post)
names(gr)
head(gr)
# save set to .csv to import to SPSS
grSPSS <- reshape(data = gr, timevar = "stage", idvar = c("ID",
"group"), direction = "wide")

write.csv2(grSPSS, file = "sample2.csv")

library(ggplot2)
library(plyr)
library(ez)
print("Omnibus mixed ANOVA - main effects and interactions")
ezPlot(data = gr, wid = ID, dv = lvl, between = group, within = stage,
type = "III", x = group, split = stage, x_lab = "Group", y_lab =
"Level of experience")
ezANOVA(data = gr, wid = ID, dv = lvl, between = group, within =
stage, detailed = TRUE, type = "III")#ezStats(data = gr, wid = ID, dv
= lvl, between = group, within = stage, type = "III")

print("Simple main effects analysis")
dataA <- subset(gr, group == "A" )
dataB <- subset(gr, group == "B" )
dataPRE <- subset(gr, stage == "pre" )
dataPOST <- subset(gr, stage == "post" )
print("GROUP = A: PRE vs POST")
simpleEffControlANOVA <- ezANOVA(data = dataA, dv = lvl, wid = ID,
within = stage, detailed = TRUE, type = "III"
)print(simpleEffControlANOVA)
print("GROUP = B: PRE vs POST")
simpleEffControlANOVA <- ezANOVA(data = dataB, dv = lvl, wid = ID,
within = stage, detailed = TRUE, type = "III"
)print(simpleEffControlANOVA)
print("STAGE = PRE: A vs B")
simpleEffControlANOVA <- ezANOVA(data = dataPRE, dv = lvl, wid = ID,
between = group, detailed = TRUE, type = "III"
)print(simpleEffControlANOVA)
print("STAGE = POST: A vs B")
simpleEffControlANOVA <- ezANOVA(data = dataPOST, dv = lvl, wid = ID,
between = group, detailed = TRUE, type = "III"
)print(simpleEffControlANOVA)

*Here is the code for SPSS Syntax which:* - calculates everything on
imported data, generated by R

DATASET ACTIVATE DataSet1.
GLM lvl.pre lvl.post BY group
  /WSFACTOR=stage 2 Polynomial
  /METHOD=SSTYPE(3)
  /POSTHOC=group(TUKEY T3)
  /EMMEANS=TABLES(group) COMPARE ADJ(BONFERRONI)
  /EMMEANS=TABLES(stage) COMPARE ADJ(BONFERRONI)
  /EMMEANS=TABLES(group*stage) COMPARE(group)
  /EMMEANS=TABLES(group*stage) COMPARE(stage)
  /PLOT=PROFILE(group*stage)
  /PRINT=DESCRIPTIVE ETASQ OPOWER HOMOGENEITY
  /CRITERIA=ALPHA(.05)
  /WSDESIGN=stage
  /DESIGN=group.

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Sun May 22 17:12:24 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Sun, 22 May 2016 16:12:24 +0100
Subject: [R] R vs SPSS - simple effects analysis in mixed 2x2 ANOVA
 scheme - same data, different results
In-Reply-To: <CAEJSOqgsRRV8CKk05u=0vX_JOJWk6Y=dqSR+FtxyQ-APUmS5pg@mail.gmail.com>
References: <CAEJSOqgsRRV8CKk05u=0vX_JOJWk6Y=dqSR+FtxyQ-APUmS5pg@mail.gmail.com>
Message-ID: <625f9ed7-a000-7038-50c9-76bde5c3af3a@dewey.myzen.co.uk>

The only people who will be able to help you are people who use both R 
and SPSS as you do not show the result from either. So even though they 
can re-run your R commands they cannot compare them with SPSS.

On 22/05/2016 09:49, Michu Kom wrote:
> down votefavoriteHell
> <http://stats.stackexchange.com/questions/213592/r-vs-spss-simple-effects-analysis-in-mixed-2x2-anova-scheme-same-data-diffe#>
>
> Hello,
>
> I prepared a mixed 2x2 ANOVA design analysis both in SPSS and in R. The
> SPSS script is correct, but in R script there is a mistake somewhere. To
> test that I generated artificial data from a normal distribution to
> simulate the interaction between two independent variables. There were no
> difference between the results in main effects, but results of simple
> effects analysis do not match when comparing between levels of variable
> which introduced repeated measures (GROUP A: PRE vs POST ; GROUP B: PRE vs
> POST).
>
> I would be very thankful if you can help me. The code below will do
> everything for you.
>
> *Here is the code in R which:* - generates the data - calculates mixed
> ANOVA - prepares data to csv format to import to SPSS - performs simple
> effect analysis (there is probably a mistake)
>
> N <- 100
> absMean <- 1
> sdCustom <- 5
>
> grA_pre <- data.frame(ID = seq(N), lvl=rnorm(N, mean=absMean,
> sd=sdCustom), group=factor('A'), stage = factor('pre'))
> grA_post <- data.frame(ID = seq(N), lvl=rnorm(N, mean=-absMean,
> sd=sdCustom), group=factor('A'), stage = factor('post'))
> grB_pre <- data.frame(ID = seq(N+1,2*N), lvl=rnorm(N, mean=-absMean,
> sd=sdCustom), group=factor('B'), stage = factor('pre'))
> grB_post <- data.frame(ID = seq(N+1,2*N), lvl=rnorm(N, mean=absMean,
> sd=sdCustom), group=factor('B'), stage = factor('post'))
>
> gr <- rbind(grA_pre, grA_post, grB_pre, grB_post)
> names(gr)
> head(gr)
> # save set to .csv to import to SPSS
> grSPSS <- reshape(data = gr, timevar = "stage", idvar = c("ID",
> "group"), direction = "wide")
>
> write.csv2(grSPSS, file = "sample2.csv")
>
> library(ggplot2)
> library(plyr)
> library(ez)
> print("Omnibus mixed ANOVA - main effects and interactions")
> ezPlot(data = gr, wid = ID, dv = lvl, between = group, within = stage,
> type = "III", x = group, split = stage, x_lab = "Group", y_lab =
> "Level of experience")
> ezANOVA(data = gr, wid = ID, dv = lvl, between = group, within =
> stage, detailed = TRUE, type = "III")#ezStats(data = gr, wid = ID, dv
> = lvl, between = group, within = stage, type = "III")
>
> print("Simple main effects analysis")
> dataA <- subset(gr, group == "A" )
> dataB <- subset(gr, group == "B" )
> dataPRE <- subset(gr, stage == "pre" )
> dataPOST <- subset(gr, stage == "post" )
> print("GROUP = A: PRE vs POST")
> simpleEffControlANOVA <- ezANOVA(data = dataA, dv = lvl, wid = ID,
> within = stage, detailed = TRUE, type = "III"
> )print(simpleEffControlANOVA)
> print("GROUP = B: PRE vs POST")
> simpleEffControlANOVA <- ezANOVA(data = dataB, dv = lvl, wid = ID,
> within = stage, detailed = TRUE, type = "III"
> )print(simpleEffControlANOVA)
> print("STAGE = PRE: A vs B")
> simpleEffControlANOVA <- ezANOVA(data = dataPRE, dv = lvl, wid = ID,
> between = group, detailed = TRUE, type = "III"
> )print(simpleEffControlANOVA)
> print("STAGE = POST: A vs B")
> simpleEffControlANOVA <- ezANOVA(data = dataPOST, dv = lvl, wid = ID,
> between = group, detailed = TRUE, type = "III"
> )print(simpleEffControlANOVA)
>
> *Here is the code for SPSS Syntax which:* - calculates everything on
> imported data, generated by R
>
> DATASET ACTIVATE DataSet1.
> GLM lvl.pre lvl.post BY group
>   /WSFACTOR=stage 2 Polynomial
>   /METHOD=SSTYPE(3)
>   /POSTHOC=group(TUKEY T3)
>   /EMMEANS=TABLES(group) COMPARE ADJ(BONFERRONI)
>   /EMMEANS=TABLES(stage) COMPARE ADJ(BONFERRONI)
>   /EMMEANS=TABLES(group*stage) COMPARE(group)
>   /EMMEANS=TABLES(group*stage) COMPARE(stage)
>   /PLOT=PROFILE(group*stage)
>   /PRINT=DESCRIPTIVE ETASQ OPOWER HOMOGENEITY
>   /CRITERIA=ALPHA(.05)
>   /WSDESIGN=stage
>   /DESIGN=group.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From oriolebaltimore at gmail.com  Sun May 22 19:58:24 2016
From: oriolebaltimore at gmail.com (Adrian Johnson)
Date: Sun, 22 May 2016 13:58:24 -0400
Subject: [R] if else condition - help
Message-ID: <CAL2fYnP3TOHBF=5vsGtpaEM8M8_dOSR26q2rnHhj6jgihNF=ZA@mail.gmail.com>

Hi group:
I am having difficulty with if else condition. I kindly request some help.

I have a matrix k

> k
           C1         C2         C3         C4
A  0.09902175 -0.1083887  0.2018689 -0.3546167
B  1.60623838 -1.4167034  0.9076373 -0.3161138
C -0.10433133 -1.7060911 -0.4030050  1.0153297
D -2.91485614  2.9201895 -2.4771802 -2.6991517

I want to convert values > 1.5 to 1, < -1.5 to -1 and rest to 0;

> k1 - desired output
           C1         C2         C3         C4
A          0           0            0           0
B           1          0            0           0
C           0        -1             0           0
D           -1        1            -1           -1


I am trying with if else but cannot do it. I could only define one
condition.  Could someone help how I can do this. I dont mean only if
else, but any other way.

k =
structure(c(0.0990217544905328, 1.60623837694539, -0.104331330281166,
-2.91485614212114, -0.108388742328104, -1.41670341534772, -1.70609114096417,
2.92018951284015, 0.201868946570178, 0.907637296638577, -0.403004972105994,
-2.47718015803221, -0.354616729237253, -0.316113789733413, 1.01532974064126,
-2.69915170731852), .Dim = c(4L, 4L), .Dimnames = list(c("A",
"B", "C", "D"), c("C1", "C2", "C3", "C4")))



k1 <- t(apply(k, 1, function(x) ifelse(x > 1.5,1,-1)))

> k1
  C1 C2 C3 C4
A -1 -1 -1 -1
B  1 -1 -1 -1
C -1 -1 -1 -1
D -1  1 -1 -1



Thanks
Adrian


From nicholas.wray at ntlworld.com  Sun May 22 20:12:25 2016
From: nicholas.wray at ntlworld.com (WRAY NICHOLAS)
Date: Sun, 22 May 2016 19:12:25 +0100 (BST)
Subject: [R] if else condition - help
In-Reply-To: <CAL2fYnP3TOHBF=5vsGtpaEM8M8_dOSR26q2rnHhj6jgihNF=ZA@mail.gmail.com>
References: <CAL2fYnP3TOHBF=5vsGtpaEM8M8_dOSR26q2rnHhj6jgihNF=ZA@mail.gmail.com>
Message-ID: <1783757620.1506190.1463940745075.JavaMail.open-xchange@oxbe21.tb.ukmail.iss.as9143.net>

Hi Adrian I'm not sure that you need to use the ifelse here.  You can simply
assign values ina vector or matrix using a simple condition -- here is a simple
example:

v<-c(4,5,6,7)
v1<-v
v1[]<-0
v1[v<5]<--1
v1[v>6]<-1
v1

Nick

> 
>     On 22 May 2016 at 18:58 Adrian Johnson <oriolebaltimore at gmail.com> wrote:
> 
> 
>     Hi group:
>     I am having difficulty with if else condition. I kindly request some help.
> 
>     I have a matrix k
> 
>     > k
>     C1 C2 C3 C4
>     A 0.09902175 -0.1083887 0.2018689 -0.3546167
>     B 1.60623838 -1.4167034 0.9076373 -0.3161138
>     C -0.10433133 -1.7060911 -0.4030050 1.0153297
>     D -2.91485614 2.9201895 -2.4771802 -2.6991517
> 
>     I want to convert values > 1.5 to 1, < -1.5 to -1 and rest to 0;
> 
>     > k1 - desired output
>     C1 C2 C3 C4
>     A 0 0 0 0
>     B 1 0 0 0
>     C 0 -1 0 0
>     D -1 1 -1 -1
> 
> 
>     I am trying with if else but cannot do it. I could only define one
>     condition. Could someone help how I can do this. I dont mean only if
>     else, but any other way.
> 
>     k =
>     structure(c(0.0990217544905328, 1.60623837694539, -0.104331330281166,
>     -2.91485614212114, -0.108388742328104, -1.41670341534772,
> -1.70609114096417,
>     2.92018951284015, 0.201868946570178, 0.907637296638577,
> -0.403004972105994,
>     -2.47718015803221, -0.354616729237253, -0.316113789733413,
> 1.01532974064126,
>     -2.69915170731852), .Dim = c(4L, 4L), .Dimnames = list(c("A",
>     "B", "C", "D"), c("C1", "C2", "C3", "C4")))
> 
> 
> 
>     k1 <- t(apply(k, 1, function(x) ifelse(x > 1.5,1,-1)))
> 
>     > k1
>     C1 C2 C3 C4
>     A -1 -1 -1 -1
>     B 1 -1 -1 -1
>     C -1 -1 -1 -1
>     D -1 1 -1 -1
> 
> 
> 
>     Thanks
>     Adrian
> 
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
> 
	[[alternative HTML version deleted]]


From varinsacha at yahoo.fr  Sun May 22 20:19:17 2016
From: varinsacha at yahoo.fr (varin sacha)
Date: Sun, 22 May 2016 18:19:17 +0000 (UTC)
Subject: [R] Plots for lmrob function
In-Reply-To: <F6BA11B2-9382-49FD-AA41-AAE68EF6EFBD@comcast.net>
References: <575281469.9654085.1463758102039.JavaMail.yahoo.ref@mail.yahoo.com>
	<575281469.9654085.1463758102039.JavaMail.yahoo@mail.yahoo.com>
	<F6BA11B2-9382-49FD-AA41-AAE68EF6EFBD@comcast.net>
Message-ID: <1351908931.1010944.1463941157854.JavaMail.yahoo@mail.yahoo.com>

Perfect, many thanks
Best
S


      De?: David Winsemius <dwinsemius at comcast.net>
 ??: varin sacha <varinsacha at yahoo.fr> 
Cc?: R-help Mailing List <r-help at r-project.org>
 Envoy? le : Vendredi 20 mai 2016 21h13
 Objet?: Re: [R] Plots for lmrob function
   

> On May 20, 2016, at 8:28 AM, varin sacha via R-help <r-help at r-project.org> wrote:
> 
> Dear R-helpers,
> 
> I have fitted a robust regression using lmrob function from robustbase package. I try to get the different plots for diagnostics of residuals and others. I can't get them, a window opens but nothing appears on it (the window remains white, no graph appears) and I get this error messages.
> 
> 
> Here is a small reproducible example
> 
> 
> a=c(1231,1415,1256,3242,3121,1567)
> b=c(12,34.3,43.5,23.5,12,54.3)
> c=c(23,56,73,21,34,45)
> d=c(43,11,15,65,76,34)
> library("robustbase")
> fit=lmrob(a~b+c+d)
> plot(fit,plot=all)
> 
> Erreur dans plot.new() : attempt to plot on null device
> 
> I have an open device :
> dev.cur()
> 
> null device 
> 1 
> 
> How can I solve my problem and finally get the different required plots ?
> 
> 
A "null device" is not going to be of much help. Generally one would have an available interactive device. On a Mac this would be the quartz device:

> dev.cur()
quartz 
? ? 2 


That said I also get a different error. I am running with the 'error' option set to `recover`, so I see only a single plot of the "Robust Standardized residuals" before an error is reported. I intially wondered is this is caused by using such a small dataset for a model when requesting three predictors and an outcome.

> plot(fit,plot=all)
recomputing robust Mahalanobis distances
saving the robust distances 'MD' as part of ?fit?
Hit <Return> to see next plot: 
Error in plot.it && missing(ylim) : invalid 'x' type in 'x && y'
In addition: Warning messages:
1: In plot.window(...) : "plot" is not a graphical parameter
2: In plot.xy(xy, type, ...) : "plot" is not a graphical parameter
3: In axis(side = side, at = at, labels = labels, ...) :
? "plot" is not a graphical parameter
4: In axis(side = side, at = at, labels = labels, ...) :
? "plot" is not a graphical parameter
5: In box(...) : "plot" is not a graphical parameter
6: In title(...) : "plot" is not a graphical parameter
7: In plot.xy(xy.coords(x, y), type = type, ...) :
? "plot" is not a graphical parameter
8: In title(sub = sub.caption, ...) : "plot" is not a graphical parameter

But reducing the model did not cure the error. Only removing `plot=all` was sufficient to get plotting of all five plots. The help page for plot.lmrob does not describe a "plot" parameter.

-- 

David Winsemius
Alameda, CA, USA


  
	[[alternative HTML version deleted]]


From oriolebaltimore at gmail.com  Sun May 22 20:23:56 2016
From: oriolebaltimore at gmail.com (Adrian Johnson)
Date: Sun, 22 May 2016 14:23:56 -0400
Subject: [R] if else condition - help
In-Reply-To: <CAOToiXb0jjV_zMpGzZNckdVFxha8spSu9L+mezxN7vQdL69hsA@mail.gmail.com>
References: <CAL2fYnP3TOHBF=5vsGtpaEM8M8_dOSR26q2rnHhj6jgihNF=ZA@mail.gmail.com>
	<CAOToiXb0jjV_zMpGzZNckdVFxha8spSu9L+mezxN7vQdL69hsA@mail.gmail.com>
Message-ID: <CAL2fYnNtc=ZT=3rQRwJAbTBSuRB=xRBrf31_qLK5gQVmq33M5g@mail.gmail.com>

Thank you both Dylan and Wray.

since my matrix is quite large and for simplicity in downstream
operation, i will use sign function. thanks a lot.

On Sun, May 22, 2016 at 2:12 PM, Dylan Keenan <dylan.keenan at gmail.com> wrote:
> Try this:
>
>> sign(ifelse(abs(k)<=1.5, 0, k))
>
>
>   C1 C2 C3 C4
> A  0  0  0  0
> B  1  0  0  0
> C  0 -1  0  0
> D -1  1 -1 -1
>
> On Sun, May 22, 2016 at 2:00 PM Adrian Johnson <oriolebaltimore at gmail.com>
> wrote:
>>
>> Hi group:
>> I am having difficulty with if else condition. I kindly request some help.
>>
>> I have a matrix k
>>
>> > k
>>            C1         C2         C3         C4
>> A  0.09902175 -0.1083887  0.2018689 -0.3546167
>> B  1.60623838 -1.4167034  0.9076373 -0.3161138
>> C -0.10433133 -1.7060911 -0.4030050  1.0153297
>> D -2.91485614  2.9201895 -2.4771802 -2.6991517
>>
>> I want to convert values > 1.5 to 1, < -1.5 to -1 and rest to 0;
>>
>> > k1 - desired output
>>            C1         C2         C3         C4
>> A          0           0            0           0
>> B           1          0            0           0
>> C           0        -1             0           0
>> D           -1        1            -1           -1
>>
>>
>> I am trying with if else but cannot do it. I could only define one
>> condition.  Could someone help how I can do this. I dont mean only if
>> else, but any other way.
>>
>> k =
>> structure(c(0.0990217544905328, 1.60623837694539, -0.104331330281166,
>> -2.91485614212114, -0.108388742328104, -1.41670341534772,
>> -1.70609114096417,
>> 2.92018951284015, 0.201868946570178, 0.907637296638577,
>> -0.403004972105994,
>> -2.47718015803221, -0.354616729237253, -0.316113789733413,
>> 1.01532974064126,
>> -2.69915170731852), .Dim = c(4L, 4L), .Dimnames = list(c("A",
>> "B", "C", "D"), c("C1", "C2", "C3", "C4")))
>>
>>
>>
>> k1 <- t(apply(k, 1, function(x) ifelse(x > 1.5,1,-1)))
>>
>> > k1
>>   C1 C2 C3 C4
>> A -1 -1 -1 -1
>> B  1 -1 -1 -1
>> C -1 -1 -1 -1
>> D -1  1 -1 -1
>>
>>
>>
>> Thanks
>> Adrian
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun May 22 20:37:09 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 22 May 2016 11:37:09 -0700
Subject: [R] if else condition - help
In-Reply-To: <CAL2fYnNtc=ZT=3rQRwJAbTBSuRB=xRBrf31_qLK5gQVmq33M5g@mail.gmail.com>
References: <CAL2fYnP3TOHBF=5vsGtpaEM8M8_dOSR26q2rnHhj6jgihNF=ZA@mail.gmail.com>
	<CAOToiXb0jjV_zMpGzZNckdVFxha8spSu9L+mezxN7vQdL69hsA@mail.gmail.com>
	<CAL2fYnNtc=ZT=3rQRwJAbTBSuRB=xRBrf31_qLK5gQVmq33M5g@mail.gmail.com>
Message-ID: <4CD3C222-DE85-4006-A8C2-FB26693B1BA4@comcast.net>


> On May 22, 2016, at 11:23 AM, Adrian Johnson <oriolebaltimore at gmail.com> wrote:
> 
> Thank you both Dylan and Wray.
> 
> since my matrix is quite large and for simplicity in downstream
> operation, i will use sign function. thanks a lot.
> 
> On Sun, May 22, 2016 at 2:12 PM, Dylan Keenan <dylan.keenan at gmail.com> wrote:
>> Try this:
>> 
>>> sign(ifelse(abs(k)<=1.5, 0, k))
>> 
>> 
>>  C1 C2 C3 C4
>> A  0  0  0  0
>> B  1  0  0  0
>> C  0 -1  0  0
>> D -1  1 -1 -1
>> 

If the problems were somewhat less symmetric or  more complex this would be a method that could be easily generalized to a larger number of less "absolutely" symmetric intervals:

 k2 <- k
 k2[] <- findInterval(k2, c(-Inf, -1.5, 1.5, Inf) ) -2  
                                             # shifts the 1-3 values to -1 to 1
 k2
  C1 C2 C3 C4
A  0  0  0  0
B  1  0  0  0
C  0 -1  0  0
D -1  1 -1 -1

Using k2[] <- ... preserves the matrix structure



>> On Sun, May 22, 2016 at 2:00 PM Adrian Johnson <oriolebaltimore at gmail.com>
>> wrote:
>>> 
>>> Hi group:
>>> I am having difficulty with if else condition. I kindly request some help.
>>> 
>>> I have a matrix k
>>> 
>>>> k
>>>           C1         C2         C3         C4
>>> A  0.09902175 -0.1083887  0.2018689 -0.3546167
>>> B  1.60623838 -1.4167034  0.9076373 -0.3161138
>>> C -0.10433133 -1.7060911 -0.4030050  1.0153297
>>> D -2.91485614  2.9201895 -2.4771802 -2.6991517
>>> 
>>> I want to convert values > 1.5 to 1, < -1.5 to -1 and rest to 0;
>>> 
>>>> k1 - desired output
>>>           C1         C2         C3         C4
>>> A          0           0            0           0
>>> B           1          0            0           0
>>> C           0        -1             0           0
>>> D           -1        1            -1           -1
>>> 
>>> 
>>> I am trying with if else but cannot do it. I could only define one
>>> condition.  Could someone help how I can do this. I dont mean only if
>>> else, but any other way.
>>> 
>>> k =
>>> structure(c(0.0990217544905328, 1.60623837694539, -0.104331330281166,
>>> -2.91485614212114, -0.108388742328104, -1.41670341534772,
>>> -1.70609114096417,
>>> 2.92018951284015, 0.201868946570178, 0.907637296638577,
>>> -0.403004972105994,
>>> -2.47718015803221, -0.354616729237253, -0.316113789733413,
>>> 1.01532974064126,
>>> -2.69915170731852), .Dim = c(4L, 4L), .Dimnames = list(c("A",
>>> "B", "C", "D"), c("C1", "C2", "C3", "C4")))
>>> 
>>> 
>>> 
>>> k1 <- t(apply(k, 1, function(x) ifelse(x > 1.5,1,-1)))
>>> 
>>>> k1
>>>  C1 C2 C3 C4
>>> A -1 -1 -1 -1
>>> B  1 -1 -1 -1
>>> C -1 -1 -1 -1
>>> D -1  1 -1 -1
>>> 
>>> 
>>> 
>>> Thanks
>>> Adrian
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bhaskar.kolkata at gmail.com  Sun May 22 18:40:52 2016
From: bhaskar.kolkata at gmail.com (Bhaskar Mitra)
Date: Sun, 22 May 2016 12:40:52 -0400
Subject: [R] Merging 2 files with different timestamp
Message-ID: <CAEGXkYXxDQJR81Q+q6AQTuT69E6gAwd-v9UHS7qAwByLQXdNfg@mail.gmail.com>

Hello, I am trying to merge two text files by using the timestamp
header for both the files:

The first file has the following format for the timestamp:"2012-01-01
23:30:00 UTC"

Timestamp for the second file : 2012-01-01 2330.

I am having problems by converting from one timestamp format to another.
Any suggestions/help in this regard?

regards,

	[[alternative HTML version deleted]]


From bhaskar.kolkata at gmail.com  Sun May 22 18:48:08 2016
From: bhaskar.kolkata at gmail.com (Bhaskar Mitra)
Date: Sun, 22 May 2016 12:48:08 -0400
Subject: [R] Merging 2 files with different timestamp
In-Reply-To: <CAEGXkYXxDQJR81Q+q6AQTuT69E6gAwd-v9UHS7qAwByLQXdNfg@mail.gmail.com>
References: <CAEGXkYXxDQJR81Q+q6AQTuT69E6gAwd-v9UHS7qAwByLQXdNfg@mail.gmail.com>
Message-ID: <CAEGXkYVgn2WRoApwRKhDROckJwKBzT3nuu1wdLmpR6smF4E_ww@mail.gmail.com>

Hello,

My apologies for the earlier posting. There was an error with regard to my
query :


I am trying to merge two text files by using the timestamp
header for both the files:

The first file has the following format for the timestamp:"27-Dec-12 23H
30M 0S"

Timestamp for the second file : 2012-12-27 2330.

I am having problems by converting from one timestamp format to another.
Any suggestions/help in this regard?

regards,




On Sun, May 22, 2016 at 12:40 PM, Bhaskar Mitra <bhaskar.kolkata at gmail.com>
wrote:

> Hello, I am trying to merge two text files by using the timestamp
> header for both the files:
>
> The first file has the following format for the timestamp:"2012-01-01
> 23:30:00 UTC"
>
> Timestamp for the second file : 2012-01-01 2330.
>
> I am having problems by converting from one timestamp format to another.
> Any suggestions/help in this regard?
>
> regards,
>
>
>

	[[alternative HTML version deleted]]


From dylan.keenan at gmail.com  Sun May 22 20:12:31 2016
From: dylan.keenan at gmail.com (Dylan Keenan)
Date: Sun, 22 May 2016 18:12:31 +0000
Subject: [R] if else condition - help
In-Reply-To: <CAL2fYnP3TOHBF=5vsGtpaEM8M8_dOSR26q2rnHhj6jgihNF=ZA@mail.gmail.com>
References: <CAL2fYnP3TOHBF=5vsGtpaEM8M8_dOSR26q2rnHhj6jgihNF=ZA@mail.gmail.com>
Message-ID: <CAOToiXb0jjV_zMpGzZNckdVFxha8spSu9L+mezxN7vQdL69hsA@mail.gmail.com>

Try this:

> sign(ifelse(abs(k)<=1.5, 0, k))


  C1 C2 C3 C4
A  0  0  0  0
B  1  0  0  0
C  0 -1  0  0
D -1  1 -1 -1

On Sun, May 22, 2016 at 2:00 PM Adrian Johnson <oriolebaltimore at gmail.com>
wrote:

> Hi group:
> I am having difficulty with if else condition. I kindly request some help.
>
> I have a matrix k
>
> > k
>            C1         C2         C3         C4
> A  0.09902175 -0.1083887  0.2018689 -0.3546167
> B  1.60623838 -1.4167034  0.9076373 -0.3161138
> C -0.10433133 -1.7060911 -0.4030050  1.0153297
> D -2.91485614  2.9201895 -2.4771802 -2.6991517
>
> I want to convert values > 1.5 to 1, < -1.5 to -1 and rest to 0;
>
> > k1 - desired output
>            C1         C2         C3         C4
> A          0           0            0           0
> B           1          0            0           0
> C           0        -1             0           0
> D           -1        1            -1           -1
>
>
> I am trying with if else but cannot do it. I could only define one
> condition.  Could someone help how I can do this. I dont mean only if
> else, but any other way.
>
> k =
> structure(c(0.0990217544905328, 1.60623837694539, -0.104331330281166,
> -2.91485614212114, -0.108388742328104, -1.41670341534772,
> -1.70609114096417,
> 2.92018951284015, 0.201868946570178, 0.907637296638577, -0.403004972105994,
> -2.47718015803221, -0.354616729237253, -0.316113789733413,
> 1.01532974064126,
> -2.69915170731852), .Dim = c(4L, 4L), .Dimnames = list(c("A",
> "B", "C", "D"), c("C1", "C2", "C3", "C4")))
>
>
>
> k1 <- t(apply(k, 1, function(x) ifelse(x > 1.5,1,-1)))
>
> > k1
>   C1 C2 C3 C4
> A -1 -1 -1 -1
> B  1 -1 -1 -1
> C -1 -1 -1 -1
> D -1  1 -1 -1
>
>
>
> Thanks
> Adrian
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun May 22 22:10:48 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 22 May 2016 13:10:48 -0700
Subject: [R] Merging 2 files with different timestamp
In-Reply-To: <CAEGXkYVgn2WRoApwRKhDROckJwKBzT3nuu1wdLmpR6smF4E_ww@mail.gmail.com>
References: <CAEGXkYXxDQJR81Q+q6AQTuT69E6gAwd-v9UHS7qAwByLQXdNfg@mail.gmail.com>
	<CAEGXkYVgn2WRoApwRKhDROckJwKBzT3nuu1wdLmpR6smF4E_ww@mail.gmail.com>
Message-ID: <BEDF8F69-13E9-4D29-A4EB-BD5B99F78A6C@dcn.davis.ca.us>

What time zone are these data in? Does daylight savings adjustment apply? 
-- 
Sent from my phone. Please excuse my brevity.

On May 22, 2016 9:48:08 AM PDT, Bhaskar Mitra <bhaskar.kolkata at gmail.com> wrote:
>Hello,
>
>My apologies for the earlier posting. There was an error with regard to
>my
>query :
>
>
>I am trying to merge two text files by using the timestamp
>header for both the files:
>
>The first file has the following format for the timestamp:"27-Dec-12
>23H
>30M 0S"
>
>Timestamp for the second file : 2012-12-27 2330.
>
>I am having problems by converting from one timestamp format to
>another.
>Any suggestions/help in this regard?
>
>regards,
>
>
>
>
>On Sun, May 22, 2016 at 12:40 PM, Bhaskar Mitra
><bhaskar.kolkata at gmail.com>
>wrote:
>
>> Hello, I am trying to merge two text files by using the timestamp
>> header for both the files:
>>
>> The first file has the following format for the timestamp:"2012-01-01
>> 23:30:00 UTC"
>>
>> Timestamp for the second file : 2012-01-01 2330.
>>
>> I am having problems by converting from one timestamp format to
>another.
>> Any suggestions/help in this regard?
>>
>> regards,
>>
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Sun May 22 22:41:17 2016
From: jholtman at gmail.com (jim holtman)
Date: Sun, 22 May 2016 16:41:17 -0400
Subject: [R] Merging 2 files with different timestamp
In-Reply-To: <CAEGXkYVgn2WRoApwRKhDROckJwKBzT3nuu1wdLmpR6smF4E_ww@mail.gmail.com>
References: <CAEGXkYXxDQJR81Q+q6AQTuT69E6gAwd-v9UHS7qAwByLQXdNfg@mail.gmail.com>
	<CAEGXkYVgn2WRoApwRKhDROckJwKBzT3nuu1wdLmpR6smF4E_ww@mail.gmail.com>
Message-ID: <CAAxdm-6vnR+OZ-32Sy-Liirw7H4hwWrPO=b_R7wyR_ZK7wUTCg@mail.gmail.com>

Is this the format of a column within the two different files?  If they are
columns, here is a way of converting to a common format for merging:


> # convert to POSIXct
> date1 <- as.POSIXct("27-Dec-12 23H 30M 0S", format = "%d-%b-%y %HH %MM
%SS")
> date2 <- as.POSIXct('2012-12-27 2330', format = "%Y-%m-%d %H%M")
>
> # now convert to a common character format for merging
> date1_new <- format(date1, "%Y%m%d%H%M%S")
> date2_new <- format(date2, "%Y%m%d%H%M%S")
> date1_new
[1] "20121227233000"
> date2_new
[1] "20121227233000"



Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sun, May 22, 2016 at 12:48 PM, Bhaskar Mitra <bhaskar.kolkata at gmail.com>
wrote:

> Hello,
>
> My apologies for the earlier posting. There was an error with regard to my
> query :
>
>
> I am trying to merge two text files by using the timestamp
> header for both the files:
>
> The first file has the following format for the timestamp:"27-Dec-12 23H
> 30M 0S"
>
> Timestamp for the second file : 2012-12-27 2330.
>
> I am having problems by converting from one timestamp format to another.
> Any suggestions/help in this regard?
>
> regards,
>
>
>
>
> On Sun, May 22, 2016 at 12:40 PM, Bhaskar Mitra <bhaskar.kolkata at gmail.com
> >
> wrote:
>
> > Hello, I am trying to merge two text files by using the timestamp
> > header for both the files:
> >
> > The first file has the following format for the timestamp:"2012-01-01
> > 23:30:00 UTC"
> >
> > Timestamp for the second file : 2012-01-01 2330.
> >
> > I am having problems by converting from one timestamp format to another.
> > Any suggestions/help in this regard?
> >
> > regards,
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun May 22 22:44:56 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 22 May 2016 13:44:56 -0700
Subject: [R] Merging 2 files with different timestamp
In-Reply-To: <CAEGXkYXxDQJR81Q+q6AQTuT69E6gAwd-v9UHS7qAwByLQXdNfg@mail.gmail.com>
References: <CAEGXkYXxDQJR81Q+q6AQTuT69E6gAwd-v9UHS7qAwByLQXdNfg@mail.gmail.com>
Message-ID: <D3E47735-01CF-4310-9292-8E462090F359@comcast.net>


> On May 22, 2016, at 9:40 AM, Bhaskar Mitra <bhaskar.kolkata at gmail.com> wrote:
> 
> Hello, I am trying to merge two text files by using the timestamp
> header for both the files:
> 
> The first file has the following format for the timestamp:"2012-01-01
> 23:30:00 UTC"
> 
> Timestamp for the second file : 2012-01-01 2330.

> as.POSIXct("2012-01-01 23:30:00 UTC",format="%Y-%m-%d %H:%M:%S", tz="UTC")
[1] "2012-01-01 23:30:00 UTC"
> as.POSIXct( "2012-01-01 2330", format="%Y-%m-%d %H%M", tz="UTC")
[1] "2012-01-01 23:30:00 UTC"

> 

> I am having problems by converting from one timestamp format to another.
> Any suggestions/help in this regard?
> 
> regards,
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jholtman at gmail.com  Sun May 22 22:47:06 2016
From: jholtman at gmail.com (jim holtman)
Date: Sun, 22 May 2016 16:47:06 -0400
Subject: [R] if else condition - help
In-Reply-To: <CAL2fYnP3TOHBF=5vsGtpaEM8M8_dOSR26q2rnHhj6jgihNF=ZA@mail.gmail.com>
References: <CAL2fYnP3TOHBF=5vsGtpaEM8M8_dOSR26q2rnHhj6jgihNF=ZA@mail.gmail.com>
Message-ID: <CAAxdm-7VoMoVM+kyw509Zc=1LtH1BTSPNRUCz9ZapEqVx-P9Hw@mail.gmail.com>

if you want to use 'ifelse', here is a way:


> k =
+ structure(c(0.0990217544905328, 1.60623837694539, -0.104331330281166,
+ -2.91485614212114, -0.108388742328104, -1.41670341534772,
-1.70609114096417,
+ 2.92018951284015, 0.201868946570178, 0.907637296638577,
-0.403004972105994,
+ -2.47718015803221, -0.354616729237253, -0.316113789733413,
1.01532974064126,
+ -2.69915170731852), .Dim = c(4L, 4L), .Dimnames = list(c("A",
+ "B", "C", "D"), c("C1", "C2", "C3", "C4")))
>
> # if you want to use 'ifelse', here is a way
>
> x <- ifelse(k > 1.5
+             , 1
+             , ifelse(k < -1.5
+                 , -1
+                 , 0
+                 )
+             )
>
> str(x)
 num [1:4, 1:4] 0 1 0 -1 0 0 -1 1 0 0 ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:4] "A" "B" "C" "D"
  ..$ : chr [1:4] "C1" "C2" "C3" "C4"
> x
  C1 C2 C3 C4
A  0  0  0  0
B  1  0  0  0
C  0 -1  0  0
D -1  1 -1 -1
>




Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sun, May 22, 2016 at 1:58 PM, Adrian Johnson <oriolebaltimore at gmail.com>
wrote:

> Hi group:
> I am having difficulty with if else condition. I kindly request some help.
>
> I have a matrix k
>
> > k
>            C1         C2         C3         C4
> A  0.09902175 -0.1083887  0.2018689 -0.3546167
> B  1.60623838 -1.4167034  0.9076373 -0.3161138
> C -0.10433133 -1.7060911 -0.4030050  1.0153297
> D -2.91485614  2.9201895 -2.4771802 -2.6991517
>
> I want to convert values > 1.5 to 1, < -1.5 to -1 and rest to 0;
>
> > k1 - desired output
>            C1         C2         C3         C4
> A          0           0            0           0
> B           1          0            0           0
> C           0        -1             0           0
> D           -1        1            -1           -1
>
>
> I am trying with if else but cannot do it. I could only define one
> condition.  Could someone help how I can do this. I dont mean only if
> else, but any other way.
>
> k =
> structure(c(0.0990217544905328, 1.60623837694539, -0.104331330281166,
> -2.91485614212114, -0.108388742328104, -1.41670341534772,
> -1.70609114096417,
> 2.92018951284015, 0.201868946570178, 0.907637296638577, -0.403004972105994,
> -2.47718015803221, -0.354616729237253, -0.316113789733413,
> 1.01532974064126,
> -2.69915170731852), .Dim = c(4L, 4L), .Dimnames = list(c("A",
> "B", "C", "D"), c("C1", "C2", "C3", "C4")))
>
>
>
> k1 <- t(apply(k, 1, function(x) ifelse(x > 1.5,1,-1)))
>
> > k1
>   C1 C2 C3 C4
> A -1 -1 -1 -1
> B  1 -1 -1 -1
> C -1 -1 -1 -1
> D -1  1 -1 -1
>
>
>
> Thanks
> Adrian
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From syen04 at gmail.com  Mon May 23 00:22:59 2016
From: syen04 at gmail.com (Steven Yen)
Date: Sun, 22 May 2016 18:22:59 -0400
Subject: [R] Element-by-element multiplication
Message-ID: <03aa9062-b24a-e6bd-5efb-9c5220de9123@gmail.com>

Dear R users:

 > # p is a vector if length 10
 > # a is a vector if length 3
 > # I like to create a matrix with
 > # the first  column being p multiplied by a[1]
 > # the second column being p multiplied by a[2]
 > # the third  column being p multiplied by a[3]
 > # The following would do that:
 >
 > a<-c(10,100,1000); a
[1]   10  100 1000
 > p<-matrix(1:10,nrow=10); p
       [,1]
  [1,]    1
  [2,]    2
  [3,]    3
  [4,]    4
  [5,]    5
  [6,]    6
  [7,]    7
  [8,]    8
  [9,]    9
[10,]   10
 > cbind(a[1]*p,a[2]*p,a[3]*p)
       [,1] [,2]  [,3]
  [1,]   10  100  1000
  [2,]   20  200  2000
  [3,]   30  300  3000
  [4,]   40  400  4000
  [5,]   50  500  5000
  [6,]   60  600  6000
  [7,]   70  700  7000
  [8,]   80  800  8000
  [9,]   90  900  9000
[10,]  100 1000 10000
 >
 > # Gauss does it easily with an element-by-element
 > # multiplicationa.*p
 > # How can I do this in R?
 >


	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon May 23 00:34:31 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 23 May 2016 08:34:31 +1000
Subject: [R] Element-by-element multiplication
In-Reply-To: <03aa9062-b24a-e6bd-5efb-9c5220de9123@gmail.com>
References: <03aa9062-b24a-e6bd-5efb-9c5220de9123@gmail.com>
Message-ID: <CA+8X3fVD6jBqxrZwTsKFNrc3G5r2HS22w37syakRQE=OzsP0iQ@mail.gmail.com>

Hi Steven,

as.data.frame(sapply(a,"*",p))

Jim


On Mon, May 23, 2016 at 8:22 AM, Steven Yen <syen04 at gmail.com> wrote:
> Dear R users:
>
>  > # p is a vector if length 10
>  > # a is a vector if length 3
>  > # I like to create a matrix with
>  > # the first  column being p multiplied by a[1]
>  > # the second column being p multiplied by a[2]
>  > # the third  column being p multiplied by a[3]
>  > # The following would do that:
>  >
>  > a<-c(10,100,1000); a
> [1]   10  100 1000
>  > p<-matrix(1:10,nrow=10); p
>        [,1]
>   [1,]    1
>   [2,]    2
>   [3,]    3
>   [4,]    4
>   [5,]    5
>   [6,]    6
>   [7,]    7
>   [8,]    8
>   [9,]    9
> [10,]   10
>  > cbind(a[1]*p,a[2]*p,a[3]*p)
>        [,1] [,2]  [,3]
>   [1,]   10  100  1000
>   [2,]   20  200  2000
>   [3,]   30  300  3000
>   [4,]   40  400  4000
>   [5,]   50  500  5000
>   [6,]   60  600  6000
>   [7,]   70  700  7000
>   [8,]   80  800  8000
>   [9,]   90  900  9000
> [10,]  100 1000 10000
>  >
>  > # Gauss does it easily with an element-by-element
>  > # multiplicationa.*p
>  > # How can I do this in R?
>  >
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Mon May 23 01:03:08 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 22 May 2016 16:03:08 -0700
Subject: [R] Element-by-element multiplication
In-Reply-To: <CA+8X3fVD6jBqxrZwTsKFNrc3G5r2HS22w37syakRQE=OzsP0iQ@mail.gmail.com>
References: <03aa9062-b24a-e6bd-5efb-9c5220de9123@gmail.com>
	<CA+8X3fVD6jBqxrZwTsKFNrc3G5r2HS22w37syakRQE=OzsP0iQ@mail.gmail.com>
Message-ID: <E5271236-3067-4AE2-A157-F2BCD333CEA9@dcn.davis.ca.us>

outer( p, a )
-- 
Sent from my phone. Please excuse my brevity.

On May 22, 2016 3:34:31 PM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
>Hi Steven,
>
>as.data.frame(sapply(a,"*",p))
>
>Jim
>
>
>On Mon, May 23, 2016 at 8:22 AM, Steven Yen <syen04 at gmail.com> wrote:
>> Dear R users:
>>
>>  > # p is a vector if length 10
>>  > # a is a vector if length 3
>>  > # I like to create a matrix with
>>  > # the first  column being p multiplied by a[1]
>>  > # the second column being p multiplied by a[2]
>>  > # the third  column being p multiplied by a[3]
>>  > # The following would do that:
>>  >
>>  > a<-c(10,100,1000); a
>> [1]   10  100 1000
>>  > p<-matrix(1:10,nrow=10); p
>>        [,1]
>>   [1,]    1
>>   [2,]    2
>>   [3,]    3
>>   [4,]    4
>>   [5,]    5
>>   [6,]    6
>>   [7,]    7
>>   [8,]    8
>>   [9,]    9
>> [10,]   10
>>  > cbind(a[1]*p,a[2]*p,a[3]*p)
>>        [,1] [,2]  [,3]
>>   [1,]   10  100  1000
>>   [2,]   20  200  2000
>>   [3,]   30  300  3000
>>   [4,]   40  400  4000
>>   [5,]   50  500  5000
>>   [6,]   60  600  6000
>>   [7,]   70  700  7000
>>   [8,]   80  800  8000
>>   [9,]   90  900  9000
>> [10,]  100 1000 10000
>>  >
>>  > # Gauss does it easily with an element-by-element
>>  > # multiplicationa.*p
>>  > # How can I do this in R?
>>  >
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From fotisfotiadis at gmail.com  Mon May 23 00:29:33 2016
From: fotisfotiadis at gmail.com (Fotis Fotiadis)
Date: Mon, 23 May 2016 01:29:33 +0300
Subject: [R] mgcv::gam(): NA parametric coefficient in a model with two
 categorical variables + model interpretation
Message-ID: <CAAO1NneNOjwWCyva-yP6Bz5D5hSBrmaqBXitwW9Md2c-nt1JRg@mail.gmail.com>

Hallo all

I am using a gam model for my data.

m2.4<-bam(acc~ 1 + igc + s(ctrial, by=igc) + shape + s(ctrial, by=shape) +
s(ctrial, sbj, bs = "fs", m = 1) , data=data, family=binomial)

igc codes condition and there are four levels (CAT.pseudo,
CAT.ideo,PA.pseudo, PA.ideo), and shape is a factor (that cannot be
considered random effect) with four levels too (rand21, rand22, rand23,
rand30).

Here is the summary of the model
> summary(m2.4)

Family: binomial
Link function: logit

Formula:
acc ~ 1 + igc + s(ctrial, by = igc) + shape + s(ctrial, by = shape) +
    s(ctrial, sbj, bs = "fs", m = 1)

Parametric coefficients:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)    3.5321     0.1930  18.302  < 2e-16 ***
igcCAT.ideo    0.0000     0.0000      NA       NA
igcPA.ideo    -0.3650     0.2441  -1.495   0.1348
igcPA.pseudo  -0.2708     0.2574  -1.052   0.2928
shaperand22   -0.1390     0.1548  -0.898   0.3693
shaperand23    0.3046     0.1670   1.823   0.0682 .
shaperand30   -0.5839     0.1163  -5.020 5.16e-07 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Approximate significance of smooth terms:
                            edf  Ref.df   Chi.sq  p-value
s(ctrial):igcCAT.pseudo   3.902   4.853   74.787 1.07e-14 ***
s(ctrial):igcCAT.ideo     2.293   2.702   13.794 0.001750 **
s(ctrial):igcPA.ideo      1.000   1.000   11.391 0.000738 ***
s(ctrial):igcPA.pseudo    3.158   3.815   20.411 0.000413 ***
s(ctrial):shaperand21     2.556   3.316   31.387 1.46e-06 ***
s(ctrial):shaperand22     1.000   1.000    0.898 0.343381
s(ctrial):shaperand23     2.304   2.850    6.144 0.118531
s(ctrial):shaperand30     4.952   5.947   27.806 0.000144 ***
s(ctrial,sbj)           221.476 574.000 1502.779  < 2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Rank: 652/655
R-sq.(adj) =  0.405   Deviance explained = 43.9%
fREML =  24003  Scale est. = 1         n = 18417


I am not sure how this model works, but I guess it creates four smooths for
each level of condition, and four smooths for each level of shape.

There is also the intercept of the model, set at the reference level of
condition (CAT.pseudo) and at the reference level of shape (rand21). Each
parametric term represents the difference of each level of each of the two
factors from the intercept.

I have two questions

Q1:
Does anyone now why I get NA results in the second line of the parametric
terms?

Q2:
The term igcCAT.ideo denotes the difference in the intercept between
(A): condition=igcCAT.ideo,  and
(B): (condition=igcCATpseudo ) &(shape=rand21).
But what is the value (level) of shape for (A)?
Is it the reference level? Or is it, perhaps, the "grand mean" of the shape
variable?


Thank you in advance for your time,
Fotis


-- 
PhD Candidate
Department of Philosophy and History of Science
University of Athens, Greece.
http://users.uoa.gr/~aprotopapas/LLL/en/members.html#fotisfotiadis

Notice: Please do not use this account for social networks invitations, for
sending chain-mails to me, or as it were a facebook account. Thank you for
respecting my privacy.

	[[alternative HTML version deleted]]


From mohdsharaiah at gmail.com  Mon May 23 03:07:08 2016
From: mohdsharaiah at gmail.com (mohammad alsharaiah)
Date: Sun, 22 May 2016 18:07:08 -0700
Subject: [R] need help to work with Boolnet package
Message-ID: <CAFUx43zrm+845wXtkwFHV=WebT2CCm-S6uORtFzoJQ0GUkSmBQ@mail.gmail.com>

Hi,

every one , im using Boolnet package inside R environment to create a
boolean network.

after i create a text file for the Boolean network  and  i loaded it by
using R  by using this command:

 > library(BoolNet)
> loadNetwork("C:/Users/mohammad/Documents/cellcontrol.txt")

then its loaded inside R screen. But when i started to do some of tasks on
this network every time i got this error message, this is an example how i
work on the created network and get the error.

> stateTransition(cellcontrol, rep(1,11))
Error in inherits(network, "BooleanNetwork") :
  object 'cellcontrol' not found
>

please can any one help me to solve this error .

Reagdrs,




*Mohammad *

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon May 23 05:40:56 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 23 May 2016 13:40:56 +1000
Subject: [R] need help to work with Boolnet package
In-Reply-To: <CAFUx43zrm+845wXtkwFHV=WebT2CCm-S6uORtFzoJQ0GUkSmBQ@mail.gmail.com>
References: <CAFUx43zrm+845wXtkwFHV=WebT2CCm-S6uORtFzoJQ0GUkSmBQ@mail.gmail.com>
Message-ID: <CA+8X3fWhqfnCm0emm9N75Tq+f8-6-G-dgt6YhrEBd-Je4pMELg@mail.gmail.com>

Hi Mohammad,
I don't have the BoolNet package installed, but the error means that
the object "cellcontrol" is not there for the function to use. It
should be a network "generated by generateRandomNKNetwork, or
reconstructed by reconstructNetwork" as detailed in the help pages.

Jim


On Mon, May 23, 2016 at 11:07 AM, mohammad alsharaiah
<mohdsharaiah at gmail.com> wrote:
> Hi,
>
> every one , im using Boolnet package inside R environment to create a
> boolean network.
>
> after i create a text file for the Boolean network  and  i loaded it by
> using R  by using this command:
>
>  > library(BoolNet)
>> loadNetwork("C:/Users/mohammad/Documents/cellcontrol.txt")
>
> then its loaded inside R screen. But when i started to do some of tasks on
> this network every time i got this error message, this is an example how i
> work on the created network and get the error.
>
>> stateTransition(cellcontrol, rep(1,11))
> Error in inherits(network, "BooleanNetwork") :
>   object 'cellcontrol' not found
>>
>
> please can any one help me to solve this error .
>
> Reagdrs,
>
>
>
>
> *Mohammad *
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Mon May 23 05:59:12 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 23 May 2016 13:59:12 +1000
Subject: [R] need help to work with Boolnet package
In-Reply-To: <CAFUx43zSphaBhBP5_dqgaMrz_4r_6wX07NgJ0tfesVaiobH6wQ@mail.gmail.com>
References: <CAFUx43zrm+845wXtkwFHV=WebT2CCm-S6uORtFzoJQ0GUkSmBQ@mail.gmail.com>
	<CA+8X3fWhqfnCm0emm9N75Tq+f8-6-G-dgt6YhrEBd-Je4pMELg@mail.gmail.com>
	<CAFUx43zSphaBhBP5_dqgaMrz_4r_6wX07NgJ0tfesVaiobH6wQ@mail.gmail.com>
Message-ID: <CA+8X3fWDUAGbA5dx5s7s9ciYdrvx5j5Srngz-NX69k8OCCwTpg@mail.gmail.com>

Okay, perhaps if you try this:

cellcontrol<-
 loadNetwork("C:/Users/mohammad/Documents/cellcontrol.txt")
stateTransition(cellcontrol, rep(1,11))

Obviously this is a guess, but it might help.

Jim


On Mon, May 23, 2016 at 1:55 PM, mohammad alsharaiah
<mohdsharaiah at gmail.com> wrote:
> Hi jim ,
> first of all iwant to thank you for your reply.
> the object "cellcontrol" its a network that i created it by using  boolnet
> package. when i call the network its loaded inside the R workspace screen.
> but i got this error when i want to work on it.
>
> boolnet allow to us to create the network and write a logical rules  in text
> file, then we can loaded it as a network inside R to study the dynamic
> behavior.
>
> but i can not work on it because this error and converting it to data file.
>
>
>
>
>
>
>
> Mohammad
>
>
> On Sun, May 22, 2016 at 8:40 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Mohammad,
>> I don't have the BoolNet package installed, but the error means that
>> the object "cellcontrol" is not there for the function to use. It
>> should be a network "generated by generateRandomNKNetwork, or
>> reconstructed by reconstructNetwork" as detailed in the help pages.
>>
>> Jim
>>
>>
>> On Mon, May 23, 2016 at 11:07 AM, mohammad alsharaiah
>> <mohdsharaiah at gmail.com> wrote:
>> > Hi,
>> >
>> > every one , im using Boolnet package inside R environment to create a
>> > boolean network.
>> >
>> > after i create a text file for the Boolean network  and  i loaded it by
>> > using R  by using this command:
>> >
>> >  > library(BoolNet)
>> >> loadNetwork("C:/Users/mohammad/Documents/cellcontrol.txt")
>> >
>> > then its loaded inside R screen. But when i started to do some of tasks
>> > on
>> > this network every time i got this error message, this is an example how
>> > i
>> > work on the created network and get the error.
>> >
>> >> stateTransition(cellcontrol, rep(1,11))
>> > Error in inherits(network, "BooleanNetwork") :
>> >   object 'cellcontrol' not found
>> >>
>> >
>> > please can any one help me to solve this error .
>> >
>> > Reagdrs,
>> >
>> >
>> >
>> >
>> > *Mohammad *
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From syen04 at gmail.com  Mon May 23 07:39:17 2016
From: syen04 at gmail.com (Steven Yen)
Date: Mon, 23 May 2016 01:39:17 -0400
Subject: [R] Element-by-element operation (adding)
Message-ID: <71b53a06-7c85-b970-eaf8-b83f0d660ab7@gmail.com>

Hi all, need help below. Thank you.

 > # Matrix v is 5 x 3
 > # Vector b is of length 3
 > # I like to add b[1] to all element in v[,1]
 > # I like to add b[2] to all element in v[,2]
 > # I like to add b[3] to all element in v[,3]
 > # as follows
 > v<-matrix(0,nrow=5,ncol=3); v
      [,1] [,2] [,3]
[1,]    0    0    0
[2,]    0    0    0
[3,]    0    0    0
[4,]    0    0    0
[5,]    0    0    0
 > b<-c(0.1,0.2,0.3)
 > cbind(
+ (b[1]+v[,1]),
+ (b[2]+v[,2]),
+ (b[3]+v[,3]))
      [,1] [,2] [,3]
[1,]  0.1  0.2  0.3
[2,]  0.1  0.2  0.3
[3,]  0.1  0.2  0.3
[4,]  0.1  0.2  0.3
[5,]  0.1  0.2  0.3
 > # I am obviously not using sapply correctly:
 > as.data.frame(sapply(b,"+",v))
     V1  V2  V3
1  0.1 0.2 0.3
2  0.1 0.2 0.3
3  0.1 0.2 0.3
4  0.1 0.2 0.3
5  0.1 0.2 0.3
6  0.1 0.2 0.3
7  0.1 0.2 0.3
8  0.1 0.2 0.3
9  0.1 0.2 0.3
10 0.1 0.2 0.3
11 0.1 0.2 0.3
12 0.1 0.2 0.3
13 0.1 0.2 0.3
14 0.1 0.2 0.3
15 0.1 0.2 0.3


	[[alternative HTML version deleted]]


From peter.langfelder at gmail.com  Mon May 23 07:44:39 2016
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Sun, 22 May 2016 22:44:39 -0700
Subject: [R] Element-by-element operation (adding)
In-Reply-To: <71b53a06-7c85-b970-eaf8-b83f0d660ab7@gmail.com>
References: <71b53a06-7c85-b970-eaf8-b83f0d660ab7@gmail.com>
Message-ID: <CA+hbrhUfhde0PfpNqzYUj-OYyKkbTzykz6THHDkFS09yXaAdng@mail.gmail.com>

Two solutions...

v + matrix(b, nrow(v), ncol(v), byrow = TRUE)

or

t(apply(v, 1, `+`, b))

Peter

On Sun, May 22, 2016 at 10:39 PM, Steven Yen <syen04 at gmail.com> wrote:
> Hi all, need help below. Thank you.
>
>  > # Matrix v is 5 x 3
>  > # Vector b is of length 3
>  > # I like to add b[1] to all element in v[,1]
>  > # I like to add b[2] to all element in v[,2]
>  > # I like to add b[3] to all element in v[,3]
>  > # as follows
>  > v<-matrix(0,nrow=5,ncol=3); v
>       [,1] [,2] [,3]
> [1,]    0    0    0
> [2,]    0    0    0
> [3,]    0    0    0
> [4,]    0    0    0
> [5,]    0    0    0
>  > b<-c(0.1,0.2,0.3)
>  > cbind(
> + (b[1]+v[,1]),
> + (b[2]+v[,2]),
> + (b[3]+v[,3]))
>       [,1] [,2] [,3]
> [1,]  0.1  0.2  0.3
> [2,]  0.1  0.2  0.3
> [3,]  0.1  0.2  0.3
> [4,]  0.1  0.2  0.3
> [5,]  0.1  0.2  0.3
>  > # I am obviously not using sapply correctly:
>  > as.data.frame(sapply(b,"+",v))
>      V1  V2  V3
> 1  0.1 0.2 0.3
> 2  0.1 0.2 0.3
> 3  0.1 0.2 0.3
> 4  0.1 0.2 0.3
> 5  0.1 0.2 0.3
> 6  0.1 0.2 0.3
> 7  0.1 0.2 0.3
> 8  0.1 0.2 0.3
> 9  0.1 0.2 0.3
> 10 0.1 0.2 0.3
> 11 0.1 0.2 0.3
> 12 0.1 0.2 0.3
> 13 0.1 0.2 0.3
> 14 0.1 0.2 0.3
> 15 0.1 0.2 0.3
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nsit315 at aucklanduni.ac.nz  Mon May 23 06:46:30 2016
From: nsit315 at aucklanduni.ac.nz (Neny Sitorus)
Date: Mon, 23 May 2016 16:46:30 +1200
Subject: [R] need help to convert animal ID to a factor
Message-ID: <CALjSv_eh+GZ1CWsuzWW5Fe+MNZWv8+urgSZq5F3xM46TRXhmjg@mail.gmail.com>

Hi,

I was trying to convert my animal ID experiment (ID) to factor to get the
ggboxplot, previously it was working well.
But since yesterday it displayed "Error" every time I tried to re-run it.
Could you help me in this issue?


# convert rat ID to factor
Leak.df <- toFactor(Leak.df, id.var=c("ID", "Time"))

>From Console:
> ets.df <- toFactor(ets.df, id.var=c("ID", "Time"))
Error: could not find function "toFactor"

Looking forward for your reply.


Kind regards,
Neny

On 23 May 2016 at 15:59, Jim Lemon <drjimlemon at gmail.com> wrote:

> Okay, perhaps if you try this:
>
> cellcontrol<-
>  loadNetwork("C:/Users/mohammad/Documents/cellcontrol.txt")
> stateTransition(cellcontrol, rep(1,11))
>
> Obviously this is a guess, but it might help.
>
> Jim
>
>
> On Mon, May 23, 2016 at 1:55 PM, mohammad alsharaiah
> <mohdsharaiah at gmail.com> wrote:
> > Hi jim ,
> > first of all iwant to thank you for your reply.
> > the object "cellcontrol" its a network that i created it by using
> boolnet
> > package. when i call the network its loaded inside the R workspace
> screen.
> > but i got this error when i want to work on it.
> >
> > boolnet allow to us to create the network and write a logical rules  in
> text
> > file, then we can loaded it as a network inside R to study the dynamic
> > behavior.
> >
> > but i can not work on it because this error and converting it to data
> file.
> >
> >
> >
> >
> >
> >
> >
> > Mohammad
> >
> >
> > On Sun, May 22, 2016 at 8:40 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> >>
> >> Hi Mohammad,
> >> I don't have the BoolNet package installed, but the error means that
> >> the object "cellcontrol" is not there for the function to use. It
> >> should be a network "generated by generateRandomNKNetwork, or
> >> reconstructed by reconstructNetwork" as detailed in the help pages.
> >>
> >> Jim
> >>
> >>
> >> On Mon, May 23, 2016 at 11:07 AM, mohammad alsharaiah
> >> <mohdsharaiah at gmail.com> wrote:
> >> > Hi,
> >> >
> >> > every one , im using Boolnet package inside R environment to create a
> >> > boolean network.
> >> >
> >> > after i create a text file for the Boolean network  and  i loaded it
> by
> >> > using R  by using this command:
> >> >
> >> >  > library(BoolNet)
> >> >> loadNetwork("C:/Users/mohammad/Documents/cellcontrol.txt")
> >> >
> >> > then its loaded inside R screen. But when i started to do some of
> tasks
> >> > on
> >> > this network every time i got this error message, this is an example
> how
> >> > i
> >> > work on the created network and get the error.
> >> >
> >> >> stateTransition(cellcontrol, rep(1,11))
> >> > Error in inherits(network, "BooleanNetwork") :
> >> >   object 'cellcontrol' not found
> >> >>
> >> >
> >> > please can any one help me to solve this error .
> >> >
> >> > Reagdrs,
> >> >
> >> >
> >> >
> >> >
> >> > *Mohammad *
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon May 23 08:39:39 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 22 May 2016 23:39:39 -0700
Subject: [R] need help to convert animal ID to a factor
In-Reply-To: <CALjSv_eh+GZ1CWsuzWW5Fe+MNZWv8+urgSZq5F3xM46TRXhmjg@mail.gmail.com>
References: <CALjSv_eh+GZ1CWsuzWW5Fe+MNZWv8+urgSZq5F3xM46TRXhmjg@mail.gmail.com>
Message-ID: <178F08B9-80E4-4C5E-8812-961283E23698@comcast.net>


> On May 22, 2016, at 9:46 PM, Neny Sitorus <nsit315 at aucklanduni.ac.nz> wrote:
> 
> Hi,
> 
> I was trying to convert my animal ID experiment (ID) to factor to get the
> ggboxplot, previously it was working well.
> But since yesterday it displayed "Error" every time I tried to re-run it.
> Could you help me in this issue?
> 
> 
> # convert rat ID to factor
> Leak.df <- toFactor(Leak.df, id.var=c("ID", "Time"))
> 
>> From Console:
>> ets.df <- toFactor(ets.df, id.var=c("ID", "Time"))
> Error: could not find function "toFactor"
> 
> Looking forward for your reply.

I've got quite a few packages loaded and yet I get:

> ?toFactor
No documentation for ?toFactor? in specified packages and libraries:
you could try ???toFactor?

So it's a function from some undetermined package and It's not even locatable with sos::findFn. I suspect you have forgotten to load it (whatever _it_ is.

-- 
David.


> 
> 
> Kind regards,
> Neny
> 
> On 23 May 2016 at 15:59, Jim Lemon <drjimlemon at gmail.com> wrote:
> 
>> Okay, perhaps if you try this:
>> 
>> cellcontrol<-
>> loadNetwork("C:/Users/mohammad/Documents/cellcontrol.txt")
>> stateTransition(cellcontrol, rep(1,11))
>> 
>> Obviously this is a guess, but it might help.
>> 
>> Jim
>> 
>> 
>> On Mon, May 23, 2016 at 1:55 PM, mohammad alsharaiah
>> <mohdsharaiah at gmail.com> wrote:
>>> Hi jim ,
>>> first of all iwant to thank you for your reply.
>>> the object "cellcontrol" its a network that i created it by using
>> boolnet
>>> package. when i call the network its loaded inside the R workspace
>> screen.
>>> but i got this error when i want to work on it.
>>> 
>>> boolnet allow to us to create the network and write a logical rules  in
>> text
>>> file, then we can loaded it as a network inside R to study the dynamic
>>> behavior.
>>> 
>>> but i can not work on it because this error and converting it to data
>> file.
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> Mohammad
>>> 
>>> 
>>> On Sun, May 22, 2016 at 8:40 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>>> 
>>>> Hi Mohammad,
>>>> I don't have the BoolNet package installed, but the error means that
>>>> the object "cellcontrol" is not there for the function to use. It
>>>> should be a network "generated by generateRandomNKNetwork, or
>>>> reconstructed by reconstructNetwork" as detailed in the help pages.
>>>> 
>>>> Jim
>>>> 
>>>> 
>>>> On Mon, May 23, 2016 at 11:07 AM, mohammad alsharaiah
>>>> <mohdsharaiah at gmail.com> wrote:
>>>>> Hi,
>>>>> 
>>>>> every one , im using Boolnet package inside R environment to create a
>>>>> boolean network.
>>>>> 
>>>>> after i create a text file for the Boolean network  and  i loaded it
>> by
>>>>> using R  by using this command:
>>>>> 
>>>>>> library(BoolNet)
>>>>>> loadNetwork("C:/Users/mohammad/Documents/cellcontrol.txt")
>>>>> 
>>>>> then its loaded inside R screen. But when i started to do some of
>> tasks
>>>>> on
>>>>> this network every time i got this error message, this is an example
>> how
>>>>> i
>>>>> work on the created network and get the error.
>>>>> 
>>>>>> stateTransition(cellcontrol, rep(1,11))
>>>>> Error in inherits(network, "BooleanNetwork") :
>>>>>  object 'cellcontrol' not found
>>>>>> 
>>>>> 
>>>>> please can any one help me to solve this error .
>>>>> 
>>>>> Reagdrs,
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> *Mohammad *
>>>>> 
>>>>>        [[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.ca.us  Mon May 23 08:49:57 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 22 May 2016 23:49:57 -0700
Subject: [R] need help to convert animal ID to a factor
In-Reply-To: <CALjSv_eh+GZ1CWsuzWW5Fe+MNZWv8+urgSZq5F3xM46TRXhmjg@mail.gmail.com>
References: <CALjSv_eh+GZ1CWsuzWW5Fe+MNZWv8+urgSZq5F3xM46TRXhmjg@mail.gmail.com>
Message-ID: <8FD7F24A-0B09-4BAC-9FD4-C468DD8BD7D5@dcn.davis.ca.us>

I am not familiar with any function called "toFactor". It may be part of some contributed package that you need to re-load. 

However, one does not ordinarily need to use a package to convert one column of a data frame into a factor, since factors are supported by base R.

Eg

MyDF$ID <- factor( MyDF$ID )

-- 
Sent from my phone. Please excuse my brevity.

On May 22, 2016 9:46:30 PM PDT, Neny Sitorus <nsit315 at aucklanduni.ac.nz> wrote:
>Hi,
>
>I was trying to convert my animal ID experiment (ID) to factor to get
>the
>ggboxplot, previously it was working well.
>But since yesterday it displayed "Error" every time I tried to re-run
>it.
>Could you help me in this issue?
>
>
># convert rat ID to factor
>Leak.df <- toFactor(Leak.df, id.var=c("ID", "Time"))
>
>>From Console:
>> ets.df <- toFactor(ets.df, id.var=c("ID", "Time"))
>Error: could not find function "toFactor"
>
>Looking forward for your reply.
>
>
>Kind regards,
>Neny
>
>On 23 May 2016 at 15:59, Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Okay, perhaps if you try this:
>>
>> cellcontrol<-
>>  loadNetwork("C:/Users/mohammad/Documents/cellcontrol.txt")
>> stateTransition(cellcontrol, rep(1,11))
>>
>> Obviously this is a guess, but it might help.
>>
>> Jim
>>
>>
>> On Mon, May 23, 2016 at 1:55 PM, mohammad alsharaiah
>> <mohdsharaiah at gmail.com> wrote:
>> > Hi jim ,
>> > first of all iwant to thank you for your reply.
>> > the object "cellcontrol" its a network that i created it by using
>> boolnet
>> > package. when i call the network its loaded inside the R workspace
>> screen.
>> > but i got this error when i want to work on it.
>> >
>> > boolnet allow to us to create the network and write a logical rules
> in
>> text
>> > file, then we can loaded it as a network inside R to study the
>dynamic
>> > behavior.
>> >
>> > but i can not work on it because this error and converting it to
>data
>> file.
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > Mohammad
>> >
>> >
>> > On Sun, May 22, 2016 at 8:40 PM, Jim Lemon <drjimlemon at gmail.com>
>wrote:
>> >>
>> >> Hi Mohammad,
>> >> I don't have the BoolNet package installed, but the error means
>that
>> >> the object "cellcontrol" is not there for the function to use. It
>> >> should be a network "generated by generateRandomNKNetwork, or
>> >> reconstructed by reconstructNetwork" as detailed in the help
>pages.
>> >>
>> >> Jim
>> >>
>> >>
>> >> On Mon, May 23, 2016 at 11:07 AM, mohammad alsharaiah
>> >> <mohdsharaiah at gmail.com> wrote:
>> >> > Hi,
>> >> >
>> >> > every one , im using Boolnet package inside R environment to
>create a
>> >> > boolean network.
>> >> >
>> >> > after i create a text file for the Boolean network  and  i
>loaded it
>> by
>> >> > using R  by using this command:
>> >> >
>> >> >  > library(BoolNet)
>> >> >> loadNetwork("C:/Users/mohammad/Documents/cellcontrol.txt")
>> >> >
>> >> > then its loaded inside R screen. But when i started to do some
>of
>> tasks
>> >> > on
>> >> > this network every time i got this error message, this is an
>example
>> how
>> >> > i
>> >> > work on the created network and get the error.
>> >> >
>> >> >> stateTransition(cellcontrol, rep(1,11))
>> >> > Error in inherits(network, "BooleanNetwork") :
>> >> >   object 'cellcontrol' not found
>> >> >>
>> >> >
>> >> > please can any one help me to solve this error .
>> >> >
>> >> > Reagdrs,
>> >> >
>> >> >
>> >> >
>> >> >
>> >> > *Mohammad *
>> >> >
>> >> >         [[alternative HTML version deleted]]
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide
>> >> > http://www.R-project.org/posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible
>code.
>> >
>> >
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From Aljosa.Aleksandrovic at man.com  Mon May 23 09:13:00 2016
From: Aljosa.Aleksandrovic at man.com (Aleksandrovic, Aljosa (Pfaeffikon))
Date: Mon, 23 May 2016 07:13:00 +0000
Subject: [R] Linear Regressions with non-negativity constraint
Message-ID: <629e5be9986f472391f68845b92c2de8@PLONINEXMS136.maninvestments.ad.man.com>

Hi all,

I hope you are doing well?

I'm currently using lm() to estimate a linear multi-factor (5 factors without intercept) model as follows ...

factor.lm <- lm(y~x1+x2+x3+x4+x5-1, data = data.frame.rbind)

Using nnls(A,b) I estimated the same model, extended by a non-negativity constraint on the 5 independent factors. It works quite well but unfortunately nnls() only returns the x estimates. Is there a way to extract the Std.Errors, t-values, p-valuess and R^2 as well?

Thanks in advance and kind regards, 
Aljosa


Aljosa Aleksandrovic, FRM, CAIA
Senior Quantitative Analyst - Convertibles
aljosa.aleksandrovic at man.com
Tel +41 55 417 76 03

Man Investments (CH) AG
Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland


This email has been sent by a member of the Man group (?Man?). Man?s parent company, Man Group plc, is registered in England and Wales (company number 08172396) at Riverbank House, 2 Swan  Lane, London, EC4R 3AD.
The contents of this email are for the named addressee(s...{{dropped:15}}


From pdalgd at gmail.com  Mon May 23 09:20:06 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 23 May 2016 09:20:06 +0200
Subject: [R] Element-by-element operation (adding)
In-Reply-To: <CA+hbrhUfhde0PfpNqzYUj-OYyKkbTzykz6THHDkFS09yXaAdng@mail.gmail.com>
References: <71b53a06-7c85-b970-eaf8-b83f0d660ab7@gmail.com>
	<CA+hbrhUfhde0PfpNqzYUj-OYyKkbTzykz6THHDkFS09yXaAdng@mail.gmail.com>
Message-ID: <21F15D83-AB7C-4935-AE11-77B57B7D8A78@gmail.com>


> On 23 May 2016, at 07:44 , Peter Langfelder <peter.langfelder at gmail.com> wrote:
> 
> or
> 
> t(apply(v, 1, `+`, b))

Or, as you're messing with transposes anyways, use the fact that the column-wise counterpart is automagically handled by recycling:

t(t(v)+b)

Or, look Ma, no transposes
 
v + rep(b, each=nrow(v))

(_always_ doublecheck the logic when you apply these and similar techniques! I have seen my share of student code where recycling had been applied along the wrong dimension of a matrix...)

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From maechler at stat.math.ethz.ch  Mon May 23 09:46:43 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 23 May 2016 09:46:43 +0200
Subject: [R] if else condition - help
In-Reply-To: <CAAxdm-7VoMoVM+kyw509Zc=1LtH1BTSPNRUCz9ZapEqVx-P9Hw@mail.gmail.com>
References: <CAL2fYnP3TOHBF=5vsGtpaEM8M8_dOSR26q2rnHhj6jgihNF=ZA@mail.gmail.com>
	<CAAxdm-7VoMoVM+kyw509Zc=1LtH1BTSPNRUCz9ZapEqVx-P9Hw@mail.gmail.com>
Message-ID: <22338.46435.636940.995371@stat.math.ethz.ch>

>>>>> jim holtman <jholtman at gmail.com>
>>>>>     on Sun, 22 May 2016 16:47:06 -0400 writes:

    > if you want to use 'ifelse', here is a way:

hmm, why should he want that ?
The OP did mention that it's about somewhat large objects, so
efficiency is one of the considerations :

ifelse() is often convenient and nicely self-explaining, but it 
is (because of its generality, but also by its definition)
much *less efficient* than the (sometimes slightly less
convenient) ways you were shown previously in this thread :

- For the generalized case findInterval() is order of magnitudes
  better, and
- for the simple case you were shown to use logical indexing,
  i.e., calls ? la    x[x > k] <- ..


In summary:
   Use  ifelse()  much less -- notably if writing
   functions/code which should scale !


Martin Maechler
ETH Zurich


From JSorkin at grecc.umaryland.edu  Mon May 23 13:26:27 2016
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Mon, 23 May 2016 07:26:27 -0400
Subject: [R] meaning of lm( y~., data=mydat ), is it a language feature,
 is it documented, is it supported?
Message-ID: <5742B0A3020000CB001550DE@smtp.medicine.umaryland.edu>

 
The syntax
mydat <- data.frame( y,x )
fit1 <- lm( y~., data=mydat )
appears to perform a multivariable regression of y on every non-y variable in the data frame mydat. I can not find this syntax (y~.) in R documentation. Is y~. a supported feature of the R language? Where can I find it documented? I would hate to write code that is dependent on a non-supported, non-documented language feature.
Thank you,
John
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From murdoch.duncan at gmail.com  Mon May 23 13:41:57 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 23 May 2016 07:41:57 -0400
Subject: [R] meaning of lm( y~., data=mydat ), is it a language feature,
 is it documented, is it supported?
In-Reply-To: <5742B0A3020000CB001550DE@smtp.medicine.umaryland.edu>
References: <5742B0A3020000CB001550DE@smtp.medicine.umaryland.edu>
Message-ID: <cafd80eb-73e7-0109-e224-6d1a53a2a63c@gmail.com>

On 23/05/2016 7:26 AM, John Sorkin wrote:
>
> The syntax
> mydat <- data.frame( y,x )
> fit1 <- lm( y~., data=mydat )
> appears to perform a multivariable regression of y on every non-y variable in the data frame mydat. I can not find this syntax (y~.) in R documentation. Is y~. a supported feature of the R language? Where can I find it documented? I would hate to write code that is dependent on a non-supported, non-documented language feature.

It is documented in the Introduction to R manual (hidden in section 
11.5, "Updating fitted models"), and in ?formula, which ?lm refers to.

Duncan Murdoch


From ivan.calandra at univ-reims.fr  Mon May 23 13:43:07 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Mon, 23 May 2016 13:43:07 +0200
Subject: [R] meaning of lm( y~., data=mydat ), is it a language feature,
 is it documented, is it supported?
In-Reply-To: <5742B0A3020000CB001550DE@smtp.medicine.umaryland.edu>
References: <5742B0A3020000CB001550DE@smtp.medicine.umaryland.edu>
Message-ID: <facbc0f4-33c4-4c06-2d43-37830d83211b@univ-reims.fr>

Hi John,

This is indeed documented, but you'll have to look at the function 
formula():
?formula

Regarding the dot (.), here is the explanation from the help of formula():
"There are two special interpretations of . in a formula. The usual one 
is in the context of a data argument of model fitting functions and 
means ?all columns not otherwise in the formula?: see terms.formula. In 
the context of update.formula, only, it means ?what was previously in 
this part of the formula?."

HTH,
Ivan

--
Ivan Calandra, PhD
Scientific Mediator
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 23/05/2016 ? 13:26, John Sorkin a ?crit :
>   
> The syntax
> mydat <- data.frame( y,x )
> fit1 <- lm( y~., data=mydat )
> appears to perform a multivariable regression of y on every non-y variable in the data frame mydat. I can not find this syntax (y~.) in R documentation. Is y~. a supported feature of the R language? Where can I find it documented? I would hate to write code that is dependent on a non-supported, non-documented language feature.
> Thank you,
> John
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:8}}


From ken.knoblauch at inserm.fr  Mon May 23 13:43:17 2016
From: ken.knoblauch at inserm.fr (Kenneth Knoblauch)
Date: Mon, 23 May 2016 11:43:17 +0000
Subject: [R]
	=?utf-8?q?meaning_of_lm=28_y=7E=2E=2C_data=3Dmydat_=29=2C_is_?=
	=?utf-8?q?it_a_language_feature=2C_is_it_documented=2C_is_it_suppo?=
	=?utf-8?q?rted=3F?=
References: <5742B0A3020000CB001550DE@smtp.medicine.umaryland.edu>
Message-ID: <loom.20160523T134234-697@post.gmane.org>

John Sorkin <JSorkin <at> grecc.umaryland.edu> writes:
> The syntax
> mydat <- data.frame( y,x )
> fit1 <- lm( y~., data=mydat )
> appears to perform a multivariable regression of y on 
every non-y variable in the data frame mydat. I can not
> find this syntax (y~.) in R documentation. Is y~. 
a supported feature of the R language? Where can I find it
> documented? I would hate to write code that
 is dependent on a non-supported, non-documented 
language feature.
> Thank you,
> John
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of 
Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913
> 

How about section 11.5 of An Introduction to R?

-- 
Kenneth Knoblauch
Inserm U1208
Stem-cell and Brain Research Institute
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html

From bgunter.4567 at gmail.com  Mon May 23 13:44:19 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 23 May 2016 04:44:19 -0700
Subject: [R] meaning of lm( y~., data=mydat ), is it a language feature,
 is it documented, is it supported?
In-Reply-To: <5742B0A3020000CB001550DE@smtp.medicine.umaryland.edu>
References: <5742B0A3020000CB001550DE@smtp.medicine.umaryland.edu>
Message-ID: <CAGxFJbQarrTEYTdRafc-MWdDJ9OpdZrMbqhffz3vwWSRr1KpQg@mail.gmail.com>

It's about formula syntax, so ?formula documents it.

Bert

On Monday, May 23, 2016, John Sorkin <JSorkin at grecc.umaryland.edu> wrote:

>
> The syntax
> mydat <- data.frame( y,x )
> fit1 <- lm( y~., data=mydat )
> appears to perform a multivariable regression of y on every non-y variable
> in the data frame mydat. I can not find this syntax (y~.) in R
> documentation. Is y~. a supported feature of the R language? Where can I
> find it documented? I would hate to write code that is dependent on a
> non-supported, non-documented language feature.
> Thank you,
> John
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:25}}


From G.Maubach at weinwolf.de  Mon May 23 15:28:11 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Mon, 23 May 2016 15:28:11 +0200
Subject: [R] Filtering String Variables
Message-ID: <OFC973FC28.2EE4FE11-ONC1257FBC.0049D8AA-C1257FBC.0049FD6E@lotus.hawesko.de>

# Hi All,
# 
# I have the following data frame (example):

Debitor <- c("968691", "968691", "968691",
             "A04046", "A04046",
             "L0006", "L0006", "L0006",
             "L0023", "L0023",
             "L0056", "L0056",
             "L0094", "L0094", "L0094",
             "L0124", "L0124",
             "L0143", 
             "L0170",
             "13459",
             "473908",
             "394704",
             "4711",
             "4712",
             "4713")
Debitor <- as.character(Debitor)
var1 <- c(11, 12, 13,
          14, 14,
          12, 13, 14,
          10, 11,
          12, 12,
          12, 12, 12,
          15, 17,
          11,
          14,
          12,
          17,
          13,
          15,
          16,
          11)
ds_example <- data.frame(Debitor, var1)
ds_example$case_id <- 1:nrow(ds_example)
ds_example <- ds_example[, sort(colnames(ds_example))]
ds_example

# I would like to generate a data frame that contains the duplicates AND 
the
# corresponding non-duplicates to the duplicates.
# For example, finding the duplicates with deliver case 2 and 3 but the 
list
# should also contain case 1 because case 1 is the corresponding case to 
the
# duplicate cases 2 and 3.
# For the whole example dataset that would be:
needed <- c(1, 1, 1,
            1, 1,
            1, 1, 1,
            1, 1,
            1, 1,
            1, 1, 1,
            1, 1,
            0, 0, 0, 0, 0, 0, 0, 0)
needed <- as.logical(needed)
ds_example <- data.frame(ds_example, needed)
ds_example

# To find the duplicates and the corresponding non-duplicates
duplicates <- duplicated(ds_example$Debitor)

list_of_duplicated_debitors <- as.character(ds_example[duplicates, 
"Debitor"])

filter_variable <- unique(list_of_duplicated_debitors)

ds_duplicates <- ds_example["Debitor" == filter_variable]  # Result: 
dataset with 0 columns

ds_duplicates <- ds_example["Debitor"] %in% filter_variable  # Result: 
FALSE

# How can I create a dataset like this

ds_example <- ds_example[needed, ]
ds_example

# using the Debitor IDs?

Kind regards

Georg Maubach


From simon.wood at bath.edu  Mon May 23 15:32:06 2016
From: simon.wood at bath.edu (Simon Wood)
Date: Mon, 23 May 2016 14:32:06 +0100
Subject: [R] mgcv::gam(): NA parametric coefficient in a model with two
 categorical variables + model interpretation
In-Reply-To: <CAAO1NneNOjwWCyva-yP6Bz5D5hSBrmaqBXitwW9Md2c-nt1JRg@mail.gmail.com>
References: <CAAO1NneNOjwWCyva-yP6Bz5D5hSBrmaqBXitwW9Md2c-nt1JRg@mail.gmail.com>
Message-ID: <57430656.1050709@bath.edu>

Q1: It looks like the model is not fully identifiably given the data and 
as a result igcCAT.ideo has been set to zero - there is no sensible test 
to conduct with such a term, hence the NAs in the test stat an p-value 
fields.

Q2: A separate (centred) smooth is estimated for each level of igc. If 
you want a baseline (igcCAT.pseudo) smooth, and difference smooths for 
the rest of the levels of igc then you need to set igc to be an ordered 
factor, and use something like...
~ igc + s(ctrial) + s(ctrial,by=igc)
- see section on `by' variables in ?gam.models.

best,
Simon

On 22/05/16 23:29, Fotis Fotiadis wrote:
> Hallo all
>
> I am using a gam model for my data.
>
> m2.4<-bam(acc~ 1 + igc + s(ctrial, by=igc) + shape + s(ctrial, by=shape) +
> s(ctrial, sbj, bs = "fs", m = 1) , data=data, family=binomial)
>
> igc codes condition and there are four levels (CAT.pseudo,
> CAT.ideo,PA.pseudo, PA.ideo), and shape is a factor (that cannot be
> considered random effect) with four levels too (rand21, rand22, rand23,
> rand30).
>
> Here is the summary of the model
>> summary(m2.4)
> Family: binomial
> Link function: logit
>
> Formula:
> acc ~ 1 + igc + s(ctrial, by = igc) + shape + s(ctrial, by = shape) +
>      s(ctrial, sbj, bs = "fs", m = 1)
>
> Parametric coefficients:
>               Estimate Std. Error z value Pr(>|z|)
> (Intercept)    3.5321     0.1930  18.302  < 2e-16 ***
> igcCAT.ideo    0.0000     0.0000      NA       NA
> igcPA.ideo    -0.3650     0.2441  -1.495   0.1348
> igcPA.pseudo  -0.2708     0.2574  -1.052   0.2928
> shaperand22   -0.1390     0.1548  -0.898   0.3693
> shaperand23    0.3046     0.1670   1.823   0.0682 .
> shaperand30   -0.5839     0.1163  -5.020 5.16e-07 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Approximate significance of smooth terms:
>                              edf  Ref.df   Chi.sq  p-value
> s(ctrial):igcCAT.pseudo   3.902   4.853   74.787 1.07e-14 ***
> s(ctrial):igcCAT.ideo     2.293   2.702   13.794 0.001750 **
> s(ctrial):igcPA.ideo      1.000   1.000   11.391 0.000738 ***
> s(ctrial):igcPA.pseudo    3.158   3.815   20.411 0.000413 ***
> s(ctrial):shaperand21     2.556   3.316   31.387 1.46e-06 ***
> s(ctrial):shaperand22     1.000   1.000    0.898 0.343381
> s(ctrial):shaperand23     2.304   2.850    6.144 0.118531
> s(ctrial):shaperand30     4.952   5.947   27.806 0.000144 ***
> s(ctrial,sbj)           221.476 574.000 1502.779  < 2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Rank: 652/655
> R-sq.(adj) =  0.405   Deviance explained = 43.9%
> fREML =  24003  Scale est. = 1         n = 18417
>
>
> I am not sure how this model works, but I guess it creates four smooths for
> each level of condition, and four smooths for each level of shape.
>
> There is also the intercept of the model, set at the reference level of
> condition (CAT.pseudo) and at the reference level of shape (rand21). Each
> parametric term represents the difference of each level of each of the two
> factors from the intercept.
>
> I have two questions
>
> Q1:
> Does anyone now why I get NA results in the second line of the parametric
> terms?
>
> Q2:
> The term igcCAT.ideo denotes the difference in the intercept between
> (A): condition=igcCAT.ideo,  and
> (B): (condition=igcCATpseudo ) &(shape=rand21).
> But what is the value (level) of shape for (A)?
> Is it the reference level? Or is it, perhaps, the "grand mean" of the shape
> variable?
>
>
> Thank you in advance for your time,
> Fotis
>
>


-- 
Simon Wood, School of Mathematics, University of Bristol BS8 1TW UK
+44 (0)117 33 18273     http://www.maths.bris.ac.uk/~sw15190


From G.Maubach at weinwolf.de  Mon May 23 15:57:04 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Mon, 23 May 2016 15:57:04 +0200
Subject: [R] WG: Filtering String Variables (SOLVED)
Message-ID: <OF498A59E4.3F9A198B-ONC1257FBC.004C6D27-C1257FBC.004CA248@lotus.hawesko.de>

Hi All,

the solution for my question is as follows

## Filter duplicates and correpsonding non-duplicates
### To filter duplicates and their corresponding non-duplicates use the
### following code snippet:
Debitor <- c("968691", "968691", "968691",
             "A04046", "A04046",
             "L0006", "L0006", "L0006",
             "L0023", "L0023",
             "L0056", "L0056",
             "L0094", "L0094", "L0094",
             "L0124", "L0124",
             "L0143", 
             "L0170",
             "13459",
             "473908",
             "394704",
             "4711",
             "4712",
             "4713")
Debitor <- as.character(Debitor)
var1 <- c(11, 12, 13,
          14, 14,
          12, 13, 14,
          10, 11,
          12, 12,
          12, 12, 12,
          15, 17,
          11,
          14,
          12,
          17,
          13,
          15,
          16,
          11)
ds_example <- data.frame(Debitor, var1)
ds_example$case_id <- 1:nrow(ds_example)
ds_example <- ds_example[, sort(colnames(ds_example))]
ds_example

# This task is to generate a data frame that contains the duplicates AND 
the
# corresponding non-duplicates to the duplicates.
# For example, finding the duplicates will deliver case 2 and 3 but the 
list
# should also contain case 1 because case 1 is the corresponding case to 
the
# duplicate cases 2 and 3.
# For the whole example dataset that would be:
needed <- c(1, 1, 1,
            1, 1,
            1, 1, 1,
            1, 1,
            1, 1,
            1, 1, 1,
            1, 1,
            0, 0, 0, 0, 0, 0, 0, 0)
needed <- as.logical(needed)
ds_example <- data.frame(ds_example, needed)
ds_example

# To find the duplicates and the corresponding non-duplicates
duplicates <- duplicated(ds_example$Debitor)

list_of_duplicated_debitors <- as.character(ds_example[duplicates, 
"Debitor"])

filter_variable <- unique(list_of_duplicated_debitors)

### Wrong code. Do not run.
### ds_duplicates <- ds_example["Debitor" == filter_variable]  # Result: 
dataset with 0 columns
### duplicates_and_correponding_non_duplicates <- ds_example["Debitor"] 
%in% filter_variable  # Result: FALSE

duplicates_and_correponding_non_duplicates <- ds_example$Debitor %in% 
filter_variable  # Result: OK
duplicates_and_correponding_non_duplicates <- ds_example[, "Debitor"] %in% 
filter_variable  # Result: OK

### Create the dataset with duplicates and corresponding non-duplicates
ds_example <- ds_example[duplicates_and_correponding_non_duplicates, ]
ds_example

It was a simple mistake when subscripting.

Kind regards

Georg Maubach


----- Weitergeleitet von Georg Maubach/WWBO/WW/HAW am 23.05.2016 15:54 
-----

Von:    Georg Maubach/WWBO/WW/HAW
An:     r-help at r-project.org, 
Datum:  23.05.2016 15:28
Betreff:        Filtering String Variables


# Hi All,
# 
# I have the following data frame (example):

Debitor <- c("968691", "968691", "968691",
             "A04046", "A04046",
             "L0006", "L0006", "L0006",
             "L0023", "L0023",
             "L0056", "L0056",
             "L0094", "L0094", "L0094",
             "L0124", "L0124",
             "L0143", 
             "L0170",
             "13459",
             "473908",
             "394704",
             "4711",
             "4712",
             "4713")
Debitor <- as.character(Debitor)
var1 <- c(11, 12, 13,
          14, 14,
          12, 13, 14,
          10, 11,
          12, 12,
          12, 12, 12,
          15, 17,
          11,
          14,
          12,
          17,
          13,
          15,
          16,
          11)
ds_example <- data.frame(Debitor, var1)
ds_example$case_id <- 1:nrow(ds_example)
ds_example <- ds_example[, sort(colnames(ds_example))]
ds_example

# I would like to generate a data frame that contains the duplicates AND 
the
# corresponding non-duplicates to the duplicates.
# For example, finding the duplicates with deliver case 2 and 3 but the 
list
# should also contain case 1 because case 1 is the corresponding case to 
the
# duplicate cases 2 and 3.
# For the whole example dataset that would be:
needed <- c(1, 1, 1,
            1, 1,
            1, 1, 1,
            1, 1,
            1, 1,
            1, 1, 1,
            1, 1,
            0, 0, 0, 0, 0, 0, 0, 0)
needed <- as.logical(needed)
ds_example <- data.frame(ds_example, needed)
ds_example

# To find the duplicates and the corresponding non-duplicates
duplicates <- duplicated(ds_example$Debitor)

list_of_duplicated_debitors <- as.character(ds_example[duplicates, 
"Debitor"])

filter_variable <- unique(list_of_duplicated_debitors)

ds_duplicates <- ds_example["Debitor" == filter_variable]  # Result: 
dataset with 0 columns

ds_duplicates <- ds_example["Debitor"] %in% filter_variable  # Result: 
FALSE

# How can I create a dataset like this

ds_example <- ds_example[needed, ]
ds_example

# using the Debitor IDs?

Kind regards

Georg Maubach


From jdnewmil at dcn.davis.ca.us  Mon May 23 16:14:09 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 23 May 2016 07:14:09 -0700
Subject: [R] WG: Filtering String Variables (SOLVED)
In-Reply-To: <OF498A59E4.3F9A198B-ONC1257FBC.004C6D27-C1257FBC.004CA248@lotus.hawesko.de>
References: <OF498A59E4.3F9A198B-ONC1257FBC.004C6D27-C1257FBC.004CA248@lotus.hawesko.de>
Message-ID: <B4288D2F-86CE-4A87-9094-A502956EDE56@dcn.davis.ca.us>

Perhaps

ds_example <- ds_example[ with( ds_example, 1 < ave( Debitor, Debitor, FUN=length ) ), ]

-- 
Sent from my phone. Please excuse my brevity.

On May 23, 2016 6:57:04 AM PDT, G.Maubach at weinwolf.de wrote:
>Hi All,
>
>the solution for my question is as follows
>
>## Filter duplicates and correpsonding non-duplicates
>### To filter duplicates and their corresponding non-duplicates use the
>### following code snippet:
>Debitor <- c("968691", "968691", "968691",
>             "A04046", "A04046",
>             "L0006", "L0006", "L0006",
>             "L0023", "L0023",
>             "L0056", "L0056",
>             "L0094", "L0094", "L0094",
>             "L0124", "L0124",
>             "L0143", 
>             "L0170",
>             "13459",
>             "473908",
>             "394704",
>             "4711",
>             "4712",
>             "4713")
>Debitor <- as.character(Debitor)
>var1 <- c(11, 12, 13,
>          14, 14,
>          12, 13, 14,
>          10, 11,
>          12, 12,
>          12, 12, 12,
>          15, 17,
>          11,
>          14,
>          12,
>          17,
>          13,
>          15,
>          16,
>          11)
>ds_example <- data.frame(Debitor, var1)
>ds_example$case_id <- 1:nrow(ds_example)
>ds_example <- ds_example[, sort(colnames(ds_example))]
>ds_example
>
># This task is to generate a data frame that contains the duplicates
>AND 
>the
># corresponding non-duplicates to the duplicates.
># For example, finding the duplicates will deliver case 2 and 3 but the
>
>list
># should also contain case 1 because case 1 is the corresponding case
>to 
>the
># duplicate cases 2 and 3.
># For the whole example dataset that would be:
>needed <- c(1, 1, 1,
>            1, 1,
>            1, 1, 1,
>            1, 1,
>            1, 1,
>            1, 1, 1,
>            1, 1,
>            0, 0, 0, 0, 0, 0, 0, 0)
>needed <- as.logical(needed)
>ds_example <- data.frame(ds_example, needed)
>ds_example
>
># To find the duplicates and the corresponding non-duplicates
>duplicates <- duplicated(ds_example$Debitor)
>
>list_of_duplicated_debitors <- as.character(ds_example[duplicates, 
>"Debitor"])
>
>filter_variable <- unique(list_of_duplicated_debitors)
>
>### Wrong code. Do not run.
>### ds_duplicates <- ds_example["Debitor" == filter_variable]  #
>Result: 
>dataset with 0 columns
>### duplicates_and_correponding_non_duplicates <- ds_example["Debitor"]
>
>%in% filter_variable  # Result: FALSE
>
>duplicates_and_correponding_non_duplicates <- ds_example$Debitor %in% 
>filter_variable  # Result: OK
>duplicates_and_correponding_non_duplicates <- ds_example[, "Debitor"]
>%in% 
>filter_variable  # Result: OK
>
>### Create the dataset with duplicates and corresponding non-duplicates
>ds_example <- ds_example[duplicates_and_correponding_non_duplicates, ]
>ds_example
>
>It was a simple mistake when subscripting.
>
>Kind regards
>
>Georg Maubach
>
>
>----- Weitergeleitet von Georg Maubach/WWBO/WW/HAW am 23.05.2016 15:54 
>-----
>
>Von:    Georg Maubach/WWBO/WW/HAW
>An:     r-help at r-project.org, 
>Datum:  23.05.2016 15:28
>Betreff:        Filtering String Variables
>
>
># Hi All,
># 
># I have the following data frame (example):
>
>Debitor <- c("968691", "968691", "968691",
>             "A04046", "A04046",
>             "L0006", "L0006", "L0006",
>             "L0023", "L0023",
>             "L0056", "L0056",
>             "L0094", "L0094", "L0094",
>             "L0124", "L0124",
>             "L0143", 
>             "L0170",
>             "13459",
>             "473908",
>             "394704",
>             "4711",
>             "4712",
>             "4713")
>Debitor <- as.character(Debitor)
>var1 <- c(11, 12, 13,
>          14, 14,
>          12, 13, 14,
>          10, 11,
>          12, 12,
>          12, 12, 12,
>          15, 17,
>          11,
>          14,
>          12,
>          17,
>          13,
>          15,
>          16,
>          11)
>ds_example <- data.frame(Debitor, var1)
>ds_example$case_id <- 1:nrow(ds_example)
>ds_example <- ds_example[, sort(colnames(ds_example))]
>ds_example
>
># I would like to generate a data frame that contains the duplicates
>AND 
>the
># corresponding non-duplicates to the duplicates.
># For example, finding the duplicates with deliver case 2 and 3 but the
>
>list
># should also contain case 1 because case 1 is the corresponding case
>to 
>the
># duplicate cases 2 and 3.
># For the whole example dataset that would be:
>needed <- c(1, 1, 1,
>            1, 1,
>            1, 1, 1,
>            1, 1,
>            1, 1,
>            1, 1, 1,
>            1, 1,
>            0, 0, 0, 0, 0, 0, 0, 0)
>needed <- as.logical(needed)
>ds_example <- data.frame(ds_example, needed)
>ds_example
>
># To find the duplicates and the corresponding non-duplicates
>duplicates <- duplicated(ds_example$Debitor)
>
>list_of_duplicated_debitors <- as.character(ds_example[duplicates, 
>"Debitor"])
>
>filter_variable <- unique(list_of_duplicated_debitors)
>
>ds_duplicates <- ds_example["Debitor" == filter_variable]  # Result: 
>dataset with 0 columns
>
>ds_duplicates <- ds_example["Debitor"] %in% filter_variable  # Result: 
>FALSE
>
># How can I create a dataset like this
>
>ds_example <- ds_example[needed, ]
>ds_example
>
># using the Debitor IDs?
>
>Kind regards
>
>Georg Maubach
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From nicoletta.sabov at hotmail.de  Mon May 23 11:30:33 2016
From: nicoletta.sabov at hotmail.de (Nicoletta Sabov)
Date: Mon, 23 May 2016 11:30:33 +0200
Subject: [R] Vectors, Loops, Rnorm and KS-Testing
Message-ID: <BLU437-SMTP62AFCF7B299A3A2D0CFAAF8B4E0@phx.gbl>

Hi there,

I need a function, that calculates the mean of a desired amount of normally distributed numbers and repeats this process for a desired number of repetitions. The function should return only a single vector consisting solely of the calculated means. Also the user of this function must be able to specify the parameters of the normal distribution used while calculating the means. I need this function for the Kolmogorov Smirnov Test.
I am a total beginner, so far I only have come to this point:

kolmo <- function(x, mean, sd, rep){
  
  for(i in rep){
    cat(mean(rnorm(x, mean, sd)))
    
}}
This returns a simple number, but I do need a vector to be returned.
Thanks a lot in advance!



	[[alternative HTML version deleted]]


From louise.mair at slu.se  Mon May 23 13:20:43 2016
From: louise.mair at slu.se (Louise Mair)
Date: Mon, 23 May 2016 11:20:43 +0000
Subject: [R] Unexpected values obtained when reading in data using ncdf
 and ncdf4
In-Reply-To: <8AFD184A-C2EE-4A29-8CE3-DFE8F27DA70C@noaa.gov>
References: <ce01ddcca00c4f72aea9ac96e3b275ec@EXCH2-1.slu.se>
	<CAL+Zad8z1cgEEQz8cPCn=M3_PALy+Q+gk=yo_Rp=O+_bv-rOOA@mail.gmail.com>
	<8AFD184A-C2EE-4A29-8CE3-DFE8F27DA70C@noaa.gov>
Message-ID: <14b164e685f54a85b6f3c5cfa9afb807@EXCH2-1.slu.se>

Hi Dave, Roy and R-users,

Many thanks for your suggestions - in later correspondence Dave suggested that I ask the data provider to run a md5 checksum on the problem files, and compare their results against a md5 checksum on my copies of the files. Having done this, I found that the results didn't match (which they should do if the files were identical), and so this indicated that some corruption must have occurred during the file transfer.

Unfortunately we haven't discovered the source of the problem, but it was very helpful to learn how to compare files and identify the problem, so thanks very much for your help!

Best wishes,
Louise




-----Original Message-----
From: Roy Mendelssohn - NOAA Federal [mailto:roy.mendelssohn at noaa.gov] 
Sent: den 22 april 2016 17:31
To: Louise Mair
Cc: r-help at r-project.org; David W. Pierce
Subject: Re: [R] Unexpected values obtained when reading in data using ncdf and ncdf4

Hi Louise:

If Dave can?t figure it out, I can give a look also.  A couple of things I would suggest:

1.  Don?t use the name ?data? in the nc_open command, that is a reserved command in R and you never know what problems that can cause.

2. You are doing calculations to get set the start and count values in the ncvar_get commands, print those values out before you make the calls to make certain they are valid.

HTH,

-Roy

> On Apr 22, 2016, at 8:08 AM, David W. Pierce <dpierce at ucsd.edu> wrote:
> 
> On Fri, Apr 22, 2016 at 1:32 AM, Louise Mair <louise.mair at slu.se> wrote:
> 
>> Dear R Users,
>> 
>> I am encountering a problem when reading nc files into R using the 
>> ncdf and ncdf4 libraries. The nc files are too large to attach an 
>> example (but if someone is interested in helping out I could send a 
>> file privately via an online drive), but the code is basic:
>> 
> ?[...]?
> 
> 
> ?Hi Louise,
> 
> I'm the author of the ncdf and ncdf4 libraries. What are the details 
> -- what operating system are you running on, what version of R and the 
> netcdf library are you using?
> 
> If you make the files available to me I can take a look.
> 
> Regards,
> 
> --Dave Pierce
> ?
> 
> 
> 
> 
> 
>> for(i in 1:length(thesenames[,1])){
>>   data <- nc_open(paste(INDIR, thesenames[i,c("wholename")], sep=""),
>> write=F)
>>   d.vars <- names(data$var)
>>   d.size <- (data$var[[length(d.vars)]])$size
>> 
>>   # Obtaining longitude and latitude values
>>   d.lon <- as.vector(ncvar_get(data, varid="lon", start=c(1,1),
>> count=c(d.size[1],d.size[2])))
>>   d.lat <- as.vector(ncvar_get(data, varid="lat", start=c(1,1),
>> count=c(d.size[1],d.size[2])))
>> 
>>   # Obtaining climate data values
>>   df.clim <- data.frame(rn=seq(1:length(d.lon)))
>>   for(y in 1:d.size[3]){
>>     df.clim[,1+y] <- as.vector(ncvar_get(data, 
>> varid=d.vars[length(d.vars)], start=c(1,1,y),
>> count=c(d.size[1],d.size[2],1)))
>>      names(df.clim)[1+y] <- paste("y",y,sep="")  }
>>   tosummarise[,,i] <- as.matrix(df.clim[,-1]) }
>> 
>> The data are temperature or precipitation, across space and time.
>> 
>> For most of the >250 files I have, there are no problems, but for 
>> around 8 of these files, I get strange values. The data should be 
>> within a relatively narrow range, yet I get values such as 
>> -8.246508e+07  or 7.659506e+11. The particularly strange part is that 
>> these kind of values occur at regularly spaced intervals across the 
>> data, usually within a single time step.
>> 
>> I have the same problem (including the exact same strange values) 
>> when using ArcMap, yet the data provider assures me that the data 
>> look normal when using CDO (climate data operators) to view them, and 
>> that there are no missing values.
>> 
>> I realise this is very difficult to diagnose without the nc files 
>> themselves, so my questions are (1) Has anyone encountered something 
>> like this before?, (2) Is there something I am failing to specify in 
>> the code when reading in?, and (3) Is anyone interested in digging 
>> into this and willing to play around with the nc files if I make them available privately?
>> 
>> Thanks very much in advance!
>> Louise
>> 
>> 
>> 
>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> 
> --
> David W. Pierce
> Division of Climate, Atmospheric Science, and Physical Oceanography 
> Scripps Institution of Oceanography, La Jolla, California, USA
> (858) 534-8276 (voice)  /  (858) 534-8561 (fax)    dpierce at ucsd.edu
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From kashyapkvora at gmail.com  Mon May 23 15:04:02 2016
From: kashyapkvora at gmail.com (kashyap vora)
Date: Mon, 23 May 2016 09:04:02 -0400
Subject: [R] Programming Assignment 1: Quiz Air Pollution (Week 2:
 Programming with R)
Message-ID: <CAOYydBtqQbDaa+ufogsgW_nbSMzvni=urFLo0fTXTf+frae=PA@mail.gmail.com>

Hello R-Programming Experts,
                                            I needed a help here in
completing this *"Programming Assignment 1: Quiz on Air Pollution" (under
Week 2: Programming with R / Course 2: R Programming)* that i am stuck on.
I tried all possible variations in debugging my function to execute the
program in RStudio; but with no success. Can you please help me out here as
to how can i successfully solve this Programming Assignment. Let me know if
you need any more details.

Let me know i can share some of my functions that i tried executing.

Thanks & Regards,
Kashyap K Vora

	[[alternative HTML version deleted]]


From hendrix.jason at gmail.com  Mon May 23 15:25:35 2016
From: hendrix.jason at gmail.com (Jason Hendrix)
Date: Mon, 23 May 2016 08:25:35 -0500
Subject: [R] Ensembles for multi-class predictions
Message-ID: <CAKg_ArihRmvmf5i_o-BTZbi8ZV+WwJPG9SBUoQKAtM4+ERdA3A@mail.gmail.com>

I have trained two models using the caret library for R and would like to
combine the two multi-class trained models into one ensemble.

My first thought was to use caretEnsemble, but it does not yet support
multi-class predictions. See
https://github.com/zachmayer/caretEnsemble/issues/8

Is there a tutorial or sample code you can point me to showing how to
combine two or more multi-class trained models?

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Mon May 23 16:37:36 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 23 May 2016 15:37:36 +0100
Subject: [R] Programming Assignment 1: Quiz Air Pollution (Week 2:
 Programming with R)
In-Reply-To: <CAOYydBtqQbDaa+ufogsgW_nbSMzvni=urFLo0fTXTf+frae=PA@mail.gmail.com>
References: <CAOYydBtqQbDaa+ufogsgW_nbSMzvni=urFLo0fTXTf+frae=PA@mail.gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403E14A8CA8@GBTEDVPEXCMB04.corp.lgc-group.com>

You are probably using the wrong forum for this question and would save time by posting elsewhere rather than waiting for a reply here.
The stock answer to this type of request on R-help is 'Please read the Posting Guide (https://www.r-project.org/posting-guide.html) with special attention to "Basic statistics and classroom homework"'

S Ellison

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of kashyap vora
> Sent: 23 May 2016 14:04
> To: r-help at r-project.org
> Subject: [R] Programming Assignment 1: Quiz Air Pollution (Week 2:
> Programming with R)
> 
> Hello R-Programming Experts,
>                                             I needed a help here in completing this
> *"Programming Assignment 1: Quiz on Air Pollution" (under Week 2:
> Programming with R / Course 2: R Programming)* that i am stuck on.
> I tried all possible variations in debugging my function to execute the program
> in RStudio; but with no success. Can you please help me out here as to how can
> i successfully solve this Programming Assignment. Let me know if you need any
> more details.
> 
> Let me know i can share some of my functions that i tried executing.
> 
> Thanks & Regards,
> Kashyap K Vora
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From ivan.calandra at univ-reims.fr  Mon May 23 16:56:03 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Mon, 23 May 2016 16:56:03 +0200
Subject: [R] Vectors, Loops, Rnorm and KS-Testing
In-Reply-To: <BLU437-SMTP62AFCF7B299A3A2D0CFAAF8B4E0@phx.gbl>
References: <BLU437-SMTP62AFCF7B299A3A2D0CFAAF8B4E0@phx.gbl>
Message-ID: <9ade2bf8-440d-5db2-d927-5263ff491b55@univ-reims.fr>

Hi Nicoletta,

You need to read more introductory material.
One of the problems with your code is that you actually don't create any 
value, let alone any vector; you just display it with cat().
Then you try to create each value of your vector with an explicit for 
loop, but you don't need to; replicate() does the job in a compact code.

So if I understand correctly what you want to achieve, I would do this:
kolmo <- function(x, meanR=0, sdR=1, repet=1){
     out <- replicate(repet, mean(rnorm(x, meanR, sdR)))
     return(out)
}
# I changed the names of your arguments to make it less confusing (but I 
wasn't imaginative)
# I set some default values for 'meanR' and 'sdR', which are actually 
the defaults of rnorm()
# 'return(out)' is not necessary but I prefer to explicitly write what I 
want the function to output

Example:
kolmo(x=10, repet=3)

HTH,
Ivan

--
Ivan Calandra, PhD
Scientific Mediator
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 23/05/2016 ? 11:30, Nicoletta Sabov a ?crit :
> Hi there,
>
> I need a function, that calculates the mean of a desired amount of normally distributed numbers and repeats this process for a desired number of repetitions. The function should return only a single vector consisting solely of the calculated means. Also the user of this function must be able to specify the parameters of the normal distribution used while calculating the means. I need this function for the Kolmogorov Smirnov Test.
> I am a total beginner, so far I only have come to this point:
>
> kolmo <- function(x, mean, sd, rep){
>    
>    for(i in rep){
>      cat(mean(rnorm(x, mean, sd)))
>      
> }}
> This returns a simple number, but I do need a vector to be returned.
> Thanks a lot in advance!
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From pdalgd at gmail.com  Mon May 23 17:31:06 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 23 May 2016 17:31:06 +0200
Subject: [R] meaning of lm( y~., data=mydat ), is it a language feature,
	is it documented, is it supported?
In-Reply-To: <facbc0f4-33c4-4c06-2d43-37830d83211b@univ-reims.fr>
References: <5742B0A3020000CB001550DE@smtp.medicine.umaryland.edu>
	<facbc0f4-33c4-4c06-2d43-37830d83211b@univ-reims.fr>
Message-ID: <0B1CA092-19DC-482F-AE58-97A1630BD6C0@gmail.com>


> On 23 May 2016, at 13:43 , Ivan Calandra <ivan.calandra at univ-reims.fr> wrote:
> 
> Hi John,
> 
> This is indeed documented, but you'll have to look at the function formula():
> ?formula
> 
> Regarding the dot (.), here is the explanation from the help of formula():
> "There are two special interpretations of . in a formula. The usual one is in the context of a data argument of model fitting functions and means ?all columns not otherwise in the formula?: see terms.formula. In the context of update.formula, only, it means ?what was previously in this part of the formula?."

Actually, it is debatable which one of those deserve to be called "usual". Once upon a time, in the heyday of John Tukey, it might have been usual to have data set of a few hundred rows and, like, a dozen columns, exactly one of which being the response. Not so much these days, I'd say.

-pd

> 
> HTH,
> Ivan
> 
> --
> Ivan Calandra, PhD
> Scientific Mediator
> University of Reims Champagne-Ardenne
> GEGENAA - EA 3795
> CREA - 2 esplanade Roland Garros
> 51100 Reims, France
> +33(0)3 26 77 36 89
> ivan.calandra at univ-reims.fr
> --
> https://www.researchgate.net/profile/Ivan_Calandra
> https://publons.com/author/705639/
> 
> Le 23/05/2016 ? 13:26, John Sorkin a ?crit :
>>  The syntax
>> mydat <- data.frame( y,x )
>> fit1 <- lm( y~., data=mydat )
>> appears to perform a multivariable regression of y on every non-y variable in the data frame mydat. I can not find this syntax (y~.) in R documentation. Is y~. a supported feature of the R language? Where can I find it documented? I would hate to write code that is dependent on a non-supported, non-documented language feature.
>> Thank you,
>> John
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>> 
>> Confidentiality Statement:
>> This email message, including any attachments, is for ...{{dropped:8}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From JLucke at ria.buffalo.edu  Mon May 23 17:59:55 2016
From: JLucke at ria.buffalo.edu (JLucke at ria.buffalo.edu)
Date: Mon, 23 May 2016 11:59:55 -0400
Subject: [R] promoting scalar arguments to vectors in a function
Message-ID: <OFBC2106C8.7A59FA6B-ON85257FBC.0056D26D-85257FBC.0057E1BA@ria.buffalo.edu>

R users: 

Suppose I have a function that takes three numeric arguments x, y,  and z, 
any of which may be scalars or vectors.
Suppose further that the user takes one of the arguments, say y, as a 
vector with the other two as scalars.
Is there an existing R function that will promote the other two arguments 
to vectors of the same size?

I know in most cases this is not a problem as the promotion is automatic. 
I need this for a function I am writing
and I don't want to write any additional code to do this if I can help it.

Joe
Joseph F. Lucke, PhD
Senior Statistician
Research Institute on Addictions
University at Buffalo
State University of New York
1021 Main Street
Buffalo, NY  14203-1016



	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Mon May 23 18:11:35 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 23 May 2016 17:11:35 +0100
Subject: [R] promoting scalar arguments to vectors in a function
In-Reply-To: <OFBC2106C8.7A59FA6B-ON85257FBC.0056D26D-85257FBC.0057E1BA@ria.buffalo.edu>
References: <OFBC2106C8.7A59FA6B-ON85257FBC.0056D26D-85257FBC.0057E1BA@ria.buffalo.edu>
Message-ID: <1A8C1289955EF649A09086A153E2672403E14A8CD6@GBTEDVPEXCMB04.corp.lgc-group.com>

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Suppose I have a function that takes three numeric arguments x, y,  and z, any
> of which may be scalars or vectors.
> Suppose further that the user takes one of the arguments, say y, as a vector
> with the other two as scalars.
> Is there an existing R function that will promote the other two arguments to
> vectors of the same size?

This depends on what you mean by 'promote' ...

If you want to do something like 'recycling', as is often done for plot colours, but need things the same length for subsetting etc, one crude but fairly straightforward way I will confess to using in a function is something like

L <- max( length(x), length(y), length(z) )
x <- rep(x, length.out=L) 
y <- rep(y, length.out=L) 
z <- rep(z, length.out=L)

If you wanted to zero-fill to the same length, or fill with NA, that'd be something else ...

S Ellison




*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From jdnewmil at dcn.davis.ca.us  Mon May 23 18:23:52 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 23 May 2016 09:23:52 -0700
Subject: [R] promoting scalar arguments to vectors in a function
In-Reply-To: <OFBC2106C8.7A59FA6B-ON85257FBC.0056D26D-85257FBC.0057E1BA@ria.buffalo.edu>
References: <OFBC2106C8.7A59FA6B-ON85257FBC.0056D26D-85257FBC.0057E1BA@ria.buffalo.edu>
Message-ID: <489080B2-DFA7-44D5-9883-9B4247203A75@dcn.davis.ca.us>

Scalar values in R are just vectors of length 1. The "promotion" you are thinking of is "recycling" that automatically occurs when vectors of different lengths are supplied to certain operations. 

One shortcut might be to put them all into a data frame using the data.frame() function.  Otherwise, I think the rep() function and some conditional code would be needed. 
-- 
Sent from my phone. Please excuse my brevity.

On May 23, 2016 8:59:55 AM PDT, JLucke at ria.buffalo.edu wrote:
>R users: 
>
>Suppose I have a function that takes three numeric arguments x, y,  and
>z, 
>any of which may be scalars or vectors.
>Suppose further that the user takes one of the arguments, say y, as a 
>vector with the other two as scalars.
>Is there an existing R function that will promote the other two
>arguments 
>to vectors of the same size?
>
>I know in most cases this is not a problem as the promotion is
>automatic. 
>I need this for a function I am writing
>and I don't want to write any additional code to do this if I can help
>it.
>
>Joe
>Joseph F. Lucke, PhD
>Senior Statistician
>Research Institute on Addictions
>University at Buffalo
>State University of New York
>1021 Main Street
>Buffalo, NY  14203-1016
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Mon May 23 18:25:26 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 23 May 2016 11:25:26 -0500
Subject: [R] promoting scalar arguments to vectors in a function
In-Reply-To: <OFBC2106C8.7A59FA6B-ON85257FBC.0056D26D-85257FBC.0057E1BA@ria.buffalo.edu>
References: <OFBC2106C8.7A59FA6B-ON85257FBC.0056D26D-85257FBC.0057E1BA@ria.buffalo.edu>
Message-ID: <D301356B-8629-4DC2-83D4-C86469A2122D@me.com>

On May 23, 2016, at 10:59 AM, JLucke at ria.buffalo.edu wrote:
> 
> R users: 
> 
> Suppose I have a function that takes three numeric arguments x, y,  and z, 
> any of which may be scalars or vectors.
> Suppose further that the user takes one of the arguments, say y, as a 
> vector with the other two as scalars.
> Is there an existing R function that will promote the other two arguments 
> to vectors of the same size?
> 
> I know in most cases this is not a problem as the promotion is automatic. 
> I need this for a function I am writing
> and I don't want to write any additional code to do this if I can help it.
> 
> Joe


For a general overview of R's recycling approach, see:

  https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Vector-arithmetic

and:

  https://cran.r-project.org/doc/manuals/r-release/R-intro.html#The-recycling-rule

The question is what type of error checking you want to embed in your function, if the lengths of each argument are not the same and that would be a problem. Do you want to presume that a user will pass arguments that fit your a priori expectation, or protect against the possibility that they do not?

What would you do if y is a vector of length 6, x is a vector of length 1 and z is a vector of length 8?

R's default rules would replicate 'x' 8 times (e.g. rep(x, 8)), while extending 'y' by 2 (e.g. y <- y[c(1:6, 1:2)]), so that both have length(z).

You can use something along the lines of:

Max.Len <- max(length(x), length(y), length(z))
x <- rep(x, length.out = Max.Len)
y <- rep(y, length.out = Max.Len)
z <- rep(z, length.out = Max.Len)

which will recycle each as may be needed so that they have a common length.

Only you will know, given your function, if that might result in problems in whatever result your function is intended to generate.

Regards,

Marc Schwartz


From dylan.keenan at gmail.com  Mon May 23 16:32:10 2016
From: dylan.keenan at gmail.com (Dylan Keenan)
Date: Mon, 23 May 2016 14:32:10 +0000
Subject: [R] Vectors, Loops, Rnorm and KS-Testing
In-Reply-To: <BLU437-SMTP62AFCF7B299A3A2D0CFAAF8B4E0@phx.gbl>
References: <BLU437-SMTP62AFCF7B299A3A2D0CFAAF8B4E0@phx.gbl>
Message-ID: <CAOToiXbohJr49aQK9=4Jcg=k0FOVP0psCMJ5MF1yj7vESksHbQ@mail.gmail.com>

Use 'replicate.'


> replicate(n1, mean(rnorm(n2, mean, sd)))

Will compute return a column vector of length n1, each entry of which is
the mean of n2 random normal variables with mean and sd specified by the
arguments of rnorm.



On Mon, May 23, 2016 at 10:25 AM Nicoletta Sabov <nicoletta.sabov at hotmail.de>
wrote:

> Hi there,
>
> I need a function, that calculates the mean of a desired amount of
> normally distributed numbers and repeats this process for a desired number
> of repetitions. The function should return only a single vector consisting
> solely of the calculated means. Also the user of this function must be able
> to specify the parameters of the normal distribution used while calculating
> the means. I need this function for the Kolmogorov Smirnov Test.
> I am a total beginner, so far I only have come to this point:
>
> kolmo <- function(x, mean, sd, rep){
>
>   for(i in rep){
>     cat(mean(rnorm(x, mean, sd)))
>
> }}
> This returns a simple number, but I do need a vector to be returned.
> Thanks a lot in advance!
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ravi.varadhan at jhu.edu  Mon May 23 17:39:20 2016
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Mon, 23 May 2016 15:39:20 +0000
Subject: [R] Linear Regressions with non-negativity constraint
Message-ID: <d3e1323df37e4c3b87d0b5226658598b@ESGEBEX10.win.ad.jhu.edu>

Hi,

Take a look at the package "ic.infer" by Ulrike Gromping.

https://www.jstatsoft.org/article/view/v033i10

Best,
Ravi

Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg)
Associate Professor,  Department of Oncology
Division of Biostatistics & Bionformatics
Sidney Kimmel Comprehensive Cancer Center
Johns Hopkins University
550 N. Broadway, Suite 1111-E
Baltimore, MD 21205
410-502-2619


	[[alternative HTML version deleted]]


From hokut1 at yahoo.com  Mon May 23 19:25:55 2016
From: hokut1 at yahoo.com (oslo)
Date: Mon, 23 May 2016 17:25:55 +0000 (UTC)
Subject: [R] Choosing rows
In-Reply-To: <20160522123520.Horde.sAzcaYYDx5NUX5gf6zesx10@mail.sapo.pt>
References: <709946481.355864.1463887872593.JavaMail.yahoo.ref@mail.yahoo.com>
	<709946481.355864.1463887872593.JavaMail.yahoo@mail.yahoo.com>
	<20160522123520.Horde.sAzcaYYDx5NUX5gf6zesx10@mail.sapo.pt>
Message-ID: <763609346.1040209.1464024355110.JavaMail.yahoo@mail.yahoo.com>

Hi Rui;
Thanks so much for this. It works perfectly.
Regards,Oslo 

    On Sunday, May 22, 2016 7:35 AM, "ruipbarradas at sapo.pt" <ruipbarradas at sapo.pt> wrote:
 

 Hello,

First of all, it's better to post data using ?dput. Below, I give an example of that? in the lines structure(...).
dat <-
structure(list(rs = c("?? rs941873? ", "?? rs634552? ", "?? rs11107175? ",
"?? rs12307687? ", "?? rs3917155? ", "?? rs1600640? ", "?? rs2871865? ",
"?? rs2955250? ", "?? rs228758? ", "?? rs224333? ", "?? rs4681725? ",
"?? rs7652177? ", "?? rs925098? ", "?? rs1662837? ", "?? rs10071837? "
), n0 = c(81139462, 75282052, 94161719, 47175866, 76444685, 84603034,
99194896, 61959740, 42148205, 34023962, 56692321, 171969077,
17919811, 82168889, 33381581), Pvalue = c(1.52e-07, 0.108, 0.0285,
0.123, 0.68, 0.000275, 0.0709, 0.0317, 0.0772, 0.021, 0.000445,
0.000634, 5.55e-09, 8.66e-05, 0.000574), V1 = c("rs941873", "rs941873",
"rs941873", "rs12307687", "rs941873", "rs12307687", "rs12307687",
"rs12307687", "rs12307687", "rs10071837", "rs10071837", "rs10071837",
"rs925098", "rs925098", "rs925098")), .Names = c("rs", "n0",
"Pvalue", "V1"), row.names = c(NA, -15L), class = "data.frame")

Now, if I understand correctly, the following might do what you want.


tmp <- split(dat[, "Pvalue"], dat[, "V1"])
idx <- unlist(lapply(tmp, function(x) x == min(x)))[order(order(dat[, "V1"]))]
rm(tmp)
result <- dat[idx, ]
result

Hope this helps,

Rui Barradas
?Citando oslo via R-help <r-help at r-project.org>:
Hi all;
I have a big data set (a small part is given below) and V1 column has repeated info in it. That is rs941873, rs12307687... are repeating many times. I need choose only one SNP (in first column named rs) which has the smallest ?Pvalue withing V1 column. That is I need choose only one SNP for repeated names in V1 which has the smallest Pvalue.
Your helps are truly appreciated,Oslo

| ?rs? | n0 | Pvalue | V1 |
|? ?rs941873? | 81139462 | 1.52E-07 | rs941873 |
|? ?rs634552? | 75282052 | 1.08E-01 | rs941873 |
|? ?rs11107175? | 94161719 | 2.85E-02 | rs941873? |
|? ?rs12307687? | 47175866 | 1.23E-01 | rs12307687 |
|? ?rs3917155? | 76444685 | 6.80E-01 | rs941873? |
|? ?rs1600640? | 84603034 | 2.75E-04 | rs12307687 |
|? ?rs2871865? | 99194896 | 7.09E-02 | rs12307687 |
|? ?rs2955250? | 61959740 | 3.17E-02 | rs12307687 |
|? ?rs228758? | 42148205 | 7.72E-02 | rs12307687 |
|? ?rs224333? | 34023962 | 2.10E-02 | rs10071837 |
|? ?rs4681725? | 56692321 | 4.45E-04 | rs10071837 |
|? ?rs7652177? | 171969077 | 6.34E-04 | rs10071837 |
|? ?rs925098? | 17919811 | 5.55E-09 | rs925098 |
|? ?rs1662837? | 82168889 | 8.66E-05 | rs925098? |
|? ?rs10071837? | 33381581 | 5.74E-04 | rs925098? |


? ? ? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.htmland provide commented, minimal, self-contained, reproducible code.

?

  
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon May 23 20:16:07 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 23 May 2016 11:16:07 -0700 (PDT)
Subject: [R] Merging 2 files with different timestamp
In-Reply-To: <CAEGXkYVfHyayZgofV_zxOOrHXUXjreUZ5ZCf4cGn+VYkqGv-mQ@mail.gmail.com>
References: <CAEGXkYXxDQJR81Q+q6AQTuT69E6gAwd-v9UHS7qAwByLQXdNfg@mail.gmail.com>
	<CAEGXkYVgn2WRoApwRKhDROckJwKBzT3nuu1wdLmpR6smF4E_ww@mail.gmail.com>
	<BEDF8F69-13E9-4D29-A4EB-BD5B99F78A6C@dcn.davis.ca.us>
	<CAEGXkYVfHyayZgofV_zxOOrHXUXjreUZ5ZCf4cGn+VYkqGv-mQ@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1605231107070.89184@pedal.dcn.davis.ca.us>

You have by now seen some other responses on the list. Keeping the list 
included will insure you continue to get mulitple eyes looking at the 
problem and will benefit others trying to use the answers.

Two comments:

1) Your first format includes a specification for seconds. If that is 
nonzero at any point you could have difficulty aligning that data with the 
second format. In some cases this may be desirable, in other cases you may 
prefer to use some kind of "nearest minute" calculation such as 
trunc.POSIXt or round.POSIXt might yield. If you do so, be aware that 
those functions always return POSIXlt, and efficient computation is 
usually obtained with POSIXct, so convert if you have to.

2) It is not necessary to convert back to character as Jim Holtman 
suggests in order to merge the data... working with POSIXct data type 
directly will be more efficient. I would warn against using POSIXlt for 
merging, though, for poor efficiency reasons.

On Mon, 23 May 2016, Bhaskar Mitra wrote:

> Dear Jeff,
> Time zone is UTC. No, daylight savings time does not?apply.
> 
> regards,
> bhaskar
> 
> On Sun, May 22, 2016 at 4:10 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>       What time zone are these data in? Does daylight savings
>       adjustment apply?
>       --
>       Sent from my phone. Please excuse my brevity.
>
>       On May 22, 2016 9:48:08 AM PDT, Bhaskar Mitra
>       <bhaskar.kolkata at gmail.com> wrote:
> 
> Hello,
> My apologies for the earlier posting. There was an error with regard to my
> query :
> I am trying to merge two text files by using the timestamp
> header for both the files:
> The first file has the following format for the timestamp:"27-Dec-12 23H
> 30M 0S"
> Timestamp for the second file : 2012-12-27 2330.
> I am having problems by converting from one timestamp format to another.
> Any suggestions/help in this regard?
> regards,
> On Sun, May 22, 2016 at 12:40 PM, Bhaskar Mitra <bhaskar.kolkata at gmail.com>
> wrote:
>  Hello, I am trying to merge two text files by using the timestamp
>  header for both the files:
>  The first file has the following format for the timestamp:"2012-01-01
>  23:30:00 UTC"
>  Timestamp for the second file : 2012-01-01 2330.
>  I am having problems by converting from one timestamp format to another.
>  Any suggestions/help in this regard?
>  regards,
>  [[alternative HTML version deleted]]
> ____________________________________________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------

From jan.kacaba at gmail.com  Mon May 23 21:26:59 2016
From: jan.kacaba at gmail.com (Jan Kacaba)
Date: Mon, 23 May 2016 21:26:59 +0200
Subject: [R] print all variables inside function
Message-ID: <CAHby=D1NB24-aqfBvk7omFN6VSy45d9rHj0G1wd7L84wfsgLLQ@mail.gmail.com>

Hello dear R-help

I would like to use some short and simple names multiple times inside
one script without collisions. I need to wrap the variables inside
some object. I know I can use class function or environment. For
example as follows:

exmp1<-function(){

########
# knowns
pa=0.35
pb=0.35
pc=0.30
pad=0.015
pbd=0.010
pcd=0.020
########

########
# unknowns
pd=pa*pad+pb*pbd+pc*pcd
pdc=pc*pcd/pd
pda=pa*pad/pd
pba=pb*pbd/pd
########

y<-c(pad=pad,pbd=pbd,pcd=pcd,pd=pd,pdc=pdc,pda=pda,pba=pba) # this
line I would like to automate so I don't have to write it every time
return(y)
}
output<-exmp1()

Is it somehow possible to print 'Unknows' and 'Knowns' from exmp1
function without the need of explicitly write the 'y' line which puts
all variables inside list? For example with an imaginary function
'fprint' which takes exmp1 as the input: fprint(exmp1).


From jvadams at usgs.gov  Mon May 23 21:33:24 2016
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 23 May 2016 14:33:24 -0500
Subject: [R] Filtering String Variables
In-Reply-To: <OFC973FC28.2EE4FE11-ONC1257FBC.0049D8AA-C1257FBC.0049FD6E@lotus.hawesko.de>
References: <OFC973FC28.2EE4FE11-ONC1257FBC.0049D8AA-C1257FBC.0049FD6E@lotus.hawesko.de>
Message-ID: <CAN5YmCEaXHpmhjjQuambe6eXpKvcfsB4sSiwL=HASMjnGhoQ8Q@mail.gmail.com>

George,

You are very close.  Try this ...

# make Debitor a character variable in the data frame
ds_example$Debitor <- as.character(ds_example$Debitor)

duplicates <- duplicated(ds_example$Debitor)
duplicated_debitors <- unique(ds_example$Debitor[duplicates])
ds_duplicates <- ds_example[ds_example$Debitor %in% duplicated_debitors, ]

Jean

On Mon, May 23, 2016 at 8:28 AM, <G.Maubach at weinwolf.de> wrote:

> # Hi All,
> #
> # I have the following data frame (example):
>
> Debitor <- c("968691", "968691", "968691",
>              "A04046", "A04046",
>              "L0006", "L0006", "L0006",
>              "L0023", "L0023",
>              "L0056", "L0056",
>              "L0094", "L0094", "L0094",
>              "L0124", "L0124",
>              "L0143",
>              "L0170",
>              "13459",
>              "473908",
>              "394704",
>              "4711",
>              "4712",
>              "4713")
> Debitor <- as.character(Debitor)
> var1 <- c(11, 12, 13,
>           14, 14,
>           12, 13, 14,
>           10, 11,
>           12, 12,
>           12, 12, 12,
>           15, 17,
>           11,
>           14,
>           12,
>           17,
>           13,
>           15,
>           16,
>           11)
> ds_example <- data.frame(Debitor, var1)
> ds_example$case_id <- 1:nrow(ds_example)
> ds_example <- ds_example[, sort(colnames(ds_example))]
> ds_example
>
> # I would like to generate a data frame that contains the duplicates AND
> the
> # corresponding non-duplicates to the duplicates.
> # For example, finding the duplicates with deliver case 2 and 3 but the
> list
> # should also contain case 1 because case 1 is the corresponding case to
> the
> # duplicate cases 2 and 3.
> # For the whole example dataset that would be:
> needed <- c(1, 1, 1,
>             1, 1,
>             1, 1, 1,
>             1, 1,
>             1, 1,
>             1, 1, 1,
>             1, 1,
>             0, 0, 0, 0, 0, 0, 0, 0)
> needed <- as.logical(needed)
> ds_example <- data.frame(ds_example, needed)
> ds_example
>
> # To find the duplicates and the corresponding non-duplicates
> duplicates <- duplicated(ds_example$Debitor)
>
> list_of_duplicated_debitors <- as.character(ds_example[duplicates,
> "Debitor"])
>
> filter_variable <- unique(list_of_duplicated_debitors)
>
> ds_duplicates <- ds_example["Debitor" == filter_variable]  # Result:
> dataset with 0 columns
>
> ds_duplicates <- ds_example["Debitor"] %in% filter_variable  # Result:
> FALSE
>
> # How can I create a dataset like this
>
> ds_example <- ds_example[needed, ]
> ds_example
>
> # using the Debitor IDs?
>
> Kind regards
>
> Georg Maubach
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon May 23 21:40:22 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 23 May 2016 15:40:22 -0400
Subject: [R] print all variables inside function
In-Reply-To: <CAHby=D1NB24-aqfBvk7omFN6VSy45d9rHj0G1wd7L84wfsgLLQ@mail.gmail.com>
References: <CAHby=D1NB24-aqfBvk7omFN6VSy45d9rHj0G1wd7L84wfsgLLQ@mail.gmail.com>
Message-ID: <6ee43c3d-b051-555a-f6ba-e7edabd94c79@gmail.com>

On 23/05/2016 3:26 PM, Jan Kacaba wrote:
> Hello dear R-help
>
> I would like to use some short and simple names multiple times inside
> one script without collisions. I need to wrap the variables inside
> some object. I know I can use class function or environment. For
> example as follows:
>
> exmp1<-function(){
>
> ########
> # knowns
> pa=0.35
> pb=0.35
> pc=0.30
> pad=0.015
> pbd=0.010
> pcd=0.020
> ########
>
> ########
> # unknowns
> pd=pa*pad+pb*pbd+pc*pcd
> pdc=pc*pcd/pd
> pda=pa*pad/pd
> pba=pb*pbd/pd
> ########
>
> y<-c(pad=pad,pbd=pbd,pcd=pcd,pd=pd,pdc=pdc,pda=pda,pba=pba) # this
> line I would like to automate so I don't have to write it every time
> return(y)
> }
> output<-exmp1()
>
> Is it somehow possible to print 'Unknows' and 'Knowns' from exmp1
> function without the need of explicitly write the 'y' line which puts
> all variables inside list? For example with an imaginary function
> 'fprint' which takes exmp1 as the input: fprint(exmp1).

Why create them first?  Just do something like this:

knowns <- c(
  pa=0.35
  pb=0.35
  pc=0.30
  pad=0.015
  pbd=0.010
  pcd=0.020)

Duncan Murdoch


From thierry.onkelinx at inbo.be  Mon May 23 21:46:56 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 23 May 2016 21:46:56 +0200
Subject: [R] print all variables inside function
In-Reply-To: <CAHby=D1NB24-aqfBvk7omFN6VSy45d9rHj0G1wd7L84wfsgLLQ@mail.gmail.com>
References: <CAHby=D1NB24-aqfBvk7omFN6VSy45d9rHj0G1wd7L84wfsgLLQ@mail.gmail.com>
Message-ID: <CAJuCY5yPvfLJpoUdW6nAiePT-B5BdjgP8RpoUdP1Tx5Bf8jMDA@mail.gmail.com>

Dear Jan,

This will return a list with all objects from within the function.

test <- function(){
  a <- 10
  b <- 3 * a + 1
  x <- -1
  output <- paste(objects(), objects(), sep = "=")
  output <- paste(output, collapse = ",")
  output <- paste("list(", output, ")")
  return(eval(parse(text = output)))
}
test()

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-05-23 21:26 GMT+02:00 Jan Kacaba <jan.kacaba at gmail.com>:

> Hello dear R-help
>
> I would like to use some short and simple names multiple times inside
> one script without collisions. I need to wrap the variables inside
> some object. I know I can use class function or environment. For
> example as follows:
>
> exmp1<-function(){
>
> ########
> # knowns
> pa=0.35
> pb=0.35
> pc=0.30
> pad=0.015
> pbd=0.010
> pcd=0.020
> ########
>
> ########
> # unknowns
> pd=pa*pad+pb*pbd+pc*pcd
> pdc=pc*pcd/pd
> pda=pa*pad/pd
> pba=pb*pbd/pd
> ########
>
> y<-c(pad=pad,pbd=pbd,pcd=pcd,pd=pd,pdc=pdc,pda=pda,pba=pba) # this
> line I would like to automate so I don't have to write it every time
> return(y)
> }
> output<-exmp1()
>
> Is it somehow possible to print 'Unknows' and 'Knowns' from exmp1
> function without the need of explicitly write the 'y' line which puts
> all variables inside list? For example with an imaginary function
> 'fprint' which takes exmp1 as the input: fprint(exmp1).
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From marceloperlin at gmail.com  Mon May 23 20:42:54 2016
From: marceloperlin at gmail.com (Marcelo Perlin)
Date: Mon, 23 May 2016 15:42:54 -0300
Subject: [R] Can I use PhantomJS or assume a firefox instalattion for
 usage with RSelenium in CRAN Machines?
In-Reply-To: <A7F9F46A-121B-4E75-B13D-447AFDE42255@comcast.net>
References: <CANMhtdz9bFR+5QaLW8sXxt6upduiayW-xn2xDrHphSkPMfBmPQ@mail.gmail.com>
	<A7F9F46A-121B-4E75-B13D-447AFDE42255@comcast.net>
Message-ID: <CANMhtdz9L_65wsbzzGX1B4SaiAE22B9a=NF4n9Ycsg0WFjDimQ@mail.gmail.com>

Thanks David,

I figured out a way to get the data I want without RSelenium.

Apreciate the help, though.

Best,



On Thu, May 19, 2016 at 8:51 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On May 19, 2016, at 7:49 AM, Marcelo Perlin <marceloperlin at gmail.com>
> wrote:
> >
> > Hi Guys,
> >
> > First time posting here.
> >
> > I have a CRAN package called GetTDData that downloads and reads public
> data
> > from a government website (
> > http://www.tesouro.fazenda.gov.br/tesouro-direto-balanco-e-estatisticas
> ).
> >
> > Recently (today), the website has changed its structure by removing
> > permanent links of the files and creating a "random" html address for the
> > files that really matter. This means that when I download the souce html
> > code, I don't have the information for the actual links, but just a bunch
> > of code.
> >
> > In the past I have dealed with this type of problem by forcing the
> > renderization of the page using RSelenium with firefox or PhantomJS and
> > then capturing the desired href locations.
> >
> > My question is, if integrate my code with RSelenium using firefox or
> > PhantonJS, will it pass on all arquitectures (win, linux, solaris) of
> CRAN?
>
> I dn't have a lot of experience at this but I can say that at least one
> person whose experience I trust recentlyreported in Rhelp that RSelenium
> tends to be a fragile interface. Nonetheless, he does use it on occasion
> and it clearly "works" on more than one platform. If your code is not
> confidential and the website has at least a guest login capacity, you could
> post it here and ask for trial runs on whatever platform(s) you may not
> have testing capacities for.
>
> >
> > --
> > Marcelo Perlin
> > Professor Adjunto | Escola de Administra??o
>
> --
>
> David Winsemius
> Alameda, CA, USA
>
>


-- 
Marcelo Perlin
Professor Adjunto | Escola de Administra??o
Universidade Federal do Rio Grande do Sul
Rua Washington Luiz, 855 | 90010-460| Porto Alegre RS| Brasil
Tel.: (51) 3308-3303 | www.ea.ufrgs.br
http://lattes.cnpq.br/3262699324398819
https://sites.google.com/site/marceloperlin/

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Mon May 23 23:03:54 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 23 May 2016 14:03:54 -0700
Subject: [R] print all variables inside function
In-Reply-To: <CAJuCY5yPvfLJpoUdW6nAiePT-B5BdjgP8RpoUdP1Tx5Bf8jMDA@mail.gmail.com>
References: <CAHby=D1NB24-aqfBvk7omFN6VSy45d9rHj0G1wd7L84wfsgLLQ@mail.gmail.com>
	<CAJuCY5yPvfLJpoUdW6nAiePT-B5BdjgP8RpoUdP1Tx5Bf8jMDA@mail.gmail.com>
Message-ID: <CAF8bMcZGf_zmhsM4vEvf2CU0Cz4K6mkxH7GUkrUOTe4Yxewnqw@mail.gmail.com>

If you really want to return all the objects in a function, I think it
is better to return as.list(environment()), perhaps adding the
all.names=TRUE argument to capture names starting with a dot.
I only have done this while debugging a function and then I
find it is more convenient to return just environment().

eval(parse(text="...")) will have problems when objects in the
environment have odd names, like 'Two words', '...', or '..1'.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, May 23, 2016 at 12:46 PM, Thierry Onkelinx <thierry.onkelinx at inbo.be
> wrote:

> Dear Jan,
>
> This will return a list with all objects from within the function.
>
> test <- function(){
>   a <- 10
>   b <- 3 * a + 1
>   x <- -1
>   output <- paste(objects(), objects(), sep = "=")
>   output <- paste(output, collapse = ",")
>   output <- paste("list(", output, ")")
>   return(eval(parse(text = output)))
> }
> test()
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2016-05-23 21:26 GMT+02:00 Jan Kacaba <jan.kacaba at gmail.com>:
>
> > Hello dear R-help
> >
> > I would like to use some short and simple names multiple times inside
> > one script without collisions. I need to wrap the variables inside
> > some object. I know I can use class function or environment. For
> > example as follows:
> >
> > exmp1<-function(){
> >
> > ########
> > # knowns
> > pa=0.35
> > pb=0.35
> > pc=0.30
> > pad=0.015
> > pbd=0.010
> > pcd=0.020
> > ########
> >
> > ########
> > # unknowns
> > pd=pa*pad+pb*pbd+pc*pcd
> > pdc=pc*pcd/pd
> > pda=pa*pad/pd
> > pba=pb*pbd/pd
> > ########
> >
> > y<-c(pad=pad,pbd=pbd,pcd=pcd,pd=pd,pdc=pdc,pda=pda,pba=pba) # this
> > line I would like to automate so I don't have to write it every time
> > return(y)
> > }
> > output<-exmp1()
> >
> > Is it somehow possible to print 'Unknows' and 'Knowns' from exmp1
> > function without the need of explicitly write the 'y' line which puts
> > all variables inside list? For example with an imaginary function
> > 'fprint' which takes exmp1 as the input: fprint(exmp1).
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From anonymous at place.de  Mon May 23 22:37:22 2016
From: anonymous at place.de (<Anonymous sender (deleted by GDPR)>)
Date: Mon, 23 May 2016 22:37:22 +0200
Subject: [R] WARNING: Method convertPointFromBase
Message-ID: <DEFEF6A4-B547-4738-9E4C-9668A540B582@uni-ulm.de>

Hello,
I?ve noticed a Warning, while working with both the R console and a document window in R:
2016-05-23 22:16:17.507 R[2985:466607] *** WARNING: Method convertPointFromBase: in class NSView is deprecated on 10.7 and later. It should not be used in new applications. 

I have Version R 3.3.0 GUI 1.68 Mavericks build (7202) installed on my Macbook Pro running Mac OS X 10.11.5 (15F34).

Is this something to worry about? Can anyone help me out? 

I downloaded R from the official servers. 

Kind regards and thank you in advance  !


From jdnewmil at dcn.davis.ca.us  Mon May 23 23:51:25 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 23 May 2016 14:51:25 -0700
Subject: [R] WARNING: Method convertPointFromBase
In-Reply-To: <DEFEF6A4-B547-4738-9E4C-9668A540B582@uni-ulm.de>
References: <DEFEF6A4-B547-4738-9E4C-9668A540B582@uni-ulm.de>
Message-ID: <E0D6EDD1-765B-4658-99B4-367840B787CD@dcn.davis.ca.us>

This is almost certainly a message from a contributed package,  not from R itself. Please figure out which package you are using and read the documentation for that package. 
-- 
Sent from my phone. Please excuse my brevity.

On May 23, 2016 1:37:22 PM PDT, <Anonymous sender (deleted by GDPR)> <anonymous at place.de> wrote:
>Hello,
>I?ve noticed a Warning, while working with both the R console and a
>document window in R:
>2016-05-23 22:16:17.507 R[2985:466607] *** WARNING: Method
>convertPointFromBase: in class NSView is deprecated on 10.7 and later.
>It should not be used in new applications. 
>
>I have Version R 3.3.0 GUI 1.68 Mavericks build (7202) installed on my
>Macbook Pro running Mac OS X 10.11.5 (15F34).
>
>Is this something to worry about? Can anyone help me out? 
>
>I downloaded R from the official servers. 
>
>Kind regards and thank you in advance  !
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Tue May 24 00:38:13 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 24 May 2016 00:38:13 +0200
Subject: [R] WARNING: Method convertPointFromBase
In-Reply-To: <E0D6EDD1-765B-4658-99B4-367840B787CD@dcn.davis.ca.us>
References: <DEFEF6A4-B547-4738-9E4C-9668A540B582@uni-ulm.de>
	<E0D6EDD1-765B-4658-99B4-367840B787CD@dcn.davis.ca.us>
Message-ID: <2B810ACF-6707-42F4-A977-81066003F3F3@gmail.com>


> On 23 May 2016, at 23:51 , Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> This is almost certainly a message from a contributed package,  not from R itself. Please figure out which package you are using and read the documentation for that package. 

Nope, it comes from OSX. AFAIR, it is something about supporting versions back to 10.6 (Snow Leopard) in the same binary, and the thing that works in 10.6 got deprecated in later versions. It's something that we probably want to fix (something about resolution independence, making a difference with hi-res displays), but I'm unsure whether it can be done without dropping support for the older versions. I think the warning is mostly harmless until Apple drops supporting the function entirely.


> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On May 23, 2016 1:37:22 PM PDT, <Anonymous sender (deleted by GDPR)> <anonymous at place.de> wrote:
>> Hello,
>> I?ve noticed a Warning, while working with both the R console and a
>> document window in R:
>> 2016-05-23 22:16:17.507 R[2985:466607] *** WARNING: Method
>> convertPointFromBase: in class NSView is deprecated on 10.7 and later.
>> It should not be used in new applications. 
>> 
>> I have Version R 3.3.0 GUI 1.68 Mavericks build (7202) installed on my
>> Macbook Pro running Mac OS X 10.11.5 (15F34).
>> 
>> Is this something to worry about? Can anyone help me out? 
>> 
>> I downloaded R from the official servers. 
>> 
>> Kind regards and thank you in advance  !
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From nsit315 at aucklanduni.ac.nz  Tue May 24 00:43:26 2016
From: nsit315 at aucklanduni.ac.nz (Neny Sitorus)
Date: Tue, 24 May 2016 10:43:26 +1200
Subject: [R] need help to convert animal ID to a factor
In-Reply-To: <CALjSv_eh+GZ1CWsuzWW5Fe+MNZWv8+urgSZq5F3xM46TRXhmjg@mail.gmail.com>
References: <CALjSv_eh+GZ1CWsuzWW5Fe+MNZWv8+urgSZq5F3xM46TRXhmjg@mail.gmail.com>
Message-ID: <CALjSv_cV9VuP4EQe-KmgjaztAV-vsumbyCYTAsvXaoMNh-FxJA@mail.gmail.com>

Thanks for your advise.
Just wondering, since I have to analyse my data with "Mixed model analysis
in R"
and I'm not familiar at all with this software, just try to use it within a
week and need to write my analysis result as soon as I can, could you
please advise me of what does mixed model analysis mean?


Kind regards,
Neny

On 23 May 2016 at 16:46, Neny Sitorus <nsit315 at aucklanduni.ac.nz> wrote:

> Hi,
>
> I was trying to convert my animal ID experiment (ID) to factor to get the
> ggboxplot, previously it was working well.
> But since yesterday it displayed "Error" every time I tried to re-run it.
> Could you help me in this issue?
>
>
> # convert rat ID to factor
> Leak.df <- toFactor(Leak.df, id.var=c("ID", "Time"))
>
> From Console:
> > ets.df <- toFactor(ets.df, id.var=c("ID", "Time"))
> Error: could not find function "toFactor"
>
> Looking forward for your reply.
>
>
> Kind regards,
> Neny
>
> On 23 May 2016 at 15:59, Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Okay, perhaps if you try this:
>>
>> cellcontrol<-
>>  loadNetwork("C:/Users/mohammad/Documents/cellcontrol.txt")
>> stateTransition(cellcontrol, rep(1,11))
>>
>> Obviously this is a guess, but it might help.
>>
>> Jim
>>
>>
>> On Mon, May 23, 2016 at 1:55 PM, mohammad alsharaiah
>> <mohdsharaiah at gmail.com> wrote:
>> > Hi jim ,
>> > first of all iwant to thank you for your reply.
>> > the object "cellcontrol" its a network that i created it by using
>> boolnet
>> > package. when i call the network its loaded inside the R workspace
>> screen.
>> > but i got this error when i want to work on it.
>> >
>> > boolnet allow to us to create the network and write a logical rules  in
>> text
>> > file, then we can loaded it as a network inside R to study the dynamic
>> > behavior.
>> >
>> > but i can not work on it because this error and converting it to data
>> file.
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > Mohammad
>> >
>> >
>> > On Sun, May 22, 2016 at 8:40 PM, Jim Lemon <drjimlemon at gmail.com>
>> wrote:
>> >>
>> >> Hi Mohammad,
>> >> I don't have the BoolNet package installed, but the error means that
>> >> the object "cellcontrol" is not there for the function to use. It
>> >> should be a network "generated by generateRandomNKNetwork, or
>> >> reconstructed by reconstructNetwork" as detailed in the help pages.
>> >>
>> >> Jim
>> >>
>> >>
>> >> On Mon, May 23, 2016 at 11:07 AM, mohammad alsharaiah
>> >> <mohdsharaiah at gmail.com> wrote:
>> >> > Hi,
>> >> >
>> >> > every one , im using Boolnet package inside R environment to create a
>> >> > boolean network.
>> >> >
>> >> > after i create a text file for the Boolean network  and  i loaded it
>> by
>> >> > using R  by using this command:
>> >> >
>> >> >  > library(BoolNet)
>> >> >> loadNetwork("C:/Users/mohammad/Documents/cellcontrol.txt")
>> >> >
>> >> > then its loaded inside R screen. But when i started to do some of
>> tasks
>> >> > on
>> >> > this network every time i got this error message, this is an example
>> how
>> >> > i
>> >> > work on the created network and get the error.
>> >> >
>> >> >> stateTransition(cellcontrol, rep(1,11))
>> >> > Error in inherits(network, "BooleanNetwork") :
>> >> >   object 'cellcontrol' not found
>> >> >>
>> >> >
>> >> > please can any one help me to solve this error .
>> >> >
>> >> > Reagdrs,
>> >> >
>> >> >
>> >> >
>> >> >
>> >> > *Mohammad *
>> >> >
>> >> >         [[alternative HTML version deleted]]
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide
>> >> > http://www.R-project.org/posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From axel.urbiz at gmail.com  Tue May 24 02:17:00 2016
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Mon, 23 May 2016 20:17:00 -0400
Subject: [R] Defining contrasts within function
Message-ID: <CAAyVsXJMCsvLR6abhoi_EttwxEbmEvn-aLNyjR51zF046XMOgQ@mail.gmail.com>

Dear All,

I'd like to change the options("contrasts") within a function, such that
"identity" contrasts
are created for unordered factors. I'm following the idea shown below,
which works fine.

However, when I include these functions in a package (with `contr` being
exported, but
`contr_identity` not exported as it is not intended to be called directly
by the user), I get
the following error message. And this is after loading and attaching the
package with library(). Why is `contr_identity` not found?

Error in get(ctr, mode = "function", envir = parent.frame()) :
  object 'contr_identity' of mode 'function' was not found


contr <- function(x) {
ocontrasts <- options(contrasts = c(unordered = "contr_identity", ordered =
"contr.diff"))
on.exit(options(ocontrasts))
contrasts(x)
}

contr_identity <- function(n, contrasts) {
    contr.treatment(n, contrasts = FALSE)
}

f <- gl(2, 8, labels = c("Control", "Treat"))
contrasts(f)
contr(f)

Thanks,
Axel.

	[[alternative HTML version deleted]]


From todd.taylor at pnnl.gov  Mon May 23 23:37:28 2016
From: todd.taylor at pnnl.gov (Taylor, Z Todd)
Date: Mon, 23 May 2016 21:37:28 +0000
Subject: [R] Replicating the SPlus "twoway" function
Message-ID: <96074A28AAA5424983F8DA582FEDD00F1A5FC5B5@EX10MBOX02.pnnl.gov>

Is there a package somewhere that replicates the SPlus twoway() function?  That function models a 2-d data matrix, which may contain NAs, as

x[i,j] = grand.effect + row.effect[i] + col.effect[j] + resid[i,j]

I'm sort of resurrecting some ancient S code and it would be handy if a twoway() function were available in R.  I've googled and RSiteSearch'd, but maybe there's something out there that goes by another name?

Thanks.

--Todd
--
Z. Todd Taylor
Pacific Northwest National Laboratory
Why are they called 'speed' bumps?



	[[alternative HTML version deleted]]


From rmh at temple.edu  Tue May 24 03:04:29 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Mon, 23 May 2016 21:04:29 -0400
Subject: [R] Replicating the SPlus "twoway" function
In-Reply-To: <96074A28AAA5424983F8DA582FEDD00F1A5FC5B5@EX10MBOX02.pnnl.gov>
References: <96074A28AAA5424983F8DA582FEDD00F1A5FC5B5@EX10MBOX02.pnnl.gov>
Message-ID: <CAGx1TMCNwh6rCcPSfU-44Bv7rb+JEBPP9C_vg0_f8dms-1ugTA@mail.gmail.com>

In the stats package
?medpolish


On Mon, May 23, 2016 at 5:37 PM, Taylor, Z Todd <todd.taylor at pnnl.gov> wrote:
> Is there a package somewhere that replicates the SPlus twoway() function?  That function models a 2-d data matrix, which may contain NAs, as
>
> x[i,j] = grand.effect + row.effect[i] + col.effect[j] + resid[i,j]
>
> I'm sort of resurrecting some ancient S code and it would be handy if a twoway() function were available in R.  I've googled and RSiteSearch'd, but maybe there's something out there that goes by another name?
>
> Thanks.
>
> --Todd
> --
> Z. Todd Taylor
> Pacific Northwest National Laboratory
> Why are they called 'speed' bumps?
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jacksonmrodrigues at gmail.com  Tue May 24 03:57:32 2016
From: jacksonmrodrigues at gmail.com (Jackson Rodrigues)
Date: Mon, 23 May 2016 22:57:32 -0300
Subject: [R] heat color on age visible on ordination
Message-ID: <CAPL76w8Pi42i1Rp9fvVACw7z1jS--0=ChNBFJA3FRUj_9Dsh9A@mail.gmail.com>

Hi everybody,

I have a big matrix spread over a long time period.
I would like to make a ordination plot (PCA, CA, DCA etc) of this matrix
and look for patterns on time by exploring a color scheme (I have heat
color in mind).
The idea is to use a progressive color scheme ranging from red (the oldest
age) until purple (the youngest one). Then, make a ordination and see if
the similar colors are plotted together, if so , I would have a pattern on
time easily identifiable on 2 dimensions.

Let me give an hypothetical case to you.

mat5 <- matrix(rnorm(2000), ,4) #I have a matrix
mat5
seq<-seq(1, 50000, by = 100) # I have a time sequence of 500 dates ranging
from 50000 to 1
seq

rownames(mat5) <- c(seq ) # making ages the row names of the matrix

library("vegan")
test.pca<-rda(mat5) # Ordination (PCA)

plot(test.pca, scaling=-3) # In this plot I would like to have the old ages
ranging from red (age 50000) to purple (age 1)

Would that be possible??

Thank you all for any help

Jackson M. Rodrigues

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue May 24 04:08:43 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 24 May 2016 12:08:43 +1000
Subject: [R] heat color on age visible on ordination
In-Reply-To: <CAPL76w8Pi42i1Rp9fvVACw7z1jS--0=ChNBFJA3FRUj_9Dsh9A@mail.gmail.com>
References: <CAPL76w8Pi42i1Rp9fvVACw7z1jS--0=ChNBFJA3FRUj_9Dsh9A@mail.gmail.com>
Message-ID: <CA+8X3fUr3rzDAZZL=gPc0ZnHG0nM1dt4BpLG_Npf6xR1b9001g@mail.gmail.com>

Hi Jackson,
One way to assign colors to values is:

library(plotrix)
ages<-seq(1, 50000, by = 100)
agecol<-color.scale(ages,extremes=c("purple","red"))

Then just use "agecol" for your point colors.

Jim


On Tue, May 24, 2016 at 11:57 AM, Jackson Rodrigues
<jacksonmrodrigues at gmail.com> wrote:
> Hi everybody,
>
> I have a big matrix spread over a long time period.
> I would like to make a ordination plot (PCA, CA, DCA etc) of this matrix
> and look for patterns on time by exploring a color scheme (I have heat
> color in mind).
> The idea is to use a progressive color scheme ranging from red (the oldest
> age) until purple (the youngest one). Then, make a ordination and see if
> the similar colors are plotted together, if so , I would have a pattern on
> time easily identifiable on 2 dimensions.
>
> Let me give an hypothetical case to you.
>
> mat5 <- matrix(rnorm(2000), ,4) #I have a matrix
> mat5
> seq<-seq(1, 50000, by = 100) # I have a time sequence of 500 dates ranging
> from 50000 to 1
> seq
>
> rownames(mat5) <- c(seq ) # making ages the row names of the matrix
>
> library("vegan")
> test.pca<-rda(mat5) # Ordination (PCA)
>
> plot(test.pca, scaling=-3) # In this plot I would like to have the old ages
> ranging from red (age 50000) to purple (age 1)
>
> Would that be possible??
>
> Thank you all for any help
>
> Jackson M. Rodrigues
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Tue May 24 05:37:34 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 24 May 2016 13:37:34 +1000
Subject: [R] heat color on age visible on ordination
In-Reply-To: <CAPL76w-zx7ACQYEgPeQCEKHy5QO7yf6+zJm4Ty7w6w6RkX8Jhg@mail.gmail.com>
References: <CAPL76w8Pi42i1Rp9fvVACw7z1jS--0=ChNBFJA3FRUj_9Dsh9A@mail.gmail.com>
	<CA+8X3fUr3rzDAZZL=gPc0ZnHG0nM1dt4BpLG_Npf6xR1b9001g@mail.gmail.com>
	<CAPL76w-zx7ACQYEgPeQCEKHy5QO7yf6+zJm4Ty7w6w6RkX8Jhg@mail.gmail.com>
Message-ID: <CA+8X3fWr5Y1Kp1sewmx+JcPH2-uTF8+4u+ygj4w05Pb3SRpdJA@mail.gmail.com>

Hi Jackson,
I'll take a wild guess at "What is wrong?". You only got one end of
the color vector, probably the purple end. As my recollection of
principal components analysis is of a data reduction method, you
probably have a lot fewer than 500 points on your plot. If you only
have, say, 50 values to plot, you will only use up 50 colors. If this
is a good guess, you will have to link the colors to the values you
are plotting, not the original values. I have very little idea of what
either set of values is like, but you may be able to work it out.

Jim


On Tue, May 24, 2016 at 12:34 PM, Jackson Rodrigues
<jacksonmrodrigues at gmail.com> wrote:
> Hi Jim,
>
> thank you very much!
> It seems to be very easy!
>
> Another question, how to implement it on ordination? What is wrong?
>
> test.pca<-rda(mat5)
> plot(test.pca, col=agecol,display="sites", cex=1, type="p",scaling=-3)
>
> Thank you very much again
>
> Jackson
>
> 2016-05-23 23:08 GMT-03:00 Jim Lemon <drjimlemon at gmail.com>:
>>
>> Hi Jackson,
>> One way to assign colors to values is:
>>
>> library(plotrix)
>> ages<-seq(1, 50000, by = 100)
>> agecol<-color.scale(ages,extremes=c("purple","red"))
>>
>> Then just use "agecol" for your point colors.
>>
>> Jim
>>
>>
>> On Tue, May 24, 2016 at 11:57 AM, Jackson Rodrigues
>> <jacksonmrodrigues at gmail.com> wrote:
>> > Hi everybody,
>> >
>> > I have a big matrix spread over a long time period.
>> > I would like to make a ordination plot (PCA, CA, DCA etc) of this matrix
>> > and look for patterns on time by exploring a color scheme (I have heat
>> > color in mind).
>> > The idea is to use a progressive color scheme ranging from red (the
>> > oldest
>> > age) until purple (the youngest one). Then, make a ordination and see if
>> > the similar colors are plotted together, if so , I would have a pattern
>> > on
>> > time easily identifiable on 2 dimensions.
>> >
>> > Let me give an hypothetical case to you.
>> >
>> > mat5 <- matrix(rnorm(2000), ,4) #I have a matrix
>> > mat5
>> > seq<-seq(1, 50000, by = 100) # I have a time sequence of 500 dates
>> > ranging
>> > from 50000 to 1
>> > seq
>> >
>> > rownames(mat5) <- c(seq ) # making ages the row names of the matrix
>> >
>> > library("vegan")
>> > test.pca<-rda(mat5) # Ordination (PCA)
>> >
>> > plot(test.pca, scaling=-3) # In this plot I would like to have the old
>> > ages
>> > ranging from red (age 50000) to purple (age 1)
>> >
>> > Would that be possible??
>> >
>> > Thank you all for any help
>> >
>> > Jackson M. Rodrigues
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
>
> Jackson M. Rodrigues
> Department of Palynology and Climate Dynamics
> Albrecht-von-Haller-Institute for Plant Sciences
> Georg-August-University G?ttingen
> Untere Karspuele 2
> 37073 G?ttingen/Germany
> Tel.:   0049 (0) 176 8186 4994
> Web: http://www.uni-goettingen.de/en/306700.html
>
> "In order to succeed, we must first believe that we can."
> Nikos Kazantzakis


From david.n.menezes at gmail.com  Tue May 24 03:57:49 2016
From: david.n.menezes at gmail.com (David Menezes)
Date: Tue, 24 May 2016 09:57:49 +0800
Subject: [R] Quantmod - modify decimal places
Message-ID: <CA+r16mzPRiqkAHhaJ1JGPAeHcwLAc=acK7RFvDKstdfQ4uZ4PA@mail.gmail.com>

Hi

Apologies if this has already been asked and answered or if I've labelled
the subject incorrectly but I can't find a solution using the search
function for this group; the vignette documentation for quantmod or general
google searches.

I'm attempting to use quantmod to download foreign currency exchange
rates.  I'm using the call "getFX" however the output results are always
restricted to 4 decimal places.  Generally this is fine but when comparing
developing and mature economies this can lead to no answer being returned
due to how weak a specific currency is (in relative terms).

For example, compare the following two results for converting USD to
Vietnamese Dong (VND):

a)      *1/getFX("USD/VND",from="2016-05-22",to ="2016-05-22", source =
"oanda", auto.assign=FALSE)*

 This yields?

                USD.VND

2016-05-22 4.473272e-05

 However my preferred call would be:

 b)*      getFX("VND/USD",from="2016-05-22",to ="2016-05-22", source =
"oanda", auto.assign=FALSE)*

 However this yields a zero result:

VND.USD

2016-05-22       0


which is clearly wrong.


I've tried various things including trying to invoke options (digits = 10)
at the start of the script, and even within the getFX wrapper as an extra
argument, but it doesn't work.  I can of course run select cross currency
rates and invert the results, but that is pretty awkward and it feels like
there ought to be a smarter and simpler solution.

Any help greatly appreciated.

Thanks
Dave

	[[alternative HTML version deleted]]


From highstat at highstat.com  Tue May 24 10:18:11 2016
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Tue, 24 May 2016 09:18:11 +0100
Subject: [R] Course: Introduction to Zero Inflated Models
Message-ID: <fe1840c4-d966-a6e9-186b-ae7e07ed9f2e@highstat.com>

There are places available on the following course:


Course: Introduction to Zero Inflated Models (Bayesian and frequentist 
approaches)

When: 13-17 June 2016

Where: Australian Institute of Marine Science, Perth, Australia

Course website: http://highstat.com/statscourse.htm

Course flyer: http://highstat.com/Courses/Flyers/Flyer2016_06Perth_ZI_V2.pdf

Keywords: Zero inflated count data. Zero inflated continuous data. 
Dependency. ZIP and ZAP models. Zero inflated GLMMs with random effects. 
Bayesian statistics, MCMC and JAGS. lme4, glmmADMB, JAGS. Overdispersion 
and solutions. Bayesian model selection.

Description: Suppose you want to study hippos and the effect of habitat 
variables on their distribution. When sampling, you may count zero 
hippos at many sites, potentially resulting in overdispersed Poisson 
GLMs.  In such cases zero inflated models can be applied. During the 
course several case studies are presented, in which the statistical 
theory for zero inflated models is integrated with applied analyses in a 
clear and understandable manner. Zero inflated models consist of two 
integrated GLMs and therefore we will start with a revision of GLM. Zero 
inflated GLMMs for nested data (repeated measurements, short time 
series, clustered data, etc.) are discussed in the second part of the 
course. We will focus on zero inflated count data, and zero inflated 
continuous data.




-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


	[[alternative HTML version deleted]]


From unwin at math.uni-augsburg.de  Tue May 24 12:21:05 2016
From: unwin at math.uni-augsburg.de (Antony Unwin)
Date: Tue, 24 May 2016 12:21:05 +0200
Subject: [R] R Course in Dublin (July 20th-22nd, 2016) Intoductory -> Modern
Message-ID: <7BF856F1-5245-4CA3-86C4-1F9C3C9702F6@math.uni-augsburg.de>

An R course from introductory to modern will be given by

Louis Aslett (Oxford University, author of the packages PhaseType and ReliabilityTheory)
and
Antony Unwin (author of the book ?Graphical Data Analysis with R? CRC Press 2015  http://www.gradaanwr.net).

The course will be offered again on September 7th-9th, 2016 in Dublin.

Details at  

http://insightsc.ie/training/r-statistical-software/ <http://insightsc.ie/training/r-statistical-software/>


Antony Unwin
Insight Statistical Consulting, Dublin, Ireland
University of Augsburg, Germany




	[[alternative HTML version deleted]]


From fotisfotiadis at gmail.com  Tue May 24 16:54:40 2016
From: fotisfotiadis at gmail.com (Fotis Fotiadis)
Date: Tue, 24 May 2016 17:54:40 +0300
Subject: [R] mgcv::gam(): NA parametric coefficient in a model with two
 categorical variables + model interpretation
In-Reply-To: <57430656.1050709@bath.edu>
References: <CAAO1NneNOjwWCyva-yP6Bz5D5hSBrmaqBXitwW9Md2c-nt1JRg@mail.gmail.com>
	<57430656.1050709@bath.edu>
Message-ID: <CAAO1Nnc53Wu_vTsQ1vzu+R_WOmtMkOELcgEi4T52gftG_6CjQA@mail.gmail.com>

Dear Prof. Wood

Thank you, again, for your immediate response.

Best,
Fotis

On Mon, May 23, 2016 at 4:32 PM, Simon Wood <simon.wood at bath.edu> wrote:

> Q1: It looks like the model is not fully identifiably given the data and
> as a result igcCAT.ideo has been set to zero - there is no sensible test to
> conduct with such a term, hence the NAs in the test stat an p-value fields.
>
> Q2: A separate (centred) smooth is estimated for each level of igc. If you
> want a baseline (igcCAT.pseudo) smooth, and difference smooths for the rest
> of the levels of igc then you need to set igc to be an ordered factor, and
> use something like...
> ~ igc + s(ctrial) + s(ctrial,by=igc)
> - see section on `by' variables in ?gam.models.
>
> best,
> Simon
>
>
> On 22/05/16 23:29, Fotis Fotiadis wrote:
>
>> Hallo all
>>
>> I am using a gam model for my data.
>>
>> m2.4<-bam(acc~ 1 + igc + s(ctrial, by=igc) + shape + s(ctrial, by=shape) +
>> s(ctrial, sbj, bs = "fs", m = 1) , data=data, family=binomial)
>>
>> igc codes condition and there are four levels (CAT.pseudo,
>> CAT.ideo,PA.pseudo, PA.ideo), and shape is a factor (that cannot be
>> considered random effect) with four levels too (rand21, rand22, rand23,
>> rand30).
>>
>> Here is the summary of the model
>>
>>> summary(m2.4)
>>>
>> Family: binomial
>> Link function: logit
>>
>> Formula:
>> acc ~ 1 + igc + s(ctrial, by = igc) + shape + s(ctrial, by = shape) +
>>      s(ctrial, sbj, bs = "fs", m = 1)
>>
>> Parametric coefficients:
>>               Estimate Std. Error z value Pr(>|z|)
>> (Intercept)    3.5321     0.1930  18.302  < 2e-16 ***
>> igcCAT.ideo    0.0000     0.0000      NA       NA
>> igcPA.ideo    -0.3650     0.2441  -1.495   0.1348
>> igcPA.pseudo  -0.2708     0.2574  -1.052   0.2928
>> shaperand22   -0.1390     0.1548  -0.898   0.3693
>> shaperand23    0.3046     0.1670   1.823   0.0682 .
>> shaperand30   -0.5839     0.1163  -5.020 5.16e-07 ***
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Approximate significance of smooth terms:
>>                              edf  Ref.df   Chi.sq  p-value
>> s(ctrial):igcCAT.pseudo   3.902   4.853   74.787 1.07e-14 ***
>> s(ctrial):igcCAT.ideo     2.293   2.702   13.794 0.001750 **
>> s(ctrial):igcPA.ideo      1.000   1.000   11.391 0.000738 ***
>> s(ctrial):igcPA.pseudo    3.158   3.815   20.411 0.000413 ***
>> s(ctrial):shaperand21     2.556   3.316   31.387 1.46e-06 ***
>> s(ctrial):shaperand22     1.000   1.000    0.898 0.343381
>> s(ctrial):shaperand23     2.304   2.850    6.144 0.118531
>> s(ctrial):shaperand30     4.952   5.947   27.806 0.000144 ***
>> s(ctrial,sbj)           221.476 574.000 1502.779  < 2e-16 ***
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Rank: 652/655
>> R-sq.(adj) =  0.405   Deviance explained = 43.9%
>> fREML =  24003  Scale est. = 1         n = 18417
>>
>>
>> I am not sure how this model works, but I guess it creates four smooths
>> for
>> each level of condition, and four smooths for each level of shape.
>>
>> There is also the intercept of the model, set at the reference level of
>> condition (CAT.pseudo) and at the reference level of shape (rand21). Each
>> parametric term represents the difference of each level of each of the two
>> factors from the intercept.
>>
>> I have two questions
>>
>> Q1:
>> Does anyone now why I get NA results in the second line of the parametric
>> terms?
>>
>> Q2:
>> The term igcCAT.ideo denotes the difference in the intercept between
>> (A): condition=igcCAT.ideo,  and
>> (B): (condition=igcCATpseudo ) &(shape=rand21).
>> But what is the value (level) of shape for (A)?
>> Is it the reference level? Or is it, perhaps, the "grand mean" of the
>> shape
>> variable?
>>
>>
>> Thank you in advance for your time,
>> Fotis
>>
>>
>>
>
> --
> Simon Wood, School of Mathematics, University of Bristol BS8 1TW UK
> +44 (0)117 33 18273     http://www.maths.bris.ac.uk/~sw15190
>
>


-- 
PhD Candidate
Department of Philosophy and History of Science
University of Athens, Greece.
http://users.uoa.gr/~aprotopapas/LLL/en/members.html#fotisfotiadis

Notice: Please do not use this account for social networks invitations, for
sending chain-mails to me, or as it were a facebook account. Thank you for
respecting my privacy.

	[[alternative HTML version deleted]]


From wewolski at gmail.com  Tue May 24 17:49:00 2016
From: wewolski at gmail.com (Witold E Wolski)
Date: Tue, 24 May 2016 17:49:00 +0200
Subject: [R] numeric inputs to sweep produce NaN...
Message-ID: <CAAjnpdj4U=VvT-60y0jPdnBqrqg3d-POMDqEdOnrP+K3EYsnww@mail.gmail.com>

I have two inputs to sweep which are numeric (with a few NA's) but the
output is NaN. How Why?


> sum(!is.numeric(unlist(protquant)))
[1] 0
> sum(!is.numeric(normalize))
[1] 0
> normprotquant <- sweep(protquant, 2, normalize, "-" )
> sum(is.nan(unlist(normprotquant)))
[1] 31


version R 3.3.0

best regards Witold
-- 
Witold Eryk Wolski


From chalabi.elahe at yahoo.de  Tue May 24 17:54:16 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Tue, 24 May 2016 15:54:16 +0000 (UTC)
Subject: [R] Factor Variable frequency
References: <137597854.3222674.1464105256516.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <137597854.3222674.1464105256516.JavaMail.yahoo@mail.yahoo.com>

Hi all,
I have the following df:


    $ Protocol       : Factor w/ 48 levels "DP FS QTSE SAG",..: 2 3 43 42 31 36 37 30 28 5 ...
    
    $ Speed         : chr  "SLOW" "SLOW" "SLOW" "VerySLOW" ...
How can I get the most frequent Protocol when Speed is "SLOW"?
Thanks for any help!
Elahe


From a.mosnier at gmail.com  Tue May 24 18:01:27 2016
From: a.mosnier at gmail.com (Arnaud Mosnier)
Date: Tue, 24 May 2016 12:01:27 -0400
Subject: [R] file connection when using parallel
Message-ID: <CANkFkEd3LoDrRHdWej_DPPdXAv5wfzHRSiyQUG5hQ2po1JdcXg@mail.gmail.com>

Dear UserRs,

I have a little problem creating a file connection when working in parallel
(see the reproducable script below).
I am sure this is something obvious,
Can you enlighten me ?

Thanks,

Arnaud



# This part works
#----------------
cat("This is a test file" , file={f <- tempfile()})
con <- file(f, "rt")


# Doing what I think is the same thing gives an error message when executed
in parallel
#--------------------------------------------------------------------------------------

library(parallel)
cl <- makeCluster(2)

## Exporting the object f into the cluster

  clusterExport(cl, "f")
  clusterEvalQ(cl[1], con <- file(f[[1]], "rt"))
   #Error in checkForRemoteErrors(lapply(cl, recvResult)) :
   # one node produced an error: cannot open the connection


## Creating the object f into the cluster

  clusterEvalQ(cl[1],cat("This is a test file" , file={f <- tempfile()}))
  clusterEvalQ(cl[1],con <- file(f, "rt"))
   #Error in checkForRemoteErrors(lapply(cl, recvResult)) :
   # one node produced an error: cannot open the connection

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Tue May 24 18:29:46 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Tue, 24 May 2016 17:29:46 +0100
Subject: [R] Factor Variable frequency
In-Reply-To: <137597854.3222674.1464105256516.JavaMail.yahoo@mail.yahoo.com>
References: <137597854.3222674.1464105256516.JavaMail.yahoo.ref@mail.yahoo.com>
	<137597854.3222674.1464105256516.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <20160524172946.Horde.9MStmdO36AbpWPdncFqmLKi@mail.sapo.pt>

Hello,

Maybe the following (untested).

table(df$Protocol[df$Speed == "SLOW"])

Hope this helps,

Rui Barradas
?

Citando ch.elahe via R-help <r-help at r-project.org>:

> Hi all,
> I have the following df:
>
> ? ?$ Protocol? ? ? ?: Factor w/ 48 levels "DP FS QTSE SAG",..: 2 3  
> 43 42 31 36 37 30 28 5 ...
>
> ? ?$ Speed? ? ? ? ?: chr? "SLOW" "SLOW" "SLOW" "VerySLOW" ...
> How can I get the most frequent Protocol when Speed is "SLOW"?
> Thanks for any help!
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide  
> http://www.R-project.org/posting-guide.htmland provide commented,  
> minimal, self-contained, reproducible code.

?

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue May 24 18:32:41 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 24 May 2016 09:32:41 -0700
Subject: [R] numeric inputs to sweep produce NaN...
In-Reply-To: <CAAjnpdj4U=VvT-60y0jPdnBqrqg3d-POMDqEdOnrP+K3EYsnww@mail.gmail.com>
References: <CAAjnpdj4U=VvT-60y0jPdnBqrqg3d-POMDqEdOnrP+K3EYsnww@mail.gmail.com>
Message-ID: <F87DBA8A-2BCD-49D3-A7C8-4C1491F11BBE@comcast.net>


> On May 24, 2016, at 8:49 AM, Witold E Wolski <wewolski at gmail.com> wrote:
> 
> I have two inputs to sweep which are numeric (with a few NA's) but the
> output is NaN. How Why?
> 
> 
>> sum(!is.numeric(unlist(protquant)))
> [1] 0
>> sum(!is.numeric(normalize))
> [1] 0
>> normprotquant <- sweep(protquant, 2, normalize, "-" )
>> sum(is.nan(unlist(normprotquant)))
> [1] 31
> 

Post output of dput(head(protquant)) and dput(head(normalize))

> 
> version R 3.3.0
> 
> best regards Witold
> -- 
> Witold Eryk Wolski
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bogaso.christofer at gmail.com  Tue May 24 19:07:14 2016
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Tue, 24 May 2016 22:37:14 +0530
Subject: [R] Downloading attachment from gmail
Message-ID: <CA+dpOJ=BJG8XWE5LGfOJo7ytr98VNd57Q5DHq5u-xpeCVV9djQ@mail.gmail.com>

Hi folks,

I am wondering if it is really possible via some R code which shall do
the following

1. Login to a Gmail account (account name and password will be provided to R)
2. Search for all mails which has a word "ABCD" in the mail body
3. Download all the attachments (if available) which will hit the criteria #2


Am not sure if above is too ambitious, however will really appreciate
if R can do this.

Thanks for your time


From string.gauraw at gmail.com  Tue May 24 17:21:38 2016
From: string.gauraw at gmail.com (Kumar Gauraw)
Date: Tue, 24 May 2016 20:51:38 +0530
Subject: [R] R help - Web Scraping of Google News using R
Message-ID: <CAF==z7WQn=Q_VzUMLm5Q8bimkDFUyt5EON_RdtT3WqLL2d5SwA@mail.gmail.com>

Hello Experts,

I am trying to scrap data from Google news for a particular topic using XML
and Curl Package of R. I am able to extract the summary part of the news
through *XPath* but in a similar way, I am trying to extract title and
Links of news which is not working.Please note this work is just for POC
purpose and I would make maximum of 500 requests per day so that Google TOS
remains intact.


library(XML)

library(RCurl)

getGoogleURL <- function(search.term, domain = '.co.in', quotes=TRUE)

{

  search.term <- gsub(' ', '%20', search.term)

  if(quotes) search.term <- paste('%22', search.term, '%22', sep='')

  getGoogleURL <- paste('http://www.google', domain,
'/search?hl=en&gl=in&tbm=nws&authuser=0&q=',search.term, sep='')

}

search.term <- "IPL 2016"

quotes <- "FALSE"

search.url <- getGoogleURL(search.term=search.term, quotes=quotes)

getGoogleSummary <- function(google.url) {

  doc <- getURL(google.url, httpheader = c("User-Agent" = "R(2.10.0)"))

  html <- htmlTreeParse(doc, useInternalNodes = TRUE, error=function(...){})

  nodes <- getNodeSet(html, "//div[@class='st']")

  return(sapply(nodes, function(x) x <- xmlValue(x)))

}

*#Problem is with this part of code*

getGoogleTitle <- function(google.url) {

  doc <- getURL(google.url, httpheader = c("User-Agent" = "R(2.10.0)"))

  html <- htmlTreeParse(doc, useInternalNodes = TRUE, error=function(...){})

 * nodes <- getNodeSet(html, "//a[@class='l _HId']")*

  return(sapply(nodes, function(x) x <- xmlValue(x)))

}

Kindly help me to understand where I am getting wrong so that I can rectify
the code and get the correct output.

Thank you.

With Regards,
Kumar Gauraw

	[[alternative HTML version deleted]]


From G.Maubach at gmx.de  Tue May 24 20:54:44 2016
From: G.Maubach at gmx.de (G.Maubach at gmx.de)
Date: Tue, 24 May 2016 20:54:44 +0200
Subject: [R] Creating a data frame from scratch
Message-ID: <trinity-9c303936-6968-4a41-a92a-e28873531408-1464116084484@3capp-gmx-bs51>

Hi All,

I need to create a data frame from scratch and fill variables created on the fly with values. What I have so far:

-- schnipp --

# Example dataset
gene <- c("ENSG00000208234","ENSG00000199674","ENSG00000221622","ENSG00000207604", 
  "ENSG00000207431","ENSG00000221312","ENSG00134940305","ENSG00394039490",
  "ENSG09943004048")
hsap <- c(0,0,0, 0, 0, 0, 1,1, 1)
mmul <- c(NA,2 ,3, NA, 2, 1 , NA,2, NA)
mmus <- c(NA,2 ,NA, NA, NA, 2 , NA,3, 1)
rnor <- c(NA,2 ,NA, 1 , NA, 3 , NA,NA, 2)
cfam <- c(NA,2,NA, 2, 1, 2, 2,NA, NA)

ds_example <- data.frame(gene, hsap, mmul, mmus, rnor, cfam)
ds_example$gene <- as.character(ds_example$gene)

t_count_na <- function(dataset,
                       variables = "all")
  # credit: http://stackoverflow.com/questions/4862178/remove-rows-with-nas-in-data-frame
  {
  ds_na <- data.frame()
  # if variables = "all" create character vector of variable names
  if (variables == "all") {
    variable_list <- dimnames(dataset)[[ 2 ]] 
  }
  # if a character vector with variable names is given
  # to run the function on a defined set of selected variables
  else {
    variable_list <- variables
  }
  
  for (var in variable_list) {
    new_name <- paste0("na_", var)
    ds_na[[ new_name ]] <- as.data.frame(is.na(dataset[[ var ]]))
  }
  
  ds_na[[ "na_count" ]] <- rowSums(ds_na)
  return(ds_na)
}

test <- t_count_na(dataset = ds_example, variables = c("mmul", "mmus"))

-- schnipp --

gives:

 Error in `[[<-.data.frame`(`*tmp*`, new_name, value = list(`is.na(dataset[[var]])` = c(TRUE,  : 
  replacement has 9 rows, data has 0 In addition: Warning message:
In if (variables == "all") { :
  the condition has length > 1 and only the first element will be used

My goal is to create a dataset from scratch on the fly which has the same amount of variables as the dataset ds_example plus a single variable storing the amount of NA's in a row for the given variables. This is the basis for a decious which cases to keep and which to drop.

I do not want to alter the base dataset like ds_example in the first place nor do I want to make a copy of the existing dataset due to memory allocation. The function shall also work with big data, e. g. datasets with more than 1 GB memory consumption.

I also do not want the newly created variables to be stored in the original data frame. They shall be separate.

A former similar solution worked:
http://r.789695.n4.nabble.com/Creating-variables-on-the-fly-td4720034.html

Why doesn't this one?

How do I create the variables within the data frame if the data frame is empty?

Kind regards

Georg Maubach


From NordlDJ at dshs.wa.gov  Tue May 24 21:38:15 2016
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Tue, 24 May 2016 19:38:15 +0000
Subject: [R] Creating a data frame from scratch
In-Reply-To: <trinity-9c303936-6968-4a41-a92a-e28873531408-1464116084484@3capp-gmx-bs51>
References: <trinity-9c303936-6968-4a41-a92a-e28873531408-1464116084484@3capp-gmx-bs51>
Message-ID: <F7E6D18CC2877149AB5296CE54EA276630968253@WAXMXOLYMB025.WAX.wa.lcl>


I would probably write the function something like this:


t_count_na <- function(dataset,
                       variables = "all") {
  if (identical(variables, "all")) {
    variable_list <- names(dataset)
  }  else {
    variable_list <- variables
  }  
  apply(dataset[,variable_list], 1, function(x) sum(is.na(x)))
}


Hope this is helpful,

Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> G.Maubach at gmx.de
> Sent: Tuesday, May 24, 2016 11:55 AM
> To: r-help at r-project.org
> Subject: [R] Creating a data frame from scratch
> 
> Hi All,
> 
> I need to create a data frame from scratch and fill variables created on the fly
> with values. What I have so far:
> 
> -- schnipp --
> 
> # Example dataset
> gene <-
> c("ENSG00000208234","ENSG00000199674","ENSG00000221622","ENSG00000
> 207604",
> 
> "ENSG00000207431","ENSG00000221312","ENSG00134940305","ENSG0039403
> 9490",
>   "ENSG09943004048")
> hsap <- c(0,0,0, 0, 0, 0, 1,1, 1)
> mmul <- c(NA,2 ,3, NA, 2, 1 , NA,2, NA)
> mmus <- c(NA,2 ,NA, NA, NA, 2 , NA,3, 1) rnor <- c(NA,2 ,NA, 1 , NA, 3 ,
> NA,NA, 2) cfam <- c(NA,2,NA, 2, 1, 2, 2,NA, NA)
> 
> ds_example <- data.frame(gene, hsap, mmul, mmus, rnor, cfam)
> ds_example$gene <- as.character(ds_example$gene)
> 
> t_count_na <- function(dataset,
>                        variables = "all")
>   # credit: http://stackoverflow.com/questions/4862178/remove-rows-with-
> nas-in-data-frame
>   {
>   ds_na <- data.frame()
>   # if variables = "all" create character vector of variable names
>   if (variables == "all") {
>     variable_list <- dimnames(dataset)[[ 2 ]]
>   }
>   # if a character vector with variable names is given
>   # to run the function on a defined set of selected variables
>   else {
>     variable_list <- variables
>   }
> 
>   for (var in variable_list) {
>     new_name <- paste0("na_", var)
>     ds_na[[ new_name ]] <- as.data.frame(is.na(dataset[[ var ]]))
>   }
> 
>   ds_na[[ "na_count" ]] <- rowSums(ds_na)
>   return(ds_na)
> }
> 
> test <- t_count_na(dataset = ds_example, variables = c("mmul", "mmus"))
> 
> -- schnipp --
> 
> gives:
> 
>  Error in `[[<-.data.frame`(`*tmp*`, new_name, value =
> list(`is.na(dataset[[var]])` = c(TRUE,  :
>   replacement has 9 rows, data has 0 In addition: Warning message:
> In if (variables == "all") { :
>   the condition has length > 1 and only the first element will be used
> 
> My goal is to create a dataset from scratch on the fly which has the same
> amount of variables as the dataset ds_example plus a single variable storing
> the amount of NA's in a row for the given variables. This is the basis for a
> decious which cases to keep and which to drop.
> 
> I do not want to alter the base dataset like ds_example in the first place nor
> do I want to make a copy of the existing dataset due to memory allocation.
> The function shall also work with big data, e. g. datasets with more than 1 GB
> memory consumption.
> 
> I also do not want the newly created variables to be stored in the original
> data frame. They shall be separate.
> 
> A former similar solution worked:
> http://r.789695.n4.nabble.com/Creating-variables-on-the-fly-td4720034.html
> 
> Why doesn't this one?
> 
> How do I create the variables within the data frame if the data frame is
> empty?
> 
> Kind regards
> 
> Georg Maubach
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mccormack at molbio.mgh.harvard.edu  Tue May 24 21:46:44 2016
From: mccormack at molbio.mgh.harvard.edu (Matthew)
Date: Tue, 24 May 2016 15:46:44 -0400
Subject: [R] identify duplicate entries in data frame and calculate mean
Message-ID: <3e8793e6-1bae-fe74-e48b-f2a5b18dfc54@molbio.mgh.harvard.edu>

I have a data frame with 10 columns.
In the last column is an alphaneumaric identifier.
For most rows, this alphaneumaric identifier is unique to the file, 
however some of these alphanemeric idenitifiers occur in duplicate, 
triplicate or more. When they do occur more than once they are in 
consecutive rows, so when there is a duplicate or triplicate or 
quadruplicate (let's call them multiplicates), they are in consecutive rows.

In column 7 there is an integer number (may or may not be unique. does 
not matter).

I want to identify each multiple entries (multiplicates) occurring in 
column 10 and then for each multiplicate calculate the mean of the 
integers column 7.

As an example, I will show just two columns:
Length  Identifier
321     A234
350     A234
340     A234
180     B123
198     B225

What I want to do (in the above example) is collapse all the A234's and 
report the mean to get this:
Length  Identifier
337     A234
180     B123
198     B225


Matthew


From tom at maladmin.com  Tue May 24 22:08:29 2016
From: tom at maladmin.com (Tom Wright)
Date: Tue, 24 May 2016 16:08:29 -0400
Subject: [R] identify duplicate entries in data frame and calculate mean
In-Reply-To: <3e8793e6-1bae-fe74-e48b-f2a5b18dfc54@molbio.mgh.harvard.edu>
References: <3e8793e6-1bae-fe74-e48b-f2a5b18dfc54@molbio.mgh.harvard.edu>
Message-ID: <CAKmUXV-b4CZoc8EvzOekO8nHyq1vuOV_33=RjXQfTmnH_29-BA@mail.gmail.com>

Using dplyr

$ library(dplyr)
$ x<-data.frame(Length=c(321,350,340,180,198),
                        ID=c(rep('A234',3),'B123','B225') )
$ x %>% group_by(ID) %>% summarise(m=mean(Length))



On Tue, May 24, 2016 at 3:46 PM, Matthew <mccormack at molbio.mgh.harvard.edu>
wrote:

> I have a data frame with 10 columns.
> In the last column is an alphaneumaric identifier.
> For most rows, this alphaneumaric identifier is unique to the file,
> however some of these alphanemeric idenitifiers occur in duplicate,
> triplicate or more. When they do occur more than once they are in
> consecutive rows, so when there is a duplicate or triplicate or
> quadruplicate (let's call them multiplicates), they are in consecutive rows.
>
> In column 7 there is an integer number (may or may not be unique. does not
> matter).
>
> I want to identify each multiple entries (multiplicates) occurring in
> column 10 and then for each multiplicate calculate the mean of the integers
> column 7.
>
> As an example, I will show just two columns:
> Length  Identifier
> 321     A234
> 350     A234
> 340     A234
> 180     B123
> 198     B225
>
> What I want to do (in the above example) is collapse all the A234's and
> report the mean to get this:
> Length  Identifier
> 337     A234
> 180     B123
> 198     B225
>
>
> Matthew
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From NordlDJ at dshs.wa.gov  Tue May 24 22:15:27 2016
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Tue, 24 May 2016 20:15:27 +0000
Subject: [R] identify duplicate entries in data frame and calculate mean
In-Reply-To: <3e8793e6-1bae-fe74-e48b-f2a5b18dfc54@molbio.mgh.harvard.edu>
References: <3e8793e6-1bae-fe74-e48b-f2a5b18dfc54@molbio.mgh.harvard.edu>
Message-ID: <F7E6D18CC2877149AB5296CE54EA2766309682AF@WAXMXOLYMB025.WAX.wa.lcl>

You have several  options.  

1.  You could use the aggregate function.  If your data frame is called DF, you could do something like

with(DF, aggregate(Length, list(Identifier), mean))

2.  You could use the dplyr package like this

library(dplyr)
summarize(group_by(DF, Identifier), mean(Length))


Hope this is helpful,

Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Matthew
> Sent: Tuesday, May 24, 2016 12:47 PM
> To: r-help at r-project.org
> Subject: [R] identify duplicate entries in data frame and calculate mean
> 
> I have a data frame with 10 columns.
> In the last column is an alphaneumaric identifier.
> For most rows, this alphaneumaric identifier is unique to the file, however
> some of these alphanemeric idenitifiers occur in duplicate, triplicate or more.
> When they do occur more than once they are in consecutive rows, so when
> there is a duplicate or triplicate or quadruplicate (let's call them multiplicates),
> they are in consecutive rows.
> 
> In column 7 there is an integer number (may or may not be unique. does not
> matter).
> 
> I want to identify each multiple entries (multiplicates) occurring in column 10
> and then for each multiplicate calculate the mean of the integers column 7.
> 
> As an example, I will show just two columns:
> Length  Identifier
> 321     A234
> 350     A234
> 340     A234
> 180     B123
> 198     B225
> 
> What I want to do (in the above example) is collapse all the A234's and report
> the mean to get this:
> Length  Identifier
> 337     A234
> 180     B123
> 198     B225
> 
> 
> Matthew
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mccormack at molbio.mgh.harvard.edu  Tue May 24 22:17:01 2016
From: mccormack at molbio.mgh.harvard.edu (Matthew)
Date: Tue, 24 May 2016 16:17:01 -0400
Subject: [R] identify duplicate entries in data frame and calculate mean
In-Reply-To: <CAKmUXV-b4CZoc8EvzOekO8nHyq1vuOV_33=RjXQfTmnH_29-BA@mail.gmail.com>
References: <3e8793e6-1bae-fe74-e48b-f2a5b18dfc54@molbio.mgh.harvard.edu>
	<CAKmUXV-b4CZoc8EvzOekO8nHyq1vuOV_33=RjXQfTmnH_29-BA@mail.gmail.com>
Message-ID: <d986cfa0-3580-2a1c-c81c-6b2caba2b1ce@molbio.mgh.harvard.edu>

Thank you very much, Tom.
This gets me thinking in the right direction.
One thing I should have mentioned that I did not is that the number of 
rows in the data frame will be a little over 40,000 rows.

On 5/24/2016 4:08 PM, Tom Wright wrote:
> Using dplyr
>
> $ library(dplyr)
> $ x<-data.frame(Length=c(321,350,340,180,198),
>                         ID=c(rep('A234',3),'B123','B225') )
> $ x %>% group_by(ID) %>% summarise(m=mean(Length))
>
>
>
> On Tue, May 24, 2016 at 3:46 PM, Matthew 
> <mccormack at molbio.mgh.harvard.edu 
> <mailto:mccormack at molbio.mgh.harvard.edu>> wrote:
>
>     I have a data frame with 10 columns.
>     In the last column is an alphaneumaric identifier.
>     For most rows, this alphaneumaric identifier is unique to the
>     file, however some of these alphanemeric idenitifiers occur in
>     duplicate, triplicate or more. When they do occur more than once
>     they are in consecutive rows, so when there is a duplicate or
>     triplicate or quadruplicate (let's call them multiplicates), they
>     are in consecutive rows.
>
>     In column 7 there is an integer number (may or may not be unique.
>     does not matter).
>
>     I want to identify each multiple entries (multiplicates) occurring
>     in column 10 and then for each multiplicate calculate the mean of
>     the integers column 7.
>
>     As an example, I will show just two columns:
>     Length  Identifier
>     321     A234
>     350     A234
>     340     A234
>     180     B123
>     198     B225
>
>     What I want to do (in the above example) is collapse all the
>     A234's and report the mean to get this:
>     Length  Identifier
>     337     A234
>     180     B123
>     198     B225
>
>
>     Matthew
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>


	[[alternative HTML version deleted]]


From tom at maladmin.com  Tue May 24 22:23:38 2016
From: tom at maladmin.com (Tom Wright)
Date: Tue, 24 May 2016 16:23:38 -0400
Subject: [R] identify duplicate entries in data frame and calculate mean
In-Reply-To: <d986cfa0-3580-2a1c-c81c-6b2caba2b1ce@molbio.mgh.harvard.edu>
References: <3e8793e6-1bae-fe74-e48b-f2a5b18dfc54@molbio.mgh.harvard.edu>
	<CAKmUXV-b4CZoc8EvzOekO8nHyq1vuOV_33=RjXQfTmnH_29-BA@mail.gmail.com>
	<d986cfa0-3580-2a1c-c81c-6b2caba2b1ce@molbio.mgh.harvard.edu>
Message-ID: <CAKmUXV8_k4TR0itZiQhkALdTSQcmBUuKpqQmgjHZKog7hkAqHQ@mail.gmail.com>

Don't see that as being a big problem. If your data grows then dplyr
supports connections to external databases. Alternately if you just want a
mean, most databases can do that directly in SQL.

On Tue, May 24, 2016 at 4:17 PM, Matthew <mccormack at molbio.mgh.harvard.edu>
wrote:

> Thank you very much, Tom.
> This gets me thinking in the right direction.
> One thing I should have mentioned that I did not is that the number of
> rows in the data frame will be a little over 40,000 rows.
>
>
> On 5/24/2016 4:08 PM, Tom Wright wrote:
>
> Using dplyr
>
> $ library(dplyr)
> $ x<-data.frame(Length=c(321,350,340,180,198),
>                         ID=c(rep('A234',3),'B123','B225') )
> $ x %>% group_by(ID) %>% summarise(m=mean(Length))
>
>
>
> On Tue, May 24, 2016 at 3:46 PM, Matthew <mccormack at molbio.mgh.harvard.edu
> > wrote:
>
>> I have a data frame with 10 columns.
>> In the last column is an alphaneumaric identifier.
>> For most rows, this alphaneumaric identifier is unique to the file,
>> however some of these alphanemeric idenitifiers occur in duplicate,
>> triplicate or more. When they do occur more than once they are in
>> consecutive rows, so when there is a duplicate or triplicate or
>> quadruplicate (let's call them multiplicates), they are in consecutive rows.
>>
>> In column 7 there is an integer number (may or may not be unique. does
>> not matter).
>>
>> I want to identify each multiple entries (multiplicates) occurring in
>> column 10 and then for each multiplicate calculate the mean of the integers
>> column 7.
>>
>> As an example, I will show just two columns:
>> Length  Identifier
>> 321     A234
>> 350     A234
>> 340     A234
>> 180     B123
>> 198     B225
>>
>> What I want to do (in the above example) is collapse all the A234's and
>> report the mean to get this:
>> Length  Identifier
>> 337     A234
>> 180     B123
>> 198     B225
>>
>>
>> Matthew
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>

	[[alternative HTML version deleted]]


From mccormack at molbio.mgh.harvard.edu  Tue May 24 22:36:26 2016
From: mccormack at molbio.mgh.harvard.edu (Matthew)
Date: Tue, 24 May 2016 16:36:26 -0400
Subject: [R] identify duplicate entries in data frame and calculate mean
In-Reply-To: <CAKmUXV8_k4TR0itZiQhkALdTSQcmBUuKpqQmgjHZKog7hkAqHQ@mail.gmail.com>
References: <3e8793e6-1bae-fe74-e48b-f2a5b18dfc54@molbio.mgh.harvard.edu>
	<CAKmUXV-b4CZoc8EvzOekO8nHyq1vuOV_33=RjXQfTmnH_29-BA@mail.gmail.com>
	<d986cfa0-3580-2a1c-c81c-6b2caba2b1ce@molbio.mgh.harvard.edu>
	<CAKmUXV8_k4TR0itZiQhkALdTSQcmBUuKpqQmgjHZKog7hkAqHQ@mail.gmail.com>
Message-ID: <cb9a243f-92aa-eb24-dd5c-7199e3f41719@molbio.mgh.harvard.edu>

Thanks, Tom.  I was making a mistake looking at your example and that's 
what my problem was.

Cool answer, works great. Thank you very much.

Matthew

On 5/24/2016 4:23 PM, Tom Wright wrote:
> Don't see that as being a big problem. If your data grows then dplyr 
> supports connections to external databases. Alternately if you just 
> want a mean, most databases can do that directly in SQL.
>
> On Tue, May 24, 2016 at 4:17 PM, Matthew 
> <mccormack at molbio.mgh.harvard.edu 
> <mailto:mccormack at molbio.mgh.harvard.edu>> wrote:
>
>     Thank you very much, Tom.
>     This gets me thinking in the right direction.
>     One thing I should have mentioned that I did not is that the
>     number of rows in the data frame will be a little over 40,000 rows.
>
>
>     On 5/24/2016 4:08 PM, Tom Wright wrote:
>>     Using dplyr
>>
>>     $ library(dplyr)
>>     $ x<-data.frame(Length=c(321,350,340,180,198),
>>     ID=c(rep('A234',3),'B123','B225') )
>>     $ x %>% group_by(ID) %>% summarise(m=mean(Length))
>>
>>
>>
>>     On Tue, May 24, 2016 at 3:46 PM, Matthew
>>     <mccormack at molbio.mgh.harvard.edu
>>     <mailto:mccormack at molbio.mgh.harvard.edu>> wrote:
>>
>>         I have a data frame with 10 columns.
>>         In the last column is an alphaneumaric identifier.
>>         For most rows, this alphaneumaric identifier is unique to the
>>         file, however some of these alphanemeric idenitifiers occur
>>         in duplicate, triplicate or more. When they do occur more
>>         than once they are in consecutive rows, so when there is a
>>         duplicate or triplicate or quadruplicate (let's call them
>>         multiplicates), they are in consecutive rows.
>>
>>         In column 7 there is an integer number (may or may not be
>>         unique. does not matter).
>>
>>         I want to identify each multiple entries (multiplicates)
>>         occurring in column 10 and then for each multiplicate
>>         calculate the mean of the integers column 7.
>>
>>         As an example, I will show just two columns:
>>         Length  Identifier
>>         321     A234
>>         350     A234
>>         340     A234
>>         180     B123
>>         198     B225
>>
>>         What I want to do (in the above example) is collapse all the
>>         A234's and report the mean to get this:
>>         Length  Identifier
>>         337     A234
>>         180     B123
>>         198     B225
>>
>>
>>         Matthew
>>
>>         ______________________________________________
>>         R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>         list -- To UNSUBSCRIBE and more, see
>>         https://stat.ethz.ch/mailman/listinfo/r-help
>>         PLEASE do read the posting guide
>>         http://www.R-project.org/posting-guide.html
>>         and provide commented, minimal, self-contained, reproducible
>>         code.
>>
>>
>
>


	[[alternative HTML version deleted]]


From mccormack at molbio.mgh.harvard.edu  Tue May 24 22:37:32 2016
From: mccormack at molbio.mgh.harvard.edu (Matthew)
Date: Tue, 24 May 2016 16:37:32 -0400
Subject: [R] identify duplicate entries in data frame and calculate mean
In-Reply-To: <F7E6D18CC2877149AB5296CE54EA2766309682AF@WAXMXOLYMB025.WAX.wa.lcl>
References: <3e8793e6-1bae-fe74-e48b-f2a5b18dfc54@molbio.mgh.harvard.edu>
	<F7E6D18CC2877149AB5296CE54EA2766309682AF@WAXMXOLYMB025.WAX.wa.lcl>
Message-ID: <35c59c34-f5d6-a774-e993-a6bb82da7553@molbio.mgh.harvard.edu>

Thank you very much, Dan.

These work great. Two more great answers to my question.

Matthew

On 5/24/2016 4:15 PM, Nordlund, Dan (DSHS/RDA) wrote:
> You have several  options.
>
> 1.  You could use the aggregate function.  If your data frame is called DF, you could do something like
>
> with(DF, aggregate(Length, list(Identifier), mean))
>
> 2.  You could use the dplyr package like this
>
> library(dplyr)
> summarize(group_by(DF, Identifier), mean(Length))
>
>
> Hope this is helpful,
>
> Dan
>
> Daniel Nordlund, PhD
> Research and Data Analysis Division
> Services & Enterprise Support Administration
> Washington State Department of Social and Health Services
>
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Matthew
>> Sent: Tuesday, May 24, 2016 12:47 PM
>> To: r-help at r-project.org
>> Subject: [R] identify duplicate entries in data frame and calculate mean
>>
>> I have a data frame with 10 columns.
>> In the last column is an alphaneumaric identifier.
>> For most rows, this alphaneumaric identifier is unique to the file, however
>> some of these alphanemeric idenitifiers occur in duplicate, triplicate or more.
>> When they do occur more than once they are in consecutive rows, so when
>> there is a duplicate or triplicate or quadruplicate (let's call them multiplicates),
>> they are in consecutive rows.
>>
>> In column 7 there is an integer number (may or may not be unique. does not
>> matter).
>>
>> I want to identify each multiple entries (multiplicates) occurring in column 10
>> and then for each multiplicate calculate the mean of the integers column 7.
>>
>> As an example, I will show just two columns:
>> Length  Identifier
>> 321     A234
>> 350     A234
>> 340     A234
>> 180     B123
>> 198     B225
>>
>> What I want to do (in the above example) is collapse all the A234's and report
>> the mean to get this:
>> Length  Identifier
>> 337     A234
>> 180     B123
>> 198     B225
>>
>>
>> Matthew
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From aguitatierra at hotmail.com  Tue May 24 22:59:42 2016
From: aguitatierra at hotmail.com (Beatriz)
Date: Tue, 24 May 2016 22:59:42 +0200
Subject: [R] Sprintf to call data frame from environment
In-Reply-To: <mailman.5.1442916002.27623.r-help@r-project.org>
References: <mailman.5.1442916002.27623.r-help@r-project.org>
Message-ID: <BLU436-SMTP2130ED5750CF3C7DEFB5BFCD94F0@phx.gbl>

In my environment I have a data frame called Samples_1.txt.
 From this data frame I need to get variable V1.  My code doesn't work.
Note: I need to do it in this way because I have the code into a for loop.

sprintf("Samples_%s.txt", 1)$V1


From aguitatierra at hotmail.com  Tue May 24 23:01:28 2016
From: aguitatierra at hotmail.com (Beatriz)
Date: Tue, 24 May 2016 23:01:28 +0200
Subject: [R] Sprintf to call data frame from environment
In-Reply-To: <BLU436-SMTP2130ED5750CF3C7DEFB5BFCD94F0@phx.gbl>
References: <BLU436-SMTP2130ED5750CF3C7DEFB5BFCD94F0@phx.gbl>
Message-ID: <BLU436-SMTP159813C8E5D06B4BB0174F3D94F0@phx.gbl>


In my environment I have a data frame called Samples_1.txt.
 From this data frame I need to get variable V1.  My code doesn't work. Thanks!

	sprintf("Samples_%s.txt", 1)$V1

Note: I need to do it in this way because I have the code into a for loop.


From dwinsemius at comcast.net  Tue May 24 23:39:37 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 24 May 2016 14:39:37 -0700
Subject: [R] Sprintf to call data frame from environment
In-Reply-To: <BLU436-SMTP159813C8E5D06B4BB0174F3D94F0@phx.gbl>
References: <BLU436-SMTP2130ED5750CF3C7DEFB5BFCD94F0@phx.gbl>
	<BLU436-SMTP159813C8E5D06B4BB0174F3D94F0@phx.gbl>
Message-ID: <FF8208EE-1E40-4C3B-B58D-DCEA21FA518A@comcast.net>


> On May 24, 2016, at 2:01 PM, Beatriz <aguitatierra at hotmail.com> wrote:
> 
> 
> In my environment I have a data frame called Samples_1.txt.
> From this data frame I need to get variable V1.  My code doesn't work. Thanks!
> 
> 	$V1
> 
> Note: I need to do it in this way because I have the code into a for loop.

You are treating this as if R were a macro processor, which it's not. The only function that lets you pull in a data-object from the store of named objects using a character vector is `get`, so perhaps:

get( sprintf("Samples_%s.txt", 1) )$V1

And if you were considering the next step of hoping to pass a computed item to `$`, then forget that as well, and learn to use `[`.

-- 

David Winsemius
Alameda, CA, USA


From NordlDJ at dshs.wa.gov  Tue May 24 23:38:54 2016
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Tue, 24 May 2016 21:38:54 +0000
Subject: [R] Sprintf to call data frame from environment
In-Reply-To: <BLU436-SMTP159813C8E5D06B4BB0174F3D94F0@phx.gbl>
References: <BLU436-SMTP2130ED5750CF3C7DEFB5BFCD94F0@phx.gbl>
	<BLU436-SMTP159813C8E5D06B4BB0174F3D94F0@phx.gbl>
Message-ID: <F7E6D18CC2877149AB5296CE54EA276630968302@WAXMXOLYMB025.WAX.wa.lcl>

It is not clear (at least to me) what your actual task is.  But, if Samples_1.txt is the actual name of a data frame that exists in memory (and not a filename), then you need to wrap the sprintf() in a get() function.

get(sprintf("Samples_%s.txt", 1))$V1

I am no expert  on "computing on the language" in R, but I can't help but think you are going about your task in the wrong way.  If you provide more detail about what you are trying to do, someone will probably be able to provide you a solution where you don't need to do it this way.


Hope this is helpful,

Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Beatriz
> Sent: Tuesday, May 24, 2016 2:01 PM
> To: r-help at r-project.org
> Subject: [R] Sprintf to call data frame from environment
> 
> 
> In my environment I have a data frame called Samples_1.txt.
>  From this data frame I need to get variable V1.  My code doesn't work.
> Thanks!
> 
> 	sprintf("Samples_%s.txt", 1)$V1
> 
> Note: I need to do it in this way because I have the code into a for loop.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed May 25 00:39:17 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 25 May 2016 08:39:17 +1000
Subject: [R] Sprintf to call data frame from environment
In-Reply-To: <BLU436-SMTP159813C8E5D06B4BB0174F3D94F0@phx.gbl>
References: <BLU436-SMTP2130ED5750CF3C7DEFB5BFCD94F0@phx.gbl>
	<BLU436-SMTP159813C8E5D06B4BB0174F3D94F0@phx.gbl>
Message-ID: <CA+8X3fW9DHbAU+JYn2tyDnWkCJvnk0kVi0G4JXSaOOpZXkZ9Kg@mail.gmail.com>

Hi Beatriz,
I'll guess that you have a number of files with names like this:

Samples_1.txt
Samples_2.txt
...

Each one can be read with a function like read.table and will return a
data frame with default names (V1, V2, ...). You then want to extract
the first element (column) of the data frame. If I'm correct, try
this:

V1s<-list()
# nfiles is the number of files you want to read
for(i in 1:nfiles) {
 filename<-paste("Samples_",i,".txt,sep="")
 # you will probably have to add the appropriate arguments to read.table
 V1s[[i]]<-read.table(filename)$V1
}

The list V1s should contain the first columns of all the data frames read.

Jim


On Wed, May 25, 2016 at 7:01 AM, Beatriz <aguitatierra at hotmail.com> wrote:
>
> In my environment I have a data frame called Samples_1.txt.
> From this data frame I need to get variable V1.  My code doesn't work.
> Thanks!
>
>         sprintf("Samples_%s.txt", 1)$V1
>
> Note: I need to do it in this way because I have the code into a for loop.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nsit315 at aucklanduni.ac.nz  Wed May 25 01:25:01 2016
From: nsit315 at aucklanduni.ac.nz (Neny Sitorus)
Date: Wed, 25 May 2016 11:25:01 +1200
Subject: [R] Mixed model analysis
Message-ID: <CALjSv_dQWJXHk0VkVKQX8gwY-56ngFXpyV0EvgYp2P5971XVDg@mail.gmail.com>

Hi,

what is exactly mixed model analysis in R?
could someone give me a better description.


Thank you,
Neny

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed May 25 03:30:34 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 25 May 2016 01:30:34 +0000
Subject: [R] Mixed model analysis
In-Reply-To: <CALjSv_dQWJXHk0VkVKQX8gwY-56ngFXpyV0EvgYp2P5971XVDg@mail.gmail.com>
References: <CALjSv_dQWJXHk0VkVKQX8gwY-56ngFXpyV0EvgYp2P5971XVDg@mail.gmail.com>
Message-ID: <CAGxFJbRipQeXN1mM+UCLXKpV8PXcroaLVpV4-0CoaRozPsCDpg@mail.gmail.com>

This has nothing to do with R, per se. This is a statistical issue. You
need to work with a statistician, as your statistical background is
inadequate (google "mixed effects models") if you really need this.

Cheers,
Bert

On Tue, May 24, 2016 at 7:27 PM Neny Sitorus <nsit315 at aucklanduni.ac.nz>
wrote:

> Hi,
>
> what is exactly mixed model analysis in R?
> could someone give me a better description.
>
>
> Thank you,
> Neny
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bob at rudis.net  Wed May 25 06:16:52 2016
From: bob at rudis.net (boB Rudis)
Date: Wed, 25 May 2016 00:16:52 -0400
Subject: [R] R help - Web Scraping of Google News using R
In-Reply-To: <CAF==z7WQn=Q_VzUMLm5Q8bimkDFUyt5EON_RdtT3WqLL2d5SwA@mail.gmail.com>
References: <CAF==z7WQn=Q_VzUMLm5Q8bimkDFUyt5EON_RdtT3WqLL2d5SwA@mail.gmail.com>
Message-ID: <CAJ4QxaMPB6g5QYsDO308NvnYSMX2C2xipENCsaNs3wu8DorgmA@mail.gmail.com>

What you are doing wrong is both trying yourself and asking others to
violate Google's Terms of Service and (amongst other things) get your
IP banned along with anyone who aids you (or worse). Please don't.
Just because something can be done does not mean it should be done.

On Tue, May 24, 2016 at 11:21 AM, Kumar Gauraw <string.gauraw at gmail.com> wrote:
> Hello Experts,
>
> I am trying to scrap data from Google news for a particular topic using XML
> and Curl Package of R. I am able to extract the summary part of the news
> through *XPath* but in a similar way, I am trying to extract title and
> Links of news which is not working.Please note this work is just for POC
> purpose and I would make maximum of 500 requests per day so that Google TOS
> remains intact.
>
>
> library(XML)
>
> library(RCurl)
>
> getGoogleURL <- function(search.term, domain = '.co.in', quotes=TRUE)
>
> {
>
>   search.term <- gsub(' ', '%20', search.term)
>
>   if(quotes) search.term <- paste('%22', search.term, '%22', sep='')
>
>   getGoogleURL <- paste('http://www.google', domain,
> '/search?hl=en&gl=in&tbm=nws&authuser=0&q=',search.term, sep='')
>
> }
>
> search.term <- "IPL 2016"
>
> quotes <- "FALSE"
>
> search.url <- getGoogleURL(search.term=search.term, quotes=quotes)
>
> getGoogleSummary <- function(google.url) {
>
>   doc <- getURL(google.url, httpheader = c("User-Agent" = "R(2.10.0)"))
>
>   html <- htmlTreeParse(doc, useInternalNodes = TRUE, error=function(...){})
>
>   nodes <- getNodeSet(html, "//div[@class='st']")
>
>   return(sapply(nodes, function(x) x <- xmlValue(x)))
>
> }
>
> *#Problem is with this part of code*
>
> getGoogleTitle <- function(google.url) {
>
>   doc <- getURL(google.url, httpheader = c("User-Agent" = "R(2.10.0)"))
>
>   html <- htmlTreeParse(doc, useInternalNodes = TRUE, error=function(...){})
>
>  * nodes <- getNodeSet(html, "//a[@class='l _HId']")*
>
>   return(sapply(nodes, function(x) x <- xmlValue(x)))
>
> }
>
> Kindly help me to understand where I am getting wrong so that I can rectify
> the code and get the correct output.
>
> Thank you.
>
> With Regards,
> Kumar Gauraw
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From G.Maubach at weinwolf.de  Wed May 25 10:12:23 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Wed, 25 May 2016 10:12:23 +0200
Subject: [R] Antwort: Re:  Creating a data frame from scratch (SOLVED)
In-Reply-To: <F7E6D18CC2877149AB5296CE54EA276630968253@WAXMXOLYMB025.WAX.wa.lcl>
References: <trinity-9c303936-6968-4a41-a92a-e28873531408-1464116084484@3capp-gmx-bs51>
	<F7E6D18CC2877149AB5296CE54EA276630968253@WAXMXOLYMB025.WAX.wa.lcl>
Message-ID: <OF0F397D14.F41EFF1F-ONC1257FBE.002C4294-C1257FBE.002D14C8@lotus.hawesko.de>

Hi Dan,
Hi All,

many thanks for your help.

Please find enclosed my little function for your use:

-- cut --

#-------------------------------------------------------------------------------
# Module        : t_count_na.R
# Author        : Georg Maubach
# Date          : 2016-05-24
# Update        : 2016-05-25
# Description   : Count NA's
# Source System : R 3.2.2 (64 Bit)
# Target System : R 3.2.2 (64 Bit)
# License       : CC-BY-SA-NC
#--------1---------2---------3---------4---------5---------6---------7---------8

test <- FALSE

t_count_na <- function(dataset,
                       variables = "all") {
  # Counts the number of NA within given set of veriables
  #
  # Args:
  #   dataset  : Object with dimnames, e.g. data frame, data table.
  #   variables: Character vector with variable names.
  #
  # Operation:
  #   Adds the variable "na_count" to the given dataset containing the 
count of
  #   NA's within the given variables
  #
  # Returns:
  #   Original dataset with variable "na_count" added.
  #
  # Error handling:
  #   None.
  #
  # Credits: 
  #   
http://stackoverflow.com/questions/4862178/remove-rows-with-nas-in-data-frame
  #   
http://r.789695.n4.nabble.com/Creating-variables-on-the-fly-td4720034.html
 
  version <- "2016-05-25"
 
  if (identical(variables, "all")) {
    variable_list <- names(dataset)
  }  else {
    variable_list <- variables
  } 
  dataset[["na_count"]] <- apply(dataset[,variable_list],
                                 1, 
                                 function(x) sum(is.na(x)))
 
  return(dataset)
 
}

#-------------------------------------------------------------------------------

test <- function(do_test = FALSE) {
 
  cat("\n", "\n", "Test function t_count_na()", "\n", "\n")
 
  # Example dataset
    gene <- 
c("ENSG00000208234","ENSG00000199674","ENSG00000221622","ENSG00000207604", 

 "ENSG00000207431","ENSG00000221312","ENSG00134940305","ENSG00394039490",
              "ENSG09943004048")
    hsap <- c(0,0,0, 0, 0, 0, 1,1, 1)
    mmul <- c(NA,2 ,3, NA, 2, 1 , NA,2, NA)
    mmus <- c(NA,2 ,NA, NA, NA, 2 , NA,3, 1)
    rnor <- c(NA,2 ,NA, 1 , NA, 3 , NA,NA, 2)
    cfam <- c(NA,2,NA, 2, 1, 2, 2,NA, NA)
    ds_example <- data.frame(gene, hsap, mmul, mmus, rnor, cfam)
    ds_example$gene <- as.character(ds_example$gene)
 
  cat("\n", "\n", "Example dataset before function call", "\n", "\n")
  print(ds_example)
 
  cat("\n", "\n", "Function call", "\n", "\n")
  ds_example <- t_count_na(dataset = ds_example,
                           variables = c("mmul", "mmus"))
 
  cat("\n", "\n", "Example dataset after function call", "\n", "\n")
  print(ds_example)
}

test(do_test = test)

# EOF .

-- cut --

Kind regards

Georg Maubach




Von:    "Nordlund, Dan (DSHS/RDA)" <NordlDJ at dshs.wa.gov>
An:      "r-help at r-project.org" <r-help at r-project.org>, 
Datum:  24.05.2016 21:41
Betreff:        Re: [R] Creating a data frame from scratch
Gesendet von:   "R-help" <r-help-bounces at r-project.org>




I would probably write the function something like this:


t_count_na <- function(dataset,
                       variables = "all") {
  if (identical(variables, "all")) {
    variable_list <- names(dataset)
  }  else {
    variable_list <- variables
  } 
  apply(dataset[,variable_list], 1, function(x) sum(is.na(x)))
}


Hope this is helpful,

Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> G.Maubach at gmx.de
> Sent: Tuesday, May 24, 2016 11:55 AM
> To: r-help at r-project.org
> Subject: [R] Creating a data frame from scratch
> 
> Hi All,
> 
> I need to create a data frame from scratch and fill variables created on 
the fly
> with values. What I have so far:
> 
> -- schnipp --
> 
> # Example dataset
> gene <-
> c("ENSG00000208234","ENSG00000199674","ENSG00000221622","ENSG00000
> 207604",
> 
> "ENSG00000207431","ENSG00000221312","ENSG00134940305","ENSG0039403
> 9490",
>   "ENSG09943004048")
> hsap <- c(0,0,0, 0, 0, 0, 1,1, 1)
> mmul <- c(NA,2 ,3, NA, 2, 1 , NA,2, NA)
> mmus <- c(NA,2 ,NA, NA, NA, 2 , NA,3, 1) rnor <- c(NA,2 ,NA, 1 , NA, 3 ,
> NA,NA, 2) cfam <- c(NA,2,NA, 2, 1, 2, 2,NA, NA)
> 
> ds_example <- data.frame(gene, hsap, mmul, mmus, rnor, cfam)
> ds_example$gene <- as.character(ds_example$gene)
> 
> t_count_na <- function(dataset,
>                        variables = "all")
>   # credit: http://stackoverflow.com/questions/4862178/remove-rows-with-
> nas-in-data-frame
>   {
>   ds_na <- data.frame()
>   # if variables = "all" create character vector of variable names
>   if (variables == "all") {
>     variable_list <- dimnames(dataset)[[ 2 ]]
>   }
>   # if a character vector with variable names is given
>   # to run the function on a defined set of selected variables
>   else {
>     variable_list <- variables
>   }
> 
>   for (var in variable_list) {
>     new_name <- paste0("na_", var)
>     ds_na[[ new_name ]] <- as.data.frame(is.na(dataset[[ var ]]))
>   }
> 
>   ds_na[[ "na_count" ]] <- rowSums(ds_na)
>   return(ds_na)
> }
> 
> test <- t_count_na(dataset = ds_example, variables = c("mmul", "mmus"))
> 
> -- schnipp --
> 
> gives:
> 
>  Error in `[[<-.data.frame`(`*tmp*`, new_name, value =
> list(`is.na(dataset[[var]])` = c(TRUE,  :
>   replacement has 9 rows, data has 0 In addition: Warning message:
> In if (variables == "all") { :
>   the condition has length > 1 and only the first element will be used
> 
> My goal is to create a dataset from scratch on the fly which has the 
same
> amount of variables as the dataset ds_example plus a single variable 
storing
> the amount of NA's in a row for the given variables. This is the basis 
for a
> decious which cases to keep and which to drop.
> 
> I do not want to alter the base dataset like ds_example in the first 
place nor
> do I want to make a copy of the existing dataset due to memory 
allocation.
> The function shall also work with big data, e. g. datasets with more 
than 1 GB
> memory consumption.
> 
> I also do not want the newly created variables to be stored in the 
original
> data frame. They shall be separate.
> 
> A former similar solution worked:
> 
http://r.789695.n4.nabble.com/Creating-variables-on-the-fly-td4720034.html
> 
> Why doesn't this one?
> 
> How do I create the variables within the data frame if the data frame is
> empty?
> 
> Kind regards
> 
> Georg Maubach
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From S.Ellison at LGCGroup.com  Wed May 25 12:49:03 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 25 May 2016 11:49:03 +0100
Subject: [R] Factor Variable frequency
In-Reply-To: <20160524172946.Horde.9MStmdO36AbpWPdncFqmLKi@mail.sapo.pt>
References: <137597854.3222674.1464105256516.JavaMail.yahoo.ref@mail.yahoo.com>
	<137597854.3222674.1464105256516.JavaMail.yahoo@mail.yahoo.com>
	<20160524172946.Horde.9MStmdO36AbpWPdncFqmLKi@mail.sapo.pt>
Message-ID: <1A8C1289955EF649A09086A153E2672403E14A90A8@GBTEDVPEXCMB04.corp.lgc-group.com>



> ruipbarradas at sapo.pt
> Maybe the following (untested).
> 
> table(df$Protocol[df$Speed == "SLOW"])

Could also use which.max to get the particular item: ...
tprot <- table(df$Protocol[df$Speed == "SLOW"])
tprot[which.max(tprot)]

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From svazzole at gmail.com  Mon May 23 19:10:24 2016
From: svazzole at gmail.com (Simone Vazzoler)
Date: Mon, 23 May 2016 19:10:24 +0200
Subject: [R] [R-pkgs] New package: sparsevar
Message-ID: <57433980.4010800@gmail.com>

Dear R users,

I would like to announce a new package called "sparsevar" version 0.0.3:

https://cran.r-project.org/web/packages/sparsevar/

The package should be useful to estimate sparse VAR/VECM models.
The developing version can be found on Github:

https://github.com/svazzole/sparsevar

Best,
Simon

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From anoop.kumar1 at ge.com  Wed May 25 15:40:47 2016
From: anoop.kumar1 at ge.com (Kumar, Anoop (GE Corporate, consultant))
Date: Wed, 25 May 2016 13:40:47 +0000
Subject: [R] Connecting to Hive in Kerberos enabled hadoop cluster  from R
Message-ID: <3E1C08ABE98D2946977745E01A1A376F0173C481@BANURBNA05.e2k.ad.ge.com>

Hi All,

Request your help.

We are trying to connect to hive from R using Rstudio. Its a kerberos secured cluster. Code snippet is below.

==============

library(rJava)
library(RJDBC)

cp = c("/usr/hdp/2.3.2.0-2950/hive/lib/hive-jdbc.jar","/usr/hdp/2.3.2.0-2950/hadoop/lib/hadoop-common-2.7.1.2.3.2.0-2950.jar")
.jinit(classpath=cp)

drv <- JDBC("org.apache.hive.jdbc.HiveDriver",classPath = list.files("/usr/hdp/2.3.2.0-2950/hadoop/lib",pattern="jar$",full.names=T, recursive = TRUE),identifier.quote="`")

conn <- dbConnect(drv, "jdbc:hive2://host.node1.com:10000/default;principal=hive/shost.node1.com at node1.com<mailto:shost.node1.com at node1.com>", "", "")

show_databases <- dbGetQuery(conn, "show databases")

show_databases

==============

But we are getting the below error

Error in .jcall(drv at jdrv, "Ljava/sql/Connection;", "connect", as.character(url)[1],  :
  java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.security.UserGroupInformation

What are we missing here? A kerberos ticket is there in place. Shall we usekerberos  keytab inside R code? What is the function for ir. Also which hadoop libraries should we import for R and hive interaction?



Thanks & Regards,

Anoop Kumar K M


From james.hirschorn at hotmail.com  Wed May 25 17:37:10 2016
From: james.hirschorn at hotmail.com (James Hirschorn)
Date: Wed, 25 May 2016 11:37:10 -0400
Subject: [R] Reduce does not work with data.table?
Message-ID: <BLU437-SMTP106ED097DCFEE035776C6A5E9400@phx.gbl>

Reduce is failing when applied to a list of elements of class 
data.table. Perhaps this is a bug?

Example:

library(data.table)

dt1 <- data.table(x = 1:3, y = 4:6)
dt2 <- data.table(x = 4:6, y = 1:3)
dt3 <- data.table(x = 0:-2, y = 0:-2)

# This works fine
dt1 + dt2 + dt2
#    x y
# 1: 5 5
# 2: 6 6
# 3: 7 7

# But:
dt_list <- list(dt1, dt2, dt3)
Reduce("+", dt_list)
# Error in f(init, x[[i]]) : non-numeric argument to binary operator
# In addition: Warning message:
# In Reduce("+", dt_list) :
#   Incompatible methods ("Ops.data.frame", "Ops.data.table") for "+"

If I use data.frame instead of data.table, Reduce works properly.


From tmrsg11 at gmail.com  Wed May 25 18:33:32 2016
From: tmrsg11 at gmail.com (C W)
Date: Wed, 25 May 2016 12:33:32 -0400
Subject: [R] What are some toy models I can use in R?
Message-ID: <CAE2FW2kA0qgLqhqYC1=zMfRra6ysYYEA4yEBSwk0gMHpvFs_dg@mail.gmail.com>

Hi everyone,

I am searching for some toy models in R.  My goal is do to model checking.

For example,

My data come from statistical model N(5, 2), with n=100, call this model_1
Then, I add bias to that data with N(3, 1), with n=100, call this model_2

Ultimately, I want to see model_1+ model_2 gives good prediction or perhaps
parameter estimation.

I think this is a pretty standard statistical analysis problem?

How do people on this list deal with it?  Any suggestions?

Thank you,

Mike

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed May 25 19:11:02 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 25 May 2016 10:11:02 -0700
Subject: [R] Reduce does not work with data.table?
In-Reply-To: <BLU437-SMTP106ED097DCFEE035776C6A5E9400@phx.gbl>
References: <BLU437-SMTP106ED097DCFEE035776C6A5E9400@phx.gbl>
Message-ID: <DB68CAC6-C1F8-4C33-A55E-6FC661B8B6AE@dcn.davis.ca.us>

This is a design feature of data.table objects, which don't conform to the normal functional programming paradigm that R is usually designed to adhere to and which Reduce expects. Specifically, they normally modify in-place rather than leaving the original object alone. 

In short, don't do that. Read more about how data.tables work. Their benefits come with distinct disadvantages that you need to be very clear about or you will get into trouble like this regularly. 
-- 
Sent from my phone. Please excuse my brevity.

On May 25, 2016 8:37:10 AM PDT, James Hirschorn <james.hirschorn at hotmail.com> wrote:
>Reduce is failing when applied to a list of elements of class 
>data.table. Perhaps this is a bug?
>
>Example:
>
>library(data.table)
>
>dt1 <- data.table(x = 1:3, y = 4:6)
>dt2 <- data.table(x = 4:6, y = 1:3)
>dt3 <- data.table(x = 0:-2, y = 0:-2)
>
># This works fine
>dt1 + dt2 + dt2
>#    x y
># 1: 5 5
># 2: 6 6
># 3: 7 7
>
># But:
>dt_list <- list(dt1, dt2, dt3)
>Reduce("+", dt_list)
># Error in f(init, x[[i]]) : non-numeric argument to binary operator
># In addition: Warning message:
># In Reduce("+", dt_list) :
>#   Incompatible methods ("Ops.data.frame", "Ops.data.table") for "+"
>
>If I use data.frame instead of data.table, Reduce works properly.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Wed May 25 19:13:04 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 25 May 2016 18:13:04 +0100
Subject: [R] What are some toy models I can use in R?
In-Reply-To: <CAE2FW2kA0qgLqhqYC1=zMfRra6ysYYEA4yEBSwk0gMHpvFs_dg@mail.gmail.com>
References: <CAE2FW2kA0qgLqhqYC1=zMfRra6ysYYEA4yEBSwk0gMHpvFs_dg@mail.gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403E14A91F8@GBTEDVPEXCMB04.corp.lgc-group.com>

> -----Original Message-----
> My data come from statistical model N(5, 2), with n=100, call this model_1
> Then, I add bias to that data with N(3, 1), with n=100, call this model_2
Do you mean you have data from N(5,2) that has had data from N(3,1) added to it, or that you have two different sets of data?
Or do you mean that you want to know how to generate such data?

> Ultimately, I want to see model_1+ model_2 gives good prediction 
If you generate random data correctly following a model, the model will indeed predict the data pretty well. But under those circumstances it seems redundant to ask the question. Were you thinking of fitting a (possibly different) model to the data at some point ?  If so, what model would you want to fit? And what would you want to predict from it?

> or perhaps parameter estimation.
What parameters do you want to estimate?


> I think this is a pretty standard statistical analysis problem?
Unclear on that at present. See above.


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From tmrsg11 at gmail.com  Wed May 25 19:23:47 2016
From: tmrsg11 at gmail.com (C W)
Date: Wed, 25 May 2016 13:23:47 -0400
Subject: [R] What are some toy models I can use in R?
In-Reply-To: <1A8C1289955EF649A09086A153E2672403E14A91F8@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <CAE2FW2kA0qgLqhqYC1=zMfRra6ysYYEA4yEBSwk0gMHpvFs_dg@mail.gmail.com>
	<1A8C1289955EF649A09086A153E2672403E14A91F8@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <CAE2FW2=02XjdURzY6Cez7Lzyaq-Rqm9TcsqNiJTbBmRUp9qosA@mail.gmail.com>

On Wed, May 25, 2016 at 1:13 PM, S Ellison <S.Ellison at lgcgroup.com> wrote:

> > -----Original Message-----
> > My data come from statistical model N(5, 2), with n=100, call this
> model_1
> > Then, I add bias to that data with N(3, 1), with n=100, call this model_2
> Do you mean you have data from N(5,2) that has had data from N(3,1) added
> to it, or that you have two different sets of data?
> Or do you mean that you want to know how to generate such data?
>

I generate toy data from N(5,2). X input will be the same for model_1 and
model_2, say, seq(-3, 3, by=0.01).


> > Ultimately, I want to see model_1+ model_2 gives good prediction
> If you generate random data correctly following a model, the model will
> indeed predict the data pretty well. But under those circumstances it seems
> redundant to ask the question. Were you thinking of fitting a (possibly
> different) model to the data at some point ?  If so, what model would you
> want to fit? And what would you want to predict from it?
>

I only use model_1, model_2 for data generation.  I am using machine
learning methods for estimation and prediction to see if the method is good
and robust.  Then, check performance by comparing results with the known
model_1 and model_2.


> > or perhaps parameter estimation.
> What parameters do you want to estimate?








>
> > I think this is a pretty standard statistical analysis problem?
> Unclear on that at present. See above.
>
>
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:13}}


From jfhenson1 at gmail.com  Wed May 25 20:59:06 2016
From: jfhenson1 at gmail.com (James Henson)
Date: Wed, 25 May 2016 13:59:06 -0500
Subject: [R] mixed models
Message-ID: <CABPq8JN974cVTJvRT-+hHigPERV+-uVzzNq6OCZuqpHB4q5xgw@mail.gmail.com>

Greetings R community,

My aim is to analyze a mixed-effects model with temporal pseudo-replication
(repeated measures on the same experimental unit) using ?nlme?.  However,
my code returns the error message ?Error in na.fail.default?, even though
the data frame does not contain missing values. My code is below, and the
data file is attached as ?Eboni2.txt.

library("nlme")

str(Eboni2)

head(Eboni2)

model1 <- lme(preDawn ~ Irrigation, random=~season_order|treeNo,
data=Eboni2)

I am genuinely confused.  Hope someone can help.

Best regards,

James F. Henson
-------------- next part --------------
number	Location	Season	season_order	Month	treeID	treeNo	preDawn	midday	Irrigation	Pnet	Gs	E	WUE	d15N	d13C 	Nper	Cper	include2
1	UCC	November	5	Nov	UCCLO 1	60	1.4	1.3	N	9	0.290700373	3.766207481	2.38967185					no
2	UCC	November	5	Nov	UCCLO 2	72	1.2	1.3	N	11	0.326258186	3.120573618	3.524992949					no
3	UCC	November	5	Nov	UCCLO 3	78	1.1	1.2	N	8	0.287095701	1.693820753	4.723049937	3	-27.44	2.12	52.12	yes
4	UCC	November	5	Nov	UCCLO 4	79	1.1	2.1	N	10	0.247517983	1.83934285	5.436724317	3.61	-29.5	1.42	51.97	yes
5	UCC	November	5	Nov	UCCLO 5	80	1.4	1.3	N	13	0.300922817	3.082277827	4.217660032					no
6	UCC	November	5	Nov	UCCLO 6	81	0.6	1.8	N	17	0.348733689	2.534550345	6.70730413	2.79	-30.5	1.49	49.94	yes
7	UCC	November	5	Nov	UCCLO 7	82	0.9	1.2	N	12	0.272690759	1.809851748	6.630377328	2.43	-29.4	1.55	53.12	yes
8	UCC	November	5	Nov	UCCLO 8	83	1.4	1.1	N	11	0.269862804	1.919849835	5.729614785	2.85	-28.37	1.78	53.52	yes
9	UCC	November	5	Nov	UCCLO 9	84	0.8	1	N	16	0.323332222	2.394825767	6.68107059	2.43	-30.1	1.54	52.88	yes
10	UCC	November	5	Nov	UCCLO 10	62	0.9	1.2	N	17	0.29488545	1.429058721	11.89594224	1.51	-31.96	1.61	52.94	yes
11	UCC	November	5	Nov	UCCLO 11	63	1.3	2	N	14	0.241601092	3.29815495	4.244797535					no
12	UCC	November	5	Nov	UCCLO 12	64	1.2	1.3	N	11	0.261040739	1.610353496	6.83079835	2.62	-28.94	1.46	51.9	yes
13	UCC	November	5	Nov	UCCLO 13	65	1.2	1.3	N	13	0.238863129	2.221057396	5.853068012	1.13	-28.81	2.08	51.43	yes
14	UCC	November	5	Nov	UCCLO 14	66	1.1	1.5	N	9	0.309603194	2.859756011	3.14712163					no
15	UCC	November	5	Nov	UCCLO 15	67	1.1	1.3	N	18	0.383441504	2.949059627	6.103640576	1.51	-30.14	1.65	52.04	yes
16	UCC	November	5	Nov	UCCLO 16	68	1.3	2.7	N	13	0.269711187	1.430856375	9.085468137	1.99	-29.09	1.87	51.21	yes
17	UCC	November	5	Nov	UCCLO 17	69	0.8	1.4	N	13	0.245685997	3.808576972	3.41334837					no
18	UCC	November	5	Nov	UCCLO 18	70	1.6	1.8	N	11	0.271419599	2.305398713	4.771408926	2.94	-29.22	1.93	51.46	yes
19	UCC	November	5	Nov	UCCLO 19	71	1	1.5	N	18	0.338103566	2.303586185	7.813903435	2.93	-30.27	1.92	51.51	yes
20	UCC	November	5	Nov	UCCLO 20	73	1.1	1.2	N	11	0.27096196	3.230604699	3.404935307					no
21	UCC	November	5	Nov	UCCLO 21	74	1.2	1.5	N	10	0.294348983	3.319661403	3.012355414					no
22	UCC	November	5	Nov	UCCLO 22	75	1.5	1.9	N	12	0.230438536	2.935053987	4.088510825	1.74	-29.49	1.64	50.28	yes
23	UCC	November	5	Nov	UCCLO 23	76	1.1	1.4	N	14	0.264963659	3.689609021	3.794439985					no
24	UCC	November	5	Nov	UCCLO 24	77	0.7	1.3	N	16	0.267920137	2.430980175	6.581707316	2.8	-30.17	1.73	51.3	yes
25	TAMU	November	5	Nov	LO 20	20	1.5	1	Y	10	0.322593857	1.453204569	6.881343627					no
26	TAMU	November	5	Nov	LO 22	21	1.7	1.9	Y	8	0.24104886	0.99667791	8.026665305	3.9	-27.74	1.61	52.86	yes
27	TAMU	November	5	Nov	LO 24	22	1.8	1.8	Y	12	0.280647763	3.254187888	3.687555978					no
28	TAMU	November	5	Nov	LO 26	23	1.3	1.3	Y	9	0.258751416	1.724860761	5.217812478					no
29	TAMU	November	5	Nov	LO 28	24	1.5	1.1	Y	9	0.236153174	1.897511729	4.743053687					no
30	TAMU	November	5	Nov	LO 30	25	1.8	1.4	Y	11	0.21951989	0.67223479	16.36333044	2.68	-28.44	1.86	54.25	yes
31	TAMU	November	5	Nov	LO 32	26	1.8	2.1	Y	7	0.299287418	1.248677324	5.605931867					no
32	TAMU	November	5	Nov	LO 34	27	1.9	1.9	Y	14	0.217162789	2.918574722	4.796861938					no
33	TAMU	November	5	Nov	LO 36	28	1.9	1.5	Y	7	0.249982368	1.789033529	3.912727116					no
34	TAMU	November	5	Nov	LO 38	29	1.8	1.8	Y	9	0.279566361	1.383706509	6.504269468					no
35	TAMU	November	5	Nov	LO 40	30	1.3	1.6	Y	10	0.300672565	1.701034558	5.878775334					no
36	TAMU	November	5	Nov	LO 42	31	1.5	1.6	Y	9	0.314102213	2.179212456	4.12993234					no
37	TAMU	November	5	Nov	LO 44	32	1.4	2	Y	13	0.299888734	1.588679576	8.182896161					no
38	TAMU	November	5	Nov	LO 46	33	1.1	1.3	Y	11	0.25718211	1.84387609	5.965693714	3.8	-28.51	1.5	52.24	yes
39	TAMU	November	5	Nov	LO 48	34	0.8	2	Y	9	0.287651796	1.377836128	6.531981427					no
40	TAMU	November	5	Nov	LO 50	35	1.8	2	Y	13	0.253516067	1.46398661	8.879862638	4.52	-28.1	1.15	53.2	yes
41	TAMU	November	5	Nov	LO 52	36	1.2	2	Y	13	0.273562505	2.539744934	5.118624247					no
42	TAMU	November	5	Nov	LO 54	37	0.8	1.9	Y	8	0.208370572	1.801589698	4.440522729					no
43	TAMU	November	5	Nov	LO 56	38	0.7	2	Y	9	0.250046763	1.587884359	5.667919045					no
44	TAMU	November	5	Nov	LO 58	39	1.1	1.9	Y	12	0.245814494	1.363896019	8.79832468					no
45	TAMU	November	5	Nov	LO 60	40	1	1.6	Y	7	0.264044038	1.543697369	4.534567553					no
46	TAMU	November	5	Nov	LO 62	41	0.8	1.3	Y	11	0.269651449	1.43295614	7.676438722	4.21	-29.43	1.31	53.5	yes
47	TAMU	November	5	Nov	LO 64	42	0.7	1.8	Y	14	0.273648671	1.32575335	10.56003366	4.99	-28.99	1.86	52.86	yes
48	TAMU	November	5	Nov	LO 66	43	1	1.2	Y	16	0.227352932	1.41692703	11.29204233	4.63	-29.7	1.8	49.65	yes
49	TAMU	November	5	Nov	LO 68	44	1.7	2.1	Y	8	0.203509699	1.78833468	4.473435588	4.11	-27.72	1.9	53.29	yes
50	TAMU	November	5	Nov	LO 70	45	0.7	2.1	Y	13	0.290851011	1.969844277	6.599506443					no
51	TAMU	November	5	Nov	LO 72	46	0.4	1.6	Y	14	0.246528837	1.342083902	10.43153858					no
52	TAMU	November	5	Nov	LO 74	47	0.4	1.1	Y	8	0.24920026	1.667721992	4.796962585					no
53	TAMU	November	5	Nov	LO 76	48	1.3	1.6	Y	10	0.230027702	1.93010901	5.181054515	4.68	-27.45	1.55	52.3	yes
54	TAMU	November	5	Nov	LO 78	49	0.6	2	Y	11	0.208788153	1.115388436	9.862035188					no
55	TAMU	November	5	Nov	LO 80	50	1.6	2.3	Y	9	0.211764744	1.29341738	6.958310704	3.87	-27.89	1.83	54.31	yes
56	TAMU	November	5	Nov	LO 82	51	1	2	Y	13	0.2479042	1.604746059	8.100970196					no
57	TAMU	November	5	Nov	LO 84	52	0.4	1.9	Y	12	0.212812308	1.181355877	10.1578197					no
58	TAMU	November	5	Nov	LO 86	53	0.9	2.3	Y	8	0.263113975	1.410474918	5.671848466					no
59	TAMU	November	5	Nov	LO 88	54	1	2.2	Y	14	0.263532325	1.584112377	8.837756843					no
60	TAMU	November	5	Nov	LO 90	55	0.9	1.8	Y	7	0.287269272	1.668603338	4.195125254					no
61	TAMU	November	5	Nov	LO 92	56	1	1.9	Y	9	0.299680407	1.114427828	8.075893097					no
62	TAMU	November	5	Nov	LO 94	57	1.1	1.4	Y	14	0.279164586	1.375108271	10.1810165					no
63	TAMU	November	5	Nov	LO 96	58	1	1.6	Y	7	0.291635927	1.075680412	6.507509038					no
64	TAMU	November	5	Nov	LO 98	59	1.7	2.5	Y	7	0.220827722	1.31191323	5.335718735	6.16	-27.79	2.09	52.89	yes
65	TAMU	November	5	Nov	LO 100	1	0.8	1.9	Y	13	0.255527908	1.758146498	7.394150612					no
66	TAMU	November	5	Nov	LO 102	2	1.3	1.7	Y	7	0.248576108	1.055111659	6.634368925					no
67	TAMU	November	5	Nov	LO 104	3	1.2	1.3	Y	10	0.253814263	1.897564295	5.26991366					no
68	TAMU	November	5	Nov	LO 106	4	0.8	2.5	Y	12	0.21028689	1.85933448	6.453922158	7.14	-29.47	1.66	53.62	yes
69	TAMU	November	5	Nov	LO 108	5	0.7	1.2	Y	16	0.277244998	1.92065268	8.330501483	10.59	-30.08	1.53	50.36	yes
70	TAMU	November	5	Nov	LO 112	6	0.5	1.7	Y	13	0.313423204	1.408380987	9.230456898					no
71	TAMU	November	5	Nov	LO 114	7	0.8	1.8	Y	11	0.296853932	1.18142335	9.310802936					no
72	TAMU	November	5	Nov	LO 116	8	0.6	1.5	Y	8	0.219052235	1.565415684	5.110463683					no
73	TAMU	November	5	Nov	LO 118	9	0.8	1.3	Y	11	0.254059832	1.439492281	7.641583181					no
74	TAMU	November	5	Nov	LO 120	10	1.4	1.2	Y	13	0.295863757	2.053470029	6.330747378					no
75	TAMU	November	5	Nov	LO 122	11	0.4	1.3	Y	14	0.255143554	1.679031848	8.338138443					no
76	TAMU	November	5	Nov	LO 124	12	1.2	1.3	Y	7	0.287092508	1.270490069	5.509684941					no
77	TAMU	November	5	Nov	LO 126	13	0.9	1.3	Y	13	0.259681657	1.547292728	8.401771537					no
78	TAMU	November	5	Nov	LO 128	14	1.5	2	Y	14	0.28384704	1.793440552	7.806224735					no
79	TAMU	November	5	Nov	LO 130	15	1	1.4	Y	12	0.210311458	1.83694222	6.532595239	5.36	-29.9	1.62	47.34	yes
80	TAMU	November	5	Nov	LO 132	16	0.9	1	Y	11	0.233376827	1.77217705	6.207054764	3.77	-29.23	1.62	52.99	yes
81	TAMU	November	5	Nov	LO 134	17	0.7	1.3	Y	12	0.242150842	1.561428058	7.685272425					no
82	TAMU	November	5	Nov	LO 136	18	1	1.1	Y	11	0.284930501	2.277942887	4.828918258					no
83	TAMU	November	5	Nov	LO 138	19	0.9	1.2	Y	9	0.291023488	1.372329228	6.558193044					no
85	UCC	January	1	Jan	UCCLO 1	60	0.9	1.4	N	7	0.161880041	1.406355778	4.977403377					no
86	UCC	January	1	Jan	UCCLO 2	72	0.8	1.3	N	8	0.156866545	1.504174784	5.318530856					no
87	UCC	January	1	Jan	UCCLO 3	78	1.1	1.7	N	8	0.12228854	1.54686668	5.171744988	3	-27.44	2.12	52.12	yes
88	UCC	January	1	Jan	UCCLO 4	79	1.1	1.8	N	11	0.161528665	1.84964731	5.947079717	3.61	-29.5	1.42	51.97	yes
89	UCC	January	1	Jan	UCCLO 5	80	0.7	1.4	N	11	0.182641088	2.499041888	4.401686924					no
90	UCC	January	1	Jan	UCCLO 6	81	0.6	0.9	N	13	0.195054357	1.7808668	7.299816022	2.79	-30.5	1.49	49.94	yes
91	UCC	January	1	Jan	UCCLO 7	82	1.2	1.7	N	9	0.188980441	1.85525606	4.851082389	2.43	-29.4	1.55	53.12	yes
92	UCC	January	1	Jan	UCCLO 8	83	1.8	1.6	N	8	0.157032847	1.90228563	4.205467294	2.85	-28.37	1.78	53.52	yes
93	UCC	January	1	Jan	UCCLO 9	84	0.9	1.2	N	11	0.162112343	1.65491951	6.646848946	2.43	-30.1	1.54	52.88	yes
94	UCC	January	1	Jan	UCCLO 10	62	0.8	1.3	N	14	0.158064634	1.61299496	8.679506351	1.51	-31.96	1.61	52.94	yes
95	UCC	January	1	Jan	UCCLO 11	63	0.9	1.9	N	14	0.128415938	2.293151463	6.105135323					no
96	UCC	January	1	Jan	UCCLO 12	64	1.7	1.4	N	10	0.153399434	1.81802617	5.500470876	2.62	-28.94	1.46	51.9	yes
97	UCC	January	1	Jan	UCCLO 13	65	1.7	2.4	N	11	0.160178589	1.83990862	5.978557783	1.13	-28.81	2.08	51.43	yes
98	UCC	January	1	Jan	UCCLO 14	66	0.8	2.6	N	6	0.218084902	2.071440489	2.89653506					no
99	UCC	January	1	Jan	UCCLO 15	67	0.9	1.4	N	15	0.180625931	1.78263396	8.41451489	1.51	-30.14	1.65	52.04	yes
100	UCC	January	1	Jan	UCCLO 16	68	1.2	2.7	N	11	0.166554865	1.73207003	6.35078248	1.99	-29.09	1.87	51.21	yes
101	UCC	January	1	Jan	UCCLO 17	69	0.7	1.5	N	12	0.158543968	1.631746744	7.354082394					no
102	UCC	January	1	Jan	UCCLO 18	70	0.7	1.7	N	11	0.162452016	1.51181973	7.275999765	2.94	-29.22	1.93	51.46	yes
103	UCC	January	1	Jan	UCCLO 19	71	0.8	1.4	N	12	0.177728036	1.93415957	6.204245082	2.93	-30.27	1.92	51.51	yes
104	UCC	January	1	Jan	UCCLO 20	73	1	1.5	N	11	0.215189319	1.444529	7.614939					no
105	UCC	January	1	Jan	UCCLO 21	74	1.7	1.5	N	9	0.190056967	2.23561021	4.02574651					no
106	UCC	January	1	Jan	UCCLO 22	75	0.8	1	N	11	0.15989473	1.76652779	6.226904588	1.74	-29.49	1.64	50.28	yes
107	UCC	January	1	Jan	UCCLO 23	76	1.4	2.8	N	12	0.153742861	1.504216309	7.977576052					no
108	UCC	January	1	Jan	UCCLO 24	77	0.8	1.2	N	14	0.183289749	1.94948647	7.181378386	2.8	-30.17	1.73	51.3	yes
109	TAMU	January	1	Jan	LO 20	20	0.8	0.9	Y	8	0.183818559	0.834314047	9.588715463					no
110	TAMU	January	1	Jan	LO 22	21	1	1.7	Y	6	0.142245885	0.79788627	7.519868715	3.9	-27.74	1.61	52.86	yes
111	TAMU	January	1	Jan	LO 24	22	0.7	1.9	Y	7	0.116291064	0.890123302	7.864079037					no
112	TAMU	January	1	Jan	LO 26	23	1.1	1.2	Y	7	0.123537025	0.815935559	8.579108883					no
113	TAMU	January	1	Jan	LO 28	24	1.4	1.8	Y	9	0.144951816	0.850424837	10.58294585					no
114	TAMU	January	1	Jan	LO 30	25	1.4	1.3	Y	10	0.173492639	0.91630918	10.91334696	2.68	-28.44	1.86	54.25	yes
115	TAMU	January	1	Jan	LO 32	26	1	2.5	Y	7	0.190240078	0.962105644	7.275708283					no
116	TAMU	January	1	Jan	LO 34	27	0.7	2.3	Y	12	0.158541474	0.86068911	13.94231653					no
117	TAMU	January	1	Jan	LO 36	28	1	1.8	Y	5	0.214456138	0.896264624	5.57870953					no
118	TAMU	January	1	Jan	LO 38	29	1	1.5	Y	6	0.1380589	0.854026215	7.025545465					no
119	TAMU	January	1	Jan	LO 40	30	1.2	1.7	Y	9	0.145923139	0.856616223	10.50645524					no
120	TAMU	January	1	Jan	LO 42	31	1.2	1.5	Y	8	0.121629444	0.77247713	10.35629365					no
121	TAMU	January	1	Jan	LO 44	32	0.7	1.7	Y	9	0.173329619	0.81600796	11.02930418					no
122	TAMU	January	1	Jan	LO 46	33	1.6	1.5	Y	7	0.169813254	0.57842496	12.10182908	3.8	-28.51	1.5	52.24	yes
123	TAMU	January	1	Jan	LO 48	34	1.2	1.8	Y	9	0.162217531	0.848908702	10.60184679					no
124	TAMU	January	1	Jan	LO 50	35	1.2	1.8	Y	10	0.172082329	0.58600172	17.06479633	4.52	-28.1	1.15	53.2	yes
125	TAMU	January	1	Jan	LO 52	36	1.1	1.6	Y	11	0.195988575	0.905926691	12.14226285					no
126	TAMU	January	1	Jan	LO 54	37	0.8	2.3	Y	7	0.176717041	0.864352122	8.0985513					no
127	TAMU	January	1	Jan	LO 56	38	0.5	1.8	Y	8	0.119738121	0.803434249	9.957255379					no
128	TAMU	January	1	Jan	LO 58	39	0.9	1.9	Y	11	0.18350771	0.765760553	14.36480368					no
129	TAMU	January	1	Jan	LO 60	40	0.6	1.3	Y	6	0.175230362	0.822160314	7.297846784					no
130	TAMU	January	1	Jan	LO 62	41	0.8	1.8	Y	11	0.174024183	0.5165785	21.29395629	4.21	-29.43	1.31	53.5	yes
131	TAMU	January	1	Jan	LO 64	42	0.6	1.6	Y	11	0.184376069	0.9064408	12.13537608	4.99	-28.99	1.86	52.86	yes
132	TAMU	January	1	Jan	LO 66	43	0.8	1.5	Y	7	0.152550508	0.66727194	10.49047559	4.63	-29.7	1.8	49.65	yes
133	TAMU	January	1	Jan	LO 68	44	1.5	2.2	Y	8	0.177155327	0.85540539	9.352290848	4.11	-27.72	1.9	53.29	yes
134	TAMU	January	1	Jan	LO 70	45	1.1	2.1	Y	8	0.133351563	0.855914299	9.34673017					no
135	TAMU	January	1	Jan	LO 72	46	0.7	1.6	Y	10	0.180345099	0.882984107	11.32523216					no
136	TAMU	January	1	Jan	LO 74	47	0.7	1.5	Y	9	0.191334105	0.824138481	10.92049481					no
137	TAMU	January	1	Jan	LO 76	48	1.5	2.3	Y	7	0.153710179	0.83080256	8.425587904	4.68	-27.45	1.55	52.3	yes
138	TAMU	January	1	Jan	LO 78	49	0.8	1.7	Y	8	0.208043455	0.731335594	10.93889052					no
139	TAMU	January	1	Jan	LO 80	50	1.4	2.7	Y	8	0.187328559	0.77089713	10.3775195	3.87	-27.89	1.83	54.31	yes
140	TAMU	January	1	Jan	LO 82	51	0.6	2.2	Y	12	0.22961866	0.852124907	14.08244249					no
141	TAMU	January	1	Jan	LO 84	52	0.6	2.2	Y	10	0.145526834	0.840222553	11.90160864					no
142	TAMU	January	1	Jan	LO 86	53	0.6	2.1	Y	7	0.177606625	0.815144542	8.587434051					no
143	TAMU	January	1	Jan	LO 88	54	0.6	2.4	Y	6	0.155279594	0.755885724	7.937707795					no
144	TAMU	January	1	Jan	LO 90	55	0.4	1.2	Y	5	0.16802609	0.935556796	5.344410964					no
145	TAMU	January	1	Jan	LO 92	56	1.1	1.8	Y	7	0.144527872	0.855718636	8.18025891					no
146	TAMU	January	1	Jan	LO 94	57	0.6	1.2	Y	12	0.210299962	0.879427361	13.64524295					no
147	TAMU	January	1	Jan	LO 96	58	0.8	1.8	Y	6	0.149986031	0.801742899	7.483695845					no
148	TAMU	January	1	Jan	LO 98	59	1.6	2.2	Y	11	0.15874532	0.97637024	11.26621803	6.16	-27.79	2.09	52.89	yes
149	TAMU	January	1	Jan	LO 100	1	0.4	1.1	Y	7	0.127252198	0.906788252	7.719553029					no
150	TAMU	January	1	Jan	LO 102	2	0.8	1.8	Y	6	0.11966337	0.859871787	6.977784467					no
151	TAMU	January	1	Jan	LO 104	3	1	1.7	Y	6	0.180602613	0.852203505	7.040571838					no
152	TAMU	January	1	Jan	LO 106	4	0.9	2.5	Y	10	0.161701328	0.76239511	13.11655842	7.14	-29.47	1.66	53.62	yes
153	TAMU	January	1	Jan	LO 108	5	0.9	1.2	Y	10	0.194166255	0.74101066	13.49508251	10.59	-30.08	1.53	50.36	yes
154	TAMU	January	1	Jan	LO 112	6	0.8	1.3	Y	10	0.20884564	0.784241455	12.75117495					no
155	TAMU	January	1	Jan	LO 114	7	0.9	1.4	Y	8	0.144724931	0.916710485	8.726855564					no
156	TAMU	January	1	Jan	LO 116	8	0.4	2.1	Y	6	0.106510845	0.801374451	7.487136626					no
157	TAMU	January	1	Jan	LO 118	9	1	1.8	Y	7	0.110283246	0.84863929	8.248498606					no
158	TAMU	January	1	Jan	LO 120	10	1.2	1.5	Y	7	0.207252084	0.802059669	8.727530225					no
159	TAMU	January	1	Jan	LO 122	11	0.5	1.9	Y	12	0.16593952	0.848360268	14.144934					no
160	TAMU	January	1	Jan	LO 124	12	0.9	1.3	Y	7	0.167302019	0.811397256	8.627093511					no
161	TAMU	January	1	Jan	LO 126	13	0.9	1.5	Y	8	0.120998308	0.817875942	9.781434554					no
162	TAMU	January	1	Jan	LO 128	14	1.1	1.7	Y	9	0.124092571	0.845438022	10.64536934					no
163	TAMU	January	1	Jan	LO 130	15	0.8	2.2	Y	9	0.188602316	0.589838	15.25842689	5.36	-29.9	1.62	47.34	yes
164	TAMU	January	1	Jan	LO 132	16	1.7	2.2	Y	9	0.171591783	0.741469731	12.13805449	3.77	-29.23	1.62	52.99	yes
165	TAMU	January	1	Jan	LO 134	17	0.7	1.4	Y	12	0.181932332	0.823824692	14.56620579					no
166	TAMU	January	1	Jan	LO 136	18	0.7	1.2	Y	12	0.170711793	0.791828085	15.15480472					no
167	TAMU	January	1	Jan	LO 138	19	0.9	1.6	Y	10	0.210658939	0.852242733	11.73374629					no
169	UCC	May	2	May	UCCLO 1	60	1.1	1.3	N	7	0.316639589	5.285635275	1.324344121					no
170	UCC	May	2	May	UCCLO 2	72	1.2	1.6	N	7	0.293141957	5.119979995	1.367192842					no
171	UCC	May	2	May	UCCLO 3	78	1.2	2.9	N	9	0.277453436	2.72302876	3.305143204	3	-27.44	2.12	52.12	yes
172	UCC	May	2	May	UCCLO 4	79	1.5	2	N	14	0.305549208	5.33021023	2.626538053	3.61	-29.5	1.42	51.97	yes
173	UCC	May	2	May	UCCLO 5	80	1.2	1.3	N	7	0.300155473	4.979026021	1.405897453					no
174	UCC	May	2	May	UCCLO 6	81	1.5	1.2	N	15	0.333257617	6.4322744	2.331990066	2.79	-30.5	1.49	49.94	yes
175	UCC	May	2	May	UCCLO 7	82	1.9	2.5	N	15	0.297234631	5.90542661	2.540036646	2.43	-29.4	1.55	53.12	yes
176	UCC	May	2	May	UCCLO 8	83	1.9	1.2	N	9	0.289897429	5.62006808	1.601404088	2.85	-28.37	1.78	53.52	yes
177	UCC	May	2	May	UCCLO 9	84	1	1.4	N	14	0.303457212	5.28754793	2.647730136	2.43	-30.1	1.54	52.88	yes
178	UCC	May	2	May	UCCLO 10	62	0.9	1.7	N	16	0.304182766	6.04044485	2.648811536	1.51	-31.96	1.61	52.94	yes
179	UCC	May	2	May	UCCLO 11	63	1.4	2.1	N	12	0.326884552	5.17612739	2.318335523					no
180	UCC	May	2	May	UCCLO 12	64	1.1	1.2	N	10	0.276244686	5.270007	1.897530686	2.62	-28.94	1.46	51.9	yes
181	UCC	May	2	May	UCCLO 13	65	1.1	2.6	N	11	0.300648574	5.24136337	2.098690593	1.13	-28.81	2.08	51.43	yes
182	UCC	May	2	May	UCCLO 14	66	1.3	2.9	N	7	0.246552761	5.545986735	1.262173953					no
183	UCC	May	2	May	UCCLO 15	67	1.5	1.9	N	13	0.335921719	6.09893218	2.131520669	1.51	-30.14	1.65	52.04	yes
184	UCC	May	2	May	UCCLO 16	68	1.6	2	N	9	0.324193597	5.72560957	1.571885035	1.99	-29.09	1.87	51.21	yes
185	UCC	May	2	May	UCCLO 17	69	1.7	1.5	N	16	0.316958126	5.648480849	2.832620031					no
186	UCC	May	2	May	UCCLO 18	70	1	2.2	N	13	0.325547599	5.85551463	2.220129369	2.94	-29.22	1.93	51.46	yes
187	UCC	May	2	May	UCCLO 19	71	1.7	1.5	N	14	0.328332375	6.04871068	2.314542841	2.93	-30.27	1.92	51.51	yes
188	UCC	May	2	May	UCCLO 20	73	2	1.7	N	11	0.30621657	5.60632127	1.962070932					no
189	UCC	May	2	May	UCCLO 21	74	1.9	1.9	N	13	0.268343145	5.724442397	2.270963545					no
190	UCC	May	2	May	UCCLO 22	75	1	1.5	N	9	0.317740317	5.27515959	1.706109521	1.74	-29.49	1.64	50.28	yes
191	UCC	May	2	May	UCCLO 23	76	0.9	2.4	N	9	0.265551512	6.193689743	1.453091836					no
192	UCC	May	2	May	UCCLO 24	77	1	1.2	N	15	0.287738681	6.29067696	2.38448105	2.8	-30.17	1.73	51.3	yes
193	TAMU	May	2	May	LO 20	20	1	1.2	Y	7	0.349811926	2.253698306	3.106005795					no
194	TAMU	May	2	May	LO 22	21	1.2	1.9	Y	6	0.275421458	1.77032779	3.389202855	3.9	-27.74	1.61	52.86	yes
195	TAMU	May	2	May	LO 24	22	0.6	1.7	Y	6	0.272986464	1.697838075	3.533905905					no
196	TAMU	May	2	May	LO 26	23	1.2	1.2	Y	8	0.249606112	1.939489906	4.124795894					no
197	TAMU	May	2	May	LO 28	24	1.2	1.9	Y	10	0.282026998	2.43014371	4.114982978					no
198	TAMU	May	2	May	LO 30	25	1	1.8	Y	9	0.30392021	2.17869223	4.130918482	2.68	-28.44	1.86	54.25	yes
199	TAMU	May	2	May	LO 32	26	0.9	2.1	Y	8	0.263862918	1.791971333	4.464357131					no
200	TAMU	May	2	May	LO 34	27	1	2.1	Y	12	0.351639853	1.849766181	6.487306407					no
201	TAMU	May	2	May	LO 36	28	1.1	1.6	Y	8	0.291926303	1.799071548	4.446738103					no
202	TAMU	May	2	May	LO 38	29	1.1	1.4	Y	7	0.332342876	1.914083759	3.657102239					no
203	TAMU	May	2	May	LO 40	30	1.2	1.2	Y	8	0.342764842	1.829052704	4.373848815					no
204	TAMU	May	2	May	LO 42	31	1.2	1.5	Y	10	0.327191117	1.441438404	6.937514621					no
205	TAMU	May	2	May	LO 44	32	1	1.5	Y	10	0.299559461	1.846397699	5.415951289					no
206	TAMU	May	2	May	LO 46	33	1.1	1.5	Y	8	0.325122142	1.77658283	4.503026746	3.8	-28.51	1.5	52.24	yes
207	TAMU	May	2	May	LO 48	34	0.9	1.8	Y	9	0.284736904	1.61697761	5.565939778					no
208	TAMU	May	2	May	LO 50	35	1.1	1.8	Y	8	0.334570345	2.0351123	3.930987003	4.52	-28.1	1.15	53.2	yes
209	TAMU	May	2	May	LO 52	36	1.2	2	Y	9	0.281119626	2.192525612	4.104855128					no
210	TAMU	May	2	May	LO 54	37	0.8	2.2	Y	8	0.270493035	1.393015109	5.742938428					no
211	TAMU	May	2	May	LO 56	38	0.8	2.5	Y	8	0.290517025	1.376717384	5.810923937					no
212	TAMU	May	2	May	LO 58	39	0.9	1.5	Y	12	0.366198032	1.591227755	7.541346589					no
213	TAMU	May	2	May	LO 60	40	0.9	1.6	Y	7	0.21682211	1.429371037	4.897258878					no
214	TAMU	May	2	May	LO 62	41	0.9	1.8	Y	11	0.323515246	1.66368315	6.611835914	4.21	-29.43	1.31	53.5	yes
215	TAMU	May	2	May	LO 64	42	0.5	1.3	Y	5	0.314276384	2.08307089	2.400302373	4.99	-28.99	1.86	52.86	yes
216	TAMU	May	2	May	LO 66	43	0.9	1.1	Y	12	0.32901877	1.79607523	6.681234616	4.63	-29.7	1.8	49.65	yes
217	TAMU	May	2	May	LO 68	44	1.5	2.6	Y	5	0.296184246	1.66827402	2.997109552	4.11	-27.72	1.9	53.29	yes
218	TAMU	May	2	May	LO 70	45	1.2	1.9	Y	9	0.275476614	1.134352009	7.9340451					no
219	TAMU	May	2	May	LO 72	46	1	1.3	Y	8	0.326263383	1.306364065	6.123867163					no
220	TAMU	May	2	May	LO 74	47	0.6	1.6	Y	9	0.341184564	1.845148325	4.877656651					no
221	TAMU	May	2	May	LO 76	48	0.8	2.4	Y	8	0.335342153	1.9424742	4.118458819	4.68	-27.45	1.55	52.3	yes
222	TAMU	May	2	May	LO 78	49	0.9	1.6	Y	8	0.282258014	1.04132604	7.682512193					no
223	TAMU	May	2	May	LO 80	50	0.9	2.2	Y	8	0.336996262	2.27329483	3.519121187	3.87	-27.89	1.83	54.31	yes
224	TAMU	May	2	May	LO 82	51	1	2.3	Y	12	0.338450348	1.556827932	7.707980925					no
225	TAMU	May	2	May	LO 84	52	0.9	2.3	Y	11	0.321803527	1.826471114	6.022542549					no
226	TAMU	May	2	May	LO 86	53	0.7	2	Y	10	0.309384795	2.08377843	4.798974717					no
227	TAMU	May	2	May	LO 88	54	0.4	2.2	Y	6	0.279809777	1.882130135	3.187877335					no
228	TAMU	May	2	May	LO 90	55	0.2	2	Y	6	0.349973703	1.821303814	3.294343291					no
229	TAMU	May	2	May	LO 92	56	1.4	2	Y	10	0.277376975	1.41291236	7.077579816					no
230	TAMU	May	2	May	LO 94	57	0.6	1.2	Y	10	0.296502629	2.06368235	4.845706995					no
231	TAMU	May	2	May	LO 96	58	0.6	1.7	Y	7	0.253435852	1.775923084	3.941612146					no
232	TAMU	May	2	May	LO 98	59	1	2.9	Y	5	0.29061346	1.66656969	3.000174568	6.16	-27.79	2.09	52.89	yes
233	TAMU	May	2	May	LO 100	1	0.3	1.9	Y	12	0.347138248	1.845001832	6.504058583					no
234	TAMU	May	2	May	LO 102	2	0.8	2	Y	8	0.344086625	1.576475416	5.074611326					no
235	TAMU	May	2	May	LO 104	3	1.2	2.2	Y	8	0.318503022	1.559496478	5.129860895					no
236	TAMU	May	2	May	LO 106	4	0.4	2.2	Y	10	0.303375648	2.21106519	4.522706994	7.14	-29.47	1.66	53.62	yes
237	TAMU	May	2	May	LO 108	5	0.8	1	Y	14	0.301311075	1.79787479	7.786971639	10.59	-30.08	1.53	50.36	yes
238	TAMU	May	2	May	LO 112	6	0.7	1.6	Y	11	0.292958558	1.851185214	5.942139079					no
239	TAMU	May	2	May	LO 114	7	1	1.8	Y	8	0.267203747	1.568525968	5.100329967					no
240	TAMU	May	2	May	LO 116	8	0.7	1.6	Y	9	0.300651284	1.895162141	4.74893404					no
241	TAMU	May	2	May	LO 118	9	0.7	1.6	Y	9	0.271812755	2.099116535	4.287518035					no
242	TAMU	May	2	May	LO 120	10	0.8	1.1	Y	6	0.336172789	1.966969803	3.050377282					no
243	TAMU	May	2	May	LO 122	11	0.8	2.2	Y	12	0.354368855	2.282681691	5.256974745					no
244	TAMU	May	2	May	LO 124	12	0.8	1.3	Y	9	0.331619855	1.880440923	4.78611154					no
245	TAMU	May	2	May	LO 126	13	0.5	1.3	Y	9	0.34734038	2.166216202	4.154709946					no
246	TAMU	May	2	May	LO 128	14	1	2	Y	10	0.298457559	2.135531794	4.68267437					no
247	TAMU	May	2	May	LO 130	15	1.2	1.3	Y	9	0.318322953	1.96851528	4.571973655	5.36	-29.9	1.62	47.34	yes
248	TAMU	May	2	May	LO 132	16	1	2.4	Y	8	0.304405389	2.10215761	3.805613795	3.77	-29.23	1.62	52.99	yes
249	TAMU	May	2	May	LO 134	17	0.8	1.3	Y	8	0.306194585	1.984399763	4.031445755					no
250	TAMU	May	2	May	LO 136	18	0.9	1.4	Y	9	0.35798065	1.745789003	5.155262169					no
251	TAMU	May	2	May	LO 138	19	1	1.4	Y	7	0.293546553	1.241598349	5.637894095					no
252	UCC	July	3	Jul	UCCLO 1	60	1.6	3.4	N	6	0.07358883	3.801758541	1.578217011					no
253	UCC	July	3	Jul	UCCLO 2	72	1.6	3	N	7	0.096565267	3.597571512	1.945757013					no
254	UCC	July	3	Jul	UCCLO 3	78	1.7	3.4	N	7	0.088690143	3.73092444	1.876210605	3	-27.44	2.12	52.12	yes
255	UCC	July	3	Jul	UCCLO 4	79	0.9	2.2	N	10	0.092660124	3.45300764	2.896026028	3.61	-29.5	1.42	51.97	yes
256	UCC	July	3	Jul	UCCLO 5	80	0.8	2.1	N	10	0.073312652	3.333340658	2.999993407					no
257	UCC	July	3	Jul	UCCLO 6	81	0.7	2.3	N	11	0.098310233	3.86988265	2.842463453	2.79	-30.5	1.49	49.94	yes
258	UCC	July	3	Jul	UCCLO 7	82	1.2	2.4	N	8	0.110177712	3.73419341	2.14236359	2.43	-29.4	1.55	53.12	yes
259	UCC	July	3	Jul	UCCLO 8	83	1.3	2.4	N	10	0.141244259	3.87064631	2.583547862	2.85	-28.37	1.78	53.52	yes
260	UCC	July	3	Jul	UCCLO 9	84	0.7	2.5	N	13	0.09978428	3.56721882	3.644295642	2.43	-30.1	1.54	52.88	yes
261	UCC	July	3	Jul	UCCLO 10	62	0.8	2.5	N	12	0.132431292	3.49015277	3.438244911	1.51	-31.96	1.61	52.94	yes
262	UCC	July	3	Jul	UCCLO 11	63	1.6	2.3	N	6	0.173230879	3.367902375	1.781524324					no
263	UCC	July	3	Jul	UCCLO 12	64	1.9	2.6	N	10	0.138587138	3.59384758	2.782533142	2.62	-28.94	1.46	51.9	yes
264	UCC	July	3	Jul	UCCLO 13	65	0.9	3	N	9	0.85995343	3.72186692	2.41814127	1.13	-28.81	2.08	51.43	yes
265	UCC	July	3	Jul	UCCLO 14	66	0.9	1.8	N	5	0.072685236	3.309860743	1.510637573					no
266	UCC	July	3	Jul	UCCLO 15	67	0.8	1.1	N	10	0.134352552	3.64300779	2.744984523	1.51	-30.14	1.65	52.04	yes
267	UCC	July	3	Jul	UCCLO 16	68	1	2.1	N	7	0.137691906	3.42866699	2.041609763	1.99	-29.09	1.87	51.21	yes
268	UCC	July	3	Jul	UCCLO 17	69	1.1	2.9	N	8	0.122262069	4.071663355	1.964798978					no
269	UCC	July	3	Jul	UCCLO 18	70	0.8	3	N	8	0.132119946	3.89273917	2.055108152	2.94	-29.22	1.93	51.46	yes
270	UCC	July	3	Jul	UCCLO 19	71	0.9	3	N	11	0.153843023	3.45730751	3.181666649	2.93	-30.27	1.92	51.51	yes
271	UCC	July	3	Jul	UCCLO 20	73	1	2.6	N	9	0.093200886	3.348868201	2.687475129					no
272	UCC	July	3	Jul	UCCLO 21	74	0.7	2.2	N	11	0.082727349	4.063290417	2.70716559					no
273	UCC	July	3	Jul	UCCLO 22	75	0.8	3	N	9	0.105730814	3.47698213	2.588451612	1.74	-29.49	1.64	50.28	yes
274	UCC	July	3	Jul	UCCLO 23	76	0.9	3.6	N	7	0.163846204	3.928843205	1.781694925					no
275	UCC	July	3	Jul	UCCLO 24	77	1	2.2	N	10	0.093755474	3.7644338	2.656441986	2.8	-30.17	1.73	51.3	yes
276	TAMU	July	3	Jul	LO 20	20	1.5	2.3	Y	5	0.133866483	0.50991785	9.805501023					no
277	TAMU	July	3	Jul	LO 22	21	1.2	1.4	Y	4	0.084319753	0.532058395	7.517971782	3.9	-27.74	1.61	52.86	yes
278	TAMU	July	3	Jul	LO 24	22	0.9	3.2	Y	8	0.087563186	0.499671201	16.01052851					no
279	TAMU	July	3	Jul	LO 26	23	1.2	2.2	Y	5	0.09005446	0.478230536	10.45520858					no
280	TAMU	July	3	Jul	LO 28	24	0.8	3.9	Y	6	0.097369767	0.464957076	12.90441702					no
281	TAMU	July	3	Jul	LO 30	25	1	4.3	Y	7	0.140214741	0.451854726	15.49170474	2.68	-28.44	1.86	54.25	yes
282	TAMU	July	3	Jul	LO 32	26	0.8	3.8	Y	3	0.167821233	0.48175864	6.227184639					no
283	TAMU	July	3	Jul	LO 34	27	0.9	3.3	Y	7	0.101156951	0.525802943	13.31297228					no
284	TAMU	July	3	Jul	LO 36	28	1.1	2.1	Y	5	0.138767504	0.530293367	9.428743245					no
285	TAMU	July	3	Jul	LO 38	29	1.1	4	Y	6	0.144081682	0.483432387	12.41124957					no
286	TAMU	July	3	Jul	LO 40	30	1.4	4.3	Y	3	0.084542391	0.482393954	6.218983412					no
287	TAMU	July	3	Jul	LO 42	31	1	2.1	Y	9	0.09448326	0.575644396	15.63465234					no
288	TAMU	July	3	Jul	LO 44	32	1.3	1.4	Y	8	0.080495282	0.482997305	16.56323943					no
289	TAMU	July	3	Jul	LO 46	33	1.1	2.1	Y	7	0.128837739	0.524811142	13.33813145	3.8	-28.51	1.5	52.24	yes
290	TAMU	July	3	Jul	LO 48	34	1.1	1.4	Y	3	0.166281992	0.47664313	6.294017081					no
291	TAMU	July	3	Jul	LO 50	35	1.5	3.4	Y	8	0.158528555	0.559728089	14.29265416	4.52	-28.1	1.15	53.2	yes
292	TAMU	July	3	Jul	LO 52	36	1.7	3.2	Y	7	0.122851867	0.494753031	14.14847319					no
293	TAMU	July	3	Jul	LO 54	37	0.6	4.1	Y	8	0.184630568	0.535500016	14.93930862					no
294	TAMU	July	3	Jul	LO 56	38	0.9	2.6	Y	3	0.083746519	0.463856316	6.467519993					no
295	TAMU	July	3	Jul	LO 58	39	0.7	3.2	Y	8	0.129995116	0.469796851	17.0286369					no
296	TAMU	July	3	Jul	LO 60	40	1.3	2	Y	2	0.082552906	0.499993252	4.000053983					no
297	TAMU	July	3	Jul	LO 62	41	0.9	2	Y	4	0.154002734	0.57720646	6.929929371	4.21	-29.43	1.31	53.5	yes
298	TAMU	July	3	Jul	LO 64	42	0.5	2.1	Y	3	0.083092974	0.459487557	6.529012493	4.99	-28.99	1.86	52.86	yes
299	TAMU	July	3	Jul	LO 66	43	0.9	1.1	Y	7	0.118750858	0.441627258	15.8504709	4.63	-29.7	1.8	49.65	yes
300	TAMU	July	3	Jul	LO 68	44	1.5	3.8	Y	4	0.146802005	0.46892564	8.530137102	4.11	-27.72	1.9	53.29	yes
301	TAMU	July	3	Jul	LO 70	45	1.8	4.1	Y	6	0.085687304	0.522448942	11.48437583					no
302	TAMU	July	3	Jul	LO 72	46	1.2	4.3	Y	10	0.094115111	0.522049321	19.15527823					no
303	TAMU	July	3	Jul	LO 74	47	0.7	2	Y	5	0.10024645	0.519188335	9.630416678					no
304	TAMU	July	3	Jul	LO 76	48	0.8	1.7	Y	3	0.134228693	0.460772865	6.510800066	4.68	-27.45	1.55	52.3	yes
305	TAMU	July	3	Jul	LO 78	49	1.4	4.3	Y	3	0.08438387	0.47796915	6.276555719					no
306	TAMU	July	3	Jul	LO 80	50	0.9	2.9	Y	4	0.085260298	0.575337231	6.952444209	3.87	-27.89	1.83	54.31	yes
307	TAMU	July	3	Jul	LO 82	51	2	4.2	Y	4	0.080374789	0.484102722	8.262709172					no
308	TAMU	July	3	Jul	LO 84	52	1.3	2.7	Y	3	0.127099383	0.522372276	5.743030668					no
309	TAMU	July	3	Jul	LO 86	53	0.9	2.5	Y	9	0.145402179	0.568970352	15.8180474					no
310	TAMU	July	3	Jul	LO 88	54	0.9	2.2	Y	5	0.143050958	0.493394982	10.13386876					no
311	TAMU	July	3	Jul	LO 90	55	0.8	2.5	Y	2	0.126497789	0.503681379	3.970764222					no
312	TAMU	July	3	Jul	LO 92	56	1.9	4.1	Y	3	0.128463244	0.447725163	6.700539184					no
313	TAMU	July	3	Jul	LO 94	57	1	1.9	Y	3	0.079970705	0.465127693	6.44984172					no
314	TAMU	July	3	Jul	LO 96	58	0.9	1.3	Y	2	0.08496332	0.502119306	3.983117115					no
315	TAMU	July	3	Jul	LO 98	59	1	2.5	Y	5	0.147062184	0.501016996	9.979701367	6.16	-27.79	2.09	52.89	yes
316	TAMU	July	3	Jul	LO 100	1	0.7	1.2	Y	9	0.194963659	0.524172007	17.16993636					no
317	TAMU	July	3	Jul	LO 102	2	1.2	3.8	Y	4	0.072127148	0.512417535	7.806134114					no
318	TAMU	July	3	Jul	LO 104	3	2.2	4.2	Y	6	0.095476264	0.499841531	12.00380445					no
319	TAMU	July	3	Jul	LO 106	4	0.4	3.1	Y	5	0.109026838	0.465831222	10.73350124	7.14	-29.47	1.66	53.62	yes
320	TAMU	July	3	Jul	LO 108	5	0.6	3.1	Y	7	0.105058149	0.58921454	11.88022278	10.59	-30.08	1.53	50.36	yes
321	TAMU	July	3	Jul	LO 112	6	1	3.8	Y	4	0.121390994	0.499356344	8.010311765					no
322	TAMU	July	3	Jul	LO 114	7	1.4	3.1	Y	5	0.164432404	0.524980369	9.524165657					no
323	TAMU	July	3	Jul	LO 116	8	0.8	4	Y	5	0.130438631	0.542903976	9.209731781					no
324	TAMU	July	3	Jul	LO 118	9	1.1	3.4	Y	6	0.141583325	0.504311004	11.89742034					no
325	TAMU	July	3	Jul	LO 120	10	1.3	3	Y	6	0.154832126	0.569586192	10.53396323					no
326	TAMU	July	3	Jul	LO 122	11	1.3	2.9	Y	5	0.187637636	0.488638061	10.23252259					no
327	TAMU	July	3	Jul	LO 124	12	1.2	2.2	Y	7	0.09313151	0.514915458	13.59446467					no
328	TAMU	July	3	Jul	LO 126	13	0.7	2.6	Y	2	0.084715787	0.594844482	3.362223339					no
329	TAMU	July	3	Jul	LO 128	14	1.4	3.6	Y	3	0.107913418	0.543275542	5.522059744					no
330	TAMU	July	3	Jul	LO 130	15	1.2	3.9	Y	6	0.085725496	0.503970259	11.90546445	5.36	-29.9	1.62	47.34	yes
331	TAMU	July	3	Jul	LO 132	16	1	4	Y	8	0.096327283	0.510193902	15.68031285	3.77	-29.23	1.62	52.99	yes
332	TAMU	July	3	Jul	LO 134	17	1	3.9	Y	6	0.12091187	0.496401065	12.08700066					no
333	TAMU	July	3	Jul	LO 136	18	1.3	2.9	Y	2	0.14104604	0.464237207	4.308142414					no
334	TAMU	July	3	Jul	LO 138	19	0.8	3.8	Y	9	0.137359046	0.58747643	15.31976355					no
335	UCC	September	4	Sep	UCCLO 1	60	0.5	0.6	N	8	0.122125711	1.764502498	4.533855865					no
336	UCC	September	4	Sep	UCCLO 2	72	0.4	0.6	N	6	0.13044168	1.514163559	3.962583808					no
337	UCC	September	4	Sep	UCCLO 3	78	0.6	0.9	N	6	0.132174778	3.19151249	1.879986376	3	-27.44	2.12	52.12	yes
338	UCC	September	4	Sep	UCCLO 4	79	0.5	0.7	N	8	0.112601555	3.32439588	2.406452266	3.61	-29.5	1.42	51.97	yes
339	UCC	September	4	Sep	UCCLO 5	80	0.4	0.8	N	5	0.14578206	1.553310467	3.218931506					no
340	UCC	September	4	Sep	UCCLO 6	81	0.4	0.9	N	10	0.115811188	3.25588847	3.071358277	2.79	-30.5	1.49	49.94	yes
341	UCC	September	4	Sep	UCCLO 7	82	0.2	0.8	N	7	0.109823674	3.05913927	2.288225341	2.43	-29.4	1.55	53.12	yes
342	UCC	September	4	Sep	UCCLO 8	83	0.5	1.2	N	6	0.101463151	3.30546182	1.815177523	2.85	-28.37	1.78	53.52	yes
343	UCC	September	4	Sep	UCCLO 9	84	0.5	0.9	N	9	0.094507442	2.88182641	3.123019474	2.43	-30.1	1.54	52.88	yes
344	UCC	September	4	Sep	UCCLO 10	62			N					1.51	-31.96	1.61	52.94	yes
345	UCC	September	4	Sep	UCCLO 11	63	0.7	1	N	8	0.188953886	1.780757066	4.492471294					no
346	UCC	September	4	Sep	UCCLO 12	64	0.7	1.1	N	6	0.094531056	3.09448541	1.938933039	2.62	-28.94	1.46	51.9	yes
347	UCC	September	4	Sep	UCCLO 13	65	0.6	1.1	N	6	0.108542413	2.97220052	2.018706329	1.13	-28.81	2.08	51.43	yes
348	UCC	September	4	Sep	UCCLO 14	66	0.6	0.9	N	6	0.916008739	1.676812343	3.578217935					no
349	UCC	September	4	Sep	UCCLO 15	67	0.5	1	N	11	0.118458648	3.23910083	3.396004193	1.51	-30.14	1.65	52.04	yes
350	UCC	September	4	Sep	UCCLO 16	68	0.6	1	N	8	0.106622889	3.19874553	2.500980439	1.99	-29.09	1.87	51.21	yes
351	UCC	September	4	Sep	UCCLO 17	69	0.8	1.3	N	3	0.062655021	1.986739699	1.510011604					no
352	UCC	September	4	Sep	UCCLO 18	70	0.7	1.1	N	9	0.127950808	3.16354885	2.844906283	2.94	-29.22	1.93	51.46	yes
353	UCC	September	4	Sep	UCCLO 19	71	0.9	1.6	N	10	0.094055261	2.99420199	3.339788041	2.93	-30.27	1.92	51.51	yes
354	UCC	September	4	Sep	UCCLO 20	73	0.8	1.3	N	6	0.186680338	2.108492159	2.845635434					no
355	UCC	September	4	Sep	UCCLO 21	74	0.4	1.8	N	6	0.154848355	1.301879686	4.60872081					no
356	UCC	September	4	Sep	UCCLO 22	75	0.8	1.9	N	7	0.097198314	3.25834397	2.148330583	1.74	-29.49	1.64	50.28	yes
357	UCC	September	4	Sep	UCCLO 23	76	0.7	1.7	N	6	0.186924424	1.805290684	3.323564483					no
358	UCC	September	4	Sep	UCCLO 24	77	0.9	1.5	N	8	0.100977627	3.23858753	2.470212686	2.8	-30.17	1.73	51.3	yes
359	TAMU	September	4	Sep	LO 20	20	1.5	2.9	Y	4	0.166589942	0.309306521	12.93215543					no
360	TAMU	September	4	Sep	LO 22	21	1	2.2	Y	5	0.126083911	1.7186665	2.909232245	3.9	-27.74	1.61	52.86	yes
361	TAMU	September	4	Sep	LO 24	22	0.5	1.8	Y	3	0.078952816	0.272393725	11.01346956					no
362	TAMU	September	4	Sep	LO 26	23	0.6	2.9	Y	5	0.084087008	0.277970167	17.9875418					no
363	TAMU	September	4	Sep	LO 28	24	1.7	2.1	Y	7	0.148260947	0.263919892	26.52319965					no
364	TAMU	September	4	Sep	LO 30	25	1.5	2.9	Y	4	0.093520859	1.73931984	2.299749539	2.68	-28.44	1.86	54.25	yes
365	TAMU	September	4	Sep	LO 32	26	0.9	2.1	Y	4	0.105228754	0.261073093	15.32137974					no
366	TAMU	September	4	Sep	LO 34	27	1.5	1.9	Y	2	0.109669294	0.277945392	7.195658052					no
367	TAMU	September	4	Sep	LO 36	28	1.9	2.1	Y	4	0.126556184	0.308004647	12.98681704					no
368	TAMU	September	4	Sep	LO 38	29	1.8	1.4	Y	4	0.179593573	0.263394794	15.18632898					no
369	TAMU	September	4	Sep	LO 40	30	2	1.4	Y	4	0.101825316	0.300608891	13.30632632					no
370	TAMU	September	4	Sep	LO 42	31	1.1	1.2	Y	8	0.168750117	0.308232289	25.95445155					no
371	TAMU	September	4	Sep	LO 44	32	1.4	1.6	Y	4	0.129176959	0.290909416	13.74998464					no
372	TAMU	September	4	Sep	LO 46	33	1.5	2.6	Y	5	0.128891998	1.21249885	4.123715251	3.8	-28.51	1.5	52.24	yes
373	TAMU	September	4	Sep	LO 48	34	2.2	1.7	Y	2	0.197593239	0.274265136	7.292213752					no
374	TAMU	September	4	Sep	LO 50	35	2.2	1.7	Y	6	0.096847341	1.43521885	4.180547099	4.52	-28.1	1.15	53.2	yes
375	TAMU	September	4	Sep	LO 52	36	1.7	1.6	Y	7	0.104152791	0.247815711	28.24679672					no
376	TAMU	September	4	Sep	LO 54	37	0.7	1.9	Y	5	0.08435901	0.319943383	15.627765					no
377	TAMU	September	4	Sep	LO 56	38	0.4	2.1	Y	6	0.087307079	0.275048114	21.81436519					no
378	TAMU	September	4	Sep	LO 58	39	0.5	2.3	Y	5	0.098914911	0.252928629	19.76842249					no
379	TAMU	September	4	Sep	LO 60	40	0.7	1.8	Y	3	0.167096164	0.254162408	11.80347645					no
380	TAMU	September	4	Sep	LO 62	41	0.4	1.9	Y	5	0.133123722	1.24073972	4.029854062	4.21	-29.43	1.31	53.5	yes
381	TAMU	September	4	Sep	LO 64	42	0.3	2.4	Y	3	0.097744059	1.61574756	1.856725688	4.99	-28.99	1.86	52.86	yes
382	TAMU	September	4	Sep	LO 66	43	0.8	1.5	Y	6	0.09869928	1.72500268	3.478255466	4.63	-29.7	1.8	49.65	yes
383	TAMU	September	4	Sep	LO 68	44	0.5	2.6	Y	4	0.106565935	1.57152588	2.545296931	4.11	-27.72	1.9	53.29	yes
384	TAMU	September	4	Sep	LO 70	45	0.7	2.3	Y	4	0.13572253	0.256117051	15.61785903					no
385	TAMU	September	4	Sep	LO 72	46	0.5	1.3	Y	6	0.15624971	0.256236816	23.41583891					no
386	TAMU	September	4	Sep	LO 74	47	0.6	0.9	Y	6	0.15577269	0.289227051	20.74494755					no
387	TAMU	September	4	Sep	LO 76	48	0.7	1.4	Y	2	0.122393538	1.61739498	1.23655633	4.68	-27.45	1.55	52.3	yes
388	TAMU	September	4	Sep	LO 78	49	0.5	1.9	Y	4	0.131201198	0.310613684	12.87773273					no
389	TAMU	September	4	Sep	LO 80	50	0.9	2.6	Y	2	0.118941549	1.43912986	1.389728652	3.87	-27.89	1.83	54.31	yes
390	TAMU	September	4	Sep	LO 82	51	1	2.3	Y	4	0.091153103	0.249055248	16.06069349					no
391	TAMU	September	4	Sep	LO 84	52	0.3	2	Y	5	0.082322741	0.313329191	15.9576578					no
392	TAMU	September	4	Sep	LO 86	53	0.7	2.2	Y	5	0.121766848	0.3072055	16.27575025					no
393	TAMU	September	4	Sep	LO 88	54	0.8	2.4	Y	5	0.12869414	0.266927848	18.73165363					no
394	TAMU	September	4	Sep	LO 90	55	0.6	2	Y	4	0.122308713	0.254178126	15.73699539					no
395	TAMU	September	4	Sep	LO 92	56	0.8	1.8	Y	4	0.088756346	0.25780455	15.51562997					no
396	TAMU	September	4	Sep	LO 94	57	0.5	1.1	Y	4	0.167039654	0.251420522	15.90960022					no
397	TAMU	September	4	Sep	LO 96	58	0.6	1.7	Y	3	0.094846647	0.281220273	10.6677942					no
398	TAMU	September	4	Sep	LO 98	59	0.8	2.7	Y	3	0.129213108	1.21624859	2.46660101	6.16	-27.79	2.09	52.89	yes
399	TAMU	September	4	Sep	LO 100	1	0.4	1.7	Y	6	0.163489819	0.306747196	19.56008099					no
400	TAMU	September	4	Sep	LO 102	2	1	2.1	Y	4	0.156884772	0.222755177	17.95693391					no
401	TAMU	September	4	Sep	LO 104	3	0.9	2.6	Y	7	0.109875414	0.30921425	22.63802523					no
402	TAMU	September	4	Sep	LO 106	4	0.3	2.6	Y	7	0.094921078	1.2181893	5.746233365	7.14	-29.47	1.66	53.62	yes
403	TAMU	September	4	Sep	LO 108	5	0.6	1.6	Y	6	0.130991181	1.43925609	4.168820297	10.59	-30.08	1.53	50.36	yes
404	TAMU	September	4	Sep	LO 112	6	0.6	2.6	Y	6	0.144633529	0.291044954	20.61537199					no
405	TAMU	September	4	Sep	LO 114	7	0.8	2.4	Y	4	0.132988252	0.319203698	12.53118315					no
406	TAMU	September	4	Sep	LO 116	8	0.9	2.6	Y	4	0.170001122	0.305215897	13.10547729					no
407	TAMU	September	4	Sep	LO 118	9	0.5	2.2	Y	7	0.108518444	0.261084708	26.81122171					no
408	TAMU	September	4	Sep	LO 120	10	0.4	1.1	Y	6	0.130422753	0.217683836	27.56291013					no
409	TAMU	September	4	Sep	LO 122	11	0.6	1.6	Y	6	0.097278301	0.235584169	25.46860444					no
410	TAMU	September	4	Sep	LO 124	12	0.9	2.4	Y	4	0.082022139	0.257621719	15.52664121					no
411	TAMU	September	4	Sep	LO 126	13	0.8	1.1	Y	4	0.160228781	0.306313944	13.05849792					no
412	TAMU	September	4	Sep	LO 128	14	0.9	1	Y	2	0.090021824	0.287197871	6.96383992					no
413	TAMU	September	4	Sep	LO 130	15	1	2.8	Y	4	0.113459117	1.26975134	3.150223098	5.36	-29.9	1.62	47.34	yes
414	TAMU	September	4	Sep	LO 132	16	0.8	1.7	Y	7	0.096354036	1.87680133	3.729750128	3.77	-29.23	1.62	52.99	yes
415	TAMU	September	4	Sep	LO 134	17	0.9	1.3	Y	4	0.083960971	0.270662633	14.77854537					no
416	TAMU	September	4	Sep	LO 136	18	0.7	1.4	Y	4	0.12050813	0.28829887	13.87449074					no
417	TAMU	September	4	Sep	LO 138	19	0.6	1.3	Y	6	0.127592629	0.304178061	19.72528845					no

From jdnewmil at dcn.davis.ca.us  Wed May 25 21:52:32 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 25 May 2016 12:52:32 -0700
Subject: [R] mixed models
In-Reply-To: <CABPq8JN974cVTJvRT-+hHigPERV+-uVzzNq6OCZuqpHB4q5xgw@mail.gmail.com>
References: <CABPq8JN974cVTJvRT-+hHigPERV+-uVzzNq6OCZuqpHB4q5xgw@mail.gmail.com>
Message-ID: <CAA84D89-4A4D-43A4-8541-F0CF660EE0AF@dcn.davis.ca.us>

You forgot to show the commands to us that you used to read the data in with (your example is not "reproducible"). This step can make all the difference in the world as to whether your analysis commands will work or not. 
-- 
Sent from my phone. Please excuse my brevity.

On May 25, 2016 11:59:06 AM PDT, James Henson <jfhenson1 at gmail.com> wrote:
>Greetings R community,
>
>My aim is to analyze a mixed-effects model with temporal
>pseudo-replication
>(repeated measures on the same experimental unit) using ?nlme?. 
>However,
>my code returns the error message ?Error in na.fail.default?, even
>though
>the data frame does not contain missing values. My code is below, and
>the
>data file is attached as ?Eboni2.txt.
>
>library("nlme")
>
>str(Eboni2)
>
>head(Eboni2)
>
>model1 <- lme(preDawn ~ Irrigation, random=~season_order|treeNo,
>data=Eboni2)
>
>I am genuinely confused.  Hope someone can help.
>
>Best regards,
>
>James F. Henson
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From alicekalkuhl at freenet.de  Wed May 25 18:56:47 2016
From: alicekalkuhl at freenet.de (alicekalkuhl at freenet.de)
Date: Wed, 25 May 2016 18:56:47 +0200
Subject: [R]  strange error
Message-ID: <873274c8eb88201a0f8babc05ca4c3fd@email.freenet.de>

Hello everyone,
almost every time I try to plot something R gives me the following mistake:
Error in plot.new() : figure margins too large
One example would be, when I tried to run a function, somebody published to create a Lorenz Attractor:
?
parameters <- c(s = 10, r = 28, b = 8/3) state <- c(X = 0, Y = 1, Z = 1)
Lorenz <- function(t, state, parameters) {   with(as.list(c(state, parameters)), {     dX <- s * (Y - X)     dY <- X * (r - Z) - Y     dZ <- X * Y - b * Z     list(c(dX, dY, dZ))   }) }
times <- seq(0, 50, by = 0.01) library(deSolve) out <- ode(y = state, times = times, func = Lorenz, parms = parameters)
par(oma = c(0, 0, 3, 0)) plot(out, xlab = "time", ylab = "-") plot(out[, "Y"], out[, "Z"], pch = ".", type = "l") mtext(outer = TRUE, side = 3, "Lorenz model", cex = 1.5)
?
It turns out to be really problematic, because there are barely functions I can plot.
My version of RStudio is R version 3.2.3 (2015-12-10) -- "Wooden Christmas Tree" and my computer uses Windows 8.1.
Would it be possible to avoid the problem by using Windows 10?
Or is there anything else I can do?
?
Thank you in advance,
Alice de Sampaio Kalkuhl

 

---
Alle Postf?cher an einem Ort. Jetzt wechseln und E-Mail-Adresse mitnehmen! Rundum gl?cklich mit freenetMail

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed May 25 22:07:06 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 25 May 2016 16:07:06 -0400
Subject: [R] strange error
In-Reply-To: <873274c8eb88201a0f8babc05ca4c3fd@email.freenet.de>
References: <873274c8eb88201a0f8babc05ca4c3fd@email.freenet.de>
Message-ID: <05593979-83f5-b9f0-3a58-8c3c756c08cf@gmail.com>

On 25/05/2016 12:56 PM, alicekalkuhl at freenet.de wrote:
> Hello everyone,
> almost every time I try to plot something R gives me the following mistake:
> Error in plot.new() : figure margins too large
> One example would be, when I tried to run a function, somebody published to create a Lorenz Attractor:
>   
> parameters <- c(s = 10, r = 28, b = 8/3) state <- c(X = 0, Y = 1, Z = 1)
> Lorenz <- function(t, state, parameters) {   with(as.list(c(state, parameters)), {     dX <- s * (Y - X)     dY <- X * (r - Z) - Y     dZ <- X * Y - b * Z     list(c(dX, dY, dZ))   }) }
> times <- seq(0, 50, by = 0.01) library(deSolve) out <- ode(y = state, times = times, func = Lorenz, parms = parameters)
> par(oma = c(0, 0, 3, 0)) plot(out, xlab = "time", ylab = "-") plot(out[, "Y"], out[, "Z"], pch = ".", type = "l") mtext(outer = TRUE, side = 3, "Lorenz model", cex = 1.5)
>   
> It turns out to be really problematic, because there are barely functions I can plot.
> My version of RStudio is R version 3.2.3 (2015-12-10) -- "Wooden Christmas Tree" and my computer uses Windows 8.1.
> Would it be possible to avoid the problem by using Windows 10?
> Or is there anything else I can do?

This is an RStudio problem, not an R problem.  One solution is to make 
the "Plots" pane bigger.  There may be others -- you'll have to contact 
RStudio for help with it.

Duncan Murdoch


From tom at maladmin.com  Wed May 25 22:16:44 2016
From: tom at maladmin.com (Tom Wright)
Date: Wed, 25 May 2016 16:16:44 -0400
Subject: [R] strange error
In-Reply-To: <873274c8eb88201a0f8babc05ca4c3fd@email.freenet.de>
References: <873274c8eb88201a0f8babc05ca4c3fd@email.freenet.de>
Message-ID: <CAKmUXV8QHgPn_zJ8KmfJfLk+YB6FPB0gjhsggBuFUf-C7QDxpg@mail.gmail.com>

It may not be the problem, but with RStudio this error pops up when
the area reserved for plotting is too small. Typically this area is in
the right hand column, if you have this minimised (perhaps to maximise
space for typing) you will hit this problem. Try making it bigger.

Edit: Just ran your code, the problem is with the line
par(oma = c(0, 0, 3, 0))

This sets the plot outer margins, my guess is that you have used this
command then managed to save the settings to your default environment.
Changing to:

par(oma = c(1, 4, 3, 4))


which I think is the default, fixes the code on my system

On Wed, May 25, 2016 at 12:56 PM,  <alicekalkuhl at freenet.de> wrote:
> Hello everyone,
> almost every time I try to plot something R gives me the following mistake:
> Error in plot.new() : figure margins too large
> One example would be, when I tried to run a function, somebody published to create a Lorenz Attractor:
>
> parameters <- c(s = 10, r = 28, b = 8/3) state <- c(X = 0, Y = 1, Z = 1)
> Lorenz <- function(t, state, parameters) {   with(as.list(c(state, parameters)), {     dX <- s * (Y - X)     dY <- X * (r - Z) - Y     dZ <- X * Y - b * Z     list(c(dX, dY, dZ))   }) }
> times <- seq(0, 50, by = 0.01) library(deSolve) out <- ode(y = state, times = times, func = Lorenz, parms = parameters)
> par(oma = c(0, 0, 3, 0)) plot(out, xlab = "time", ylab = "-") plot(out[, "Y"], out[, "Z"], pch = ".", type = "l") mtext(outer = TRUE, side = 3, "Lorenz model", cex = 1.5)
>
> It turns out to be really problematic, because there are barely functions I can plot.
> My version of RStudio is R version 3.2.3 (2015-12-10) -- "Wooden Christmas Tree" and my computer uses Windows 8.1.
> Would it be possible to avoid the problem by using Windows 10?
> Or is there anything else I can do?
>
> Thank you in advance,
> Alice de Sampaio Kalkuhl
>
>
>
> ---
> Alle Postf?cher an einem Ort. Jetzt wechseln und E-Mail-Adresse mitnehmen! Rundum gl?cklich mit freenetMail
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dicuell at gmail.com  Wed May 25 22:32:13 2016
From: dicuell at gmail.com (Diego Cuellar)
Date: Wed, 25 May 2016 15:32:13 -0500
Subject: [R] svymean in multistage desing
Message-ID: <CAEJjatR+BUNyO6Jv87hb61MSBXCgomJBtyrmC_19MFiTGh6dJw@mail.gmail.com>

Thanks for your attention. I have been using  your R library, survey, I
made an example for two stage sampling  SI ? SI, an estimate the total and
the mean,  (the point estimation y de SE)

and also, I remaking the estimation.





For the total, point estimation and estimation of the variance, we have
exactly the same number. But for the mean, the estimated sample variance I
found different number.



I have been using  the formula   8.6.6 of S?rdall,  -Model Assisted Survey
Sampling-.  That for the  case of  Simple Random sample without replacement
is equal, to the Taylor approximation for two stage sample, Example 5.6.3
of S?rdall,  -Model Assisted Survey Sampling-













Can you please help me telling me which one is the formula that function
svymean or svratio are using.



I copy the code.





mydata <- read.table( text =

                               "id UPS str_UPS USS str_USS hou85 ue91 lab91
clu_1 clu_2 uno

             3  1 1 1a 1 9230  1623  13727 62 95  1

             4  1 1 2a 1 4896  760   5919  62 95  1

             5  1 1 3a 1 4264  767   5823  62 95  1

             6  1 1 4a 1 3119  568   4011  62 95  1

             7  1 1 5a 2 1946  331   2543  62 95  1

             8  1 1 6a 2 1463  187   1448  62 95  1

             9  1 1 7a 2 675   129   927   62 95  1

             1  2 1 1b 1 26881 4123  33786 62 22  1

             2  2 1 2b 1 26881 4123  33786 62 22  1

             10 2 1 3b 1 18494 823   18649 62 22  1

             11 2 1 4b 2 18196 1543  21004 62 22  1

             12 2 1 5b 2 26814 2735  18796 62 22  1

             13 2 1 6b 2 26510 2638  920   62 22  1

             14 3 2 1c 1 25694 1792  15625 62 256 1

             15 3 2 2c 1 14676 494   26122 62 256 1

             16 3 2 3c 1 5742  520   4007  62 256 1

             17 3 2 4c 1 26024 3827       16850 62 256 1

             18 3 2 5c 2 9534  1458        273   62 256 1

             19 3 2 6c 2 18236 204         25497 62 256 1

             20 3 2 7c 2 22311 1743  13217 62 256 1

             21 4 2 1d 1 1689  1797  13383 62 15  1

             22 4 2 2d 1 12632 2136  5206  62 15  1

             23 4 2 3d 1 11685 534   13461 62 15  1

             24 4 2 4d 1 14404 2851  3202  62 15  1

             25 4 2 5d 2 3072  223   12818 62 15  1

             26 4 2 6d 2 24476 989   414   62 15  1

             27 4 2 7d 2 1562  476   20837 62 15  1" ,

                               header = TRUE )



View(mydata)



Dis_mues_2_stage<-svydesign(id=~UPS+USS, fpc=~clu_1+clu_2, data=mydata)





svytotal(~ue91, Dis_mues_2_stage)



svymean(~ue91, design=Dis_mues_2_stage)

svyratio(~ue91, ~uno, design=Dis_mues_2_stage,separate=FALSE, na.rm=FALSE)

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu May 26 01:23:22 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 25 May 2016 16:23:22 -0700
Subject: [R] mixed models
In-Reply-To: <CABPq8JN26=NuKPj977n5wM_eMGU5Cv0A4Sxok4sZno3VJUVngA@mail.gmail.com>
References: <CABPq8JN974cVTJvRT-+hHigPERV+-uVzzNq6OCZuqpHB4q5xgw@mail.gmail.com>
	<CAA84D89-4A4D-43A4-8541-F0CF660EE0AF@dcn.davis.ca.us>
	<CABPq8JMMqC450qda2QW75j0amaXw4rG+u8ZCG33e-_ynP3YW0w@mail.gmail.com>
	<CABPq8JN26=NuKPj977n5wM_eMGU5Cv0A4Sxok4sZno3VJUVngA@mail.gmail.com>
Message-ID: <DD212DC3-B1A3-4C9B-BD8F-40DD7B3AC576@dcn.davis.ca.us>

Please keep the mailing list in the loop by using reply-all.

I don't think there is a requirement that the number of levels is equal, but there may be problems if you don't have the minimum number of records corresponding to each combination of levels specified in your model. 

You can change the csv extension to txt and attach for the mailing list. Or, better yet, you can use the dput function to embed the data directly in your sample code. 

Also,  please learn to post plain text email to avoid corruption of R code by the HTML formatting. 
-- 
Sent from my phone. Please excuse my brevity.

On May 25, 2016 2:26:54 PM PDT, James Henson <jfhenson1 at gmail.com> wrote:
>Good afternoon Jeff,
>The sample sizes for levels of the factor "Irrigation" are not equal.
>If
>'nlme' requires equal sample sizes this may be the problem. The same
>data
>frame runs in 'lme4' without a problem.
>
>Best regards,
>James
>
>
>On Wed, May 25, 2016 at 3:41 PM, James Henson <jfhenson1 at gmail.com>
>wrote:
>
>> Good afternoon Jeff,
>>
>> When working with this data frame, I just open the .csv file in R
>Studio.
>> But, we should not send .csv file to R_help.  What should I send?
>>
>> Best regards,
>> James
>>
>> On Wed, May 25, 2016 at 2:52 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>> wrote:
>>
>>> You forgot to show the commands to us that you used to read the data
>in
>>> with (your example is not "reproducible"). This step can make all
>the
>>> difference in the world as to whether your analysis commands will
>work or
>>> not.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On May 25, 2016 11:59:06 AM PDT, James Henson <jfhenson1 at gmail.com>
>>> wrote:
>>>
>>>> Greetings R community,
>>>>
>>>> My aim is to analyze a mixed-effects model with temporal
>pseudo-replication
>>>> (repeated measures on the same experimental unit) using ?nlme?. 
>However,
>>>> my code returns the error message ?Error in na.fail.default?, even
>though
>>>> the data frame does not contain missing values. My code is below,
>and the
>>>> data file is attached as ?Eboni2.txt.
>>>>
>>>> library("nlme")
>>>>
>>>> str(Eboni2)
>>>>
>>>> head(Eboni2)
>>>>
>>>> model1 <- lme(preDawn ~ Irrigation, random=~season_order|treeNo,
>>>> data=Eboni2)
>>>>
>>>> I am genuinely confused.  Hope someone can help.
>>>>
>>>> Best regards,
>>>>
>>>> James F. Henson
>>>>
>>>> ------------------------------
>>>>
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>

	[[alternative HTML version deleted]]


From kmnanus at gmail.com  Thu May 26 00:37:54 2016
From: kmnanus at gmail.com (KMNanus)
Date: Wed, 25 May 2016 18:37:54 -0400
Subject: [R] Computing means of multiple variables based on a condition
Message-ID: <B203F983-BD0A-4E3F-9D08-A08E27F5136C@gmail.com>

I have a large dataset, a sample of which is:

a<- c(?A?, ?B?,?A?, ?B?,?A?, ?B?,?A?, ?B?,?A?, ?B?)
b <-c(15, 35, 20,  99, 75, 64, 33, 78, 45, 20)
c<- c( 111, 234, 456, 876, 246, 662, 345, 480, 512, 179)
d<- c(1.1, 3.2, 14.2, 8.7, 12.5, 5.9, 8.3, 6.0, 2.9, 9.3) 

df <- data.frame(a,b,c,d)

I?m trying to construct a data frame that shows the means of c & b based on the condition of d and grouped by a.

I want to create the data frame below, then use ggplot2 to create a line plot of b at various conditions of d.

I can compute the grouped means (d>=2, d>=4, etc.) one at a time using dplyr but haven?t figured out how to put them all together or put them in one data frame.

I?d rather not use a loop and am relatively new to R.  Is there a way i can use tapply and set it to the conditions above so that I can create the df below?


        condition    mean(b)     mean(c)    
A        d>=2          ____         _____
B        d>=2          ____         _____
A        d>=4          ____         _____
B        d>=4         ____         _____
A        d>=6         ____         _____
B       d>=6         ____         _____



Ken
kmnanus at gmail.com
914-450-0816 (tel)
347-730-4813 (fax)




From wdunlap at tibco.com  Thu May 26 03:06:38 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 25 May 2016 18:06:38 -0700
Subject: [R] Computing means of multiple variables based on a condition
In-Reply-To: <B203F983-BD0A-4E3F-9D08-A08E27F5136C@gmail.com>
References: <B203F983-BD0A-4E3F-9D08-A08E27F5136C@gmail.com>
Message-ID: <CAF8bMcbj8ioL56Pi8TL2UOr_=gXQ4sAAoWnQSphCL0y86nsAAw@mail.gmail.com>

Just to be clear, do you really want your 'condition' groups to be be
subsets
of one another?  Most (all?) of the *ply functions assume you want
non-overlapping groups so they do a split-summarize-combine sequence.
You would have to replace the split part of that.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, May 25, 2016 at 3:37 PM, KMNanus <kmnanus at gmail.com> wrote:

> I have a large dataset, a sample of which is:
>
> a<- c(?A?, ?B?,?A?, ?B?,?A?, ?B?,?A?, ?B?,?A?, ?B?)
> b <-c(15, 35, 20,  99, 75, 64, 33, 78, 45, 20)
> c<- c( 111, 234, 456, 876, 246, 662, 345, 480, 512, 179)
> d<- c(1.1, 3.2, 14.2, 8.7, 12.5, 5.9, 8.3, 6.0, 2.9, 9.3)
>
> df <- data.frame(a,b,c,d)
>
> I?m trying to construct a data frame that shows the means of c & b based
> on the condition of d and grouped by a.
>
> I want to create the data frame below, then use ggplot2 to create a line
> plot of b at various conditions of d.
>
> I can compute the grouped means (d>=2, d>=4, etc.) one at a time using
> dplyr but haven?t figured out how to put them all together or put them in
> one data frame.
>
> I?d rather not use a loop and am relatively new to R.  Is there a way i
> can use tapply and set it to the conditions above so that I can create the
> df below?
>
>
>         condition    mean(b)     mean(c)
> A        d>=2          ____         _____
> B        d>=2          ____         _____
> A        d>=4          ____         _____
> B        d>=4         ____         _____
> A        d>=6         ____         _____
> B       d>=6         ____         _____
>
>
>
> Ken
> kmnanus at gmail.com
> 914-450-0816 (tel)
> 347-730-4813 (fax)
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jwd at surewest.net  Thu May 26 06:20:32 2016
From: jwd at surewest.net (John Dougherty)
Date: Wed, 25 May 2016 21:20:32 -0700
Subject: [R] strange error
In-Reply-To: <873274c8eb88201a0f8babc05ca4c3fd@email.freenet.de>
References: <873274c8eb88201a0f8babc05ca4c3fd@email.freenet.de>
Message-ID: <20160525212032.1591a203@draco>

On Wed, 25 May 2016 18:56:47 +0200
alicekalkuhl at freenet.de wrote:

Alice,

Have you tried running the code in R in a terminal?  If the error
persists, then this may be the right place to ask for help.  If it is
specific to R Studio, then you need to ask them.
-- 

John


From kmnanus at gmail.com  Thu May 26 04:04:04 2016
From: kmnanus at gmail.com (KMNanus)
Date: Wed, 25 May 2016 22:04:04 -0400
Subject: [R] Computing means of multiple variables based on a condition
In-Reply-To: <CAF8bMcbj8ioL56Pi8TL2UOr_=gXQ4sAAoWnQSphCL0y86nsAAw@mail.gmail.com>
References: <B203F983-BD0A-4E3F-9D08-A08E27F5136C@gmail.com>
	<CAF8bMcbj8ioL56Pi8TL2UOr_=gXQ4sAAoWnQSphCL0y86nsAAw@mail.gmail.com>
Message-ID: <1A5C188E-663F-4ECD-AB50-028D695A7CA6@gmail.com>

These will be overlapping subgroups from the same data frame.  For example, d<=2 will have length=9, d<=4 will have length=7, etc.


Ken
kmnanus at gmail.com
914-450-0816 (tel)
347-730-4813 (fax)



> On May 25, 2016, at 9:06 PM, William Dunlap <wdunlap at tibco.com> wrote:
> 
> Just to be clear, do you really want your 'condition' groups to be be subsets
> of one another?  Most (all?) of the *ply functions assume you want
> non-overlapping groups so they do a split-summarize-combine sequence.
> You would have to replace the split part of that.
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com <http://tibco.com/>
> On Wed, May 25, 2016 at 3:37 PM, KMNanus <kmnanus at gmail.com <mailto:kmnanus at gmail.com>> wrote:
> I have a large dataset, a sample of which is:
> 
> a<- c(?A?, ?B?,?A?, ?B?,?A?, ?B?,?A?, ?B?,?A?, ?B?)
> b <-c(15, 35, 20,  99, 75, 64, 33, 78, 45, 20)
> c<- c( 111, 234, 456, 876, 246, 662, 345, 480, 512, 179)
> d<- c(1.1, 3.2, 14.2, 8.7, 12.5, 5.9, 8.3, 6.0, 2.9, 9.3)
> 
> df <- data.frame(a,b,c,d)
> 
> I?m trying to construct a data frame that shows the means of c & b based on the condition of d and grouped by a.
> 
> I want to create the data frame below, then use ggplot2 to create a line plot of b at various conditions of d.
> 
> I can compute the grouped means (d>=2, d>=4, etc.) one at a time using dplyr but haven?t figured out how to put them all together or put them in one data frame.
> 
> I?d rather not use a loop and am relatively new to R.  Is there a way i can use tapply and set it to the conditions above so that I can create the df below?
> 
> 
>         condition    mean(b)     mean(c)
> A        d>=2          ____         _____
> B        d>=2          ____         _____
> A        d>=4          ____         _____
> B        d>=4         ____         _____
> A        d>=6         ____         _____
> B       d>=6         ____         _____
> 
> 
> 
> Ken
> kmnanus at gmail.com <mailto:kmnanus at gmail.com>
> 914-450-0816 <tel:914-450-0816> (tel)
> 347-730-4813 <tel:347-730-4813> (fax)
> 
> 
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
> 


From 25695076 at qq.com  Thu May 26 06:43:27 2016
From: 25695076 at qq.com (=?gb18030?B?SmVzc2ljYSBXYW5n?=)
Date: Thu, 26 May 2016 12:43:27 +0800
Subject: [R] R help- fit distribution "fitdistr"
Message-ID: <tencent_54BBFE453A5A22471530ADEE@qq.com>

Hello, I just start using R. I want to use ?fitdistr? to fit distribution of the data. Then how can I verify if the data really fit the distribution? Thanks [data is attached]
 
res<-fitdistr(data$Report.delay, "Poisson") 
 
h<-hist(data$Report.delay) 
 
xfit<-floor(seq(0, 250, 50)) 
 
yfit<-dpois(xfit,res[[1]][1]) 
 
yfit<-yfit*diff(h$mids[1:2])*length(xfit) 
 
lines(xfit, yfit, col="blue", lwd=2)

From jdnewmil at dcn.davis.ca.us  Thu May 26 08:34:31 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 25 May 2016 23:34:31 -0700 (PDT)
Subject: [R] Computing means of multiple variables based on a condition
In-Reply-To: <1A5C188E-663F-4ECD-AB50-028D695A7CA6@gmail.com>
References: <B203F983-BD0A-4E3F-9D08-A08E27F5136C@gmail.com>
	<CAF8bMcbj8ioL56Pi8TL2UOr_=gXQ4sAAoWnQSphCL0y86nsAAw@mail.gmail.com>
	<1A5C188E-663F-4ECD-AB50-028D695A7CA6@gmail.com>
Message-ID: <alpine.BSF.2.00.1605252323230.33518@pedal.dcn.davis.ca.us>

Thank you for including some sample data, but I have to ask that you 
please invest some time in learning how to edit your code in a text editor 
and to post in plain text. The quote marks in your example were "curly", 
which R does not understand. There are other ways in which HTML email 
leads to corruption on this mailing list as well, so you will save 
everyone numerous headaches by investing this time sooner rather than 
later.

The type of operation you are looking for is referred to as an "outer 
join" in SQL nomenclature, and it is intrinsically slow because the only 
way to accomplish it is computationally equivalent to a for loop that 
successively applies each minimum "d" value to your whole data set.

Having said that, you can accomplish this in the "dplyr" syntax instead of 
using a for loop, if that makes you happy, but it is not really any 
"better" than a for loop (and some people might consider it misleading 
to drape a for loop in such fancy syntax):

DF <- data.frame( a = c( "A", "B", "A", "B", "A", "B", "A", "B", "A", "B" )
                 , b = c( 15, 35, 20,  99, 75, 64, 33, 78, 45, 20 )
                 , c = c( 111, 234, 456, 876, 246, 662, 345, 480, 512, 179 )
                 , d = c( 1.1, 3.2, 14.2, 8.7, 12.5, 5.9, 8.3, 6.0, 2.9, 9.3 )
                 , stringsAsFactors = FALSE
                 )
passes <- data.frame( dmin = c( 2, 4, 6 ) )

library(dplyr)

DF2 <- (   passes
        %>% rowwise
        %>% do({ # run once for each row in "passes"
             dmin <- .$dmin # dot here refers to row of
                            # "passes" data frame
             (   DF
             %>% filter( d >= dmin )
             %>% group_by( a )
             %>% summarise( meanb = mean( b )
                          , meanc = mean( c )
                          )
             %>% mutate( condition = paste0( "d>=", dmin ) )
             )
            })
        %>% select( a, condition, meanb, meanc )
        %>% as.data.frame
        )


On Wed, 25 May 2016, KMNanus wrote:

> These will be overlapping subgroups from the same data frame.  For example, d<=2 will have length=9, d<=4 will have length=7, etc.
>
>
> Ken
> kmnanus at gmail.com
> 914-450-0816 (tel)
> 347-730-4813 (fax)
>
>
>
>> On May 25, 2016, at 9:06 PM, William Dunlap <wdunlap at tibco.com> wrote:
>> 
>> Just to be clear, do you really want your 'condition' groups to be be subsets
>> of one another?  Most (all?) of the *ply functions assume you want
>> non-overlapping groups so they do a split-summarize-combine sequence.
>> You would have to replace the split part of that.
>> 
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com <http://tibco.com/>
>> On Wed, May 25, 2016 at 3:37 PM, KMNanus <kmnanus at gmail.com <mailto:kmnanus at gmail.com>> wrote:
>> I have a large dataset, a sample of which is:
>> 
>> a<- c(?A?, ?B?,?A?, ?B?,?A?, ?B?,?A?, ?B?,?A?, ?B?)
>> b <-c(15, 35, 20,  99, 75, 64, 33, 78, 45, 20)
>> c<- c( 111, 234, 456, 876, 246, 662, 345, 480, 512, 179)
>> d<- c(1.1, 3.2, 14.2, 8.7, 12.5, 5.9, 8.3, 6.0, 2.9, 9.3)
>> 
>> df <- data.frame(a,b,c,d)
>> 
>> I?m trying to construct a data frame that shows the means of c & b based on the condition of d and grouped by a.
>> 
>> I want to create the data frame below, then use ggplot2 to create a line plot of b at various conditions of d.
>> 
>> I can compute the grouped means (d>=2, d>=4, etc.) one at a time using dplyr but haven?t figured out how to put them all together or put them in one data frame.
>> 
>> I?d rather not use a loop and am relatively new to R.  Is there a way i can use tapply and set it to the conditions above so that I can create the df below?
>> 
>>
>>         condition    mean(b)     mean(c)
>> A        d>=2          ____         _____
>> B        d>=2          ____         _____
>> A        d>=4          ____         _____
>> B        d>=4         ____         _____
>> A        d>=6         ____         _____
>> B       d>=6         ____         _____
>> 
>> 
>> 
>> Ken
>> kmnanus at gmail.com <mailto:kmnanus at gmail.com>
>> 914-450-0816 <tel:914-450-0816> (tel)
>> 347-730-4813 <tel:347-730-4813> (fax)
>> 
>> 
>> 
>> ______________________________________________
>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From bgunter.4567 at gmail.com  Thu May 26 13:24:24 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 26 May 2016 04:24:24 -0700
Subject: [R] R help- fit distribution "fitdistr"
In-Reply-To: <tencent_54BBFE453A5A22471530ADEE@qq.com>
References: <tencent_54BBFE453A5A22471530ADEE@qq.com>
Message-ID: <CAGxFJbRe20A95TE2ywsH=P=t_HeLk_UbY+Qvy3Q6m70cprRNbQ@mail.gmail.com>

Inline.

On Thursday, May 26, 2016, Jessica Wang <25695076 at qq.com> wrote:

> Hello, I just start using R. I want to use ?fitdistr? to fit distribution
> of the data. Then how can I verify if the data really fit the distribution?
> Thanks [data is attached]
>
> You can't. There are many ways to judge/quantify the **quality** of the
fit, but your question indicates a complete misunderstanding of basic
statistical concepts (imo of course) . I suggest you spend time with a
local statistical resource, take some courses, do some reading, etc.

Cheers,
Bert


> res<-fitdistr(data$Report.delay, "Poisson")
>
> h<-hist(data$Report.delay)
>
> xfit<-floor(seq(0, 250, 50))
>
> yfit<-dpois(xfit,res[[1]][1])
>
> yfit<-yfit*diff(h$mids[1:2])*length(xfit)
>
> lines(xfit, yfit, col="blue", lwd=2)
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu May 26 15:55:30 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 26 May 2016 15:55:30 +0200
Subject: [R] Computing means of multiple variables based on a condition
In-Reply-To: <alpine.BSF.2.00.1605252323230.33518@pedal.dcn.davis.ca.us>
References: <B203F983-BD0A-4E3F-9D08-A08E27F5136C@gmail.com>
	<CAF8bMcbj8ioL56Pi8TL2UOr_=gXQ4sAAoWnQSphCL0y86nsAAw@mail.gmail.com>
	<1A5C188E-663F-4ECD-AB50-028D695A7CA6@gmail.com>
	<alpine.BSF.2.00.1605252323230.33518@pedal.dcn.davis.ca.us>
Message-ID: <CAJuCY5wuewY9SEe-mBi64kQL_5dk6BPMpzsvr2VeEEM_8yA27g@mail.gmail.com>

Another option would be to convert the data into a long format and add
columns for each condition.

library(dplyr)
library(tidyr)
DF %>%
  gather(key = "key", value = "value", -a, -d) %>%
  mutate(
    "d>=2" = ifelse(d >= 2, value, NA),
    "d>=4" = ifelse(d >= 4, value, NA),
    "d>=6" = ifelse(d >= 6, value, NA)
  ) %>%
  select(-d, -value) %>%
  gather(key = "condition", value = "value", -a, -key, na.rm = TRUE) %>%
  group_by(a, key, condition) %>%
  summarise(mean = mean(value)) %>%
  spread(key = key, value = mean) %>%
  arrange(condition, a)


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-05-26 8:34 GMT+02:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:

> Thank you for including some sample data, but I have to ask that you
> please invest some time in learning how to edit your code in a text editor
> and to post in plain text. The quote marks in your example were "curly",
> which R does not understand. There are other ways in which HTML email leads
> to corruption on this mailing list as well, so you will save everyone
> numerous headaches by investing this time sooner rather than later.
>
> The type of operation you are looking for is referred to as an "outer
> join" in SQL nomenclature, and it is intrinsically slow because the only
> way to accomplish it is computationally equivalent to a for loop that
> successively applies each minimum "d" value to your whole data set.
>
> Having said that, you can accomplish this in the "dplyr" syntax instead of
> using a for loop, if that makes you happy, but it is not really any
> "better" than a for loop (and some people might consider it misleading to
> drape a for loop in such fancy syntax):
>
> DF <- data.frame( a = c( "A", "B", "A", "B", "A", "B", "A", "B", "A", "B" )
>                 , b = c( 15, 35, 20,  99, 75, 64, 33, 78, 45, 20 )
>                 , c = c( 111, 234, 456, 876, 246, 662, 345, 480, 512, 179 )
>                 , d = c( 1.1, 3.2, 14.2, 8.7, 12.5, 5.9, 8.3, 6.0, 2.9,
> 9.3 )
>                 , stringsAsFactors = FALSE
>                 )
> passes <- data.frame( dmin = c( 2, 4, 6 ) )
>
> library(dplyr)
>
> DF2 <- (   passes
>        %>% rowwise
>        %>% do({ # run once for each row in "passes"
>             dmin <- .$dmin # dot here refers to row of
>                            # "passes" data frame
>             (   DF
>             %>% filter( d >= dmin )
>             %>% group_by( a )
>             %>% summarise( meanb = mean( b )
>                          , meanc = mean( c )
>                          )
>             %>% mutate( condition = paste0( "d>=", dmin ) )
>             )
>            })
>        %>% select( a, condition, meanb, meanc )
>        %>% as.data.frame
>        )
>
>
> On Wed, 25 May 2016, KMNanus wrote:
>
> These will be overlapping subgroups from the same data frame.  For
>> example, d<=2 will have length=9, d<=4 will have length=7, etc.
>>
>>
>> Ken
>> kmnanus at gmail.com
>> 914-450-0816 (tel)
>> 347-730-4813 (fax)
>>
>>
>>
>> On May 25, 2016, at 9:06 PM, William Dunlap <wdunlap at tibco.com> wrote:
>>>
>>> Just to be clear, do you really want your 'condition' groups to be be
>>> subsets
>>> of one another?  Most (all?) of the *ply functions assume you want
>>> non-overlapping groups so they do a split-summarize-combine sequence.
>>> You would have to replace the split part of that.
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com <http://tibco.com/>
>>> On Wed, May 25, 2016 at 3:37 PM, KMNanus <kmnanus at gmail.com <mailto:
>>> kmnanus at gmail.com>> wrote:
>>> I have a large dataset, a sample of which is:
>>>
>>> a<- c(?A?, ?B?,?A?, ?B?,?A?, ?B?,?A?, ?B?,?A?, ?B?)
>>> b <-c(15, 35, 20,  99, 75, 64, 33, 78, 45, 20)
>>> c<- c( 111, 234, 456, 876, 246, 662, 345, 480, 512, 179)
>>> d<- c(1.1, 3.2, 14.2, 8.7, 12.5, 5.9, 8.3, 6.0, 2.9, 9.3)
>>>
>>> df <- data.frame(a,b,c,d)
>>>
>>> I?m trying to construct a data frame that shows the means of c & b based
>>> on the condition of d and grouped by a.
>>>
>>> I want to create the data frame below, then use ggplot2 to create a line
>>> plot of b at various conditions of d.
>>>
>>> I can compute the grouped means (d>=2, d>=4, etc.) one at a time using
>>> dplyr but haven?t figured out how to put them all together or put them in
>>> one data frame.
>>>
>>> I?d rather not use a loop and am relatively new to R.  Is there a way i
>>> can use tapply and set it to the conditions above so that I can create the
>>> df below?
>>>
>>>
>>>         condition    mean(b)     mean(c)
>>> A        d>=2          ____         _____
>>> B        d>=2          ____         _____
>>> A        d>=4          ____         _____
>>> B        d>=4         ____         _____
>>> A        d>=6         ____         _____
>>> B       d>=6         ____         _____
>>>
>>>
>>>
>>> Ken
>>> kmnanus at gmail.com <mailto:kmnanus at gmail.com>
>>> 914-450-0816 <tel:914-450-0816> (tel)
>>> 347-730-4813 <tel:347-730-4813> (fax)
>>>
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To
>>> UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help <
>>> https://stat.ethz.ch/mailman/listinfo/r-help>
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html <
>>> http://www.r-project.org/posting-guide.html>
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From oscar.jimenez.fdez at gmail.com  Thu May 26 11:37:33 2016
From: oscar.jimenez.fdez at gmail.com (=?UTF-8?B?w5NzY2FyIEppbcOpbmV6?=)
Date: Thu, 26 May 2016 11:37:33 +0200
Subject: [R] Shaded areas in R
Message-ID: <CAJAnTBXtLMADaak8JyPcXcJ3WLPPkczyZ+ktvAaXUrDr5p-T4g@mail.gmail.com>

Hello,

I'm working with R language, and plotting some parameters over time. I need
to draw a shaded area under the curve of eacj parameter.

For that, I might use the polygon (x,y) function, assigning coordinates
(x,y) to each vertex of my polygon. To do so, "x" and "y" must be vectors
with numerical values, but since my x-axis is a time series, I cannot
assing a numerical value to my "x" coordinate, because time variable is a
"character" variable.

Is there any option to use the function polygin (x,y) in this case, or any
other function that allows me to draw a shaded area under the curve on a
time series basis?

Thank you in advance for your help

Best regards

?scar

	[[alternative HTML version deleted]]


From sebastian.salentin at biotec.tu-dresden.de  Thu May 26 11:49:09 2016
From: sebastian.salentin at biotec.tu-dresden.de (Sebastian Salentin)
Date: Thu, 26 May 2016 11:49:09 +0200
Subject: [R] Segmentation Fault with large dataframes and packages using
	rJava
Message-ID: <5746C695.7000902@biotec.tu-dresden.de>

Dear all,

I have been trying to perform machine learning/feature selection tasks 
in R using various packages (e.g. mlr and FSelector).
However, when giving larger data frames as input for the functions, I 
get a segmentation fault (memory not mapped).

This happened first when using the mlr benchmark function with 
dataframes in the order of 200 rows x 10,000 columns (all integer values).

I prepared a minimal working example where I get a segmentation fault 
trying to calculate the information gain with FSelector package.

require("FSelector")
# Random dataframe 200 rows * 25,000 cols
large.df <- data.frame(replicate(25000,sample(0:1,200,rep=TRUE)))
weights <- information.gain(X24978~., large.df)
print(weights)


I am using R version 3.3.0 64-bit on Ubuntu 14.04.4 LTS with FSelector 
v0.20 and rJava v0.9.8 on a machine with 32 core Intel i7 and 250 GB 
Ram. Java is OpenJDK 1.7 74bit.

I would highly appreciate if you could give me any hint on how to solve 
the problem.

Best
ssalentin

-- 
Sebastian Salentin, PhD student
Bioinformatics Group

Technische Universit?t Dresden
Biotechnology Center (BIOTEC)
Tatzberg 47/49
01307 Dresden, Germany


From tom at maladmin.com  Thu May 26 16:17:56 2016
From: tom at maladmin.com (Tom Wright)
Date: Thu, 26 May 2016 10:17:56 -0400
Subject: [R] Shaded areas in R
In-Reply-To: <CAJAnTBXtLMADaak8JyPcXcJ3WLPPkczyZ+ktvAaXUrDr5p-T4g@mail.gmail.com>
References: <CAJAnTBXtLMADaak8JyPcXcJ3WLPPkczyZ+ktvAaXUrDr5p-T4g@mail.gmail.com>
Message-ID: <CAKmUXV9v7xaiR9b3tNfBTJLbahAFGySxWXDHjtD4H0M1dgFSHw@mail.gmail.com>

Hi ?scar,

Not really sure what you mean by the time variable being a "character"
vector. Unless you are plotting a barchart or boxplot (or similar), I
don't this this makes sense. If you can post a sample of your data,
preferably using the dput() command we can probably help more.

On Thu, May 26, 2016 at 5:37 AM, ?scar Jim?nez
<oscar.jimenez.fdez at gmail.com> wrote:
> Hello,
>
> I'm working with R language, and plotting some parameters over time. I need
> to draw a shaded area under the curve of eacj parameter.
>
> For that, I might use the polygon (x,y) function, assigning coordinates
> (x,y) to each vertex of my polygon. To do so, "x" and "y" must be vectors
> with numerical values, but since my x-axis is a time series, I cannot
> assing a numerical value to my "x" coordinate, because time variable is a
> "character" variable.
>
> Is there any option to use the function polygin (x,y) in this case, or any
> other function that allows me to draw a shaded area under the curve on a
> time series basis?
>
> Thank you in advance for your help
>
> Best regards
>
> ?scar
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Thu May 26 16:32:16 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 26 May 2016 10:32:16 -0400
Subject: [R] Shaded areas in R
In-Reply-To: <CAJAnTBXtLMADaak8JyPcXcJ3WLPPkczyZ+ktvAaXUrDr5p-T4g@mail.gmail.com>
References: <CAJAnTBXtLMADaak8JyPcXcJ3WLPPkczyZ+ktvAaXUrDr5p-T4g@mail.gmail.com>
Message-ID: <888fc5b0-5d21-1c84-6b44-5096eda64d13@gmail.com>

On 26/05/2016 5:37 AM, ?scar Jim?nez wrote:
> Hello,
>
> I'm working with R language, and plotting some parameters over time. I need
> to draw a shaded area under the curve of eacj parameter.
>
> For that, I might use the polygon (x,y) function, assigning coordinates
> (x,y) to each vertex of my polygon. To do so, "x" and "y" must be vectors
> with numerical values, but since my x-axis is a time series, I cannot
> assing a numerical value to my "x" coordinate, because time variable is a
> "character" variable.
>
> Is there any option to use the function polygin (x,y) in this case, or any
> other function that allows me to draw a shaded area under the curve on a
> time series basis?

Times and dates just print like characters, they aren't actually 
characters.  For example,

  x <- Sys.Date() + 1:20
  y <- rnorm(20)
  plot(y ~ x)
  polygon(c(x, x[20], x[1]), c(y, 0, 0), col="gray")

Duncan Murdoch


From murdoch.duncan at gmail.com  Thu May 26 17:12:42 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 26 May 2016 11:12:42 -0400
Subject: [R] Shaded areas in R
In-Reply-To: <CAJAnTBWc0mHXMN0uQr2HGz9gv0SyzuJky3C6jkai+8SYmA1hxg@mail.gmail.com>
References: <CAJAnTBXtLMADaak8JyPcXcJ3WLPPkczyZ+ktvAaXUrDr5p-T4g@mail.gmail.com>
	<888fc5b0-5d21-1c84-6b44-5096eda64d13@gmail.com>
	<CAJAnTBWc0mHXMN0uQr2HGz9gv0SyzuJky3C6jkai+8SYmA1hxg@mail.gmail.com>
Message-ID: <674e138c-f49b-8d18-a2e2-fd3386b600ea@gmail.com>

On 26/05/2016 11:03 AM, ?scar Jim?nez wrote:
> Hi Duncan,
>
> Thanks for the quick reply  :)
> Does the function Sys.Date return a time series (created with the 
> function POSIXct), with numerical values?

It returns a Date object.  The str() function will show you that. But 
Date, POSIXct, and even POSIXlt are supported by many of the graphics 
functions, so you don't need to worry about the conversions.

> I mean... I think the best option is to convert the time series 
> (plotted as characters), into numerical values, right?

No, that is not needed.

> Or is there any other function that allows me to draw the shade under 
> the curve using time series as the "x" variable?

polygon() does.

You should try things; R won't break.
>
> If you need more info I can share my script and my database and you 
> can see it properly.

You should always do that when you pose your question; you should also 
send your questions to R-help, not privately.  I've cc'd my response there.

Duncan Murdoch


From lists at dewey.myzen.co.uk  Thu May 26 17:19:47 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Thu, 26 May 2016 16:19:47 +0100
Subject: [R] Fortune candidate, was Re:  Shaded areas in R
In-Reply-To: <674e138c-f49b-8d18-a2e2-fd3386b600ea@gmail.com>
References: <CAJAnTBXtLMADaak8JyPcXcJ3WLPPkczyZ+ktvAaXUrDr5p-T4g@mail.gmail.com>
	<888fc5b0-5d21-1c84-6b44-5096eda64d13@gmail.com>
	<CAJAnTBWc0mHXMN0uQr2HGz9gv0SyzuJky3C6jkai+8SYmA1hxg@mail.gmail.com>
	<674e138c-f49b-8d18-a2e2-fd3386b600ea@gmail.com>
Message-ID: <88fd893c-0687-bdfe-5b1a-5410879b26a5@dewey.myzen.co.uk>

In a reply Duncan said

On 26/05/2016 16:12, Duncan Murdoch wrote:
> On 26/05/2016 11:03 AM, ?scar Jim?nez wrote:
>
> You should try things; R won't break.
>>
>

> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From james.hirschorn at hotmail.com  Thu May 26 19:01:48 2016
From: james.hirschorn at hotmail.com (James Hirschorn)
Date: Thu, 26 May 2016 13:01:48 -0400
Subject: [R] data.table exact matching numeric keys
Message-ID: <BLU436-SMTP1619701079FFE3F304C1F1E9410@phx.gbl>

I have looked over the documentation and did not see an answer to this 
seemingly basic question:

I noticed that if I have a data.table with a key containing numeric 
values, then a close number is considered a match when searching. For 
example,

 > dt[J(a)]
#     certainty probability
# 1: 0.8596491          -1
# 2: 0.8596491          -1

But in fact the two certainty values differ by 5.797585e-13.

Is there a way to only return exact matches, or set the epsilon value 
(to something like machine epsilon)?


From lordpreetam at gmail.com  Thu May 26 21:33:05 2016
From: lordpreetam at gmail.com (Preetam Pal)
Date: Fri, 27 May 2016 01:03:05 +0530
Subject: [R] Proportion of 1's in terminal nodes of CTREE()
Message-ID: <CAHVFrXGTa23vepAzQL7oZA=c5A7CpB-JCPoCQ8s4Q2qhJv-32g@mail.gmail.com>

Hi R-users,

I have created a Conditional Tree using the ctree function ( in package
partykit). The data had a factor - the y variable - and a host  of
categorical x-variables.
Now, I want to find the proportion of cases where y = 1 in each of the
terminal nodes.

Is it possible to do so programmatically?


*Tree <- ctree( y~., data = mydata, ctree_control = c(maxdepth = 4))*

Regards,
Preetam

	[[alternative HTML version deleted]]


From chalabi.elahe at yahoo.de  Thu May 26 21:35:52 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Thu, 26 May 2016 19:35:52 +0000 (UTC)
Subject: [R] subset data right
References: <927632887.2224306.1464291352800.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <927632887.2224306.1464291352800.JavaMail.yahoo@mail.yahoo.com>

Hi all,
I have the following df and I want to know which Protocols are VeryFast, which are FAST, which are SLOW and also which ones are VerySLOW :

    
  $ Protocol       : Factor w/ 48 levels "DP FS QTSE SAG",..: 5 5 28 5 5 5 7 7 47 5 ...

  $ quant          : Factor w/ 4 levels "FAST","SLOW",..: 2 2 2 4 2 1 1 2 4 

I do the following subset but nothing is changed in my df:


  subdf=subset(df,quant%in%c("VeryFast"))
  subdf$quant=factor(subdf$quant)
and when I get the str(df) again Protocol has 48 levels. Does anyone know how can I get these subsets right?
Thanks for any help!
Elahe


From lordpreetam at gmail.com  Thu May 26 21:55:08 2016
From: lordpreetam at gmail.com (Preetam Pal)
Date: Fri, 27 May 2016 01:25:08 +0530
Subject: [R] Factor Analysis using weights for each variable
Message-ID: <CAHVFrXG8=jTuY0JKXURnX2sXKfFb8rfZT_cPtSNjWWn=ixjHKQ@mail.gmail.com>

Hi R-users,

I have 1020 time series ( each of length 10,000), say, X1,X2,......,X1020
and I want to perform Factor Analysis using 50 factors on their correlation
matrix.

The issue is: for every series, I have a weight, i.e. *the series X_i has a
pre-defined weight of w_i* ( i = 1,2,...., 1020). I want to estimate the
factor loadings and specific variances in the model by optimizing the
likelihood function (assuming multivariate normality, as usual).
Is it possible to estimate the model parameters using the weights for each
time series variable in the objective function?

One comment here - For computational purposes or otherwise, it is *ok to
 change my objective function* (instead of taking the likelihood function,
may be something like minimizing the weighted sum of squared specific
variances for the variables would make sense).

Any help with this will be really appreciated.

Regards,
Preetam

-- 
Preetam Pal
(+91)-9432212774
M-Stat 2nd Year,                                             Room No. N-114
Statistics Division,                                           C.V.Raman
Hall
Indian Statistical Institute,                                 B.H.O.S.
Kolkata.

	[[alternative HTML version deleted]]


From oscar.jimenez.fdez at gmail.com  Thu May 26 17:57:27 2016
From: oscar.jimenez.fdez at gmail.com (=?UTF-8?B?w5NzY2FyIEppbcOpbmV6?=)
Date: Thu, 26 May 2016 17:57:27 +0200
Subject: [R] Shaded areas in R
In-Reply-To: <6cdb6c07-d5f0-dd08-9c58-68ca67628dc7@gmail.com>
References: <CAJAnTBXtLMADaak8JyPcXcJ3WLPPkczyZ+ktvAaXUrDr5p-T4g@mail.gmail.com>
	<888fc5b0-5d21-1c84-6b44-5096eda64d13@gmail.com>
	<CAJAnTBWc0mHXMN0uQr2HGz9gv0SyzuJky3C6jkai+8SYmA1hxg@mail.gmail.com>
	<674e138c-f49b-8d18-a2e2-fd3386b600ea@gmail.com>
	<CAJAnTBV1jtS3+0JnNrDsL_F6QOb22o5s_SCaHETBxmKw2DYVrg@mail.gmail.com>
	<6cdb6c07-d5f0-dd08-9c58-68ca67628dc7@gmail.com>
Message-ID: <CAJAnTBUQJ34Q+aauT7Xzfsx_apSpwiZ2jhPrVvyrrFKpZ5rhcg@mail.gmail.com>

Thanks for your answers

I'm going to share my script and my database in an excel file, where you
can check the kind of graph I would like to make (see attached document,
you can find it in Sheet1. Sheet 3 is the one that I used in .csv format to
work with in R).

Script:

# HYDROGRAPH SEPARATION ANALYSIS FOR EVENTS: JULY 9TH AND SEPT 11TH

# Event 20. July 9th, 2015

setwd("C:\\Users\\Asus\\Desktop\\MSc Thesis - INIRENA\\R\\Downloads")
dir()

  # Ev20HS: P event 20. Hydrograph separation
Ev20HS <- read.table("Event20_Hydrograph_Separation.txt", skip=4,
header=FALSE, stringsAsFactors=FALSE)
as.data.frame(Ev20HP)
colnames(Ev20HS)<- c("Date","Hour","P", "Qt", "St2H", "P2H", "GW2H",
"St18O", "P18O", "GW18O",
                     "Qold2H", "Qnew2H", "%old2H", "%new2H", "Qold18O",
"Qnew18O", "%old18O", "%new18O")
paste(Ev20HS$Date, Ev20HS$Hour)
Ev20HS$date.time <- paste(Ev20HS$Date, Ev20HS$Hour)
as.POSIXct(Ev20HS$date.time, format="%Y/%m/%d %H:%M:%S", tz="-7")
Ev20HS$date.time <- as.POSIXct(Ev20HS$date.time, format="%Y/%m/%d
%H:%M:%S", tz="-7")

par(mar=c(4, 4, 4, 4))
plot(Ev20HS$date.time, Ev20HS$P, type="h", axes= FALSE, col="cadetblue4",
ylim=c(10,0),
     lwd=2, xlab= "Hour", xline= 1.5, ylab = " ")
axis (4, lwd= 1)
mtext (4, line=2, text="P (mm)")
par(new=T)
plot(Ev20HS$date.time, Ev20HS$Qt, type="l", col="deepskyblue", lwd=2,
ylim=c(0,0.02), xlab= " ", ylab = " ")
axis (2, lwd= 1)
mtext (2, line=2.25, text="Q (mm/10min)")
par(new=T)
plot(Ev20HS$date.time, Ev20HS$Qold2H, type="l", axes= FALSE, col="sienna3",
lwd=2, ylim=c(0,0.02), xlab= " ", ylab = " ")
cord.x <- c(7, 7, 13, 13)
cord.y <- c(0.00223742, 0.00238599, 0.01043445, 0.00970288)
polygon(cord.x, cord.y, col="steelblue3")


I want to plot in the same graph:

a) Precipitation (P) as a barplot (downwards) --> DONE
b) Total discharge in Stream (Qt) --> DONE
c) Discharge of groundwater, i.e. old component (Qold2H) --> The space
between Qt and Qold2H needs to be shaded with one colour, and the space
between Qold2H and x-axes needs to be shaded as well.


Another question, is there any option to make these curves smoother? I
don't really like those ugly peaks.

On 26 May 2016 at 17:21, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 26/05/2016 11:20 AM, ?scar Jim?nez wrote:
>
>> oops, sorry I didn't know that... I'll answer in R-help. It was the 1st
>> time I was using this tool.
>>
>> Also, I never learned programming and R... so I do not control theses
>> languages. I'm just trying to work with it and got no support, and so many
>> questions arises.. hahaha
>>
>
> Don't worry about it.  I was just giving advice for the future.
>
> Duncan Murdoch
>
>
>
>> On 26 May 2016 at 17:12, Duncan Murdoch <murdoch.duncan at gmail.com
>> <mailto:murdoch.duncan at gmail.com>> wrote:
>>
>>     On 26/05/2016 11:03 AM, ?scar Jim?nez wrote:
>>
>>         Hi Duncan,
>>
>>         Thanks for the quick reply  :)
>>         Does the function Sys.Date return a time series (created with
>>         the function POSIXct), with numerical values?
>>
>>
>>     It returns a Date object.  The str() function will show you that.
>>     But Date, POSIXct, and even POSIXlt are supported by many of the
>>     graphics functions, so you don't need to worry about the conversions.
>>
>>         I mean... I think the best option is to convert the time
>>         series (plotted as characters), into numerical values, right?
>>
>>
>>     No, that is not needed.
>>
>>         Or is there any other function that allows me to draw the
>>         shade under the curve using time series as the "x" variable?
>>
>>
>>     polygon() does.
>>
>>     You should try things; R won't break.
>>
>>
>>         If you need more info I can share my script and my database
>>         and you can see it properly.
>>
>>
>>     You should always do that when you pose your question; you should
>>     also send your questions to R-help, not privately. I've cc'd my
>>     response there.
>>
>>     Duncan Murdoch
>>
>>
>>
>

From maillists at pp.inet.fi  Thu May 26 16:51:46 2016
From: maillists at pp.inet.fi (K. Elo)
Date: Thu, 26 May 2016 17:51:46 +0300
Subject: [R] Scale y-labels based on a value with 'lattice'
Message-ID: <bf9a8711-f098-cf66-6cfd-55b3bee9e9c7@pp.inet.fi>

Dear R-helpers!

I have a data frame storing data for word co-occurrences, average 
distances and co-occurence frequency:

       Group.1    Group.2     x Freq
1 deutschland  achtziger  2.00    1
2 deutschland        alt  1.25    4
3 deutschland     anfang -2.00    1
4 deutschland    ansehen  1.00    2
5 deutschland     arbeit  0.50    2
6 deutschland arbeitslos -2.00    1

Now I want to plot a lattice 'dotplot' with the formula 'Group.2~x'. 
This works fine.

However, I would like to scale the y-label (based on 'Group.2' according 
the 'Freq' value using a log-scaled value (log(Freq+.5)). In other 
words: the higher the 'Freq' value of a term, the bigger its label 
should be printed in my dotplot.

The problem is that I cannot figure out how to tell lattice to scale 
each y-label with according 'Freq' value. I am quite sure I should build 
a function for scales=list(y=...), but I don't know how to it.

Many thanks in advance for your help!

Best,
Kimmo Elo

--
?bo Akademi University / German studies
Turku, Finland


From jennifer.sheng2002 at gmail.com  Thu May 26 19:19:44 2016
From: jennifer.sheng2002 at gmail.com (Jennifer Sheng)
Date: Thu, 26 May 2016 13:19:44 -0400
Subject: [R] JM plotting
Message-ID: <CALvAKXKjL_+zUGVLmHjsED+enOsbK4xYHKf2BjabEdGRVV-efg@mail.gmail.com>

Dear Users,

When the joint modeling was run in ER, the run was completed successfully
with co-eff output.  However, in the terms plotting, somehow the plot
(fitjoint.null) does not work, with following error message.  Any advice
from the group?  Thank you very much!

Best regards,
Jenny

Error in Zs * b[id.GK, , drop = FALSE] : non-conformable arrays

	[[alternative HTML version deleted]]


From Achim.Zeileis at uibk.ac.at  Thu May 26 22:28:52 2016
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Thu, 26 May 2016 22:28:52 +0200 (CEST)
Subject: [R] Fortune candidate, was Re:  Shaded areas in R
In-Reply-To: <88fd893c-0687-bdfe-5b1a-5410879b26a5@dewey.myzen.co.uk>
References: <CAJAnTBXtLMADaak8JyPcXcJ3WLPPkczyZ+ktvAaXUrDr5p-T4g@mail.gmail.com>
	<888fc5b0-5d21-1c84-6b44-5096eda64d13@gmail.com>
	<CAJAnTBWc0mHXMN0uQr2HGz9gv0SyzuJky3C6jkai+8SYmA1hxg@mail.gmail.com>
	<674e138c-f49b-8d18-a2e2-fd3386b600ea@gmail.com>
	<88fd893c-0687-bdfe-5b1a-5410879b26a5@dewey.myzen.co.uk>
Message-ID: <alpine.DEB.2.20.1605262228240.17689@paninaro>

On Thu, 26 May 2016, Michael Dewey wrote:

> In a reply Duncan said

Nice, thanks, added to the "fortunes" package on R-Forge now.
Best,
Z

> On 26/05/2016 16:12, Duncan Murdoch wrote:
>> On 26/05/2016 11:03 AM, ?scar Jim?nez wrote:
>> 
>> You should try things; R won't break.
>>> 
>> 
>
>> Duncan Murdoch
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> -- 
> Michael
> http://www.dewey.myzen.co.uk/home.html
>

From ruipbarradas at sapo.pt  Thu May 26 22:58:28 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Thu, 26 May 2016 21:58:28 +0100
Subject: [R] subset data right
In-Reply-To: <927632887.2224306.1464291352800.JavaMail.yahoo@mail.yahoo.com>
References: <927632887.2224306.1464291352800.JavaMail.yahoo.ref@mail.yahoo.com>
	<927632887.2224306.1464291352800.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <20160526215828.Horde.O4ivTBcx102Z_FfD3k0IIjo@mail.sapo.pt>

Hello,

Don't use subset, use indexing.

subdf <- df[df$quant %in% "VeryFast", ]

By the way, instead of %in% you can use ==, since you're interested in  
just one value of quant.

Hope this helps,

Rui Barradas

Citando ch.elahe via R-help <r-help at r-project.org>:

> Hi all,
> I have the following df and I want to know which Protocols are  
> VeryFast, which are FAST, which are SLOW and also which ones are  
> VerySLOW :
>
> $ Protocol? ? ? ?: Factor w/ 48 levels "DP FS QTSE SAG",..: 5 5 28 5  
> 5 5 7 7 47 5 ...
>
> $ quant? ? ? ? ? : Factor w/ 4 levels "FAST","SLOW",..: 2 2 2 4 2 1 1 2 4
>
> I do the following subset but nothing is changed in my df:
>
> subdf=subset(df,quant%in%c("VeryFast"))
> subdf$quant=factor(subdf$quant)
> and when I get the str(df) again Protocol has 48 levels. Does anyone  
> know how can I get these subsets right?
> Thanks for any help!
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide  
> http://www.R-project.org/posting-guide.htmland provide commented,  
> minimal, self-contained, reproducible code.

?

	[[alternative HTML version deleted]]


From milujisb at gmail.com  Thu May 26 23:30:30 2016
From: milujisb at gmail.com (Miluji Sb)
Date: Thu, 26 May 2016 23:30:30 +0200
Subject: [R] Match Coordinates to NUTS 2 ID
Message-ID: <CAMLwc7PHcJgVaQzg4hOUd-u9_7hOY1xiv-YBFotCiQn6HF60Ow@mail.gmail.com>

Dear all,


I have downloaded the NUTS 2 level data from
library(?rgdal?)
library(?RColorBrewer?)
library(?classInt?)
#library(?SmarterPoland?)
library(fields)

# Download Administrative Level data from EuroStat
temp <- tempfile(fileext = ".zip")
download.file("
http://ec.europa.eu/eurostat/cache/GISCO/geodatafiles/NUTS_2010_60M_SH.zip
",
              temp)
unzip(temp)

# Read data
EU_NUTS <- readOGR(dsn = "./NUTS_2010_60M_SH/data", layer =
"NUTS_RG_60M_2010")

# Subset NUTS 2 level data
map_nuts2 <- subset(EU_NUTS, STAT_LEVL_ == 2)

I also have data for a variable by coordinates, which looks like this:

structure(list(LON = c(-125.25, -124.75, -124.25, -124.25, -124.25,
-124.25), LAT = c(49.75, 49.25, 42.75, 43.25, 48.75, 49.25),
    yr = c(2.91457704560515, 9.94774197180345, -2.71956412885765,
    -0.466213169185147, -36.6645659563374, 10.5168056769535)), .Names =
c("LON",
"LAT", "yr"), row.names = c(NA, 6L), class = "data.frame")

I would like to match the coordinates to their corresponding NUTS 2 region
- is this possible? Any help will be high appreciated. Thank you!

Sincerely,

Milu

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Thu May 26 23:48:24 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 26 May 2016 14:48:24 -0700
Subject: [R] subset data right
In-Reply-To: <927632887.2224306.1464291352800.JavaMail.yahoo@mail.yahoo.com>
References: <927632887.2224306.1464291352800.JavaMail.yahoo.ref@mail.yahoo.com>
	<927632887.2224306.1464291352800.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAF8bMcZ+QfavNVdpTJ+29XAbRbEQ1ExN0CKJqNKhJKD96t3aKQ@mail.gmail.com>

You did not change df$quant - you made a new object called 'subdf'
containing a column called 'quant' that had only one level.  Changing
subdf has no effect on df.

> df <- data.frame(quant=factor(letters))
> str(df)
'data.frame':   26 obs. of  1 variable:
 $ quant: Factor w/ 26 levels "a","b","c","d",..: 1 2 3 4 5 6 7 8 9 10 ...
> subdf <- subset(df, quant %in% "a")
> subdf$quant <- factor(subdf$quant)
> str(df)
'data.frame':   26 obs. of  1 variable:
 $ quant: Factor w/ 26 levels "a","b","c","d",..: 1 2 3 4 5 6 7 8 9 10 ...
> str(subdf)
'data.frame':   1 obs. of  1 variable:
 $ quant: Factor w/ 1 level "a": 1



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, May 26, 2016 at 12:35 PM, ch.elahe via R-help <r-help at r-project.org>
wrote:

> Hi all,
> I have the following df and I want to know which Protocols are VeryFast,
> which are FAST, which are SLOW and also which ones are VerySLOW :
>
>
>   $ Protocol       : Factor w/ 48 levels "DP FS QTSE SAG",..: 5 5 28 5 5 5
> 7 7 47 5 ...
>
>   $ quant          : Factor w/ 4 levels "FAST","SLOW",..: 2 2 2 4 2 1 1 2 4
>
> I do the following subset but nothing is changed in my df:
>
>
>   subdf=subset(df,quant%in%c("VeryFast"))
>   subdf$quant=factor(subdf$quant)
> and when I get the str(df) again Protocol has 48 levels. Does anyone know
> how can I get these subsets right?
> Thanks for any help!
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri May 27 00:08:48 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 27 May 2016 08:08:48 +1000
Subject: [R] Scale y-labels based on a value with 'lattice'
In-Reply-To: <bf9a8711-f098-cf66-6cfd-55b3bee9e9c7@pp.inet.fi>
References: <bf9a8711-f098-cf66-6cfd-55b3bee9e9c7@pp.inet.fi>
Message-ID: <CA+8X3fURLgnnXN_HYxqaAfEq7Vs716P_=5GCXMsJGT_KHYMiMA@mail.gmail.com>

Hi Kimmo,
I was unable to work out how to do this in lattice, but this might help:

kedf<-read.table(text="Group.1    Group.2     x Freq
 deutschland  achtziger  2.00    1
 deutschland        alt  1.25    4
 deutschland     anfang -2.00    1
 deutschland    ansehen  1.00    2
 deutschland     arbeit  0.50    2
 deutschland arbeitslos -2.00    1",header=TRUE)

par(mar=c(5,7,4,2))
dotchart(kedf$x)
mtext(kedf$Group.2,side=2,at=1:6,line=0.5,
 las=2,cex=log(abs(kedf$Freq))+1)

Jim


On Fri, May 27, 2016 at 12:51 AM, K. Elo <maillists at pp.inet.fi> wrote:
> Dear R-helpers!
>
> I have a data frame storing data for word co-occurrences, average distances
> and co-occurence frequency:
>
>       Group.1    Group.2     x Freq
> 1 deutschland  achtziger  2.00    1
> 2 deutschland        alt  1.25    4
> 3 deutschland     anfang -2.00    1
> 4 deutschland    ansehen  1.00    2
> 5 deutschland     arbeit  0.50    2
> 6 deutschland arbeitslos -2.00    1
>
> Now I want to plot a lattice 'dotplot' with the formula 'Group.2~x'. This
> works fine.
>
> However, I would like to scale the y-label (based on 'Group.2' according the
> 'Freq' value using a log-scaled value (log(Freq+.5)). In other words: the
> higher the 'Freq' value of a term, the bigger its label should be printed in
> my dotplot.
>
> The problem is that I cannot figure out how to tell lattice to scale each
> y-label with according 'Freq' value. I am quite sure I should build a
> function for scales=list(y=...), but I don't know how to it.
>
> Many thanks in advance for your help!
>
> Best,
> Kimmo Elo
>
> --
> ?bo Akademi University / German studies
> Turku, Finland
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Fri May 27 00:49:23 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 26 May 2016 22:49:23 +0000
Subject: [R] Match Coordinates to NUTS 2 ID
In-Reply-To: <CAMLwc7PHcJgVaQzg4hOUd-u9_7hOY1xiv-YBFotCiQn6HF60Ow@mail.gmail.com>
References: <CAMLwc7PHcJgVaQzg4hOUd-u9_7hOY1xiv-YBFotCiQn6HF60Ow@mail.gmail.com>
Message-ID: <D36CCB1E.1758DC%macqueen1@llnl.gov>

Perhaps the
  over()
function in the sp package.

(in which case, R-sig-geo might be a better place to ask).

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 5/26/16, 2:30 PM, "R-help on behalf of Miluji Sb"
<r-help-bounces at r-project.org on behalf of milujisb at gmail.com> wrote:

>Dear all,
>
>
>I have downloaded the NUTS 2 level data from
>library(?rgdal?)
>library(?RColorBrewer?)
>library(?classInt?)
>#library(?SmarterPoland?)
>library(fields)
>
># Download Administrative Level data from EuroStat
>temp <- tempfile(fileext = ".zip")
>download.file("
>http://ec.europa.eu/eurostat/cache/GISCO/geodatafiles/NUTS_2010_60M_SH.zip
>",
>              temp)
>unzip(temp)
>
># Read data
>EU_NUTS <- readOGR(dsn = "./NUTS_2010_60M_SH/data", layer =
>"NUTS_RG_60M_2010")
>
># Subset NUTS 2 level data
>map_nuts2 <- subset(EU_NUTS, STAT_LEVL_ == 2)
>
>I also have data for a variable by coordinates, which looks like this:
>
>structure(list(LON = c(-125.25, -124.75, -124.25, -124.25, -124.25,
>-124.25), LAT = c(49.75, 49.25, 42.75, 43.25, 48.75, 49.25),
>    yr = c(2.91457704560515, 9.94774197180345, -2.71956412885765,
>    -0.466213169185147, -36.6645659563374, 10.5168056769535)), .Names =
>c("LON",
>"LAT", "yr"), row.names = c(NA, 6L), class = "data.frame")
>
>I would like to match the coordinates to their corresponding NUTS 2 region
>- is this possible? Any help will be high appreciated. Thank you!
>
>Sincerely,
>
>Milu
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From emorway at usgs.gov  Fri May 27 01:59:52 2016
From: emorway at usgs.gov (Morway, Eric)
Date: Thu, 26 May 2016 16:59:52 -0700
Subject: [R] rollapply and difftime
Message-ID: <CAPoqHzqtWd+iUFXcsBtF3gd_8MymjYbmFtESYXhwkeHVK8b5qg@mail.gmail.com>

Technically, the code below works and results in a column that I'm
interested in working with for further processing.  However, it is both
inefficient on lengthy (>100 yr) daily time series and is, frankly, not the
R way of doing things.  Using the 'Daily' data.frame provided below, I'm
interested to know the propeR way of accomplishing this same task in an
efficient manner.  I tried combinations of rollapply and difftime, but was
unsuccessful.  Eric

Daily <- read.table(textConnection("     Date        Q
1911-04-01 4.530695
1911-04-02 4.700596
1911-04-03 4.898814
1911-04-04 5.097032
1911-04-05 5.295250
1911-04-06 6.569508
1911-04-07 5.861587
1911-04-08 5.153666
1911-04-09 4.445745
1911-04-10 3.737824
1911-04-11 3.001586
1911-04-12 3.001586
1911-04-13 2.350298
1911-04-14 2.661784
1911-04-16 3.001586
1911-04-17 2.661784
1911-04-19 2.661784
1911-04-28 3.369705
1911-04-29 3.001586
1911-05-20 2.661784"),header=TRUE)

Daily$Date <- as.Date(Daily$Date)
Daily$tmdiff <- NA
for(i in seq(2,length(Daily$Date),by=1)){
  Daily$tmdiff[i] <- as.numeric(difftime(Daily$Date[i],Daily$Date[i-1]))
}

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Fri May 27 02:09:20 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 27 May 2016 00:09:20 +0000
Subject: [R] rollapply and difftime
In-Reply-To: <CAPoqHzqtWd+iUFXcsBtF3gd_8MymjYbmFtESYXhwkeHVK8b5qg@mail.gmail.com>
References: <CAPoqHzqtWd+iUFXcsBtF3gd_8MymjYbmFtESYXhwkeHVK8b5qg@mail.gmail.com>
Message-ID: <D36CDDFA.1758E9%macqueen1@llnl.gov>

You want the number of days between dates?
Does this do the trick?

dts <- Sys.Date()+ c(1,2,3,5,6,9)
dts[-1] - dts[-length(dts)]

Time differences in days
[1] 1 1 2 1 3



-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 5/26/16, 4:59 PM, "R-help on behalf of Morway, Eric"
<r-help-bounces at r-project.org on behalf of emorway at usgs.gov> wrote:

>Technically, the code below works and results in a column that I'm
>interested in working with for further processing.  However, it is both
>inefficient on lengthy (>100 yr) daily time series and is, frankly, not
>the
>R way of doing things.  Using the 'Daily' data.frame provided below, I'm
>interested to know the propeR way of accomplishing this same task in an
>efficient manner.  I tried combinations of rollapply and difftime, but was
>unsuccessful.  Eric
>
>Daily <- read.table(textConnection("     Date        Q
>1911-04-01 4.530695
>1911-04-02 4.700596
>1911-04-03 4.898814
>1911-04-04 5.097032
>1911-04-05 5.295250
>1911-04-06 6.569508
>1911-04-07 5.861587
>1911-04-08 5.153666
>1911-04-09 4.445745
>1911-04-10 3.737824
>1911-04-11 3.001586
>1911-04-12 3.001586
>1911-04-13 2.350298
>1911-04-14 2.661784
>1911-04-16 3.001586
>1911-04-17 2.661784
>1911-04-19 2.661784
>1911-04-28 3.369705
>1911-04-29 3.001586
>1911-05-20 2.661784"),header=TRUE)
>
>Daily$Date <- as.Date(Daily$Date)
>Daily$tmdiff <- NA
>for(i in seq(2,length(Daily$Date),by=1)){
>  Daily$tmdiff[i] <- as.numeric(difftime(Daily$Date[i],Daily$Date[i-1]))
>}
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Fri May 27 02:37:04 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 26 May 2016 17:37:04 -0700
Subject: [R] rollapply and difftime
In-Reply-To: <D36CDDFA.1758E9%macqueen1@llnl.gov>
References: <CAPoqHzqtWd+iUFXcsBtF3gd_8MymjYbmFtESYXhwkeHVK8b5qg@mail.gmail.com>
	<D36CDDFA.1758E9%macqueen1@llnl.gov>
Message-ID: <8A6F1AEA-0316-4394-A6F6-514D08A331D6@dcn.davis.ca.us>

What about just

diff( dts )

or

as.numeric( diff( dts ), units="days" )

?
-- 
Sent from my phone. Please excuse my brevity.

On May 26, 2016 5:09:20 PM PDT, "MacQueen, Don" <macqueen1 at llnl.gov> wrote:
>You want the number of days between dates?
>Does this do the trick?
>
>dts <- Sys.Date()+ c(1,2,3,5,6,9)
>dts[-1] - dts[-length(dts)]
>
>Time differences in days
>[1] 1 1 2 1 3
>
>
>
>-- 
>Don MacQueen
>
>Lawrence Livermore National Laboratory
>7000 East Ave., L-627
>Livermore, CA 94550
>925-423-1062
>
>
>
>
>
>On 5/26/16, 4:59 PM, "R-help on behalf of Morway, Eric"
><r-help-bounces at r-project.org on behalf of emorway at usgs.gov> wrote:
>
>>Technically, the code below works and results in a column that I'm
>>interested in working with for further processing.  However, it is
>both
>>inefficient on lengthy (>100 yr) daily time series and is, frankly,
>not
>>the
>>R way of doing things.  Using the 'Daily' data.frame provided below,
>I'm
>>interested to know the propeR way of accomplishing this same task in
>an
>>efficient manner.  I tried combinations of rollapply and difftime, but
>was
>>unsuccessful.  Eric
>>
>>Daily <- read.table(textConnection("     Date        Q
>>1911-04-01 4.530695
>>1911-04-02 4.700596
>>1911-04-03 4.898814
>>1911-04-04 5.097032
>>1911-04-05 5.295250
>>1911-04-06 6.569508
>>1911-04-07 5.861587
>>1911-04-08 5.153666
>>1911-04-09 4.445745
>>1911-04-10 3.737824
>>1911-04-11 3.001586
>>1911-04-12 3.001586
>>1911-04-13 2.350298
>>1911-04-14 2.661784
>>1911-04-16 3.001586
>>1911-04-17 2.661784
>>1911-04-19 2.661784
>>1911-04-28 3.369705
>>1911-04-29 3.001586
>>1911-05-20 2.661784"),header=TRUE)
>>
>>Daily$Date <- as.Date(Daily$Date)
>>Daily$tmdiff <- NA
>>for(i in seq(2,length(Daily$Date),by=1)){
>>  Daily$tmdiff[i] <-
>as.numeric(difftime(Daily$Date[i],Daily$Date[i-1]))
>>}
>>
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From NordlDJ at dshs.wa.gov  Fri May 27 03:01:49 2016
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Fri, 27 May 2016 01:01:49 +0000
Subject: [R] rollapply and difftime
In-Reply-To: <CAPoqHzqtWd+iUFXcsBtF3gd_8MymjYbmFtESYXhwkeHVK8b5qg@mail.gmail.com>
References: <CAPoqHzqtWd+iUFXcsBtF3gd_8MymjYbmFtESYXhwkeHVK8b5qg@mail.gmail.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA276630968815@WAXMXOLYMB025.WAX.wa.lcl>

Another option

Daily$tmdiff <- with(Daily, c(NA, diff(Date, units='days')))


Hope this is helpful,

Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Morway,
> Eric
> Sent: Thursday, May 26, 2016 5:00 PM
> To: R mailing list
> Subject: [R] rollapply and difftime
> 
> Technically, the code below works and results in a column that I'm interested
> in working with for further processing.  However, it is both inefficient on
> lengthy (>100 yr) daily time series and is, frankly, not the R way of doing
> things.  Using the 'Daily' data.frame provided below, I'm interested to know
> the propeR way of accomplishing this same task in an efficient manner.  I
> tried combinations of rollapply and difftime, but was unsuccessful.  Eric
> 
> Daily <- read.table(textConnection("     Date        Q
> 1911-04-01 4.530695
> 1911-04-02 4.700596
> 1911-04-03 4.898814
> 1911-04-04 5.097032
> 1911-04-05 5.295250
> 1911-04-06 6.569508
> 1911-04-07 5.861587
> 1911-04-08 5.153666
> 1911-04-09 4.445745
> 1911-04-10 3.737824
> 1911-04-11 3.001586
> 1911-04-12 3.001586
> 1911-04-13 2.350298
> 1911-04-14 2.661784
> 1911-04-16 3.001586
> 1911-04-17 2.661784
> 1911-04-19 2.661784
> 1911-04-28 3.369705
> 1911-04-29 3.001586
> 1911-05-20 2.661784"),header=TRUE)
> 
> Daily$Date <- as.Date(Daily$Date)
> Daily$tmdiff <- NA
> for(i in seq(2,length(Daily$Date),by=1)){
>   Daily$tmdiff[i] <- as.numeric(difftime(Daily$Date[i],Daily$Date[i-1]))
> }
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Fri May 27 07:51:11 2016
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Fri, 27 May 2016 15:51:11 +1000
Subject: [R] Scale y-labels based on a value with 'lattice'
In-Reply-To: <bf9a8711-f098-cf66-6cfd-55b3bee9e9c7@pp.inet.fi>
References: <bf9a8711-f098-cf66-6cfd-55b3bee9e9c7@pp.inet.fi>
Message-ID: <000001d1b7db$c67481a0$535d84e0$@bigpond.com>

Hi

If you want to change the cex of the labels see

library(lattice)
 ?yscale.components.default

Possibly an easier way is to size the symbols

I will use Jims data.frame to plot with lattice
dotplot(Group.2 ~ x, data = kedf, 
                 scales = list(y = list(labels = kedf[,"Group2"], cex = = kedf[,"Freq"]))) 

 If you want to magnify the size of the symbol according to Freq

dotplot(Group.2 ~ x, data = kedf, 
                cex = kedf[,"Freq"])

or with modifications
dotplot(Group.2 ~ x, data = kedf, 
                col = "black",
               pch = 15,
                cex = kedf[,"Freq"])

If you wanted to go further

dotplot(Group.2 ~ x, data = kedf,
        par.settings = list(dot.symbol = list(col = "black",
                                              pch = 15)  ),
        cex = kedf[,"Freq"])

without further work cex will not work as it is in par settings

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of K. Elo
Sent: Friday, 27 May 2016 00:52
To: r-help at r-project.org
Subject: [R] Scale y-labels based on a value with 'lattice'

Dear R-helpers!

I have a data frame storing data for word co-occurrences, average 
distances and co-occurence frequency:

       Group.1    Group.2     x Freq
1 deutschland  achtziger  2.00    1
2 deutschland        alt  1.25    4
3 deutschland     anfang -2.00    1
4 deutschland    ansehen  1.00    2
5 deutschland     arbeit  0.50    2
6 deutschland arbeitslos -2.00    1

Now I want to plot a lattice 'dotplot' with the formula 'Group.2~x'. 
This works fine.

However, I would like to scale the y-label (based on 'Group.2' according 
the 'Freq' value using a log-scaled value (log(Freq+.5)). In other 
words: the higher the 'Freq' value of a term, the bigger its label 
should be printed in my dotplot.

The problem is that I cannot figure out how to tell lattice to scale 
each y-label with according 'Freq' value. I am quite sure I should build 
a function for scales=list(y=...), but I don't know how to it.

Many thanks in advance for your help!

Best,
Kimmo Elo

--
?bo Akademi University / German studies
Turku, Finland

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From lorenzo.isella at gmail.com  Fri May 27 12:14:32 2016
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Fri, 27 May 2016 12:14:32 +0200
Subject: [R] Getting Rid of NaN in ts Object
Message-ID: <20160527101432.GA3282@localhost.localdomain>

Dear All,
I am sure the answer is a one liner, but I am banging my head against
the wall and googling here and there has not helped much.
Consider the following time series

tt<-structure(c(NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,
NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, 1133.09, 1155.77, 1179.12,
1182.85, 1133.43, 1103.36, 1081.19, 1058.55, 1056.95, 1059.13,
1018.18, 920.62, 865.99, 856.29, 841.58, 857.7, 852.71, 890.76
), .Tsp = c(1980, 2015, 1), class = "ts")


where the NaN do *not* occur internally. How can I automatically get
rid of them and adjust the start and end year of the time series
accordingly?
Many thanks

Lorenzo


From milujisb at gmail.com  Fri May 27 12:20:57 2016
From: milujisb at gmail.com (Miluji Sb)
Date: Fri, 27 May 2016 12:20:57 +0200
Subject: [R] Match Coordinates to NUTS 2 ID
In-Reply-To: <D36CCB1E.1758DC%macqueen1@llnl.gov>
References: <CAMLwc7PHcJgVaQzg4hOUd-u9_7hOY1xiv-YBFotCiQn6HF60Ow@mail.gmail.com>
	<D36CCB1E.1758DC%macqueen1@llnl.gov>
Message-ID: <CAMLwc7O31mUnOBrTtv9JcSUz6C4ha0iti2B2MEF1VQbpq_e_cA@mail.gmail.com>

Thank you for your reply. I am trying to use the over function - but having
trouble. Asked at R-sig-geo. Thanks again!

Sincerely,

Milu

On Fri, May 27, 2016 at 12:49 AM, MacQueen, Don <macqueen1 at llnl.gov> wrote:

> Perhaps the
>   over()
> function in the sp package.
>
> (in which case, R-sig-geo might be a better place to ask).
>
> -Don
>
> --
> Don MacQueen
>
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
>
>
>
>
>
> On 5/26/16, 2:30 PM, "R-help on behalf of Miluji Sb"
> <r-help-bounces at r-project.org on behalf of milujisb at gmail.com> wrote:
>
> >Dear all,
> >
> >
> >I have downloaded the NUTS 2 level data from
> >library(?rgdal?)
> >library(?RColorBrewer?)
> >library(?classInt?)
> >#library(?SmarterPoland?)
> >library(fields)
> >
> ># Download Administrative Level data from EuroStat
> >temp <- tempfile(fileext = ".zip")
> >download.file("
> >
> http://ec.europa.eu/eurostat/cache/GISCO/geodatafiles/NUTS_2010_60M_SH.zip
> >",
> >              temp)
> >unzip(temp)
> >
> ># Read data
> >EU_NUTS <- readOGR(dsn = "./NUTS_2010_60M_SH/data", layer =
> >"NUTS_RG_60M_2010")
> >
> ># Subset NUTS 2 level data
> >map_nuts2 <- subset(EU_NUTS, STAT_LEVL_ == 2)
> >
> >I also have data for a variable by coordinates, which looks like this:
> >
> >structure(list(LON = c(-125.25, -124.75, -124.25, -124.25, -124.25,
> >-124.25), LAT = c(49.75, 49.25, 42.75, 43.25, 48.75, 49.25),
> >    yr = c(2.91457704560515, 9.94774197180345, -2.71956412885765,
> >    -0.466213169185147, -36.6645659563374, 10.5168056769535)), .Names =
> >c("LON",
> >"LAT", "yr"), row.names = c(NA, 6L), class = "data.frame")
> >
> >I would like to match the coordinates to their corresponding NUTS 2 region
> >- is this possible? Any help will be high appreciated. Thank you!
> >
> >Sincerely,
> >
> >Milu
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Fri May 27 12:37:31 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 27 May 2016 11:37:31 +0100
Subject: [R] subset data right
In-Reply-To: <CAF8bMcZ+QfavNVdpTJ+29XAbRbEQ1ExN0CKJqNKhJKD96t3aKQ@mail.gmail.com>
References: <927632887.2224306.1464291352800.JavaMail.yahoo.ref@mail.yahoo.com>
	<927632887.2224306.1464291352800.JavaMail.yahoo@mail.yahoo.com>
	<CAF8bMcZ+QfavNVdpTJ+29XAbRbEQ1ExN0CKJqNKhJKD96t3aKQ@mail.gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403E14A94D2@GBTEDVPEXCMB04.corp.lgc-group.com>

> You did not change df$quant - you made a new object called 'subdf'
> containing a column called 'quant' that had only one level.  Changing subdf has
> no effect on df.

Also, subsetting a factor _intentionally_ does not change the number of levels. Example:
f <- factor(sample(letters[1:3], 30, replace=TRUE))
f[1]  #One element, still three levels

If you want to drop levels, use droplevels() either on the factor or on the subset of your data frame. Example: 
droplevels(f[1]) #One element, only one level


Also worth noting that df is a function.
 > df <- data.frame(quant=factor(letters))
looks very like you're assigning a data frame to the function 'df' (density for the F distribution)
It doesn't, because R is clever. But it's really not good practice to use common function names as variable names. Too much potential for confusion.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From drjimlemon at gmail.com  Fri May 27 12:46:20 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 27 May 2016 20:46:20 +1000
Subject: [R] Getting Rid of NaN in ts Object
In-Reply-To: <20160527101432.GA3282@localhost.localdomain>
References: <20160527101432.GA3282@localhost.localdomain>
Message-ID: <CA+8X3fXDkJ8RdQbFwn92FivA5Q4JanXSzuV4r0_ZpJps5aPwYg@mail.gmail.com>

Hi Lorenzo,
Maybe:

tt<-tt[!is.nan(tt)]

Jim


On Fri, May 27, 2016 at 8:14 PM, Lorenzo Isella
<lorenzo.isella at gmail.com> wrote:
> Dear All,
> I am sure the answer is a one liner, but I am banging my head against
> the wall and googling here and there has not helped much.
> Consider the following time series
>
> tt<-structure(c(NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,
> NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, 1133.09, 1155.77, 1179.12,
> 1182.85, 1133.43, 1103.36, 1081.19, 1058.55, 1056.95, 1059.13,
> 1018.18, 920.62, 865.99, 856.29, 841.58, 857.7, 852.71, 890.76
> ), .Tsp = c(1980, 2015, 1), class = "ts")
>
>
> where the NaN do *not* occur internally. How can I automatically get
> rid of them and adjust the start and end year of the time series
> accordingly?
> Many thanks
>
> Lorenzo
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lorenzo.isella at gmail.com  Fri May 27 13:38:14 2016
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Fri, 27 May 2016 13:38:14 +0200
Subject: [R] Getting Rid of NaN in ts Object
In-Reply-To: <CA+8X3fXDkJ8RdQbFwn92FivA5Q4JanXSzuV4r0_ZpJps5aPwYg@mail.gmail.com>
References: <20160527101432.GA3282@localhost.localdomain>
	<CA+8X3fXDkJ8RdQbFwn92FivA5Q4JanXSzuV4r0_ZpJps5aPwYg@mail.gmail.com>
Message-ID: <20160527113814.GB3282@localhost.localdomain>

On Fri, May 27, 2016 at 08:46:20PM +1000, Jim Lemon wrote:
>Hi Lorenzo,
>Maybe:
>
>tt<-tt[!is.nan(tt)]
>
>Jim


Not really.

> tt<-structure(c(NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,
+ NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, 1133.09, 1155.77, 1179.12,
+ 1182.85, 1133.43, 1103.36, 1081.19, 1058.55, 1056.95, 1059.13,
+ 1018.18, 920.62, 865.99, 856.29, 841.58, 857.7, 852.71, 890.76
+ ), .Tsp = c(1980, 2015, 1), class = "ts")
>
> tt2<-tt[!is.nan(tt)]
> class(tt)
[1] "ts"
> class(tt2)
[1] "numeric"


and I lose all the info about the years.

Lorenzo







>
>
>On Fri, May 27, 2016 at 8:14 PM, Lorenzo Isella
><lorenzo.isella at gmail.com> wrote:
>> Dear All,
>> I am sure the answer is a one liner, but I am banging my head against
>> the wall and googling here and there has not helped much.
>> Consider the following time series
>>
>> tt<-structure(c(NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,
>> NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, 1133.09, 1155.77, 1179.12,
>> 1182.85, 1133.43, 1103.36, 1081.19, 1058.55, 1056.95, 1059.13,
>> 1018.18, 920.62, 865.99, 856.29, 841.58, 857.7, 852.71, 890.76
>> ), .Tsp = c(1980, 2015, 1), class = "ts")
>>
>>
>> where the NaN do *not* occur internally. How can I automatically get
>> rid of them and adjust the start and end year of the time series
>> accordingly?
>> Many thanks
>>
>> Lorenzo
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From bran.chri at gmail.com  Fri May 27 13:50:03 2016
From: bran.chri at gmail.com (=?UTF-8?Q?Christian_Brandst=c3=a4tter?=)
Date: Fri, 27 May 2016 13:50:03 +0200
Subject: [R] Getting Rid of NaN in ts Object
In-Reply-To: <20160527113814.GB3282@localhost.localdomain>
References: <20160527101432.GA3282@localhost.localdomain>
	<CA+8X3fXDkJ8RdQbFwn92FivA5Q4JanXSzuV4r0_ZpJps5aPwYg@mail.gmail.com>
	<20160527113814.GB3282@localhost.localdomain>
Message-ID: <e2c2f43b-9c21-9bf5-ab4f-4b007b3ec038@gmail.com>

Hi Lorenzo,

Try:

tt[is.nan(tt)] <- NA
tt <- na.omit(tt)

Best,

Christian


Am 27.05.2016 um 13:38 schrieb Lorenzo Isella:
> On Fri, May 27, 2016 at 08:46:20PM +1000, Jim Lemon wrote:
>> Hi Lorenzo,
>> Maybe:
>>
>> tt<-tt[!is.nan(tt)]
>>
>> Jim
>
>
> Not really.
>
>> tt<-structure(c(NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,
> + NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, 1133.09, 1155.77, 1179.12,
> + 1182.85, 1133.43, 1103.36, 1081.19, 1058.55, 1056.95, 1059.13,
> + 1018.18, 920.62, 865.99, 856.29, 841.58, 857.7, 852.71, 890.76
> + ), .Tsp = c(1980, 2015, 1), class = "ts")
>>
>> tt2<-tt[!is.nan(tt)]
>> class(tt)
> [1] "ts"
>> class(tt2)
> [1] "numeric"
>
>
> and I lose all the info about the years.
>
> Lorenzo
>
>
>
>
>
>
>
>>
>>
>> On Fri, May 27, 2016 at 8:14 PM, Lorenzo Isella
>> <lorenzo.isella at gmail.com> wrote:
>>> Dear All,
>>> I am sure the answer is a one liner, but I am banging my head against
>>> the wall and googling here and there has not helped much.
>>> Consider the following time series
>>>
>>> tt<-structure(c(NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,
>>> NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, 1133.09, 1155.77, 1179.12,
>>> 1182.85, 1133.43, 1103.36, 1081.19, 1058.55, 1056.95, 1059.13,
>>> 1018.18, 920.62, 865.99, 856.29, 841.58, 857.7, 852.71, 890.76
>>> ), .Tsp = c(1980, 2015, 1), class = "ts")
>>>
>>>
>>> where the NaN do *not* occur internally. How can I automatically get
>>> rid of them and adjust the start and end year of the time series
>>> accordingly?
>>> Many thanks
>>>
>>> Lorenzo
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lorenzo.isella at gmail.com  Fri May 27 13:51:08 2016
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Fri, 27 May 2016 13:51:08 +0200
Subject: [R] Getting Rid of NaN in ts Object
In-Reply-To: <e2c2f43b-9c21-9bf5-ab4f-4b007b3ec038@gmail.com>
References: <20160527101432.GA3282@localhost.localdomain>
	<CA+8X3fXDkJ8RdQbFwn92FivA5Q4JanXSzuV4r0_ZpJps5aPwYg@mail.gmail.com>
	<20160527113814.GB3282@localhost.localdomain>
	<e2c2f43b-9c21-9bf5-ab4f-4b007b3ec038@gmail.com>
Message-ID: <20160527115108.GC3282@localhost.localdomain>

Perfect!
Exactly what I was looking for.
Thanks

Lorenzo

On Fri, May 27, 2016 at 01:50:03PM +0200, Christian Brandst?tter wrote:
>Hi Lorenzo,
>
>Try:
>
>tt[is.nan(tt)] <- NA
>tt <- na.omit(tt)
>
>Best,
>
>Christian
>
>
>Am 27.05.2016 um 13:38 schrieb Lorenzo Isella:
>>On Fri, May 27, 2016 at 08:46:20PM +1000, Jim Lemon wrote:
>>>Hi Lorenzo,
>>>Maybe:
>>>
>>>tt<-tt[!is.nan(tt)]
>>>
>>>Jim
>>
>>
>>Not really.
>>
>>>tt<-structure(c(NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,
>>+ NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, 1133.09, 1155.77, 1179.12,
>>+ 1182.85, 1133.43, 1103.36, 1081.19, 1058.55, 1056.95, 1059.13,
>>+ 1018.18, 920.62, 865.99, 856.29, 841.58, 857.7, 852.71, 890.76
>>+ ), .Tsp = c(1980, 2015, 1), class = "ts")
>>>
>>>tt2<-tt[!is.nan(tt)]
>>>class(tt)
>>[1] "ts"
>>>class(tt2)
>>[1] "numeric"
>>
>>
>>and I lose all the info about the years.
>>
>>Lorenzo
>>
>>
>>
>>
>>
>>
>>
>>>
>>>
>>>On Fri, May 27, 2016 at 8:14 PM, Lorenzo Isella
>>><lorenzo.isella at gmail.com> wrote:
>>>>Dear All,
>>>>I am sure the answer is a one liner, but I am banging my head against
>>>>the wall and googling here and there has not helped much.
>>>>Consider the following time series
>>>>
>>>>tt<-structure(c(NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,
>>>>NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, 1133.09, 1155.77, 1179.12,
>>>>1182.85, 1133.43, 1103.36, 1081.19, 1058.55, 1056.95, 1059.13,
>>>>1018.18, 920.62, 865.99, 856.29, 841.58, 857.7, 852.71, 890.76
>>>>), .Tsp = c(1980, 2015, 1), class = "ts")
>>>>
>>>>
>>>>where the NaN do *not* occur internally. How can I automatically get
>>>>rid of them and adjust the start and end year of the time series
>>>>accordingly?
>>>>Many thanks
>>>>
>>>>Lorenzo
>>>>
>>>>______________________________________________
>>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide 
>>>>http://www.R-project.org/posting-guide.html
>>>>and provide commented, minimal, self-contained, reproducible code.
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide 
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>


From hhoeflin at gmail.com  Fri May 27 15:07:40 2016
From: hhoeflin at gmail.com (Holger Hoefling)
Date: Fri, 27 May 2016 15:07:40 +0200
Subject: [R] Package index.html pages in repository
Message-ID: <CAFDswJs8A_0SUY7kfjLZZxStvyT-dAbS3srE6Df2yQaQ=yReEg@mail.gmail.com>

Hi,

I am hosting a small repository (of partly non-public repositories) and was
wondering if it is possible to create the package-index page on CRAN (e.g.
here for drat https://cran.rstudio.com/web/packages/drat/drat.pdf)

automatically somehow out of an existing repo (i.e. create the package from
the descriptions, extract the manual, extract the vignette, link them etc.).

Thanks!

Holger

	[[alternative HTML version deleted]]


From chalabi.elahe at yahoo.de  Fri May 27 15:08:07 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Fri, 27 May 2016 13:08:07 +0000 (UTC)
Subject: [R] add value to Bar chart ggplot2
References: <1350119254.568749.1464354487609.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1350119254.568749.1464354487609.JavaMail.yahoo@mail.yahoo.com>


Hi all ,
I have the following bar chart and I want to add SLC variable values to the charts but I don't know how to use geom_text:
 
 
    ggplot(df,(Protocol,fill=quant))+geom_bar()+coord_flip()
 
Thanks for any help!
Elahe


From ulrik.stervbo at gmail.com  Fri May 27 15:22:39 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 27 May 2016 13:22:39 +0000
Subject: [R] add value to Bar chart ggplot2
In-Reply-To: <1350119254.568749.1464354487609.JavaMail.yahoo@mail.yahoo.com>
References: <1350119254.568749.1464354487609.JavaMail.yahoo.ref@mail.yahoo.com>
	<1350119254.568749.1464354487609.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAKVAULOsE=XtPaf0r2uaQZw=AUHBshbmsxx2aKv2zirmUX8U9Q@mail.gmail.com>

Hi Elahe,

maybe this will help:
http://stackoverflow.com/questions/6455088/how-to-put-labels-over-geom-bar-in-r-with-ggplot2
or this:
http://stackoverflow.com/questions/12018499/how-to-put-labels-over-geom-bar-for-each-bar-in-r-with-ggplot2

Best,
Ulrik

On Fri, 27 May 2016 at 15:12 ch.elahe via R-help <r-help at r-project.org>
wrote:

>
> Hi all ,
> I have the following bar chart and I want to add SLC variable values to
> the charts but I don't know how to use geom_text:
>
>
>     ggplot(df,(Protocol,fill=quant))+geom_bar()+coord_flip()
>
> Thanks for any help!
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Fri May 27 15:52:35 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 27 May 2016 08:52:35 -0500
Subject: [R] Quantmod - modify decimal places
In-Reply-To: <CA+r16mzPRiqkAHhaJ1JGPAeHcwLAc=acK7RFvDKstdfQ4uZ4PA@mail.gmail.com>
References: <CA+r16mzPRiqkAHhaJ1JGPAeHcwLAc=acK7RFvDKstdfQ4uZ4PA@mail.gmail.com>
Message-ID: <CAPPM_gSmhuPM9zPtiq5qdxoah3zotzfTQ2aCv59pd6a9D2PSew@mail.gmail.com>

On Mon, May 23, 2016 at 8:57 PM, David Menezes
<david.n.menezes at gmail.com> wrote:
> Hi
>
> Apologies if this has already been asked and answered or if I've labelled
> the subject incorrectly but I can't find a solution using the search
> function for this group; the vignette documentation for quantmod or general
> google searches.
>
> I'm attempting to use quantmod to download foreign currency exchange
> rates.  I'm using the call "getFX" however the output results are always
> restricted to 4 decimal places.  Generally this is fine but when comparing
> developing and mature economies this can lead to no answer being returned
> due to how weak a specific currency is (in relative terms).
>
> For example, compare the following two results for converting USD to
> Vietnamese Dong (VND):
>
> a)      *1/getFX("USD/VND",from="2016-05-22",to ="2016-05-22", source =
> "oanda", auto.assign=FALSE)*
>
>  This yields?
>
>                 USD.VND
>
> 2016-05-22 4.473272e-05
>
>  However my preferred call would be:
>
>  b)*      getFX("VND/USD",from="2016-05-22",to ="2016-05-22", source =
> "oanda", auto.assign=FALSE)*
>
>  However this yields a zero result:
>
> VND.USD
>
> 2016-05-22       0
>
>
> which is clearly wrong.
>
That's the data Oanda provides via the URL quantmod::getSymbols.oanda
uses. Look for yourself:

http://www.oanda.com/currency/historical-rates/download?quote_currency=VND&end_date=2016-05-22&start_date=2016-05-22&period=daily&display=absolute&rate=0&data_range=d7&price=mid&view=table&base_currency_0=USD&base_currency_1=&base_currency_2=&base_currency_3=&base_currency_4=&download=csv

>
> I've tried various things including trying to invoke options (digits = 10)
> at the start of the script, and even within the getFX wrapper as an extra
> argument, but it doesn't work.  I can of course run select cross currency
> rates and invert the results, but that is pretty awkward and it feels like
> there ought to be a smarter and simpler solution.
>
In case it's not clear from what I said above, there's nothing you can
do to fix this after you've retrieved the data.  You need a more
accurate data source.

> Any help greatly appreciated.
>
> Thanks
> Dave
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2016 | www.rinfinance.com


From andrew_perrin at unc.edu  Thu May 26 23:00:26 2016
From: andrew_perrin at unc.edu (Andrew Perrin)
Date: Thu, 26 May 2016 17:00:26 -0400
Subject: [R] Sample selection using multiple logit or similar
Message-ID: <5626172f-21f2-4298-228b-fc740c4441d7@unc.edu>

Greetings-

I am seeking to fit a model using Heckman-style selection; however the 
wrinkle is that the selection is into multiple categories, not a binary 
in/out. In this case, selection is into the type of higher-education 
institution a student attended; the goal is to estimate post-graduation 
outcomes while correcting for selection into universities.

There is an old Stata file, svyselmlog, that may or may not solve this 
problem in stata. Any guidance or pointers toward solving it in R would 
be most welcome.

Thanks-
Andy Perrin

-- 
-----------------------------------------------------------------
Andrew J Perrin - Professor of Sociology, UNC-Chapel Hill
Director, Carolina Seminars       http://carolinaseminars.unc.edu
Special Assistant to the Provost and Dean for Accreditation
     and Curricular Innovation
andrew_perrin at unc.edu             http://perrin.socsci.unc.edu


From fradarola at hotmail.com  Fri May 27 04:51:21 2016
From: fradarola at hotmail.com (Franco Danilo Roca Landaveri)
Date: Thu, 26 May 2016 21:51:21 -0500
Subject: [R] Fitting quantile (or cdf?) function to data with specified
 percentiles
Message-ID: <COL125-W15DB9E7C88C717CDDF5B0AF420@phx.gbl>

Hello,

I hope you can help me. In class, we were given an Excel worksheet with specified formulas that take the total score from a survey (or from a specific section) and convert it to a percentage, according to a table that assigns scores to a percentile. Since the formulas are too long and complicated (some have been input by hand) I figured we could fit the data with a function with some parameters. I plotted the table and sure it resembled a more-or-less symmetrical quantile function, and I wanted to use R to find a curve that fittted the data. Here it is:

percentile <- c(0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.05, 0.05, 0.05,
0.05, 0.05, 0.10, 0.10, 0.15, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50,
0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.90, 0.95, 0.95, 0.99, 0.99, 0.99, 0.99,
0.99, 0.99, 0.99, 0.99, 0.99)

score <- c(10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,
25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44,
45, 46, 47, 48, 49, 50)

I looked up the quantreg package, but I didn't know how to use it properly since I don't have the raw data, only the percentiles, and also because what I'm trying to get is the percentile based on the score, not the other way around. Then I tried to fit it using a sigmoid curve (similar to a cdf), using the following code:

require(drc)
model1 <- drm(percentile ~ score, fct = LL.4())
summary(model1)

But I found another problem, the fitted curve apparently went over 1 on the y axis, something not possible for a cdf. I'd like to know what would be the most appropiate way to do this, and also if it is possible to fit a quantile function with this data, apart from the cdf.

Thank you very much for your help
 		 	   		  

From petr.pikal at precheza.cz  Fri May 27 12:55:39 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 27 May 2016 10:55:39 +0000
Subject: [R] Getting Rid of NaN in ts Object
In-Reply-To: <CA+8X3fXDkJ8RdQbFwn92FivA5Q4JanXSzuV4r0_ZpJps5aPwYg@mail.gmail.com>
References: <20160527101432.GA3282@localhost.localdomain>
	<CA+8X3fXDkJ8RdQbFwn92FivA5Q4JanXSzuV4r0_ZpJps5aPwYg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C502C5F6@SRVEXCHMBX.precheza.cz>

Hm

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
> Sent: Friday, May 27, 2016 12:46 PM
> To: Lorenzo Isella <lorenzo.isella at gmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] Getting Rid of NaN in ts Object
>
> Hi Lorenzo,
> Maybe:
>
> tt<-tt[!is.nan(tt)]

This gives you tt object as numeric vector. If you want to retain ts properties you can use window, but in this case you have to know in which year you want to start

e.g.
tt <- window(tt, 1998, 2015)

Regards
Petr


>
> Jim
>
>
> On Fri, May 27, 2016 at 8:14 PM, Lorenzo Isella <lorenzo.isella at gmail.com>
> wrote:
> > Dear All,
> > I am sure the answer is a one liner, but I am banging my head against
> > the wall and googling here and there has not helped much.
> > Consider the following time series
> >
> > tt<-structure(c(NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,
> NaN,
> > NaN, NaN, NaN, NaN, NaN, NaN, NaN, 1133.09, 1155.77, 1179.12, 1182.85,
> > 1133.43, 1103.36, 1081.19, 1058.55, 1056.95, 1059.13, 1018.18, 920.62,
> > 865.99, 856.29, 841.58, 857.7, 852.71, 890.76 ), .Tsp = c(1980, 2015,
> > 1), class = "ts")
> >
> >
> > where the NaN do *not* occur internally. How can I automatically get
> > rid of them and adjust the start and end year of the time series
> > accordingly?
> > Many thanks
> >
> > Lorenzo
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From chalabi.elahe at yahoo.de  Fri May 27 16:41:25 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Fri, 27 May 2016 14:41:25 +0000 (UTC)
Subject: [R] add value to Bar chart ggplot2
In-Reply-To: <CAKVAULOsE=XtPaf0r2uaQZw=AUHBshbmsxx2aKv2zirmUX8U9Q@mail.gmail.com>
References: <1350119254.568749.1464354487609.JavaMail.yahoo.ref@mail.yahoo.com>
	<1350119254.568749.1464354487609.JavaMail.yahoo@mail.yahoo.com>
	<CAKVAULOsE=XtPaf0r2uaQZw=AUHBshbmsxx2aKv2zirmUX8U9Q@mail.gmail.com>
Message-ID: <614504854.662668.1464360085704.JavaMail.yahoo@mail.yahoo.com>

Thanks Ulrik,
But in these examples they want to mark the percentage or frequency of plot variables, in my case I want to mark the bars with a different variable of my df. DO you have any idea?



On Friday, May 27, 2016 3:22 PM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:



Hi Elahe,

maybe this will help: http://stackoverflow.com/questions/6455088/how-to-put-labels-over-geom-bar-in-r-with-ggplot2 or this: http://stackoverflow.com/questions/12018499/how-to-put-labels-over-geom-bar-for-each-bar-in-r-with-ggplot2

Best,
Ulrik


On Fri, 27 May 2016 at 15:12 ch.elahe via R-help <r-help at r-project.org> wrote:


>Hi all ,
>I have the following bar chart and I want to add SLC variable values to the charts but I don't know how to use geom_text:
>
>
>    ggplot(df,(Protocol,fill=quant))+geom_bar()+coord_flip()
>
>Thanks for any help!
>Elahe
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.ca.us  Fri May 27 16:58:02 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 27 May 2016 07:58:02 -0700
Subject: [R] add value to Bar chart ggplot2
In-Reply-To: <614504854.662668.1464360085704.JavaMail.yahoo@mail.yahoo.com>
References: <1350119254.568749.1464354487609.JavaMail.yahoo.ref@mail.yahoo.com>
	<1350119254.568749.1464354487609.JavaMail.yahoo@mail.yahoo.com>
	<CAKVAULOsE=XtPaf0r2uaQZw=AUHBshbmsxx2aKv2zirmUX8U9Q@mail.gmail.com>
	<614504854.662668.1464360085704.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <DAC3735C-F313-472E-AD03-EAF637713716@dcn.davis.ca.us>

I think you need to read those questions again more carefully... particularly the second one. 
-- 
Sent from my phone. Please excuse my brevity.

On May 27, 2016 7:41:25 AM PDT, "ch.elahe via R-help" <r-help at r-project.org> wrote:
>Thanks Ulrik,
>But in these examples they want to mark the percentage or frequency of
>plot variables, in my case I want to mark the bars with a different
>variable of my df. DO you have any idea?
>
>
>
>On Friday, May 27, 2016 3:22 PM, Ulrik Stervbo
><ulrik.stervbo at gmail.com> wrote:
>
>
>
>Hi Elahe,
>
>maybe this will help:
>http://stackoverflow.com/questions/6455088/how-to-put-labels-over-geom-bar-in-r-with-ggplot2
>or this:
>http://stackoverflow.com/questions/12018499/how-to-put-labels-over-geom-bar-for-each-bar-in-r-with-ggplot2
>
>Best,
>Ulrik
>
>
>On Fri, 27 May 2016 at 15:12 ch.elahe via R-help <r-help at r-project.org>
>wrote:
>
>
>>Hi all ,
>>I have the following bar chart and I want to add SLC variable values
>to the charts but I don't know how to use geom_text:
>>
>>
>>    ggplot(df,(Protocol,fill=quant))+geom_bar()+coord_flip()
>>
>>Thanks for any help!
>>Elahe
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Fri May 27 17:07:33 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 27 May 2016 15:07:33 +0000
Subject: [R] add value to Bar chart ggplot2
In-Reply-To: <DAC3735C-F313-472E-AD03-EAF637713716@dcn.davis.ca.us>
References: <1350119254.568749.1464354487609.JavaMail.yahoo.ref@mail.yahoo.com>
	<1350119254.568749.1464354487609.JavaMail.yahoo@mail.yahoo.com>
	<CAKVAULOsE=XtPaf0r2uaQZw=AUHBshbmsxx2aKv2zirmUX8U9Q@mail.gmail.com>
	<614504854.662668.1464360085704.JavaMail.yahoo@mail.yahoo.com>
	<DAC3735C-F313-472E-AD03-EAF637713716@dcn.davis.ca.us>
Message-ID: <CAKVAULNd1f_woahVGCfKx1FtH=7irGDBCicTZzpDnCiWOP-CLA@mail.gmail.com>

Hi Elahe,

Based on this and your other questions I think you could benefit from
spending time with tutorials on ggplot and on R in general.

Google should give you plenty and I quickly found this:
http://www.ats.ucla.edu/stat/r/ and this:
https://www.nceas.ucsb.edu/files/scicomp/Dloads/RProgramming/BestFirstRTutorial.pdf
R tutorial but others might suit your needs. For the ggplot tutorial I came
across http://tutorials.iq.harvard.edu/R/Rgraphics/Rgraphics.html and
http://www.r-bloggers.com/basic-introduction-to-ggplot2/

I have only skimmed the linked pages and it looks like a good starting
point.

Hope this helps
Ulrik



On Fri, 27 May 2016 at 16:58 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> I think you need to read those questions again more carefully...
> particularly the second one.
> --
> Sent from my phone. Please excuse my brevity.
>
> On May 27, 2016 7:41:25 AM PDT, "ch.elahe via R-help" <
> r-help at r-project.org> wrote:
>
>> Thanks Ulrik,
>> But in these examples they want to mark the percentage or frequency of plot variables, in my case I want to mark the bars with a different variable of my df. DO you have any idea?
>>
>>
>>
>> On Friday, May 27, 2016 3:22 PM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
>>
>>
>>
>> Hi Elahe,
>>
>> maybe this will help: http://stackoverflow.com/questions/6455088/how-to-put-labels-over-geom-bar-in-r-with-ggplot2 or this: http://stackoverflow.com/questions/12018499/how-to-put-labels-over-geom-bar-for-each-bar-in-r-with-ggplot2
>>
>> Best,
>> Ulrik
>>
>>
>> On Fri, 27 May 2016 at 15:12 ch.elahe via R-help <r-help at r-project.org> wrote:
>>
>>
>> Hi all ,
>>> I have the following bar chart and I want to add SLC variable values to the charts but I don't know how to use geom_text:
>>>
>>>
>>>     ggplot(df,(Protocol,fill=quant))+geom_bar()+coord_flip()
>>>
>>> Thanks for any help!
>>> Elahe
>>>
>>> ------------------------------
>>>
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> ------------------------------
>>
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE
>> do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From jun.shen.ut at gmail.com  Fri May 27 17:10:57 2016
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Fri, 27 May 2016 11:10:57 -0400
Subject: [R] How to replace all commas with semicolon in a string
Message-ID: <CAMCXXmq2xGj=AiaFs3M1ABnN3Dg9r53XgbaZuPG=XuaaBv37fw@mail.gmail.com>

Dear list,

Say I have a data frame

test <- data.frame(C1=c('a,b,c,d'),C2=c('g,h,f'))

I want to replace the commas with semicolons

sub(',',';',test$C1) -> test$C1 will only replace the first comma of a string.

How do I replace them all in one run? Thanks.

Jun

	[[alternative HTML version deleted]]


From bob at rudis.net  Fri May 27 17:13:18 2016
From: bob at rudis.net (boB Rudis)
Date: Fri, 27 May 2016 11:13:18 -0400
Subject: [R] How to replace all commas with semicolon in a string
In-Reply-To: <CAMCXXmq2xGj=AiaFs3M1ABnN3Dg9r53XgbaZuPG=XuaaBv37fw@mail.gmail.com>
References: <CAMCXXmq2xGj=AiaFs3M1ABnN3Dg9r53XgbaZuPG=XuaaBv37fw@mail.gmail.com>
Message-ID: <CAJ4QxaPCDpSA+TVy8kbDG_oNjKbbSfPP6p4sS4iTMRAA-1UHaQ@mail.gmail.com>

You can use gsub() instead of sub()

On Fri, May 27, 2016 at 11:10 AM, Jun Shen <jun.shen.ut at gmail.com> wrote:
> Dear list,
>
> Say I have a data frame
>
> test <- data.frame(C1=c('a,b,c,d'),C2=c('g,h,f'))
>
> I want to replace the commas with semicolons
>
> sub(',',';',test$C1) -> test$C1 will only replace the first comma of a string.
>
> How do I replace them all in one run? Thanks.
>
> Jun
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ulrik.stervbo at gmail.com  Fri May 27 17:14:15 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 27 May 2016 15:14:15 +0000
Subject: [R] How to replace all commas with semicolon in a string
In-Reply-To: <CAMCXXmq2xGj=AiaFs3M1ABnN3Dg9r53XgbaZuPG=XuaaBv37fw@mail.gmail.com>
References: <CAMCXXmq2xGj=AiaFs3M1ABnN3Dg9r53XgbaZuPG=XuaaBv37fw@mail.gmail.com>
Message-ID: <CAKVAULMatJck=Fxyf8PVaeyJOKdTu18CFxeMmiCndzct35shdg@mail.gmail.com>

use gsub()

On Fri, 27 May 2016 at 17:12 Jun Shen <jun.shen.ut at gmail.com> wrote:

> Dear list,
>
> Say I have a data frame
>
> test <- data.frame(C1=c('a,b,c,d'),C2=c('g,h,f'))
>
> I want to replace the commas with semicolons
>
> sub(',',';',test$C1) -> test$C1 will only replace the first comma of a
> string.
>
> How do I replace them all in one run? Thanks.
>
> Jun
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jun.shen.ut at gmail.com  Fri May 27 17:21:22 2016
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Fri, 27 May 2016 11:21:22 -0400
Subject: [R] How to replace all commas with semicolon in a string
In-Reply-To: <CAKVAULMatJck=Fxyf8PVaeyJOKdTu18CFxeMmiCndzct35shdg@mail.gmail.com>
References: <CAMCXXmq2xGj=AiaFs3M1ABnN3Dg9r53XgbaZuPG=XuaaBv37fw@mail.gmail.com>
	<CAKVAULMatJck=Fxyf8PVaeyJOKdTu18CFxeMmiCndzct35shdg@mail.gmail.com>
Message-ID: <CAMCXXmoRpF9kG=NBvNHayrb+dwFOw1vfEJBrEV3Yw61L5UeL_Q@mail.gmail.com>

Thanks Ulrik and Bob for your reply.

gsub worked for one column!

If I want to replace the whole data frame, gsub doesn't seem to work. Any
idea

On Fri, May 27, 2016 at 11:14 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
wrote:

> use gsub()
>
> On Fri, 27 May 2016 at 17:12 Jun Shen <jun.shen.ut at gmail.com> wrote:
>
>> Dear list,
>>
>> Say I have a data frame
>>
>> test <- data.frame(C1=c('a,b,c,d'),C2=c('g,h,f'))
>>
>> I want to replace the commas with semicolons
>>
>> sub(',',';',test$C1) -> test$C1 will only replace the first comma of a
>> string.
>>
>> How do I replace them all in one run? Thanks.
>>
>> Jun
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Fri May 27 17:36:06 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 27 May 2016 15:36:06 +0000
Subject: [R] How to replace all commas with semicolon in a string
In-Reply-To: <CAMCXXmoRpF9kG=NBvNHayrb+dwFOw1vfEJBrEV3Yw61L5UeL_Q@mail.gmail.com>
References: <CAMCXXmq2xGj=AiaFs3M1ABnN3Dg9r53XgbaZuPG=XuaaBv37fw@mail.gmail.com>
	<CAKVAULMatJck=Fxyf8PVaeyJOKdTu18CFxeMmiCndzct35shdg@mail.gmail.com>
	<CAMCXXmoRpF9kG=NBvNHayrb+dwFOw1vfEJBrEV3Yw61L5UeL_Q@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D734AB9@mb02.ads.tamu.edu>

> sapply(test, gsub, pattern=",", replacement=";")
       C1        C2 
"a;b;c;d"   "g;h;f" 

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jun Shen
Sent: Friday, May 27, 2016 10:21 AM
To: Ulrik Stervbo
Cc: R-help
Subject: Re: [R] How to replace all commas with semicolon in a string

Thanks Ulrik and Bob for your reply.

gsub worked for one column!

If I want to replace the whole data frame, gsub doesn't seem to work. Any
idea

On Fri, May 27, 2016 at 11:14 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
wrote:

> use gsub()
>
> On Fri, 27 May 2016 at 17:12 Jun Shen <jun.shen.ut at gmail.com> wrote:
>
>> Dear list,
>>
>> Say I have a data frame
>>
>> test <- data.frame(C1=c('a,b,c,d'),C2=c('g,h,f'))
>>
>> I want to replace the commas with semicolons
>>
>> sub(',',';',test$C1) -> test$C1 will only replace the first comma of a
>> string.
>>
>> How do I replace them all in one run? Thanks.
>>
>> Jun
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ulrik.stervbo at gmail.com  Fri May 27 17:39:28 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 27 May 2016 15:39:28 +0000
Subject: [R] How to replace all commas with semicolon in a string
In-Reply-To: <CAMCXXmoRpF9kG=NBvNHayrb+dwFOw1vfEJBrEV3Yw61L5UeL_Q@mail.gmail.com>
References: <CAMCXXmq2xGj=AiaFs3M1ABnN3Dg9r53XgbaZuPG=XuaaBv37fw@mail.gmail.com>
	<CAKVAULMatJck=Fxyf8PVaeyJOKdTu18CFxeMmiCndzct35shdg@mail.gmail.com>
	<CAMCXXmoRpF9kG=NBvNHayrb+dwFOw1vfEJBrEV3Yw61L5UeL_Q@mail.gmail.com>
Message-ID: <CAKVAULOeRT0athGYrAkuZm4Ff8g0ZOuiDR4t1zsMcb7pF=iGjg@mail.gmail.com>

If your data.frame is a mix you can loop over each column - along the lines
of:

library(plyr)

adply(test, 2, function(x){
if(!is.numeric(x[[1]]){
gsub(",", ";", x[[1]])
}else{
x[[1]]
}
})

Ulrik

On Fri, 27 May 2016 at 17:21 Jun Shen <jun.shen.ut at gmail.com> wrote:

> Thanks Ulrik and Bob for your reply.
>
> gsub worked for one column!
>
> If I want to replace the whole data frame, gsub doesn't seem to work. Any
> idea
>
> On Fri, May 27, 2016 at 11:14 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
> wrote:
>
>> use gsub()
>>
>> On Fri, 27 May 2016 at 17:12 Jun Shen <jun.shen.ut at gmail.com> wrote:
>>
>>> Dear list,
>>>
>>> Say I have a data frame
>>>
>>> test <- data.frame(C1=c('a,b,c,d'),C2=c('g,h,f'))
>>>
>>> I want to replace the commas with semicolons
>>>
>>> sub(',',';',test$C1) -> test$C1 will only replace the first comma of a
>>> string.
>>>
>>> How do I replace them all in one run? Thanks.
>>>
>>> Jun
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri May 27 17:49:57 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 27 May 2016 08:49:57 -0700
Subject: [R] subset data right
In-Reply-To: <1A8C1289955EF649A09086A153E2672403E14A94D2@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <927632887.2224306.1464291352800.JavaMail.yahoo.ref@mail.yahoo.com>
	<927632887.2224306.1464291352800.JavaMail.yahoo@mail.yahoo.com>
	<CAF8bMcZ+QfavNVdpTJ+29XAbRbEQ1ExN0CKJqNKhJKD96t3aKQ@mail.gmail.com>
	<1A8C1289955EF649A09086A153E2672403E14A94D2@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <CAF8bMcbYtaKXNxGdm240+4xBhAhxVW42OCNyszV+nkaGUqd=MA@mail.gmail.com>

>If you want to drop levels, use droplevels() either on the factor or on
the >subset of your data frame. Example:
>droplevels(f[1]) #One element, only one level

Calling factor() on a factor, as the OP did, also drops any unused levels,
as the examples showed.

> str(factor(factor(letters)[11:13]))
 Factor w/ 3 levels "k","l","m": 1 2 3
> str(droplevels(factor(letters)[11:13]))
 Factor w/ 3 levels "k","l","m": 1 2 3

Using droplevels instead of factor does make the intent clearer and
droplevels works on data.frames.





Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, May 27, 2016 at 3:37 AM, S Ellison <S.Ellison at lgcgroup.com> wrote:

> > You did not change df$quant - you made a new object called 'subdf'
> > containing a column called 'quant' that had only one level.  Changing
> subdf has
> > no effect on df.
>
> Also, subsetting a factor _intentionally_ does not change the number of
> levels. Example:
> f <- factor(sample(letters[1:3], 30, replace=TRUE))
> f[1]  #One element, still three levels
>
> If you want to drop levels, use droplevels() either on the factor or on
> the subset of your data frame. Example:
> droplevels(f[1]) #One element, only one level
>
>
> Also worth noting that df is a function.
>  > df <- data.frame(quant=factor(letters))
> looks very like you're assigning a data frame to the function 'df'
> (density for the F distribution)
> It doesn't, because R is clever. But it's really not good practice to use
> common function names as variable names. Too much potential for confusion.
>
> S Ellison
>
>
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:13}}


From vito.muggeo at unipa.it  Fri May 27 17:54:39 2016
From: vito.muggeo at unipa.it (Vito Michele Rosario Muggeo)
Date: Fri, 27 May 2016 17:54:39 +0200
Subject: [R] Fitting quantile (or cdf?) function to data with specified
 percentiles
In-Reply-To: <COL125-W15DB9E7C88C717CDDF5B0AF420@phx.gbl>
References: <COL125-W15DB9E7C88C717CDDF5B0AF420@phx.gbl>
Message-ID: <20160527175439.Horde.4hyYqN2RwKA4ZGUpg_pqvA2@webmail.unipa.it>

A possible (simple) solution is to use a binomial GLM which guarantees  
fitted values (percentiles) in (0,1):

plot(percentile, score)
o<-glm(percentile~sc, family=binomial)
points(fitted(o), sc, col=2)

You can "predict" percentiles given score via predict.glm()
best,
vito


Franco Danilo Roca Landaveri <fradarola at hotmail.com> ha scritto:

> Hello,
>
> I hope you can help me. In class, we were given an Excel worksheet  
> with specified formulas that take the total score from a survey (or  
> from a specific section) and convert it to a percentage, according  
> to a table that assigns scores to a percentile. Since the formulas  
> are too long and complicated (some have been input by hand) I  
> figured we could fit the data with a function with some parameters.  
> I plotted the table and sure it resembled a more-or-less symmetrical  
> quantile function, and I wanted to use R to find a curve that  
> fittted the data. Here it is:
>
> percentile <- c(0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.05, 0.05, 0.05,
> 0.05, 0.05, 0.10, 0.10, 0.15, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50,
> 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.90, 0.95, 0.95, 0.99, 0.99, 0.99, 0.99,
> 0.99, 0.99, 0.99, 0.99, 0.99)
>
> score <- c(10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,
> 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,  
> 42, 43, 44,
> 45, 46, 47, 48, 49, 50)
>
> I looked up the quantreg package, but I didn't know how to use it  
> properly since I don't have the raw data, only the percentiles, and  
> also because what I'm trying to get is the percentile based on the  
> score, not the other way around. Then I tried to fit it using a  
> sigmoid curve (similar to a cdf), using the following code:
>
> require(drc)
> model1 <- drm(percentile ~ score, fct = LL.4())
> summary(model1)
>
> But I found another problem, the fitted curve apparently went over 1  
> on the y axis, something not possible for a cdf. I'd like to know  
> what would be the most appropiate way to do this, and also if it is  
> possible to fit a quantile function with this data, apart from the  
> cdf.
>
> Thank you very much for your help
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jfhenson1 at gmail.com  Fri May 27 19:07:33 2016
From: jfhenson1 at gmail.com (James Henson)
Date: Fri, 27 May 2016 12:07:33 -0500
Subject: [R] mixed models
In-Reply-To: <DD212DC3-B1A3-4C9B-BD8F-40DD7B3AC576@dcn.davis.ca.us>
References: <CABPq8JN974cVTJvRT-+hHigPERV+-uVzzNq6OCZuqpHB4q5xgw@mail.gmail.com>
	<CAA84D89-4A4D-43A4-8541-F0CF660EE0AF@dcn.davis.ca.us>
	<CABPq8JMMqC450qda2QW75j0amaXw4rG+u8ZCG33e-_ynP3YW0w@mail.gmail.com>
	<CABPq8JN26=NuKPj977n5wM_eMGU5Cv0A4Sxok4sZno3VJUVngA@mail.gmail.com>
	<DD212DC3-B1A3-4C9B-BD8F-40DD7B3AC576@dcn.davis.ca.us>
Message-ID: <CABPq8JOT85fQESy39FM88pB-sweJjZJqtx9Pt6=tU=gBN2eB3A@mail.gmail.com>

Greetings Jeff,
You are correct that the unequal number of levels is not the problem.
I revised the data frame so that the number of levels was equal and
the same error message occurred.  The code is below, and the
Eboni2.txt file is attached. This problem baffles me.  I appreciate
any help.
Best regards,
James
 Eboni2 <- read.csv("Eboni2.csv", header = TRUE)

library("nlme")

str(Eboni2)

head(Eboni2)

model1 <- lme(preDawn ~ Irrigation, random=~season_order|treeNo, data=Eboni2)

On Wed, May 25, 2016 at 6:23 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> Please keep the mailing list in the loop by using reply-all.
>
> I don't think there is a requirement that the number of levels is equal, but
> there may be problems if you don't have the minimum number of records
> corresponding to each combination of levels specified in your model.
>
> You can change the csv extension to txt and attach for the mailing list. Or,
> better yet, you can use the dput function to embed the data directly in your
> sample code.
>
> Also, please learn to post plain text email to avoid corruption of R code by
> the HTML formatting.
> --
> Sent from my phone. Please excuse my brevity.
>
> On May 25, 2016 2:26:54 PM PDT, James Henson <jfhenson1 at gmail.com> wrote:
>>
>> Good afternoon Jeff,
>> The sample sizes for levels of the factor "Irrigation" are not equal. If
>> 'nlme' requires equal sample sizes this may be the problem. The same data
>> frame runs in 'lme4' without a problem.
>>
>> Best regards,
>> James
>>
>>
>> On Wed, May 25, 2016 at 3:41 PM, James Henson <jfhenson1 at gmail.com> wrote:
>>>
>>> Good afternoon Jeff,
>>>
>>> When working with this data frame, I just open the .csv file in R Studio.
>>> But, we should not send .csv file to R_help.  What should I send?
>>>
>>> Best regards,
>>> James
>>>
>>> On Wed, May 25, 2016 at 2:52 PM, Jeff Newmiller
>>> <jdnewmil at dcn.davis.ca.us> wrote:
>>>>
>>>> You forgot to show the commands to us that you used to read the data in
>>>> with (your example is not "reproducible"). This step can make all the
>>>> difference in the world as to whether your analysis commands will work or
>>>> not.
>>>> --
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> On May 25, 2016 11:59:06 AM PDT, James Henson <jfhenson1 at gmail.com>
>>>> wrote:
>>>>>
>>>>> Greetings R community,
>>>>>
>>>>> My aim is to analyze a mixed-effects model with temporal
>>>>> pseudo-replication
>>>>> (repeated measures on the same experimental unit) using ?nlme?.
>>>>> However,
>>>>> my code returns the error message ?Error in na.fail.default?, even
>>>>> though
>>>>> the data frame does not contain missing values. My code is below, and
>>>>> the
>>>>> data file is attached as ?Eboni2.txt.
>>>>>
>>>>> library("nlme")
>>>>>
>>>>> str(Eboni2)
>>>>>
>>>>> head(Eboni2)
>>>>>
>>>>> model1 <- lme(preDawn ~ Irrigation, random=~season_order|treeNo,
>>>>> data=Eboni2)
>>>>>
>>>>> I am genuinely confused.  Hope someone can help.
>>>>>
>>>>> Best regards,
>>>>>
>>>>> James F. Henson
>>>>>
>>>>> ________________________________
>>>>>
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>


From syen04 at gmail.com  Fri May 27 19:56:32 2016
From: syen04 at gmail.com (Steven Yen)
Date: Fri, 27 May 2016 13:56:32 -0400
Subject: [R] read.fortran format
Message-ID: <8e33af64-a127-00d0-e38d-6cbb55bfdb10@gmail.com>

Dear fellow R users:
I am reading a data (ascii) file with fortran fixed format, containing 
multiple records. R does not recognize fortran's record break (a slash). 
I tried to do the following but it does not work. Help appreciated.

  60 FORMAT(1X,F6.0,5F8.6/1X,5F8.4,F10.6/1X,2F6.0,3E15.9,F8.0,F5.2,F5.3
      *      /1X,F7.0,2E15.9,F9.4,F5.3)

mydata<-read.fortran("G:/Journals/Disk1/12_restat_95/estimate/GROUPD.DAT",
         c("1X","F6.0","5F8.6"/"1X","5F8.4","F10.6"
          /"1X","2F6.0","3E15.9","F8.0","F5.2","F5.3"
          /"1X","F7.0","2E15.9","F9.4","F5.3"),
col.names=c("year","w1","w2","w3","w4","w5","w6","v1","v2","v3",
"v4","v5","v6","z","chyes","chno","ec","vc","cvc",
"pop","ahs","fah","tnh","eq","vq","ups","zm1 "))



	[[alternative HTML version deleted]]


From emorway at usgs.gov  Fri May 27 20:04:17 2016
From: emorway at usgs.gov (Morway, Eric)
Date: Fri, 27 May 2016 11:04:17 -0700
Subject: [R] Trimming time series to only include complete years
Message-ID: <CAPoqHzrZpb=S6GQRo0O0fszw06pW2_-HKe1MQ34emZANsDJeyQ@mail.gmail.com>

In bulk processing streamflow data available from an online database, I'm
wanting to trim the beginning and end of the time series so that daily data
associated with incomplete "water years" (defined as extending from Oct 1st
to the following September 30th) is trimmed off the beginning and end of
the series.

For a small reproducible example, the time series below starts on
2010-01-01 and ends on 2011-11-05.  So the data between 2010-01-01 and
2010-09-30 and also between 2011-10-01 and 2011-11-05 is not associated
with a complete set of data for their respective water years.  With the
real data, the initial date of collection is arbitrary, could be 1901 or
1938, etc.  Because I'm cycling through potentially thousands of records, I
need help in designing a function that is efficient.

dat <-
data.frame(Date=seq(as.Date("2010-01-01"),as.Date("2011-11-05"),by="day"))
dat$Q <- rnorm(nrow(dat))

dat$wyr <- as.numeric(format(dat$Date,"%Y"))
is.nxt <- as.numeric(format(dat$Date,"%m")) %in% 1:9
dat$wyr[!is.nxt] <- dat$wyr[!is.nxt] + 1


function(dat) {
   ...
   returns a subset of dat such that dat$Date > xxxx-09-30 & dat$Date <
yyyy-10-01
   ...
}

where the years between xxxx-yyyy are "complete" (no missing days).  In the
example above, the returned dat would extend from 2010-10-01 to 2011-09-30

Any offered guidance is very much appreciated.

	[[alternative HTML version deleted]]


From lid.zigh at gmail.com  Fri May 27 20:08:27 2016
From: lid.zigh at gmail.com (Lida Zeighami)
Date: Fri, 27 May 2016 13:08:27 -0500
Subject: [R] couldn't install pcalg package in R 3.1.3
Message-ID: <CAMqbV1BuGnUR-85yidmRqkMCXFPL4X+LjPGftZeNtN=-dM3Tgw@mail.gmail.com>

Hi Dears!

Would you please let me know how I can install package pcalg for R version
3.1.3 ?
I've tried different ways but got error!

Thanks inadvance!

	[[alternative HTML version deleted]]


From john.archie.mckown at gmail.com  Fri May 27 20:21:08 2016
From: john.archie.mckown at gmail.com (John McKown)
Date: Fri, 27 May 2016 13:21:08 -0500
Subject: [R] read.fortran format
In-Reply-To: <8e33af64-a127-00d0-e38d-6cbb55bfdb10@gmail.com>
References: <8e33af64-a127-00d0-e38d-6cbb55bfdb10@gmail.com>
Message-ID: <CAAJSdjgk_Fhb6yj5Y=whr7C4hUQqfJzxxn7AYmDQoc9_tt0KKA@mail.gmail.com>

On Fri, May 27, 2016 at 12:56 PM, Steven Yen <syen04 at gmail.com> wrote:

> Dear fellow R users:
> I am reading a data (ascii) file with fortran fixed format, containing
> multiple records. R does not recognize fortran's record break (a slash).
> I tried to do the following but it does not work. Help appreciated.
>
>   60 FORMAT(1X,F6.0,5F8.6/1X,5F8.4,F10.6/1X,2F6.0,3E15.9,F8.0,F5.2,F5.3
>       *      /1X,F7.0,2E15.9,F9.4,F5.3)
>
> mydata<-read.fortran("G:/Journals/Disk1/12_restat_95/estimate/GROUPD.DAT",
> ??
>          c("1X","F6.0","5F8.6"/"1X","5F8.4","F10.6"
>           /"1X","2F6.0","3E15.9","F8.0","F5.2","F5.3"
>           /"1X","F7.0","2E15.9","F9.4","F5.3"),
> ??
> col.names=c("year","w1","w2","w3","w4","w5","w6","v1","v2","v3",
> "v4","v5","v6","z","chyes","chno","ec","vc","cvc",
> "pop","ahs","fah","tnh","eq","vq","ups","zm1 "))
>

?Did you see this from ?read.fortran

<quote>

 For a single-line record, ?format? should be a character vector.
     For a multiline record it should be a list with a character vector
     for each line.

</quote>?


?I think (not sure) you need:

mydata<-read.frotran("G:/Journals/Disk1/12_restat_95/estimate/GROUPD.DAT",
list(c("1X","F6.0","5F8.6"),c("1X","5F8.4","F10.6"),c("1X","2F6.0","3E15.9","F8.0","F5.2","F5.3"),c("1X","F7.0","2E15.9","F9.4","F5.3")).
?
col.names=c("year","w1","w2","w3","w4","w5","w6","v1","v2","v3",
"v4","v5","v6","z","chyes","chno","ec","vc","cvc",
"pop","ahs","fah","tnh","eq","vq","ups","zm1 "))





-- 
The unfacts, did we have them, are too imprecisely few to warrant our
certitude.

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri May 27 20:34:09 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 27 May 2016 11:34:09 -0700
Subject: [R] couldn't install pcalg package in R 3.1.3
In-Reply-To: <CAMqbV1BuGnUR-85yidmRqkMCXFPL4X+LjPGftZeNtN=-dM3Tgw@mail.gmail.com>
References: <CAMqbV1BuGnUR-85yidmRqkMCXFPL4X+LjPGftZeNtN=-dM3Tgw@mail.gmail.com>
Message-ID: <B327041D-3706-4055-A2BD-6B7BA5DF46BE@dcn.davis.ca.us>

If you read the Posting Guide it warns you against posting in HTML (it doesn't say why but basically what you think you sent is not necessarily what we saw). It also mentions that you should update to the latest version of R (yours is not) if you want help (though we might try anyway). It also mentions that you need to post a reproducible example... what the heck did you do that did not work? 

install.packages( "pcalg" )

worked fine for me on Windows 7.

-- 
Sent from my phone. Please excuse my brevity.

On May 27, 2016 11:08:27 AM PDT, Lida Zeighami <lid.zigh at gmail.com> wrote:
>Hi Dears!
>
>Would you please let me know how I can install package pcalg for R
>version
>3.1.3 ?
>I've tried different ways but got error!
>
>Thanks inadvance!
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri May 27 20:49:55 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 27 May 2016 11:49:55 -0700
Subject: [R] mixed models
In-Reply-To: <CABPq8JOT85fQESy39FM88pB-sweJjZJqtx9Pt6=tU=gBN2eB3A@mail.gmail.com>
References: <CABPq8JN974cVTJvRT-+hHigPERV+-uVzzNq6OCZuqpHB4q5xgw@mail.gmail.com>
	<CAA84D89-4A4D-43A4-8541-F0CF660EE0AF@dcn.davis.ca.us>
	<CABPq8JMMqC450qda2QW75j0amaXw4rG+u8ZCG33e-_ynP3YW0w@mail.gmail.com>
	<CABPq8JN26=NuKPj977n5wM_eMGU5Cv0A4Sxok4sZno3VJUVngA@mail.gmail.com>
	<DD212DC3-B1A3-4C9B-BD8F-40DD7B3AC576@dcn.davis.ca.us>
	<CABPq8JOT85fQESy39FM88pB-sweJjZJqtx9Pt6=tU=gBN2eB3A@mail.gmail.com>
Message-ID: <18F3CE5C-C207-4922-94F6-DADA30379BC5@comcast.net>


> On May 27, 2016, at 10:07 AM, James Henson <jfhenson1 at gmail.com> wrote:
> 
> Greetings Jeff,
> You are correct that the unequal number of levels is not the problem.
> I revised the data frame so that the number of levels was equal and
> the same error message occurred.  The code is below, and the
> Eboni2.txt file is attached. This problem baffles me.  I appreciate
> any help.
> Best regards,
> James
> Eboni2 <- read.csv("Eboni2.csv", header = TRUE)
> 
> library("nlme")
> 
> str(Eboni2)
> 
> head(Eboni2)
> 
> model1 <- lme(preDawn ~ Irrigation, random=~season_order|treeNo, data=Eboni2)

I downloaded the attached file to your first posting that was called a "csv" file but it was tab-separated (as could be clearly seen with the str output, so would only load properly with read.delim rather than read.csv. Running then with the lme call, it produced this message

> model1 <- lme(preDawn ~ Irrigation, random=~season_order|treeNo, data=Eboni2)
Error in na.fail.default(list(season_order = c(5L, 5L, 5L, 5L, 5L, 5L,  : 
  missing values in object

And looking at the str result made it clear that there were many NA's in the file.

> head(Eboni2)
  number Location   Season season_order Month  treeID treeNo preDawn midday
1      1      UCC November            5   Nov UCCLO 1     60     1.4    1.3
2      2      UCC November            5   Nov UCCLO 2     72     1.2    1.3
3      3      UCC November            5   Nov UCCLO 3     78     1.1    1.2
4      4      UCC November            5   Nov UCCLO 4     79     1.1    2.1
5      5      UCC November            5   Nov UCCLO 5     80     1.4    1.3
6      6      UCC November            5   Nov UCCLO 6     81     0.6    1.8
  Irrigation Pnet        Gs        E      WUE d15N   d13C Nper  Cper include2
1          N    9 0.2907004 3.766207 2.389672   NA     NA   NA    NA       no
2          N   11 0.3262582 3.120574 3.524993   NA     NA   NA    NA       no
3          N    8 0.2870957 1.693821 4.723050 3.00 -27.44 2.12 52.12      yes
4          N   10 0.2475180 1.839343 5.436724 3.61 -29.50 1.42 51.97      yes
5          N   13 0.3009228 3.082278 4.217660   NA     NA   NA    NA       no
6          N   17 0.3487337 2.534550 6.707304 2.79 -30.50 1.49 49.94      yes

And even more importantly, there was one NA in your outcome variable:
> sum( is.na(Eboni2$Irrigation))
[1] 0
> sum( is.na(Eboni2$preDawn))
[1] 1

So after restricting to complete.cases, I then formed the hypothesis that you reversed the order of the variables in the formula for the random parameter:

> table(Eboni2$season_order)

 1  2  3  4  5 
83 83 83 83 83 
> length( Eboni2$treeNo)
[1] 415

So it seemed unreasonable to have a "grouping" on variable with only one item per group.

> model1 <- lme(preDawn ~ Irrigation, random=~treeNo|season_order, data=Eboni2[ complete.cases( Eboni2[ , c('preDawn','Irrigation','season_order','treeNo')]), ] )
> model1
Linear mixed-effects model fit by REML
  Data: Eboni2[complete.cases(Eboni2[, c("preDawn", "Irrigation", "season_order",      "treeNo")]), ] 
  Log-restricted-likelihood: -183.4708
  Fixed: preDawn ~ Irrigation 
(Intercept) IrrigationY 
 1.04520145 -0.06037706 

Random effects:
 Formula: ~treeNo | season_order
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev      Corr  
(Intercept) 0.140239324 (Intr)
treeNo      0.003766019 -0.725
Residual    0.365678898       

Number of Observations: 414
Number of Groups: 5 

(Warning, I'm not a frequent user of this package or any of the mixed effects packages.)



Just to correct some misinformation that appeared earlier: You can attach "csv" or "tsv" files as long as you name them with an .txt extension so the mail clients and servers consider them to be MIME-text.

-- 
David.


> On Wed, May 25, 2016 at 6:23 PM, Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> wrote:
>> Please keep the mailing list in the loop by using reply-all.
>> 
>> I don't think there is a requirement that the number of levels is equal, but
>> there may be problems if you don't have the minimum number of records
>> corresponding to each combination of levels specified in your model.
>> 
>> You can change the csv extension to txt and attach for the mailing list. Or,
>> better yet, you can use the dput function to embed the data directly in your
>> sample code.
>> 
>> Also, please learn to post plain text email to avoid corruption of R code by
>> the HTML formatting.
>> --
>> Sent from my phone. Please excuse my brevity.
>> 
>> On May 25, 2016 2:26:54 PM PDT, James Henson <jfhenson1 at gmail.com> wrote:
>>> 
>>> Good afternoon Jeff,
>>> The sample sizes for levels of the factor "Irrigation" are not equal. If
>>> 'nlme' requires equal sample sizes this may be the problem. The same data
>>> frame runs in 'lme4' without a problem.
>>> 
>>> Best regards,
>>> James
>>> 
>>> 
>>> On Wed, May 25, 2016 at 3:41 PM, James Henson <jfhenson1 at gmail.com> wrote:
>>>> 
>>>> Good afternoon Jeff,
>>>> 
>>>> When working with this data frame, I just open the .csv file in R Studio.
>>>> But, we should not send .csv file to R_help.  What should I send?
>>>> 
>>>> Best regards,
>>>> James
>>>> 
>>>> On Wed, May 25, 2016 at 2:52 PM, Jeff Newmiller
>>>> <jdnewmil at dcn.davis.ca.us> wrote:
>>>>> 
>>>>> You forgot to show the commands to us that you used to read the data in
>>>>> with (your example is not "reproducible"). This step can make all the
>>>>> difference in the world as to whether your analysis commands will work or
>>>>> not.
>>>>> --
>>>>> Sent from my phone. Please excuse my brevity.
>>>>> 
>>>>> On May 25, 2016 11:59:06 AM PDT, James Henson <jfhenson1 at gmail.com>
>>>>> wrote:
>>>>>> 
>>>>>> Greetings R community,
>>>>>> 
>>>>>> My aim is to analyze a mixed-effects model with temporal
>>>>>> pseudo-replication
>>>>>> (repeated measures on the same experimental unit) using ?nlme?.
>>>>>> However,
>>>>>> my code returns the error message ?Error in na.fail.default?, even
>>>>>> though
>>>>>> the data frame does not contain missing values. My code is below, and
>>>>>> the
>>>>>> data file is attached as ?Eboni2.txt.
>>>>>> 
>>>>>> library("nlme")
>>>>>> 
>>>>>> str(Eboni2)
>>>>>> 
>>>>>> head(Eboni2)
>>>>>> 
>>>>>> model1 <- lme(preDawn ~ Irrigation, random=~season_order|treeNo,
>>>>>> data=Eboni2)
>>>>>> 
>>>>>> I am genuinely confused.  Hope someone can help.
>>>>>> 
>>>>>> Best regards,
>>>>>> 
>>>>>> James F. Henson
>>>>>> 
>>>>>> ________________________________
>>>>>> 
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> 
>>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From fredgca at hotmail.com  Fri May 27 20:38:10 2016
From: fredgca at hotmail.com (Frederico Arnoldi)
Date: Fri, 27 May 2016 18:38:10 +0000
Subject: [R] performance of svm (e1071) on windows 64 bits vs 32 bits
Message-ID: <BAY178-W23EF4CFCD6FA5340BFB44ABF420@phx.gbl>

Dear R users,
I?ve been using SVM (e1071) on different 64 bits linux distributions very successfully. 
Very recently I had to migrate some of our codes to a server with xeon e7 processors, 65 gb of RAM, running Windows. Very surprisingly, the peformance of the same code, in the same server, on R 32 bits was much better than on R 64 bits (~5 times).   I confirmed these results in another windows machine, now a notebook, to exclude the possibility of a problem specific to that server.
In both cases, R 32 bits is using more RAM memory (~900 mb) than 64 bits (~600 mb). Changing cache size of SVM doesn?t impact it.
As I need to use de 64 bits version, I went to internet looking for ways of improving the perfomance of 64 bits version. Reading about possible causes, I arrived to Blas and Lapack issues. I have tried different pre-compiled Rblas.dll available on the internet, including SurviveGotoBLAS-3.14. Also, I tried to use R from Revolution Analytics (Revolution R Open) that has a optimized Blas (Intel MKL) , without any visible.
Could you give any help or share similar experience with this issue? 
Thank you very much for your help.
Frederico Arnoldi

 		 	   		  
	[[alternative HTML version deleted]]


From david.n.menezes at gmail.com  Fri May 27 16:13:27 2016
From: david.n.menezes at gmail.com (David Menezes)
Date: Fri, 27 May 2016 22:13:27 +0800
Subject: [R] Quantmod - modify decimal places
In-Reply-To: <CAPPM_gSmhuPM9zPtiq5qdxoah3zotzfTQ2aCv59pd6a9D2PSew@mail.gmail.com>
References: <CA+r16mzPRiqkAHhaJ1JGPAeHcwLAc=acK7RFvDKstdfQ4uZ4PA@mail.gmail.com>
	<CAPPM_gSmhuPM9zPtiq5qdxoah3zotzfTQ2aCv59pd6a9D2PSew@mail.gmail.com>
Message-ID: <CD784F6F-4FFB-42D0-AE5B-F5B6580F89E9@gmail.com>

Hi Josh 

Thanks a lot - appreciate the answer. Figured it may have worked that way but investigating the url called by the package was a smart move. Guess I'll need to get the info from Bloomberg!

Thanks again
David


Sent from my iPhone

> On 27 May 2016, at 9:52 PM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
> 
> On Mon, May 23, 2016 at 8:57 PM, David Menezes
> <david.n.menezes at gmail.com> wrote:
>> Hi
>> 
>> Apologies if this has already been asked and answered or if I've labelled
>> the subject incorrectly but I can't find a solution using the search
>> function for this group; the vignette documentation for quantmod or general
>> google searches.
>> 
>> I'm attempting to use quantmod to download foreign currency exchange
>> rates.  I'm using the call "getFX" however the output results are always
>> restricted to 4 decimal places.  Generally this is fine but when comparing
>> developing and mature economies this can lead to no answer being returned
>> due to how weak a specific currency is (in relative terms).
>> 
>> For example, compare the following two results for converting USD to
>> Vietnamese Dong (VND):
>> 
>> a)      *1/getFX("USD/VND",from="2016-05-22",to ="2016-05-22", source =
>> "oanda", auto.assign=FALSE)*
>> 
>> This yields?
>> 
>>                USD.VND
>> 
>> 2016-05-22 4.473272e-05
>> 
>> However my preferred call would be:
>> 
>> b)*      getFX("VND/USD",from="2016-05-22",to ="2016-05-22", source =
>> "oanda", auto.assign=FALSE)*
>> 
>> However this yields a zero result:
>> 
>> VND.USD
>> 
>> 2016-05-22       0
>> 
>> 
>> which is clearly wrong.
> That's the data Oanda provides via the URL quantmod::getSymbols.oanda
> uses. Look for yourself:
> 
> http://www.oanda.com/currency/historical-rates/download?quote_currency=VND&end_date=2016-05-22&start_date=2016-05-22&period=daily&display=absolute&rate=0&data_range=d7&price=mid&view=table&base_currency_0=USD&base_currency_1=&base_currency_2=&base_currency_3=&base_currency_4=&download=csv
> 
>> 
>> I've tried various things including trying to invoke options (digits = 10)
>> at the start of the script, and even within the getFX wrapper as an extra
>> argument, but it doesn't work.  I can of course run select cross currency
>> rates and invert the results, but that is pretty awkward and it feels like
>> there ought to be a smarter and simpler solution.
> In case it's not clear from what I said above, there's nothing you can
> do to fix this after you've retrieved the data.  You need a more
> accurate data source.
> 
>> Any help greatly appreciated.
>> 
>> Thanks
>> Dave
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com
> R/Finance 2016 | www.rinfinance.com


From jdnewmil at dcn.davis.ca.us  Fri May 27 21:06:10 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 27 May 2016 12:06:10 -0700
Subject: [R] couldn't install pcalg package in R 3.1.3
In-Reply-To: <CAMqbV1DeX+k6PFSZsSc5Un5wfSb4dSwn8pDm+L8DRUs-0xP3-g@mail.gmail.com>
References: <CAMqbV1BuGnUR-85yidmRqkMCXFPL4X+LjPGftZeNtN=-dM3Tgw@mail.gmail.com>
	<B327041D-3706-4055-A2BD-6B7BA5DF46BE@dcn.davis.ca.us>
	<CAMqbV1DeX+k6PFSZsSc5Un5wfSb4dSwn8pDm+L8DRUs-0xP3-g@mail.gmail.com>
Message-ID: <CA593AE3-FDE5-4C8B-B378-A149F6393635@dcn.davis.ca.us>

Use reply-all to keep the list in the loop. 

I happen to have this old version of R still around on Windows 7 and it installs just fine for me. 

You may be able to get it to install by choosing a different CRAN mirror, but I still recommend that you upgrade R and try with that before posting again. 

-- 
Sent from my phone. Please excuse my brevity.

On May 27, 2016 11:45:38 AM PDT, Lida Zeighami <lid.zigh at gmail.com> wrote:
>Thank you Jeff for your reply,
>
>I've run install.packages( "pcalg" ) in my R version 3.1.3 but got
>error:
>
>- package ?pcalg? is not available (for R version 3.1.3)
>
>
>
>On Fri, May 27, 2016 at 1:34 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> If you read the Posting Guide it warns you against posting in HTML
>(it
>> doesn't say why but basically what you think you sent is not
>necessarily
>> what we saw). It also mentions that you should update to the latest
>version
>> of R (yours is not) if you want help (though we might try anyway). It
>also
>> mentions that you need to post a reproducible example... what the
>heck did
>> you do that did not work?
>>
>> install.packages( "pcalg" )
>>
>> worked fine for me on Windows 7.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On May 27, 2016 11:08:27 AM PDT, Lida Zeighami <lid.zigh at gmail.com>
>wrote:
>>
>>> Hi Dears!
>>>
>>> Would you please let me know how I can install package pcalg for R
>version
>>> 3.1.3 ?
>>> I've tried different ways but got error!
>>>
>>> Thanks inadvance!
>>>
>>>  [[alternative HTML version deleted]]
>>>
>>> ------------------------------
>>>
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>

	[[alternative HTML version deleted]]


From jfhenson1 at gmail.com  Fri May 27 23:25:48 2016
From: jfhenson1 at gmail.com (James Henson)
Date: Fri, 27 May 2016 16:25:48 -0500
Subject: [R] mixed models
In-Reply-To: <18F3CE5C-C207-4922-94F6-DADA30379BC5@comcast.net>
References: <CABPq8JN974cVTJvRT-+hHigPERV+-uVzzNq6OCZuqpHB4q5xgw@mail.gmail.com>
	<CAA84D89-4A4D-43A4-8541-F0CF660EE0AF@dcn.davis.ca.us>
	<CABPq8JMMqC450qda2QW75j0amaXw4rG+u8ZCG33e-_ynP3YW0w@mail.gmail.com>
	<CABPq8JN26=NuKPj977n5wM_eMGU5Cv0A4Sxok4sZno3VJUVngA@mail.gmail.com>
	<DD212DC3-B1A3-4C9B-BD8F-40DD7B3AC576@dcn.davis.ca.us>
	<CABPq8JOT85fQESy39FM88pB-sweJjZJqtx9Pt6=tU=gBN2eB3A@mail.gmail.com>
	<18F3CE5C-C207-4922-94F6-DADA30379BC5@comcast.net>
Message-ID: <CABPq8JNJruoF5WM97H5Cn1DjNiqrhGQFdbOc8OicRBJvWzDG_A@mail.gmail.com>

Greetings David,
I am new to R and neglected to check vigorously for missing values.
Apologize for posting without checking and finding the one NA.

I appreciate your help.
Thanks.
James F. Henson

On Fri, May 27, 2016 at 1:49 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On May 27, 2016, at 10:07 AM, James Henson <jfhenson1 at gmail.com> wrote:
>>
>> Greetings Jeff,
>> You are correct that the unequal number of levels is not the problem.
>> I revised the data frame so that the number of levels was equal and
>> the same error message occurred.  The code is below, and the
>> Eboni2.txt file is attached. This problem baffles me.  I appreciate
>> any help.
>> Best regards,
>> James
>> Eboni2 <- read.csv("Eboni2.csv", header = TRUE)
>>
>> library("nlme")
>>
>> str(Eboni2)
>>
>> head(Eboni2)
>>
>> model1 <- lme(preDawn ~ Irrigation, random=~season_order|treeNo, data=Eboni2)
>
> I downloaded the attached file to your first posting that was called a "csv" file but it was tab-separated (as could be clearly seen with the str output, so would only load properly with read.delim rather than read.csv. Running then with the lme call, it produced this message
>
>> model1 <- lme(preDawn ~ Irrigation, random=~season_order|treeNo, data=Eboni2)
> Error in na.fail.default(list(season_order = c(5L, 5L, 5L, 5L, 5L, 5L,  :
>   missing values in object
>
> And looking at the str result made it clear that there were many NA's in the file.
>
>> head(Eboni2)
>   number Location   Season season_order Month  treeID treeNo preDawn midday
> 1      1      UCC November            5   Nov UCCLO 1     60     1.4    1.3
> 2      2      UCC November            5   Nov UCCLO 2     72     1.2    1.3
> 3      3      UCC November            5   Nov UCCLO 3     78     1.1    1.2
> 4      4      UCC November            5   Nov UCCLO 4     79     1.1    2.1
> 5      5      UCC November            5   Nov UCCLO 5     80     1.4    1.3
> 6      6      UCC November            5   Nov UCCLO 6     81     0.6    1.8
>   Irrigation Pnet        Gs        E      WUE d15N   d13C Nper  Cper include2
> 1          N    9 0.2907004 3.766207 2.389672   NA     NA   NA    NA       no
> 2          N   11 0.3262582 3.120574 3.524993   NA     NA   NA    NA       no
> 3          N    8 0.2870957 1.693821 4.723050 3.00 -27.44 2.12 52.12      yes
> 4          N   10 0.2475180 1.839343 5.436724 3.61 -29.50 1.42 51.97      yes
> 5          N   13 0.3009228 3.082278 4.217660   NA     NA   NA    NA       no
> 6          N   17 0.3487337 2.534550 6.707304 2.79 -30.50 1.49 49.94      yes
>
> And even more importantly, there was one NA in your outcome variable:
>> sum( is.na(Eboni2$Irrigation))
> [1] 0
>> sum( is.na(Eboni2$preDawn))
> [1] 1
>
> So after restricting to complete.cases, I then formed the hypothesis that you reversed the order of the variables in the formula for the random parameter:
>
>> table(Eboni2$season_order)
>
>  1  2  3  4  5
> 83 83 83 83 83
>> length( Eboni2$treeNo)
> [1] 415
>
> So it seemed unreasonable to have a "grouping" on variable with only one item per group.
>
>> model1 <- lme(preDawn ~ Irrigation, random=~treeNo|season_order, data=Eboni2[ complete.cases( Eboni2[ , c('preDawn','Irrigation','season_order','treeNo')]), ] )
>> model1
> Linear mixed-effects model fit by REML
>   Data: Eboni2[complete.cases(Eboni2[, c("preDawn", "Irrigation", "season_order",      "treeNo")]), ]
>   Log-restricted-likelihood: -183.4708
>   Fixed: preDawn ~ Irrigation
> (Intercept) IrrigationY
>  1.04520145 -0.06037706
>
> Random effects:
>  Formula: ~treeNo | season_order
>  Structure: General positive-definite, Log-Cholesky parametrization
>             StdDev      Corr
> (Intercept) 0.140239324 (Intr)
> treeNo      0.003766019 -0.725
> Residual    0.365678898
>
> Number of Observations: 414
> Number of Groups: 5
>
> (Warning, I'm not a frequent user of this package or any of the mixed effects packages.)
>
>
>
> Just to correct some misinformation that appeared earlier: You can attach "csv" or "tsv" files as long as you name them with an .txt extension so the mail clients and servers consider them to be MIME-text.
>
> --
> David.
>
>
>> On Wed, May 25, 2016 at 6:23 PM, Jeff Newmiller
>> <jdnewmil at dcn.davis.ca.us> wrote:
>>> Please keep the mailing list in the loop by using reply-all.
>>>
>>> I don't think there is a requirement that the number of levels is equal, but
>>> there may be problems if you don't have the minimum number of records
>>> corresponding to each combination of levels specified in your model.
>>>
>>> You can change the csv extension to txt and attach for the mailing list. Or,
>>> better yet, you can use the dput function to embed the data directly in your
>>> sample code.
>>>
>>> Also, please learn to post plain text email to avoid corruption of R code by
>>> the HTML formatting.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On May 25, 2016 2:26:54 PM PDT, James Henson <jfhenson1 at gmail.com> wrote:
>>>>
>>>> Good afternoon Jeff,
>>>> The sample sizes for levels of the factor "Irrigation" are not equal. If
>>>> 'nlme' requires equal sample sizes this may be the problem. The same data
>>>> frame runs in 'lme4' without a problem.
>>>>
>>>> Best regards,
>>>> James
>>>>
>>>>
>>>> On Wed, May 25, 2016 at 3:41 PM, James Henson <jfhenson1 at gmail.com> wrote:
>>>>>
>>>>> Good afternoon Jeff,
>>>>>
>>>>> When working with this data frame, I just open the .csv file in R Studio.
>>>>> But, we should not send .csv file to R_help.  What should I send?
>>>>>
>>>>> Best regards,
>>>>> James
>>>>>
>>>>> On Wed, May 25, 2016 at 2:52 PM, Jeff Newmiller
>>>>> <jdnewmil at dcn.davis.ca.us> wrote:
>>>>>>
>>>>>> You forgot to show the commands to us that you used to read the data in
>>>>>> with (your example is not "reproducible"). This step can make all the
>>>>>> difference in the world as to whether your analysis commands will work or
>>>>>> not.
>>>>>> --
>>>>>> Sent from my phone. Please excuse my brevity.
>>>>>>
>>>>>> On May 25, 2016 11:59:06 AM PDT, James Henson <jfhenson1 at gmail.com>
>>>>>> wrote:
>>>>>>>
>>>>>>> Greetings R community,
>>>>>>>
>>>>>>> My aim is to analyze a mixed-effects model with temporal
>>>>>>> pseudo-replication
>>>>>>> (repeated measures on the same experimental unit) using ?nlme?.
>>>>>>> However,
>>>>>>> my code returns the error message ?Error in na.fail.default?, even
>>>>>>> though
>>>>>>> the data frame does not contain missing values. My code is below, and
>>>>>>> the
>>>>>>> data file is attached as ?Eboni2.txt.
>>>>>>>
>>>>>>> library("nlme")
>>>>>>>
>>>>>>> str(Eboni2)
>>>>>>>
>>>>>>> head(Eboni2)
>>>>>>>
>>>>>>> model1 <- lme(preDawn ~ Irrigation, random=~season_order|treeNo,
>>>>>>> data=Eboni2)
>>>>>>>
>>>>>>> I am genuinely confused.  Hope someone can help.
>>>>>>>
>>>>>>> Best regards,
>>>>>>>
>>>>>>> James F. Henson
>>>>>>>
>>>>>>> ________________________________
>>>>>>>
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>
>>>>
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>


From r.turner at auckland.ac.nz  Fri May 27 23:48:11 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 28 May 2016 09:48:11 +1200
Subject: [R] [FORGED]  couldn't install pcalg package in R 3.1.3
In-Reply-To: <CAMqbV1BuGnUR-85yidmRqkMCXFPL4X+LjPGftZeNtN=-dM3Tgw@mail.gmail.com>
References: <CAMqbV1BuGnUR-85yidmRqkMCXFPL4X+LjPGftZeNtN=-dM3Tgw@mail.gmail.com>
Message-ID: <0b74b237-3247-1c2e-3fb1-2317bc04959f@auckland.ac.nz>

On 28/05/16 06:08, Lida Zeighami wrote:
> Hi Dears!
>
> Would you please let me know how I can install package pcalg for R version
> 3.1.3 ?
> I've tried different ways but got error!
>
> Thanks inadvance!


An answer the helpfulness of which is commensurate with the clarity of 
your question:  Do it correctly.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From syen04 at gmail.com  Sat May 28 00:15:07 2016
From: syen04 at gmail.com (Steven Yen)
Date: Fri, 27 May 2016 18:15:07 -0400
Subject: [R] read.fortran format
In-Reply-To: <CAAJSdjgk_Fhb6yj5Y=whr7C4hUQqfJzxxn7AYmDQoc9_tt0KKA@mail.gmail.com>
References: <8e33af64-a127-00d0-e38d-6cbb55bfdb10@gmail.com>
	<CAAJSdjgk_Fhb6yj5Y=whr7C4hUQqfJzxxn7AYmDQoc9_tt0KKA@mail.gmail.com>
Message-ID: <641c437c-c302-aa69-cf86-857733090ad2@gmail.com>

Thanks John. That helped, but I got a mixed of good thing and bad thing. 
Good is R does not like the scientific number format "3E15.9" but I was 
able to read with alphanumerical format "3A15" (and convert to 
numerical). Bad is R does not like the numbers .1234, .2345 without the 
zeros before the decimal points. My data look like:

   1950. .614350 .026834 .087227 .006821 .180001 .084766

The first variable was read correctly, followed by six 0's.

As the instructions say, this fortran format is approximation at best 
and in this case, a poort approximation.

On 5/27/2016 2:21 PM, John McKown wrote:
> On Fri, May 27, 2016 at 12:56 PM, Steven Yen <syen04 at gmail.com 
> <mailto:syen04 at gmail.com>>wrote:
>
>     Dear fellow R users:
>     I am reading a data (ascii) file with fortran fixed format, containing
>     multiple records. R does not recognize fortran's record break (a
>     slash).
>     I tried to do the following but it does not work. Help appreciated.
>
>       60
>     FORMAT(1X,F6.0,5F8.6/1X,5F8.4,F10.6/1X,2F6.0,3E15.9,F8.0,F5.2,F5.3
>           *      /1X,F7.0,2E15.9,F9.4,F5.3)
>
>     mydata<-read.fortran("G:/Journals/Disk1/12_restat_95/estimate/GROUPD.DAT",
>     ??
>              c("1X","F6.0","5F8.6"/"1X","5F8.4","F10.6"
>               /"1X","2F6.0","3E15.9","F8.0","F5.2","F5.3"
>               /"1X","F7.0","2E15.9","F9.4","F5.3"),
>     ??
>     col.names=c("year","w1","w2","w3","w4","w5","w6","v1","v2","v3",
>     "v4","v5","v6","z","chyes","chno","ec","vc","cvc",
>     "pop","ahs","fah","tnh","eq","vq","ups","zm1 "))
>
>
> ?Did you see this from ?read.fortran
>
> <quote>
>
>  For a single-line record, ?format? should be a character vector.
>    For a multiline record it should be a list with a character vector
>    for each line.
>
> </quote>?
>
> ?I think (not sure) you need:
>
> mydata<-read.frotran("G:/Journals/Disk1/12_restat_95/estimate/GROUPD.DAT",
> list(c("1X","F6.0","5F8.6"),c("1X","5F8.4","F10.6"),c("1X","2F6.0","3E15.9","F8.0","F5.2","F5.3"),c("1X","F7.0","2E15.9","F9.4","F5.3")).
> ?
> col.names=c("year","w1","w2","w3","w4","w5","w6","v1","v2","v3",
> "v4","v5","v6","z","chyes","chno","ec","vc","cvc",
> "pop","ahs","fah","tnh","eq","vq","ups","zm1 "))
>
>
>
>
>
> -- 
> The unfacts, did we have them, are too imprecisely few to warrant our 
> certitude.
>
> Maranatha! <><
> John McKown


	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Sat May 28 00:33:56 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 27 May 2016 15:33:56 -0700
Subject: [R] read.fortran format
In-Reply-To: <641c437c-c302-aa69-cf86-857733090ad2@gmail.com>
References: <8e33af64-a127-00d0-e38d-6cbb55bfdb10@gmail.com>
	<CAAJSdjgk_Fhb6yj5Y=whr7C4hUQqfJzxxn7AYmDQoc9_tt0KKA@mail.gmail.com>
	<641c437c-c302-aa69-cf86-857733090ad2@gmail.com>
Message-ID: <CAF8bMcZvjOxdSY5FqcXR8Pz0-+VuVCvN9Cz4bzaSN+t_1OvPOQ@mail.gmail.com>

It has been a while since I used Fortran formatted input, but the following,
without dots in the format, works:

> txt <- "1950. .614350 .026834 .087227 .006821 .180001 4.56E-2"
> print(read.fortran(textConnection(txt), c("f5", "6f8")), digits=10)
    V1      V2       V3       V4       V5       V6     V7
1 1950 0.61435 0.026834 0.087227 0.006821 0.180001 0.0456


If I recall correctly, a dot in the format pushes the decimal point:

> print(read.fortran(textConnection(txt), c("f5", "6f8.3")), digits=10)
    V1         V2         V3         V4        V5          V6       V7
1 1950 0.00061435 2.6834e-05 8.7227e-05 6.821e-06 0.000180001 4.56e-05



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, May 27, 2016 at 3:15 PM, Steven Yen <syen04 at gmail.com> wrote:

> Thanks John. That helped, but I got a mixed of good thing and bad thing.
> Good is R does not like the scientific number format "3E15.9" but I was
> able to read with alphanumerical format "3A15" (and convert to
> numerical). Bad is R does not like the numbers .1234, .2345 without the
> zeros before the decimal points. My data look like:
>
>    1950. .614350 .026834 .087227 .006821 .180001 .084766
>
> The first variable was read correctly, followed by six 0's.
>
> As the instructions say, this fortran format is approximation at best
> and in this case, a poort approximation.
>
> On 5/27/2016 2:21 PM, John McKown wrote:
> > On Fri, May 27, 2016 at 12:56 PM, Steven Yen <syen04 at gmail.com
> > <mailto:syen04 at gmail.com>>wrote:
> >
> >     Dear fellow R users:
> >     I am reading a data (ascii) file with fortran fixed format,
> containing
> >     multiple records. R does not recognize fortran's record break (a
> >     slash).
> >     I tried to do the following but it does not work. Help appreciated.
> >
> >       60
> >     FORMAT(1X,F6.0,5F8.6/1X,5F8.4,F10.6/1X,2F6.0,3E15.9,F8.0,F5.2,F5.3
> >           *      /1X,F7.0,2E15.9,F9.4,F5.3)
> >
> >
>  mydata<-read.fortran("G:/Journals/Disk1/12_restat_95/estimate/GROUPD.DAT",
> >     ??
> >              c("1X","F6.0","5F8.6"/"1X","5F8.4","F10.6"
> >               /"1X","2F6.0","3E15.9","F8.0","F5.2","F5.3"
> >               /"1X","F7.0","2E15.9","F9.4","F5.3"),
> >     ??
> >     col.names=c("year","w1","w2","w3","w4","w5","w6","v1","v2","v3",
> >     "v4","v5","v6","z","chyes","chno","ec","vc","cvc",
> >     "pop","ahs","fah","tnh","eq","vq","ups","zm1 "))
> >
> >
> > ?Did you see this from ?read.fortran
> >
> > <quote>
> >
> >  For a single-line record, ?format? should be a character vector.
> >    For a multiline record it should be a list with a character vector
> >    for each line.
> >
> > </quote>?
> >
> > ?I think (not sure) you need:
> >
> >
> mydata<-read.frotran("G:/Journals/Disk1/12_restat_95/estimate/GROUPD.DAT",
> >
> list(c("1X","F6.0","5F8.6"),c("1X","5F8.4","F10.6"),c("1X","2F6.0","3E15.9","F8.0","F5.2","F5.3"),c("1X","F7.0","2E15.9","F9.4","F5.3")).
> > ?
> > col.names=c("year","w1","w2","w3","w4","w5","w6","v1","v2","v3",
> > "v4","v5","v6","z","chyes","chno","ec","vc","cvc",
> > "pop","ahs","fah","tnh","eq","vq","ups","zm1 "))
> >
> >
> >
> >
> >
> > --
> > The unfacts, did we have them, are too imprecisely few to warrant our
> > certitude.
> >
> > Maranatha! <><
> > John McKown
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From santosh2005 at gmail.com  Sat May 28 01:00:14 2016
From: santosh2005 at gmail.com (Santosh)
Date: Fri, 27 May 2016 16:00:14 -0700
Subject: [R] Application of "merge" and "within"
Message-ID: <CAN_e6XtOQ97qnmEw_bhthw+Sy_g7y98VLfiaw2ga0nTWZ=rkDw@mail.gmail.com>

Dear Rxperts!

Is there a way to compute relative values.. using within().. function?

Any assistance/suggestions are highly welcome!!
Thanks again,
Santosh...
___________________________________________________________________
A sample dataset and the computation "outside" within()  function is shown..

q <- data.frame(GL = rep(paste("G",1:3,sep = ""),each = 50),
                G  = rep(1:3,each = 50),
                D = rep(paste("D",1:5,sep = ""),each = 30),
                a = rep(1:15,each = 10),
                t = rep(seq(10),15),
                b = round(runif(150,10,20)))
r <- subset(q,!duplicated(paste(G,a)),sel=c(G,a,b))
names(r)[3] <- "bl"
s <- merge(q,r)
 s$db <- s$b-s$bl

> head(s,5)
    G  a GL  D  t  b bl db
1   1  1 G1 D1  1 13 13  0
2   1  1 G1 D1  2 16 13  3
3   1  1 G1 D1  3 19 13  6
4   1  1 G1 D1  4 12 13 -1
5   1  1 G1 D1  5 19 13  6

	[[alternative HTML version deleted]]


From matteo.richiardi at gmail.com  Sat May 28 02:31:41 2016
From: matteo.richiardi at gmail.com (Matteo Richiardi)
Date: Sat, 28 May 2016 01:31:41 +0100
Subject: [R] Dynamically populate a vector by iteratively applying a
 function to its previous element.
Message-ID: <CABSrU1KfOky3Q92k8g2j_etehsFnBq_=apqkGUGW8ZYpvAhuWQ@mail.gmail.com>

I want to dynamically populate a vector by iteratively applying a
function to its previous element, without using a 'for' cycle. My
solution, based on a question I posted some times ago for a more
complicated problem (see "updating elements of a list of matrixes
without 'for' cycles") was to define a matrix of indexes, and then
apply the function to the indexes. Here's a trivial example:

# my vector, all elements still unassigned
v <- rep(NA, 10)
# initialisation
v[1] <- 0

# the function to be applied
v.fun = function(x) {
  i <- x[1]
  return(v[i]+1)
}

# The matrix of array indices
idx <- as.matrix(expand.grid(c(1:9)))

# Application of the function
r[2:10] <- invisible(apply(idx, 1, v.fun))

[Note that this example is deliberately trivial: v <-c(0:9) would
solve the problem. In general, the function can be more complicated.]

The trick works only for v[2]. I imagine this is because the vector is
not dynamically updated during the iteration, so all values v[2:10]
are retained as NA.

How can I solve the problem, without using a 'for' cycle?
Thanks for your help ! Matteo


From jdnewmil at dcn.davis.ca.us  Sat May 28 03:14:22 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 27 May 2016 18:14:22 -0700
Subject: [R] Dynamically populate a vector by iteratively applying a
	function to its previous element.
In-Reply-To: <CABSrU1KfOky3Q92k8g2j_etehsFnBq_=apqkGUGW8ZYpvAhuWQ@mail.gmail.com>
References: <CABSrU1KfOky3Q92k8g2j_etehsFnBq_=apqkGUGW8ZYpvAhuWQ@mail.gmail.com>
Message-ID: <F7CB9927-FB6D-45A5-AB58-316B45DAD806@dcn.davis.ca.us>

You have set yourself an impossible goal. Either you can reformulate your problem as non-iterative and can process your data as arrays, or you have to use some kind of for loop. The lapply and Vectorize functions are popular "pretty" ways to do this, but they amount to hidden for loops. 

Note that certain instances of iterative algorithms may have optimized compiled calculation functions ready for your use,  but unless someone has figured out some algorithm-specific optimization they won't be significantly faster than an R for loop. 

The best you can do is avoid allocating growing data structures... pre-allocate your result and fill it in as you go.
-- 
Sent from my phone. Please excuse my brevity.

On May 27, 2016 5:31:41 PM PDT, Matteo Richiardi <matteo.richiardi at gmail.com> wrote:
>I want to dynamically populate a vector by iteratively applying a
>function to its previous element, without using a 'for' cycle. My
>solution, based on a question I posted some times ago for a more
>complicated problem (see "updating elements of a list of matrixes
>without 'for' cycles") was to define a matrix of indexes, and then
>apply the function to the indexes. Here's a trivial example:
>
># my vector, all elements still unassigned
>v <- rep(NA, 10)
># initialisation
>v[1] <- 0
>
># the function to be applied
>v.fun = function(x) {
>  i <- x[1]
>  return(v[i]+1)
>}
>
># The matrix of array indices
>idx <- as.matrix(expand.grid(c(1:9)))
>
># Application of the function
>r[2:10] <- invisible(apply(idx, 1, v.fun))
>
>[Note that this example is deliberately trivial: v <-c(0:9) would
>solve the problem. In general, the function can be more complicated.]
>
>The trick works only for v[2]. I imagine this is because the vector is
>not dynamically updated during the iteration, so all values v[2:10]
>are retained as NA.
>
>How can I solve the problem, without using a 'for' cycle?
>Thanks for your help ! Matteo
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From syen04 at gmail.com  Sat May 28 05:30:49 2016
From: syen04 at gmail.com (Steven Yen)
Date: Fri, 27 May 2016 23:30:49 -0400
Subject: [R] read.fortran format
In-Reply-To: <CAF8bMcZvjOxdSY5FqcXR8Pz0-+VuVCvN9Cz4bzaSN+t_1OvPOQ@mail.gmail.com>
References: <8e33af64-a127-00d0-e38d-6cbb55bfdb10@gmail.com>
	<CAAJSdjgk_Fhb6yj5Y=whr7C4hUQqfJzxxn7AYmDQoc9_tt0KKA@mail.gmail.com>
	<641c437c-c302-aa69-cf86-857733090ad2@gmail.com>
	<CAF8bMcZvjOxdSY5FqcXR8Pz0-+VuVCvN9Cz4bzaSN+t_1OvPOQ@mail.gmail.com>
Message-ID: <46e14b88-a98a-b9ef-695c-f1587d51bc26@gmail.com>

That's great, John. Your mother told you when you were born? How am I 
supposed to know? Thank you both.
The following format statement did it!! I just change F5.3 to F5, 5F8.4 
to 5F8. I also change 2E15.9 to 2A9, and then use the following 
as.numeric to convert the alphanumerical to numerical. Thank you!!!

mydata<-read.fortran("GROUPC.DAT",
         list(c("1X","F6","5F8"),
              c("1X","5F8","F10"),
              c("1X","2F6","3A15","F8","F5","F5"),
              c("1X","F7","2A15","F9","F5")),
col.names=c("year","w1","w2","w3","w4","w5","v1","v2","v3",
"v4","v5","m","chyes","chno","ec","vc","cvc",
"pop","ahs","fah","tnh","eq","vq","ups","zm1"))
mydata$ec <-as.numeric(mydata$ec)

On 5/27/2016 6:33 PM, William Dunlap wrote:
> It has been a while since I used Fortran formatted input, but the 
> following,
> without dots in the format, works:
>
>     > txt <- "1950. .614350 .026834 .087227 .006821 .180001 4.56E-2"
>     > print(read.fortran(textConnection(txt), c("f5", "6f8")), digits=10)
>         V1      V2       V3       V4       V5       V6 V7
>     1 1950 0.61435 0.026834 0.087227 0.006821 0.180001 0.0456
>
>
> If I recall correctly, a dot in the format pushes the decimal point:
>
>     > print(read.fortran(textConnection(txt), c("f5", "6f8.3")),
>     digits=10)
>         V1         V2         V3         V4        V5          V6       V7
>     1 1950 0.00061435 2.6834e-05 8.7227e-05 6.821e-06 0.000180001 4.56e-05
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com <http://tibco.com>
>
> On Fri, May 27, 2016 at 3:15 PM, Steven Yen <syen04 at gmail.com 
> <mailto:syen04 at gmail.com>> wrote:
>
>     Thanks John. That helped, but I got a mixed of good thing and bad
>     thing.
>     Good is R does not like the scientific number format "3E15.9" but
>     I was
>     able to read with alphanumerical format "3A15" (and convert to
>     numerical). Bad is R does not like the numbers .1234, .2345
>     without the
>     zeros before the decimal points. My data look like:
>
>        1950. .614350 .026834 .087227 .006821 .180001 .084766
>
>     The first variable was read correctly, followed by six 0's.
>
>     As the instructions say, this fortran format is approximation at best
>     and in this case, a poort approximation.
>
>     On 5/27/2016 2:21 PM, John McKown wrote:
>     > On Fri, May 27, 2016 at 12:56 PM, Steven Yen <syen04 at gmail.com
>     <mailto:syen04 at gmail.com>
>     > <mailto:syen04 at gmail.com <mailto:syen04 at gmail.com>>>wrote:
>     >
>     >     Dear fellow R users:
>     >     I am reading a data (ascii) file with fortran fixed format,
>     containing
>     >     multiple records. R does not recognize fortran's record break (a
>     >     slash).
>     >     I tried to do the following but it does not work. Help
>     appreciated.
>     >
>     >       60
>     >  FORMAT(1X,F6.0,5F8.6/1X,5F8.4,F10.6/1X,2F6.0,3E15.9,F8.0,F5.2,F5.3
>     >           *      /1X,F7.0,2E15.9,F9.4,F5.3)
>     >
>     >
>      mydata<-read.fortran("G:/Journals/Disk1/12_restat_95/estimate/GROUPD.DAT",
>     >     ??
>     >              c("1X","F6.0","5F8.6"/"1X","5F8.4","F10.6"
>     >  /"1X","2F6.0","3E15.9","F8.0","F5.2","F5.3"
>     >               /"1X","F7.0","2E15.9","F9.4","F5.3"),
>     >     ??
>     >  col.names=c("year","w1","w2","w3","w4","w5","w6","v1","v2","v3",
>     >     "v4","v5","v6","z","chyes","chno","ec","vc","cvc",
>     >     "pop","ahs","fah","tnh","eq","vq","ups","zm1 "))
>     >
>     >
>     > ?Did you see this from ?read.fortran
>     >
>     > <quote>
>     >
>     >  For a single-line record, ?format? should be a character vector.
>     >    For a multiline record it should be a list with a character
>     vector
>     >    for each line.
>     >
>     > </quote>?
>     >
>     > ?I think (not sure) you need:
>     >
>     >
>     mydata<-read.frotran("G:/Journals/Disk1/12_restat_95/estimate/GROUPD.DAT",
>     >
>     list(c("1X","F6.0","5F8.6"),c("1X","5F8.4","F10.6"),c("1X","2F6.0","3E15.9","F8.0","F5.2","F5.3"),c("1X","F7.0","2E15.9","F9.4","F5.3")).
>     > ?
>     > col.names=c("year","w1","w2","w3","w4","w5","w6","v1","v2","v3",
>     > "v4","v5","v6","z","chyes","chno","ec","vc","cvc",
>     > "pop","ahs","fah","tnh","eq","vq","ups","zm1 "))
>     >
>     >
>     >
>     >
>     >
>     > --
>     > The unfacts, did we have them, are too imprecisely few to
>     warrant our
>     > certitude.
>     >
>     > Maranatha! <><
>     > John McKown
>
>
>             [[alternative HTML version deleted]]
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat May 28 07:14:19 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 27 May 2016 22:14:19 -0700
Subject: [R] read.fortran format
In-Reply-To: <46e14b88-a98a-b9ef-695c-f1587d51bc26@gmail.com>
References: <8e33af64-a127-00d0-e38d-6cbb55bfdb10@gmail.com>
	<CAAJSdjgk_Fhb6yj5Y=whr7C4hUQqfJzxxn7AYmDQoc9_tt0KKA@mail.gmail.com>
	<641c437c-c302-aa69-cf86-857733090ad2@gmail.com>
	<CAF8bMcZvjOxdSY5FqcXR8Pz0-+VuVCvN9Cz4bzaSN+t_1OvPOQ@mail.gmail.com>
	<46e14b88-a98a-b9ef-695c-f1587d51bc26@gmail.com>
Message-ID: <9F742C71-6792-4D93-97A3-55B151877904@dcn.davis.ca.us>

Your rather sarcastic comment about knowledge given by John's mother seems inappropriate, given that he told you where his information came from and it is the first place you should have looked. 

The bit about the decimal leading to a shift in the decimal place pointed out by Bill is a bit obscure, though it to is mentioned in the help file. 

The "D" format is broken though... the regex template in the processFormat embedded function is missing that option. Bill's use of 'F' instead with no decimal is the easy workaround, but that is a bug.
-- 
Sent from my phone. Please excuse my brevity.

On May 27, 2016 8:30:49 PM PDT, Steven Yen <syen04 at gmail.com> wrote:
>That's great, John. Your mother told you when you were born? How am I 
>supposed to know? Thank you both.
>The following format statement did it!! I just change F5.3 to F5, 5F8.4
>
>to 5F8. I also change 2E15.9 to 2A9, and then use the following 
>as.numeric to convert the alphanumerical to numerical. Thank you!!!
>
>mydata<-read.fortran("GROUPC.DAT",
>         list(c("1X","F6","5F8"),
>              c("1X","5F8","F10"),
>              c("1X","2F6","3A15","F8","F5","F5"),
>              c("1X","F7","2A15","F9","F5")),
>col.names=c("year","w1","w2","w3","w4","w5","v1","v2","v3",
>"v4","v5","m","chyes","chno","ec","vc","cvc",
>"pop","ahs","fah","tnh","eq","vq","ups","zm1"))
>mydata$ec <-as.numeric(mydata$ec)
>
>On 5/27/2016 6:33 PM, William Dunlap wrote:
>> It has been a while since I used Fortran formatted input, but the 
>> following,
>> without dots in the format, works:
>>
>>     > txt <- "1950. .614350 .026834 .087227 .006821 .180001 4.56E-2"
>>     > print(read.fortran(textConnection(txt), c("f5", "6f8")),
>digits=10)
>>         V1      V2       V3       V4       V5       V6 V7
>>     1 1950 0.61435 0.026834 0.087227 0.006821 0.180001 0.0456
>>
>>
>> If I recall correctly, a dot in the format pushes the decimal point:
>>
>>     > print(read.fortran(textConnection(txt), c("f5", "6f8.3")),
>>     digits=10)
>>         V1         V2         V3         V4        V5          V6    
>  V7
>>     1 1950 0.00061435 2.6834e-05 8.7227e-05 6.821e-06 0.000180001
>4.56e-05
>>
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com <http://tibco.com>
>>
>> On Fri, May 27, 2016 at 3:15 PM, Steven Yen <syen04 at gmail.com 
>> <mailto:syen04 at gmail.com>> wrote:
>>
>>     Thanks John. That helped, but I got a mixed of good thing and bad
>>     thing.
>>     Good is R does not like the scientific number format "3E15.9" but
>>     I was
>>     able to read with alphanumerical format "3A15" (and convert to
>>     numerical). Bad is R does not like the numbers .1234, .2345
>>     without the
>>     zeros before the decimal points. My data look like:
>>
>>        1950. .614350 .026834 .087227 .006821 .180001 .084766
>>
>>     The first variable was read correctly, followed by six 0's.
>>
>>     As the instructions say, this fortran format is approximation at
>best
>>     and in this case, a poort approximation.
>>
>>     On 5/27/2016 2:21 PM, John McKown wrote:
>>     > On Fri, May 27, 2016 at 12:56 PM, Steven Yen <syen04 at gmail.com
>>     <mailto:syen04 at gmail.com>
>>     > <mailto:syen04 at gmail.com <mailto:syen04 at gmail.com>>>wrote:
>>     >
>>     >     Dear fellow R users:
>>     >     I am reading a data (ascii) file with fortran fixed format,
>>     containing
>>     >     multiple records. R does not recognize fortran's record
>break (a
>>     >     slash).
>>     >     I tried to do the following but it does not work. Help
>>     appreciated.
>>     >
>>     >       60
>>     > 
>FORMAT(1X,F6.0,5F8.6/1X,5F8.4,F10.6/1X,2F6.0,3E15.9,F8.0,F5.2,F5.3
>>     >           *      /1X,F7.0,2E15.9,F9.4,F5.3)
>>     >
>>     >
>>     
>mydata<-read.fortran("G:/Journals/Disk1/12_restat_95/estimate/GROUPD.DAT",
>>     >     ??
>>     >              c("1X","F6.0","5F8.6"/"1X","5F8.4","F10.6"
>>     >  /"1X","2F6.0","3E15.9","F8.0","F5.2","F5.3"
>>     >               /"1X","F7.0","2E15.9","F9.4","F5.3"),
>>     >     ??
>>     > 
>col.names=c("year","w1","w2","w3","w4","w5","w6","v1","v2","v3",
>>     >     "v4","v5","v6","z","chyes","chno","ec","vc","cvc",
>>     >     "pop","ahs","fah","tnh","eq","vq","ups","zm1 "))
>>     >
>>     >
>>     > ?Did you see this from ?read.fortran
>>     >
>>     > <quote>
>>     >
>>     >  For a single-line record, ?format? should be a character
>vector.
>>     >    For a multiline record it should be a list with a character
>>     vector
>>     >    for each line.
>>     >
>>     > </quote>?
>>     >
>>     > ?I think (not sure) you need:
>>     >
>>     >
>>    
>mydata<-read.frotran("G:/Journals/Disk1/12_restat_95/estimate/GROUPD.DAT",
>>     >
>>    
>list(c("1X","F6.0","5F8.6"),c("1X","5F8.4","F10.6"),c("1X","2F6.0","3E15.9","F8.0","F5.2","F5.3"),c("1X","F7.0","2E15.9","F9.4","F5.3")).
>>     > ?
>>     >
>col.names=c("year","w1","w2","w3","w4","w5","w6","v1","v2","v3",
>>     > "v4","v5","v6","z","chyes","chno","ec","vc","cvc",
>>     > "pop","ahs","fah","tnh","eq","vq","ups","zm1 "))
>>     >
>>     >
>>     >
>>     >
>>     >
>>     > --
>>     > The unfacts, did we have them, are too imprecisely few to
>>     warrant our
>>     > certitude.
>>     >
>>     > Maranatha! <><
>>     > John McKown
>>
>>
>>             [[alternative HTML version deleted]]
>>
>>     ______________________________________________
>>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>--
>>     To UNSUBSCRIBE and more, see
>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>     PLEASE do read the posting guide
>>     http://www.R-project.org/posting-guide.html
>>     and provide commented, minimal, self-contained, reproducible
>code.
>>
>>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From infinite2849 at yahoo.com  Sat May 28 01:40:20 2016
From: infinite2849 at yahoo.com (infinite2849 at yahoo.com)
Date: Fri, 27 May 2016 23:40:20 +0000 (UTC)
Subject: [R] Creating R file
References: <1307115750.786056.1464392420436.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1307115750.786056.1464392420436.JavaMail.yahoo@mail.yahoo.com>

?Hi. I am new to R and confused by some conflicting and contradictory information about it. Where and how do I create a numeric data file with .csv extension for use in R? So numbers meaning numeric data will be separated by commas and will consist of one line of numbers randomly chosen from 1 to 40. Thanks to all who reply. jay28.
Sent from Yahoo Mail. Get the app
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat May 28 09:22:44 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 28 May 2016 00:22:44 -0700
Subject: [R] Creating R file
In-Reply-To: <1307115750.786056.1464392420436.JavaMail.yahoo@mail.yahoo.com>
References: <1307115750.786056.1464392420436.JavaMail.yahoo.ref@mail.yahoo.com>
	<1307115750.786056.1464392420436.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <8841C476-ED72-4887-968B-7D74C270C15B@comcast.net>


> On May 27, 2016, at 4:40 PM, jay28 via R-help <r-help at r-project.org> wrote:
> 
>  Hi. I am new to R and confused by some conflicting and contradictory information about it. Where and how do I create a numeric data file with .csv extension for use in R? So numbers meaning numeric data will be separated by commas and will consist of one line of numbers randomly chosen from 1 to 40. Thanks to all who reply. jay28.
> Sent from Yahoo Mail. Get the app
> 	[[alternative HTML version deleted]]
> 

I don?t understand how the calls to the help function would not answer both aspects:

?write.csv
?sample

? 
David.


> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hyu0401 at hotmail.com  Sat May 28 09:37:02 2016
From: hyu0401 at hotmail.com (Hong Yu)
Date: Sat, 28 May 2016 15:37:02 +0800
Subject: [R] Creating R file
Message-ID: <SNT405-EAS101E096CFDC6E2078E88B7DAE430@phx.gbl>


When you need numerical data input in R programs, you can use EXCEL to create .csv file.  When you need output calculation results, you can write out .csv file in R programs.

Yes, the most common .cvs file format is comma seperated numerical values.  You can use EXCEL to create .csv file, and view the content with text editor.



From: jay28 via R-help 
Sent: Saturday, May 28, 2016 2:59 PM
To: r-help at r-project.org 
Subject: [R] Creating R file

Hi. I am new to R and confused by some conflicting and contradictory information about it. Where and how do I create a numeric data file with .csv extension for use in R? So numbers meaning numeric data will be separated by commas and will consist of one line of numbers randomly chosen from 1 to 40. Thanks to all who reply. jay28.
Sent from Yahoo Mail. Get the app
        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat May 28 09:37:39 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 28 May 2016 00:37:39 -0700
Subject: [R] Creating R file
In-Reply-To: <8841C476-ED72-4887-968B-7D74C270C15B@comcast.net>
References: <1307115750.786056.1464392420436.JavaMail.yahoo.ref@mail.yahoo.com>
	<1307115750.786056.1464392420436.JavaMail.yahoo@mail.yahoo.com>
	<8841C476-ED72-4887-968B-7D74C270C15B@comcast.net>
Message-ID: <6A9D9D6B-163B-4865-9668-6FDAEE0D3565@dcn.davis.ca.us>

This sounds like homework, which has been determined to be off-topic on this help list. Please read the Posting Guide before posting. 

That said, it would appear the OP may need to read about data frames in, say, the Introduction to R... and perhaps about matrices... and using the as.* functions to convert between them... in addition to the below-mentioned help pages. 
-- 
Sent from my phone. Please excuse my brevity.

On May 28, 2016 12:22:44 AM PDT, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On May 27, 2016, at 4:40 PM, jay28 via R-help <r-help at r-project.org>
>wrote:
>> 
>>  Hi. I am new to R and confused by some conflicting and contradictory
>information about it. Where and how do I create a numeric data file
>with .csv extension for use in R? So numbers meaning numeric data will
>be separated by commas and will consist of one line of numbers randomly
>chosen from 1 to 40. Thanks to all who reply. jay28.
>> Sent from Yahoo Mail. Get the app
>> 	[[alternative HTML version deleted]]
>> 
>
>I don?t understand how the calls to the help function would not answer
>both aspects:
>
>?write.csv
>?sample
>
>? 
>David.
>
>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ajdamico at gmail.com  Sat May 28 11:14:24 2016
From: ajdamico at gmail.com (Anthony Damico)
Date: Sat, 28 May 2016 05:14:24 -0400
Subject: [R] code to provoke a crash running rterm.exe on windows
Message-ID: <CAOwvMDwWZTyhMPXwaw7zCKeXQ0S6ncuYOvLS2ReniSBNGV9yzg@mail.gmail.com>

hi, here's a minimal reproducible example that crashes my R 3.3.0 console
on a powerful windows server.  below the example, i've put the error (not
crash) that occurs on R 3.2.3.

should this be reported to http://bugs.r-project.org/ or am i doing
something silly?  thanx





# C:\Users\AnthonyD>"c:\Program Files\R\R-3.3.0\bin\x64\Rterm.exe"

# R version 3.3.0 (2016-05-03) -- "Supposedly Educational"
# Copyright (C) 2016 The R Foundation for Statistical Computing
# Platform: x86_64-w64-mingw32/x64 (64-bit)

# R is free software and comes with ABSOLUTELY NO WARRANTY.
# You are welcome to redistribute it under certain conditions.
# Type 'license()' or 'licence()' for distribution details.

  # Natural language support but running in an English locale

# R is a collaborative project with many contributors.
# Type 'contributors()' for more information and
# 'citation()' on how to cite R or R packages in publications.

# Type 'demo()' for some demos, 'help()' for on-line help, or
# 'help.start()' for an HTML browser interface to help.
# Type 'q()' to quit R.

sessionInfo()
# R version 3.3.0 (2016-05-03)
# Platform: x86_64-w64-mingw32/x64 (64-bit)
# Running under: Windows Server 2012 R2 x64 (build 9600)

# locale:
# [1] LC_COLLATE=English_United States.1252
# [2] LC_CTYPE=English_United States.1252
# [3] LC_MONETARY=English_United States.1252
# [4] LC_NUMERIC=C
# [5] LC_TIME=English_United States.1252

# attached base packages:
# [1] stats     graphics  grDevices utils     datasets  methods   base

memory.limit()
# [1] 229247

# works fine
grpsize = ceiling(10^5/26)

# simple data.frame
my_df <-
  data.frame(
  x=rep(LETTERS,each=26*grpsize),
  v=runif(grpsize*26),
  stringsAsFactors=FALSE
  )

# mis-match the number of elements
my_df <-
  data.frame(
  x=rep(LETTERS,each=26*grpsize),
  v=runif(grpsize*26),
  stringsAsFactors=FALSE
  )

# make this much bigger
grpsize = ceiling(10^8/26)

# simple data.frame
my_df <-
  data.frame(
  x=rep(LETTERS,each=grpsize),
  v=runif(grpsize*26),
  stringsAsFactors=FALSE
  )

# mis-match the number of elements
my_df <-
  data.frame(
  x=rep(LETTERS,each=26*grpsize),
  v=runif(grpsize*26),
  stringsAsFactors=FALSE
  )

# CONSOLE CRASH WITHOUT EXPLANATION
C:\Users\AnthonyD>



# # # # # running the exact same commands on r version 3.2.3 on windows:

C:\Users\AnthonyD>"C:\Program Files\R\R-3.2.3\bin\x64\Rterm.exe"

memory.limit()
# [1] 229247

grpsize = ceiling(10^8/26)

# mis-matched number of elements
my_df <-
  data.frame(
  x=rep(LETTERS,each=26*grpsize),
  v=runif(grpsize*26),
  stringsAsFactors=FALSE
  )
# Error in if (mirn && nrows[i] > 0L) { :
  # missing value where TRUE/FALSE needed
# In addition: Warning message:
# In as.data.frame.vector(x, ..., nm = nm) :
  # NAs introduced by coercion to integer range

# # # # but console does not crash # # # #

	[[alternative HTML version deleted]]


From naresh_gurbuxani at hotmail.com  Sat May 28 15:10:53 2016
From: naresh_gurbuxani at hotmail.com (Naresh Gurbuxani)
Date: Sat, 28 May 2016 13:10:53 +0000
Subject: [R] colored table
Message-ID: <CY1PR07MB2588649657A578FE4E6A6BE8FA430@CY1PR07MB2588.namprd07.prod.outlook.com>

I want to print a table where table elements are colored according to the frequency of the bin. ?For example, consider below table.?

Function values that I would like to print in the table

                            x.eq.minus1  x.eq.zero  x.eq.plus1
y.eq.minus1             -20                 10            -5
y.eq.zero                 -10                  6             22
y.eq.plus1                -8                    10           -14


Frequency table to color the above table

                            x.eq.minus1  x.eq.zero  x.eq.plus1
y.eq.minus1             0.05             0.15           0.1
y.eq.zero                 0.07             0.3           0.08
y.eq.plus1                0.05            0.15           0.05


In the resulting table, the element for (x = 0, y = 0) will be 6.  This will be printed with a dark color background.  The element for (x = -1, y = -1) will be -20.  This will be printed with a light color background.  And so on.  

Thanks for your help,
Naresh


From bgunter.4567 at gmail.com  Sat May 28 16:41:53 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 28 May 2016 14:41:53 +0000
Subject: [R] colored table
In-Reply-To: <CY1PR07MB2588649657A578FE4E6A6BE8FA430@CY1PR07MB2588.namprd07.prod.outlook.com>
References: <CY1PR07MB2588649657A578FE4E6A6BE8FA430@CY1PR07MB2588.namprd07.prod.outlook.com>
Message-ID: <CAGxFJbRLMS=UHsgws7CoM3SneT+N=Tx45cLceZaZ+KkkXqKysA@mail.gmail.com>

Hi Naresh:

I shall be brief, as discussions of what statistical/graphical techniques
to use are largely OT.

IMO, this is a bad idea. I think the table entries will be very difficult
to read and groc. If the tables are unrelated, use 2 tables. If you think
they might be related, plot the entries of one versus the other in a
scatter plot. Another possibility would be plot the values as separate bars
in a trellis plot with you table x and y categorical values as conditioning
factors. Judging and comparing bar lengths is much more accurate than
trying to quantify shading density.

Cheers,
Bert
On Sat, May 28, 2016 at 9:12 AM Naresh Gurbuxani <
naresh_gurbuxani at hotmail.com> wrote:

> I want to print a table where table elements are colored according to the
> frequency of the bin.  For example, consider below table.
>
> Function values that I would like to print in the table
>
>                             x.eq.minus1  x.eq.zero  x.eq.plus1
> y.eq.minus1             -20                 10            -5
> y.eq.zero                 -10                  6             22
> y.eq.plus1                -8                    10           -14
>
>
> Frequency table to color the above table
>
>                             x.eq.minus1  x.eq.zero  x.eq.plus1
> y.eq.minus1             0.05             0.15           0.1
> y.eq.zero                 0.07             0.3           0.08
> y.eq.plus1                0.05            0.15           0.05
>
>
> In the resulting table, the element for (x = 0, y = 0) will be 6.  This
> will be printed with a dark color background.  The element for (x = -1, y =
> -1) will be -20.  This will be printed with a light color background.  And
> so on.
>
> Thanks for your help,
> Naresh
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat May 28 17:10:54 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 28 May 2016 08:10:54 -0700
Subject: [R] colored table
In-Reply-To: <CAGxFJbRLMS=UHsgws7CoM3SneT+N=Tx45cLceZaZ+KkkXqKysA@mail.gmail.com>
References: <CY1PR07MB2588649657A578FE4E6A6BE8FA430@CY1PR07MB2588.namprd07.prod.outlook.com>
	<CAGxFJbRLMS=UHsgws7CoM3SneT+N=Tx45cLceZaZ+KkkXqKysA@mail.gmail.com>
Message-ID: <A24ED42F-1347-480B-AF96-2B7E4EC4516B@dcn.davis.ca.us>

If you don't mix the text and color, heatmaps are pretty standard presentation techniques. 
-- 
Sent from my phone. Please excuse my brevity.

On May 28, 2016 7:41:53 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>Hi Naresh:
>
>I shall be brief, as discussions of what statistical/graphical
>techniques
>to use are largely OT.
>
>IMO, this is a bad idea. I think the table entries will be very
>difficult
>to read and groc. If the tables are unrelated, use 2 tables. If you
>think
>they might be related, plot the entries of one versus the other in a
>scatter plot. Another possibility would be plot the values as separate
>bars
>in a trellis plot with you table x and y categorical values as
>conditioning
>factors. Judging and comparing bar lengths is much more accurate than
>trying to quantify shading density.
>
>Cheers,
>Bert
>On Sat, May 28, 2016 at 9:12 AM Naresh Gurbuxani <
>naresh_gurbuxani at hotmail.com> wrote:
>
>> I want to print a table where table elements are colored according to
>the
>> frequency of the bin.  For example, consider below table.
>>
>> Function values that I would like to print in the table
>>
>>                             x.eq.minus1  x.eq.zero  x.eq.plus1
>> y.eq.minus1             -20                 10            -5
>> y.eq.zero                 -10                  6             22
>> y.eq.plus1                -8                    10           -14
>>
>>
>> Frequency table to color the above table
>>
>>                             x.eq.minus1  x.eq.zero  x.eq.plus1
>> y.eq.minus1             0.05             0.15           0.1
>> y.eq.zero                 0.07             0.3           0.08
>> y.eq.plus1                0.05            0.15           0.05
>>
>>
>> In the resulting table, the element for (x = 0, y = 0) will be 6. 
>This
>> will be printed with a dark color background.  The element for (x =
>-1, y =
>> -1) will be -20.  This will be printed with a light color background.
> And
>> so on.
>>
>> Thanks for your help,
>> Naresh
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sat May 28 17:42:45 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 28 May 2016 15:42:45 +0000
Subject: [R] code to provoke a crash running rterm.exe on windows
References: <CAOwvMDwWZTyhMPXwaw7zCKeXQ0S6ncuYOvLS2ReniSBNGV9yzg@mail.gmail.com>
Message-ID: <loom.20160528T173936-714@post.gmane.org>

Anthony Damico <ajdamico <at> gmail.com> writes:

> 
> hi, here's a minimal reproducible example that crashes my R 3.3.0 console
> on a powerful windows server.  below the example, i've put the error (not
> crash) that occurs on R 3.2.3.
> 
> should this be reported to http://bugs.r-project.org/ or am i doing
> something silly?  thanx


From the R FAQ (9.1):

If R executes an illegal instruction, or dies with an operating system
error message that indicates a problem in the program (as opposed to
something like ?disk full?), then it is certainly a bug.

  So you could submit a bug report, *or* open a discussion on
r-devel at r-project.org  (which I'd have said was a more appropriate
venue for this question in any case) ...

  Ben Bolker

From murdoch.duncan at gmail.com  Sat May 28 18:25:19 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 28 May 2016 12:25:19 -0400
Subject: [R] colored table
In-Reply-To: <CY1PR07MB2588649657A578FE4E6A6BE8FA430@CY1PR07MB2588.namprd07.prod.outlook.com>
References: <CY1PR07MB2588649657A578FE4E6A6BE8FA430@CY1PR07MB2588.namprd07.prod.outlook.com>
Message-ID: <2db6ddd3-5ef1-bd47-ae9d-00259c8b7a5e@gmail.com>

On 28/05/2016 9:10 AM, Naresh Gurbuxani wrote:
> I want to print a table where table elements are colored according to the frequency of the bin.  For example, consider below table.

How to do this depends on how you want to print the result.  Are you 
looking for a LaTeX table, HTML, Word, or what?

Duncan Murdoch

>
> Function values that I would like to print in the table
>
>                             x.eq.minus1  x.eq.zero  x.eq.plus1
> y.eq.minus1             -20                 10            -5
> y.eq.zero                 -10                  6             22
> y.eq.plus1                -8                    10           -14
>
>
> Frequency table to color the above table
>
>                             x.eq.minus1  x.eq.zero  x.eq.plus1
> y.eq.minus1             0.05             0.15           0.1
> y.eq.zero                 0.07             0.3           0.08
> y.eq.plus1                0.05            0.15           0.05
>
>
> In the resulting table, the element for (x = 0, y = 0) will be 6.  This will be printed with a dark color background.  The element for (x = -1, y = -1) will be -20.  This will be printed with a light color background.  And so on.
>
> Thanks for your help,
> Naresh
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From maechler at stat.math.ethz.ch  Sat May 28 18:38:54 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 28 May 2016 18:38:54 +0200
Subject: [R] asking for large memory - crash running rterm.exe on windows
In-Reply-To: <loom.20160528T173936-714@post.gmane.org>
References: <CAOwvMDwWZTyhMPXwaw7zCKeXQ0S6ncuYOvLS2ReniSBNGV9yzg@mail.gmail.com>
	<loom.20160528T173936-714@post.gmane.org>
Message-ID: <22345.51614.595312.481673@stat.math.ethz.ch>

>>>>> Ben Bolker <bbolker at gmail.com>
>>>>>     on Sat, 28 May 2016 15:42:45 +0000 writes:

    > Anthony Damico <ajdamico <at> gmail.com> writes:
    >> 
    >> hi, here's a minimal reproducible example that crashes my
    >> R 3.3.0 console on a powerful windows server.  below the
    >> example, i've put the error (not crash) that occurs on R
    >> 3.2.3.
    >> 
    >> should this be reported to http://bugs.r-project.org/ or
    >> am i doing something silly?  thanx


    > From the R FAQ (9.1):

    > If R executes an illegal instruction, or dies with an
    > operating system error message that indicates a problem in
    > the program (as opposed to something like ?disk full?),
    > then it is certainly a bug.

    >   So you could submit a bug report, *or* open a discussion
    > on r-devel at r-project.org (which I'd have said was a more
    > appropriate venue for this question in any case) ...

Indeed.
In this case, this is a known problem -- not just of R, but of
many programs that you can run ---
You are requesting (much) more memory than your computer has
RAM, and in this situation -- depending on the OS ---
your computer will kill R (what you saw) or your it will become
very slow trying to shove all memory to R and start swapping
(out to disk other running / sleeping processes on the
computer).

Both is very unpleasant...
But it is you as R user who asked R to allocate an object of
about 41.6 Gigabytes (26 * 1.6, see below).

As Ben mentioned this may be worth a discussion on R-devel ...
or you rather follow up the existing thread opened by Marius
Hofert  three weeks ago, with subject
 "[Rd] R process killed when allocating too large matrix (Mac OS X)"

  -->  https://stat.ethz.ch/pipermail/r-devel/2016-May/072648.html
 
His simple command to "crash R" was

   matrix(0, 1e5, 1e5)

which for some of use gives an error such as

> x <- matrix(0, 1e5,1e5)
Error: cannot allocate vector of size 74.5 Gb

but for others it had the same effect as your example.
BTW: I repeat it here in a functionalized form with added
     comments which makes apparent what's going on:


## Make simple data.frame
mkDf <- function(grpsize, wrongSize = FALSE) {
    ne <- (if(wrongSize) 26 else 1) *grpsize
    data.frame(x = rep(LETTERS, each = ne),
               v = runif(grpsize*26), stringsAsFactors=FALSE)
}

g1 <- ceiling(10^5/26)
d1 <- mkDf(g1) # works fine
str(d1)
## 'data.frame':	100022 obs. of  2 variables:

dP <- mkDf(g1, wrong=TRUE)# mis-matching the number of elements

str(dP) # is 26 times larger
## 'data.frame': 2600572 obs. of  2 variables: .....


# make this much bigger
gLarge <- ceiling(10^8/26)

dL <- mkDf(gLarge) # works "fine" .. (well, takes time!!)
str(dL)
## 'data.frame': 100000004 obs. of  2 variables:
as.numeric(print(object.size(dL)) / 1e6)
## 1600002088 bytes
## [1] 1600.002  Mega  i.e.,  1.6 GBytes

## Well, this will be 26 times larger than already large ==> your R may crash *OR*
 ## your computer may basically slow down to a crawl, when R requests all its memory...
if(FALSE) ## ==> do *NOT* evaluate the following lightly !!
dLL <- mkDf(gLarge, wrong=TRUE)
# CONSOLE CRASH WITHOUT EXPLANATION
# C:\Users\AnthonyD>


From maechler at stat.math.ethz.ch  Sat May 28 18:47:52 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 28 May 2016 18:47:52 +0200
Subject: [R] Getting Rid of NaN in ts Object
In-Reply-To: <20160527115108.GC3282@localhost.localdomain>
References: <20160527101432.GA3282@localhost.localdomain>
	<CA+8X3fXDkJ8RdQbFwn92FivA5Q4JanXSzuV4r0_ZpJps5aPwYg@mail.gmail.com>
	<20160527113814.GB3282@localhost.localdomain>
	<e2c2f43b-9c21-9bf5-ab4f-4b007b3ec038@gmail.com>
	<20160527115108.GC3282@localhost.localdomain>
Message-ID: <22345.52152.903070.508901@stat.math.ethz.ch>


> Perfect!
> Exactly what I was looking for.
> Thanks

> Lorenzo

> On Fri, May 27, 2016 at 01:50:03PM +0200, Christian Brandst?tter wrote:
>> Hi Lorenzo,
>> 
>> Try:
>> 
>> tt[is.nan(tt)] <- NA
>> tt <- na.omit(tt)
>> 

or simply  na.omit(tt)

as it omits both NA and NaN (and *does* keep the 'ts' properties
as you have noted).

Martin

>> Best,
>> 
>> Christian
>>


From tr206 at kent.ac.uk  Sat May 28 19:01:50 2016
From: tr206 at kent.ac.uk (T.Riedle)
Date: Sat, 28 May 2016 17:01:50 +0000
Subject: [R] sandwich package: HAC estimators
Message-ID: <5a4a4884895348f8b010876f9ca10151@ex13-live-mbn1.ad.kent.ac.uk>

Dear R users,

I am running a logistic regression using the rms package and the code looks as follows:

crisis_bubble4<-lrm(stock.market.crash~crash.MA+bubble.MA+MP.MA+UTS.MA+UPR.MA+PPI.MA+RV.MA,data=Data_logitregression_movingaverage)

Now, I would like to calculate HAC robust standard errors using the sandwich package assuming the NeweyWest estimator which looks as follows:


coeftest(crisis_bubble4,df=Inf,vcov=NeweyWest)

Error in match.arg(type) :

  'arg' should be one of "li.shepherd", "ordinary", "score", "score.binary", "pearson", "deviance", "pseudo.dep", "partial", "dfbeta", "dfbetas", "dffit", "dffits", "hat", "gof", "lp1"

As you can see, it doesn't work. Therefore, I did the same using the glm() instead of lrm():


crisis_bubble4<-glm(stock.market.crash~crash.MA+bubble.MA+MP.MA+UTS.MA+UPR.MA+PPI.MA+RV.MA,family=binomial("logit"),data=Data_logitregression_movingaverage)



If I use the coeftest() function, I get following results.

coeftest(crisis_bubble4,df=Inf,vcov=NeweyWest)



z test of coefficients:



              Estimate Std. Error z value Pr(>|z|)

(Intercept)   -5.26088    5.01706 -1.0486  0.29436

crash.MA       0.49219    2.41688  0.2036  0.83863

bubble.MA     12.12868    5.85228  2.0725  0.03822 *

MP.MA        -20.07238  499.37589 -0.0402  0.96794

UTS.MA       -58.18142   77.08409 -0.7548  0.45038

UPR.MA      -337.57985  395.35639 -0.8539  0.39318

PPI.MA       729.37693  358.60868  2.0339  0.04196 *

RV.MA        116.00106   79.52421  1.4587  0.14465

---

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1


I am unsure whether the coeftest from the lmtest package is appropriate in case of a logistic regression. Is there another function for logistic regressions? Furthermore, I would like to present the regression coefficients, the F-statistic and the HAC estimators in one single table. How can I do that?

I thought it would be useful to incorporate the HAC consistent covariance matrix into the logistic regression directly and generate an output of coefficients and the corresponding standard errors. Is there such a function in R?

Thanks for your support.

Kind regards

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Sat May 28 19:02:44 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 28 May 2016 10:02:44 -0700
Subject: [R] read.fortran format
In-Reply-To: <9F742C71-6792-4D93-97A3-55B151877904@dcn.davis.ca.us>
References: <8e33af64-a127-00d0-e38d-6cbb55bfdb10@gmail.com>
	<CAAJSdjgk_Fhb6yj5Y=whr7C4hUQqfJzxxn7AYmDQoc9_tt0KKA@mail.gmail.com>
	<641c437c-c302-aa69-cf86-857733090ad2@gmail.com>
	<CAF8bMcZvjOxdSY5FqcXR8Pz0-+VuVCvN9Cz4bzaSN+t_1OvPOQ@mail.gmail.com>
	<46e14b88-a98a-b9ef-695c-f1587d51bc26@gmail.com>
	<9F742C71-6792-4D93-97A3-55B151877904@dcn.davis.ca.us>
Message-ID: <CAF8bMcZwc-ecgtey6i=ZPrgjDsOPrCLmc5ZU7__Y_2R6HShiow@mail.gmail.com>

>The bit about the decimal leading to a shift in the decimal place
>pointed out by Bill is a bit obscure, though it to is mentioned in the
help file.

I don't think that is how real Fortran formats work.  My memory is that
you only put a dot in the format if there were no dots in your data file
(so you could avoid wasting one of the 80 columns on the punched card
on a dot).

With current gfortran, putting a dot in the data overrides the decimal
place specification in the format.

% cat format.f
      double precision d1, d2
      integer*4 i1
      integer*4 i

 10   format(I2F7.1F7.6)
      do 20 i=1,100
        read(*,10) i1, d1, d2
        write(*,*) i1, d1, d2
 20   continue
      stop
      end

% gfortran format.f -o format.exe
% ./format.exe
1234012340987654
          12   340123.40000000002       0.98765400000000003
123.0123409.7e20
          12   3.0123400000000000        9.7000000000000000E+020
123.012340976e20
          12   3.0123400000000000        97600000000000000.






Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, May 27, 2016 at 10:14 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Your rather sarcastic comment about knowledge given by John's mother seems
> inappropriate, given that he told you where his information came from and
> it is the first place you should have looked.
>
> The bit about the decimal leading to a shift in the decimal place pointed
> out by Bill is a bit obscure, though it to is mentioned in the help file.
>
> The "D" format is broken though... the regex template in the processFormat
> embedded function is missing that option. Bill's use of 'F' instead with no
> decimal is the easy workaround, but that is a bug.
> --
> Sent from my phone. Please excuse my brevity.
>
> On May 27, 2016 8:30:49 PM PDT, Steven Yen <syen04 at gmail.com> wrote:
> >That's great, John. Your mother told you when you were born? How am I
> >supposed to know? Thank you both.
> >The following format statement did it!! I just change F5.3 to F5, 5F8.4
> >
> >to 5F8. I also change 2E15.9 to 2A9, and then use the following
> >as.numeric to convert the alphanumerical to numerical. Thank you!!!
> >
> >mydata<-read.fortran("GROUPC.DAT",
> >         list(c("1X","F6","5F8"),
> >              c("1X","5F8","F10"),
> >              c("1X","2F6","3A15","F8","F5","F5"),
> >              c("1X","F7","2A15","F9","F5")),
> >col.names=c("year","w1","w2","w3","w4","w5","v1","v2","v3",
> >"v4","v5","m","chyes","chno","ec","vc","cvc",
> >"pop","ahs","fah","tnh","eq","vq","ups","zm1"))
> >mydata$ec <-as.numeric(mydata$ec)
> >
> >On 5/27/2016 6:33 PM, William Dunlap wrote:
> >> It has been a while since I used Fortran formatted input, but the
> >> following,
> >> without dots in the format, works:
> >>
> >>     > txt <- "1950. .614350 .026834 .087227 .006821 .180001 4.56E-2"
> >>     > print(read.fortran(textConnection(txt), c("f5", "6f8")),
> >digits=10)
> >>         V1      V2       V3       V4       V5       V6 V7
> >>     1 1950 0.61435 0.026834 0.087227 0.006821 0.180001 0.0456
> >>
> >>
> >> If I recall correctly, a dot in the format pushes the decimal point:
> >>
> >>     > print(read.fortran(textConnection(txt), c("f5", "6f8.3")),
> >>     digits=10)
> >>         V1         V2         V3         V4        V5          V6
> >  V7
> >>     1 1950 0.00061435 2.6834e-05 8.7227e-05 6.821e-06 0.000180001
> >4.56e-05
> >>
> >>
> >>
> >> Bill Dunlap
> >> TIBCO Software
> >> wdunlap tibco.com <http://tibco.com>
> >>
> >> On Fri, May 27, 2016 at 3:15 PM, Steven Yen <syen04 at gmail.com
> >> <mailto:syen04 at gmail.com>> wrote:
> >>
> >>     Thanks John. That helped, but I got a mixed of good thing and bad
> >>     thing.
> >>     Good is R does not like the scientific number format "3E15.9" but
> >>     I was
> >>     able to read with alphanumerical format "3A15" (and convert to
> >>     numerical). Bad is R does not like the numbers .1234, .2345
> >>     without the
> >>     zeros before the decimal points. My data look like:
> >>
> >>        1950. .614350 .026834 .087227 .006821 .180001 .084766
> >>
> >>     The first variable was read correctly, followed by six 0's.
> >>
> >>     As the instructions say, this fortran format is approximation at
> >best
> >>     and in this case, a poort approximation.
> >>
> >>     On 5/27/2016 2:21 PM, John McKown wrote:
> >>     > On Fri, May 27, 2016 at 12:56 PM, Steven Yen <syen04 at gmail.com
> >>     <mailto:syen04 at gmail.com>
> >>     > <mailto:syen04 at gmail.com <mailto:syen04 at gmail.com>>>wrote:
> >>     >
> >>     >     Dear fellow R users:
> >>     >     I am reading a data (ascii) file with fortran fixed format,
> >>     containing
> >>     >     multiple records. R does not recognize fortran's record
> >break (a
> >>     >     slash).
> >>     >     I tried to do the following but it does not work. Help
> >>     appreciated.
> >>     >
> >>     >       60
> >>     >
> >FORMAT(1X,F6.0,5F8.6/1X,5F8.4,F10.6/1X,2F6.0,3E15.9,F8.0,F5.2,F5.3
> >>     >           *      /1X,F7.0,2E15.9,F9.4,F5.3)
> >>     >
> >>     >
> >>
> >mydata<-read.fortran("G:/Journals/Disk1/12_restat_95/estimate/GROUPD.DAT",
> >>     >     ??
> >>     >              c("1X","F6.0","5F8.6"/"1X","5F8.4","F10.6"
> >>     >  /"1X","2F6.0","3E15.9","F8.0","F5.2","F5.3"
> >>     >               /"1X","F7.0","2E15.9","F9.4","F5.3"),
> >>     >     ??
> >>     >
> >col.names=c("year","w1","w2","w3","w4","w5","w6","v1","v2","v3",
> >>     >     "v4","v5","v6","z","chyes","chno","ec","vc","cvc",
> >>     >     "pop","ahs","fah","tnh","eq","vq","ups","zm1 "))
> >>     >
> >>     >
> >>     > ?Did you see this from ?read.fortran
> >>     >
> >>     > <quote>
> >>     >
> >>     >  For a single-line record, ?format? should be a character
> >vector.
> >>     >    For a multiline record it should be a list with a character
> >>     vector
> >>     >    for each line.
> >>     >
> >>     > </quote>?
> >>     >
> >>     > ?I think (not sure) you need:
> >>     >
> >>     >
> >>
> >mydata<-read.frotran("G:/Journals/Disk1/12_restat_95/estimate/GROUPD.DAT",
> >>     >
> >>
>
> >list(c("1X","F6.0","5F8.6"),c("1X","5F8.4","F10.6"),c("1X","2F6.0","3E15.9","F8.0","F5.2","F5.3"),c("1X","F7.0","2E15.9","F9.4","F5.3")).
> >>     > ?
> >>     >
> >col.names=c("year","w1","w2","w3","w4","w5","w6","v1","v2","v3",
> >>     > "v4","v5","v6","z","chyes","chno","ec","vc","cvc",
> >>     > "pop","ahs","fah","tnh","eq","vq","ups","zm1 "))
> >>     >
> >>     >
> >>     >
> >>     >
> >>     >
> >>     > --
> >>     > The unfacts, did we have them, are too imprecisely few to
> >>     warrant our
> >>     > certitude.
> >>     >
> >>     > Maranatha! <><
> >>     > John McKown
> >>
> >>
> >>             [[alternative HTML version deleted]]
> >>
> >>     ______________________________________________
> >>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> >--
> >>     To UNSUBSCRIBE and more, see
> >>     https://stat.ethz.ch/mailman/listinfo/r-help
> >>     PLEASE do read the posting guide
> >>     http://www.R-project.org/posting-guide.html
> >>     and provide commented, minimal, self-contained, reproducible
> >code.
> >>
> >>
> >
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Sat May 28 19:55:50 2016
From: hannah.hlx at gmail.com (li li)
Date: Sat, 28 May 2016 13:55:50 -0400
Subject: [R] read multiple sheets of excel data into R
Message-ID: <CAHLnndY5b+P9ouE6b9_Yinxic6W9BH5J9NvM=A1yoeDHqDdvOw@mail.gmail.com>

Hi all,
  I tried to use the package "XLConnect" to read excel data into R.  I got
the following error message:

Error : .onLoad failed in loadNamespace() for 'rJava', details:
  call: fun(libname, pkgname)
  error: No CurrentVersion entry in Software/JavaSoft registry! Try
re-installing Java and make sure R and Java have matching
architectures.


  I tried read.xls and got the following error  message:

> library(gdata)> one <- read.xls ("one.xlsx", sheet=1)Error in findPerl(verbose = verbose) :
  perl executable not found. Use perl= argument to specify the correct
path.Error in file.exists(tfn) : invalid 'file' argument


  Can anyone give me some input on this?
  Thanks.
    Hanna

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat May 28 20:34:27 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 28 May 2016 11:34:27 -0700
Subject: [R] read multiple sheets of excel data into R
In-Reply-To: <CAHLnndY5b+P9ouE6b9_Yinxic6W9BH5J9NvM=A1yoeDHqDdvOw@mail.gmail.com>
References: <CAHLnndY5b+P9ouE6b9_Yinxic6W9BH5J9NvM=A1yoeDHqDdvOw@mail.gmail.com>
Message-ID: <506124C4-5642-4494-8073-ADE667DEE64E@dcn.davis.ca.us>

Apparently you need to get your Java runtime setup, or install Perl, depending which of these tools you want to use. 

Or if your data are laid out simply, you might be able to use the readxl package. 
-- 
Sent from my phone. Please excuse my brevity.

On May 28, 2016 10:55:50 AM PDT, li li <hannah.hlx at gmail.com> wrote:
>Hi all,
>I tried to use the package "XLConnect" to read excel data into R.  I
>got
>the following error message:
>
>Error : .onLoad failed in loadNamespace() for 'rJava', details:
>  call: fun(libname, pkgname)
>  error: No CurrentVersion entry in Software/JavaSoft registry! Try
>re-installing Java and make sure R and Java have matching
>architectures.
>
>
>  I tried read.xls and got the following error  message:
>
>> library(gdata)> one <- read.xls ("one.xlsx", sheet=1)Error in
>findPerl(verbose = verbose) :
>  perl executable not found. Use perl= argument to specify the correct
>path.Error in file.exists(tfn) : invalid 'file' argument
>
>
>  Can anyone give me some input on this?
>  Thanks.
>    Hanna
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From Achim.Zeileis at uibk.ac.at  Sat May 28 20:50:47 2016
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Sat, 28 May 2016 20:50:47 +0200 (CEST)
Subject: [R] sandwich package: HAC estimators
In-Reply-To: <5a4a4884895348f8b010876f9ca10151@ex13-live-mbn1.ad.kent.ac.uk>
References: <5a4a4884895348f8b010876f9ca10151@ex13-live-mbn1.ad.kent.ac.uk>
Message-ID: <alpine.DEB.2.20.1605282044060.26454@paninaro>

On Sat, 28 May 2016, T.Riedle wrote:

> Dear R users,
>
> I am running a logistic regression using the rms package and the code 
> looks as follows:
>
> crisis_bubble4<-lrm(stock.market.crash~crash.MA+bubble.MA+MP.MA+UTS.MA+UPR.MA+PPI.MA+RV.MA,data=Data_logitregression_movingaverage)
>
> Now, I would like to calculate HAC robust standard errors using the 
> sandwich package assuming the NeweyWest estimator which looks as 
> follows:
>
> coeftest(crisis_bubble4,df=Inf,vcov=NeweyWest)
>
> Error in match.arg(type) :
>
>  'arg' should be one of "li.shepherd", "ordinary", "score", 
> "score.binary", "pearson", "deviance", "pseudo.dep", "partial", 
> "dfbeta", "dfbetas", "dffit", "dffits", "hat", "gof", "lp1"
>
> As you can see, it doesn't work.

Yes. The "sandwich" package relies on two methods being available: bread() 
and estfun(). See vignette("sandwich-OOP", package = "sandwich") for the 
background details.

For objects of class "lrm" no such methods are available. But as "lrm" 
objects inherit from "glm" the corresponding methods are called. However, 
"lrm" objects are actually too different from "glm" objects (despite the 
inheritance) resulting in the error.

It is easy to add these methods, though, because "lrm" brings all the 
necessary information:

bread.lrm <- function(x, ...) vcov(x) * nobs(x)
estfun.lrm <- function(x, ...) residuals(x, "score")

> Therefore, I did the same using the glm() instead of lrm():
>
> crisis_bubble4<-glm(stock.market.crash~crash.MA+bubble.MA+MP.MA+UTS.MA+UPR.MA+PPI.MA+RV.MA,family=binomial("logit"),data=Data_logitregression_movingaverage)
>
> If I use the coeftest() function, I get following results.
>
> coeftest(crisis_bubble4,df=Inf,vcov=NeweyWest)
>
> z test of coefficients:
>
>              Estimate Std. Error z value Pr(>|z|)
> (Intercept)   -5.26088    5.01706 -1.0486  0.29436
> crash.MA       0.49219    2.41688  0.2036  0.83863
> bubble.MA     12.12868    5.85228  2.0725  0.03822 *
> MP.MA        -20.07238  499.37589 -0.0402  0.96794
> UTS.MA       -58.18142   77.08409 -0.7548  0.45038
> UPR.MA      -337.57985  395.35639 -0.8539  0.39318
> PPI.MA       729.37693  358.60868  2.0339  0.04196 *
> RV.MA        116.00106   79.52421  1.4587  0.14465
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Some of these coefficients and standard errors are suspiciously large. It 
might make sense to check for quasi-complete separation.

> I am unsure whether the coeftest from the lmtest package is appropriate 
> in case of a logistic regression.

Yes, this is ok. (Whether or not the application of HAC standard errors is 
the best way to go is a different matter though.)

> Is there another function for logistic regressions? Furthermore, I would 
> like to present the regression coefficients, the F-statistic and the HAC 
> estimators in one single table. How can I do that?

Running first coeftest() and then lrtest() should get you close to what 
you want - even though it is not a single table.

> I thought it would be useful to incorporate the HAC consistent 
> covariance matrix into the logistic regression directly and generate an 
> output of coefficients and the corresponding standard errors. Is there 
> such a function in R?

Not with HAC standard errors, I think.

> Thanks for your support.
>
> Kind regards
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.ca.us  Sat May 28 21:56:55 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 28 May 2016 12:56:55 -0700 (PDT)
Subject: [R] Trimming time series to only include complete years
In-Reply-To: <CAPoqHzrZpb=S6GQRo0O0fszw06pW2_-HKe1MQ34emZANsDJeyQ@mail.gmail.com>
References: <CAPoqHzrZpb=S6GQRo0O0fszw06pW2_-HKe1MQ34emZANsDJeyQ@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1605281251250.73491@pedal.dcn.davis.ca.us>

# read about POSIXlt at ?DateTimeClasses
# note that the "mon" element is 0-11
isPartialWaterYear <- function( d ) {
   dtl <- as.POSIXlt( dat$Date )
   wy1 <- cumsum( ( 9 == dtl$mon ) & ( 1 == dtl$mday ) )
   ( 0 == wy1  # first partial year
   | (  8 != dtl$mon[ nrow( dat ) ] # end partial year
     & 30 != dtl$mday[ nrow( dat ) ]
     ) & wy1[ nrow( dat ) ] == wy1
   )
}

dat2 <- dat[ !isPartialWaterYear( dat$Date ), ]

The above assumes that, as you said, the data are continuous at one-day 
intervals, such that the only partial years will occur at the beginning 
and end. The "diff" function could be used to identify irregular data 
within the data interval if needed.

On Fri, 27 May 2016, Morway, Eric wrote:

> In bulk processing streamflow data available from an online database, I'm
> wanting to trim the beginning and end of the time series so that daily data
> associated with incomplete "water years" (defined as extending from Oct 1st
> to the following September 30th) is trimmed off the beginning and end of
> the series.
>
> For a small reproducible example, the time series below starts on
> 2010-01-01 and ends on 2011-11-05.  So the data between 2010-01-01 and
> 2010-09-30 and also between 2011-10-01 and 2011-11-05 is not associated
> with a complete set of data for their respective water years.  With the
> real data, the initial date of collection is arbitrary, could be 1901 or
> 1938, etc.  Because I'm cycling through potentially thousands of records, I
> need help in designing a function that is efficient.
>
> dat <-
> data.frame(Date=seq(as.Date("2010-01-01"),as.Date("2011-11-05"),by="day"))
> dat$Q <- rnorm(nrow(dat))
>
> dat$wyr <- as.numeric(format(dat$Date,"%Y"))
> is.nxt <- as.numeric(format(dat$Date,"%m")) %in% 1:9
> dat$wyr[!is.nxt] <- dat$wyr[!is.nxt] + 1
>
>
> function(dat) {
>   ...
>   returns a subset of dat such that dat$Date > xxxx-09-30 & dat$Date <
> yyyy-10-01
>   ...
> }
>
> where the years between xxxx-yyyy are "complete" (no missing days).  In the
> example above, the returned dat would extend from 2010-10-01 to 2011-09-30
>
> Any offered guidance is very much appreciated.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jdnewmil at dcn.davis.ca.us  Sat May 28 22:20:36 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 28 May 2016 13:20:36 -0700
Subject: [R] Application of "merge" and "within"
In-Reply-To: <CAN_e6XtOQ97qnmEw_bhthw+Sy_g7y98VLfiaw2ga0nTWZ=rkDw@mail.gmail.com>
References: <CAN_e6XtOQ97qnmEw_bhthw+Sy_g7y98VLfiaw2ga0nTWZ=rkDw@mail.gmail.com>
Message-ID: <80C56FE8-D9E7-40E4-BDB1-90C599B36283@dcn.davis.ca.us>

Why do you want to do this?
-- 
Sent from my phone. Please excuse my brevity.

On May 27, 2016 4:00:14 PM PDT, Santosh <santosh2005 at gmail.com> wrote:
>Dear Rxperts!
>
>Is there a way to compute relative values.. using within().. function?
>
>Any assistance/suggestions are highly welcome!!
>Thanks again,
>Santosh...
>___________________________________________________________________
>A sample dataset and the computation "outside" within()  function is
>shown..
>
>q <- data.frame(GL = rep(paste("G",1:3,sep = ""),each = 50),
>                G  = rep(1:3,each = 50),
>                D = rep(paste("D",1:5,sep = ""),each = 30),
>                a = rep(1:15,each = 10),
>                t = rep(seq(10),15),
>                b = round(runif(150,10,20)))
>r <- subset(q,!duplicated(paste(G,a)),sel=c(G,a,b))
>names(r)[3] <- "bl"
>s <- merge(q,r)
> s$db <- s$b-s$bl
>
>> head(s,5)
>    G  a GL  D  t  b bl db
>1   1  1 G1 D1  1 13 13  0
>2   1  1 G1 D1  2 16 13  3
>3   1  1 G1 D1  3 19 13  6
>4   1  1 G1 D1  4 12 13 -1
>5   1  1 G1 D1  5 19 13  6
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sat May 28 22:53:50 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 28 May 2016 16:53:50 -0400
Subject: [R] Application of "merge" and "within"
In-Reply-To: <CAN_e6XtOQ97qnmEw_bhthw+Sy_g7y98VLfiaw2ga0nTWZ=rkDw@mail.gmail.com>
References: <CAN_e6XtOQ97qnmEw_bhthw+Sy_g7y98VLfiaw2ga0nTWZ=rkDw@mail.gmail.com>
Message-ID: <f4bc3443-6e82-e70e-8a4f-fa2a03fb14b8@gmail.com>

On 27/05/2016 7:00 PM, Santosh wrote:
> Dear Rxperts!
>
> Is there a way to compute relative values.. using within().. function?
>
> Any assistance/suggestions are highly welcome!!
> Thanks again,
> Santosh...
> ___________________________________________________________________
> A sample dataset and the computation "outside" within()  function is shown..
>
> q <- data.frame(GL = rep(paste("G",1:3,sep = ""),each = 50),
>                 G  = rep(1:3,each = 50),
>                 D = rep(paste("D",1:5,sep = ""),each = 30),
>                 a = rep(1:15,each = 10),
>                 t = rep(seq(10),15),
>                 b = round(runif(150,10,20)))
> r <- subset(q,!duplicated(paste(G,a)),sel=c(G,a,b))
> names(r)[3] <- "bl"
> s <- merge(q,r)
>  s$db <- s$b-s$bl
>
>> head(s,5)
>     G  a GL  D  t  b bl db
> 1   1  1 G1 D1  1 13 13  0
> 2   1  1 G1 D1  2 16 13  3
> 3   1  1 G1 D1  3 19 13  6
> 4   1  1 G1 D1  4 12 13 -1
> 5   1  1 G1 D1  5 19 13  6

Just use

  s <- within(s, db <- b - bl)

Duncan Murdoch


From r.turner at auckland.ac.nz  Sat May 28 23:57:38 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 29 May 2016 09:57:38 +1200
Subject: [R] Creating R file
In-Reply-To: <SNT405-EAS101E096CFDC6E2078E88B7DAE430@phx.gbl>
References: <SNT405-EAS101E096CFDC6E2078E88B7DAE430@phx.gbl>
Message-ID: <d85a6ba7-6af3-ccec-0772-666c56d24da1@auckland.ac.nz>

On 28/05/16 19:37, Hong Yu wrote:
>

> When you need numerical data input in R programs, you can use EXCEL
> to create .csv file.  When you need output calculation results, you
> can write out .csv file in R programs.
>
> Yes, the most common .cvs file format is comma seperated numerical
> values.  You can use EXCEL to create .csv file, and view the content
> with text editor.

There are myriad ways to create *.csv files, including text editors and 
R itself, and other sound statistical packages.  There is no need to use 
the abomination that is known as Excel.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From jholtman at gmail.com  Sun May 29 04:11:30 2016
From: jholtman at gmail.com (jim holtman)
Date: Sat, 28 May 2016 22:11:30 -0400
Subject: [R] read multiple sheets of excel data into R
In-Reply-To: <506124C4-5642-4494-8073-ADE667DEE64E@dcn.davis.ca.us>
References: <CAHLnndY5b+P9ouE6b9_Yinxic6W9BH5J9NvM=A1yoeDHqDdvOw@mail.gmail.com>
	<506124C4-5642-4494-8073-ADE667DEE64E@dcn.davis.ca.us>
Message-ID: <CAAxdm-4a3Z9MS-kxKRyUQtMWhsQWYg39y8Y35bbK-UnOY9o1Dw@mail.gmail.com>

Try the 'openxlsx' package.  I gave up using XLConnect because of the Java
requirement, and speed on larger tables. "openxlsx" has the access routines
written in C so you don't need any other outside dependencies.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sat, May 28, 2016 at 2:34 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Apparently you need to get your Java runtime setup, or install Perl,
> depending which of these tools you want to use.
>
> Or if your data are laid out simply, you might be able to use the readxl
> package.
> --
> Sent from my phone. Please excuse my brevity.
>
> On May 28, 2016 10:55:50 AM PDT, li li <hannah.hlx at gmail.com> wrote:
> >Hi all,
> >I tried to use the package "XLConnect" to read excel data into R.  I
> >got
> >the following error message:
> >
> >Error : .onLoad failed in loadNamespace() for 'rJava', details:
> >  call: fun(libname, pkgname)
> >  error: No CurrentVersion entry in Software/JavaSoft registry! Try
> >re-installing Java and make sure R and Java have matching
> >architectures.
> >
> >
> >  I tried read.xls and got the following error  message:
> >
> >> library(gdata)> one <- read.xls ("one.xlsx", sheet=1)Error in
> >findPerl(verbose = verbose) :
> >  perl executable not found. Use perl= argument to specify the correct
> >path.Error in file.exists(tfn) : invalid 'file' argument
> >
> >
> >  Can anyone give me some input on this?
> >  Thanks.
> >    Hanna
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From hyu0401 at hotmail.com  Sun May 29 04:13:07 2016
From: hyu0401 at hotmail.com (Hong Yu)
Date: Sun, 29 May 2016 10:13:07 +0800
Subject: [R] Creating R file
Message-ID: <SNT405-EAS294593C7A1758F4F10B7B87AE440@phx.gbl>


You are right, that it is unnecessary to relate to excel.  I explain this way, because I often tutor people with little programming experience, and often I tutor people with no concept of ?text editors?.



From: Rolf Turner 
Sent: Sunday, May 29, 2016 5:57 AM
To: Hong Yu 
Cc: infinite2849 at yahoo.com ; r-help at r-project.org 
Subject: Re: [R] Creating R file

On 28/05/16 19:37, Hong Yu wrote:
>

> When you need numerical data input in R programs, you can use EXCEL
> to create .csv file.  When you need output calculation results, you
> can write out .csv file in R programs.
>
> Yes, the most common .cvs file format is comma seperated numerical
> values.  You can use EXCEL to create .csv file, and view the content
> with text editor.

There are myriad ways to create *.csv files, including text editors and 
R itself, and other sound statistical packages.  There is no need to use 
the abomination that is known as Excel.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

	[[alternative HTML version deleted]]


From ajdamico at gmail.com  Sun May 29 06:24:52 2016
From: ajdamico at gmail.com (Anthony Damico)
Date: Sun, 29 May 2016 00:24:52 -0400
Subject: [R] asking for large memory - crash running rterm.exe on windows
In-Reply-To: <22345.51614.595312.481673@stat.math.ethz.ch>
References: <CAOwvMDwWZTyhMPXwaw7zCKeXQ0S6ncuYOvLS2ReniSBNGV9yzg@mail.gmail.com>
	<loom.20160528T173936-714@post.gmane.org>
	<22345.51614.595312.481673@stat.math.ethz.ch>
Message-ID: <CAOwvMDz1u9SyF=FFe2K-Z88TY_D30g8rZC4KEjOVaOaMLHXh9Q@mail.gmail.com>

hi, thanks to you both!  note the large memory.limit() on the machine
before the crash (200+ gb) so i'm not sure it's a simple overloading
explosion?  i've filed a bug report..

https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16927



On Saturday, May 28, 2016, Martin Maechler <maechler at stat.math.ethz.ch>
wrote:

> >>>>> Ben Bolker <bbolker at gmail.com>
> >>>>>     on Sat, 28 May 2016 15:42:45 +0000 writes:
>
>     > Anthony Damico <ajdamico <at> gmail.com> writes:
>     >>
>     >> hi, here's a minimal reproducible example that crashes my
>     >> R 3.3.0 console on a powerful windows server.  below the
>     >> example, i've put the error (not crash) that occurs on R
>     >> 3.2.3.
>     >>
>     >> should this be reported to http://bugs.r-project.org/ or
>     >> am i doing something silly?  thanx
>
>
>     > From the R FAQ (9.1):
>
>     > If R executes an illegal instruction, or dies with an
>     > operating system error message that indicates a problem in
>     > the program (as opposed to something like ?disk full?),
>     > then it is certainly a bug.
>
>     >   So you could submit a bug report, *or* open a discussion
>     > on r-devel at r-project.org (which I'd have said was a more
>     > appropriate venue for this question in any case) ...
>
> Indeed.
> In this case, this is a known problem -- not just of R, but of
> many programs that you can run ---
> You are requesting (much) more memory than your computer has
> RAM, and in this situation -- depending on the OS ---
> your computer will kill R (what you saw) or your it will become
> very slow trying to shove all memory to R and start swapping
> (out to disk other running / sleeping processes on the
> computer).
>
> Both is very unpleasant...
> But it is you as R user who asked R to allocate an object of
> about 41.6 Gigabytes (26 * 1.6, see below).
>
> As Ben mentioned this may be worth a discussion on R-devel ...
> or you rather follow up the existing thread opened by Marius
> Hofert  three weeks ago, with subject
>  "[Rd] R process killed when allocating too large matrix (Mac OS X)"
>
>   -->  https://stat.ethz.ch/pipermail/r-devel/2016-May/072648.html
>
> His simple command to "crash R" was
>
>    matrix(0, 1e5, 1e5)
>
> which for some of use gives an error such as
>
> > x <- matrix(0, 1e5,1e5)
> Error: cannot allocate vector of size 74.5 Gb
>
> but for others it had the same effect as your example.
> BTW: I repeat it here in a functionalized form with added
>      comments which makes apparent what's going on:
>
>
> ## Make simple data.frame
> mkDf <- function(grpsize, wrongSize = FALSE) {
>     ne <- (if(wrongSize) 26 else 1) *grpsize
>     data.frame(x = rep(LETTERS, each = ne),
>                v = runif(grpsize*26), stringsAsFactors=FALSE)
> }
>
> g1 <- ceiling(10^5/26)
> d1 <- mkDf(g1) # works fine
> str(d1)
> ## 'data.frame':        100022 obs. of  2 variables:
>
> dP <- mkDf(g1, wrong=TRUE)# mis-matching the number of elements
>
> str(dP) # is 26 times larger
> ## 'data.frame': 2600572 obs. of  2 variables: .....
>
>
> # make this much bigger
> gLarge <- ceiling(10^8/26)
>
> dL <- mkDf(gLarge) # works "fine" .. (well, takes time!!)
> str(dL)
> ## 'data.frame': 100000004 obs. of  2 variables:
> as.numeric(print(object.size(dL)) / 1e6)
> ## 1600002088 bytes
> ## [1] 1600.002  Mega  i.e.,  1.6 GBytes
>
> ## Well, this will be 26 times larger than already large ==> your R may
> crash *OR*
>  ## your computer may basically slow down to a crawl, when R requests all
> its memory...
> if(FALSE) ## ==> do *NOT* evaluate the following lightly !!
> dLL <- mkDf(gLarge, wrong=TRUE)
> # CONSOLE CRASH WITHOUT EXPLANATION
> # C:\Users\AnthonyD>
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sun May 29 10:00:21 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 29 May 2016 18:00:21 +1000
Subject: [R] colored table
In-Reply-To: <CY1PR07MB2588649657A578FE4E6A6BE8FA430@CY1PR07MB2588.namprd07.prod.outlook.com>
References: <CY1PR07MB2588649657A578FE4E6A6BE8FA430@CY1PR07MB2588.namprd07.prod.outlook.com>
Message-ID: <CA+8X3fWSc6ZXrDEAd7_2VWRucRa=aj1GZqsjG6RDTBGAaUFc3g@mail.gmail.com>

Hi Naresh,
Have a look a the addtable2plot function (plotrix), especially the
second example, and the color.scale function, also in plotrix.

Jim


On Sat, May 28, 2016 at 11:10 PM, Naresh Gurbuxani
<naresh_gurbuxani at hotmail.com> wrote:
> I want to print a table where table elements are colored according to the frequency of the bin.  For example, consider below table.
>
> Function values that I would like to print in the table
>
>                             x.eq.minus1  x.eq.zero  x.eq.plus1
> y.eq.minus1             -20                 10            -5
> y.eq.zero                 -10                  6             22
> y.eq.plus1                -8                    10           -14
>
>
> Frequency table to color the above table
>
>                             x.eq.minus1  x.eq.zero  x.eq.plus1
> y.eq.minus1             0.05             0.15           0.1
> y.eq.zero                 0.07             0.3           0.08
> y.eq.plus1                0.05            0.15           0.05
>
>
> In the resulting table, the element for (x = 0, y = 0) will be 6.  This will be printed with a dark color background.  The element for (x = -1, y = -1) will be -20.  This will be printed with a light color background.  And so on.
>
> Thanks for your help,
> Naresh
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From maillists at pp.inet.fi  Sun May 29 10:30:29 2016
From: maillists at pp.inet.fi (K. Elo)
Date: Sun, 29 May 2016 11:30:29 +0300
Subject: [R] Scale y-labels based on a value with 'lattice'
In-Reply-To: <000001d1b7db$c67481a0$535d84e0$@bigpond.com>
References: <bf9a8711-f098-cf66-6cfd-55b3bee9e9c7@pp.inet.fi>
	<000001d1b7db$c67481a0$535d84e0$@bigpond.com>
Message-ID: <f7795dc5-a7bb-2e18-78d3-cca5fc6c5b1f@pp.inet.fi>

Hi!

Many thanks to Duncan and Jim for their quick replies.

27.05.2016, 01:08, Jim Lemon wrote:
> Hi Kimmo,
> par(mar=c(5,7,4,2))
> dotchart(kedf$x)
> mtext(kedf$Group.2,side=2,at=1:6,line=0.5,
>  las=2,cex=log(abs(kedf$Freq))+1)
>
> Jim

This 'dotchart' solution worked fine and I got what I wanted :) However, 
I still wonder why the same idea does not work with lattice (e.g. using 
'scales=list(y=list(cex=log(abs(kedf$Freq))+1))'

27.05.2016, 08:51, Duncan Mackay wrote:
> Hi
>
> If you want to change the cex of the labels see
>
> library(lattice)
>  ?yscale.components.default

Seem a bit more complex, but I'll give it a try.

> Possibly an easier way is to size the symbols
>
> I will use Jims data.frame to plot with lattice
> dotplot(Group.2 ~ x, data = kedf,
>                  scales = list(y = list(labels = kedf[,"Group2"], cex = = kedf[,"Freq"])))
> [...}
> Regards
>
> Duncan

This is also a nice idea to scale the dots. Thanks for pointing this out.

Best,
Kimmo


From pd.mes at cbs.dk  Sun May 29 12:02:01 2016
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Sun, 29 May 2016 10:02:01 +0000
Subject: [R]  Release of R 3.3.1 scheduled for June 21
Message-ID: <C77C111C-EBCC-4CBE-B89D-E5C10D65E847@cbs.dk>

We intend to have a patch release on June 21, nickname will be "Bug in Your Hair". The detailed schedule will be made available via developer.r-project.org as usual.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From khadija.shakeel10 at gmail.com  Sun May 29 09:20:13 2016
From: khadija.shakeel10 at gmail.com (Khadija Shakeel)
Date: Sun, 29 May 2016 12:20:13 +0500
Subject: [R] Query about Text Preprocessing (Encoding)
Message-ID: <CADFbrKpQz=EaVDYdzGy9_0J1R6QkM8_GW1_WZNLsBG4PXiaMyg@mail.gmail.com>

i want to work with Urdu language but R is only displaying Urdu text but
cant work with Urdu text. Actually I want to apply preproessing steps of
text mining. but R is nor responding for this text.
Help me how can I handle this problem?

here are some pictures of word cloud of Urdu text.

-- 
Khadija Shakeel
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Cloud.PNG
Type: image/png
Size: 8455 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160529/930a0413/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: CLUSTPLOT_as.matrix_d.PNG
Type: image/png
Size: 24780 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160529/930a0413/attachment-0001.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: wordCloud.PNG
Type: image/png
Size: 6824 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160529/930a0413/attachment-0002.png>

From murdoch.duncan at gmail.com  Sun May 29 16:45:53 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 29 May 2016 10:45:53 -0400
Subject: [R] Query about Text Preprocessing (Encoding)
In-Reply-To: <CADFbrKpQz=EaVDYdzGy9_0J1R6QkM8_GW1_WZNLsBG4PXiaMyg@mail.gmail.com>
References: <CADFbrKpQz=EaVDYdzGy9_0J1R6QkM8_GW1_WZNLsBG4PXiaMyg@mail.gmail.com>
Message-ID: <a346979f-22ef-29b1-38d3-d688872c1df3@gmail.com>

On 29/05/2016 3:20 AM, Khadija Shakeel wrote:
> i want to work with Urdu language but R is only displaying Urdu text but
> cant work with Urdu text. Actually I want to apply preproessing steps of
> text mining. but R is nor responding for this text.
> Help me how can I handle this problem?
>
> here are some pictures of word cloud of Urdu text.
>

R doesn't currently have a translation team (see 
translation.r-project.org) for Urdu, so it may be hard for you to get 
Urdu-specific support.  However, I would guess the problems you are 
having are common to other languages that use non-Roman alphabets, and 
you may get some advice from the translation teams for one of them.

The general issues that I know of are:

  - R needs to know your encoding.  On Unix-alikes the best support is 
for UTF-8; Windows support is weaker, because Windows tends to use 
UTF-16 or other multibyte encodings, and R's support for those is mixed.

  - You need to make sure your graphics device supports your alphabet. 
Not all graphics devices have character support for all languages.

Duncan Murdoch


From friendly at yorku.ca  Sun May 29 17:01:14 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Sun, 29 May 2016 11:01:14 -0400
Subject: [R] colored table
In-Reply-To: <CY1PR07MB2588649657A578FE4E6A6BE8FA430@CY1PR07MB2588.namprd07.prod.outlook.com>
References: <CY1PR07MB2588649657A578FE4E6A6BE8FA430@CY1PR07MB2588.namprd07.prod.outlook.com>
Message-ID: <b6832b6f-9a38-109e-6230-c6081a3accf5@yorku.ca>

Hi Naresh

If you want to make a graphic of the table, with the frequencies printed 
in the cells try a mosaic plot from the vcd package

library(vcd)
mosaic(HairEyeColor[,,1], shade = TRUE, legend=FALSE, 
labeling=labeling_values)

or to make cell sizes proportional to expected frequencies,

mosaic(HairEyeColor[,,1], shade = TRUE, legend=FALSE, 
labeling=labeling_values, type="expected")

You can also use ggplot2::geom_tile() for something that is a more 
direct version of a table or a heatmap, with shaded backgrounds, and 
geom_text()
to print the values.

 From an non-reproducible example of mine, where cells are filled
with a unidimensional range of colors from white to blue, and
the text is printed in black, until the background gets too dark:

p <- ggplot(ht2, aes(decade, variable)) +
       geom_tile(aes(fill = Freq), color = "white") +
       scale_fill_gradient(low = "white", high = "blue") +
       geom_text(aes(fill = Freq, label = Freq),
                 colour = ifelse(ht2$Freq > 40, "white", "black")) +
       labs(title = "Keyword Occurrences by Topic and Year",
            x = "Decade", y = "Keyword")

In contrast to what someone else expressed, for some purposes --- where 
you want to show the _pattern_ of values in a table directly, colored 
backgrounds, if done judiciously can be extremely useful to show the 
viewer what is important.

-Michael

On 5/28/2016 9:10 AM, Naresh Gurbuxani wrote:
> I want to print a table where table elements are colored according to the frequency of the bin.  For example, consider below table.
>
> Function values that I would like to print in the table
>
>                             x.eq.minus1  x.eq.zero  x.eq.plus1
> y.eq.minus1             -20                 10            -5
> y.eq.zero                 -10                  6             22
> y.eq.plus1                -8                    10           -14
>
>
> Frequency table to color the above table
>
>                             x.eq.minus1  x.eq.zero  x.eq.plus1
> y.eq.minus1             0.05             0.15           0.1
> y.eq.zero                 0.07             0.3           0.08
> y.eq.plus1                0.05            0.15           0.05
>
>
> In the resulting table, the element for (x = 0, y = 0) will be 6.  This will be printed with a dark color background.  The element for (x = -1, y = -1) will be -20.  This will be printed with a light color background.  And so on.
>
> Thanks for your help,
> Naresh
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From lists at dewey.myzen.co.uk  Sun May 29 17:33:57 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Sun, 29 May 2016 16:33:57 +0100
Subject: [R] Urdu text problems,
 was Re:  Query about Text Preprocessing (Encoding)
In-Reply-To: <CADFbrKpQz=EaVDYdzGy9_0J1R6QkM8_GW1_WZNLsBG4PXiaMyg@mail.gmail.com>
References: <CADFbrKpQz=EaVDYdzGy9_0J1R6QkM8_GW1_WZNLsBG4PXiaMyg@mail.gmail.com>
Message-ID: <74a124ba-d3fd-2791-f748-0d56ccfd6cdc@dewey.myzen.co.uk>

Would it be a good idea to mention Urdu in the subject line as other 
people who deal with Urdu, but not specifically text mining, may be able 
to help? I have added it to my reply

On 29/05/2016 08:20, Khadija Shakeel wrote:
> i want to work with Urdu language but R is only displaying Urdu text but
> cant work with Urdu text. Actually I want to apply preproessing steps of
> text mining. but R is nor responding for this text.
> Help me how can I handle this problem?
>
> here are some pictures of word cloud of Urdu text.
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From tr206 at kent.ac.uk  Sun May 29 19:48:07 2016
From: tr206 at kent.ac.uk (T.Riedle)
Date: Sun, 29 May 2016 17:48:07 +0000
Subject: [R] zelig package: robust SE
Message-ID: <8c76c3349731445dba5ba8feca07daf1@ex13-live-mbn1.ad.kent.ac.uk>

Dear R users,

I am trying to run a logistic regression using zelig. The simple logistic regression works well but now I want to have HAC robust standard errors. I have read in the manual that there is an option called "robust" and that zelig() computes robust SE via the sandwich package. However, it doesn't work. My code looks as follows:


crisis_bubble4<-zelig(stock.market.crash~crash.MA+bubble.MA+MP.MA<http://mp.ma/>+UTS.MA<http://uts.ma/>+UPR.MA<http://upr.ma/>+PPI.MA<http://ppi.ma/>+RV.MA<http://rv.ma/>,robust=TRUE,model="logit",data=Data_logitregression_movingaverage)

Error in glm.control(robust = TRUE) : unused argument (robust = TRUE)



I took this code from the zelig manual and don't understand why I get an error. What is more, I want to calculate NeweyWest SE or the SE using the weights by Andrews via the kernHAC function. How can I do that?

Thanks for your support.

Kind regards

	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Sun May 29 21:23:33 2016
From: hannah.hlx at gmail.com (li li)
Date: Sun, 29 May 2016 15:23:33 -0400
Subject: [R] model specification using lme
Message-ID: <CAHLnndYK-UEt84Mb9Rncm_Q1aTOX8EzttfE-Jt1JGN0dg0MMDg@mail.gmail.com>

Hi all,
  For the following data, I consider the following random intercept and
random slope model. Denote as y_ijk the response value from *j*th
individual within *i*th method at time point *k*. Assume the following
model for y_ijk:

      y_ijk= (alpha_0+ tau_i +a_j(i))+(beta_i+b_j(i)) T_k + e_ijk


Here alpha_0 is the grand mean;
          tau_i is the fixed effect for ith method;
          a_j(i) is random intercept corresponding to the *j*th individual
within *i*th method, assumed to be common for all three methods;
          beta_i is the fixed slope corresponding to the ith method;
          b_j(i) is the random slope corresponding to jth individual for
the ith method, assumed to be different for different methods;
          T_k is the time corresponding to y_ijk;
          e_ijk is the residual.

For this model, I consider the three specification using  the lme function
as follows:


mod1 <- lme(fixed= reponse ~ method*time, random=~ 1 +time | individual,
data=one, weights= varIdent(form=~1|method),
            control = lmeControl(opt = "optim"))

mod2 <- lme(fixed= reponse ~ method*time, random=~ 0 +time | individual,
data=one, weights= varIdent(form=~1|method),
            control = lmeControl(opt = "optim"))

mod3 <- lme(fixed= reponse ~ method*time, random=~ method +time |
individual, data=one, weights= varIdent(form=~1|method),
            control = lmeControl(opt = "optim"))

I think mod1 is the correct one. However, I am kind of confused with the
right usage of lme function. Can someone familiar with this give some help
here?

Another question is regarding the fixed effect   tau_1, tau_2 and tau_3
(corresponding to the three methods). One main question I am interested in
is whether each of them are statistically different from zero. In the
summary results below (shaded part), it looks that the result for method 2
and 3 are given with reference to method 1). Is there a way to obtain
specific result separately for alpha_0 (the overall mean) and also tau_1,
tau_2 and tau3?

Thanks very much for the help!
   Hanna

> summary(mod1)Linear mixed-effects model fit by REML
 Data: one
       AIC      BIC    logLik
  304.4703 330.1879 -140.2352

Random effects:
 Formula: ~1 + time | individual
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev       Corr
(Intercept) 0.2487869075 (Intr)
time        0.0001841179 -0.056
Residual    0.3718305953

Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | method
 Parameter estimates:
       3        1        2
 1.00000 26.59750 24.74476
Fixed effects: reponse ~ method * time
                Value Std.Error DF   t-value p-value(Intercept)
96.65395  3.528586 57 27.391694  0.0000
method2       1.17851  4.856026 57  0.242689  0.8091
method3       5.87505  3.528617 57  1.664973  0.1014time
0.07010  0.250983 57  0.279301  0.7810
method2:time -0.12616  0.360585 57 -0.349877  0.7277
method3:time -0.08010  0.251105 57 -0.318999  0.7509
 Correlation:
             (Intr) methd2 methd3 time   mthd2:
method2      -0.726
method3      -0.999  0.726
time         -0.779  0.566  0.779
method2:time  0.542 -0.712 -0.542 -0.696
method3:time  0.778 -0.566 -0.779 -0.999  0.696

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max
-2.67575293 -0.51633192  0.06742723  0.59706762  2.81061874

Number of Observations: 69
Number of Groups: 7 >





> one   response individual time method
1    102.9          3    0      3
2    103.0          3    3      3
3    103.0          3    6      3
4    102.8          3    9      3
5    102.2          3   12      3
6    102.5          3   15      3
7    103.0          3   18      3
8    102.0          3   24      3
9    102.8          1    0      3
10   102.7          1    3      3
11   103.0          1    6      3
12   102.2          1    9      3
13   103.0          1   12      3
14   102.8          1   15      3
15   102.8          1   18      3
16   102.9          1   24      3
17   102.2          2    0      3
18   102.6          2    3      3
19   103.4          2    6      3
20   102.3          2    9      3
21   101.3          2   12      3
22   102.1          2   15      3
23   102.1          2   18      3
24   102.2          2   24      3
25   102.7          4    0      3
26   102.3          4    3      3
27   102.6          4    6      3
28   102.7          4    9      3
29   102.8          4   12      3
30   102.5          5    0      3
31   102.4          5    3      3
32   102.1          5    6      3
33   102.3          6    0      3
34   102.3          6    3      3
35   101.9          7    0      3
36   102.0          7    3      3
37   107.4          3    0      1
38   101.3          3   12      1
39    92.8          3   15      1
40    73.7          3   18      1
41   104.7          3   24      1
42    92.6          1    0      1
43   101.9          1   12      1
44   106.3          1   15      1
45   104.1          1   18      1
46    95.6          1   24      1
47    79.8          2    0      1
48    89.7          2   12      1
49    97.0          2   15      1
50   108.4          2   18      1
51   103.5          2   24      1
52    96.4          4    0      1
53    89.3          4   12      1
54   112.6          5    0      1
55    93.3          6    0      1
56    99.6          7    0      1
57   109.5          3    0      2
58    98.5          3   12      2
59   103.5          3   24      2
60   113.5          1    0      2
61    94.5          1   12      2
62    88.5          1   24      2
63    99.5          2    0      2
64    97.5          2   12      2
65    98.5          2   24      2
66   103.5          4    0      2
67    89.5          5    0      2
68    87.5          6    0      2
69    82.5          7    0      2

	[[alternative HTML version deleted]]


From Achim.Zeileis at uibk.ac.at  Sun May 29 21:34:57 2016
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Sun, 29 May 2016 21:34:57 +0200 (CEST)
Subject: [R] zelig package: robust SE
In-Reply-To: <8c76c3349731445dba5ba8feca07daf1@ex13-live-mbn1.ad.kent.ac.uk>
References: <8c76c3349731445dba5ba8feca07daf1@ex13-live-mbn1.ad.kent.ac.uk>
Message-ID: <alpine.DEB.2.20.1605292117280.791@paninaro>

On Sun, 29 May 2016, T.Riedle wrote:

> Dear R users,
>
> I am trying to run a logistic regression using zelig. The simple 
> logistic regression works well but now I want to have HAC robust 
> standard errors. I have read in the manual that there is an option 
> called "robust" and that zelig() computes robust SE via the sandwich 
> package. However, it doesn't work. My code looks as follows:
>
> crisis_bubble4<-zelig(stock.market.crash~crash.MA+bubble.MA+MP.MA+UTS.MA+UPR.MA+PPI.MA+RV.MA<http://rv.ma/>,robust=TRUE,model="logit",data=Data_logitregression_movingaverage)
>
> Error in glm.control(robust = TRUE) : unused argument (robust = TRUE)

Possibly this changed in recent versions of "Zelig". The documentation 
for relogit on the official Zelig web page shows the same error:
http://docs.zeligproject.org/en/latest/zelig-relogit.html#example-2-one-tau-with-weighting-robust-standard-errors-and-bias-correction

In any case, Zelig only interfaced the so-called "robust" standard errors 
(sandwich or HC0) and not the ones with HAC correction.

> I took this code from the zelig manual and don't understand why I get an 
> error. What is more, I want to calculate NeweyWest SE or the SE using 
> the weights by Andrews via the kernHAC function. How can I do that?

Why do you want to use Zelig? Apparently, the solution using plain glm() 
along with the sandwich package and coeftest() did work for you. And in my 
other e-mail I showed you how you can use lrm().

> Thanks for your support.
>
> Kind regards
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Sun May 29 22:07:47 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 29 May 2016 13:07:47 -0700
Subject: [R] Fitting quantile (or cdf?) function to data with specified
	percentiles
In-Reply-To: <COL125-W15DB9E7C88C717CDDF5B0AF420@phx.gbl>
References: <COL125-W15DB9E7C88C717CDDF5B0AF420@phx.gbl>
Message-ID: <30DFE357-9DF8-4268-A100-13D91ED964D4@comcast.net>


> On May 26, 2016, at 7:51 PM, Franco Danilo Roca Landaveri <fradarola at hotmail.com> wrote:
> 
> Hello,
> 
> I hope you can help me. In class, we were given an Excel worksheet with specified formulas that take the total score from a survey (or from a specific section) and convert it to a percentage, according to a table that assigns scores to a percentile. Since the formulas are too long and complicated (some have been input by hand) I figured we could fit the data with a function with some parameters. I plotted the table and sure it resembled a more-or-less symmetrical quantile function, and I wanted to use R to find a curve that fitted the data. Here it is:
> 
> percentile <- c(0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.05, 0.05, 0.05,
> 0.05, 0.05, 0.10, 0.10, 0.15, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50,
> 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.90, 0.95, 0.95, 0.99, 0.99, 0.99, 0.99,
> 0.99, 0.99, 0.99, 0.99, 0.99)
> 
> score <- c(10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,
> 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44,
> 45, 46, 47, 48, 49, 50)
> 

Use approxfun:

myapprox <- approxfun( x=score, y=percentile)

> myapprox(27.8)
[1] 0.29

> myapprox(27.8)
[1] 0.29

> myapprox(50)
[1] 0.99
> myapprox(51)
[1] NA

You can change how values outside the max and min limits are handles with furhter arguments to approxfun.

? 
David.


> I looked up the quantreg package, but I didn't know how to use it properly since I don't have the raw data, only the percentiles, and also because what I'm trying to get is the percentile based on the score, not the other way around. Then I tried to fit it using a sigmoid curve (similar to a cdf), using the following code:
> 
> require(drc)
> model1 <- drm(percentile ~ score, fct = LL.4())
> summary(model1)
> 
> But I found another problem, the fitted curve apparently went over 1 on the y axis, something not possible for a cdf. I'd like to know what would be the most appropiate way to do this, and also if it is possible to fit a quantile function with this data, apart from the cdf.
> 
> Thank you very much for your help
> 		 	   		  
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From w1malik at hotmail.com  Sun May 29 20:39:18 2016
From: w1malik at hotmail.com (Waseem Ali)
Date: Sun, 29 May 2016 23:39:18 +0500
Subject: [R] How to real multiple raster and serial correlation between
 series of rasters
Message-ID: <SNT151-W95DFBC94C5A64DB9BCC09DEB440@phx.gbl>




Hi,
I have 120 raster (10 years) files
in tif format of one variable (say X1) and same numbers for second variables (Say
X2). Each raster consists the mean monthly values of corresponding variables. I
want to write a script in R which operates the following operations:

?        
First reads the one by one
raster from folder and save into the objects. 

?        
Resample/aggregate the both
raster over same spatial resolution 2? x 2.5?.

?        
After resampling the all
raster over same resolution, conversions of all raster to points by using the
rasterToPoint() function of raster library.

?        
After retrieving the same
monthly raster values (like month of January for X1 and X2) into data frame, I
want to compute regression and correlation values for all 120 raster for both
variables (X1 and X2) and save into the data frame.

Is there any way out to deal with
such task.


library(raster)

x <- list.files("C:/site-download/",
pattern = "*.tif", full.names = TRUE)

x1 <- raster(x1)

p <- as(x1, 'SpatialPixels')

plot(x1)

points(p)
Resultant figure has been attached for you for only x1 variable. I have also attached the X1 and X2 variable tif raster for January 2002 for computation purpose. I need to operate it through loop for reading all these rasters and computing the correlation of each pairs. My next step to compute the Lag -1 correlations which is Serial Correlation for both variables.
Waseem Ali 
 		 	   		  

From bbolker at gmail.com  Sun May 29 23:01:30 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 29 May 2016 21:01:30 +0000
Subject: [R] model specification using lme
References: <CAHLnndYK-UEt84Mb9Rncm_Q1aTOX8EzttfE-Jt1JGN0dg0MMDg@mail.gmail.com>
Message-ID: <loom.20160529T230022-765@post.gmane.org>

li li <hannah.hlx <at> gmail.com> writes:

> 
> Hi all,
>   For the following data, I consider the following random intercept and
> random slope model. Denote as y_ijk the response value from *j*th
> individual within *i*th method at time point *k*. Assume the following
> model for y_ijk:
> 
>       y_ijk= (alpha_0+ tau_i +a_j(i))+(beta_i+b_j(i)) T_k + e_ijk
> 

  If someone answers here, that's great, but I'm guessing that you
will have better luck re-posting this to r-sig-mixed-models at r-project.org
(maybe wait a day or so before re-posting, and when you do, mention that 
you're reposting)

  cheers
    Ben Bolker


From tal.galili at gmail.com  Mon May 30 09:05:14 2016
From: tal.galili at gmail.com (Tal Galili)
Date: Mon, 30 May 2016 10:05:14 +0300
Subject: [R] colored table
In-Reply-To: <CY1PR07MB2588649657A578FE4E6A6BE8FA430@CY1PR07MB2588.namprd07.prod.outlook.com>
References: <CY1PR07MB2588649657A578FE4E6A6BE8FA430@CY1PR07MB2588.namprd07.prod.outlook.com>
Message-ID: <CANdJ3dXCL2J4EX1yae+6pLCXHqF5JZ77FmHh7tf_of96GVvCYQ@mail.gmail.com>

Hell Naresh,

If to add to what others already wrote, there is also the new {heatmaply
<https://cran.r-project.org/web/packages/heatmaply/>} package, which enable
you to create *interactive* heatmaps. For examples, you can view the
vignette here:
https://cran.r-project.org/web/packages/heatmaply/vignettes/heatmaply.html

With regards,
Tal




----------------Contact
Details:-------------------------------------------------------
Contact me: Tal.Galili at gmail.com |
Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
www.r-statistics.com (English)
----------------------------------------------------------------------------------------------


On Sat, May 28, 2016 at 4:10 PM, Naresh Gurbuxani <
naresh_gurbuxani at hotmail.com> wrote:

> I want to print a table where table elements are colored according to the
> frequency of the bin.  For example, consider below table.
>
> Function values that I would like to print in the table
>
>                             x.eq.minus1  x.eq.zero  x.eq.plus1
> y.eq.minus1             -20                 10            -5
> y.eq.zero                 -10                  6             22
> y.eq.plus1                -8                    10           -14
>
>
> Frequency table to color the above table
>
>                             x.eq.minus1  x.eq.zero  x.eq.plus1
> y.eq.minus1             0.05             0.15           0.1
> y.eq.zero                 0.07             0.3           0.08
> y.eq.plus1                0.05            0.15           0.05
>
>
> In the resulting table, the element for (x = 0, y = 0) will be 6.  This
> will be printed with a dark color background.  The element for (x = -1, y =
> -1) will be -20.  This will be printed with a light color background.  And
> so on.
>
> Thanks for your help,
> Naresh
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon May 30 10:40:14 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 30 May 2016 10:40:14 +0200
Subject: [R] model specification using lme
In-Reply-To: <CAHLnndYK-UEt84Mb9Rncm_Q1aTOX8EzttfE-Jt1JGN0dg0MMDg@mail.gmail.com>
References: <CAHLnndYK-UEt84Mb9Rncm_Q1aTOX8EzttfE-Jt1JGN0dg0MMDg@mail.gmail.com>
Message-ID: <CAJuCY5wMrELKbj+SY7MeAz+qV=-Ya8GRiNRDMSV2dPr_5WJSMg@mail.gmail.com>

Dear Hanna,

None of the models are correct is you want the same random intercept for
the different methods but different random slope per method.

You can random = ~ 1 + time:method | individual

The easiest way to get alpha_0 and tau_i is to apply post-hoc contrasts.
That is fairly easy to do with the multcomp package.

alpha_0 = (m1 + m2 + m3) / 3
m1 = intercept
m2 = intercept + method2
m3 = intercept + method3
hence alpha_0 = intercept + method2/3 + method3/3

m1 = alpha_0 + tau_1
tau_1 = intercept - method2/3 - method3/3

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-05-29 21:23 GMT+02:00 li li <hannah.hlx at gmail.com>:

> Hi all,
>   For the following data, I consider the following random intercept and
> random slope model. Denote as y_ijk the response value from *j*th
> individual within *i*th method at time point *k*. Assume the following
> model for y_ijk:
>
>       y_ijk= (alpha_0+ tau_i +a_j(i))+(beta_i+b_j(i)) T_k + e_ijk
>
>
> Here alpha_0 is the grand mean;
>           tau_i is the fixed effect for ith method;
>           a_j(i) is random intercept corresponding to the *j*th individual
> within *i*th method, assumed to be common for all three methods;
>           beta_i is the fixed slope corresponding to the ith method;
>           b_j(i) is the random slope corresponding to jth individual for
> the ith method, assumed to be different for different methods;
>           T_k is the time corresponding to y_ijk;
>           e_ijk is the residual.
>
> For this model, I consider the three specification using  the lme function
> as follows:
>
>
> mod1 <- lme(fixed= reponse ~ method*time, random=~ 1 +time | individual,
> data=one, weights= varIdent(form=~1|method),
>             control = lmeControl(opt = "optim"))
>
> mod2 <- lme(fixed= reponse ~ method*time, random=~ 0 +time | individual,
> data=one, weights= varIdent(form=~1|method),
>             control = lmeControl(opt = "optim"))
>
> mod3 <- lme(fixed= reponse ~ method*time, random=~ method +time |
> individual, data=one, weights= varIdent(form=~1|method),
>             control = lmeControl(opt = "optim"))
>
> I think mod1 is the correct one. However, I am kind of confused with the
> right usage of lme function. Can someone familiar with this give some help
> here?
>
> Another question is regarding the fixed effect   tau_1, tau_2 and tau_3
> (corresponding to the three methods). One main question I am interested in
> is whether each of them are statistically different from zero. In the
> summary results below (shaded part), it looks that the result for method 2
> and 3 are given with reference to method 1). Is there a way to obtain
> specific result separately for alpha_0 (the overall mean) and also tau_1,
> tau_2 and tau3?
>
> Thanks very much for the help!
>    Hanna
>
> > summary(mod1)Linear mixed-effects model fit by REML
>  Data: one
>        AIC      BIC    logLik
>   304.4703 330.1879 -140.2352
>
> Random effects:
>  Formula: ~1 + time | individual
>  Structure: General positive-definite, Log-Cholesky parametrization
>             StdDev       Corr
> (Intercept) 0.2487869075 (Intr)
> time        0.0001841179 -0.056
> Residual    0.3718305953
>
> Variance function:
>  Structure: Different standard deviations per stratum
>  Formula: ~1 | method
>  Parameter estimates:
>        3        1        2
>  1.00000 26.59750 24.74476
> Fixed effects: reponse ~ method * time
>                 Value Std.Error DF   t-value p-value(Intercept)
> 96.65395  3.528586 57 27.391694  0.0000
> method2       1.17851  4.856026 57  0.242689  0.8091
> method3       5.87505  3.528617 57  1.664973  0.1014time
> 0.07010  0.250983 57  0.279301  0.7810
> method2:time -0.12616  0.360585 57 -0.349877  0.7277
> method3:time -0.08010  0.251105 57 -0.318999  0.7509
>  Correlation:
>              (Intr) methd2 methd3 time   mthd2:
> method2      -0.726
> method3      -0.999  0.726
> time         -0.779  0.566  0.779
> method2:time  0.542 -0.712 -0.542 -0.696
> method3:time  0.778 -0.566 -0.779 -0.999  0.696
>
> Standardized Within-Group Residuals:
>         Min          Q1         Med          Q3         Max
> -2.67575293 -0.51633192  0.06742723  0.59706762  2.81061874
>
> Number of Observations: 69
> Number of Groups: 7 >
>
>
>
>
>
> > one   response individual time method
> 1    102.9          3    0      3
> 2    103.0          3    3      3
> 3    103.0          3    6      3
> 4    102.8          3    9      3
> 5    102.2          3   12      3
> 6    102.5          3   15      3
> 7    103.0          3   18      3
> 8    102.0          3   24      3
> 9    102.8          1    0      3
> 10   102.7          1    3      3
> 11   103.0          1    6      3
> 12   102.2          1    9      3
> 13   103.0          1   12      3
> 14   102.8          1   15      3
> 15   102.8          1   18      3
> 16   102.9          1   24      3
> 17   102.2          2    0      3
> 18   102.6          2    3      3
> 19   103.4          2    6      3
> 20   102.3          2    9      3
> 21   101.3          2   12      3
> 22   102.1          2   15      3
> 23   102.1          2   18      3
> 24   102.2          2   24      3
> 25   102.7          4    0      3
> 26   102.3          4    3      3
> 27   102.6          4    6      3
> 28   102.7          4    9      3
> 29   102.8          4   12      3
> 30   102.5          5    0      3
> 31   102.4          5    3      3
> 32   102.1          5    6      3
> 33   102.3          6    0      3
> 34   102.3          6    3      3
> 35   101.9          7    0      3
> 36   102.0          7    3      3
> 37   107.4          3    0      1
> 38   101.3          3   12      1
> 39    92.8          3   15      1
> 40    73.7          3   18      1
> 41   104.7          3   24      1
> 42    92.6          1    0      1
> 43   101.9          1   12      1
> 44   106.3          1   15      1
> 45   104.1          1   18      1
> 46    95.6          1   24      1
> 47    79.8          2    0      1
> 48    89.7          2   12      1
> 49    97.0          2   15      1
> 50   108.4          2   18      1
> 51   103.5          2   24      1
> 52    96.4          4    0      1
> 53    89.3          4   12      1
> 54   112.6          5    0      1
> 55    93.3          6    0      1
> 56    99.6          7    0      1
> 57   109.5          3    0      2
> 58    98.5          3   12      2
> 59   103.5          3   24      2
> 60   113.5          1    0      2
> 61    94.5          1   12      2
> 62    88.5          1   24      2
> 63    99.5          2    0      2
> 64    97.5          2   12      2
> 65    98.5          2   24      2
> 66   103.5          4    0      2
> 67    89.5          5    0      2
> 68    87.5          6    0      2
> 69    82.5          7    0      2
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Mark.Fowler at dfo-mpo.gc.ca  Mon May 30 14:51:54 2016
From: Mark.Fowler at dfo-mpo.gc.ca (Fowler, Mark)
Date: Mon, 30 May 2016 12:51:54 +0000
Subject: [R] email threads chronology
Message-ID: <88388BFE50A61F408122CBAEB917FD5736827C1A@SVNSBIOMBX02.ENT.dfo-mpo.ca>

Hi all,

I'm seeing the natural sequencing of email threads getting corrupted. For example, a May 26 thread on subject 'Shaded areas in R' would have been initiated by an email at 6:58am. However I did not get that email until 1:48pm, preceded by 3 replies to the post. Trivial but irritating. The preceding replies suggest this is something going on at my end, perhaps related to network security. I'm curious what might be causing it, and if there is something I can do about it - short of contacting IT staff, which is more irritating than the corrupted threads.

Mark Fowler
Population Ecology Division
Bedford Inst of Oceanography
Dept Fisheries & Oceans
Dartmouth NS Canada
B2Y 4A2
Tel. (902) 426-3529
Fax (902) 426-9710
Email Mark.Fowler at dfo-mpo.gc.ca<mailto:Mark.Fowler at dfo-mpo.gc.ca>



	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon May 30 17:58:46 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 30 May 2016 08:58:46 -0700
Subject: [R] email threads chronology
In-Reply-To: <88388BFE50A61F408122CBAEB917FD5736827C1A@SVNSBIOMBX02.ENT.dfo-mpo.ca>
References: <88388BFE50A61F408122CBAEB917FD5736827C1A@SVNSBIOMBX02.ENT.dfo-mpo.ca>
Message-ID: <CAGxFJbQP8jW+FAtM+Wu2z2dT4N1sXH8QST_exVcXdWgG9Z+XZQ@mail.gmail.com>

Inline:

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, May 30, 2016 at 5:51 AM, Fowler, Mark <Mark.Fowler at dfo-mpo.gc.ca> wrote:
...
"The preceding replies suggest this is something going on at my end,
perhaps related to network security. I'm curious what might be causing
it, and if there is something I can do about it - short of contacting
IT staff, which is more irritating than the corrupted threads."

Semi-Fortune!? This is probably not quite suitable for the fortunes
package, but I still think it's clever.

Best,
Bert


>
> Mark Fowler
> Population Ecology Division
> Bedford Inst of Oceanography
> Dept Fisheries & Oceans
> Dartmouth NS Canada
> B2Y 4A2
> Tel. (902) 426-3529
> Fax (902) 426-9710
> Email Mark.Fowler at dfo-mpo.gc.ca<mailto:Mark.Fowler at dfo-mpo.gc.ca>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From leonardof at leonardof.med.br  Mon May 30 19:50:48 2016
From: leonardof at leonardof.med.br (Leonardo Ferreira Fontenelle)
Date: Mon, 30 May 2016 14:50:48 -0300
Subject: [R] How to replace all commas with semicolon in a string
In-Reply-To: <CAMCXXmq2xGj=AiaFs3M1ABnN3Dg9r53XgbaZuPG=XuaaBv37fw@mail.gmail.com>
References: <CAMCXXmq2xGj=AiaFs3M1ABnN3Dg9r53XgbaZuPG=XuaaBv37fw@mail.gmail.com>
Message-ID: <1464630648.788955.622837161.0D2E3EE4@webmail.messagingengine.com>

Em Sex 27 mai. 2016, ?s 12:10, Jun Shen escreveu:
> Dear list,
> 
> Say I have a data frame
> 
> test <- data.frame(C1=c('a,b,c,d'),C2=c('g,h,f'))
> 
> I want to replace the commas with semicolons
> 
> sub(',',';',test$C1) -> test$C1 will only replace the first comma of a
> string.
> 
> How do I replace them all in one run? Thanks.

If it's a CSV, you may read the file and then write it again (second
file name, for safety) with write.csv2.

HTH,

Leonardo Ferreira Fontenelle, MD, MPH
PhD candidate in epidemiology, Federal University of Pelotas
Professor of medicine, Vila Velha University
Legislative consultant in health, Municipal Chamber of Vit?ria


From suttoncarl at ymail.com  Mon May 30 20:38:46 2016
From: suttoncarl at ymail.com (Carl Sutton)
Date: Mon, 30 May 2016 18:38:46 +0000 (UTC)
Subject: [R] matrix indexing/subset error
References: <1788267112.1856982.1464633526404.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1788267112.1856982.1464633526404.JavaMail.yahoo@mail.yahoo.com>

Hi Guru's
In my quest to understand R I have what I thought was a simple exercise that now has me baffled.? Why the error message after running this code?? I am totally baffled by the error message.? I was expecting rows 1 and 3 of the x matrix to be returned, and have not a clue as to why this becomes a subscript difficulty.? The manual was of no help in this matter.

x <- c(1:3,2:4)
x? <- matrix(x, nrow = 3)
x
z <- c(1:4,1,1,0,0,1,0,1,0)
z <- matrix(z, ncol = 3)
z
x[x[,2]>= 3,]
x
z %% 2 == 1
x[z %% 2 == 1,]Error in x[z%%2 == 1, ] : (subscript) logical subscript too long
Many thanks for your assistance.
Carl Sutton CPA

	[[alternative HTML version deleted]]


From bran.chri at gmail.com  Mon May 30 21:23:36 2016
From: bran.chri at gmail.com (=?UTF-8?Q?Christian_Brandst=c3=a4tter?=)
Date: Mon, 30 May 2016 21:23:36 +0200
Subject: [R] graphic device Windows tickmarks
Message-ID: <71669970-af54-6f16-0f88-e3edc9cf8101@gmail.com>

Dear List,

I discovered an issue; when plotting (base) in R, the tickmark-labels 
are slightly off (Windows machine).

Thus, when saving the plot in R with x11() and dev(...) the 
plot-tickmarks shift, see the example below.

Session Info:

R version 3.2.3 (2015-12-10)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

With savePlot it works, but the graph quality is not as nice. Am I 
missing something here?


Example:
thickticks <- 
c(0,40,90,140,200,260,320,380,440,500,560,620,680,740,800,860,920,980)

x11(width=12,height=12)
plot(seq(0,1000),rep(10,1001),xaxt="n")
axis(1,seq(0,1000,by=10),at=seq(0,1000,by=10),tick=TRUE)
axis(1, at = thickticks, labels=FALSE, las = 1,lwd.ticks=2)

# plots
dev.print(device=png,"test.png",units="in",width=12,height=12,res=500) # 
won't display prop.
dev.print(device=postscript,"test.eps",width=12,height=12)  # won't 
display prop.
dev.print(device=pdf,"test.pdf",width=12,height=12)  # won't display prop.
savePlot("test_2.png",type="png") # displays prop.


From jdnewmil at dcn.davis.ca.us  Mon May 30 21:47:50 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 30 May 2016 12:47:50 -0700
Subject: [R] matrix indexing/subset error
In-Reply-To: <1788267112.1856982.1464633526404.JavaMail.yahoo@mail.yahoo.com>
References: <1788267112.1856982.1464633526404.JavaMail.yahoo.ref@mail.yahoo.com>
	<1788267112.1856982.1464633526404.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <EAF28379-3503-44DE-8196-7B12FDD03A99@dcn.davis.ca.us>

z %% 2 == 1

has 12 logical values.  What do you expect R to do with it worth respect to 4 rows? 
-- 
Sent from my phone. Please excuse my brevity.

On May 30, 2016 11:38:46 AM PDT, Carl Sutton via R-help <r-help at r-project.org> wrote:
>Hi Guru's
>In my quest to understand R I have what I thought was a simple exercise
>that now has me baffled.? Why the error message after running this
>code?? I am totally baffled by the error message.? I was expecting rows
>1 and 3 of the x matrix to be returned, and have not a clue as to why
>this becomes a subscript difficulty.? The manual was of no help in this
>matter.
>
>x <- c(1:3,2:4)
>x? <- matrix(x, nrow = 3)
>x
>z <- c(1:4,1,1,0,0,1,0,1,0)
>z <- matrix(z, ncol = 3)
>z
>x[x[,2]>= 3,]
>x
>z %% 2 == 1
>x[z %% 2 == 1,]Error in x[z%%2 == 1, ] : (subscript) logical subscript
>too long
>Many thanks for your assistance.
>Carl Sutton CPA
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From kolubind at lsbu.ac.uk  Mon May 30 20:27:52 2016
From: kolubind at lsbu.ac.uk (Dan Kolubinski)
Date: Mon, 30 May 2016 19:27:52 +0100
Subject: [R] Regression and Sub-Groups Analysis in Metafor
Message-ID: <CAB01jfLmwNozOh0d+L=R1nVL6O1L1kLO+YiKU1F6VqiNxmD=rQ@mail.gmail.com>

I am completing a meta-analysis on the effect of CBT on low self-esteem and
I could use some help regarding the regression feature in metafor.  Based
on the studies that I am using for the analysis, I identified 4 potential
moderators that I want to explore:
- Some of the studies that I am using used RCTs to compare an intervention
with a waitlist and others used the pre-score as the control in a
single-group design.
- Some of the groups took place in one day and others took several weeks.
- There are three discernible interventions being represented
- The initial level of self-esteem varies

Based on the above, I used this command to conduct a meta-analysis using
standarized mean differences:



MetaMod<-rma(m1i=m1, m2i=m2, sd1i=sd1, sd2i=sd2, n1i=n1, n2i=n2,
mods=cbind(dur, rct, int, level),measure = "SMD")



Would this be the best command to use for what I described?  Also, what
could I add to the command so that the forest plot shows a sub-group
analysis using the 'dur' variable as a between-groups distinction?


Also, with respect to the moderators, this is what was delivered:



Test of Moderators (coefficient(s) 2,3,4,5):
QM(df = 4) = 8.7815, p-val = 0.0668

Model Results:

         estimate      se     zval    pval    ci.lb   ci.ub
intrcpt    0.7005  0.6251   1.1207  0.2624  -0.5246  1.9256
dur        0.5364  0.2411   2.2249  0.0261   0.0639  1.0090  *
rct       -0.3714  0.1951  -1.9035  0.0570  -0.7537  0.0110  .
int        0.0730  0.1102   0.6628  0.5075  -0.1430  0.2890
level     -0.2819  0.2139  -1.3180  0.1875  -0.7010  0.1373

---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1



>From this, can I interpret that the variable 'dur' (duration of
intervention) has a significant effect and the variable 'rct' (whether a
study was an RCT or used pre-post scores) was just shy of being
statistically significant?  I mainly ask, because the QM-score has a
p-value of 0.0668, which I thought would mean that none of the moderators
would be significant.  Would I be better off just listing one or two
moderators instead of four?

Much appreciated,
Dan

	[[alternative HTML version deleted]]


From leonardof at leonardof.med.br  Mon May 30 23:50:44 2016
From: leonardof at leonardof.med.br (Leonardo Ferreira Fontenelle)
Date: Mon, 30 May 2016 18:50:44 -0300
Subject: [R] sandwich package: HAC estimators
In-Reply-To: <alpine.DEB.2.20.1605282044060.26454@paninaro>
References: <5a4a4884895348f8b010876f9ca10151@ex13-live-mbn1.ad.kent.ac.uk>
	<alpine.DEB.2.20.1605282044060.26454@paninaro>
Message-ID: <1464645044.828551.622982401.23A6C61F@webmail.messagingengine.com>

Em S?b 28 mai. 2016, ?s 15:50, Achim Zeileis escreveu:
> On Sat, 28 May 2016, T.Riedle wrote:
> > I thought it would be useful to incorporate the HAC consistent 
> > covariance matrix into the logistic regression directly and generate an 
> > output of coefficients and the corresponding standard errors. Is there 
> > such a function in R?
> 
> Not with HAC standard errors, I think.
> 

Don't glmrob() and summary.glmrob(), from robustbase, do that?


Leonardo Ferreira Fontenelle, MD, MPH


From r.turner at auckland.ac.nz  Tue May 31 00:00:56 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 31 May 2016 10:00:56 +1200
Subject: [R] [FORGED] Re:  email threads chronology
In-Reply-To: <CAGxFJbQP8jW+FAtM+Wu2z2dT4N1sXH8QST_exVcXdWgG9Z+XZQ@mail.gmail.com>
References: <88388BFE50A61F408122CBAEB917FD5736827C1A@SVNSBIOMBX02.ENT.dfo-mpo.ca>
	<CAGxFJbQP8jW+FAtM+Wu2z2dT4N1sXH8QST_exVcXdWgG9Z+XZQ@mail.gmail.com>
Message-ID: <daad696d-253d-5619-b68a-cfdf97e7de01@auckland.ac.nz>

On 31/05/16 03:58, Bert Gunter wrote:

<SNIP>

> On Mon, May 30, 2016 at 5:51 AM, Fowler, Mark <Mark.Fowler at dfo-mpo.gc.ca> wrote:
> ...
> "The preceding replies suggest this is something going on at my end,
> perhaps related to network security. I'm curious what might be causing
> it, and if there is something I can do about it - short of contacting
> IT staff, which is more irritating than the corrupted threads."
>
> Semi-Fortune!? This is probably not quite suitable for the fortunes
> package, but I still think it's clever.

I think this would be an excellent fortune!

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From drjimlemon at gmail.com  Tue May 31 00:03:31 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 31 May 2016 08:03:31 +1000
Subject: [R] email threads chronology
In-Reply-To: <88388BFE50A61F408122CBAEB917FD5736827C1A@SVNSBIOMBX02.ENT.dfo-mpo.ca>
References: <88388BFE50A61F408122CBAEB917FD5736827C1A@SVNSBIOMBX02.ENT.dfo-mpo.ca>
Message-ID: <CA+8X3fWvYpu8W3pzAaw+DfRZviqchM3eBP1DpW_QgP0WcgvfvQ@mail.gmail.com>

Hi Mark,
As with most other annoying, time-consuming operations in the internet
and computing in general, blame the spammers and the scammers. The R
help list is attacked by both and requires both automatic and human
scanning of messages to minimize intrusions. Unfortunately no one has
come up with a simple and inexpensive way to convert the senders to
fertilizer.

Jim


On Mon, May 30, 2016 at 10:51 PM, Fowler, Mark
<Mark.Fowler at dfo-mpo.gc.ca> wrote:
> Hi all,
>
> I'm seeing the natural sequencing of email threads getting corrupted. For example, a May 26 thread on subject 'Shaded areas in R' would have been initiated by an email at 6:58am. However I did not get that email until 1:48pm, preceded by 3 replies to the post. Trivial but irritating. The preceding replies suggest this is something going on at my end, perhaps related to network security. I'm curious what might be causing it, and if there is something I can do about it - short of contacting IT staff, which is more irritating than the corrupted threads.
>
> Mark Fowler
> Population Ecology Division
> Bedford Inst of Oceanography
> Dept Fisheries & Oceans
> Dartmouth NS Canada
> B2Y 4A2
> Tel. (902) 426-3529
> Fax (902) 426-9710
> Email Mark.Fowler at dfo-mpo.gc.ca<mailto:Mark.Fowler at dfo-mpo.gc.ca>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Tue May 31 00:13:14 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 31 May 2016 08:13:14 +1000
Subject: [R] How to replace all commas with semicolon in a string
Message-ID: <CA+8X3fUNjJ-Onkv4=JePPtZqxgRoBQ+SNOUEequtkLLFXcHovA@mail.gmail.com>

Hi Jun,
As you do seem to want to replace commas within, not between, strings, try gsub:

gsub(",",";",test[,1])

Jim

> Dear list,
>
> Say I have a data frame
>
> test <- data.frame(C1=c('a,b,c,d'),C2=c('g,h,f'))
>
> I want to replace the commas with semicolons
>
> sub(',',';',test$C1) -> test$C1 will only replace the first comma of a
> string.
>
> How do I replace them all in one run? Thanks.


From jdnewmil at dcn.davis.ca.us  Tue May 31 00:15:54 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 30 May 2016 15:15:54 -0700 (PDT)
Subject: [R] Trimming time series to only include complete years
In-Reply-To: <alpine.BSF.2.00.1605281251250.73491@pedal.dcn.davis.ca.us>
References: <CAPoqHzrZpb=S6GQRo0O0fszw06pW2_-HKe1MQ34emZANsDJeyQ@mail.gmail.com>
	<alpine.BSF.2.00.1605281251250.73491@pedal.dcn.davis.ca.us>
Message-ID: <alpine.BSF.2.00.1605301456310.85144@pedal.dcn.davis.ca.us>

Sorry, I put too many bugs (opportunities for excellence!) in this on my 
first pass on this to leave it alone :-(

isPartialWaterYear2 <- function( d ) {
   dtl <- as.POSIXlt( d )
   wy1 <- cumsum( ( 9 == dtl$mon ) & ( 1 == dtl$mday ) )
   # any 0 in wy1 corresponds to first partial water year
   result <- 0 == wy1
   # if last day is not Sep 30, mark last water year as partial
   if ( 8 != dtl$mon[ length( d ) ]
      | 30 != dtl$mday[ length( d ) ] ) {
         result[ wy1[ length( d ) ] == wy1 ] <- TRUE
   }
   result
}

dat2 <- dat[ !isPartialWaterYear( dat$Date ), ]

On Sat, 28 May 2016, Jeff Newmiller wrote:

> # read about POSIXlt at ?DateTimeClasses
> # note that the "mon" element is 0-11
> isPartialWaterYear <- function( d ) {
>  dtl <- as.POSIXlt( dat$Date )
>  wy1 <- cumsum( ( 9 == dtl$mon ) & ( 1 == dtl$mday ) )
>  ( 0 == wy1  # first partial year
>  | (  8 != dtl$mon[ nrow( dat ) ] # end partial year
>    & 30 != dtl$mday[ nrow( dat ) ]
>    ) & wy1[ nrow( dat ) ] == wy1
>  )
> }
>
> dat2 <- dat[ !isPartialWaterYear( dat$Date ), ]
>
> The above assumes that, as you said, the data are continuous at one-day 
> intervals, such that the only partial years will occur at the beginning and 
> end. The "diff" function could be used to identify irregular data within the 
> data interval if needed.
>
> On Fri, 27 May 2016, Morway, Eric wrote:
>
>> In bulk processing streamflow data available from an online database, I'm
>> wanting to trim the beginning and end of the time series so that daily data
>> associated with incomplete "water years" (defined as extending from Oct 1st
>> to the following September 30th) is trimmed off the beginning and end of
>> the series.
>> 
>> For a small reproducible example, the time series below starts on
>> 2010-01-01 and ends on 2011-11-05.  So the data between 2010-01-01 and
>> 2010-09-30 and also between 2011-10-01 and 2011-11-05 is not associated
>> with a complete set of data for their respective water years.  With the
>> real data, the initial date of collection is arbitrary, could be 1901 or
>> 1938, etc.  Because I'm cycling through potentially thousands of records, I
>> need help in designing a function that is efficient.
>> 
>> dat <-
>> data.frame(Date=seq(as.Date("2010-01-01"),as.Date("2011-11-05"),by="day"))
>> dat$Q <- rnorm(nrow(dat))
>> 
>> dat$wyr <- as.numeric(format(dat$Date,"%Y"))
>> is.nxt <- as.numeric(format(dat$Date,"%m")) %in% 1:9
>> dat$wyr[!is.nxt] <- dat$wyr[!is.nxt] + 1
>> 
>> 
>> function(dat) {
>>   ...
>>   returns a subset of dat such that dat$Date > xxxx-09-30 & dat$Date <
>> yyyy-10-01
>>   ...
>> }
>> 
>> where the years between xxxx-yyyy are "complete" (no missing days).  In the
>> example above, the returned dat would extend from 2010-10-01 to 2011-09-30
>> 
>> Any offered guidance is very much appreciated.
>>
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jdnewmil at dcn.davis.ca.us  Tue May 31 01:20:06 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 30 May 2016 16:20:06 -0700 (PDT)
Subject: [R] email threads chronology
In-Reply-To: <CA+8X3fWvYpu8W3pzAaw+DfRZviqchM3eBP1DpW_QgP0WcgvfvQ@mail.gmail.com>
References: <88388BFE50A61F408122CBAEB917FD5736827C1A@SVNSBIOMBX02.ENT.dfo-mpo.ca>
	<CA+8X3fWvYpu8W3pzAaw+DfRZviqchM3eBP1DpW_QgP0WcgvfvQ@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1605301559110.85144@pedal.dcn.davis.ca.us>

Mark, you can follow the bouncing emails by looking at the raw message 
headers. How you would access them depends on your email client, 
but "Received:" headers appear in reverse chronological order above the 
"From:" line, indicating the times when the email had reached various 
servers in its journey. Just be sure to subtract the timezone offset 
before comparing timestamps to see the chronology in UTC.

The original email appears to have spent about 4.5 hours at 
"phil3.ethz.ch", possibly awaiting moderator approval. The mailing list 
spam evaluation headers indicate that it did not think the email was spam, 
so some more basic rule or server downtime must have delayed it. 
Subsequent emails in that thread appear to have come in chronological 
order to my email server.

Sorry, I don't have R code to do that analysis (I did the above by 
inspection), so I will shut up now.

On Tue, 31 May 2016, Jim Lemon wrote:

> Hi Mark,
> As with most other annoying, time-consuming operations in the internet
> and computing in general, blame the spammers and the scammers. The R
> help list is attacked by both and requires both automatic and human
> scanning of messages to minimize intrusions. Unfortunately no one has
> come up with a simple and inexpensive way to convert the senders to
> fertilizer.
>
> Jim
>
>
> On Mon, May 30, 2016 at 10:51 PM, Fowler, Mark
> <Mark.Fowler at dfo-mpo.gc.ca> wrote:
>> Hi all,
>>
>> I'm seeing the natural sequencing of email threads getting corrupted. For example, a May 26 thread on subject 'Shaded areas in R' would have been initiated by an email at 6:58am. However I did not get that email until 1:48pm, preceded by 3 replies to the post. Trivial but irritating. The preceding replies suggest this is something going on at my end, perhaps related to network security. I'm curious what might be causing it, and if there is something I can do about it - short of contacting IT staff, which is more irritating than the corrupted threads.
>>
>> Mark Fowler
>> Population Ecology Division
>> Bedford Inst of Oceanography
>> Dept Fisheries & Oceans
>> Dartmouth NS Canada
>> B2Y 4A2
>> Tel. (902) 426-3529
>> Fax (902) 426-9710
>> Email Mark.Fowler at dfo-mpo.gc.ca<mailto:Mark.Fowler at dfo-mpo.gc.ca>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From valkremk at gmail.com  Tue May 31 02:13:36 2016
From: valkremk at gmail.com (Val)
Date: Mon, 30 May 2016 19:13:36 -0500
Subject: [R] Extract from a text file
Message-ID: <CAJOiR6YNh5300ziX6MGCUN+i-029tX7JKdpZeKoUNs00xP1-3A@mail.gmail.com>

Hi all,

I have a messy text file and from this text file I want extract some
information
here is the text file (out.txt).  One record has tow lines. The mean comes
in the first line and the SE of the mean is on the second line. Here is the
sample of the data.

Mean of weight  group 1, SE of mean  :  72.289037489555276
 11.512956539215610
Average weight of group 2, SE of Mean :  83.940053900595013
  10.198495690144522
group 3 mean , SE of Mean     :                78.310441258245469
 13.015876679555
Mean of weight of group 4, SE of Mean               : 76.967516495101669
 12.1254882985

I want produce the following  table. How do i read it first and then
produce a


Gr1  72.289037489555276   11.512956539215610
Gr2  83.940053900595013   10.198495690144522
Gr3  78.310441258245469   13.015876679555
Gr4  76.967516495101669   12.1254882985


Thank you in advance

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Tue May 31 06:21:21 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Tue, 31 May 2016 04:21:21 +0000
Subject: [R] Extract from a text file
In-Reply-To: <CAJOiR6YNh5300ziX6MGCUN+i-029tX7JKdpZeKoUNs00xP1-3A@mail.gmail.com>
References: <CAJOiR6YNh5300ziX6MGCUN+i-029tX7JKdpZeKoUNs00xP1-3A@mail.gmail.com>
Message-ID: <CAKVAULOAf-rZu-yKY-CyYd7hA51V16sAangudwtjkD7+6i--Sw@mail.gmail.com>

Hi Val,

Take a kook at read.table. If for some reason the file dosen't have the
same separator between the columns you can use strsplit after loading the
file.

This might helpyou along getting data into R:
http://www.statmethods.net/input/importingdata.html

Best

On Tue, 31 May 2016, 02:15 Val, <valkremk at gmail.com> wrote:

> Hi all,
>
> I have a messy text file and from this text file I want extract some
> information
> here is the text file (out.txt).  One record has tow lines. The mean comes
> in the first line and the SE of the mean is on the second line. Here is the
> sample of the data.
>
> Mean of weight  group 1, SE of mean  :  72.289037489555276
>  11.512956539215610
> Average weight of group 2, SE of Mean :  83.940053900595013
>   10.198495690144522
> group 3 mean , SE of Mean     :                78.310441258245469
>  13.015876679555
> Mean of weight of group 4, SE of Mean               : 76.967516495101669
>  12.1254882985
>
> I want produce the following  table. How do i read it first and then
> produce a
>
>
> Gr1  72.289037489555276   11.512956539215610
> Gr2  83.940053900595013   10.198495690144522
> Gr3  78.310441258245469   13.015876679555
> Gr4  76.967516495101669   12.1254882985
>
>
> Thank you in advance
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue May 31 08:12:48 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 30 May 2016 23:12:48 -0700 (PDT)
Subject: [R] Extract from a text file
In-Reply-To: <CAJOiR6YNh5300ziX6MGCUN+i-029tX7JKdpZeKoUNs00xP1-3A@mail.gmail.com>
References: <CAJOiR6YNh5300ziX6MGCUN+i-029tX7JKdpZeKoUNs00xP1-3A@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1605302239170.3513@pedal.dcn.davis.ca.us>

Please learn to post in plain text (the setting is in your email client... 
somewhere), as HTML is "What We See Is Not What You Saw" on this mailing 
list.  In conjunction with that, try reading some of the fine material 
mentioned in the Posting Guide about making reproducible examples like 
this one:

# You could read in a file
# indta <- readLines( "out.txt" )
# but there is no "current directory" in an email
# so here I have used the dput() function to make source code
# that creates a self-contained R object

indta <- c(
"Mean of weight  group 1, SE of mean  :  72.289037489555276",
" 11.512956539215610",
"Average weight of group 2, SE of Mean :  83.940053900595013",
"  10.198495690144522",
"group 3 mean , SE of Mean     :                78.310441258245469",
" 13.015876679555",
"Mean of weight of group 4, SE of Mean               : 76.967516495101669",
" 12.1254882985", "")

# Regular expression patterns are discussed all over the internet
# in many places OTHER than R
# You can start with ?regex, but there are many fine tutorials also

pattern <- "^.*group (\\d+)[^:]*: *([-+0-9.eE]*).*$"
# For this task the regex has to match the whole "first line" of each set
#  ^ =match starting at the beginning of the string
#  .* =any character, zero or more times
#  "group " =match these characters
#  ( =first capture string starts here
#  \\d = any digit (first backslash for R, second backslash for regex)
#  + =one or more of the preceding (any digit)
#  ) =end of first capture string
#  [^:] =any non-colon character
#  * =zero or more of the preceding (non-colon character)
#  : =match a colon exactly
#  " *" =match zero or more spaces
#  ( =second capture string starts here
#  [ =start of a set of equally acceptable characters
#  -+ =either of these characters are acceptable
#  0-9 =any digit would be acceptable
#  . =a period is acceptable (this is inside the [])
#  eE =in case you get exponential notation input
#  ] =end of the set of acceptable characters (number)
#  * =number of acceptable characters can be zero or more
#  ) =second capture string stops here
#  .* =zero or more of any character (just in case)
#  $ =at end of pattern, requires that the match reach the end
#     of the string

# identify indexes of strings that match the pattern
firstlines <- grep( pattern, indta )
# Replace the matched portion (entire string) with the first capture 
# string
v1 <- as.numeric( sub( pattern, "\\1", indta[ firstlines ] ) )
# Replace the matched portion (entire string) with the second capture 
# string
v2 <- as.numeric( sub( pattern, "\\2", indta[ firstlines ] ) )
# Convert the lines just after the first lines to numeric
v3 <- as.numeric( indta[ firstlines + 1 ] )
# put it all into a data frame
result <- data.frame( Group = v1, Mean = v2, SE = v3 )

Figuring out how to deliver your result (output) is a separate question 
that depends where you want it to go.

On Mon, 30 May 2016, Val wrote:

> Hi all,
>
> I have a messy text file and from this text file I want extract some
> information
> here is the text file (out.txt).  One record has tow lines. The mean comes
> in the first line and the SE of the mean is on the second line. Here is the
> sample of the data.
>
> Mean of weight  group 1, SE of mean  :  72.289037489555276
> 11.512956539215610
> Average weight of group 2, SE of Mean :  83.940053900595013
>  10.198495690144522
> group 3 mean , SE of Mean     :                78.310441258245469
> 13.015876679555
> Mean of weight of group 4, SE of Mean               : 76.967516495101669
> 12.1254882985
>
> I want produce the following  table. How do i read it first and then
> produce a
>
>
> Gr1  72.289037489555276   11.512956539215610
> Gr2  83.940053900595013   10.198495690144522
> Gr3  78.310441258245469   13.015876679555
> Gr4  76.967516495101669   12.1254882985
>
>
> Thank you in advance
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From dulcalma at bigpond.com  Tue May 31 08:17:47 2016
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Tue, 31 May 2016 16:17:47 +1000
Subject: [R] graphic device Windows tickmarks
In-Reply-To: <71669970-af54-6f16-0f88-e3edc9cf8101@gmail.com>
References: <71669970-af54-6f16-0f88-e3edc9cf8101@gmail.com>
Message-ID: <000a01d1bb04$27604960$7620dc20$@bigpond.com>

Hi 

Without looking at the help guide I think there are restrictions on
resolution
and just in case of unit problems I worked in the default units

> png("test.png",units="in",width=12,height=12,res=300)
Error in png("test.png", units = "in", width = 12, height = 12, res = 300) :

  unable to start png() device
In addition: Warning messages:
1: In png("test.png", units = "in", width = 12, height = 12, res = 300) :
  unable to allocate bitmap
2: In png("test.png", units = "in", width = 12, height = 12, res = 300) :
  opening device failed
> 12*72
[1] 864
> png("test.png",width=864,height=834,res=150)
> plot(seq(0,1000),rep(10,1001),xaxt="n")
> axis(1,seq(0,1000,by=10),at=seq(0,1000,by=10),tick=TRUE)
> axis(1, at = thickticks, labels=FALSE, las = 1,lwd.ticks=2)
> dev.off()

Check ?postscript and the options as eps and pdf require different
arguments.
> postscript("test.eps", paper = "special", width = 12,height = 12)
> plot(seq(0,1000),rep(10,1001),xaxt="n")
> axis(1,seq(0,1000,by=10),at=seq(0,1000,by=10),tick=TRUE)
> axis(1, at = thickticks, labels=FALSE, las = 1,lwd.ticks=2)
> dev.off()

> pdf("test.pdf", paper = "special", width = 12,height = 12)
> plot(seq(0,1000),rep(10,1001),xaxt="n")
> axis(1,seq(0,1000,by=10),at=seq(0,1000,by=10),tick=TRUE)
> axis(1, at = thickticks, labels=FALSE, las = 1,lwd.ticks=2)
> dev.off()

All the above work for me on Win 7 32

platform       i386-w64-mingw32                           
arch           i386                                       
os             mingw32                                    
system         i386, mingw32

Similar to the above has worked on Win 64

Regards

Duncan


Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Christian
Brandst?tter
Sent: Tuesday, 31 May 2016 05:24
To: r-help at r-project.org
Subject: [R] graphic device Windows tickmarks

Dear List,

I discovered an issue; when plotting (base) in R, the tickmark-labels 
are slightly off (Windows machine).

Thus, when saving the plot in R with x11() and dev(...) the 
plot-tickmarks shift, see the example below.

Session Info:

R version 3.2.3 (2015-12-10)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

With savePlot it works, but the graph quality is not as nice. Am I 
missing something here?


Example:
thickticks <- 
c(0,40,90,140,200,260,320,380,440,500,560,620,680,740,800,860,920,980)

x11(width=12,height=12)
plot(seq(0,1000),rep(10,1001),xaxt="n")
axis(1,seq(0,1000,by=10),at=seq(0,1000,by=10),tick=TRUE)
axis(1, at = thickticks, labels=FALSE, las = 1,lwd.ticks=2)

# plots
dev.print(device=png,"test.png",units="in",width=12,height=12,res=500) # 
won't display prop.
dev.print(device=postscript,"test.eps",width=12,height=12)  # won't 
display prop.
dev.print(device=pdf,"test.pdf",width=12,height=12)  # won't display prop.
savePlot("test_2.png",type="png") # displays prop.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From G.Maubach at weinwolf.de  Tue May 31 08:45:52 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 31 May 2016 08:45:52 +0200
Subject: [R] Difference subsetting (dataset$variable vs. dataset["variable"]
Message-ID: <OF702AD287.C1621E4D-ONC1257FAF.004E779F-C1257FC4.002528E9@lotus.hawesko.de>

Hi All,

I thought dataset$variable is the same as dataset["variable"]. I tried the 
following:

> str(ZWW_Kunden$Branche)
 chr [1:49673] "231" "151" "151" "231" "231" "111" "231" "111" "231" "231" 
"151" "111" ...
> str(ZWW_Kunden["Branche"])
'data.frame':            49673 obs. of  1 variable:
 $ Branche: chr  "231" "151" "151" "231" ...

and get different results: "chr {1:49673]" vs. "data.frame". First one is 
a simple vector, second one is a data.frame.

This has consequences when subsetting a dataset and filter cases:

> ZWW_Kunden["Branche"] %in% c("315", "316", "317")
[1] FALSE

> head(ZWW_Kunden$Branche %in% c("315", "316", "317")) # head() only to 
shorten output
[1] FALSE FALSE FALSE FALSE FALSE FALSE

I have thought dataset$variable is the same as dataset["variable"] but 
actually it's not.

Can you explain what the difference is?

Kind regards

Georg


From haenlein at escpeurope.eu  Tue May 31 09:05:05 2016
From: haenlein at escpeurope.eu (Michael Haenlein)
Date: Tue, 31 May 2016 09:05:05 +0200
Subject: [R] Fractional Factorial Design on 4-level factor
Message-ID: <CAOyz9G7Usi-idHK-UerLZx4rWGP+PLO4Jt6iBkHdHLLzGBfYdQ@mail.gmail.com>

Dear all,

I am running a simulation experiment with 8 factors that each have 4
levels. Each combination is repeated 100 times. If I run a full factorial
this would mean 100*8^4 = 409,600 runs.

I am trying to reduce the number of scenarios to run using a fractional
factorial design. I'm interested in estimating the main effects of the 8
factors plus their 2-way interactions. Any higher level interactions are
not of interest to me. My plan is to use a standard OLS regression for
that, once the simulations are over.

I tried to use the FrF2 package to derive a fractional factorial design but
it seems that this is only working for factors on two levels. Any idea how
I could derive a fractional factorial design on factors with four levels?

Thanks for your help,

Michael



Michael Haenlein
Professor of Marketing
ESCP Europe

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue May 31 09:28:34 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 31 May 2016 00:28:34 -0700
Subject: [R] Difference subsetting (dataset$variable vs.
	dataset["variable"]
In-Reply-To: <OF702AD287.C1621E4D-ONC1257FAF.004E779F-C1257FC4.002528E9@lotus.hawesko.de>
References: <OF702AD287.C1621E4D-ONC1257FAF.004E779F-C1257FC4.002528E9@lotus.hawesko.de>
Message-ID: <17461847-901B-4600-9267-08491A6D586C@dcn.davis.ca.us>

You were clearly mistaken. 

dataframe$column is almost the same as dataframe[["column"]], except that the $ does partial matching. Both of these "extract" a list element. 

A data frame is a list where all elements are vectors of the same length.  A list is a vector where each element can refer to any of a variety of types of objects. The names of the objects in the list are associated with the list vector, not the referred objects (e.g. columns).  The [] operator "slices" the list but keeps the names and referring semantics. The [[]] extraction operator (and its pal $) refer to a single element out of the list, losing access to the containing list and the names that go with it. 

The Introduction to R document has all this in it... it just usually glazes your eyes the first few times you read it.  You might find the R Inferno more entertaining. 

-- 
Sent from my phone. Please excuse my brevity.

On May 30, 2016 11:45:52 PM PDT, G.Maubach at weinwolf.de wrote:
>Hi All,
>
>I thought dataset$variable is the same as dataset["variable"]. I tried
>the 
>following:
>
>> str(ZWW_Kunden$Branche)
>chr [1:49673] "231" "151" "151" "231" "231" "111" "231" "111" "231"
>"231" 
>"151" "111" ...
>> str(ZWW_Kunden["Branche"])
>'data.frame':            49673 obs. of  1 variable:
> $ Branche: chr  "231" "151" "151" "231" ...
>
>and get different results: "chr {1:49673]" vs. "data.frame". First one
>is 
>a simple vector, second one is a data.frame.
>
>This has consequences when subsetting a dataset and filter cases:
>
>> ZWW_Kunden["Branche"] %in% c("315", "316", "317")
>[1] FALSE
>
>> head(ZWW_Kunden$Branche %in% c("315", "316", "317")) # head() only to
>
>shorten output
>[1] FALSE FALSE FALSE FALSE FALSE FALSE
>
>I have thought dataset$variable is the same as dataset["variable"] but 
>actually it's not.
>
>Can you explain what the difference is?
>
>Kind regards
>
>Georg
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From Achim.Zeileis at uibk.ac.at  Tue May 31 09:36:02 2016
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Tue, 31 May 2016 09:36:02 +0200 (CEST)
Subject: [R] sandwich package: HAC estimators
In-Reply-To: <1464645044.828551.622982401.23A6C61F@webmail.messagingengine.com>
References: <5a4a4884895348f8b010876f9ca10151@ex13-live-mbn1.ad.kent.ac.uk>
	<alpine.DEB.2.20.1605282044060.26454@paninaro>
	<1464645044.828551.622982401.23A6C61F@webmail.messagingengine.com>
Message-ID: <alpine.DEB.2.20.1605310929070.23365@paninaro>

On Mon, 30 May 2016, Leonardo Ferreira Fontenelle wrote:

> Em S?b 28 mai. 2016, ?s 15:50, Achim Zeileis escreveu:
>> On Sat, 28 May 2016, T.Riedle wrote:
>> > I thought it would be useful to incorporate the HAC consistent 
>> > covariance matrix into the logistic regression directly and generate an 
>> > output of coefficients and the corresponding standard errors. Is there 
>> > such a function in R?
>> 
>> Not with HAC standard errors, I think.
>
> Don't glmrob() and summary.glmrob(), from robustbase, do that?

No, they implement a different concept of robustness. See also
https://CRAN.R-project.org/view=Robust

glmrob() implements GLMs that are "robust" or rather "resistant" to 
outliers and other observations that do not come from the main model 
equation. Instead of maximum likelihood (ML) estimation other estimation 
techniques (along with corresponding covariances/standard errors) are 
used.

In contrast, the OP asked for HAC standard errors. The motivation for 
these is that the main model equation does hold for all observations but 
that the observations might be heteroskedastic and/or autocorrelated. In 
this situation, ML estimation is still consistent (albeit not efficient) 
but the covariance matrix estimate needs to be adjusted.

>
> Leonardo Ferreira Fontenelle, MD, MPH
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From lists at dewey.myzen.co.uk  Tue May 31 13:02:45 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Tue, 31 May 2016 12:02:45 +0100
Subject: [R] Regression and Sub-Groups Analysis in Metafor
In-Reply-To: <CAB01jfLmwNozOh0d+L=R1nVL6O1L1kLO+YiKU1F6VqiNxmD=rQ@mail.gmail.com>
References: <CAB01jfLmwNozOh0d+L=R1nVL6O1L1kLO+YiKU1F6VqiNxmD=rQ@mail.gmail.com>
Message-ID: <ed44259a-0c32-2354-0e7f-be83b302df71@dewey.myzen.co.uk>

In-line

On 30/05/2016 19:27, Dan Kolubinski wrote:
> I am completing a meta-analysis on the effect of CBT on low self-esteem and
> I could use some help regarding the regression feature in metafor.  Based
> on the studies that I am using for the analysis, I identified 4 potential
> moderators that I want to explore:
> - Some of the studies that I am using used RCTs to compare an intervention
> with a waitlist and others used the pre-score as the control in a
> single-group design.
> - Some of the groups took place in one day and others took several weeks.
> - There are three discernible interventions being represented
> - The initial level of self-esteem varies
>
> Based on the above, I used this command to conduct a meta-analysis using
> standarized mean differences:
>
>
>
> MetaMod<-rma(m1i=m1, m2i=m2, sd1i=sd1, sd2i=sd2, n1i=n1, n2i=n2,
> mods=cbind(dur, rct, int, level),measure = "SMD")
>

You could also say mods = ~ dur + rct + int + level

>
>
> Would this be the best command to use for what I described?  Also, what
> could I add to the command so that the forest plot shows a sub-group
> analysis using the 'dur' variable as a between-groups distinction?
>

You have to adjust the forest plot by hand and then use add.polygon to 
add the summaries for each level of dur.

>
> Also, with respect to the moderators, this is what was delivered:
>
>
>
> Test of Moderators (coefficient(s) 2,3,4,5):
> QM(df = 4) = 8.7815, p-val = 0.0668
>
> Model Results:
>
>          estimate      se     zval    pval    ci.lb   ci.ub
> intrcpt    0.7005  0.6251   1.1207  0.2624  -0.5246  1.9256
> dur        0.5364  0.2411   2.2249  0.0261   0.0639  1.0090  *
> rct       -0.3714  0.1951  -1.9035  0.0570  -0.7537  0.0110  .
> int        0.0730  0.1102   0.6628  0.5075  -0.1430  0.2890
> level     -0.2819  0.2139  -1.3180  0.1875  -0.7010  0.1373
>
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>

So the totality of moderators did not reach an arbitrary level of 
significance.

>
>>From this, can I interpret that the variable 'dur' (duration of
> intervention) has a significant effect and the variable 'rct' (whether a
> study was an RCT or used pre-post scores) was just shy of being
> statistically significant?  I mainly ask, because the QM-score has a
> p-value of 0.0668, which I thought would mean that none of the moderators
> would be significant.  Would I be better off just listing one or two
> moderators instead of four?
>

At the moment you get an overall test of the moderators which you had a 
scientific reason for using. If you start selecting based on the data 
you run the risk of ending up with confidence intervals and significance 
levels which do not have the meaning they are supposed to have.


> Much appreciated,
> Dan
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From tr206 at kent.ac.uk  Tue May 31 13:50:21 2016
From: tr206 at kent.ac.uk (T.Riedle)
Date: Tue, 31 May 2016 11:50:21 +0000
Subject: [R] sandwich package: HAC estimators
In-Reply-To: <alpine.DEB.2.20.1605310929070.23365@paninaro>
References: <5a4a4884895348f8b010876f9ca10151@ex13-live-mbn1.ad.kent.ac.uk>
	<alpine.DEB.2.20.1605282044060.26454@paninaro>
	<1464645044.828551.622982401.23A6C61F@webmail.messagingengine.com>,
	<alpine.DEB.2.20.1605310929070.23365@paninaro>
Message-ID: <1464695293382.79381@kent.ac.uk>

I understood. But how do I get the R2 an Chi2 of my logistic regression under HAC standard errors? I would like to create a table with HAC SE via e.g. stargazer(). 

Do I get these information by using the functions

bread.lrm <- function(x, ...) vcov(x) * nobs(x)
estfun.lrm <- function(x, ...) residuals(x, "score")?
 
Do I need to use the coeftest() in this case?
________________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Achim Zeileis <Achim.Zeileis at uibk.ac.at>
Sent: 31 May 2016 08:36
To: Leonardo Ferreira Fontenelle
Cc: r-help at r-project.org
Subject: Re: [R] sandwich package: HAC estimators

On Mon, 30 May 2016, Leonardo Ferreira Fontenelle wrote:

> Em S?b 28 mai. 2016, ?s 15:50, Achim Zeileis escreveu:
>> On Sat, 28 May 2016, T.Riedle wrote:
>> > I thought it would be useful to incorporate the HAC consistent
>> > covariance matrix into the logistic regression directly and generate an
>> > output of coefficients and the corresponding standard errors. Is there
>> > such a function in R?
>>
>> Not with HAC standard errors, I think.
>
> Don't glmrob() and summary.glmrob(), from robustbase, do that?

No, they implement a different concept of robustness. See also
https://CRAN.R-project.org/view=Robust

glmrob() implements GLMs that are "robust" or rather "resistant" to
outliers and other observations that do not come from the main model
equation. Instead of maximum likelihood (ML) estimation other estimation
techniques (along with corresponding covariances/standard errors) are
used.

In contrast, the OP asked for HAC standard errors. The motivation for
these is that the main model equation does hold for all observations but
that the observations might be heteroskedastic and/or autocorrelated. In
this situation, ML estimation is still consistent (albeit not efficient)
but the covariance matrix estimate needs to be adjusted.

>
> Leonardo Ferreira Fontenelle, MD, MPH
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bran.chri at gmail.com  Tue May 31 13:57:51 2016
From: bran.chri at gmail.com (=?UTF-8?Q?Christian_Brandst=c3=a4tter?=)
Date: Tue, 31 May 2016 13:57:51 +0200
Subject: [R] graphic device Windows tickmarks
In-Reply-To: <000a01d1bb04$27604960$7620dc20$@bigpond.com>
References: <71669970-af54-6f16-0f88-e3edc9cf8101@gmail.com>
	<000a01d1bb04$27604960$7620dc20$@bigpond.com>
Message-ID: <4b4d2450-c8cc-25fc-f69d-e2a544e9697f@gmail.com>

Hi,

thank you for your answer. To tackle down the problem, I tried this 
(modified from your code):

thickticks <- c(0,60,130,210,290,370,450,530,610,690,770,850,930)

png("test.png",width=864,height=834,res=150)
plot(seq(0,1000),rep(10,1001),xaxt="n")
axis(1,seq(0,1000,by=10),at=seq(0,1000,by=10),tick=TRUE)
axis(1, at = thickticks, labels=FALSE, las = 1,lwd.ticks=2)
dev.off()

x11()
plot(seq(0,1000),rep(10,1001),xaxt="n")
axis(1,seq(0,1000,by=10),at=seq(0,1000,by=10),tick=TRUE)
axis(1, at = thickticks, labels=FALSE, las = 1,lwd.ticks=2)

On my machine the x-axis-labels differ.
In the test.png the labels are 0,70,170,...
In the x11 window they are the same values as in the thickticks-vector.
Why? I tried to play with different resolution values, this didn't help.

Best, Christian


Am 31.05.2016 um 08:17 schrieb Duncan Mackay:
> Hi
>
> Without looking at the help guide I think there are restrictions on
> resolution
> and just in case of unit problems I worked in the default units
>
>> png("test.png",units="in",width=12,height=12,res=300)
> Error in png("test.png", units = "in", width = 12, height = 12, res = 300) :
>
>    unable to start png() device
> In addition: Warning messages:
> 1: In png("test.png", units = "in", width = 12, height = 12, res = 300) :
>    unable to allocate bitmap
> 2: In png("test.png", units = "in", width = 12, height = 12, res = 300) :
>    opening device failed
>> 12*72
> [1] 864
>> png("test.png",width=864,height=834,res=150)
>> plot(seq(0,1000),rep(10,1001),xaxt="n")
>> axis(1,seq(0,1000,by=10),at=seq(0,1000,by=10),tick=TRUE)
>> axis(1, at = thickticks, labels=FALSE, las = 1,lwd.ticks=2)
>> dev.off()
> Check ?postscript and the options as eps and pdf require different
> arguments.
>> postscript("test.eps", paper = "special", width = 12,height = 12)
>> plot(seq(0,1000),rep(10,1001),xaxt="n")
>> axis(1,seq(0,1000,by=10),at=seq(0,1000,by=10),tick=TRUE)
>> axis(1, at = thickticks, labels=FALSE, las = 1,lwd.ticks=2)
>> dev.off()
>> pdf("test.pdf", paper = "special", width = 12,height = 12)
>> plot(seq(0,1000),rep(10,1001),xaxt="n")
>> axis(1,seq(0,1000,by=10),at=seq(0,1000,by=10),tick=TRUE)
>> axis(1, at = thickticks, labels=FALSE, las = 1,lwd.ticks=2)
>> dev.off()
> All the above work for me on Win 7 32
>
> platform       i386-w64-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
>
> Similar to the above has worked on Win 64
>
> Regards
>
> Duncan
>
>
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Christian
> Brandst?tter
> Sent: Tuesday, 31 May 2016 05:24
> To: r-help at r-project.org
> Subject: [R] graphic device Windows tickmarks
>
> Dear List,
>
> I discovered an issue; when plotting (base) in R, the tickmark-labels
> are slightly off (Windows machine).
>
> Thus, when saving the plot in R with x11() and dev(...) the
> plot-tickmarks shift, see the example below.
>
> Session Info:
>
> R version 3.2.3 (2015-12-10)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> With savePlot it works, but the graph quality is not as nice. Am I
> missing something here?
>
>
> Example:
> thickticks <-
> c(0,40,90,140,200,260,320,380,440,500,560,620,680,740,800,860,920,980)
>
> x11(width=12,height=12)
> plot(seq(0,1000),rep(10,1001),xaxt="n")
> axis(1,seq(0,1000,by=10),at=seq(0,1000,by=10),tick=TRUE)
> axis(1, at = thickticks, labels=FALSE, las = 1,lwd.ticks=2)
>
> # plots
> dev.print(device=png,"test.png",units="in",width=12,height=12,res=500) #
> won't display prop.
> dev.print(device=postscript,"test.eps",width=12,height=12)  # won't
> display prop.
> dev.print(device=pdf,"test.pdf",width=12,height=12)  # won't display prop.
> savePlot("test_2.png",type="png") # displays prop.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From G.Maubach at weinwolf.de  Tue May 31 14:00:45 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 31 May 2016 14:00:45 +0200
Subject: [R] Variable labels and value labels
Message-ID: <OF1C9BED83.8BE86DD3-ONC1257FC4.00413344-C1257FC4.0041FD1B@lotus.hawesko.de>

Hi All,

I am using R for social sciences. In this field I am used to use short 
variable names like "q1" for question 1, "q2" for question 2 and so on and 
label the variables like q1 : "Please tell us your age" or q2 : "Could you 
state us your household income?" or something similar indicating which 
question is stored in the variable.

Similar I am used to label values like 1: "Less than 18 years", 2 : "18 to 
30 years", 3 : "31 to 60 years" and 4 : "61 years and more".

I know that the packages Hmisc and memisc have a functionality for this 
but these labeling functions are limited to the packages they were defined 
for. Using the question tests as variable names is possible but very 
inconvenient.

I there another way for labeling variables and values in R?

Kind regards

Georg Maubach


From Achim.Zeileis at uibk.ac.at  Tue May 31 14:18:46 2016
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Tue, 31 May 2016 14:18:46 +0200 (CEST)
Subject: [R] sandwich package: HAC estimators
In-Reply-To: <1464695293382.79381@kent.ac.uk>
References: <5a4a4884895348f8b010876f9ca10151@ex13-live-mbn1.ad.kent.ac.uk>
	<alpine.DEB.2.20.1605282044060.26454@paninaro>
	<1464645044.828551.622982401.23A6C61F@webmail.messagingengine.com>,
	<alpine.DEB.2.20.1605310929070.23365@paninaro>
	<1464695293382.79381@kent.ac.uk>
Message-ID: <alpine.DEB.2.20.1605311406360.9953@paninaro>

On Tue, 31 May 2016, T.Riedle wrote:

> I understood. But how do I get the R2 an Chi2 of my logistic regression 
> under HAC standard errors? I would like to create a table with HAC SE 
> via e.g. stargazer().
>
> Do I get these information by using the functions
>
> bread.lrm <- function(x, ...) vcov(x) * nobs(x)
> estfun.lrm <- function(x, ...) residuals(x, "score")?
>
> Do I need to use the coeftest() in this case?

The bread()/estfun() methods enable application of vcovHAC(), kernHAC(), 
NeweyWest(). This in turn enables the application of coeftest(),
waldtest(), or linearHypothesis() with a suitable vcov argument.

All of these give you different kinds of Wald tests with HAC covariances 
including marginal tests of individual coefficients (coeftest) or global 
tests of nested models (waldtest/linearHypothesis). The latter can serve 
as replacement for the "chi-squared test". For pseudo-R-squared values I'm 
not familiar with HAC-adjusted variants.

And I'm not sure whether there is a LaTeX export solution that encompasses 
all of these aspects simultaneously.

> ________________________________________
> From: R-help <r-help-bounces at r-project.org> on behalf of Achim Zeileis <Achim.Zeileis at uibk.ac.at>
> Sent: 31 May 2016 08:36
> To: Leonardo Ferreira Fontenelle
> Cc: r-help at r-project.org
> Subject: Re: [R] sandwich package: HAC estimators
>
> On Mon, 30 May 2016, Leonardo Ferreira Fontenelle wrote:
>
>> Em S?b 28 mai. 2016, ?s 15:50, Achim Zeileis escreveu:
>>> On Sat, 28 May 2016, T.Riedle wrote:
>>>> I thought it would be useful to incorporate the HAC consistent
>>>> covariance matrix into the logistic regression directly and generate an
>>>> output of coefficients and the corresponding standard errors. Is there
>>>> such a function in R?
>>>
>>> Not with HAC standard errors, I think.
>>
>> Don't glmrob() and summary.glmrob(), from robustbase, do that?
>
> No, they implement a different concept of robustness. See also
> https://CRAN.R-project.org/view=Robust
>
> glmrob() implements GLMs that are "robust" or rather "resistant" to
> outliers and other observations that do not come from the main model
> equation. Instead of maximum likelihood (ML) estimation other estimation
> techniques (along with corresponding covariances/standard errors) are
> used.
>
> In contrast, the OP asked for HAC standard errors. The motivation for
> these is that the main model equation does hold for all observations but
> that the observations might be heteroskedastic and/or autocorrelated. In
> this situation, ML estimation is still consistent (albeit not efficient)
> but the covariance matrix estimate needs to be adjusted.
>
>>
>> Leonardo Ferreira Fontenelle, MD, MPH
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

From prasad.prasad.kale at gmail.com  Tue May 31 09:22:59 2016
From: prasad.prasad.kale at gmail.com (Prasad Kale)
Date: Tue, 31 May 2016 12:52:59 +0530
Subject: [R] Whether statistical background is must to learn R language
Message-ID: <CAHKdztUOFjYCNi35TwCa_LJ7Edy-yAX6V_jDpqC0_byd7OwiYA@mail.gmail.com>

Hi,

I am very new to R and just started learning R. But i am not from
statistical background so can i learn R or to learn R statistical
background is must.

Please guide.

Thanks in Advance
Prasad

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue May 31 11:43:35 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 31 May 2016 09:43:35 +0000
Subject: [R] Fractional Factorial Design on 4-level factor
In-Reply-To: <CAOyz9G7Usi-idHK-UerLZx4rWGP+PLO4Jt6iBkHdHLLzGBfYdQ@mail.gmail.com>
References: <CAOyz9G7Usi-idHK-UerLZx4rWGP+PLO4Jt6iBkHdHLLzGBfYdQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C502D032@SRVEXCHMBX.precheza.cz>

Hi

I do not consider myself as an expert in factorial design but why do you insist on 4 levels in factors. My opinion is that you need more than 2 levels only if you expect and you want to evaluate nonlinear relationship of the response on such factor.

If you used only 2 levels you could find which factors are influential and they can be further tested on nonlinear response.

And even if you used only 2 levels you have to test 8 factors in at least 16 runs which, with 100 repetitions, gives me 1600 experiments (that seems to me quite a big deal).

Regards
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Michael
> Haenlein
> Sent: Tuesday, May 31, 2016 9:05 AM
> To: r-help at r-project.org
> Subject: [R] Fractional Factorial Design on 4-level factor
>
> Dear all,
>
> I am running a simulation experiment with 8 factors that each have 4 levels.
> Each combination is repeated 100 times. If I run a full factorial this would
> mean 100*8^4 = 409,600 runs.
>
> I am trying to reduce the number of scenarios to run using a fractional
> factorial design. I'm interested in estimating the main effects of the 8 factors
> plus their 2-way interactions. Any higher level interactions are not of interest
> to me. My plan is to use a standard OLS regression for that, once the
> simulations are over.
>
> I tried to use the FrF2 package to derive a fractional factorial design but it
> seems that this is only working for factors on two levels. Any idea how I could
> derive a fractional factorial design on factors with four levels?
>
> Thanks for your help,
>
> Michael
>
>
>
> Michael Haenlein
> Professor of Marketing
> ESCP Europe
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From amene.deljoo at gmail.com  Tue May 31 12:12:42 2016
From: amene.deljoo at gmail.com (ameneh deljoo)
Date: Tue, 31 May 2016 12:12:42 +0200
Subject: [R] Pairwise table from cloumns
Message-ID: <CAF+w_Q0aKGUFA=mt+tZpeh1pS9mBv4NWki21t47ZsyaFRXoyPg@mail.gmail.com>

*Hi Group
**I have a large data set of individual pairwise values (100 rows)
**that I** need to reshape into a pairwise matrix for mantel tests of
similarity these values** .
**I need this matrix for a Pathfinder network analysis. *

*I have a different data(word) such as :*





  living thing
  0


  animal
  1


  blood
  2


  bird
  3


  feathers
  4


  robin
  5


  chicken
....
  6



  *I need the final matrix to be formatted as based on the similarity
**      A1    A2    A3    A4
** A1  0     32   40     32
* *A2  32    0    49     38
** A3  40    49   0      53
** A4  32    38   53     0*

*....*


Are there any functions/packages that will make this easier? Thanks Ameneh

	[[alternative HTML version deleted]]


From G.Maubach at weinwolf.de  Tue May 31 12:36:12 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 31 May 2016 12:36:12 +0200
Subject: [R] Utility Functions
Message-ID: <OFCF636014.2BA0C977-ONC1257FC4.0025451E-C1257FC4.003A3FA9@lotus.hawesko.de>

Hi All,

I was new to R and this list a couple of mounths ago. When processing my 
data I got tremendous support from R-Help mailing list.

The solutions I have worked out with your help might be also helpful for 
others. I have put the solutions in a couple of small functions with 
documentation and tests. You can find the software on Sourceforge.net at

https://sourceforge.net/projects/r-project-utilities/files/?source=navbar

You should download at least "r_toolbox.R" and store it in a directory 
like "r_toolbox" in your favourite project folder. Within "r_toolbox" 
folder put all the other files. You have to adjust the variable 
"t_toolbox_path" to your favourite project directory including the 
"r_toolbox" folder, e. g. "C:\My-Projects\t-toolbox\" on Windows or 
"/home/username/my-projects/r-toolbox" on Unix-like systems.

You can use them for your projects. Although I developed them with great 
care these functions come with absolutely no warrenty. You need to use 
them at your own risk. As the functions are small and overseeable you will 
find out quickly by reading the source code that the functions are save to 
use.

If you have any recommendations or improvement proposals please get back 
to me.

Kind regards

Georg Maubach


From nikolai.stenfors at gapps.umu.se  Tue May 31 12:44:21 2016
From: nikolai.stenfors at gapps.umu.se (Nikolai Stenfors)
Date: Tue, 31 May 2016 10:44:21 +0000
Subject: [R] How to import sensitive data when multiple users collaborate on
	R-script?
Message-ID: <loom.20160531T123953-299@post.gmane.org>

We conduct medical research and our datafiles therefore contain sensitive
data, not to be shared in the cloud (Dropboc, Box, Drive, Bitbucket, GitHub).
When we collaborate on a r-analysis-script, we stumble upon the following
annoyance. Researcher 1 has a line in the script importing the sensitive
data from his/her personal computer. Researcher 2 has to put an additional
line importing the data from his/her personal computer. Thus, we have lines
in the script that are unnecessery for one or the other researcher. How can
we avoid this? Is there another way of conducting the collaboration. Other
workflow? 

I'm perhaps looking for something like:
"If the script is run on researcher 1 computer, load file from this
directory. If the script is run on researcher 2 computer, load data from
that directory". 

Example:
## Import data-------------------------------------
# Researcher 1 import data from laptop1, unnecessery line for Researcher 2
data <- read.table("/path/to_researcher1_computer/sensitive_data.csv") 

# Researcher 2 import data from laptop2 (unnecessery line for Researcher 1)
data <- read.table("/path/to_researcher2_computer/sensitive_data.csv") 

## Clean data
data$var1 <- NULL

## Analyze data
boxplot(data$var2)


From mohammad.godarzi at gmail.com  Tue May 31 14:55:30 2016
From: mohammad.godarzi at gmail.com (Mohammad Goodarzi)
Date: Tue, 31 May 2016 14:55:30 +0200
Subject: [R]  How to replace all commas with semicolon in a string
Message-ID: <CAO4=jh5d4QKo1Mva0hWGnS_O05Euv0+r5zYAe8se-G1yJ3T7EA@mail.gmail.com>

here is the solution to your question

test <- data.frame(C1=c('a,b,c,d'),C2=c('g,h,f'))

you should use gsub instead sub if you want it to be on all elements of
each column

tFun <- function(x) {gsub(",",";",x)}
newTest <- apply(test, 2, tFun )

Cheers,

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue May 31 14:56:38 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 31 May 2016 12:56:38 +0000
Subject: [R] Variable labels and value labels
In-Reply-To: <OF1C9BED83.8BE86DD3-ONC1257FC4.00413344-C1257FC4.0041FD1B@lotus.hawesko.de>
References: <OF1C9BED83.8BE86DD3-ONC1257FC4.00413344-C1257FC4.0041FD1B@lotus.hawesko.de>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C502D135@SRVEXCHMBX.precheza.cz>

Hi

see in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> G.Maubach at weinwolf.de
> Sent: Tuesday, May 31, 2016 2:01 PM
> To: r-help at r-project.org
> Subject: [R] Variable labels and value labels
>
> Hi All,
>
> I am using R for social sciences. In this field I am used to use short variable
> names like "q1" for question 1, "q2" for question 2 and so on and label the
> variables like q1 : "Please tell us your age" or q2 : "Could you state us your
> household income?" or something similar indicating which question is stored
> in the variable.
>
> Similar I am used to label values like 1: "Less than 18 years", 2 : "18 to
> 30 years", 3 : "31 to 60 years" and 4 : "61 years and more".

Seems to me that it is work for factors

nnn <- sample(1:4, 20, replace=TRUE)
q1 <-factor(nnn, labels=c("Less than 18 years", "18 to 30 years", "31 to 60 years","61 years and more"))

You can store such variables in data.frame with names "q1" to "qwhatever" and possibly "Subject"

And you can store annotation of questions in another data frame with 2 columns e.g. "Question" and "Description"

Basically it is an approach similar to database and in R you can merge those two data.frames by ?merge.
>
> I know that the packages Hmisc and memisc have a functionality for this but
> these labeling functions are limited to the packages they were defined for.

It seems to me strange. What prevents you to use functions from Hmisc?

Regards
Petr

> Using the question tests as variable names is possible but very inconvenient.
>
> I there another way for labeling variables and values in R?
>
> Kind regards
>
> Georg Maubach
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From john.archie.mckown at gmail.com  Tue May 31 14:58:27 2016
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 31 May 2016 07:58:27 -0500
Subject: [R] Whether statistical background is must to learn R language
In-Reply-To: <CAHKdztUOFjYCNi35TwCa_LJ7Edy-yAX6V_jDpqC0_byd7OwiYA@mail.gmail.com>
References: <CAHKdztUOFjYCNi35TwCa_LJ7Edy-yAX6V_jDpqC0_byd7OwiYA@mail.gmail.com>
Message-ID: <CAAJSdjhJFJA4EU08Dk5+qM6aEaNvR-M9uZt0650Hvc0k5=GyRg@mail.gmail.com>

On Tue, May 31, 2016 at 2:22 AM, Prasad Kale <prasad.prasad.kale at gmail.com>
wrote:

> Hi,
>
> I am very new to R and just started learning R. But i am not from
> statistical background so can i learn R or to learn R statistical
> background is must.
>

?Well, I got a B.Sc. in Math back many years ago. I "earned" a C- in
Statistics (deserved). I don't use statistics normally. And I use R for
non-statistical purposes. In particular, I use it to read files into data
frames; do some minor statistical stuff (sum, mean, standard deviation,
other really simple stuff); then use ggplot2 to create really nice graphs
which I embed into a web page. I also use R to read a web site in order to
extract data in an HTML table into an R data frame. I then do some minor
manipulation and put the data into a PostgreSQL data base?. I even use it
to create Excel spreadsheets (for people at work who aren't wise enough to
abandon it for LibreOffice).

All that to say that, depending on your need, you don't need to learn
statistics to be able to use R. Of course, R was designed to make it easy
to do statistics. And many users here use it for that. But it is not a "one
trick pony".



>
> Please guide.
>
> Thanks in Advance
> Prasad
>
>

-- 
The unfacts, did we have them, are too imprecisely few to warrant our
certitude.

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From tom at maladmin.com  Tue May 31 15:01:37 2016
From: tom at maladmin.com (Tom Wright)
Date: Tue, 31 May 2016 09:01:37 -0400
Subject: [R] How to import sensitive data when multiple users
 collaborate on R-script?
In-Reply-To: <loom.20160531T123953-299@post.gmane.org>
References: <loom.20160531T123953-299@post.gmane.org>
Message-ID: <CAKmUXV_J7rpRXcBMxKDBdzHv+MsK=2OKp7pu+CB=MtZeqZPcgQ@mail.gmail.com>

My general approach to this is to put the function for loading data
into a separate file which is then sourced in the main analysis file.
Occasionally I'll use a construct like:

if file.exists("loadData_local.R")
  {
    source("loadData_local.R")
  }else{
    source("loadData_generic.R")
  }

Where loadData_generic.R contains the path to some sample (non-sensitive) data.

On Tue, May 31, 2016 at 6:44 AM, Nikolai Stenfors
<nikolai.stenfors at gapps.umu.se> wrote:
> We conduct medical research and our datafiles therefore contain sensitive
> data, not to be shared in the cloud (Dropboc, Box, Drive, Bitbucket, GitHub).
> When we collaborate on a r-analysis-script, we stumble upon the following
> annoyance. Researcher 1 has a line in the script importing the sensitive
> data from his/her personal computer. Researcher 2 has to put an additional
> line importing the data from his/her personal computer. Thus, we have lines
> in the script that are unnecessery for one or the other researcher. How can
> we avoid this? Is there another way of conducting the collaboration. Other
> workflow?
>
> I'm perhaps looking for something like:
> "If the script is run on researcher 1 computer, load file from this
> directory. If the script is run on researcher 2 computer, load data from
> that directory".
>
> Example:
> ## Import data-------------------------------------
> # Researcher 1 import data from laptop1, unnecessery line for Researcher 2
> data <- read.table("/path/to_researcher1_computer/sensitive_data.csv")
>
> # Researcher 2 import data from laptop2 (unnecessery line for Researcher 1)
> data <- read.table("/path/to_researcher2_computer/sensitive_data.csv")
>
> ## Clean data
> data$var1 <- NULL
>
> ## Analyze data
> boxplot(data$var2)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Tue May 31 15:04:24 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 31 May 2016 13:04:24 +0000
Subject: [R] Whether statistical background is must to learn R language
In-Reply-To: <CAHKdztUOFjYCNi35TwCa_LJ7Edy-yAX6V_jDpqC0_byd7OwiYA@mail.gmail.com>
References: <CAHKdztUOFjYCNi35TwCa_LJ7Edy-yAX6V_jDpqC0_byd7OwiYA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C502D15A@SRVEXCHMBX.precheza.cz>

Hi

Well, it seems to me like cooking.

You does not have to be educated cook to be able prepare some food in your kitchen, but knowledge of some recipes can lead to tasty results

Regards
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Prasad
> Kale
> Sent: Tuesday, May 31, 2016 9:23 AM
> To: R-help at r-project.org
> Subject: [R] Whether statistical background is must to learn R language
>
> Hi,
>
> I am very new to R and just started learning R. But i am not from statistical
> background so can i learn R or to learn R statistical background is must.
>
> Please guide.
>
> Thanks in Advance
> Prasad
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From john.archie.mckown at gmail.com  Tue May 31 15:19:31 2016
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 31 May 2016 08:19:31 -0500
Subject: [R] How to import sensitive data when multiple users
 collaborate on R-script?
In-Reply-To: <loom.20160531T123953-299@post.gmane.org>
References: <loom.20160531T123953-299@post.gmane.org>
Message-ID: <CAAJSdjjAYnTBTnOBbGWLaw0ROgpA7vGuLJW-Mss4YRL-oL=bGQ@mail.gmail.com>

On Tue, May 31, 2016 at 5:44 AM, Nikolai Stenfors <
nikolai.stenfors at gapps.umu.se> wrote:

> We conduct medical research and our datafiles therefore contain sensitive
> data, not to be shared in the cloud (Dropboc, Box, Drive, Bitbucket,
> GitHub).
> When we collaborate on a r-analysis-script, we stumble upon the following
> annoyance. Researcher 1 has a line in the script importing the sensitive
> data from his/her personal computer. Researcher 2 has to put an additional
> line importing the data from his/her personal computer. Thus, we have lines
> in the script that are unnecessery for one or the other researcher. How can
> we avoid this? Is there another way of conducting the collaboration. Other
> workflow?
>
> I'm perhaps looking for something like:
> "If the script is run on researcher 1 computer, load file from this
> directory. If the script is run on researcher 2 computer, load data from
> that directory".
>
> Example:
> ## Import data-------------------------------------
> # Researcher 1 import data from laptop1, unnecessery line for Researcher 2
> data <- read.table("/path/to_researcher1_computer/sensitive_data.csv")
>
> # Researcher 2 import data from laptop2 (unnecessery line for Researcher 1)
> data <- read.table("/path/to_researcher2_computer/sensitive_data.csv")
>
> ## Clean data
> data$var1 <- NULL
>
> ## Analyze data
> boxplot(data$var2)
>
>
?Can you have the researchers input the name of the data file to be
analyzed? I use code similar to:

arguments <- commandArgs(trailingOnly=TRUE);
#
# I put in the next command due to my own ignorance
# If you invoke an R script file using just R, you
# need to say something like:
# R BATCH CMD script.R --args ... other arguments ...
#
# but if you use Rscript, you invoke it like:
# Rscript script.R ... other arguments ...
#
# Well, I got confused and did:
# Rscript script.R --args ... other arguments ...
#
# The next line adjusts for my own idiocy.
if ("--args" == arguments[1]) arguments <- arguments[-1];
#
for (file in arguments) {
...
}

Please ignore the line about my own idiocy :-}

Another thought is to use an environment variable which is set in the
user's logon profile (or the Windows registry, forgive my ignorance of
Windows). I think this would be something like:

filename <- Sys.getenv("FILENAME")
if (filename = "") {
... no file name in environment, what to do?
}

You could have someone do this for the user, if he is not familiar with ?
the process.
?


-- 
The unfacts, did we have them, are too imprecisely few to warrant our
certitude.

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue May 31 15:19:44 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 31 May 2016 13:19:44 +0000
Subject: [R] Pairwise table from cloumns
In-Reply-To: <CAF+w_Q0aKGUFA=mt+tZpeh1pS9mBv4NWki21t47ZsyaFRXoyPg@mail.gmail.com>
References: <CAF+w_Q0aKGUFA=mt+tZpeh1pS9mBv4NWki21t47ZsyaFRXoyPg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C502D18F@SRVEXCHMBX.precheza.cz>

Hi

your message is rather scrambled and to be honest not well understandable (by me).

having two column matrix

> mat<-matrix(1:8, 4,2)
> mat
     [,1] [,2]
[1,]    1    5
[2,]    2    6
[3,]    3    7
[4,]    4    8

You can calculate eg. distance

> dist(mat, diag=T, upper=T)
         1        2        3        4
1 0.000000 1.414214 2.828427 4.242641
2 1.414214 0.000000 1.414214 2.828427
3 2.828427 1.414214 0.000000 1.414214
4 4.242641 2.828427 1.414214 0.000000

But from your description I do not understand how you want to reshape your data.

Example, please.

Regards
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of ameneh
> deljoo
> Sent: Tuesday, May 31, 2016 12:13 PM
> To: r-help at r-project.org
> Subject: [R] Pairwise table from cloumns
>
> *Hi Group
> **I have a large data set of individual pairwise values (100 rows) **that I**
> need to reshape into a pairwise matrix for mantel tests of similarity these
> values** .
> **I need this matrix for a Pathfinder network analysis. *
>
> *I have a different data(word) such as :*
>
>
>
>
>
>   living thing
>   0
>
>
>   animal
>   1
>
>
>   blood
>   2
>
>
>   bird
>   3
>
>
>   feathers
>   4
>
>
>   robin
>   5
>
>
>   chicken
> ....
>   6
>
>
>
>   *I need the final matrix to be formatted as based on the similarity
> **      A1    A2    A3    A4
> ** A1  0     32   40     32
> * *A2  32    0    49     38
> ** A3  40    49   0      53
> ** A4  32    38   53     0*
>
> *....*
>
>
> Are there any functions/packages that will make this easier? Thanks Ameneh
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jdnewmil at dcn.davis.ca.us  Tue May 31 15:39:41 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 31 May 2016 06:39:41 -0700
Subject: [R] How to import sensitive data when multiple users
	collaborate on	R-script?
In-Reply-To: <loom.20160531T123953-299@post.gmane.org>
References: <loom.20160531T123953-299@post.gmane.org>
Message-ID: <B31655FF-D0AE-413D-B182-860164E5453D@dcn.davis.ca.us>

Assume everyone will begin their work in a suitable working directory for their computer. Put data in that working directory or some directory "near" it. Then use relative paths to the data instead of absolute paths (don't use paths that start with "/"). I usually start by reading in a "configuration" file that I keep customized for per computer, that includes such things as the names of files I want to analyze. Sometimes there is only one row in that file, other times I select one row on the fly to use. 
-- 
Sent from my phone. Please excuse my brevity.

On May 31, 2016 3:44:21 AM PDT, Nikolai Stenfors <nikolai.stenfors at gapps.umu.se> wrote:
>We conduct medical research and our datafiles therefore contain
>sensitive
>data, not to be shared in the cloud (Dropboc, Box, Drive, Bitbucket,
>GitHub).
>When we collaborate on a r-analysis-script, we stumble upon the
>following
>annoyance. Researcher 1 has a line in the script importing the
>sensitive
>data from his/her personal computer. Researcher 2 has to put an
>additional
>line importing the data from his/her personal computer. Thus, we have
>lines
>in the script that are unnecessery for one or the other researcher. How
>can
>we avoid this? Is there another way of conducting the collaboration.
>Other
>workflow? 
>
>I'm perhaps looking for something like:
>"If the script is run on researcher 1 computer, load file from this
>directory. If the script is run on researcher 2 computer, load data
>from
>that directory". 
>
>Example:
>## Import data-------------------------------------
># Researcher 1 import data from laptop1, unnecessery line for
>Researcher 2
>data <- read.table("/path/to_researcher1_computer/sensitive_data.csv") 
>
># Researcher 2 import data from laptop2 (unnecessery line for
>Researcher 1)
>data <- read.table("/path/to_researcher2_computer/sensitive_data.csv") 
>
>## Clean data
>data$var1 <- NULL
>
>## Analyze data
>boxplot(data$var2)
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue May 31 16:13:09 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 31 May 2016 07:13:09 -0700
Subject: [R] Fractional Factorial Design on 4-level factor
In-Reply-To: <CAOyz9G7Usi-idHK-UerLZx4rWGP+PLO4Jt6iBkHdHLLzGBfYdQ@mail.gmail.com>
References: <CAOyz9G7Usi-idHK-UerLZx4rWGP+PLO4Jt6iBkHdHLLzGBfYdQ@mail.gmail.com>
Message-ID: <CAGxFJbQT61r+mmpK_dxs4pz=GBq72nQ8Vt-aEsPZ8wdG_2TMHg@mail.gmail.com>

Inline.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, May 31, 2016 at 12:05 AM, Michael Haenlein
<haenlein at escpeurope.eu> wrote:
> Dear all,
>
> I am running a simulation experiment with 8 factors that each have 4
> levels. Each combination is repeated 100 times. If I run a full factorial
> this would mean 100*8^4 = 409,600 runs.

Come again?!  8 factors at 4 levels each is 4^8 possible combinations!

I will reply in more detail off list, as this is OT for r-help.


>
> I am trying to reduce the number of scenarios to run using a fractional
> factorial design. I'm interested in estimating the main effects of the 8
> factors plus their 2-way interactions. Any higher level interactions are
> not of interest to me. My plan is to use a standard OLS regression for
> that, once the simulations are over.
>
> I tried to use the FrF2 package to derive a fractional factorial design but
> it seems that this is only working for factors on two levels. Any idea how
> I could derive a fractional factorial design on factors with four levels?
>
> Thanks for your help,
>
> Michael
>
>
>
> Michael Haenlein
> Professor of Marketing
> ESCP Europe
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jfhenson1 at gmail.com  Tue May 31 16:33:25 2016
From: jfhenson1 at gmail.com (James Henson)
Date: Tue, 31 May 2016 09:33:25 -0500
Subject: [R] Whether statistical background is must to learn R language
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C502D15A@SRVEXCHMBX.precheza.cz>
References: <CAHKdztUOFjYCNi35TwCa_LJ7Edy-yAX6V_jDpqC0_byd7OwiYA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C502D15A@SRVEXCHMBX.precheza.cz>
Message-ID: <CABPq8JPddZNV1PTw4xV22DNX4+DjktMfFmxK+4wzT_7-wJUGSQ@mail.gmail.com>

Greetings Prasad,

Here are some tutorials on statistics using R.Statistics and Actuarial
Science ? Carl James Schwarz

http://people.stat.sfu.ca/~cschwarz/CourseNotes/



Statistics and Actuarial Science ? Carl James Schwarz - Programs

http://people.stat.sfu.ca/~cschwarz/Stat-650/Notes/MyPrograms/



Design Analysis and Interpretation of Experiments

http://www.unh.edu/halelab/BIOL933/

Great YouTube channel of R tutorials by Mike Marin,

https://www.youtube.com/user/marinstatlectures

Best regards,
James


On Tue, May 31, 2016 at 8:04 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> Hi
>
> Well, it seems to me like cooking.
>
> You does not have to be educated cook to be able prepare some food in your kitchen, but knowledge of some recipes can lead to tasty results
>
> Regards
> Petr
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Prasad
>> Kale
>> Sent: Tuesday, May 31, 2016 9:23 AM
>> To: R-help at r-project.org
>> Subject: [R] Whether statistical background is must to learn R language
>>
>> Hi,
>>
>> I am very new to R and just started learning R. But i am not from statistical
>> background so can i learn R or to learn R statistical background is must.
>>
>> Please guide.
>>
>> Thanks in Advance
>> Prasad
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue May 31 16:49:07 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 31 May 2016 07:49:07 -0700
Subject: [R] Variable labels and value labels
In-Reply-To: <OF1C9BED83.8BE86DD3-ONC1257FC4.00413344-C1257FC4.0041FD1B@lotus.hawesko.de>
References: <OF1C9BED83.8BE86DD3-ONC1257FC4.00413344-C1257FC4.0041FD1B@lotus.hawesko.de>
Message-ID: <CAGxFJbS5W-L1OZrecDdWT5_uPv+GGm1etUOcfg4AVqNHcBVGkg@mail.gmail.com>

I am not sure this is relevant or helpful, but see ?abbreviate, which
one can use to abbreviate long strings as labels (but only for
English-like languages, I believe).

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, May 31, 2016 at 5:00 AM,  <G.Maubach at weinwolf.de> wrote:
> Hi All,
>
> I am using R for social sciences. In this field I am used to use short
> variable names like "q1" for question 1, "q2" for question 2 and so on and
> label the variables like q1 : "Please tell us your age" or q2 : "Could you
> state us your household income?" or something similar indicating which
> question is stored in the variable.
>
> Similar I am used to label values like 1: "Less than 18 years", 2 : "18 to
> 30 years", 3 : "31 to 60 years" and 4 : "61 years and more".
>
> I know that the packages Hmisc and memisc have a functionality for this
> but these labeling functions are limited to the packages they were defined
> for. Using the question tests as variable names is possible but very
> inconvenient.
>
> I there another way for labeling variables and values in R?
>
> Kind regards
>
> Georg Maubach
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Suphajak at phatrasecurities.com  Tue May 31 16:52:23 2016
From: Suphajak at phatrasecurities.com (Suphajak Ngamlak)
Date: Tue, 31 May 2016 14:52:23 +0000
Subject: [R] Return Misalignment in Return.portfolio function in
 PerformanceAnalytics Package
In-Reply-To: <429C286A082D0D4A8D2EAE084350DB25012000CCEC@PTSECMSMBX04.phatrasec.com>
References: <429C286A082D0D4A8D2EAE084350DB25012000CCEC@PTSECMSMBX04.phatrasec.com>
Message-ID: <429C286A082D0D4A8D2EAE084350DB25012000CD2D@PTSECMSMBX04.phatrasec.com>

Dear R users,



I am trying to calculate NAV of portfolio using Return.portfolio function in PerformanceAnalytics Package. I am having difficulties with how I should specify weight in the function.

I tried to replicate using fixed weights with rebalance_on = "months" by specifying weights explicitly. However, the returns I got were different



Below is the example of the code



# clear memory



rm(list=ls())



library(quantmod)

library(PerformanceAnalytics)



symbols = c(

  "SPY", # US equities, SP500

  "AGG"  # US bonds, Barclay Agg

)

getSymbols(symbols, from="1970-01-01" , to="2014-09-15")

x.P <- do.call(merge, lapply(symbols, function(x) {

  Cl(to.monthly(Ad(get(x)), drop.time = TRUE,

                indexAt='endof'))

}))

colnames(x.P) = paste0(symbols, ".Adjusted")

x.R <- na.omit(Return.calculate(x.P))



# Create a weights vector

w = c(.6,.4) # Traditional 60/40 Equity/Bond portfolio weights



# Create monthly weight

w_mon = x.R[endpoints(x.R, on="months")]

w_mon$SPY.Adjusted = 0.6

w_mon$AGG.Adjusted = 0.4



# Rebalance back to 60/40 proportion

result.months1 = Return.portfolio(x.R, weights=w, rebalance_on = "months", verbose=TRUE)

result.months2 = Return.portfolio(x.R, weights=w_mon, verbose=TRUE)



test1 = data.frame(BOP = result.months1$BOP.Value, EOP = result.months1$EOP.Value, Ret = x.R)

test2 = data.frame(BOP = result.months2$BOP.Value, EOP = result.months2$EOP.Value, Ret = x.R)



# Show input and result



w

head(w_mon)



head(test1)

head(test2)



> w

[1] 0.6 0.4

> head(w_mon)

           SPY.Adjusted AGG.Adjusted

2003-10-31          0.6          0.4

2003-11-28          0.6          0.4

2003-12-31          0.6          0.4

2004-01-30          0.6          0.4

2004-02-27          0.6          0.4

2004-03-31          0.6          0.4

>

> head(test1)

           BOP.SPY.Adjusted BOP.AGG.Adjusted EOP.SPY.Adjusted EOP.AGG.Adjusted Ret.SPY.Adjusted Ret.AGG.Adjusted

2003-10-31        0.6000000        0.4000000        0.6321161        0.3962610       0.05352682     -0.009347612

2003-11-28        0.6170262        0.4113508        0.6237648        0.4127263       0.01092112      0.003343882

2003-12-31        0.6218947        0.4145965        0.6531841        0.4186563       0.05031296      0.009792217

2004-01-30        0.6431042        0.4287361        0.6558184        0.4306248       0.01976999      0.004405247

2004-02-27        0.6518659        0.4345773        0.6607121        0.4395380       0.01357061      0.011414925

2004-03-31        0.6601501        0.4401000        0.6514060        0.4431095      -0.01324559      0.006838188

> head(test2)

           BOP.SPY.Adjusted BOP.AGG.Adjusted EOP.SPY.Adjusted EOP.AGG.Adjusted Ret.SPY.Adjusted Ret.AGG.Adjusted

2003-10-31        0.6000000        0.4000000        0.6065527        0.4013376       0.05352682     -0.009347612

2003-11-28        0.6047341        0.4031561        0.6351601        0.4071039       0.01092112      0.003343882

2003-12-31        0.6253584        0.4169056        0.6377217        0.4187422       0.05031296      0.009792217

2004-01-30        0.6338783        0.4225856        0.6424804        0.4274093       0.01976999      0.004405247

2004-02-27        0.6419339        0.4279559        0.6334311        0.4308824       0.01357061      0.011414925

2004-03-31        0.6385881        0.4257254        0.6265051        0.4137777      -0.01324559      0.006838188



We can see that even though test1 (from using rebalance_on) and test2 (from specifying weight) showed the same Ret.SPY.Adjusted and Ret.AGG.Adjusted.

The return that test 2 used in calculating EOP was from the next period. For example, for test2, EOP.SPY.Adjusted on 2003-10-31 (0.6065527) = BOP.SPY.Adjusted on 2003-10-31 (0.6000000) * Ret.SPY.Adjusted on 2003-11-28 (1+0.01092112)

Could you please suggest how should I set weight to get the same result as in test1?





	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Tue May 31 16:57:04 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Tue, 31 May 2016 15:57:04 +0100
Subject: [R] Whether statistical background is must to learn R language
In-Reply-To: <CAHKdztUOFjYCNi35TwCa_LJ7Edy-yAX6V_jDpqC0_byd7OwiYA@mail.gmail.com>
References: <CAHKdztUOFjYCNi35TwCa_LJ7Edy-yAX6V_jDpqC0_byd7OwiYA@mail.gmail.com>
Message-ID: <e6ec230f-5a5e-2bdb-4b87-a522402cf492@dewey.myzen.co.uk>

Dear Prasad

If you want to use R to do statistics then statistical knowledge is 
essential. If you want to use R to do one of the many, many other things 
it can do then you only need knowledge of whichever of those is your target.

On 31/05/2016 08:22, Prasad Kale wrote:
> Hi,
>
> I am very new to R and just started learning R. But i am not from
> statistical background so can i learn R or to learn R statistical
> background is must.
>
> Please guide.
>
> Thanks in Advance
> Prasad
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From tr206 at kent.ac.uk  Tue May 31 17:05:29 2016
From: tr206 at kent.ac.uk (T.Riedle)
Date: Tue, 31 May 2016 15:05:29 +0000
Subject: [R] sandwich package: HAC estimators
In-Reply-To: <alpine.DEB.2.20.1605311406360.9953@paninaro>
References: <5a4a4884895348f8b010876f9ca10151@ex13-live-mbn1.ad.kent.ac.uk>
	<alpine.DEB.2.20.1605282044060.26454@paninaro>
	<1464645044.828551.622982401.23A6C61F@webmail.messagingengine.com>,
	<alpine.DEB.2.20.1605310929070.23365@paninaro>
	<1464695293382.79381@kent.ac.uk>,
	<alpine.DEB.2.20.1605311406360.9953@paninaro>
Message-ID: <1464707128487.37363@kent.ac.uk>

Many thanks for your feedback.

If I get the code for the waldtest right I can calculate the Chi2 and the F statistic using waldtest(). Can I use the waldtest() without using bread()/ estfun()? That is, I estimate the logit regression using glm() e.g. logit<-glm(...) and insert logit into the waldtest() function.

Does that work to get chi2 under HAC standard errors?

________________________________________
From: Achim Zeileis <Achim.Zeileis at uibk.ac.at>
Sent: 31 May 2016 13:18
To: T.Riedle
Cc: r-help at r-project.org
Subject: Re: [R] sandwich package: HAC estimators

On Tue, 31 May 2016, T.Riedle wrote:

> I understood. But how do I get the R2 an Chi2 of my logistic regression
> under HAC standard errors? I would like to create a table with HAC SE
> via e.g. stargazer().
>
> Do I get these information by using the functions
>
> bread.lrm <- function(x, ...) vcov(x) * nobs(x)
> estfun.lrm <- function(x, ...) residuals(x, "score")?
>
> Do I need to use the coeftest() in this case?

The bread()/estfun() methods enable application of vcovHAC(), kernHAC(),
NeweyWest(). This in turn enables the application of coeftest(),
waldtest(), or linearHypothesis() with a suitable vcov argument.

All of these give you different kinds of Wald tests with HAC covariances
including marginal tests of individual coefficients (coeftest) or global
tests of nested models (waldtest/linearHypothesis). The latter can serve
as replacement for the "chi-squared test". For pseudo-R-squared values I'm
not familiar with HAC-adjusted variants.

And I'm not sure whether there is a LaTeX export solution that encompasses
all of these aspects simultaneously.

> ________________________________________
> From: R-help <r-help-bounces at r-project.org> on behalf of Achim Zeileis <Achim.Zeileis at uibk.ac.at>
> Sent: 31 May 2016 08:36
> To: Leonardo Ferreira Fontenelle
> Cc: r-help at r-project.org
> Subject: Re: [R] sandwich package: HAC estimators
>
> On Mon, 30 May 2016, Leonardo Ferreira Fontenelle wrote:
>
>> Em S?b 28 mai. 2016, ?s 15:50, Achim Zeileis escreveu:
>>> On Sat, 28 May 2016, T.Riedle wrote:
>>>> I thought it would be useful to incorporate the HAC consistent
>>>> covariance matrix into the logistic regression directly and generate an
>>>> output of coefficients and the corresponding standard errors. Is there
>>>> such a function in R?
>>>
>>> Not with HAC standard errors, I think.
>>
>> Don't glmrob() and summary.glmrob(), from robustbase, do that?
>
> No, they implement a different concept of robustness. See also
> https://CRAN.R-project.org/view=Robust
>
> glmrob() implements GLMs that are "robust" or rather "resistant" to
> outliers and other observations that do not come from the main model
> equation. Instead of maximum likelihood (ML) estimation other estimation
> techniques (along with corresponding covariances/standard errors) are
> used.
>
> In contrast, the OP asked for HAC standard errors. The motivation for
> these is that the main model equation does hold for all observations but
> that the observations might be heteroskedastic and/or autocorrelated. In
> this situation, ML estimation is still consistent (albeit not efficient)
> but the covariance matrix estimate needs to be adjusted.
>
>>
>> Leonardo Ferreira Fontenelle, MD, MPH
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.ca.us  Tue May 31 17:09:42 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 31 May 2016 08:09:42 -0700
Subject: [R] Whether statistical background is must to learn R language
In-Reply-To: <CAHKdztUOFjYCNi35TwCa_LJ7Edy-yAX6V_jDpqC0_byd7OwiYA@mail.gmail.com>
References: <CAHKdztUOFjYCNi35TwCa_LJ7Edy-yAX6V_jDpqC0_byd7OwiYA@mail.gmail.com>
Message-ID: <CC70B01D-D71D-4780-908E-B23B8336AE5C@dcn.davis.ca.us>

In every activity, knowing something about it allows you to avoid repeating the mistakes of the past. There are non-statistical uses of programming languages, so you could use it for domains you are familiar with. Or you could see some intriguing statistical analysis and study in that area to understand it so you can apply it.  The difficulty in such ad-hoc approaches to learning is that it can be inefficient and leave big holes in your knowledge. Of course, you may have limited options at this point, so inefficient may be better than not at all.  To minimize the risk of missing a significant point, you should try to be thorough in your self-study and use expert consultation if you are unsure. (This list is not a good venue for purely theoretical questions, but such venues like stats.stackexchange.com or your local university do exist.)

However, please don't apply R like a magic answers box, because you can mislead others and cause harm. 
-- 
Sent from my phone. Please excuse my brevity.

On May 31, 2016 12:22:59 AM PDT, Prasad Kale <prasad.prasad.kale at gmail.com> wrote:
>Hi,
>
>I am very new to R and just started learning R. But i am not from
>statistical background so can i learn R or to learn R statistical
>background is must.
>
>Please guide.
>
>Thanks in Advance
>Prasad
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Tue May 31 17:15:46 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 31 May 2016 11:15:46 -0400
Subject: [R] Fortune candidate: Re: Whether statistical background is must
 to learn R language
Message-ID: <CAM_vjukbqXxDuMTL=+8KixNmji1aSN07asw7sb4GOaKUjr9GQg@mail.gmail.com>

On Tue, May 31, 2016 at 11:09 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
>
>
> However, please don't apply R like a magic answers box, because you can mislead others and cause harm.


From macqueen1 at llnl.gov  Tue May 31 17:55:04 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Tue, 31 May 2016 15:55:04 +0000
Subject: [R] How to import sensitive data when multiple users
 collaborate on R-script?
In-Reply-To: <loom.20160531T123953-299@post.gmane.org>
References: <loom.20160531T123953-299@post.gmane.org>
Message-ID: <D373015E.175E1D%macqueen1@llnl.gov>

There are lots of ways to handle this kind of thing, and the other
suggestions are good. But specific to your "something like" idea, see the
output of

  Sys.info()

in particular
  Sys.info()['nodename']
  Sys.info()['user']

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 5/31/16, 3:44 AM, "R-help on behalf of Nikolai Stenfors"
<r-help-bounces at r-project.org on behalf of nikolai.stenfors at gapps.umu.se>
wrote:

>We conduct medical research and our datafiles therefore contain sensitive
>data, not to be shared in the cloud (Dropboc, Box, Drive, Bitbucket,
>GitHub).
>When we collaborate on a r-analysis-script, we stumble upon the following
>annoyance. Researcher 1 has a line in the script importing the sensitive
>data from his/her personal computer. Researcher 2 has to put an additional
>line importing the data from his/her personal computer. Thus, we have
>lines
>in the script that are unnecessery for one or the other researcher. How
>can
>we avoid this? Is there another way of conducting the collaboration. Other
>workflow? 
>
>I'm perhaps looking for something like:
>"If the script is run on researcher 1 computer, load file from this
>directory. If the script is run on researcher 2 computer, load data from
>that directory". 
>
>Example:
>## Import data-------------------------------------
># Researcher 1 import data from laptop1, unnecessery line for Researcher 2
>data <- read.table("/path/to_researcher1_computer/sensitive_data.csv")
>
># Researcher 2 import data from laptop2 (unnecessery line for Researcher
>1)
>data <- read.table("/path/to_researcher2_computer/sensitive_data.csv")
>
>## Clean data
>data$var1 <- NULL
>
>## Analyze data
>boxplot(data$var2)
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From Achim.Zeileis at uibk.ac.at  Tue May 31 18:19:04 2016
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Tue, 31 May 2016 18:19:04 +0200 (CEST)
Subject: [R] sandwich package: HAC estimators
In-Reply-To: <1464707128487.37363@kent.ac.uk>
References: <5a4a4884895348f8b010876f9ca10151@ex13-live-mbn1.ad.kent.ac.uk>
	<alpine.DEB.2.20.1605282044060.26454@paninaro>
	<1464645044.828551.622982401.23A6C61F@webmail.messagingengine.com>,
	<alpine.DEB.2.20.1605310929070.23365@paninaro>
	<1464695293382.79381@kent.ac.uk>, 
	<alpine.DEB.2.20.1605311406360.9953@paninaro>
	<1464707128487.37363@kent.ac.uk>
Message-ID: <alpine.DEB.2.20.1605311810442.22754@paninaro>

On Tue, 31 May 2016, T.Riedle wrote:

> Many thanks for your feedback.
>
> If I get the code for the waldtest right I can calculate the Chi2 and 
> the F statistic using waldtest().

Yes. In a logit model you would usually use the chi-squared statistic.

> Can I use the waldtest() without using bread()/ estfun()? That is, I 
> estimate the logit regression using glm() e.g. logit<-glm(...) and 
> insert logit into the waldtest() function.
>
> Does that work to get chi2 under HAC standard errors?

I'm not sure what you mean here but I include a worked example. Caveat: 
The data I use are cross-section data with an overly simplified set of 
regressors. So none of this makes sense for the application - but it shows 
how to use the commands.

## load AER package which provides the example data
## and automatically loads "lmtest" and "sandwich"
library("AER")
data("PSID1976", package = "AER")

## fit a simple logit model and obtain marginal Wald tests
## for the coefficients and an overall chi-squared statistic
m <- glm(participation ~ education, data = PSID1976, family = binomial)
summary(m)
anova(m, test = "Chisq")

## replicate the same statistics with coeftest() and lrtest()
coeftest(m)
lrtest(m)

## the likelihood ratio test is asymptotically equivalent
## to the Wald test leading to a similar chi-squared test here
waldtest(m)

## obtain HAC-corrected (Newey-West) versions of the Wald tests
coeftest(m, vcov = NeweyWest)
waldtest(m, vcov = NeweyWest)

Instead of NeweyWest other covariance estimators (e.g., vcovHAC, kernHAC, 
etc.) can also be plugged in.

hth,
Z

> ________________________________________
> From: Achim Zeileis <Achim.Zeileis at uibk.ac.at>
> Sent: 31 May 2016 13:18
> To: T.Riedle
> Cc: r-help at r-project.org
> Subject: Re: [R] sandwich package: HAC estimators
>
> On Tue, 31 May 2016, T.Riedle wrote:
>
>> I understood. But how do I get the R2 an Chi2 of my logistic regression
>> under HAC standard errors? I would like to create a table with HAC SE
>> via e.g. stargazer().
>>
>> Do I get these information by using the functions
>>
>> bread.lrm <- function(x, ...) vcov(x) * nobs(x)
>> estfun.lrm <- function(x, ...) residuals(x, "score")?
>>
>> Do I need to use the coeftest() in this case?
>
> The bread()/estfun() methods enable application of vcovHAC(), kernHAC(),
> NeweyWest(). This in turn enables the application of coeftest(),
> waldtest(), or linearHypothesis() with a suitable vcov argument.
>
> All of these give you different kinds of Wald tests with HAC covariances
> including marginal tests of individual coefficients (coeftest) or global
> tests of nested models (waldtest/linearHypothesis). The latter can serve
> as replacement for the "chi-squared test". For pseudo-R-squared values I'm
> not familiar with HAC-adjusted variants.
>
> And I'm not sure whether there is a LaTeX export solution that encompasses
> all of these aspects simultaneously.
>
>> ________________________________________
>> From: R-help <r-help-bounces at r-project.org> on behalf of Achim Zeileis <Achim.Zeileis at uibk.ac.at>
>> Sent: 31 May 2016 08:36
>> To: Leonardo Ferreira Fontenelle
>> Cc: r-help at r-project.org
>> Subject: Re: [R] sandwich package: HAC estimators
>>
>> On Mon, 30 May 2016, Leonardo Ferreira Fontenelle wrote:
>>
>>> Em S?b 28 mai. 2016, ?s 15:50, Achim Zeileis escreveu:
>>>> On Sat, 28 May 2016, T.Riedle wrote:
>>>>> I thought it would be useful to incorporate the HAC consistent
>>>>> covariance matrix into the logistic regression directly and generate an
>>>>> output of coefficients and the corresponding standard errors. Is there
>>>>> such a function in R?
>>>>
>>>> Not with HAC standard errors, I think.
>>>
>>> Don't glmrob() and summary.glmrob(), from robustbase, do that?
>>
>> No, they implement a different concept of robustness. See also
>> https://CRAN.R-project.org/view=Robust
>>
>> glmrob() implements GLMs that are "robust" or rather "resistant" to
>> outliers and other observations that do not come from the main model
>> equation. Instead of maximum likelihood (ML) estimation other estimation
>> techniques (along with corresponding covariances/standard errors) are
>> used.
>>
>> In contrast, the OP asked for HAC standard errors. The motivation for
>> these is that the main model equation does hold for all observations but
>> that the observations might be heteroskedastic and/or autocorrelated. In
>> this situation, ML estimation is still consistent (albeit not efficient)
>> but the covariance matrix estimate needs to be adjusted.
>>
>>>
>>> Leonardo Ferreira Fontenelle, MD, MPH
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

From Achim.Zeileis at uibk.ac.at  Tue May 31 18:39:16 2016
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Tue, 31 May 2016 18:39:16 +0200 (CEST)
Subject: [R] Fortune candidate: Re: Whether statistical background is
 must to learn R language
In-Reply-To: <CAM_vjukbqXxDuMTL=+8KixNmji1aSN07asw7sb4GOaKUjr9GQg@mail.gmail.com>
References: <CAM_vjukbqXxDuMTL=+8KixNmji1aSN07asw7sb4GOaKUjr9GQg@mail.gmail.com>
Message-ID: <alpine.DEB.2.20.1605311838420.22754@paninaro>

Thanks, Sarah, added now in the devel-package on R-Forge.
Z

On Tue, 31 May 2016, Sarah Goslee wrote:

> On Tue, May 31, 2016 at 11:09 AM, Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> wrote:
>>
>>
>> However, please don't apply R like a magic answers box, because you can mislead others and cause harm.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From santosh2005 at gmail.com  Tue May 31 19:50:24 2016
From: santosh2005 at gmail.com (Santosh)
Date: Tue, 31 May 2016 10:50:24 -0700
Subject: [R] Application of "merge" and "within"
In-Reply-To: <f4bc3443-6e82-e70e-8a4f-fa2a03fb14b8@gmail.com>
References: <CAN_e6XtOQ97qnmEw_bhthw+Sy_g7y98VLfiaw2ga0nTWZ=rkDw@mail.gmail.com>
	<f4bc3443-6e82-e70e-8a4f-fa2a03fb14b8@gmail.com>
Message-ID: <CAN_e6Xu8hN85C+BvmPAyT0YSzRAvHXMMH_GO94TaJw+JprGiNQ@mail.gmail.com>

Thanks for response.. I want to merge two data frames using "within"
function..the columns to used for merge could vary.. then the other
commands become simpler..

Thanks so much for your help!
Santosh

On Sat, May 28, 2016 at 1:53 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 27/05/2016 7:00 PM, Santosh wrote:
>
>> Dear Rxperts!
>>
>> Is there a way to compute relative values.. using within().. function?
>>
>> Any assistance/suggestions are highly welcome!!
>> Thanks again,
>> Santosh...
>> ___________________________________________________________________
>> A sample dataset and the computation "outside" within()  function is
>> shown..
>>
>> q <- data.frame(GL = rep(paste("G",1:3,sep = ""),each = 50),
>>                 G  = rep(1:3,each = 50),
>>                 D = rep(paste("D",1:5,sep = ""),each = 30),
>>                 a = rep(1:15,each = 10),
>>                 t = rep(seq(10),15),
>>                 b = round(runif(150,10,20)))
>> r <- subset(q,!duplicated(paste(G,a)),sel=c(G,a,b))
>> names(r)[3] <- "bl"
>> s <- merge(q,r)
>>  s$db <- s$b-s$bl
>>
>> head(s,5)
>>>
>>     G  a GL  D  t  b bl db
>> 1   1  1 G1 D1  1 13 13  0
>> 2   1  1 G1 D1  2 16 13  3
>> 3   1  1 G1 D1  3 19 13  6
>> 4   1  1 G1 D1  4 12 13 -1
>> 5   1  1 G1 D1  5 19 13  6
>>
>
> Just use
>
>  s <- within(s, db <- b - bl)
>
> Duncan Murdoch
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue May 31 20:29:19 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 31 May 2016 11:29:19 -0700
Subject: [R] Application of "merge" and "within"
In-Reply-To: <CAN_e6Xu8hN85C+BvmPAyT0YSzRAvHXMMH_GO94TaJw+JprGiNQ@mail.gmail.com>
References: <CAN_e6XtOQ97qnmEw_bhthw+Sy_g7y98VLfiaw2ga0nTWZ=rkDw@mail.gmail.com>
	<f4bc3443-6e82-e70e-8a4f-fa2a03fb14b8@gmail.com>
	<CAN_e6Xu8hN85C+BvmPAyT0YSzRAvHXMMH_GO94TaJw+JprGiNQ@mail.gmail.com>
Message-ID: <4B391DF4-B5DB-468E-AF55-9CBB8B3539E5@dcn.davis.ca.us>

What is complicated about merge( q, r )?

Keep in mind that there is nothing simple about the rules for non-standard evaluation of variables that within() uses, and it only gets more complicated if you try to apply those rules to two data frames at once. While I am not quite sure I understand what you really want, I suspect you won't like the behavior you get when you pile too much context into within(). 

Note that dplyr::inner_join, which is designed to fit into a whole ecosystem of NSE functions, uses strings to specify column names to join by just like the merge "by" parameters do rather than using NSE, because it is actually the least confusing approach when two data frames are being referenced. 
-- 
Sent from my phone. Please excuse my brevity.

On May 31, 2016 10:50:24 AM PDT, Santosh <santosh2005 at gmail.com> wrote:
>Thanks for response.. I want to merge two data frames using "within"
>function..the columns to used for merge could vary.. then the other
>commands become simpler..
>
>Thanks so much for your help!
>Santosh
>
>On Sat, May 28, 2016 at 1:53 PM, Duncan Murdoch
><murdoch.duncan at gmail.com>
>wrote:
>
>> On 27/05/2016 7:00 PM, Santosh wrote:
>>
>>> Dear Rxperts!
>>>
>>> Is there a way to compute relative values.. using within()..
>function?
>>>
>>> Any assistance/suggestions are highly welcome!!
>>> Thanks again,
>>> Santosh...
>>> ___________________________________________________________________
>>> A sample dataset and the computation "outside" within()  function is
>>> shown..
>>>
>>> q <- data.frame(GL = rep(paste("G",1:3,sep = ""),each = 50),
>>>                 G  = rep(1:3,each = 50),
>>>                 D = rep(paste("D",1:5,sep = ""),each = 30),
>>>                 a = rep(1:15,each = 10),
>>>                 t = rep(seq(10),15),
>>>                 b = round(runif(150,10,20)))
>>> r <- subset(q,!duplicated(paste(G,a)),sel=c(G,a,b))
>>> names(r)[3] <- "bl"
>>> s <- merge(q,r)
>>>  s$db <- s$b-s$bl
>>>
>>> head(s,5)
>>>>
>>>     G  a GL  D  t  b bl db
>>> 1   1  1 G1 D1  1 13 13  0
>>> 2   1  1 G1 D1  2 16 13  3
>>> 3   1  1 G1 D1  3 19 13  6
>>> 4   1  1 G1 D1  4 12 13 -1
>>> 5   1  1 G1 D1  5 19 13  6
>>>
>>
>> Just use
>>
>>  s <- within(s, db <- b - bl)
>>
>> Duncan Murdoch
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From santosh2005 at gmail.com  Tue May 31 20:39:04 2016
From: santosh2005 at gmail.com (Santosh)
Date: Tue, 31 May 2016 11:39:04 -0700
Subject: [R] Application of "merge" and "within"
In-Reply-To: <4B391DF4-B5DB-468E-AF55-9CBB8B3539E5@dcn.davis.ca.us>
References: <CAN_e6XtOQ97qnmEw_bhthw+Sy_g7y98VLfiaw2ga0nTWZ=rkDw@mail.gmail.com>
	<f4bc3443-6e82-e70e-8a4f-fa2a03fb14b8@gmail.com>
	<CAN_e6Xu8hN85C+BvmPAyT0YSzRAvHXMMH_GO94TaJw+JprGiNQ@mail.gmail.com>
	<4B391DF4-B5DB-468E-AF55-9CBB8B3539E5@dcn.davis.ca.us>
Message-ID: <CAN_e6Xsz9OQEviAzT9PYvt3_o7SwCGiLR45_aTYaRq9SAreWMQ@mail.gmail.com>

I agree that performing merge outside the scope of "within" function, is
pretty straight forward.. At times there are situations when many, if not
all, of the operations are needed to be done within the scope the "within"
environment..

Thanks so much..
Regards,
Santosh

On Tue, May 31, 2016 at 11:29 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> What is complicated about merge( q, r )?
>
> Keep in mind that there is nothing simple about the rules for non-standard
> evaluation of variables that within() uses, and it only gets more
> complicated if you try to apply those rules to two data frames at once.
> While I am not quite sure I understand what you really want, I suspect you
> won't like the behavior you get when you pile too much context into
> within().
>
> Note that dplyr::inner_join, which is designed to fit into a whole
> ecosystem of NSE functions, uses strings to specify column names to join by
> just like the merge "by" parameters do rather than using NSE, because it is
> actually the least confusing approach when two data frames are being
> referenced.
> --
> Sent from my phone. Please excuse my brevity.
>
> On May 31, 2016 10:50:24 AM PDT, Santosh <santosh2005 at gmail.com> wrote:
>>
>> Thanks for response.. I want to merge two data frames using "within"
>> function..the columns to used for merge could vary.. then the other
>> commands become simpler..
>>
>> Thanks so much for your help!
>> Santosh
>>
>> On Sat, May 28, 2016 at 1:53 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
>> wrote:
>>
>>  On 27/05/2016 7:00 PM, Santosh wrote:
>>>
>>>  Dear Rxperts!
>>>>
>>>>  Is there a way to compute relative values.. using within().. function?
>>>>
>>>>  Any assistance/suggestions are highly welcome!!
>>>>  Thanks again,
>>>>  Santosh...
>>>> ------------------------------
>>>>
>>>>  A sample dataset and the computation "outside" within()  function is
>>>>  shown..
>>>>
>>>>  q <- data.frame(GL =
>>>> rep(paste("G",1:3,sep = ""),each = 50),
>>>>                  G  = rep(1:3,each = 50),
>>>>                  D = rep(paste("D",1:5,sep = ""),each = 30),
>>>>                  a = rep(1:15,each = 10),
>>>>                  t = rep(seq(10),15),
>>>>                  b = round(runif(150,10,20)))
>>>>  r <- subset(q,!duplicated(paste(G,a)),sel=c(G,a,b))
>>>>  names(r)[3] <- "bl"
>>>>  s <- merge(q,r)
>>>>   s$db <- s$b-s$bl
>>>>
>>>>  head(s,5)
>>>>
>>>>>
>>>>>      G  a GL  D  t  b bl db
>>>>  1   1  1 G1 D1  1 13 13  0
>>>>  2   1  1 G1 D1  2 16 13  3
>>>>  3   1  1 G1 D1  3 19 13  6
>>>>  4   1  1 G1 D1  4 12 13 -1
>>>>  5   1  1 G1 D1  5 19 13  6
>>>
>>>
>>>
>>>  Just use
>>>
>>>   s <- within(s, db <- b - bl)
>>>
>>>  Duncan Murdoch
>>
>>
>>
>>
>>  [[alternative HTML version deleted]]
>>
>> ------------------------------
>>
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue May 31 20:46:06 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 31 May 2016 11:46:06 -0700
Subject: [R] Application of "merge" and "within"
In-Reply-To: <CAN_e6Xsz9OQEviAzT9PYvt3_o7SwCGiLR45_aTYaRq9SAreWMQ@mail.gmail.com>
References: <CAN_e6XtOQ97qnmEw_bhthw+Sy_g7y98VLfiaw2ga0nTWZ=rkDw@mail.gmail.com>
	<f4bc3443-6e82-e70e-8a4f-fa2a03fb14b8@gmail.com>
	<CAN_e6Xu8hN85C+BvmPAyT0YSzRAvHXMMH_GO94TaJw+JprGiNQ@mail.gmail.com>
	<4B391DF4-B5DB-468E-AF55-9CBB8B3539E5@dcn.davis.ca.us>
	<CAN_e6Xsz9OQEviAzT9PYvt3_o7SwCGiLR45_aTYaRq9SAreWMQ@mail.gmail.com>
Message-ID: <AF778A4F-2FB0-4A64-B160-B8A5E0C1D761@dcn.davis.ca.us>

Then perhaps your example should illustrate one of these "many situations" that trouble you but you are not being clear about. 
-- 
Sent from my phone. Please excuse my brevity.

On May 31, 2016 11:39:04 AM PDT, Santosh <santosh2005 at gmail.com> wrote:
>I agree that performing merge outside the scope of "within" function,
>is
>pretty straight forward.. At times there are situations when many, if
>not
>all, of the operations are needed to be done within the scope the
>"within"
>environment..
>
>Thanks so much..
>Regards,
>Santosh
>
>On Tue, May 31, 2016 at 11:29 AM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> What is complicated about merge( q, r )?
>>
>> Keep in mind that there is nothing simple about the rules for
>non-standard
>> evaluation of variables that within() uses, and it only gets more
>> complicated if you try to apply those rules to two data frames at
>once.
>> While I am not quite sure I understand what you really want, I
>suspect you
>> won't like the behavior you get when you pile too much context into
>> within().
>>
>> Note that dplyr::inner_join, which is designed to fit into a whole
>> ecosystem of NSE functions, uses strings to specify column names to
>join by
>> just like the merge "by" parameters do rather than using NSE, because
>it is
>> actually the least confusing approach when two data frames are being
>> referenced.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On May 31, 2016 10:50:24 AM PDT, Santosh <santosh2005 at gmail.com>
>wrote:
>>>
>>> Thanks for response.. I want to merge two data frames using "within"
>>> function..the columns to used for merge could vary.. then the other
>>> commands become simpler..
>>>
>>> Thanks so much for your help!
>>> Santosh
>>>
>>> On Sat, May 28, 2016 at 1:53 PM, Duncan Murdoch
><murdoch.duncan at gmail.com>
>>> wrote:
>>>
>>>  On 27/05/2016 7:00 PM, Santosh wrote:
>>>>
>>>>  Dear Rxperts!
>>>>>
>>>>>  Is there a way to compute relative values.. using within()..
>function?
>>>>>
>>>>>  Any assistance/suggestions are highly welcome!!
>>>>>  Thanks again,
>>>>>  Santosh...
>>>>> ------------------------------
>>>>>
>>>>>  A sample dataset and the computation "outside" within()  function
>is
>>>>>  shown..
>>>>>
>>>>>  q <- data.frame(GL =
>>>>> rep(paste("G",1:3,sep = ""),each = 50),
>>>>>                  G  = rep(1:3,each = 50),
>>>>>                  D = rep(paste("D",1:5,sep = ""),each = 30),
>>>>>                  a = rep(1:15,each = 10),
>>>>>                  t = rep(seq(10),15),
>>>>>                  b = round(runif(150,10,20)))
>>>>>  r <- subset(q,!duplicated(paste(G,a)),sel=c(G,a,b))
>>>>>  names(r)[3] <- "bl"
>>>>>  s <- merge(q,r)
>>>>>   s$db <- s$b-s$bl
>>>>>
>>>>>  head(s,5)
>>>>>
>>>>>>
>>>>>>      G  a GL  D  t  b bl db
>>>>>  1   1  1 G1 D1  1 13 13  0
>>>>>  2   1  1 G1 D1  2 16 13  3
>>>>>  3   1  1 G1 D1  3 19 13  6
>>>>>  4   1  1 G1 D1  4 12 13 -1
>>>>>  5   1  1 G1 D1  5 19 13  6
>>>>
>>>>
>>>>
>>>>  Just use
>>>>
>>>>   s <- within(s, db <- b - bl)
>>>>
>>>>  Duncan Murdoch
>>>
>>>
>>>
>>>
>>>  [[alternative HTML version deleted]]
>>>
>>> ------------------------------
>>>
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>

	[[alternative HTML version deleted]]


From vivek4 at mail.usf.edu  Tue May 31 20:29:10 2016
From: vivek4 at mail.usf.edu (Vivek Singh)
Date: Tue, 31 May 2016 14:29:10 -0400
Subject: [R] R getting "Killed" while running VAR model
Message-ID: <CAJGK8=-AW81ypB_cZsO55XCXfk9+uNL26fv0UyjubUZpeLpBAQ@mail.gmail.com>

Hi,

I am using VARS (vector autoregressive model). The process gets killed
after running for sometime. Following is the output of R.

vivek at isds-research:~/cloudAuction/padding/panel$ cat var.Rout

R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> data=read.csv("output1.csv")
> attach(data)
> only_variables= subset(data, select=c(-date,-hour,-minute,-sec))
>
> library("vars")
Loading required package: MASS
Loading required package: strucchange
Loading required package: zoo

Attaching package: ?zoo?

The following objects are masked from ?package:base?:

    as.Date, as.Date.numeric

Loading required package: sandwich
Loading required package: urca
Loading required package: lmtest
> summary(VAR(only_variables, p = 1, type ="both"))
*Killed*

	[[alternative HTML version deleted]]


From kolubind at lsbu.ac.uk  Tue May 31 20:32:28 2016
From: kolubind at lsbu.ac.uk (Dan Kolubinski)
Date: Tue, 31 May 2016 19:32:28 +0100
Subject: [R] Regression and Sub-Groups Analysis in Metafor
In-Reply-To: <ed44259a-0c32-2354-0e7f-be83b302df71@dewey.myzen.co.uk>
References: <CAB01jfLmwNozOh0d+L=R1nVL6O1L1kLO+YiKU1F6VqiNxmD=rQ@mail.gmail.com>
	<ed44259a-0c32-2354-0e7f-be83b302df71@dewey.myzen.co.uk>
Message-ID: <CAB01jfJHerGxb2f0zU08YmF5szGux-Q+smqA0tiGr6BRuUUyBQ@mail.gmail.com>

That makes perfect sense.  Thank you, Michael.  I take your point about not
chasing the data and definitely see the risks involved in doing so.  Our
hypothesis was that the first, second and fourth variables would be
significant, but the third one (intervention) would not be.  I will
double-check the dataset to make sure that there are not any errors and
will report the results as we see them.  I much appreciate you taking the
time!

Best wishes,
Dan

On Tue, May 31, 2016 at 12:02 PM, Michael Dewey <lists at dewey.myzen.co.uk>
wrote:

> In-line
>
> On 30/05/2016 19:27, Dan Kolubinski wrote:
>
>> I am completing a meta-analysis on the effect of CBT on low self-esteem
>> and
>> I could use some help regarding the regression feature in metafor.  Based
>> on the studies that I am using for the analysis, I identified 4 potential
>> moderators that I want to explore:
>> - Some of the studies that I am using used RCTs to compare an intervention
>> with a waitlist and others used the pre-score as the control in a
>> single-group design.
>> - Some of the groups took place in one day and others took several weeks.
>> - There are three discernible interventions being represented
>> - The initial level of self-esteem varies
>>
>> Based on the above, I used this command to conduct a meta-analysis using
>> standarized mean differences:
>>
>>
>>
>> MetaMod<-rma(m1i=m1, m2i=m2, sd1i=sd1, sd2i=sd2, n1i=n1, n2i=n2,
>> mods=cbind(dur, rct, int, level),measure = "SMD")
>>
>>
> You could also say mods = ~ dur + rct + int + level
>
>
>>
>> Would this be the best command to use for what I described?  Also, what
>> could I add to the command so that the forest plot shows a sub-group
>> analysis using the 'dur' variable as a between-groups distinction?
>>
>>
> You have to adjust the forest plot by hand and then use add.polygon to
> add the summaries for each level of dur.
>
>
>> Also, with respect to the moderators, this is what was delivered:
>>
>>
>>
>> Test of Moderators (coefficient(s) 2,3,4,5):
>> QM(df = 4) = 8.7815, p-val = 0.0668
>>
>> Model Results:
>>
>>          estimate      se     zval    pval    ci.lb   ci.ub
>> intrcpt    0.7005  0.6251   1.1207  0.2624  -0.5246  1.9256
>> dur        0.5364  0.2411   2.2249  0.0261   0.0639  1.0090  *
>> rct       -0.3714  0.1951  -1.9035  0.0570  -0.7537  0.0110  .
>> int        0.0730  0.1102   0.6628  0.5075  -0.1430  0.2890
>> level     -0.2819  0.2139  -1.3180  0.1875  -0.7010  0.1373
>>
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>>
>>
> So the totality of moderators did not reach an arbitrary level of
> significance.
>
>
>> From this, can I interpret that the variable 'dur' (duration of
>>>
>> intervention) has a significant effect and the variable 'rct' (whether a
>> study was an RCT or used pre-post scores) was just shy of being
>> statistically significant?  I mainly ask, because the QM-score has a
>> p-value of 0.0668, which I thought would mean that none of the moderators
>> would be significant.  Would I be better off just listing one or two
>> moderators instead of four?
>>
>>
> At the moment you get an overall test of the moderators which you had a
> scientific reason for using. If you start selecting based on the data
> you run the risk of ending up with confidence intervals and significance
> levels which do not have the meaning they are supposed to have.
>
>
> Much appreciated,
>> Dan
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>

	[[alternative HTML version deleted]]


From vinaypkulkarni at yahoo.com  Tue May 31 20:28:51 2016
From: vinaypkulkarni at yahoo.com (VINAY KULKARNI)
Date: Tue, 31 May 2016 18:28:51 +0000 (UTC)
Subject: [R] SEM GFI
References: <1103804586.1954135.1464719331934.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1103804586.1954135.1464719331934.JavaMail.yahoo@mail.yahoo.com>

Hi,
I am exactly replicating the SEM model which was done in SAS using Proc Calis in R.
Used sem package in R but not getting the GFI as same as in SAS (approximately 15% difference)
and also one link is insignificant but in SAS am getting significant.
Searched through online in different blogs but not able to get the solution.
Please let me know what might be the reason.
Thanks,Vinay



	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue May 31 22:40:37 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 31 May 2016 13:40:37 -0700
Subject: [R] R getting "Killed" while running VAR model
In-Reply-To: <CAJGK8=-AW81ypB_cZsO55XCXfk9+uNL26fv0UyjubUZpeLpBAQ@mail.gmail.com>
References: <CAJGK8=-AW81ypB_cZsO55XCXfk9+uNL26fv0UyjubUZpeLpBAQ@mail.gmail.com>
Message-ID: <CAGxFJbQsgY08n3OgyVJhMy=j7yk_b8RQMkyan1nnr5fRyok9fQ@mail.gmail.com>

Standard reply (see posting guide):

Update to the current version of R (3.3.0 or so) and retry. Your
version is old -- this often leads to incompatibilities with newer
software versions.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, May 31, 2016 at 11:29 AM, Vivek Singh <vivek4 at mail.usf.edu> wrote:
> Hi,
>
> I am using VARS (vector autoregressive model). The process gets killed
> after running for sometime. Following is the output of R.
>
> vivek at isds-research:~/cloudAuction/padding/panel$ cat var.Rout
>
> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
> Copyright (C) 2013 The R Foundation for Statistical Computing
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
>   Natural language support but running in an English locale
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
>
> [Previously saved workspace restored]
>
>> data=read.csv("output1.csv")
>> attach(data)
>> only_variables= subset(data, select=c(-date,-hour,-minute,-sec))
>>
>> library("vars")
> Loading required package: MASS
> Loading required package: strucchange
> Loading required package: zoo
>
> Attaching package: ?zoo?
>
> The following objects are masked from ?package:base?:
>
>     as.Date, as.Date.numeric
>
> Loading required package: sandwich
> Loading required package: urca
> Loading required package: lmtest
>> summary(VAR(only_variables, p = 1, type ="both"))
> *Killed*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ligges at statistik.tu-dortmund.de  Tue May 31 22:41:38 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 31 May 2016 22:41:38 +0200
Subject: [R] R getting "Killed" while running VAR model
In-Reply-To: <CAJGK8=-AW81ypB_cZsO55XCXfk9+uNL26fv0UyjubUZpeLpBAQ@mail.gmail.com>
References: <CAJGK8=-AW81ypB_cZsO55XCXfk9+uNL26fv0UyjubUZpeLpBAQ@mail.gmail.com>
Message-ID: <377df3ac-38e3-9e64-c516-4c5e6f900b38@statistik.tu-dortmund.de>

Wild guess: You have huge and high dimensional VAR models, i.e. the 
matrices get huge and you use huge amounts of memory and you use more 
than what is available physically. The operating system protects itself 
by killing processes in such a case...

Best,
Uwe Ligges


On 31.05.2016 20:29, Vivek Singh wrote:
> Hi,
>
> I am using VARS (vector autoregressive model). The process gets killed
> after running for sometime. Following is the output of R.
>
> vivek at isds-research:~/cloudAuction/padding/panel$ cat var.Rout
>
> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
> Copyright (C) 2013 The R Foundation for Statistical Computing
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
>   Natural language support but running in an English locale
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
>
> [Previously saved workspace restored]
>
>> data=read.csv("output1.csv")
>> attach(data)
>> only_variables= subset(data, select=c(-date,-hour,-minute,-sec))
>>
>> library("vars")
> Loading required package: MASS
> Loading required package: strucchange
> Loading required package: zoo
>
> Attaching package: ?zoo?
>
> The following objects are masked from ?package:base?:
>
>     as.Date, as.Date.numeric
>
> Loading required package: sandwich
> Loading required package: urca
> Loading required package: lmtest
>> summary(VAR(only_variables, p = 1, type ="both"))
> *Killed*
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter.4567 at gmail.com  Tue May 31 22:43:35 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 31 May 2016 13:43:35 -0700
Subject: [R] Regression and Sub-Groups Analysis in Metafor
In-Reply-To: <CAB01jfJHerGxb2f0zU08YmF5szGux-Q+smqA0tiGr6BRuUUyBQ@mail.gmail.com>
References: <CAB01jfLmwNozOh0d+L=R1nVL6O1L1kLO+YiKU1F6VqiNxmD=rQ@mail.gmail.com>
	<ed44259a-0c32-2354-0e7f-be83b302df71@dewey.myzen.co.uk>
	<CAB01jfJHerGxb2f0zU08YmF5szGux-Q+smqA0tiGr6BRuUUyBQ@mail.gmail.com>
Message-ID: <CAGxFJbRGCLYZxT6RUUbsAeyE=b0+Z1dTARnNFMZkjt=t2d3vhg@mail.gmail.com>

Briefly, as this is off-topic, and inline:
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, May 31, 2016 at 11:32 AM, Dan Kolubinski <kolubind at lsbu.ac.uk> wrote:
> That makes perfect sense.  Thank you, Michael.  I take your point about not
> chasing the data and definitely see the risks involved in doing so.  Our
> hypothesis was that the first, second and fourth variables would be
> significant, but the third one (intervention) would not be.

That is **not** a legitimate scientific hypothesis. Post to a
statistical list like stats.stackexchange.com to learn why not.

Cheers,
Bert



 I will
> double-check the dataset to make sure that there are not any errors and
> will report the results as we see them.  I much appreciate you taking the
> time!
>
> Best wishes,
> Dan
>
> On Tue, May 31, 2016 at 12:02 PM, Michael Dewey <lists at dewey.myzen.co.uk>
> wrote:
>
>> In-line
>>
>> On 30/05/2016 19:27, Dan Kolubinski wrote:
>>
>>> I am completing a meta-analysis on the effect of CBT on low self-esteem
>>> and
>>> I could use some help regarding the regression feature in metafor.  Based
>>> on the studies that I am using for the analysis, I identified 4 potential
>>> moderators that I want to explore:
>>> - Some of the studies that I am using used RCTs to compare an intervention
>>> with a waitlist and others used the pre-score as the control in a
>>> single-group design.
>>> - Some of the groups took place in one day and others took several weeks.
>>> - There are three discernible interventions being represented
>>> - The initial level of self-esteem varies
>>>
>>> Based on the above, I used this command to conduct a meta-analysis using
>>> standarized mean differences:
>>>
>>>
>>>
>>> MetaMod<-rma(m1i=m1, m2i=m2, sd1i=sd1, sd2i=sd2, n1i=n1, n2i=n2,
>>> mods=cbind(dur, rct, int, level),measure = "SMD")
>>>
>>>
>> You could also say mods = ~ dur + rct + int + level
>>
>>
>>>
>>> Would this be the best command to use for what I described?  Also, what
>>> could I add to the command so that the forest plot shows a sub-group
>>> analysis using the 'dur' variable as a between-groups distinction?
>>>
>>>
>> You have to adjust the forest plot by hand and then use add.polygon to
>> add the summaries for each level of dur.
>>
>>
>>> Also, with respect to the moderators, this is what was delivered:
>>>
>>>
>>>
>>> Test of Moderators (coefficient(s) 2,3,4,5):
>>> QM(df = 4) = 8.7815, p-val = 0.0668
>>>
>>> Model Results:
>>>
>>>          estimate      se     zval    pval    ci.lb   ci.ub
>>> intrcpt    0.7005  0.6251   1.1207  0.2624  -0.5246  1.9256
>>> dur        0.5364  0.2411   2.2249  0.0261   0.0639  1.0090  *
>>> rct       -0.3714  0.1951  -1.9035  0.0570  -0.7537  0.0110  .
>>> int        0.0730  0.1102   0.6628  0.5075  -0.1430  0.2890
>>> level     -0.2819  0.2139  -1.3180  0.1875  -0.7010  0.1373
>>>
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>
>>>
>>>
>> So the totality of moderators did not reach an arbitrary level of
>> significance.
>>
>>
>>> From this, can I interpret that the variable 'dur' (duration of
>>>>
>>> intervention) has a significant effect and the variable 'rct' (whether a
>>> study was an RCT or used pre-post scores) was just shy of being
>>> statistically significant?  I mainly ask, because the QM-score has a
>>> p-value of 0.0668, which I thought would mean that none of the moderators
>>> would be significant.  Would I be better off just listing one or two
>>> moderators instead of four?
>>>
>>>
>> At the moment you get an overall test of the moderators which you had a
>> scientific reason for using. If you start selecting based on the data
>> you run the risk of ending up with confidence intervals and significance
>> levels which do not have the meaning they are supposed to have.
>>
>>
>> Much appreciated,
>>> Dan
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>> --
>> Michael
>> http://www.dewey.myzen.co.uk/home.html
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue May 31 22:46:06 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 31 May 2016 13:46:06 -0700
Subject: [R] SEM GFI
In-Reply-To: <1103804586.1954135.1464719331934.JavaMail.yahoo@mail.yahoo.com>
References: <1103804586.1954135.1464719331934.JavaMail.yahoo.ref@mail.yahoo.com>
	<1103804586.1954135.1464719331934.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAGxFJbTp+0uDC1YDxF-LgDsvcEx_69BU=Nc+BBqMMZnP9j3t9Q@mail.gmail.com>

Probably impossible to answer without your following the posting guide
and posting your code, etc.

Cheers,

Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, May 31, 2016 at 11:28 AM, VINAY KULKARNI via R-help
<r-help at r-project.org> wrote:
> Hi,
> I am exactly replicating the SEM model which was done in SAS using Proc Calis in R.
> Used sem package in R but not getting the GFI as same as in SAS (approximately 15% difference)
> and also one link is insignificant but in SAS am getting significant.
> Searched through online in different blogs but not able to get the solution.
> Please let me know what might be the reason.
> Thanks,Vinay
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From arnobras at hotmail.com  Tue May 31 22:14:53 2016
From: arnobras at hotmail.com (Carlos)
Date: Tue, 31 May 2016 22:14:53 +0200
Subject: [R]  Searching for antilog function
In-Reply-To: <loom.20041125T051716-875@post.gmane.org>
References: <loom.20041125T051716-875@post.gmane.org>
Message-ID: <BLU436-SMTP1727A2BB2DBF0627C8FA469DF460@phx.gbl>

The following function can do the work as well

  antilog<-function(lx,base)
  {
  lbx<-lx/log(exp(1),base=base)
  result<-exp(lbx)
  result
  }

This solution is based on the change of base formula which states that :

log (x,base=b) = log(x,base=a)/log(b,base=a)

The original logarithm is changed into natural logarithm and then the 
exponential function is employed

The arguments are:

'lx', de logarithm we have.
'base', the base what was employed to obtain lx

For example:

log(78,10) = 1.892095

Then the antllog is

antilog(1.892095,10)

78

As expected.


From kolubind at lsbu.ac.uk  Tue May 31 22:52:56 2016
From: kolubind at lsbu.ac.uk (Dan Kolubinski)
Date: Tue, 31 May 2016 21:52:56 +0100
Subject: [R] Regression and Sub-Groups Analysis in Metafor
In-Reply-To: <CAGxFJbRGCLYZxT6RUUbsAeyE=b0+Z1dTARnNFMZkjt=t2d3vhg@mail.gmail.com>
References: <CAB01jfLmwNozOh0d+L=R1nVL6O1L1kLO+YiKU1F6VqiNxmD=rQ@mail.gmail.com>
	<ed44259a-0c32-2354-0e7f-be83b302df71@dewey.myzen.co.uk>
	<CAB01jfJHerGxb2f0zU08YmF5szGux-Q+smqA0tiGr6BRuUUyBQ@mail.gmail.com>
	<CAGxFJbRGCLYZxT6RUUbsAeyE=b0+Z1dTARnNFMZkjt=t2d3vhg@mail.gmail.com>
Message-ID: <CAB01jfK2GUFVkORUHS0ZL_X-1o_qDch=QHUHk5bhAPJ1NyDv8w@mail.gmail.com>

Thank you, Bert.  That's perfect!  I will do.
On 31 May 2016 21:43, "Bert Gunter" <bgunter.4567 at gmail.com> wrote:

> Briefly, as this is off-topic, and inline:
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, May 31, 2016 at 11:32 AM, Dan Kolubinski <kolubind at lsbu.ac.uk>
> wrote:
> > That makes perfect sense.  Thank you, Michael.  I take your point about
> not
> > chasing the data and definitely see the risks involved in doing so.  Our
> > hypothesis was that the first, second and fourth variables would be
> > significant, but the third one (intervention) would not be.
>
> That is **not** a legitimate scientific hypothesis. Post to a
> statistical list like stats.stackexchange.com to learn why not.
>
> Cheers,
> Bert
>
>
>
>  I will
> > double-check the dataset to make sure that there are not any errors and
> > will report the results as we see them.  I much appreciate you taking the
> > time!
> >
> > Best wishes,
> > Dan
> >
> > On Tue, May 31, 2016 at 12:02 PM, Michael Dewey <lists at dewey.myzen.co.uk
> >
> > wrote:
> >
> >> In-line
> >>
> >> On 30/05/2016 19:27, Dan Kolubinski wrote:
> >>
> >>> I am completing a meta-analysis on the effect of CBT on low self-esteem
> >>> and
> >>> I could use some help regarding the regression feature in metafor.
> Based
> >>> on the studies that I am using for the analysis, I identified 4
> potential
> >>> moderators that I want to explore:
> >>> - Some of the studies that I am using used RCTs to compare an
> intervention
> >>> with a waitlist and others used the pre-score as the control in a
> >>> single-group design.
> >>> - Some of the groups took place in one day and others took several
> weeks.
> >>> - There are three discernible interventions being represented
> >>> - The initial level of self-esteem varies
> >>>
> >>> Based on the above, I used this command to conduct a meta-analysis
> using
> >>> standarized mean differences:
> >>>
> >>>
> >>>
> >>> MetaMod<-rma(m1i=m1, m2i=m2, sd1i=sd1, sd2i=sd2, n1i=n1, n2i=n2,
> >>> mods=cbind(dur, rct, int, level),measure = "SMD")
> >>>
> >>>
> >> You could also say mods = ~ dur + rct + int + level
> >>
> >>
> >>>
> >>> Would this be the best command to use for what I described?  Also, what
> >>> could I add to the command so that the forest plot shows a sub-group
> >>> analysis using the 'dur' variable as a between-groups distinction?
> >>>
> >>>
> >> You have to adjust the forest plot by hand and then use add.polygon to
> >> add the summaries for each level of dur.
> >>
> >>
> >>> Also, with respect to the moderators, this is what was delivered:
> >>>
> >>>
> >>>
> >>> Test of Moderators (coefficient(s) 2,3,4,5):
> >>> QM(df = 4) = 8.7815, p-val = 0.0668
> >>>
> >>> Model Results:
> >>>
> >>>          estimate      se     zval    pval    ci.lb   ci.ub
> >>> intrcpt    0.7005  0.6251   1.1207  0.2624  -0.5246  1.9256
> >>> dur        0.5364  0.2411   2.2249  0.0261   0.0639  1.0090  *
> >>> rct       -0.3714  0.1951  -1.9035  0.0570  -0.7537  0.0110  .
> >>> int        0.0730  0.1102   0.6628  0.5075  -0.1430  0.2890
> >>> level     -0.2819  0.2139  -1.3180  0.1875  -0.7010  0.1373
> >>>
> >>> ---
> >>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >>>
> >>>
> >>>
> >> So the totality of moderators did not reach an arbitrary level of
> >> significance.
> >>
> >>
> >>> From this, can I interpret that the variable 'dur' (duration of
> >>>>
> >>> intervention) has a significant effect and the variable 'rct' (whether
> a
> >>> study was an RCT or used pre-post scores) was just shy of being
> >>> statistically significant?  I mainly ask, because the QM-score has a
> >>> p-value of 0.0668, which I thought would mean that none of the
> moderators
> >>> would be significant.  Would I be better off just listing one or two
> >>> moderators instead of four?
> >>>
> >>>
> >> At the moment you get an overall test of the moderators which you had a
> >> scientific reason for using. If you start selecting based on the data
> >> you run the risk of ending up with confidence intervals and significance
> >> levels which do not have the meaning they are supposed to have.
> >>
> >>
> >> Much appreciated,
> >>> Dan
> >>>
> >>>       [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>>
> >> --
> >> Michael
> >> http://www.dewey.myzen.co.uk/home.html
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> Copyright in this email and in any attachments belongs to London South
> Bank University. This email, and its attachments if any, may be
> confidential or legally privileged and is intended to be seen only by the
> person to whom it is addressed. If you are not the intended recipient,
> please note the following: (1) You should take immediate action to notify
> the sender and delete the original email and all copies from your computer
> systems; (2) You should not read copy or use the contents of the email nor
> disclose it or its existence to anyone else. The views expressed herein are
> those of the author(s) and should not be taken as those of London South
> Bank University, unless this is specifically stated. London South Bank
> University is a company limited by guarantee registered in England and
> Wales. The following details apply to London South Bank University: Company
> number - 00986761; Registered office and trading address - 103 Borough Road
> London SE1 0AA; VAT number - 778 1116 17 Email address -
> LSBUinfo at lsbu.ac.uk
> ============================================
> The LSBU communications disclaimer can be found at
> http://www.lsbu.ac.uk/ict/legal/
>

	[[alternative HTML version deleted]]


