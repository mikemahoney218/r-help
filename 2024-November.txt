From |kry|ov @end|ng |rom d|@root@org  Fri Nov  1 22:29:45 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Sat, 2 Nov 2024 00:29:45 +0300
Subject: [R] 
 Invalid term in model formula with gmm after formula.tools is loaded
In-Reply-To: <CALcKxsq+6FKxX_JFA9RDoc1JWfiuCNSqKopQ3j=ex=Z+hdN8Tg@mail.gmail.com>
References: <CALcKxsq+6FKxX_JFA9RDoc1JWfiuCNSqKopQ3j=ex=Z+hdN8Tg@mail.gmail.com>
Message-ID: <20241102002945.64b6c79a@Tarkus>

Hi Aristide and welcome to R-help!

Your message was a bit mangled [*]. It's best to compose messages to
this mailing list in plain text. Otherwise (when composed in HTML), the
mailing list eats the HTML part and we're left with the plain text part
automatically generated by your mailer, which isn't always readable.

? Wed, 30 Oct 2024 17:45:29 +0100
Elys?e Aristide <ariel92and at gmail.com> ?????:

> I am using the gmm function from the gmm package and encountered an
> unexpected error. No model can be estimated if I load formula.tools?I
> need to restart R each time.

I can reproduce the problem:

library(gmm)
data(Finance)
r <- Finance[1:300, 1:10]                                              
rm <- Finance[1:300, "rm"]                             
rf <- Finance[1:300, "rf"]
z <- as.matrix(r-rf) 
zm <- rm-rf
res <- gmm(z ~ zm, x = ~ zm)
library(formula.tools)
gmm(z ~ zm, x = ~ zm) # signals an error

Looking at the traceback(), I see the formula being transformed into NA
~ NA at some point:

10: terms.formula(formula, data = data) # <-- error happens here
9: terms(formula, data = data)
8: model.frame.default(data = object$data, formula = NA ~ NA, drop.unused.levels = TRUE, 
       na.action = "na.pass")
7: model.frame(data = object$data, formula = NA ~ NA, drop.unused.levels = TRUE, 
       na.action = "na.pass") # <-- formula is already NA ~ NA here
6: eval(mfh, parent.frame())
5: eval(mfh, parent.frame())
4: getDat(object$g, object$x, data = object$data)
3: getModel.baseGmm(all_args, ...)
2: getModel(all_args, ...)
1: gmm(z ~ zm, x = ~zm)

It seems that in base R, as.character(z ~ zm) returns a three-element
character vector, while with formula.tools loaded, it only returns a
single string, 'z ~ zm'. This breaks formula manipulation in getDat().

An immediate workaround is to replace the method provided by
formula.tools with one that immediately delegates back to R:

.S3method('as.character', 'formula', function (x, ...) NextMethod())
gmm(z ~ zm, x = ~ zm) # seems to work once again

(Is there a way to truly unregister an S3 method?)

Perhaps gmm::getDat could be made more robust by working directly on
the formula/call object instead of going through the string
representation.

-- 
Best regards,
Ivan

[*] https://stat.ethz.ch/pipermail/r-help/2024-October/480157.html


From @|by||e@@toeck|| @end|ng |rom gmx@ch  Sat Nov  2 09:23:14 2024
From: @|by||e@@toeck|| @end|ng |rom gmx@ch (=?utf-8?Q?Sibylle_St=C3=B6ckli?=)
Date: Sat, 2 Nov 2024 09:23:14 +0100
Subject: [R] foreSIGHT package
Message-ID: <0050F99A-A468-43BD-A9CD-B36AF05BD623@gmx.ch>

Dear community

I have started to use the foreSIGHT package fo calculate some climatic indicators.

Example
library(foreSIGHT)
func_avgDSD(WAAR$Ta, attArgs)

Dataset (WAAR, Ta = average daily temperature)
Year DOY Ta
1990 1 -2.45
1990 2 1.54
.
.
2001 1 4.54
,
2001 205 15.65
2001 206 20.14
.
2001 365 8.65
..
2023 1 0.45


Questions:
Is it possible to run the foreSIGHT with DOY numbers not dates (e.g. 1983-04-09 23.64) and additionally separate years? 
 
I have some problems to understand attArgs. Up to now I have not found any reference. How do I need to prepare the list? And where I can set the threshold?
 
Sometimes there are indicators without any definition of the threshold? E.g. cold seasons length: func_CSL (data) how is a cold day defined here (the threshold for cold days), there is no attArgs?

Many thanks 
Sibylle



	[[alternative HTML version deleted]]


From @r|e|92@nd @end|ng |rom gm@||@com  Sun Nov  3 12:53:52 2024
From: @r|e|92@nd @end|ng |rom gm@||@com (=?UTF-8?Q?Elys=C3=A9e_Aristide?=)
Date: Sun, 3 Nov 2024 12:53:52 +0100
Subject: [R] 
 Invalid term in model formula with gmm after formula.tools is loaded
In-Reply-To: <20241102002945.64b6c79a@Tarkus>
References: <CALcKxsq+6FKxX_JFA9RDoc1JWfiuCNSqKopQ3j=ex=Z+hdN8Tg@mail.gmail.com>
 <20241102002945.64b6c79a@Tarkus>
Message-ID: <CALcKxso-+3Fc22nL9Nfy9Zv3TQVjstXbU1bPHiPQK13ZvJR=wQ@mail.gmail.com>

Hi Ivan,

Thank you for your message. Does that mean that I should send a new
message? Or is it okay for this time?

Best,
Aristide

On Fri, Nov 1, 2024, 22:29 Ivan Krylov <ikrylov at disroot.org> wrote:

> Hi Aristide and welcome to R-help!
>
> Your message was a bit mangled [*]. It's best to compose messages to
> this mailing list in plain text. Otherwise (when composed in HTML), the
> mailing list eats the HTML part and we're left with the plain text part
> automatically generated by your mailer, which isn't always readable.
>
> ? Wed, 30 Oct 2024 17:45:29 +0100
> Elys?e Aristide <ariel92and at gmail.com> ?????:
>
> > I am using the gmm function from the gmm package and encountered an
> > unexpected error. No model can be estimated if I load formula.tools?I
> > need to restart R each time.
>
> I can reproduce the problem:
>
> library(gmm)
> data(Finance)
> r <- Finance[1:300, 1:10]
> rm <- Finance[1:300, "rm"]
> rf <- Finance[1:300, "rf"]
> z <- as.matrix(r-rf)
> zm <- rm-rf
> res <- gmm(z ~ zm, x = ~ zm)
> library(formula.tools)
> gmm(z ~ zm, x = ~ zm) # signals an error
>
> Looking at the traceback(), I see the formula being transformed into NA
> ~ NA at some point:
>
> 10: terms.formula(formula, data = data) # <-- error happens here
> 9: terms(formula, data = data)
> 8: model.frame.default(data = object$data, formula = NA ~ NA,
> drop.unused.levels = TRUE,
>        na.action = "na.pass")
> 7: model.frame(data = object$data, formula = NA ~ NA, drop.unused.levels =
> TRUE,
>        na.action = "na.pass") # <-- formula is already NA ~ NA here
> 6: eval(mfh, parent.frame())
> 5: eval(mfh, parent.frame())
> 4: getDat(object$g, object$x, data = object$data)
> 3: getModel.baseGmm(all_args, ...)
> 2: getModel(all_args, ...)
> 1: gmm(z ~ zm, x = ~zm)
>
> It seems that in base R, as.character(z ~ zm) returns a three-element
> character vector, while with formula.tools loaded, it only returns a
> single string, 'z ~ zm'. This breaks formula manipulation in getDat().
>
> An immediate workaround is to replace the method provided by
> formula.tools with one that immediately delegates back to R:
>
> .S3method('as.character', 'formula', function (x, ...) NextMethod())
> gmm(z ~ zm, x = ~ zm) # seems to work once again
>
> (Is there a way to truly unregister an S3 method?)
>
> Perhaps gmm::getDat could be made more robust by working directly on
> the formula/call object instead of going through the string
> representation.
>
> --
> Best regards,
> Ivan
>
> [*] https://stat.ethz.ch/pipermail/r-help/2024-October/480157.html
>

	[[alternative HTML version deleted]]


From |kry|ov @end|ng |rom d|@root@org  Mon Nov  4 11:37:33 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Mon, 4 Nov 2024 13:37:33 +0300
Subject: [R] 
 Invalid term in model formula with gmm after formula.tools is loaded
In-Reply-To: <CALcKxso-+3Fc22nL9Nfy9Zv3TQVjstXbU1bPHiPQK13ZvJR=wQ@mail.gmail.com>
References: <CALcKxsq+6FKxX_JFA9RDoc1JWfiuCNSqKopQ3j=ex=Z+hdN8Tg@mail.gmail.com>
 <20241102002945.64b6c79a@Tarkus>
 <CALcKxso-+3Fc22nL9Nfy9Zv3TQVjstXbU1bPHiPQK13ZvJR=wQ@mail.gmail.com>
Message-ID: <20241104133733.6f3f7506@Tarkus>

? Sun, 3 Nov 2024 12:53:52 +0100
Elys?e Aristide <ariel92and at gmail.com> ?????:

> Does that mean that I should send a new message? Or is it okay for
> this time?

No need to post it again. Did it help to replace the as.character()
method for formulas provided by 'formula.tools'? I see the problem is
already reported to the 'formula.tools' maintainer [*], so there isn't
much else to do about it.

-- 
Best regards,
Ivan

[*] https://github.com/decisionpatterns/formula.tools/issues/11


From @r|e|92@nd @end|ng |rom gm@||@com  Mon Nov  4 13:37:24 2024
From: @r|e|92@nd @end|ng |rom gm@||@com (=?UTF-8?Q?Elys=C3=A9e_Aristide?=)
Date: Mon, 4 Nov 2024 13:37:24 +0100
Subject: [R] 
 Invalid term in model formula with gmm after formula.tools is loaded
In-Reply-To: <20241104133733.6f3f7506@Tarkus>
References: <CALcKxsq+6FKxX_JFA9RDoc1JWfiuCNSqKopQ3j=ex=Z+hdN8Tg@mail.gmail.com>
 <20241102002945.64b6c79a@Tarkus>
 <CALcKxso-+3Fc22nL9Nfy9Zv3TQVjstXbU1bPHiPQK13ZvJR=wQ@mail.gmail.com>
 <20241104133733.6f3f7506@Tarkus>
Message-ID: <CALcKxspZLE7ymTQXYT4F_bG5dNx=FZaMKoLKYB31dvtWFfBtdw@mail.gmail.com>

Hi Ivan,

I tried that solution, but unfortunately, it did not help.
The issue is about the formula of the instruments when converting into
data. I finally converted this formula to a matrix by myself and gave the
matrix to gmm directly. So, gmm does not need to convert tit.

Best regards,

Aristide




On Mon, Nov 4, 2024 at 11:37?AM Ivan Krylov <ikrylov at disroot.org> wrote:

> ? Sun, 3 Nov 2024 12:53:52 +0100
> Elys?e Aristide <ariel92and at gmail.com> ?????:
>
> > Does that mean that I should send a new message? Or is it okay for
> > this time?
>
> No need to post it again. Did it help to replace the as.character()
> method for formulas provided by 'formula.tools'? I see the problem is
> already reported to the 'formula.tools' maintainer [*], so there isn't
> much else to do about it.
>
> --
> Best regards,
> Ivan
>
> [*] https://github.com/decisionpatterns/formula.tools/issues/11
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Nov  4 18:06:36 2024
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 4 Nov 2024 12:06:36 -0500
Subject: [R] 
 Invalid term in model formula with gmm after formula.tools is loaded
In-Reply-To: <20241104133733.6f3f7506@Tarkus>
References: <CALcKxsq+6FKxX_JFA9RDoc1JWfiuCNSqKopQ3j=ex=Z+hdN8Tg@mail.gmail.com>
 <20241102002945.64b6c79a@Tarkus>
 <CALcKxso-+3Fc22nL9Nfy9Zv3TQVjstXbU1bPHiPQK13ZvJR=wQ@mail.gmail.com>
 <20241104133733.6f3f7506@Tarkus>
Message-ID: <a47638c1-2872-47e1-b0ab-d8e4c6475eba@gmail.com>

On 2024-11-04 5:37 a.m., Ivan Krylov via R-help wrote:
> ? Sun, 3 Nov 2024 12:53:52 +0100
> Elys?e Aristide <ariel92and at gmail.com> ?????:
> 
>> Does that mean that I should send a new message? Or is it okay for
>> this time?
> 
> No need to post it again. Did it help to replace the as.character()
> method for formulas provided by 'formula.tools'? I see the problem is
> already reported to the 'formula.tools' maintainer [*], so there isn't
> much else to do about it.
> 

One thing Aristide or someone else could do is to fix the bug in 
formula.tools, and submit a PR.  Five years ago the author said he 
didn't have time to fix the bug.  Apparently nobody else has had time 
either.

Another choice is to recognize that there isn't much interest in 
supporting that package from the author or any of its users, and abandon it.

Duncan Murdoch


From n@re@h_gurbux@n| @end|ng |rom hotm@||@com  Tue Nov  5 13:26:07 2024
From: n@re@h_gurbux@n| @end|ng |rom hotm@||@com (Naresh Gurbuxani)
Date: Tue, 5 Nov 2024 12:26:07 +0000
Subject: [R] lattice subscripts with both condition and group
Message-ID: <IA1P223MB049910B784B00782216C74E2FA522@IA1P223MB0499.NAMP223.PROD.OUTLOOK.COM>

How can I use subscripts to draw the last graph with one call to ? ? ? ? ? ? ? ? ? ? ? ??
function xyplot()? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
Thanks, ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
Naresh ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
library(data.table) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
library(lattice) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??
library(latticeExtra) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
mydt2024 <- data.table( ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
? ? date = rep(as.Date(c("2024-11-01", "2024-11-04")), c(8, 8)), ? ? ? ? ? ? ? ? ? ? ? ??
? ? day_forward = rep(1:8, 2), ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??
? ? news_clicks = c(10, 12, 13, 18, 20, 21, 15, 11, 21, 23, 25, 18, 14, 12, ? ? ? ? ? ? ?
? ? ? ? ? ? ? ? ? ? 12, 10), ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??
? ? days_to_election = rep(c(4, 1), c(8, 8)), ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
? ? electyear = "Election 2024") ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
## Works when only condition is present ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
mydt2024[ ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
? , xyplot(news_clicks ~ day_forward | date, type = c("l", "g"), ? ? ? ? ? ? ? ? ? ? ? ??
? ? ? ? ? ?panel = function(x, y, ..., subscripts) { ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??
? ? ? ? ? ? ? ?panel.xyplot(x, y, ...) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??
? ? ? ? ? ? ? ?panel.abline(v = days_to_election[subscripts][1], lty = 2) ? ? ? ? ? ? ? ?
? ? ? ? ? ?}) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
] ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
mydt2020 <- data.table( ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
? ? date = rep(as.Date(c("2020-10-30", "2020-11-02")), c(8, 8)), ? ? ? ? ? ? ? ? ? ? ? ??
? ? day_forward = rep(1:8, 2), ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??
? ? news_clicks = c(9, 11, 12, 17, 21, 20, 14, 8, 20, 24, 28, 15, 12, 10, ? ? ? ? ? ? ? ?
? ? ? ? ? ? ? ? ? ? 8, 6), ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??
? ? days_to_election = rep(c(4, 1), c(8, 8)), ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
? ? electyear = "Election 2020" ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
mydt <- rbind(mydt2020, mydt2024) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
mydt[, `:=`(electlabel = paste(days_to_election, "Days Before"))] ? ? ? ? ? ? ? ? ? ? ? ?
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
## This does not work with both condition and group ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
mydt[ ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
? , xyplot(news_clicks ~ day_forward | electlabel, groups = electyear, ? ? ? ? ? ? ? ? ??
? ? ? ? ? ?type = c("o", "g"), auto.key = list(columns = 2, space = "bottom"), ? ? ? ? ??
? ? ? ? ? ?panel = function(x, y, ..., subscripts) { ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??
? ? ? ? ? ? ? ?panel.xyplot(x, y, ...) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??
? ? ? ? ? ? ? ?panel.abline(v = days_to_election[subscripts][1], lty = 2) ? ? ? ? ? ? ? ?
? ? ? ? ? ?}) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
] ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
## This works ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
electplot <- mydt[ ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??
? , xyplot(news_clicks ~ day_forward | electlabel, groups = electyear, ? ? ? ? ? ? ? ? ??
? ? ? ? ? ?type = c("o", "g"), auto.key = list(columns = 2, space = "bottom")) ? ? ? ? ??
] ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
vlineplot <- mydt[ ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??
? , xyplot(news_clicks ~ day_forward | electlabel, ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??
? ? ? ? ? ?panel = function(x, y, ..., subscripts) { ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??
? ? ? ? ? ? ? ?panel.abline(v = days_to_election[subscripts][1], lty = 2) ? ? ? ? ? ? ? ?
? ? ? ? ? ?}) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
] ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
electplot + vlineplot ??

From @|by||e@@toeck|| @end|ng |rom gmx@ch  Wed Nov  6 07:29:27 2024
From: @|by||e@@toeck|| @end|ng |rom gmx@ch (=?utf-8?Q?Sibylle_St=C3=B6ckli?=)
Date: Wed, 6 Nov 2024 07:29:27 +0100
Subject: [R] Using multiple dat files
References: <B8E50D3E-29D2-4E6D-B90A-A08259C803BD@unige.ch>
Message-ID: <6E7A7742-21DC-4E9E-8AA3-059ECA813E43@gmx.ch>

Dear community

To import multiple .dat  weather files I am using list.files().
I intend to use the R package ?ClimInd? to calculate different agroclimatic indicators. 

Question: Is there another solution to import multiple .dat files so that I can select elements from the list, e.g. one specific weather file (example AAR_DailyWeather)?
 
 
# Import multiple .dat files weather data
filelist <- list.files(path = "O:/Data-Work/??./Daten_RA-MeteoCH_1990-2021", pattern='*.dat', all.files= T, full.names= T)
W <- lapply(filelist, function(x) read.table(x, header = TRUE, sep = "", colClasses = "numeric", comment.char = ""))
W[[1]]
 
> dd(data = W[[1]]$Precip, time.scale = W[[1]]$year)
Fehler in W[[1]]$year : $ operator is invalid for atomic vectors
 
Kind regards
Sibylle
 
 
 

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Nov  6 18:17:58 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 6 Nov 2024 17:17:58 +0000
Subject: [R] Using multiple dat files
In-Reply-To: <6E7A7742-21DC-4E9E-8AA3-059ECA813E43@gmx.ch>
References: <B8E50D3E-29D2-4E6D-B90A-A08259C803BD@unige.ch>
 <6E7A7742-21DC-4E9E-8AA3-059ECA813E43@gmx.ch>
Message-ID: <65aef957-7552-4789-8864-2502e59d7ed9@sapo.pt>

?s 06:29 de 06/11/2024, Sibylle St?ckli via R-help escreveu:
> Dear community
> 
> To import multiple .dat  weather files I am using list.files().
> I intend to use the R package ?ClimInd? to calculate different agroclimatic indicators.
> 
> Question: Is there another solution to import multiple .dat files so that I can select elements from the list, e.g. one specific weather file (example AAR_DailyWeather)?
>   
>   
> # Import multiple .dat files weather data
> filelist <- list.files(path = "O:/Data-Work/??./Daten_RA-MeteoCH_1990-2021", pattern='*.dat', all.files= T, full.names= T)
> W <- lapply(filelist, function(x) read.table(x, header = TRUE, sep = "", colClasses = "numeric", comment.char = ""))
> W[[1]]
>   
>> dd(data = W[[1]]$Precip, time.scale = W[[1]]$year)
> Fehler in W[[1]]$year : $ operator is invalid for atomic vectors
>   
> Kind regards
> Sibylle
>   
>   
>   
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

I find it strange that the error is complaining about the 2nd argument, 
W[[1]]$year. It seems that column W[[1]]$Precip exists but not year.

What does

str(W[[1]])

return? A data.frame?

And why sep = "" when reading the files, aren't those files csv files?

Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From bgunter@4567 @end|ng |rom gm@||@com  Wed Nov  6 18:28:29 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 6 Nov 2024 09:28:29 -0800
Subject: [R] Using multiple dat files
In-Reply-To: <6E7A7742-21DC-4E9E-8AA3-059ECA813E43@gmx.ch>
References: <B8E50D3E-29D2-4E6D-B90A-A08259C803BD@unige.ch>
 <6E7A7742-21DC-4E9E-8AA3-059ECA813E43@gmx.ch>
Message-ID: <CAGxFJbTHiqLXgo-L7zBLZFy61Dt-GEHgbnOWfyUaVborYykRfQ@mail.gmail.com>

Not quite sure if I understand you.

list.files() simply returns a character vector(not a list). You can simply
use a vector index to select whatever file you wish to read. So if your
desired filename is the 5th element of filelist above, something like

myfile <- read.table(filename[5], ...)

You can also use regular expressions to choose a bunch of files that have
some common signature to their names that you can read in simultaneously
using your "filelist" vector of names via something like:

myfiles <- lapply(grep("weath", filelist, value = TRUE), \(x)
read.table(x,...))
### Note that the result of lapply *is* a list, so use list indexing for
extraction from myfiles.


You can also choose files to read interactively (via a GUI interface) using
file.choose() instead of using list.files() if you prefer to do it that way.

Cheers,
Bert

On Wed, Nov 6, 2024 at 8:25?AM Sibylle St?ckli via R-help <
r-help at r-project.org> wrote:

> Dear community
>
> To import multiple .dat  weather files I am using list.files().
> I intend to use the R package ?ClimInd? to calculate different
> agroclimatic indicators.
>
> Question: Is there another solution to import multiple .dat files so that
> I can select elements from the list, e.g. one specific weather file
> (example AAR_DailyWeather)?
>
>
> # Import multiple .dat files weather data
> filelist <- list.files(path =
> "O:/Data-Work/??./Daten_RA-MeteoCH_1990-2021", pattern='*.dat', all.files=
> T, full.names= T)
> W <- lapply(filelist, function(x) read.table(x, header = TRUE, sep = "",
> colClasses = "numeric", comment.char = ""))
> W[[1]]
>
> > dd(data = W[[1]]$Precip, time.scale = W[[1]]$year)
> Fehler in W[[1]]$year : $ operator is invalid for atomic vectors
>
> Kind regards
> Sibylle
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Nov  6 21:46:27 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 6 Nov 2024 12:46:27 -0800
Subject: [R] Using multiple dat files
In-Reply-To: <trinity-e67b69c2-afc2-4b13-a41c-4906c0a5e2c2-1730919598265@trinity-msg-rest-gmx-gmx-live-c75c5fb4b-m9vrp>
References: <B8E50D3E-29D2-4E6D-B90A-A08259C803BD@unige.ch>
 <6E7A7742-21DC-4E9E-8AA3-059ECA813E43@gmx.ch>
 <CAGxFJbTHiqLXgo-L7zBLZFy61Dt-GEHgbnOWfyUaVborYykRfQ@mail.gmail.com>
 <trinity-e67b69c2-afc2-4b13-a41c-4906c0a5e2c2-1730919598265@trinity-msg-rest-gmx-gmx-live-c75c5fb4b-m9vrp>
Message-ID: <CAGxFJbSQkRirQcJKQWRdcShE6_5ebgBqvn2Aefm5MoC_gNea1w@mail.gmail.com>

"It seems therefore that there is no other way than read in individually >
100 weather tables using read.tables., right? Using file.choose() doesn't
change the work."

Yes. With that many files, file.choose() does not make sense. However, I
still do not understand what is the problem with using lapply() on the
character vector of file names with read.table() as you did in your
original post to read in all the files as components of the W list. As data
frames are also lists, you can extract individual columns as you did before
using  the $ extractor, i.e. W[[1]]$year, etc.. You can also use data frame
indices for the columns, i.e. W[[1]][ ,1] or W[[1]][ ,"year"] . All of
which I believe you know.

However, I will hazard a *guess* (so exercise due diligence and check) as
to the cause of your original error,

"dd(data = W[[1]]$Precip, time.scale = W[[1]]$year)
Fehler in W[[1]]$year : $ operator is invalid for atomic vectors'

even though I know **nothing** about the dd() function. My guess is:
"data" is usually an argument to a function that tells it to use
"nonstandard evaluation" to look for arguments and other names in the
function first in the "data" argument, rather than by following R's
"standard" evaluation by looking first through the function's closures.
**If** this guess is correct, the call you gave above should be something
like:

dd(data = W[[1]], time.scale = year, precip = Precip,...)

where precip (small "p") is a formal argument of the dd() function and
Precip is a column in the data frame W[[1]].  If this is wrong, my
apologies, and feel free to ignore without responding.

Best,
Bert

On Wed, Nov 6, 2024 at 10:59?AM Sibylle St?ckli <sibylle.stoeckli at gmx.ch>
wrote:

> Dear Rui
> Dear Bert
>
> Many thanks
>
> Solution
> filelist <- list.files(path =
> "O:/Data-Work/2.../Daten_RA-MeteoCH_1990-2021", pattern='*.dat', all.files=
> T, full.names= T)
> AAR<-read.table(filelist[1])
>
> It seems therefore that there is no other way than read in individually >
> 100 weather tables using read.tables., right? Using file.choose() doesn't
> change the work.
>
> Yes my .dat files are data.frames
>
> > str(W[[1]])'data.frame':	11688 obs. of  7 variables:
>  $ year  : num  1990 1990 1990 1990 1990 1990 1990 1990 1990 1990 ...
>  $ DOY   : num  1 2 3 4 5 6 7 8 9 10 ...
>  $ Ta    : num  -2.67 -2.77 -2.23 -2.21 -0.98 0.82 0.49 -1.02 -2.31 -3.36 ...
>  $ Tmin  : num  -3.5 -3.7 -4.26 -2.87 -2.98 0.3 -0.83 -1.27 -3 -3.82 ...
>  $ Tmax  : num  -1.13 -0.15 -0.13 -0.45 1 1.87 1.72 -0.35 -0.85 -2.3 ...
>  $ Precip: num  0 0 0 0 0.45 1.81 0.03 0 0 0 ...
>  $ rSSD  : num  0 0.08 0 0 0.08 0 0 0 0 0 ...
>
>
> *Gesendet: *Mittwoch, 6. November 2024 um 18:28
> *Von: *"Bert Gunter" <bgunter.4567 at gmail.com>
> *An: *"Sibylle St?ckli" <sibylle.stoeckli at gmx.ch>
> *CC: *r-help at r-project.org
> *Betreff: *Re: [R] Using multiple dat files
> Not quite sure if I understand you.
>
> list.files() simply returns a character vector(not a list). You can simply
> use a vector index to select whatever file you wish to read. So if your
> desired filename is the 5th element of filelist above, something like
>
> myfile <- read.table(filename[5], ...)
>
> You can also use regular expressions to choose a bunch of files that have
> some common signature to their names that you can read in simultaneously
> using your "filelist" vector of names via something like:
>
> myfiles <- lapply(grep("weath", filelist, value = TRUE), \(x)
> read.table(x,...))
> ### Note that the result of lapply *is* a list, so use list indexing for
> extraction from myfiles.
>
>
> You can also choose files to read interactively (via a GUI interface)
> using file.choose() instead of using list.files() if you prefer to do it
> that way.
>
> Cheers,
> Bert
>
> On Wed, Nov 6, 2024 at 8:25?AM Sibylle St?ckli via R-help <
> r-help at r-project.org> wrote:
>
>> Dear community
>>
>> To import multiple .dat  weather files I am using list.files().
>> I intend to use the R package ?ClimInd? to calculate different
>> agroclimatic indicators.
>>
>> Question: Is there another solution to import multiple .dat files so that
>> I can select elements from the list, e.g. one specific weather file
>> (example AAR_DailyWeather)?
>>
>>
>> # Import multiple .dat files weather data
>> filelist <- list.files(path =
>> "O:/Data-Work/??./Daten_RA-MeteoCH_1990-2021", pattern='*.dat', all.files=
>> T, full.names= T)
>> W <- lapply(filelist, function(x) read.table(x, header = TRUE, sep = "",
>> colClasses = "numeric", comment.char = ""))
>> W[[1]]
>>
>> > dd(data = W[[1]]$Precip, time.scale = W[[1]]$year)
>> Fehler in W[[1]]$year : $ operator is invalid for atomic vectors
>>
>> Kind regards
>> Sibylle
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> https://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Nov  6 21:52:54 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 6 Nov 2024 12:52:54 -0800
Subject: [R] Using multiple dat files
In-Reply-To: <CAGxFJbSQkRirQcJKQWRdcShE6_5ebgBqvn2Aefm5MoC_gNea1w@mail.gmail.com>
References: <B8E50D3E-29D2-4E6D-B90A-A08259C803BD@unige.ch>
 <6E7A7742-21DC-4E9E-8AA3-059ECA813E43@gmx.ch>
 <CAGxFJbTHiqLXgo-L7zBLZFy61Dt-GEHgbnOWfyUaVborYykRfQ@mail.gmail.com>
 <trinity-e67b69c2-afc2-4b13-a41c-4906c0a5e2c2-1730919598265@trinity-msg-rest-gmx-gmx-live-c75c5fb4b-m9vrp>
 <CAGxFJbSQkRirQcJKQWRdcShE6_5ebgBqvn2Aefm5MoC_gNea1w@mail.gmail.com>
Message-ID: <CAGxFJbQ5qGAikqTMm9X86Jbw5zwgG5PaxOe8QbGzrDG67==Ftg@mail.gmail.com>

Sorry, wrong language.
"through the function's closures" in my email should be:
through the function's chain of environments. (A function in R *is* a
closure).

-- Bert



On Wed, Nov 6, 2024 at 12:46?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> "It seems therefore that there is no other way than read in individually
> > 100 weather tables using read.tables., right? Using file.choose() doesn't
> change the work."
>
> Yes. With that many files, file.choose() does not make sense. However, I
> still do not understand what is the problem with using lapply() on the
> character vector of file names with read.table() as you did in your
> original post to read in all the files as components of the W list. As data
> frames are also lists, you can extract individual columns as you did before
> using  the $ extractor, i.e. W[[1]]$year, etc.. You can also use data frame
> indices for the columns, i.e. W[[1]][ ,1] or W[[1]][ ,"year"] . All of
> which I believe you know.
>
> However, I will hazard a *guess* (so exercise due diligence and check) as
> to the cause of your original error,
>
> "dd(data = W[[1]]$Precip, time.scale = W[[1]]$year)
> Fehler in W[[1]]$year : $ operator is invalid for atomic vectors'
>
> even though I know **nothing** about the dd() function. My guess is:
> "data" is usually an argument to a function that tells it to use
> "nonstandard evaluation" to look for arguments and other names in the
> function first in the "data" argument, rather than by following R's
> "standard" evaluation by looking first through the function's closures.
> **If** this guess is correct, the call you gave above should be something
> like:
>
> dd(data = W[[1]], time.scale = year, precip = Precip,...)
>
> where precip (small "p") is a formal argument of the dd() function and
> Precip is a column in the data frame W[[1]].  If this is wrong, my
> apologies, and feel free to ignore without responding.
>
> Best,
> Bert
>
> On Wed, Nov 6, 2024 at 10:59?AM Sibylle St?ckli <sibylle.stoeckli at gmx.ch>
> wrote:
>
>> Dear Rui
>> Dear Bert
>>
>> Many thanks
>>
>> Solution
>> filelist <- list.files(path =
>> "O:/Data-Work/2.../Daten_RA-MeteoCH_1990-2021", pattern='*.dat', all.files=
>> T, full.names= T)
>> AAR<-read.table(filelist[1])
>>
>> It seems therefore that there is no other way than read in individually >
>> 100 weather tables using read.tables., right? Using file.choose() doesn't
>> change the work.
>>
>> Yes my .dat files are data.frames
>>
>> > str(W[[1]])'data.frame':	11688 obs. of  7 variables:
>>  $ year  : num  1990 1990 1990 1990 1990 1990 1990 1990 1990 1990 ...
>>  $ DOY   : num  1 2 3 4 5 6 7 8 9 10 ...
>>  $ Ta    : num  -2.67 -2.77 -2.23 -2.21 -0.98 0.82 0.49 -1.02 -2.31 -3.36 ...
>>  $ Tmin  : num  -3.5 -3.7 -4.26 -2.87 -2.98 0.3 -0.83 -1.27 -3 -3.82 ...
>>  $ Tmax  : num  -1.13 -0.15 -0.13 -0.45 1 1.87 1.72 -0.35 -0.85 -2.3 ...
>>  $ Precip: num  0 0 0 0 0.45 1.81 0.03 0 0 0 ...
>>  $ rSSD  : num  0 0.08 0 0 0.08 0 0 0 0 0 ...
>>
>>
>> *Gesendet: *Mittwoch, 6. November 2024 um 18:28
>> *Von: *"Bert Gunter" <bgunter.4567 at gmail.com>
>> *An: *"Sibylle St?ckli" <sibylle.stoeckli at gmx.ch>
>> *CC: *r-help at r-project.org
>> *Betreff: *Re: [R] Using multiple dat files
>> Not quite sure if I understand you.
>>
>> list.files() simply returns a character vector(not a list). You can
>> simply use a vector index to select whatever file you wish to read. So if
>> your desired filename is the 5th element of filelist above, something like
>>
>> myfile <- read.table(filename[5], ...)
>>
>> You can also use regular expressions to choose a bunch of files that have
>> some common signature to their names that you can read in simultaneously
>> using your "filelist" vector of names via something like:
>>
>> myfiles <- lapply(grep("weath", filelist, value = TRUE), \(x)
>> read.table(x,...))
>> ### Note that the result of lapply *is* a list, so use list indexing for
>> extraction from myfiles.
>>
>>
>> You can also choose files to read interactively (via a GUI interface)
>> using file.choose() instead of using list.files() if you prefer to do it
>> that way.
>>
>> Cheers,
>> Bert
>>
>> On Wed, Nov 6, 2024 at 8:25?AM Sibylle St?ckli via R-help <
>> r-help at r-project.org> wrote:
>>
>>> Dear community
>>>
>>> To import multiple .dat  weather files I am using list.files().
>>> I intend to use the R package ?ClimInd? to calculate different
>>> agroclimatic indicators.
>>>
>>> Question: Is there another solution to import multiple .dat files so
>>> that I can select elements from the list, e.g. one specific weather file
>>> (example AAR_DailyWeather)?
>>>
>>>
>>> # Import multiple .dat files weather data
>>> filelist <- list.files(path =
>>> "O:/Data-Work/??./Daten_RA-MeteoCH_1990-2021", pattern='*.dat', all.files=
>>> T, full.names= T)
>>> W <- lapply(filelist, function(x) read.table(x, header = TRUE, sep = "",
>>> colClasses = "numeric", comment.char = ""))
>>> W[[1]]
>>>
>>> > dd(data = W[[1]]$Precip, time.scale = W[[1]]$year)
>>> Fehler in W[[1]]$year : $ operator is invalid for atomic vectors
>>>
>>> Kind regards
>>> Sibylle
>>>
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> https://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Nov  7 05:41:16 2024
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 6 Nov 2024 20:41:16 -0800
Subject: [R] Using multiple dat files
In-Reply-To: <6E7A7742-21DC-4E9E-8AA3-059ECA813E43@gmx.ch>
References: <B8E50D3E-29D2-4E6D-B90A-A08259C803BD@unige.ch>
 <6E7A7742-21DC-4E9E-8AA3-059ECA813E43@gmx.ch>
Message-ID: <e11d5071-de36-0875-8ca5-5f83059f5062@comcast.net>


On 11/5/24 22:29, Sibylle St?ckli via R-help wrote:
> Dear community
>
> To import multiple .dat  weather files I am using list.files().
> I intend to use the R package ?ClimInd? to calculate different agroclimatic indicators.
>
> Question: Is there another solution to import multiple .dat files so that I can select elements from the list, e.g. one specific weather file (example AAR_DailyWeather)?
>   
>   
> # Import multiple .dat files weather data
> filelist <- list.files(path = "O:/Data-Work/??./Daten_RA-MeteoCH_1990-2021", pattern='*.dat', all.files= T, full.names= T)
> W <- lapply(filelist, function(x) read.table(x, header = TRUE, sep = "", colClasses = "numeric", comment.char = ""))
> W[[1]]

`W[[1]]` should be a data.frame, but it will not have the name 
"AAR_DailyWeather" unless you assign names using the values in `filelist`.


>> dd(data = W[[1]]$Precip, time.scale = W[[1]]$year)
It is unclear what this code snippet is supposed to represent. There is 
no function named `dd` in the base packages. There is a `dd` function in 
package Hmisc but if you use it you need to assign the results to an 
object name. Just executing the call will do nothing except perhaps 
checking to see if there are errors.
> Fehler in W[[1]]$year : $ operator is invalid for atomic vectors


Also unclear is how that error message came about. It seems to indicate 
that W[[1]] is not a dataframe. You can examine the `W` object with 
`str(W)`.

Looking at the help page for ClimInd::dd it appears that the 
'time.scale' argument is supposed to signify what time scale to assume, 
namely one of {month, season, year}. Pretty crappy documentation since 
it is unstated what type the allowable values are and the usage example 
shows

|time.scale = YEAR|

And there does not appear to be any definition of what the value of `YEAR` is supposed to be.

It appears to me that you have been assigned a task in a poorly 
documented package.

Contact the package author.

-- 

David.

>   
> Kind regards
> Sibylle
>   
>   
>   
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Nov  7 11:45:00 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 7 Nov 2024 10:45:00 +0000
Subject: [R] Using multiple dat files
In-Reply-To: <trinity-e67b69c2-afc2-4b13-a41c-4906c0a5e2c2-1730919598265@trinity-msg-rest-gmx-gmx-live-c75c5fb4b-m9vrp>
References: <B8E50D3E-29D2-4E6D-B90A-A08259C803BD@unige.ch>
 <6E7A7742-21DC-4E9E-8AA3-059ECA813E43@gmx.ch>
 <CAGxFJbTHiqLXgo-L7zBLZFy61Dt-GEHgbnOWfyUaVborYykRfQ@mail.gmail.com>
 <trinity-e67b69c2-afc2-4b13-a41c-4906c0a5e2c2-1730919598265@trinity-msg-rest-gmx-gmx-live-c75c5fb4b-m9vrp>
Message-ID: <30a9682a-89be-4090-93cc-1281287ed8a7@sapo.pt>

?s 18:59 de 06/11/2024, Sibylle St?ckli escreveu:
> Dear Rui
> Dear Bert
> Many thanks
> Solution
> filelist <- list.files(path = "O:/Data-Work/2.../Daten_RA-MeteoCH_1990-2021",
> pattern='*.dat', all.files= T, full.names= T)
> AAR<-read.table(filelist[1])
> It seems therefore that there is no other way than read in individually > 100
> weather tables using read.tables., right? Using file.choose() doesn't change the
> work.
> Yes my .dat files are data.frames
> 
>> str(W[[1]]) 'data.frame': 11688 obs. of 7 variables: $ year : num 1990 1990 1990 
> 1990 1990 1990 1990 1990 1990 1990 ... $ DOY : num 1 2 3 4 5 6 7 8 9 10 ... $
> Ta : num -2.67 -2.77 -2.23 -2.21 -0.98 0.82 0.49 -1.02 -2.31 -3.36 ... $ Tmin :
> num -3.5 -3.7 -4.26 -2.87 -2.98 0.3 -0.83 -1.27 -3 -3.82 ... $ Tmax : num -1.13
> -0.15 -0.13 -0.45 1 1.87 1.72 -0.35 -0.85 -2.3 ... $ Precip: num 0 0 0 0 0.45
> 1.81 0.03 0 0 0 ... $ rSSD : num 0 0.08 0 0 0.08 0 0 0 0 0 ...
> 
> *Gesendet: *Mittwoch, 6. November 2024 um 18:28
> *Von: *"Bert Gunter" <bgunter.4567 at gmail.com>
> *An: *"Sibylle St?ckli" <sibylle.stoeckli at gmx.ch>
> *CC: *r-help at r-project.org
> *Betreff: *Re: [R] Using multiple dat files
> Not quite sure if I understand you.
> list.files() simply returns a character vector(not a list). You can simply use a
> vector index to select whatever file you wish to read. So if your desired
> filename is the 5th element of filelist above, something like
> myfile <- read.table(filename[5], ...)
> You can also use regular expressions to choose a bunch of files that have some
> common signature to their names that you can read in simultaneously using your
> "filelist" vector of names via something like:
> myfiles <- lapply(grep("weath", filelist, value = TRUE), \(x) read.table(x,...))
> ### Note that the result of lapply *is* a list, so use list indexing for
> extraction from myfiles.
> You can also choose files to read interactively (via a GUI interface) using
> file.choose() instead of using list.files() if you prefer to do it that way.
> Cheers,
> Bert
> 
> On Wed, Nov 6, 2024 at 8:25?AM Sibylle St?ckli via R-help <r-help at r-project.org
> <mailto:r-help at r-project.org>> wrote:
> 
>      Dear community
> 
>      To import multiple .dat  weather files I am using list.files().
>      I intend to use the R package ?ClimInd? to calculate different agroclimatic
>      indicators.
> 
>      Question: Is there another solution to import multiple .dat files so that I
>      can select elements from the list, e.g. one specific weather file (example
>      AAR_DailyWeather)?
> 
> 
>      # Import multiple .dat files weather data
>      filelist <- list.files(path = "O:/Data-Work/??./Daten_RA-MeteoCH_1990-2021",
>      pattern='*.dat', all.files= T, full.names= T)
>      W <- lapply(filelist, function(x) read.table(x, header = TRUE, sep = "",
>      colClasses = "numeric", comment.char = ""))
>      W[[1]]
> 
>       > dd(data = W[[1]]$Precip, time.scale = W[[1]]$year)
>      Fehler in W[[1]]$year : $ operator is invalid for atomic vectors
> 
>      Kind regards
>      Sibylle
> 
> 
> 
>      ______________________________________________
>      R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To
>      UNSUBSCRIBE and more, see
>      https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/
>      listinfo/r-help>
>      PLEASE do read the posting guide https://www.R-project.org/posting-
>      guide.html <https://www.R-project.org/posting-guide.html>
>      and provide commented, minimal, self-contained, reproducible code.
> 
Hello,

If read.table as you have posted it solves the problem of reading one 
file, then the following should read all of them.


# No further options passed to read.table. Was that the problem?
AAR_list <- lapply(filelist, read.table)
# You can also set the returned list's names, like Bert "suggested"
AAR_list <- setNames(AAR_list, basename(filelist))


Or you can test in a small subset of the files


# If this works then it's probably safe to read them all
# (and you don't have to, if it doesn't)
AAR_list <- lapply(filelist[1:3], read.table)



Hope this helps,

Rui Barradas



-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From v@|kremk @end|ng |rom gm@||@com  Sat Nov  9 01:58:18 2024
From: v@|kremk @end|ng |rom gm@||@com (Val)
Date: Fri, 8 Nov 2024 18:58:18 -0600
Subject: [R] Limit
Message-ID: <CAJOiR6ZJQtubj=go6+qftiLYTxJYv+W8BCKsMpL5Tuq7GaOs7Q@mail.gmail.com>

Hi All,

I am reading data file ( > 1B rows) and do some date formatting like
      dat=fread(mydatafile)
     dat$date1 <- as.Date(ymd(dat$date1))

However, I am getting an error message saying that
    Error: cons memory exhausted (limit reached?)

The  script was working  when the number rows were  around 650M.

Is there another way to  handle  a big data set in R?


Thank you.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Nov  9 02:13:16 2024
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 08 Nov 2024 17:13:16 -0800
Subject: [R] Limit
In-Reply-To: <CAJOiR6ZJQtubj=go6+qftiLYTxJYv+W8BCKsMpL5Tuq7GaOs7Q@mail.gmail.com>
References: <CAJOiR6ZJQtubj=go6+qftiLYTxJYv+W8BCKsMpL5Tuq7GaOs7Q@mail.gmail.com>
Message-ID: <85D9A450-DF64-401D-BB20-00B78714BFD5@dcn.davis.ca.us>

Can you tell us what is wrong with the "chunked" package which comes up when you Google "r read large file in chunks"?

On November 8, 2024 4:58:18 PM PST, Val <valkremk at gmail.com> wrote:
>Hi All,
>
>I am reading data file ( > 1B rows) and do some date formatting like
>      dat=fread(mydatafile)
>     dat$date1 <- as.Date(ymd(dat$date1))
>
>However, I am getting an error message saying that
>    Error: cons memory exhausted (limit reached?)
>
>The  script was working  when the number rows were  around 650M.
>
>Is there another way to  handle  a big data set in R?
>
>
>Thank you.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Sat Nov  9 02:30:30 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 8 Nov 2024 17:30:30 -0800
Subject: [R] Limit
In-Reply-To: <85D9A450-DF64-401D-BB20-00B78714BFD5@dcn.davis.ca.us>
References: <CAJOiR6ZJQtubj=go6+qftiLYTxJYv+W8BCKsMpL5Tuq7GaOs7Q@mail.gmail.com>
 <85D9A450-DF64-401D-BB20-00B78714BFD5@dcn.davis.ca.us>
Message-ID: <CAGxFJbRSSFBqJJL286TR7xcNGFDY=Og_JxFvFn=F+dA0tRNWew@mail.gmail.com>

Is the problem reading the file in or processing it after it has been read
in?

Bert

On Fri, Nov 8, 2024 at 5:13?PM Jeff Newmiller via R-help <
r-help at r-project.org> wrote:

> Can you tell us what is wrong with the "chunked" package which comes up
> when you Google "r read large file in chunks"?
>
> On November 8, 2024 4:58:18 PM PST, Val <valkremk at gmail.com> wrote:
> >Hi All,
> >
> >I am reading data file ( > 1B rows) and do some date formatting like
> >      dat=fread(mydatafile)
> >     dat$date1 <- as.Date(ymd(dat$date1))
> >
> >However, I am getting an error message saying that
> >    Error: cons memory exhausted (limit reached?)
> >
> >The  script was working  when the number rows were  around 650M.
> >
> >Is there another way to  handle  a big data set in R?
> >
> >
> >Thank you.
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From v@|kremk @end|ng |rom gm@||@com  Sat Nov  9 02:38:37 2024
From: v@|kremk @end|ng |rom gm@||@com (Val)
Date: Fri, 8 Nov 2024 19:38:37 -0600
Subject: [R] Limit
In-Reply-To: <CAGxFJbRSSFBqJJL286TR7xcNGFDY=Og_JxFvFn=F+dA0tRNWew@mail.gmail.com>
References: <CAJOiR6ZJQtubj=go6+qftiLYTxJYv+W8BCKsMpL5Tuq7GaOs7Q@mail.gmail.com>
 <85D9A450-DF64-401D-BB20-00B78714BFD5@dcn.davis.ca.us>
 <CAGxFJbRSSFBqJJL286TR7xcNGFDY=Og_JxFvFn=F+dA0tRNWew@mail.gmail.com>
Message-ID: <CAJOiR6b9PzaKR4njnkGppFMy+3TPDhXXmNBquFHt6-kJoahpCA@mail.gmail.com>

The data was read. The problem is with processing.

On Fri, Nov 8, 2024 at 7:30?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Is the problem reading the file in or processing it after it has been read in?
>
> Bert
>
> On Fri, Nov 8, 2024 at 5:13?PM Jeff Newmiller via R-help <r-help at r-project.org> wrote:
>>
>> Can you tell us what is wrong with the "chunked" package which comes up when you Google "r read large file in chunks"?
>>
>> On November 8, 2024 4:58:18 PM PST, Val <valkremk at gmail.com> wrote:
>> >Hi All,
>> >
>> >I am reading data file ( > 1B rows) and do some date formatting like
>> >      dat=fread(mydatafile)
>> >     dat$date1 <- as.Date(ymd(dat$date1))
>> >
>> >However, I am getting an error message saying that
>> >    Error: cons memory exhausted (limit reached?)
>> >
>> >The  script was working  when the number rows were  around 650M.
>> >
>> >Is there another way to  handle  a big data set in R?
>> >
>> >
>> >Thank you.
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Nov  9 02:50:01 2024
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 08 Nov 2024 17:50:01 -0800
Subject: [R] Limit
In-Reply-To: <CAJOiR6b9PzaKR4njnkGppFMy+3TPDhXXmNBquFHt6-kJoahpCA@mail.gmail.com>
References: <CAJOiR6ZJQtubj=go6+qftiLYTxJYv+W8BCKsMpL5Tuq7GaOs7Q@mail.gmail.com>
 <85D9A450-DF64-401D-BB20-00B78714BFD5@dcn.davis.ca.us>
 <CAGxFJbRSSFBqJJL286TR7xcNGFDY=Og_JxFvFn=F+dA0tRNWew@mail.gmail.com>
 <CAJOiR6b9PzaKR4njnkGppFMy+3TPDhXXmNBquFHt6-kJoahpCA@mail.gmail.com>
Message-ID: <AD1512AD-3CCD-40A3-8E2D-968B30F97924@dcn.davis.ca.us>

Then you don't have enough memory to process the whole thing at once. Not unlike stuffing your mouth with cookies and not being able to chew for lack of space to move the food around in your mouth. 

Now, can you answer my question?

On November 8, 2024 5:38:37 PM PST, Val <valkremk at gmail.com> wrote:
>The data was read. The problem is with processing.
>
>On Fri, Nov 8, 2024 at 7:30?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> Is the problem reading the file in or processing it after it has been read in?
>>
>> Bert
>>
>> On Fri, Nov 8, 2024 at 5:13?PM Jeff Newmiller via R-help <r-help at r-project.org> wrote:
>>>
>>> Can you tell us what is wrong with the "chunked" package which comes up when you Google "r read large file in chunks"?
>>>
>>> On November 8, 2024 4:58:18 PM PST, Val <valkremk at gmail.com> wrote:
>>> >Hi All,
>>> >
>>> >I am reading data file ( > 1B rows) and do some date formatting like
>>> >      dat=fread(mydatafile)
>>> >     dat$date1 <- as.Date(ymd(dat$date1))
>>> >
>>> >However, I am getting an error message saying that
>>> >    Error: cons memory exhausted (limit reached?)
>>> >
>>> >The  script was working  when the number rows were  around 650M.
>>> >
>>> >Is there another way to  handle  a big data set in R?
>>> >
>>> >
>>> >Thank you.
>>> >
>>> >______________________________________________
>>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >https://stat.ethz.ch/mailman/listinfo/r-help
>>> >PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>>> >and provide commented, minimal, self-contained, reproducible code.
>>>
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From v@|kremk @end|ng |rom gm@||@com  Sat Nov  9 03:08:16 2024
From: v@|kremk @end|ng |rom gm@||@com (Val)
Date: Fri, 8 Nov 2024 20:08:16 -0600
Subject: [R] Limit
In-Reply-To: <AD1512AD-3CCD-40A3-8E2D-968B30F97924@dcn.davis.ca.us>
References: <CAJOiR6ZJQtubj=go6+qftiLYTxJYv+W8BCKsMpL5Tuq7GaOs7Q@mail.gmail.com>
 <85D9A450-DF64-401D-BB20-00B78714BFD5@dcn.davis.ca.us>
 <CAGxFJbRSSFBqJJL286TR7xcNGFDY=Og_JxFvFn=F+dA0tRNWew@mail.gmail.com>
 <CAJOiR6b9PzaKR4njnkGppFMy+3TPDhXXmNBquFHt6-kJoahpCA@mail.gmail.com>
 <AD1512AD-3CCD-40A3-8E2D-968B30F97924@dcn.davis.ca.us>
Message-ID: <CAJOiR6bR1ovJ+Y1dAi5D39EOB8foxC4kygYi34Y6S9B-b+--8Q@mail.gmail.com>

Hi Jeff,

Memory was not an issue. The system only used 75% of the memory
allocated for the job.

 I am trying to understand what  "r read large file in chunks" is doing.

On Fri, Nov 8, 2024 at 7:50?PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> Then you don't have enough memory to process the whole thing at once. Not unlike stuffing your mouth with cookies and not being able to chew for lack of space to move the food around in your mouth.
>
> Now, can you answer my question?
>
> On November 8, 2024 5:38:37 PM PST, Val <valkremk at gmail.com> wrote:
> >The data was read. The problem is with processing.
> >
> >On Fri, Nov 8, 2024 at 7:30?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >>
> >> Is the problem reading the file in or processing it after it has been read in?
> >>
> >> Bert
> >>
> >> On Fri, Nov 8, 2024 at 5:13?PM Jeff Newmiller via R-help <r-help at r-project.org> wrote:
> >>>
> >>> Can you tell us what is wrong with the "chunked" package which comes up when you Google "r read large file in chunks"?
> >>>
> >>> On November 8, 2024 4:58:18 PM PST, Val <valkremk at gmail.com> wrote:
> >>> >Hi All,
> >>> >
> >>> >I am reading data file ( > 1B rows) and do some date formatting like
> >>> >      dat=fread(mydatafile)
> >>> >     dat$date1 <- as.Date(ymd(dat$date1))
> >>> >
> >>> >However, I am getting an error message saying that
> >>> >    Error: cons memory exhausted (limit reached?)
> >>> >
> >>> >The  script was working  when the number rows were  around 650M.
> >>> >
> >>> >Is there another way to  handle  a big data set in R?
> >>> >
> >>> >
> >>> >Thank you.
> >>> >
> >>> >______________________________________________
> >>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> >https://stat.ethz.ch/mailman/listinfo/r-help
> >>> >PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> >>> >and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>> --
> >>> Sent from my phone. Please excuse my brevity.
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.


From bbo|ker @end|ng |rom gm@||@com  Sat Nov  9 03:09:21 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 8 Nov 2024 21:09:21 -0500
Subject: [R] Limit
In-Reply-To: <CAJOiR6ZJQtubj=go6+qftiLYTxJYv+W8BCKsMpL5Tuq7GaOs7Q@mail.gmail.com>
References: <CAJOiR6ZJQtubj=go6+qftiLYTxJYv+W8BCKsMpL5Tuq7GaOs7Q@mail.gmail.com>
Message-ID: <CABghstQBO5X-PdH4hheDCE60x7bvMWTcFA+gt5tojEs8Aqr6wg@mail.gmail.com>

Check the "high performance task view" on CRAN ...
https://cran.r-project.org/web/views/HighPerformanceComputing.html

On Fri, Nov 8, 2024, 7:58 PM Val <valkremk at gmail.com> wrote:

> Hi All,
>
> I am reading data file ( > 1B rows) and do some date formatting like
>       dat=fread(mydatafile)
>      dat$date1 <- as.Date(ymd(dat$date1))
>
> However, I am getting an error message saying that
>     Error: cons memory exhausted (limit reached?)
>
> The  script was working  when the number rows were  around 650M.
>
> Is there another way to  handle  a big data set in R?
>
>
> Thank you.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Nov  9 03:30:14 2024
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 08 Nov 2024 18:30:14 -0800
Subject: [R] Limit
In-Reply-To: <CAJOiR6bR1ovJ+Y1dAi5D39EOB8foxC4kygYi34Y6S9B-b+--8Q@mail.gmail.com>
References: <CAJOiR6ZJQtubj=go6+qftiLYTxJYv+W8BCKsMpL5Tuq7GaOs7Q@mail.gmail.com>
 <85D9A450-DF64-401D-BB20-00B78714BFD5@dcn.davis.ca.us>
 <CAGxFJbRSSFBqJJL286TR7xcNGFDY=Og_JxFvFn=F+dA0tRNWew@mail.gmail.com>
 <CAJOiR6b9PzaKR4njnkGppFMy+3TPDhXXmNBquFHt6-kJoahpCA@mail.gmail.com>
 <AD1512AD-3CCD-40A3-8E2D-968B30F97924@dcn.davis.ca.us>
 <CAJOiR6bR1ovJ+Y1dAi5D39EOB8foxC4kygYi34Y6S9B-b+--8Q@mail.gmail.com>
Message-ID: <E897B5C8-FAE9-4893-86FF-404615DD01F1@dcn.davis.ca.us>

There is always an implied "and do computations on it before writing the processed data out" when reading chunks of a file.

And you would almost certainly not be getting that error if you were not out of memory.  A good rule of thumb is that you need 4 times as much free memory to process data than you need to read it in.

On November 8, 2024 6:08:16 PM PST, Val <valkremk at gmail.com> wrote:
>Hi Jeff,
>
>Memory was not an issue. The system only used 75% of the memory
>allocated for the job.
>
> I am trying to understand what  "r read large file in chunks" is doing.
>
>On Fri, Nov 8, 2024 at 7:50?PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>
>> Then you don't have enough memory to process the whole thing at once. Not unlike stuffing your mouth with cookies and not being able to chew for lack of space to move the food around in your mouth.
>>
>> Now, can you answer my question?
>>
>> On November 8, 2024 5:38:37 PM PST, Val <valkremk at gmail.com> wrote:
>> >The data was read. The problem is with processing.
>> >
>> >On Fri, Nov 8, 2024 at 7:30?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> >>
>> >> Is the problem reading the file in or processing it after it has been read in?
>> >>
>> >> Bert
>> >>
>> >> On Fri, Nov 8, 2024 at 5:13?PM Jeff Newmiller via R-help <r-help at r-project.org> wrote:
>> >>>
>> >>> Can you tell us what is wrong with the "chunked" package which comes up when you Google "r read large file in chunks"?
>> >>>
>> >>> On November 8, 2024 4:58:18 PM PST, Val <valkremk at gmail.com> wrote:
>> >>> >Hi All,
>> >>> >
>> >>> >I am reading data file ( > 1B rows) and do some date formatting like
>> >>> >      dat=fread(mydatafile)
>> >>> >     dat$date1 <- as.Date(ymd(dat$date1))
>> >>> >
>> >>> >However, I am getting an error message saying that
>> >>> >    Error: cons memory exhausted (limit reached?)
>> >>> >
>> >>> >The  script was working  when the number rows were  around 650M.
>> >>> >
>> >>> >Is there another way to  handle  a big data set in R?
>> >>> >
>> >>> >
>> >>> >Thank you.
>> >>> >
>> >>> >______________________________________________
>> >>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> >PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>> >>> >and provide commented, minimal, self-contained, reproducible code.
>> >>>
>> >>> --
>> >>> Sent from my phone. Please excuse my brevity.
>> >>>
>> >>> ______________________________________________
>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.

-- 
Sent from my phone. Please excuse my brevity.


From v@|kremk @end|ng |rom gm@||@com  Sat Nov  9 03:38:46 2024
From: v@|kremk @end|ng |rom gm@||@com (Val)
Date: Fri, 8 Nov 2024 20:38:46 -0600
Subject: [R] Limit
In-Reply-To: <CABghstQBO5X-PdH4hheDCE60x7bvMWTcFA+gt5tojEs8Aqr6wg@mail.gmail.com>
References: <CAJOiR6ZJQtubj=go6+qftiLYTxJYv+W8BCKsMpL5Tuq7GaOs7Q@mail.gmail.com>
 <CABghstQBO5X-PdH4hheDCE60x7bvMWTcFA+gt5tojEs8Aqr6wg@mail.gmail.com>
Message-ID: <CAJOiR6Y0e5K5XTF57Ou=pQUcbtdi_V+_LXBcNUHoswLmL-ZPwg@mail.gmail.com>

Thank you, I will take a look.

On Fri, Nov 8, 2024 at 8:09?PM Ben Bolker <bbolker at gmail.com> wrote:
>
> Check the "high performance task view" on CRAN ... https://cran.r-project.org/web/views/HighPerformanceComputing.html
>
> On Fri, Nov 8, 2024, 7:58 PM Val <valkremk at gmail.com> wrote:
>>
>> Hi All,
>>
>> I am reading data file ( > 1B rows) and do some date formatting like
>>       dat=fread(mydatafile)
>>      dat$date1 <- as.Date(ymd(dat$date1))
>>
>> However, I am getting an error message saying that
>>     Error: cons memory exhausted (limit reached?)
>>
>> The  script was working  when the number rows were  around 650M.
>>
>> Is there another way to  handle  a big data set in R?
>>
>>
>> Thank you.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From v@|kremk @end|ng |rom gm@||@com  Sat Nov  9 03:39:25 2024
From: v@|kremk @end|ng |rom gm@||@com (Val)
Date: Fri, 8 Nov 2024 20:39:25 -0600
Subject: [R] Limit
In-Reply-To: <E897B5C8-FAE9-4893-86FF-404615DD01F1@dcn.davis.ca.us>
References: <CAJOiR6ZJQtubj=go6+qftiLYTxJYv+W8BCKsMpL5Tuq7GaOs7Q@mail.gmail.com>
 <85D9A450-DF64-401D-BB20-00B78714BFD5@dcn.davis.ca.us>
 <CAGxFJbRSSFBqJJL286TR7xcNGFDY=Og_JxFvFn=F+dA0tRNWew@mail.gmail.com>
 <CAJOiR6b9PzaKR4njnkGppFMy+3TPDhXXmNBquFHt6-kJoahpCA@mail.gmail.com>
 <AD1512AD-3CCD-40A3-8E2D-968B30F97924@dcn.davis.ca.us>
 <CAJOiR6bR1ovJ+Y1dAi5D39EOB8foxC4kygYi34Y6S9B-b+--8Q@mail.gmail.com>
 <E897B5C8-FAE9-4893-86FF-404615DD01F1@dcn.davis.ca.us>
Message-ID: <CAJOiR6ZLw3SUyui0mv6T++X5qzXRHVi2SLL9tBnD93zBF_vWDw@mail.gmail.com>

Thank you Jeff for the tip!   I don't think I have  4 times as much
free memory to process data... .
I  allocated the max memory of the system.has.

On Fri, Nov 8, 2024 at 8:30?PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> There is always an implied "and do computations on it before writing the processed data out" when reading chunks of a file.
>
> And you would almost certainly not be getting that error if you were not out of memory.  A good rule of thumb is that you need 4 times as much free memory to process data than you need to read it in.
>
> On November 8, 2024 6:08:16 PM PST, Val <valkremk at gmail.com> wrote:
> >Hi Jeff,
> >
> >Memory was not an issue. The system only used 75% of the memory
> >allocated for the job.
> >
> > I am trying to understand what  "r read large file in chunks" is doing.
> >
> >On Fri, Nov 8, 2024 at 7:50?PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> >>
> >> Then you don't have enough memory to process the whole thing at once. Not unlike stuffing your mouth with cookies and not being able to chew for lack of space to move the food around in your mouth.
> >>
> >> Now, can you answer my question?
> >>
> >> On November 8, 2024 5:38:37 PM PST, Val <valkremk at gmail.com> wrote:
> >> >The data was read. The problem is with processing.
> >> >
> >> >On Fri, Nov 8, 2024 at 7:30?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >> >>
> >> >> Is the problem reading the file in or processing it after it has been read in?
> >> >>
> >> >> Bert
> >> >>
> >> >> On Fri, Nov 8, 2024 at 5:13?PM Jeff Newmiller via R-help <r-help at r-project.org> wrote:
> >> >>>
> >> >>> Can you tell us what is wrong with the "chunked" package which comes up when you Google "r read large file in chunks"?
> >> >>>
> >> >>> On November 8, 2024 4:58:18 PM PST, Val <valkremk at gmail.com> wrote:
> >> >>> >Hi All,
> >> >>> >
> >> >>> >I am reading data file ( > 1B rows) and do some date formatting like
> >> >>> >      dat=fread(mydatafile)
> >> >>> >     dat$date1 <- as.Date(ymd(dat$date1))
> >> >>> >
> >> >>> >However, I am getting an error message saying that
> >> >>> >    Error: cons memory exhausted (limit reached?)
> >> >>> >
> >> >>> >The  script was working  when the number rows were  around 650M.
> >> >>> >
> >> >>> >Is there another way to  handle  a big data set in R?
> >> >>> >
> >> >>> >
> >> >>> >Thank you.
> >> >>> >
> >> >>> >______________________________________________
> >> >>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >>> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>> >PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> >> >>> >and provide commented, minimal, self-contained, reproducible code.
> >> >>>
> >> >>> --
> >> >>> Sent from my phone. Please excuse my brevity.
> >> >>>
> >> >>> ______________________________________________
> >> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> >> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> --
> >> Sent from my phone. Please excuse my brevity.
>
> --
> Sent from my phone. Please excuse my brevity.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Nov  9 07:16:58 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 9 Nov 2024 06:16:58 +0000
Subject: [R] Limit
In-Reply-To: <CAJOiR6ZJQtubj=go6+qftiLYTxJYv+W8BCKsMpL5Tuq7GaOs7Q@mail.gmail.com>
References: <CAJOiR6ZJQtubj=go6+qftiLYTxJYv+W8BCKsMpL5Tuq7GaOs7Q@mail.gmail.com>
Message-ID: <437035ba-22d6-4db6-b96b-8bbdb4f99bba@sapo.pt>

?s 00:58 de 09/11/2024, Val escreveu:
> Hi All,
> 
> I am reading data file ( > 1B rows) and do some date formatting like
>        dat=fread(mydatafile)
>       dat$date1 <- as.Date(ymd(dat$date1))
> 
> However, I am getting an error message saying that
>      Error: cons memory exhausted (limit reached?)
> 
> The  script was working  when the number rows were  around 650M.
> 
> Is there another way to  handle  a big data set in R?
> 
> 
> Thank you.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

fread works but as.Date(ymd(.)) does not?
You probably don't need both date coercion functions, get rid of one of 
them and try again.


dat$date1 <- ymd(dat$date1)

or

dat$date1 <- as.Date(dat$date1)


Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From dyk|m7411 @end|ng |rom gm@||@com  Sat Nov  9 18:01:05 2024
From: dyk|m7411 @end|ng |rom gm@||@com (D)
Date: Sat, 9 Nov 2024 12:01:05 -0500
Subject: [R] How to install rgeoda in R
Message-ID: <CADmwX-+nT-Dxd1vfTq7R8ZhSWF1Ya-75RZ94f_xpMC5sCD7zNw@mail.gmail.com>

When trying to install rgeoda in R, I received an error message:

Warning in install.packages : package ?rgeoda? is not available for this
version of R

A version of this package for your version of R might be available
elsewhere, see the ideas at
https://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Installing-packages

How could I install the code of rgeoda? Any advice would be appreciated.

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Nov 10 17:49:40 2024
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 10 Nov 2024 08:49:40 -0800
Subject: [R] How to install rgeoda in R
In-Reply-To: <CADmwX-+nT-Dxd1vfTq7R8ZhSWF1Ya-75RZ94f_xpMC5sCD7zNw@mail.gmail.com>
References: <CADmwX-+nT-Dxd1vfTq7R8ZhSWF1Ya-75RZ94f_xpMC5sCD7zNw@mail.gmail.com>
Message-ID: <0A4717E1-0D45-41CD-B288-29C148BDA16C@dcn.davis.ca.us>

The rgeoda maintainer seems to be having difficulty keeping up with required changes to be supported on CRAN. This may get corrected soon or never.  There are instructions for compiling it yourself at https://geodacenter.github.io/rgeoda/ or you can contact the maintainer about their plans for getting it back on CRAN from there.

On November 9, 2024 9:01:05 AM PST, D <dykim7411 at gmail.com> wrote:
>When trying to install rgeoda in R, I received an error message:
>
>Warning in install.packages : package ?rgeoda? is not available for this
>version of R
>
>A version of this package for your version of R might be available
>elsewhere, see the ideas at
>https://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Installing-packages
>
>How could I install the code of rgeoda? Any advice would be appreciated.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From roy@mende|@@ohn @end|ng |rom no@@@gov  Sun Nov 10 19:43:10 2024
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Sun, 10 Nov 2024 10:43:10 -0800
Subject: [R] How to install rgeoda in R
In-Reply-To: <0A4717E1-0D45-41CD-B288-29C148BDA16C@dcn.davis.ca.us>
References: <CADmwX-+nT-Dxd1vfTq7R8ZhSWF1Ya-75RZ94f_xpMC5sCD7zNw@mail.gmail.com>
 <0A4717E1-0D45-41CD-B288-29C148BDA16C@dcn.davis.ca.us>
Message-ID: <3BAA3A9F-43C2-4CC5-BD1C-CF27E3D4D881@noaa.gov>

https://geodacenter.r-universe.dev/rgeoda


HTH,

-Roy

> On Nov 10, 2024, at 8:49?AM, Jeff Newmiller via R-help <r-help at r-project.org> wrote:
> 
> The rgeoda maintainer seems to be having difficulty keeping up with required changes to be supported on CRAN. This may get corrected soon or never.  There are instructions for compiling it yourself at https://geodacenter.github.io/rgeoda/ or you can contact the maintainer about their plans for getting it back on CRAN from there.
> 
> On November 9, 2024 9:01:05 AM PST, D <dykim7411 at gmail.com> wrote:
>> When trying to install rgeoda in R, I received an error message:
>> 
>> Warning in install.packages : package ?rgeoda? is not available for this
>> version of R
>> 
>> A version of this package for your version of R might be available
>> elsewhere, see the ideas at
>> https://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Installing-packages
>> 
>> How could I install the code of rgeoda? Any advice would be appreciated.
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From Roger@B|v@nd @end|ng |rom nhh@no  Mon Nov 11 13:07:34 2024
From: Roger@B|v@nd @end|ng |rom nhh@no (Roger Bivand)
Date: Mon, 11 Nov 2024 12:07:34 +0000
Subject: [R] How to install rgeoda in R
Message-ID: <SV0P279MB047504573165CDD5A59F860BEE582@SV0P279MB0475.NORP279.PROD.OUTLOOK.COM>

The rgeoda package, version 0.0.10-4, is, as mentioned in this thread, available from https://geodacenter.r-universe.dev/rgeoda, pending the release of an updated version of the BH package with corrected Boost C++ headers that do not fail on forthcoming clang++ 19, see https://github.com/GeoDaCenter/rgeoda/issues/49. A source version of rgeoda 0.0.10-7 is archived on https://cran.r-project.org/incoming/archive/, probably because it vendors (bundles in the package) the updated Boost headers (roughly 150MB), making the installed package very large indeed. The advice in https://github.com/eddelbuettel/bh/issues/101 suggests that others have also had difficulty limiting the vendoring to the failing component of the Boost headers.

Roger

--
Roger Bivand
Emeritus Professor
Norwegian School of Economics
Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway
Roger.Bivand at nhh.no

From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Mon Nov 11 14:53:32 2024
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Mon, 11 Nov 2024 14:53:32 +0100
Subject: [R] Matrix - querying dsCMatrix  how to save it
In-Reply-To: <ce8f517454084f91b839397e550e457b@DummenOrange.com>
References: <ce8f517454084f91b839397e550e457b@DummenOrange.com>
Message-ID: <26418.3164.708655.940106@stat.math.ethz.ch>

I was asked privately

    > I have been using <the Matrix package> extensively to
    > calculate the relatedness-matrix based on the pedigree for
    > our ornamental plants.  I was wondering if you could give
    > me some advice, for which I would like to thank you in
    > advance!

    > The output of the relatedness matrix I get from
    > the nadiv package is a dsCMatrix. I would like to save it
    > in some way, so I could query a subset of this matrix
    > later on, as in most cases, the full matrix is not
    > needed. Do you know what kind of format is ideal for
    > data-storage (either in file or in a database) for a
    > sparse matrix?  Thanks in advance!

as that is a relative general question, I allow myself to answer
in public such that the answer my help others as well.

Let's use an example from package 'nadiv':

require(nadiv)

?makeA # to learn about the function

## create a largish example
Awarcol <- makeA(ggTutorial[1:2000, 1:3])

str(Awarcol)
nnzero(Awarcol)
object.size(Awarcol)
object.size(as.matrix(Awarcol)) # ~ 14 times large

image(Awarcol) # wait a bit .. ... but it's worth it!

-------------

> Awarcol <- makeA(ggTutorial[1:2000, 1:3])
> str(Awarcol)
Formal class 'dsCMatrix' [package "Matrix"] with 7 slots
  ..@ i       : int [1:164107] 0 1 2 3 4 5 6 7 8 9 ...
  ..@ p       : int [1:2001] 0 1 2 3 4 5 6 7 8 9 ...
  ..@ Dim     : int [1:2] 2000 2000
  ..@ Dimnames:List of 2
  .. ..$ : chr [1:2000] "1" "2" "3" "4" ...
  .. ..$ : chr [1:2000] "1" "2" "3" "4" ...
  ..@ x       : num [1:164107] 1 1 1 1 1 1 1 1 1 1 ...
  ..@ uplo    : chr "U"
  ..@ factors : list()

> nnzero(Awarcol)
[1] 326214
> object.size(Awarcol)
2235112 bytes
> object.size(as.matrix(Awarcol))
32256488 bytes
>
------------------------------------------------

Now, save it (as file to current working directory) via

saveRDS(Awarcol, file = "makeA_warc.rds")

## and that is *only* 110 Kbytes :
> file.size("makeA_warc.rds")
[1] 115288


Or restore it in a later R session

Amat.warcol <- readRDS("makeA_warc.rds")

> str(Awarc)
Loading required package: Matrix
Formal class 'dsCMatrix' [package "Matrix"] with 7 slots
  ..@ i       : int [1:164107] 0 1 2 3 4 5 6 7 8 9 ...
  ..@ p       : int [1:2001] 0 1 2 3 4 5 6 7 8 9 ...
  ..@ Dim     : int [1:2] 2000 2000
  ..@ Dimnames:List of 2
  .. ..$ : chr [1:2000] "1" "2" "3" "4" ...
  .. ..$ : chr [1:2000] "1" "2" "3" "4" ...
  ..@ x       : num [1:164107] 1 1 1 1 1 1 1 1 1 1 ...
  ..@ uplo    : chr "U"
  ..@ factors : list()
> image(Awarc)
>

Note how 'str(..)' automatically loaded the Matrix package
which you do need for  image(<dsCMatrix>) to work nicely.


Best regards,
Martin

--
Martin Maechler
ETH Zurich  and  R Core team


From |vo@we|ch @end|ng |rom gm@||@com  Wed Nov 13 21:02:52 2024
From: |vo@we|ch @end|ng |rom gm@||@com (Ivo Welch)
Date: Wed, 13 Nov 2024 12:02:52 -0800
Subject: [R] Mac ARM for lm() ?
Message-ID: <CACi4-JnC+xBQbgsEL+7q9jptBNJG5ts0JsK4sGginwFrFz=tZg@mail.gmail.com>

I have found more general questions, but I have a specific one.  I
have a few million (independent) short regressions that I would like
to run (each reg has about 60 observations, though they can have
missing observations [yikes]).  So, I would like to be running as many
`lm` and `coef(lm)` in parallel as possible.  my hardware is Mac, with
nice GPUs and integrated memory --- and so far completely useless to
me.  `mclapply` is obviously very useful, but I want more, more, more
cores.

is there a recommended plug-in library to speed up just `lm` by also
using the GPU cores?


From @pro @end|ng |rom un|me|b@edu@@u  Thu Nov 14 13:45:44 2024
From: @pro @end|ng |rom un|me|b@edu@@u (Andrew Robinson)
Date: Thu, 14 Nov 2024 12:45:44 +0000
Subject: [R] [EXT]  Mac ARM for lm() ?
In-Reply-To: <CACi4-JnC+xBQbgsEL+7q9jptBNJG5ts0JsK4sGginwFrFz=tZg@mail.gmail.com>
References: <CACi4-JnC+xBQbgsEL+7q9jptBNJG5ts0JsK4sGginwFrFz=tZg@mail.gmail.com>
Message-ID: <6a0bda3b-6a2f-4cd0-8642-8681dd897f4a@Spark>

Not a direct answer but you may find lm.fit worth experimenting with.

Also try the high-performance computing task view on CRAN

Cheers,

Andrew

--
Andrew Robinson
Chief Executive Officer, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955
Email: apro at unimelb.edu.au
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/

I acknowledge the Traditional Owners of the land I inhabit, and pay my respects to their Elders.
On 14 Nov 2024 at 1:13?PM +0100, Ivo Welch <ivo.welch at gmail.com>, wrote:
External email: Please exercise caution

I have found more general questions, but I have a specific one. I
have a few million (independent) short regressions that I would like
to run (each reg has about 60 observations, though they can have
missing observations [yikes]). So, I would like to be running as many
`lm` and `coef(lm)` in parallel as possible. my hardware is Mac, with
nice GPUs and integrated memory --- and so far completely useless to
me. `mclapply` is obviously very useful, but I want more, more, more
cores.

is there a recommended plug-in library to speed up just `lm` by also
using the GPU cores?

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From pd@|gd @end|ng |rom gm@||@com  Thu Nov 14 14:51:29 2024
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Thu, 14 Nov 2024 14:51:29 +0100
Subject: [R] Mac ARM for lm() ?
In-Reply-To: <CACi4-JnC+xBQbgsEL+7q9jptBNJG5ts0JsK4sGginwFrFz=tZg@mail.gmail.com>
References: <CACi4-JnC+xBQbgsEL+7q9jptBNJG5ts0JsK4sGginwFrFz=tZg@mail.gmail.com>
Message-ID: <A74CD976-848E-4277-B6B8-C1B53E984A08@gmail.com>

Just curious...

1) Are these just simple linear regression fits?
2) How many different patterns of missingness are there?

What I am thinking is that parallel processing works best on similar tasks, so data shuffling could easily out drown out the actual regression computations.
What you might do could be to group the data according to the pattern of missing values, and then for each group work out the regressions in matrix form - essentially B = (X'X)^{-1}X', but could do smarter - and then do a million regressions as BY where Y has a million columns.

-pd


> On 13 Nov 2024, at 21:02 , Ivo Welch <ivo.welch at gmail.com> wrote:
> 
> I have found more general questions, but I have a specific one.  I
> have a few million (independent) short regressions that I would like
> to run (each reg has about 60 observations, though they can have
> missing observations [yikes]).  So, I would like to be running as many
> `lm` and `coef(lm)` in parallel as possible.  my hardware is Mac, with
> nice GPUs and integrated memory --- and so far completely useless to
> me.  `mclapply` is obviously very useful, but I want more, more, more
> cores.
> 
> is there a recommended plug-in library to speed up just `lm` by also
> using the GPU cores?
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jeremy@c|@rk @end|ng |rom pum@edu@p|  Fri Nov 15 10:55:05 2024
From: jeremy@c|@rk @end|ng |rom pum@edu@p| (Clark Jeremy)
Date: Fri, 15 Nov 2024 09:55:05 +0000
Subject: [R] R coding to extract allele frequencies from NCBI for ALL
 alleles of one SNP?
Message-ID: <AS2PR02MB9932BF24727B21A8FFD989C7AF242@AS2PR02MB9932.eurprd02.prod.outlook.com>

Dear All,

The following code extracts from NCBI very nice output for ONE allele of a SNP (often the allele with the second largest frequency - usually termed the minor allele). It gives an average minor allele frequency from all NCBI sources (which is what I want, except I'd like the addition of data for all the other alleles of one SNP) plus a table of minor allele frequencies from each source (which would also be nice - but not necessary). Does there exist a package in R with coding which could extract the data from NCBI for all the alleles of one SNP ? I've looked at getBM() from package biomaRt and searched via Google and Copilot- so far with no success. Many thanks.

remotes::install_github("ropensci/rsnps")
library("rsnps")
# Define the SNP ID
snp_id <- "rs11134679" ## this SNP has alleles A, C, G and T, but results are only for A
# Query the dbSNP database
result <- rsnps::ncbi_snp_query(snp_id)
result2 <- as.data.frame(result)
result2
result2$maf_population



	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Nov 15 15:06:20 2024
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 15 Nov 2024 15:06:20 +0100
Subject: [R] [EXT]  Mac ARM for lm() ?
In-Reply-To: <6a0bda3b-6a2f-4cd0-8642-8681dd897f4a@Spark>
References: <CACi4-JnC+xBQbgsEL+7q9jptBNJG5ts0JsK4sGginwFrFz=tZg@mail.gmail.com>
 <6a0bda3b-6a2f-4cd0-8642-8681dd897f4a@Spark>
Message-ID: <26423.21852.221255.781685@stat.math.ethz.ch>

>>>>> Andrew Robinson via R-help 
>>>>>     on Thu, 14 Nov 2024 12:45:44 +0000 writes:

    > Not a direct answer but you may find lm.fit worth
    > experimenting with.  

Yes, lm.fit() is already faster, and
    .lm.fit() {added to base R by me, when a similar question
    was asked years ago ...}
    is even an order of magnitude faster  in some cases.

See ?lm.fit
and notably

example(lm.fit)

which uses pkg microbenchmark for timing and  after which

   png("lmfit-ex.png")
   boxplot(mb, notch=TRUE)
   dev.off()

produces the attached nice image.

    > Also try the high-performance computing task view on CRAN

    > Cheers,
    > Andrew

    > --
    > Andrew Robinson Chief Executive Officer, CEBRA and
    > Professor of Biosecurity, School/s of BioSciences and
    > Mathematics & Statistics University of Melbourne, VIC 3010
    > Australia Tel: (+61) 0403 138 955 Email:
    > apro at unimelb.edu.au Website:
    > https://researchers.ms.unimelb.edu.au/~apro at unimelb/

    > I acknowledge the Traditional Owners of the land I
    > inhabit, and pay my respects to their Elders.  On 14 Nov
    > 2024 at 1:13?PM +0100, Ivo Welch <ivo.welch at gmail.com>,
    > wrote: External email: Please exercise caution

    > I have found more general questions, but I have a specific
    > one. I have a few million (independent) short regressions
    > that I would like to run (each reg has about 60
    > observations, though they can have missing observations
    > [yikes]). So, I would like to be running as many `lm` and
    > `coef(lm)` in parallel as possible. my hardware is Mac,
    > with nice GPUs and integrated memory --- and so far
    > completely useless to me. `mclapply` is obviously very
    > useful, but I want more, more, more cores.

    > is there a recommended plug-in library to speed up just
    > `lm` by also using the GPU cores?



-------------- next part --------------
A non-text attachment was scrubbed...
Name: lmfit-ex.png
Type: image/png
Size: 7605 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20241115/9ee1c007/attachment.png>

From bgunter@4567 @end|ng |rom gm@||@com  Fri Nov 15 16:28:01 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 15 Nov 2024 07:28:01 -0800
Subject: [R] R coding to extract allele frequencies from NCBI for ALL
 alleles of one SNP?
In-Reply-To: <AS2PR02MB9932BF24727B21A8FFD989C7AF242@AS2PR02MB9932.eurprd02.prod.outlook.com>
References: <AS2PR02MB9932BF24727B21A8FFD989C7AF242@AS2PR02MB9932.eurprd02.prod.outlook.com>
Message-ID: <CAGxFJbRBqy-=bb0=gL-ELKRsGEpU6C9x6Uh6wnkEEehcrUjkwQ@mail.gmail.com>

If you haven't already done so,  this might be better posted on
Bioconductor:
https://www.bioconductor.org/

Cheers,
Bert

On Fri, Nov 15, 2024 at 2:53?AM Clark Jeremy <jeremy.clark at pum.edu.pl>
wrote:

> Dear All,
>
> The following code extracts from NCBI very nice output for ONE allele of a
> SNP (often the allele with the second largest frequency - usually termed
> the minor allele). It gives an average minor allele frequency from all NCBI
> sources (which is what I want, except I'd like the addition of data for all
> the other alleles of one SNP) plus a table of minor allele frequencies from
> each source (which would also be nice - but not necessary). Does there
> exist a package in R with coding which could extract the data from NCBI for
> all the alleles of one SNP ? I've looked at getBM() from package biomaRt
> and searched via Google and Copilot- so far with no success. Many thanks.
>
> remotes::install_github("ropensci/rsnps")
> library("rsnps")
> # Define the SNP ID
> snp_id <- "rs11134679" ## this SNP has alleles A, C, G and T, but results
> are only for A
> # Query the dbSNP database
> result <- rsnps::ncbi_snp_query(snp_id)
> result2 <- as.data.frame(result)
> result2
> result2$maf_population
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From |vo@we|ch @end|ng |rom uc|@@edu  Sat Nov 16 01:07:15 2024
From: |vo@we|ch @end|ng |rom uc|@@edu (ivo welch)
Date: Fri, 15 Nov 2024 16:07:15 -0800
Subject: [R] [EXT] Mac ARM for lm() ?
In-Reply-To: <26423.21852.221255.781685@stat.math.ethz.ch>
References: <CACi4-JnC+xBQbgsEL+7q9jptBNJG5ts0JsK4sGginwFrFz=tZg@mail.gmail.com>
 <6a0bda3b-6a2f-4cd0-8642-8681dd897f4a@Spark>
 <26423.21852.221255.781685@stat.math.ethz.ch>
Message-ID: <CAJrNScRd+Gf3J3X=TFqPc8bkBseDTAA0jovphpB=M5WpRRsqnw@mail.gmail.com>

Thanks, and all well taken.  But are my beautiful GPUs (with integrated
memory architecture) really nothing more than a cooling area for the chip?

On Fri, Nov 15, 2024 at 6:06?AM Martin Maechler <maechler at stat.math.ethz.ch>
wrote:

> >>>>> Andrew Robinson via R-help
> >>>>>     on Thu, 14 Nov 2024 12:45:44 +0000 writes:
>
>     > Not a direct answer but you may find lm.fit worth
>     > experimenting with.
>
> Yes, lm.fit() is already faster, and
>     .lm.fit() {added to base R by me, when a similar question
>     was asked years ago ...}
>     is even an order of magnitude faster  in some cases.
>
> See ?lm.fit
> and notably
>
> example(lm.fit)
>
> which uses pkg microbenchmark for timing and  after which
>
>    png("lmfit-ex.png")
>    boxplot(mb, notch=TRUE)
>    dev.off()
>
> produces the attached nice image.
>
>     > Also try the high-performance computing task view on CRAN
>
>     > Cheers,
>     > Andrew
>
>     > --
>     > Andrew Robinson Chief Executive Officer, CEBRA and
>     > Professor of Biosecurity, School/s of BioSciences and
>     > Mathematics & Statistics University of Melbourne, VIC 3010
>     > Australia Tel: (+61) 0403 138 955 Email:
>     > apro at unimelb.edu.au Website:
>     > https://researchers.ms.unimelb.edu.au/~apro at unimelb/
>
>     > I acknowledge the Traditional Owners of the land I
>     > inhabit, and pay my respects to their Elders.  On 14 Nov
>     > 2024 at 1:13?PM +0100, Ivo Welch <ivo.welch at gmail.com>,
>     > wrote: External email: Please exercise caution
>
>     > I have found more general questions, but I have a specific
>     > one. I have a few million (independent) short regressions
>     > that I would like to run (each reg has about 60
>     > observations, though they can have missing observations
>     > [yikes]). So, I would like to be running as many `lm` and
>     > `coef(lm)` in parallel as possible. my hardware is Mac,
>     > with nice GPUs and integrated memory --- and so far
>     > completely useless to me. `mclapply` is obviously very
>     > useful, but I want more, more, more cores.
>
>     > is there a recommended plug-in library to speed up just
>     > `lm` by also using the GPU cores?
>
>
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Nov 16 14:55:26 2024
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 16 Nov 2024 05:55:26 -0800
Subject: [R] [EXT] Mac ARM for lm() ?
In-Reply-To: <CAJrNScRd+Gf3J3X=TFqPc8bkBseDTAA0jovphpB=M5WpRRsqnw@mail.gmail.com>
References: <CACi4-JnC+xBQbgsEL+7q9jptBNJG5ts0JsK4sGginwFrFz=tZg@mail.gmail.com>
 <6a0bda3b-6a2f-4cd0-8642-8681dd897f4a@Spark>
 <26423.21852.221255.781685@stat.math.ethz.ch>
 <CAJrNScRd+Gf3J3X=TFqPc8bkBseDTAA0jovphpB=M5WpRRsqnw@mail.gmail.com>
Message-ID: <5F0CB0D9-EE3E-41DD-AD5D-A606BF715440@dcn.davis.ca.us>

Mostly yes. GPU computing is much less flexible than CPU computing. Sometimes a small algorithmic adjustment such as Martin suggested is enough. Also, if you divide your work into a small-ish number of chunks then you can benefit from using the parallel package built into R.

That said, Google sez [1], but I haven't used it myself. It seems highly specialized and requires that you setup Python (a nontrivial task if you don't already know how to configure Python) and only works with Nvidia hardware.

[1] https://cran.r-project.org/package=GPUmatrix


On November 15, 2024 4:07:15 PM PST, ivo welch <ivo.welch at ucla.edu> wrote:
>Thanks, and all well taken.  But are my beautiful GPUs (with integrated
>memory architecture) really nothing more than a cooling area for the chip?
>
>On Fri, Nov 15, 2024 at 6:06?AM Martin Maechler <maechler at stat.math.ethz.ch>
>wrote:
>
>> >>>>> Andrew Robinson via R-help
>> >>>>>     on Thu, 14 Nov 2024 12:45:44 +0000 writes:
>>
>>     > Not a direct answer but you may find lm.fit worth
>>     > experimenting with.
>>
>> Yes, lm.fit() is already faster, and
>>     .lm.fit() {added to base R by me, when a similar question
>>     was asked years ago ...}
>>     is even an order of magnitude faster  in some cases.
>>
>> See ?lm.fit
>> and notably
>>
>> example(lm.fit)
>>
>> which uses pkg microbenchmark for timing and  after which
>>
>>    png("lmfit-ex.png")
>>    boxplot(mb, notch=TRUE)
>>    dev.off()
>>
>> produces the attached nice image.
>>
>>     > Also try the high-performance computing task view on CRAN
>>
>>     > Cheers,
>>     > Andrew
>>
>>     > --
>>     > Andrew Robinson Chief Executive Officer, CEBRA and
>>     > Professor of Biosecurity, School/s of BioSciences and
>>     > Mathematics & Statistics University of Melbourne, VIC 3010
>>     > Australia Tel: (+61) 0403 138 955 Email:
>>     > apro at unimelb.edu.au Website:
>>     > https://researchers.ms.unimelb.edu.au/~apro at unimelb/
>>
>>     > I acknowledge the Traditional Owners of the land I
>>     > inhabit, and pay my respects to their Elders.  On 14 Nov
>>     > 2024 at 1:13?PM +0100, Ivo Welch <ivo.welch at gmail.com>,
>>     > wrote: External email: Please exercise caution
>>
>>     > I have found more general questions, but I have a specific
>>     > one. I have a few million (independent) short regressions
>>     > that I would like to run (each reg has about 60
>>     > observations, though they can have missing observations
>>     > [yikes]). So, I would like to be running as many `lm` and
>>     > `coef(lm)` in parallel as possible. my hardware is Mac,
>>     > with nice GPUs and integrated memory --- and so far
>>     > completely useless to me. `mclapply` is obviously very
>>     > useful, but I want more, more, more cores.
>>
>>     > is there a recommended plug-in library to speed up just
>>     > `lm` by also using the GPU cores?
>>
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From z@he|d@r|@gh @end|ng |rom gm@||@com  Mon Nov 18 17:18:39 2024
From: z@he|d@r|@gh @end|ng |rom gm@||@com (zahra heidari gh)
Date: Mon, 18 Nov 2024 19:48:39 +0330
Subject: [R] Issue with non-standard file 'vert.txt' in R CMD check
Message-ID: <CAH7t7eoqYF2X+byg9K0CkF+qHoYSn6yq4-d=OSRZooN=H4Utng@mail.gmail.com>

Dear R Support Team,



I am experiencing an issue with my R package during the `R CMD check`
process. A non-standard file named `vert.txt` is being generated in the
check directory, causing a NOTE in the check results. Despite adding
`vert.txt` to `.Rbuildignore`, the file is still appearing. And, there are
no commands in any part of my package's code that would generate this file.



Here are the details of the issue:

- Package name: RHC

- Version: 0.1.0

- R version: 4.4.2

- Operating system: Windows 10

Attached (package building error):

?  checking examples ... [12s] OK (12.6s)

N  checking for non-standard things in the check directory

   Found the following files/directories:

     'vert.txt'

?  checking for detritus in the temp directory



   See


'C:/Users/sana/AppData/Local/Temp/RtmpGWGa7s/file32b039da423/RHC.Rcheck/00check.log'


   for details.



?? R CMD check results ??????????????? RHC 0.1.0 ????

Duration: 1m 38.5s



? checking for non-standard things in the check directory ... NOTE

  Found the following files/directories:

    'vert.txt'



0 errors ? | 0 warnings ? | 1 note ?

Thank you for your cooperation.



I would appreciate any guidance on resolving this issue.



Best regards,

Zahra Heidari Ghahfarrokhi

z.heidari.gh at gmail.com

2024.11.18

-- 

Zahra Heidari Ghahfarrokhi
PhD Student, Faculty of Natural Resources and Earth Sciences, Shahrekord
University, IRAN
Email: z_heidari_gh at yahoo.com <aa_naghipour at yahoo.com>,
*zahra.heydarigh at stu.sku.ac.ir
<zahra.heydarigh at stu.sku.ac.ir>*

	[[alternative HTML version deleted]]


From |kry|ov @end|ng |rom d|@root@org  Tue Nov 19 13:17:08 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Tue, 19 Nov 2024 15:17:08 +0300
Subject: [R] Issue with non-standard file 'vert.txt' in R CMD check
In-Reply-To: <CAH7t7eoqYF2X+byg9K0CkF+qHoYSn6yq4-d=OSRZooN=H4Utng@mail.gmail.com>
References: <CAH7t7eoqYF2X+byg9K0CkF+qHoYSn6yq4-d=OSRZooN=H4Utng@mail.gmail.com>
Message-ID: <20241119151708.17ba3020@arachnoid>

Dear Zahra Heidari Ghahfarrokhi,

Welcome to R-help!

? Mon, 18 Nov 2024 19:48:39 +0330
zahra heidari gh <z.heidari.gh at gmail.com> ?????:

>  A non-standard file named `vert.txt` is being generated in the
> check directory, causing a NOTE in the check results. Despite adding
> `vert.txt` to `.Rbuildignore`, the file is still appearing. And,
> there are no commands in any part of my package's code that would
> generate this file.

Does your package use the packages 'FD' or 'STEPCAM'? A quick search
for "vert.txt" on the GitHub mirror of CRAN demonstrates that these
packages create a file with this name [1], possibly in the current
directory, possibly without cleaning it up afterwards.

If yes, you might have to point the maintainer to the CRAN policy [2]
and the CRAN Cookbook [3]. These packages should not be creating a file
named "vert.txt" in the current directory because the user may have a
different important file named "vert.txt" in the current directory.

Next time you have a similar question, it's better addressed to
r-package-devel at r-project.org, not r-help at r-project.org.

-- 
Best regards,
Ivan

[1]
https://github.com/cran/FD/blob/1993781d8fa7e6f4107ebd3f52f919c6fe1760f7/R/dbFD.R#L685
https://github.com/cran/STEPCAM/blob/920bf1877374edc51b004af42a1339c4654c9344/R/modified_dbFD.R#L339

[2]
https://cran.r-project.org/web/packages/policies.html

[3]
https://contributor.r-project.org/cran-cookbook/code_issues.html#writing-files-and-directories-to-the-home-filespace


From ressw m@iii@g oii meer@@et  Wed Nov 20 19:09:01 2024
From: ressw m@iii@g oii meer@@et (ressw m@iii@g oii meer@@et)
Date: Wed, 20 Nov 2024 13:09:01 -0500
Subject: [R] grDevices::bringToTop is documented but not available: A bug?
Message-ID: <20241120130901.13227a50lkoapvgg@webmail.meer.net>



There is help for grDevices::bringToTop but the function is
not present.

> bringToTop()
Error in bringToTop() : could not find function "bringToTop"
> grDevices::bringToTop()
Error: 'bringToTop' is not an exported object from 'namespace:grDevices'
> getAnywhere(bringToTop)
no object named ?bringToTop? was found
# help output:
> ?bringToTop
bringToTop              package:grDevices              R Documentation

Assign Focus to a Window

  ... etc

Is this considered a bug?

(first time posting; hope I did this right)

sessionInfo:

R version 4.4.2 (2024-10-31)
Platform: x86_64-pc-linux-gnu
Running under: Ubuntu 20.04.6 LTS

Matrix products: default
BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0
LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

time zone: America/Los_Angeles
tzcode source: system (glibc)

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_4.4.2

Output from "library(help=grDevices)"

                 Information on package ?grDevices?

Description:

Package:            grDevices
Version:            4.4.2
Priority:           base
Title:              The R Graphics Devices and Support for Colours and
                     Fonts
Author:             R Core Team and contributors worldwide
Maintainer:         R Core Team <do-use-Contact-address at r-project.org>
Contact:            R-help mailing list <r-help at r-project.org>
Description:        Graphics devices and support for base and grid
                     graphics.
License:            Part of R 4.4.2
Suggests:           KernSmooth
NeedsCompilation:   yes
Built:              R 4.4.2; x86_64-pc-linux-gnu; 2024-11-04 01:29:04
                     UTC; unix


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Nov 21 11:41:58 2024
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 21 Nov 2024 05:41:58 -0500
Subject: [R] 
 grDevices::bringToTop is documented but not available: A bug?
In-Reply-To: <20241120130901.13227a50lkoapvgg@webmail.meer.net>
References: <20241120130901.13227a50lkoapvgg@webmail.meer.net>
Message-ID: <38ee958a-42e8-4a88-adc0-c41d220f7a8d@gmail.com>

It's a Windows-only function.  It looks like revision r75103 moved it 
out of the Windows section of the help pages six years ago.  Some other 
help pages were similarly moved, e.g.
   - ?windows and ?windowsFonts, document the functions as being 
Windows-only.
   - ?msgWindow and ?windows.options have the same issue as ?bringToTop.

Maybe someone remembers the intention of that move...

Duncan Murdoch

On 2024-11-20 1:09 p.m., ressw at meer.net wrote:
> 
> 
> There is help for grDevices::bringToTop but the function is
> not present.
> 
>> bringToTop()
> Error in bringToTop() : could not find function "bringToTop"
>> grDevices::bringToTop()
> Error: 'bringToTop' is not an exported object from 'namespace:grDevices'
>> getAnywhere(bringToTop)
> no object named ?bringToTop? was found
> # help output:
>> ?bringToTop
> bringToTop              package:grDevices              R Documentation
> 
> Assign Focus to a Window
> 
>    ... etc
> 
> Is this considered a bug?
> 
> (first time posting; hope I did this right)
> 
> sessionInfo:
> 
> R version 4.4.2 (2024-10-31)
> Platform: x86_64-pc-linux-gnu
> Running under: Ubuntu 20.04.6 LTS
> 
> Matrix products: default
> BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0
> LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0
> 
> locale:
>    [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>    [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>    [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>    [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>    [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> 
> time zone: America/Los_Angeles
> tzcode source: system (glibc)
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] compiler_4.4.2
> 
> Output from "library(help=grDevices)"
> 
>                   Information on package ?grDevices?
> 
> Description:
> 
> Package:            grDevices
> Version:            4.4.2
> Priority:           base
> Title:              The R Graphics Devices and Support for Colours and
>                       Fonts
> Author:             R Core Team and contributors worldwide
> Maintainer:         R Core Team <do-use-Contact-address at r-project.org>
> Contact:            R-help mailing list <r-help at r-project.org>
> Description:        Graphics devices and support for base and grid
>                       graphics.
> License:            Part of R 4.4.2
> Suggests:           KernSmooth
> NeedsCompilation:   yes
> Built:              R 4.4.2; x86_64-pc-linux-gnu; 2024-11-04 01:29:04
>                       UTC; unix
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Nov 22 22:24:58 2024
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 22 Nov 2024 22:24:58 +0100
Subject: [R] 
 grDevices::bringToTop is documented but not available: A bug?
In-Reply-To: <38ee958a-42e8-4a88-adc0-c41d220f7a8d@gmail.com>
References: <20241120130901.13227a50lkoapvgg@webmail.meer.net>
 <38ee958a-42e8-4a88-adc0-c41d220f7a8d@gmail.com>
Message-ID: <26432.63146.846578.328076@stat.math.ethz.ch>

>>>>> Duncan Murdoch 
>>>>>     on Thu, 21 Nov 2024 05:41:58 -0500 writes:

    > It's a Windows-only function.  It looks like revision
    > r75103 moved it out of the Windows section of the help
    > pages six years ago.  Some other help pages were similarly
    > moved, e.g.  - ?windows and ?windowsFonts, document the
    > functions as being Windows-only.  - ?msgWindow and
    > ?windows.options have the same issue as ?bringToTop.

    > Maybe someone remembers the intention of that move...

    > Duncan Murdoch

Yes, I do.
R-core had agreed that the R Reference Manual  should not be
platform dependent and we would want all such documentation to
be available and the same, independently of the platform,
*but* then of course, mark  paragraphs (mostly) or full "pages"
(in this case) as  "Windows only" / etc.

I had been working quite a lot afterwards to get close to this
goal, but there are still parts to do, notably in the "devices space",
where *some* platform dependency may seem ok.

==> To answer the OP's question:

 Yes, there *is* a documentation bug here:

 All three help you (Duncan) mention above should be marked with something like
 __"Only on Windows"__

Martin

--
Martin Maechler
ETH Zurich   and   R Core team

    > On 2024-11-20 1:09 p.m., ressw at meer.net wrote:
    >> 
    >> 
    >> There is help for grDevices::bringToTop but the function
    >> is not present.
    >> 
    >>> bringToTop()
    >> Error in bringToTop() : could not find function
    >> "bringToTop"
    >>> grDevices::bringToTop()
    >> Error: 'bringToTop' is not an exported object from
    >> 'namespace:grDevices'
    >>> getAnywhere(bringToTop)
    >> no object named ?bringToTop? was found # help output:
    >>> ?bringToTop
    >> bringToTop package:grDevices R Documentation
    >> 
    >> Assign Focus to a Window
    >> 
    >> ... etc
    >> 
    >> Is this considered a bug?
    >> 
    >> (first time posting; hope I did this right)
    >> 
    >> sessionInfo:
    >> 
    >> R version 4.4.2 (2024-10-31) Platform:
    >> x86_64-pc-linux-gnu Running under: Ubuntu 20.04.6 LTS
    >> 
    >> Matrix products: default BLAS:
    >> /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0 LAPACK:
    >> /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0
    >> 
    >> locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3]
    >> LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5]
    >> LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7]
    >> LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C
    >> LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8
    >> LC_IDENTIFICATION=C
    >> 
    >> time zone: America/Los_Angeles tzcode source: system
    >> (glibc)
    >> 
    >> attached base packages: [1] stats graphics grDevices
    >> utils datasets methods base
    >> 
    >> loaded via a namespace (and not attached): [1]
    >> compiler_4.4.2
    >> 
    >> Output from "library(help=grDevices)"
    >> 
    >> Information on package ?grDevices?
    >> 
    >> Description:
    >> 
    >> Package: grDevices Version: 4.4.2 Priority: base Title:
    >> The R Graphics Devices and Support for Colours and Fonts
    >> Author: R Core Team and contributors worldwide
    >> Maintainer: R Core Team
    >> <do-use-Contact-address at r-project.org> Contact: R-help
    >> mailing list <r-help at r-project.org> Description: Graphics
    >> devices and support for base and grid graphics.  License:
    >> Part of R 4.4.2 Suggests: KernSmooth NeedsCompilation:
    >> yes Built: R 4.4.2; x86_64-pc-linux-gnu; 2024-11-04
    >> 01:29:04 UTC; unix
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    >> more, see https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide
    >> https://www.R-project.org/posting-guide.html and provide
    >> commented, minimal, self-contained, reproducible code.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    > more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > https://www.R-project.org/posting-guide.html and provide
    > commented, minimal, self-contained, reproducible code.


From tgs77m m@iii@g oii y@hoo@com  Sat Nov 23 06:52:47 2024
From: tgs77m m@iii@g oii y@hoo@com (tgs77m m@iii@g oii y@hoo@com)
Date: Fri, 22 Nov 2024 21:52:47 -0800
Subject: [R] dplyr summarize by groups
References: <005b01db3d6b$ed2288a0$c76799e0$.ref@yahoo.com>
Message-ID: <005b01db3d6b$ed2288a0$c76799e0$@yahoo.com>

# Get mean, min, max sigma and skew by group

 options (digits = 3)
 library (ISwR
data(energy)

data %>%
  group_by(stature) %>%
  summarize(
    Mean = mean(expend),
    Min =  min(expend),
    Max = max(expend),
    Sigma = sd(expend),
    Skew = skew(expend))

# Output

  stature  Mean   Min   Max Sigma  Skew
  <fct>   <dbl> <dbl> <dbl> <dbl> <dbl>
1 lean     8.07  6.13  10.9  1.24 0.907
2 obese   10.3   8.79  12.8  1.40 0.587

Why does output stats vary in decimal places even when options (digits=3)
were set?

All the best

Thomas S.




	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Sat Nov 23 11:43:46 2024
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sat, 23 Nov 2024 12:43:46 +0200
Subject: [R] dplyr summarize by groups
In-Reply-To: <005b01db3d6b$ed2288a0$c76799e0$@yahoo.com>
References: <005b01db3d6b$ed2288a0$c76799e0$.ref@yahoo.com>
 <005b01db3d6b$ed2288a0$c76799e0$@yahoo.com>
Message-ID: <CAGgJW76iR8oNCQb4Wy6FgmpMW+_86yLBsufGgFZfw7ees5-aDw@mail.gmail.com>

This is because options(digits=3) specifies the number of significant
digits, not the number of decimal places.
See ?options and search for digits.

> a <- 12.345
> options(digits=4)
> print(a)
[1] 12.35
> options(digits=5)
> print(a)
[1] 12.345
> options(digits=2)
> print(a)
[1] 12
>

On Sat, Nov 23, 2024 at 7:53?AM tgs77m--- via R-help <r-help at r-project.org>
wrote:

> # Get mean, min, max sigma and skew by group
>
>  options (digits = 3)
>  library (ISwR
> data(energy)
>
> data %>%
>   group_by(stature) %>%
>   summarize(
>     Mean = mean(expend),
>     Min =  min(expend),
>     Max = max(expend),
>     Sigma = sd(expend),
>     Skew = skew(expend))
>
> # Output
>
>   stature  Mean   Min   Max Sigma  Skew
>   <fct>   <dbl> <dbl> <dbl> <dbl> <dbl>
> 1 lean     8.07  6.13  10.9  1.24 0.907
> 2 obese   10.3   8.79  12.8  1.40 0.587
>
> Why does output stats vary in decimal places even when options (digits=3)
> were set?
>
> All the best
>
> Thomas S.
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ro||turner @end|ng |rom po@teo@net  Tue Nov 26 02:09:32 2024
From: ro||turner @end|ng |rom po@teo@net (Rolf Turner)
Date: Tue, 26 Nov 2024 01:09:32 +0000
Subject: [R] Using vi syntax in command line editing.
Message-ID: <20241126140932.671e4a7c@new-hp>



I have recently acquired a new laptop.  (My old one was giving me
ominous messages on boot-up, about possible hard drive problems.)

I want to get everything running "just as it was" on the old laptop (So
that I can stay in my comfort zone).  In particular, I would like to
do command line editing with vi syntax, which is what I am used to.

I cannot for the life of me remember how I told R to use vi syntax on
my old laptop.  I am sure it was very simple.  A web search led me to
advice that this had to be do be done by installing some "plugins"
(???), but I am certain that stuff like that was not necessary.

Can anyone refesh my aging memory?  Thanks.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Stats. Dep't. (secretaries) phone:
         +64-9-373-7599 ext. 89622
Home phone: +64-9-480-4619


From bbo|ker @end|ng |rom gm@||@com  Tue Nov 26 02:13:02 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 25 Nov 2024 20:13:02 -0500
Subject: [R] Using vi syntax in command line editing.
In-Reply-To: <20241126140932.671e4a7c@new-hp>
References: <20241126140932.671e4a7c@new-hp>
Message-ID: <df8dbe7d-85ea-4143-bf17-a1a179f135af@gmail.com>

   Maybe

https://stackoverflow.com/questions/6235034/vi-keybindings-for-r-command-line-like-in-bash

  ?? (tl;dr "set editing-mode vi" or "set keymap vi" in .inputrc ... )


On 11/25/24 20:09, Rolf Turner wrote:
> 
> 
> I have recently acquired a new laptop.  (My old one was giving me
> ominous messages on boot-up, about possible hard drive problems.)
> 
> I want to get everything running "just as it was" on the old laptop (So
> that I can stay in my comfort zone).  In particular, I would like to
> do command line editing with vi syntax, which is what I am used to.
> 
> I cannot for the life of me remember how I told R to use vi syntax on
> my old laptop.  I am sure it was very simple.  A web search led me to
> advice that this had to be do be done by installing some "plugins"
> (???), but I am certain that stuff like that was not necessary.
> 
> Can anyone refesh my aging memory?  Thanks.
> 
> cheers,
> 
> Rolf Turner
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
* E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From ro||turner @end|ng |rom po@teo@net  Tue Nov 26 02:54:36 2024
From: ro||turner @end|ng |rom po@teo@net (Rolf Turner)
Date: Tue, 26 Nov 2024 01:54:36 +0000
Subject: [R] Using vi syntax in command line editing.
In-Reply-To: <df8dbe7d-85ea-4143-bf17-a1a179f135af@gmail.com>
References: <20241126140932.671e4a7c@new-hp>
 <df8dbe7d-85ea-4143-bf17-a1a179f135af@gmail.com>
Message-ID: <20241126145436.0aa60583@elderly-dell>


On Mon, 25 Nov 2024 20:13:02 -0500
Ben Bolker <bbolker at gmail.com> wrote:

>    Maybe
> 
> https://stackoverflow.com/questions/6235034/vi-keybindings-for-r-command-line-like-in-bash
> 
>   ?? (tl;dr "set editing-mode vi" or "set keymap vi" in .inputrc ... )

Yew bewdy!!!  That (set editing-mode vi) did it.  My everlasting
gratitude.

cheers

Rolf

> 
> 
> On 11/25/24 20:09, Rolf Turner wrote:
> > 
> > 
> > I have recently acquired a new laptop.  (My old one was giving me
> > ominous messages on boot-up, about possible hard drive problems.)
> > 
> > I want to get everything running "just as it was" on the old laptop
> > (So that I can stay in my comfort zone).  In particular, I would
> > like to do command line editing with vi syntax, which is what I am
> > used to.
> > 
> > I cannot for the life of me remember how I told R to use vi syntax
> > on my old laptop.  I am sure it was very simple.  A web search led
> > me to advice that this had to be do be done by installing some
> > "plugins" (???), but I am certain that stuff like that was not
> > necessary.
> > 
> > Can anyone refesh my aging memory?  Thanks.
> > 
> > cheers,
> > 
> > Rolf Turner
> > 
> 



-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Stats. Dep't. (secretaries) phone:
         +64-9-373-7599 ext. 89622
Home phone: +64-9-480-4619


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Wed Nov 27 01:53:27 2024
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Wed, 27 Nov 2024 00:53:27 +0000
Subject: [R] Convert string to date time
Message-ID: <DM6PR03MB504981E45B90563A848A6692E2282@DM6PR03MB5049.namprd03.prod.outlook.com>

I am reading a string that has the following form:

"2020-08-26_05:15:01"

I want to convert the string to a date-time variable. I tired:

x <- "2007-02-01_10:10:30"
x <- as.POSIXct(x,tz=Sys.timezone())
x

but this did not work; the time portion was ignored. I suspect the problem is the _ between the date and time, but I don't know how to account for this character in the string.

I hope someone can tell me how to read the string as a date time constant.

John?



John David Sorkin M.D., Ph.D.
Professor of Medicine, University of Maryland School of Medicine;
Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;?
PI?Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;
Senior Statistician University of Maryland Center for Vascular Research;

Division of Gerontology and Paliative Care,
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
Cell phone 443-418-5382




From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Nov 27 01:59:59 2024
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Tue, 26 Nov 2024 16:59:59 -0800
Subject: [R] Convert string to date time
In-Reply-To: <DM6PR03MB504981E45B90563A848A6692E2282@DM6PR03MB5049.namprd03.prod.outlook.com>
References: <DM6PR03MB504981E45B90563A848A6692E2282@DM6PR03MB5049.namprd03.prod.outlook.com>
Message-ID: <67735a8b-8e53-4d7d-8331-d11a2deb9ecd@comcast.net>


On 11/26/24 16:53, Sorkin, John wrote:
> I am reading a string that has the following form:
>
> "2020-08-26_05:15:01"
>
> I want to convert the string to a date-time variable. I tired:
>
> x <- "2007-02-01_10:10:30"

That underscore is what's causing your problems. If it needs to stay in 
there because you have a bunch of them in htat format then you need to 
add the appropriate format string.


---

David

> x <- as.POSIXct(x,tz=Sys.timezone())
> x
>
> but this did not work; the time portion was ignored. I suspect the problem is the _ between the date and time, but I don't know how to account for this character in the string.
>
> I hope someone can tell me how to read the string as a date time constant.
>
> John
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine, University of Maryland School of Medicine;
> Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;
> PI?Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;
> Senior Statistician University of Maryland Center for Vascular Research;
>
> Division of Gerontology and Paliative Care,
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> Cell phone 443-418-5382
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh @end|ng |rom temp|e@edu  Wed Nov 27 02:11:35 2024
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Wed, 27 Nov 2024 01:11:35 +0000
Subject: [R] [External]  Convert string to date time
In-Reply-To: <DM6PR03MB504981E45B90563A848A6692E2282@DM6PR03MB5049.namprd03.prod.outlook.com>
References: <DM6PR03MB504981E45B90563A848A6692E2282@DM6PR03MB5049.namprd03.prod.outlook.com>
Message-ID: <4A289EDA-E074-4CC5-A863-0CF1D7EBA80A@temple.edu>

> as.POSIXct(x, tz=Sys.timezone(), format="%Y-%m-%d_%H:%M:%OS")
[1] "2007-02-01 10:10:30 EST"


> On Nov 26, 2024, at 19:53, Sorkin, John <jsorkin at som.umaryland.edu> wrote:
> 
> x <- "2007-02-01_10:10:30"
> x <- as.POSIXct(x,tz=Sys.timezone())


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Nov 27 07:34:19 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 27 Nov 2024 06:34:19 +0000
Subject: [R] Convert string to date time
In-Reply-To: <DM6PR03MB504981E45B90563A848A6692E2282@DM6PR03MB5049.namprd03.prod.outlook.com>
References: <DM6PR03MB504981E45B90563A848A6692E2282@DM6PR03MB5049.namprd03.prod.outlook.com>
Message-ID: <4915c7e1-2e05-454c-85d2-4d17fb04808f@sapo.pt>

?s 00:53 de 27/11/2024, Sorkin, John escreveu:
> I am reading a string that has the following form:
> 
> "2020-08-26_05:15:01"
> 
> I want to convert the string to a date-time variable. I tired:
> 
> x <- "2007-02-01_10:10:30"
> x <- as.POSIXct(x,tz=Sys.timezone())
> x
> 
> but this did not work; the time portion was ignored. I suspect the problem is the _ between the date and time, but I don't know how to account for this character in the string.
> 
> I hope someone can tell me how to read the string as a date time constant.
> 
> John
> 
> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine, University of Maryland School of Medicine;
> Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;
> PI?Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;
> Senior Statistician University of Maryland Center for Vascular Research;
> 
> Division of Gerontology and Paliative Care,
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> Cell phone 443-418-5382
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

Pass an explicit format string with the underscore between the date and 
time parts.


x <- "2007-02-01_10:10:30"
as.POSIXct(x, format = "%Y-%m-%d_%H:%M:%S", tz = Sys.timezone())


Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From oren@@h@n| @end|ng |rom m@||@huj|@@c@||  Tue Nov 26 10:17:58 2024
From: oren@@h@n| @end|ng |rom m@||@huj|@@c@|| (Oren Shani)
Date: Tue, 26 Nov 2024 11:17:58 +0200
Subject: [R] Problem installing some r-packages via spack
Message-ID: <CAAJJGPmrUYxjJ7xiC4BMz6gW14Ww6TWOHP2HxXC0rTrykFAPRA@mail.gmail.com>

Hi All,

This occurs when I try to install certain r packages via the Spack package
manager (the example is for DelayedArray):

     70    ** R
     71    ** inst
     72    ** byte-compile and prepare package for lazy loading
  >> 73    Error: objects 'crossprod', 'tcrossprod' are not exported by
'namespace:Matrix'
     74    Execution halted
     75    ERROR: lazy loading failed for package 'DelayedArray'

The command that Spack is executing is something like this:

/usr/local/spack/opt/spack/linux-debian12-x86_64/gcc-12.2.0/r-4.4.1-loskbhydpk5kch62qtgxfwl3zdova22s/rlib/R/bin/INSTALL
--library=/usr/local/spack/opt/spack/linux-debian12-x86_64/gcc-12.2.0/r-delayedarray-0.32.0-5bysjvs6ohawjzdg3j6xzgzz4ps4ukbg/rlib/R/library
 .

I was able to tell Spack to add the --no-byte-compile flag but that doesn't
make any difference

I am really out of my wits here and this problem inhibits the installation
of several software packages that our users really need, so any help is
much appreciated

Many thanks,

Oren

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Wed Nov 27 08:41:16 2024
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 27 Nov 2024 09:41:16 +0200
Subject: [R] Problem installing some r-packages via spack
In-Reply-To: <CAAJJGPmrUYxjJ7xiC4BMz6gW14Ww6TWOHP2HxXC0rTrykFAPRA@mail.gmail.com>
References: <CAAJJGPmrUYxjJ7xiC4BMz6gW14Ww6TWOHP2HxXC0rTrykFAPRA@mail.gmail.com>
Message-ID: <CAGgJW75XFWiW8R8wf6b6ccWnXD4ii41VFkZonRdxEgcsnxifSg@mail.gmail.com>

I have never used Spack but I took a quick look at their website. They have
the option to install binaries. Perhaps this could work for you and avoid
the compilation error. Here is where they describe how to do it:
https://spack.io/spack-binary-packages/

On Wed, Nov 27, 2024 at 9:29?AM Oren Shani <oren.shani at mail.huji.ac.il>
wrote:

> Hi All,
>
> This occurs when I try to install certain r packages via the Spack package
> manager (the example is for DelayedArray):
>
>      70    ** R
>      71    ** inst
>      72    ** byte-compile and prepare package for lazy loading
>   >> 73    Error: objects 'crossprod', 'tcrossprod' are not exported by
> 'namespace:Matrix'
>      74    Execution halted
>      75    ERROR: lazy loading failed for package 'DelayedArray'
>
> The command that Spack is executing is something like this:
>
>
> /usr/local/spack/opt/spack/linux-debian12-x86_64/gcc-12.2.0/r-4.4.1-loskbhydpk5kch62qtgxfwl3zdova22s/rlib/R/bin/INSTALL
>
> --library=/usr/local/spack/opt/spack/linux-debian12-x86_64/gcc-12.2.0/r-delayedarray-0.32.0-5bysjvs6ohawjzdg3j6xzgzz4ps4ukbg/rlib/R/library
>  .
>
> I was able to tell Spack to add the --no-byte-compile flag but that doesn't
> make any difference
>
> I am really out of my wits here and this problem inhibits the installation
> of several software packages that our users really need, so any help is
> much appreciated
>
> Many thanks,
>
> Oren
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Wed Nov 27 17:30:34 2024
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Wed, 27 Nov 2024 16:30:34 +0000
Subject: [R] R Processing dataframe by group - equivalent to SAS by group
 processing with a first. and retain statments
Message-ID: <DM6PR03MB5049284BA7D21AA086B765D3E2282@DM6PR03MB5049.namprd03.prod.outlook.com>

I am an old, long time SAS programmer. I need to produce R code that processes a dataframe in a manner that is equivalent to that produced by using a by statement in SAS and an if first.day statement and a retain statement:

I want to take data (olddata) that looks like this
ID	Day
1	1
1	1
1	2
1	2
1	3
1	3
1	4
1	4
1	5
1	5
2	5
2	5
2	5
2	6
2	6
2	6
3	10
3	10

and make it look like this:
(withing each ID I am copying the first value of Day into a new variable, FirstDay, and propagating the FirstDay value through all rows that have the same ID:

ID	Day	FirstDay
1	1	1
1	1	1
1	2	1
1	2	1
1	3	1
1	3	1
1	4	1
1	4	1
1	5	1
1	5	1
2	5	5
2	5	5
2	5	5
2	6	5
2	6	5
2	6	5
3	10	3
3	10	3

SAS code that can do this is:

proc sort data=olddata;
  by ID Day;
run;

data newdata;
  retain FirstDay;
  set olddata;
  by ID;
  if first.ID then FirstDay=Day;
run;

I have NO idea how to do this is R (so I can't post test-code), but below I have R code that creates olddata:

ID <- c(rep(1,10),rep(2,6),rep(3,2))
date <- c(rep(1,2),rep(2,2),rep(3,2),rep(4,2),rep(5,2),
          rep(5,3),rep(6,3),rep(10,2))
date
olddata <- data.frame(ID=ID,date=date)
olddata

Any suggestions on how to do this would be appreciated. . . I have worked on this for more than 12-hours, despite multiple we searches I have gotten nowhere. . . 

Thanks
John




John David Sorkin M.D., Ph.D.
Professor of Medicine, University of Maryland School of Medicine;
Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;?
PI?Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;
Senior Statistician University of Maryland Center for Vascular Research;

Division of Gerontology and Paliative Care,
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
Cell phone 443-418-5382




From twoo|m@n @end|ng |rom ont@rgettek@com  Wed Nov 27 18:05:06 2024
From: twoo|m@n @end|ng |rom ont@rgettek@com (Tom Woolman)
Date: Wed, 27 Nov 2024 17:05:06 +0000
Subject: [R] 
 R Processing dataframe by group - equivalent to SAS by group
 processing with a first. and retain statments
In-Reply-To: <DM6PR03MB5049284BA7D21AA086B765D3E2282@DM6PR03MB5049.namprd03.prod.outlook.com>
References: <DM6PR03MB5049284BA7D21AA086B765D3E2282@DM6PR03MB5049.namprd03.prod.outlook.com>
Message-ID: <Te18drcvnOwJUpPTLCxlkYthSx6zu9jHwuP-SbAeagWR78JoqTByxwVxBRbfnvP1ztfN_LBmvup6o4TQ5alhRvgBZRtNH0tMz2f92SolUZ8=@ontargettek.com>

Check out the dplyr package, specifically the mutate function.

# Create new column based on existing column value 

df <- df %>% mutate(FirstDay = if(ID = 2, 5))

df



Repeat as needed to capture all of the day/firstday combinations you want to account for.

Like everything else in R, there are probably at least a dozen other ways to do this, between base R and all of the library packages available.




On Wednesday, November 27th, 2024 at 11:30 AM, Sorkin, John <jsorkin at som.umaryland.edu> wrote:

> 
> 
> I am an old, long time SAS programmer. I need to produce R code that processes a dataframe in a manner that is equivalent to that produced by using a by statement in SAS and an if first.day statement and a retain statement:
> 
> I want to take data (olddata) that looks like this
> ID Day
> 1 1
> 1 1
> 1 2
> 1 2
> 1 3
> 1 3
> 1 4
> 1 4
> 1 5
> 1 5
> 2 5
> 2 5
> 2 5
> 2 6
> 2 6
> 2 6
> 3 10
> 3 10
> 
> and make it look like this:
> (withing each ID I am copying the first value of Day into a new variable, FirstDay, and propagating the FirstDay value through all rows that have the same ID:
> 
> ID Day FirstDay
> 1 1 1
> 1 1 1
> 1 2 1
> 1 2 1
> 1 3 1
> 1 3 1
> 1 4 1
> 1 4 1
> 1 5 1
> 1 5 1
> 2 5 5
> 2 5 5
> 2 5 5
> 2 6 5
> 2 6 5
> 2 6 5
> 3 10 3
> 3 10 3
> 
> SAS code that can do this is:
> 
> proc sort data=olddata;
> by ID Day;
> run;
> 
> data newdata;
> retain FirstDay;
> set olddata;
> by ID;
> if first.ID then FirstDay=Day;
> run;
> 
> I have NO idea how to do this is R (so I can't post test-code), but below I have R code that creates olddata:
> 
> ID <- c(rep(1,10),rep(2,6),rep(3,2))
> date <- c(rep(1,2),rep(2,2),rep(3,2),rep(4,2),rep(5,2),
> rep(5,3),rep(6,3),rep(10,2))
> date
> olddata <- data.frame(ID=ID,date=date)
> olddata
> 
> Any suggestions on how to do this would be appreciated. . . I have worked on this for more than 12-hours, despite multiple we searches I have gotten nowhere. . .
> 
> Thanks
> John
> 
> 
> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine, University of Maryland School of Medicine;
> Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;
> PI Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;
> Senior Statistician University of Maryland Center for Vascular Research;
> 
> Division of Gerontology and Paliative Care,
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> Cell phone 443-418-5382
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From twoo|m@n @end|ng |rom ont@rgettek@com  Wed Nov 27 18:07:49 2024
From: twoo|m@n @end|ng |rom ont@rgettek@com (Tom Woolman)
Date: Wed, 27 Nov 2024 17:07:49 +0000
Subject: [R] 
 R Processing dataframe by group - equivalent to SAS by group
 processing with a first. and retain statments
In-Reply-To: <Te18drcvnOwJUpPTLCxlkYthSx6zu9jHwuP-SbAeagWR78JoqTByxwVxBRbfnvP1ztfN_LBmvup6o4TQ5alhRvgBZRtNH0tMz2f92SolUZ8=@ontargettek.com>
References: <DM6PR03MB5049284BA7D21AA086B765D3E2282@DM6PR03MB5049.namprd03.prod.outlook.com>
 <Te18drcvnOwJUpPTLCxlkYthSx6zu9jHwuP-SbAeagWR78JoqTByxwVxBRbfnvP1ztfN_LBmvup6o4TQ5alhRvgBZRtNH0tMz2f92SolUZ8=@ontargettek.com>
Message-ID: <LUTLdTJ_nO8Dk-8CPc-8d92On8nWM1gRGIHR2f8LP9fS1GjV_QRPYw3rjPc3D4VZOjeV5SddszrUkvkagrTW2Yzf7uq8cI-xIkP2Zf6tX5U=@ontargettek.com>

Oh and don't forget:

#first line of code, bring dplyr into memory after that package has been installed.

library(dplyr)




On Wednesday, November 27th, 2024 at 12:05 PM, Tom Woolman <twoolman at ontargettek.com> wrote:

> 
> 
> Check out the dplyr package, specifically the mutate function.
> 
> # Create new column based on existing column value
> 
> df <- df %>% mutate(FirstDay = if(ID = 2, 5))
> 
> 
> df
> 
> 
> 
> Repeat as needed to capture all of the day/firstday combinations you want to account for.
> 
> Like everything else in R, there are probably at least a dozen other ways to do this, between base R and all of the library packages available.
> 
> 
> 
> 
> On Wednesday, November 27th, 2024 at 11:30 AM, Sorkin, John jsorkin at som.umaryland.edu wrote:
> 
> > I am an old, long time SAS programmer. I need to produce R code that processes a dataframe in a manner that is equivalent to that produced by using a by statement in SAS and an if first.day statement and a retain statement:
> > 
> > I want to take data (olddata) that looks like this
> > ID Day
> > 1 1
> > 1 1
> > 1 2
> > 1 2
> > 1 3
> > 1 3
> > 1 4
> > 1 4
> > 1 5
> > 1 5
> > 2 5
> > 2 5
> > 2 5
> > 2 6
> > 2 6
> > 2 6
> > 3 10
> > 3 10
> > 
> > and make it look like this:
> > (withing each ID I am copying the first value of Day into a new variable, FirstDay, and propagating the FirstDay value through all rows that have the same ID:
> > 
> > ID Day FirstDay
> > 1 1 1
> > 1 1 1
> > 1 2 1
> > 1 2 1
> > 1 3 1
> > 1 3 1
> > 1 4 1
> > 1 4 1
> > 1 5 1
> > 1 5 1
> > 2 5 5
> > 2 5 5
> > 2 5 5
> > 2 6 5
> > 2 6 5
> > 2 6 5
> > 3 10 3
> > 3 10 3
> > 
> > SAS code that can do this is:
> > 
> > proc sort data=olddata;
> > by ID Day;
> > run;
> > 
> > data newdata;
> > retain FirstDay;
> > set olddata;
> > by ID;
> > if first.ID then FirstDay=Day;
> > run;
> > 
> > I have NO idea how to do this is R (so I can't post test-code), but below I have R code that creates olddata:
> > 
> > ID <- c(rep(1,10),rep(2,6),rep(3,2))
> > date <- c(rep(1,2),rep(2,2),rep(3,2),rep(4,2),rep(5,2),
> > rep(5,3),rep(6,3),rep(10,2))
> > date
> > olddata <- data.frame(ID=ID,date=date)
> > olddata
> > 
> > Any suggestions on how to do this would be appreciated. . . I have worked on this for more than 12-hours, despite multiple we searches I have gotten nowhere. . .
> > 
> > Thanks
> > John
> > 
> > John David Sorkin M.D., Ph.D.
> > Professor of Medicine, University of Maryland School of Medicine;
> > Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;
> > PI Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;
> > Senior Statistician University of Maryland Center for Vascular Research;
> > 
> > Division of Gerontology and Paliative Care,
> > 10 North Greene Street
> > GRECC (BT/18/GR)
> > Baltimore, MD 21201-1524
> > Cell phone 443-418-5382
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From o||v|er@crouzet @end|ng |rom un|v-n@nte@@|r  Wed Nov 27 18:13:29 2024
From: o||v|er@crouzet @end|ng |rom un|v-n@nte@@|r (Olivier Crouzet)
Date: Wed, 27 Nov 2024 18:13:29 +0100
Subject: [R] 
 R Processing dataframe by group - equivalent to SAS by group
 processing with a first. and retain statments
In-Reply-To: <Te18drcvnOwJUpPTLCxlkYthSx6zu9jHwuP-SbAeagWR78JoqTByxwVxBRbfnvP1ztfN_LBmvup6o4TQ5alhRvgBZRtNH0tMz2f92SolUZ8=@ontargettek.com>
References: <DM6PR03MB5049284BA7D21AA086B765D3E2282@DM6PR03MB5049.namprd03.prod.outlook.com>
 <Te18drcvnOwJUpPTLCxlkYthSx6zu9jHwuP-SbAeagWR78JoqTByxwVxBRbfnvP1ztfN_LBmvup6o4TQ5alhRvgBZRtNH0tMz2f92SolUZ8=@ontargettek.com>
Message-ID: <20241127181329.0f5f4d90f393468963af1bcd@univ-nantes.fr>

Dear John,

Considering that you've got the following dataframe:

ID <- c(rep(1,10),rep(2,6),rep(3,2))
date <- c(rep(1,2),rep(2,2),rep(3,2),rep(4,2),rep(5,2),
          rep(5,3),rep(6,3),rep(10,2))
df <- data.frame(ID, date)

I would suggest to go this way:

newdf <- df %>% dplyr::group_by(ID) %>% dplyr::mutate(firstday =
first(date))

Which produces:

> newdf
# A tibble: 18 ? 3
# Groups:   ID [3]
      ID  date   ave
   <dbl> <dbl> <dbl>
 1     1     1     1
 2     1     1     1
 3     1     2     1
 4     1     2     1
 5     1     3     1
 6     1     3     1
 7     1     4     1
 8     1     4     1
 9     1     5     1
10     1     5     1
11     2     5     5
12     2     5     5
13     2     5     5
14     2     6     5
15     2     6     5
16     2     6     5
17     3    10    10
18     3    10    10


I think it does what you need
Olivier.


Tom Woolman <twoolman at ontargettek.com> wrote:

> Check out the dplyr package, specifically the mutate function.
> 
> # Create new column based on existing column value 
> 
> df <- df %>% mutate(FirstDay = if(ID = 2, 5))
> 
> df
> 
> 
> 
> Repeat as needed to capture all of the day/firstday combinations you
> want to account for.
> 
> Like everything else in R, there are probably at least a dozen other
> ways to do this, between base R and all of the library packages
> available.
> 
> 
> 
> 
> On Wednesday, November 27th, 2024 at 11:30 AM, Sorkin, John
> <jsorkin at som.umaryland.edu> wrote:
> 
> > 
> > 
> > I am an old, long time SAS programmer. I need to produce R code
> > that processes a dataframe in a manner that is equivalent to that
> > produced by using a by statement in SAS and an if first.day
> > statement and a retain statement:
> > 
> > I want to take data (olddata) that looks like this
> > ID Day
> > 1 1
> > 1 1
> > 1 2
> > 1 2
> > 1 3
> > 1 3
> > 1 4
> > 1 4
> > 1 5
> > 1 5
> > 2 5
> > 2 5
> > 2 5
> > 2 6
> > 2 6
> > 2 6
> > 3 10
> > 3 10
> > 
> > and make it look like this:
> > (withing each ID I am copying the first value of Day into a new
> > variable, FirstDay, and propagating the FirstDay value through all
> > rows that have the same ID:
> > 
> > ID Day FirstDay
> > 1 1 1
> > 1 1 1
> > 1 2 1
> > 1 2 1
> > 1 3 1
> > 1 3 1
> > 1 4 1
> > 1 4 1
> > 1 5 1
> > 1 5 1
> > 2 5 5
> > 2 5 5
> > 2 5 5
> > 2 6 5
> > 2 6 5
> > 2 6 5
> > 3 10 3
> > 3 10 3
> > 
> > SAS code that can do this is:
> > 
> > proc sort data=olddata;
> > by ID Day;
> > run;
> > 
> > data newdata;
> > retain FirstDay;
> > set olddata;
> > by ID;
> > if first.ID then FirstDay=Day;
> > run;
> > 
> > I have NO idea how to do this is R (so I can't post test-code), but
> > below I have R code that creates olddata:
> > 
> > ID <- c(rep(1,10),rep(2,6),rep(3,2))
> > date <- c(rep(1,2),rep(2,2),rep(3,2),rep(4,2),rep(5,2),
> > rep(5,3),rep(6,3),rep(10,2))
> > date
> > olddata <- data.frame(ID=ID,date=date)
> > olddata
> > 
> > Any suggestions on how to do this would be appreciated. . . I have
> > worked on this for more than 12-hours, despite multiple we searches
> > I have gotten nowhere. . .
> > 
> > Thanks
> > John
> > 
> > 
> > 
> > 
> > John David Sorkin M.D., Ph.D.
> > Professor of Medicine, University of Maryland School of Medicine;
> > Associate Director for Biostatistics and Informatics, Baltimore VA
> > Medical Center Geriatrics Research, Education, and Clinical Center;
> > PI Biostatistics and Informatics Core, University of Maryland
> > School of Medicine Claude D. Pepper Older Americans Independence
> > Center; Senior Statistician University of Maryland Center for
> > Vascular Research;
> > 
> > Division of Gerontology and Paliative Care,
> > 10 North Greene Street
> > GRECC (BT/18/GR)
> > Baltimore, MD 21201-1524
> > Cell phone 443-418-5382
> > 
> > 
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > https://www.R-project.org/posting-guide.html and provide commented,
> > minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.


-- 
  Olivier Crouzet, PhD
  http://olivier.ghostinthemachine.space
  /Ma?tre de Conf?rences/
  @LLING - Laboratoire de Linguistique de Nantes
    UMR6310 CNRS / Universit? de Nantes


From rmh @end|ng |rom temp|e@edu  Wed Nov 27 18:22:59 2024
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Wed, 27 Nov 2024 17:22:59 +0000
Subject: [R] 
 [External] R Processing dataframe by group - equivalent to SAS
 by group processing with a first. and retain statments
In-Reply-To: <DM6PR03MB5049284BA7D21AA086B765D3E2282@DM6PR03MB5049.namprd03.prod.outlook.com>
References: <DM6PR03MB5049284BA7D21AA086B765D3E2282@DM6PR03MB5049.namprd03.prod.outlook.com>
Message-ID: <ED6EBAD6-A729-4073-AD8E-1ECDA48DF811@temple.edu>

I would use base R.


newdata <- cbind(olddata, FirstDay=olddata$date)
newdata$FirstDay <- with(newdata, {
  for (thisID in unique(ID))
    FirstDay[ID==thisID] <- FirstDay[ID==thisID][1]
  FirstDay}
  )
newdata

note that both my solution and Olivier have newdata$FirstDay[17:18] == 10
which is what I thinkk you intended.

Rich

> On Nov 27, 2024, at 11:30, Sorkin, John <jsorkin at som.umaryland.edu> wrote:
>
> I am an old, long time SAS programmer. I need to produce R code that processes a dataframe in a manner that is equivalent to that produced by using a by statement in SAS and an if first.day statement and a retain statement:
>
> I want to take data (olddata) that looks like this
> ID Day
> 1 1
> 1 1
> 1 2
> 1 2
> 1 3
> 1 3
> 1 4
> 1 4
> 1 5
> 1 5
> 2 5
> 2 5
> 2 5
> 2 6
> 2 6
> 2 6
> 3 10
> 3 10
>
> and make it look like this:
> (withing each ID I am copying the first value of Day into a new variable, FirstDay, and propagating the FirstDay value through all rows that have the same ID:
>
> ID Day FirstDay
> 1 1 1
> 1 1 1
> 1 2 1
> 1 2 1
> 1 3 1
> 1 3 1
> 1 4 1
> 1 4 1
> 1 5 1
> 1 5 1
> 2 5 5
> 2 5 5
> 2 5 5
> 2 6 5
> 2 6 5
> 2 6 5
> 3 10 3
> 3 10 3
>
> SAS code that can do this is:
>
> proc sort data=olddata;
>  by ID Day;
> run;
>
> data newdata;
>  retain FirstDay;
>  set olddata;
>  by ID;
>  if first.ID then FirstDay=Day;
> run;
>
> I have NO idea how to do this is R (so I can't post test-code), but below I have R code that creates olddata:
>
> ID <- c(rep(1,10),rep(2,6),rep(3,2))
> date <- c(rep(1,2),rep(2,2),rep(3,2),rep(4,2),rep(5,2),
>          rep(5,3),rep(6,3),rep(10,2))
> date
> olddata <- data.frame(ID=ID,date=date)
> olddata
>
> Any suggestions on how to do this would be appreciated. . . I have worked on this for more than 12-hours, despite multiple we searches I have gotten nowhere. . .
>
> Thanks
> John
>
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine, University of Maryland School of Medicine;
> Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;
> PI Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;
> Senior Statistician University of Maryland Center for Vascular Research;
>
> Division of Gerontology and Paliative Care,
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> Cell phone 443-418-5382
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.r-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tebert @end|ng |rom u||@edu  Wed Nov 27 18:37:01 2024
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Wed, 27 Nov 2024 17:37:01 +0000
Subject: [R] 
 R Processing dataframe by group - equivalent to SAS by group
 processing with a first. and retain statments
In-Reply-To: <Te18drcvnOwJUpPTLCxlkYthSx6zu9jHwuP-SbAeagWR78JoqTByxwVxBRbfnvP1ztfN_LBmvup6o4TQ5alhRvgBZRtNH0tMz2f92SolUZ8=@ontargettek.com>
References: <DM6PR03MB5049284BA7D21AA086B765D3E2282@DM6PR03MB5049.namprd03.prod.outlook.com>
 <Te18drcvnOwJUpPTLCxlkYthSx6zu9jHwuP-SbAeagWR78JoqTByxwVxBRbfnvP1ztfN_LBmvup6o4TQ5alhRvgBZRtNH0tMz2f92SolUZ8=@ontargettek.com>
Message-ID: <CH3PR22MB4514E9FDD3AA51649649C78BCF282@CH3PR22MB4514.namprd22.prod.outlook.com>

Very similar to what Oliver posted:
library(dplyr)
newdata <-  olddata |>
  group_by(ID) |>
  mutate(firstdate = first(date))
newdata


1) I attached dplyr to the entire program. Oliver used dplyr::group_by() and dplyr::mutate() to do the same thing.
2) I used the base R |> pipe while Oliver used the %>% pipe from the magritter package to do the same thing.

If you want a version that is closer to how SAS would process the data, then you could use for loops after sorting the data.
Tim

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Tom Woolman
Sent: Wednesday, November 27, 2024 12:05 PM
To: Sorkin, John <jsorkin at som.umaryland.edu>
Cc: r-help at r-project.org (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] R Processing dataframe by group - equivalent to SAS by group processing with a first. and retain statments

[External Email]

Check out the dplyr package, specifically the mutate function.

# Create new column based on existing column value

df <- df %>% mutate(FirstDay = if(ID = 2, 5))

df



Repeat as needed to capture all of the day/firstday combinations you want to account for.

Like everything else in R, there are probably at least a dozen other ways to do this, between base R and all of the library packages available.




On Wednesday, November 27th, 2024 at 11:30 AM, Sorkin, John <jsorkin at som.umaryland.edu> wrote:

>
>
> I am an old, long time SAS programmer. I need to produce R code that processes a dataframe in a manner that is equivalent to that produced by using a by statement in SAS and an if first.day statement and a retain statement:
>
> I want to take data (olddata) that looks like this ID Day
> 1 1
> 1 1
> 1 2
> 1 2
> 1 3
> 1 3
> 1 4
> 1 4
> 1 5
> 1 5
> 2 5
> 2 5
> 2 5
> 2 6
> 2 6
> 2 6
> 3 10
> 3 10
>
> and make it look like this:
> (withing each ID I am copying the first value of Day into a new variable, FirstDay, and propagating the FirstDay value through all rows that have the same ID:
>
> ID Day FirstDay
> 1 1 1
> 1 1 1
> 1 2 1
> 1 2 1
> 1 3 1
> 1 3 1
> 1 4 1
> 1 4 1
> 1 5 1
> 1 5 1
> 2 5 5
> 2 5 5
> 2 5 5
> 2 6 5
> 2 6 5
> 2 6 5
> 3 10 3
> 3 10 3
>
> SAS code that can do this is:
>
> proc sort data=olddata;
> by ID Day;
> run;
>
> data newdata;
> retain FirstDay;
> set olddata;
> by ID;
> if first.ID then FirstDay=Day;
> run;
>
> I have NO idea how to do this is R (so I can't post test-code), but below I have R code that creates olddata:
>
> ID <- c(rep(1,10),rep(2,6),rep(3,2))
> date <- c(rep(1,2),rep(2,2),rep(3,2),rep(4,2),rep(5,2),
> rep(5,3),rep(6,3),rep(10,2))
> date
> olddata <- data.frame(ID=ID,date=date) olddata
>
> Any suggestions on how to do this would be appreciated. . . I have worked on this for more than 12-hours, despite multiple we searches I have gotten nowhere. . .
>
> Thanks
> John
>
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine, University of Maryland School of Medicine;
> Associate Director for Biostatistics and Informatics, Baltimore VA
> Medical Center Geriatrics Research, Education, and Clinical Center; PI
> Biostatistics and Informatics Core, University of Maryland School of
> Medicine Claude D. Pepper Older Americans Independence Center; Senior
> Statistician University of Maryland Center for Vascular Research;
>
> Division of Gerontology and Paliative Care,
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> Cell phone 443-418-5382
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat/
> .ethz.ch%2Fmailman%2Flistinfo%2Fr-help&data=05%7C02%7Ctebert%40ufl.edu
> %7Cd2ffd4065fbb410d5c0008dd0f05b081%7C0d4da0f84a314d76ace60a62331e1b84
> %7C0%7C0%7C638683239328228378%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGki
> OnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ
> %3D%3D%7C0%7C%7C%7C&sdata=MvED5XRiFxLMfQsagl1K8IoadbM7lxMPLWm9ord6Oac%
> 3D&reserved=0 PLEASE do read the posting guide
> https://www/.
> r-project.org%2Fposting-guide.html&data=05%7C02%7Ctebert%40ufl.edu%7Cd
> 2ffd4065fbb410d5c0008dd0f05b081%7C0d4da0f84a314d76ace60a62331e1b84%7C0
> %7C0%7C638683239328245109%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRy
> dWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%
> 3D%7C0%7C%7C%7C&sdata=LTYa1YLUtR%2Bm26jjfvejSZq8WDfEsOlMKMdHxBsh9cg%3D
> &reserved=0 and provide commented, minimal, self-contained,
> reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide https://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Nov 27 18:39:08 2024
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 27 Nov 2024 09:39:08 -0800
Subject: [R] 
 R Processing dataframe by group - equivalent to SAS by group
 processing with a first. and retain statments
In-Reply-To: <DM6PR03MB5049284BA7D21AA086B765D3E2282@DM6PR03MB5049.namprd03.prod.outlook.com>
References: <DM6PR03MB5049284BA7D21AA086B765D3E2282@DM6PR03MB5049.namprd03.prod.outlook.com>
Message-ID: <2f498957-0048-0cdd-5640-91997221589b@comcast.net>


On 11/27/24 08:30, Sorkin, John wrote:
> I am an old, long time SAS programmer. I need to produce R code that processes a dataframe in a manner that is equivalent to that produced by using a by statement in SAS and an if first.day statement and a retain statement:
>
> I want to take data (olddata) that looks like this
> ID	Day
> 1	1
> 1	1
> 1	2
> 1	2
> 1	3
> 1	3
> 1	4
> 1	4
> 1	5
> 1	5
> 2	5
> 2	5
> 2	5
> 2	6
> 2	6
> 2	6
> 3	10
> 3	10
>
> and make it look like this:
> (withing each ID I am copying the first value of Day into a new variable, FirstDay, and propagating the FirstDay value through all rows that have the same ID:
>
> ID	Day	FirstDay
> 1	1	1
> 1	1	1
> 1	2	1
> 1	2	1
> 1	3	1
> 1	3	1
> 1	4	1
> 1	4	1
> 1	5	1
> 1	5	1
> 2	5	5
> 2	5	5
> 2	5	5
> 2	6	5
> 2	6	5
> 2	6	5
> 3	10	3
> 3	10	3
>
> SAS code that can do this is:
>
> proc sort data=olddata;
>    by ID Day;
> run;
>
> data newdata;
>    retain FirstDay;
>    set olddata;
>    by ID;
>    if first.ID then FirstDay=Day;
> run;
>
> I have NO idea how to do this is R (so I can't post test-code), but below I have R code that creates olddata:
>
> ID <- c(rep(1,10),rep(2,6),rep(3,2))
> date <- c(rep(1,2),rep(2,2),rep(3,2),rep(4,2),rep(5,2),
>            rep(5,3),rep(6,3),rep(10,2))
> date
> olddata <- data.frame(ID=ID,date=date)
> olddata
>
> Any suggestions on how to do this would be appreciated. . . I have worked on this for more than 12-hours, despite multiple we searches I have gotten nowhere. . .

There's an R base function named, wait for it, ... `by`

It returns a list? that is the results of a function applied to the 
sub-dataframes indexed by whatever grouping variable you specify in the 
second argument. My memory told me that it needed to be presented as a 
list which was why I chose to use the `[` function rather than `$` or `[[`

by(olddata, olddata["ID"], FUN= function(x) { rep( x$ID[1], 
times=nrow(x) )}) #------------------- ID: 1 [1] 1 1 1 1 1 1 1 1 1 1 
------------------------------------------------------------------------------------ 
ID: 2 [1] 2 2 2 2 2 2 
------------------------------------------------------------------------------------ 
ID: 3 [1] 3 3 So all you need to do from there is unlist it and assign 
to the new named column #------------------ olddata$FirstDay <- unlist( 
by(olddata, olddata["ID"], FUN= function(x) { rep( x$ID[1], 
times=nrow(x) )}) ) olddata #---------------------------- ID date 
FirstDay 1 1 1 1 2 1 1 1 3 1 2 1 4 1 2 1 5 1 3 1 6 1 3 1 7 1 4 1 8 1 4 1 
9 1 5 1 10 1 5 1 11 2 5 2 12 2 5 2 13 2 5 2 14 2 6 2 15 2 6 2 16 2 6 2 
17 3 10 3 18 3 10 3

HTH

David.

>   
>
> Thanks
> John
>
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine, University of Maryland School of Medicine;
> Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;
> PI?Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;
> Senior Statistician University of Maryland Center for Vascular Research;
>
> Division of Gerontology and Paliative Care,
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> Cell phone 443-418-5382
>
>
>
> ______________________________________________
> R-help at r-project.org  mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guidehttps://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Nov 27 18:44:45 2024
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 27 Nov 2024 09:44:45 -0800
Subject: [R] 
 R Processing dataframe by group - equivalent to SAS by group
 processing with a first. and retain statments
In-Reply-To: <DM6PR03MB5049284BA7D21AA086B765D3E2282@DM6PR03MB5049.namprd03.prod.outlook.com>
References: <DM6PR03MB5049284BA7D21AA086B765D3E2282@DM6PR03MB5049.namprd03.prod.outlook.com>
Message-ID: <271cb898-9e26-f0d3-a90d-077579546f9a@comcast.net>


On 11/27/24 08:30, Sorkin, John wrote:
> I am an old, long time SAS programmer. I need to produce R code that processes a dataframe in a manner that is equivalent to that produced by using a by statement in SAS and an if first.day statement and a retain statement:
>
> I want to take data (olddata) that looks like this
> ID	Day
> 1	1
> 1	1
> 1	2
> 1	2
> 1	3
> 1	3
> 1	4
> 1	4
> 1	5
> 1	5
> 2	5
> 2	5
> 2	5
> 2	6
> 2	6
> 2	6
> 3	10
> 3	10
>
> and make it look like this:
> (withing each ID I am copying the first value of Day into a new variable, FirstDay, and propagating the FirstDay value through all rows that have the same ID:
>
> ID	Day	FirstDay
> 1	1	1
> 1	1	1
> 1	2	1
> 1	2	1
> 1	3	1
> 1	3	1
> 1	4	1
> 1	4	1
> 1	5	1
> 1	5	1
> 2	5	5
> 2	5	5
> 2	5	5
> 2	6	5
> 2	6	5
> 2	6	5
> 3	10	3
> 3	10	3
>
> SAS code that can do this is:
>
> proc sort data=olddata;
>    by ID Day;
> run;
>
> data newdata;
>    retain FirstDay;
>    set olddata;
>    by ID;
>    if first.ID then FirstDay=Day;
> run;
>
> I have NO idea how to do this is R (so I can't post test-code), but below I have R code that creates olddata:
>
> ID <- c(rep(1,10),rep(2,6),rep(3,2))
> date <- c(rep(1,2),rep(2,2),rep(3,2),rep(4,2),rep(5,2),
>            rep(5,3),rep(6,3),rep(10,2))
> date
> olddata <- data.frame(ID=ID,date=date)
> olddata
>
> Any suggestions on how to do this would be appreciated. . . I have worked on this for more than 12-hours, despite multiple we searches I have gotten nowhere. . .


My earlier approach incorrectly picked the firs of the ID column rather 
than the first of the `date` column to be repeated withing the indexed 
group so here's the correct code:


> olddata$FirstDay <- unlist( by(olddata, olddata["ID"], FUN= function(x) 
{ rep( x$date[1], times=nrow(x) )}) ) > olddata ID date FirstDay 1 1 1 1 
2 1 1 1 3 1 2 1 4 1 2 1 5 1 3 1 6 1 3 1 7 1 4 1 8 1 4 1 9 1 5 1 10 1 5 1 
11 2 5 5 12 2 5 5 13 2 5 5 14 2 6 5 15 2 6 5 16 2 6 5 17 3 10 10 18 3 10 10

>
> Thanks
> John
>
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine, University of Maryland School of Medicine;
> Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;
> PI?Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;
> Senior Statistician University of Maryland Center for Vascular Research;
>
> Division of Gerontology and Paliative Care,
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> Cell phone 443-418-5382
>
>
>
> ______________________________________________
> R-help at r-project.org  mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guidehttps://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Nov 27 19:08:12 2024
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 27 Nov 2024 10:08:12 -0800
Subject: [R] 
 R Processing dataframe by group - equivalent to SAS by group
 processing with a first. and retain statments
In-Reply-To: <271cb898-9e26-f0d3-a90d-077579546f9a@comcast.net>
References: <DM6PR03MB5049284BA7D21AA086B765D3E2282@DM6PR03MB5049.namprd03.prod.outlook.com>
 <271cb898-9e26-f0d3-a90d-077579546f9a@comcast.net>
Message-ID: <d636a330-1548-cc1e-c0a1-20a3e52754c5@comcast.net>


On 11/27/24 09:44, David Winsemius via R-help wrote:
> On 11/27/24 08:30, Sorkin, John wrote:
>> I am an old, long time SAS programmer. I need to produce R code that processes a dataframe in a manner that is equivalent to that produced by using a by statement in SAS and an if first.day statement and a retain statement:
>>
>> I want to take data (olddata) that looks like this
>> ID	Day
>> 1	1
>> 1	1
>> 1	2
>> 1	2
>> 1	3
>> 1	3
>> 1	4
>> 1	4
>> 1	5
>> 1	5
>> 2	5
>> 2	5
>> 2	5
>> 2	6
>> 2	6
>> 2	6
>> 3	10
>> 3	10
>>
>> and make it look like this:
>> (withing each ID I am copying the first value of Day into a new variable, FirstDay, and propagating the FirstDay value through all rows that have the same ID:
>>
>> ID	Day	FirstDay
>> 1	1	1
>> 1	1	1
>> 1	2	1
>> 1	2	1
>> 1	3	1
>> 1	3	1
>> 1	4	1
>> 1	4	1
>> 1	5	1
>> 1	5	1
>> 2	5	5
>> 2	5	5
>> 2	5	5
>> 2	6	5
>> 2	6	5
>> 2	6	5
>> 3	10	3
>> 3	10	3
>>
>> SAS code that can do this is:
>>
>> proc sort data=olddata;
>>     by ID Day;
>> run;
>>
>> data newdata;
>>     retain FirstDay;
>>     set olddata;
>>     by ID;
>>     if first.ID then FirstDay=Day;
>> run;
>>
>> I have NO idea how to do this is R (so I can't post test-code), but below I have R code that creates olddata:
>>
>> ID <- c(rep(1,10),rep(2,6),rep(3,2))
>> date <- c(rep(1,2),rep(2,2),rep(3,2),rep(4,2),rep(5,2),
>>             rep(5,3),rep(6,3),rep(10,2))
>> date
>> olddata <- data.frame(ID=ID,date=date)
>> olddata
>>
>> Any suggestions on how to do this would be appreciated. . . I have worked on this for more than 12-hours, despite multiple we searches I have gotten nowhere. . .
>
> My earlier approach incorrectly picked the firs of the ID column rather
> than the first of the `date` column to be repeated withing the indexed
> group so here's the correct code:

That's embarrassing. Sorry for the HTML. I thought that Thunderbird was 
smart enough to reply in kind.. This should be formatted correctly

> olddata$FirstDay <- unlist( by(olddata, olddata["ID"], FUN= function(x) 
{ rep( x$date[1], times=nrow(x) )}) ) > olddata ID date FirstDay 1 1 1 1 
2 1 1 1 3 1 2 1 4 1 2 1 5 1 3 1 6 1 3 1 7 1 4 1 8 1 4 1 9 1 5 1 10 1 5 1 
11 2 5 5 12 2 5 5 13 2 5 5 14 2 6 5 15 2 6 5 16 2 6 5 17 3 10 10 18 3 10 10


>
>> olddata$FirstDay <- unlist( by(olddata, olddata["ID"], FUN= function(x)
> { rep( x$date[1], times=nrow(x) )}) ) > olddata ID date FirstDay 1 1 1 1
> 2 1 1 1 3 1 2 1 4 1 2 1 5 1 3 1 6 1 3 1 7 1 4 1 8 1 4 1 9 1 5 1 10 1 5 1
> 11 2 5 5 12 2 5 5 13 2 5 5 14 2 6 5 15 2 6 5 16 2 6 5 17 3 10 10 18 3 10 10
>
>> Thanks
>> John
>>
>>
>>
>>
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine, University of Maryland School of Medicine;
>> Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;
>> PI?Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;
>> Senior Statistician University of Maryland Center for Vascular Research;
>>
>> Division of Gerontology and Paliative Care,
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> Cell phone 443-418-5382
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org  mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guidehttps://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tebert @end|ng |rom u||@edu  Wed Nov 27 19:16:42 2024
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Wed, 27 Nov 2024 18:16:42 +0000
Subject: [R] 
 R Processing dataframe by group - equivalent to SAS by group
 processing with a first. and retain statments
In-Reply-To: <Te18drcvnOwJUpPTLCxlkYthSx6zu9jHwuP-SbAeagWR78JoqTByxwVxBRbfnvP1ztfN_LBmvup6o4TQ5alhRvgBZRtNH0tMz2f92SolUZ8=@ontargettek.com>
References: <DM6PR03MB5049284BA7D21AA086B765D3E2282@DM6PR03MB5049.namprd03.prod.outlook.com>
 <Te18drcvnOwJUpPTLCxlkYthSx6zu9jHwuP-SbAeagWR78JoqTByxwVxBRbfnvP1ztfN_LBmvup6o4TQ5alhRvgBZRtNH0tMz2f92SolUZ8=@ontargettek.com>
Message-ID: <CH3PR22MB45143EF6FF0C024EAF230436CF282@CH3PR22MB4514.namprd22.prod.outlook.com>

Here is another version using for loops.

newdata3 <- olddata |>
  dplyr::arrange(ID, date)
newdata3$firstday <- NA
for (i in 1:nrow(newdata3)) {
  if (i == 1) {
    dayz <- newdata3$date[i]
  } else {
    if (newdata3$ID[i] != newdata3$ID[i - 1]) {
      dayz <- newdata3$date[i]
    }
  }
  newdata3$firstday[i] <- dayz
}

newdata3

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Tom Woolman
Sent: Wednesday, November 27, 2024 12:05 PM
To: Sorkin, John <jsorkin at som.umaryland.edu>
Cc: r-help at r-project.org (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] R Processing dataframe by group - equivalent to SAS by group processing with a first. and retain statments

[External Email]

Check out the dplyr package, specifically the mutate function.

# Create new column based on existing column value

df <- df %>% mutate(FirstDay = if(ID = 2, 5))

df



Repeat as needed to capture all of the day/firstday combinations you want to account for.

Like everything else in R, there are probably at least a dozen other ways to do this, between base R and all of the library packages available.




On Wednesday, November 27th, 2024 at 11:30 AM, Sorkin, John <jsorkin at som.umaryland.edu> wrote:

>
>
> I am an old, long time SAS programmer. I need to produce R code that processes a dataframe in a manner that is equivalent to that produced by using a by statement in SAS and an if first.day statement and a retain statement:
>
> I want to take data (olddata) that looks like this ID Day
> 1 1
> 1 1
> 1 2
> 1 2
> 1 3
> 1 3
> 1 4
> 1 4
> 1 5
> 1 5
> 2 5
> 2 5
> 2 5
> 2 6
> 2 6
> 2 6
> 3 10
> 3 10
>
> and make it look like this:
> (withing each ID I am copying the first value of Day into a new variable, FirstDay, and propagating the FirstDay value through all rows that have the same ID:
>
> ID Day FirstDay
> 1 1 1
> 1 1 1
> 1 2 1
> 1 2 1
> 1 3 1
> 1 3 1
> 1 4 1
> 1 4 1
> 1 5 1
> 1 5 1
> 2 5 5
> 2 5 5
> 2 5 5
> 2 6 5
> 2 6 5
> 2 6 5
> 3 10 3
> 3 10 3
>
> SAS code that can do this is:
>
> proc sort data=olddata;
> by ID Day;
> run;
>
> data newdata;
> retain FirstDay;
> set olddata;
> by ID;
> if first.ID then FirstDay=Day;
> run;
>
> I have NO idea how to do this is R (so I can't post test-code), but below I have R code that creates olddata:
>
> ID <- c(rep(1,10),rep(2,6),rep(3,2))
> date <- c(rep(1,2),rep(2,2),rep(3,2),rep(4,2),rep(5,2),
> rep(5,3),rep(6,3),rep(10,2))
> date
> olddata <- data.frame(ID=ID,date=date) olddata
>
> Any suggestions on how to do this would be appreciated. . . I have worked on this for more than 12-hours, despite multiple we searches I have gotten nowhere. . .
>
> Thanks
> John
>
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine, University of Maryland School of Medicine;
> Associate Director for Biostatistics and Informatics, Baltimore VA
> Medical Center Geriatrics Research, Education, and Clinical Center; PI
> Biostatistics and Informatics Core, University of Maryland School of
> Medicine Claude D. Pepper Older Americans Independence Center; Senior
> Statistician University of Maryland Center for Vascular Research;
>
> Division of Gerontology and Paliative Care,
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> Cell phone 443-418-5382
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat/
> .ethz.ch%2Fmailman%2Flistinfo%2Fr-help&data=05%7C02%7Ctebert%40ufl.edu
> %7Cd2ffd4065fbb410d5c0008dd0f05b081%7C0d4da0f84a314d76ace60a62331e1b84
> %7C0%7C0%7C638683239328228378%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGki
> OnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ
> %3D%3D%7C0%7C%7C%7C&sdata=MvED5XRiFxLMfQsagl1K8IoadbM7lxMPLWm9ord6Oac%
> 3D&reserved=0 PLEASE do read the posting guide
> https://www/.
> r-project.org%2Fposting-guide.html&data=05%7C02%7Ctebert%40ufl.edu%7Cd
> 2ffd4065fbb410d5c0008dd0f05b081%7C0d4da0f84a314d76ace60a62331e1b84%7C0
> %7C0%7C638683239328245109%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRy
> dWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%
> 3D%7C0%7C%7C%7C&sdata=LTYa1YLUtR%2Bm26jjfvejSZq8WDfEsOlMKMdHxBsh9cg%3D
> &reserved=0 and provide commented, minimal, self-contained,
> reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide https://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From @vi@e@gross m@iii@g oii gm@ii@com  Wed Nov 27 19:27:28 2024
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Wed, 27 Nov 2024 13:27:28 -0500
Subject: [R] 
 R Processing dataframe by group - equivalent to SAS by group
 processing with a first. and retain statments
In-Reply-To: <DM6PR03MB5049284BA7D21AA086B765D3E2282@DM6PR03MB5049.namprd03.prod.outlook.com>
References: <DM6PR03MB5049284BA7D21AA086B765D3E2282@DM6PR03MB5049.namprd03.prod.outlook.com>
Message-ID: <005601db40fa$03c78290$0b5687b0$@gmail.com>

John,

If I understood you, you want to take the minimum value of Day  for each
grouping by ID and add a new column to contain that. Right?

There are likely many ways to do this in base R, but I prefer the
dplyr/tidyverse package in which you can use group_by(ID) piped to
mutate(FirstDay = min(Day))



-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Sorkin, John
Sent: Wednesday, November 27, 2024 11:31 AM
To: r-help at r-project.org (r-help at r-project.org) <r-help at r-project.org>
Subject: [R] R Processing dataframe by group - equivalent to SAS by group
processing with a first. and retain statments

I am an old, long time SAS programmer. I need to produce R code that
processes a dataframe in a manner that is equivalent to that produced by
using a by statement in SAS and an if first.day statement and a retain
statement:

I want to take data (olddata) that looks like this
ID	Day
1	1
1	1
1	2
1	2
1	3
1	3
1	4
1	4
1	5
1	5
2	5
2	5
2	5
2	6
2	6
2	6
3	10
3	10

and make it look like this:
(withing each ID I am copying the first value of Day into a new variable,
FirstDay, and propagating the FirstDay value through all rows that have the
same ID:

ID	Day	FirstDay
1	1	1
1	1	1
1	2	1
1	2	1
1	3	1
1	3	1
1	4	1
1	4	1
1	5	1
1	5	1
2	5	5
2	5	5
2	5	5
2	6	5
2	6	5
2	6	5
3	10	3
3	10	3

SAS code that can do this is:

proc sort data=olddata;
  by ID Day;
run;

data newdata;
  retain FirstDay;
  set olddata;
  by ID;
  if first.ID then FirstDay=Day;
run;

I have NO idea how to do this is R (so I can't post test-code), but below I
have R code that creates olddata:

ID <- c(rep(1,10),rep(2,6),rep(3,2))
date <- c(rep(1,2),rep(2,2),rep(3,2),rep(4,2),rep(5,2),
          rep(5,3),rep(6,3),rep(10,2))
date
olddata <- data.frame(ID=ID,date=date)
olddata

Any suggestions on how to do this would be appreciated. . . I have worked on
this for more than 12-hours, despite multiple we searches I have gotten
nowhere. . . 

Thanks
John




John David Sorkin M.D., Ph.D.
Professor of Medicine, University of Maryland School of Medicine;
Associate Director for Biostatistics and Informatics, Baltimore VA Medical
Center Geriatrics Research, Education, and Clinical Center;?
PI?Biostatistics and Informatics Core, University of Maryland School of
Medicine Claude D. Pepper Older Americans Independence Center;
Senior Statistician University of Maryland Center for Vascular Research;

Division of Gerontology and Paliative Care,
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
Cell phone 443-418-5382



______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
https://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Nov 27 20:13:49 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 27 Nov 2024 19:13:49 +0000
Subject: [R] 
 R Processing dataframe by group - equivalent to SAS by group
 processing with a first. and retain statments
In-Reply-To: <DM6PR03MB5049284BA7D21AA086B765D3E2282@DM6PR03MB5049.namprd03.prod.outlook.com>
References: <DM6PR03MB5049284BA7D21AA086B765D3E2282@DM6PR03MB5049.namprd03.prod.outlook.com>
Message-ID: <609bab5a-d8db-4648-8f20-7bb8c10d2979@sapo.pt>

?s 16:30 de 27/11/2024, Sorkin, John escreveu:
> I am an old, long time SAS programmer. I need to produce R code that processes a dataframe in a manner that is equivalent to that produced by using a by statement in SAS and an if first.day statement and a retain statement:
> 
> I want to take data (olddata) that looks like this
> ID	Day
> 1	1
> 1	1
> 1	2
> 1	2
> 1	3
> 1	3
> 1	4
> 1	4
> 1	5
> 1	5
> 2	5
> 2	5
> 2	5
> 2	6
> 2	6
> 2	6
> 3	10
> 3	10
> 
> and make it look like this:
> (withing each ID I am copying the first value of Day into a new variable, FirstDay, and propagating the FirstDay value through all rows that have the same ID:
> 
> ID	Day	FirstDay
> 1	1	1
> 1	1	1
> 1	2	1
> 1	2	1
> 1	3	1
> 1	3	1
> 1	4	1
> 1	4	1
> 1	5	1
> 1	5	1
> 2	5	5
> 2	5	5
> 2	5	5
> 2	6	5
> 2	6	5
> 2	6	5
> 3	10	3
> 3	10	3
> 
> SAS code that can do this is:
> 
> proc sort data=olddata;
>    by ID Day;
> run;
> 
> data newdata;
>    retain FirstDay;
>    set olddata;
>    by ID;
>    if first.ID then FirstDay=Day;
> run;
> 
> I have NO idea how to do this is R (so I can't post test-code), but below I have R code that creates olddata:
> 
> ID <- c(rep(1,10),rep(2,6),rep(3,2))
> date <- c(rep(1,2),rep(2,2),rep(3,2),rep(4,2),rep(5,2),
>            rep(5,3),rep(6,3),rep(10,2))
> date
> olddata <- data.frame(ID=ID,date=date)
> olddata
> 
> Any suggestions on how to do this would be appreciated. . . I have worked on this for more than 12-hours, despite multiple we searches I have gotten nowhere. . .
> 
> Thanks
> John
> 
> 
> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine, University of Maryland School of Medicine;
> Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;
> PI?Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;
> Senior Statistician University of Maryland Center for Vascular Research;
> 
> Division of Gerontology and Paliative Care,
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> Cell phone 443-418-5382
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

Isn't ?ave the simplest way?
The first one-liner assumes the dates are sorted in ascending order.


ave(olddata$date, olddata$ID, FUN = \(x) x[1L])
#>  [1]  1  1  1  1  1  1  1  1  1  1  5  5  5  5  5  5 10 10


If the dates are not sorted,


ave(olddata$date, olddata$ID, FUN = \(x) min(x))



Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Nov 27 20:38:21 2024
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 27 Nov 2024 11:38:21 -0800
Subject: [R] 
 R Processing dataframe by group - equivalent to SAS by group
 processing with a first. and retain statments
In-Reply-To: <609bab5a-d8db-4648-8f20-7bb8c10d2979@sapo.pt>
References: <DM6PR03MB5049284BA7D21AA086B765D3E2282@DM6PR03MB5049.namprd03.prod.outlook.com>
 <609bab5a-d8db-4648-8f20-7bb8c10d2979@sapo.pt>
Message-ID: <82DB7A28-B9B9-4229-B949-B5EDD3DBD7A9@dcn.davis.ca.us>

Was wondering when this would be suggested. But the question was about getting the final dataframe...


newdta <- olddta
newdta$FirstDay <- ave(newdata$date, newdata$ID, FUN = \(x) x[1L])

On November 27, 2024 11:13:49 AM PST, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>?s 16:30 de 27/11/2024, Sorkin, John escreveu:
>> I am an old, long time SAS programmer. I need to produce R code that processes a dataframe in a manner that is equivalent to that produced by using a by statement in SAS and an if first.day statement and a retain statement:
>> 
>> I want to take data (olddata) that looks like this
>> ID	Day
>> 1	1
>> 1	1
>> 1	2
>> 1	2
>> 1	3
>> 1	3
>> 1	4
>> 1	4
>> 1	5
>> 1	5
>> 2	5
>> 2	5
>> 2	5
>> 2	6
>> 2	6
>> 2	6
>> 3	10
>> 3	10
>> 
>> and make it look like this:
>> (withing each ID I am copying the first value of Day into a new variable, FirstDay, and propagating the FirstDay value through all rows that have the same ID:
>> 
>> ID	Day	FirstDay
>> 1	1	1
>> 1	1	1
>> 1	2	1
>> 1	2	1
>> 1	3	1
>> 1	3	1
>> 1	4	1
>> 1	4	1
>> 1	5	1
>> 1	5	1
>> 2	5	5
>> 2	5	5
>> 2	5	5
>> 2	6	5
>> 2	6	5
>> 2	6	5
>> 3	10	3
>> 3	10	3
>> 
>> SAS code that can do this is:
>> 
>> proc sort data=olddata;
>>    by ID Day;
>> run;
>> 
>> data newdata;
>>    retain FirstDay;
>>    set olddata;
>>    by ID;
>>    if first.ID then FirstDay=Day;
>> run;
>> 
>> I have NO idea how to do this is R (so I can't post test-code), but below I have R code that creates olddata:
>> 
>> ID <- c(rep(1,10),rep(2,6),rep(3,2))
>> date <- c(rep(1,2),rep(2,2),rep(3,2),rep(4,2),rep(5,2),
>>            rep(5,3),rep(6,3),rep(10,2))
>> date
>> olddata <- data.frame(ID=ID,date=date)
>> olddata
>> 
>> Any suggestions on how to do this would be appreciated. . . I have worked on this for more than 12-hours, despite multiple we searches I have gotten nowhere. . .
>> 
>> Thanks
>> John
>> 
>> 
>> 
>> 
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine, University of Maryland School of Medicine;
>> Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;
>> PI?Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;
>> Senior Statistician University of Maryland Center for Vascular Research;
>> 
>> Division of Gerontology and Paliative Care,
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> Cell phone 443-418-5382
>> 
>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>Hello,
>
>Isn't ?ave the simplest way?
>The first one-liner assumes the dates are sorted in ascending order.
>
>
>ave(olddata$date, olddata$ID, FUN = \(x) x[1L])
>#>  [1]  1  1  1  1  1  1  1  1  1  1  5  5  5  5  5  5 10 10
>
>
>If the dates are not sorted,
>
>
>ave(olddata$date, olddata$ID, FUN = \(x) min(x))
>
>
>
>Hope this helps,
>
>Rui Barradas
>
>

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Wed Nov 27 22:38:36 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 27 Nov 2024 13:38:36 -0800
Subject: [R] 
 R Processing dataframe by group - equivalent to SAS by group
 processing with a first. and retain statments
In-Reply-To: <82DB7A28-B9B9-4229-B949-B5EDD3DBD7A9@dcn.davis.ca.us>
References: <DM6PR03MB5049284BA7D21AA086B765D3E2282@DM6PR03MB5049.namprd03.prod.outlook.com>
 <609bab5a-d8db-4648-8f20-7bb8c10d2979@sapo.pt>
 <82DB7A28-B9B9-4229-B949-B5EDD3DBD7A9@dcn.davis.ca.us>
Message-ID: <CAGxFJbRX0CPhzLiO0jT6cPzuaoaDvOHJ2g6Vg3mv6HBsSfL4Xg@mail.gmail.com>

The grouping solutions offered seem to be the obvious way to do this and
may even be more efficient in R then what follows below.  However, note
that they are to some extent doing unnecessary work, since the ordering in
the data frame already implicitly provides the grouping, and the hashing or
whatever is under the hood of the grouping functions to determine this is
therefore unnecessary.

So I was wondering how easy it would be to use purely elementary means to
take advantage of this and avoid the "unnecessary" work.  A more or less
obvious approach that occurred to me was to use R's rle() function. I'll
first give a prolix, step-by-step explanation for those who may not have
used rle(). Then I'll give a concise version of code.

Assume "dat" is the example data frame of two columns that John gave.
Then:
rle(dat[,1])  ##gives a list with two components:
Run Length Encoding
  lengths: int [1:3] 10 6 2
  values : int [1:3] 1 2 3

This gives us the grouping for the ID column: 10 1's, followed by 6 2's,
followed by 2 3's.
Clearly, the row indices for the first row in each group are 1, 11, and 17.
we can get this from the "lengths" component of rle() by:

lens <- rle(dat[,1)]$lengths
## Then
cumsum(c(1, lens[-length(lens)]))
1]  1 11 17
## Therefore, the first days are
dat[cumsum(c(1, lens[-length(lens)])), 2]
[1]  1  5 10
##  So just rep() this with lens to give the FirstDay column:
rep(dat[cumsum(c(1, lens[-length(lens)])), 2], lens)
[1]  1  1  1  1  1  1  1  1  1  1  5  5  5  5  5  5 10 10

Here's a concise version of the code:

lens <- rle(dat$ID)$lengths
dat <- within(dat,
   FirstDay <- Day[cumsum(c(1, lens[-length(lens)]))] |> rep(lens)
)

Again, I realize that this sacrifices the clarity of the other solutions
that have been given, so I certainly do not claim that it is "better".
Nevertheless, I hope it shows another approach that might be interesting
and occasionally even useful.

Cheers,
Bert


On Wed, Nov 27, 2024 at 11:38?AM Jeff Newmiller via R-help <
r-help at r-project.org> wrote:

> Was wondering when this would be suggested. But the question was about
> getting the final dataframe...
>
>
> newdta <- olddta
> newdta$FirstDay <- ave(newdata$date, newdata$ID, FUN = \(x) x[1L])
>
> On November 27, 2024 11:13:49 AM PST, Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
> >?s 16:30 de 27/11/2024, Sorkin, John escreveu:
> >> I am an old, long time SAS programmer. I need to produce R code that
> processes a dataframe in a manner that is equivalent to that produced by
> using a by statement in SAS and an if first.day statement and a retain
> statement:
> >>
> >> I want to take data (olddata) that looks like this
> >> ID   Day
> >> 1    1
> >> 1    1
> >> 1    2
> >> 1    2
> >> 1    3
> >> 1    3
> >> 1    4
> >> 1    4
> >> 1    5
> >> 1    5
> >> 2    5
> >> 2    5
> >> 2    5
> >> 2    6
> >> 2    6
> >> 2    6
> >> 3    10
> >> 3    10
> >>
> >> and make it look like this:
> >> (withing each ID I am copying the first value of Day into a new
> variable, FirstDay, and propagating the FirstDay value through all rows
> that have the same ID:
> >>
> >> ID   Day     FirstDay
> >> 1    1       1
> >> 1    1       1
> >> 1    2       1
> >> 1    2       1
> >> 1    3       1
> >> 1    3       1
> >> 1    4       1
> >> 1    4       1
> >> 1    5       1
> >> 1    5       1
> >> 2    5       5
> >> 2    5       5
> >> 2    5       5
> >> 2    6       5
> >> 2    6       5
> >> 2    6       5
> >> 3    10      3
> >> 3    10      3
> >>
> >> SAS code that can do this is:
> >>
> >> proc sort data=olddata;
> >>    by ID Day;
> >> run;
> >>
> >> data newdata;
> >>    retain FirstDay;
> >>    set olddata;
> >>    by ID;
> >>    if first.ID then FirstDay=Day;
> >> run;
> >>
> >> I have NO idea how to do this is R (so I can't post test-code), but
> below I have R code that creates olddata:
> >>
> >> ID <- c(rep(1,10),rep(2,6),rep(3,2))
> >> date <- c(rep(1,2),rep(2,2),rep(3,2),rep(4,2),rep(5,2),
> >>            rep(5,3),rep(6,3),rep(10,2))
> >> date
> >> olddata <- data.frame(ID=ID,date=date)
> >> olddata
> >>
> >> Any suggestions on how to do this would be appreciated. . . I have
> worked on this for more than 12-hours, despite multiple we searches I have
> gotten nowhere. . .
> >>
> >> Thanks
> >> John
> >>
> >>
> >>
> >>
> >> John David Sorkin M.D., Ph.D.
> >> Professor of Medicine, University of Maryland School of Medicine;
> >> Associate Director for Biostatistics and Informatics, Baltimore VA
> Medical Center Geriatrics Research, Education, and Clinical Center;
> >> PI Biostatistics and Informatics Core, University of Maryland School of
> Medicine Claude D. Pepper Older Americans Independence Center;
> >> Senior Statistician University of Maryland Center for Vascular Research;
> >>
> >> Division of Gerontology and Paliative Care,
> >> 10 North Greene Street
> >> GRECC (BT/18/GR)
> >> Baltimore, MD 21201-1524
> >> Cell phone 443-418-5382
> >>
> >>
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >Hello,
> >
> >Isn't ?ave the simplest way?
> >The first one-liner assumes the dates are sorted in ascending order.
> >
> >
> >ave(olddata$date, olddata$ID, FUN = \(x) x[1L])
> >#>  [1]  1  1  1  1  1  1  1  1  1  1  5  5  5  5  5  5 10 10
> >
> >
> >If the dates are not sorted,
> >
> >
> >ave(olddata$date, olddata$ID, FUN = \(x) min(x))
> >
> >
> >
> >Hope this helps,
> >
> >Rui Barradas
> >
> >
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From n@re@h_gurbux@n| @end|ng |rom hotm@||@com  Thu Nov 28 04:35:03 2024
From: n@re@h_gurbux@n| @end|ng |rom hotm@||@com (Naresh Gurbuxani)
Date: Thu, 28 Nov 2024 03:35:03 +0000
Subject: [R] 
 R Processing dataframe by group - equivalent to SAS by group
 processing with a first. and retain statments
In-Reply-To: <DM6PR03MB5049284BA7D21AA086B765D3E2282@DM6PR03MB5049.namprd03.prod.outlook.com>
References: <DM6PR03MB5049284BA7D21AA086B765D3E2282@DM6PR03MB5049.namprd03.prod.outlook.com>
Message-ID: <5772E2E4-5455-415C-BD82-4A184A72F807@hotmail.com>

In addition to many good solutions already provided, this solution uses data.table package.

library(data.table)
mydf <- data.frame(id = c(rep(1,10),rep(2,6),rep(3,2)), date = c(rep(1,2),rep(2,2),rep(3,2),rep(4,2),rep(5,2), rep(5,3),rep(6,3),rep(10,2)))
setDT(mydf)
mydf[, `:=`(firstdate = with(.SD, min(date))), by = .(id)]
setDF(mydf)

On Nov 27, 2024, at 11:30?AM, Sorkin, John <jsorkin at som.umaryland.edu> wrote:

c(rep(1,2),rep(2,2),rep(3,2),rep(4,2),rep(5,2),
         rep(5,3),rep(6,3),rep(10,2))


	[[alternative HTML version deleted]]


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Thu Nov 28 14:36:21 2024
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Thu, 28 Nov 2024 13:36:21 +0000
Subject: [R] Remove all box around a plot except bottom line (base graphics)
Message-ID: <9e377afe-4603-4936-9db8-4159259e3cfd@dewey.myzen.co.uk>

To make the plot clearer I have removed the axes but I wish to remove 
all the boz except the bottom horizontal line. Using the bty parameter 
does not seem to enable me to just leave the horizontal line at the 
foot. I can get the "l" version to remove everything except the left 
hand side and the base. I could also remove the entire box but that 
looks odd. Am I reading the documentation incorrectly or is it really 
impossible?

-- 
Michael


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Nov 28 14:52:49 2024
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 28 Nov 2024 08:52:49 -0500
Subject: [R] 
 Remove all box around a plot except bottom line (base graphics)
In-Reply-To: <9e377afe-4603-4936-9db8-4159259e3cfd@dewey.myzen.co.uk>
References: <9e377afe-4603-4936-9db8-4159259e3cfd@dewey.myzen.co.uk>
Message-ID: <b336466b-f256-4cd9-99e6-bd1dadd0295e@gmail.com>

On 2024-11-28 8:36 a.m., Michael Dewey wrote:
> To make the plot clearer I have removed the axes but I wish to remove
> all the boz except the bottom horizontal line. Using the bty parameter
> does not seem to enable me to just leave the horizontal line at the
> foot. I can get the "l" version to remove everything except the left
> hand side and the base. I could also remove the entire box but that
> looks odd. Am I reading the documentation incorrectly or is it really
> impossible?
> 

It's not something that `bty` can specify or `box()` can do, but you can 
draw a line using lines() or segments().  For example:

  plot(rnorm(100), yaxt="n", bty="n")
  usr <- par("usr")
  lines(usr[c(1,2)], usr[c(3,3)], xpd = TRUE)

You might not even need the lines() call if you don't care how far the 
axis extends.

Duncan Murdoch


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Thu Nov 28 16:27:59 2024
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Thu, 28 Nov 2024 15:27:59 +0000
Subject: [R] 
 Remove all box around a plot except bottom line (base graphics)
In-Reply-To: <b336466b-f256-4cd9-99e6-bd1dadd0295e@gmail.com>
References: <9e377afe-4603-4936-9db8-4159259e3cfd@dewey.myzen.co.uk>
 <b336466b-f256-4cd9-99e6-bd1dadd0295e@gmail.com>
Message-ID: <bb8667f7-7ec9-c694-24fe-f5e228d887f7@dewey.myzen.co.uk>

Thank you Duncan, I will try that next.

Michael

On 28/11/2024 13:52, Duncan Murdoch wrote:
> On 2024-11-28 8:36 a.m., Michael Dewey wrote:
>> To make the plot clearer I have removed the axes but I wish to remove
>> all the boz except the bottom horizontal line. Using the bty parameter
>> does not seem to enable me to just leave the horizontal line at the
>> foot. I can get the "l" version to remove everything except the left
>> hand side and the base. I could also remove the entire box but that
>> looks odd. Am I reading the documentation incorrectly or is it really
>> impossible?
>>
> 
> It's not something that `bty` can specify or `box()` can do, but you can 
> draw a line using lines() or segments().? For example:
> 
>  ?plot(rnorm(100), yaxt="n", bty="n")
>  ?usr <- par("usr")
>  ?lines(usr[c(1,2)], usr[c(3,3)], xpd = TRUE)
> 
> You might not even need the lines() call if you don't care how far the 
> axis extends.
> 
> Duncan Murdoch
> 

-- 
Michael


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Nov 28 17:51:23 2024
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 28 Nov 2024 17:51:23 +0100
Subject: [R] 
 Remove all box around a plot except bottom line (base graphics)
In-Reply-To: <bb8667f7-7ec9-c694-24fe-f5e228d887f7@dewey.myzen.co.uk>
References: <9e377afe-4603-4936-9db8-4159259e3cfd@dewey.myzen.co.uk>
 <b336466b-f256-4cd9-99e6-bd1dadd0295e@gmail.com>
 <bb8667f7-7ec9-c694-24fe-f5e228d887f7@dewey.myzen.co.uk>
Message-ID: <26440.40843.977816.261079@stat.math.ethz.ch>

>>>>> Michael Dewey 
>>>>>     on Thu, 28 Nov 2024 15:27:59 +0000 writes:

    > Thank you Duncan, I will try that next.
    > Michael

    > On 28/11/2024 13:52, Duncan Murdoch wrote:
    >> On 2024-11-28 8:36 a.m., Michael Dewey wrote:
    >>> To make the plot clearer I have removed the axes but I wish to remove
    >>> all the boz except the bottom horizontal line. Using the bty parameter
    >>> does not seem to enable me to just leave the horizontal line at the
    >>> foot. I can get the "l" version to remove everything except the left
    >>> hand side and the base. I could also remove the entire box but that
    >>> looks odd. Am I reading the documentation incorrectly or is it really
    >>> impossible?
    >>> 
    >> 
    >> It's not something that `bty` can specify or `box()` can do, but you can 
    >> draw a line using lines() or segments().? For example:
    >> 
    >> ?plot(rnorm(100), yaxt="n", bty="n")
    >> ?usr <- par("usr")
    >> ?lines(usr[c(1,2)], usr[c(3,3)], xpd = TRUE)
    >> 
    >> You might not even need the lines() call if you don't care how far the 
    >> axis extends.
    >> 
    >> Duncan Murdoch

also, if like in this example, you are talking about using  plot.default()
{or something that *calls* plot.default() eventually, such as
 plot.formula() ...}

you might want to play with  frame.plot = FALSE  :

    plot(rnorm(50), frame.plot=FALSE, yaxt="n")

maybe what you want?  {a bit more efficient internally than 'bty = "n"'}

Martin


From o||v|er@crouzet @end|ng |rom un|v-n@nte@@|r  Thu Nov 28 19:43:19 2024
From: o||v|er@crouzet @end|ng |rom un|v-n@nte@@|r (Olivier Crouzet)
Date: Thu, 28 Nov 2024 19:43:19 +0100
Subject: [R] 
 Remove all box around a plot except bottom line (base graphics)
In-Reply-To: <9e377afe-4603-4936-9db8-4159259e3cfd@dewey.myzen.co.uk>
References: <9e377afe-4603-4936-9db8-4159259e3cfd@dewey.myzen.co.uk>
Message-ID: <20241128194319.33730fec77270b20c89cfcbf@univ-nantes.fr>

Dear Michael,

Isn't the axis() function what you're looking for?

plot(rnorm(10), rnorm(10), axes=FALSE)
axis(1)
 
see help(axis)

Yours.
Olivier.


On Thu, 28 Nov 2024 13:36:21 +0000
Michael Dewey <lists at dewey.myzen.co.uk> wrote:

> To make the plot clearer I have removed the axes but I wish to remove 
> all the boz except the bottom horizontal line. Using the bty
> parameter does not seem to enable me to just leave the horizontal
> line at the foot. I can get the "l" version to remove everything
> except the left hand side and the base. I could also remove the
> entire box but that looks odd. Am I reading the documentation
> incorrectly or is it really impossible?
> 
> -- 
> Michael
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.


-- 
  Olivier Crouzet, PhD
  http://olivier.ghostinthemachine.space
  /Ma?tre de Conf?rences/
  @LLING - Laboratoire de Linguistique de Nantes
    UMR6310 CNRS / Universit? de Nantes


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Fri Nov 29 02:25:42 2024
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Fri, 29 Nov 2024 01:25:42 +0000
Subject: [R] Trying to get the prior value of a record from a data.frame . .
 . data.frame
Message-ID: <DM6PR03MB50499EBB4A90D668242E8AC3E22A2@DM6PR03MB5049.namprd03.prod.outlook.com>

I need to write code that will give me the previous value of from a data.frame. I have written the following code using the shift function from data.table . It does not work. I hope someone can help me correct the code.
###########################
# Try to understand shift #
###########################
if(!require(data.table)) install.packages("data.table")
library(data.table)
# Create data
x <- data.frame(Id=rep(1:10),num=rep(11:20))
cat("This is the input data.frame used in the code below","\n")
x

for (i in 1:10) {
  cat("x[i,num]",x[i,"num"],"\n")
  # Get previous value of x[i,"num"] 
  zoop<-shift(x[i,"num"], n=1L, type="lag") 
  cat("Previous value of x[,num]=",zoop,"\n")
  }
###############################
# END Try to understand shift #
###############################

Thank you,
John


John David Sorkin M.D., Ph.D.
Professor of Medicine, University of Maryland School of Medicine;
Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;?
PI?Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;
Senior Statistician University of Maryland Center for Vascular Research;

Division of Gerontology and Paliative Care,
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
Cell phone 443-418-5382




From k|mmo@e|o @end|ng |rom ue|@||  Fri Nov 29 07:59:04 2024
From: k|mmo@e|o @end|ng |rom ue|@|| (Kimmo Elo)
Date: Fri, 29 Nov 2024 06:59:04 +0000
Subject: [R] 
 Trying to get the prior value of a record from a data.frame . .
 . data.frame
In-Reply-To: <DM6PR03MB50499EBB4A90D668242E8AC3E22A2@DM6PR03MB5049.namprd03.prod.outlook.com>
References: <DM6PR03MB50499EBB4A90D668242E8AC3E22A2@DM6PR03MB5049.namprd03.prod.outlook.com>
Message-ID: <472734fe-0fe7-4429-9c42-2ce06ae8ce4b@uef.fi>

Hi,

is there a specific reason to use "shift"? I mean, you could easily
achieve what you described by simple indexing:

--- snjp ---

for (i in 1:10) {
         cat("x[i,num]",x[i,"num"],"\n")
         # Get previous value of x[i,"num"]
         zoop<-x[i-1,"num"] # NB! Returns "integer(0)" for row index 0
         cat("Previous value of x[,num]=",zoop,"\n")
}

--- snip ---

The code above just loops through the *rows* from 1 to 10 and dumps the
"num" value from the previous row. If you want to get the "num" value
from the row above a specific "Id", then the zoop-line should look
something like this:

zoop<-x[which(x["Id"]==i)-1, "num"]

HTH,

Kimmo


Sorkin, John kirjoitti 29.11.2024 klo 3.25:
> I need to write code that will give me the previous value of from a data.frame. I have written the following code using the shift function from data.table . It does not work. I hope someone can help me correct the code.
> ###########################
> # Try to understand shift #
> ###########################
> if(!require(data.table)) install.packages("data.table")
> library(data.table)
> # Create data
> x <- data.frame(Id=rep(1:10),num=rep(11:20))
> cat("This is the input data.frame used in the code below","\n")
> x
>
> for (i in 1:10) {
>    cat("x[i,num]",x[i,"num"],"\n")
>    # Get previous value of x[i,"num"]
>    zoop<-shift(x[i,"num"], n=1L, type="lag")
>    cat("Previous value of x[,num]=",zoop,"\n")
>    }
> ###############################
> # END Try to understand shift #
> ###############################
>
> Thank you,
> John
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine, University of Maryland School of Medicine;
> Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;
> PI Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;
> Senior Statistician University of Maryland Center for Vascular Research;
>
> Division of Gerontology and Paliative Care,
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> Cell phone 443-418-5382
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.r-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Kimmo Elo
Senior Lecturer | Adjunct professor, Dr.
========================================================
University of Eastern Finland
Department of Geographical and Historical Studies
P.O. Box 111
FIN-80101 Joensuu
Finland
E-mail: kimmo.elo at uef.fi
ResearchGate: http://www.researchgate.net/profile/Kimmo_Elo
LAWPOL Consortium (PI): https://lawpol.fi/en
========================================================

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Nov 29 09:33:47 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 29 Nov 2024 08:33:47 +0000
Subject: [R] 
 Trying to get the prior value of a record from a data.frame . .
 . data.frame
In-Reply-To: <DM6PR03MB50499EBB4A90D668242E8AC3E22A2@DM6PR03MB5049.namprd03.prod.outlook.com>
References: <DM6PR03MB50499EBB4A90D668242E8AC3E22A2@DM6PR03MB5049.namprd03.prod.outlook.com>
Message-ID: <4b462602-b6bc-460d-a28a-85e93bf5d717@sapo.pt>

?s 01:25 de 29/11/2024, Sorkin, John escreveu:
> I need to write code that will give me the previous value of from a data.frame. I have written the following code using the shift function from data.table . It does not work. I hope someone can help me correct the code.
> ###########################
> # Try to understand shift #
> ###########################
> if(!require(data.table)) install.packages("data.table")
> library(data.table)
> # Create data
> x <- data.frame(Id=rep(1:10),num=rep(11:20))
> cat("This is the input data.frame used in the code below","\n")
> x
> 
> for (i in 1:10) {
>    cat("x[i,num]",x[i,"num"],"\n")
>    # Get previous value of x[i,"num"]
>    zoop<-shift(x[i,"num"], n=1L, type="lag")
>    cat("Previous value of x[,num]=",zoop,"\n")
>    }
> ###############################
> # END Try to understand shift #
> ###############################
> 
> Thank you,
> John
> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine, University of Maryland School of Medicine;
> Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;
> PI?Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;
> Senior Statistician University of Maryland Center for Vascular Research;
> 
> Division of Gerontology and Paliative Care,
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> Cell phone 443-418-5382
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

If you want to shift an entire vector, you don't need the loop, pass the 
vector itself to data.table::shift.



x <- data.frame(Id=rep(1:10),num=rep(11:20))

data.table::shift(x[["num"]], n = 1L)
#>  [1] NA 11 12 13 14 15 16 17 18 19
data.table::shift(x[, "num"], n = 1L)
#>  [1] NA 11 12 13 14 15 16 17 18 19


Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From |@rcego@p| @end|ng |rom gm@||@com  Thu Nov 28 18:36:38 2024
From: |@rcego@p| @end|ng |rom gm@||@com (Fer)
Date: Thu, 28 Nov 2024 18:36:38 +0100
Subject: [R] 
 Remove all box around a plot except bottom line (base graphics)
In-Reply-To: <b336466b-f256-4cd9-99e6-bd1dadd0295e@gmail.com>
References: <9e377afe-4603-4936-9db8-4159259e3cfd@dewey.myzen.co.uk>
 <b336466b-f256-4cd9-99e6-bd1dadd0295e@gmail.com>
Message-ID: <66cb494e-a55e-4991-8895-8f772af23968@gmail.com>

That's pretty similar to call axis function, i.e.


 ?plot(rnorm(100), yaxt="n", bty="n")
 ?usr <- par("usr")
 ?## lines(usr[c(1,2)], usr[c(3,3)], xpd = TRUE)

 ?axis(1, ...) # where 1 is bottom, 2 left, 3 top, and 4 right sides of 
the plot box)

Best

Fer

On 11/28/24 14:52, Duncan Murdoch wrote:
> On 2024-11-28 8:36 a.m., Michael Dewey wrote:
>> To make the plot clearer I have removed the axes but I wish to remove
>> all the boz except the bottom horizontal line. Using the bty parameter
>> does not seem to enable me to just leave the horizontal line at the
>> foot. I can get the "l" version to remove everything except the left
>> hand side and the base. I could also remove the entire box but that
>> looks odd. Am I reading the documentation incorrectly or is it really
>> impossible?
>>
>
> It's not something that `bty` can specify or `box()` can do, but you 
> can draw a line using lines() or segments().? For example:
>
> ?plot(rnorm(100), yaxt="n", bty="n")
> ?usr <- par("usr")
> ?lines(usr[c(1,2)], usr[c(3,3)], xpd = TRUE)
>
> You might not even need the lines() call if you don't care how far the 
> axis extends.
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Nov 29 11:16:53 2024
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 29 Nov 2024 05:16:53 -0500
Subject: [R] 
 Remove all box around a plot except bottom line (base graphics)
In-Reply-To: <66cb494e-a55e-4991-8895-8f772af23968@gmail.com>
References: <9e377afe-4603-4936-9db8-4159259e3cfd@dewey.myzen.co.uk>
 <b336466b-f256-4cd9-99e6-bd1dadd0295e@gmail.com>
 <66cb494e-a55e-4991-8895-8f772af23968@gmail.com>
Message-ID: <7f9bcf7c-1cf1-4750-a978-b88fd1cf753d@gmail.com>

On 2024-11-28 12:36 p.m., Fer wrote:
> That's pretty similar to call axis function, i.e.
> 
> 
>   ?plot(rnorm(100), yaxt="n", bty="n")
>   ?usr <- par("usr")
>   ?## lines(usr[c(1,2)], usr[c(3,3)], xpd = TRUE)
> 
>   ?axis(1, ...) # where 1 is bottom, 2 left, 3 top, and 4 right sides of
> the plot box)

You don't need the axis() call.  plot() already includes the x axis.

Duncan Murdoch

> 
> Best
> 
> Fer
> 
> On 11/28/24 14:52, Duncan Murdoch wrote:
>> On 2024-11-28 8:36 a.m., Michael Dewey wrote:
>>> To make the plot clearer I have removed the axes but I wish to remove
>>> all the boz except the bottom horizontal line. Using the bty parameter
>>> does not seem to enable me to just leave the horizontal line at the
>>> foot. I can get the "l" version to remove everything except the left
>>> hand side and the base. I could also remove the entire box but that
>>> looks odd. Am I reading the documentation incorrectly or is it really
>>> impossible?
>>>
>>
>> It's not something that `bty` can specify or `box()` can do, but you
>> can draw a line using lines() or segments().? For example:
>>
>>  ?plot(rnorm(100), yaxt="n", bty="n")
>>  ?usr <- par("usr")
>>  ?lines(usr[c(1,2)], usr[c(3,3)], xpd = TRUE)
>>
>> You might not even need the lines() call if you don't care how far the
>> axis extends.
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> https://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dyk|m7411 @end|ng |rom gm@||@com  Sat Nov 30 05:12:31 2024
From: dyk|m7411 @end|ng |rom gm@||@com (D)
Date: Fri, 29 Nov 2024 23:12:31 -0500
Subject: [R] Save spatial data in a csv file
Message-ID: <CADmwX-LXiw0yrVy2a0X+eERg=Vuv=pYGG8h16kdyuLLw3x2p+w@mail.gmail.com>

> print(nyc_ct_geo) Simple feature collection with 2325 features and 1
field Geometry type: MULTIPOLYGON Dimension: XY Bounding box: xmin:
913175.1 ymin: 120128.4 xmax: 1067383 ymax: 272844.3 Projected CRS: NAD83 /
New York Long Island (ftUS) First 10 features: geoid geometry 1 36061000100
MULTIPOLYGON (((972081.8 19... 2 36061000201 MULTIPOLYGON (((988548.2 19...
3 36061000600 MULTIPOLYGON (((986961.2 19... 4 36061001401 MULTIPOLYGON
(((987475 2002... 5 36061001402 MULTIPOLYGON (((988387.7 20... 6
36061001800 MULTIPOLYGON (((987062.3 20... 7 36061002201 MULTIPOLYGON
(((990139.8 20... 8 36061002601 MULTIPOLYGON (((990655.2 20... 9
36061002602 MULTIPOLYGON (((991015.1 20... 10 36061002800 MULTIPOLYGON
(((991650.9 20...

I am trying to save the above spatial data in a csv file using the code:
write.csv(nyc_ct_geo, 'nyc_ct_geo.csv',row.names=FALSE).   However, when I
ran said code, all geometry coordinates for each spatial unit were placed
in different columns.  I think they should be placed in one single column.
Any advice would be appreciated.

	[[alternative HTML version deleted]]


From h@@@n@d|w@n @end|ng |rom gm@||@com  Sat Nov 30 18:46:17 2024
From: h@@@n@d|w@n @end|ng |rom gm@||@com (Hasan Diwan)
Date: Sat, 30 Nov 2024 09:46:17 -0800
Subject: [R] Save spatial data in a csv file
In-Reply-To: <CADmwX-LXiw0yrVy2a0X+eERg=Vuv=pYGG8h16kdyuLLw3x2p+w@mail.gmail.com>
References: <CADmwX-LXiw0yrVy2a0X+eERg=Vuv=pYGG8h16kdyuLLw3x2p+w@mail.gmail.com>
Message-ID: <CAP+bYWCkzSSiBJ_FPH7fyYYcUV=4yGRP_baBe4UvMbMg87p0OQ@mail.gmail.com>

Kindly respond with the output of `dput(nyc_ct_geo)` -- thank you! -- H


-- 
OpenPGP: https://hasan.d8u.us/openpgp.asc
If you wish to request my time, please do so using
*bit.ly/hd1AppointmentRequest
<http://bit.ly/hd1AppointmentRequest>*.
Si vous voudriez faire connnaisance, allez a *bit.ly/hd1AppointmentRequest
<http://bit.ly/hd1AppointmentRequest>*.

<https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1>Sent
from my mobile device
Envoye de mon portable

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Nov 30 21:21:01 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 30 Nov 2024 12:21:01 -0800
Subject: [R] 
 Trying to get the prior value of a record from a data.frame . .
 . data.frame
In-Reply-To: <DM6PR03MB50499EBB4A90D668242E8AC3E22A2@DM6PR03MB5049.namprd03.prod.outlook.com>
References: <DM6PR03MB50499EBB4A90D668242E8AC3E22A2@DM6PR03MB5049.namprd03.prod.outlook.com>
Message-ID: <CAGxFJbS-y=DfYLW-0VfGA_psfQ+Em7Dce_JLakkx0x4QSnauJg@mail.gmail.com>

I assume that the responses that John already received to his recent
post met his needs. However, when I read it, I had a slightly
different interpretation. So feel free to ignore the rest of this post
if you like, but here's my interpretation and a simple solution to it.

An example to help explain:

set.seed(453)
df <- data.frame(
      group = sample(letters[1:4],30, rep = TRUE),
      gender = sample(c("M", "F", "NB"), 30, rep = TRUE),
      value = 1:30
)

df is a data frame with 30 records/rows of 3 columns giving a group
identifier, gender, and value for each record. I kept the values
artificially simple to (I hope) make it easier to understand the
problem and my solution.

The problem: create a new column, prev.value, that gives the value of
the previous record that has the same group and gender as the current
record if any such exist; or NA if no such previous id and gender
combination occur.
I think this is a slightly more complex task than John's original
request, but it is actually straightforward even in base R -- and
undoubtedly also using similar functionality in the Tidyverse or other
packages.

Here is my solution (using the R pipe, "|>", syntax):

df$prev.value <- with(df, {
   f <- paste0(group,gender) ## a simple 'hash' to identify the combinations
      ## "shift" the values for each group defined by f:
   f |> tapply(value, INDEX = _, FUN = \(x)c(NA, head(x, -1)))  |>
      ## reassemble according to f:
   unsplit(f)
})
df


Cheers,
Bert


On Thu, Nov 28, 2024 at 5:25?PM Sorkin, John <jsorkin at som.umaryland.edu> wrote:
>
> I need to write code that will give me the previous value of from a data.frame. I have written the following code using the shift function from data.table . It does not work. I hope someone can help me correct the code.
> ###########################
> # Try to understand shift #
> ###########################
> if(!require(data.table)) install.packages("data.table")
> library(data.table)
> # Create data
> x <- data.frame(Id=rep(1:10),num=rep(11:20))
> cat("This is the input data.frame used in the code below","\n")
> x
>
> for (i in 1:10) {
>   cat("x[i,num]",x[i,"num"],"\n")
>   # Get previous value of x[i,"num"]
>   zoop<-shift(x[i,"num"], n=1L, type="lag")
>   cat("Previous value of x[,num]=",zoop,"\n")
>   }
> ###############################
> # END Try to understand shift #
> ###############################
>
> Thank you,
> John
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine, University of Maryland School of Medicine;
> Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;
> PI Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;
> Senior Statistician University of Maryland Center for Vascular Research;
>
> Division of Gerontology and Paliative Care,
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> Cell phone 443-418-5382
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


