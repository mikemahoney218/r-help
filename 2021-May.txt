From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat May  1 00:38:40 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 1 May 2021 10:38:40 +1200
Subject: [R] Package "hse" has been REPLACED by package "dbd".
Message-ID: <20210501103840.651431b6@rolf-Latitude-E7470>


A reviewer of a paper that I wrote, of which the "hse" package was
a central consideration, thought that users might find the name "hse"
("hope springs eternal") to be indicative of a lack of seriousness.

Consequently I have changed the name of the package to "dbd"
("discretised beta distribution").  The underlying distribution, on
which the package is focussed, is now called "db" ("discretised beta").

The "hse" package still exists, *only* in order to produce a message
(when the package is loaded) to the effect that the package is
deprecated and that users should install and utilse the dbd package
instead.

The dbd package includes a number of modifications which (it is to be
hoped) make it an improvement over the hse package that it replaces.

I would be grateful to anyone who points out any problems with or
errors in the dbd package.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat May  1 00:56:18 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 30 Apr 2021 23:56:18 +0100
Subject: [R] Help understanding loop behaviour
In-Reply-To: <CAGxFJbSkp59-qXn67kHcZvUbYwgf_qk8iYzszVXxtUYKo1U=zw@mail.gmail.com>
References: <679279936.579089.1619710842379@mail2.virginmedia.com>
 <CA+8X3fVm3mhCTP3z=Uzn2GJL21-iawt-c205T6+nJzFEBO=hzQ@mail.gmail.com>
 <b1031b55f1904a408de7aa67b19d9e6f@SRVEXCHCM1302.precheza.cz>
 <2b419e1d-292c-e826-5810-c224d9d9e112@sapo.pt>
 <CAGxFJbSkp59-qXn67kHcZvUbYwgf_qk8iYzszVXxtUYKo1U=zw@mail.gmail.com>
Message-ID: <47666adf-355a-7bab-7b2f-45d09791583a@sapo.pt>

Hello,

Right, thanks. I should be


xx$I <- ave(xx$NUMBER_OF_YEARS, xx$COMPANY_NUMBER, FUN = function(x){
         c(rep(1, length(x) - 1), length(x))  ### ???
     })


Hope this helps,

Rui Barradas

?s 19:46 de 30/04/21, Bert Gunter escreveu:
> There is something wrong here I believe -- see inline below:
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along 
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Fri, Apr 30, 2021 at 10:37 AM Rui Barradas <ruipbarradas at sapo.pt 
> <mailto:ruipbarradas at sapo.pt>> wrote:
> 
>     Hello,
> 
>     For column J, ave/seq_along seems to be the simplest. For column I, ave
>     is also a good option, it avoids split/lapply.
> 
> 
>     xx$I <- ave(xx$NUMBER_OF_YEARS, xx$COMPANY_NUMBER, FUN = function(x){
>      ? ?c(rep(1, length(x) - 1), max(length(x)))? ### ???
>     })
> 
> **********
> length() returns a single integer, so max(length(x)) makes no sense
> ************************************
> 
>     xx$J <- ave(xx$NUMBER_OF_YEARS, xx$COMPANY_NUMBER, FUN = seq_along)
> 
> 
>     Hope this helps,
> 
>     ?s 11:49 de 30/04/21, PIKAL Petr escreveu:
>      > Hallo,
>      >
>      > Sorry, my suggestion did not worked in your case correctly as
>     split used
>      > natural factor ordering.
>      >
>      > So using Jim's data, this results in desired output.
>      >
>      > #prepare factor in original ordering
>      > ff <- factor(xx[,1], levels=unique(xx[,1]))
>      > lll <- split(xx$COMPANY_NUMBER, ff)
>      > xx$I <- unlist(lapply(lll, function(x) c(rep(1, length(x)-1),
>      > max(length(x)))),use.names=FALSE)
>      > xx$J <- unlist(lapply(lll, function(x) 1:length(x)), use.names=FALSE)
>      >> xx
>      >? ? ?COMPANY_NUMBER NUMBER_OF_YEARS I J
>      > 1? ? ? ? ? ?70837? ? ? ? ? ? ? ?3 1 1
>      > 2? ? ? ? ? ?70837? ? ? ? ? ? ? ?3 1 2
>      > 3? ? ? ? ? ?70837? ? ? ? ? ? ? ?3 3 3
>      > 4? ? ? ? ?1000403? ? ? ? ? ? ? ?4 1 1
>      > 5? ? ? ? ?1000403? ? ? ? ? ? ? ?4 1 2
>      > 6? ? ? ? ?1000403? ? ? ? ? ? ? ?4 1 3
>      > 7? ? ? ? ?1000403? ? ? ? ? ? ? ?4 4 4
>      > 8? ? ? ? 10029943? ? ? ? ? ? ? ?3 1 1
>      > 9? ? ? ? 10029943? ? ? ? ? ? ? ?3 1 2
>      > 10? ? ? ?10029943? ? ? ? ? ? ? ?3 3 3
>      > 11? ? ? ?10037980? ? ? ? ? ? ? ?4 1 1
>      > 12? ? ? ?10037980? ? ? ? ? ? ? ?4 1 2
>      > 13? ? ? ?10037980? ? ? ? ? ? ? ?4 1 3
>      > 14? ? ? ?10037980? ? ? ? ? ? ? ?4 4 4
>      > 15? ? ? ?10057418? ? ? ? ? ? ? ?3 1 1
>      > 16? ? ? ?10057418? ? ? ? ? ? ? ?3 1 2
>      > 17? ? ? ?10057418? ? ? ? ? ? ? ?3 3 3
>      > 18? ? ? ? 1009550? ? ? ? ? ? ? ?4 1 1
>      > 19? ? ? ? 1009550? ? ? ? ? ? ? ?4 1 2
>      > 20? ? ? ? 1009550? ? ? ? ? ? ? ?4 1 3
>      > 21? ? ? ? 1009550? ? ? ? ? ? ? ?4 4 4
>      >
>      > Cheers.
>      > Petr
>      >
>      >> -----Original Message-----
>      >> From: R-help <r-help-bounces at r-project.org
>     <mailto:r-help-bounces at r-project.org>> On Behalf Of Jim Lemon
>      >> Sent: Friday, April 30, 2021 11:45 AM
>      >> To: e-mail ma015k3113 <ma015k3113 at blueyonder.co.uk
>     <mailto:ma015k3113 at blueyonder.co.uk>>; r-help mailing list
>      >> <r-help at r-project.org <mailto:r-help at r-project.org>>
>      >> Subject: Re: [R] Help understanding loop behaviour
>      >>
>      >> Hi email,
>      >> If you want what you described, try this:
>      >>
>      >> xx<-read.table(text="COMPANY_NUMBER NUMBER_OF_YEARS
>      >> 0070837? 3
>      >> 0070837? 3
>      >> 0070837? 3
>      >> 1000403? 4
>      >> 1000403? 4
>      >> 1000403? 4
>      >> 1000403? 4
>      >> 10029943? 3
>      >> 10029943? 3
>      >> 10029943? 3
>      >> 10037980? 4
>      >> 10037980? 4
>      >> 10037980? 4
>      >> 10037980? 4
>      >> 10057418? 3
>      >> 10057418? 3
>      >> 10057418? 3
>      >> 1009550? 4
>      >> 1009550? 4
>      >> 1009550? 4
>      >> 1009550? 4",
>      >> header=TRUE,stringsAsFactors=FALSE)
>      >> xx$I<-NA
>      >> xx$J<-NA
>      >> row_count<-1
>      >> for(row in 1:nrow(xx)) {
>      >>? ?if(row == nrow(xx) ||
>      >> xx$COMPANY_NUMBER[row]==xx$COMPANY_NUMBER[row+1]) {
>      >>? ? xx$I[row]<-1
>      >>? ? xx$J[row]<-row_count
>      >>? ? row_count<-row_count+1
>      >>? ?} else {
>      >>? ? xx$I[row]<-xx$J[row]<-xx$NUMBER_OF_YEARS[row]
>      >>? ? row_count<-1
>      >>? ?}
>      >> }
>      >> xx
>      >>
>      >> Like Petr, I am assuming that you want company 10057418 treated
>     the same
>      >> as the others. If not, let us know why. I am also adssuming that
>     the first
>      > three
>      >> rows should _not_ have a "#" at the beginning, which means that
>     they will
>      > be
>      >> discarded.
>      >>
>      >> Jim
>      >>
>      >> On Fri, Apr 30, 2021 at 1:41 AM e-mail ma015k3113 via R-help
>     <r-help at r-
>      >> project.org <http://project.org>> wrote:
>      >>>
>      >>> I am trying to understand how loops in operate. I have a simple
>      >>> dataframe xx which is as follows
>      >>>
>      >>> COMPANY_NUMBER? ?NUMBER_OF_YEARS
>      >>>
>      >>> #0070837? ? ? ? ? ? ? ? ? ? ? ? ? ? ?3
>      >>> #0070837? ? ? ? ? ? ? ? ? ? ? ? ? ? ?3
>      >>> #0070837? ? ? ? ? ? ? ? ? ? ? ? ? ? ?3
>      >>> 1000403? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?4
>      >>> 1000403? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?4
>      >>> 1000403? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?4
>      >>> 1000403? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?4
>      >>> 10029943? ? ? ? ? ? ? ? ? ? ? ? ? ? ?3
>      >>> 10029943? ? ? ? ? ? ? ? ? ? ? ? ? ? ?3
>      >>> 10029943? ? ? ? ? ? ? ? ? ? ? ? ? ? ?3
>      >>> 10037980? ? ? ? ? ? ? ? ? ? ? ? ? ? ?4
>      >>> 10037980? ? ? ? ? ? ? ? ? ? ? ? ? ? ?4
>      >>> 10037980? ? ? ? ? ? ? ? ? ? ? ? ? ? ?4
>      >>> 10037980? ? ? ? ? ? ? ? ? ? ? ? ? ? ?4
>      >>> 10057418? ? ? ? ? ? ? ? ? ? ? ? ? ? ?3
>      >>> 10057418? ? ? ? ? ? ? ? ? ? ? ? ? ? ?3
>      >>>
>      >>> 10057418? ? ? ? ? ? ? ? ? ? ? ? ? ? ?3
>      >>> 1009550? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?4
>      >>> 1009550? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?4
>      >>> 1009550? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?4
>      >>> 1009550? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?4
>      >>> The code I have written is
>      >>>
>      >>> while (i <= nrow(xx1) )
>      >>>
>      >>> {
>      >>>
>      >>> for (j in 1:xx1$NUMBER_OF_YEARS[i])
>      >>> {
>      >>> xx1$I[i] <- i
>      >>> xx1$J[j] <- j
>      >>> xx1$NUMBER_OF_YEARS_j[j] <- xx1$NUMBER_OF_YEARS[j] } i=i +
>      >>> (xx1$NUMBER_OF_YEARS[i] ) } After running the code I want my
>      >> dataframe
>      >>> to look like
>      >>>
>      >>> |COMPANY_NUMBER |NUMBER_OF_YEARS| | I| |J|
>      >>>
>      >>> |#0070837 |3| |1| |1|
>      >>> |#0070837 |3| |1| |2|
>      >>> |#0070837 |3| |3| |3|
>      >>> |1000403 |4| |1| |1|
>      >>> |1000403 |4| |1| |2|
>      >>> |1000403 |4| |1| |3|
>      >>> |1000403 |4| |4| |4|
>      >>> |10029943 |3| |1| |1|
>      >>> |10029943 |3| |1| |2|
>      >>> |10029943 |3| |3| |3|
>      >>> |10037980 |4| |1| |1|
>      >>> |10037980 |4| |1| |2|
>      >>> |10037980 |4| |1| |3|
>      >>> |10037980 |4| |4| |4|
>      >>> |10057418 |3| |1| |1|
>      >>> |10057418 |3| |1| |1|
>      >>> |10057418 |3| |1| |1|
>      >>> |1009550 |4| |1| |1|
>      >>> |1009550 |4| |1| |2|
>      >>> |1009550 |4| |1| |3|
>      >>> |1009550 |4| |4| |4|
>      >>>
>      >>>
>      >>> I get the correct value of I but in the wrong row but the vaule
>     of J
>      >>> is correct in the first iteration and then it goes to 1
>      >>>
>      >>> Any help will be greatly appreciated
>      >>>? ? ? ? ? [[alternative HTML version deleted]]
>      >>>
>      >>> ______________________________________________
>      >>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      >>> https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>      >>> PLEASE do read the posting guide
>      >>> http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>      >>> and provide commented, minimal, self-contained, reproducible code.
>      >>
>      >> ______________________________________________
>      >> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      >> https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>      >> PLEASE do read the posting guide
>     http://www.R-project.org/posting- <http://www.R-project.org/posting->
>      >> guide.html
>      >> and provide commented, minimal, self-contained, reproducible code.
>      >>
>      >> ______________________________________________
>      >> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      >> https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>      >> PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>      >> and provide commented, minimal, self-contained, reproducible code.
> 
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>


From m@j@@@n@|yt|c@@b|og @end|ng |rom gm@||@com  Sat May  1 20:17:42 2021
From: m@j@@@n@|yt|c@@b|og @end|ng |rom gm@||@com (Maja Analytics)
Date: Sat, 1 May 2021 20:17:42 +0200
Subject: [R] Question about using R sample datasets
Message-ID: <CALbYN6xwv5fd2c2bN2cebMMNeK-2PgnqqE84uChbvpissv4Nog@mail.gmail.com>

Hello!

I would like to make tutorials for non-data scientists in R on Medium and
as LinkedIn articles. Could you tell me if I can use R sample datasets (I
would note the acknowledgements on the end) for that?

Thanks in advance, kind regards,
Maja

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Sun May  2 01:16:52 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sat, 1 May 2021 17:16:52 -0600
Subject: [R] Question about using R sample datasets
In-Reply-To: <CALbYN6xwv5fd2c2bN2cebMMNeK-2PgnqqE84uChbvpissv4Nog@mail.gmail.com>
References: <CALbYN6xwv5fd2c2bN2cebMMNeK-2PgnqqE84uChbvpissv4Nog@mail.gmail.com>
Message-ID: <AFF3AC76-DD69-48B2-A782-D52DEB3E371E@comcast.net>

Any answer you get here will will have all the authority of "some guy on the Internet", but my reading of the licenses is that as long as you give proper credit that you can use any material in teaching or commercial purposes AND derivative works are likewise copy-able on an open source (FOSS) basis. You should read the LinkedIn TOS and make sure that posting there is not subject to some sort of publisher's copyright. That might be a violation fo the licensing for material copied from CRAN sources. Acknowledgment alone might not be an acceptable use. You may need to seek appropriate legal counsel or get opinions from the creators of the licensing language, since there are a variety of license.

David Winsemius, MD, (IANAL)


> On May 1, 2021, at 12:17 PM, Maja Analytics <maja.analytics.blog at gmail.com> wrote:
> 
> Hello!
> 
> I would like to make tutorials for non-data scientists in R on Medium and
> as LinkedIn articles. Could you tell me if I can use R sample datasets (I
> would note the acknowledgements on the end) for that?
> 
> Thanks in advance, kind regards,
> Maja
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mjung4 @end|ng |rom go@o|em|@@@edu  Sun May  2 01:50:04 2021
From: mjung4 @end|ng |rom go@o|em|@@@edu (Myungjin Jung)
Date: Sat, 1 May 2021 18:50:04 -0500
Subject: [R] Question
Message-ID: <CAApF_pgB6p_pXmxh-d+oTthYyMyMVpQ1ib6Y77=6b1jpeyPtMg@mail.gmail.com>

Good evening,

I have a quick question about the "robumeta" package in R software. Below
is my question:

Is it possible to create funnel plots as well as assess (Egger's test) and
adjust (Trim and fill approach) for publication bias in meta-analysis with
RVE methods?

Thank you so much for your help.

Best regards,
Myungjin

*Myungjin Jung*
Doctoral Graduate Assistant
The University of Mississippi
Department of Health, Exercise Science, and Recreation Management
P.O. Box 1848
234 Turner Center
University, MS 38677-1848
*mjung4 at go.olemiss.ed <mjung4 at go.olemiss.edu>u*

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sun May  2 04:02:54 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 1 May 2021 19:02:54 -0700
Subject: [R] Question
In-Reply-To: <CAApF_pgB6p_pXmxh-d+oTthYyMyMVpQ1ib6Y77=6b1jpeyPtMg@mail.gmail.com>
References: <CAApF_pgB6p_pXmxh-d+oTthYyMyMVpQ1ib6Y77=6b1jpeyPtMg@mail.gmail.com>
Message-ID: <CAGxFJbTWs=AGr02xomaX66DBEywMfEVWSyu5TVY_ZLmWaNRR9A@mail.gmail.com>

Do note, per the posting guide linked below (which you should read):

"For questions about functions in standard packages distributed with R (see
the FAQ Add-on packages in R
<https://cran.r-project.org/doc/FAQ/R-FAQ.html#Add-on-packages-in-R>), ask
questions on R-help.

If the question relates to a *contributed package* , e.g., one downloaded
from CRAN, try contacting the package maintainer first. You can also use
find("functionname") and packageDescription("packagename") to find this
information. *Only* send such questions to R-help or R-devel if you get no
reply or need further assistance. This applies to both requests for help
and to bug reports."

So do not be surprised if you do not receive a response here. You would
probably have a better chance for success on the SIG devoted to
meta-analysis:
https://stat.ethz.ch/mailman/listinfo/r-sig-meta-analysis  .

Also per the posting guide, post in plain text not html. Not a problem
here, but it can be when one posts code.

Cheers,
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, May 1, 2021 at 5:59 PM Myungjin Jung <mjung4 at go.olemiss.edu> wrote:

> Good evening,
>
> I have a quick question about the "robumeta" package in R software. Below
> is my question:
>
> Is it possible to create funnel plots as well as assess (Egger's test) and
> adjust (Trim and fill approach) for publication bias in meta-analysis with
> RVE methods?
>
> Thank you so much for your help.
>
> Best regards,
> Myungjin
>
> *Myungjin Jung*
> Doctoral Graduate Assistant
> The University of Mississippi
> Department of Health, Exercise Science, and Recreation Management
> P.O. Box 1848
> 234 Turner Center
> University, MS 38677-1848
> *mjung4 at go.olemiss.ed <mjung4 at go.olemiss.edu>u*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Sun May  2 08:10:48 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sun, 2 May 2021 16:10:48 +1000
Subject: [R] Question
In-Reply-To: <CAApF_pgB6p_pXmxh-d+oTthYyMyMVpQ1ib6Y77=6b1jpeyPtMg@mail.gmail.com>
References: <CAApF_pgB6p_pXmxh-d+oTthYyMyMVpQ1ib6Y77=6b1jpeyPtMg@mail.gmail.com>
Message-ID: <CA+8X3fVZeQOFfrpunF=pt_S4mPytExDp70JN_HB=2LQcz+mtNw@mail.gmail.com>

Hi Myungjin,
The funnel plot is no more than the precision of the estimates of
related studies plotted against the estimates. That is, if your
measure of precision is the sample size (SS) and the estimate is named
E,

plot(E,SS)

Look at the metafor package for good funnel plot functions. Egger's
test can be misleading, see:

https://training.cochrane.org/resource/identifying-publication-bias-meta-analyses-continuous-outcomes

for a good introduction.

Jim


produces a very basic funnel plot. Enclosing lines or curves are
usually added, forming the inverted "funnel".

On Sun, May 2, 2021 at 11:00 AM Myungjin Jung <mjung4 at go.olemiss.edu> wrote:
>
> Good evening,
>
> I have a quick question about the "robumeta" package in R software. Below
> is my question:
>
> Is it possible to create funnel plots as well as assess (Egger's test) and
> adjust (Trim and fill approach) for publication bias in meta-analysis with
> RVE methods?
>
> Thank you so much for your help.
>
> Best regards,
> Myungjin
>
> *Myungjin Jung*
> Doctoral Graduate Assistant
> The University of Mississippi
> Department of Health, Exercise Science, and Recreation Management
> P.O. Box 1848
> 234 Turner Center
> University, MS 38677-1848
> *mjung4 at go.olemiss.ed <mjung4 at go.olemiss.edu>u*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dw|n@em|u@ @end|ng |rom comc@@t@net  Sun May  2 15:04:04 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sun, 2 May 2021 07:04:04 -0600
Subject: [R] Question about using R sample datasets
In-Reply-To: <CALbYN6yfvGvSLqjJPhK0p+pcH8ihEg5CAExyKPysVLWAvq7Uog@mail.gmail.com>
References: <CALbYN6yfvGvSLqjJPhK0p+pcH8ihEg5CAExyKPysVLWAvq7Uog@mail.gmail.com>
Message-ID: <1785B336-C184-4A4A-B1A3-BA7A8709E371@comcast.net>

Again, the terms of the license govern the legalities. I don?t think you would need any further efforts at licensing your commentary. Screenshots or text copies would both be just copies and the appropriate citations would probably be all that were needed. I do not think your commentary or explanatory work would need to be considered FOSS or a copyleft license. There are many instances of commercial, copyrighted books that contain portions of R source code. Several businesses exist that sell accessories or packages that depend on but are not part of core R. Some of them seem to me to be skirting the line of legality but I don?t think there have been any cases brought before judicial authorities. So your plans seems completely safe and well inside accepted and legal boundaries to my understanding. 

David 

Sent from my iPhone

> On May 2, 2021, at 2:39 AM, Maja Analytics <maja.analytics.blog at gmail.com> wrote:
> 
> ?
> Thanks for the advice.
> 
> What about R code? Is that free to share? I would use my own dataset or made up dataset, so I am only now interested what about R code, can I screenshot it and then explain what is on the photo?
> 
> Maja
> 
> ned, 2. svi 2021. u 01:17 David Winsemius <dwinsemius at comcast.net> napisao je:
>> Any answer you get here will will have all the authority of "some guy on the Internet", but my reading of the licenses is that as long as you give proper credit that you can use any material in teaching or commercial purposes AND derivative works are likewise copy-able on an open source (FOSS) basis. You should read the LinkedIn TOS and make sure that posting there is not subject to some sort of publisher's copyright. That might be a violation fo the licensing for material copied from CRAN sources. Acknowledgment alone might not be an acceptable use. You may need to seek appropriate legal counsel or get opinions from the creators of the licensing language, since there are a variety of license.
>> 
>> David Winsemius, MD, (IANAL)
>> 
>> 
>> > On May 1, 2021, at 12:17 PM, Maja Analytics <maja.analytics.blog at gmail.com> wrote:
>> > 
>> > Hello!
>> > 
>> > I would like to make tutorials for non-data scientists in R on Medium and
>> > as LinkedIn articles. Could you tell me if I can use R sample datasets (I
>> > would note the acknowledgements on the end) for that?
>> > 
>> > Thanks in advance, kind regards,
>> > Maja
>> > 
>> >       [[alternative HTML version deleted]]
>> > 
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> 

	[[alternative HTML version deleted]]


From b@k|un@| @end|ng |rom y@hoo@com  Sun May  2 20:38:18 2021
From: b@k|un@| @end|ng |rom y@hoo@com (Baki UNAL)
Date: Sun, 2 May 2021 18:38:18 +0000 (UTC)
Subject: [R] Plotting two time series in one graph
References: <1481832980.304712.1619980698034.ref@mail.yahoo.com>
Message-ID: <1481832980.304712.1619980698034@mail.yahoo.com>

Hi

I'm trying to plot two time series in one graph. I tried the following code:


p = ggplot() +?
? geom_line(data = dovrez, aes(x = Date, y = Res), color = "blue") +
? geom_line(data = rqa_df_USD, aes(x = DATE, y = LAM), color = "red") +
? xlab('Dates') +
? ylab('Values')
print(p)

But I got the following error:

Hata: `mapped_discrete` objects can only be created from numeric vectors
Run `rlang::last_error()` to see where the error occurred.

Time indexes of my dataframes (dovrez, rqa_df_USD) are not same. First dataframe (dovrez) has 820 date points. Second dataframe (rqa_df_USD) has 75 date points.

How can I plot these two data in one graph?

Best Regards
Baki ?nal


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun May  2 21:45:12 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 2 May 2021 20:45:12 +0100
Subject: [R] Plotting two time series in one graph
In-Reply-To: <1481832980.304712.1619980698034@mail.yahoo.com>
References: <1481832980.304712.1619980698034.ref@mail.yahoo.com>
 <1481832980.304712.1619980698034@mail.yahoo.com>
Message-ID: <79e78d1d-aafe-8aad-7f6e-fdff31a0d125@sapo.pt>

Hello,

Can you post sample data? For instance, the output of

dput(head(dovrez, 20))
dput(head(rqa_df_USD, 20))


Or maybe you could rbind the data.frames with one column telling which 
of Res or LAM the values come from.


Hope this helps,

Rui Barradas

?s 19:38 de 02/05/21, Baki UNAL via R-help escreveu:
> Hi
> 
> I'm trying to plot two time series in one graph. I tried the following code:
> 
> 
> p = ggplot() +
>  ? geom_line(data = dovrez, aes(x = Date, y = Res), color = "blue") +
>  ? geom_line(data = rqa_df_USD, aes(x = DATE, y = LAM), color = "red") +
>  ? xlab('Dates') +
>  ? ylab('Values')
> print(p)
> 
> But I got the following error:
> 
> Hata: `mapped_discrete` objects can only be created from numeric vectors
> Run `rlang::last_error()` to see where the error occurred.
> 
> Time indexes of my dataframes (dovrez, rqa_df_USD) are not same. First dataframe (dovrez) has 820 date points. Second dataframe (rqa_df_USD) has 75 date points.
> 
> How can I plot these two data in one graph?
> 
> Best Regards
> Baki ?nal
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From m@j@@@n@|yt|c@@b|og @end|ng |rom gm@||@com  Sun May  2 10:38:49 2021
From: m@j@@@n@|yt|c@@b|og @end|ng |rom gm@||@com (Maja Analytics)
Date: Sun, 2 May 2021 10:38:49 +0200
Subject: [R] Question about using R sample datasets
In-Reply-To: <AFF3AC76-DD69-48B2-A782-D52DEB3E371E@comcast.net>
References: <CALbYN6xwv5fd2c2bN2cebMMNeK-2PgnqqE84uChbvpissv4Nog@mail.gmail.com>
 <AFF3AC76-DD69-48B2-A782-D52DEB3E371E@comcast.net>
Message-ID: <CALbYN6yfvGvSLqjJPhK0p+pcH8ihEg5CAExyKPysVLWAvq7Uog@mail.gmail.com>

Thanks for the advice.

What about R code? Is that free to share? I would use my own dataset or
made up dataset, so I am only now interested what about R code, can I
screenshot it and then explain what is on the photo?

Maja

ned, 2. svi 2021. u 01:17 David Winsemius <dwinsemius at comcast.net> napisao
je:

> Any answer you get here will will have all the authority of "some guy on
> the Internet", but my reading of the licenses is that as long as you give
> proper credit that you can use any material in teaching or commercial
> purposes AND derivative works are likewise copy-able on an open source
> (FOSS) basis. You should read the LinkedIn TOS and make sure that posting
> there is not subject to some sort of publisher's copyright. That might be a
> violation fo the licensing for material copied from CRAN sources.
> Acknowledgment alone might not be an acceptable use. You may need to seek
> appropriate legal counsel or get opinions from the creators of the
> licensing language, since there are a variety of license.
>
> David Winsemius, MD, (IANAL)
>
>
> > On May 1, 2021, at 12:17 PM, Maja Analytics <
> maja.analytics.blog at gmail.com> wrote:
> >
> > Hello!
> >
> > I would like to make tutorials for non-data scientists in R on Medium and
> > as LinkedIn articles. Could you tell me if I can use R sample datasets (I
> > would note the acknowledgements on the end) for that?
> >
> > Thanks in advance, kind regards,
> > Maja
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Mon May  3 02:42:30 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abbs Spurdle)
Date: Mon, 3 May 2021 12:42:30 +1200
Subject: [R] Package "hse" has been REPLACED by package "dbd".
In-Reply-To: <20210501103840.651431b6@rolf-Latitude-E7470>
References: <20210501103840.651431b6@rolf-Latitude-E7470>
Message-ID: <CAB8pepwF_gCauek2wL+XE2uGD9JT3w3m3F9DKY8m-h4PwOM1zg@mail.gmail.com>

Previously, I disliked some of R's names.
e.g. Action of the Toes.
But then later realized toes are really important.

I don't want to disagree with a 'reviewer'.
But I would say subtle references to literature and philosophy
demonstrate 'depth'.

Was your reviewer a member of the (A)merican (S)tatistical (S)ociety...?
Who came up with that name...?

It's all subjective really...


On Sat, May 1, 2021 at 10:39 AM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
> A reviewer of a paper that I wrote, of which the "hse" package was
> a central consideration, thought that users might find the name "hse"
> ("hope springs eternal") to be indicative of a lack of seriousness.
>
> Consequently I have changed the name of the package to "dbd"
> ("discretised beta distribution").  The underlying distribution, on
> which the package is focussed, is now called "db" ("discretised beta").
>
> The "hse" package still exists, *only* in order to produce a message
> (when the package is loaded) to the effect that the package is
> deprecated and that users should install and utilse the dbd package
> instead.
>
> The dbd package includes a number of modifications which (it is to be
> hoped) make it an improvement over the hse package that it replaces.
>
> I would be grateful to anyone who points out any problems with or
> errors in the dbd package.
>
> cheers,
>
> Rolf Turner
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon May  3 03:29:30 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 02 May 2021 18:29:30 -0700
Subject: [R] Question about using R sample datasets
In-Reply-To: <CALbYN6yfvGvSLqjJPhK0p+pcH8ihEg5CAExyKPysVLWAvq7Uog@mail.gmail.com>
References: <CALbYN6xwv5fd2c2bN2cebMMNeK-2PgnqqE84uChbvpissv4Nog@mail.gmail.com>
 <AFF3AC76-DD69-48B2-A782-D52DEB3E371E@comcast.net>
 <CALbYN6yfvGvSLqjJPhK0p+pcH8ihEg5CAExyKPysVLWAvq7Uog@mail.gmail.com>
Message-ID: <F614473D-DF75-43F7-AF63-B82262DF95A1@dcn.davis.ca.us>

You have already been reminded that none of us are lawyers. There is license text associated with every package and base R, and it is not necessarily the same for all parts of R, so there is no way for us to answer your question in its vague form and no way for you to rely our opinions even if you do clarify.

On May 2, 2021 1:38:49 AM PDT, Maja Analytics <maja.analytics.blog at gmail.com> wrote:
>Thanks for the advice.
>
>What about R code? Is that free to share? I would use my own dataset or
>made up dataset, so I am only now interested what about R code, can I
>screenshot it and then explain what is on the photo?
>
>Maja
>
>ned, 2. svi 2021. u 01:17 David Winsemius <dwinsemius at comcast.net>
>napisao
>je:
>
>> Any answer you get here will will have all the authority of "some guy
>on
>> the Internet", but my reading of the licenses is that as long as you
>give
>> proper credit that you can use any material in teaching or commercial
>> purposes AND derivative works are likewise copy-able on an open
>source
>> (FOSS) basis. You should read the LinkedIn TOS and make sure that
>posting
>> there is not subject to some sort of publisher's copyright. That
>might be a
>> violation fo the licensing for material copied from CRAN sources.
>> Acknowledgment alone might not be an acceptable use. You may need to
>seek
>> appropriate legal counsel or get opinions from the creators of the
>> licensing language, since there are a variety of license.
>>
>> David Winsemius, MD, (IANAL)
>>
>>
>> > On May 1, 2021, at 12:17 PM, Maja Analytics <
>> maja.analytics.blog at gmail.com> wrote:
>> >
>> > Hello!
>> >
>> > I would like to make tutorials for non-data scientists in R on
>Medium and
>> > as LinkedIn articles. Could you tell me if I can use R sample
>datasets (I
>> > would note the acknowledgements on the end) for that?
>> >
>> > Thanks in advance, kind regards,
>> > Maja
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From therne@u @end|ng |rom m@yo@edu  Tue May  4 00:34:03 2021
From: therne@u @end|ng |rom m@yo@edu (Therneau, Terry M., Ph.D.)
Date: Mon, 03 May 2021 17:34:03 -0500
Subject: [R] inverse of the methods function
Message-ID: <9b53cf$fsqt82@ironport10.mayo.edu>

Is there a complement to the methods function, that will list all the defined methods for 
a class???? One solution is to look directly at the NAMESPACE file, for the package that 
defines it, and parse out the entries.?? I was looking for something built-in, i.e., easier.


-- 
Terry M Therneau, PhD
Department of Health Science Research
Mayo Clinic
therneau at mayo.edu

"TERR-ree THUR-noh"


	[[alternative HTML version deleted]]


From mtmorg@n@b|oc @end|ng |rom gm@||@com  Tue May  4 00:37:15 2021
From: mtmorg@n@b|oc @end|ng |rom gm@||@com (Martin Morgan)
Date: Mon, 3 May 2021 22:37:15 +0000
Subject: [R] inverse of the methods function
In-Reply-To: <9b53cf$fsqt82@ironport10.mayo.edu>
References: <9b53cf$fsqt82@ironport10.mayo.edu>
Message-ID: <BN8PR04MB6241D9A119003AF109F97B99F95B9@BN8PR04MB6241.namprd04.prod.outlook.com>

> methods(class = "lm")
 [1] add1           alias          anova          case.names     coerce
 [6] confint        cooks.distance deviance       dfbeta         dfbetas
[11] drop1          dummy.coef     effects        extractAIC     family
[16] formula        hatvalues      influence      initialize     kappa
[21] labels         logLik         model.frame    model.matrix   nobs
[26] plot           predict        print          proj           qr
[31] residuals      rstandard      rstudent       show           simulate
[36] slotsFromS3    summary        variable.names vcov
see '?methods' for accessing help and source code

Martin Morgan

?On 5/3/21, 6:34 PM, "R-help on behalf of Therneau, Terry M., Ph.D. via R-help" <r-help-bounces at r-project.org on behalf of r-help at R-project.org> wrote:

    Is there a complement to the methods function, that will list all the defined methods for 
    a class?    One solution is to look directly at the NAMESPACE file, for the package that 
    defines it, and parse out the entries.   I was looking for something built-in, i.e., easier.


    -- 
    Terry M Therneau, PhD
    Department of Health Science Research
    Mayo Clinic
    therneau at mayo.edu

    "TERR-ree THUR-noh"


    	[[alternative HTML version deleted]]

    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.

From @purd|e@@ @end|ng |rom gm@||@com  Tue May  4 00:42:31 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abbs Spurdle)
Date: Tue, 4 May 2021 10:42:31 +1200
Subject: [R] inverse of the methods function
In-Reply-To: <9b53cf$fsqt82@ironport10.mayo.edu>
References: <9b53cf$fsqt82@ironport10.mayo.edu>
Message-ID: <CAB8pepwzztUgBADwm7xPhXvgE9MgHd4nEwqHPTLU6BP9vCU5BA@mail.gmail.com>

methods (,"glm")


On Tue, May 4, 2021 at 10:34 AM Therneau, Terry M., Ph.D. via R-help
<r-help at r-project.org> wrote:
>
> Is there a complement to the methods function, that will list all the defined methods for
> a class?    One solution is to look directly at the NAMESPACE file, for the package that
> defines it, and parse out the entries.   I was looking for something built-in, i.e., easier.
>
>
> --
> Terry M Therneau, PhD
> Department of Health Science Research
> Mayo Clinic
> therneau at mayo.edu
>
> "TERR-ree THUR-noh"
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @gne@g2g @end|ng |rom hotm@||@com  Tue May  4 22:23:41 2021
From: @gne@g2g @end|ng |rom hotm@||@com (Agnes g2g)
Date: Tue, 4 May 2021 20:23:41 +0000
Subject: [R] =?utf-8?q?Warning_=E2=80=9CUnknown_or_uninitialised_column?=
 =?utf-8?q?=3A_=60ntree=60=2E=E2=80=9D_when_trying_to_pass_hyperparameters?=
 =?utf-8?q?_to_a_learner_with_package_mlr?=
Message-ID: <AM0PR0602MB34276CC7EA4B614D46C4BF35835A9@AM0PR0602MB3427.eurprd06.prod.outlook.com>

?Dear all,
I posted this question on stats exchange and got the message that it was off-topic.https://stats.stackexchange.com/questions/522745/warning-unknown-or-uninitialised-column-ntree-when-trying-to-pass-hyperpar
They suggested to use this email list instead.
So that's why I am posting it here. I have read the instructions, but if I have overlooked something that said this question does not belong on this mailing list, I apologise.

Thanks in advance for reading this message!

Kind regards,
Agnes Wattel
problem

I want to do a grid search with different hyperparameters that are provided by a self-made grid. But when I am running the code I get a warning: "Unknown or uninitialised column: ntree."

create grid

gs <- list(ntree = c(50,100,150,200,300,500,550),mtry = c(1,2,3,4,5)) %>% cross_df()


select hyperparameters

  for (h in 1:nrow(gs)) {
    ntree_entry <- gs$ntree[h]
    mtry_entry <- gs$mtry[h]
    (...)
    lrn <- makeMultilabelClassifierChainsWrapper(lrn, order = NULL)
    lrn <- setPredictType(lrn,"prob")
    task <- makeMultilabelTask(data = data[train_lines,], target = label_bact)
    mod <- mlr::train(lrn,task)
    }


On the place of (...) I have tried two different ways to get the hyperparameters into the learner:

option 1: pass hyperparameters to the learner

lrn <- makeLearner("classif.randomForest",ntree = ntree_entry,mtry = mtry_entry)


option 2: pass hyperparameters to the learner

lrn <- makeLearner("classif.randomForest")
lrn <- setHyperPars(lrn,par.vals = list(ntree = ntree_entry,mtry = mtry_entry))


check

The console tells me that the hyperparameters are in the learner:

>lrn
Learner classif.randomForest from package randomForest
Type: classif
Name: Random Forest; Short name: rf
Class: classif.randomForest
Properties: twoclass,multiclass,numerics,factors,ordered,prob,class.weights,oobpreds,featimp
Predict-Type: response
Hyperparameters: ntree=50,mtry=1


ntree and mtry are hyperparameters that are known to the makeLearner, because they are both in getParamSet:

> getParamSet("classif.randomForest")

                     Type  len   Def   Constr Req Tunable Trafo
ntree             integer    -   500 1 to Inf   -    TRUE     -
mtry              integer    -     - 1 to Inf   -    TRUE     -
replace           logical    -  TRUE        -   -    TRUE     -
classwt     numericvector <NA>     - 0 to Inf   -    TRUE     -
cutoff      numericvector <NA>     -   0 to 1   -    TRUE     -
strata            untyped    -     -        -   -   FALSE     -
sampsize    integervector <NA>     - 1 to Inf   -    TRUE     -
nodesize          integer    -     1 1 to Inf   -    TRUE     -
maxnodes          integer    -     - 1 to Inf   -    TRUE     -
importance        logical    - FALSE        -   -    TRUE     -
localImp          logical    - FALSE        -   -    TRUE     -
proximity         logical    - FALSE        -   -   FALSE     -
oob.prox          logical    -     -        -   Y   FALSE     -
norm.votes        logical    -  TRUE        -   -   FALSE     -
do.trace          logical    - FALSE        -   -   FALSE     -
keep.forest       logical    -  TRUE        -   -   FALSE     -
keep.inbag        logical    - FALSE        -   -   FALSE     -


Question

Why do I get the message "Unknown or uninitialised column: ntree"? Although it is only a warning, not an error, I am afraid that it will only use the first line of the grid that I created. The sizes of the models seem to confirm that. They all have the same size. I hope that someone can help me with this problem. Thanks in advance!


	[[alternative HTML version deleted]]


From thebudget72 m@iii@g oii gm@ii@com  Wed May  5 20:55:09 2021
From: thebudget72 m@iii@g oii gm@ii@com (thebudget72 m@iii@g oii gm@ii@com)
Date: Wed, 5 May 2021 20:55:09 +0200
Subject: [R] [MatchIt] Naive Estimator for ATT after Full Matching
Message-ID: <32188880-69bf-8aff-f69f-35d6b2713f02@gmail.com>

Dear R-help ML,

I would like to compute a Naive Estimator for the Average Treatment 
Effect (ATT) after a Propensity Score Matching with full matching.

Since it is full matching, the resulting post-matching database contains 
all the observations of the original dataset.

I came up with this code, which does a weighted average of the outcomes, 
using the weights provided by the matching process, but I'm not sure 
this is the correct way to achieve it.

How can I compute the ATT using a Naive Estimator after PSM?

I know I am supposed to do a regression, but I am interested in 
computing a Naive Estimator as a difference between the means across the 
two groups.


```r
library("MatchIt")
data("lalonde")

m.out2 <- matchit(treat ~ age + educ + race + married +
 ????????????????? nodegree + re74 + re75,
 ????????????????? data = lalonde,
 ????????????????? method = "full",
 ????????????????? distance = "glm",
 ????????????????? link = "probit")

m.data2 <- match.data(m.out2)

te <- weighted.mean(m.data2$re78[m.data2$treat],
 ??????????????????? m.data2$weights[m.data2$treat])
nte <- weighted.mean(m.data2$re78[!m.data2$treat],
 ???????????????????? m.data2$weights[!m.data2$treat])
ne2w <- round(te-nte, 2)

print(paste0("The ATT estimated with a NE is: ", ne2w))
```


Thanks in advance and best regards.


From bgunter@4567 @end|ng |rom gm@||@com  Wed May  5 22:07:41 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 5 May 2021 13:07:41 -0700
Subject: [R] [MatchIt] Naive Estimator for ATT after Full Matching
In-Reply-To: <32188880-69bf-8aff-f69f-35d6b2713f02@gmail.com>
References: <32188880-69bf-8aff-f69f-35d6b2713f02@gmail.com>
Message-ID: <CAGxFJbQwCkXR+PHH=TLSCfAdV53H9+HG0QRcb5awj0HCARZhrg@mail.gmail.com>

Do note, per the posting guide linked below (please read it if you haven't
done so already):

1. *"Questions about statistics:* The R mailing lists are primarily
intended for questions and discussion about the R software. However,
questions about statistical methodology are sometimes posted. If the
question is well-asked and of interest to someone on the list, it *may*
elicit an informative up-to-date answer. "

So do not be surprised if you do not get a response here.
stats.stackexchange.com *may* be a better alternative if you do not.

2. "For questions about functions in standard packages distributed with R
(see the FAQ Add-on packages in R
<https://cran.r-project.org/doc/FAQ/R-FAQ.html#Add-on-packages-in-R>), ask
questions on R-help.
If the question relates to a *contributed package* , e.g., one downloaded
from CRAN, try contacting the package maintainer first."

The matchit package maintainer can be found by: maintainer("matchit") if
you think the above applies.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, May 5, 2021 at 11:55 AM <thebudget72 at gmail.com> wrote:

> Dear R-help ML,
>
> I would like to compute a Naive Estimator for the Average Treatment
> Effect (ATT) after a Propensity Score Matching with full matching.
>
> Since it is full matching, the resulting post-matching database contains
> all the observations of the original dataset.
>
> I came up with this code, which does a weighted average of the outcomes,
> using the weights provided by the matching process, but I'm not sure
> this is the correct way to achieve it.
>
> How can I compute the ATT using a Naive Estimator after PSM?
>
> I know I am supposed to do a regression, but I am interested in
> computing a Naive Estimator as a difference between the means across the
> two groups.
>
>
> ```r
> library("MatchIt")
> data("lalonde")
>
> m.out2 <- matchit(treat ~ age + educ + race + married +
>                    nodegree + re74 + re75,
>                    data = lalonde,
>                    method = "full",
>                    distance = "glm",
>                    link = "probit")
>
> m.data2 <- match.data(m.out2)
>
> te <- weighted.mean(m.data2$re78[m.data2$treat],
>                      m.data2$weights[m.data2$treat])
> nte <- weighted.mean(m.data2$re78[!m.data2$treat],
>                       m.data2$weights[!m.data2$treat])
> ne2w <- round(te-nte, 2)
>
> print(paste0("The ATT estimated with a NE is: ", ne2w))
> ```
>
>
> Thanks in advance and best regards.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From utr|go@ @end|ng |rom um|ch@edu  Wed May  5 19:39:01 2021
From: utr|go@ @end|ng |rom um|ch@edu (Ursula Trigos-Raczkowski)
Date: Wed, 5 May 2021 13:39:01 -0400
Subject: [R] solving integral equations with undefined parameters using
 multiroot
Message-ID: <CANSXP2RHWd7CkRMOCb8n5Nm2ei5LHyzUBhTsTjdsCH+hq6Ac-w@mail.gmail.com>

Hello,
I am trying to solve a system of integral equations using multiroot. I have
tried asking on stack exchange and reddit without any luck.
Multiroot uses the library(RootSolve).

I have two integral equations involving constants S[1] and S[2] (which are
free.) I would like to find what *positive* values of S[1] and S[2] make
the resulting
(Integrals-1) = 0.
(I know that the way I have the parameters set up the equations are very
similar but I am interested in changing the parameters once I have the code
working.)
My attempt at code:

```{r}
a11 <- 1 #alpha_{11}
a12 <- 1 #alpha_{12}
a21 <- 1 #alpha_{21}
a22 <- 1 #alpha_{22}
b1 <- 2  #beta1
b2 <- 2 #beta2
d1 <- 1 #delta1
d2 <- 1 #delta2
g <- 0.5 #gamma


integrand1 <- function(x,S) {b1*g/d1*exp(-g*x)*(1-exp(-d1*
x))*exp(-a11*b1*S[1]/d1*(1-exp(-d1*x))-a12*b2*S[2]/d2*(1-exp(-d2*x)))}
integrand2 <- function(x,S) {b2*g/d2*exp(-g*x)*(1-exp(-d2*
x))*exp(-a22*b2*S[2]/d2*(1-exp(-d2*x))-a21*b1*S[1]/d1*(1-exp(-d1*x)))}

#defining equation we would like to solve
intfun1<- function(S) {integrate(function(x) integrand1(x,
S),lower=0,upper=Inf)[[1]]-1}
intfun2<- function(S) {integrate(function(x) integrand2(x,
S),lower=0,upper=Inf)[[1]]-1}

#putting both equations into one term
model <- function(S) c(F1 = intfun1,F2 = intfun2)

#Solving for roots
(ss <-multiroot(f=model, start=c(0,0)))
```

This gives me the error Error in stode(y, times, func, parms = parms, ...) :
  REAL() can only be applied to a 'numeric', not a 'list'

However this simpler example works fine:

```{r}
#Defining the functions
model <- function(x) c(F1 = x[1]+ 4*x[2] -8,F2 = x[1]-4*x[2])

#Solving for the roots
(ss <- multiroot(f = model, start = c(0,0)))
```

Giving me the required x_1= 4 and x_2 =1.

I was given some code to perform a least squares analysis on the same
system but I neither understand the code, nor believe that it is doing what
I am looking for as different initial values give wildly different S values.

```{r}
a11 <- 1 #alpha_{11}
a12 <- 1 #alpha_{12}
a21 <- 1 #alpha_{21}
a22 <- 1 #alpha_{22}
b1 <- 2  #beta1
b2 <- 2 #beta2
d1 <- 1 #delta1
d2 <- 1 #delta2
g <- 0.5 #gamma


integrand1 <- function(x,S) {b1*g/d1*exp(-g*x)*(1-exp(-d1*
x))*exp(-a11*b1*S[1]/d1*(1-exp(-d1*x))-a12*b2*S[2]/d2*(1-exp(-d2*x)))}
integrand2 <- function(x,S) {b2*g/d2*exp(-g*x)*(1-exp(-d2*
x))*exp(-a22*b2*S[2]/d2*(1-exp(-d2*x))-a21*b1*S[1]/d1*(1-exp(-d1*x)))}

#defining equation we would like to solve
intfun1<- function(S) {integrate(function(x)integrand1(x,
S),lower=0,upper=Inf)[[1]]-1}
intfun2<- function(S) {integrate(function(x)integrand2(x,
S),lower=0,upper=Inf)[[1]]-1}

#putting both equations into one term
model <- function(S) if(any(S<0))NA else intfun1(S)**2+ intfun2(S)**2

#Solving for roots
optim(c(0,0), model)
```

I appreciate any tips/help as I have been struggling with this for some
weeks now.
thank you,
-- 
Ursula
Ph.D. student, University of Michigan
Applied and Interdisciplinary Mathematics
utrigos at umich.edu

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu May  6 00:59:57 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 6 May 2021 10:59:57 +1200
Subject: [R] Package "hse" has been REPLACED by package "dbd".
In-Reply-To: <CAB8pepwF_gCauek2wL+XE2uGD9JT3w3m3F9DKY8m-h4PwOM1zg@mail.gmail.com>
References: <20210501103840.651431b6@rolf-Latitude-E7470>
 <CAB8pepwF_gCauek2wL+XE2uGD9JT3w3m3F9DKY8m-h4PwOM1zg@mail.gmail.com>
Message-ID: <20210506105957.4e66b647@rolf-Latitude-E7470>


On Mon, 3 May 2021 12:42:30 +1200
Abbs Spurdle <spurdle.a at gmail.com> wrote:

> Previously, I disliked some of R's names.
> e.g. Action of the Toes.
> But then later realized toes are really important.
> 
> I don't want to disagree with a 'reviewer'.
> But I would say subtle references to literature and philosophy
> demonstrate 'depth'.

Well, I thought so too. :-)  OTOH I recognise that I have a tendency to
be flippant, and perhaps it is just as well to curb this tendency.

> Was your reviewer a member of the (A)merican (S)tatistical
> (S)ociety...? Who came up with that name...?

Isn't it called the 'American Statistical *Association*"?  (Presumably
just so as to avoid that unfortunate acronym.)

I of course have no idea who the (anonymous) reviewer is.

> It's all subjective really...

Or a matter of taste.  And (as my late older brother was fond of
saying) there is no accounting for taste, or the lack thereof. :-)

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From @purd|e@@ @end|ng |rom gm@||@com  Thu May  6 10:39:00 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abbs Spurdle)
Date: Thu, 6 May 2021 20:39:00 +1200
Subject: [R] solving integral equations with undefined parameters using
 multiroot
In-Reply-To: <CANSXP2RHWd7CkRMOCb8n5Nm2ei5LHyzUBhTsTjdsCH+hq6Ac-w@mail.gmail.com>
References: <CANSXP2RHWd7CkRMOCb8n5Nm2ei5LHyzUBhTsTjdsCH+hq6Ac-w@mail.gmail.com>
Message-ID: <CAB8pepx-PjtOOP7KT5Z-637+7wnh5-UqgYSvLfimfBh03VWb5Q@mail.gmail.com>

Hi Ursula,

If I'm not mistaken, there's an infinite number of solutions, which
form a straight (or near straight) line.
Refer to the following code, and attached plot.

----begin code---
library (barsurf)
vF1 <- function (u, v)
{   n <- length (u)
    k <- numeric (n)
    for (i in seq_len (n) )
        k [i] <- intfun1 (c (u [i], v [i]) )
    k
}
plotf_cfield (vF1, c (0, 0.2), fb = (-2:2) / 10,
    main="(integral_1 - 1)",
    xlab="S[1]", ylab="S[2]",
    n=40, raster=TRUE, theme="heat", contour.labels=TRUE)
----end code----

I'm not familiar with the RootSolve package.
Nor am I quite sure what you're trying to compute, given the apparent
infinite set of solutions.

So, for now at least, I'll leave comments on the root finding to someone who is.


Abby


On Thu, May 6, 2021 at 8:46 AM Ursula Trigos-Raczkowski
<utrigos at umich.edu> wrote:
>
> Hello,
> I am trying to solve a system of integral equations using multiroot. I have
> tried asking on stack exchange and reddit without any luck.
> Multiroot uses the library(RootSolve).
>
> I have two integral equations involving constants S[1] and S[2] (which are
> free.) I would like to find what *positive* values of S[1] and S[2] make
> the resulting
> (Integrals-1) = 0.
> (I know that the way I have the parameters set up the equations are very
> similar but I am interested in changing the parameters once I have the code
> working.)
> My attempt at code:
>
> ```{r}
> a11 <- 1 #alpha_{11}
> a12 <- 1 #alpha_{12}
> a21 <- 1 #alpha_{21}
> a22 <- 1 #alpha_{22}
> b1 <- 2  #beta1
> b2 <- 2 #beta2
> d1 <- 1 #delta1
> d2 <- 1 #delta2
> g <- 0.5 #gamma
>
>
> integrand1 <- function(x,S) {b1*g/d1*exp(-g*x)*(1-exp(-d1*
> x))*exp(-a11*b1*S[1]/d1*(1-exp(-d1*x))-a12*b2*S[2]/d2*(1-exp(-d2*x)))}
> integrand2 <- function(x,S) {b2*g/d2*exp(-g*x)*(1-exp(-d2*
> x))*exp(-a22*b2*S[2]/d2*(1-exp(-d2*x))-a21*b1*S[1]/d1*(1-exp(-d1*x)))}
>
> #defining equation we would like to solve
> intfun1<- function(S) {integrate(function(x) integrand1(x,
> S),lower=0,upper=Inf)[[1]]-1}
> intfun2<- function(S) {integrate(function(x) integrand2(x,
> S),lower=0,upper=Inf)[[1]]-1}
>
> #putting both equations into one term
> model <- function(S) c(F1 = intfun1,F2 = intfun2)
>
> #Solving for roots
> (ss <-multiroot(f=model, start=c(0,0)))
> ```
>
> This gives me the error Error in stode(y, times, func, parms = parms, ...) :
>   REAL() can only be applied to a 'numeric', not a 'list'
>
> However this simpler example works fine:
>
> ```{r}
> #Defining the functions
> model <- function(x) c(F1 = x[1]+ 4*x[2] -8,F2 = x[1]-4*x[2])
>
> #Solving for the roots
> (ss <- multiroot(f = model, start = c(0,0)))
> ```
>
> Giving me the required x_1= 4 and x_2 =1.
>
> I was given some code to perform a least squares analysis on the same
> system but I neither understand the code, nor believe that it is doing what
> I am looking for as different initial values give wildly different S values.
>
> ```{r}
> a11 <- 1 #alpha_{11}
> a12 <- 1 #alpha_{12}
> a21 <- 1 #alpha_{21}
> a22 <- 1 #alpha_{22}
> b1 <- 2  #beta1
> b2 <- 2 #beta2
> d1 <- 1 #delta1
> d2 <- 1 #delta2
> g <- 0.5 #gamma
>
>
> integrand1 <- function(x,S) {b1*g/d1*exp(-g*x)*(1-exp(-d1*
> x))*exp(-a11*b1*S[1]/d1*(1-exp(-d1*x))-a12*b2*S[2]/d2*(1-exp(-d2*x)))}
> integrand2 <- function(x,S) {b2*g/d2*exp(-g*x)*(1-exp(-d2*
> x))*exp(-a22*b2*S[2]/d2*(1-exp(-d2*x))-a21*b1*S[1]/d1*(1-exp(-d1*x)))}
>
> #defining equation we would like to solve
> intfun1<- function(S) {integrate(function(x)integrand1(x,
> S),lower=0,upper=Inf)[[1]]-1}
> intfun2<- function(S) {integrate(function(x)integrand2(x,
> S),lower=0,upper=Inf)[[1]]-1}
>
> #putting both equations into one term
> model <- function(S) if(any(S<0))NA else intfun1(S)**2+ intfun2(S)**2
>
> #Solving for roots
> optim(c(0,0), model)
> ```
>
> I appreciate any tips/help as I have been struggling with this for some
> weeks now.
> thank you,
> --
> Ursula
> Ph.D. student, University of Michigan
> Applied and Interdisciplinary Mathematics
> utrigos at umich.edu
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: solution.png
Type: image/png
Size: 36474 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210506/561a8bc4/attachment.png>

From @purd|e@@ @end|ng |rom gm@||@com  Thu May  6 11:27:07 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abbs Spurdle)
Date: Thu, 6 May 2021 21:27:07 +1200
Subject: [R] solving integral equations with undefined parameters using
 multiroot
In-Reply-To: <CAB8pepx-PjtOOP7KT5Z-637+7wnh5-UqgYSvLfimfBh03VWb5Q@mail.gmail.com>
References: <CANSXP2RHWd7CkRMOCb8n5Nm2ei5LHyzUBhTsTjdsCH+hq6Ac-w@mail.gmail.com>
 <CAB8pepx-PjtOOP7KT5Z-637+7wnh5-UqgYSvLfimfBh03VWb5Q@mail.gmail.com>
Message-ID: <CAB8pepwP_H88QVZ7Jn858nfKdzFEvG_iQLh1DRhMmnBtJL+XcA@mail.gmail.com>

Just realized five minutes after posting that I misinterpreted your
question, slightly.
However, after comparing the solution sets for *both* equations, I
can't see any obvious difference between the two.
If there is any difference, presumably that difference is extremely small.


On Thu, May 6, 2021 at 8:39 PM Abbs Spurdle <spurdle.a at gmail.com> wrote:
>
> Hi Ursula,
>
> If I'm not mistaken, there's an infinite number of solutions, which
> form a straight (or near straight) line.
> Refer to the following code, and attached plot.
>
> ----begin code---
> library (barsurf)
> vF1 <- function (u, v)
> {   n <- length (u)
>     k <- numeric (n)
>     for (i in seq_len (n) )
>         k [i] <- intfun1 (c (u [i], v [i]) )
>     k
> }
> plotf_cfield (vF1, c (0, 0.2), fb = (-2:2) / 10,
>     main="(integral_1 - 1)",
>     xlab="S[1]", ylab="S[2]",
>     n=40, raster=TRUE, theme="heat", contour.labels=TRUE)
> ----end code----
>
> I'm not familiar with the RootSolve package.
> Nor am I quite sure what you're trying to compute, given the apparent
> infinite set of solutions.
>
> So, for now at least, I'll leave comments on the root finding to someone who is.
>
>
> Abby
>
>
> On Thu, May 6, 2021 at 8:46 AM Ursula Trigos-Raczkowski
> <utrigos at umich.edu> wrote:
> >
> > Hello,
> > I am trying to solve a system of integral equations using multiroot. I have
> > tried asking on stack exchange and reddit without any luck.
> > Multiroot uses the library(RootSolve).
> >
> > I have two integral equations involving constants S[1] and S[2] (which are
> > free.) I would like to find what *positive* values of S[1] and S[2] make
> > the resulting
> > (Integrals-1) = 0.
> > (I know that the way I have the parameters set up the equations are very
> > similar but I am interested in changing the parameters once I have the code
> > working.)
> > My attempt at code:
> >
> > ```{r}
> > a11 <- 1 #alpha_{11}
> > a12 <- 1 #alpha_{12}
> > a21 <- 1 #alpha_{21}
> > a22 <- 1 #alpha_{22}
> > b1 <- 2  #beta1
> > b2 <- 2 #beta2
> > d1 <- 1 #delta1
> > d2 <- 1 #delta2
> > g <- 0.5 #gamma
> >
> >
> > integrand1 <- function(x,S) {b1*g/d1*exp(-g*x)*(1-exp(-d1*
> > x))*exp(-a11*b1*S[1]/d1*(1-exp(-d1*x))-a12*b2*S[2]/d2*(1-exp(-d2*x)))}
> > integrand2 <- function(x,S) {b2*g/d2*exp(-g*x)*(1-exp(-d2*
> > x))*exp(-a22*b2*S[2]/d2*(1-exp(-d2*x))-a21*b1*S[1]/d1*(1-exp(-d1*x)))}
> >
> > #defining equation we would like to solve
> > intfun1<- function(S) {integrate(function(x) integrand1(x,
> > S),lower=0,upper=Inf)[[1]]-1}
> > intfun2<- function(S) {integrate(function(x) integrand2(x,
> > S),lower=0,upper=Inf)[[1]]-1}
> >
> > #putting both equations into one term
> > model <- function(S) c(F1 = intfun1,F2 = intfun2)
> >
> > #Solving for roots
> > (ss <-multiroot(f=model, start=c(0,0)))
> > ```
> >
> > This gives me the error Error in stode(y, times, func, parms = parms, ...) :
> >   REAL() can only be applied to a 'numeric', not a 'list'
> >
> > However this simpler example works fine:
> >
> > ```{r}
> > #Defining the functions
> > model <- function(x) c(F1 = x[1]+ 4*x[2] -8,F2 = x[1]-4*x[2])
> >
> > #Solving for the roots
> > (ss <- multiroot(f = model, start = c(0,0)))
> > ```
> >
> > Giving me the required x_1= 4 and x_2 =1.
> >
> > I was given some code to perform a least squares analysis on the same
> > system but I neither understand the code, nor believe that it is doing what
> > I am looking for as different initial values give wildly different S values.
> >
> > ```{r}
> > a11 <- 1 #alpha_{11}
> > a12 <- 1 #alpha_{12}
> > a21 <- 1 #alpha_{21}
> > a22 <- 1 #alpha_{22}
> > b1 <- 2  #beta1
> > b2 <- 2 #beta2
> > d1 <- 1 #delta1
> > d2 <- 1 #delta2
> > g <- 0.5 #gamma
> >
> >
> > integrand1 <- function(x,S) {b1*g/d1*exp(-g*x)*(1-exp(-d1*
> > x))*exp(-a11*b1*S[1]/d1*(1-exp(-d1*x))-a12*b2*S[2]/d2*(1-exp(-d2*x)))}
> > integrand2 <- function(x,S) {b2*g/d2*exp(-g*x)*(1-exp(-d2*
> > x))*exp(-a22*b2*S[2]/d2*(1-exp(-d2*x))-a21*b1*S[1]/d1*(1-exp(-d1*x)))}
> >
> > #defining equation we would like to solve
> > intfun1<- function(S) {integrate(function(x)integrand1(x,
> > S),lower=0,upper=Inf)[[1]]-1}
> > intfun2<- function(S) {integrate(function(x)integrand2(x,
> > S),lower=0,upper=Inf)[[1]]-1}
> >
> > #putting both equations into one term
> > model <- function(S) if(any(S<0))NA else intfun1(S)**2+ intfun2(S)**2
> >
> > #Solving for roots
> > optim(c(0,0), model)
> > ```
> >
> > I appreciate any tips/help as I have been struggling with this for some
> > weeks now.
> > thank you,
> > --
> > Ursula
> > Ph.D. student, University of Michigan
> > Applied and Interdisciplinary Mathematics
> > utrigos at umich.edu
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From utr|go@ @end|ng |rom um|ch@edu  Thu May  6 12:17:48 2021
From: utr|go@ @end|ng |rom um|ch@edu (Ursula Trigos-Raczkowski)
Date: Thu, 6 May 2021 06:17:48 -0400
Subject: [R] solving integral equations with undefined parameters using
 multiroot
In-Reply-To: <CAB8pepwP_H88QVZ7Jn858nfKdzFEvG_iQLh1DRhMmnBtJL+XcA@mail.gmail.com>
References: <CANSXP2RHWd7CkRMOCb8n5Nm2ei5LHyzUBhTsTjdsCH+hq6Ac-w@mail.gmail.com>
 <CAB8pepx-PjtOOP7KT5Z-637+7wnh5-UqgYSvLfimfBh03VWb5Q@mail.gmail.com>
 <CAB8pepwP_H88QVZ7Jn858nfKdzFEvG_iQLh1DRhMmnBtJL+XcA@mail.gmail.com>
Message-ID: <CANSXP2RQDf-bnEjDU6m4+vu9m3XyDfCPYamRYvqL8NhQEkrD3Q@mail.gmail.com>

Thanks for your reply. Unfortunately the code doesn't work even when I
change the parameters to ensure I have "different" equations.
Using mathematica I do see that my two equations form planes, intersecting
in a line of infinite solutions but it is not very accurate, I was hoping R
would be more accurate and tell me what this line is, or at least a set of
solutions.

On Thu, May 6, 2021 at 5:28 AM Abbs Spurdle <spurdle.a at gmail.com> wrote:

> Just realized five minutes after posting that I misinterpreted your
> question, slightly.
> However, after comparing the solution sets for *both* equations, I
> can't see any obvious difference between the two.
> If there is any difference, presumably that difference is extremely small.
>
>
> On Thu, May 6, 2021 at 8:39 PM Abbs Spurdle <spurdle.a at gmail.com> wrote:
> >
> > Hi Ursula,
> >
> > If I'm not mistaken, there's an infinite number of solutions, which
> > form a straight (or near straight) line.
> > Refer to the following code, and attached plot.
> >
> > ----begin code---
> > library (barsurf)
> > vF1 <- function (u, v)
> > {   n <- length (u)
> >     k <- numeric (n)
> >     for (i in seq_len (n) )
> >         k [i] <- intfun1 (c (u [i], v [i]) )
> >     k
> > }
> > plotf_cfield (vF1, c (0, 0.2), fb = (-2:2) / 10,
> >     main="(integral_1 - 1)",
> >     xlab="S[1]", ylab="S[2]",
> >     n=40, raster=TRUE, theme="heat", contour.labels=TRUE)
> > ----end code----
> >
> > I'm not familiar with the RootSolve package.
> > Nor am I quite sure what you're trying to compute, given the apparent
> > infinite set of solutions.
> >
> > So, for now at least, I'll leave comments on the root finding to someone
> who is.
> >
> >
> > Abby
> >
> >
> > On Thu, May 6, 2021 at 8:46 AM Ursula Trigos-Raczkowski
> > <utrigos at umich.edu> wrote:
> > >
> > > Hello,
> > > I am trying to solve a system of integral equations using multiroot. I
> have
> > > tried asking on stack exchange and reddit without any luck.
> > > Multiroot uses the library(RootSolve).
> > >
> > > I have two integral equations involving constants S[1] and S[2] (which
> are
> > > free.) I would like to find what *positive* values of S[1] and S[2]
> make
> > > the resulting
> > > (Integrals-1) = 0.
> > > (I know that the way I have the parameters set up the equations are
> very
> > > similar but I am interested in changing the parameters once I have the
> code
> > > working.)
> > > My attempt at code:
> > >
> > > ```{r}
> > > a11 <- 1 #alpha_{11}
> > > a12 <- 1 #alpha_{12}
> > > a21 <- 1 #alpha_{21}
> > > a22 <- 1 #alpha_{22}
> > > b1 <- 2  #beta1
> > > b2 <- 2 #beta2
> > > d1 <- 1 #delta1
> > > d2 <- 1 #delta2
> > > g <- 0.5 #gamma
> > >
> > >
> > > integrand1 <- function(x,S) {b1*g/d1*exp(-g*x)*(1-exp(-d1*
> > > x))*exp(-a11*b1*S[1]/d1*(1-exp(-d1*x))-a12*b2*S[2]/d2*(1-exp(-d2*x)))}
> > > integrand2 <- function(x,S) {b2*g/d2*exp(-g*x)*(1-exp(-d2*
> > > x))*exp(-a22*b2*S[2]/d2*(1-exp(-d2*x))-a21*b1*S[1]/d1*(1-exp(-d1*x)))}
> > >
> > > #defining equation we would like to solve
> > > intfun1<- function(S) {integrate(function(x) integrand1(x,
> > > S),lower=0,upper=Inf)[[1]]-1}
> > > intfun2<- function(S) {integrate(function(x) integrand2(x,
> > > S),lower=0,upper=Inf)[[1]]-1}
> > >
> > > #putting both equations into one term
> > > model <- function(S) c(F1 = intfun1,F2 = intfun2)
> > >
> > > #Solving for roots
> > > (ss <-multiroot(f=model, start=c(0,0)))
> > > ```
> > >
> > > This gives me the error Error in stode(y, times, func, parms = parms,
> ...) :
> > >   REAL() can only be applied to a 'numeric', not a 'list'
> > >
> > > However this simpler example works fine:
> > >
> > > ```{r}
> > > #Defining the functions
> > > model <- function(x) c(F1 = x[1]+ 4*x[2] -8,F2 = x[1]-4*x[2])
> > >
> > > #Solving for the roots
> > > (ss <- multiroot(f = model, start = c(0,0)))
> > > ```
> > >
> > > Giving me the required x_1= 4 and x_2 =1.
> > >
> > > I was given some code to perform a least squares analysis on the same
> > > system but I neither understand the code, nor believe that it is doing
> what
> > > I am looking for as different initial values give wildly different S
> values.
> > >
> > > ```{r}
> > > a11 <- 1 #alpha_{11}
> > > a12 <- 1 #alpha_{12}
> > > a21 <- 1 #alpha_{21}
> > > a22 <- 1 #alpha_{22}
> > > b1 <- 2  #beta1
> > > b2 <- 2 #beta2
> > > d1 <- 1 #delta1
> > > d2 <- 1 #delta2
> > > g <- 0.5 #gamma
> > >
> > >
> > > integrand1 <- function(x,S) {b1*g/d1*exp(-g*x)*(1-exp(-d1*
> > > x))*exp(-a11*b1*S[1]/d1*(1-exp(-d1*x))-a12*b2*S[2]/d2*(1-exp(-d2*x)))}
> > > integrand2 <- function(x,S) {b2*g/d2*exp(-g*x)*(1-exp(-d2*
> > > x))*exp(-a22*b2*S[2]/d2*(1-exp(-d2*x))-a21*b1*S[1]/d1*(1-exp(-d1*x)))}
> > >
> > > #defining equation we would like to solve
> > > intfun1<- function(S) {integrate(function(x)integrand1(x,
> > > S),lower=0,upper=Inf)[[1]]-1}
> > > intfun2<- function(S) {integrate(function(x)integrand2(x,
> > > S),lower=0,upper=Inf)[[1]]-1}
> > >
> > > #putting both equations into one term
> > > model <- function(S) if(any(S<0))NA else intfun1(S)**2+ intfun2(S)**2
> > >
> > > #Solving for roots
> > > optim(c(0,0), model)
> > > ```
> > >
> > > I appreciate any tips/help as I have been struggling with this for some
> > > weeks now.
> > > thank you,
> > > --
> > > Ursula
> > > Ph.D. student, University of Michigan
> > > Applied and Interdisciplinary Mathematics
> > > utrigos at umich.edu
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
>


-- 
Ursula Trigos-Raczkowski (she/her/hers)
Ph.D. student, University of Michigan
Applied and Interdisciplinary Mathematics
5828 East Hall
530 Church St.
Ann Arbor, MI 48109-1085
utrigos at umich.edu

	[[alternative HTML version deleted]]


From meyer@j@me@ @end|ng |rom u@@@net  Thu May  6 13:24:18 2021
From: meyer@j@me@ @end|ng |rom u@@@net (james meyer)
Date: Thu, 06 May 2021 07:24:18 -0400
Subject: [R] calculating area of ellipse
Message-ID: <788ZeFLXs9152Set.1620300258@web07.cms.usa.net>

In doing meta-analysis of diagnostic accuracy I produce ellipses of confidence
and prediction intervals in two dimensions.  How can I calculate the area of
the ellipse in ggplot2 or base R?

thank you
James Meyer


From j|ox @end|ng |rom mcm@@ter@c@  Thu May  6 21:06:45 2021
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Thu, 6 May 2021 15:06:45 -0400
Subject: [R] calculating area of ellipse
In-Reply-To: <14678_1620323470_146Hp9BO009977_788ZeFLXs9152Set.1620300258@web07.cms.usa.net>
References: <14678_1620323470_146Hp9BO009977_788ZeFLXs9152Set.1620300258@web07.cms.usa.net>
Message-ID: <e0ac21ae-5e96-a9ea-21d3-44ce384e10fc@mcmaster.ca>

Dear James,

To mix notation a bit, presumably the (border of the) confidence ellipse 
is of the form (b - beta)'V(b)^-1 (b - beta) = c, where V(b) is the 
covariance matrix of b and c is a constant. Then the area of the ellipse 
is pi*c^2*sqrt(det(V(b))). It shouldn't be hard to translate that into R 
code.

I hope this helps,
  John

John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

On 2021-05-06 7:24 a.m., james meyer wrote:
> In doing meta-analysis of diagnostic accuracy I produce ellipses of confidence
> and prediction intervals in two dimensions.  How can I calculate the area of
> the ellipse in ggplot2 or base R?
> 
> thank you
> James Meyer
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Thu May  6 21:36:50 2021
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Thu, 6 May 2021 14:36:50 -0500
Subject: [R] Transforming data
References: <001401d742af$29a4dfa0$7cee9ee0$.ref@sbcglobal.net>
Message-ID: <001401d742af$29a4dfa0$7cee9ee0$@sbcglobal.net>

R Help Forum

I am attempting to transform the data frame in Table 1 to the form shown in
Table 2. Any suggestions. I?ve started by removing duplicate rows 

 

Jeff

 

 

Table 1


Taxon

Importer


Guarouba guarouba

AE


Acipenser gueldenstaedtii

AE


Caiman crocodilus fuscus

AE


Caiman crocodilus fuscus

AE


Caiman crocodilus fuscus

AE


Ara ararauna

AG


Ara chloropterus

AG


Python reticulatus

AE


Strombus gigas

AE


Strombus gigas

AE


Strombus gigas

AE


Strombus gigas

AE


Strombus gigas

AE


Varanus niloticus

AE


Varanus niloticus

AE


Caiman crocodilus fuscus

AE

 

 

Table 2


Country 

Guarouba guarouba

Acipenser gueldenstaedtii

Caiman crocodilus fuscus

Python reticulatus

Strombus gigas

Varanus niloticus

Caiman crocodilus fuscus

Ara ararauna

Caiman crocodilus fuscus


AE

1

1

1

1

1

1

1

0

0


AG

0

0

0

0

0

0

0

1

1

 


	[[alternative HTML version deleted]]


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Thu May  6 22:13:16 2021
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Thu, 6 May 2021 15:13:16 -0500
Subject: [R] Transforming data
In-Reply-To: <001401d742af$29a4dfa0$7cee9ee0$@sbcglobal.net>
References: <001401d742af$29a4dfa0$7cee9ee0$.ref@sbcglobal.net>
 <001401d742af$29a4dfa0$7cee9ee0$@sbcglobal.net>
Message-ID: <002701d742b4$40243460$c06c9d20$@sbcglobal.net>

R-help

Never mind I figured out a working solution

- remove duplicate
- mutate a new column  == 1
- spread the data from long  to wide
- replace NA with 0's

Not sure it?s the most elegant but gets the gob done


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Reichman
Sent: Thursday, May 6, 2021 2:37 PM
To: R-help at r-project.org
Subject: [R] Transforming data

R Help Forum

I am attempting to transform the data frame in Table 1 to the form shown in Table 2. Any suggestions. I ve started by removing duplicate rows 

 

Jeff

 

 

Table 1


Taxon

Importer


Guarouba guarouba

AE


Acipenser gueldenstaedtii

AE


Caiman crocodilus fuscus

AE


Caiman crocodilus fuscus

AE


Caiman crocodilus fuscus

AE


Ara ararauna

AG


Ara chloropterus

AG


Python reticulatus

AE


Strombus gigas

AE


Strombus gigas

AE


Strombus gigas

AE


Strombus gigas

AE


Strombus gigas

AE


Varanus niloticus

AE


Varanus niloticus

AE


Caiman crocodilus fuscus

AE

 

 

Table 2


Country 

Guarouba guarouba

Acipenser gueldenstaedtii

Caiman crocodilus fuscus

Python reticulatus

Strombus gigas

Varanus niloticus

Caiman crocodilus fuscus

Ara ararauna

Caiman crocodilus fuscus


AE

1

1

1

1

1

1

1

0

0


AG

0

0

0

0

0

0

0

1

1

 


	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu May  6 22:48:55 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 06 May 2021 13:48:55 -0700
Subject: [R] Transforming data
In-Reply-To: <002701d742b4$40243460$c06c9d20$@sbcglobal.net>
References: <001401d742af$29a4dfa0$7cee9ee0$.ref@sbcglobal.net>
 <001401d742af$29a4dfa0$7cee9ee0$@sbcglobal.net>
 <002701d742b4$40243460$c06c9d20$@sbcglobal.net>
Message-ID: <311218FA-DB98-4B7B-84EF-1BD8CF173F59@dcn.davis.ca.us>

Posting HTML email is a good way to reduce your chances of getting a response.

On May 6, 2021 1:13:16 PM PDT, Jeff Reichman <reichmanj at sbcglobal.net> wrote:
>R-help
>
>Never mind I figured out a working solution
>
>- remove duplicate
>- mutate a new column  == 1
>- spread the data from long  to wide
>- replace NA with 0's
>
>Not sure it?s the most elegant but gets the gob done
>
>
>-----Original Message-----
>From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Reichman
>Sent: Thursday, May 6, 2021 2:37 PM
>To: R-help at r-project.org
>Subject: [R] Transforming data
>
>R Help Forum
>
>I am attempting to transform the data frame in Table 1 to the form
>shown in Table 2. Any suggestions. I ve started by removing duplicate
>rows 
>
> 
>
>Jeff
>
> 
>
> 
>
>Table 1
>
>
>Taxon
>
>Importer
>
>
>Guarouba guarouba
>
>AE
>
>
>Acipenser gueldenstaedtii
>
>AE
>
>
>Caiman crocodilus fuscus
>
>AE
>
>
>Caiman crocodilus fuscus
>
>AE
>
>
>Caiman crocodilus fuscus
>
>AE
>
>
>Ara ararauna
>
>AG
>
>
>Ara chloropterus
>
>AG
>
>
>Python reticulatus
>
>AE
>
>
>Strombus gigas
>
>AE
>
>
>Strombus gigas
>
>AE
>
>
>Strombus gigas
>
>AE
>
>
>Strombus gigas
>
>AE
>
>
>Strombus gigas
>
>AE
>
>
>Varanus niloticus
>
>AE
>
>
>Varanus niloticus
>
>AE
>
>
>Caiman crocodilus fuscus
>
>AE
>
> 
>
> 
>
>Table 2
>
>
>Country 
>
>Guarouba guarouba
>
>Acipenser gueldenstaedtii
>
>Caiman crocodilus fuscus
>
>Python reticulatus
>
>Strombus gigas
>
>Varanus niloticus
>
>Caiman crocodilus fuscus
>
>Ara ararauna
>
>Caiman crocodilus fuscus
>
>
>AE
>
>1
>
>1
>
>1
>
>1
>
>1
>
>1
>
>1
>
>0
>
>0
>
>
>AG
>
>0
>
>0
>
>0
>
>0
>
>0
>
>0
>
>0
>
>1
>
>1
>
> 
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From c||n|c@|0910 @end|ng |rom gm@||@com  Thu May  6 21:40:56 2021
From: c||n|c@|0910 @end|ng |rom gm@||@com (Ahmad Raza)
Date: Thu, 6 May 2021 23:40:56 +0400
Subject: [R] Analysing data with repeated measure variable
Message-ID: <CANSYM40wKq0c9Vp6PyCAZJrV-bNH4Xve1vHuYq1knC+SQyWS3g@mail.gmail.com>

Dear Experts,
Greetings

I have the following type of repeated measures data (table 1), and events
data in table 2 (single measure). I want to perform the following tasks (in
R or excel sheet please).

   - To filter subjects who had any response at least 3 days.
   - Response should be > 5 in each day.
   - Then table 1 should have another column, date first response recorded.
   - Then both tables should be merged

Table 1 ? Response Data

Sub_No    Response     Date1          5          01-Jan1          5
      02-Jan2          5          01-Jan2          10         02-Jan2
        10         03-Jan2          10         04-Jan2          10
    05-Jan3          10         01-Jan3          10         02-Jan3
      10         03-Jan4          5          01-Jan4          5
  02-Jan4          10         03-Jan4          10         04-Jan4
    10         05-Jan


Table 2 ? Event Data

Sub_No   Response        Date1          No2         Yes          30
Jan3         Yes          29 Jan4          No

Thanks for your help.
Regards,

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri May  7 00:07:01 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 6 May 2021 15:07:01 -0700
Subject: [R] Analysing data with repeated measure variable
In-Reply-To: <CANSYM40wKq0c9Vp6PyCAZJrV-bNH4Xve1vHuYq1knC+SQyWS3g@mail.gmail.com>
References: <CANSYM40wKq0c9Vp6PyCAZJrV-bNH4Xve1vHuYq1knC+SQyWS3g@mail.gmail.com>
Message-ID: <CAGxFJbQ_tzaO7en8xV++SpT8P8_rOEARQ4J29GTfRWEDU8C=VA@mail.gmail.com>

This looks like homework. We don't do homework on this list.

To see what is done here, read and follow the posting guide linked below.
If not homework, I think it is still very much out of  bounds anyway, as
you appear to be asking us to do your work for you.

On Thu, May 6, 2021, 2:32 PM Ahmad Raza <clinical0910 at gmail.com> wrote:

> Dear Experts,
> Greetings
>
> I have the following type of repeated measures data (table 1), and events
> data in table 2 (single measure). I want to perform the following tasks (in
> R or excel sheet please).
>
>    - To filter subjects who had any response at least 3 days.
>    - Response should be > 5 in each day.
>    - Then table 1 should have another column, date first response recorded.
>    - Then both tables should be merged
>
> Table 1 ? Response Data
>
> Sub_No    Response     Date1          5          01-Jan1          5
>       02-Jan2          5          01-Jan2          10         02-Jan2
>         10         03-Jan2          10         04-Jan2          10
>     05-Jan3          10         01-Jan3          10         02-Jan3
>       10         03-Jan4          5          01-Jan4          5
>   02-Jan4          10         03-Jan4          10         04-Jan4
>     10         05-Jan
>
>
> Table 2 ? Event Data
>
> Sub_No   Response        Date1          No2         Yes          30
> Jan3         Yes          29 Jan4          No
>
> Thanks for your help.
> Regards,
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Fri May  7 03:29:42 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 7 May 2021 11:29:42 +1000
Subject: [R] calculating area of ellipse
In-Reply-To: <788ZeFLXs9152Set.1620300258@web07.cms.usa.net>
References: <788ZeFLXs9152Set.1620300258@web07.cms.usa.net>
Message-ID: <CA+8X3fWb1vamG21m09SLZnbytOmE3HeVaGTC0CqWdZ+ShFF47A@mail.gmail.com>

Hi James,
If the result contains the major (a) and minor (b) axes of the
ellipse, it's easy:

area<-pi*a*b

try using str() on the result you get.

Jim

On Fri, May 7, 2021 at 3:51 AM james meyer <meyer.james at usa.net> wrote:
>
> In doing meta-analysis of diagnostic accuracy I produce ellipses of confidence
> and prediction intervals in two dimensions.  How can I calculate the area of
> the ellipse in ggplot2 or base R?
>
> thank you
> James Meyer
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @purd|e@@ @end|ng |rom gm@||@com  Fri May  7 03:56:40 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abbs Spurdle)
Date: Fri, 7 May 2021 13:56:40 +1200
Subject: [R] solving integral equations with undefined parameters using
 multiroot
In-Reply-To: <CANSXP2RQDf-bnEjDU6m4+vu9m3XyDfCPYamRYvqL8NhQEkrD3Q@mail.gmail.com>
References: <CANSXP2RHWd7CkRMOCb8n5Nm2ei5LHyzUBhTsTjdsCH+hq6Ac-w@mail.gmail.com>
 <CAB8pepx-PjtOOP7KT5Z-637+7wnh5-UqgYSvLfimfBh03VWb5Q@mail.gmail.com>
 <CAB8pepwP_H88QVZ7Jn858nfKdzFEvG_iQLh1DRhMmnBtJL+XcA@mail.gmail.com>
 <CANSXP2RQDf-bnEjDU6m4+vu9m3XyDfCPYamRYvqL8NhQEkrD3Q@mail.gmail.com>
Message-ID: <CAB8pepxdSrSY=wOZK_ciqif0bXyCSu_9OFcRnxHj=6Cu0D29kQ@mail.gmail.com>

#using vF1 function
#from my previous posts
u <- seq (0, 0.25,, 200)
cl <- contourLines (u, u, outer (u, u, vF1),, 0)[[1]]
plot (cl$x, cl$y, type="l")


On Thu, May 6, 2021 at 10:18 PM Ursula Trigos-Raczkowski
<utrigos at umich.edu> wrote:
>
> Thanks for your reply. Unfortunately the code doesn't work even when I change the parameters to ensure I have "different" equations.
> Using mathematica I do see that my two equations form planes, intersecting in a line of infinite solutions but it is not very accurate, I was hoping R would be more accurate and tell me what this line is, or at least a set of solutions.
>
> On Thu, May 6, 2021 at 5:28 AM Abbs Spurdle <spurdle.a at gmail.com> wrote:
>>
>> Just realized five minutes after posting that I misinterpreted your
>> question, slightly.
>> However, after comparing the solution sets for *both* equations, I
>> can't see any obvious difference between the two.
>> If there is any difference, presumably that difference is extremely small.
>>
>>
>> On Thu, May 6, 2021 at 8:39 PM Abbs Spurdle <spurdle.a at gmail.com> wrote:
>> >
>> > Hi Ursula,
>> >
>> > If I'm not mistaken, there's an infinite number of solutions, which
>> > form a straight (or near straight) line.
>> > Refer to the following code, and attached plot.
>> >
>> > ----begin code---
>> > library (barsurf)
>> > vF1 <- function (u, v)
>> > {   n <- length (u)
>> >     k <- numeric (n)
>> >     for (i in seq_len (n) )
>> >         k [i] <- intfun1 (c (u [i], v [i]) )
>> >     k
>> > }
>> > plotf_cfield (vF1, c (0, 0.2), fb = (-2:2) / 10,
>> >     main="(integral_1 - 1)",
>> >     xlab="S[1]", ylab="S[2]",
>> >     n=40, raster=TRUE, theme="heat", contour.labels=TRUE)
>> > ----end code----
>> >
>> > I'm not familiar with the RootSolve package.
>> > Nor am I quite sure what you're trying to compute, given the apparent
>> > infinite set of solutions.
>> >
>> > So, for now at least, I'll leave comments on the root finding to someone who is.
>> >
>> >
>> > Abby
>> >
>> >
>> > On Thu, May 6, 2021 at 8:46 AM Ursula Trigos-Raczkowski
>> > <utrigos at umich.edu> wrote:
>> > >
>> > > Hello,
>> > > I am trying to solve a system of integral equations using multiroot. I have
>> > > tried asking on stack exchange and reddit without any luck.
>> > > Multiroot uses the library(RootSolve).
>> > >
>> > > I have two integral equations involving constants S[1] and S[2] (which are
>> > > free.) I would like to find what *positive* values of S[1] and S[2] make
>> > > the resulting
>> > > (Integrals-1) = 0.
>> > > (I know that the way I have the parameters set up the equations are very
>> > > similar but I am interested in changing the parameters once I have the code
>> > > working.)
>> > > My attempt at code:
>> > >
>> > > ```{r}
>> > > a11 <- 1 #alpha_{11}
>> > > a12 <- 1 #alpha_{12}
>> > > a21 <- 1 #alpha_{21}
>> > > a22 <- 1 #alpha_{22}
>> > > b1 <- 2  #beta1
>> > > b2 <- 2 #beta2
>> > > d1 <- 1 #delta1
>> > > d2 <- 1 #delta2
>> > > g <- 0.5 #gamma
>> > >
>> > >
>> > > integrand1 <- function(x,S) {b1*g/d1*exp(-g*x)*(1-exp(-d1*
>> > > x))*exp(-a11*b1*S[1]/d1*(1-exp(-d1*x))-a12*b2*S[2]/d2*(1-exp(-d2*x)))}
>> > > integrand2 <- function(x,S) {b2*g/d2*exp(-g*x)*(1-exp(-d2*
>> > > x))*exp(-a22*b2*S[2]/d2*(1-exp(-d2*x))-a21*b1*S[1]/d1*(1-exp(-d1*x)))}
>> > >
>> > > #defining equation we would like to solve
>> > > intfun1<- function(S) {integrate(function(x) integrand1(x,
>> > > S),lower=0,upper=Inf)[[1]]-1}
>> > > intfun2<- function(S) {integrate(function(x) integrand2(x,
>> > > S),lower=0,upper=Inf)[[1]]-1}
>> > >
>> > > #putting both equations into one term
>> > > model <- function(S) c(F1 = intfun1,F2 = intfun2)
>> > >
>> > > #Solving for roots
>> > > (ss <-multiroot(f=model, start=c(0,0)))
>> > > ```
>> > >
>> > > This gives me the error Error in stode(y, times, func, parms = parms, ...) :
>> > >   REAL() can only be applied to a 'numeric', not a 'list'
>> > >
>> > > However this simpler example works fine:
>> > >
>> > > ```{r}
>> > > #Defining the functions
>> > > model <- function(x) c(F1 = x[1]+ 4*x[2] -8,F2 = x[1]-4*x[2])
>> > >
>> > > #Solving for the roots
>> > > (ss <- multiroot(f = model, start = c(0,0)))
>> > > ```
>> > >
>> > > Giving me the required x_1= 4 and x_2 =1.
>> > >
>> > > I was given some code to perform a least squares analysis on the same
>> > > system but I neither understand the code, nor believe that it is doing what
>> > > I am looking for as different initial values give wildly different S values.
>> > >
>> > > ```{r}
>> > > a11 <- 1 #alpha_{11}
>> > > a12 <- 1 #alpha_{12}
>> > > a21 <- 1 #alpha_{21}
>> > > a22 <- 1 #alpha_{22}
>> > > b1 <- 2  #beta1
>> > > b2 <- 2 #beta2
>> > > d1 <- 1 #delta1
>> > > d2 <- 1 #delta2
>> > > g <- 0.5 #gamma
>> > >
>> > >
>> > > integrand1 <- function(x,S) {b1*g/d1*exp(-g*x)*(1-exp(-d1*
>> > > x))*exp(-a11*b1*S[1]/d1*(1-exp(-d1*x))-a12*b2*S[2]/d2*(1-exp(-d2*x)))}
>> > > integrand2 <- function(x,S) {b2*g/d2*exp(-g*x)*(1-exp(-d2*
>> > > x))*exp(-a22*b2*S[2]/d2*(1-exp(-d2*x))-a21*b1*S[1]/d1*(1-exp(-d1*x)))}
>> > >
>> > > #defining equation we would like to solve
>> > > intfun1<- function(S) {integrate(function(x)integrand1(x,
>> > > S),lower=0,upper=Inf)[[1]]-1}
>> > > intfun2<- function(S) {integrate(function(x)integrand2(x,
>> > > S),lower=0,upper=Inf)[[1]]-1}
>> > >
>> > > #putting both equations into one term
>> > > model <- function(S) if(any(S<0))NA else intfun1(S)**2+ intfun2(S)**2
>> > >
>> > > #Solving for roots
>> > > optim(c(0,0), model)
>> > > ```
>> > >
>> > > I appreciate any tips/help as I have been struggling with this for some
>> > > weeks now.
>> > > thank you,
>> > > --
>> > > Ursula
>> > > Ph.D. student, University of Michigan
>> > > Applied and Interdisciplinary Mathematics
>> > > utrigos at umich.edu
>> > >
>> > >         [[alternative HTML version deleted]]
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Ursula Trigos-Raczkowski (she/her/hers)
> Ph.D. student, University of Michigan
> Applied and Interdisciplinary Mathematics
> 5828 East Hall
> 530 Church St.
> Ann Arbor, MI 48109-1085
> utrigos at umich.edu
>


From @purd|e@@ @end|ng |rom gm@||@com  Fri May  7 04:02:16 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abbs Spurdle)
Date: Fri, 7 May 2021 14:02:16 +1200
Subject: [R] solving integral equations with undefined parameters using
 multiroot
In-Reply-To: <CAB8pepxdSrSY=wOZK_ciqif0bXyCSu_9OFcRnxHj=6Cu0D29kQ@mail.gmail.com>
References: <CANSXP2RHWd7CkRMOCb8n5Nm2ei5LHyzUBhTsTjdsCH+hq6Ac-w@mail.gmail.com>
 <CAB8pepx-PjtOOP7KT5Z-637+7wnh5-UqgYSvLfimfBh03VWb5Q@mail.gmail.com>
 <CAB8pepwP_H88QVZ7Jn858nfKdzFEvG_iQLh1DRhMmnBtJL+XcA@mail.gmail.com>
 <CANSXP2RQDf-bnEjDU6m4+vu9m3XyDfCPYamRYvqL8NhQEkrD3Q@mail.gmail.com>
 <CAB8pepxdSrSY=wOZK_ciqif0bXyCSu_9OFcRnxHj=6Cu0D29kQ@mail.gmail.com>
Message-ID: <CAB8pepyWLhROb=-YSqACdfRT0N0e+oixWOrYov0of6MKxXuiCA@mail.gmail.com>

lm (cl$y ~ cl$x)$coef
(Intercept)        cl$x
  0.1817509  -1.0000000


On Fri, May 7, 2021 at 1:56 PM Abbs Spurdle <spurdle.a at gmail.com> wrote:
>
> #using vF1 function
> #from my previous posts
> u <- seq (0, 0.25,, 200)
> cl <- contourLines (u, u, outer (u, u, vF1),, 0)[[1]]
> plot (cl$x, cl$y, type="l")
>
>
> On Thu, May 6, 2021 at 10:18 PM Ursula Trigos-Raczkowski
> <utrigos at umich.edu> wrote:
> >
> > Thanks for your reply. Unfortunately the code doesn't work even when I change the parameters to ensure I have "different" equations.
> > Using mathematica I do see that my two equations form planes, intersecting in a line of infinite solutions but it is not very accurate, I was hoping R would be more accurate and tell me what this line is, or at least a set of solutions.
> >
> > On Thu, May 6, 2021 at 5:28 AM Abbs Spurdle <spurdle.a at gmail.com> wrote:
> >>
> >> Just realized five minutes after posting that I misinterpreted your
> >> question, slightly.
> >> However, after comparing the solution sets for *both* equations, I
> >> can't see any obvious difference between the two.
> >> If there is any difference, presumably that difference is extremely small.
> >>
> >>
> >> On Thu, May 6, 2021 at 8:39 PM Abbs Spurdle <spurdle.a at gmail.com> wrote:
> >> >
> >> > Hi Ursula,
> >> >
> >> > If I'm not mistaken, there's an infinite number of solutions, which
> >> > form a straight (or near straight) line.
> >> > Refer to the following code, and attached plot.
> >> >
> >> > ----begin code---
> >> > library (barsurf)
> >> > vF1 <- function (u, v)
> >> > {   n <- length (u)
> >> >     k <- numeric (n)
> >> >     for (i in seq_len (n) )
> >> >         k [i] <- intfun1 (c (u [i], v [i]) )
> >> >     k
> >> > }
> >> > plotf_cfield (vF1, c (0, 0.2), fb = (-2:2) / 10,
> >> >     main="(integral_1 - 1)",
> >> >     xlab="S[1]", ylab="S[2]",
> >> >     n=40, raster=TRUE, theme="heat", contour.labels=TRUE)
> >> > ----end code----
> >> >
> >> > I'm not familiar with the RootSolve package.
> >> > Nor am I quite sure what you're trying to compute, given the apparent
> >> > infinite set of solutions.
> >> >
> >> > So, for now at least, I'll leave comments on the root finding to someone who is.
> >> >
> >> >
> >> > Abby
> >> >
> >> >
> >> > On Thu, May 6, 2021 at 8:46 AM Ursula Trigos-Raczkowski
> >> > <utrigos at umich.edu> wrote:
> >> > >
> >> > > Hello,
> >> > > I am trying to solve a system of integral equations using multiroot. I have
> >> > > tried asking on stack exchange and reddit without any luck.
> >> > > Multiroot uses the library(RootSolve).
> >> > >
> >> > > I have two integral equations involving constants S[1] and S[2] (which are
> >> > > free.) I would like to find what *positive* values of S[1] and S[2] make
> >> > > the resulting
> >> > > (Integrals-1) = 0.
> >> > > (I know that the way I have the parameters set up the equations are very
> >> > > similar but I am interested in changing the parameters once I have the code
> >> > > working.)
> >> > > My attempt at code:
> >> > >
> >> > > ```{r}
> >> > > a11 <- 1 #alpha_{11}
> >> > > a12 <- 1 #alpha_{12}
> >> > > a21 <- 1 #alpha_{21}
> >> > > a22 <- 1 #alpha_{22}
> >> > > b1 <- 2  #beta1
> >> > > b2 <- 2 #beta2
> >> > > d1 <- 1 #delta1
> >> > > d2 <- 1 #delta2
> >> > > g <- 0.5 #gamma
> >> > >
> >> > >
> >> > > integrand1 <- function(x,S) {b1*g/d1*exp(-g*x)*(1-exp(-d1*
> >> > > x))*exp(-a11*b1*S[1]/d1*(1-exp(-d1*x))-a12*b2*S[2]/d2*(1-exp(-d2*x)))}
> >> > > integrand2 <- function(x,S) {b2*g/d2*exp(-g*x)*(1-exp(-d2*
> >> > > x))*exp(-a22*b2*S[2]/d2*(1-exp(-d2*x))-a21*b1*S[1]/d1*(1-exp(-d1*x)))}
> >> > >
> >> > > #defining equation we would like to solve
> >> > > intfun1<- function(S) {integrate(function(x) integrand1(x,
> >> > > S),lower=0,upper=Inf)[[1]]-1}
> >> > > intfun2<- function(S) {integrate(function(x) integrand2(x,
> >> > > S),lower=0,upper=Inf)[[1]]-1}
> >> > >
> >> > > #putting both equations into one term
> >> > > model <- function(S) c(F1 = intfun1,F2 = intfun2)
> >> > >
> >> > > #Solving for roots
> >> > > (ss <-multiroot(f=model, start=c(0,0)))
> >> > > ```
> >> > >
> >> > > This gives me the error Error in stode(y, times, func, parms = parms, ...) :
> >> > >   REAL() can only be applied to a 'numeric', not a 'list'
> >> > >
> >> > > However this simpler example works fine:
> >> > >
> >> > > ```{r}
> >> > > #Defining the functions
> >> > > model <- function(x) c(F1 = x[1]+ 4*x[2] -8,F2 = x[1]-4*x[2])
> >> > >
> >> > > #Solving for the roots
> >> > > (ss <- multiroot(f = model, start = c(0,0)))
> >> > > ```
> >> > >
> >> > > Giving me the required x_1= 4 and x_2 =1.
> >> > >
> >> > > I was given some code to perform a least squares analysis on the same
> >> > > system but I neither understand the code, nor believe that it is doing what
> >> > > I am looking for as different initial values give wildly different S values.
> >> > >
> >> > > ```{r}
> >> > > a11 <- 1 #alpha_{11}
> >> > > a12 <- 1 #alpha_{12}
> >> > > a21 <- 1 #alpha_{21}
> >> > > a22 <- 1 #alpha_{22}
> >> > > b1 <- 2  #beta1
> >> > > b2 <- 2 #beta2
> >> > > d1 <- 1 #delta1
> >> > > d2 <- 1 #delta2
> >> > > g <- 0.5 #gamma
> >> > >
> >> > >
> >> > > integrand1 <- function(x,S) {b1*g/d1*exp(-g*x)*(1-exp(-d1*
> >> > > x))*exp(-a11*b1*S[1]/d1*(1-exp(-d1*x))-a12*b2*S[2]/d2*(1-exp(-d2*x)))}
> >> > > integrand2 <- function(x,S) {b2*g/d2*exp(-g*x)*(1-exp(-d2*
> >> > > x))*exp(-a22*b2*S[2]/d2*(1-exp(-d2*x))-a21*b1*S[1]/d1*(1-exp(-d1*x)))}
> >> > >
> >> > > #defining equation we would like to solve
> >> > > intfun1<- function(S) {integrate(function(x)integrand1(x,
> >> > > S),lower=0,upper=Inf)[[1]]-1}
> >> > > intfun2<- function(S) {integrate(function(x)integrand2(x,
> >> > > S),lower=0,upper=Inf)[[1]]-1}
> >> > >
> >> > > #putting both equations into one term
> >> > > model <- function(S) if(any(S<0))NA else intfun1(S)**2+ intfun2(S)**2
> >> > >
> >> > > #Solving for roots
> >> > > optim(c(0,0), model)
> >> > > ```
> >> > >
> >> > > I appreciate any tips/help as I have been struggling with this for some
> >> > > weeks now.
> >> > > thank you,
> >> > > --
> >> > > Ursula
> >> > > Ph.D. student, University of Michigan
> >> > > Applied and Interdisciplinary Mathematics
> >> > > utrigos at umich.edu
> >> > >
> >> > >         [[alternative HTML version deleted]]
> >> > >
> >> > > ______________________________________________
> >> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Ursula Trigos-Raczkowski (she/her/hers)
> > Ph.D. student, University of Michigan
> > Applied and Interdisciplinary Mathematics
> > 5828 East Hall
> > 530 Church St.
> > Ann Arbor, MI 48109-1085
> > utrigos at umich.edu
> >


From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri May  7 04:31:50 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Thu, 6 May 2021 19:31:50 -0700
Subject: [R] calculating area of ellipse
In-Reply-To: <CA+8X3fWb1vamG21m09SLZnbytOmE3HeVaGTC0CqWdZ+ShFF47A@mail.gmail.com>
References: <788ZeFLXs9152Set.1620300258@web07.cms.usa.net>
 <CA+8X3fWb1vamG21m09SLZnbytOmE3HeVaGTC0CqWdZ+ShFF47A@mail.gmail.com>
Message-ID: <5b857aca-8940-74fd-13d1-5504057851e6@comcast.net>


On 5/6/21 6:29 PM, Jim Lemon wrote:
> Hi James,
> If the result contains the major (a) and minor (b) axes of the
> ellipse, it's easy:
>
> area<-pi*a*b


ITYM semi-major and semi-minor axes.


-- 

David

>
> try using str() on the result you get.
>
> Jim
>
> On Fri, May 7, 2021 at 3:51 AM james meyer <meyer.james at usa.net> wrote:
>> In doing meta-analysis of diagnostic accuracy I produce ellipses of confidence
>> and prediction intervals in two dimensions.  How can I calculate the area of
>> the ellipse in ggplot2 or base R?
>>
>> thank you
>> James Meyer
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j|ox @end|ng |rom mcm@@ter@c@  Fri May  7 18:15:03 2021
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Fri, 7 May 2021 12:15:03 -0400
Subject: [R] calculating area of ellipse
In-Reply-To: <32731_1620354746_1472UmbU009599_5b857aca-8940-74fd-13d1-5504057851e6@comcast.net>
References: <788ZeFLXs9152Set.1620300258@web07.cms.usa.net>
 <CA+8X3fWb1vamG21m09SLZnbytOmE3HeVaGTC0CqWdZ+ShFF47A@mail.gmail.com>
 <32731_1620354746_1472UmbU009599_5b857aca-8940-74fd-13d1-5504057851e6@comcast.net>
Message-ID: <91e6a5f5-3216-6f9d-871f-7087ce884376@mcmaster.ca>

Dear David and Jim,

As I explained yesterday, a confidence ellipse is based on a quadratic 
form in the inverse of the covariance matrix of the estimated 
coefficients. When the coefficients are uncorrelated, the axes of the 
ellipse are parallel to the parameter axes, and the radii of the ellipse 
are just a constant times the inverses of the standard deviations of the 
coefficients. The constant is typically the square root of twice a 
corresponding quantile (say, 0.95) of an F distribution with 2 numerator 
df, or a quantile of the chi-square distribution with 2 df.

In the more general case, the confidence ellipse is tilted, and the 
radii correspond to the square roots of the eigenvalues of the 
coefficient covariance matrix, again multiplied by a constant. That 
explains the result I gave yesterday based on the determinant of the 
coefficient covariance matrix, which is the product of its eigenvalues.

These results generalize readily to ellipsoids in higher dimensions, and 
to degenerate cases, such as perfectly correlated coefficients.

For more on the statistics of ellipses, see 
<http://euclid.psych.yorku.ca/datavis/papers/ellipses-STS402.pdf>.

Best,
  John

John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

On 2021-05-06 10:31 p.m., David Winsemius wrote:
> 
> On 5/6/21 6:29 PM, Jim Lemon wrote:
>> Hi James,
>> If the result contains the major (a) and minor (b) axes of the
>> ellipse, it's easy:
>>
>> area<-pi*a*b
> 
> 
> ITYM semi-major and semi-minor axes.
> 
>


From drj|m|emon @end|ng |rom gm@||@com  Fri May  7 23:34:04 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 8 May 2021 07:34:04 +1000
Subject: [R] calculating area of ellipse
In-Reply-To: <91e6a5f5-3216-6f9d-871f-7087ce884376@mcmaster.ca>
References: <788ZeFLXs9152Set.1620300258@web07.cms.usa.net>
 <CA+8X3fWb1vamG21m09SLZnbytOmE3HeVaGTC0CqWdZ+ShFF47A@mail.gmail.com>
 <32731_1620354746_1472UmbU009599_5b857aca-8940-74fd-13d1-5504057851e6@comcast.net>
 <91e6a5f5-3216-6f9d-871f-7087ce884376@mcmaster.ca>
Message-ID: <CA+8X3fUBL2s=BcHSjVoGo93ePA5MYX8YFkFhSvK2K=38gkpw6g@mail.gmail.com>

Hi John,
Thanks for that. An education for me and my advice to use "str" to
check for the radii in the return value
 was clearly mistaken.

Jim

On Sat, May 8, 2021 at 2:15 AM John Fox <jfox at mcmaster.ca> wrote:
>
> Dear David and Jim,
>
> As I explained yesterday, a confidence ellipse is based on a quadratic
> form in the inverse of the covariance matrix of the estimated
> coefficients. When the coefficients are uncorrelated, the axes of the
> ellipse are parallel to the parameter axes, and the radii of the ellipse
> are just a constant times the inverses of the standard deviations of the
> coefficients. The constant is typically the square root of twice a
> corresponding quantile (say, 0.95) of an F distribution with 2 numerator
> df, or a quantile of the chi-square distribution with 2 df.
>
> In the more general case, the confidence ellipse is tilted, and the
> radii correspond to the square roots of the eigenvalues of the
> coefficient covariance matrix, again multiplied by a constant. That
> explains the result I gave yesterday based on the determinant of the
> coefficient covariance matrix, which is the product of its eigenvalues.
>
> These results generalize readily to ellipsoids in higher dimensions, and
> to degenerate cases, such as perfectly correlated coefficients.
>
> For more on the statistics of ellipses, see
> <http://euclid.psych.yorku.ca/datavis/papers/ellipses-STS402.pdf>.
>
> Best,
>   John
>
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/
>
> On 2021-05-06 10:31 p.m., David Winsemius wrote:
> >
> > On 5/6/21 6:29 PM, Jim Lemon wrote:
> >> Hi James,
> >> If the result contains the major (a) and minor (b) axes of the
> >> ellipse, it's easy:
> >>
> >> area<-pi*a*b
> >
> >
> > ITYM semi-major and semi-minor axes.
> >
> >


From @tyen @end|ng |rom ntu@edu@tw  Sat May  8 19:00:12 2021
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Sun, 9 May 2021 01:00:12 +0800
Subject: [R] grep
Message-ID: <b5f941cd-ce01-b60f-583a-2c7524e9e106@ntu.edu.tw>

Below, the first command simply creates a list of 16 names (labels) 
which can be ignore.

In the 2nd and 3rd commands, I am able to identify names containing "black".

In line 4, I am trying to identify names containing "black" or "conserv" 
but obviously it does not work. Can someone help? Thanks.

 > names<-names(tp.nohs$estimate)[c(1:8,58:65)]; names
 ?[1] "x1.one"????? "x1.black"??? "x1.othrrace" "x1.moddkna" 
"x1.conserv"? "x1.nstrprty"
 ?[7] "x1.strrep"?? "x1.sevngprt" "x2.one"????? "x2.black" "x2.othrrace" 
"x2.moddkna"
[13] "x2.conserv"? "x2.nstrprty" "x2.strrep"?? "x2.sevngprt"
 > grep("black",names,value=TRUE)
[1] "x1.black" "x2.black"
 > grep("black",names,value=FALSE)
[1]? 2 10
 > grep(c("black","conserv"),names,value=TRUE)
[1] "x1.black" "x2.black"
Warning message:
In grep(c("black", "conserv"), names, value = TRUE) :
 ? argument 'pattern' has length > 1 and only the first element will be used


From dw|n@em|u@ @end|ng |rom comc@@t@net  Sat May  8 19:05:00 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sat, 8 May 2021 10:05:00 -0700
Subject: [R] grep
In-Reply-To: <b5f941cd-ce01-b60f-583a-2c7524e9e106@ntu.edu.tw>
References: <b5f941cd-ce01-b60f-583a-2c7524e9e106@ntu.edu.tw>
Message-ID: <cb3cb9a3-f133-d95c-855d-c901b6141d61@comcast.net>


On 5/8/21 10:00 AM, Steven Yen wrote:
> Below, the first command simply creates a list of 16 names (labels) 
> which can be ignore.
>
> In the 2nd and 3rd commands, I am able to identify names containing 
> "black".
>
> In line 4, I am trying to identify names containing "black" or 
> "conserv" but obviously it does not work. Can someone help? Thanks.
>
> > names<-names(tp.nohs$estimate)[c(1:8,58:65)]; names
> ?[1] "x1.one"????? "x1.black"??? "x1.othrrace" "x1.moddkna" 
> "x1.conserv"? "x1.nstrprty"
> ?[7] "x1.strrep"?? "x1.sevngprt" "x2.one"????? "x2.black" 
> "x2.othrrace" "x2.moddkna"
> [13] "x2.conserv"? "x2.nstrprty" "x2.strrep"?? "x2.sevngprt"
> > grep("black",names,value=TRUE)
> [1] "x1.black" "x2.black"
> > grep("black",names,value=FALSE)
> [1]? 2 10
> > grep(c("black","conserv"),names,value=TRUE)
> [1] "x1.black" "x2.black"
> Warning message:
> In grep(c("black", "conserv"), names, value = TRUE) :
> ? argument 'pattern' has length > 1 and only the first element will be 
> used


Try using the logical OR operator (vertical bar, AKA "pipe")

grep(c("black|conserv"), names, value=TRUE)

-- 

David.

>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat May  8 19:20:23 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 08 May 2021 10:20:23 -0700
Subject: [R] grep
In-Reply-To: <b5f941cd-ce01-b60f-583a-2c7524e9e106@ntu.edu.tw>
References: <b5f941cd-ce01-b60f-583a-2c7524e9e106@ntu.edu.tw>
Message-ID: <95812983-6A72-4392-A293-43CF974E3FF7@dcn.davis.ca.us>

Regular expression patterns are not vectorized... only the data to be searched are. Use one of the many websites dedicated to tutoring regular expressions to learn how they work. (Using function names like "names" as data names is bad practice.)

nms <- c( "x1.one", "x1.black", "x1.othrrace", "x1.moddkna", "x1.conserv", "x1.nstrprty", "x1.strrep", "x1.sevngprt", "x2.one", "x2.black", "x2.othrrace", "x2.moddkna", "x2.conserv", "x2.nstrprty", "x2.strrep", "x2.sevngprt" )

grep( "black|conserv", nms, value = TRUE )

On May 8, 2021 10:00:12 AM PDT, Steven Yen <styen at ntu.edu.tw> wrote:
>Below, the first command simply creates a list of 16 names (labels) 
>which can be ignore.
>
>In the 2nd and 3rd commands, I am able to identify names containing
>"black".
>
>In line 4, I am trying to identify names containing "black" or
>"conserv" 
>but obviously it does not work. Can someone help? Thanks.
>
> > names<-names(tp.nohs$estimate)[c(1:8,58:65)]; names
> ?[1] "x1.one"????? "x1.black"??? "x1.othrrace" "x1.moddkna" 
>"x1.conserv"? "x1.nstrprty"
>?[7] "x1.strrep"?? "x1.sevngprt" "x2.one"????? "x2.black" "x2.othrrace"
>
>"x2.moddkna"
>[13] "x2.conserv"? "x2.nstrprty" "x2.strrep"?? "x2.sevngprt"
> > grep("black",names,value=TRUE)
>[1] "x1.black" "x2.black"
> > grep("black",names,value=FALSE)
>[1]? 2 10
> > grep(c("black","conserv"),names,value=TRUE)
>[1] "x1.black" "x2.black"
>Warning message:
>In grep(c("black", "conserv"), names, value = TRUE) :
>? argument 'pattern' has length > 1 and only the first element will be
>used
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat May  8 21:02:32 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 8 May 2021 20:02:32 +0100
Subject: [R] grep
In-Reply-To: <95812983-6A72-4392-A293-43CF974E3FF7@dcn.davis.ca.us>
References: <b5f941cd-ce01-b60f-583a-2c7524e9e106@ntu.edu.tw>
 <95812983-6A72-4392-A293-43CF974E3FF7@dcn.davis.ca.us>
Message-ID: <2e7f26fa-cfc1-d3c8-7575-c03c4a32402d@sapo.pt>

Hello,

The pattern can be assembled with paste(., collapse = "|").
With the same vector of names, nms:


words <- c("black","conserv")
pattern <- paste(words, collapse = "|")
grep(pattern = pattern, nms, value = TRUE)
#[1] "x1.black"   "x1.conserv" "x2.black"   "x2.conserv"


Hope this helps,

Rui Barradas

?s 18:20 de 08/05/21, Jeff Newmiller escreveu:
> Regular expression patterns are not vectorized... only the data to be searched are. Use one of the many websites dedicated to tutoring regular expressions to learn how they work. (Using function names like "names" as data names is bad practice.)
> 
> nms <- c( "x1.one", "x1.black", "x1.othrrace", "x1.moddkna", "x1.conserv", "x1.nstrprty", "x1.strrep", "x1.sevngprt", "x2.one", "x2.black", "x2.othrrace", "x2.moddkna", "x2.conserv", "x2.nstrprty", "x2.strrep", "x2.sevngprt" )
> 
> grep( "black|conserv", nms, value = TRUE )
> 
> On May 8, 2021 10:00:12 AM PDT, Steven Yen <styen at ntu.edu.tw> wrote:
>> Below, the first command simply creates a list of 16 names (labels)
>> which can be ignore.
>>
>> In the 2nd and 3rd commands, I am able to identify names containing
>> "black".
>>
>> In line 4, I am trying to identify names containing "black" or
>> "conserv"
>> but obviously it does not work. Can someone help? Thanks.
>>
>>> names<-names(tp.nohs$estimate)[c(1:8,58:65)]; names
>>  ?[1] "x1.one"????? "x1.black"??? "x1.othrrace" "x1.moddkna"
>> "x1.conserv"? "x1.nstrprty"
>>  ?[7] "x1.strrep"?? "x1.sevngprt" "x2.one"????? "x2.black" "x2.othrrace"
>>
>> "x2.moddkna"
>> [13] "x2.conserv"? "x2.nstrprty" "x2.strrep"?? "x2.sevngprt"
>>> grep("black",names,value=TRUE)
>> [1] "x1.black" "x2.black"
>>> grep("black",names,value=FALSE)
>> [1]? 2 10
>>> grep(c("black","conserv"),names,value=TRUE)
>> [1] "x1.black" "x2.black"
>> Warning message:
>> In grep(c("black", "conserv"), names, value = TRUE) :
>>  ? argument 'pattern' has length > 1 and only the first element will be
>> used
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From hyun@ @end|ng |rom @nu@@c@kr  Sat May  8 12:05:12 2021
From: hyun@ @end|ng |rom @nu@@c@kr (Hyun Soo Park)
Date: Sat, 8 May 2021 19:05:12 +0900
Subject: [R] factor analysis of dynamic structure (FADS) for a huge
 time-series data
Message-ID: <CAPwByMzqdjTcQyf1c8sKkqOaQDSq=koT0NmuxQRXfdjwzMZHRw@mail.gmail.com>

Dear R users,

I want to find the latent factors from a kind of time-series data
describing temporal changes of concentration using a factor analysis
technique called 'factor analysis of dynamic structure (FADS).' I learned
how to form the data for the analysis using a proper package embedding
FADS, such as 'fad' package.

The analysis with 'fad' worked and gave me results, but the problem was
raised when the time-series data is vast.

The time-series data extracted from the 3-dimensional matrix (i.e., 3D
image volume of 50 x 50 x 163) repeatedly acquired at 54-time points is
consisted of 50 x 50 x 163 x 54 = 22,005,000 observations. The desired
number of the latent factor (k) is 4. What I got from fad(MATRIX, k) is
following:

Error in fun(A, k, nu, nv, opts, mattype = "matrix") :
  TridiagEigen: eigen decomposition failed

When I resize the matrix smaller into 5 x 5 x 15, it gives me what I wanted
properly.

I found that some resampling methods such as random sampling, data
stratification, etc., could resolve this kind of problem, but I have no
ideas which one could be appropriate.

Please teach me with any ideas and comments.

Thanks in advance,

Park

-- 
*??????, ?????????*
*????:*
(???) +82-31-787-2936
(????) +82-10-8833-2806
*??:* +82-31-787-4018
*???:* hyuns at snu.ac.kr

*Hyun Soo Park, PhD*
*--*
*Research professor*
Department of Nuclear Medicine
Seoul National University Bundang Hospital, Seongnam, Korea
*Telephone:*
(Office) +82-31-787-2936
(Mobile) +82-10-8833-2806
*Fax:* +82-31-787-4018
*email:* hyuns at snu.ac.kr

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat May  8 23:00:42 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 08 May 2021 14:00:42 -0700
Subject: [R] factor analysis of dynamic structure (FADS) for a huge
 time-series data
In-Reply-To: <CAPwByMzqdjTcQyf1c8sKkqOaQDSq=koT0NmuxQRXfdjwzMZHRw@mail.gmail.com>
References: <CAPwByMzqdjTcQyf1c8sKkqOaQDSq=koT0NmuxQRXfdjwzMZHRw@mail.gmail.com>
Message-ID: <59BC5CB2-5AC0-4F34-95B7-48107A7FCB36@dcn.davis.ca.us>

This not being a question about R, but rather about statistics, or possibly about a contributed package, means (per the Posting Guide) that you should be asking in a statistics forum like stats.stackexchange.com or corresponding with the author of the package in question. If you are lucky someone here will have something to offer, but it is not very likely.

On May 8, 2021 3:05:12 AM PDT, Hyun Soo Park <hyuns at snu.ac.kr> wrote:
>Dear R users,
>
>I want to find the latent factors from a kind of time-series data
>describing temporal changes of concentration using a factor analysis
>technique called 'factor analysis of dynamic structure (FADS).' I
>learned
>how to form the data for the analysis using a proper package embedding
>FADS, such as 'fad' package.
>
>The analysis with 'fad' worked and gave me results, but the problem was
>raised when the time-series data is vast.
>
>The time-series data extracted from the 3-dimensional matrix (i.e., 3D
>image volume of 50 x 50 x 163) repeatedly acquired at 54-time points is
>consisted of 50 x 50 x 163 x 54 = 22,005,000 observations. The desired
>number of the latent factor (k) is 4. What I got from fad(MATRIX, k) is
>following:
>
>Error in fun(A, k, nu, nv, opts, mattype = "matrix") :
>  TridiagEigen: eigen decomposition failed
>
>When I resize the matrix smaller into 5 x 5 x 15, it gives me what I
>wanted
>properly.
>
>I found that some resampling methods such as random sampling, data
>stratification, etc., could resolve this kind of problem, but I have no
>ideas which one could be appropriate.
>
>Please teach me with any ideas and comments.
>
>Thanks in advance,
>
>Park

-- 
Sent from my phone. Please excuse my brevity.


From @tyen @end|ng |rom ntu@edu@tw  Sun May  9 03:54:43 2021
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Sun, 9 May 2021 09:54:43 +0800
Subject: [R] grep
In-Reply-To: <2e7f26fa-cfc1-d3c8-7575-c03c4a32402d@sapo.pt>
References: <b5f941cd-ce01-b60f-583a-2c7524e9e106@ntu.edu.tw>
 <95812983-6A72-4392-A293-43CF974E3FF7@dcn.davis.ca.us>
 <2e7f26fa-cfc1-d3c8-7575-c03c4a32402d@sapo.pt>
Message-ID: <26cf6075-2181-3b40-2b8a-5cc7b7631f17@ntu.edu.tw>

Thank to Rui, Jeff, and Bert. They are all very useful.
Somewhat related is the following, in which jindex is a numeric or 
alphanumeric vector in a function that starts with

try<-function(...., jindex=NA)

In the if loop, in the first line I am trying to determine whether the 
vector jindex is NA;
In the second line, I am trying to determine whether elements in vector 
jindex is are all non-numeric.

Not sure how so I tried to judge by the first element of jindex. Any 
better way? Thannks.

 ? if (!is.na(jindex[1])){?????? # like to improve this line
 ??? if(!is.numeric(jindex)[1]){ # like to improve this line
 ????? words? <-jindex
 ????? pattern<-paste(words,collapse="|")
 ????? jindex <-grep(pattern=pattern,x.label,value=FALSE)
 ??? }
 ??? jj<-jindex; x.label<-x.label[jj]
 ? }

On 2021/5/9 ?? 03:02, Rui Barradas wrote:
> Hello,
>
> The pattern can be assembled with paste(., collapse = "|").
> With the same vector of names, nms:
>
>
> words <- c("black","conserv")
> pattern <- paste(words, collapse = "|")
> grep(pattern = pattern, nms, value = TRUE)
> #[1] "x1.black"?? "x1.conserv" "x2.black"?? "x2.conserv"
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 18:20 de 08/05/21, Jeff Newmiller escreveu:
>> Regular expression patterns are not vectorized... only the data to be 
>> searched are. Use one of the many websites dedicated to tutoring 
>> regular expressions to learn how they work. (Using function names 
>> like "names" as data names is bad practice.)
>>
>> nms <- c( "x1.one", "x1.black", "x1.othrrace", "x1.moddkna", 
>> "x1.conserv", "x1.nstrprty", "x1.strrep", "x1.sevngprt", "x2.one", 
>> "x2.black", "x2.othrrace", "x2.moddkna", "x2.conserv", "x2.nstrprty", 
>> "x2.strrep", "x2.sevngprt" )
>>
>> grep( "black|conserv", nms, value = TRUE )
>>
>> On May 8, 2021 10:00:12 AM PDT, Steven Yen <styen at ntu.edu.tw> wrote:
>>> Below, the first command simply creates a list of 16 names (labels)
>>> which can be ignore.
>>>
>>> In the 2nd and 3rd commands, I am able to identify names containing
>>> "black".
>>>
>>> In line 4, I am trying to identify names containing "black" or
>>> "conserv"
>>> but obviously it does not work. Can someone help? Thanks.
>>>
>>>> names<-names(tp.nohs$estimate)[c(1:8,58:65)]; names
>>> ??[1] "x1.one"????? "x1.black"??? "x1.othrrace" "x1.moddkna"
>>> "x1.conserv"? "x1.nstrprty"
>>> ??[7] "x1.strrep"?? "x1.sevngprt" "x2.one"????? "x2.black" 
>>> "x2.othrrace"
>>>
>>> "x2.moddkna"
>>> [13] "x2.conserv"? "x2.nstrprty" "x2.strrep"?? "x2.sevngprt"
>>>> grep("black",names,value=TRUE)
>>> [1] "x1.black" "x2.black"
>>>> grep("black",names,value=FALSE)
>>> [1]? 2 10
>>>> grep(c("black","conserv"),names,value=TRUE)
>>> [1] "x1.black" "x2.black"
>>> Warning message:
>>> In grep(c("black", "conserv"), names, value = TRUE) :
>>> ?? argument 'pattern' has length > 1 and only the first element will be
>>> used
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>


From m@|tr@ @end|ng |rom em@||@com  Sun May  9 04:28:47 2021
From: m@|tr@ @end|ng |rom em@||@com (Ranjan Maitra)
Date: Sun, 9 May 2021 04:28:47 +0200
Subject: [R] factor analysis of dynamic structure (FADS) for a huge
 time-series data
In-Reply-To: <CAPwByMzqdjTcQyf1c8sKkqOaQDSq=koT0NmuxQRXfdjwzMZHRw@mail.gmail.com>
References: <CAPwByMzqdjTcQyf1c8sKkqOaQDSq=koT0NmuxQRXfdjwzMZHRw@mail.gmail.com>
Message-ID: <trinity-b7063bb7-7fc1-446e-9d63-04017802f369-1620527327464@3c-app-mailcom-lxa11>

I am an author of the paper behind the fad package. I suspect that the call is not correct. Actually, fad does not quite account for time series or other structured data and you have to enter it, as in all general EFA packages as a n x p matrix, with n the number of observations and p the number of coordinates.
 
So, if you can provide a reproducible example, I can look into it, or you can also file an issue on the github site.
 
One thing to note that EFA requires all variances in the dispersion matrix to be positive, and it is possible that your images have some background where there is no activity and hence the sd for those pixel/voxels are zero. 

Of course, ideally, your EFA should account for the image structure, but that is a different topic and not part of fad or any similar package.

Ranjan

PS: I monitor this e-mail address only through this list.
 

?
?
?

Sent:?Saturday, May 08, 2021 at 5:05 AM
From:?"Hyun Soo Park" <hyuns at snu.ac.kr>
To:?"r-help at r-project.org" <r-help at r-project.org>
Subject:?[R] factor analysis of dynamic structure (FADS) for a huge time-series data
Dear R users,

I want to find the latent factors from a kind of time-series data
describing temporal changes of concentration using a factor analysis
technique called 'factor analysis of dynamic structure (FADS).' I learned
how to form the data for the analysis using a proper package embedding
FADS, such as 'fad' package.

The analysis with 'fad' worked and gave me results, but the problem was
raised when the time-series data is vast.

The time-series data extracted from the 3-dimensional matrix (i.e., 3D
image volume of 50 x 50 x 163) repeatedly acquired at 54-time points is
consisted of 50 x 50 x 163 x 54 = 22,005,000 observations. The desired
number of the latent factor (k) is 4. What I got from fad(MATRIX, k) is
following:

Error in fun(A, k, nu, nv, opts, mattype = "matrix") :
TridiagEigen: eigen decomposition failed

When I resize the matrix smaller into 5 x 5 x 15, it gives me what I wanted
properly.

I found that some resampling methods such as random sampling, data
stratification, etc., could resolve this kind of problem, but I have no
ideas which one could be appropriate.

Please teach me with any ideas and comments.

Thanks in advance,

Park

--
*??????, ?????????*
*????:*
(???) +82-31-787-2936
(????) +82-10-8833-2806
*??:* +82-31-787-4018
*???:* hyuns at snu.ac.kr

*Hyun Soo Park, PhD*
*--*
*Research professor*
Department of Nuclear Medicine
Seoul National University Bundang Hospital, Seongnam, Korea
*Telephone:*
(Office) +82-31-787-2936
(Mobile) +82-10-8833-2806
*Fax:* +82-31-787-4018
*email:* hyuns at snu.ac.kr

[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html[http://www.R-project.org/posting-guide.html]
and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun May  9 08:41:17 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 9 May 2021 07:41:17 +0100
Subject: [R] grep
In-Reply-To: <26cf6075-2181-3b40-2b8a-5cc7b7631f17@ntu.edu.tw>
References: <b5f941cd-ce01-b60f-583a-2c7524e9e106@ntu.edu.tw>
 <95812983-6A72-4392-A293-43CF974E3FF7@dcn.davis.ca.us>
 <2e7f26fa-cfc1-d3c8-7575-c03c4a32402d@sapo.pt>
 <26cf6075-2181-3b40-2b8a-5cc7b7631f17@ntu.edu.tw>
Message-ID: <a54e605e-87cb-c15e-9b4f-1035f6b56c87@sapo.pt>

Hello,

Maybe instead of a loop, vectorize with logical indices.


i1 <- is.na(jindex)
i2 <- is.numeric(jindex)
if(any(!i1)){
   if(any(!i2)){
     words <- jindex[!i1 & !i2]
     pattern <- paste(words, collapse = "|")
     jindex <- grep(pattern = pattern, x.label, value = FALSE)
   }
   jj <- jindex[!i1]
   x.label <- x.label[jj]
}


Or even simpler

if(any(!i1 & !i2)){
   words <- jindex[!i1 & !i2]
   pattern <- paste(words, collapse = "|")
   jindex <- grep(pattern = pattern, x.label, value = FALSE)
   jj <- jindex[!i1]
   x.label <- x.label[jj]
}


Hope this helps,

Rui Barradas

?s 02:54 de 09/05/21, Steven Yen escreveu:
> Thank to Rui, Jeff, and Bert. They are all very useful.
> Somewhat related is the following, in which jindex is a numeric or 
> alphanumeric vector in a function that starts with
> 
> try<-function(...., jindex=NA)
> 
> In the if loop, in the first line I am trying to determine whether the 
> vector jindex is NA;
> In the second line, I am trying to determine whether elements in vector 
> jindex is are all non-numeric.
> 
> Not sure how so I tried to judge by the first element of jindex. Any 
> better way? Thannks.
> 
>  ? if (!is.na(jindex[1])){?????? # like to improve this line
>  ??? if(!is.numeric(jindex)[1]){ # like to improve this line
>  ????? words? <-jindex
>  ????? pattern<-paste(words,collapse="|")
>  ????? jindex <-grep(pattern=pattern,x.label,value=FALSE)
>  ??? }
>  ??? jj<-jindex; x.label<-x.label[jj]
>  ? }
> 
> On 2021/5/9 ?? 03:02, Rui Barradas wrote:
>> Hello,
>>
>> The pattern can be assembled with paste(., collapse = "|").
>> With the same vector of names, nms:
>>
>>
>> words <- c("black","conserv")
>> pattern <- paste(words, collapse = "|")
>> grep(pattern = pattern, nms, value = TRUE)
>> #[1] "x1.black"?? "x1.conserv" "x2.black"?? "x2.conserv"
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?s 18:20 de 08/05/21, Jeff Newmiller escreveu:
>>> Regular expression patterns are not vectorized... only the data to be 
>>> searched are. Use one of the many websites dedicated to tutoring 
>>> regular expressions to learn how they work. (Using function names 
>>> like "names" as data names is bad practice.)
>>>
>>> nms <- c( "x1.one", "x1.black", "x1.othrrace", "x1.moddkna", 
>>> "x1.conserv", "x1.nstrprty", "x1.strrep", "x1.sevngprt", "x2.one", 
>>> "x2.black", "x2.othrrace", "x2.moddkna", "x2.conserv", "x2.nstrprty", 
>>> "x2.strrep", "x2.sevngprt" )
>>>
>>> grep( "black|conserv", nms, value = TRUE )
>>>
>>> On May 8, 2021 10:00:12 AM PDT, Steven Yen <styen at ntu.edu.tw> wrote:
>>>> Below, the first command simply creates a list of 16 names (labels)
>>>> which can be ignore.
>>>>
>>>> In the 2nd and 3rd commands, I am able to identify names containing
>>>> "black".
>>>>
>>>> In line 4, I am trying to identify names containing "black" or
>>>> "conserv"
>>>> but obviously it does not work. Can someone help? Thanks.
>>>>
>>>>> names<-names(tp.nohs$estimate)[c(1:8,58:65)]; names
>>>> ??[1] "x1.one"????? "x1.black"??? "x1.othrrace" "x1.moddkna"
>>>> "x1.conserv"? "x1.nstrprty"
>>>> ??[7] "x1.strrep"?? "x1.sevngprt" "x2.one"????? "x2.black" 
>>>> "x2.othrrace"
>>>>
>>>> "x2.moddkna"
>>>> [13] "x2.conserv"? "x2.nstrprty" "x2.strrep"?? "x2.sevngprt"
>>>>> grep("black",names,value=TRUE)
>>>> [1] "x1.black" "x2.black"
>>>>> grep("black",names,value=FALSE)
>>>> [1]? 2 10
>>>>> grep(c("black","conserv"),names,value=TRUE)
>>>> [1] "x1.black" "x2.black"
>>>> Warning message:
>>>> In grep(c("black", "conserv"), names, value = TRUE) :
>>>> ?? argument 'pattern' has length > 1 and only the first element will be
>>>> used
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>


From hyun@ @end|ng |rom @nu@@c@kr  Sun May  9 03:41:43 2021
From: hyun@ @end|ng |rom @nu@@c@kr (Hyun Soo Park)
Date: Sun, 9 May 2021 10:41:43 +0900
Subject: [R] factor analysis of dynamic structure (FADS) for a huge
 time-series data
In-Reply-To: <59BC5CB2-5AC0-4F34-95B7-48107A7FCB36@dcn.davis.ca.us>
References: <CAPwByMzqdjTcQyf1c8sKkqOaQDSq=koT0NmuxQRXfdjwzMZHRw@mail.gmail.com>
 <59BC5CB2-5AC0-4F34-95B7-48107A7FCB36@dcn.davis.ca.us>
Message-ID: <CAPwByMx5xpPip+88D_MFXJyhAE9snw-XhVjtXPEUZL2Rn2wRMg@mail.gmail.com>

Dear Newmiller,

Thank  you for your reply. I?ve just posted the same question in the
another forum for stats as you suggested.

Meanwhile, I would like to keep the question submitted to learn from R
users, if it is available .

Park

On Sun, May 9, 2021 at 6:01 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> This not being a question about R, but rather about statistics, or
> possibly about a contributed package, means (per the Posting Guide) that
> you should be asking in a statistics forum like stats.stackexchange.com
> or corresponding with the author of the package in question. If you are
> lucky someone here will have something to offer, but it is not very likely.
>
> On May 8, 2021 3:05:12 AM PDT, Hyun Soo Park <hyuns at snu.ac.kr> wrote:
> >Dear R users,
> >
> >I want to find the latent factors from a kind of time-series data
> >describing temporal changes of concentration using a factor analysis
> >technique called 'factor analysis of dynamic structure (FADS).' I
> >learned
> >how to form the data for the analysis using a proper package embedding
> >FADS, such as 'fad' package.
> >
> >The analysis with 'fad' worked and gave me results, but the problem was
> >raised when the time-series data is vast.
> >
> >The time-series data extracted from the 3-dimensional matrix (i.e., 3D
> >image volume of 50 x 50 x 163) repeatedly acquired at 54-time points is
> >consisted of 50 x 50 x 163 x 54 = 22,005,000 observations. The desired
> >number of the latent factor (k) is 4. What I got from fad(MATRIX, k) is
> >following:
> >
> >Error in fun(A, k, nu, nv, opts, mattype = "matrix") :
> >  TridiagEigen: eigen decomposition failed
> >
> >When I resize the matrix smaller into 5 x 5 x 15, it gives me what I
> >wanted
> >properly.
> >
> >I found that some resampling methods such as random sampling, data
> >stratification, etc., could resolve this kind of problem, but I have no
> >ideas which one could be appropriate.
> >
> >Please teach me with any ideas and comments.
> >
> >Thanks in advance,
> >
> >Park
>
> --
> Sent from my phone. Please excuse my brevity.
>
-- 
*??????, ?????????*
*????:*
(???) +82-31-787-2936
(????) +82-10-8833-2806
*??:* +82-31-787-4018
*???:* hyuns at snu.ac.kr

*Hyun Soo Park, PhD*
*--*
*Research professor*
Department of Nuclear Medicine
Seoul National University Bundang Hospital, Seongnam, Korea
*Telephone:*
(Office) +82-31-787-2936
(Mobile) +82-10-8833-2806
*Fax:* +82-31-787-4018
*email:* hyuns at snu.ac.kr

	[[alternative HTML version deleted]]


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Sun May  9 20:39:32 2021
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Sun, 9 May 2021 18:39:32 +0000 (UTC)
Subject: [R] No error message but don't get the 8 graphs
References: <294893856.3283193.1620585572644.ref@mail.yahoo.com>
Message-ID: <294893856.3283193.1620585572644@mail.yahoo.com>

Dear R-experts,

I am trying to get the 8 graphs like the ones in this paper : 
https://statweb.stanford.edu/~tibs/reshef/comment.pdf 
My R code does not show any error message neither warnings but I d'on't get what I would like to get (I mean the 8 graphs), so I am missing something. What's it ? Many thanks for your precious help.

#################
set.seed(1)
library(energy) 

# Here we define parameters which we use to simulate the data?
# The number of null datasets we use to estimate our rejection reject #regions for an alternative with level 0.05
nsim=50 

# Number of alternative datasets we use to estimate our power
nsim2=50

# The number of different noise levels used
num.noise <- 30????????????????????

# A constant to determine the amount of noise
noise <- 3? 

# Number of data points per simulation
n=100

# Vectors holding the null "correlations" (for pearson, for spearman, for kendall and dcor respectively) for each # of the nsim null datasets at a #given noise level
val.cor=val.cors=val.cork=val.dcor=rep(NA,nsim)

# Vectors holding the alternative "correlations" (for pearson, for #spearman, for kendall and dcor respectively) #for each of the nsim2 alternative datasets at a given noise level
val.cor2=val.cors2=val.cork2=val.dcor2= rep(NA,nsim2)
?

# Arrays holding the estimated power for each of the 4 "correlation" types, for each data type (linear, #parabolic, etc...) with each noise level
power.cor=power.cors=power.cork=power.dcor= array(NA, c(8,num.noise))

## We loop through the noise level and functional form; each time we #estimate a null distribution based on #the marginals of the data, and then #use that null distribution to estimate power 
## We use a uniformly distributed x, because in the original paper the #authors used the same

for(l in 1:num.noise) {??

????? for(typ in 1:8) {

## This next loop simulates data under the null with the correct marginals (x is uniform, and y is a function of a #uniform with gaussian noise)

??? for(ii in 1:nsim) {?????? 
????? x=runif(n)

#lin+noise??????????????????????????????????????????????????????? 
if(typ==1) {??????? 
y=x+ noise *(l/num.noise)* rnorm(n)??????
}

#parabolic+noise
if(typ==2) {??????? 
y=4*(x-.5)^2+? noise * (l/num.noise) * rnorm(n)????? 
}

#cubic+noise
if(typ==3) {??????? 
y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise? * (l/num.noise) *rnorm(n)????? 
}

#sin+noise
if(typ==4) {??????? 
y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)????? 
}

#their sine + noise
if(typ==5) {??????? 
y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)????? 
}

#x^(1/4) + noise
if(typ==6) {??????? 
y=x^(1/4) + noise * (l/num.noise) *rnorm(n)????? 
}

#circle
if(typ==7) {??????? 
y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise *rnorm(n)????? 
}

#step function
if(typ==8) {??????? 
y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)????? 
}??????

# We resimulate x so that we have the null scenario
x <- runif(n)

# Calculate the 4 correlations????? ??????
val.cor[ii]=(cor(x,y))
val.cors[ii]=(cor(x,y,method=c("spearman")))
val.cork[ii]=(cor(x,y,method=c("kendal")))
val.dcor[ii]=dcor(x,y)??? ?????????
}

## Next we calculate our 4 rejection cutoffs???????? 
cut.cor=quantile(val.cor,.95) ??? 
cut.cors=quantile(val.cors,.95)
cut.cork=quantile(val.cork,.95)
cut.dcor=quantile(val.dcor,.95)

## Next we simulate the data again, this time under the alternative

??? for(ii in 1:nsim2) {?????? 
????? x=runif(n)

#lin+noise??????????????????????????????????????????????????????? 
if(typ==1) {??????? 
y=x+ noise *(l/num.noise)* rnorm(n)????? 
}

#parabolic+noise
if(typ==2) {??????? 
y=4*(x-.5)^2+? noise * (l/num.noise) * rnorm(n)????? 
}

#cubic+noise
if(typ==3) {??????? 
y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise? * (l/num.noise) *rnorm(n)????? 
}

#sin+noise
if(typ==4) {??????? 
y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)????? 
}

#their sine + noise
if(typ==5) {??????? 
y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)????? 
}

#x^(1/4) + noise
if(typ==6) {??????? 
y=x^(1/4) + noise * (l/num.noise) *rnorm(n)????? 
}

#circle
if(typ==7) {??????? 
y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise *rnorm(n)????? 
}

#step function
if(typ==8) {??????? 
y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)????? 
}??????

## We again calculate our 4 "correlations"????????????? 
val.cor2[ii]=(cor(x,y))????? 
val.cors2[ii]=(cor(x,y,method=c("spearman")))
val.cork2[ii]=(cor(x,y,method=c("kendal")))
val.dcor2[ii]=dcor(x,y)?????????????? 
}

## Now we estimate the power as the number of alternative statistics #exceeding our estimated cutoffs???????? 
power.cor[typ,l] <- sum(val.cor2 > cut.cor)/nsim2??? 
power.cors[typ,l] <- sum(val.cors2 > cut.cor)/nsim2
power.cork[typ,l] <- sum(val.cork2 > cut.cor)/nsim2
power.dcor[typ,l] <- sum(val.dcor2 > cut.dcor)/nsim2???????
}
}

save.image()?

## The rest of the code is for plotting the image 
pdf("power.pdf")
par(mfrow = c(4,2), cex = 0.45)
plot((1:30)/10, power.cor[1,], ylim = c(0,1), main = "Linear", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
points((1:30)/10, power.cors[1,], pch = 2, col = "green", type = 'b')
points((1:30)/10, power.cork[1,], pch = 3, col = "blue", type = 'b')
points((1:30)/10, power.dcor[1,], pch = 4, col = "red", type = 'b')
legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))

plot((1:30)/10, power.cor[2,], ylim = c(0,1), main = "Quadratic", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
points((1:30)/10, power.cors[2,], pch = 2, col = "green", type = 'b')
points((1:30)/10, power.cork[2,], pch = 3, col = "blue", type = 'b')
points((1:30)/10, power.dcor[2,], pch = 4, col = "red", type = 'b')
legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))

plot((1:30)/10, power.cor[3,], ylim = c(0,1), main = "Cubic", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
points((1:30)/10, power.cors[3,], pch = 2, col = "green", type = 'b')
points((1:30)/10, power.cork[3,], pch = 3, col = "blue", type = 'b')
points((1:30)/10, power.dcor[3,], pch = 4, col = "red", type = 'b')
legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))

plot((1:30)/10, power.cor[5,], ylim = c(0,1), main = "Sine: period 1/8", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
points((1:30)/10, power.cors[5,], pch = 2, col = "green", type = 'b')
points((1:30)/10, power.cork[5,], pch = 3, col = "blue", type = 'b')
points((1:30)/10, power.dcor[5,], pch = 4, col = "red", type = 'b')
legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))

plot((1:30)/10, power.cor[4,], ylim = c(0,1), main = "Sine: period 1/2", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
points((1:30)/10, power.cors[4,], pch = 2, col = "green", type = 'b')
points((1:30)/10, power.cork[4,], pch = 3, col = "blue", type = 'b')
points((1:30)/10, power.dcor[4,], pch = 4, col = "red", type = 'b')
legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))

plot((1:30)/10, power.cor[6,], ylim = c(0,1), main = "X^(1/4)", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
points((1:30)/10, power.cors[6,], pch = 2, col = "green", type = 'b')
points((1:30)/10, power.cork[6,], pch = 3, col = "blue", type = 'b')
points((1:30)/10, power.dcor[6,], pch = 4, col = "red", type = 'b')
legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))

plot((1:30)/10, power.cor[7,], ylim = c(0,1), main = "Circle", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
points((1:30)/10, power.cors[7,], pch = 2, col = "green", type = 'b')
points((1:30)/10, power.cork[7,], pch = 3, col = "blue", type = 'b')
points((1:30)/10, power.dcor[7,], pch = 4, col = "red", type = 'b')
legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))

plot((1:30)/10, power.cor[8,], ylim = c(0,1), main = "Step function", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
points((1:30)/10, power.cors[8,], pch = 2, col = "green", type = 'b')
points((1:30)/10, power.cork[8,], pch = 3, col = "blue", type = 'b')
points((1:30)/10, power.dcor[8,], pch = 4, col = "red", type = 'b')
legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))

#################


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun May  9 22:44:19 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 9 May 2021 21:44:19 +0100
Subject: [R] No error message but don't get the 8 graphs
In-Reply-To: <294893856.3283193.1620585572644@mail.yahoo.com>
References: <294893856.3283193.1620585572644.ref@mail.yahoo.com>
 <294893856.3283193.1620585572644@mail.yahoo.com>
Message-ID: <b9186679-16a2-d6e4-afac-eecebbba7e01@sapo.pt>

Hello,

You are not closing the pdf device.
The only changes I have made to your code are right at the beginning of 
the plotting instructions and at the end of the code.


## The rest of the code is for plotting the image
pdf(file = "power.pdf")
op <- par(mfrow = c(4,2), cex = 0.45)

[...]

par(op)
dev.off()
#################

The comments only line is your last code line.
The result is attached.

Hope this helps,

Rui Barradas

?s 19:39 de 09/05/21, varin sacha via R-help escreveu:
> Dear R-experts,
> 
> I am trying to get the 8 graphs like the ones in this paper :
> https://statweb.stanford.edu/~tibs/reshef/comment.pdf
> My R code does not show any error message neither warnings but I d'on't get what I would like to get (I mean the 8 graphs), so I am missing something. What's it ? Many thanks for your precious help.
> 
> #################
> set.seed(1)
> library(energy)
> 
> # Here we define parameters which we use to simulate the data
> # The number of null datasets we use to estimate our rejection reject #regions for an alternative with level 0.05
> nsim=50
> 
> # Number of alternative datasets we use to estimate our power
> nsim2=50
> 
> # The number of different noise levels used
> num.noise <- 30
> 
> # A constant to determine the amount of noise
> noise <- 3
> 
> # Number of data points per simulation
> n=100
> 
> # Vectors holding the null "correlations" (for pearson, for spearman, for kendall and dcor respectively) for each # of the nsim null datasets at a #given noise level
> val.cor=val.cors=val.cork=val.dcor=rep(NA,nsim)
> 
> # Vectors holding the alternative "correlations" (for pearson, for #spearman, for kendall and dcor respectively) #for each of the nsim2 alternative datasets at a given noise level
> val.cor2=val.cors2=val.cork2=val.dcor2= rep(NA,nsim2)
>   
> 
> # Arrays holding the estimated power for each of the 4 "correlation" types, for each data type (linear, #parabolic, etc...) with each noise level
> power.cor=power.cors=power.cork=power.dcor= array(NA, c(8,num.noise))
> 
> ## We loop through the noise level and functional form; each time we #estimate a null distribution based on #the marginals of the data, and then #use that null distribution to estimate power
> ## We use a uniformly distributed x, because in the original paper the #authors used the same
> 
> for(l in 1:num.noise) {
> 
>  ????? for(typ in 1:8) {
> 
> ## This next loop simulates data under the null with the correct marginals (x is uniform, and y is a function of a #uniform with gaussian noise)
> 
>  ??? for(ii in 1:nsim) {
>  ????? x=runif(n)
> 
> #lin+noise
> if(typ==1) {
> y=x+ noise *(l/num.noise)* rnorm(n)
> }
> 
> #parabolic+noise
> if(typ==2) {
> y=4*(x-.5)^2+? noise * (l/num.noise) * rnorm(n)
> }
> 
> #cubic+noise
> if(typ==3) {
> y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise? * (l/num.noise) *rnorm(n)
> }
> 
> #sin+noise
> if(typ==4) {
> y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
> }
> 
> #their sine + noise
> if(typ==5) {
> y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
> }
> 
> #x^(1/4) + noise
> if(typ==6) {
> y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
> }
> 
> #circle
> if(typ==7) {
> y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise *rnorm(n)
> }
> 
> #step function
> if(typ==8) {
> y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
> }
> 
> # We resimulate x so that we have the null scenario
> x <- runif(n)
> 
> # Calculate the 4 correlations
> val.cor[ii]=(cor(x,y))
> val.cors[ii]=(cor(x,y,method=c("spearman")))
> val.cork[ii]=(cor(x,y,method=c("kendal")))
> val.dcor[ii]=dcor(x,y)
> }
> 
> ## Next we calculate our 4 rejection cutoffs
> cut.cor=quantile(val.cor,.95)
> cut.cors=quantile(val.cors,.95)
> cut.cork=quantile(val.cork,.95)
> cut.dcor=quantile(val.dcor,.95)
> 
> ## Next we simulate the data again, this time under the alternative
> 
>  ??? for(ii in 1:nsim2) {
>  ????? x=runif(n)
> 
> #lin+noise
> if(typ==1) {
> y=x+ noise *(l/num.noise)* rnorm(n)
> }
> 
> #parabolic+noise
> if(typ==2) {
> y=4*(x-.5)^2+? noise * (l/num.noise) * rnorm(n)
> }
> 
> #cubic+noise
> if(typ==3) {
> y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise? * (l/num.noise) *rnorm(n)
> }
> 
> #sin+noise
> if(typ==4) {
> y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
> }
> 
> #their sine + noise
> if(typ==5) {
> y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
> }
> 
> #x^(1/4) + noise
> if(typ==6) {
> y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
> }
> 
> #circle
> if(typ==7) {
> y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise *rnorm(n)
> }
> 
> #step function
> if(typ==8) {
> y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
> }
> 
> ## We again calculate our 4 "correlations"
> val.cor2[ii]=(cor(x,y))
> val.cors2[ii]=(cor(x,y,method=c("spearman")))
> val.cork2[ii]=(cor(x,y,method=c("kendal")))
> val.dcor2[ii]=dcor(x,y)
> }
> 
> ## Now we estimate the power as the number of alternative statistics #exceeding our estimated cutoffs
> power.cor[typ,l] <- sum(val.cor2 > cut.cor)/nsim2
> power.cors[typ,l] <- sum(val.cors2 > cut.cor)/nsim2
> power.cork[typ,l] <- sum(val.cork2 > cut.cor)/nsim2
> power.dcor[typ,l] <- sum(val.dcor2 > cut.dcor)/nsim2
> }
> }
> 
> save.image()
> 
> ## The rest of the code is for plotting the image
> pdf("power.pdf")
> par(mfrow = c(4,2), cex = 0.45)
> plot((1:30)/10, power.cor[1,], ylim = c(0,1), main = "Linear", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[1,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[1,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[1,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
> 
> plot((1:30)/10, power.cor[2,], ylim = c(0,1), main = "Quadratic", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[2,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[2,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[2,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
> 
> plot((1:30)/10, power.cor[3,], ylim = c(0,1), main = "Cubic", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[3,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[3,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[3,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
> 
> plot((1:30)/10, power.cor[5,], ylim = c(0,1), main = "Sine: period 1/8", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[5,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[5,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[5,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
> 
> plot((1:30)/10, power.cor[4,], ylim = c(0,1), main = "Sine: period 1/2", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[4,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[4,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[4,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
> 
> plot((1:30)/10, power.cor[6,], ylim = c(0,1), main = "X^(1/4)", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[6,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[6,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[6,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
> 
> plot((1:30)/10, power.cor[7,], ylim = c(0,1), main = "Circle", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[7,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[7,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[7,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
> 
> plot((1:30)/10, power.cor[8,], ylim = c(0,1), main = "Step function", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[8,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[8,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[8,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
> 
> #################
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-------------- next part --------------
A non-text attachment was scrubbed...
Name: power.pdf
Type: application/pdf
Size: 44649 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210509/a24b613f/attachment.pdf>

From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Sun May  9 23:27:29 2021
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Sun, 9 May 2021 21:27:29 +0000 (UTC)
Subject: [R] No error message but don't get the 8 graphs
In-Reply-To: <b9186679-16a2-d6e4-afac-eecebbba7e01@sapo.pt>
References: <294893856.3283193.1620585572644.ref@mail.yahoo.com>
 <294893856.3283193.1620585572644@mail.yahoo.com>
 <b9186679-16a2-d6e4-afac-eecebbba7e01@sapo.pt>
Message-ID: <928869154.3343817.1620595649281@mail.yahoo.com>

Dear Rui,

I thank you for your response but when I run the code with your few modifications, I still don't get the 8 graphs but I get the following answer :

null device
????????? 1

Here below my R code with your modifications. I don't know what I am still missing ? 

##############
set.seed(1)
library(energy)

# Here we define parameters which we use to simulate the data 
# The number of null datasets we use to estimate our rejection reject #regions for an alternative with level 0.05
nsim=50 

# Number of alternative datasets we use to estimate our power
nsim2=50

# The number of different noise levels used
num.noise <- 30????????????????????

# A constant to determine the amount of noise
noise <- 3?

# Number of data points per simulation
n=100

# Vectors holding the null "correlations" (for pearson, for spearman, for kendall and dcor respectively) for each # of the nsim null datasets at a #given noise level
val.cor=val.cors=val.cork=val.dcor=rep(NA,nsim)

# Vectors holding the alternative "correlations" (for pearson, for #spearman, for kendall and dcor respectively) #for each of the nsim2 alternative datasets at a given noise level
val.cor2=val.cors2=val.cork2=val.dcor2= rep(NA,nsim2)

# Arrays holding the estimated power for each of the 4 "correlation" types, for each data type (linear, #parabolic, etc...) with each noise level
power.cor=power.cors=power.cork=power.dcor= array(NA, c(8,num.noise))

## We loop through the noise level and functional form; each time we #estimate a null distribution based on #the marginals of the data, and then #use that null distribution to estimate power
## We use a uniformly distributed x, because in the original paper the #authors used the same

for(l in 1:num.noise) {??

????? for(typ in 1:8) {

## This next loop simulates data under the null with the correct marginals (x is uniform, and y is a function of a #uniform with gaussian noise)

??? for(ii in 1:nsim) {????? 
????? x=runif(n)

#lin+noise?????????????????????????????????????????????????????? 
if(typ==1) {?????? 
y=x+ noise *(l/num.noise)* rnorm(n)????? 
}

#parabolic+noise
if(typ==2) {?????? 
y=4*(x-.5)^2+? noise * (l/num.noise) * rnorm(n)???? 
}

#cubic+noise
if(typ==3) {?????? 
y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise? * (l/num.noise) *rnorm(n)???? 
} 

#sin+noise
if(typ==4) {?????? 
y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)???? 
}

#their sine + noise
if(typ==5) {?????? 
y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)???? 
}

#x^(1/4) + noise
if(typ==6) {?????? 
y=x^(1/4) + noise * (l/num.noise) *rnorm(n)???? 
}

#circle
if(typ==7) {?????? 
y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise *rnorm(n)???? 
}

#step function
if(typ==8) {?????? 
y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)???? 
}??????

?
# We resimulate x so that we have the null scenario
x <- runif(n)

# Calculate the 4 correlations????? ????? 
val.cor[ii]=(cor(x,y))
val.cors[ii]=(cor(x,y,method=c("spearman")))
val.cork[ii]=(cor(x,y,method=c("kendal")))
val.dcor[ii]=dcor(x,y)??? ?????????
}

## Next we calculate our 4 rejection cutoffs??????? 
cut.cor=quantile(val.cor,.95) ?? 
cut.cors=quantile(val.cors,.95)
cut.cork=quantile(val.cork,.95)
cut.dcor=quantile(val.dcor,.95)

## Next we simulate the data again, this time under the alternative

??? for(ii in 1:nsim2) {????? 
????? x=runif(n)

#lin+noise?????????????????????????????????????????????????????? 
if(typ==1) {?????? 
y=x+ noise *(l/num.noise)* rnorm(n)???? 
} 

#parabolic+noise
if(typ==2) {?????? 
y=4*(x-.5)^2+? noise * (l/num.noise) * rnorm(n)???? 
}

#cubic+noise
if(typ==3) {?????? 
y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise? * (l/num.noise) *rnorm(n)???? 
}

#sin+noise
if(typ==4) {?????? 
y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)???? 
}

#their sine + noise
if(typ==5) {?????? 
y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)???? 
}

#x^(1/4) + noise
if(typ==6) {?????? 
y=x^(1/4) + noise * (l/num.noise) *rnorm(n)???? 
}

#circle
if(typ==7) {?????? 
y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise *rnorm(n)???? 
}

#step function
if(typ==8) {?????? 
y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)???? 
}??????

## We again calculate our 4 "correlations"???????????? 
val.cor2[ii]=(cor(x,y))???? 
val.cors2[ii]=(cor(x,y,method=c("spearman")))
val.cork2[ii]=(cor(x,y,method=c("kendal")))
val.dcor2[ii]=dcor(x,y)??????????????
}

## Now we estimate the power as the number of alternative statistics #exceeding our estimated cutoffs??????? 
power.cor[typ,l] <- sum(val.cor2 > cut.cor)/nsim2?? 
power.cors[typ,l] <- sum(val.cors2 > cut.cor)/nsim2
power.cork[typ,l] <- sum(val.cork2 > cut.cor)/nsim2
power.dcor[typ,l] <- sum(val.dcor2 > cut.dcor)/nsim2???????
}
}

save.image()?

## The rest of the code is for plotting the image
pdf(file = "power.pdf")
op <- par(mfrow = c(4,2), cex = 0.45)
plot((1:30)/10, power.cor[1,], ylim = c(0,1), main = "Linear", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
points((1:30)/10, power.cors[1,], pch = 2, col = "green", type = 'b')
points((1:30)/10, power.cork[1,], pch = 3, col = "blue", type = 'b')
points((1:30)/10, power.dcor[1,], pch = 4, col = "red", type = 'b')
legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))

?plot((1:30)/10, power.cor[2,], ylim = c(0,1), main = "Quadratic", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
points((1:30)/10, power.cors[2,], pch = 2, col = "green", type = 'b')
points((1:30)/10, power.cork[2,], pch = 3, col = "blue", type = 'b')
points((1:30)/10, power.dcor[2,], pch = 4, col = "red", type = 'b')
legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))

?plot((1:30)/10, power.cor[3,], ylim = c(0,1), main = "Cubic", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
points((1:30)/10, power.cors[3,], pch = 2, col = "green", type = 'b')
points((1:30)/10, power.cork[3,], pch = 3, col = "blue", type = 'b')
points((1:30)/10, power.dcor[3,], pch = 4, col = "red", type = 'b')
legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))

plot((1:30)/10, power.cor[5,], ylim = c(0,1), main = "Sine: period 1/8", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
points((1:30)/10, power.cors[5,], pch = 2, col = "green", type = 'b')
points((1:30)/10, power.cork[5,], pch = 3, col = "blue", type = 'b')
points((1:30)/10, power.dcor[5,], pch = 4, col = "red", type = 'b')
legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))

plot((1:30)/10, power.cor[4,], ylim = c(0,1), main = "Sine: period 1/2", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
points((1:30)/10, power.cors[4,], pch = 2, col = "green", type = 'b')
points((1:30)/10, power.cork[4,], pch = 3, col = "blue", type = 'b')
points((1:30)/10, power.dcor[4,], pch = 4, col = "red", type = 'b')
legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))

plot((1:30)/10, power.cor[6,], ylim = c(0,1), main = "X^(1/4)", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
points((1:30)/10, power.cors[6,], pch = 2, col = "green", type = 'b')
points((1:30)/10, power.cork[6,], pch = 3, col = "blue", type = 'b')
points((1:30)/10, power.dcor[6,], pch = 4, col = "red", type = 'b')
legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))

plot((1:30)/10, power.cor[7,], ylim = c(0,1), main = "Circle", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
points((1:30)/10, power.cors[7,], pch = 2, col = "green", type = 'b')
points((1:30)/10, power.cork[7,], pch = 3, col = "blue", type = 'b')
points((1:30)/10, power.dcor[7,], pch = 4, col = "red", type = 'b')
legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))

plot((1:30)/10, power.cor[8,], ylim = c(0,1), main = "Step function", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
points((1:30)/10, power.cors[8,], pch = 2, col = "green", type = 'b')
points((1:30)/10, power.cork[8,], pch = 3, col = "blue", type = 'b')
points((1:30)/10, power.dcor[8,], pch = 4, col = "red", type = 'b')
legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
par(op)
dev.off()
#################







Le dimanche 9 mai 2021 ? 22:44:22 UTC+2, Rui Barradas <ruipbarradas at sapo.pt> a ?crit : 





Hello,

You are not closing the pdf device.
The only changes I have made to your code are right at the beginning of 
the plotting instructions and at the end of the code.


## The rest of the code is for plotting the image
pdf(file = "power.pdf")
op <- par(mfrow = c(4,2), cex = 0.45)

[...]

par(op)
dev.off()
#################

The comments only line is your last code line.
The result is attached.

Hope this helps,

Rui Barradas

?s 19:39 de 09/05/21, varin sacha via R-help escreveu:
> Dear R-experts,
> 
> I am trying to get the 8 graphs like the ones in this paper :
> https://statweb.stanford.edu/~tibs/reshef/comment.pdf
> My R code does not show any error message neither warnings but I d'on't get what I would like to get (I mean the 8 graphs), so I am missing something. What's it ? Many thanks for your precious help.
> 
> #################
> set.seed(1)
> library(energy)
> 
> # Here we define parameters which we use to simulate the data
> # The number of null datasets we use to estimate our rejection reject #regions for an alternative with level 0.05
> nsim=50
> 
> # Number of alternative datasets we use to estimate our power
> nsim2=50
> 
> # The number of different noise levels used
> num.noise <- 30
> 
> # A constant to determine the amount of noise
> noise <- 3
> 
> # Number of data points per simulation
> n=100
> 
> # Vectors holding the null "correlations" (for pearson, for spearman, for kendall and dcor respectively) for each # of the nsim null datasets at a #given noise level
> val.cor=val.cors=val.cork=val.dcor=rep(NA,nsim)
> 
> # Vectors holding the alternative "correlations" (for pearson, for #spearman, for kendall and dcor respectively) #for each of the nsim2 alternative datasets at a given noise level
> val.cor2=val.cors2=val.cork2=val.dcor2= rep(NA,nsim2)
>? 
> 
> # Arrays holding the estimated power for each of the 4 "correlation" types, for each data type (linear, #parabolic, etc...) with each noise level
> power.cor=power.cors=power.cork=power.dcor= array(NA, c(8,num.noise))
> 
> ## We loop through the noise level and functional form; each time we #estimate a null distribution based on #the marginals of the data, and then #use that null distribution to estimate power
> ## We use a uniformly distributed x, because in the original paper the #authors used the same
> 
> for(l in 1:num.noise) {
> 
>? ????? for(typ in 1:8) {
> 
> ## This next loop simulates data under the null with the correct marginals (x is uniform, and y is a function of a #uniform with gaussian noise)
> 
>? ??? for(ii in 1:nsim) {
>? ????? x=runif(n)
> 
> #lin+noise
> if(typ==1) {
> y=x+ noise *(l/num.noise)* rnorm(n)
> }
> 
> #parabolic+noise
> if(typ==2) {
> y=4*(x-.5)^2+? noise * (l/num.noise) * rnorm(n)
> }
> 
> #cubic+noise
> if(typ==3) {
> y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise? * (l/num.noise) *rnorm(n)
> }
> 
> #sin+noise
> if(typ==4) {
> y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
> }
> 
> #their sine + noise
> if(typ==5) {
> y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
> }
> 
> #x^(1/4) + noise
> if(typ==6) {
> y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
> }
> 
> #circle
> if(typ==7) {
> y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise *rnorm(n)
> }
> 
> #step function
> if(typ==8) {
> y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
> }
> 
> # We resimulate x so that we have the null scenario
> x <- runif(n)
> 
> # Calculate the 4 correlations
> val.cor[ii]=(cor(x,y))
> val.cors[ii]=(cor(x,y,method=c("spearman")))
> val.cork[ii]=(cor(x,y,method=c("kendal")))
> val.dcor[ii]=dcor(x,y)
> }
> 
> ## Next we calculate our 4 rejection cutoffs
> cut.cor=quantile(val.cor,.95)
> cut.cors=quantile(val.cors,.95)
> cut.cork=quantile(val.cork,.95)
> cut.dcor=quantile(val.dcor,.95)
> 
> ## Next we simulate the data again, this time under the alternative
> 
>? ??? for(ii in 1:nsim2) {
>? ????? x=runif(n)
> 
> #lin+noise
> if(typ==1) {
> y=x+ noise *(l/num.noise)* rnorm(n)
> }
> 
> #parabolic+noise
> if(typ==2) {
> y=4*(x-.5)^2+? noise * (l/num.noise) * rnorm(n)
> }
> 
> #cubic+noise
> if(typ==3) {
> y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise? * (l/num.noise) *rnorm(n)
> }
> 
> #sin+noise
> if(typ==4) {
> y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
> }
> 
> #their sine + noise
> if(typ==5) {
> y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
> }
> 
> #x^(1/4) + noise
> if(typ==6) {
> y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
> }
> 
> #circle
> if(typ==7) {
> y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise *rnorm(n)
> }
> 
> #step function
> if(typ==8) {
> y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
> }
> 
> ## We again calculate our 4 "correlations"
> val.cor2[ii]=(cor(x,y))
> val.cors2[ii]=(cor(x,y,method=c("spearman")))
> val.cork2[ii]=(cor(x,y,method=c("kendal")))
> val.dcor2[ii]=dcor(x,y)
> }
> 
> ## Now we estimate the power as the number of alternative statistics #exceeding our estimated cutoffs
> power.cor[typ,l] <- sum(val.cor2 > cut.cor)/nsim2
> power.cors[typ,l] <- sum(val.cors2 > cut.cor)/nsim2
> power.cork[typ,l] <- sum(val.cork2 > cut.cor)/nsim2
> power.dcor[typ,l] <- sum(val.dcor2 > cut.dcor)/nsim2
> }
> }
> 
> save.image()
> 
> ## The rest of the code is for plotting the image
> pdf("power.pdf")
> par(mfrow = c(4,2), cex = 0.45)
> plot((1:30)/10, power.cor[1,], ylim = c(0,1), main = "Linear", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[1,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[1,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[1,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
> 
> plot((1:30)/10, power.cor[2,], ylim = c(0,1), main = "Quadratic", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[2,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[2,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[2,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
> 
> plot((1:30)/10, power.cor[3,], ylim = c(0,1), main = "Cubic", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[3,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[3,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[3,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
> 
> plot((1:30)/10, power.cor[5,], ylim = c(0,1), main = "Sine: period 1/8", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[5,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[5,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[5,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
> 
> plot((1:30)/10, power.cor[4,], ylim = c(0,1), main = "Sine: period 1/2", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[4,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[4,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[4,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
> 
> plot((1:30)/10, power.cor[6,], ylim = c(0,1), main = "X^(1/4)", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[6,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[6,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[6,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
> 
> plot((1:30)/10, power.cor[7,], ylim = c(0,1), main = "Circle", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[7,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[7,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[7,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
> 
> plot((1:30)/10, power.cor[8,], ylim = c(0,1), main = "Step function", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[8,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[8,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[8,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))

> 
> #################
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

> 


From c@nty @end|ng |rom m@th@mcm@@ter@c@  Sun May  9 23:48:50 2021
From: c@nty @end|ng |rom m@th@mcm@@ter@c@ (Angelo Canty)
Date: Sun, 9 May 2021 17:48:50 -0400
Subject: [R] No error message but don't get the 8 graphs
In-Reply-To: <928869154.3343817.1620595649281@mail.yahoo.com>
References: <294893856.3283193.1620585572644.ref@mail.yahoo.com>
 <294893856.3283193.1620585572644@mail.yahoo.com>
 <b9186679-16a2-d6e4-afac-eecebbba7e01@sapo.pt>
 <928869154.3343817.1620595649281@mail.yahoo.com>
Message-ID: <5ba132c7-e604-8c5d-d9c1-2c1335b3bff8@math.mcmaster.ca>

Have you looked in the pdf file (power.pdf) to which you instructed R to 
send the plots?


On 2021-05-09 5:27 p.m., varin sacha via R-help wrote:
> Dear Rui,
>
> I thank you for your response but when I run the code with your few modifications, I still don't get the 8 graphs but I get the following answer :
>
> null device
>  ????????? 1
>
> Here below my R code with your modifications. I don't know what I am still missing ?
>
> ##############
> set.seed(1)
> library(energy)
>
> # Here we define parameters which we use to simulate the data
> # The number of null datasets we use to estimate our rejection reject #regions for an alternative with level 0.05
> nsim=50
>
> # Number of alternative datasets we use to estimate our power
> nsim2=50
>
> # The number of different noise levels used
> num.noise <- 30
>
> # A constant to determine the amount of noise
> noise <- 3
>
> # Number of data points per simulation
> n=100
>
> # Vectors holding the null "correlations" (for pearson, for spearman, for kendall and dcor respectively) for each # of the nsim null datasets at a #given noise level
> val.cor=val.cors=val.cork=val.dcor=rep(NA,nsim)
>
> # Vectors holding the alternative "correlations" (for pearson, for #spearman, for kendall and dcor respectively) #for each of the nsim2 alternative datasets at a given noise level
> val.cor2=val.cors2=val.cork2=val.dcor2= rep(NA,nsim2)
>
> # Arrays holding the estimated power for each of the 4 "correlation" types, for each data type (linear, #parabolic, etc...) with each noise level
> power.cor=power.cors=power.cork=power.dcor= array(NA, c(8,num.noise))
>
> ## We loop through the noise level and functional form; each time we #estimate a null distribution based on #the marginals of the data, and then #use that null distribution to estimate power
> ## We use a uniformly distributed x, because in the original paper the #authors used the same
>
> for(l in 1:num.noise) {
>
>  ????? for(typ in 1:8) {
>
> ## This next loop simulates data under the null with the correct marginals (x is uniform, and y is a function of a #uniform with gaussian noise)
>
>  ??? for(ii in 1:nsim) {
>  ????? x=runif(n)
>
> #lin+noise
> if(typ==1) {
> y=x+ noise *(l/num.noise)* rnorm(n)
> }
>
> #parabolic+noise
> if(typ==2) {
> y=4*(x-.5)^2+? noise * (l/num.noise) * rnorm(n)
> }
>
> #cubic+noise
> if(typ==3) {
> y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise? * (l/num.noise) *rnorm(n)
> }
>
> #sin+noise
> if(typ==4) {
> y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
> }
>
> #their sine + noise
> if(typ==5) {
> y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
> }
>
> #x^(1/4) + noise
> if(typ==6) {
> y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
> }
>
> #circle
> if(typ==7) {
> y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise *rnorm(n)
> }
>
> #step function
> if(typ==8) {
> y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
> }
>
>   
> # We resimulate x so that we have the null scenario
> x <- runif(n)
>
> # Calculate the 4 correlations
> val.cor[ii]=(cor(x,y))
> val.cors[ii]=(cor(x,y,method=c("spearman")))
> val.cork[ii]=(cor(x,y,method=c("kendal")))
> val.dcor[ii]=dcor(x,y)
> }
>
> ## Next we calculate our 4 rejection cutoffs
> cut.cor=quantile(val.cor,.95)
> cut.cors=quantile(val.cors,.95)
> cut.cork=quantile(val.cork,.95)
> cut.dcor=quantile(val.dcor,.95)
>
> ## Next we simulate the data again, this time under the alternative
>
>  ??? for(ii in 1:nsim2) {
>  ????? x=runif(n)
>
> #lin+noise
> if(typ==1) {
> y=x+ noise *(l/num.noise)* rnorm(n)
> }
>
> #parabolic+noise
> if(typ==2) {
> y=4*(x-.5)^2+? noise * (l/num.noise) * rnorm(n)
> }
>
> #cubic+noise
> if(typ==3) {
> y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise? * (l/num.noise) *rnorm(n)
> }
>
> #sin+noise
> if(typ==4) {
> y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
> }
>
> #their sine + noise
> if(typ==5) {
> y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
> }
>
> #x^(1/4) + noise
> if(typ==6) {
> y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
> }
>
> #circle
> if(typ==7) {
> y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise *rnorm(n)
> }
>
> #step function
> if(typ==8) {
> y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
> }
>
> ## We again calculate our 4 "correlations"
> val.cor2[ii]=(cor(x,y))
> val.cors2[ii]=(cor(x,y,method=c("spearman")))
> val.cork2[ii]=(cor(x,y,method=c("kendal")))
> val.dcor2[ii]=dcor(x,y)
> }
>
> ## Now we estimate the power as the number of alternative statistics #exceeding our estimated cutoffs
> power.cor[typ,l] <- sum(val.cor2 > cut.cor)/nsim2
> power.cors[typ,l] <- sum(val.cors2 > cut.cor)/nsim2
> power.cork[typ,l] <- sum(val.cork2 > cut.cor)/nsim2
> power.dcor[typ,l] <- sum(val.dcor2 > cut.dcor)/nsim2
> }
> }
>
> save.image()
>
> ## The rest of the code is for plotting the image
> pdf(file = "power.pdf")
> op <- par(mfrow = c(4,2), cex = 0.45)
> plot((1:30)/10, power.cor[1,], ylim = c(0,1), main = "Linear", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[1,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[1,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[1,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>
>  ?plot((1:30)/10, power.cor[2,], ylim = c(0,1), main = "Quadratic", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[2,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[2,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[2,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>
>  ?plot((1:30)/10, power.cor[3,], ylim = c(0,1), main = "Cubic", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[3,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[3,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[3,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>
> plot((1:30)/10, power.cor[5,], ylim = c(0,1), main = "Sine: period 1/8", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[5,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[5,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[5,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>
> plot((1:30)/10, power.cor[4,], ylim = c(0,1), main = "Sine: period 1/2", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[4,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[4,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[4,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>
> plot((1:30)/10, power.cor[6,], ylim = c(0,1), main = "X^(1/4)", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[6,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[6,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[6,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>
> plot((1:30)/10, power.cor[7,], ylim = c(0,1), main = "Circle", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[7,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[7,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[7,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>
> plot((1:30)/10, power.cor[8,], ylim = c(0,1), main = "Step function", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[8,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[8,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[8,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
> par(op)
> dev.off()
> #################
>
>
>
>
>
>
>
> Le dimanche 9 mai 2021 ? 22:44:22 UTC+2, Rui Barradas <ruipbarradas at sapo.pt> a ?crit :
>
>
>
>
>
> Hello,
>
> You are not closing the pdf device.
> The only changes I have made to your code are right at the beginning of
> the plotting instructions and at the end of the code.
>
>
> ## The rest of the code is for plotting the image
> pdf(file = "power.pdf")
> op <- par(mfrow = c(4,2), cex = 0.45)
>
> [...]
>
> par(op)
> dev.off()
> #################
>
> The comments only line is your last code line.
> The result is attached.
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 19:39 de 09/05/21, varin sacha via R-help escreveu:
>> Dear R-experts,
>>
>> I am trying to get the 8 graphs like the ones in this paper :
>> https://statweb.stanford.edu/~tibs/reshef/comment.pdf
>> My R code does not show any error message neither warnings but I d'on't get what I would like to get (I mean the 8 graphs), so I am missing something. What's it ? Many thanks for your precious help.
>>
>> #################
>> set.seed(1)
>> library(energy)
>>
>> # Here we define parameters which we use to simulate the data
>> # The number of null datasets we use to estimate our rejection reject #regions for an alternative with level 0.05
>> nsim=50
>>
>> # Number of alternative datasets we use to estimate our power
>> nsim2=50
>>
>> # The number of different noise levels used
>> num.noise <- 30
>>
>> # A constant to determine the amount of noise
>> noise <- 3
>>
>> # Number of data points per simulation
>> n=100
>>
>> # Vectors holding the null "correlations" (for pearson, for spearman, for kendall and dcor respectively) for each # of the nsim null datasets at a #given noise level
>> val.cor=val.cors=val.cork=val.dcor=rep(NA,nsim)
>>
>> # Vectors holding the alternative "correlations" (for pearson, for #spearman, for kendall and dcor respectively) #for each of the nsim2 alternative datasets at a given noise level
>> val.cor2=val.cors2=val.cork2=val.dcor2= rep(NA,nsim2)
>>    
>>
>> # Arrays holding the estimated power for each of the 4 "correlation" types, for each data type (linear, #parabolic, etc...) with each noise level
>> power.cor=power.cors=power.cork=power.dcor= array(NA, c(8,num.noise))
>>
>> ## We loop through the noise level and functional form; each time we #estimate a null distribution based on #the marginals of the data, and then #use that null distribution to estimate power
>> ## We use a uniformly distributed x, because in the original paper the #authors used the same
>>
>> for(l in 1:num.noise) {
>>
>>  ? ????? for(typ in 1:8) {
>>
>> ## This next loop simulates data under the null with the correct marginals (x is uniform, and y is a function of a #uniform with gaussian noise)
>>
>>  ? ??? for(ii in 1:nsim) {
>>  ? ????? x=runif(n)
>>
>> #lin+noise
>> if(typ==1) {
>> y=x+ noise *(l/num.noise)* rnorm(n)
>> }
>>
>> #parabolic+noise
>> if(typ==2) {
>> y=4*(x-.5)^2+? noise * (l/num.noise) * rnorm(n)
>> }
>>
>> #cubic+noise
>> if(typ==3) {
>> y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise? * (l/num.noise) *rnorm(n)
>> }
>>
>> #sin+noise
>> if(typ==4) {
>> y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
>> }
>>
>> #their sine + noise
>> if(typ==5) {
>> y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
>> }
>>
>> #x^(1/4) + noise
>> if(typ==6) {
>> y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
>> }
>>
>> #circle
>> if(typ==7) {
>> y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise *rnorm(n)
>> }
>>
>> #step function
>> if(typ==8) {
>> y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
>> }
>>
>> # We resimulate x so that we have the null scenario
>> x <- runif(n)
>>
>> # Calculate the 4 correlations
>> val.cor[ii]=(cor(x,y))
>> val.cors[ii]=(cor(x,y,method=c("spearman")))
>> val.cork[ii]=(cor(x,y,method=c("kendal")))
>> val.dcor[ii]=dcor(x,y)
>> }
>>
>> ## Next we calculate our 4 rejection cutoffs
>> cut.cor=quantile(val.cor,.95)
>> cut.cors=quantile(val.cors,.95)
>> cut.cork=quantile(val.cork,.95)
>> cut.dcor=quantile(val.dcor,.95)
>>
>> ## Next we simulate the data again, this time under the alternative
>>
>>  ? ??? for(ii in 1:nsim2) {
>>  ? ????? x=runif(n)
>>
>> #lin+noise
>> if(typ==1) {
>> y=x+ noise *(l/num.noise)* rnorm(n)
>> }
>>
>> #parabolic+noise
>> if(typ==2) {
>> y=4*(x-.5)^2+? noise * (l/num.noise) * rnorm(n)
>> }
>>
>> #cubic+noise
>> if(typ==3) {
>> y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise? * (l/num.noise) *rnorm(n)
>> }
>>
>> #sin+noise
>> if(typ==4) {
>> y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
>> }
>>
>> #their sine + noise
>> if(typ==5) {
>> y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
>> }
>>
>> #x^(1/4) + noise
>> if(typ==6) {
>> y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
>> }
>>
>> #circle
>> if(typ==7) {
>> y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise *rnorm(n)
>> }
>>
>> #step function
>> if(typ==8) {
>> y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
>> }
>>
>> ## We again calculate our 4 "correlations"
>> val.cor2[ii]=(cor(x,y))
>> val.cors2[ii]=(cor(x,y,method=c("spearman")))
>> val.cork2[ii]=(cor(x,y,method=c("kendal")))
>> val.dcor2[ii]=dcor(x,y)
>> }
>>
>> ## Now we estimate the power as the number of alternative statistics #exceeding our estimated cutoffs
>> power.cor[typ,l] <- sum(val.cor2 > cut.cor)/nsim2
>> power.cors[typ,l] <- sum(val.cors2 > cut.cor)/nsim2
>> power.cork[typ,l] <- sum(val.cork2 > cut.cor)/nsim2
>> power.dcor[typ,l] <- sum(val.dcor2 > cut.dcor)/nsim2
>> }
>> }
>>
>> save.image()
>>
>> ## The rest of the code is for plotting the image
>> pdf("power.pdf")
>> par(mfrow = c(4,2), cex = 0.45)
>> plot((1:30)/10, power.cor[1,], ylim = c(0,1), main = "Linear", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> points((1:30)/10, power.cors[1,], pch = 2, col = "green", type = 'b')
>> points((1:30)/10, power.cork[1,], pch = 3, col = "blue", type = 'b')
>> points((1:30)/10, power.dcor[1,], pch = 4, col = "red", type = 'b')
>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>>
>> plot((1:30)/10, power.cor[2,], ylim = c(0,1), main = "Quadratic", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> points((1:30)/10, power.cors[2,], pch = 2, col = "green", type = 'b')
>> points((1:30)/10, power.cork[2,], pch = 3, col = "blue", type = 'b')
>> points((1:30)/10, power.dcor[2,], pch = 4, col = "red", type = 'b')
>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>>
>> plot((1:30)/10, power.cor[3,], ylim = c(0,1), main = "Cubic", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> points((1:30)/10, power.cors[3,], pch = 2, col = "green", type = 'b')
>> points((1:30)/10, power.cork[3,], pch = 3, col = "blue", type = 'b')
>> points((1:30)/10, power.dcor[3,], pch = 4, col = "red", type = 'b')
>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>>
>> plot((1:30)/10, power.cor[5,], ylim = c(0,1), main = "Sine: period 1/8", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> points((1:30)/10, power.cors[5,], pch = 2, col = "green", type = 'b')
>> points((1:30)/10, power.cork[5,], pch = 3, col = "blue", type = 'b')
>> points((1:30)/10, power.dcor[5,], pch = 4, col = "red", type = 'b')
>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>>
>> plot((1:30)/10, power.cor[4,], ylim = c(0,1), main = "Sine: period 1/2", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> points((1:30)/10, power.cors[4,], pch = 2, col = "green", type = 'b')
>> points((1:30)/10, power.cork[4,], pch = 3, col = "blue", type = 'b')
>> points((1:30)/10, power.dcor[4,], pch = 4, col = "red", type = 'b')
>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>>
>> plot((1:30)/10, power.cor[6,], ylim = c(0,1), main = "X^(1/4)", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> points((1:30)/10, power.cors[6,], pch = 2, col = "green", type = 'b')
>> points((1:30)/10, power.cork[6,], pch = 3, col = "blue", type = 'b')
>> points((1:30)/10, power.dcor[6,], pch = 4, col = "red", type = 'b')
>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>>
>> plot((1:30)/10, power.cor[7,], ylim = c(0,1), main = "Circle", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> points((1:30)/10, power.cors[7,], pch = 2, col = "green", type = 'b')
>> points((1:30)/10, power.cork[7,], pch = 3, col = "blue", type = 'b')
>> points((1:30)/10, power.dcor[7,], pch = 4, col = "red", type = 'b')
>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>>
>> plot((1:30)/10, power.cor[8,], ylim = c(0,1), main = "Step function", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> points((1:30)/10, power.cors[8,], pch = 2, col = "green", type = 'b')
>> points((1:30)/10, power.cork[8,], pch = 3, col = "blue", type = 'b')
>> points((1:30)/10, power.dcor[8,], pch = 4, col = "red", type = 'b')
>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>> #################
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
------------------------------------------------------------------
|   Angelo J. Canty                Email: cantya at mcmaster.ca     |
|   Mathematics and Statistics     Phone: (905) 525-9140 x 27079 |
|   McMaster University            Fax  : (905) 522-0935         |
|   1280 Main St. W.                                             |
|   Hamilton ON L8S 4K1                                          |


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Sun May  9 23:50:14 2021
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Sun, 9 May 2021 21:50:14 +0000 (UTC)
Subject: [R] No error message but don't get the 8 graphs
In-Reply-To: <b9186679-16a2-d6e4-afac-eecebbba7e01@sapo.pt>
References: <294893856.3283193.1620585572644.ref@mail.yahoo.com>
 <294893856.3283193.1620585572644@mail.yahoo.com>
 <b9186679-16a2-d6e4-afac-eecebbba7e01@sapo.pt>
Message-ID: <1115549345.3369846.1620597015000@mail.yahoo.com>

Rui,

The created pdf.file is off-screen device. Indeed after dev.off() I should view the pdf file on my computer. But I don't find it. Where do I find the pdf.file ?

Regards,



Le dimanche 9 mai 2021 ? 22:44:22 UTC+2, Rui Barradas <ruipbarradas at sapo.pt> a ?crit : 





Hello,

You are not closing the pdf device.
The only changes I have made to your code are right at the beginning of 
the plotting instructions and at the end of the code.


## The rest of the code is for plotting the image
pdf(file = "power.pdf")
op <- par(mfrow = c(4,2), cex = 0.45)

[...]

par(op)
dev.off()
#################

The comments only line is your last code line.
The result is attached.

Hope this helps,

Rui Barradas

?s 19:39 de 09/05/21, varin sacha via R-help escreveu:
> Dear R-experts,
> 
> I am trying to get the 8 graphs like the ones in this paper :
> https://statweb.stanford.edu/~tibs/reshef/comment.pdf
> My R code does not show any error message neither warnings but I d'on't get what I would like to get (I mean the 8 graphs), so I am missing something. What's it ? Many thanks for your precious help.
> 
> #################
> set.seed(1)
> library(energy)
> 
> # Here we define parameters which we use to simulate the data
> # The number of null datasets we use to estimate our rejection reject #regions for an alternative with level 0.05
> nsim=50
> 
> # Number of alternative datasets we use to estimate our power
> nsim2=50
> 
> # The number of different noise levels used
> num.noise <- 30
> 
> # A constant to determine the amount of noise
> noise <- 3
> 
> # Number of data points per simulation
> n=100
> 
> # Vectors holding the null "correlations" (for pearson, for spearman, for kendall and dcor respectively) for each # of the nsim null datasets at a #given noise level
> val.cor=val.cors=val.cork=val.dcor=rep(NA,nsim)
> 
> # Vectors holding the alternative "correlations" (for pearson, for #spearman, for kendall and dcor respectively) #for each of the nsim2 alternative datasets at a given noise level
> val.cor2=val.cors2=val.cork2=val.dcor2= rep(NA,nsim2)
>? 
> 
> # Arrays holding the estimated power for each of the 4 "correlation" types, for each data type (linear, #parabolic, etc...) with each noise level
> power.cor=power.cors=power.cork=power.dcor= array(NA, c(8,num.noise))
> 
> ## We loop through the noise level and functional form; each time we #estimate a null distribution based on #the marginals of the data, and then #use that null distribution to estimate power
> ## We use a uniformly distributed x, because in the original paper the #authors used the same
> 
> for(l in 1:num.noise) {
> 
>? ????? for(typ in 1:8) {
> 
> ## This next loop simulates data under the null with the correct marginals (x is uniform, and y is a function of a #uniform with gaussian noise)
> 
>? ??? for(ii in 1:nsim) {
>? ????? x=runif(n)
> 
> #lin+noise
> if(typ==1) {
> y=x+ noise *(l/num.noise)* rnorm(n)
> }
> 
> #parabolic+noise
> if(typ==2) {
> y=4*(x-.5)^2+? noise * (l/num.noise) * rnorm(n)
> }
> 
> #cubic+noise
> if(typ==3) {
> y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise? * (l/num.noise) *rnorm(n)
> }
> 
> #sin+noise
> if(typ==4) {
> y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
> }
> 
> #their sine + noise
> if(typ==5) {
> y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
> }
> 
> #x^(1/4) + noise
> if(typ==6) {
> y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
> }
> 
> #circle
> if(typ==7) {
> y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise *rnorm(n)
> }
> 
> #step function
> if(typ==8) {
> y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
> }
> 
> # We resimulate x so that we have the null scenario
> x <- runif(n)
> 
> # Calculate the 4 correlations
> val.cor[ii]=(cor(x,y))
> val.cors[ii]=(cor(x,y,method=c("spearman")))
> val.cork[ii]=(cor(x,y,method=c("kendal")))
> val.dcor[ii]=dcor(x,y)
> }
> 
> ## Next we calculate our 4 rejection cutoffs
> cut.cor=quantile(val.cor,.95)
> cut.cors=quantile(val.cors,.95)
> cut.cork=quantile(val.cork,.95)
> cut.dcor=quantile(val.dcor,.95)
> 
> ## Next we simulate the data again, this time under the alternative
> 
>? ??? for(ii in 1:nsim2) {
>? ????? x=runif(n)
> 
> #lin+noise
> if(typ==1) {
> y=x+ noise *(l/num.noise)* rnorm(n)
> }
> 
> #parabolic+noise
> if(typ==2) {
> y=4*(x-.5)^2+? noise * (l/num.noise) * rnorm(n)
> }
> 
> #cubic+noise
> if(typ==3) {
> y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise? * (l/num.noise) *rnorm(n)
> }
> 
> #sin+noise
> if(typ==4) {
> y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
> }
> 
> #their sine + noise
> if(typ==5) {
> y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
> }
> 
> #x^(1/4) + noise
> if(typ==6) {
> y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
> }
> 
> #circle
> if(typ==7) {
> y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise *rnorm(n)
> }
> 
> #step function
> if(typ==8) {
> y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
> }
> 
> ## We again calculate our 4 "correlations"
> val.cor2[ii]=(cor(x,y))
> val.cors2[ii]=(cor(x,y,method=c("spearman")))
> val.cork2[ii]=(cor(x,y,method=c("kendal")))
> val.dcor2[ii]=dcor(x,y)
> }
> 
> ## Now we estimate the power as the number of alternative statistics #exceeding our estimated cutoffs
> power.cor[typ,l] <- sum(val.cor2 > cut.cor)/nsim2
> power.cors[typ,l] <- sum(val.cors2 > cut.cor)/nsim2
> power.cork[typ,l] <- sum(val.cork2 > cut.cor)/nsim2
> power.dcor[typ,l] <- sum(val.dcor2 > cut.dcor)/nsim2
> }
> }
> 
> save.image()
> 
> ## The rest of the code is for plotting the image
> pdf("power.pdf")
> par(mfrow = c(4,2), cex = 0.45)
> plot((1:30)/10, power.cor[1,], ylim = c(0,1), main = "Linear", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[1,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[1,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[1,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
> 
> plot((1:30)/10, power.cor[2,], ylim = c(0,1), main = "Quadratic", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[2,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[2,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[2,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
> 
> plot((1:30)/10, power.cor[3,], ylim = c(0,1), main = "Cubic", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[3,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[3,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[3,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
> 
> plot((1:30)/10, power.cor[5,], ylim = c(0,1), main = "Sine: period 1/8", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[5,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[5,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[5,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
> 
> plot((1:30)/10, power.cor[4,], ylim = c(0,1), main = "Sine: period 1/2", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[4,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[4,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[4,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
> 
> plot((1:30)/10, power.cor[6,], ylim = c(0,1), main = "X^(1/4)", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[6,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[6,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[6,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
> 
> plot((1:30)/10, power.cor[7,], ylim = c(0,1), main = "Circle", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[7,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[7,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[7,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
> 
> plot((1:30)/10, power.cor[8,], ylim = c(0,1), main = "Step function", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[8,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[8,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[8,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
> 
> #################
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Sun May  9 23:54:46 2021
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Sun, 9 May 2021 21:54:46 +0000 (UTC)
Subject: [R] No error message but don't get the 8 graphs
In-Reply-To: <5ba132c7-e604-8c5d-d9c1-2c1335b3bff8@math.mcmaster.ca>
References: <294893856.3283193.1620585572644.ref@mail.yahoo.com>
 <294893856.3283193.1620585572644@mail.yahoo.com>
 <b9186679-16a2-d6e4-afac-eecebbba7e01@sapo.pt>
 <928869154.3343817.1620595649281@mail.yahoo.com>
 <5ba132c7-e604-8c5d-d9c1-2c1335b3bff8@math.mcmaster.ca>
Message-ID: <736209186.3358686.1620597286766@mail.yahoo.com>

Rui, 
Angelo,

I found it :=) 

Many thanks

S.


Le dimanche 9 mai 2021 ? 23:49:41 UTC+2, Angelo Canty <canty at math.mcmaster.ca> a ?crit : 





Have you looked in the pdf file (power.pdf) to which you instructed R to 
send the plots?


On 2021-05-09 5:27 p.m., varin sacha via R-help wrote:
> Dear Rui,
>
> I thank you for your response but when I run the code with your few modifications, I still don't get the 8 graphs but I get the following answer :
>
> null device
>? ????????? 1
>
> Here below my R code with your modifications. I don't know what I am still missing ?
>
> ##############
> set.seed(1)
> library(energy)
>
> # Here we define parameters which we use to simulate the data
> # The number of null datasets we use to estimate our rejection reject #regions for an alternative with level 0.05
> nsim=50
>
> # Number of alternative datasets we use to estimate our power
> nsim2=50
>
> # The number of different noise levels used
> num.noise <- 30
>
> # A constant to determine the amount of noise
> noise <- 3
>
> # Number of data points per simulation
> n=100
>
> # Vectors holding the null "correlations" (for pearson, for spearman, for kendall and dcor respectively) for each # of the nsim null datasets at a #given noise level
> val.cor=val.cors=val.cork=val.dcor=rep(NA,nsim)
>
> # Vectors holding the alternative "correlations" (for pearson, for #spearman, for kendall and dcor respectively) #for each of the nsim2 alternative datasets at a given noise level
> val.cor2=val.cors2=val.cork2=val.dcor2= rep(NA,nsim2)
>
> # Arrays holding the estimated power for each of the 4 "correlation" types, for each data type (linear, #parabolic, etc...) with each noise level
> power.cor=power.cors=power.cork=power.dcor= array(NA, c(8,num.noise))
>
> ## We loop through the noise level and functional form; each time we #estimate a null distribution based on #the marginals of the data, and then #use that null distribution to estimate power
> ## We use a uniformly distributed x, because in the original paper the #authors used the same
>
> for(l in 1:num.noise) {
>
>? ????? for(typ in 1:8) {
>
> ## This next loop simulates data under the null with the correct marginals (x is uniform, and y is a function of a #uniform with gaussian noise)
>
>? ??? for(ii in 1:nsim) {
>? ????? x=runif(n)
>
> #lin+noise
> if(typ==1) {
> y=x+ noise *(l/num.noise)* rnorm(n)
> }
>
> #parabolic+noise
> if(typ==2) {
> y=4*(x-.5)^2+? noise * (l/num.noise) * rnorm(n)
> }
>
> #cubic+noise
> if(typ==3) {
> y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise? * (l/num.noise) *rnorm(n)
> }
>
> #sin+noise
> if(typ==4) {
> y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
> }
>
> #their sine + noise
> if(typ==5) {
> y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
> }
>
> #x^(1/4) + noise
> if(typ==6) {
> y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
> }
>
> #circle
> if(typ==7) {
> y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise *rnorm(n)
> }
>
> #step function
> if(typ==8) {
> y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
> }
>
>? 
> # We resimulate x so that we have the null scenario
> x <- runif(n)
>
> # Calculate the 4 correlations
> val.cor[ii]=(cor(x,y))
> val.cors[ii]=(cor(x,y,method=c("spearman")))
> val.cork[ii]=(cor(x,y,method=c("kendal")))
> val.dcor[ii]=dcor(x,y)
> }
>
> ## Next we calculate our 4 rejection cutoffs
> cut.cor=quantile(val.cor,.95)
> cut.cors=quantile(val.cors,.95)
> cut.cork=quantile(val.cork,.95)
> cut.dcor=quantile(val.dcor,.95)
>
> ## Next we simulate the data again, this time under the alternative
>
>? ??? for(ii in 1:nsim2) {
>? ????? x=runif(n)
>
> #lin+noise
> if(typ==1) {
> y=x+ noise *(l/num.noise)* rnorm(n)
> }
>
> #parabolic+noise
> if(typ==2) {
> y=4*(x-.5)^2+? noise * (l/num.noise) * rnorm(n)
> }
>
> #cubic+noise
> if(typ==3) {
> y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise? * (l/num.noise) *rnorm(n)
> }
>
> #sin+noise
> if(typ==4) {
> y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
> }
>
> #their sine + noise
> if(typ==5) {
> y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
> }
>
> #x^(1/4) + noise
> if(typ==6) {
> y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
> }
>
> #circle
> if(typ==7) {
> y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise *rnorm(n)
> }
>
> #step function
> if(typ==8) {
> y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
> }
>
> ## We again calculate our 4 "correlations"
> val.cor2[ii]=(cor(x,y))
> val.cors2[ii]=(cor(x,y,method=c("spearman")))
> val.cork2[ii]=(cor(x,y,method=c("kendal")))
> val.dcor2[ii]=dcor(x,y)
> }
>
> ## Now we estimate the power as the number of alternative statistics #exceeding our estimated cutoffs
> power.cor[typ,l] <- sum(val.cor2 > cut.cor)/nsim2
> power.cors[typ,l] <- sum(val.cors2 > cut.cor)/nsim2
> power.cork[typ,l] <- sum(val.cork2 > cut.cor)/nsim2
> power.dcor[typ,l] <- sum(val.dcor2 > cut.dcor)/nsim2
> }
> }
>
> save.image()
>
> ## The rest of the code is for plotting the image
> pdf(file = "power.pdf")
> op <- par(mfrow = c(4,2), cex = 0.45)
> plot((1:30)/10, power.cor[1,], ylim = c(0,1), main = "Linear", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[1,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[1,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[1,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>
>? ?plot((1:30)/10, power.cor[2,], ylim = c(0,1), main = "Quadratic", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[2,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[2,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[2,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>
>? ?plot((1:30)/10, power.cor[3,], ylim = c(0,1), main = "Cubic", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[3,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[3,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[3,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>
> plot((1:30)/10, power.cor[5,], ylim = c(0,1), main = "Sine: period 1/8", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[5,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[5,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[5,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>
> plot((1:30)/10, power.cor[4,], ylim = c(0,1), main = "Sine: period 1/2", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[4,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[4,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[4,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>
> plot((1:30)/10, power.cor[6,], ylim = c(0,1), main = "X^(1/4)", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[6,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[6,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[6,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>
> plot((1:30)/10, power.cor[7,], ylim = c(0,1), main = "Circle", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[7,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[7,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[7,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>
> plot((1:30)/10, power.cor[8,], ylim = c(0,1), main = "Step function", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[8,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[8,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[8,], pch = 4, col = "red", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
> par(op)
> dev.off()
> #################
>
>
>
>
>
>
>
> Le dimanche 9 mai 2021 ? 22:44:22 UTC+2, Rui Barradas <ruipbarradas at sapo.pt> a ?crit :
>
>
>
>
>
> Hello,
>
> You are not closing the pdf device.
> The only changes I have made to your code are right at the beginning of
> the plotting instructions and at the end of the code.
>
>
> ## The rest of the code is for plotting the image
> pdf(file = "power.pdf")
> op <- par(mfrow = c(4,2), cex = 0.45)
>
> [...]
>
> par(op)
> dev.off()
> #################
>
> The comments only line is your last code line.
> The result is attached.
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 19:39 de 09/05/21, varin sacha via R-help escreveu:
>> Dear R-experts,
>>
>> I am trying to get the 8 graphs like the ones in this paper :
>> https://statweb.stanford.edu/~tibs/reshef/comment.pdf
>> My R code does not show any error message neither warnings but I d'on't get what I would like to get (I mean the 8 graphs), so I am missing something. What's it ? Many thanks for your precious help.
>>
>> #################
>> set.seed(1)
>> library(energy)
>>
>> # Here we define parameters which we use to simulate the data
>> # The number of null datasets we use to estimate our rejection reject #regions for an alternative with level 0.05
>> nsim=50
>>
>> # Number of alternative datasets we use to estimate our power
>> nsim2=50
>>
>> # The number of different noise levels used
>> num.noise <- 30
>>
>> # A constant to determine the amount of noise
>> noise <- 3
>>
>> # Number of data points per simulation
>> n=100
>>
>> # Vectors holding the null "correlations" (for pearson, for spearman, for kendall and dcor respectively) for each # of the nsim null datasets at a #given noise level
>> val.cor=val.cors=val.cork=val.dcor=rep(NA,nsim)
>>
>> # Vectors holding the alternative "correlations" (for pearson, for #spearman, for kendall and dcor respectively) #for each of the nsim2 alternative datasets at a given noise level
>> val.cor2=val.cors2=val.cork2=val.dcor2= rep(NA,nsim2)
>>? ? 
>>
>> # Arrays holding the estimated power for each of the 4 "correlation" types, for each data type (linear, #parabolic, etc...) with each noise level
>> power.cor=power.cors=power.cork=power.dcor= array(NA, c(8,num.noise))
>>
>> ## We loop through the noise level and functional form; each time we #estimate a null distribution based on #the marginals of the data, and then #use that null distribution to estimate power
>> ## We use a uniformly distributed x, because in the original paper the #authors used the same
>>
>> for(l in 1:num.noise) {
>>
>>? ? ????? for(typ in 1:8) {
>>
>> ## This next loop simulates data under the null with the correct marginals (x is uniform, and y is a function of a #uniform with gaussian noise)
>>
>>? ? ??? for(ii in 1:nsim) {
>>? ? ????? x=runif(n)
>>
>> #lin+noise
>> if(typ==1) {
>> y=x+ noise *(l/num.noise)* rnorm(n)
>> }
>>
>> #parabolic+noise
>> if(typ==2) {
>> y=4*(x-.5)^2+? noise * (l/num.noise) * rnorm(n)
>> }
>>
>> #cubic+noise
>> if(typ==3) {
>> y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise? * (l/num.noise) *rnorm(n)
>> }
>>
>> #sin+noise
>> if(typ==4) {
>> y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
>> }
>>
>> #their sine + noise
>> if(typ==5) {
>> y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
>> }
>>
>> #x^(1/4) + noise
>> if(typ==6) {
>> y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
>> }
>>
>> #circle
>> if(typ==7) {
>> y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise *rnorm(n)
>> }
>>
>> #step function
>> if(typ==8) {
>> y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
>> }
>>
>> # We resimulate x so that we have the null scenario
>> x <- runif(n)
>>
>> # Calculate the 4 correlations
>> val.cor[ii]=(cor(x,y))
>> val.cors[ii]=(cor(x,y,method=c("spearman")))
>> val.cork[ii]=(cor(x,y,method=c("kendal")))
>> val.dcor[ii]=dcor(x,y)
>> }
>>
>> ## Next we calculate our 4 rejection cutoffs
>> cut.cor=quantile(val.cor,.95)
>> cut.cors=quantile(val.cors,.95)
>> cut.cork=quantile(val.cork,.95)
>> cut.dcor=quantile(val.dcor,.95)
>>
>> ## Next we simulate the data again, this time under the alternative
>>
>>? ? ??? for(ii in 1:nsim2) {
>>? ? ????? x=runif(n)
>>
>> #lin+noise
>> if(typ==1) {
>> y=x+ noise *(l/num.noise)* rnorm(n)
>> }
>>
>> #parabolic+noise
>> if(typ==2) {
>> y=4*(x-.5)^2+? noise * (l/num.noise) * rnorm(n)
>> }
>>
>> #cubic+noise
>> if(typ==3) {
>> y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise? * (l/num.noise) *rnorm(n)
>> }
>>
>> #sin+noise
>> if(typ==4) {
>> y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
>> }
>>
>> #their sine + noise
>> if(typ==5) {
>> y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
>> }
>>
>> #x^(1/4) + noise
>> if(typ==6) {
>> y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
>> }
>>
>> #circle
>> if(typ==7) {
>> y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise *rnorm(n)
>> }
>>
>> #step function
>> if(typ==8) {
>> y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
>> }
>>
>> ## We again calculate our 4 "correlations"
>> val.cor2[ii]=(cor(x,y))
>> val.cors2[ii]=(cor(x,y,method=c("spearman")))
>> val.cork2[ii]=(cor(x,y,method=c("kendal")))
>> val.dcor2[ii]=dcor(x,y)
>> }
>>
>> ## Now we estimate the power as the number of alternative statistics #exceeding our estimated cutoffs
>> power.cor[typ,l] <- sum(val.cor2 > cut.cor)/nsim2
>> power.cors[typ,l] <- sum(val.cors2 > cut.cor)/nsim2
>> power.cork[typ,l] <- sum(val.cork2 > cut.cor)/nsim2
>> power.dcor[typ,l] <- sum(val.dcor2 > cut.dcor)/nsim2
>> }
>> }
>>
>> save.image()
>>
>> ## The rest of the code is for plotting the image
>> pdf("power.pdf")
>> par(mfrow = c(4,2), cex = 0.45)
>> plot((1:30)/10, power.cor[1,], ylim = c(0,1), main = "Linear", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> points((1:30)/10, power.cors[1,], pch = 2, col = "green", type = 'b')
>> points((1:30)/10, power.cork[1,], pch = 3, col = "blue", type = 'b')
>> points((1:30)/10, power.dcor[1,], pch = 4, col = "red", type = 'b')
>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>>
>> plot((1:30)/10, power.cor[2,], ylim = c(0,1), main = "Quadratic", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> points((1:30)/10, power.cors[2,], pch = 2, col = "green", type = 'b')
>> points((1:30)/10, power.cork[2,], pch = 3, col = "blue", type = 'b')
>> points((1:30)/10, power.dcor[2,], pch = 4, col = "red", type = 'b')
>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>>
>> plot((1:30)/10, power.cor[3,], ylim = c(0,1), main = "Cubic", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> points((1:30)/10, power.cors[3,], pch = 2, col = "green", type = 'b')
>> points((1:30)/10, power.cork[3,], pch = 3, col = "blue", type = 'b')
>> points((1:30)/10, power.dcor[3,], pch = 4, col = "red", type = 'b')
>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>>
>> plot((1:30)/10, power.cor[5,], ylim = c(0,1), main = "Sine: period 1/8", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> points((1:30)/10, power.cors[5,], pch = 2, col = "green", type = 'b')
>> points((1:30)/10, power.cork[5,], pch = 3, col = "blue", type = 'b')
>> points((1:30)/10, power.dcor[5,], pch = 4, col = "red", type = 'b')
>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>>
>> plot((1:30)/10, power.cor[4,], ylim = c(0,1), main = "Sine: period 1/2", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> points((1:30)/10, power.cors[4,], pch = 2, col = "green", type = 'b')
>> points((1:30)/10, power.cork[4,], pch = 3, col = "blue", type = 'b')
>> points((1:30)/10, power.dcor[4,], pch = 4, col = "red", type = 'b')
>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>>
>> plot((1:30)/10, power.cor[6,], ylim = c(0,1), main = "X^(1/4)", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> points((1:30)/10, power.cors[6,], pch = 2, col = "green", type = 'b')
>> points((1:30)/10, power.cork[6,], pch = 3, col = "blue", type = 'b')
>> points((1:30)/10, power.dcor[6,], pch = 4, col = "red", type = 'b')
>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>>
>> plot((1:30)/10, power.cor[7,], ylim = c(0,1), main = "Circle", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> points((1:30)/10, power.cors[7,], pch = 2, col = "green", type = 'b')
>> points((1:30)/10, power.cork[7,], pch = 3, col = "blue", type = 'b')
>> points((1:30)/10, power.dcor[7,], pch = 4, col = "red", type = 'b')
>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>>
>> plot((1:30)/10, power.cor[8,], ylim = c(0,1), main = "Step function", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> points((1:30)/10, power.cors[8,], pch = 2, col = "green", type = 'b')
>> points((1:30)/10, power.cork[8,], pch = 3, col = "blue", type = 'b')
>> points((1:30)/10, power.dcor[8,], pch = 4, col = "red", type = 'b')
>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"), pch = c(1,2,3), col = c("black","green","blue","red"))
>> #################
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
------------------------------------------------------------------
|? Angelo J. Canty? ? ? ? ? ? ? ? Email: cantya at mcmaster.ca? ? |
|? Mathematics and Statistics? ? Phone: (905) 525-9140 x 27079 |
|? McMaster University? ? ? ? ? ? Fax? : (905) 522-0935? ? ? ? |
|? 1280 Main St. W.? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? |
|? Hamilton ON L8S 4K1? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? |

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Mon May 10 02:13:00 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 9 May 2021 17:13:00 -0700
Subject: [R] No error message but don't get the 8 graphs
In-Reply-To: <1115549345.3369846.1620597015000@mail.yahoo.com>
References: <294893856.3283193.1620585572644.ref@mail.yahoo.com>
 <294893856.3283193.1620585572644@mail.yahoo.com>
 <b9186679-16a2-d6e4-afac-eecebbba7e01@sapo.pt>
 <1115549345.3369846.1620597015000@mail.yahoo.com>
Message-ID: <CAGxFJbTdN4e9RtgFVBsPA1ktbNXo66KpQ6d9=Tv7LveNz3OqxQ@mail.gmail.com>

?getwd

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, May 9, 2021 at 2:59 PM varin sacha via R-help <r-help at r-project.org>
wrote:

> Rui,
>
> The created pdf.file is off-screen device. Indeed after dev.off() I should
> view the pdf file on my computer. But I don't find it. Where do I find the
> pdf.file ?
>
> Regards,
>
>
>
> Le dimanche 9 mai 2021 ? 22:44:22 UTC+2, Rui Barradas <
> ruipbarradas at sapo.pt> a ?crit :
>
>
>
>
>
> Hello,
>
> You are not closing the pdf device.
> The only changes I have made to your code are right at the beginning of
> the plotting instructions and at the end of the code.
>
>
> ## The rest of the code is for plotting the image
> pdf(file = "power.pdf")
> op <- par(mfrow = c(4,2), cex = 0.45)
>
> [...]
>
> par(op)
> dev.off()
> #################
>
> The comments only line is your last code line.
> The result is attached.
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 19:39 de 09/05/21, varin sacha via R-help escreveu:
> > Dear R-experts,
> >
> > I am trying to get the 8 graphs like the ones in this paper :
> > https://statweb.stanford.edu/~tibs/reshef/comment.pdf
> > My R code does not show any error message neither warnings but I d'on't
> get what I would like to get (I mean the 8 graphs), so I am missing
> something. What's it ? Many thanks for your precious help.
> >
> > #################
> > set.seed(1)
> > library(energy)
> >
> > # Here we define parameters which we use to simulate the data
> > # The number of null datasets we use to estimate our rejection reject
> #regions for an alternative with level 0.05
> > nsim=50
> >
> > # Number of alternative datasets we use to estimate our power
> > nsim2=50
> >
> > # The number of different noise levels used
> > num.noise <- 30
> >
> > # A constant to determine the amount of noise
> > noise <- 3
> >
> > # Number of data points per simulation
> > n=100
> >
> > # Vectors holding the null "correlations" (for pearson, for spearman,
> for kendall and dcor respectively) for each # of the nsim null datasets at
> a #given noise level
> > val.cor=val.cors=val.cork=val.dcor=rep(NA,nsim)
> >
> > # Vectors holding the alternative "correlations" (for pearson, for
> #spearman, for kendall and dcor respectively) #for each of the nsim2
> alternative datasets at a given noise level
> > val.cor2=val.cors2=val.cork2=val.dcor2= rep(NA,nsim2)
> >
> >
> > # Arrays holding the estimated power for each of the 4 "correlation"
> types, for each data type (linear, #parabolic, etc...) with each noise level
> > power.cor=power.cors=power.cork=power.dcor= array(NA, c(8,num.noise))
> >
> > ## We loop through the noise level and functional form; each time we
> #estimate a null distribution based on #the marginals of the data, and then
> #use that null distribution to estimate power
> > ## We use a uniformly distributed x, because in the original paper the
> #authors used the same
> >
> > for(l in 1:num.noise) {
> >
> >        for(typ in 1:8) {
> >
> > ## This next loop simulates data under the null with the correct
> marginals (x is uniform, and y is a function of a #uniform with gaussian
> noise)
> >
> >      for(ii in 1:nsim) {
> >        x=runif(n)
> >
> > #lin+noise
> > if(typ==1) {
> > y=x+ noise *(l/num.noise)* rnorm(n)
> > }
> >
> > #parabolic+noise
> > if(typ==2) {
> > y=4*(x-.5)^2+  noise * (l/num.noise) * rnorm(n)
> > }
> >
> > #cubic+noise
> > if(typ==3) {
> > y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise  * (l/num.noise)
> *rnorm(n)
> > }
> >
> > #sin+noise
> > if(typ==4) {
> > y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
> > }
> >
> > #their sine + noise
> > if(typ==5) {
> > y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
> > }
> >
> > #x^(1/4) + noise
> > if(typ==6) {
> > y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
> > }
> >
> > #circle
> > if(typ==7) {
> > y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise
> *rnorm(n)
> > }
> >
> > #step function
> > if(typ==8) {
> > y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
> > }
> >
> > # We resimulate x so that we have the null scenario
> > x <- runif(n)
> >
> > # Calculate the 4 correlations
> > val.cor[ii]=(cor(x,y))
> > val.cors[ii]=(cor(x,y,method=c("spearman")))
> > val.cork[ii]=(cor(x,y,method=c("kendal")))
> > val.dcor[ii]=dcor(x,y)
> > }
> >
> > ## Next we calculate our 4 rejection cutoffs
> > cut.cor=quantile(val.cor,.95)
> > cut.cors=quantile(val.cors,.95)
> > cut.cork=quantile(val.cork,.95)
> > cut.dcor=quantile(val.dcor,.95)
> >
> > ## Next we simulate the data again, this time under the alternative
> >
> >      for(ii in 1:nsim2) {
> >        x=runif(n)
> >
> > #lin+noise
> > if(typ==1) {
> > y=x+ noise *(l/num.noise)* rnorm(n)
> > }
> >
> > #parabolic+noise
> > if(typ==2) {
> > y=4*(x-.5)^2+  noise * (l/num.noise) * rnorm(n)
> > }
> >
> > #cubic+noise
> > if(typ==3) {
> > y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise  * (l/num.noise)
> *rnorm(n)
> > }
> >
> > #sin+noise
> > if(typ==4) {
> > y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
> > }
> >
> > #their sine + noise
> > if(typ==5) {
> > y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
> > }
> >
> > #x^(1/4) + noise
> > if(typ==6) {
> > y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
> > }
> >
> > #circle
> > if(typ==7) {
> > y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise
> *rnorm(n)
> > }
> >
> > #step function
> > if(typ==8) {
> > y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
> > }
> >
> > ## We again calculate our 4 "correlations"
> > val.cor2[ii]=(cor(x,y))
> > val.cors2[ii]=(cor(x,y,method=c("spearman")))
> > val.cork2[ii]=(cor(x,y,method=c("kendal")))
> > val.dcor2[ii]=dcor(x,y)
> > }
> >
> > ## Now we estimate the power as the number of alternative statistics
> #exceeding our estimated cutoffs
> > power.cor[typ,l] <- sum(val.cor2 > cut.cor)/nsim2
> > power.cors[typ,l] <- sum(val.cors2 > cut.cor)/nsim2
> > power.cork[typ,l] <- sum(val.cork2 > cut.cor)/nsim2
> > power.dcor[typ,l] <- sum(val.dcor2 > cut.dcor)/nsim2
> > }
> > }
> >
> > save.image()
> >
> > ## The rest of the code is for plotting the image
> > pdf("power.pdf")
> > par(mfrow = c(4,2), cex = 0.45)
> > plot((1:30)/10, power.cor[1,], ylim = c(0,1), main = "Linear", xlab =
> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> > points((1:30)/10, power.cors[1,], pch = 2, col = "green", type = 'b')
> > points((1:30)/10, power.cork[1,], pch = 3, col = "blue", type = 'b')
> > points((1:30)/10, power.dcor[1,], pch = 4, col = "red", type = 'b')
> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
> pch = c(1,2,3), col = c("black","green","blue","red"))
> >
> > plot((1:30)/10, power.cor[2,], ylim = c(0,1), main = "Quadratic", xlab =
> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> > points((1:30)/10, power.cors[2,], pch = 2, col = "green", type = 'b')
> > points((1:30)/10, power.cork[2,], pch = 3, col = "blue", type = 'b')
> > points((1:30)/10, power.dcor[2,], pch = 4, col = "red", type = 'b')
> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
> pch = c(1,2,3), col = c("black","green","blue","red"))
> >
> > plot((1:30)/10, power.cor[3,], ylim = c(0,1), main = "Cubic", xlab =
> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> > points((1:30)/10, power.cors[3,], pch = 2, col = "green", type = 'b')
> > points((1:30)/10, power.cork[3,], pch = 3, col = "blue", type = 'b')
> > points((1:30)/10, power.dcor[3,], pch = 4, col = "red", type = 'b')
> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
> pch = c(1,2,3), col = c("black","green","blue","red"))
> >
> > plot((1:30)/10, power.cor[5,], ylim = c(0,1), main = "Sine: period 1/8",
> xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> > points((1:30)/10, power.cors[5,], pch = 2, col = "green", type = 'b')
> > points((1:30)/10, power.cork[5,], pch = 3, col = "blue", type = 'b')
> > points((1:30)/10, power.dcor[5,], pch = 4, col = "red", type = 'b')
> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
> pch = c(1,2,3), col = c("black","green","blue","red"))
> >
> > plot((1:30)/10, power.cor[4,], ylim = c(0,1), main = "Sine: period 1/2",
> xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> > points((1:30)/10, power.cors[4,], pch = 2, col = "green", type = 'b')
> > points((1:30)/10, power.cork[4,], pch = 3, col = "blue", type = 'b')
> > points((1:30)/10, power.dcor[4,], pch = 4, col = "red", type = 'b')
> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
> pch = c(1,2,3), col = c("black","green","blue","red"))
> >
> > plot((1:30)/10, power.cor[6,], ylim = c(0,1), main = "X^(1/4)", xlab =
> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> > points((1:30)/10, power.cors[6,], pch = 2, col = "green", type = 'b')
> > points((1:30)/10, power.cork[6,], pch = 3, col = "blue", type = 'b')
> > points((1:30)/10, power.dcor[6,], pch = 4, col = "red", type = 'b')
> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
> pch = c(1,2,3), col = c("black","green","blue","red"))
> >
> > plot((1:30)/10, power.cor[7,], ylim = c(0,1), main = "Circle", xlab =
> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> > points((1:30)/10, power.cors[7,], pch = 2, col = "green", type = 'b')
> > points((1:30)/10, power.cork[7,], pch = 3, col = "blue", type = 'b')
> > points((1:30)/10, power.dcor[7,], pch = 4, col = "red", type = 'b')
> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
> pch = c(1,2,3), col = c("black","green","blue","red"))
> >
> > plot((1:30)/10, power.cor[8,], ylim = c(0,1), main = "Step function",
> xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> > points((1:30)/10, power.cors[8,], pch = 2, col = "green", type = 'b')
> > points((1:30)/10, power.cork[8,], pch = 3, col = "blue", type = 'b')
> > points((1:30)/10, power.dcor[8,], pch = 4, col = "red", type = 'b')
> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
> pch = c(1,2,3), col = c("black","green","blue","red"))
> >
> > #################
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Mon May 10 11:16:12 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Mon, 10 May 2021 09:16:12 +0000
Subject: [R] Analysing data with repeated measure variable
In-Reply-To: <CANSYM40wKq0c9Vp6PyCAZJrV-bNH4Xve1vHuYq1knC+SQyWS3g@mail.gmail.com>
References: <CANSYM40wKq0c9Vp6PyCAZJrV-bNH4Xve1vHuYq1knC+SQyWS3g@mail.gmail.com>
Message-ID: <067287e10d634933bf25ce89652dca0b@SRVEXCHCM1302.precheza.cz>

Hi

Do not post in HTML, if you do not want your data to be messed.
see 

?ifelse and/or logical operations
maybe ?sort or ?order and ?min
maybe ?merge

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Ahmad Raza
> Sent: Thursday, May 6, 2021 9:41 PM
> To: r-help at r-project.org
> Subject: [R] Analysing data with repeated measure variable
> 
> Dear Experts,
> Greetings
> 
> I have the following type of repeated measures data (table 1), and events
> data in table 2 (single measure). I want to perform the following tasks (in R
> or excel sheet please).
> 
>    - To filter subjects who had any response at least 3 days.
>    - Response should be > 5 in each day.
>    - Then table 1 should have another column, date first response recorded.
>    - Then both tables should be merged
> 
> Table 1 ? Response Data
> 
> Sub_No    Response     Date1          5          01-Jan1          5
>       02-Jan2          5          01-Jan2          10         02-Jan2
>         10         03-Jan2          10         04-Jan2          10
>     05-Jan3          10         01-Jan3          10         02-Jan3
>       10         03-Jan4          5          01-Jan4          5
>   02-Jan4          10         03-Jan4          10         04-Jan4
>     10         05-Jan
> 
> 
> Table 2 ? Event Data
> 
> Sub_No   Response        Date1          No2         Yes          30
> Jan3         Yes          29 Jan4          No
> 
> Thanks for your help.
> Regards,
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From w||||@mwdun|@p @end|ng |rom gm@||@com  Mon May 10 17:17:38 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Mon, 10 May 2021 08:17:38 -0700
Subject: [R] No error message but don't get the 8 graphs
In-Reply-To: <CAGxFJbTdN4e9RtgFVBsPA1ktbNXo66KpQ6d9=Tv7LveNz3OqxQ@mail.gmail.com>
References: <294893856.3283193.1620585572644.ref@mail.yahoo.com>
 <294893856.3283193.1620585572644@mail.yahoo.com>
 <b9186679-16a2-d6e4-afac-eecebbba7e01@sapo.pt>
 <1115549345.3369846.1620597015000@mail.yahoo.com>
 <CAGxFJbTdN4e9RtgFVBsPA1ktbNXo66KpQ6d9=Tv7LveNz3OqxQ@mail.gmail.com>
Message-ID: <CAHqSRuR52W2to6UYMe_Mmv500AZx9CwMz7s7+oR4kcsVocN=ww@mail.gmail.com>

Also, normalizePath("power.pdf").

On Sun, May 9, 2021 at 5:13 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> ?getwd
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, May 9, 2021 at 2:59 PM varin sacha via R-help <
> r-help at r-project.org>
> wrote:
>
> > Rui,
> >
> > The created pdf.file is off-screen device. Indeed after dev.off() I
> should
> > view the pdf file on my computer. But I don't find it. Where do I find
> the
> > pdf.file ?
> >
> > Regards,
> >
> >
> >
> > Le dimanche 9 mai 2021 ? 22:44:22 UTC+2, Rui Barradas <
> > ruipbarradas at sapo.pt> a ?crit :
> >
> >
> >
> >
> >
> > Hello,
> >
> > You are not closing the pdf device.
> > The only changes I have made to your code are right at the beginning of
> > the plotting instructions and at the end of the code.
> >
> >
> > ## The rest of the code is for plotting the image
> > pdf(file = "power.pdf")
> > op <- par(mfrow = c(4,2), cex = 0.45)
> >
> > [...]
> >
> > par(op)
> > dev.off()
> > #################
> >
> > The comments only line is your last code line.
> > The result is attached.
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > ?s 19:39 de 09/05/21, varin sacha via R-help escreveu:
> > > Dear R-experts,
> > >
> > > I am trying to get the 8 graphs like the ones in this paper :
> > > https://statweb.stanford.edu/~tibs/reshef/comment.pdf
> > > My R code does not show any error message neither warnings but I d'on't
> > get what I would like to get (I mean the 8 graphs), so I am missing
> > something. What's it ? Many thanks for your precious help.
> > >
> > > #################
> > > set.seed(1)
> > > library(energy)
> > >
> > > # Here we define parameters which we use to simulate the data
> > > # The number of null datasets we use to estimate our rejection reject
> > #regions for an alternative with level 0.05
> > > nsim=50
> > >
> > > # Number of alternative datasets we use to estimate our power
> > > nsim2=50
> > >
> > > # The number of different noise levels used
> > > num.noise <- 30
> > >
> > > # A constant to determine the amount of noise
> > > noise <- 3
> > >
> > > # Number of data points per simulation
> > > n=100
> > >
> > > # Vectors holding the null "correlations" (for pearson, for spearman,
> > for kendall and dcor respectively) for each # of the nsim null datasets
> at
> > a #given noise level
> > > val.cor=val.cors=val.cork=val.dcor=rep(NA,nsim)
> > >
> > > # Vectors holding the alternative "correlations" (for pearson, for
> > #spearman, for kendall and dcor respectively) #for each of the nsim2
> > alternative datasets at a given noise level
> > > val.cor2=val.cors2=val.cork2=val.dcor2= rep(NA,nsim2)
> > >
> > >
> > > # Arrays holding the estimated power for each of the 4 "correlation"
> > types, for each data type (linear, #parabolic, etc...) with each noise
> level
> > > power.cor=power.cors=power.cork=power.dcor= array(NA, c(8,num.noise))
> > >
> > > ## We loop through the noise level and functional form; each time we
> > #estimate a null distribution based on #the marginals of the data, and
> then
> > #use that null distribution to estimate power
> > > ## We use a uniformly distributed x, because in the original paper the
> > #authors used the same
> > >
> > > for(l in 1:num.noise) {
> > >
> > >        for(typ in 1:8) {
> > >
> > > ## This next loop simulates data under the null with the correct
> > marginals (x is uniform, and y is a function of a #uniform with gaussian
> > noise)
> > >
> > >      for(ii in 1:nsim) {
> > >        x=runif(n)
> > >
> > > #lin+noise
> > > if(typ==1) {
> > > y=x+ noise *(l/num.noise)* rnorm(n)
> > > }
> > >
> > > #parabolic+noise
> > > if(typ==2) {
> > > y=4*(x-.5)^2+  noise * (l/num.noise) * rnorm(n)
> > > }
> > >
> > > #cubic+noise
> > > if(typ==3) {
> > > y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise  * (l/num.noise)
> > *rnorm(n)
> > > }
> > >
> > > #sin+noise
> > > if(typ==4) {
> > > y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
> > > }
> > >
> > > #their sine + noise
> > > if(typ==5) {
> > > y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
> > > }
> > >
> > > #x^(1/4) + noise
> > > if(typ==6) {
> > > y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
> > > }
> > >
> > > #circle
> > > if(typ==7) {
> > > y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise
> > *rnorm(n)
> > > }
> > >
> > > #step function
> > > if(typ==8) {
> > > y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
> > > }
> > >
> > > # We resimulate x so that we have the null scenario
> > > x <- runif(n)
> > >
> > > # Calculate the 4 correlations
> > > val.cor[ii]=(cor(x,y))
> > > val.cors[ii]=(cor(x,y,method=c("spearman")))
> > > val.cork[ii]=(cor(x,y,method=c("kendal")))
> > > val.dcor[ii]=dcor(x,y)
> > > }
> > >
> > > ## Next we calculate our 4 rejection cutoffs
> > > cut.cor=quantile(val.cor,.95)
> > > cut.cors=quantile(val.cors,.95)
> > > cut.cork=quantile(val.cork,.95)
> > > cut.dcor=quantile(val.dcor,.95)
> > >
> > > ## Next we simulate the data again, this time under the alternative
> > >
> > >      for(ii in 1:nsim2) {
> > >        x=runif(n)
> > >
> > > #lin+noise
> > > if(typ==1) {
> > > y=x+ noise *(l/num.noise)* rnorm(n)
> > > }
> > >
> > > #parabolic+noise
> > > if(typ==2) {
> > > y=4*(x-.5)^2+  noise * (l/num.noise) * rnorm(n)
> > > }
> > >
> > > #cubic+noise
> > > if(typ==3) {
> > > y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise  * (l/num.noise)
> > *rnorm(n)
> > > }
> > >
> > > #sin+noise
> > > if(typ==4) {
> > > y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
> > > }
> > >
> > > #their sine + noise
> > > if(typ==5) {
> > > y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
> > > }
> > >
> > > #x^(1/4) + noise
> > > if(typ==6) {
> > > y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
> > > }
> > >
> > > #circle
> > > if(typ==7) {
> > > y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise
> > *rnorm(n)
> > > }
> > >
> > > #step function
> > > if(typ==8) {
> > > y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
> > > }
> > >
> > > ## We again calculate our 4 "correlations"
> > > val.cor2[ii]=(cor(x,y))
> > > val.cors2[ii]=(cor(x,y,method=c("spearman")))
> > > val.cork2[ii]=(cor(x,y,method=c("kendal")))
> > > val.dcor2[ii]=dcor(x,y)
> > > }
> > >
> > > ## Now we estimate the power as the number of alternative statistics
> > #exceeding our estimated cutoffs
> > > power.cor[typ,l] <- sum(val.cor2 > cut.cor)/nsim2
> > > power.cors[typ,l] <- sum(val.cors2 > cut.cor)/nsim2
> > > power.cork[typ,l] <- sum(val.cork2 > cut.cor)/nsim2
> > > power.dcor[typ,l] <- sum(val.dcor2 > cut.dcor)/nsim2
> > > }
> > > }
> > >
> > > save.image()
> > >
> > > ## The rest of the code is for plotting the image
> > > pdf("power.pdf")
> > > par(mfrow = c(4,2), cex = 0.45)
> > > plot((1:30)/10, power.cor[1,], ylim = c(0,1), main = "Linear", xlab =
> > "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> > > points((1:30)/10, power.cors[1,], pch = 2, col = "green", type = 'b')
> > > points((1:30)/10, power.cork[1,], pch = 3, col = "blue", type = 'b')
> > > points((1:30)/10, power.dcor[1,], pch = 4, col = "red", type = 'b')
> > > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
> > pch = c(1,2,3), col = c("black","green","blue","red"))
> > >
> > > plot((1:30)/10, power.cor[2,], ylim = c(0,1), main = "Quadratic", xlab
> =
> > "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> > > points((1:30)/10, power.cors[2,], pch = 2, col = "green", type = 'b')
> > > points((1:30)/10, power.cork[2,], pch = 3, col = "blue", type = 'b')
> > > points((1:30)/10, power.dcor[2,], pch = 4, col = "red", type = 'b')
> > > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
> > pch = c(1,2,3), col = c("black","green","blue","red"))
> > >
> > > plot((1:30)/10, power.cor[3,], ylim = c(0,1), main = "Cubic", xlab =
> > "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> > > points((1:30)/10, power.cors[3,], pch = 2, col = "green", type = 'b')
> > > points((1:30)/10, power.cork[3,], pch = 3, col = "blue", type = 'b')
> > > points((1:30)/10, power.dcor[3,], pch = 4, col = "red", type = 'b')
> > > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
> > pch = c(1,2,3), col = c("black","green","blue","red"))
> > >
> > > plot((1:30)/10, power.cor[5,], ylim = c(0,1), main = "Sine: period
> 1/8",
> > xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> > > points((1:30)/10, power.cors[5,], pch = 2, col = "green", type = 'b')
> > > points((1:30)/10, power.cork[5,], pch = 3, col = "blue", type = 'b')
> > > points((1:30)/10, power.dcor[5,], pch = 4, col = "red", type = 'b')
> > > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
> > pch = c(1,2,3), col = c("black","green","blue","red"))
> > >
> > > plot((1:30)/10, power.cor[4,], ylim = c(0,1), main = "Sine: period
> 1/2",
> > xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> > > points((1:30)/10, power.cors[4,], pch = 2, col = "green", type = 'b')
> > > points((1:30)/10, power.cork[4,], pch = 3, col = "blue", type = 'b')
> > > points((1:30)/10, power.dcor[4,], pch = 4, col = "red", type = 'b')
> > > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
> > pch = c(1,2,3), col = c("black","green","blue","red"))
> > >
> > > plot((1:30)/10, power.cor[6,], ylim = c(0,1), main = "X^(1/4)", xlab =
> > "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> > > points((1:30)/10, power.cors[6,], pch = 2, col = "green", type = 'b')
> > > points((1:30)/10, power.cork[6,], pch = 3, col = "blue", type = 'b')
> > > points((1:30)/10, power.dcor[6,], pch = 4, col = "red", type = 'b')
> > > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
> > pch = c(1,2,3), col = c("black","green","blue","red"))
> > >
> > > plot((1:30)/10, power.cor[7,], ylim = c(0,1), main = "Circle", xlab =
> > "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> > > points((1:30)/10, power.cors[7,], pch = 2, col = "green", type = 'b')
> > > points((1:30)/10, power.cork[7,], pch = 3, col = "blue", type = 'b')
> > > points((1:30)/10, power.dcor[7,], pch = 4, col = "red", type = 'b')
> > > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
> > pch = c(1,2,3), col = c("black","green","blue","red"))
> > >
> > > plot((1:30)/10, power.cor[8,], ylim = c(0,1), main = "Step function",
> > xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> > > points((1:30)/10, power.cors[8,], pch = 2, col = "green", type = 'b')
> > > points((1:30)/10, power.cork[8,], pch = 3, col = "blue", type = 'b')
> > > points((1:30)/10, power.dcor[8,], pch = 4, col = "red", type = 'b')
> > > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
> > pch = c(1,2,3), col = c("black","green","blue","red"))
> > >
> > > #################
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ch@|@b|@e|@he @end|ng |rom y@hoo@de  Tue May 11 13:11:46 2021
From: ch@|@b|@e|@he @end|ng |rom y@hoo@de (Elahe chalabi)
Date: Tue, 11 May 2021 11:11:46 +0000 (UTC)
Subject: [R] Group by and duplicate a value/dplyr
References: <1222077831.4309120.1620731506656.ref@mail.yahoo.com>
Message-ID: <1222077831.4309120.1620731506656@mail.yahoo.com>

Hi all,

I have the following data frame?


dput(df)
? ??structure(list(Department = c("A", "A", "A", "A", "A", "A", "A",?
"A", "B", "B", "B", "B", "B", "B", "B", "B"), Class = c(1L, 1L,?
1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L), Value = c(0L,?
100L, 800L, 800L, 0L, 300L, 1200L, 1200L, 0L, 0L, 400L, 400L,?
200L, 800L, 1200L, 1200L)), class = "data.frame", row.names = c(NA,?
-16L))


I would like to group by "Department" and "Class" and repeat the minimum value of "Valule" excluding zeros or get the second minimum value. The desired output is:


? ??dput(df)
? ??structure(list(Department = c("A", "A", "A", "A", "A", "A", "A",?
"A", "B", "B", "B", "B", "B", "B", "B", "B"), Class = c(1L, 1L,?
1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L), Value = c(0L,?
100L, 800L, 800L, 0L, 300L, 1200L, 1200L, 0L, 0L, 400L, 400L,?
200L, 800L, 1200L, 1200L), MinValue = c(100L, 100L, 100L, 100L,?
300L, 300L, 300L, 300L, 400L, 400L, 400L, 400L, 200L, 200L, 200L,?
200L)), class = "data.frame", row.names = c(NA, -16L))

? ?
how should I change the following dplyr to give me the desired output??


? ?df <-?
? df %>%
? group_by(Department,Class) %>%
? mutate(MinValue=min(Value) )


Thanks for any help.
Elahe


From gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de  Tue May 11 13:26:10 2021
From: gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de (Gerrit Eichner)
Date: Tue, 11 May 2021 13:26:10 +0200
Subject: [R] Group by and duplicate a value/dplyr
In-Reply-To: <1222077831.4309120.1620731506656@mail.yahoo.com>
References: <1222077831.4309120.1620731506656.ref@mail.yahoo.com>
 <1222077831.4309120.1620731506656@mail.yahoo.com>
Message-ID: <fe15327d-599e-965c-3bcb-eb86a0b21c5b@math.uni-giessen.de>

Homework?

Try maybe

mutate(MinValue = min(Value[Value != 0]) )

or

mutate(MinValue = sort(unique(Value))[2])

  Hth  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

Am 11.05.2021 um 13:11 schrieb Elahe chalabi via R-help:
> Hi all,
> 
> I have the following data frame
> 
> 
> dput(df)
>  ? ??structure(list(Department = c("A", "A", "A", "A", "A", "A", "A",
> "A", "B", "B", "B", "B", "B", "B", "B", "B"), Class = c(1L, 1L,
> 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L), Value = c(0L,
> 100L, 800L, 800L, 0L, 300L, 1200L, 1200L, 0L, 0L, 400L, 400L,
> 200L, 800L, 1200L, 1200L)), class = "data.frame", row.names = c(NA,
> -16L))
> 
> 
> I would like to group by "Department" and "Class" and repeat the minimum value of "Valule" excluding zeros or get the second minimum value. The desired output is:
> 
> 
>  ? ??dput(df)
>  ? ??structure(list(Department = c("A", "A", "A", "A", "A", "A", "A",
> "A", "B", "B", "B", "B", "B", "B", "B", "B"), Class = c(1L, 1L,
> 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L), Value = c(0L,
> 100L, 800L, 800L, 0L, 300L, 1200L, 1200L, 0L, 0L, 400L, 400L,
> 200L, 800L, 1200L, 1200L), MinValue = c(100L, 100L, 100L, 100L,
> 300L, 300L, 300L, 300L, 400L, 400L, 400L, 400L, 200L, 200L, 200L,
> 200L)), class = "data.frame", row.names = c(NA, -16L))
> 
>     
> how should I change the following dplyr to give me the desired output?
> 
> 
>  ? ?df <-
>  ? df %>%
>  ? group_by(Department,Class) %>%
>  ? mutate(MinValue=min(Value) )
> 
> 
> Thanks for any help.
> Elahe
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From petr@p|k@| @end|ng |rom prechez@@cz  Tue May 11 13:27:42 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 11 May 2021 11:27:42 +0000
Subject: [R] FW:  Group by and duplicate a value/dplyr
In-Reply-To: <d2435deb59f54329bc09bfd6c5da7295@SRVEXCHCM1302.precheza.cz>
References: <1222077831.4309120.1620731506656.ref@mail.yahoo.com>
 <1222077831.4309120.1620731506656@mail.yahoo.com>
 <d2435deb59f54329bc09bfd6c5da7295@SRVEXCHCM1302.precheza.cz>
Message-ID: <b7b75f61bf2f4245b252cc244091524a@SRVEXCHCM1302.precheza.cz>

I forgot to cc to rhelp.

Petr

Hi
Dunno how to do it by dplyr
I would use ave

df$MinValue <- ave(df$Value, paste(df$Class, df$Department), FUN =
function(x)
min(x[x>0]))

Cheers
Petr



> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Elahe chalabi
> via
> > R-help
> > Sent: Tuesday, May 11, 2021 1:12 PM
> > To: R-help Mailing List <r-help at r-project.org>
> > Subject: [R] Group by and duplicate a value/dplyr
> >
> > Hi all,
> >
> > I have the following data frame
> >
> >
> > dput(df)
> >     structure(list(Department = c("A", "A", "A", "A", "A", "A", "A", "A",
> > "B", "B",
> > "B", "B", "B", "B", "B", "B"), Class = c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
> > 1L,
> > 1L, 1L, 1L,
> > 2L, 2L, 2L, 2L), Value = c(0L, 100L, 800L, 800L, 0L, 300L, 1200L, 1200L, 
> > 0L,
> > 0L,
> > 400L, 400L, 200L, 800L, 1200L, 1200L)), class = "data.frame", row.names =
> > c(NA,
> > -16L))
> >
> >
> > I would like to group by "Department" and "Class" and repeat the minimum
> > value of "Valule" excluding zeros or get the second minimum value. The
> > desired output is:
> >
> >
> >     dput(df)
> >     structure(list(Department = c("A", "A", "A", "A", "A", "A", "A", "A",
> > "B", "B",
> > "B", "B", "B", "B", "B", "B"), Class = c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
> > 1L,
> > 1L, 1L, 1L,
> > 2L, 2L, 2L, 2L), Value = c(0L, 100L, 800L, 800L, 0L, 300L, 1200L, 1200L, 
> > 0L,
> > 0L,
> > 400L, 400L, 200L, 800L, 1200L, 1200L), MinValue = c(100L, 100L, 100L, 
> > 100L,
> > 300L, 300L, 300L, 300L, 400L, 400L, 400L, 400L, 200L, 200L, 200L, 200L)),
> > class =
> > "data.frame", row.names = c(NA, -16L))
> >
> >
> > how should I change the following dplyr to give me the desired output?
> >
> >
> >    df <-
> >   df %>%
> >   group_by(Department,Class) %>%
> >   mutate(MinValue=min(Value) )
> >
> >
> > Thanks for any help.
> > Elahe
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue May 11 13:39:20 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 11 May 2021 12:39:20 +0100
Subject: [R] Group by and duplicate a value/dplyr
In-Reply-To: <1222077831.4309120.1620731506656@mail.yahoo.com>
References: <1222077831.4309120.1620731506656.ref@mail.yahoo.com>
 <1222077831.4309120.1620731506656@mail.yahoo.com>
Message-ID: <628d0bcc-8918-dd2d-b453-3679d91da5b0@sapo.pt>

Hello,

This can be done by getting the min of Value[Value != 0].
In the code that follows I have named the expected output df2 and 
assigned the result to df3 and df4.


library(dplyr)

df3 <- df %>%
   group_by(Department,Class) %>%
   mutate(flag = Value != 0,
     MinValue = min(Value[flag]) ) %>%
   select(-flag)

identical(df2$MinValue, df3$MinValue)
#[1] TRUE


Or, simpler:


df4 <- df %>%
   group_by(Department,Class) %>%
   mutate(MinValue = min(Value[Value != 0]) )

identical(df2$MinValue, df4$MinValue)
#[1] TRUE


Hope this helps,

Rui Barradas



?s 12:11 de 11/05/21, Elahe chalabi via R-help escreveu:
> Hi all,
> 
> I have the following data frame
> 
> 
> dput(df)
>  ? ??structure(list(Department = c("A", "A", "A", "A", "A", "A", "A",
> "A", "B", "B", "B", "B", "B", "B", "B", "B"), Class = c(1L, 1L,
> 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L), Value = c(0L,
> 100L, 800L, 800L, 0L, 300L, 1200L, 1200L, 0L, 0L, 400L, 400L,
> 200L, 800L, 1200L, 1200L)), class = "data.frame", row.names = c(NA,
> -16L))
> 
> 
> I would like to group by "Department" and "Class" and repeat the minimum value of "Valule" excluding zeros or get the second minimum value. The desired output is:
> 
> 
>  ? ??dput(df)
>  ? ??structure(list(Department = c("A", "A", "A", "A", "A", "A", "A",
> "A", "B", "B", "B", "B", "B", "B", "B", "B"), Class = c(1L, 1L,
> 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L), Value = c(0L,
> 100L, 800L, 800L, 0L, 300L, 1200L, 1200L, 0L, 0L, 400L, 400L,
> 200L, 800L, 1200L, 1200L), MinValue = c(100L, 100L, 100L, 100L,
> 300L, 300L, 300L, 300L, 400L, 400L, 400L, 400L, 200L, 200L, 200L,
> 200L)), class = "data.frame", row.names = c(NA, -16L))
> 
>     
> how should I change the following dplyr to give me the desired output?
> 
> 
>  ? ?df <-
>  ? df %>%
>  ? group_by(Department,Class) %>%
>  ? mutate(MinValue=min(Value) )
> 
> 
> Thanks for any help.
> Elahe
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ch@|@b|@e|@he @end|ng |rom y@hoo@de  Tue May 11 13:40:57 2021
From: ch@|@b|@e|@he @end|ng |rom y@hoo@de (Elahe chalabi)
Date: Tue, 11 May 2021 11:40:57 +0000 (UTC)
Subject: [R] Group by and duplicate a value/dplyr
In-Reply-To: <fe15327d-599e-965c-3bcb-eb86a0b21c5b@math.uni-giessen.de>
References: <1222077831.4309120.1620731506656.ref@mail.yahoo.com>
 <1222077831.4309120.1620731506656@mail.yahoo.com>
 <fe15327d-599e-965c-3bcb-eb86a0b21c5b@math.uni-giessen.de>
Message-ID: <903693759.4419750.1620733257904@mail.yahoo.com>

Hello Gerit

mutate(MinValue = min(Value[Value != 0]) )? or? mutate(MinValue = sort(unique(Value))[2]) only mutates one value which is 100, it doesnt mutate minimum?Value != 0 per group by element








On Tuesday, May 11, 2021, 01:26:49 PM GMT+2, Gerrit Eichner <gerrit.eichner at math.uni-giessen.de> wrote: 





Homework?

Try maybe

mutate(MinValue = min(Value[Value != 0]) )

or

mutate(MinValue = sort(unique(Value))[2])

? Hth? --? Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner? ? ? ? ? ? ? ? ? Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de? Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104? ? ? ? ? Arndtstr. 2, 35392 Giessen, Germany
http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

Am 11.05.2021 um 13:11 schrieb Elahe chalabi via R-help:
> Hi all,
> 
> I have the following data frame
> 
> 
> dput(df)
>? ? ??structure(list(Department = c("A", "A", "A", "A", "A", "A", "A",
> "A", "B", "B", "B", "B", "B", "B", "B", "B"), Class = c(1L, 1L,
> 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L), Value = c(0L,
> 100L, 800L, 800L, 0L, 300L, 1200L, 1200L, 0L, 0L, 400L, 400L,
> 200L, 800L, 1200L, 1200L)), class = "data.frame", row.names = c(NA,
> -16L))
> 
> 
> I would like to group by "Department" and "Class" and repeat the minimum value of "Valule" excluding zeros or get the second minimum value. The desired output is:
> 
> 
>? ? ??dput(df)
>? ? ??structure(list(Department = c("A", "A", "A", "A", "A", "A", "A",
> "A", "B", "B", "B", "B", "B", "B", "B", "B"), Class = c(1L, 1L,
> 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L), Value = c(0L,
> 100L, 800L, 800L, 0L, 300L, 1200L, 1200L, 0L, 0L, 400L, 400L,
> 200L, 800L, 1200L, 1200L), MinValue = c(100L, 100L, 100L, 100L,
> 300L, 300L, 300L, 300L, 400L, 400L, 400L, 400L, 200L, 200L, 200L,
> 200L)), class = "data.frame", row.names = c(NA, -16L))
> 
>? ? 
> how should I change the following dplyr to give me the desired output?
> 
> 
>? ? ?df <-
>? ? df %>%
>? ? group_by(Department,Class) %>%
>? ? mutate(MinValue=min(Value) )
> 
> 
> Thanks for any help.
> Elahe

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ch@|@b|@e|@he @end|ng |rom y@hoo@de  Tue May 11 14:07:11 2021
From: ch@|@b|@e|@he @end|ng |rom y@hoo@de (Elahe chalabi)
Date: Tue, 11 May 2021 12:07:11 +0000 (UTC)
Subject: [R] FW:  Group by and duplicate a value/dplyr
In-Reply-To: <b7b75f61bf2f4245b252cc244091524a@SRVEXCHCM1302.precheza.cz>
References: <1222077831.4309120.1620731506656.ref@mail.yahoo.com>
 <1222077831.4309120.1620731506656@mail.yahoo.com>
 <d2435deb59f54329bc09bfd6c5da7295@SRVEXCHCM1302.precheza.cz>
 <b7b75f61bf2f4245b252cc244091524a@SRVEXCHCM1302.precheza.cz>
Message-ID: <1365945208.4420132.1620734831580@mail.yahoo.com>

Hi Petr,

Thanks for your help! it works perfectly fine.?






On Tuesday, May 11, 2021, 01:36:50 PM GMT+2, PIKAL Petr <petr.pikal at precheza.cz> wrote: 





I forgot to cc to rhelp.

Petr


Hi
Dunno how to do it by dplyr
I would use ave

df$MinValue <- ave(df$Value, paste(df$Class, df$Department), FUN =
function(x)
min(x[x>0]))

Cheers
Petr



> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Elahe chalabi
> via
> > R-help
> > Sent: Tuesday, May 11, 2021 1:12 PM
> > To: R-help Mailing List <r-help at r-project.org>
> > Subject: [R] Group by and duplicate a value/dplyr
> >
> > Hi all,
> >
> > I have the following data frame
> >
> >
> > dput(df)
> >? ? structure(list(Department = c("A", "A", "A", "A", "A", "A", "A", "A",
> > "B", "B",
> > "B", "B", "B", "B", "B", "B"), Class = c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
> > 1L,
> > 1L, 1L, 1L,
> > 2L, 2L, 2L, 2L), Value = c(0L, 100L, 800L, 800L, 0L, 300L, 1200L, 1200L, 
> > 0L,
> > 0L,
> > 400L, 400L, 200L, 800L, 1200L, 1200L)), class = "data.frame", row.names =
> > c(NA,
> > -16L))
> >
> >
> > I would like to group by "Department" and "Class" and repeat the minimum
> > value of "Valule" excluding zeros or get the second minimum value. The
> > desired output is:
> >
> >
> >? ? dput(df)
> >? ? structure(list(Department = c("A", "A", "A", "A", "A", "A", "A", "A",
> > "B", "B",
> > "B", "B", "B", "B", "B", "B"), Class = c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
> > 1L,
> > 1L, 1L, 1L,
> > 2L, 2L, 2L, 2L), Value = c(0L, 100L, 800L, 800L, 0L, 300L, 1200L, 1200L, 
> > 0L,
> > 0L,
> > 400L, 400L, 200L, 800L, 1200L, 1200L), MinValue = c(100L, 100L, 100L, 
> > 100L,
> > 300L, 300L, 300L, 300L, 400L, 400L, 400L, 400L, 200L, 200L, 200L, 200L)),
> > class =
> > "data.frame", row.names = c(NA, -16L))
> >
> >
> > how should I change the following dplyr to give me the desired output?
> >
> >
> >? ? df <-
> >? df %>%
> >? group_by(Department,Class) %>%
> >? mutate(MinValue=min(Value) )
> >
> >
> > Thanks for any help.
> > Elahe
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de  Tue May 11 15:10:45 2021
From: gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de (Gerrit Eichner)
Date: Tue, 11 May 2021 15:10:45 +0200
Subject: [R] Group by and duplicate a value/dplyr
In-Reply-To: <903693759.4419750.1620733257904@mail.yahoo.com>
References: <1222077831.4309120.1620731506656.ref@mail.yahoo.com>
 <1222077831.4309120.1620731506656@mail.yahoo.com>
 <fe15327d-599e-965c-3bcb-eb86a0b21c5b@math.uni-giessen.de>
 <903693759.4419750.1620733257904@mail.yahoo.com>
Message-ID: <dec6b8b9-4374-b4a3-5aac-defc1031a071@math.uni-giessen.de>

Hello, Elahe,

you were, of course, supposed to insert my suggested
code-snippet into you code and test it therein ...

  Regards  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

Am 11.05.2021 um 13:40 schrieb Elahe chalabi:
> Hello Gerit
> 
> mutate(MinValue = min(Value[Value != 0]) )? or? mutate(MinValue = sort(unique(Value))[2]) only mutates one value which is 100, it doesnt mutate minimum?Value != 0 per group by element
> 
> 
> 
> 
> 
> 
> 
> 
> On Tuesday, May 11, 2021, 01:26:49 PM GMT+2, Gerrit Eichner <gerrit.eichner at math.uni-giessen.de> wrote:
> 
> 
> 
> 
> 
> Homework?
> 
> Try maybe
> 
> mutate(MinValue = min(Value[Value != 0]) )
> 
> or
> 
> mutate(MinValue = sort(unique(Value))[2])
> 
>  ? Hth? --? Gerrit
> 
> ---------------------------------------------------------------------
> Dr. Gerrit Eichner? ? ? ? ? ? ? ? ? Mathematical Institute, Room 212
> gerrit.eichner at math.uni-giessen.de? Justus-Liebig-University Giessen
> Tel: +49-(0)641-99-32104? ? ? ? ? Arndtstr. 2, 35392 Giessen, Germany
> http://www.uni-giessen.de/eichner
> ---------------------------------------------------------------------
> 
> Am 11.05.2021 um 13:11 schrieb Elahe chalabi via R-help:
>> Hi all,
>>
>> I have the following data frame
>>
>>
>> dput(df)
>>  ? ? ??structure(list(Department = c("A", "A", "A", "A", "A", "A", "A",
>> "A", "B", "B", "B", "B", "B", "B", "B", "B"), Class = c(1L, 1L,
>> 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L), Value = c(0L,
>> 100L, 800L, 800L, 0L, 300L, 1200L, 1200L, 0L, 0L, 400L, 400L,
>> 200L, 800L, 1200L, 1200L)), class = "data.frame", row.names = c(NA,
>> -16L))
>>
>>
>> I would like to group by "Department" and "Class" and repeat the minimum value of "Valule" excluding zeros or get the second minimum value. The desired output is:
>>
>>
>>  ? ? ??dput(df)
>>  ? ? ??structure(list(Department = c("A", "A", "A", "A", "A", "A", "A",
>> "A", "B", "B", "B", "B", "B", "B", "B", "B"), Class = c(1L, 1L,
>> 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L), Value = c(0L,
>> 100L, 800L, 800L, 0L, 300L, 1200L, 1200L, 0L, 0L, 400L, 400L,
>> 200L, 800L, 1200L, 1200L), MinValue = c(100L, 100L, 100L, 100L,
>> 300L, 300L, 300L, 300L, 400L, 400L, 400L, 400L, 200L, 200L, 200L,
>> 200L)), class = "data.frame", row.names = c(NA, -16L))
>>
>>      
>> how should I change the following dplyr to give me the desired output?
>>
>>
>>  ? ? ?df <-
>>  ? ? df %>%
>>  ? ? group_by(Department,Class) %>%
>>  ? ? mutate(MinValue=min(Value) )
>>
>>
>> Thanks for any help.
>> Elahe
> 
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From S@E|||@on @end|ng |rom LGCGroup@com  Tue May 11 16:20:28 2021
From: S@E|||@on @end|ng |rom LGCGroup@com (Stephen Ellison)
Date: Tue, 11 May 2021 14:20:28 +0000
Subject: [R] calculating area of ellipse
Message-ID: <12cb19b5dcf447b78504324790b5a359@GBDCVPEXC04.corp.lgc-group.com>

> In doing meta-analysis of diagnostic accuracy I produce ellipses of confidence
> and prediction intervals in two dimensions.  How can I calculate the area of
> the ellipse in ggplot2 or base R?

There are established formulae for ellipse area, but I am curious: in a 2-d ellipse with different quantities (eg coefficients for salary and age) represented by the different dimensions, what does 'area' mean?

S


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From j|ox @end|ng |rom mcm@@ter@c@  Tue May 11 16:30:22 2021
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Tue, 11 May 2021 10:30:22 -0400
Subject: [R] calculating area of ellipse
In-Reply-To: <27354_1620742859_14BEJAU3016065_12cb19b5dcf447b78504324790b5a359@GBDCVPEXC04.corp.lgc-group.com>
References: <27354_1620742859_14BEJAU3016065_12cb19b5dcf447b78504324790b5a359@GBDCVPEXC04.corp.lgc-group.com>
Message-ID: <afc58281-7c2f-0d12-4936-2305e776dfc4@mcmaster.ca>

Dear Stephen,

On 2021-05-11 10:20 a.m., Stephen Ellison wrote:
 >> In doing meta-analysis of diagnostic accuracy I produce ellipses of 
confidence
 >> and prediction intervals in two dimensions.  How can I calculate the 
area of
 >> the ellipse in ggplot2 or base R?
 >
 > There are established formulae for ellipse area, but I am curious: in 
a 2-d ellipse with different quantities (eg coefficients for salary and 
age) represented by the different dimensions, what does 'area' mean?

I answered James's question narrowly, but the point you raise is correct 
-- the area isn't directly interpretable unless the coefficients are 
measured in the same units.

It still may be possible to compare areas of ellipsoids for, say, 
different regressions with the same predictors, as ratios, however, 
since these ratios would be unaffected by rescaling the coefficients. 
The generalization of this idea to ellipsoids of any dimension is the 
basis for the generalized variance-inflation factors computed by the 
vif() function in the car package.

Best,
  John

John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

 >
 > S
 >
 >
 > *******************************************************************
 > This email and any attachments are confidential. Any use...{{dropped:8}}
 >
 > ______________________________________________
 > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
 > and provide commented, minimal, self-contained, reproducible code.
 >


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue May 11 16:48:16 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 11 May 2021 07:48:16 -0700
Subject: [R] calculating area of ellipse
In-Reply-To: <afc58281-7c2f-0d12-4936-2305e776dfc4@mcmaster.ca>
References: <27354_1620742859_14BEJAU3016065_12cb19b5dcf447b78504324790b5a359@GBDCVPEXC04.corp.lgc-group.com>
 <afc58281-7c2f-0d12-4936-2305e776dfc4@mcmaster.ca>
Message-ID: <A0F333A3-9581-489D-8012-B9609CFC3159@dcn.davis.ca.us>

The area is a product, not a ratio. There are certainly examples out there of meaningful products of different units, such as distance * force (work) or power " time (work).

If you choose to form a ratio with the area as numerator, you could conceivably obtain the numerator with force snd distance and then meaningfully form a ratio with time (power). So this asserted requirement as to homogeneous units seems inaccurate. But without context I don't know if any of this will aid in interpretation of variance for the OP.

On May 11, 2021 7:30:22 AM PDT, John Fox <jfox at mcmaster.ca> wrote:
>Dear Stephen,
>
>On 2021-05-11 10:20 a.m., Stephen Ellison wrote:
>>> In doing meta-analysis of diagnostic accuracy I produce ellipses of 
>confidence
>>> and prediction intervals in two dimensions.  How can I calculate the
>
>area of
> >> the ellipse in ggplot2 or base R?
> >
>> There are established formulae for ellipse area, but I am curious: in
>
>a 2-d ellipse with different quantities (eg coefficients for salary and
>
>age) represented by the different dimensions, what does 'area' mean?
>
>I answered James's question narrowly, but the point you raise is
>correct 
>-- the area isn't directly interpretable unless the coefficients are 
>measured in the same units.
>
>It still may be possible to compare areas of ellipsoids for, say, 
>different regressions with the same predictors, as ratios, however, 
>since these ratios would be unaffected by rescaling the coefficients. 
>The generalization of this idea to ellipsoids of any dimension is the 
>basis for the generalized variance-inflation factors computed by the 
>vif() function in the car package.
>
>Best,
>  John
>
>John Fox, Professor Emeritus
>McMaster University
>Hamilton, Ontario, Canada
>web: https://socialsciences.mcmaster.ca/jfox/
>
> >
> > S
> >
> >
> > *******************************************************************
>> This email and any attachments are confidential. Any
>use...{{dropped:8}}
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
>http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Tue May 11 19:06:03 2021
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Tue, 11 May 2021 18:06:03 +0100
Subject: [R] calculating area of ellipse
In-Reply-To: <12cb19b5dcf447b78504324790b5a359@GBDCVPEXC04.corp.lgc-group.com>
References: <12cb19b5dcf447b78504324790b5a359@GBDCVPEXC04.corp.lgc-group.com>
Message-ID: <5e9ec32c-9ce0-74b3-0f1e-3f422ee11b2c@dewey.myzen.co.uk>

Dear Stephen

In that application the axes would be sensitivity and specificity (or 
their inverses) or some transformation of them like logits so the units 
would be the same. Whether the area has any scientific meaning I am not 
sure.

Michael

On 11/05/2021 15:20, Stephen Ellison wrote:
>> In doing meta-analysis of diagnostic accuracy I produce ellipses of confidence
>> and prediction intervals in two dimensions.  How can I calculate the area of
>> the ellipse in ggplot2 or base R?
> 
> There are established formulae for ellipse area, but I am curious: in a 2-d ellipse with different quantities (eg coefficients for salary and age) represented by the different dimensions, what does 'area' mean?
> 
> S
> 
> 
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:13}}


From j|ox @end|ng |rom mcm@@ter@c@  Tue May 11 19:21:04 2021
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Tue, 11 May 2021 13:21:04 -0400
Subject: [R] calculating area of ellipse
In-Reply-To: <29148_1620744532_14BEl3Vk006355_A0F333A3-9581-489D-8012-B9609CFC3159@dcn.davis.ca.us>
References: <27354_1620742859_14BEJAU3016065_12cb19b5dcf447b78504324790b5a359@GBDCVPEXC04.corp.lgc-group.com>
 <afc58281-7c2f-0d12-4936-2305e776dfc4@mcmaster.ca>
 <29148_1620744532_14BEl3Vk006355_A0F333A3-9581-489D-8012-B9609CFC3159@dcn.davis.ca.us>
Message-ID: <05da711f-8b93-b064-54dd-9614edfb33c4@mcmaster.ca>

Dear Jeff,

I don't think that it would be sensible to claim that it *never* makes 
sense to multiply quantities measured in different units, but rather 
that this would rarely make sense for regression coefficients. James 
might have a justification for finding the area, but it is still, I 
think, reasonable to point out that doing so may be problematic.

With respect to ratios of areas: I apologize if my examples were 
cryptic. Imagine, for example, that the same regression model is fit to 
two groups and joint-confidence ellipse for two coefficients computed 
for each. The ratio of the two areas would reflect the relative 
precision of the estimates in the two groups, which is unaffected by the 
units of measurement of the coefficients. This is also the idea behind 
generalized variance inflation, where the comparison is to a "utopian" 
situation in which the parameters are uncorrelated. For details, see 
help("vif", package="car") and in particular Fox, J. and Monette, G. 
(1992) Generalized collinearity diagnostics. JASA, 87, 178?183.

Best,
  John


On 2021-05-11 10:48 a.m., Jeff Newmiller wrote:
> The area is a product, not a ratio. There are certainly examples out there of meaningful products of different units, such as distance * force (work) or power " time (work).
> 
> If you choose to form a ratio with the area as numerator, you could conceivably obtain the numerator with force snd distance and then meaningfully form a ratio with time (power). So this asserted requirement as to homogeneous units seems inaccurate. But without context I don't know if any of this will aid in interpretation of variance for the OP.
> 
> On May 11, 2021 7:30:22 AM PDT, John Fox <jfox at mcmaster.ca> wrote:
>> Dear Stephen,
>>
>> On 2021-05-11 10:20 a.m., Stephen Ellison wrote:
>>>> In doing meta-analysis of diagnostic accuracy I produce ellipses of
>> confidence
>>>> and prediction intervals in two dimensions.  How can I calculate the
>>
>> area of
>>>> the ellipse in ggplot2 or base R?
>>>
>>> There are established formulae for ellipse area, but I am curious: in
>>
>> a 2-d ellipse with different quantities (eg coefficients for salary and
>>
>> age) represented by the different dimensions, what does 'area' mean?
>>
>> I answered James's question narrowly, but the point you raise is
>> correct
>> -- the area isn't directly interpretable unless the coefficients are
>> measured in the same units.
>>
>> It still may be possible to compare areas of ellipsoids for, say,
>> different regressions with the same predictors, as ratios, however,
>> since these ratios would be unaffected by rescaling the coefficients.
>> The generalization of this idea to ellipsoids of any dimension is the
>> basis for the generalized variance-inflation factors computed by the
>> vif() function in the car package.
>>
>> Best,
>>   John
>>
>> John Fox, Professor Emeritus
>> McMaster University
>> Hamilton, Ontario, Canada
>> web: https://socialsciences.mcmaster.ca/jfox/
>>
>>>
>>> S
>>>
>>>
>>> *******************************************************************
>>> This email and any attachments are confidential. Any
>> use...{{dropped:8}}
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Tue May 11 19:59:51 2021
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Tue, 11 May 2021 17:59:51 +0000 (UTC)
Subject: [R] No error message but don't get the 8 graphs
In-Reply-To: <CAHqSRuR52W2to6UYMe_Mmv500AZx9CwMz7s7+oR4kcsVocN=ww@mail.gmail.com>
References: <294893856.3283193.1620585572644.ref@mail.yahoo.com>
 <294893856.3283193.1620585572644@mail.yahoo.com>
 <b9186679-16a2-d6e4-afac-eecebbba7e01@sapo.pt>
 <1115549345.3369846.1620597015000@mail.yahoo.com>
 <CAGxFJbTdN4e9RtgFVBsPA1ktbNXo66KpQ6d9=Tv7LveNz3OqxQ@mail.gmail.com>
 <CAHqSRuR52W2to6UYMe_Mmv500AZx9CwMz7s7+oR4kcsVocN=ww@mail.gmail.com>
Message-ID: <1754150943.4687777.1620755991674@mail.yahoo.com>

Dear all,

Many thanks for your responses.

Best
S.







Le lundi 10 mai 2021 ? 17:18:59 UTC+2, Bill Dunlap <williamwdunlap at gmail.com> a ?crit : 





Also, normalizePath("power.pdf").

On Sun, May 9, 2021 at 5:13 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> ?getwd
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Sun, May 9, 2021 at 2:59 PM varin sacha via R-help <r-help at r-project.org>
> wrote:
> 
>> Rui,
>>
>> The created pdf.file is off-screen device. Indeed after dev.off() I should
>> view the pdf file on my computer. But I don't find it. Where do I find the
>> pdf.file ?
>>
>> Regards,
>>
>>
>>
>> Le dimanche 9 mai 2021 ? 22:44:22 UTC+2, Rui Barradas <
>> ruipbarradas at sapo.pt> a ?crit :
>>
>>
>>
>>
>>
>> Hello,
>>
>> You are not closing the pdf device.
>> The only changes I have made to your code are right at the beginning of
>> the plotting instructions and at the end of the code.
>>
>>
>> ## The rest of the code is for plotting the image
>> pdf(file = "power.pdf")
>> op <- par(mfrow = c(4,2), cex = 0.45)
>>
>> [...]
>>
>> par(op)
>> dev.off()
>> #################
>>
>> The comments only line is your last code line.
>> The result is attached.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?s 19:39 de 09/05/21, varin sacha via R-help escreveu:
>> > Dear R-experts,
>> >
>> > I am trying to get the 8 graphs like the ones in this paper :
>> > https://statweb.stanford.edu/~tibs/reshef/comment.pdf
>> > My R code does not show any error message neither warnings but I d'on't
>> get what I would like to get (I mean the 8 graphs), so I am missing
>> something. What's it ? Many thanks for your precious help.
>> >
>> > #################
>> > set.seed(1)
>> > library(energy)
>> >
>> > # Here we define parameters which we use to simulate the data
>> > # The number of null datasets we use to estimate our rejection reject
>> #regions for an alternative with level 0.05
>> > nsim=50
>> >
>> > # Number of alternative datasets we use to estimate our power
>> > nsim2=50
>> >
>> > # The number of different noise levels used
>> > num.noise <- 30
>> >
>> > # A constant to determine the amount of noise
>> > noise <- 3
>> >
>> > # Number of data points per simulation
>> > n=100
>> >
>> > # Vectors holding the null "correlations" (for pearson, for spearman,
>> for kendall and dcor respectively) for each # of the nsim null datasets at
>> a #given noise level
>> > val.cor=val.cors=val.cork=val.dcor=rep(NA,nsim)
>> >
>> > # Vectors holding the alternative "correlations" (for pearson, for
>> #spearman, for kendall and dcor respectively) #for each of the nsim2
>> alternative datasets at a given noise level
>> > val.cor2=val.cors2=val.cork2=val.dcor2= rep(NA,nsim2)
>> >
>> >
>> > # Arrays holding the estimated power for each of the 4 "correlation"
>> types, for each data type (linear, #parabolic, etc...) with each noise level
>> > power.cor=power.cors=power.cork=power.dcor= array(NA, c(8,num.noise))
>> >
>> > ## We loop through the noise level and functional form; each time we
>> #estimate a null distribution based on #the marginals of the data, and then
>> #use that null distribution to estimate power
>> > ## We use a uniformly distributed x, because in the original paper the
>> #authors used the same
>> >
>> > for(l in 1:num.noise) {
>> >
>> >? ? ? ? for(typ in 1:8) {
>> >
>> > ## This next loop simulates data under the null with the correct
>> marginals (x is uniform, and y is a function of a #uniform with gaussian
>> noise)
>> >
>> >? ? ? for(ii in 1:nsim) {
>> >? ? ? ? x=runif(n)
>> >
>> > #lin+noise
>> > if(typ==1) {
>> > y=x+ noise *(l/num.noise)* rnorm(n)
>> > }
>> >
>> > #parabolic+noise
>> > if(typ==2) {
>> > y=4*(x-.5)^2+? noise * (l/num.noise) * rnorm(n)
>> > }
>> >
>> > #cubic+noise
>> > if(typ==3) {
>> > y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise? * (l/num.noise)
>> *rnorm(n)
>> > }
>> >
>> > #sin+noise
>> > if(typ==4) {
>> > y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
>> > }
>> >
>> > #their sine + noise
>> > if(typ==5) {
>> > y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
>> > }
>> >
>> > #x^(1/4) + noise
>> > if(typ==6) {
>> > y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
>> > }
>> >
>> > #circle
>> > if(typ==7) {
>> > y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise
>> *rnorm(n)
>> > }
>> >
>> > #step function
>> > if(typ==8) {
>> > y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
>> > }
>> >
>> > # We resimulate x so that we have the null scenario
>> > x <- runif(n)
>> >
>> > # Calculate the 4 correlations
>> > val.cor[ii]=(cor(x,y))
>> > val.cors[ii]=(cor(x,y,method=c("spearman")))
>> > val.cork[ii]=(cor(x,y,method=c("kendal")))
>> > val.dcor[ii]=dcor(x,y)
>> > }
>> >
>> > ## Next we calculate our 4 rejection cutoffs
>> > cut.cor=quantile(val.cor,.95)
>> > cut.cors=quantile(val.cors,.95)
>> > cut.cork=quantile(val.cork,.95)
>> > cut.dcor=quantile(val.dcor,.95)
>> >
>> > ## Next we simulate the data again, this time under the alternative
>> >
>> >? ? ? for(ii in 1:nsim2) {
>> >? ? ? ? x=runif(n)
>> >
>> > #lin+noise
>> > if(typ==1) {
>> > y=x+ noise *(l/num.noise)* rnorm(n)
>> > }
>> >
>> > #parabolic+noise
>> > if(typ==2) {
>> > y=4*(x-.5)^2+? noise * (l/num.noise) * rnorm(n)
>> > }
>> >
>> > #cubic+noise
>> > if(typ==3) {
>> > y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise? * (l/num.noise)
>> *rnorm(n)
>> > }
>> >
>> > #sin+noise
>> > if(typ==4) {
>> > y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
>> > }
>> >
>> > #their sine + noise
>> > if(typ==5) {
>> > y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
>> > }
>> >
>> > #x^(1/4) + noise
>> > if(typ==6) {
>> > y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
>> > }
>> >
>> > #circle
>> > if(typ==7) {
>> > y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise
>> *rnorm(n)
>> > }
>> >
>> > #step function
>> > if(typ==8) {
>> > y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
>> > }
>> >
>> > ## We again calculate our 4 "correlations"
>> > val.cor2[ii]=(cor(x,y))
>> > val.cors2[ii]=(cor(x,y,method=c("spearman")))
>> > val.cork2[ii]=(cor(x,y,method=c("kendal")))
>> > val.dcor2[ii]=dcor(x,y)
>> > }
>> >
>> > ## Now we estimate the power as the number of alternative statistics
>> #exceeding our estimated cutoffs
>> > power.cor[typ,l] <- sum(val.cor2 > cut.cor)/nsim2
>> > power.cors[typ,l] <- sum(val.cors2 > cut.cor)/nsim2
>> > power.cork[typ,l] <- sum(val.cork2 > cut.cor)/nsim2
>> > power.dcor[typ,l] <- sum(val.dcor2 > cut.dcor)/nsim2
>> > }
>> > }
>> >
>> > save.image()
>> >
>> > ## The rest of the code is for plotting the image
>> > pdf("power.pdf")
>> > par(mfrow = c(4,2), cex = 0.45)
>> > plot((1:30)/10, power.cor[1,], ylim = c(0,1), main = "Linear", xlab =
>> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> > points((1:30)/10, power.cors[1,], pch = 2, col = "green", type = 'b')
>> > points((1:30)/10, power.cork[1,], pch = 3, col = "blue", type = 'b')
>> > points((1:30)/10, power.dcor[1,], pch = 4, col = "red", type = 'b')
>> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>> pch = c(1,2,3), col = c("black","green","blue","red"))
>> >
>> > plot((1:30)/10, power.cor[2,], ylim = c(0,1), main = "Quadratic", xlab =
>> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> > points((1:30)/10, power.cors[2,], pch = 2, col = "green", type = 'b')
>> > points((1:30)/10, power.cork[2,], pch = 3, col = "blue", type = 'b')
>> > points((1:30)/10, power.dcor[2,], pch = 4, col = "red", type = 'b')
>> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>> pch = c(1,2,3), col = c("black","green","blue","red"))
>> >
>> > plot((1:30)/10, power.cor[3,], ylim = c(0,1), main = "Cubic", xlab =
>> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> > points((1:30)/10, power.cors[3,], pch = 2, col = "green", type = 'b')
>> > points((1:30)/10, power.cork[3,], pch = 3, col = "blue", type = 'b')
>> > points((1:30)/10, power.dcor[3,], pch = 4, col = "red", type = 'b')
>> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>> pch = c(1,2,3), col = c("black","green","blue","red"))
>> >
>> > plot((1:30)/10, power.cor[5,], ylim = c(0,1), main = "Sine: period 1/8",
>> xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> > points((1:30)/10, power.cors[5,], pch = 2, col = "green", type = 'b')
>> > points((1:30)/10, power.cork[5,], pch = 3, col = "blue", type = 'b')
>> > points((1:30)/10, power.dcor[5,], pch = 4, col = "red", type = 'b')
>> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>> pch = c(1,2,3), col = c("black","green","blue","red"))
>> >
>> > plot((1:30)/10, power.cor[4,], ylim = c(0,1), main = "Sine: period 1/2",
>> xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> > points((1:30)/10, power.cors[4,], pch = 2, col = "green", type = 'b')
>> > points((1:30)/10, power.cork[4,], pch = 3, col = "blue", type = 'b')
>> > points((1:30)/10, power.dcor[4,], pch = 4, col = "red", type = 'b')
>> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>> pch = c(1,2,3), col = c("black","green","blue","red"))
>> >
>> > plot((1:30)/10, power.cor[6,], ylim = c(0,1), main = "X^(1/4)", xlab =
>> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> > points((1:30)/10, power.cors[6,], pch = 2, col = "green", type = 'b')
>> > points((1:30)/10, power.cork[6,], pch = 3, col = "blue", type = 'b')
>> > points((1:30)/10, power.dcor[6,], pch = 4, col = "red", type = 'b')
>> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>> pch = c(1,2,3), col = c("black","green","blue","red"))
>> >
>> > plot((1:30)/10, power.cor[7,], ylim = c(0,1), main = "Circle", xlab =
>> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> > points((1:30)/10, power.cors[7,], pch = 2, col = "green", type = 'b')
>> > points((1:30)/10, power.cork[7,], pch = 3, col = "blue", type = 'b')
>> > points((1:30)/10, power.dcor[7,], pch = 4, col = "red", type = 'b')
>> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>> pch = c(1,2,3), col = c("black","green","blue","red"))
>> >
>> > plot((1:30)/10, power.cor[8,], ylim = c(0,1), main = "Step function",
>> xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> > points((1:30)/10, power.cors[8,], pch = 2, col = "green", type = 'b')
>> > points((1:30)/10, power.cork[8,], pch = 3, col = "blue", type = 'b')
>> > points((1:30)/10, power.dcor[8,], pch = 4, col = "red", type = 'b')
>> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>> pch = c(1,2,3), col = c("black","green","blue","red"))
>> >
>> > #################
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ? ? ? ? [[alternative HTML version deleted]]
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Wed May 12 10:33:27 2021
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Wed, 12 May 2021 08:33:27 +0000 (UTC)
Subject: [R] empty plots !
In-Reply-To: <1754150943.4687777.1620755991674@mail.yahoo.com>
References: <294893856.3283193.1620585572644.ref@mail.yahoo.com>
 <294893856.3283193.1620585572644@mail.yahoo.com>
 <b9186679-16a2-d6e4-afac-eecebbba7e01@sapo.pt>
 <1115549345.3369846.1620597015000@mail.yahoo.com>
 <CAGxFJbTdN4e9RtgFVBsPA1ktbNXo66KpQ6d9=Tv7LveNz3OqxQ@mail.gmail.com>
 <CAHqSRuR52W2to6UYMe_Mmv500AZx9CwMz7s7+oR4kcsVocN=ww@mail.gmail.com>
 <1754150943.4687777.1620755991674@mail.yahoo.com>
Message-ID: <1662076064.4942636.1620808407847@mail.yahoo.com>

Dear Experts,

My R code was perfectly working since I decide to add a 5th correlation coefficient : hoeffdings' D.
fter a google search, I guess I need somewhere in my R code "unlist" but I don't know where !
Here below my R code with 1 error message. At the end I get my 8 plots but they are empty !
Many thanks for your precious help !

################# 
set.seed(1)
library(energy)
library(independence)
library(TauStar)

# Here we define parameters which we use to simulate the data 
# The number of null datasets we use to estimate our rejection reject #regions for an alternative with level 0.05
nsim=50

# Number of alternative datasets we use to estimate our power
nsim2=50

# The number of different noise levels used
num.noise <- 30????????????????????

# A constant to determine the amount of noise
noise <- 3?

# Number of data points per simulation

n=100

# Vectors holding the null "correlations" (for pearson, for spearman, for #kendall, for hoeffding and dcor respectively) for each of the nsim null datasets at a #given noise level
val.cor=val.cors=val.cork=val.dcor=val.hoe=rep(NA,nsim)

# Vectors holding the alternative "correlations" (for pearson, for #spearman, for kendall, for hoeffding and dcor respectively) for each of #the nsim2 #alternative datasets at a given noise level
val.cor2=val.cors2=val.cork2=val.dcor2=val.hoe2= rep(NA,nsim2)
?
# Arrays holding the estimated power for each of the 4 "correlation" types, #for each data type (linear, parabolic, etc...) with each noise level
power.cor=power.cors=power.cork=power.dcor=power.hoe= array(NA, c(8,num.noise))

## We loop through the noise level and functional form; each time we #estimate a null distribution based on the marginals of the data, and then #use that null distribution to estimate power 
## We use a uniformly distributed x, because in the original paper the #authors used the same

for(l in 1:num.noise){??

????? for(typ in 1:8){

## This next loop simulates data under the null with the correct marginals #(x is uniform, and y is a function of a uniform with gaussian noise)
?
??? for(ii in 1:nsim){?????? 
????? x=runif(n)

#lin+noise?????????? ??????????????????????????????????????????????
if(typ==1){????????
y=x+ noise *(l/num.noise)* rnorm(n)??????
}
?
#parabolic+noise
if(typ==2){????????
y=4*(x-.5)^2+? noise * (l/num.noise) * rnorm(n)??????
}

#cubic+noise
if(typ==3){????????
y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise? * (l/num.noise) *rnorm(n)??????
}

#sin+noise
if(typ==4){????????
y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)??????
}

#their sine + noise
if(typ==5){????????
y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)??????
}

#x^(1/4) + noise
if(typ==6){????????
y=x^(1/4) + noise * (l/num.noise) *rnorm(n)??????
}

#circle
if(typ==7){????????
y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise *rnorm(n)??????
}

#step function
if(typ==8){???? ????
y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)??????
}??????

# We resimulate x so that we have the null scenario
x <- runif(n)

# Calculate the 5 correlations????? ??????
val.cor[ii]=(cor(x,y))
val.cors[ii]=(cor(x,y,method=c("spearman")))
val.cork[ii]=(cor(x,y,method=c("kendal")))
val.dcor[ii]=dcor(x,y)??? ?????????
val.hoe[ii]=(hoeffding.D.test(x,y,na.rm=TRUE,collisions=TRUE))??? ?????????
}

## Next we calculate our 5 rejection cutoffs?????????
cut.cor=quantile(val.cor,.95)????
cut.cors=quantile(val.cors,.95)
cut.cork=quantile(val.cork,.95)
cut.dcor=quantile(val.dcor,.95)
cut.hoe=quantile(val.hoe,.95)

## Next we simulate the data again, this time under the alternative

??? for(ii in 1:nsim2){?????? 
????? x=runif(n)

#lin+noise?????????????????????? ??????????????????????????????????
if(typ==1){????????
y=x+ noise *(l/num.noise)* rnorm(n)??????
}

#parabolic+noise
if(typ==2){????????
y=4*(x-.5)^2+? noise * (l/num.noise) * rnorm(n)??????
}

#cubic+noise
if(typ==3){????????
y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise? * (l/num.noise) *rnorm(n)??????
}

#sin+noise
if(typ==4){????????
y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)??????
}

#their sine + noise
if(typ==5){????????
y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)??????
}

#x^(1/4) + noise
if(typ==6){????????
y=x^(1/4) + noise * (l/num.noise) *rnorm(n)??????
}

#circle
if(typ==7){????????
y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise *rnorm(n)??????
}

#step function
if(typ==8){????????
y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)??????
}??????

## We again calculate our 5 correlations?????????????
val.cor2[ii]=(cor(x,y))??????
val.cors2[ii]=(cor(x,y,method=c("spearman")))
val.cork2[ii]=(cor(x,y,method=c("kendal")))
val.dcor2[ii]=dcor(x,y)?
val.hoe2[ii]=(hoeffding.D.test(x,y,na.rm=TRUE,collisions=TRUE))??? ??????????????????????
}

## Now we estimate the power as the number of alternative statistics #exceeding our estimated cutoffs?????????
power.cor[typ,l] <- sum(val.cor2 > cut.cor)/nsim2????
power.cors[typ,l] <- sum(val.cors2 > cut.cor)/nsim2
power.cork[typ,l] <- sum(val.cork2 > cut.cor)/nsim2
power.dcor[typ,l] <- sum(val.dcor2 > cut.dcor)/nsim2
power.hoe[typ,l] <- sum(val.hoe2 > cut.hoe)/nsim2??????
}
}

## The rest of the code is for plotting the image?
par(mfrow = c(4,2), cex = 0.45)
plot((1:30)/10, power.cor[1,], ylim = c(0,1), main = "Linear", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
points((1:30)/10, power.cors[1,], pch = 2, col = "green", type = 'b')
points((1:30)/10, power.cork[1,], pch = 3, col = "blue", type = 'b')
points((1:30)/10, power.dcor[1,], pch = 4, col = "red", type = 'b')
points((1:30)/10, power.hoe[1,], pch = 5, col = "purple", type = 'b')
legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red",?"purple"))

plot((1:30)/10, power.cor[2,], ylim = c(0,1), main = "Quadratic", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
points((1:30)/10, power.cors[2,], pch = 2, col = "green", type = 'b')
points((1:30)/10, power.cork[2,], pch = 3, col = "blue", type = 'b')
points((1:30)/10, power.dcor[2,], pch = 4, col = "red", type = 'b')
points((1:30)/10, power.hoe[2,], pch = 5, col = "purple", type = 'b')
legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red",?"purple"))

plot((1:30)/10, power.cor[3,], ylim = c(0,1), main = "Cubic", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
points((1:30)/10, power.cors[3,], pch = 2, col = "green", type = 'b')
points((1:30)/10, power.cork[3,], pch = 3, col = "blue", type = 'b')
points((1:30)/10, power.dcor[3,], pch = 4, col = "red", type = 'b')
points((1:30)/10, power.hoe[3,], pch = 5, col = "purple", type = 'b')
legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red",?"purple")) 

plot((1:30)/10, power.cor[5,], ylim = c(0,1), main = "Sine: period 1/8", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
points((1:30)/10, power.cors[5,], pch = 2, col = "green", type = 'b')
points((1:30)/10, power.cork[5,], pch = 3, col = "blue", type = 'b')
points((1:30)/10, power.dcor[5,], pch = 4, col = "red", type = 'b')
points((1:30)/10, power.hoe[5,], pch = 5, col = "purple", type = 'b')
legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red",?"purple")) 

plot((1:30)/10, power.cor[4,], ylim = c(0,1), main = "Sine: period 1/2", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
points((1:30)/10, power.cors[4,], pch = 2, col = "green", type = 'b')
points((1:30)/10, power.cork[4,], pch = 3, col = "blue", type = 'b')
points((1:30)/10, power.dcor[4,], pch = 4, col = "red", type = 'b')
points((1:30)/10, power.hoe[4,], pch = 5, col = "purple", type = 'b')
legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red",?"purple")) 

plot((1:30)/10, power.cor[6,], ylim = c(0,1), main = "X^(1/4)", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
points((1:30)/10, power.cors[6,], pch = 2, col = "green", type = 'b')
points((1:30)/10, power.cork[6,], pch = 3, col = "blue", type = 'b')
points((1:30)/10, power.dcor[6,], pch = 4, col = "red", type = 'b')
points((1:30)/10, power.hoe[6,], pch = 5, col = "purple", type = 'b')
legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red",?"purple"))
?
plot((1:30)/10, power.cor[7,], ylim = c(0,1), main = "Circle", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
points((1:30)/10, power.cors[7,], pch = 2, col = "green", type = 'b')
points((1:30)/10, power.cork[7,], pch = 3, col = "blue", type = 'b')
points((1:30)/10, power.dcor[7,], pch = 4, col = "red", type = 'b')
points((1:30)/10, power.hoe[7,], pch = 5, col = "purple", type = 'b')
legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red",?"purple")) 

plot((1:30)/10, power.cor[8,], ylim = c(0,1), main = "Step function", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
points((1:30)/10, power.cors[8,], pch = 2, col = "green", type = 'b')
points((1:30)/10, power.cork[8,], pch = 3, col = "blue", type = 'b')
points((1:30)/10, power.dcor[8,], pch = 4, col = "red", type = 'b')
points((1:30)/10, power.hoe[8,], pch = 5, col = "purple", type = 'b')
legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red",?"purple"))
#################

?







Le mardi 11 mai 2021 ? 20:00:49 UTC+2, varin sacha via R-help <r-help at r-project.org> a ?crit : 





Dear all,

Many thanks for your responses.

Best
S.







Le lundi 10 mai 2021 ? 17:18:59 UTC+2, Bill Dunlap <williamwdunlap at gmail.com> a ?crit : 





Also, normalizePath("power.pdf").

On Sun, May 9, 2021 at 5:13 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> ?getwd
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Sun, May 9, 2021 at 2:59 PM varin sacha via R-help <r-help at r-project.org>
> wrote:
> 
>> Rui,
>>
>> The created pdf.file is off-screen device. Indeed after dev.off() I should
>> view the pdf file on my computer. But I don't find it. Where do I find the
>> pdf.file ?
>>
>> Regards,
>>
>>
>>
>> Le dimanche 9 mai 2021 ? 22:44:22 UTC+2, Rui Barradas <
>> ruipbarradas at sapo.pt> a ?crit :
>>
>>
>>
>>
>>
>> Hello,
>>
>> You are not closing the pdf device.
>> The only changes I have made to your code are right at the beginning of
>> the plotting instructions and at the end of the code.
>>
>>
>> ## The rest of the code is for plotting the image
>> pdf(file = "power.pdf")
>> op <- par(mfrow = c(4,2), cex = 0.45)
>>
>> [...]
>>
>> par(op)
>> dev.off()
>> #################
>>
>> The comments only line is your last code line.
>> The result is attached.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?s 19:39 de 09/05/21, varin sacha via R-help escreveu:
>> > Dear R-experts,
>> >
>> > I am trying to get the 8 graphs like the ones in this paper :
>> > https://statweb.stanford.edu/~tibs/reshef/comment.pdf
>> > My R code does not show any error message neither warnings but I d'on't
>> get what I would like to get (I mean the 8 graphs), so I am missing
>> something. What's it ? Many thanks for your precious help.
>> >
>> > #################
>> > set.seed(1)
>> > library(energy)
>> >
>> > # Here we define parameters which we use to simulate the data
>> > # The number of null datasets we use to estimate our rejection reject
>> #regions for an alternative with level 0.05
>> > nsim=50
>> >
>> > # Number of alternative datasets we use to estimate our power
>> > nsim2=50
>> >
>> > # The number of different noise levels used
>> > num.noise <- 30
>> >
>> > # A constant to determine the amount of noise
>> > noise <- 3
>> >
>> > # Number of data points per simulation
>> > n=100
>> >
>> > # Vectors holding the null "correlations" (for pearson, for spearman,
>> for kendall and dcor respectively) for each # of the nsim null datasets at
>> a #given noise level
>> > val.cor=val.cors=val.cork=val.dcor=rep(NA,nsim)
>> >
>> > # Vectors holding the alternative "correlations" (for pearson, for
>> #spearman, for kendall and dcor respectively) #for each of the nsim2
>> alternative datasets at a given noise level
>> > val.cor2=val.cors2=val.cork2=val.dcor2= rep(NA,nsim2)
>> >
>> >
>> > # Arrays holding the estimated power for each of the 4 "correlation"
>> types, for each data type (linear, #parabolic, etc...) with each noise level
>> > power.cor=power.cors=power.cork=power.dcor= array(NA, c(8,num.noise))
>> >
>> > ## We loop through the noise level and functional form; each time we
>> #estimate a null distribution based on #the marginals of the data, and then
>> #use that null distribution to estimate power
>> > ## We use a uniformly distributed x, because in the original paper the
>> #authors used the same
>> >
>> > for(l in 1:num.noise) {
>> >
>> >? ? ? ? for(typ in 1:8) {
>> >
>> > ## This next loop simulates data under the null with the correct
>> marginals (x is uniform, and y is a function of a #uniform with gaussian
>> noise)
>> >
>> >? ? ? for(ii in 1:nsim) {
>> >? ? ? ? x=runif(n)
>> >
>> > #lin+noise
>> > if(typ==1) {
>> > y=x+ noise *(l/num.noise)* rnorm(n)
>> > }
>> >
>> > #parabolic+noise
>> > if(typ==2) {
>> > y=4*(x-.5)^2+? noise * (l/num.noise) * rnorm(n)
>> > }
>> >
>> > #cubic+noise
>> > if(typ==3) {
>> > y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise? * (l/num.noise)
>> *rnorm(n)
>> > }
>> >
>> > #sin+noise
>> > if(typ==4) {
>> > y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
>> > }
>> >
>> > #their sine + noise
>> > if(typ==5) {
>> > y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
>> > }
>> >
>> > #x^(1/4) + noise
>> > if(typ==6) {
>> > y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
>> > }
>> >
>> > #circle
>> > if(typ==7) {
>> > y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise
>> *rnorm(n)
>> > }
>> >
>> > #step function
>> > if(typ==8) {
>> > y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
>> > }
>> >
>> > # We resimulate x so that we have the null scenario
>> > x <- runif(n)
>> >
>> > # Calculate the 4 correlations
>> > val.cor[ii]=(cor(x,y))
>> > val.cors[ii]=(cor(x,y,method=c("spearman")))
>> > val.cork[ii]=(cor(x,y,method=c("kendal")))
>> > val.dcor[ii]=dcor(x,y)
>> > }
>> >
>> > ## Next we calculate our 4 rejection cutoffs
>> > cut.cor=quantile(val.cor,.95)
>> > cut.cors=quantile(val.cors,.95)
>> > cut.cork=quantile(val.cork,.95)
>> > cut.dcor=quantile(val.dcor,.95)
>> >
>> > ## Next we simulate the data again, this time under the alternative
>> >
>> >? ? ? for(ii in 1:nsim2) {
>> >? ? ? ? x=runif(n)
>> >
>> > #lin+noise
>> > if(typ==1) {
>> > y=x+ noise *(l/num.noise)* rnorm(n)
>> > }
>> >
>> > #parabolic+noise
>> > if(typ==2) {
>> > y=4*(x-.5)^2+? noise * (l/num.noise) * rnorm(n)
>> > }
>> >
>> > #cubic+noise
>> > if(typ==3) {
>> > y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise? * (l/num.noise)
>> *rnorm(n)
>> > }
>> >
>> > #sin+noise
>> > if(typ==4) {
>> > y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
>> > }
>> >
>> > #their sine + noise
>> > if(typ==5) {
>> > y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
>> > }
>> >
>> > #x^(1/4) + noise
>> > if(typ==6) {
>> > y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
>> > }
>> >
>> > #circle
>> > if(typ==7) {
>> > y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise
>> *rnorm(n)
>> > }
>> >
>> > #step function
>> > if(typ==8) {
>> > y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
>> > }
>> >
>> > ## We again calculate our 4 "correlations"
>> > val.cor2[ii]=(cor(x,y))
>> > val.cors2[ii]=(cor(x,y,method=c("spearman")))
>> > val.cork2[ii]=(cor(x,y,method=c("kendal")))
>> > val.dcor2[ii]=dcor(x,y)
>> > }
>> >
>> > ## Now we estimate the power as the number of alternative statistics
>> #exceeding our estimated cutoffs
>> > power.cor[typ,l] <- sum(val.cor2 > cut.cor)/nsim2
>> > power.cors[typ,l] <- sum(val.cors2 > cut.cor)/nsim2
>> > power.cork[typ,l] <- sum(val.cork2 > cut.cor)/nsim2
>> > power.dcor[typ,l] <- sum(val.dcor2 > cut.dcor)/nsim2
>> > }
>> > }
>> >
>> > save.image()
>> >
>> > ## The rest of the code is for plotting the image
>> > pdf("power.pdf")
>> > par(mfrow = c(4,2), cex = 0.45)
>> > plot((1:30)/10, power.cor[1,], ylim = c(0,1), main = "Linear", xlab =
>> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> > points((1:30)/10, power.cors[1,], pch = 2, col = "green", type = 'b')
>> > points((1:30)/10, power.cork[1,], pch = 3, col = "blue", type = 'b')
>> > points((1:30)/10, power.dcor[1,], pch = 4, col = "red", type = 'b')
>> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>> pch = c(1,2,3), col = c("black","green","blue","red"))
>> >
>> > plot((1:30)/10, power.cor[2,], ylim = c(0,1), main = "Quadratic", xlab =
>> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> > points((1:30)/10, power.cors[2,], pch = 2, col = "green", type = 'b')
>> > points((1:30)/10, power.cork[2,], pch = 3, col = "blue", type = 'b')
>> > points((1:30)/10, power.dcor[2,], pch = 4, col = "red", type = 'b')
>> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>> pch = c(1,2,3), col = c("black","green","blue","red"))
>> >
>> > plot((1:30)/10, power.cor[3,], ylim = c(0,1), main = "Cubic", xlab =
>> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> > points((1:30)/10, power.cors[3,], pch = 2, col = "green", type = 'b')
>> > points((1:30)/10, power.cork[3,], pch = 3, col = "blue", type = 'b')
>> > points((1:30)/10, power.dcor[3,], pch = 4, col = "red", type = 'b')
>> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>> pch = c(1,2,3), col = c("black","green","blue","red"))
>> >
>> > plot((1:30)/10, power.cor[5,], ylim = c(0,1), main = "Sine: period 1/8",
>> xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> > points((1:30)/10, power.cors[5,], pch = 2, col = "green", type = 'b')
>> > points((1:30)/10, power.cork[5,], pch = 3, col = "blue", type = 'b')
>> > points((1:30)/10, power.dcor[5,], pch = 4, col = "red", type = 'b')
>> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>> pch = c(1,2,3), col = c("black","green","blue","red"))
>> >
>> > plot((1:30)/10, power.cor[4,], ylim = c(0,1), main = "Sine: period 1/2",
>> xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> > points((1:30)/10, power.cors[4,], pch = 2, col = "green", type = 'b')
>> > points((1:30)/10, power.cork[4,], pch = 3, col = "blue", type = 'b')
>> > points((1:30)/10, power.dcor[4,], pch = 4, col = "red", type = 'b')
>> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>> pch = c(1,2,3), col = c("black","green","blue","red"))
>> >
>> > plot((1:30)/10, power.cor[6,], ylim = c(0,1), main = "X^(1/4)", xlab =
>> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> > points((1:30)/10, power.cors[6,], pch = 2, col = "green", type = 'b')
>> > points((1:30)/10, power.cork[6,], pch = 3, col = "blue", type = 'b')
>> > points((1:30)/10, power.dcor[6,], pch = 4, col = "red", type = 'b')
>> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>> pch = c(1,2,3), col = c("black","green","blue","red"))
>> >
>> > plot((1:30)/10, power.cor[7,], ylim = c(0,1), main = "Circle", xlab =
>> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> > points((1:30)/10, power.cors[7,], pch = 2, col = "green", type = 'b')
>> > points((1:30)/10, power.cork[7,], pch = 3, col = "blue", type = 'b')
>> > points((1:30)/10, power.dcor[7,], pch = 4, col = "red", type = 'b')
>> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>> pch = c(1,2,3), col = c("black","green","blue","red"))
>> >
>> > plot((1:30)/10, power.cor[8,], ylim = c(0,1), main = "Step function",
>> xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> > points((1:30)/10, power.cors[8,], pch = 2, col = "green", type = 'b')
>> > points((1:30)/10, power.cork[8,], pch = 3, col = "blue", type = 'b')
>> > points((1:30)/10, power.dcor[8,], pch = 4, col = "red", type = 'b')
>> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>> pch = c(1,2,3), col = c("black","green","blue","red"))
>> >
>> > #################
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ? ? ? ? [[alternative HTML version deleted]]

> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Wed May 12 13:03:32 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 12 May 2021 21:03:32 +1000
Subject: [R] empty plots !
In-Reply-To: <1662076064.4942636.1620808407847@mail.yahoo.com>
References: <294893856.3283193.1620585572644.ref@mail.yahoo.com>
 <294893856.3283193.1620585572644@mail.yahoo.com>
 <b9186679-16a2-d6e4-afac-eecebbba7e01@sapo.pt>
 <1115549345.3369846.1620597015000@mail.yahoo.com>
 <CAGxFJbTdN4e9RtgFVBsPA1ktbNXo66KpQ6d9=Tv7LveNz3OqxQ@mail.gmail.com>
 <CAHqSRuR52W2to6UYMe_Mmv500AZx9CwMz7s7+oR4kcsVocN=ww@mail.gmail.com>
 <1754150943.4687777.1620755991674@mail.yahoo.com>
 <1662076064.4942636.1620808407847@mail.yahoo.com>
Message-ID: <CA+8X3fXq-AXPAnKJAkJfWEH=z5AxLCnBX1fogUsHLKUqO9OOXA@mail.gmail.com>

Hi varin,
Were you expecting image files? I don't see any plot device e.g. pdf()
in your code.

Jim

On Wed, May 12, 2021 at 6:34 PM varin sacha via R-help
<r-help at r-project.org> wrote:
>
> Dear Experts,
>
> My R code was perfectly working since I decide to add a 5th correlation coefficient : hoeffdings' D.
> fter a google search, I guess I need somewhere in my R code "unlist" but I don't know where !
> Here below my R code with 1 error message. At the end I get my 8 plots but they are empty !
> Many thanks for your precious help !
>
> #################
> set.seed(1)
> library(energy)
> library(independence)
> library(TauStar)
>
> # Here we define parameters which we use to simulate the data
> # The number of null datasets we use to estimate our rejection reject #regions for an alternative with level 0.05
> nsim=50
>
> # Number of alternative datasets we use to estimate our power
> nsim2=50
>
> # The number of different noise levels used
> num.noise <- 30
>
> # A constant to determine the amount of noise
> noise <- 3
>
> # Number of data points per simulation
>
> n=100
>
> # Vectors holding the null "correlations" (for pearson, for spearman, for #kendall, for hoeffding and dcor respectively) for each of the nsim null datasets at a #given noise level
> val.cor=val.cors=val.cork=val.dcor=val.hoe=rep(NA,nsim)
>
> # Vectors holding the alternative "correlations" (for pearson, for #spearman, for kendall, for hoeffding and dcor respectively) for each of #the nsim2 #alternative datasets at a given noise level
> val.cor2=val.cors2=val.cork2=val.dcor2=val.hoe2= rep(NA,nsim2)
>
> # Arrays holding the estimated power for each of the 4 "correlation" types, #for each data type (linear, parabolic, etc...) with each noise level
> power.cor=power.cors=power.cork=power.dcor=power.hoe= array(NA, c(8,num.noise))
>
> ## We loop through the noise level and functional form; each time we #estimate a null distribution based on the marginals of the data, and then #use that null distribution to estimate power
> ## We use a uniformly distributed x, because in the original paper the #authors used the same
>
> for(l in 1:num.noise){
>
>       for(typ in 1:8){
>
> ## This next loop simulates data under the null with the correct marginals #(x is uniform, and y is a function of a uniform with gaussian noise)
>
>     for(ii in 1:nsim){
>       x=runif(n)
>
> #lin+noise
> if(typ==1){
> y=x+ noise *(l/num.noise)* rnorm(n)
> }
>
> #parabolic+noise
> if(typ==2){
> y=4*(x-.5)^2+  noise * (l/num.noise) * rnorm(n)
> }
>
> #cubic+noise
> if(typ==3){
> y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise  * (l/num.noise) *rnorm(n)
> }
>
> #sin+noise
> if(typ==4){
> y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
> }
>
> #their sine + noise
> if(typ==5){
> y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
> }
>
> #x^(1/4) + noise
> if(typ==6){
> y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
> }
>
> #circle
> if(typ==7){
> y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise *rnorm(n)
> }
>
> #step function
> if(typ==8){
> y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
> }
>
> # We resimulate x so that we have the null scenario
> x <- runif(n)
>
> # Calculate the 5 correlations
> val.cor[ii]=(cor(x,y))
> val.cors[ii]=(cor(x,y,method=c("spearman")))
> val.cork[ii]=(cor(x,y,method=c("kendal")))
> val.dcor[ii]=dcor(x,y)
> val.hoe[ii]=(hoeffding.D.test(x,y,na.rm=TRUE,collisions=TRUE))
> }
>
> ## Next we calculate our 5 rejection cutoffs
> cut.cor=quantile(val.cor,.95)
> cut.cors=quantile(val.cors,.95)
> cut.cork=quantile(val.cork,.95)
> cut.dcor=quantile(val.dcor,.95)
> cut.hoe=quantile(val.hoe,.95)
>
> ## Next we simulate the data again, this time under the alternative
>
>     for(ii in 1:nsim2){
>       x=runif(n)
>
> #lin+noise
> if(typ==1){
> y=x+ noise *(l/num.noise)* rnorm(n)
> }
>
> #parabolic+noise
> if(typ==2){
> y=4*(x-.5)^2+  noise * (l/num.noise) * rnorm(n)
> }
>
> #cubic+noise
> if(typ==3){
> y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise  * (l/num.noise) *rnorm(n)
> }
>
> #sin+noise
> if(typ==4){
> y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
> }
>
> #their sine + noise
> if(typ==5){
> y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
> }
>
> #x^(1/4) + noise
> if(typ==6){
> y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
> }
>
> #circle
> if(typ==7){
> y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise *rnorm(n)
> }
>
> #step function
> if(typ==8){
> y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
> }
>
> ## We again calculate our 5 correlations
> val.cor2[ii]=(cor(x,y))
> val.cors2[ii]=(cor(x,y,method=c("spearman")))
> val.cork2[ii]=(cor(x,y,method=c("kendal")))
> val.dcor2[ii]=dcor(x,y)
> val.hoe2[ii]=(hoeffding.D.test(x,y,na.rm=TRUE,collisions=TRUE))
> }
>
> ## Now we estimate the power as the number of alternative statistics #exceeding our estimated cutoffs
> power.cor[typ,l] <- sum(val.cor2 > cut.cor)/nsim2
> power.cors[typ,l] <- sum(val.cors2 > cut.cor)/nsim2
> power.cork[typ,l] <- sum(val.cork2 > cut.cor)/nsim2
> power.dcor[typ,l] <- sum(val.dcor2 > cut.dcor)/nsim2
> power.hoe[typ,l] <- sum(val.hoe2 > cut.hoe)/nsim2
> }
> }
>
> ## The rest of the code is for plotting the image
> par(mfrow = c(4,2), cex = 0.45)
> plot((1:30)/10, power.cor[1,], ylim = c(0,1), main = "Linear", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[1,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[1,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[1,], pch = 4, col = "red", type = 'b')
> points((1:30)/10, power.hoe[1,], pch = 5, col = "purple", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red", "purple"))
>
> plot((1:30)/10, power.cor[2,], ylim = c(0,1), main = "Quadratic", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[2,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[2,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[2,], pch = 4, col = "red", type = 'b')
> points((1:30)/10, power.hoe[2,], pch = 5, col = "purple", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red", "purple"))
>
> plot((1:30)/10, power.cor[3,], ylim = c(0,1), main = "Cubic", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[3,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[3,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[3,], pch = 4, col = "red", type = 'b')
> points((1:30)/10, power.hoe[3,], pch = 5, col = "purple", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red", "purple"))
>
> plot((1:30)/10, power.cor[5,], ylim = c(0,1), main = "Sine: period 1/8", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[5,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[5,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[5,], pch = 4, col = "red", type = 'b')
> points((1:30)/10, power.hoe[5,], pch = 5, col = "purple", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red", "purple"))
>
> plot((1:30)/10, power.cor[4,], ylim = c(0,1), main = "Sine: period 1/2", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[4,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[4,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[4,], pch = 4, col = "red", type = 'b')
> points((1:30)/10, power.hoe[4,], pch = 5, col = "purple", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red", "purple"))
>
> plot((1:30)/10, power.cor[6,], ylim = c(0,1), main = "X^(1/4)", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[6,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[6,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[6,], pch = 4, col = "red", type = 'b')
> points((1:30)/10, power.hoe[6,], pch = 5, col = "purple", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red", "purple"))
>
> plot((1:30)/10, power.cor[7,], ylim = c(0,1), main = "Circle", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[7,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[7,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[7,], pch = 4, col = "red", type = 'b')
> points((1:30)/10, power.hoe[7,], pch = 5, col = "purple", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red", "purple"))
>
> plot((1:30)/10, power.cor[8,], ylim = c(0,1), main = "Step function", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[8,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[8,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[8,], pch = 4, col = "red", type = 'b')
> points((1:30)/10, power.hoe[8,], pch = 5, col = "purple", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red", "purple"))
> #################
>
>
>
>
>
>
>
>
>
> Le mardi 11 mai 2021 ? 20:00:49 UTC+2, varin sacha via R-help <r-help at r-project.org> a ?crit :
>
>
>
>
>
> Dear all,
>
> Many thanks for your responses.
>
> Best
> S.
>
>
>
>
>
>
>
> Le lundi 10 mai 2021 ? 17:18:59 UTC+2, Bill Dunlap <williamwdunlap at gmail.com> a ?crit :
>
>
>
>
>
> Also, normalizePath("power.pdf").
>
> On Sun, May 9, 2021 at 5:13 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> > ?getwd
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along and
> > sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Sun, May 9, 2021 at 2:59 PM varin sacha via R-help <r-help at r-project.org>
> > wrote:
> >
> >> Rui,
> >>
> >> The created pdf.file is off-screen device. Indeed after dev.off() I should
> >> view the pdf file on my computer. But I don't find it. Where do I find the
> >> pdf.file ?
> >>
> >> Regards,
> >>
> >>
> >>
> >> Le dimanche 9 mai 2021 ? 22:44:22 UTC+2, Rui Barradas <
> >> ruipbarradas at sapo.pt> a ?crit :
> >>
> >>
> >>
> >>
> >>
> >> Hello,
> >>
> >> You are not closing the pdf device.
> >> The only changes I have made to your code are right at the beginning of
> >> the plotting instructions and at the end of the code.
> >>
> >>
> >> ## The rest of the code is for plotting the image
> >> pdf(file = "power.pdf")
> >> op <- par(mfrow = c(4,2), cex = 0.45)
> >>
> >> [...]
> >>
> >> par(op)
> >> dev.off()
> >> #################
> >>
> >> The comments only line is your last code line.
> >> The result is attached.
> >>
> >> Hope this helps,
> >>
> >> Rui Barradas
> >>
> >> ?s 19:39 de 09/05/21, varin sacha via R-help escreveu:
> >> > Dear R-experts,
> >> >
> >> > I am trying to get the 8 graphs like the ones in this paper :
> >> > https://statweb.stanford.edu/~tibs/reshef/comment.pdf
> >> > My R code does not show any error message neither warnings but I d'on't
> >> get what I would like to get (I mean the 8 graphs), so I am missing
> >> something. What's it ? Many thanks for your precious help.
> >> >
> >> > #################
> >> > set.seed(1)
> >> > library(energy)
> >> >
> >> > # Here we define parameters which we use to simulate the data
> >> > # The number of null datasets we use to estimate our rejection reject
> >> #regions for an alternative with level 0.05
> >> > nsim=50
> >> >
> >> > # Number of alternative datasets we use to estimate our power
> >> > nsim2=50
> >> >
> >> > # The number of different noise levels used
> >> > num.noise <- 30
> >> >
> >> > # A constant to determine the amount of noise
> >> > noise <- 3
> >> >
> >> > # Number of data points per simulation
> >> > n=100
> >> >
> >> > # Vectors holding the null "correlations" (for pearson, for spearman,
> >> for kendall and dcor respectively) for each # of the nsim null datasets at
> >> a #given noise level
> >> > val.cor=val.cors=val.cork=val.dcor=rep(NA,nsim)
> >> >
> >> > # Vectors holding the alternative "correlations" (for pearson, for
> >> #spearman, for kendall and dcor respectively) #for each of the nsim2
> >> alternative datasets at a given noise level
> >> > val.cor2=val.cors2=val.cork2=val.dcor2= rep(NA,nsim2)
> >> >
> >> >
> >> > # Arrays holding the estimated power for each of the 4 "correlation"
> >> types, for each data type (linear, #parabolic, etc...) with each noise level
> >> > power.cor=power.cors=power.cork=power.dcor= array(NA, c(8,num.noise))
> >> >
> >> > ## We loop through the noise level and functional form; each time we
> >> #estimate a null distribution based on #the marginals of the data, and then
> >> #use that null distribution to estimate power
> >> > ## We use a uniformly distributed x, because in the original paper the
> >> #authors used the same
> >> >
> >> > for(l in 1:num.noise) {
> >> >
> >> >        for(typ in 1:8) {
> >> >
> >> > ## This next loop simulates data under the null with the correct
> >> marginals (x is uniform, and y is a function of a #uniform with gaussian
> >> noise)
> >> >
> >> >      for(ii in 1:nsim) {
> >> >        x=runif(n)
> >> >
> >> > #lin+noise
> >> > if(typ==1) {
> >> > y=x+ noise *(l/num.noise)* rnorm(n)
> >> > }
> >> >
> >> > #parabolic+noise
> >> > if(typ==2) {
> >> > y=4*(x-.5)^2+  noise * (l/num.noise) * rnorm(n)
> >> > }
> >> >
> >> > #cubic+noise
> >> > if(typ==3) {
> >> > y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise  * (l/num.noise)
> >> *rnorm(n)
> >> > }
> >> >
> >> > #sin+noise
> >> > if(typ==4) {
> >> > y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
> >> > }
> >> >
> >> > #their sine + noise
> >> > if(typ==5) {
> >> > y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
> >> > }
> >> >
> >> > #x^(1/4) + noise
> >> > if(typ==6) {
> >> > y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
> >> > }
> >> >
> >> > #circle
> >> > if(typ==7) {
> >> > y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise
> >> *rnorm(n)
> >> > }
> >> >
> >> > #step function
> >> > if(typ==8) {
> >> > y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
> >> > }
> >> >
> >> > # We resimulate x so that we have the null scenario
> >> > x <- runif(n)
> >> >
> >> > # Calculate the 4 correlations
> >> > val.cor[ii]=(cor(x,y))
> >> > val.cors[ii]=(cor(x,y,method=c("spearman")))
> >> > val.cork[ii]=(cor(x,y,method=c("kendal")))
> >> > val.dcor[ii]=dcor(x,y)
> >> > }
> >> >
> >> > ## Next we calculate our 4 rejection cutoffs
> >> > cut.cor=quantile(val.cor,.95)
> >> > cut.cors=quantile(val.cors,.95)
> >> > cut.cork=quantile(val.cork,.95)
> >> > cut.dcor=quantile(val.dcor,.95)
> >> >
> >> > ## Next we simulate the data again, this time under the alternative
> >> >
> >> >      for(ii in 1:nsim2) {
> >> >        x=runif(n)
> >> >
> >> > #lin+noise
> >> > if(typ==1) {
> >> > y=x+ noise *(l/num.noise)* rnorm(n)
> >> > }
> >> >
> >> > #parabolic+noise
> >> > if(typ==2) {
> >> > y=4*(x-.5)^2+  noise * (l/num.noise) * rnorm(n)
> >> > }
> >> >
> >> > #cubic+noise
> >> > if(typ==3) {
> >> > y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise  * (l/num.noise)
> >> *rnorm(n)
> >> > }
> >> >
> >> > #sin+noise
> >> > if(typ==4) {
> >> > y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
> >> > }
> >> >
> >> > #their sine + noise
> >> > if(typ==5) {
> >> > y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
> >> > }
> >> >
> >> > #x^(1/4) + noise
> >> > if(typ==6) {
> >> > y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
> >> > }
> >> >
> >> > #circle
> >> > if(typ==7) {
> >> > y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise
> >> *rnorm(n)
> >> > }
> >> >
> >> > #step function
> >> > if(typ==8) {
> >> > y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
> >> > }
> >> >
> >> > ## We again calculate our 4 "correlations"
> >> > val.cor2[ii]=(cor(x,y))
> >> > val.cors2[ii]=(cor(x,y,method=c("spearman")))
> >> > val.cork2[ii]=(cor(x,y,method=c("kendal")))
> >> > val.dcor2[ii]=dcor(x,y)
> >> > }
> >> >
> >> > ## Now we estimate the power as the number of alternative statistics
> >> #exceeding our estimated cutoffs
> >> > power.cor[typ,l] <- sum(val.cor2 > cut.cor)/nsim2
> >> > power.cors[typ,l] <- sum(val.cors2 > cut.cor)/nsim2
> >> > power.cork[typ,l] <- sum(val.cork2 > cut.cor)/nsim2
> >> > power.dcor[typ,l] <- sum(val.dcor2 > cut.dcor)/nsim2
> >> > }
> >> > }
> >> >
> >> > save.image()
> >> >
> >> > ## The rest of the code is for plotting the image
> >> > pdf("power.pdf")
> >> > par(mfrow = c(4,2), cex = 0.45)
> >> > plot((1:30)/10, power.cor[1,], ylim = c(0,1), main = "Linear", xlab =
> >> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> >> > points((1:30)/10, power.cors[1,], pch = 2, col = "green", type = 'b')
> >> > points((1:30)/10, power.cork[1,], pch = 3, col = "blue", type = 'b')
> >> > points((1:30)/10, power.dcor[1,], pch = 4, col = "red", type = 'b')
> >> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
> >> pch = c(1,2,3), col = c("black","green","blue","red"))
> >> >
> >> > plot((1:30)/10, power.cor[2,], ylim = c(0,1), main = "Quadratic", xlab =
> >> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> >> > points((1:30)/10, power.cors[2,], pch = 2, col = "green", type = 'b')
> >> > points((1:30)/10, power.cork[2,], pch = 3, col = "blue", type = 'b')
> >> > points((1:30)/10, power.dcor[2,], pch = 4, col = "red", type = 'b')
> >> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
> >> pch = c(1,2,3), col = c("black","green","blue","red"))
> >> >
> >> > plot((1:30)/10, power.cor[3,], ylim = c(0,1), main = "Cubic", xlab =
> >> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> >> > points((1:30)/10, power.cors[3,], pch = 2, col = "green", type = 'b')
> >> > points((1:30)/10, power.cork[3,], pch = 3, col = "blue", type = 'b')
> >> > points((1:30)/10, power.dcor[3,], pch = 4, col = "red", type = 'b')
> >> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
> >> pch = c(1,2,3), col = c("black","green","blue","red"))
> >> >
> >> > plot((1:30)/10, power.cor[5,], ylim = c(0,1), main = "Sine: period 1/8",
> >> xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> >> > points((1:30)/10, power.cors[5,], pch = 2, col = "green", type = 'b')
> >> > points((1:30)/10, power.cork[5,], pch = 3, col = "blue", type = 'b')
> >> > points((1:30)/10, power.dcor[5,], pch = 4, col = "red", type = 'b')
> >> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
> >> pch = c(1,2,3), col = c("black","green","blue","red"))
> >> >
> >> > plot((1:30)/10, power.cor[4,], ylim = c(0,1), main = "Sine: period 1/2",
> >> xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> >> > points((1:30)/10, power.cors[4,], pch = 2, col = "green", type = 'b')
> >> > points((1:30)/10, power.cork[4,], pch = 3, col = "blue", type = 'b')
> >> > points((1:30)/10, power.dcor[4,], pch = 4, col = "red", type = 'b')
> >> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
> >> pch = c(1,2,3), col = c("black","green","blue","red"))
> >> >
> >> > plot((1:30)/10, power.cor[6,], ylim = c(0,1), main = "X^(1/4)", xlab =
> >> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> >> > points((1:30)/10, power.cors[6,], pch = 2, col = "green", type = 'b')
> >> > points((1:30)/10, power.cork[6,], pch = 3, col = "blue", type = 'b')
> >> > points((1:30)/10, power.dcor[6,], pch = 4, col = "red", type = 'b')
> >> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
> >> pch = c(1,2,3), col = c("black","green","blue","red"))
> >> >
> >> > plot((1:30)/10, power.cor[7,], ylim = c(0,1), main = "Circle", xlab =
> >> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> >> > points((1:30)/10, power.cors[7,], pch = 2, col = "green", type = 'b')
> >> > points((1:30)/10, power.cork[7,], pch = 3, col = "blue", type = 'b')
> >> > points((1:30)/10, power.dcor[7,], pch = 4, col = "red", type = 'b')
> >> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
> >> pch = c(1,2,3), col = c("black","green","blue","red"))
> >> >
> >> > plot((1:30)/10, power.cor[8,], ylim = c(0,1), main = "Step function",
> >> xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> >> > points((1:30)/10, power.cors[8,], pch = 2, col = "green", type = 'b')
> >> > points((1:30)/10, power.cork[8,], pch = 3, col = "blue", type = 'b')
> >> > points((1:30)/10, power.dcor[8,], pch = 4, col = "red", type = 'b')
> >> > legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
> >> pch = c(1,2,3), col = c("black","green","blue","red"))
> >> >
> >> > #################
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >> >
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >         [[alternative HTML version deleted]]
>
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j@zh@o @end|ng |rom ye@h@net  Wed May 12 13:49:28 2021
From: j@zh@o @end|ng |rom ye@h@net (Jinsong Zhao)
Date: Wed, 12 May 2021 19:49:28 +0800
Subject: [R] question about the difference of AIC()
Message-ID: <3bea56e6-703d-ec31-012f-37195d7d89ad@yeah.net>

Hi there,

I learned that AIC = 2 * npar - 2 * log(logLik(model)), where k is the 
number of estimated parameters in the model.

For examle:
 > set.seed(123)
 > y <- rnorm(15)
 > fm <- lm(y ~ 1)
In this example, npar should be 1, so, AIC is:
 > 2*1 - 2 * logLik(fm)
'log Lik.' 38.49275 (df=2)

However, AIC() give:
 > AIC(fm)
[1] 40.49275

I also try another AIC extract function:
 > extractAIC(fm)
[1]  1.000000 -4.075406

Since extractAIC() does not include the constant: n + n * log(2 * pi), so:
 > extractAIC(fm)[2] + 15 + 15 * log(2 * pi)
[1] 38.49275

It equals to the AIC calculated by 2*1 - 2 * logLik(fm), but different 
with the return of AIC().

It seems that AIC use 2 * (npar + 1) instead of 2 * npar.

In the help page of logLik, it said:
  '"df"' (*d*egrees of *f*reedom), giving the number of (estimated) 
parameters in the model.

The "df" is used by AIC() as npar, however, "df" is not number of 
estimated parameters in the model, df - 1 is. Am I correct?

Best wishes,
Jinsong


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed May 12 14:03:47 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 12 May 2021 13:03:47 +0100
Subject: [R] empty plots !
In-Reply-To: <1662076064.4942636.1620808407847@mail.yahoo.com>
References: <294893856.3283193.1620585572644.ref@mail.yahoo.com>
 <294893856.3283193.1620585572644@mail.yahoo.com>
 <b9186679-16a2-d6e4-afac-eecebbba7e01@sapo.pt>
 <1115549345.3369846.1620597015000@mail.yahoo.com>
 <CAGxFJbTdN4e9RtgFVBsPA1ktbNXo66KpQ6d9=Tv7LveNz3OqxQ@mail.gmail.com>
 <CAHqSRuR52W2to6UYMe_Mmv500AZx9CwMz7s7+oR4kcsVocN=ww@mail.gmail.com>
 <1754150943.4687777.1620755991674@mail.yahoo.com>
 <1662076064.4942636.1620808407847@mail.yahoo.com>
Message-ID: <f40a07a0-8610-5366-0ae3-74b40bbea1fa@sapo.pt>

Hello,

All power.* are filled with NA, please revise the code that produces 
those matrices, there's nothing wrong with the plotting code.

Also, suggested in an answer to your previous e-mail *with* code that 
you should save

old_par <- par(mfrow = c(4,2), cex = 0.45)
[...]
par(old_par)  # at the end, put the graphics device pars back.


Hope this helps,

Rui Barradas

?s 09:33 de 12/05/21, varin sacha via R-help escreveu:
> Dear Experts,
> 
> My R code was perfectly working since I decide to add a 5th correlation coefficient : hoeffdings' D.
> fter a google search, I guess I need somewhere in my R code "unlist" but I don't know where !
> Here below my R code with 1 error message. At the end I get my 8 plots but they are empty !
> Many thanks for your precious help !
> 
> #################
> set.seed(1)
> library(energy)
> library(independence)
> library(TauStar)
> 
> # Here we define parameters which we use to simulate the data
> # The number of null datasets we use to estimate our rejection reject #regions for an alternative with level 0.05
> nsim=50
> 
> # Number of alternative datasets we use to estimate our power
> nsim2=50
> 
> # The number of different noise levels used
> num.noise <- 30
> 
> # A constant to determine the amount of noise
> noise <- 3
> 
> # Number of data points per simulation
> 
> n=100
> 
> # Vectors holding the null "correlations" (for pearson, for spearman, for #kendall, for hoeffding and dcor respectively) for each of the nsim null datasets at a #given noise level
> val.cor=val.cors=val.cork=val.dcor=val.hoe=rep(NA,nsim)
> 
> # Vectors holding the alternative "correlations" (for pearson, for #spearman, for kendall, for hoeffding and dcor respectively) for each of #the nsim2 #alternative datasets at a given noise level
> val.cor2=val.cors2=val.cork2=val.dcor2=val.hoe2= rep(NA,nsim2)
>   
> # Arrays holding the estimated power for each of the 4 "correlation" types, #for each data type (linear, parabolic, etc...) with each noise level
> power.cor=power.cors=power.cork=power.dcor=power.hoe= array(NA, c(8,num.noise))
> 
> ## We loop through the noise level and functional form; each time we #estimate a null distribution based on the marginals of the data, and then #use that null distribution to estimate power
> ## We use a uniformly distributed x, because in the original paper the #authors used the same
> 
> for(l in 1:num.noise){
> 
>  ????? for(typ in 1:8){
> 
> ## This next loop simulates data under the null with the correct marginals #(x is uniform, and y is a function of a uniform with gaussian noise)
>   
>  ??? for(ii in 1:nsim){
>  ????? x=runif(n)
> 
> #lin+noise
> if(typ==1){
> y=x+ noise *(l/num.noise)* rnorm(n)
> }
>   
> #parabolic+noise
> if(typ==2){
> y=4*(x-.5)^2+? noise * (l/num.noise) * rnorm(n)
> }
> 
> #cubic+noise
> if(typ==3){
> y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise? * (l/num.noise) *rnorm(n)
> }
> 
> #sin+noise
> if(typ==4){
> y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
> }
> 
> #their sine + noise
> if(typ==5){
> y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
> }
> 
> #x^(1/4) + noise
> if(typ==6){
> y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
> }
> 
> #circle
> if(typ==7){
> y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise *rnorm(n)
> }
> 
> #step function
> if(typ==8){
> y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
> }
> 
> # We resimulate x so that we have the null scenario
> x <- runif(n)
> 
> # Calculate the 5 correlations
> val.cor[ii]=(cor(x,y))
> val.cors[ii]=(cor(x,y,method=c("spearman")))
> val.cork[ii]=(cor(x,y,method=c("kendal")))
> val.dcor[ii]=dcor(x,y)
> val.hoe[ii]=(hoeffding.D.test(x,y,na.rm=TRUE,collisions=TRUE))
> }
> 
> ## Next we calculate our 5 rejection cutoffs
> cut.cor=quantile(val.cor,.95)
> cut.cors=quantile(val.cors,.95)
> cut.cork=quantile(val.cork,.95)
> cut.dcor=quantile(val.dcor,.95)
> cut.hoe=quantile(val.hoe,.95)
> 
> ## Next we simulate the data again, this time under the alternative
> 
>  ??? for(ii in 1:nsim2){
>  ????? x=runif(n)
> 
> #lin+noise
> if(typ==1){
> y=x+ noise *(l/num.noise)* rnorm(n)
> }
> 
> #parabolic+noise
> if(typ==2){
> y=4*(x-.5)^2+? noise * (l/num.noise) * rnorm(n)
> }
> 
> #cubic+noise
> if(typ==3){
> y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise? * (l/num.noise) *rnorm(n)
> }
> 
> #sin+noise
> if(typ==4){
> y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
> }
> 
> #their sine + noise
> if(typ==5){
> y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
> }
> 
> #x^(1/4) + noise
> if(typ==6){
> y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
> }
> 
> #circle
> if(typ==7){
> y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise *rnorm(n)
> }
> 
> #step function
> if(typ==8){
> y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
> }
> 
> ## We again calculate our 5 correlations
> val.cor2[ii]=(cor(x,y))
> val.cors2[ii]=(cor(x,y,method=c("spearman")))
> val.cork2[ii]=(cor(x,y,method=c("kendal")))
> val.dcor2[ii]=dcor(x,y)
> val.hoe2[ii]=(hoeffding.D.test(x,y,na.rm=TRUE,collisions=TRUE))
> }
> 
> ## Now we estimate the power as the number of alternative statistics #exceeding our estimated cutoffs
> power.cor[typ,l] <- sum(val.cor2 > cut.cor)/nsim2
> power.cors[typ,l] <- sum(val.cors2 > cut.cor)/nsim2
> power.cork[typ,l] <- sum(val.cork2 > cut.cor)/nsim2
> power.dcor[typ,l] <- sum(val.dcor2 > cut.dcor)/nsim2
> power.hoe[typ,l] <- sum(val.hoe2 > cut.hoe)/nsim2
> }
> }
> 
> ## The rest of the code is for plotting the image
> par(mfrow = c(4,2), cex = 0.45)
> plot((1:30)/10, power.cor[1,], ylim = c(0,1), main = "Linear", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[1,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[1,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[1,], pch = 4, col = "red", type = 'b')
> points((1:30)/10, power.hoe[1,], pch = 5, col = "purple", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red",?"purple"))
> 
> plot((1:30)/10, power.cor[2,], ylim = c(0,1), main = "Quadratic", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[2,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[2,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[2,], pch = 4, col = "red", type = 'b')
> points((1:30)/10, power.hoe[2,], pch = 5, col = "purple", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red",?"purple"))
> 
> plot((1:30)/10, power.cor[3,], ylim = c(0,1), main = "Cubic", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[3,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[3,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[3,], pch = 4, col = "red", type = 'b')
> points((1:30)/10, power.hoe[3,], pch = 5, col = "purple", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red",?"purple"))
> 
> plot((1:30)/10, power.cor[5,], ylim = c(0,1), main = "Sine: period 1/8", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[5,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[5,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[5,], pch = 4, col = "red", type = 'b')
> points((1:30)/10, power.hoe[5,], pch = 5, col = "purple", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red",?"purple"))
> 
> plot((1:30)/10, power.cor[4,], ylim = c(0,1), main = "Sine: period 1/2", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[4,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[4,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[4,], pch = 4, col = "red", type = 'b')
> points((1:30)/10, power.hoe[4,], pch = 5, col = "purple", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red",?"purple"))
> 
> plot((1:30)/10, power.cor[6,], ylim = c(0,1), main = "X^(1/4)", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[6,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[6,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[6,], pch = 4, col = "red", type = 'b')
> points((1:30)/10, power.hoe[6,], pch = 5, col = "purple", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red",?"purple"))
>   
> plot((1:30)/10, power.cor[7,], ylim = c(0,1), main = "Circle", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[7,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[7,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[7,], pch = 4, col = "red", type = 'b')
> points((1:30)/10, power.hoe[7,], pch = 5, col = "purple", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red",?"purple"))
> 
> plot((1:30)/10, power.cor[8,], ylim = c(0,1), main = "Step function", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
> points((1:30)/10, power.cors[8,], pch = 2, col = "green", type = 'b')
> points((1:30)/10, power.cork[8,], pch = 3, col = "blue", type = 'b')
> points((1:30)/10, power.dcor[8,], pch = 4, col = "red", type = 'b')
> points((1:30)/10, power.hoe[8,], pch = 5, col = "purple", type = 'b')
> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red",?"purple"))
> #################
> 
>   
> 
> 
> 
> 
> 
> 
> 
> Le mardi 11 mai 2021 ? 20:00:49 UTC+2, varin sacha via R-help <r-help at r-project.org> a ?crit :
> 
> 
> 
> 
> 
> Dear all,
> 
> Many thanks for your responses.
> 
> Best
> S.
> 
> 
> 
> 
> 
> 
> 
> Le lundi 10 mai 2021 ? 17:18:59 UTC+2, Bill Dunlap <williamwdunlap at gmail.com> a ?crit :
> 
> 
> 
> 
> 
> Also, normalizePath("power.pdf").
> 
> On Sun, May 9, 2021 at 5:13 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> ?getwd
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sun, May 9, 2021 at 2:59 PM varin sacha via R-help <r-help at r-project.org>
>> wrote:
>>
>>> Rui,
>>>
>>> The created pdf.file is off-screen device. Indeed after dev.off() I should
>>> view the pdf file on my computer. But I don't find it. Where do I find the
>>> pdf.file ?
>>>
>>> Regards,
>>>
>>>
>>>
>>> Le dimanche 9 mai 2021 ? 22:44:22 UTC+2, Rui Barradas <
>>> ruipbarradas at sapo.pt> a ?crit :
>>>
>>>
>>>
>>>
>>>
>>> Hello,
>>>
>>> You are not closing the pdf device.
>>> The only changes I have made to your code are right at the beginning of
>>> the plotting instructions and at the end of the code.
>>>
>>>
>>> ## The rest of the code is for plotting the image
>>> pdf(file = "power.pdf")
>>> op <- par(mfrow = c(4,2), cex = 0.45)
>>>
>>> [...]
>>>
>>> par(op)
>>> dev.off()
>>> #################
>>>
>>> The comments only line is your last code line.
>>> The result is attached.
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>> ?s 19:39 de 09/05/21, varin sacha via R-help escreveu:
>>>> Dear R-experts,
>>>>
>>>> I am trying to get the 8 graphs like the ones in this paper :
>>>> https://statweb.stanford.edu/~tibs/reshef/comment.pdf
>>>> My R code does not show any error message neither warnings but I d'on't
>>> get what I would like to get (I mean the 8 graphs), so I am missing
>>> something. What's it ? Many thanks for your precious help.
>>>>
>>>> #################
>>>> set.seed(1)
>>>> library(energy)
>>>>
>>>> # Here we define parameters which we use to simulate the data
>>>> # The number of null datasets we use to estimate our rejection reject
>>> #regions for an alternative with level 0.05
>>>> nsim=50
>>>>
>>>> # Number of alternative datasets we use to estimate our power
>>>> nsim2=50
>>>>
>>>> # The number of different noise levels used
>>>> num.noise <- 30
>>>>
>>>> # A constant to determine the amount of noise
>>>> noise <- 3
>>>>
>>>> # Number of data points per simulation
>>>> n=100
>>>>
>>>> # Vectors holding the null "correlations" (for pearson, for spearman,
>>> for kendall and dcor respectively) for each # of the nsim null datasets at
>>> a #given noise level
>>>> val.cor=val.cors=val.cork=val.dcor=rep(NA,nsim)
>>>>
>>>> # Vectors holding the alternative "correlations" (for pearson, for
>>> #spearman, for kendall and dcor respectively) #for each of the nsim2
>>> alternative datasets at a given noise level
>>>> val.cor2=val.cors2=val.cork2=val.dcor2= rep(NA,nsim2)
>>>>
>>>>
>>>> # Arrays holding the estimated power for each of the 4 "correlation"
>>> types, for each data type (linear, #parabolic, etc...) with each noise level
>>>> power.cor=power.cors=power.cork=power.dcor= array(NA, c(8,num.noise))
>>>>
>>>> ## We loop through the noise level and functional form; each time we
>>> #estimate a null distribution based on #the marginals of the data, and then
>>> #use that null distribution to estimate power
>>>> ## We use a uniformly distributed x, because in the original paper the
>>> #authors used the same
>>>>
>>>> for(l in 1:num.noise) {
>>>>
>>>>  ? ? ? ? for(typ in 1:8) {
>>>>
>>>> ## This next loop simulates data under the null with the correct
>>> marginals (x is uniform, and y is a function of a #uniform with gaussian
>>> noise)
>>>>
>>>>  ? ? ? for(ii in 1:nsim) {
>>>>  ? ? ? ? x=runif(n)
>>>>
>>>> #lin+noise
>>>> if(typ==1) {
>>>> y=x+ noise *(l/num.noise)* rnorm(n)
>>>> }
>>>>
>>>> #parabolic+noise
>>>> if(typ==2) {
>>>> y=4*(x-.5)^2+? noise * (l/num.noise) * rnorm(n)
>>>> }
>>>>
>>>> #cubic+noise
>>>> if(typ==3) {
>>>> y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise? * (l/num.noise)
>>> *rnorm(n)
>>>> }
>>>>
>>>> #sin+noise
>>>> if(typ==4) {
>>>> y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
>>>> }
>>>>
>>>> #their sine + noise
>>>> if(typ==5) {
>>>> y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
>>>> }
>>>>
>>>> #x^(1/4) + noise
>>>> if(typ==6) {
>>>> y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
>>>> }
>>>>
>>>> #circle
>>>> if(typ==7) {
>>>> y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise
>>> *rnorm(n)
>>>> }
>>>>
>>>> #step function
>>>> if(typ==8) {
>>>> y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
>>>> }
>>>>
>>>> # We resimulate x so that we have the null scenario
>>>> x <- runif(n)
>>>>
>>>> # Calculate the 4 correlations
>>>> val.cor[ii]=(cor(x,y))
>>>> val.cors[ii]=(cor(x,y,method=c("spearman")))
>>>> val.cork[ii]=(cor(x,y,method=c("kendal")))
>>>> val.dcor[ii]=dcor(x,y)
>>>> }
>>>>
>>>> ## Next we calculate our 4 rejection cutoffs
>>>> cut.cor=quantile(val.cor,.95)
>>>> cut.cors=quantile(val.cors,.95)
>>>> cut.cork=quantile(val.cork,.95)
>>>> cut.dcor=quantile(val.dcor,.95)
>>>>
>>>> ## Next we simulate the data again, this time under the alternative
>>>>
>>>>  ? ? ? for(ii in 1:nsim2) {
>>>>  ? ? ? ? x=runif(n)
>>>>
>>>> #lin+noise
>>>> if(typ==1) {
>>>> y=x+ noise *(l/num.noise)* rnorm(n)
>>>> }
>>>>
>>>> #parabolic+noise
>>>> if(typ==2) {
>>>> y=4*(x-.5)^2+? noise * (l/num.noise) * rnorm(n)
>>>> }
>>>>
>>>> #cubic+noise
>>>> if(typ==3) {
>>>> y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise? * (l/num.noise)
>>> *rnorm(n)
>>>> }
>>>>
>>>> #sin+noise
>>>> if(typ==4) {
>>>> y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
>>>> }
>>>>
>>>> #their sine + noise
>>>> if(typ==5) {
>>>> y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
>>>> }
>>>>
>>>> #x^(1/4) + noise
>>>> if(typ==6) {
>>>> y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
>>>> }
>>>>
>>>> #circle
>>>> if(typ==7) {
>>>> y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise
>>> *rnorm(n)
>>>> }
>>>>
>>>> #step function
>>>> if(typ==8) {
>>>> y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
>>>> }
>>>>
>>>> ## We again calculate our 4 "correlations"
>>>> val.cor2[ii]=(cor(x,y))
>>>> val.cors2[ii]=(cor(x,y,method=c("spearman")))
>>>> val.cork2[ii]=(cor(x,y,method=c("kendal")))
>>>> val.dcor2[ii]=dcor(x,y)
>>>> }
>>>>
>>>> ## Now we estimate the power as the number of alternative statistics
>>> #exceeding our estimated cutoffs
>>>> power.cor[typ,l] <- sum(val.cor2 > cut.cor)/nsim2
>>>> power.cors[typ,l] <- sum(val.cors2 > cut.cor)/nsim2
>>>> power.cork[typ,l] <- sum(val.cork2 > cut.cor)/nsim2
>>>> power.dcor[typ,l] <- sum(val.dcor2 > cut.dcor)/nsim2
>>>> }
>>>> }
>>>>
>>>> save.image()
>>>>
>>>> ## The rest of the code is for plotting the image
>>>> pdf("power.pdf")
>>>> par(mfrow = c(4,2), cex = 0.45)
>>>> plot((1:30)/10, power.cor[1,], ylim = c(0,1), main = "Linear", xlab =
>>> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>>>> points((1:30)/10, power.cors[1,], pch = 2, col = "green", type = 'b')
>>>> points((1:30)/10, power.cork[1,], pch = 3, col = "blue", type = 'b')
>>>> points((1:30)/10, power.dcor[1,], pch = 4, col = "red", type = 'b')
>>>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>>> pch = c(1,2,3), col = c("black","green","blue","red"))
>>>>
>>>> plot((1:30)/10, power.cor[2,], ylim = c(0,1), main = "Quadratic", xlab =
>>> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>>>> points((1:30)/10, power.cors[2,], pch = 2, col = "green", type = 'b')
>>>> points((1:30)/10, power.cork[2,], pch = 3, col = "blue", type = 'b')
>>>> points((1:30)/10, power.dcor[2,], pch = 4, col = "red", type = 'b')
>>>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>>> pch = c(1,2,3), col = c("black","green","blue","red"))
>>>>
>>>> plot((1:30)/10, power.cor[3,], ylim = c(0,1), main = "Cubic", xlab =
>>> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>>>> points((1:30)/10, power.cors[3,], pch = 2, col = "green", type = 'b')
>>>> points((1:30)/10, power.cork[3,], pch = 3, col = "blue", type = 'b')
>>>> points((1:30)/10, power.dcor[3,], pch = 4, col = "red", type = 'b')
>>>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>>> pch = c(1,2,3), col = c("black","green","blue","red"))
>>>>
>>>> plot((1:30)/10, power.cor[5,], ylim = c(0,1), main = "Sine: period 1/8",
>>> xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>>>> points((1:30)/10, power.cors[5,], pch = 2, col = "green", type = 'b')
>>>> points((1:30)/10, power.cork[5,], pch = 3, col = "blue", type = 'b')
>>>> points((1:30)/10, power.dcor[5,], pch = 4, col = "red", type = 'b')
>>>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>>> pch = c(1,2,3), col = c("black","green","blue","red"))
>>>>
>>>> plot((1:30)/10, power.cor[4,], ylim = c(0,1), main = "Sine: period 1/2",
>>> xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>>>> points((1:30)/10, power.cors[4,], pch = 2, col = "green", type = 'b')
>>>> points((1:30)/10, power.cork[4,], pch = 3, col = "blue", type = 'b')
>>>> points((1:30)/10, power.dcor[4,], pch = 4, col = "red", type = 'b')
>>>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>>> pch = c(1,2,3), col = c("black","green","blue","red"))
>>>>
>>>> plot((1:30)/10, power.cor[6,], ylim = c(0,1), main = "X^(1/4)", xlab =
>>> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>>>> points((1:30)/10, power.cors[6,], pch = 2, col = "green", type = 'b')
>>>> points((1:30)/10, power.cork[6,], pch = 3, col = "blue", type = 'b')
>>>> points((1:30)/10, power.dcor[6,], pch = 4, col = "red", type = 'b')
>>>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>>> pch = c(1,2,3), col = c("black","green","blue","red"))
>>>>
>>>> plot((1:30)/10, power.cor[7,], ylim = c(0,1), main = "Circle", xlab =
>>> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>>>> points((1:30)/10, power.cors[7,], pch = 2, col = "green", type = 'b')
>>>> points((1:30)/10, power.cork[7,], pch = 3, col = "blue", type = 'b')
>>>> points((1:30)/10, power.dcor[7,], pch = 4, col = "red", type = 'b')
>>>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>>> pch = c(1,2,3), col = c("black","green","blue","red"))
>>>>
>>>> plot((1:30)/10, power.cor[8,], ylim = c(0,1), main = "Step function",
>>> xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>>>> points((1:30)/10, power.cors[8,], pch = 2, col = "green", type = 'b')
>>>> points((1:30)/10, power.cork[8,], pch = 3, col = "blue", type = 'b')
>>>> points((1:30)/10, power.dcor[8,], pch = 4, col = "red", type = 'b')
>>>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>>> pch = c(1,2,3), col = c("black","green","blue","red"))
>>>>
>>>> #################
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>  ? ? ? ? [[alternative HTML version deleted]]
> 
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From j@zh@o @end|ng |rom ye@h@net  Wed May 12 14:07:33 2021
From: j@zh@o @end|ng |rom ye@h@net (Jinsong Zhao)
Date: Wed, 12 May 2021 20:07:33 +0800
Subject: [R] question about the difference of AIC()
In-Reply-To: <3bea56e6-703d-ec31-012f-37195d7d89ad@yeah.net>
References: <3bea56e6-703d-ec31-012f-37195d7d89ad@yeah.net>
Message-ID: <59de55ba-cee1-5632-6397-d8d9c5c5c73a@yeah.net>

On 2021/5/12 19:49, Jinsong Zhao wrote:
> Hi there,
> 
> I learned that AIC = 2 * npar - 2 * log(logLik(model)), where k is the 
> number of estimated parameters in the model.

k should be npar in the above sentence. Sorry for the mistake.

> 
> For examle:
>  > set.seed(123)
>  > y <- rnorm(15)
>  > fm <- lm(y ~ 1)
> In this example, npar should be 1, so, AIC is:
>  > 2*1 - 2 * logLik(fm)
> 'log Lik.' 38.49275 (df=2)
> 
> However, AIC() give:
>  > AIC(fm)
> [1] 40.49275
> 
> I also try another AIC extract function:
>  > extractAIC(fm)
> [1]? 1.000000 -4.075406
> 
> Since extractAIC() does not include the constant: n + n * log(2 * pi), so:
>  > extractAIC(fm)[2] + 15 + 15 * log(2 * pi)
> [1] 38.49275
> 
> It equals to the AIC calculated by 2*1 - 2 * logLik(fm), but different 
> with the return of AIC().
> 
> It seems that AIC use 2 * (npar + 1) instead of 2 * npar.
> 
> In the help page of logLik, it said:
>  ?'"df"' (*d*egrees of *f*reedom), giving the number of (estimated) 
> parameters in the model.
> 
> The "df" is used by AIC() as npar, however, "df" is not number of 
> estimated parameters in the model, df - 1 is. Am I correct?
> 
> Best wishes,
> Jinsong


From @orenh @end|ng |rom m@th@@@u@dk  Wed May 12 14:10:31 2021
From: @orenh @end|ng |rom m@th@@@u@dk (=?utf-8?B?U8O4cmVuIEjDuGpzZ2FhcmQ=?=)
Date: Wed, 12 May 2021 12:10:31 +0000
Subject: [R] question about the difference of AIC()
In-Reply-To: <3bea56e6-703d-ec31-012f-37195d7d89ad@yeah.net>
References: <3bea56e6-703d-ec31-012f-37195d7d89ad@yeah.net>
Message-ID: <7feec70a45bbf6cc3747bf63e9cb2efd9a688cb2.camel@math.aau.dk>

In the first model, I believe you estimate two parameters: the mean and
the variance:
> fm <- lm(y ~ 1)
> 2*2 - 2 * logLik(fm)
'log Lik.' 40.49275 (df=2)
>
AIC(fm)
[1] 40.49275


A zero mean model:

fm0 <- lm(y ~ -1)
> 2*1 - 2 * logLik(fm0)
'log Lik.' 39.00611 (df=1)
> AIC(fm0)
[1] 39.00611

Regards
S?ren


On Wed, 2021-05-12 at 19:49 +0800, Jinsong Zhao wrote:
> Hi there,
> 
> I learned that AIC = 2 * npar - 2 * log(logLik(model)), where k is
> the 
> number of estimated parameters in the model.
> 
> For examle:
>  > set.seed(123)
>  > y <- rnorm(15)
>  > fm <- lm(y ~ 1)
> In this example, npar should be 1, so, AIC is:
>  > 2*1 - 2 * logLik(fm)
> 'log Lik.' 38.49275 (df=2)
> 
> However, AIC() give:
>  > AIC(fm)
> [1] 40.49275
> 
> I also try another AIC extract function:
>  > extractAIC(fm)
> [1]  1.000000 -4.075406
> 
> Since extractAIC() does not include the constant: n + n * log(2 *
> pi), so:
>  > extractAIC(fm)[2] + 15 + 15 * log(2 * pi)
> [1] 38.49275
> 
> It equals to the AIC calculated by 2*1 - 2 * logLik(fm), but
> different 
> with the return of AIC().
> 
> It seems that AIC use 2 * (npar + 1) instead of 2 * npar.
> 
> In the help page of logLik, it said:
>   '"df"' (*d*egrees of *f*reedom), giving the number of (estimated) 
> parameters in the model.
> 
> The "df" is used by AIC() as npar, however, "df" is not number of 
> estimated parameters in the model, df - 1 is. Am I correct?
> 
> Best wishes,
> Jinsong
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Wed May 12 14:33:37 2021
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Wed, 12 May 2021 14:33:37 +0200
Subject: [R] empty plots !
In-Reply-To: <CA+8X3fXq-AXPAnKJAkJfWEH=z5AxLCnBX1fogUsHLKUqO9OOXA@mail.gmail.com>
References: <CA+8X3fXq-AXPAnKJAkJfWEH=z5AxLCnBX1fogUsHLKUqO9OOXA@mail.gmail.com>
Message-ID: <F5BBF32B-4BE7-442E-A6A2-3DE6BC6CFB20@yahoo.fr>

Hi Jim,

No, I just want my R code to run correctly. I don?t want a pdf.file or other off-screen files.
There is 1 error message and I guess it is due to that error message I don?t get the 8 plots.

Envoy? de mon iPhone

> Le 12 mai 2021 ? 13:03, Jim Lemon <drjimlemon at gmail.com> a ?crit :
> 
> ?Hi varin,
> Were you expecting image files? I don't see any plot device e.g. pdf()
> in your code.
> 
> Jim
> 
>> On Wed, May 12, 2021 at 6:34 PM varin sacha via R-help
>> <r-help at r-project.org> wrote:
>> 
>> Dear Experts,
>> 
>> My R code was perfectly working since I decide to add a 5th correlation coefficient : hoeffdings' D.
>> fter a google search, I guess I need somewhere in my R code "unlist" but I don't know where !
>> Here below my R code with 1 error message. At the end I get my 8 plots but they are empty !
>> Many thanks for your precious help !
>> 
>> #################
>> set.seed(1)
>> library(energy)
>> library(independence)
>> library(TauStar)
>> 
>> # Here we define parameters which we use to simulate the data
>> # The number of null datasets we use to estimate our rejection reject #regions for an alternative with level 0.05
>> nsim=50
>> 
>> # Number of alternative datasets we use to estimate our power
>> nsim2=50
>> 
>> # The number of different noise levels used
>> num.noise <- 30
>> 
>> # A constant to determine the amount of noise
>> noise <- 3
>> 
>> # Number of data points per simulation
>> 
>> n=100
>> 
>> # Vectors holding the null "correlations" (for pearson, for spearman, for #kendall, for hoeffding and dcor respectively) for each of the nsim null datasets at a #given noise level
>> val.cor=val.cors=val.cork=val.dcor=val.hoe=rep(NA,nsim)
>> 
>> # Vectors holding the alternative "correlations" (for pearson, for #spearman, for kendall, for hoeffding and dcor respectively) for each of #the nsim2 #alternative datasets at a given noise level
>> val.cor2=val.cors2=val.cork2=val.dcor2=val.hoe2= rep(NA,nsim2)
>> 
>> # Arrays holding the estimated power for each of the 4 "correlation" types, #for each data type (linear, parabolic, etc...) with each noise level
>> power.cor=power.cors=power.cork=power.dcor=power.hoe= array(NA, c(8,num.noise))
>> 
>> ## We loop through the noise level and functional form; each time we #estimate a null distribution based on the marginals of the data, and then #use that null distribution to estimate power
>> ## We use a uniformly distributed x, because in the original paper the #authors used the same
>> 
>> for(l in 1:num.noise){
>> 
>>      for(typ in 1:8){
>> 
>> ## This next loop simulates data under the null with the correct marginals #(x is uniform, and y is a function of a uniform with gaussian noise)
>> 
>>    for(ii in 1:nsim){
>>      x=runif(n)
>> 
>> #lin+noise
>> if(typ==1){
>> y=x+ noise *(l/num.noise)* rnorm(n)
>> }
>> 
>> #parabolic+noise
>> if(typ==2){
>> y=4*(x-.5)^2+  noise * (l/num.noise) * rnorm(n)
>> }
>> 
>> #cubic+noise
>> if(typ==3){
>> y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise  * (l/num.noise) *rnorm(n)
>> }
>> 
>> #sin+noise
>> if(typ==4){
>> y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
>> }
>> 
>> #their sine + noise
>> if(typ==5){
>> y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
>> }
>> 
>> #x^(1/4) + noise
>> if(typ==6){
>> y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
>> }
>> 
>> #circle
>> if(typ==7){
>> y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise *rnorm(n)
>> }
>> 
>> #step function
>> if(typ==8){
>> y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
>> }
>> 
>> # We resimulate x so that we have the null scenario
>> x <- runif(n)
>> 
>> # Calculate the 5 correlations
>> val.cor[ii]=(cor(x,y))
>> val.cors[ii]=(cor(x,y,method=c("spearman")))
>> val.cork[ii]=(cor(x,y,method=c("kendal")))
>> val.dcor[ii]=dcor(x,y)
>> val.hoe[ii]=(hoeffding.D.test(x,y,na.rm=TRUE,collisions=TRUE))
>> }
>> 
>> ## Next we calculate our 5 rejection cutoffs
>> cut.cor=quantile(val.cor,.95)
>> cut.cors=quantile(val.cors,.95)
>> cut.cork=quantile(val.cork,.95)
>> cut.dcor=quantile(val.dcor,.95)
>> cut.hoe=quantile(val.hoe,.95)
>> 
>> ## Next we simulate the data again, this time under the alternative
>> 
>>    for(ii in 1:nsim2){
>>      x=runif(n)
>> 
>> #lin+noise
>> if(typ==1){
>> y=x+ noise *(l/num.noise)* rnorm(n)
>> }
>> 
>> #parabolic+noise
>> if(typ==2){
>> y=4*(x-.5)^2+  noise * (l/num.noise) * rnorm(n)
>> }
>> 
>> #cubic+noise
>> if(typ==3){
>> y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise  * (l/num.noise) *rnorm(n)
>> }
>> 
>> #sin+noise
>> if(typ==4){
>> y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
>> }
>> 
>> #their sine + noise
>> if(typ==5){
>> y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
>> }
>> 
>> #x^(1/4) + noise
>> if(typ==6){
>> y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
>> }
>> 
>> #circle
>> if(typ==7){
>> y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise *rnorm(n)
>> }
>> 
>> #step function
>> if(typ==8){
>> y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
>> }
>> 
>> ## We again calculate our 5 correlations
>> val.cor2[ii]=(cor(x,y))
>> val.cors2[ii]=(cor(x,y,method=c("spearman")))
>> val.cork2[ii]=(cor(x,y,method=c("kendal")))
>> val.dcor2[ii]=dcor(x,y)
>> val.hoe2[ii]=(hoeffding.D.test(x,y,na.rm=TRUE,collisions=TRUE))
>> }
>> 
>> ## Now we estimate the power as the number of alternative statistics #exceeding our estimated cutoffs
>> power.cor[typ,l] <- sum(val.cor2 > cut.cor)/nsim2
>> power.cors[typ,l] <- sum(val.cors2 > cut.cor)/nsim2
>> power.cork[typ,l] <- sum(val.cork2 > cut.cor)/nsim2
>> power.dcor[typ,l] <- sum(val.dcor2 > cut.dcor)/nsim2
>> power.hoe[typ,l] <- sum(val.hoe2 > cut.hoe)/nsim2
>> }
>> }
>> 
>> ## The rest of the code is for plotting the image
>> par(mfrow = c(4,2), cex = 0.45)
>> plot((1:30)/10, power.cor[1,], ylim = c(0,1), main = "Linear", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> points((1:30)/10, power.cors[1,], pch = 2, col = "green", type = 'b')
>> points((1:30)/10, power.cork[1,], pch = 3, col = "blue", type = 'b')
>> points((1:30)/10, power.dcor[1,], pch = 4, col = "red", type = 'b')
>> points((1:30)/10, power.hoe[1,], pch = 5, col = "purple", type = 'b')
>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red", "purple"))
>> 
>> plot((1:30)/10, power.cor[2,], ylim = c(0,1), main = "Quadratic", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> points((1:30)/10, power.cors[2,], pch = 2, col = "green", type = 'b')
>> points((1:30)/10, power.cork[2,], pch = 3, col = "blue", type = 'b')
>> points((1:30)/10, power.dcor[2,], pch = 4, col = "red", type = 'b')
>> points((1:30)/10, power.hoe[2,], pch = 5, col = "purple", type = 'b')
>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red", "purple"))
>> 
>> plot((1:30)/10, power.cor[3,], ylim = c(0,1), main = "Cubic", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> points((1:30)/10, power.cors[3,], pch = 2, col = "green", type = 'b')
>> points((1:30)/10, power.cork[3,], pch = 3, col = "blue", type = 'b')
>> points((1:30)/10, power.dcor[3,], pch = 4, col = "red", type = 'b')
>> points((1:30)/10, power.hoe[3,], pch = 5, col = "purple", type = 'b')
>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red", "purple"))
>> 
>> plot((1:30)/10, power.cor[5,], ylim = c(0,1), main = "Sine: period 1/8", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> points((1:30)/10, power.cors[5,], pch = 2, col = "green", type = 'b')
>> points((1:30)/10, power.cork[5,], pch = 3, col = "blue", type = 'b')
>> points((1:30)/10, power.dcor[5,], pch = 4, col = "red", type = 'b')
>> points((1:30)/10, power.hoe[5,], pch = 5, col = "purple", type = 'b')
>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red", "purple"))
>> 
>> plot((1:30)/10, power.cor[4,], ylim = c(0,1), main = "Sine: period 1/2", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> points((1:30)/10, power.cors[4,], pch = 2, col = "green", type = 'b')
>> points((1:30)/10, power.cork[4,], pch = 3, col = "blue", type = 'b')
>> points((1:30)/10, power.dcor[4,], pch = 4, col = "red", type = 'b')
>> points((1:30)/10, power.hoe[4,], pch = 5, col = "purple", type = 'b')
>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red", "purple"))
>> 
>> plot((1:30)/10, power.cor[6,], ylim = c(0,1), main = "X^(1/4)", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> points((1:30)/10, power.cors[6,], pch = 2, col = "green", type = 'b')
>> points((1:30)/10, power.cork[6,], pch = 3, col = "blue", type = 'b')
>> points((1:30)/10, power.dcor[6,], pch = 4, col = "red", type = 'b')
>> points((1:30)/10, power.hoe[6,], pch = 5, col = "purple", type = 'b')
>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red", "purple"))
>> 
>> plot((1:30)/10, power.cor[7,], ylim = c(0,1), main = "Circle", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> points((1:30)/10, power.cors[7,], pch = 2, col = "green", type = 'b')
>> points((1:30)/10, power.cork[7,], pch = 3, col = "blue", type = 'b')
>> points((1:30)/10, power.dcor[7,], pch = 4, col = "red", type = 'b')
>> points((1:30)/10, power.hoe[7,], pch = 5, col = "purple", type = 'b')
>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red", "purple"))
>> 
>> plot((1:30)/10, power.cor[8,], ylim = c(0,1), main = "Step function", xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>> points((1:30)/10, power.cors[8,], pch = 2, col = "green", type = 'b')
>> points((1:30)/10, power.cork[8,], pch = 3, col = "blue", type = 'b')
>> points((1:30)/10, power.dcor[8,], pch = 4, col = "red", type = 'b')
>> points((1:30)/10, power.hoe[8,], pch = 5, col = "purple", type = 'b')
>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor","hoe" ), pch = c(1,2,3,4,5), col = c("black","green","blue","red", "purple"))
>> #################
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> Le mardi 11 mai 2021 ? 20:00:49 UTC+2, varin sacha via R-help <r-help at r-project.org> a ?crit :
>> 
>> 
>> 
>> 
>> 
>> Dear all,
>> 
>> Many thanks for your responses.
>> 
>> Best
>> S.
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> Le lundi 10 mai 2021 ? 17:18:59 UTC+2, Bill Dunlap <williamwdunlap at gmail.com> a ?crit :
>> 
>> 
>> 
>> 
>> 
>> Also, normalizePath("power.pdf").
>> 
>>> On Sun, May 9, 2021 at 5:13 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> ?getwd
>>> 
>>> Bert Gunter
>>> 
>>> "The trouble with having an open mind is that people keep coming along and
>>> sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> 
>>> 
>>> On Sun, May 9, 2021 at 2:59 PM varin sacha via R-help <r-help at r-project.org>
>>> wrote:
>>> 
>>>> Rui,
>>>> 
>>>> The created pdf.file is off-screen device. Indeed after dev.off() I should
>>>> view the pdf file on my computer. But I don't find it. Where do I find the
>>>> pdf.file ?
>>>> 
>>>> Regards,
>>>> 
>>>> 
>>>> 
>>>> Le dimanche 9 mai 2021 ? 22:44:22 UTC+2, Rui Barradas <
>>>> ruipbarradas at sapo.pt> a ?crit :
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> Hello,
>>>> 
>>>> You are not closing the pdf device.
>>>> The only changes I have made to your code are right at the beginning of
>>>> the plotting instructions and at the end of the code.
>>>> 
>>>> 
>>>> ## The rest of the code is for plotting the image
>>>> pdf(file = "power.pdf")
>>>> op <- par(mfrow = c(4,2), cex = 0.45)
>>>> 
>>>> [...]
>>>> 
>>>> par(op)
>>>> dev.off()
>>>> #################
>>>> 
>>>> The comments only line is your last code line.
>>>> The result is attached.
>>>> 
>>>> Hope this helps,
>>>> 
>>>> Rui Barradas
>>>> 
>>>> ?s 19:39 de 09/05/21, varin sacha via R-help escreveu:
>>>>> Dear R-experts,
>>>>> 
>>>>> I am trying to get the 8 graphs like the ones in this paper :
>>>>> https://statweb.stanford.edu/~tibs/reshef/comment.pdf
>>>>> My R code does not show any error message neither warnings but I d'on't
>>>> get what I would like to get (I mean the 8 graphs), so I am missing
>>>> something. What's it ? Many thanks for your precious help.
>>>>> 
>>>>> #################
>>>>> set.seed(1)
>>>>> library(energy)
>>>>> 
>>>>> # Here we define parameters which we use to simulate the data
>>>>> # The number of null datasets we use to estimate our rejection reject
>>>> #regions for an alternative with level 0.05
>>>>> nsim=50
>>>>> 
>>>>> # Number of alternative datasets we use to estimate our power
>>>>> nsim2=50
>>>>> 
>>>>> # The number of different noise levels used
>>>>> num.noise <- 30
>>>>> 
>>>>> # A constant to determine the amount of noise
>>>>> noise <- 3
>>>>> 
>>>>> # Number of data points per simulation
>>>>> n=100
>>>>> 
>>>>> # Vectors holding the null "correlations" (for pearson, for spearman,
>>>> for kendall and dcor respectively) for each # of the nsim null datasets at
>>>> a #given noise level
>>>>> val.cor=val.cors=val.cork=val.dcor=rep(NA,nsim)
>>>>> 
>>>>> # Vectors holding the alternative "correlations" (for pearson, for
>>>> #spearman, for kendall and dcor respectively) #for each of the nsim2
>>>> alternative datasets at a given noise level
>>>>> val.cor2=val.cors2=val.cork2=val.dcor2= rep(NA,nsim2)
>>>>> 
>>>>> 
>>>>> # Arrays holding the estimated power for each of the 4 "correlation"
>>>> types, for each data type (linear, #parabolic, etc...) with each noise level
>>>>> power.cor=power.cors=power.cork=power.dcor= array(NA, c(8,num.noise))
>>>>> 
>>>>> ## We loop through the noise level and functional form; each time we
>>>> #estimate a null distribution based on #the marginals of the data, and then
>>>> #use that null distribution to estimate power
>>>>> ## We use a uniformly distributed x, because in the original paper the
>>>> #authors used the same
>>>>> 
>>>>> for(l in 1:num.noise) {
>>>>> 
>>>>>       for(typ in 1:8) {
>>>>> 
>>>>> ## This next loop simulates data under the null with the correct
>>>> marginals (x is uniform, and y is a function of a #uniform with gaussian
>>>> noise)
>>>>> 
>>>>>     for(ii in 1:nsim) {
>>>>>       x=runif(n)
>>>>> 
>>>>> #lin+noise
>>>>> if(typ==1) {
>>>>> y=x+ noise *(l/num.noise)* rnorm(n)
>>>>> }
>>>>> 
>>>>> #parabolic+noise
>>>>> if(typ==2) {
>>>>> y=4*(x-.5)^2+  noise * (l/num.noise) * rnorm(n)
>>>>> }
>>>>> 
>>>>> #cubic+noise
>>>>> if(typ==3) {
>>>>> y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise  * (l/num.noise)
>>>> *rnorm(n)
>>>>> }
>>>>> 
>>>>> #sin+noise
>>>>> if(typ==4) {
>>>>> y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
>>>>> }
>>>>> 
>>>>> #their sine + noise
>>>>> if(typ==5) {
>>>>> y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
>>>>> }
>>>>> 
>>>>> #x^(1/4) + noise
>>>>> if(typ==6) {
>>>>> y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
>>>>> }
>>>>> 
>>>>> #circle
>>>>> if(typ==7) {
>>>>> y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise
>>>> *rnorm(n)
>>>>> }
>>>>> 
>>>>> #step function
>>>>> if(typ==8) {
>>>>> y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
>>>>> }
>>>>> 
>>>>> # We resimulate x so that we have the null scenario
>>>>> x <- runif(n)
>>>>> 
>>>>> # Calculate the 4 correlations
>>>>> val.cor[ii]=(cor(x,y))
>>>>> val.cors[ii]=(cor(x,y,method=c("spearman")))
>>>>> val.cork[ii]=(cor(x,y,method=c("kendal")))
>>>>> val.dcor[ii]=dcor(x,y)
>>>>> }
>>>>> 
>>>>> ## Next we calculate our 4 rejection cutoffs
>>>>> cut.cor=quantile(val.cor,.95)
>>>>> cut.cors=quantile(val.cors,.95)
>>>>> cut.cork=quantile(val.cork,.95)
>>>>> cut.dcor=quantile(val.dcor,.95)
>>>>> 
>>>>> ## Next we simulate the data again, this time under the alternative
>>>>> 
>>>>>     for(ii in 1:nsim2) {
>>>>>       x=runif(n)
>>>>> 
>>>>> #lin+noise
>>>>> if(typ==1) {
>>>>> y=x+ noise *(l/num.noise)* rnorm(n)
>>>>> }
>>>>> 
>>>>> #parabolic+noise
>>>>> if(typ==2) {
>>>>> y=4*(x-.5)^2+  noise * (l/num.noise) * rnorm(n)
>>>>> }
>>>>> 
>>>>> #cubic+noise
>>>>> if(typ==3) {
>>>>> y=128*(x-1/3)^3-48*(x-1/3)^3-12*(x-1/3)+10* noise  * (l/num.noise)
>>>> *rnorm(n)
>>>>> }
>>>>> 
>>>>> #sin+noise
>>>>> if(typ==4) {
>>>>> y=sin(4*pi*x) + 2*noise * (l/num.noise) *rnorm(n)
>>>>> }
>>>>> 
>>>>> #their sine + noise
>>>>> if(typ==5) {
>>>>> y=sin(16*pi*x) + noise * (l/num.noise) *rnorm(n)
>>>>> }
>>>>> 
>>>>> #x^(1/4) + noise
>>>>> if(typ==6) {
>>>>> y=x^(1/4) + noise * (l/num.noise) *rnorm(n)
>>>>> }
>>>>> 
>>>>> #circle
>>>>> if(typ==7) {
>>>>> y=(2*rbinom(n,1,0.5)-1) * (sqrt(1 - (2*x - 1)^2)) + noise/4*l/num.noise
>>>> *rnorm(n)
>>>>> }
>>>>> 
>>>>> #step function
>>>>> if(typ==8) {
>>>>> y = (x > 0.5) + noise*5*l/num.noise *rnorm(n)
>>>>> }
>>>>> 
>>>>> ## We again calculate our 4 "correlations"
>>>>> val.cor2[ii]=(cor(x,y))
>>>>> val.cors2[ii]=(cor(x,y,method=c("spearman")))
>>>>> val.cork2[ii]=(cor(x,y,method=c("kendal")))
>>>>> val.dcor2[ii]=dcor(x,y)
>>>>> }
>>>>> 
>>>>> ## Now we estimate the power as the number of alternative statistics
>>>> #exceeding our estimated cutoffs
>>>>> power.cor[typ,l] <- sum(val.cor2 > cut.cor)/nsim2
>>>>> power.cors[typ,l] <- sum(val.cors2 > cut.cor)/nsim2
>>>>> power.cork[typ,l] <- sum(val.cork2 > cut.cor)/nsim2
>>>>> power.dcor[typ,l] <- sum(val.dcor2 > cut.dcor)/nsim2
>>>>> }
>>>>> }
>>>>> 
>>>>> save.image()
>>>>> 
>>>>> ## The rest of the code is for plotting the image
>>>>> pdf("power.pdf")
>>>>> par(mfrow = c(4,2), cex = 0.45)
>>>>> plot((1:30)/10, power.cor[1,], ylim = c(0,1), main = "Linear", xlab =
>>>> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>>>>> points((1:30)/10, power.cors[1,], pch = 2, col = "green", type = 'b')
>>>>> points((1:30)/10, power.cork[1,], pch = 3, col = "blue", type = 'b')
>>>>> points((1:30)/10, power.dcor[1,], pch = 4, col = "red", type = 'b')
>>>>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>>>> pch = c(1,2,3), col = c("black","green","blue","red"))
>>>>> 
>>>>> plot((1:30)/10, power.cor[2,], ylim = c(0,1), main = "Quadratic", xlab =
>>>> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>>>>> points((1:30)/10, power.cors[2,], pch = 2, col = "green", type = 'b')
>>>>> points((1:30)/10, power.cork[2,], pch = 3, col = "blue", type = 'b')
>>>>> points((1:30)/10, power.dcor[2,], pch = 4, col = "red", type = 'b')
>>>>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>>>> pch = c(1,2,3), col = c("black","green","blue","red"))
>>>>> 
>>>>> plot((1:30)/10, power.cor[3,], ylim = c(0,1), main = "Cubic", xlab =
>>>> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>>>>> points((1:30)/10, power.cors[3,], pch = 2, col = "green", type = 'b')
>>>>> points((1:30)/10, power.cork[3,], pch = 3, col = "blue", type = 'b')
>>>>> points((1:30)/10, power.dcor[3,], pch = 4, col = "red", type = 'b')
>>>>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>>>> pch = c(1,2,3), col = c("black","green","blue","red"))
>>>>> 
>>>>> plot((1:30)/10, power.cor[5,], ylim = c(0,1), main = "Sine: period 1/8",
>>>> xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>>>>> points((1:30)/10, power.cors[5,], pch = 2, col = "green", type = 'b')
>>>>> points((1:30)/10, power.cork[5,], pch = 3, col = "blue", type = 'b')
>>>>> points((1:30)/10, power.dcor[5,], pch = 4, col = "red", type = 'b')
>>>>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>>>> pch = c(1,2,3), col = c("black","green","blue","red"))
>>>>> 
>>>>> plot((1:30)/10, power.cor[4,], ylim = c(0,1), main = "Sine: period 1/2",
>>>> xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>>>>> points((1:30)/10, power.cors[4,], pch = 2, col = "green", type = 'b')
>>>>> points((1:30)/10, power.cork[4,], pch = 3, col = "blue", type = 'b')
>>>>> points((1:30)/10, power.dcor[4,], pch = 4, col = "red", type = 'b')
>>>>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>>>> pch = c(1,2,3), col = c("black","green","blue","red"))
>>>>> 
>>>>> plot((1:30)/10, power.cor[6,], ylim = c(0,1), main = "X^(1/4)", xlab =
>>>> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>>>>> points((1:30)/10, power.cors[6,], pch = 2, col = "green", type = 'b')
>>>>> points((1:30)/10, power.cork[6,], pch = 3, col = "blue", type = 'b')
>>>>> points((1:30)/10, power.dcor[6,], pch = 4, col = "red", type = 'b')
>>>>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>>>> pch = c(1,2,3), col = c("black","green","blue","red"))
>>>>> 
>>>>> plot((1:30)/10, power.cor[7,], ylim = c(0,1), main = "Circle", xlab =
>>>> "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>>>>> points((1:30)/10, power.cors[7,], pch = 2, col = "green", type = 'b')
>>>>> points((1:30)/10, power.cork[7,], pch = 3, col = "blue", type = 'b')
>>>>> points((1:30)/10, power.dcor[7,], pch = 4, col = "red", type = 'b')
>>>>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>>>> pch = c(1,2,3), col = c("black","green","blue","red"))
>>>>> 
>>>>> plot((1:30)/10, power.cor[8,], ylim = c(0,1), main = "Step function",
>>>> xlab = "Noise Level", ylab = "Power", pch = 1, col = "black", type = 'b')
>>>>> points((1:30)/10, power.cors[8,], pch = 2, col = "green", type = 'b')
>>>>> points((1:30)/10, power.cork[8,], pch = 3, col = "blue", type = 'b')
>>>>> points((1:30)/10, power.dcor[8,], pch = 4, col = "red", type = 'b')
>>>>> legend("topright",c("cor pearson","cor spearman", "cor kendal","dcor"),
>>>> pch = c(1,2,3), col = c("black","green","blue","red"))
>>>>> 
>>>>> #################
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>>        [[alternative HTML version deleted]]
>> 
>>> 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From @tyen @end|ng |rom ntu@edu@tw  Thu May 13 04:48:43 2021
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Thu, 13 May 2021 10:48:43 +0800
Subject: [R] Variable labels
Message-ID: <2acfbbbc-cf71-90a7-079f-874d63470d25@ntu.edu.tw>

I insert variable with the expss function as shown below. No error 
message. My question is, how to save the variable labels in the data 
frame so that I can click to read the labels. Thank you.

mydata<-read_excel("data/Excel/hseinv.xlsx",na=".")
library(expss)
mydata=apply_labels(mydata,
 ??????????????????? year?? ="1947-1988",
 ??????????????????? inv??? ="real housing inv, millions $",
 ??????????????????? pop??? ="population, 1000s",
 ??????????????????? price? ="housing price index; 1982 = 1",
 ??????????????????? linv?? ="log(inv)",
 ??????????????????? lpop?? ="log(pop)",
 ??????????????????? lprice? ="log(price)",
 ??????????????????? t?????? ="time trend: t=1,...,42",
 ??????????????????? invpc?? ="per capita inv: inv/pop",
 ??????????????????? linvpc? ="log(invpc)",
 ??????????????????? lprice_1="lprice[_n-1]",
 ??????????????????? linvpc_1="linvpc[_n-1]",
 ??????????????????? gprice? ="lprice - lprice_1",
 ??????????????????? ginvpc? ="linvpc - linvpc_1")


From d@rgo@ch @end|ng |rom gm@||@com  Thu May 13 08:56:52 2021
From: d@rgo@ch @end|ng |rom gm@||@com (Fredrik Karlsson)
Date: Thu, 13 May 2021 08:56:52 +0200
Subject: [R] Variable labels
In-Reply-To: <2acfbbbc-cf71-90a7-079f-874d63470d25@ntu.edu.tw>
References: <2acfbbbc-cf71-90a7-079f-874d63470d25@ntu.edu.tw>
Message-ID: <CANO=ohJ9UMLqBNPequ-njsnn+3wYvOv=Q7h-qOPqf0cmWh8Tpw@mail.gmail.com>

Hi,

I am sorry but I don't understand your question, Generally, "clicking" is
not something you can assume to be implemented for anything in R.
However, if you read the manual for the package

 https://gdemin.github.io/expss/

you get an example at the bottom where an illustration of how the package
can be used to create Excel tables which would then be easy to interact
with through clicking.
Is that what you wanted?

Fredrik

On Thu, May 13, 2021 at 4:49 AM Steven Yen <styen at ntu.edu.tw> wrote:

> I insert variable with the expss function as shown below. No error
> message. My question is, how to save the variable labels in the data
> frame so that I can click to read the labels. Thank you.
>
> mydata<-read_excel("data/Excel/hseinv.xlsx",na=".")
> library(expss)
> mydata=apply_labels(mydata,
>                      year   ="1947-1988",
>                      inv    ="real housing inv, millions $",
>                      pop    ="population, 1000s",
>                      price  ="housing price index; 1982 = 1",
>                      linv   ="log(inv)",
>                      lpop   ="log(pop)",
>                      lprice  ="log(price)",
>                      t       ="time trend: t=1,...,42",
>                      invpc   ="per capita inv: inv/pop",
>                      linvpc  ="log(invpc)",
>                      lprice_1="lprice[_n-1]",
>                      linvpc_1="linvpc[_n-1]",
>                      gprice  ="lprice - lprice_1",
>                      ginvpc  ="linvpc - linvpc_1")
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
"Life is like a trumpet - if you don't put anything into it, you don't get
anything out of it."

	[[alternative HTML version deleted]]


From @tyen @end|ng |rom ntu@edu@tw  Thu May 13 10:07:02 2021
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Thu, 13 May 2021 16:07:02 +0800
Subject: [R] Variable labels
In-Reply-To: <CANO=ohJ9UMLqBNPequ-njsnn+3wYvOv=Q7h-qOPqf0cmWh8Tpw@mail.gmail.com>
References: <CANO=ohJ9UMLqBNPequ-njsnn+3wYvOv=Q7h-qOPqf0cmWh8Tpw@mail.gmail.com>
Message-ID: <6445C370-0081-4F80-9D9C-A0F1511BA397@ntu.edu.tw>

Thanks. What I need ?appears? simple. The .RData file is provided by a third party (likely converted from a different data format such as SAS in which variable labels (not value labels) are common). When I load the binary file, in the ?environment? I see, as expected, a data frame showing how many observations for how many variables. In addition, there is also an item (in the environment) (say ?desc?) containing a list of variable labels (definitions).  I simply like to know how to get ?desc? in the environment?-it is a convenient way to show definitions of all variables when you send a binary data file to a third party. Thank you.

> On May 13, 2021, at 2:57 PM, Fredrik Karlsson <dargosch at gmail.com> wrote:
> 
> ?
> Hi,
> 
> I am sorry but I don't understand your question, Generally, "clicking" is not something you can assume to be implemented for anything in R.
> However, if you read the manual for the package 
> 
>  https://gdemin.github.io/expss/
> 
> you get an example at the bottom where an illustration of how the package can be used to create Excel tables which would then be easy to interact with through clicking.
> Is that what you wanted?
> 
> Fredrik
> 
>> On Thu, May 13, 2021 at 4:49 AM Steven Yen <styen at ntu.edu.tw> wrote:
>> I insert variable with the expss function as shown below. No error 
>> message. My question is, how to save the variable labels in the data 
>> frame so that I can click to read the labels. Thank you.
>> 
>> mydata<-read_excel("data/Excel/hseinv.xlsx",na=".")
>> library(expss)
>> mydata=apply_labels(mydata,
>>                      year   ="1947-1988",
>>                      inv    ="real housing inv, millions $",
>>                      pop    ="population, 1000s",
>>                      price  ="housing price index; 1982 = 1",
>>                      linv   ="log(inv)",
>>                      lpop   ="log(pop)",
>>                      lprice  ="log(price)",
>>                      t       ="time trend: t=1,...,42",
>>                      invpc   ="per capita inv: inv/pop",
>>                      linvpc  ="log(invpc)",
>>                      lprice_1="lprice[_n-1]",
>>                      linvpc_1="linvpc[_n-1]",
>>                      gprice  ="lprice - lprice_1",
>>                      ginvpc  ="linvpc - linvpc_1")
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> -- 
> "Life is like a trumpet - if you don't put anything into it, you don't get anything out of it."

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Thu May 13 12:31:49 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 13 May 2021 10:31:49 +0000
Subject: [R] Variable labels
In-Reply-To: <6445C370-0081-4F80-9D9C-A0F1511BA397@ntu.edu.tw>
References: <CANO=ohJ9UMLqBNPequ-njsnn+3wYvOv=Q7h-qOPqf0cmWh8Tpw@mail.gmail.com>
 <6445C370-0081-4F80-9D9C-A0F1511BA397@ntu.edu.tw>
Message-ID: <88a95efb70564eec83ce0a479dd9f0d1@SRVEXCHCM1302.precheza.cz>

Hi.

Maybe you could use attributes.

dput(vec.m)
structure(list(Group.1 = c(2003, 2021, 2003, 2021, 2003, 2021, 
2003, 2021, 2003, 2021, 2003, 2021, 2003, 2021, 2003, 2021, 2003, 
2021), variable = structure(c(1L, 1L, 2L, 2L, 3L, 3L, 4L, 4L, 
5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L), .Label = c("s6", "s5", 
"s4", "s3", "s2", "s1.5", "s.7", "s.5", "pod"), class = "factor"), 
    value = c(3.29, 0.525, 5.01, 1.385, 16.38, 7.67, 5.535, 3.28, 
    25.49, 24.41, 10.285, 12.79, 8.905, 12.92, 1.68, 3.67, 2.595, 
    5.06)), row.names = c(NA, -18L), class = "data.frame")

> attr(vec.m, "some.kind.of.value") <- c("some specialvector", "another special vector", "just ordinary vector")

You can access them by attributes or attr.

 attributes(vec.m)
$row.names
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18

$names
[1] "Group.1"  "variable" "value"   

$class
[1] "data.frame"

$some.kind.of.value
[1] "some specialvector"     "another special vector" "just ordinary vector"  

> attr(vec.m, "some")
[1] "some specialvector"     "another special vector" "just ordinary vector"  
>

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Steven Yen
> Sent: Thursday, May 13, 2021 10:07 AM
> To: Fredrik Karlsson <dargosch at gmail.com>
> Cc: R-help Mailing List <r-help at r-project.org>
> Subject: Re: [R] Variable labels
> 
> Thanks. What I need ?appears? simple. The .RData file is provided by a third
> party (likely converted from a different data format such as SAS in which
> variable labels (not value labels) are common). When I load the binary file, in
> the ?environment? I see, as expected, a data frame showing how many
> observations for how many variables. In addition, there is also an item (in the
> environment) (say ?desc?) containing a list of variable labels (definitions).  I
> simply like to know how to get ?desc? in the environment?-it is a convenient
> way to show definitions of all variables when you send a binary data file to a
> third party. Thank you.
> 
> > On May 13, 2021, at 2:57 PM, Fredrik Karlsson <dargosch at gmail.com>
> wrote:
> >
> > 
> > Hi,
> >
> > I am sorry but I don't understand your question, Generally, "clicking" is not
> something you can assume to be implemented for anything in R.
> > However, if you read the manual for the package
> >
> >  https://gdemin.github.io/expss/
> >
> > you get an example at the bottom where an illustration of how the package
> can be used to create Excel tables which would then be easy to interact with
> through clicking.
> > Is that what you wanted?
> >
> > Fredrik
> >
> >> On Thu, May 13, 2021 at 4:49 AM Steven Yen <styen at ntu.edu.tw> wrote:
> >> I insert variable with the expss function as shown below. No error
> >> message. My question is, how to save the variable labels in the data
> >> frame so that I can click to read the labels. Thank you.
> >>
> >> mydata<-read_excel("data/Excel/hseinv.xlsx",na=".")
> >> library(expss)
> >> mydata=apply_labels(mydata,
> >>                      year   ="1947-1988",
> >>                      inv    ="real housing inv, millions $",
> >>                      pop    ="population, 1000s",
> >>                      price  ="housing price index; 1982 = 1",
> >>                      linv   ="log(inv)",
> >>                      lpop   ="log(pop)",
> >>                      lprice  ="log(price)",
> >>                      t       ="time trend: t=1,...,42",
> >>                      invpc   ="per capita inv: inv/pop",
> >>                      linvpc  ="log(invpc)",
> >>                      lprice_1="lprice[_n-1]",
> >>                      linvpc_1="linvpc[_n-1]",
> >>                      gprice  ="lprice - lprice_1",
> >>                      ginvpc  ="linvpc - linvpc_1")
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> > --
> > "Life is like a trumpet - if you don't put anything into it, you don't get
> anything out of it."
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From hr@pchr|@ten@en @end|ng |rom gm@||@com  Wed May 12 14:14:47 2021
From: hr@pchr|@ten@en @end|ng |rom gm@||@com (Peer Christensen)
Date: Wed, 12 May 2021 14:14:47 +0200
Subject: [R] [R-pkgs] modelimpact
Message-ID: <CAKoOfS3DaQ8dgDRjXY=khi0F_yf_HkhGDMqz9UrLiZYmCQRxEA@mail.gmail.com>

Dear R users,

I am happy to announce that modelimpact is now on CRAN.

modelimpact contains functions to assess the expected business value
of using a churn prediction model in e.g. a marketing campaign.

Examples are shown in the GitHub readme: https://github.com/
<https://github.com/PeerChristensen/modelimpact>PeerChristensen/modelimpact

Best regards

Peer Christensen

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From petr@p|k@| @end|ng |rom prechez@@cz  Fri May 14 08:59:02 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Fri, 14 May 2021 06:59:02 +0000
Subject: [R] Variable labels
In-Reply-To: <859b4136-bbba-a4c1-7920-9e31fa1335de@ntu.edu.tw>
References: <CANO=ohJ9UMLqBNPequ-njsnn+3wYvOv=Q7h-qOPqf0cmWh8Tpw@mail.gmail.com>
 <6445C370-0081-4F80-9D9C-A0F1511BA397@ntu.edu.tw>
 <88a95efb70564eec83ce0a479dd9f0d1@SRVEXCHCM1302.precheza.cz>
 <3e134457-7d43-e934-32f1-26d54489d832@ntu.edu.tw>
 <7c9393a8fbcb434985fe9c3d31e67ae3@SRVEXCHCM1302.precheza.cz>
 <859b4136-bbba-a4c1-7920-9e31fa1335de@ntu.edu.tw>
Message-ID: <9083181e865e4549994706f6a799d67d@SRVEXCHCM1302.precheza.cz>

Hallo Steven

You probably need to be more specific what is your intention. I still wonder what is the real problem you want to solve.

You loaded binary file and it resulted to 2 data frames. So far so good. But now I am lost.

You want to merge info from data frame "desc" to data frame "data"? You can use attr.
You want to make binary file which behaves like the one you get?  Use save/load.
You want to do something different? So please explain what exactly.

Cheers
Petr


> -----Original Message-----
> From: Steven Yen <styen at ntu.edu.tw>
> Sent: Thursday, May 13, 2021 5:53 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Subject: Re: [R] Variable labels
> 
> Petr
> 
> Those attachments (1.jpg, 2.jpg) I sent earlier were just screen captures
> (with a third-party program) of what I saw in the Environment pane right
> after loading the data. Sorry I cannot explain my questions well enough.
> 
> All I was showing you was, right after loading the binary data file, I saw two
> data frames---data which contain the data, and desc which contains
> definitions of all variables (as shown in 2.jpg). This is a data file from the
> publisher and I wanted to know what it takes to create a binary data files
> along with definitions of variables, both in the environment.
> 
> Steven
> 
> On 2021/5/13 ?? 09:51, PIKAL Petr wrote:
> > Hi Steven
> >
> > I probably do not understand your question correctly. In 1 you show two
> objects "data" 14x42 data frame and "desc" which is 2x14 data frame, both
> residing in global environment.
> >
> > In 2 you show contents of data frame desc where variable are probably
> variable names which are also in data object.
> >
> > names(data)
> >
> > and label which is some more elaborate description of the variable.
> >
> > If you want to move this label into your data object you probably
> > could use attr
> >
> > attr(data, "label") <- desc$label
> >
> > If the order of "variable" is same as the order of data columns.
> >
> > I do not understand what do you mean by - how to get that "desc" in
> > there in the environment? It is already part of global environment. You
> want to create some new environment and move you desc there?
> >
> > Beside, your images are not familiar to me, this is plain R or some kind of
> special GUI like R studio?
> >
> > Cheers
> > Petr
> >
> >> -----Original Message-----
> >> From: Steven Yen <styen at ntu.edu.tw>
> >> Sent: Thursday, May 13, 2021 1:37 PM
> >> To: PIKAL Petr <petr.pikal at precheza.cz>
> >> Subject: Re: [R] Variable labels
> >>
> >> Petr
> >>
> >> Thanks. I am sending this to you privately as I am sending attachment.
> >>
> >> 1. I load the binary file and see the data frame and what appears to
> >> be description (desc) alongside it (1.jpg).
> >>
> >> 2. Expanding "desc", I get to read the documentation (contents of desc).
> >> (2.jpg).
> >>
> >> #2 is all I need. I do not need to do anything fancy with the
> >> variable label. I just like my students to have a simple ways of
> >> learning the variables is the data file I provide to them.
> >>
> >> Again, my main question is, how to get that "desc" in there in the
> >> environment. Thanks.
> >>
> >> Steven
> >>
> >> On 2021/5/13 ?? 06:31, PIKAL Petr wrote:
> >>> Hi.
> >>>
> >>> Maybe you could use attributes.
> >>>
> >>> dput(vec.m)
> >>> structure(list(Group.1 = c(2003, 2021, 2003, 2021, 2003, 2021, 2003,
> >>> 2021, 2003, 2021, 2003, 2021, 2003, 2021, 2003, 2021, 2003, 2021),
> >>> variable = structure(c(1L, 1L, 2L, 2L, 3L, 3L, 4L, 4L, 5L, 5L, 6L,
> >>> 6L, 7L, 7L, 8L, 8L, 9L, 9L), .Label = c("s6", "s5", "s4", "s3",
> >>> "s2", "s1.5", "s.7", "s.5", "pod"), class = "factor"),
> >>>       value = c(3.29, 0.525, 5.01, 1.385, 16.38, 7.67, 5.535, 3.28,
> >>>       25.49, 24.41, 10.285, 12.79, 8.905, 12.92, 1.68, 3.67, 2.595,
> >>>       5.06)), row.names = c(NA, -18L), class = "data.frame")
> >>>
> >>>> attr(vec.m, "some.kind.of.value") <- c("some specialvector",
> >>>> "another special vector", "just ordinary vector")
> >>> You can access them by attributes or attr.
> >>>
> >>>    attributes(vec.m)
> >>> $row.names
> >>>    [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18
> >>>
> >>> $names
> >>> [1] "Group.1"  "variable" "value"
> >>>
> >>> $class
> >>> [1] "data.frame"
> >>>
> >>> $some.kind.of.value
> >>> [1] "some specialvector"     "another special vector" "just ordinary
> vector"
> >>>
> >>>> attr(vec.m, "some")
> >>> [1] "some specialvector"     "another special vector" "just ordinary
> vector"
> >>> Cheers
> >>> Petr
> >>>
> >>>> -----Original Message-----
> >>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Steven
> Yen
> >>>> Sent: Thursday, May 13, 2021 10:07 AM
> >>>> To: Fredrik Karlsson <dargosch at gmail.com>
> >>>> Cc: R-help Mailing List <r-help at r-project.org>
> >>>> Subject: Re: [R] Variable labels
> >>>>
> >>>> Thanks. What I need ?appears? simple. The .RData file is provided
> >>>> by a third party (likely converted from a different data format
> >>>> such as SAS in which variable labels (not value labels) are
> >>>> common). When I load the binary file, in the ?environment? I see,
> >>>> as expected, a data frame showing how many observations for how
> >>>> many variables. In addition, there is also an item (in the
> >>>> environment) (say ?desc?) containing a list of variable labels
> >>>> (definitions).  I simply like to know how to get ?desc? in the
> >>>> environment?-it is a convenient way to show definitions of all
> >>>> variables when you send a binary data file to a third party. Thank you.
> >>>>
> >>>>> On May 13, 2021, at 2:57 PM, Fredrik Karlsson <dargosch at gmail.com>
> >>>> wrote:
> >>>>> Hi,
> >>>>>
> >>>>> I am sorry but I don't understand your question, Generally,
> >>>>> "clicking" is not
> >>>> something you can assume to be implemented for anything in R.
> >>>>> However, if you read the manual for the package
> >>>>>
> >>>>>    https://gdemin.github.io/expss/
> >>>>>
> >>>>> you get an example at the bottom where an illustration of how the
> >>>>> package
> >>>> can be used to create Excel tables which would then be easy to
> >>>> interact with through clicking.
> >>>>> Is that what you wanted?
> >>>>>
> >>>>> Fredrik
> >>>>>
> >>>>>> On Thu, May 13, 2021 at 4:49 AM Steven Yen <styen at ntu.edu.tw>
> >> wrote:
> >>>>>> I insert variable with the expss function as shown below. No
> >>>>>> error message. My question is, how to save the variable labels in
> >>>>>> the data frame so that I can click to read the labels. Thank you.
> >>>>>>
> >>>>>> mydata<-read_excel("data/Excel/hseinv.xlsx",na=".")
> >>>>>> library(expss)
> >>>>>> mydata=apply_labels(mydata,
> >>>>>>                        year   ="1947-1988",
> >>>>>>                        inv    ="real housing inv, millions $",
> >>>>>>                        pop    ="population, 1000s",
> >>>>>>                        price  ="housing price index; 1982 = 1",
> >>>>>>                        linv   ="log(inv)",
> >>>>>>                        lpop   ="log(pop)",
> >>>>>>                        lprice  ="log(price)",
> >>>>>>                        t       ="time trend: t=1,...,42",
> >>>>>>                        invpc   ="per capita inv: inv/pop",
> >>>>>>                        linvpc  ="log(invpc)",
> >>>>>>                        lprice_1="lprice[_n-1]",
> >>>>>>                        linvpc_1="linvpc[_n-1]",
> >>>>>>                        gprice  ="lprice - lprice_1",
> >>>>>>                        ginvpc  ="linvpc - linvpc_1")
> >>>>>>
> >>>>>> ______________________________________________
> >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>> PLEASE do read the posting guide
> >>>>>> http://www.R-project.org/posting-guide.html
> >>>>>> and provide commented, minimal, self-contained, reproducible
> code.
> >>>>> --
> >>>>> "Life is like a trumpet - if you don't put anything into it, you
> >>>>> don't get
> >>>> anything out of it."
> >>>>
> >>>> 	[[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide http://www.R-project.org/posting-
> >>>> guide.html and provide commented, minimal, self-contained,
> >>>> reproducible code.

From drj|m|emon @end|ng |rom gm@||@com  Fri May 14 11:15:06 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 14 May 2021 19:15:06 +1000
Subject: [R] Variable labels
In-Reply-To: <9083181e865e4549994706f6a799d67d@SRVEXCHCM1302.precheza.cz>
References: <CANO=ohJ9UMLqBNPequ-njsnn+3wYvOv=Q7h-qOPqf0cmWh8Tpw@mail.gmail.com>
 <6445C370-0081-4F80-9D9C-A0F1511BA397@ntu.edu.tw>
 <88a95efb70564eec83ce0a479dd9f0d1@SRVEXCHCM1302.precheza.cz>
 <3e134457-7d43-e934-32f1-26d54489d832@ntu.edu.tw>
 <7c9393a8fbcb434985fe9c3d31e67ae3@SRVEXCHCM1302.precheza.cz>
 <859b4136-bbba-a4c1-7920-9e31fa1335de@ntu.edu.tw>
 <9083181e865e4549994706f6a799d67d@SRVEXCHCM1302.precheza.cz>
Message-ID: <CA+8X3fUb8OoFR8BJ4ez_uGbNheJ=Wi8dwMTXu+hCG2Bn9BKDUA@mail.gmail.com>

Hi Steven,
I just happened to scan Petr's message to you and wondered if you were
looking for something related to the "describe" function in the
prettyR package (and a few others). For instance, if you do this:

library(prettyR)
describe(mtcars)

you get this:

Description of mtcars

Numeric
      mean median      var     sd valid.n
mpg   20.09  19.20    36.32   6.03      32
cyl    6.19   6.00     3.19   1.79      32
disp 230.72 196.30 15360.80 123.94      32
hp   146.69 123.00  4700.87  68.56      32
drat   3.60   3.70     0.29   0.53      32
wt     3.22   3.33     0.96   0.98      32
qsec  17.85  17.71     3.19   1.79      32
vs     0.44   0.00     0.25   0.50      32
am     0.41   0.00     0.25   0.50      32
gear   3.69   4.00     0.54   0.74      32
carb   2.81   2.00     2.61   1.62      32

However, you can call almost any summary function as an argument to
describe. Suppose I wrote a function "fackey" that produced this
output on a factor variable "city":

fackey(city)

label          numeric    count
New York   10            30
London       15            23
Paris          16            22
Rome         20            25

So if you ran "describe" on your data frame, you would get a list of
summary data frames that could be saved with the data frame in an
.Rdata file. Is this what you are looking for?

Jim

On Fri, May 14, 2021 at 4:59 PM PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> Hallo Steven
>
> You probably need to be more specific what is your intention. I still wonder what is the real problem you want to solve.
>
> You loaded binary file and it resulted to 2 data frames. So far so good. But now I am lost.
>
> You want to merge info from data frame "desc" to data frame "data"? You can use attr.
> You want to make binary file which behaves like the one you get?  Use save/load.
> You want to do something different? So please explain what exactly.
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: Steven Yen <styen at ntu.edu.tw>
> > Sent: Thursday, May 13, 2021 5:53 PM
> > To: PIKAL Petr <petr.pikal at precheza.cz>
> > Subject: Re: [R] Variable labels
> >
> > Petr
> >
> > Those attachments (1.jpg, 2.jpg) I sent earlier were just screen captures
> > (with a third-party program) of what I saw in the Environment pane right
> > after loading the data. Sorry I cannot explain my questions well enough.
> >
> > All I was showing you was, right after loading the binary data file, I saw two
> > data frames---data which contain the data, and desc which contains
> > definitions of all variables (as shown in 2.jpg). This is a data file from the
> > publisher and I wanted to know what it takes to create a binary data files
> > along with definitions of variables, both in the environment.
> >
> > Steven
> >
> > On 2021/5/13 ?? 09:51, PIKAL Petr wrote:
> > > Hi Steven
> > >
> > > I probably do not understand your question correctly. In 1 you show two
> > objects "data" 14x42 data frame and "desc" which is 2x14 data frame, both
> > residing in global environment.
> > >
> > > In 2 you show contents of data frame desc where variable are probably
> > variable names which are also in data object.
> > >
> > > names(data)
> > >
> > > and label which is some more elaborate description of the variable.
> > >
> > > If you want to move this label into your data object you probably
> > > could use attr
> > >
> > > attr(data, "label") <- desc$label
> > >
> > > If the order of "variable" is same as the order of data columns.
> > >
> > > I do not understand what do you mean by - how to get that "desc" in
> > > there in the environment? It is already part of global environment. You
> > want to create some new environment and move you desc there?
> > >
> > > Beside, your images are not familiar to me, this is plain R or some kind of
> > special GUI like R studio?
> > >
> > > Cheers
> > > Petr
> > >
> > >> -----Original Message-----
> > >> From: Steven Yen <styen at ntu.edu.tw>
> > >> Sent: Thursday, May 13, 2021 1:37 PM
> > >> To: PIKAL Petr <petr.pikal at precheza.cz>
> > >> Subject: Re: [R] Variable labels
> > >>
> > >> Petr
> > >>
> > >> Thanks. I am sending this to you privately as I am sending attachment.
> > >>
> > >> 1. I load the binary file and see the data frame and what appears to
> > >> be description (desc) alongside it (1.jpg).
> > >>
> > >> 2. Expanding "desc", I get to read the documentation (contents of desc).
> > >> (2.jpg).
> > >>
> > >> #2 is all I need. I do not need to do anything fancy with the
> > >> variable label. I just like my students to have a simple ways of
> > >> learning the variables is the data file I provide to them.
> > >>
> > >> Again, my main question is, how to get that "desc" in there in the
> > >> environment. Thanks.
> > >>
> > >> Steven
> > >>
> > >> On 2021/5/13 ?? 06:31, PIKAL Petr wrote:
> > >>> Hi.
> > >>>
> > >>> Maybe you could use attributes.
> > >>>
> > >>> dput(vec.m)
> > >>> structure(list(Group.1 = c(2003, 2021, 2003, 2021, 2003, 2021, 2003,
> > >>> 2021, 2003, 2021, 2003, 2021, 2003, 2021, 2003, 2021, 2003, 2021),
> > >>> variable = structure(c(1L, 1L, 2L, 2L, 3L, 3L, 4L, 4L, 5L, 5L, 6L,
> > >>> 6L, 7L, 7L, 8L, 8L, 9L, 9L), .Label = c("s6", "s5", "s4", "s3",
> > >>> "s2", "s1.5", "s.7", "s.5", "pod"), class = "factor"),
> > >>>       value = c(3.29, 0.525, 5.01, 1.385, 16.38, 7.67, 5.535, 3.28,
> > >>>       25.49, 24.41, 10.285, 12.79, 8.905, 12.92, 1.68, 3.67, 2.595,
> > >>>       5.06)), row.names = c(NA, -18L), class = "data.frame")
> > >>>
> > >>>> attr(vec.m, "some.kind.of.value") <- c("some specialvector",
> > >>>> "another special vector", "just ordinary vector")
> > >>> You can access them by attributes or attr.
> > >>>
> > >>>    attributes(vec.m)
> > >>> $row.names
> > >>>    [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18
> > >>>
> > >>> $names
> > >>> [1] "Group.1"  "variable" "value"
> > >>>
> > >>> $class
> > >>> [1] "data.frame"
> > >>>
> > >>> $some.kind.of.value
> > >>> [1] "some specialvector"     "another special vector" "just ordinary
> > vector"
> > >>>
> > >>>> attr(vec.m, "some")
> > >>> [1] "some specialvector"     "another special vector" "just ordinary
> > vector"
> > >>> Cheers
> > >>> Petr
> > >>>
> > >>>> -----Original Message-----
> > >>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Steven
> > Yen
> > >>>> Sent: Thursday, May 13, 2021 10:07 AM
> > >>>> To: Fredrik Karlsson <dargosch at gmail.com>
> > >>>> Cc: R-help Mailing List <r-help at r-project.org>
> > >>>> Subject: Re: [R] Variable labels
> > >>>>
> > >>>> Thanks. What I need ?appears? simple. The .RData file is provided
> > >>>> by a third party (likely converted from a different data format
> > >>>> such as SAS in which variable labels (not value labels) are
> > >>>> common). When I load the binary file, in the ?environment? I see,
> > >>>> as expected, a data frame showing how many observations for how
> > >>>> many variables. In addition, there is also an item (in the
> > >>>> environment) (say ?desc?) containing a list of variable labels
> > >>>> (definitions).  I simply like to know how to get ?desc? in the
> > >>>> environment?-it is a convenient way to show definitions of all
> > >>>> variables when you send a binary data file to a third party. Thank you.
> > >>>>
> > >>>>> On May 13, 2021, at 2:57 PM, Fredrik Karlsson <dargosch at gmail.com>
> > >>>> wrote:
> > >>>>> Hi,
> > >>>>>
> > >>>>> I am sorry but I don't understand your question, Generally,
> > >>>>> "clicking" is not
> > >>>> something you can assume to be implemented for anything in R.
> > >>>>> However, if you read the manual for the package
> > >>>>>
> > >>>>>    https://gdemin.github.io/expss/
> > >>>>>
> > >>>>> you get an example at the bottom where an illustration of how the
> > >>>>> package
> > >>>> can be used to create Excel tables which would then be easy to
> > >>>> interact with through clicking.
> > >>>>> Is that what you wanted?
> > >>>>>
> > >>>>> Fredrik
> > >>>>>
> > >>>>>> On Thu, May 13, 2021 at 4:49 AM Steven Yen <styen at ntu.edu.tw>
> > >> wrote:
> > >>>>>> I insert variable with the expss function as shown below. No
> > >>>>>> error message. My question is, how to save the variable labels in
> > >>>>>> the data frame so that I can click to read the labels. Thank you.
> > >>>>>>
> > >>>>>> mydata<-read_excel("data/Excel/hseinv.xlsx",na=".")
> > >>>>>> library(expss)
> > >>>>>> mydata=apply_labels(mydata,
> > >>>>>>                        year   ="1947-1988",
> > >>>>>>                        inv    ="real housing inv, millions $",
> > >>>>>>                        pop    ="population, 1000s",
> > >>>>>>                        price  ="housing price index; 1982 = 1",
> > >>>>>>                        linv   ="log(inv)",
> > >>>>>>                        lpop   ="log(pop)",
> > >>>>>>                        lprice  ="log(price)",
> > >>>>>>                        t       ="time trend: t=1,...,42",
> > >>>>>>                        invpc   ="per capita inv: inv/pop",
> > >>>>>>                        linvpc  ="log(invpc)",
> > >>>>>>                        lprice_1="lprice[_n-1]",
> > >>>>>>                        linvpc_1="linvpc[_n-1]",
> > >>>>>>                        gprice  ="lprice - lprice_1",
> > >>>>>>                        ginvpc  ="linvpc - linvpc_1")
> > >>>>>>
> > >>>>>> ______________________________________________
> > >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>>>> PLEASE do read the posting guide
> > >>>>>> http://www.R-project.org/posting-guide.html
> > >>>>>> and provide commented, minimal, self-contained, reproducible
> > code.
> > >>>>> --
> > >>>>> "Life is like a trumpet - if you don't put anything into it, you
> > >>>>> don't get
> > >>>> anything out of it."
> > >>>>
> > >>>>  [[alternative HTML version deleted]]
> > >>>>
> > >>>> ______________________________________________
> > >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>> PLEASE do read the posting guide http://www.R-project.org/posting-
> > >>>> guide.html and provide commented, minimal, self-contained,
> > >>>> reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @tyen @end|ng |rom ntu@edu@tw  Fri May 14 11:20:20 2021
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Fri, 14 May 2021 17:20:20 +0800
Subject: [R] Variable labels
In-Reply-To: <CA+8X3fUb8OoFR8BJ4ez_uGbNheJ=Wi8dwMTXu+hCG2Bn9BKDUA@mail.gmail.com>
References: <CANO=ohJ9UMLqBNPequ-njsnn+3wYvOv=Q7h-qOPqf0cmWh8Tpw@mail.gmail.com>
 <6445C370-0081-4F80-9D9C-A0F1511BA397@ntu.edu.tw>
 <88a95efb70564eec83ce0a479dd9f0d1@SRVEXCHCM1302.precheza.cz>
 <3e134457-7d43-e934-32f1-26d54489d832@ntu.edu.tw>
 <7c9393a8fbcb434985fe9c3d31e67ae3@SRVEXCHCM1302.precheza.cz>
 <859b4136-bbba-a4c1-7920-9e31fa1335de@ntu.edu.tw>
 <9083181e865e4549994706f6a799d67d@SRVEXCHCM1302.precheza.cz>
 <CA+8X3fUb8OoFR8BJ4ez_uGbNheJ=Wi8dwMTXu+hCG2Bn9BKDUA@mail.gmail.com>
Message-ID: <93e8290e-89a2-4fca-27be-8c6b2b3166e1@ntu.edu.tw>

Thanks to all, for bearing with me.

Now I realize expss may not be what I need. I have now written a 
self-runnable, replicable set of codes (listed below). Perhaps that 
gives an idea of what I need. Question is, whethet this is the right way 
to do this (to have a clickable object to learn about variable 
definitions) or whether there are better ways. Thanks!

Steven

rm(list=ls())
n<-6
mydata<-data.frame(id=1:n,
 ?????????????????? age=floor(rnorm(n,25,10)),
 ?????????????????? yrmarry=floor(rnorm(n,5,2)))
var.labels<-c(id? = "Individual ID",
 ????????????? age = "Age in Years",
 ????????????? yrmarry = "Years of marriage")
definitions<-as.data.frame(var.labels) # declare definitions as a data frame
save.image("c:/temp/a/try1.RData")???? # save binary .RData file
rm(list=ls())????????????????????????? # clean environment
load("c:/temp/a/try1.RData") # now load .RData file and definitions are 
clickable
 ???????????????????????????? # all I need is for user to be able to click
 ???????????????????????????? # and read the variable definitions

On 2021/5/14 ?? 05:15, Jim Lemon wrote:
> Hi Steven,
> I just happened to scan Petr's message to you and wondered if you were
> looking for something related to the "describe" function in the
> prettyR package (and a few others). For instance, if you do this:
>
> library(prettyR)
> describe(mtcars)
>
> you get this:
>
> Description of mtcars
>
> Numeric
>        mean median      var     sd valid.n
> mpg   20.09  19.20    36.32   6.03      32
> cyl    6.19   6.00     3.19   1.79      32
> disp 230.72 196.30 15360.80 123.94      32
> hp   146.69 123.00  4700.87  68.56      32
> drat   3.60   3.70     0.29   0.53      32
> wt     3.22   3.33     0.96   0.98      32
> qsec  17.85  17.71     3.19   1.79      32
> vs     0.44   0.00     0.25   0.50      32
> am     0.41   0.00     0.25   0.50      32
> gear   3.69   4.00     0.54   0.74      32
> carb   2.81   2.00     2.61   1.62      32
>
> However, you can call almost any summary function as an argument to
> describe. Suppose I wrote a function "fackey" that produced this
> output on a factor variable "city":
>
> fackey(city)
>
> label          numeric    count
> New York   10            30
> London       15            23
> Paris          16            22
> Rome         20            25
>
> So if you ran "describe" on your data frame, you would get a list of
> summary data frames that could be saved with the data frame in an
> .Rdata file. Is this what you are looking for?
>
> Jim
>
> On Fri, May 14, 2021 at 4:59 PM PIKAL Petr <petr.pikal at precheza.cz> wrote:
>> Hallo Steven
>>
>> You probably need to be more specific what is your intention. I still wonder what is the real problem you want to solve.
>>
>> You loaded binary file and it resulted to 2 data frames. So far so good. But now I am lost.
>>
>> You want to merge info from data frame "desc" to data frame "data"? You can use attr.
>> You want to make binary file which behaves like the one you get?  Use save/load.
>> You want to do something different? So please explain what exactly.
>>
>> Cheers
>> Petr
>>
>>
>>> -----Original Message-----
>>> From: Steven Yen <styen at ntu.edu.tw>
>>> Sent: Thursday, May 13, 2021 5:53 PM
>>> To: PIKAL Petr <petr.pikal at precheza.cz>
>>> Subject: Re: [R] Variable labels
>>>
>>> Petr
>>>
>>> Those attachments (1.jpg, 2.jpg) I sent earlier were just screen captures
>>> (with a third-party program) of what I saw in the Environment pane right
>>> after loading the data. Sorry I cannot explain my questions well enough.
>>>
>>> All I was showing you was, right after loading the binary data file, I saw two
>>> data frames---data which contain the data, and desc which contains
>>> definitions of all variables (as shown in 2.jpg). This is a data file from the
>>> publisher and I wanted to know what it takes to create a binary data files
>>> along with definitions of variables, both in the environment.
>>>
>>> Steven
>>>
>>> On 2021/5/13 ?? 09:51, PIKAL Petr wrote:
>>>> Hi Steven
>>>>
>>>> I probably do not understand your question correctly. In 1 you show two
>>> objects "data" 14x42 data frame and "desc" which is 2x14 data frame, both
>>> residing in global environment.
>>>> In 2 you show contents of data frame desc where variable are probably
>>> variable names which are also in data object.
>>>> names(data)
>>>>
>>>> and label which is some more elaborate description of the variable.
>>>>
>>>> If you want to move this label into your data object you probably
>>>> could use attr
>>>>
>>>> attr(data, "label") <- desc$label
>>>>
>>>> If the order of "variable" is same as the order of data columns.
>>>>
>>>> I do not understand what do you mean by - how to get that "desc" in
>>>> there in the environment? It is already part of global environment. You
>>> want to create some new environment and move you desc there?
>>>> Beside, your images are not familiar to me, this is plain R or some kind of
>>> special GUI like R studio?
>>>> Cheers
>>>> Petr
>>>>
>>>>> -----Original Message-----
>>>>> From: Steven Yen <styen at ntu.edu.tw>
>>>>> Sent: Thursday, May 13, 2021 1:37 PM
>>>>> To: PIKAL Petr <petr.pikal at precheza.cz>
>>>>> Subject: Re: [R] Variable labels
>>>>>
>>>>> Petr
>>>>>
>>>>> Thanks. I am sending this to you privately as I am sending attachment.
>>>>>
>>>>> 1. I load the binary file and see the data frame and what appears to
>>>>> be description (desc) alongside it (1.jpg).
>>>>>
>>>>> 2. Expanding "desc", I get to read the documentation (contents of desc).
>>>>> (2.jpg).
>>>>>
>>>>> #2 is all I need. I do not need to do anything fancy with the
>>>>> variable label. I just like my students to have a simple ways of
>>>>> learning the variables is the data file I provide to them.
>>>>>
>>>>> Again, my main question is, how to get that "desc" in there in the
>>>>> environment. Thanks.
>>>>>
>>>>> Steven
>>>>>
>>>>> On 2021/5/13 ?? 06:31, PIKAL Petr wrote:
>>>>>> Hi.
>>>>>>
>>>>>> Maybe you could use attributes.
>>>>>>
>>>>>> dput(vec.m)
>>>>>> structure(list(Group.1 = c(2003, 2021, 2003, 2021, 2003, 2021, 2003,
>>>>>> 2021, 2003, 2021, 2003, 2021, 2003, 2021, 2003, 2021, 2003, 2021),
>>>>>> variable = structure(c(1L, 1L, 2L, 2L, 3L, 3L, 4L, 4L, 5L, 5L, 6L,
>>>>>> 6L, 7L, 7L, 8L, 8L, 9L, 9L), .Label = c("s6", "s5", "s4", "s3",
>>>>>> "s2", "s1.5", "s.7", "s.5", "pod"), class = "factor"),
>>>>>>        value = c(3.29, 0.525, 5.01, 1.385, 16.38, 7.67, 5.535, 3.28,
>>>>>>        25.49, 24.41, 10.285, 12.79, 8.905, 12.92, 1.68, 3.67, 2.595,
>>>>>>        5.06)), row.names = c(NA, -18L), class = "data.frame")
>>>>>>
>>>>>>> attr(vec.m, "some.kind.of.value") <- c("some specialvector",
>>>>>>> "another special vector", "just ordinary vector")
>>>>>> You can access them by attributes or attr.
>>>>>>
>>>>>>     attributes(vec.m)
>>>>>> $row.names
>>>>>>     [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18
>>>>>>
>>>>>> $names
>>>>>> [1] "Group.1"  "variable" "value"
>>>>>>
>>>>>> $class
>>>>>> [1] "data.frame"
>>>>>>
>>>>>> $some.kind.of.value
>>>>>> [1] "some specialvector"     "another special vector" "just ordinary
>>> vector"
>>>>>>> attr(vec.m, "some")
>>>>>> [1] "some specialvector"     "another special vector" "just ordinary
>>> vector"
>>>>>> Cheers
>>>>>> Petr
>>>>>>
>>>>>>> -----Original Message-----
>>>>>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Steven
>>> Yen
>>>>>>> Sent: Thursday, May 13, 2021 10:07 AM
>>>>>>> To: Fredrik Karlsson <dargosch at gmail.com>
>>>>>>> Cc: R-help Mailing List <r-help at r-project.org>
>>>>>>> Subject: Re: [R] Variable labels
>>>>>>>
>>>>>>> Thanks. What I need ?appears? simple. The .RData file is provided
>>>>>>> by a third party (likely converted from a different data format
>>>>>>> such as SAS in which variable labels (not value labels) are
>>>>>>> common). When I load the binary file, in the ?environment? I see,
>>>>>>> as expected, a data frame showing how many observations for how
>>>>>>> many variables. In addition, there is also an item (in the
>>>>>>> environment) (say ?desc?) containing a list of variable labels
>>>>>>> (definitions).  I simply like to know how to get ?desc? in the
>>>>>>> environment?-it is a convenient way to show definitions of all
>>>>>>> variables when you send a binary data file to a third party. Thank you.
>>>>>>>
>>>>>>>> On May 13, 2021, at 2:57 PM, Fredrik Karlsson <dargosch at gmail.com>
>>>>>>> wrote:
>>>>>>>> Hi,
>>>>>>>>
>>>>>>>> I am sorry but I don't understand your question, Generally,
>>>>>>>> "clicking" is not
>>>>>>> something you can assume to be implemented for anything in R.
>>>>>>>> However, if you read the manual for the package
>>>>>>>>
>>>>>>>>     https://gdemin.github.io/expss/
>>>>>>>>
>>>>>>>> you get an example at the bottom where an illustration of how the
>>>>>>>> package
>>>>>>> can be used to create Excel tables which would then be easy to
>>>>>>> interact with through clicking.
>>>>>>>> Is that what you wanted?
>>>>>>>>
>>>>>>>> Fredrik
>>>>>>>>
>>>>>>>>> On Thu, May 13, 2021 at 4:49 AM Steven Yen <styen at ntu.edu.tw>
>>>>> wrote:
>>>>>>>>> I insert variable with the expss function as shown below. No
>>>>>>>>> error message. My question is, how to save the variable labels in
>>>>>>>>> the data frame so that I can click to read the labels. Thank you.
>>>>>>>>>
>>>>>>>>> mydata<-read_excel("data/Excel/hseinv.xlsx",na=".")
>>>>>>>>> library(expss)
>>>>>>>>> mydata=apply_labels(mydata,
>>>>>>>>>                         year   ="1947-1988",
>>>>>>>>>                         inv    ="real housing inv, millions $",
>>>>>>>>>                         pop    ="population, 1000s",
>>>>>>>>>                         price  ="housing price index; 1982 = 1",
>>>>>>>>>                         linv   ="log(inv)",
>>>>>>>>>                         lpop   ="log(pop)",
>>>>>>>>>                         lprice  ="log(price)",
>>>>>>>>>                         t       ="time trend: t=1,...,42",
>>>>>>>>>                         invpc   ="per capita inv: inv/pop",
>>>>>>>>>                         linvpc  ="log(invpc)",
>>>>>>>>>                         lprice_1="lprice[_n-1]",
>>>>>>>>>                         linvpc_1="linvpc[_n-1]",
>>>>>>>>>                         gprice  ="lprice - lprice_1",
>>>>>>>>>                         ginvpc  ="linvpc - linvpc_1")
>>>>>>>>>
>>>>>>>>> ______________________________________________
>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>> PLEASE do read the posting guide
>>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>> and provide commented, minimal, self-contained, reproducible
>>> code.
>>>>>>>> --
>>>>>>>> "Life is like a trumpet - if you don't put anything into it, you
>>>>>>>> don't get
>>>>>>> anything out of it."
>>>>>>>
>>>>>>>   [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>>>>>> guide.html and provide commented, minimal, self-contained,
>>>>>>> reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From petr@p|k@| @end|ng |rom prechez@@cz  Fri May 14 12:37:17 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Fri, 14 May 2021 10:37:17 +0000
Subject: [R] Variable labels
In-Reply-To: <93e8290e-89a2-4fca-27be-8c6b2b3166e1@ntu.edu.tw>
References: <CANO=ohJ9UMLqBNPequ-njsnn+3wYvOv=Q7h-qOPqf0cmWh8Tpw@mail.gmail.com>
 <6445C370-0081-4F80-9D9C-A0F1511BA397@ntu.edu.tw>
 <88a95efb70564eec83ce0a479dd9f0d1@SRVEXCHCM1302.precheza.cz>
 <3e134457-7d43-e934-32f1-26d54489d832@ntu.edu.tw>
 <7c9393a8fbcb434985fe9c3d31e67ae3@SRVEXCHCM1302.precheza.cz>
 <859b4136-bbba-a4c1-7920-9e31fa1335de@ntu.edu.tw>
 <9083181e865e4549994706f6a799d67d@SRVEXCHCM1302.precheza.cz>
 <CA+8X3fUb8OoFR8BJ4ez_uGbNheJ=Wi8dwMTXu+hCG2Bn9BKDUA@mail.gmail.com>
 <93e8290e-89a2-4fca-27be-8c6b2b3166e1@ntu.edu.tw>
Message-ID: <830c1063882b4852ba6a068bf8e7a639@SRVEXCHCM1302.precheza.cz>

Hm. What do you mean by "clickable".

#I can save any objects to a file
save(mydata,definitions, file="test.R") 
rm("mydata", "definitions")

#load them back
load("test.R")

#but it does not make them "clickable". Point and click is something I am familiar with in Excel or similar programs byt not in R.

#objects are back in the environment and one can inspect them by regular way (print, str, head, ...)
mydata
  id age yrmarry
1  1  35       4
2  2  31       6
3  3  21       4
4  4  20       3
5  5  19       7
6  6  24       5
definitions
               var.labels
id          Individual ID
age          Age in Years
yrmarry Years of marriage

If you want definitions to be part of the data file just use attr.

attr(mydata, "var.labels") <- definitions$var.labels

 attributes(mydata)
$names
[1] "id"      "age"     "yrmarry"

$class
[1] "data.frame"

$row.names
[1] 1 2 3 4 5 6

$var.labels
[1] "Individual ID"     "Age in Years"      "Years of marriage"

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Steven Yen
> Sent: Friday, May 14, 2021 11:20 AM
> To: Jim Lemon <drjimlemon at gmail.com>
> Cc: R-help Mailing List <r-help at r-project.org>
> Subject: Re: [R] Variable labels
> 
> Thanks to all, for bearing with me.
> 
> Now I realize expss may not be what I need. I have now written a self-
> runnable, replicable set of codes (listed below). Perhaps that gives an idea of
> what I need. Question is, whethet this is the right way to do this (to have a
> clickable object to learn about variable
> definitions) or whether there are better ways. Thanks!
> 
> Steven
> 
> rm(list=ls())
> n<-6
> mydata<-data.frame(id=1:n,
>                     age=floor(rnorm(n,25,10)),
>                     yrmarry=floor(rnorm(n,5,2))) var.labels<-c(id  = "Individual ID",
>                age = "Age in Years",
>                yrmarry = "Years of marriage")
> definitions<-as.data.frame(var.labels) # declare definitions as a data frame
> save.image("c:/temp/a/try1.RData")     # save binary .RData file
> rm(list=ls())                          # clean environment
> load("c:/temp/a/try1.RData") # now load .RData file and definitions are
> clickable
>                               # all I need is for user to be able to click
>                               # and read the variable definitions
> 
> On 2021/5/14 ?? 05:15, Jim Lemon wrote:
> > Hi Steven,
> > I just happened to scan Petr's message to you and wondered if you were
> > looking for something related to the "describe" function in the
> > prettyR package (and a few others). For instance, if you do this:
> >
> > library(prettyR)
> > describe(mtcars)
> >
> > you get this:
> >
> > Description of mtcars
> >
> > Numeric
> >        mean median      var     sd valid.n
> > mpg   20.09  19.20    36.32   6.03      32
> > cyl    6.19   6.00     3.19   1.79      32
> > disp 230.72 196.30 15360.80 123.94      32
> > hp   146.69 123.00  4700.87  68.56      32
> > drat   3.60   3.70     0.29   0.53      32
> > wt     3.22   3.33     0.96   0.98      32
> > qsec  17.85  17.71     3.19   1.79      32
> > vs     0.44   0.00     0.25   0.50      32
> > am     0.41   0.00     0.25   0.50      32
> > gear   3.69   4.00     0.54   0.74      32
> > carb   2.81   2.00     2.61   1.62      32
> >
> > However, you can call almost any summary function as an argument to
> > describe. Suppose I wrote a function "fackey" that produced this
> > output on a factor variable "city":
> >
> > fackey(city)
> >
> > label          numeric    count
> > New York   10            30
> > London       15            23
> > Paris          16            22
> > Rome         20            25
> >
> > So if you ran "describe" on your data frame, you would get a list of
> > summary data frames that could be saved with the data frame in an
> > .Rdata file. Is this what you are looking for?
> >
> > Jim
> >
> > On Fri, May 14, 2021 at 4:59 PM PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
> >> Hallo Steven
> >>
> >> You probably need to be more specific what is your intention. I still
> wonder what is the real problem you want to solve.
> >>
> >> You loaded binary file and it resulted to 2 data frames. So far so good. But
> now I am lost.
> >>
> >> You want to merge info from data frame "desc" to data frame "data"? You
> can use attr.
> >> You want to make binary file which behaves like the one you get?  Use
> save/load.
> >> You want to do something different? So please explain what exactly.
> >>
> >> Cheers
> >> Petr
> >>
> >>
> >>> -----Original Message-----
> >>> From: Steven Yen <styen at ntu.edu.tw>
> >>> Sent: Thursday, May 13, 2021 5:53 PM
> >>> To: PIKAL Petr <petr.pikal at precheza.cz>
> >>> Subject: Re: [R] Variable labels
> >>>
> >>> Petr
> >>>
> >>> Those attachments (1.jpg, 2.jpg) I sent earlier were just screen
> >>> captures (with a third-party program) of what I saw in the
> >>> Environment pane right after loading the data. Sorry I cannot explain my
> questions well enough.
> >>>
> >>> All I was showing you was, right after loading the binary data file,
> >>> I saw two data frames---data which contain the data, and desc which
> >>> contains definitions of all variables (as shown in 2.jpg). This is a
> >>> data file from the publisher and I wanted to know what it takes to
> >>> create a binary data files along with definitions of variables, both in the
> environment.
> >>>
> >>> Steven
> >>>
> >>> On 2021/5/13 ?? 09:51, PIKAL Petr wrote:
> >>>> Hi Steven
> >>>>
> >>>> I probably do not understand your question correctly. In 1 you show
> >>>> two
> >>> objects "data" 14x42 data frame and "desc" which is 2x14 data frame,
> >>> both residing in global environment.
> >>>> In 2 you show contents of data frame desc where variable are
> >>>> probably
> >>> variable names which are also in data object.
> >>>> names(data)
> >>>>
> >>>> and label which is some more elaborate description of the variable.
> >>>>
> >>>> If you want to move this label into your data object you probably
> >>>> could use attr
> >>>>
> >>>> attr(data, "label") <- desc$label
> >>>>
> >>>> If the order of "variable" is same as the order of data columns.
> >>>>
> >>>> I do not understand what do you mean by - how to get that "desc" in
> >>>> there in the environment? It is already part of global environment.
> >>>> You
> >>> want to create some new environment and move you desc there?
> >>>> Beside, your images are not familiar to me, this is plain R or some
> >>>> kind of
> >>> special GUI like R studio?
> >>>> Cheers
> >>>> Petr
> >>>>
> >>>>> -----Original Message-----
> >>>>> From: Steven Yen <styen at ntu.edu.tw>
> >>>>> Sent: Thursday, May 13, 2021 1:37 PM
> >>>>> To: PIKAL Petr <petr.pikal at precheza.cz>
> >>>>> Subject: Re: [R] Variable labels
> >>>>>
> >>>>> Petr
> >>>>>
> >>>>> Thanks. I am sending this to you privately as I am sending attachment.
> >>>>>
> >>>>> 1. I load the binary file and see the data frame and what appears
> >>>>> to be description (desc) alongside it (1.jpg).
> >>>>>
> >>>>> 2. Expanding "desc", I get to read the documentation (contents of
> desc).
> >>>>> (2.jpg).
> >>>>>
> >>>>> #2 is all I need. I do not need to do anything fancy with the
> >>>>> variable label. I just like my students to have a simple ways of
> >>>>> learning the variables is the data file I provide to them.
> >>>>>
> >>>>> Again, my main question is, how to get that "desc" in there in the
> >>>>> environment. Thanks.
> >>>>>
> >>>>> Steven
> >>>>>
> >>>>> On 2021/5/13 ?? 06:31, PIKAL Petr wrote:
> >>>>>> Hi.
> >>>>>>
> >>>>>> Maybe you could use attributes.
> >>>>>>
> >>>>>> dput(vec.m)
> >>>>>> structure(list(Group.1 = c(2003, 2021, 2003, 2021, 2003, 2021,
> >>>>>> 2003, 2021, 2003, 2021, 2003, 2021, 2003, 2021, 2003, 2021, 2003,
> >>>>>> 2021), variable = structure(c(1L, 1L, 2L, 2L, 3L, 3L, 4L, 4L, 5L,
> >>>>>> 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L), .Label = c("s6", "s5", "s4",
> >>>>>> "s3", "s2", "s1.5", "s.7", "s.5", "pod"), class = "factor"),
> >>>>>>        value = c(3.29, 0.525, 5.01, 1.385, 16.38, 7.67, 5.535, 3.28,
> >>>>>>        25.49, 24.41, 10.285, 12.79, 8.905, 12.92, 1.68, 3.67, 2.595,
> >>>>>>        5.06)), row.names = c(NA, -18L), class = "data.frame")
> >>>>>>
> >>>>>>> attr(vec.m, "some.kind.of.value") <- c("some specialvector",
> >>>>>>> "another special vector", "just ordinary vector")
> >>>>>> You can access them by attributes or attr.
> >>>>>>
> >>>>>>     attributes(vec.m)
> >>>>>> $row.names
> >>>>>>     [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18
> >>>>>>
> >>>>>> $names
> >>>>>> [1] "Group.1"  "variable" "value"
> >>>>>>
> >>>>>> $class
> >>>>>> [1] "data.frame"
> >>>>>>
> >>>>>> $some.kind.of.value
> >>>>>> [1] "some specialvector"     "another special vector" "just ordinary
> >>> vector"
> >>>>>>> attr(vec.m, "some")
> >>>>>> [1] "some specialvector"     "another special vector" "just ordinary
> >>> vector"
> >>>>>> Cheers
> >>>>>> Petr
> >>>>>>
> >>>>>>> -----Original Message-----
> >>>>>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Steven
> >>> Yen
> >>>>>>> Sent: Thursday, May 13, 2021 10:07 AM
> >>>>>>> To: Fredrik Karlsson <dargosch at gmail.com>
> >>>>>>> Cc: R-help Mailing List <r-help at r-project.org>
> >>>>>>> Subject: Re: [R] Variable labels
> >>>>>>>
> >>>>>>> Thanks. What I need ?appears? simple. The .RData file is
> >>>>>>> provided by a third party (likely converted from a different
> >>>>>>> data format such as SAS in which variable labels (not value
> >>>>>>> labels) are common). When I load the binary file, in the
> >>>>>>> ?environment? I see, as expected, a data frame showing how many
> >>>>>>> observations for how many variables. In addition, there is also
> >>>>>>> an item (in the
> >>>>>>> environment) (say ?desc?) containing a list of variable labels
> >>>>>>> (definitions).  I simply like to know how to get ?desc? in the
> >>>>>>> environment?-it is a convenient way to show definitions of all
> >>>>>>> variables when you send a binary data file to a third party. Thank
> you.
> >>>>>>>
> >>>>>>>> On May 13, 2021, at 2:57 PM, Fredrik Karlsson
> >>>>>>>> <dargosch at gmail.com>
> >>>>>>> wrote:
> >>>>>>>> Hi,
> >>>>>>>>
> >>>>>>>> I am sorry but I don't understand your question, Generally,
> >>>>>>>> "clicking" is not
> >>>>>>> something you can assume to be implemented for anything in R.
> >>>>>>>> However, if you read the manual for the package
> >>>>>>>>
> >>>>>>>>     https://gdemin.github.io/expss/
> >>>>>>>>
> >>>>>>>> you get an example at the bottom where an illustration of how
> >>>>>>>> the package
> >>>>>>> can be used to create Excel tables which would then be easy to
> >>>>>>> interact with through clicking.
> >>>>>>>> Is that what you wanted?
> >>>>>>>>
> >>>>>>>> Fredrik
> >>>>>>>>
> >>>>>>>>> On Thu, May 13, 2021 at 4:49 AM Steven Yen
> <styen at ntu.edu.tw>
> >>>>> wrote:
> >>>>>>>>> I insert variable with the expss function as shown below. No
> >>>>>>>>> error message. My question is, how to save the variable labels
> >>>>>>>>> in the data frame so that I can click to read the labels. Thank you.
> >>>>>>>>>
> >>>>>>>>> mydata<-read_excel("data/Excel/hseinv.xlsx",na=".")
> >>>>>>>>> library(expss)
> >>>>>>>>> mydata=apply_labels(mydata,
> >>>>>>>>>                         year   ="1947-1988",
> >>>>>>>>>                         inv    ="real housing inv, millions $",
> >>>>>>>>>                         pop    ="population, 1000s",
> >>>>>>>>>                         price  ="housing price index; 1982 = 1",
> >>>>>>>>>                         linv   ="log(inv)",
> >>>>>>>>>                         lpop   ="log(pop)",
> >>>>>>>>>                         lprice  ="log(price)",
> >>>>>>>>>                         t       ="time trend: t=1,...,42",
> >>>>>>>>>                         invpc   ="per capita inv: inv/pop",
> >>>>>>>>>                         linvpc  ="log(invpc)",
> >>>>>>>>>                         lprice_1="lprice[_n-1]",
> >>>>>>>>>                         linvpc_1="linvpc[_n-1]",
> >>>>>>>>>                         gprice  ="lprice - lprice_1",
> >>>>>>>>>                         ginvpc  ="linvpc - linvpc_1")
> >>>>>>>>>
> >>>>>>>>> ______________________________________________
> >>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >>>>>>>>> see https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>>> PLEASE do read the posting guide
> >>>>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>>>> and provide commented, minimal, self-contained, reproducible
> >>> code.
> >>>>>>>> --
> >>>>>>>> "Life is like a trumpet - if you don't put anything into it,
> >>>>>>>> you don't get
> >>>>>>> anything out of it."
> >>>>>>>
> >>>>>>>   [[alternative HTML version deleted]]
> >>>>>>>
> >>>>>>> ______________________________________________
> >>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >>>>>>> see https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>> PLEASE do read the posting guide
> >>>>>>> http://www.R-project.org/posting- guide.html and provide
> >>>>>>> commented, minimal, self-contained, reproducible code.
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From @tyen @end|ng |rom ntu@edu@tw  Fri May 14 12:48:14 2021
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Fri, 14 May 2021 18:48:14 +0800
Subject: [R] Variable labels
In-Reply-To: <830c1063882b4852ba6a068bf8e7a639@SRVEXCHCM1302.precheza.cz>
References: <CANO=ohJ9UMLqBNPequ-njsnn+3wYvOv=Q7h-qOPqf0cmWh8Tpw@mail.gmail.com>
 <6445C370-0081-4F80-9D9C-A0F1511BA397@ntu.edu.tw>
 <88a95efb70564eec83ce0a479dd9f0d1@SRVEXCHCM1302.precheza.cz>
 <3e134457-7d43-e934-32f1-26d54489d832@ntu.edu.tw>
 <7c9393a8fbcb434985fe9c3d31e67ae3@SRVEXCHCM1302.precheza.cz>
 <859b4136-bbba-a4c1-7920-9e31fa1335de@ntu.edu.tw>
 <9083181e865e4549994706f6a799d67d@SRVEXCHCM1302.precheza.cz>
 <CA+8X3fUb8OoFR8BJ4ez_uGbNheJ=Wi8dwMTXu+hCG2Bn9BKDUA@mail.gmail.com>
 <93e8290e-89a2-4fca-27be-8c6b2b3166e1@ntu.edu.tw>
 <830c1063882b4852ba6a068bf8e7a639@SRVEXCHCM1302.precheza.cz>
Message-ID: <7e2dc332-6d15-ad0e-4311-3d63915e10f0@ntu.edu.tw>

Never mind what I said about "Clickable". All I meant was I created an 
item "definitions" that appears after I load the binary file, and that I 
can "click" (don's ask me what I mean by "click") the item in RStudio to 
read its contents -- variable definitions.

All I want to know at this pointis, is whether my way of getting the 
definitions in the environment "clumsy" and whether there are better 
ways to do it. Yes, you mention "attr..." but that is not as simple as 
viewing it in RStudio's environment pane. Thank you!

On 2021/5/14 ?? 06:37, PIKAL Petr wrote:
> Hm. What do you mean by "clickable".
>
> #I can save any objects to a file
> save(mydata,definitions, file="test.R")
> rm("mydata", "definitions")
>
> #load them back
> load("test.R")
>
> #but it does not make them "clickable". Point and click is something I am familiar with in Excel or similar programs byt not in R.
>
> #objects are back in the environment and one can inspect them by regular way (print, str, head, ...)
> mydata
>    id age yrmarry
> 1  1  35       4
> 2  2  31       6
> 3  3  21       4
> 4  4  20       3
> 5  5  19       7
> 6  6  24       5
> definitions
>                 var.labels
> id          Individual ID
> age          Age in Years
> yrmarry Years of marriage
>
> If you want definitions to be part of the data file just use attr.
>
> attr(mydata, "var.labels") <- definitions$var.labels
>
>   attributes(mydata)
> $names
> [1] "id"      "age"     "yrmarry"
>
> $class
> [1] "data.frame"
>
> $row.names
> [1] 1 2 3 4 5 6
>
> $var.labels
> [1] "Individual ID"     "Age in Years"      "Years of marriage"
>
> Cheers
> Petr
>
>> -----Original Message-----
>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Steven Yen
>> Sent: Friday, May 14, 2021 11:20 AM
>> To: Jim Lemon <drjimlemon at gmail.com>
>> Cc: R-help Mailing List <r-help at r-project.org>
>> Subject: Re: [R] Variable labels
>>
>> Thanks to all, for bearing with me.
>>
>> Now I realize expss may not be what I need. I have now written a self-
>> runnable, replicable set of codes (listed below). Perhaps that gives an idea of
>> what I need. Question is, whethet this is the right way to do this (to have a
>> clickable object to learn about variable
>> definitions) or whether there are better ways. Thanks!
>>
>> Steven
>>
>> rm(list=ls())
>> n<-6
>> mydata<-data.frame(id=1:n,
>>                      age=floor(rnorm(n,25,10)),
>>                      yrmarry=floor(rnorm(n,5,2))) var.labels<-c(id  = "Individual ID",
>>                 age = "Age in Years",
>>                 yrmarry = "Years of marriage")
>> definitions<-as.data.frame(var.labels) # declare definitions as a data frame
>> save.image("c:/temp/a/try1.RData")     # save binary .RData file
>> rm(list=ls())                          # clean environment
>> load("c:/temp/a/try1.RData") # now load .RData file and definitions are
>> clickable
>>                                # all I need is for user to be able to click
>>                                # and read the variable definitions
>>
>> On 2021/5/14 ?? 05:15, Jim Lemon wrote:
>>> Hi Steven,
>>> I just happened to scan Petr's message to you and wondered if you were
>>> looking for something related to the "describe" function in the
>>> prettyR package (and a few others). For instance, if you do this:
>>>
>>> library(prettyR)
>>> describe(mtcars)
>>>
>>> you get this:
>>>
>>> Description of mtcars
>>>
>>> Numeric
>>>         mean median      var     sd valid.n
>>> mpg   20.09  19.20    36.32   6.03      32
>>> cyl    6.19   6.00     3.19   1.79      32
>>> disp 230.72 196.30 15360.80 123.94      32
>>> hp   146.69 123.00  4700.87  68.56      32
>>> drat   3.60   3.70     0.29   0.53      32
>>> wt     3.22   3.33     0.96   0.98      32
>>> qsec  17.85  17.71     3.19   1.79      32
>>> vs     0.44   0.00     0.25   0.50      32
>>> am     0.41   0.00     0.25   0.50      32
>>> gear   3.69   4.00     0.54   0.74      32
>>> carb   2.81   2.00     2.61   1.62      32
>>>
>>> However, you can call almost any summary function as an argument to
>>> describe. Suppose I wrote a function "fackey" that produced this
>>> output on a factor variable "city":
>>>
>>> fackey(city)
>>>
>>> label          numeric    count
>>> New York   10            30
>>> London       15            23
>>> Paris          16            22
>>> Rome         20            25
>>>
>>> So if you ran "describe" on your data frame, you would get a list of
>>> summary data frames that could be saved with the data frame in an
>>> .Rdata file. Is this what you are looking for?
>>>
>>> Jim
>>>
>>> On Fri, May 14, 2021 at 4:59 PM PIKAL Petr <petr.pikal at precheza.cz>
>> wrote:
>>>> Hallo Steven
>>>>
>>>> You probably need to be more specific what is your intention. I still
>> wonder what is the real problem you want to solve.
>>>> You loaded binary file and it resulted to 2 data frames. So far so good. But
>> now I am lost.
>>>> You want to merge info from data frame "desc" to data frame "data"? You
>> can use attr.
>>>> You want to make binary file which behaves like the one you get?  Use
>> save/load.
>>>> You want to do something different? So please explain what exactly.
>>>>
>>>> Cheers
>>>> Petr
>>>>
>>>>
>>>>> -----Original Message-----
>>>>> From: Steven Yen <styen at ntu.edu.tw>
>>>>> Sent: Thursday, May 13, 2021 5:53 PM
>>>>> To: PIKAL Petr <petr.pikal at precheza.cz>
>>>>> Subject: Re: [R] Variable labels
>>>>>
>>>>> Petr
>>>>>
>>>>> Those attachments (1.jpg, 2.jpg) I sent earlier were just screen
>>>>> captures (with a third-party program) of what I saw in the
>>>>> Environment pane right after loading the data. Sorry I cannot explain my
>> questions well enough.
>>>>> All I was showing you was, right after loading the binary data file,
>>>>> I saw two data frames---data which contain the data, and desc which
>>>>> contains definitions of all variables (as shown in 2.jpg). This is a
>>>>> data file from the publisher and I wanted to know what it takes to
>>>>> create a binary data files along with definitions of variables, both in the
>> environment.
>>>>> Steven
>>>>>
>>>>> On 2021/5/13 ?? 09:51, PIKAL Petr wrote:
>>>>>> Hi Steven
>>>>>>
>>>>>> I probably do not understand your question correctly. In 1 you show
>>>>>> two
>>>>> objects "data" 14x42 data frame and "desc" which is 2x14 data frame,
>>>>> both residing in global environment.
>>>>>> In 2 you show contents of data frame desc where variable are
>>>>>> probably
>>>>> variable names which are also in data object.
>>>>>> names(data)
>>>>>>
>>>>>> and label which is some more elaborate description of the variable.
>>>>>>
>>>>>> If you want to move this label into your data object you probably
>>>>>> could use attr
>>>>>>
>>>>>> attr(data, "label") <- desc$label
>>>>>>
>>>>>> If the order of "variable" is same as the order of data columns.
>>>>>>
>>>>>> I do not understand what do you mean by - how to get that "desc" in
>>>>>> there in the environment? It is already part of global environment.
>>>>>> You
>>>>> want to create some new environment and move you desc there?
>>>>>> Beside, your images are not familiar to me, this is plain R or some
>>>>>> kind of
>>>>> special GUI like R studio?
>>>>>> Cheers
>>>>>> Petr
>>>>>>
>>>>>>> -----Original Message-----
>>>>>>> From: Steven Yen <styen at ntu.edu.tw>
>>>>>>> Sent: Thursday, May 13, 2021 1:37 PM
>>>>>>> To: PIKAL Petr <petr.pikal at precheza.cz>
>>>>>>> Subject: Re: [R] Variable labels
>>>>>>>
>>>>>>> Petr
>>>>>>>
>>>>>>> Thanks. I am sending this to you privately as I am sending attachment.
>>>>>>>
>>>>>>> 1. I load the binary file and see the data frame and what appears
>>>>>>> to be description (desc) alongside it (1.jpg).
>>>>>>>
>>>>>>> 2. Expanding "desc", I get to read the documentation (contents of
>> desc).
>>>>>>> (2.jpg).
>>>>>>>
>>>>>>> #2 is all I need. I do not need to do anything fancy with the
>>>>>>> variable label. I just like my students to have a simple ways of
>>>>>>> learning the variables is the data file I provide to them.
>>>>>>>
>>>>>>> Again, my main question is, how to get that "desc" in there in the
>>>>>>> environment. Thanks.
>>>>>>>
>>>>>>> Steven
>>>>>>>
>>>>>>> On 2021/5/13 ?? 06:31, PIKAL Petr wrote:
>>>>>>>> Hi.
>>>>>>>>
>>>>>>>> Maybe you could use attributes.
>>>>>>>>
>>>>>>>> dput(vec.m)
>>>>>>>> structure(list(Group.1 = c(2003, 2021, 2003, 2021, 2003, 2021,
>>>>>>>> 2003, 2021, 2003, 2021, 2003, 2021, 2003, 2021, 2003, 2021, 2003,
>>>>>>>> 2021), variable = structure(c(1L, 1L, 2L, 2L, 3L, 3L, 4L, 4L, 5L,
>>>>>>>> 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L), .Label = c("s6", "s5", "s4",
>>>>>>>> "s3", "s2", "s1.5", "s.7", "s.5", "pod"), class = "factor"),
>>>>>>>>         value = c(3.29, 0.525, 5.01, 1.385, 16.38, 7.67, 5.535, 3.28,
>>>>>>>>         25.49, 24.41, 10.285, 12.79, 8.905, 12.92, 1.68, 3.67, 2.595,
>>>>>>>>         5.06)), row.names = c(NA, -18L), class = "data.frame")
>>>>>>>>
>>>>>>>>> attr(vec.m, "some.kind.of.value") <- c("some specialvector",
>>>>>>>>> "another special vector", "just ordinary vector")
>>>>>>>> You can access them by attributes or attr.
>>>>>>>>
>>>>>>>>      attributes(vec.m)
>>>>>>>> $row.names
>>>>>>>>      [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18
>>>>>>>>
>>>>>>>> $names
>>>>>>>> [1] "Group.1"  "variable" "value"
>>>>>>>>
>>>>>>>> $class
>>>>>>>> [1] "data.frame"
>>>>>>>>
>>>>>>>> $some.kind.of.value
>>>>>>>> [1] "some specialvector"     "another special vector" "just ordinary
>>>>> vector"
>>>>>>>>> attr(vec.m, "some")
>>>>>>>> [1] "some specialvector"     "another special vector" "just ordinary
>>>>> vector"
>>>>>>>> Cheers
>>>>>>>> Petr
>>>>>>>>
>>>>>>>>> -----Original Message-----
>>>>>>>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Steven
>>>>> Yen
>>>>>>>>> Sent: Thursday, May 13, 2021 10:07 AM
>>>>>>>>> To: Fredrik Karlsson <dargosch at gmail.com>
>>>>>>>>> Cc: R-help Mailing List <r-help at r-project.org>
>>>>>>>>> Subject: Re: [R] Variable labels
>>>>>>>>>
>>>>>>>>> Thanks. What I need ?appears? simple. The .RData file is
>>>>>>>>> provided by a third party (likely converted from a different
>>>>>>>>> data format such as SAS in which variable labels (not value
>>>>>>>>> labels) are common). When I load the binary file, in the
>>>>>>>>> ?environment? I see, as expected, a data frame showing how many
>>>>>>>>> observations for how many variables. In addition, there is also
>>>>>>>>> an item (in the
>>>>>>>>> environment) (say ?desc?) containing a list of variable labels
>>>>>>>>> (definitions).  I simply like to know how to get ?desc? in the
>>>>>>>>> environment?-it is a convenient way to show definitions of all
>>>>>>>>> variables when you send a binary data file to a third party. Thank
>> you.
>>>>>>>>>> On May 13, 2021, at 2:57 PM, Fredrik Karlsson
>>>>>>>>>> <dargosch at gmail.com>
>>>>>>>>> wrote:
>>>>>>>>>> Hi,
>>>>>>>>>>
>>>>>>>>>> I am sorry but I don't understand your question, Generally,
>>>>>>>>>> "clicking" is not
>>>>>>>>> something you can assume to be implemented for anything in R.
>>>>>>>>>> However, if you read the manual for the package
>>>>>>>>>>
>>>>>>>>>>      https://gdemin.github.io/expss/
>>>>>>>>>>
>>>>>>>>>> you get an example at the bottom where an illustration of how
>>>>>>>>>> the package
>>>>>>>>> can be used to create Excel tables which would then be easy to
>>>>>>>>> interact with through clicking.
>>>>>>>>>> Is that what you wanted?
>>>>>>>>>>
>>>>>>>>>> Fredrik
>>>>>>>>>>
>>>>>>>>>>> On Thu, May 13, 2021 at 4:49 AM Steven Yen
>> <styen at ntu.edu.tw>
>>>>>>> wrote:
>>>>>>>>>>> I insert variable with the expss function as shown below. No
>>>>>>>>>>> error message. My question is, how to save the variable labels
>>>>>>>>>>> in the data frame so that I can click to read the labels. Thank you.
>>>>>>>>>>>
>>>>>>>>>>> mydata<-read_excel("data/Excel/hseinv.xlsx",na=".")
>>>>>>>>>>> library(expss)
>>>>>>>>>>> mydata=apply_labels(mydata,
>>>>>>>>>>>                          year   ="1947-1988",
>>>>>>>>>>>                          inv    ="real housing inv, millions $",
>>>>>>>>>>>                          pop    ="population, 1000s",
>>>>>>>>>>>                          price  ="housing price index; 1982 = 1",
>>>>>>>>>>>                          linv   ="log(inv)",
>>>>>>>>>>>                          lpop   ="log(pop)",
>>>>>>>>>>>                          lprice  ="log(price)",
>>>>>>>>>>>                          t       ="time trend: t=1,...,42",
>>>>>>>>>>>                          invpc   ="per capita inv: inv/pop",
>>>>>>>>>>>                          linvpc  ="log(invpc)",
>>>>>>>>>>>                          lprice_1="lprice[_n-1]",
>>>>>>>>>>>                          linvpc_1="linvpc[_n-1]",
>>>>>>>>>>>                          gprice  ="lprice - lprice_1",
>>>>>>>>>>>                          ginvpc  ="linvpc - linvpc_1")
>>>>>>>>>>>
>>>>>>>>>>> ______________________________________________
>>>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>>>>>>>>>> see https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>>>> PLEASE do read the posting guide
>>>>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>>>> and provide commented, minimal, self-contained, reproducible
>>>>> code.
>>>>>>>>>> --
>>>>>>>>>> "Life is like a trumpet - if you don't put anything into it,
>>>>>>>>>> you don't get
>>>>>>>>> anything out of it."
>>>>>>>>>
>>>>>>>>>    [[alternative HTML version deleted]]
>>>>>>>>>
>>>>>>>>> ______________________________________________
>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>>>>>>>> see https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>> PLEASE do read the posting guide
>>>>>>>>> http://www.R-project.org/posting- guide.html and provide
>>>>>>>>> commented, minimal, self-contained, reproducible code.
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From petr@p|k@| @end|ng |rom prechez@@cz  Fri May 14 13:52:05 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Fri, 14 May 2021 11:52:05 +0000
Subject: [R] Variable labels
In-Reply-To: <7e2dc332-6d15-ad0e-4311-3d63915e10f0@ntu.edu.tw>
References: <CANO=ohJ9UMLqBNPequ-njsnn+3wYvOv=Q7h-qOPqf0cmWh8Tpw@mail.gmail.com>
 <6445C370-0081-4F80-9D9C-A0F1511BA397@ntu.edu.tw>
 <88a95efb70564eec83ce0a479dd9f0d1@SRVEXCHCM1302.precheza.cz>
 <3e134457-7d43-e934-32f1-26d54489d832@ntu.edu.tw>
 <7c9393a8fbcb434985fe9c3d31e67ae3@SRVEXCHCM1302.precheza.cz>
 <859b4136-bbba-a4c1-7920-9e31fa1335de@ntu.edu.tw>
 <9083181e865e4549994706f6a799d67d@SRVEXCHCM1302.precheza.cz>
 <CA+8X3fUb8OoFR8BJ4ez_uGbNheJ=Wi8dwMTXu+hCG2Bn9BKDUA@mail.gmail.com>
 <93e8290e-89a2-4fca-27be-8c6b2b3166e1@ntu.edu.tw>
 <830c1063882b4852ba6a068bf8e7a639@SRVEXCHCM1302.precheza.cz>
 <7e2dc332-6d15-ad0e-4311-3d63915e10f0@ntu.edu.tw>
Message-ID: <0f88e0feea884debbec27a2322211d2f@SRVEXCHCM1302.precheza.cz>

Well, that is the point. 

I do not use RStudio and dont know what it can or cannot do. So the save/load is probably everything you need if somebody with better knowledge of Rstudio does not come with better suggestion.

Cheers
Petr

> -----Original Message-----
> From: Steven Yen <styen at ntu.edu.tw>
> Sent: Friday, May 14, 2021 12:48 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: R-help Mailing List <r-help at r-project.org>
> Subject: Re: [R] Variable labels
> 
> Never mind what I said about "Clickable". All I meant was I created an item
> "definitions" that appears after I load the binary file, and that I can "click"
> (don's ask me what I mean by "click") the item in RStudio to read its contents
> -- variable definitions.
> 
> All I want to know at this pointis, is whether my way of getting the definitions
> in the environment "clumsy" and whether there are better ways to do it.
> Yes, you mention "attr..." but that is not as simple as viewing it in RStudio's
> environment pane. Thank you!
> 
> On 2021/5/14 ?? 06:37, PIKAL Petr wrote:
> > Hm. What do you mean by "clickable".
> >
> > #I can save any objects to a file
> > save(mydata,definitions, file="test.R") rm("mydata", "definitions")
> >
> > #load them back
> > load("test.R")
> >
> > #but it does not make them "clickable". Point and click is something I am
> familiar with in Excel or similar programs byt not in R.
> >
> > #objects are back in the environment and one can inspect them by
> > regular way (print, str, head, ...) mydata
> >    id age yrmarry
> > 1  1  35       4
> > 2  2  31       6
> > 3  3  21       4
> > 4  4  20       3
> > 5  5  19       7
> > 6  6  24       5
> > definitions
> >                 var.labels
> > id          Individual ID
> > age          Age in Years
> > yrmarry Years of marriage
> >
> > If you want definitions to be part of the data file just use attr.
> >
> > attr(mydata, "var.labels") <- definitions$var.labels
> >
> >   attributes(mydata)
> > $names
> > [1] "id"      "age"     "yrmarry"
> >
> > $class
> > [1] "data.frame"
> >
> > $row.names
> > [1] 1 2 3 4 5 6
> >
> > $var.labels
> > [1] "Individual ID"     "Age in Years"      "Years of marriage"
> >
> > Cheers
> > Petr
> >
> >> -----Original Message-----
> >> From: R-help <r-help-bounces at r-project.org> On Behalf Of Steven Yen
> >> Sent: Friday, May 14, 2021 11:20 AM
> >> To: Jim Lemon <drjimlemon at gmail.com>
> >> Cc: R-help Mailing List <r-help at r-project.org>
> >> Subject: Re: [R] Variable labels
> >>
> >> Thanks to all, for bearing with me.
> >>
> >> Now I realize expss may not be what I need. I have now written a
> >> self- runnable, replicable set of codes (listed below). Perhaps that
> >> gives an idea of what I need. Question is, whethet this is the right
> >> way to do this (to have a clickable object to learn about variable
> >> definitions) or whether there are better ways. Thanks!
> >>
> >> Steven
> >>
> >> rm(list=ls())
> >> n<-6
> >> mydata<-data.frame(id=1:n,
> >>                      age=floor(rnorm(n,25,10)),
> >>                      yrmarry=floor(rnorm(n,5,2))) var.labels<-c(id  = "Individual ID",
> >>                 age = "Age in Years",
> >>                 yrmarry = "Years of marriage")
> >> definitions<-as.data.frame(var.labels) # declare definitions as a data
> frame
> >> save.image("c:/temp/a/try1.RData")     # save binary .RData file
> >> rm(list=ls())                          # clean environment
> >> load("c:/temp/a/try1.RData") # now load .RData file and definitions
> >> are clickable
> >>                                # all I need is for user to be able to click
> >>                                # and read the variable definitions
> >>
> >> On 2021/5/14 ?? 05:15, Jim Lemon wrote:
> >>> Hi Steven,
> >>> I just happened to scan Petr's message to you and wondered if you
> >>> were looking for something related to the "describe" function in the
> >>> prettyR package (and a few others). For instance, if you do this:
> >>>
> >>> library(prettyR)
> >>> describe(mtcars)
> >>>
> >>> you get this:
> >>>
> >>> Description of mtcars
> >>>
> >>> Numeric
> >>>         mean median      var     sd valid.n
> >>> mpg   20.09  19.20    36.32   6.03      32
> >>> cyl    6.19   6.00     3.19   1.79      32
> >>> disp 230.72 196.30 15360.80 123.94      32
> >>> hp   146.69 123.00  4700.87  68.56      32
> >>> drat   3.60   3.70     0.29   0.53      32
> >>> wt     3.22   3.33     0.96   0.98      32
> >>> qsec  17.85  17.71     3.19   1.79      32
> >>> vs     0.44   0.00     0.25   0.50      32
> >>> am     0.41   0.00     0.25   0.50      32
> >>> gear   3.69   4.00     0.54   0.74      32
> >>> carb   2.81   2.00     2.61   1.62      32
> >>>
> >>> However, you can call almost any summary function as an argument to
> >>> describe. Suppose I wrote a function "fackey" that produced this
> >>> output on a factor variable "city":
> >>>
> >>> fackey(city)
> >>>
> >>> label          numeric    count
> >>> New York   10            30
> >>> London       15            23
> >>> Paris          16            22
> >>> Rome         20            25
> >>>
> >>> So if you ran "describe" on your data frame, you would get a list of
> >>> summary data frames that could be saved with the data frame in an
> >>> .Rdata file. Is this what you are looking for?
> >>>
> >>> Jim
> >>>
> >>> On Fri, May 14, 2021 at 4:59 PM PIKAL Petr <petr.pikal at precheza.cz>
> >> wrote:
> >>>> Hallo Steven
> >>>>
> >>>> You probably need to be more specific what is your intention. I
> >>>> still
> >> wonder what is the real problem you want to solve.
> >>>> You loaded binary file and it resulted to 2 data frames. So far so
> >>>> good. But
> >> now I am lost.
> >>>> You want to merge info from data frame "desc" to data frame "data"?
> >>>> You
> >> can use attr.
> >>>> You want to make binary file which behaves like the one you get?
> >>>> Use
> >> save/load.
> >>>> You want to do something different? So please explain what exactly.
> >>>>
> >>>> Cheers
> >>>> Petr
> >>>>
> >>>>
> >>>>> -----Original Message-----
> >>>>> From: Steven Yen <styen at ntu.edu.tw>
> >>>>> Sent: Thursday, May 13, 2021 5:53 PM
> >>>>> To: PIKAL Petr <petr.pikal at precheza.cz>
> >>>>> Subject: Re: [R] Variable labels
> >>>>>
> >>>>> Petr
> >>>>>
> >>>>> Those attachments (1.jpg, 2.jpg) I sent earlier were just screen
> >>>>> captures (with a third-party program) of what I saw in the
> >>>>> Environment pane right after loading the data. Sorry I cannot
> >>>>> explain my
> >> questions well enough.
> >>>>> All I was showing you was, right after loading the binary data
> >>>>> file, I saw two data frames---data which contain the data, and
> >>>>> desc which contains definitions of all variables (as shown in
> >>>>> 2.jpg). This is a data file from the publisher and I wanted to
> >>>>> know what it takes to create a binary data files along with
> >>>>> definitions of variables, both in the
> >> environment.
> >>>>> Steven
> >>>>>
> >>>>> On 2021/5/13 ?? 09:51, PIKAL Petr wrote:
> >>>>>> Hi Steven
> >>>>>>
> >>>>>> I probably do not understand your question correctly. In 1 you
> >>>>>> show two
> >>>>> objects "data" 14x42 data frame and "desc" which is 2x14 data
> >>>>> frame, both residing in global environment.
> >>>>>> In 2 you show contents of data frame desc where variable are
> >>>>>> probably
> >>>>> variable names which are also in data object.
> >>>>>> names(data)
> >>>>>>
> >>>>>> and label which is some more elaborate description of the variable.
> >>>>>>
> >>>>>> If you want to move this label into your data object you probably
> >>>>>> could use attr
> >>>>>>
> >>>>>> attr(data, "label") <- desc$label
> >>>>>>
> >>>>>> If the order of "variable" is same as the order of data columns.
> >>>>>>
> >>>>>> I do not understand what do you mean by - how to get that "desc"
> >>>>>> in there in the environment? It is already part of global environment.
> >>>>>> You
> >>>>> want to create some new environment and move you desc there?
> >>>>>> Beside, your images are not familiar to me, this is plain R or
> >>>>>> some kind of
> >>>>> special GUI like R studio?
> >>>>>> Cheers
> >>>>>> Petr
> >>>>>>
> >>>>>>> -----Original Message-----
> >>>>>>> From: Steven Yen <styen at ntu.edu.tw>
> >>>>>>> Sent: Thursday, May 13, 2021 1:37 PM
> >>>>>>> To: PIKAL Petr <petr.pikal at precheza.cz>
> >>>>>>> Subject: Re: [R] Variable labels
> >>>>>>>
> >>>>>>> Petr
> >>>>>>>
> >>>>>>> Thanks. I am sending this to you privately as I am sending
> attachment.
> >>>>>>>
> >>>>>>> 1. I load the binary file and see the data frame and what
> >>>>>>> appears to be description (desc) alongside it (1.jpg).
> >>>>>>>
> >>>>>>> 2. Expanding "desc", I get to read the documentation (contents
> >>>>>>> of
> >> desc).
> >>>>>>> (2.jpg).
> >>>>>>>
> >>>>>>> #2 is all I need. I do not need to do anything fancy with the
> >>>>>>> variable label. I just like my students to have a simple ways of
> >>>>>>> learning the variables is the data file I provide to them.
> >>>>>>>
> >>>>>>> Again, my main question is, how to get that "desc" in there in
> >>>>>>> the environment. Thanks.
> >>>>>>>
> >>>>>>> Steven
> >>>>>>>
> >>>>>>> On 2021/5/13 ?? 06:31, PIKAL Petr wrote:
> >>>>>>>> Hi.
> >>>>>>>>
> >>>>>>>> Maybe you could use attributes.
> >>>>>>>>
> >>>>>>>> dput(vec.m)
> >>>>>>>> structure(list(Group.1 = c(2003, 2021, 2003, 2021, 2003, 2021,
> >>>>>>>> 2003, 2021, 2003, 2021, 2003, 2021, 2003, 2021, 2003, 2021,
> >>>>>>>> 2003, 2021), variable = structure(c(1L, 1L, 2L, 2L, 3L, 3L, 4L,
> >>>>>>>> 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L), .Label = c("s6",
> >>>>>>>> "s5", "s4", "s3", "s2", "s1.5", "s.7", "s.5", "pod"), class = "factor"),
> >>>>>>>>         value = c(3.29, 0.525, 5.01, 1.385, 16.38, 7.67, 5.535, 3.28,
> >>>>>>>>         25.49, 24.41, 10.285, 12.79, 8.905, 12.92, 1.68, 3.67, 2.595,
> >>>>>>>>         5.06)), row.names = c(NA, -18L), class = "data.frame")
> >>>>>>>>
> >>>>>>>>> attr(vec.m, "some.kind.of.value") <- c("some specialvector",
> >>>>>>>>> "another special vector", "just ordinary vector")
> >>>>>>>> You can access them by attributes or attr.
> >>>>>>>>
> >>>>>>>>      attributes(vec.m)
> >>>>>>>> $row.names
> >>>>>>>>      [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18
> >>>>>>>>
> >>>>>>>> $names
> >>>>>>>> [1] "Group.1"  "variable" "value"
> >>>>>>>>
> >>>>>>>> $class
> >>>>>>>> [1] "data.frame"
> >>>>>>>>
> >>>>>>>> $some.kind.of.value
> >>>>>>>> [1] "some specialvector"     "another special vector" "just ordinary
> >>>>> vector"
> >>>>>>>>> attr(vec.m, "some")
> >>>>>>>> [1] "some specialvector"     "another special vector" "just ordinary
> >>>>> vector"
> >>>>>>>> Cheers
> >>>>>>>> Petr
> >>>>>>>>
> >>>>>>>>> -----Original Message-----
> >>>>>>>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of
> >>>>>>>>> Steven
> >>>>> Yen
> >>>>>>>>> Sent: Thursday, May 13, 2021 10:07 AM
> >>>>>>>>> To: Fredrik Karlsson <dargosch at gmail.com>
> >>>>>>>>> Cc: R-help Mailing List <r-help at r-project.org>
> >>>>>>>>> Subject: Re: [R] Variable labels
> >>>>>>>>>
> >>>>>>>>> Thanks. What I need ?appears? simple. The .RData file is
> >>>>>>>>> provided by a third party (likely converted from a different
> >>>>>>>>> data format such as SAS in which variable labels (not value
> >>>>>>>>> labels) are common). When I load the binary file, in the
> >>>>>>>>> ?environment? I see, as expected, a data frame showing how
> >>>>>>>>> many observations for how many variables. In addition, there
> >>>>>>>>> is also an item (in the
> >>>>>>>>> environment) (say ?desc?) containing a list of variable labels
> >>>>>>>>> (definitions).  I simply like to know how to get ?desc? in the
> >>>>>>>>> environment?-it is a convenient way to show definitions of all
> >>>>>>>>> variables when you send a binary data file to a third party.
> >>>>>>>>> Thank
> >> you.
> >>>>>>>>>> On May 13, 2021, at 2:57 PM, Fredrik Karlsson
> >>>>>>>>>> <dargosch at gmail.com>
> >>>>>>>>> wrote:
> >>>>>>>>>> Hi,
> >>>>>>>>>>
> >>>>>>>>>> I am sorry but I don't understand your question, Generally,
> >>>>>>>>>> "clicking" is not
> >>>>>>>>> something you can assume to be implemented for anything in R.
> >>>>>>>>>> However, if you read the manual for the package
> >>>>>>>>>>
> >>>>>>>>>>      https://gdemin.github.io/expss/
> >>>>>>>>>>
> >>>>>>>>>> you get an example at the bottom where an illustration of how
> >>>>>>>>>> the package
> >>>>>>>>> can be used to create Excel tables which would then be easy to
> >>>>>>>>> interact with through clicking.
> >>>>>>>>>> Is that what you wanted?
> >>>>>>>>>>
> >>>>>>>>>> Fredrik
> >>>>>>>>>>
> >>>>>>>>>>> On Thu, May 13, 2021 at 4:49 AM Steven Yen
> >> <styen at ntu.edu.tw>
> >>>>>>> wrote:
> >>>>>>>>>>> I insert variable with the expss function as shown below. No
> >>>>>>>>>>> error message. My question is, how to save the variable
> >>>>>>>>>>> labels in the data frame so that I can click to read the labels.
> Thank you.
> >>>>>>>>>>>
> >>>>>>>>>>> mydata<-read_excel("data/Excel/hseinv.xlsx",na=".")
> >>>>>>>>>>> library(expss)
> >>>>>>>>>>> mydata=apply_labels(mydata,
> >>>>>>>>>>>                          year   ="1947-1988",
> >>>>>>>>>>>                          inv    ="real housing inv, millions $",
> >>>>>>>>>>>                          pop    ="population, 1000s",
> >>>>>>>>>>>                          price  ="housing price index; 1982 = 1",
> >>>>>>>>>>>                          linv   ="log(inv)",
> >>>>>>>>>>>                          lpop   ="log(pop)",
> >>>>>>>>>>>                          lprice  ="log(price)",
> >>>>>>>>>>>                          t       ="time trend: t=1,...,42",
> >>>>>>>>>>>                          invpc   ="per capita inv: inv/pop",
> >>>>>>>>>>>                          linvpc  ="log(invpc)",
> >>>>>>>>>>>                          lprice_1="lprice[_n-1]",
> >>>>>>>>>>>                          linvpc_1="linvpc[_n-1]",
> >>>>>>>>>>>                          gprice  ="lprice - lprice_1",
> >>>>>>>>>>>                          ginvpc  ="linvpc - linvpc_1")
> >>>>>>>>>>>
> >>>>>>>>>>> ______________________________________________
> >>>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> >>>>>>>>>>> more, see https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>>>>> PLEASE do read the posting guide
> >>>>>>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>>>>>> and provide commented, minimal, self-contained,
> reproducible
> >>>>> code.
> >>>>>>>>>> --
> >>>>>>>>>> "Life is like a trumpet - if you don't put anything into it,
> >>>>>>>>>> you don't get
> >>>>>>>>> anything out of it."
> >>>>>>>>>
> >>>>>>>>>    [[alternative HTML version deleted]]
> >>>>>>>>>
> >>>>>>>>> ______________________________________________
> >>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >>>>>>>>> see https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>>> PLEASE do read the posting guide
> >>>>>>>>> http://www.R-project.org/posting- guide.html and provide
> >>>>>>>>> commented, minimal, self-contained, reproducible code.
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html and provide commented, minimal, self-contained,
> >> reproducible code.

From deep@y@n@@@rk@r @end|ng |rom gm@||@com  Fri May 14 14:14:13 2021
From: deep@y@n@@@rk@r @end|ng |rom gm@||@com (Deepayan Sarkar)
Date: Fri, 14 May 2021 17:44:13 +0530
Subject: [R] Variable labels
In-Reply-To: <7e2dc332-6d15-ad0e-4311-3d63915e10f0@ntu.edu.tw>
References: <CANO=ohJ9UMLqBNPequ-njsnn+3wYvOv=Q7h-qOPqf0cmWh8Tpw@mail.gmail.com>
 <6445C370-0081-4F80-9D9C-A0F1511BA397@ntu.edu.tw>
 <88a95efb70564eec83ce0a479dd9f0d1@SRVEXCHCM1302.precheza.cz>
 <3e134457-7d43-e934-32f1-26d54489d832@ntu.edu.tw>
 <7c9393a8fbcb434985fe9c3d31e67ae3@SRVEXCHCM1302.precheza.cz>
 <859b4136-bbba-a4c1-7920-9e31fa1335de@ntu.edu.tw>
 <9083181e865e4549994706f6a799d67d@SRVEXCHCM1302.precheza.cz>
 <CA+8X3fUb8OoFR8BJ4ez_uGbNheJ=Wi8dwMTXu+hCG2Bn9BKDUA@mail.gmail.com>
 <93e8290e-89a2-4fca-27be-8c6b2b3166e1@ntu.edu.tw>
 <830c1063882b4852ba6a068bf8e7a639@SRVEXCHCM1302.precheza.cz>
 <7e2dc332-6d15-ad0e-4311-3d63915e10f0@ntu.edu.tw>
Message-ID: <CADfFDC559BY4+nAqJmUFbXKfpkhMd4eAuVxgKf1w7uDjTyV8RQ@mail.gmail.com>

On Fri, May 14, 2021 at 4:19 PM Steven Yen <styen at ntu.edu.tw> wrote:
>
> Never mind what I said about "Clickable". All I meant was I created an
> item "definitions" that appears after I load the binary file, and that I
> can "click" (don's ask me what I mean by "click") the item in RStudio to
> read its contents -- variable definitions.

I _think_ what you see as 'clickable' items are the names of variables
in your workspace. So if you need to make some attributes clickable,
you need to save them with a new name. E.g.,

f <- foreign::read.dta("https://sites.google.com/site/md4stata/linked/international-macroeconomic-data-set/ERS_USDA_Historical.dta")

f.attrs <- attributes(f)

'f.attrs' should now be visible and 'clickable'. But in theory, this
could also now contain more attributes that you cannot see in the
RStudio inspector, and you would have no way of knowing...

Hope that helps,

-Deepayan

> All I want to know at this pointis, is whether my way of getting the
> definitions in the environment "clumsy" and whether there are better
> ways to do it. Yes, you mention "attr..." but that is not as simple as
> viewing it in RStudio's environment pane. Thank you!
>
> On 2021/5/14 ?? 06:37, PIKAL Petr wrote:
> > Hm. What do you mean by "clickable".
> >
> > #I can save any objects to a file
> > save(mydata,definitions, file="test.R")
> > rm("mydata", "definitions")
> >
> > #load them back
> > load("test.R")
> >
> > #but it does not make them "clickable". Point and click is something I am familiar with in Excel or similar programs byt not in R.
> >
> > #objects are back in the environment and one can inspect them by regular way (print, str, head, ...)
> > mydata
> >    id age yrmarry
> > 1  1  35       4
> > 2  2  31       6
> > 3  3  21       4
> > 4  4  20       3
> > 5  5  19       7
> > 6  6  24       5
> > definitions
> >                 var.labels
> > id          Individual ID
> > age          Age in Years
> > yrmarry Years of marriage
> >
> > If you want definitions to be part of the data file just use attr.
> >
> > attr(mydata, "var.labels") <- definitions$var.labels
> >
> >   attributes(mydata)
> > $names
> > [1] "id"      "age"     "yrmarry"
> >
> > $class
> > [1] "data.frame"
> >
> > $row.names
> > [1] 1 2 3 4 5 6
> >
> > $var.labels
> > [1] "Individual ID"     "Age in Years"      "Years of marriage"
> >
> > Cheers
> > Petr
> >
> >> -----Original Message-----
> >> From: R-help <r-help-bounces at r-project.org> On Behalf Of Steven Yen
> >> Sent: Friday, May 14, 2021 11:20 AM
> >> To: Jim Lemon <drjimlemon at gmail.com>
> >> Cc: R-help Mailing List <r-help at r-project.org>
> >> Subject: Re: [R] Variable labels
> >>
> >> Thanks to all, for bearing with me.
> >>
> >> Now I realize expss may not be what I need. I have now written a self-
> >> runnable, replicable set of codes (listed below). Perhaps that gives an idea of
> >> what I need. Question is, whethet this is the right way to do this (to have a
> >> clickable object to learn about variable
> >> definitions) or whether there are better ways. Thanks!
> >>
> >> Steven
> >>
> >> rm(list=ls())
> >> n<-6
> >> mydata<-data.frame(id=1:n,
> >>                      age=floor(rnorm(n,25,10)),
> >>                      yrmarry=floor(rnorm(n,5,2))) var.labels<-c(id  = "Individual ID",
> >>                 age = "Age in Years",
> >>                 yrmarry = "Years of marriage")
> >> definitions<-as.data.frame(var.labels) # declare definitions as a data frame
> >> save.image("c:/temp/a/try1.RData")     # save binary .RData file
> >> rm(list=ls())                          # clean environment
> >> load("c:/temp/a/try1.RData") # now load .RData file and definitions are
> >> clickable
> >>                                # all I need is for user to be able to click
> >>                                # and read the variable definitions
> >>
> >> On 2021/5/14 ?? 05:15, Jim Lemon wrote:
> >>> Hi Steven,
> >>> I just happened to scan Petr's message to you and wondered if you were
> >>> looking for something related to the "describe" function in the
> >>> prettyR package (and a few others). For instance, if you do this:
> >>>
> >>> library(prettyR)
> >>> describe(mtcars)
> >>>
> >>> you get this:
> >>>
> >>> Description of mtcars
> >>>
> >>> Numeric
> >>>         mean median      var     sd valid.n
> >>> mpg   20.09  19.20    36.32   6.03      32
> >>> cyl    6.19   6.00     3.19   1.79      32
> >>> disp 230.72 196.30 15360.80 123.94      32
> >>> hp   146.69 123.00  4700.87  68.56      32
> >>> drat   3.60   3.70     0.29   0.53      32
> >>> wt     3.22   3.33     0.96   0.98      32
> >>> qsec  17.85  17.71     3.19   1.79      32
> >>> vs     0.44   0.00     0.25   0.50      32
> >>> am     0.41   0.00     0.25   0.50      32
> >>> gear   3.69   4.00     0.54   0.74      32
> >>> carb   2.81   2.00     2.61   1.62      32
> >>>
> >>> However, you can call almost any summary function as an argument to
> >>> describe. Suppose I wrote a function "fackey" that produced this
> >>> output on a factor variable "city":
> >>>
> >>> fackey(city)
> >>>
> >>> label          numeric    count
> >>> New York   10            30
> >>> London       15            23
> >>> Paris          16            22
> >>> Rome         20            25
> >>>
> >>> So if you ran "describe" on your data frame, you would get a list of
> >>> summary data frames that could be saved with the data frame in an
> >>> .Rdata file. Is this what you are looking for?
> >>>
> >>> Jim
> >>>
> >>> On Fri, May 14, 2021 at 4:59 PM PIKAL Petr <petr.pikal at precheza.cz>
> >> wrote:
> >>>> Hallo Steven
> >>>>
> >>>> You probably need to be more specific what is your intention. I still
> >> wonder what is the real problem you want to solve.
> >>>> You loaded binary file and it resulted to 2 data frames. So far so good. But
> >> now I am lost.
> >>>> You want to merge info from data frame "desc" to data frame "data"? You
> >> can use attr.
> >>>> You want to make binary file which behaves like the one you get?  Use
> >> save/load.
> >>>> You want to do something different? So please explain what exactly.
> >>>>
> >>>> Cheers
> >>>> Petr
> >>>>
> >>>>
> >>>>> -----Original Message-----
> >>>>> From: Steven Yen <styen at ntu.edu.tw>
> >>>>> Sent: Thursday, May 13, 2021 5:53 PM
> >>>>> To: PIKAL Petr <petr.pikal at precheza.cz>
> >>>>> Subject: Re: [R] Variable labels
> >>>>>
> >>>>> Petr
> >>>>>
> >>>>> Those attachments (1.jpg, 2.jpg) I sent earlier were just screen
> >>>>> captures (with a third-party program) of what I saw in the
> >>>>> Environment pane right after loading the data. Sorry I cannot explain my
> >> questions well enough.
> >>>>> All I was showing you was, right after loading the binary data file,
> >>>>> I saw two data frames---data which contain the data, and desc which
> >>>>> contains definitions of all variables (as shown in 2.jpg). This is a
> >>>>> data file from the publisher and I wanted to know what it takes to
> >>>>> create a binary data files along with definitions of variables, both in the
> >> environment.
> >>>>> Steven
> >>>>>
> >>>>> On 2021/5/13 ?? 09:51, PIKAL Petr wrote:
> >>>>>> Hi Steven
> >>>>>>
> >>>>>> I probably do not understand your question correctly. In 1 you show
> >>>>>> two
> >>>>> objects "data" 14x42 data frame and "desc" which is 2x14 data frame,
> >>>>> both residing in global environment.
> >>>>>> In 2 you show contents of data frame desc where variable are
> >>>>>> probably
> >>>>> variable names which are also in data object.
> >>>>>> names(data)
> >>>>>>
> >>>>>> and label which is some more elaborate description of the variable.
> >>>>>>
> >>>>>> If you want to move this label into your data object you probably
> >>>>>> could use attr
> >>>>>>
> >>>>>> attr(data, "label") <- desc$label
> >>>>>>
> >>>>>> If the order of "variable" is same as the order of data columns.
> >>>>>>
> >>>>>> I do not understand what do you mean by - how to get that "desc" in
> >>>>>> there in the environment? It is already part of global environment.
> >>>>>> You
> >>>>> want to create some new environment and move you desc there?
> >>>>>> Beside, your images are not familiar to me, this is plain R or some
> >>>>>> kind of
> >>>>> special GUI like R studio?
> >>>>>> Cheers
> >>>>>> Petr
> >>>>>>
> >>>>>>> -----Original Message-----
> >>>>>>> From: Steven Yen <styen at ntu.edu.tw>
> >>>>>>> Sent: Thursday, May 13, 2021 1:37 PM
> >>>>>>> To: PIKAL Petr <petr.pikal at precheza.cz>
> >>>>>>> Subject: Re: [R] Variable labels
> >>>>>>>
> >>>>>>> Petr
> >>>>>>>
> >>>>>>> Thanks. I am sending this to you privately as I am sending attachment.
> >>>>>>>
> >>>>>>> 1. I load the binary file and see the data frame and what appears
> >>>>>>> to be description (desc) alongside it (1.jpg).
> >>>>>>>
> >>>>>>> 2. Expanding "desc", I get to read the documentation (contents of
> >> desc).
> >>>>>>> (2.jpg).
> >>>>>>>
> >>>>>>> #2 is all I need. I do not need to do anything fancy with the
> >>>>>>> variable label. I just like my students to have a simple ways of
> >>>>>>> learning the variables is the data file I provide to them.
> >>>>>>>
> >>>>>>> Again, my main question is, how to get that "desc" in there in the
> >>>>>>> environment. Thanks.
> >>>>>>>
> >>>>>>> Steven
> >>>>>>>
> >>>>>>> On 2021/5/13 ?? 06:31, PIKAL Petr wrote:
> >>>>>>>> Hi.
> >>>>>>>>
> >>>>>>>> Maybe you could use attributes.
> >>>>>>>>
> >>>>>>>> dput(vec.m)
> >>>>>>>> structure(list(Group.1 = c(2003, 2021, 2003, 2021, 2003, 2021,
> >>>>>>>> 2003, 2021, 2003, 2021, 2003, 2021, 2003, 2021, 2003, 2021, 2003,
> >>>>>>>> 2021), variable = structure(c(1L, 1L, 2L, 2L, 3L, 3L, 4L, 4L, 5L,
> >>>>>>>> 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L), .Label = c("s6", "s5", "s4",
> >>>>>>>> "s3", "s2", "s1.5", "s.7", "s.5", "pod"), class = "factor"),
> >>>>>>>>         value = c(3.29, 0.525, 5.01, 1.385, 16.38, 7.67, 5.535, 3.28,
> >>>>>>>>         25.49, 24.41, 10.285, 12.79, 8.905, 12.92, 1.68, 3.67, 2.595,
> >>>>>>>>         5.06)), row.names = c(NA, -18L), class = "data.frame")
> >>>>>>>>
> >>>>>>>>> attr(vec.m, "some.kind.of.value") <- c("some specialvector",
> >>>>>>>>> "another special vector", "just ordinary vector")
> >>>>>>>> You can access them by attributes or attr.
> >>>>>>>>
> >>>>>>>>      attributes(vec.m)
> >>>>>>>> $row.names
> >>>>>>>>      [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18
> >>>>>>>>
> >>>>>>>> $names
> >>>>>>>> [1] "Group.1"  "variable" "value"
> >>>>>>>>
> >>>>>>>> $class
> >>>>>>>> [1] "data.frame"
> >>>>>>>>
> >>>>>>>> $some.kind.of.value
> >>>>>>>> [1] "some specialvector"     "another special vector" "just ordinary
> >>>>> vector"
> >>>>>>>>> attr(vec.m, "some")
> >>>>>>>> [1] "some specialvector"     "another special vector" "just ordinary
> >>>>> vector"
> >>>>>>>> Cheers
> >>>>>>>> Petr
> >>>>>>>>
> >>>>>>>>> -----Original Message-----
> >>>>>>>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Steven
> >>>>> Yen
> >>>>>>>>> Sent: Thursday, May 13, 2021 10:07 AM
> >>>>>>>>> To: Fredrik Karlsson <dargosch at gmail.com>
> >>>>>>>>> Cc: R-help Mailing List <r-help at r-project.org>
> >>>>>>>>> Subject: Re: [R] Variable labels
> >>>>>>>>>
> >>>>>>>>> Thanks. What I need ?appears? simple. The .RData file is
> >>>>>>>>> provided by a third party (likely converted from a different
> >>>>>>>>> data format such as SAS in which variable labels (not value
> >>>>>>>>> labels) are common). When I load the binary file, in the
> >>>>>>>>> ?environment? I see, as expected, a data frame showing how many
> >>>>>>>>> observations for how many variables. In addition, there is also
> >>>>>>>>> an item (in the
> >>>>>>>>> environment) (say ?desc?) containing a list of variable labels
> >>>>>>>>> (definitions).  I simply like to know how to get ?desc? in the
> >>>>>>>>> environment?-it is a convenient way to show definitions of all
> >>>>>>>>> variables when you send a binary data file to a third party. Thank
> >> you.
> >>>>>>>>>> On May 13, 2021, at 2:57 PM, Fredrik Karlsson
> >>>>>>>>>> <dargosch at gmail.com>
> >>>>>>>>> wrote:
> >>>>>>>>>> Hi,
> >>>>>>>>>>
> >>>>>>>>>> I am sorry but I don't understand your question, Generally,
> >>>>>>>>>> "clicking" is not
> >>>>>>>>> something you can assume to be implemented for anything in R.
> >>>>>>>>>> However, if you read the manual for the package
> >>>>>>>>>>
> >>>>>>>>>>      https://gdemin.github.io/expss/
> >>>>>>>>>>
> >>>>>>>>>> you get an example at the bottom where an illustration of how
> >>>>>>>>>> the package
> >>>>>>>>> can be used to create Excel tables which would then be easy to
> >>>>>>>>> interact with through clicking.
> >>>>>>>>>> Is that what you wanted?
> >>>>>>>>>>
> >>>>>>>>>> Fredrik
> >>>>>>>>>>
> >>>>>>>>>>> On Thu, May 13, 2021 at 4:49 AM Steven Yen
> >> <styen at ntu.edu.tw>
> >>>>>>> wrote:
> >>>>>>>>>>> I insert variable with the expss function as shown below. No
> >>>>>>>>>>> error message. My question is, how to save the variable labels
> >>>>>>>>>>> in the data frame so that I can click to read the labels. Thank you.
> >>>>>>>>>>>
> >>>>>>>>>>> mydata<-read_excel("data/Excel/hseinv.xlsx",na=".")
> >>>>>>>>>>> library(expss)
> >>>>>>>>>>> mydata=apply_labels(mydata,
> >>>>>>>>>>>                          year   ="1947-1988",
> >>>>>>>>>>>                          inv    ="real housing inv, millions $",
> >>>>>>>>>>>                          pop    ="population, 1000s",
> >>>>>>>>>>>                          price  ="housing price index; 1982 = 1",
> >>>>>>>>>>>                          linv   ="log(inv)",
> >>>>>>>>>>>                          lpop   ="log(pop)",
> >>>>>>>>>>>                          lprice  ="log(price)",
> >>>>>>>>>>>                          t       ="time trend: t=1,...,42",
> >>>>>>>>>>>                          invpc   ="per capita inv: inv/pop",
> >>>>>>>>>>>                          linvpc  ="log(invpc)",
> >>>>>>>>>>>                          lprice_1="lprice[_n-1]",
> >>>>>>>>>>>                          linvpc_1="linvpc[_n-1]",
> >>>>>>>>>>>                          gprice  ="lprice - lprice_1",
> >>>>>>>>>>>                          ginvpc  ="linvpc - linvpc_1")
> >>>>>>>>>>>
> >>>>>>>>>>> ______________________________________________
> >>>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >>>>>>>>>>> see https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>>>>> PLEASE do read the posting guide
> >>>>>>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>>>>>> and provide commented, minimal, self-contained, reproducible
> >>>>> code.
> >>>>>>>>>> --
> >>>>>>>>>> "Life is like a trumpet - if you don't put anything into it,
> >>>>>>>>>> you don't get
> >>>>>>>>> anything out of it."
> >>>>>>>>>
> >>>>>>>>>    [[alternative HTML version deleted]]
> >>>>>>>>>
> >>>>>>>>> ______________________________________________
> >>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >>>>>>>>> see https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>>> PLEASE do read the posting guide
> >>>>>>>>> http://www.R-project.org/posting- guide.html and provide
> >>>>>>>>> commented, minimal, self-contained, reproducible code.
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dc@r|@on @end|ng |rom t@mu@edu  Fri May 14 18:00:32 2021
From: dc@r|@on @end|ng |rom t@mu@edu (David Carlson)
Date: Fri, 14 May 2021 11:00:32 -0500
Subject: [R] Variable labels
In-Reply-To: <9083181e865e4549994706f6a799d67d@SRVEXCHCM1302.precheza.cz>
References: <CANO=ohJ9UMLqBNPequ-njsnn+3wYvOv=Q7h-qOPqf0cmWh8Tpw@mail.gmail.com>
 <6445C370-0081-4F80-9D9C-A0F1511BA397@ntu.edu.tw>
 <88a95efb70564eec83ce0a479dd9f0d1@SRVEXCHCM1302.precheza.cz>
 <3e134457-7d43-e934-32f1-26d54489d832@ntu.edu.tw>
 <7c9393a8fbcb434985fe9c3d31e67ae3@SRVEXCHCM1302.precheza.cz>
 <859b4136-bbba-a4c1-7920-9e31fa1335de@ntu.edu.tw>
 <9083181e865e4549994706f6a799d67d@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAE-dL2qsVDxes2HCfudKSdZk3H+Y6BUzrdVvkV2dCjH3cwwxSQ@mail.gmail.com>

You might also look into packages `Hmisc` and `labelVector` that provide
some support for labeling variable names.

David C


On Fri, May 14, 2021 at 1:59 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hallo Steven
>
> You probably need to be more specific what is your intention. I still
> wonder what is the real problem you want to solve.
>
> You loaded binary file and it resulted to 2 data frames. So far so good.
> But now I am lost.
>
> You want to merge info from data frame "desc" to data frame "data"? You
> can use attr.
> You want to make binary file which behaves like the one you get?  Use
> save/load.
> You want to do something different? So please explain what exactly.
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: Steven Yen <styen at ntu.edu.tw>
> > Sent: Thursday, May 13, 2021 5:53 PM
> > To: PIKAL Petr <petr.pikal at precheza.cz>
> > Subject: Re: [R] Variable labels
> >
> > Petr
> >
> > Those attachments (1.jpg, 2.jpg) I sent earlier were just screen captures
> > (with a third-party program) of what I saw in the Environment pane right
> > after loading the data. Sorry I cannot explain my questions well enough.
> >
> > All I was showing you was, right after loading the binary data file, I
> saw two
> > data frames---data which contain the data, and desc which contains
> > definitions of all variables (as shown in 2.jpg). This is a data file
> from the
> > publisher and I wanted to know what it takes to create a binary data
> files
> > along with definitions of variables, both in the environment.
> >
> > Steven
> >
> > On 2021/5/13 ?? 09:51, PIKAL Petr wrote:
> > > Hi Steven
> > >
> > > I probably do not understand your question correctly. In 1 you show two
> > objects "data" 14x42 data frame and "desc" which is 2x14 data frame, both
> > residing in global environment.
> > >
> > > In 2 you show contents of data frame desc where variable are probably
> > variable names which are also in data object.
> > >
> > > names(data)
> > >
> > > and label which is some more elaborate description of the variable.
> > >
> > > If you want to move this label into your data object you probably
> > > could use attr
> > >
> > > attr(data, "label") <- desc$label
> > >
> > > If the order of "variable" is same as the order of data columns.
> > >
> > > I do not understand what do you mean by - how to get that "desc" in
> > > there in the environment? It is already part of global environment. You
> > want to create some new environment and move you desc there?
> > >
> > > Beside, your images are not familiar to me, this is plain R or some
> kind of
> > special GUI like R studio?
> > >
> > > Cheers
> > > Petr
> > >
> > >> -----Original Message-----
> > >> From: Steven Yen <styen at ntu.edu.tw>
> > >> Sent: Thursday, May 13, 2021 1:37 PM
> > >> To: PIKAL Petr <petr.pikal at precheza.cz>
> > >> Subject: Re: [R] Variable labels
> > >>
> > >> Petr
> > >>
> > >> Thanks. I am sending this to you privately as I am sending attachment.
> > >>
> > >> 1. I load the binary file and see the data frame and what appears to
> > >> be description (desc) alongside it (1.jpg).
> > >>
> > >> 2. Expanding "desc", I get to read the documentation (contents of
> desc).
> > >> (2.jpg).
> > >>
> > >> #2 is all I need. I do not need to do anything fancy with the
> > >> variable label. I just like my students to have a simple ways of
> > >> learning the variables is the data file I provide to them.
> > >>
> > >> Again, my main question is, how to get that "desc" in there in the
> > >> environment. Thanks.
> > >>
> > >> Steven
> > >>
> > >> On 2021/5/13 ?? 06:31, PIKAL Petr wrote:
> > >>> Hi.
> > >>>
> > >>> Maybe you could use attributes.
> > >>>
> > >>> dput(vec.m)
> > >>> structure(list(Group.1 = c(2003, 2021, 2003, 2021, 2003, 2021, 2003,
> > >>> 2021, 2003, 2021, 2003, 2021, 2003, 2021, 2003, 2021, 2003, 2021),
> > >>> variable = structure(c(1L, 1L, 2L, 2L, 3L, 3L, 4L, 4L, 5L, 5L, 6L,
> > >>> 6L, 7L, 7L, 8L, 8L, 9L, 9L), .Label = c("s6", "s5", "s4", "s3",
> > >>> "s2", "s1.5", "s.7", "s.5", "pod"), class = "factor"),
> > >>>       value = c(3.29, 0.525, 5.01, 1.385, 16.38, 7.67, 5.535, 3.28,
> > >>>       25.49, 24.41, 10.285, 12.79, 8.905, 12.92, 1.68, 3.67, 2.595,
> > >>>       5.06)), row.names = c(NA, -18L), class = "data.frame")
> > >>>
> > >>>> attr(vec.m, "some.kind.of.value") <- c("some specialvector",
> > >>>> "another special vector", "just ordinary vector")
> > >>> You can access them by attributes or attr.
> > >>>
> > >>>    attributes(vec.m)
> > >>> $row.names
> > >>>    [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18
> > >>>
> > >>> $names
> > >>> [1] "Group.1"  "variable" "value"
> > >>>
> > >>> $class
> > >>> [1] "data.frame"
> > >>>
> > >>> $some.kind.of.value
> > >>> [1] "some specialvector"     "another special vector" "just ordinary
> > vector"
> > >>>
> > >>>> attr(vec.m, "some")
> > >>> [1] "some specialvector"     "another special vector" "just ordinary
> > vector"
> > >>> Cheers
> > >>> Petr
> > >>>
> > >>>> -----Original Message-----
> > >>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Steven
> > Yen
> > >>>> Sent: Thursday, May 13, 2021 10:07 AM
> > >>>> To: Fredrik Karlsson <dargosch at gmail.com>
> > >>>> Cc: R-help Mailing List <r-help at r-project.org>
> > >>>> Subject: Re: [R] Variable labels
> > >>>>
> > >>>> Thanks. What I need ?appears? simple. The .RData file is provided
> > >>>> by a third party (likely converted from a different data format
> > >>>> such as SAS in which variable labels (not value labels) are
> > >>>> common). When I load the binary file, in the ?environment? I see,
> > >>>> as expected, a data frame showing how many observations for how
> > >>>> many variables. In addition, there is also an item (in the
> > >>>> environment) (say ?desc?) containing a list of variable labels
> > >>>> (definitions).  I simply like to know how to get ?desc? in the
> > >>>> environment?-it is a convenient way to show definitions of all
> > >>>> variables when you send a binary data file to a third party. Thank
> you.
> > >>>>
> > >>>>> On May 13, 2021, at 2:57 PM, Fredrik Karlsson <dargosch at gmail.com>
> > >>>> wrote:
> > >>>>> Hi,
> > >>>>>
> > >>>>> I am sorry but I don't understand your question, Generally,
> > >>>>> "clicking" is not
> > >>>> something you can assume to be implemented for anything in R.
> > >>>>> However, if you read the manual for the package
> > >>>>>
> > >>>>>
> https://urldefense.com/v3/__https://gdemin.github.io/expss/__;!!KwNVnqRv!U8ymUDChjP_1oBH6pjmrcYLLTL_FL6xmEsTlSAvVuix4Lw4fBPE7gW7LzanEAOY$
> > >>>>>
> > >>>>> you get an example at the bottom where an illustration of how the
> > >>>>> package
> > >>>> can be used to create Excel tables which would then be easy to
> > >>>> interact with through clicking.
> > >>>>> Is that what you wanted?
> > >>>>>
> > >>>>> Fredrik
> > >>>>>
> > >>>>>> On Thu, May 13, 2021 at 4:49 AM Steven Yen <styen at ntu.edu.tw>
> > >> wrote:
> > >>>>>> I insert variable with the expss function as shown below. No
> > >>>>>> error message. My question is, how to save the variable labels in
> > >>>>>> the data frame so that I can click to read the labels. Thank you.
> > >>>>>>
> > >>>>>> mydata<-read_excel("data/Excel/hseinv.xlsx",na=".")
> > >>>>>> library(expss)
> > >>>>>> mydata=apply_labels(mydata,
> > >>>>>>                        year   ="1947-1988",
> > >>>>>>                        inv    ="real housing inv, millions $",
> > >>>>>>                        pop    ="population, 1000s",
> > >>>>>>                        price  ="housing price index; 1982 = 1",
> > >>>>>>                        linv   ="log(inv)",
> > >>>>>>                        lpop   ="log(pop)",
> > >>>>>>                        lprice  ="log(price)",
> > >>>>>>                        t       ="time trend: t=1,...,42",
> > >>>>>>                        invpc   ="per capita inv: inv/pop",
> > >>>>>>                        linvpc  ="log(invpc)",
> > >>>>>>                        lprice_1="lprice[_n-1]",
> > >>>>>>                        linvpc_1="linvpc[_n-1]",
> > >>>>>>                        gprice  ="lprice - lprice_1",
> > >>>>>>                        ginvpc  ="linvpc - linvpc_1")
> > >>>>>>
> > >>>>>> ______________________________________________
> > >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>>>>>
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!U8ymUDChjP_1oBH6pjmrcYLLTL_FL6xmEsTlSAvVuix4Lw4fBPE7gW7LqEyShTQ$
> > >>>>>> PLEASE do read the posting guide
> > >>>>>>
> https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!U8ymUDChjP_1oBH6pjmrcYLLTL_FL6xmEsTlSAvVuix4Lw4fBPE7gW7LJcwnVeY$
> > >>>>>> and provide commented, minimal, self-contained, reproducible
> > code.
> > >>>>> --
> > >>>>> "Life is like a trumpet - if you don't put anything into it, you
> > >>>>> don't get
> > >>>> anything out of it."
> > >>>>
> > >>>>  [[alternative HTML version deleted]]
> > >>>>
> > >>>> ______________________________________________
> > >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>>>
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!U8ymUDChjP_1oBH6pjmrcYLLTL_FL6xmEsTlSAvVuix4Lw4fBPE7gW7LqEyShTQ$
> > >>>> PLEASE do read the posting guide
> https://urldefense.com/v3/__http://www.R-project.org/posting-__;!!KwNVnqRv!U8ymUDChjP_1oBH6pjmrcYLLTL_FL6xmEsTlSAvVuix4Lw4fBPE7gW7LkrYTQZQ$
> > >>>> guide.html and provide commented, minimal, self-contained,
> > >>>> reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!U8ymUDChjP_1oBH6pjmrcYLLTL_FL6xmEsTlSAvVuix4Lw4fBPE7gW7LqEyShTQ$
> PLEASE do read the posting guide
> https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!U8ymUDChjP_1oBH6pjmrcYLLTL_FL6xmEsTlSAvVuix4Lw4fBPE7gW7LJcwnVeY$
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From y@ngk@|9999 @end|ng |rom y@hoo@com  Fri May 14 19:42:12 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Fri, 14 May 2021 17:42:12 +0000 (UTC)
Subject: [R] Create a function problem
References: <1707044017.381120.1621014132648.ref@mail.yahoo.com>
Message-ID: <1707044017.381120.1621014132648@mail.yahoo.com>

Hello List,?I was trying to write a function.?But I got a error message. Can someone help me how to fix it?
Many thanks,Kai
> k_subset <- function(p, a, b, c){
+ ? p ?<- select(raw
+ ? ? ? ? ? ? ? ?,Pedigree.name
+ ? ? ? ? ? ? ? ?,UPN
+ ? ? ? ? ? ? ? ?,a
+ ? ? ? ? ? ? ? ?,b
+ ? ? ? ? ? ? ? ?,c
+ ? ) ?
+ }
> k_subset(p1, Test.Result.tr_Test.Result1, Result.tr_gene1, Test.Result.tr_Variant..nucleotide.1 )
?Error: object 'Test.Result.tr_Test.Result1' not found

	[[alternative HTML version deleted]]


From jwd @end|ng |rom @urewe@t@net  Sat May 15 00:31:06 2021
From: jwd @end|ng |rom @urewe@t@net (John Dougherty)
Date: Fri, 14 May 2021 15:31:06 -0700
Subject: [R] Variable labels
In-Reply-To: <93e8290e-89a2-4fca-27be-8c6b2b3166e1@ntu.edu.tw>
References: <CANO=ohJ9UMLqBNPequ-njsnn+3wYvOv=Q7h-qOPqf0cmWh8Tpw@mail.gmail.com>
 <6445C370-0081-4F80-9D9C-A0F1511BA397@ntu.edu.tw>
 <88a95efb70564eec83ce0a479dd9f0d1@SRVEXCHCM1302.precheza.cz>
 <3e134457-7d43-e934-32f1-26d54489d832@ntu.edu.tw>
 <7c9393a8fbcb434985fe9c3d31e67ae3@SRVEXCHCM1302.precheza.cz>
 <859b4136-bbba-a4c1-7920-9e31fa1335de@ntu.edu.tw>
 <9083181e865e4549994706f6a799d67d@SRVEXCHCM1302.precheza.cz>
 <CA+8X3fUb8OoFR8BJ4ez_uGbNheJ=Wi8dwMTXu+hCG2Bn9BKDUA@mail.gmail.com>
 <93e8290e-89a2-4fca-27be-8c6b2b3166e1@ntu.edu.tw>
Message-ID: <20210514153106.0877e282.jwd@surewest.net>

On Fri, 14 May 2021 17:20:20 +0800
Steven Yen <styen at ntu.edu.tw> wrote:

> Thanks to all, for bearing with me.
> 
> Now I realize expss may not be what I need. I have now written a 
> self-runnable, replicable set of codes (listed below). Perhaps that 
> gives an idea of what I need. Question is, whethet this is the right
> way to do this (to have a clickable object to learn about variable 
> definitions) or whether there are better ways. Thanks!
> 
> Steven
> 
From your example, after loading "try1.RData" you see a
"definitions" entry in the Environment pane.  Clicking on the name
"definitions" as opposed to the icon to expand the entry opens the
"definitions" data frame in its own tab in a pane on the upper left
where files such as scripts are displayed.  Clicking that tab opens the
list of "definitions" which is a list of three entries, where the
variable ids from the "mydata" file are row names.  

That will be the case in any session accessed using RStudio and opening
your saved .RData file.

If you are concerned about non-RStudio users being able to access that
data.frame in the Windows version R, if they load the .RData file that
will load the "definitions" data frame, which can be listed simply
typing "definitions" at the command prompt.

There is no "right way" do this.  Your approach works, though it will
get awkward if the data frame contains very many definitions.  If you
look at SPSS (or PSPP) for instance the Data Name and Label are both
elements of the definition of the variable, and the Label element of
the SPSS variable definition is essentially what your example seems to
use as a definition.  Otherwise you seem to be treading around the edges
of metadata which is also a set of data definitions.

R is more flexible about these things, which makes it somewhat more of
a chore at times.  


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat May 15 02:38:13 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 15 May 2021 12:38:13 +1200
Subject: [R] Create a function problem
In-Reply-To: <1707044017.381120.1621014132648@mail.yahoo.com>
References: <1707044017.381120.1621014132648.ref@mail.yahoo.com>
 <1707044017.381120.1621014132648@mail.yahoo.com>
Message-ID: <20210515123813.15cf2360@rolf-Latitude-E7470>


On Fri, 14 May 2021 17:42:12 +0000 (UTC)
Kai Yang via R-help <r-help at r-project.org> wrote:

> Hello List,?I was trying to write a function.?But I got a error
> message. Can someone help me how to fix it? Many thanks,Kai
> > k_subset <- function(p, a, b, c){
> + ? p ?<- select(raw
> + ? ? ? ? ? ? ? ?,Pedigree.name
> + ? ? ? ? ? ? ? ?,UPN
> + ? ? ? ? ? ? ? ?,a
> + ? ? ? ? ? ? ? ?,b
> + ? ? ? ? ? ? ? ?,c
> + ? ) ?
> + }
> > k_subset(p1, Test.Result.tr_Test.Result1, Result.tr_gene1,
> > Test.Result.tr_Variant..nucleotide.1 )
> ?Error: object 'Test.Result.tr_Test.Result1' not found

I would have thought the error message to be completely
self-explanatory.  The object in question cannot be found.  I.e. it
does not exist, in your workspace or in any of the data bases on your
search path.

It would appear that you have not created "Test.Result.tr_Test.Result1".
Why did you expect it to be present?

Moreover, the code of your function makes no sense at all, at least not
to *my* feeble brain.  The quantities "raw", "Pedigree.name" and "UPN"
are not arguments of your function.  How do you expect k_subset() to
know what they are?

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From y@ngk@|9999 @end|ng |rom y@hoo@com  Sat May 15 02:55:08 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Sat, 15 May 2021 00:55:08 +0000 (UTC)
Subject: [R] Create a function problem
In-Reply-To: <20210515123813.15cf2360@rolf-Latitude-E7470>
References: <1707044017.381120.1621014132648.ref@mail.yahoo.com>
 <1707044017.381120.1621014132648@mail.yahoo.com>
 <20210515123813.15cf2360@rolf-Latitude-E7470>
Message-ID: <1816218276.449052.1621040108551@mail.yahoo.com>

 Hi Rolf,
I am a beginner for R.?
I have a date frame raw. it contents the fields of?pedigree.name, UPN, Test.Result.tr_Test.Result1, Result.tr_gene1, Test.Result.tr_Variant..nucleotide.1 ......?Test.Result.tr_Test.Result20, Result.tr_gene20, Test.Result.tr_Variant..nucleotide.20
Basically, I want transpose the data frame from wide format into long format.?So, I hope the function can generate subset the those fields for 20 times, rename them and then stack them into one long format data frame.?After that, I hope I can use "for" loop to do this.
And now, I don't know how to fix the error
Thank you,Kai




    On Friday, May 14, 2021, 05:38:18 PM PDT, Rolf Turner <r.turner at auckland.ac.nz> wrote:  
 
 
On Fri, 14 May 2021 17:42:12 +0000 (UTC)
Kai Yang via R-help <r-help at r-project.org> wrote:

> Hello List,?I was trying to write a function.?But I got a error
> message. Can someone help me how to fix it? Many thanks,Kai
> > k_subset <- function(p, a, b, c){
> + ? p ?<- select(raw
> + ? ? ? ? ? ? ? ?,Pedigree.name
> + ? ? ? ? ? ? ? ?,UPN
> + ? ? ? ? ? ? ? ?,a
> + ? ? ? ? ? ? ? ?,b
> + ? ? ? ? ? ? ? ?,c
> + ? ) ?
> + }
> > k_subset(p1, Test.Result.tr_Test.Result1, Result.tr_gene1,
> > Test.Result.tr_Variant..nucleotide.1 )
> ?Error: object 'Test.Result.tr_Test.Result1' not found

I would have thought the error message to be completely
self-explanatory.? The object in question cannot be found.? I.e. it
does not exist, in your workspace or in any of the data bases on your
search path.

It would appear that you have not created "Test.Result.tr_Test.Result1".
Why did you expect it to be present?

Moreover, the code of your function makes no sense at all, at least not
to *my* feeble brain.? The quantities "raw", "Pedigree.name" and "UPN"
are not arguments of your function.? How do you expect k_subset() to
know what they are?

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

  
	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat May 15 03:47:48 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 15 May 2021 13:47:48 +1200
Subject: [R] Create a function problem
In-Reply-To: <1816218276.449052.1621040108551@mail.yahoo.com>
References: <1707044017.381120.1621014132648.ref@mail.yahoo.com>
 <1707044017.381120.1621014132648@mail.yahoo.com>
 <20210515123813.15cf2360@rolf-Latitude-E7470>
 <1816218276.449052.1621040108551@mail.yahoo.com>
Message-ID: <20210515134748.5bf818be@rolf-Latitude-E7470>

On Sat, 15 May 2021 00:55:08 +0000 (UTC)
Kai Yang <yangkai9999 at yahoo.com> wrote:

> Hi Rolf,
> I am a beginner for R.

Then I suggest that you spend some time learning basic R syntax, with
the help of some of the excellent online tutorials.  "An Introduction
to R" from https://cran.r-project.org/manuals.html would be a good
place to start.

> I have a date frame raw. it contents the fields of?pedigree.name,
> UPN, Test.Result.tr_Test.Result1, Result.tr_gene1,
> Test.Result.tr_Variant..nucleotide.1 ......
> Test.Result.tr_Test.Result20, Result.tr_gene20,
> Test.Result.tr_Variant..nucleotide.20

In this case something along the lines of the following *might*
work:

xxx <- with(raw,k_subset(<some arguments>))

but you would have to rewrite the function k_subset() so that its
argument list actually makes sense.

> Basically, I want transpose the
> data frame from wide format into long format.

I'm not actually very good at this sort of thing, but a quick web
search tells me that there are existing ways to do this, using tools
from the tidyr package.  Apparently there are also tools for this sort
of thing in the dplyr package.  Since the function select() that you
invoke is from the dplyr package (and you really should have mentioned
this rather than expecting your readers to be psychic) using dplyr tools
might be the best way for you to go.

> So, I hope the function
> can generate subset the those fields for 20 times, rename them and
> then stack them into one long format data frame.?After that, I hope I
> can use "for" loop to do this. And now, I don't know how to fix the
> error Thank you,Kai

As I said, this sort of thing is not my fort?, so I cannot help you
further.  If you want others on the list to help you then you should
provide an example data set ("raw" or some version thereof).  Use
dput() to provide the data in your posting.

*DO NOT* post in html!!!

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From mrgu|||oy|e @end|ng |rom gm@||@com  Sat May 15 08:26:58 2021
From: mrgu|||oy|e @end|ng |rom gm@||@com (Mathew Guilfoyle)
Date: Sat, 15 May 2021 07:26:58 +0100
Subject: [R] Create a function problem
Message-ID: <2239314D-FB91-4B29-BC85-B7DF311A51A3@gmail.com>

Have you tried putting the a,b, and c column names you are passing in quotes i.e. as strings? Currently your function is expecting separate objects with those names.

The select function itself can accept unquoted column names, as can others in R, because specific processing they do in the background.  Your wrapper function doesn?t have that facility.  I have a very limited understanding of the details to explain this but it is one of the ?gotchas? when starting.

No doubt others will point out that the approach you are using is probably not the best (lacks flexibility; some column names are hard coded etc), but if it gets the job done, to some extent that?s all that matters.

> On 14 May 2021, at 23:06, Kai Yang via R-help <r-help at r-project.org> wrote:
> 


From @b@bub|o @end|ng |rom gm@||@com  Sat May 15 03:59:35 2021
From: @b@bub|o @end|ng |rom gm@||@com (Padmanabhan Anbazhagan)
Date: Sat, 15 May 2021 09:59:35 +0800
Subject: [R] Reg:K-Means cluster/Matrix Analysis
Message-ID: <CAJQ-BR1ugn3Oz0TgPT3KGmh4DGyS+tcfYvUo+nzdfEkEQ9zmpQ@mail.gmail.com>

Dear All,
I have a cluster (.csv) file and need to extract the values of col1 based
on Col2 and store it. For instance, if Col2 = 1 it should store the values
Bat, Hat and Mat.  Then, the stored values have to be searched in a
similarity matrix file to get the scores and average. For example in
cluster 1, I need to get the scores between Bat-Hat, Bat-Mat, Hat-Bat,
Hat-Mat, Mat-Bat, Mat-Hat. Lastly, need to print the average score of
(Bat-Hat, Bat-Mat), (Hat-Bat, Hat-Mat), and (Mat-Bat, Mat-Hat). To do so,
any help with R script would be greatly appreciated. Many thanks in advance.

Col1Col2
Bat 1
Hat 1
Mat  1
Dog 2
Cow 2
Ant 2
Man 3
Bun 3
Pen 3

   Bat

  Hat

  Mat

   Dog

   Cow

   Ant

   Man

   Bun

   Pen

Bat

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

Hat

0.9

0

1.1

1.2

1.3

1.4

1.5

1.6

1.7

Mat

1.8

1.9

0

2.1

2.2

2.3

2.4

2.5

2.6

Dog

2.7

2.8

2.9

0

3.1

3.2

3.3

3.4

3.5

Cow

3.6

3.7

3.8

3.9

0

4.1

4.2

4.3

4.4

Ant

4.5

4.6

4.7

4.8

4.9

0

5.1

5.2

5.3

Man

5.4

5.5

5.6

5.7

5.8

5.9

0

6.1

6.2

Bun

6.3

6.4

6.5

6.6

6.7

6.8

6.9

0

7.1

Pen

7.2

7.3

7.4

7.5

7.6

7.7

7.8

7.9

0

Best regards
Padhu

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat May 15 16:49:28 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 15 May 2021 07:49:28 -0700
Subject: [R] Reg:K-Means cluster/Matrix Analysis
In-Reply-To: <CAJQ-BR1ugn3Oz0TgPT3KGmh4DGyS+tcfYvUo+nzdfEkEQ9zmpQ@mail.gmail.com>
References: <CAJQ-BR1ugn3Oz0TgPT3KGmh4DGyS+tcfYvUo+nzdfEkEQ9zmpQ@mail.gmail.com>
Message-ID: <CAGxFJbQ-cQK8kyPJ3e6phh5rma1S=rWaiODMeGW9CXxW3RLyww@mail.gmail.com>

Sounds like homework. This list has a no homework policy. See the posting
guide linked below, which says:

"*Basic statistics and classroom homework:* R-help is not intended for
these."

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, May 15, 2021 at 7:35 AM Padmanabhan Anbazhagan <ababubio at gmail.com>
wrote:

> Dear All,
> I have a cluster (.csv) file and need to extract the values of col1 based
> on Col2 and store it. For instance, if Col2 = 1 it should store the values
> Bat, Hat and Mat.  Then, the stored values have to be searched in a
> similarity matrix file to get the scores and average. For example in
> cluster 1, I need to get the scores between Bat-Hat, Bat-Mat, Hat-Bat,
> Hat-Mat, Mat-Bat, Mat-Hat. Lastly, need to print the average score of
> (Bat-Hat, Bat-Mat), (Hat-Bat, Hat-Mat), and (Mat-Bat, Mat-Hat). To do so,
> any help with R script would be greatly appreciated. Many thanks in
> advance.
>
> Col1Col2
> Bat 1
> Hat 1
> Mat  1
> Dog 2
> Cow 2
> Ant 2
> Man 3
> Bun 3
> Pen 3
>
>    Bat
>
>   Hat
>
>   Mat
>
>    Dog
>
>    Cow
>
>    Ant
>
>    Man
>
>    Bun
>
>    Pen
>
> Bat
>
> 0
>
> 0.1
>
> 0.2
>
> 0.3
>
> 0.4
>
> 0.5
>
> 0.6
>
> 0.7
>
> 0.8
>
> Hat
>
> 0.9
>
> 0
>
> 1.1
>
> 1.2
>
> 1.3
>
> 1.4
>
> 1.5
>
> 1.6
>
> 1.7
>
> Mat
>
> 1.8
>
> 1.9
>
> 0
>
> 2.1
>
> 2.2
>
> 2.3
>
> 2.4
>
> 2.5
>
> 2.6
>
> Dog
>
> 2.7
>
> 2.8
>
> 2.9
>
> 0
>
> 3.1
>
> 3.2
>
> 3.3
>
> 3.4
>
> 3.5
>
> Cow
>
> 3.6
>
> 3.7
>
> 3.8
>
> 3.9
>
> 0
>
> 4.1
>
> 4.2
>
> 4.3
>
> 4.4
>
> Ant
>
> 4.5
>
> 4.6
>
> 4.7
>
> 4.8
>
> 4.9
>
> 0
>
> 5.1
>
> 5.2
>
> 5.3
>
> Man
>
> 5.4
>
> 5.5
>
> 5.6
>
> 5.7
>
> 5.8
>
> 5.9
>
> 0
>
> 6.1
>
> 6.2
>
> Bun
>
> 6.3
>
> 6.4
>
> 6.5
>
> 6.6
>
> 6.7
>
> 6.8
>
> 6.9
>
> 0
>
> 7.1
>
> Pen
>
> 7.2
>
> 7.3
>
> 7.4
>
> 7.5
>
> 7.6
>
> 7.7
>
> 7.8
>
> 7.9
>
> 0
>
> Best regards
> Padhu
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tuh|nch@kr@borty50 @end|ng |rom gm@||@com  Sat May 15 19:07:57 2021
From: tuh|nch@kr@borty50 @end|ng |rom gm@||@com (Tuhin Chakraborty)
Date: Sat, 15 May 2021 22:37:57 +0530
Subject: [R] Finding strings in a dataset
Message-ID: <CAM-s6UA29GrO_MdXQCm4z1KpOBU2OHrdVgb1YDWwk4nBazYp+g@mail.gmail.com>

Hi,
How can I find the location of string data in my 2D dataset? spec(Dataset)
will reveal the columns that contain the strings. But can I know where
exactly the string values are in the column?

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat May 15 23:30:26 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 15 May 2021 22:30:26 +0100
Subject: [R] Finding strings in a dataset
In-Reply-To: <CAM-s6UA29GrO_MdXQCm4z1KpOBU2OHrdVgb1YDWwk4nBazYp+g@mail.gmail.com>
References: <CAM-s6UA29GrO_MdXQCm4z1KpOBU2OHrdVgb1YDWwk4nBazYp+g@mail.gmail.com>
Message-ID: <3a755fb1-fcf4-6e6a-f6e8-11e32a9475aa@sapo.pt>

Hello,

You should post a working example, we have no idea what your 2d data set 
is. A matrix? A data.frame? Something else?

And the string you are looking for? Are you thinking of regular 
expressions (grep) or is it a simple equality '=='?

Here is a reproducible example of the use of ?which() with argument 
arr.ind set to TRUE.

# create a data set
set.seed(2021)
A <- matrix(sample(letters, 24, TRUE), ncol = 4)

# Test for equality, this returns
# a logical matrix and which() can
# be applied to it
found <- A == "g"
which(found, arr.ind = TRUE)
#     row col
#[1,]   1   1
#[2,]   5   1
#[3,]   2   3


# The same code can be use if the data is
# a data.frame
df1 <- as.data.frame(A)
df1 == "g"


But if you want to look for a regex, try sapply. In this example the 
pattern is a simple one, and I use grepl.


pattern <- "g"
found2 <- sapply(df1, function(x) grepl(pattern, x))
which(found2, arr.ind = TRUE)


Hope this helps,

Rui Barradas



?s 18:07 de 15/05/21, Tuhin Chakraborty escreveu:
> Hi,
> How can I find the location of string data in my 2D dataset? spec(Dataset)
> will reveal the columns that contain the strings. But can I know where
> exactly the string values are in the column?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @v|gro@@ @end|ng |rom ver|zon@net  Sun May 16 00:54:40 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Sat, 15 May 2021 18:54:40 -0400
Subject: [R] Finding strings in a dataset
In-Reply-To: <CAM-s6UA29GrO_MdXQCm4z1KpOBU2OHrdVgb1YDWwk4nBazYp+g@mail.gmail.com>
References: <CAM-s6UA29GrO_MdXQCm4z1KpOBU2OHrdVgb1YDWwk4nBazYp+g@mail.gmail.com>
Message-ID: <01a301d749dd$4a3c8800$deb59800$@verizon.net>

Tuhin,

What do you mean by a 2-D dataset? You say some columns contain strings so
it does not sound like you are using a matrix as then  ALL columns would be
of the same type.

So are you using a data.frame or tibble or something you made on your own?

Can you address one column at a time and would that be of type vector? Some
methods work fairly easily on those and some also on lists.

Once you have that vector, there are quite a few ways to find what you want.
Is it fixed text like looking for an exact full match so it would be
something like "theta" to be matched in full, or would you want to match
"the" and both "theta" and "lathe" would match? Or are you matching a
pattern that is more complex like looking for all text that has two vowels
in a row in it?

Once you figure out what you have and what you want, how do you want to
identify what you are looking for? Will there be one match or possibly many
or even all? Many methods will return a TRUE/FALSE vector of the same length
or the integer offset of a match such as telling you it is the fifth item.

R has collections of string functions including in packages like
stringr/stringi that deal well with many things you might need. For matching
patterns, there is a family of functions using "grep" and so on.

Good luck.

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Tuhin Chakraborty
Sent: Saturday, May 15, 2021 1:08 PM
To: r-help at r-project.org
Subject: [R] Finding strings in a dataset

Hi,
How can I find the location of string data in my 2D dataset? spec(Dataset)
will reveal the columns that contain the strings. But can I know where
exactly the string values are in the column?

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bobby@kn|ght @end|ng |rom gm@||@com  Sun May 16 05:52:01 2021
From: bobby@kn|ght @end|ng |rom gm@||@com (Robert Knight)
Date: Sat, 15 May 2021 22:52:01 -0500
Subject: [R] Variable labels
In-Reply-To: <2acfbbbc-cf71-90a7-079f-874d63470d25@ntu.edu.tw>
References: <2acfbbbc-cf71-90a7-079f-874d63470d25@ntu.edu.tw>
Message-ID: <CAKBFG3bvnLkrMs4OGNSnWN3UhCQ6H6HPqBao7HfU3k=KimPTYA@mail.gmail.com>

Hi Steven,

You make great sense wanting to have labels for your variables.   When in
RStudio, the little arrow beside "mydata" in the Environment tab can be
clicked and you see all the variables there.  And so you would like to see
a description under the variable names.   Here is one way to accomplish
that. The following is not pseudocode, it's the actual code you should use.

Step 1, create a function that applies an attribute called "description" to
a variable.

desc <- function(obj) attr(obj, "description")

Step 2,  use attribute to apply the description

attr(mydata$invpc, "description") <- "Per capita inventory"



Step 3, Now you can either click the arrow beside "mydata" on the
environment tab and see that written description with the word
"description" in quotes.  You can also type

desc(mydata$invpc)

And that will provide you the associated description in text form.


Robert D. Knight, MBA

Developer of Meal Plan and Grocery List maker for Android and iOS.
https://play.google.com/store/apps/details?id=io.robertknight.MPGL






On Wed, May 12, 2021 at 9:49 PM Steven Yen <styen at ntu.edu.tw> wrote:

> I insert variable with the expss function as shown below. No error
> message. My question is, how to save the variable labels in the data
> frame so that I can click to read the labels. Thank you.
>
> mydata<-read_excel("data/Excel/hseinv.xlsx",na=".")
> library(expss)
> mydata=apply_labels(mydata,
>                      year   ="1947-1988",
>                      inv    ="real housing inv, millions $",
>                      pop    ="population, 1000s",
>                      price  ="housing price index; 1982 = 1",
>                      linv   ="log(inv)",
>                      lpop   ="log(pop)",
>                      lprice  ="log(price)",
>                      t       ="time trend: t=1,...,42",
>                      invpc   ="per capita inv: inv/pop",
>                      linvpc  ="log(invpc)",
>                      lprice_1="lprice[_n-1]",
>                      linvpc_1="linvpc[_n-1]",
>                      gprice  ="lprice - lprice_1",
>                      ginvpc  ="linvpc - linvpc_1")
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bobby@kn|ght @end|ng |rom gm@||@com  Sun May 16 06:20:58 2021
From: bobby@kn|ght @end|ng |rom gm@||@com (Robert Knight)
Date: Sat, 15 May 2021 23:20:58 -0500
Subject: [R] Variable labels
In-Reply-To: <2acfbbbc-cf71-90a7-079f-874d63470d25@ntu.edu.tw>
References: <2acfbbbc-cf71-90a7-079f-874d63470d25@ntu.edu.tw>
Message-ID: <CAKBFG3Y2NmNxaVhsBty=kFPZeFpiKAvOiVw9H8sOzS=WtbOXMA@mail.gmail.com>

Actually, I just found exactly what you want.  Before that though, I am
having a hard time finding any such cool job despite having even had
classes with some great professors in economics at UND, and so I work in a
completely non data related thing.

Here is exactly what you want, code included.  Then on the right side of
Rstudio you can click the word "desc" and get a table of the variable name
and it's description.

variable <- c("year", "inv", "pop", "price", "linv", "lpop", "lprice", "t",
       "invpc", "linvpc", "lprice_1", "linvpc_1", "gprice", "ginvpc")
description <- c("1947-1988","real housing inv, millions $","population,
1000s","housing price index; 1982 = 1",
       "log(inv)","log(pop)","log(price)","time trend: t=1,...,42","per
capita inv: inv/pop",
       "log(invpc)","lprice[_n-1]","linvpc[_n-1]","lprice -
lprice_1","linvpc - linvpc_1")
desc <- cbind(variable, description)

Robert D. Knight, MBA

Developer of Meal Plan and Grocery List maker for Android and iOS.
https://play.google.com/store/apps/details?id=io.robertknight.MPGL






On Wed, May 12, 2021 at 9:49 PM Steven Yen <styen at ntu.edu.tw> wrote:

> I insert variable with the expss function as shown below. No error
> message. My question is, how to save the variable labels in the data
> frame so that I can click to read the labels. Thank you.
>
> mydata<-read_excel("data/Excel/hseinv.xlsx",na=".")
> library(expss)
> mydata=apply_labels(mydata,
>                      year   ="1947-1988",
>                      inv    ="real housing inv, millions $",
>                      pop    ="population, 1000s",
>                      price  ="housing price index; 1982 = 1",
>                      linv   ="log(inv)",
>                      lpop   ="log(pop)",
>                      lprice  ="log(price)",
>                      t       ="time trend: t=1,...,42",
>                      invpc   ="per capita inv: inv/pop",
>                      linvpc  ="log(invpc)",
>                      lprice_1="lprice[_n-1]",
>                      linvpc_1="linvpc[_n-1]",
>                      gprice  ="lprice - lprice_1",
>                      ginvpc  ="linvpc - linvpc_1")
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @tyen @end|ng |rom ntu@edu@tw  Sun May 16 06:55:49 2021
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Sun, 16 May 2021 12:55:49 +0800
Subject: [R] Variable labels
In-Reply-To: <CAKBFG3bvnLkrMs4OGNSnWN3UhCQ6H6HPqBao7HfU3k=KimPTYA@mail.gmail.com>
References: <2acfbbbc-cf71-90a7-079f-874d63470d25@ntu.edu.tw>
 <CAKBFG3bvnLkrMs4OGNSnWN3UhCQ6H6HPqBao7HfU3k=KimPTYA@mail.gmail.com>
Message-ID: <9b86abf8-bbd8-38b0-6e1f-28e8bd077cf0@ntu.edu.tw>

Thanks.

On 2021/5/16 ?? 11:52, Robert Knight wrote:
> Hi Steven,
>
> You make great sense wanting to have labels for your variables.? ?When 
> in RStudio, the little arrow beside "mydata" in the Environment tab 
> can be clicked and you see all the variables there.? And so you would 
> like to see a description under the variable names.? ?Here is one way 
> to accomplish that. The following is not pseudocode, it's the actual 
> code you should use.
>
> Step 1, create a function that applies an attribute called 
> "description" to a variable.
> desc <- function(obj) attr(obj, "description")
> Step 2, use attribute to apply the description
> attr(mydata$invpc, "description") <- "Per capita inventory"
> Step 3, Now you can either click the arrow beside "mydata" on the 
> environment tab and see that written description with the word 
> "description" in quotes.? You can also type
> desc(mydata$invpc)
> And that will provide you the associated description in text form.
>
>
> Robert D. Knight, MBA
>
> Developer of Meal Plan and Grocery List maker for Android and iOS.
> https://play.google.com/store/apps/details?id=io.robertknight.MPGL 
> <https://play.google.com/store/apps/details?id=io.robertknight.MPGL>
>
>
>
>
>
>
> On Wed, May 12, 2021 at 9:49 PM Steven Yen <styen at ntu.edu.tw 
> <mailto:styen at ntu.edu.tw>> wrote:
>
>     I insert variable with the expss function as shown below. No error
>     message. My question is, how to save the variable labels in the data
>     frame so that I can click to read the labels. Thank you.
>
>     mydata<-read_excel("data/Excel/hseinv.xlsx",na=".")
>     library(expss)
>     mydata=apply_labels(mydata,
>     ???????????????????? year?? ="1947-1988",
>     ???????????????????? inv??? ="real housing inv, millions $",
>     ???????????????????? pop??? ="population, 1000s",
>     ???????????????????? price? ="housing price index; 1982 = 1",
>     ???????????????????? linv?? ="log(inv)",
>     ???????????????????? lpop?? ="log(pop)",
>     ???????????????????? lprice? ="log(price)",
>     ???????????????????? t?????? ="time trend: t=1,...,42",
>     ???????????????????? invpc?? ="per capita inv: inv/pop",
>     ???????????????????? linvpc? ="log(invpc)",
>     ???????????????????? lprice_1="lprice[_n-1]",
>     ???????????????????? linvpc_1="linvpc[_n-1]",
>     ???????????????????? gprice? ="lprice - lprice_1",
>     ???????????????????? ginvpc? ="linvpc - linvpc_1")
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tuh|nch@kr@borty50 @end|ng |rom gm@||@com  Sun May 16 07:31:22 2021
From: tuh|nch@kr@borty50 @end|ng |rom gm@||@com (Tuhin Chakraborty)
Date: Sun, 16 May 2021 11:01:22 +0530
Subject: [R] Finding strings in a dataset
In-Reply-To: <01a301d749dd$4a3c8800$deb59800$@verizon.net>
References: <CAM-s6UA29GrO_MdXQCm4z1KpOBU2OHrdVgb1YDWwk4nBazYp+g@mail.gmail.com>
 <01a301d749dd$4a3c8800$deb59800$@verizon.net>
Message-ID: <CAM-s6UDN-cMz7iN-31LcmmB6PwYXuELd5Apx+j+4MqwQGz=4_w@mail.gmail.com>

Thank you everyone, for the very helpful suggestions. I understand that my
question is not altogether clear. So let me share an example.
The below is a part of a dataset, there are around 40000 rows.
LI(PPM) SC(PPM) TI(PPM) V(PPM)
3.1/0.5 ? ? ?
? ? 0.2/0.3
?
? 2.8/0.75 ? >0.2
0.0389 108.6591 0.0214 85.18818
0.0688 146.1739 0.0117 108.0221
0.0265 121.3268 0.00749 85.34932
0.139901 125.3066 0.00984 97.23175

Now the 0.2/0.3, >0.2 these are treated as strings. When I am using the
spec(Dataset) function in R, it shows me which columns contain strings.
Like it will tell me that LI (PPM), SC(PPM) etc. contain strings. But, I
would like to know if there is someway where I can learn exactly where the
string values are, like for LI(PPM) in the top row. As this is a huge
dataset, it is difficult to go through all the rows manually.
Thank you again and in anticipation.
Tuhin



On Sun, May 16, 2021 at 4:25 AM Avi Gross via R-help <r-help at r-project.org>
wrote:

> Tuhin,
>
> What do you mean by a 2-D dataset? You say some columns contain strings so
> it does not sound like you are using a matrix as then  ALL columns would be
> of the same type.
>
> So are you using a data.frame or tibble or something you made on your own?
>
> Can you address one column at a time and would that be of type vector? Some
> methods work fairly easily on those and some also on lists.
>
> Once you have that vector, there are quite a few ways to find what you
> want.
> Is it fixed text like looking for an exact full match so it would be
> something like "theta" to be matched in full, or would you want to match
> "the" and both "theta" and "lathe" would match? Or are you matching a
> pattern that is more complex like looking for all text that has two vowels
> in a row in it?
>
> Once you figure out what you have and what you want, how do you want to
> identify what you are looking for? Will there be one match or possibly many
> or even all? Many methods will return a TRUE/FALSE vector of the same
> length
> or the integer offset of a match such as telling you it is the fifth item.
>
> R has collections of string functions including in packages like
> stringr/stringi that deal well with many things you might need. For
> matching
> patterns, there is a family of functions using "grep" and so on.
>
> Good luck.
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Tuhin Chakraborty
> Sent: Saturday, May 15, 2021 1:08 PM
> To: r-help at r-project.org
> Subject: [R] Finding strings in a dataset
>
> Hi,
> How can I find the location of string data in my 2D dataset? spec(Dataset)
> will reveal the columns that contain the strings. But can I know where
> exactly the string values are in the column?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun May 16 07:55:03 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 15 May 2021 22:55:03 -0700
Subject: [R] Finding strings in a dataset
In-Reply-To: <CAM-s6UDN-cMz7iN-31LcmmB6PwYXuELd5Apx+j+4MqwQGz=4_w@mail.gmail.com>
References: <CAM-s6UA29GrO_MdXQCm4z1KpOBU2OHrdVgb1YDWwk4nBazYp+g@mail.gmail.com>
 <01a301d749dd$4a3c8800$deb59800$@verizon.net>
 <CAM-s6UDN-cMz7iN-31LcmmB6PwYXuELd5Apx+j+4MqwQGz=4_w@mail.gmail.com>
Message-ID: <F61A0ACF-D9C8-4B53-B9F4-D9C5A6BA1F1C@dcn.davis.ca.us>

Do look at the mess below that we received, and make an effort not to send HTML email to this list. What you saw when you sent it is not what we see when it gets to us.

On May 15, 2021 10:31:22 PM PDT, Tuhin Chakraborty <tuhinchakraborty50 at gmail.com> wrote:
>Thank you everyone, for the very helpful suggestions. I understand that
>my
>question is not altogether clear. So let me share an example.
>The below is a part of a dataset, there are around 40000 rows.
>LI(PPM) SC(PPM) TI(PPM) V(PPM)
>3.1/0.5 ? ? ?
>? ? 0.2/0.3
>?
>? 2.8/0.75 ? >0.2
>0.0389 108.6591 0.0214 85.18818
>0.0688 146.1739 0.0117 108.0221
>0.0265 121.3268 0.00749 85.34932
>0.139901 125.3066 0.00984 97.23175
>
>Now the 0.2/0.3, >0.2 these are treated as strings. When I am using the
>spec(Dataset) function in R, it shows me which columns contain strings.
>Like it will tell me that LI (PPM), SC(PPM) etc. contain strings. But,
>I
>would like to know if there is someway where I can learn exactly where
>the
>string values are, like for LI(PPM) in the top row. As this is a huge
>dataset, it is difficult to go through all the rows manually.
>Thank you again and in anticipation.
>Tuhin
>
>
>
>On Sun, May 16, 2021 at 4:25 AM Avi Gross via R-help
><r-help at r-project.org>
>wrote:
>
>> Tuhin,
>>
>> What do you mean by a 2-D dataset? You say some columns contain
>strings so
>> it does not sound like you are using a matrix as then  ALL columns
>would be
>> of the same type.
>>
>> So are you using a data.frame or tibble or something you made on your
>own?
>>
>> Can you address one column at a time and would that be of type
>vector? Some
>> methods work fairly easily on those and some also on lists.
>>
>> Once you have that vector, there are quite a few ways to find what
>you
>> want.
>> Is it fixed text like looking for an exact full match so it would be
>> something like "theta" to be matched in full, or would you want to
>match
>> "the" and both "theta" and "lathe" would match? Or are you matching a
>> pattern that is more complex like looking for all text that has two
>vowels
>> in a row in it?
>>
>> Once you figure out what you have and what you want, how do you want
>to
>> identify what you are looking for? Will there be one match or
>possibly many
>> or even all? Many methods will return a TRUE/FALSE vector of the same
>> length
>> or the integer offset of a match such as telling you it is the fifth
>item.
>>
>> R has collections of string functions including in packages like
>> stringr/stringi that deal well with many things you might need. For
>> matching
>> patterns, there is a family of functions using "grep" and so on.
>>
>> Good luck.
>>
>> -----Original Message-----
>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Tuhin
>Chakraborty
>> Sent: Saturday, May 15, 2021 1:08 PM
>> To: r-help at r-project.org
>> Subject: [R] Finding strings in a dataset
>>
>> Hi,
>> How can I find the location of string data in my 2D dataset?
>spec(Dataset)
>> will reveal the columns that contain the strings. But can I know
>where
>> exactly the string values are in the column?
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun May 16 09:30:41 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 16 May 2021 08:30:41 +0100
Subject: [R] Finding strings in a dataset
In-Reply-To: <CAM-s6UDN-cMz7iN-31LcmmB6PwYXuELd5Apx+j+4MqwQGz=4_w@mail.gmail.com>
References: <CAM-s6UA29GrO_MdXQCm4z1KpOBU2OHrdVgb1YDWwk4nBazYp+g@mail.gmail.com>
 <01a301d749dd$4a3c8800$deb59800$@verizon.net>
 <CAM-s6UDN-cMz7iN-31LcmmB6PwYXuELd5Apx+j+4MqwQGz=4_w@mail.gmail.com>
Message-ID: <b7b588ce-cbfe-d129-fc42-cc3000174637@sapo.pt>

Hello,

The data makes clearer.
Do you want to know where are the values that cannot be coerced to numeric?
The auxiliary function f outputs a logical vector, sapply applies it 
column by column and which(., arr.ind) gives the TRUE values as (row, 
col) pairs.


txt <- "
LI(PPM) SC(PPM) TI(PPM) V(PPM)
3.1/0.5 ? ? ?
? ? 0.2/0.3 ?
? 2.8/0.75 ? >0.2
0.0389 108.6591 0.0214 85.18818
0.0688 146.1739 0.0117 108.0221
0.0265 121.3268 0.00749 85.34932
0.139901 125.3066 0.00984 97.23175
"
df1 <- read.table(text = txt, header = TRUE)
df1

f <- function(x){
   suppressWarnings(is.na(as.numeric(x)))
}
found <- sapply(df1, f)
which(found, arr.ind = TRUE)



Hope this helps,

Rui Barradas


?s 06:31 de 16/05/21, Tuhin Chakraborty escreveu:
> Thank you everyone, for the very helpful suggestions. I understand that my
> question is not altogether clear. So let me share an example.
> The below is a part of a dataset, there are around 40000 rows.
> LI(PPM) SC(PPM) TI(PPM) V(PPM)
> 3.1/0.5 ? ? ?
> ? ? 0.2/0.3
> ?
> ? 2.8/0.75 ? >0.2
> 0.0389 108.6591 0.0214 85.18818
> 0.0688 146.1739 0.0117 108.0221
> 0.0265 121.3268 0.00749 85.34932
> 0.139901 125.3066 0.00984 97.23175
> 
> Now the 0.2/0.3, >0.2 these are treated as strings. When I am using the
> spec(Dataset) function in R, it shows me which columns contain strings.
> Like it will tell me that LI (PPM), SC(PPM) etc. contain strings. But, I
> would like to know if there is someway where I can learn exactly where the
> string values are, like for LI(PPM) in the top row. As this is a huge
> dataset, it is difficult to go through all the rows manually.
> Thank you again and in anticipation.
> Tuhin
> 
> 
> 
> On Sun, May 16, 2021 at 4:25 AM Avi Gross via R-help <r-help at r-project.org>
> wrote:
> 
>> Tuhin,
>>
>> What do you mean by a 2-D dataset? You say some columns contain strings so
>> it does not sound like you are using a matrix as then  ALL columns would be
>> of the same type.
>>
>> So are you using a data.frame or tibble or something you made on your own?
>>
>> Can you address one column at a time and would that be of type vector? Some
>> methods work fairly easily on those and some also on lists.
>>
>> Once you have that vector, there are quite a few ways to find what you
>> want.
>> Is it fixed text like looking for an exact full match so it would be
>> something like "theta" to be matched in full, or would you want to match
>> "the" and both "theta" and "lathe" would match? Or are you matching a
>> pattern that is more complex like looking for all text that has two vowels
>> in a row in it?
>>
>> Once you figure out what you have and what you want, how do you want to
>> identify what you are looking for? Will there be one match or possibly many
>> or even all? Many methods will return a TRUE/FALSE vector of the same
>> length
>> or the integer offset of a match such as telling you it is the fifth item.
>>
>> R has collections of string functions including in packages like
>> stringr/stringi that deal well with many things you might need. For
>> matching
>> patterns, there is a family of functions using "grep" and so on.
>>
>> Good luck.
>>
>> -----Original Message-----
>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Tuhin Chakraborty
>> Sent: Saturday, May 15, 2021 1:08 PM
>> To: r-help at r-project.org
>> Subject: [R] Finding strings in a dataset
>>
>> Hi,
>> How can I find the location of string data in my 2D dataset? spec(Dataset)
>> will reveal the columns that contain the strings. But can I know where
>> exactly the string values are in the column?
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun May 16 10:28:30 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 16 May 2021 09:28:30 +0100
Subject: [R] Finding strings in a dataset
In-Reply-To: <b7b588ce-cbfe-d129-fc42-cc3000174637@sapo.pt>
References: <CAM-s6UA29GrO_MdXQCm4z1KpOBU2OHrdVgb1YDWwk4nBazYp+g@mail.gmail.com>
 <01a301d749dd$4a3c8800$deb59800$@verizon.net>
 <CAM-s6UDN-cMz7iN-31LcmmB6PwYXuELd5Apx+j+4MqwQGz=4_w@mail.gmail.com>
 <b7b588ce-cbfe-d129-fc42-cc3000174637@sapo.pt>
Message-ID: <ceefbfa2-1b5d-6b70-c341-54f696879cfd@sapo.pt>

Hello,

You can also create an extra column with the column names corresponding 
to the column col. I believe this extra column is not needed and with a 
big data set it's even a waste of time and memory space but the code 
below creates it.


res <- which(found, arr.ind = TRUE)
res <- as.data.frame(res)
res$col_name <- names(df1)[ res$col ]


With a big data set the first res is a numeric matrix and it's access 
and extraction is faster, matrix operations are generally faster than 
data.frame operations.

Hope this helps,

Rui Barradas

?s 08:30 de 16/05/21, Rui Barradas escreveu:
> Hello,
> 
> The data makes clearer.
> Do you want to know where are the values that cannot be coerced to numeric?
> The auxiliary function f outputs a logical vector, sapply applies it 
> column by column and which(., arr.ind) gives the TRUE values as (row, 
> col) pairs.
> 
> 
> txt <- "
> LI(PPM) SC(PPM) TI(PPM) V(PPM)
> 3.1/0.5 ? ? ?
> ? ? 0.2/0.3 ?
> ? 2.8/0.75 ? >0.2
> 0.0389 108.6591 0.0214 85.18818
> 0.0688 146.1739 0.0117 108.0221
> 0.0265 121.3268 0.00749 85.34932
> 0.139901 125.3066 0.00984 97.23175
> "
> df1 <- read.table(text = txt, header = TRUE)
> df1
> 
> f <- function(x){
>  ? suppressWarnings(is.na(as.numeric(x)))
> }
> found <- sapply(df1, f)
> which(found, arr.ind = TRUE)
> 
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
> ?s 06:31 de 16/05/21, Tuhin Chakraborty escreveu:
>> Thank you everyone, for the very helpful suggestions. I understand 
>> that my
>> question is not altogether clear. So let me share an example.
>> The below is a part of a dataset, there are around 40000 rows.
>> LI(PPM) SC(PPM) TI(PPM) V(PPM)
>> 3.1/0.5 ? ? ?
>> ? ? 0.2/0.3
>> ?
>> ? 2.8/0.75 ? >0.2
>> 0.0389 108.6591 0.0214 85.18818
>> 0.0688 146.1739 0.0117 108.0221
>> 0.0265 121.3268 0.00749 85.34932
>> 0.139901 125.3066 0.00984 97.23175
>>
>> Now the 0.2/0.3, >0.2 these are treated as strings. When I am using the
>> spec(Dataset) function in R, it shows me which columns contain strings.
>> Like it will tell me that LI (PPM), SC(PPM) etc. contain strings. But, I
>> would like to know if there is someway where I can learn exactly where 
>> the
>> string values are, like for LI(PPM) in the top row. As this is a huge
>> dataset, it is difficult to go through all the rows manually.
>> Thank you again and in anticipation.
>> Tuhin
>>
>>
>>
>> On Sun, May 16, 2021 at 4:25 AM Avi Gross via R-help 
>> <r-help at r-project.org>
>> wrote:
>>
>>> Tuhin,
>>>
>>> What do you mean by a 2-D dataset? You say some columns contain 
>>> strings so
>>> it does not sound like you are using a matrix as then? ALL columns 
>>> would be
>>> of the same type.
>>>
>>> So are you using a data.frame or tibble or something you made on your 
>>> own?
>>>
>>> Can you address one column at a time and would that be of type 
>>> vector? Some
>>> methods work fairly easily on those and some also on lists.
>>>
>>> Once you have that vector, there are quite a few ways to find what you
>>> want.
>>> Is it fixed text like looking for an exact full match so it would be
>>> something like "theta" to be matched in full, or would you want to match
>>> "the" and both "theta" and "lathe" would match? Or are you matching a
>>> pattern that is more complex like looking for all text that has two 
>>> vowels
>>> in a row in it?
>>>
>>> Once you figure out what you have and what you want, how do you want to
>>> identify what you are looking for? Will there be one match or 
>>> possibly many
>>> or even all? Many methods will return a TRUE/FALSE vector of the same
>>> length
>>> or the integer offset of a match such as telling you it is the fifth 
>>> item.
>>>
>>> R has collections of string functions including in packages like
>>> stringr/stringi that deal well with many things you might need. For
>>> matching
>>> patterns, there is a family of functions using "grep" and so on.
>>>
>>> Good luck.
>>>
>>> -----Original Message-----
>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Tuhin 
>>> Chakraborty
>>> Sent: Saturday, May 15, 2021 1:08 PM
>>> To: r-help at r-project.org
>>> Subject: [R] Finding strings in a dataset
>>>
>>> Hi,
>>> How can I find the location of string data in my 2D dataset? 
>>> spec(Dataset)
>>> will reveal the columns that contain the strings. But can I know where
>>> exactly the string values are in the column?
>>>
>>> ???????? [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ????[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From petr@p|k@| @end|ng |rom prechez@@cz  Mon May 17 08:42:31 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Mon, 17 May 2021 06:42:31 +0000
Subject: [R] Create a function problem
In-Reply-To: <1816218276.449052.1621040108551@mail.yahoo.com>
References: <1707044017.381120.1621014132648.ref@mail.yahoo.com>
 <1707044017.381120.1621014132648@mail.yahoo.com>
 <20210515123813.15cf2360@rolf-Latitude-E7470>
 <1816218276.449052.1621040108551@mail.yahoo.com>
Message-ID: <5353e6e539cc46f0ad2617ac31dd2b6d@SRVEXCHCM1302.precheza.cz>

Hi.

You also could try functions melt/cast from reshape2 package.

https://seananderson.ca/2013/10/19/reshape/

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Kai Yang via R-
> help
> Sent: Saturday, May 15, 2021 2:55 AM
> To: r-help at r-project.org; Rolf Turner <r.turner at auckland.ac.nz>
> Subject: Re: [R] Create a function problem
> 
>  Hi Rolf,
> I am a beginner for R.
> I have a date frame raw. it contents the fields of pedigree.name, UPN,
> Test.Result.tr_Test.Result1, Result.tr_gene1,
> Test.Result.tr_Variant..nucleotide.1 ...... Test.Result.tr_Test.Result20,
> Result.tr_gene20, Test.Result.tr_Variant..nucleotide.20
> Basically, I want transpose the data frame from wide format into long
> format. So, I hope the function can generate subset the those fields for 20
> times, rename them and then stack them into one long format data
> frame. After that, I hope I can use "for" loop to do this.
> And now, I don't know how to fix the error Thank you,Kai
> 
> 
> 
> 
>     On Friday, May 14, 2021, 05:38:18 PM PDT, Rolf Turner
> <r.turner at auckland.ac.nz> wrote:
> 
> 
> On Fri, 14 May 2021 17:42:12 +0000 (UTC)
> Kai Yang via R-help <r-help at r-project.org> wrote:
> 
> > Hello List, I was trying to write a function. But I got a error
> > message. Can someone help me how to fix it? Many thanks,Kai
> > > k_subset <- function(p, a, b, c){
> > +   p  <- select(raw
> > +                ,Pedigree.name
> > +                ,UPN
> > +                ,a
> > +                ,b
> > +                ,c
> > +   )
> > + }
> > > k_subset(p1, Test.Result.tr_Test.Result1, Result.tr_gene1,
> > > Test.Result.tr_Variant..nucleotide.1 )
> >  Error: object 'Test.Result.tr_Test.Result1' not found
> 
> I would have thought the error message to be completely
> self-explanatory.  The object in question cannot be found.  I.e. it
> does not exist, in your workspace or in any of the data bases on your
> search path.
> 
> It would appear that you have not created "Test.Result.tr_Test.Result1".
> Why did you expect it to be present?
> 
> Moreover, the code of your function makes no sense at all, at least not
> to *my* feeble brain.  The quantities "raw", "Pedigree.name" and "UPN"
> are not arguments of your function.  How do you expect k_subset() to
> know what they are?
> 
> cheers,
> 
> Rolf Turner
> 
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From tuh|nch@kr@borty50 @end|ng |rom gm@||@com  Mon May 17 08:44:47 2021
From: tuh|nch@kr@borty50 @end|ng |rom gm@||@com (Tuhin Chakraborty)
Date: Mon, 17 May 2021 12:14:47 +0530
Subject: [R] Finding strings in a dataset
In-Reply-To: <ceefbfa2-1b5d-6b70-c341-54f696879cfd@sapo.pt>
References: <CAM-s6UA29GrO_MdXQCm4z1KpOBU2OHrdVgb1YDWwk4nBazYp+g@mail.gmail.com>
 <01a301d749dd$4a3c8800$deb59800$@verizon.net>
 <CAM-s6UDN-cMz7iN-31LcmmB6PwYXuELd5Apx+j+4MqwQGz=4_w@mail.gmail.com>
 <b7b588ce-cbfe-d129-fc42-cc3000174637@sapo.pt>
 <ceefbfa2-1b5d-6b70-c341-54f696879cfd@sapo.pt>
Message-ID: <CAM-s6UDGyFYSuOyThQp5ZBYxUU=00c7ZrGdkmBFPpkmefg9N=g@mail.gmail.com>

Thank you. This possibly will work.
Tuhin Chakraborty
PhD
Geology & Geophysics
Indian Institute Of Technology, Kharagpur
Kharagpur-721302


On Sun, May 16, 2021 at 1:58 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> You can also create an extra column with the column names corresponding
> to the column col. I believe this extra column is not needed and with a
> big data set it's even a waste of time and memory space but the code
> below creates it.
>
>
> res <- which(found, arr.ind = TRUE)
> res <- as.data.frame(res)
> res$col_name <- names(df1)[ res$col ]
>
>
> With a big data set the first res is a numeric matrix and it's access
> and extraction is faster, matrix operations are generally faster than
> data.frame operations.
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 08:30 de 16/05/21, Rui Barradas escreveu:
> > Hello,
> >
> > The data makes clearer.
> > Do you want to know where are the values that cannot be coerced to
> numeric?
> > The auxiliary function f outputs a logical vector, sapply applies it
> > column by column and which(., arr.ind) gives the TRUE values as (row,
> > col) pairs.
> >
> >
> > txt <- "
> > LI(PPM) SC(PPM) TI(PPM) V(PPM)
> > 3.1/0.5 ? ? ?
> > ? ? 0.2/0.3 ?
> > ? 2.8/0.75 ? >0.2
> > 0.0389 108.6591 0.0214 85.18818
> > 0.0688 146.1739 0.0117 108.0221
> > 0.0265 121.3268 0.00749 85.34932
> > 0.139901 125.3066 0.00984 97.23175
> > "
> > df1 <- read.table(text = txt, header = TRUE)
> > df1
> >
> > f <- function(x){
> >    suppressWarnings(is.na(as.numeric(x)))
> > }
> > found <- sapply(df1, f)
> > which(found, arr.ind = TRUE)
> >
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> >
> > ?s 06:31 de 16/05/21, Tuhin Chakraborty escreveu:
> >> Thank you everyone, for the very helpful suggestions. I understand
> >> that my
> >> question is not altogether clear. So let me share an example.
> >> The below is a part of a dataset, there are around 40000 rows.
> >> LI(PPM) SC(PPM) TI(PPM) V(PPM)
> >> 3.1/0.5 ? ? ?
> >> ? ? 0.2/0.3
> >> ?
> >> ? 2.8/0.75 ? >0.2
> >> 0.0389 108.6591 0.0214 85.18818
> >> 0.0688 146.1739 0.0117 108.0221
> >> 0.0265 121.3268 0.00749 85.34932
> >> 0.139901 125.3066 0.00984 97.23175
> >>
> >> Now the 0.2/0.3, >0.2 these are treated as strings. When I am using the
> >> spec(Dataset) function in R, it shows me which columns contain strings.
> >> Like it will tell me that LI (PPM), SC(PPM) etc. contain strings. But, I
> >> would like to know if there is someway where I can learn exactly where
> >> the
> >> string values are, like for LI(PPM) in the top row. As this is a huge
> >> dataset, it is difficult to go through all the rows manually.
> >> Thank you again and in anticipation.
> >> Tuhin
> >>
> >>
> >>
> >> On Sun, May 16, 2021 at 4:25 AM Avi Gross via R-help
> >> <r-help at r-project.org>
> >> wrote:
> >>
> >>> Tuhin,
> >>>
> >>> What do you mean by a 2-D dataset? You say some columns contain
> >>> strings so
> >>> it does not sound like you are using a matrix as then  ALL columns
> >>> would be
> >>> of the same type.
> >>>
> >>> So are you using a data.frame or tibble or something you made on your
> >>> own?
> >>>
> >>> Can you address one column at a time and would that be of type
> >>> vector? Some
> >>> methods work fairly easily on those and some also on lists.
> >>>
> >>> Once you have that vector, there are quite a few ways to find what you
> >>> want.
> >>> Is it fixed text like looking for an exact full match so it would be
> >>> something like "theta" to be matched in full, or would you want to
> match
> >>> "the" and both "theta" and "lathe" would match? Or are you matching a
> >>> pattern that is more complex like looking for all text that has two
> >>> vowels
> >>> in a row in it?
> >>>
> >>> Once you figure out what you have and what you want, how do you want to
> >>> identify what you are looking for? Will there be one match or
> >>> possibly many
> >>> or even all? Many methods will return a TRUE/FALSE vector of the same
> >>> length
> >>> or the integer offset of a match such as telling you it is the fifth
> >>> item.
> >>>
> >>> R has collections of string functions including in packages like
> >>> stringr/stringi that deal well with many things you might need. For
> >>> matching
> >>> patterns, there is a family of functions using "grep" and so on.
> >>>
> >>> Good luck.
> >>>
> >>> -----Original Message-----
> >>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Tuhin
> >>> Chakraborty
> >>> Sent: Saturday, May 15, 2021 1:08 PM
> >>> To: r-help at r-project.org
> >>> Subject: [R] Finding strings in a dataset
> >>>
> >>> Hi,
> >>> How can I find the location of string data in my 2D dataset?
> >>> spec(Dataset)
> >>> will reveal the columns that contain the strings. But can I know where
> >>> exactly the string values are in the column?
> >>>
> >>>          [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>     [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
>

	[[alternative HTML version deleted]]


From @p|uque @end|ng |rom gm@||@com  Fri May 14 05:43:14 2021
From: @p|uque @end|ng |rom gm@||@com (Sebastian P. Luque)
Date: Thu, 13 May 2021 22:43:14 -0500
Subject: [R] [R-pkgs] diveMove 1.6.0 released
Message-ID: <878s4iq8tp.fsf@phoca.sebkatja.org>

Dear R community,

A new version of diveMove (1.6.0) is now on CRAN
(https://cran.r-project.org/package=diveMove).  diveMove offers tools
and utilities for performing essential tasks for the analysis of
time-depth recoder (TDR) data loggers.

The latest version completes the framework for modelling mixtures of
exponential distributions, a common approach for identifying transitions
between events such as dives occurring in bouts.  A new class is now
available to represent such data, with methods and functions available
for:

* Fitting models via non-linear least squares and maximum likelihood
  (recommended).
* Determining bout-ending criteria.
* Plotting predicted and observed data, including cumulative frequency
  distribution.
* Generating samples from mixtures of distributions.

The new class and associated methods make a number of functions in
previous versions obsolete.  Please see help(diveMove-defunct) and
help(diveMove-deprecated) for details.

https://github.com/spluque/diveMove

--
Sebastian P. Luque

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From r-p@ck@ge@ @end|ng |rom r-project@org  Mon May 17 14:47:02 2021
From: r-p@ck@ge@ @end|ng |rom r-project@org (Marc Schwartz via R-packages)
Date: Mon, 17 May 2021 08:47:02 -0400
Subject: [R] [R-pkgs] New CRAN Package: BI - Generate James (1996) and Bang
 (2004) Blinding Indexes
Message-ID: <1912de5a-0f18-9441-b630-253ea0eaa050@me.com>

Hi All,

Version 1.0.0 of the new BI package is now on CRAN.

The BI package will generate the James Blinding Index, as described in 
James et al (1996, https://pubmed.ncbi.nlm.nih.gov/8841652/) and the 
Bang Blinding Index, as described in Bang et al (2004, 
https://pubmed.ncbi.nlm.nih.gov/15020033/).

These are measures to assess whether or not satisfactory blinding has 
been maintained in a randomized, controlled, clinical trial. These can 
be generated for trial subjects, research coordinators and principal 
investigators, based upon standardized questionnaires that have been 
administered, to assess whether or not they can correctly guess to which 
treatment arm (e.g. placebo or treatment) subjects were assigned at 
randomization.


The package is available from:

   https://CRAN.R-project.org/package=BI

and is maintained on Github:

   https://github.com/marcschwartz/BI


Warm regards,

Marc Schwartz

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From r@md@@ @end|ng |rom ek@@gr@@com  Mon May 17 09:05:39 2021
From: r@md@@ @end|ng |rom ek@@gr@@com (Ramdas Menon)
Date: Mon, 17 May 2021 12:35:39 +0530
Subject: [R] R stalling frequently
Message-ID: <CANuvUTdF7av_bRwMJXSTFcXN6eOTgbyi-=bGTOpYvYB07DzEPw@mail.gmail.com>

I have a working knowledge of R, and have been teaching statistics courses
based on R for quite some time now.

I started with ver 4.0.2, and am now using Ver 4.0.5 which I downloaded a
week ago. The system works when I type Object <- read.csv(file.choose())
for a couple of times, and then just stalls.

I used the above function to read in a few csv files, and then R just
hanged. This has happened four times in the last 2 days.

Each time I need to abort R and restart it. Will any of you be able to help
me with this?

Best regards
*Ramdas Menon, +91-98404-58652*

*www.ekaagra.com <http://www.ekaagra.com>*

	[[alternative HTML version deleted]]


From @tch|rume @end|ng |rom gm@||@com  Mon May 17 09:44:01 2021
From: @tch|rume @end|ng |rom gm@||@com (Admire Tarisirayi Chirume)
Date: Mon, 17 May 2021 09:44:01 +0200
Subject: [R] Wide to long format in R
Message-ID: <CAFfFd+tO_7O89BHyXBy_jeS9vz=UVXxtcLHABKcWjaBKHoxRVQ@mail.gmail.com>

I need help on reshaping my data frame which is currently in wide format.

I ran the following codes to create panel ids based on the variable for
country names  "*Country"; *

*bop.df$id<-as.numeric(as.factor(bop.df$Country))*

then ran the code below to reshape from wide to long format;

*reshaped.bop <- pivot_longer(bop.df,3:17,names_to =  "year", values_to =
"value")*

by running the code:  *print( reshaped.bop), the following table in long
format came out;*


Country year bank_ratio Reserve_ratio broad_money id
Angola 2006 24 77 163 1
Angola 2007 25 59 188 1
Botswana 2008 38 64 317 1
Botswana 2009 34 65 361 1
Zimbabwe 2010 42 57 150 1
Zimbabwe 2006 49 86 288 2


This, however, is not what i wanted. kindly help with the code that formats
my table in the following way?

Country Variables id year value
Angola bank_ratio 1 2006 24
Angola bank_ratio 1 2007 25
Angola Reserve_ratio 1 2008 77
Angola Reserve_ratio 1 2009 59
Angola broad_money 1 2010 163
Angola broad_money 1 2006 188
Botswana bank_ratio 2 2006 38
Botswana bank_ratio 2 2007 34
Botswana Reserve_ratio 2 2008 64
Botswana Reserve_ratio 2 2009 65
Botswana broad_money 2 2010 317
Botswana broad_money 2 2006 361
Zimbabwe bank_ratio 3 2006 42
Zimbabwe bank_ratio 3 2007 49
Zimbabwe Reserve_ratio 3 2008 57
Zimbabwe Reserve_ratio 3 2009 86
Zimbabwe broad_money 3 2010 150
Zimbabwe broad_money 3 2006 288

Thank you

Alternative email: addtarris at icloud.com/TChirume at rbz.co.zw
Skype: admirechirume
Call: +263773369884
whatsapp: +818099861504

	[[alternative HTML version deleted]]


From @tch|rume @end|ng |rom gm@||@com  Mon May 17 09:48:58 2021
From: @tch|rume @end|ng |rom gm@||@com (Admire Tarisirayi Chirume)
Date: Mon, 17 May 2021 09:48:58 +0200
Subject: [R] Filtering a dataframe
Message-ID: <CAFfFd+uyFNkZuT5=Z9dmMGr7cG-uMNTx4fhBTENbDKR5fmfrww@mail.gmail.com>

Can someone help on how to filter my data frame below such that it retains
a country if a given id (last column) is satisfied eg filtering a data
frame that has countries with id 1 and 2 only

Country year bank_ratio Reserve_ratio broad_money id
Angola 2006 24 77 163 1
Angola 2007 25 59 188 1
Botswana 2008 38 64 317 2
Botswana 2009 34 65 361 2
Zimbabwe 2010 42 57 150 3
Zimbabwe 2006 49 86 288 3



Alternative email: addtarris at icloud.com/TChirume at rbz.co.zw
Skype: admirechirume
Call: +263773369884
whatsapp: +818099861504

	[[alternative HTML version deleted]]


From d@v|d@co@t@nt|n| @end|ng |rom mnhn@|r  Mon May 17 11:48:54 2021
From: d@v|d@co@t@nt|n| @end|ng |rom mnhn@|r (David Costantini)
Date: Mon, 17 May 2021 11:48:54 +0200 (CEST)
Subject: [R] phylogenetic correction and MCMC model
In-Reply-To: <2082987372.190752.1621242378297.JavaMail.zimbra@mnhn.fr>
References: <2082987372.190752.1621242378297.JavaMail.zimbra@mnhn.fr>
Message-ID: <218164214.238135.1621244934796.JavaMail.zimbra@mnhn.fr>

Dear All 
I am trying to apply a phylogenetic correction to an MCMC model, but I have problems in making the inverse matrix. I can visualise the treeplot very well, but when I use the script: 
inv.phylo<-inverseA(phylo_ultra,nodes="TIPS",scale=TRUE) 

R tells me that there is an error: 

Error in pedigree[, 2] : incorrect number of dimensions 
In addition: Warning message: 
In if (attr(pedigree, "class") == "phylo") { : 

Do you have any experience with this? I couldn't find a solution so far on your website 
Thanks in advance 
David 


	[[alternative HTML version deleted]]


From tr|ng @end|ng |rom gvdnet@dk  Mon May 17 16:44:01 2021
From: tr|ng @end|ng |rom gvdnet@dk (Troels Ring)
Date: Mon, 17 May 2021 16:44:01 +0200
Subject: [R] series of densities
Message-ID: <3dab5b13-445d-88eb-134b-7a69870ac236@gvdnet.dk>

Dear friends
I'm trying to plot in silico derived values of 3 types of 
buffer-capacities? over pH values and want densities of the three types 
together at each pH with the pH values on the abscissa.

I have generated some data

set.seed(2345)
pHs <- c(7.2,7.4,7.6)
pH <- rep(pHs,each=30)
BC <- rep(rep(c(20,10,10),each=10),3)+rnorm(90,0,5)
type <- rep(rep(c("TOT","NC","CA"),each=10),3)

ddd <- data.frame(pH,BC,type)

GG <- ggplot()
for (i in 1:3) {
 ? dd <- ddd[ddd$pH==pHs[i],]
 ? GG <- GG + geom_density(data=dd,aes(x=BC,fill=type),alpha=0.1)
}
GG

but here I only get all pH values? plotted together whereas I want 3 
series in the vertical direction at the three pH values.

I wonder how this could be done?

All best wishes

Troels Ring, MD
Aalborg, Denmark

PS: Windows 10,

R version 4.0.5 (2021-03-31


From bgunter@4567 @end|ng |rom gm@||@com  Mon May 17 16:46:15 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 17 May 2021 07:46:15 -0700
Subject: [R] Wide to long format in R
In-Reply-To: <CAFfFd+tO_7O89BHyXBy_jeS9vz=UVXxtcLHABKcWjaBKHoxRVQ@mail.gmail.com>
References: <CAFfFd+tO_7O89BHyXBy_jeS9vz=UVXxtcLHABKcWjaBKHoxRVQ@mail.gmail.com>
Message-ID: <CAGxFJbTmgsyjb+7Uy_fVvH4fNT7qnn+819PMnKHDiuHZjshR5w@mail.gmail.com>

I believe you'll need to show us exactly what bop.df looks like, e.g. via
head(bop.df) .

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, May 17, 2021 at 7:32 AM Admire Tarisirayi Chirume <
atchirume at gmail.com> wrote:

> I need help on reshaping my data frame which is currently in wide format.
>
> I ran the following codes to create panel ids based on the variable for
> country names  "*Country"; *
>
> *bop.df$id<-as.numeric(as.factor(bop.df$Country))*
>
> then ran the code below to reshape from wide to long format;
>
> *reshaped.bop <- pivot_longer(bop.df,3:17,names_to =  "year", values_to =
> "value")*
>
> by running the code:  *print( reshaped.bop), the following table in long
> format came out;*
>
>
> Country year bank_ratio Reserve_ratio broad_money id
> Angola 2006 24 77 163 1
> Angola 2007 25 59 188 1
> Botswana 2008 38 64 317 1
> Botswana 2009 34 65 361 1
> Zimbabwe 2010 42 57 150 1
> Zimbabwe 2006 49 86 288 2
>
>
> This, however, is not what i wanted. kindly help with the code that formats
> my table in the following way?
>
> Country Variables id year value
> Angola bank_ratio 1 2006 24
> Angola bank_ratio 1 2007 25
> Angola Reserve_ratio 1 2008 77
> Angola Reserve_ratio 1 2009 59
> Angola broad_money 1 2010 163
> Angola broad_money 1 2006 188
> Botswana bank_ratio 2 2006 38
> Botswana bank_ratio 2 2007 34
> Botswana Reserve_ratio 2 2008 64
> Botswana Reserve_ratio 2 2009 65
> Botswana broad_money 2 2010 317
> Botswana broad_money 2 2006 361
> Zimbabwe bank_ratio 3 2006 42
> Zimbabwe bank_ratio 3 2007 49
> Zimbabwe Reserve_ratio 3 2008 57
> Zimbabwe Reserve_ratio 3 2009 86
> Zimbabwe broad_money 3 2010 150
> Zimbabwe broad_money 3 2006 288
>
> Thank you
>
> Alternative email: addtarris at icloud.com/TChirume at rbz.co.zw
> Skype: admirechirume
> Call: +263773369884
> whatsapp: +818099861504
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Mon May 17 16:46:07 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Mon, 17 May 2021 17:46:07 +0300
Subject: [R] R stalling frequently
In-Reply-To: <CANuvUTdF7av_bRwMJXSTFcXN6eOTgbyi-=bGTOpYvYB07DzEPw@mail.gmail.com>
References: <CANuvUTdF7av_bRwMJXSTFcXN6eOTgbyi-=bGTOpYvYB07DzEPw@mail.gmail.com>
Message-ID: <CAGgJW76wJDKtx34mLSBJyh58eCHQg7O1qM0kS+22HAzahrTnvg@mail.gmail.com>

Hi Ramdas,
I have no idea what might be causing this but it would probably help those
who might be able to help if you supply additional information, such as the
output of sessionInfo() in an R session.

Also try to send your emails to the list in plain text (not HTML).

Good luck,
Eric

On Mon, May 17, 2021 at 5:32 PM Ramdas Menon <ramdas at ekaagra.com> wrote:

> I have a working knowledge of R, and have been teaching statistics courses
> based on R for quite some time now.
>
> I started with ver 4.0.2, and am now using Ver 4.0.5 which I downloaded a
> week ago. The system works when I type Object <- read.csv(file.choose())
> for a couple of times, and then just stalls.
>
> I used the above function to read in a few csv files, and then R just
> hanged. This has happened four times in the last 2 days.
>
> Each time I need to abort R and restart it. Will any of you be able to help
> me with this?
>
> Best regards
> *Ramdas Menon, +91-98404-58652*
>
> *www.ekaagra.com <http://www.ekaagra.com>*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Mon May 17 16:49:56 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Mon, 17 May 2021 17:49:56 +0300
Subject: [R] Filtering a dataframe
In-Reply-To: <CAFfFd+uyFNkZuT5=Z9dmMGr7cG-uMNTx4fhBTENbDKR5fmfrww@mail.gmail.com>
References: <CAFfFd+uyFNkZuT5=Z9dmMGr7cG-uMNTx4fhBTENbDKR5fmfrww@mail.gmail.com>
Message-ID: <CAGgJW77DRAv6-Pz-WH-AiXeH0Kc2EYA+79FPqMVXhVVO6D_AZQ@mail.gmail.com>

If your data frame is named x then

y <- x[ x$id %in% c(1,2), ]

would create a new data frame y that has what you want.


On Mon, May 17, 2021 at 5:33 PM Admire Tarisirayi Chirume <
atchirume at gmail.com> wrote:

> Can someone help on how to filter my data frame below such that it retains
> a country if a given id (last column) is satisfied eg filtering a data
> frame that has countries with id 1 and 2 only
>
> Country year bank_ratio Reserve_ratio broad_money id
> Angola 2006 24 77 163 1
> Angola 2007 25 59 188 1
> Botswana 2008 38 64 317 2
> Botswana 2009 34 65 361 2
> Zimbabwe 2010 42 57 150 3
> Zimbabwe 2006 49 86 288 3
>
>
>
> Alternative email: addtarris at icloud.com/TChirume at rbz.co.zw
> Skype: admirechirume
> Call: +263773369884
> whatsapp: +818099861504
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon May 17 16:51:08 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 17 May 2021 07:51:08 -0700
Subject: [R] phylogenetic correction and MCMC model
In-Reply-To: <218164214.238135.1621244934796.JavaMail.zimbra@mnhn.fr>
References: <2082987372.190752.1621242378297.JavaMail.zimbra@mnhn.fr>
 <218164214.238135.1621244934796.JavaMail.zimbra@mnhn.fr>
Message-ID: <CAGxFJbQHnxjcM6RRbzWQz8aG5UWu_2cBjuA+qy6ss-4me=hhBw@mail.gmail.com>

Such specialized questions are usually better posted on appropriate R-sigs,
in this case, https://stat.ethz.ch/mailman/listinfo/r-sig-phylo I presume.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, May 17, 2021 at 7:33 AM David Costantini <david.costantini at mnhn.fr>
wrote:

> Dear All
> I am trying to apply a phylogenetic correction to an MCMC model, but I
> have problems in making the inverse matrix. I can visualise the treeplot
> very well, but when I use the script:
> inv.phylo<-inverseA(phylo_ultra,nodes="TIPS",scale=TRUE)
>
> R tells me that there is an error:
>
> Error in pedigree[, 2] : incorrect number of dimensions
> In addition: Warning message:
> In if (attr(pedigree, "class") == "phylo") { :
>
> Do you have any experience with this? I couldn't find a solution so far on
> your website
> Thanks in advance
> David
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @|ec @end|ng |rom @|ec@t@@hev@ky@com  Mon May 17 16:03:53 2021
From: @|ec @end|ng |rom @|ec@t@@hev@ky@com (Alec Stashevsky)
Date: Mon, 17 May 2021 14:03:53 +0000
Subject: [R] [R-pkgs] blocklength 0.1.4 released
Message-ID: <45WYJhX3rLMXX8kaLCj7rclaxYWs5gN8xWu1n-_UPOwGp9GKvjbJHa-EUM2605peA5kh8b91vaNrzyMnmJ6ZYXFvPLEFagqEFyc4ykUv-hI=@alecstashevsky.com>

Dear R Community,

blocklength 0.1.4 has been released to CRAN (https://cran.r-project.org/package=blocklength! blocklength is a package with several methods to automatically select the optimal block-length parameter to be used in a block-bootstrap procedure of dependent data, such as stationary time series.

The newest version includes two methods. A cross-validation method proposed by Hall, Horowitz, and Jing (1995) <[doi:10.1093/biomet/82.3.561](https://doi.org/10.1093%2Fbiomet%2F82.3.561)> and a non-parametric plug-in method based on spectral density estimation proposed by Politis and White (2004) <[doi:10.1081/ETC-120028836](https://doi.org/10.1081%2FETC-120028836)> including the Patton, Politis, and White (2009) <[doi:10.1080/07474930802459016](https://doi.org/10.1080%2F07474930802459016)> correction with a corresponding set of S3 plot methods.

blocklength has also received a fancy hex sticker - thanks to Malina Cheeneebash!

Best,

Alec Stashevsky

[Website](https://alecstashevsky.com)
[Recent Publications](https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2775666)
[GitHub](https://github.com/Alec-Stashevsky/GAP-climate-research)
	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From c@@@nee@h@|e@ @end|ng |rom gm@||@com  Mon May 17 19:11:09 2021
From: c@@@nee@h@|e@ @end|ng |rom gm@||@com (Saneesh C S)
Date: Mon, 17 May 2021 19:11:09 +0200
Subject: [R] Filtering a dataframe
In-Reply-To: <CAGgJW77DRAv6-Pz-WH-AiXeH0Kc2EYA+79FPqMVXhVVO6D_AZQ@mail.gmail.com>
References: <CAFfFd+uyFNkZuT5=Z9dmMGr7cG-uMNTx4fhBTENbDKR5fmfrww@mail.gmail.com>
 <CAGgJW77DRAv6-Pz-WH-AiXeH0Kc2EYA+79FPqMVXhVVO6D_AZQ@mail.gmail.com>
Message-ID: <CAGA4D+qZAt89rCous642_fKL8APkf5XGpCB_18d9ZgEVFjOYew@mail.gmail.com>

Country <- c('Angola', 'Angola','Botswana',
'Botswana','Zimbabwe','Zimbabwe')
year <- c('2006', '2007', '2008', '2009', '2010', '2006')
bank_ratio <- c(24,25,38,34,42,49)
Reserve_ratio <- c(77,59,64,65,57,86)
broad_money <- c(163,188,317,361,150,288)
id <- (c(1,1,2,2,3,3))

df <- data.frame(Country, year, bank_ratio, Reserve_ratio,broad_money, id)

library(dplyr)

df1<- df %>%
  filter(id%in% c(1,2))



On Mon, May 17, 2021 at 5:13 PM Eric Berger <ericjberger at gmail.com> wrote:

> If your data frame is named x then
>
> y <- x[ x$id %in% c(1,2), ]
>
> would create a new data frame y that has what you want.
>
>
> On Mon, May 17, 2021 at 5:33 PM Admire Tarisirayi Chirume <
> atchirume at gmail.com> wrote:
>
> > Can someone help on how to filter my data frame below such that it
> retains
> > a country if a given id (last column) is satisfied eg filtering a data
> > frame that has countries with id 1 and 2 only
> >
> > Country year bank_ratio Reserve_ratio broad_money id
> > Angola 2006 24 77 163 1
> > Angola 2007 25 59 188 1
> > Botswana 2008 38 64 317 2
> > Botswana 2009 34 65 361 2
> > Zimbabwe 2010 42 57 150 3
> > Zimbabwe 2006 49 86 288 3
> >
> >
> >
> > Alternative email: addtarris at icloud.com/TChirume at rbz.co.zw
> > Skype: admirechirume
> > Call: +263773369884
> > whatsapp: +818099861504
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From p@@c@|@kuend|g @end|ng |rom b|uew|n@ch  Mon May 17 21:09:54 2021
From: p@@c@|@kuend|g @end|ng |rom b|uew|n@ch (=?UTF-8?Q?Pascal_K=c3=bcndig?=)
Date: Mon, 17 May 2021 21:09:54 +0200
Subject: [R] Solving a quadratically constrained linear program with inital
 values
Message-ID: <98059e39-8b68-52f1-e30a-c1c09f92bcb5@bluewin.ch>

Hi everyone,
I'm looking for an R-function that solves a quadratically constrained 
linear program of the form:

min(x) -\mu' x
subject to
x' \Sigma x <= s
1'x <= 1
-1'x <= -1
Ix <= u
-Ix <= -b

while considering a given starting value for the vector x.
The above problem results from a larger program of the same structure 
and by setting the constraint that some elements of the solution vector 
\tilde{x} of this larger program have to be 0 if they lie below a 
certain threshold. The starting value for the vector x is therefore a 
subvector of \tilde{x}. \Sigma is symmetric but not necessarily positive 
definite.


From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue May 18 01:22:24 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Mon, 17 May 2021 16:22:24 -0700
Subject: [R] series of densities
In-Reply-To: <3dab5b13-445d-88eb-134b-7a69870ac236@gvdnet.dk>
References: <3dab5b13-445d-88eb-134b-7a69870ac236@gvdnet.dk>
Message-ID: <5a418d18-2aac-9fb7-1abb-41973b93de90@comcast.net>


On 5/17/21 7:44 AM, Troels Ring wrote:
> Dear friends
> I'm trying to plot in silico derived values of 3 types of 
> buffer-capacities? over pH values and want densities of the three 
> types together at each pH with the pH values on the abscissa.
>
> I have generated some data
>
> set.seed(2345)
> pHs <- c(7.2,7.4,7.6)
> pH <- rep(pHs,each=30)
> BC <- rep(rep(c(20,10,10),each=10),3)+rnorm(90,0,5)
> type <- rep(rep(c("TOT","NC","CA"),each=10),3)
>
> ddd <- data.frame(pH,BC,type)
>
> GG <- ggplot()
> for (i in 1:3) {
> ? dd <- ddd[ddd$pH==pHs[i],]
> ? GG <- GG + geom_density(data=dd,aes(x=BC,fill=type),alpha=0.1)
> }
> GG
>
> but here I only get all pH values? plotted together whereas I want 3 
> series in the vertical direction at the three pH values.


Are you perhaps hoping for means of grouped values connected by lines?


Of perhaps a bee-swarm type plot? there are quite a few overlapping points.


-- --

David.

>
> I wonder how this could be done?
>
> All best wishes
>
> Troels Ring, MD
> Aalborg, Denmark
>
> PS: Windows 10,
>
> R version 4.0.5 (2021-03-31
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Tue May 18 02:27:27 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 17 May 2021 17:27:27 -0700
Subject: [R] 
 Solving a quadratically constrained linear program with inital
 values
In-Reply-To: <98059e39-8b68-52f1-e30a-c1c09f92bcb5@bluewin.ch>
References: <98059e39-8b68-52f1-e30a-c1c09f92bcb5@bluewin.ch>
Message-ID: <CAGxFJbRK3Vv0XiswgVecFC4tfwBcctJVSS9Q1KtPyWWC6UubGQ@mail.gmail.com>

Have you looked here: https://cran.r-project.org/web/views/Optimization.html

(Warning: I have no idea whether your query even makes mathematical sense.)

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, May 17, 2021 at 12:56 PM Pascal K?ndig <pascal.kuendig at bluewin.ch>
wrote:

> Hi everyone,
> I'm looking for an R-function that solves a quadratically constrained
> linear program of the form:
>
> min(x) -\mu' x
> subject to
> x' \Sigma x <= s
> 1'x <= 1
> -1'x <= -1
> Ix <= u
> -Ix <= -b
>
> while considering a given starting value for the vector x.
> The above problem results from a larger program of the same structure
> and by setting the constraint that some elements of the solution vector
> \tilde{x} of this larger program have to be 0 if they lie below a
> certain threshold. The starting value for the vector x is therefore a
> subvector of \tilde{x}. \Sigma is symmetric but not necessarily positive
> definite.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue May 18 02:27:55 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Mon, 17 May 2021 17:27:55 -0700
Subject: [R] series of densities
In-Reply-To: <3dab5b13-445d-88eb-134b-7a69870ac236@gvdnet.dk>
References: <3dab5b13-445d-88eb-134b-7a69870ac236@gvdnet.dk>
Message-ID: <3c1c35a4-c946-f9b7-1057-2c2c261f06f3@comcast.net>


On 5/17/21 7:44 AM, Troels Ring wrote:
> Dear friends
> I'm trying to plot in silico derived values of 3 types of 
> buffer-capacities? over pH values and want densities of the three 
> types together at each pH with the pH values on the abscissa.
>
> I have generated some data
>
> set.seed(2345)
> pHs <- c(7.2,7.4,7.6)
> pH <- rep(pHs,each=30)
> BC <- rep(rep(c(20,10,10),each=10),3)+rnorm(90,0,5)
> type <- rep(rep(c("TOT","NC","CA"),each=10),3)
>
> ddd <- data.frame(pH,BC,type)
>
> GG <- ggplot()
> for (i in 1:3) {
> ? dd <- ddd[ddd$pH==pHs[i],]
> ? GG <- GG + geom_density(data=dd,aes(x=BC,fill=type),alpha=0.1)
> }
> GG
>
> but here I only get all pH values? plotted together whereas I want 3 
> series in the vertical direction at the three pH values.
>
> I wonder how this could be done?

Here are two different displays of the data. I haven't figured out what 
was intended by the request for " 3 series in the vertical direction at 
the three pH values".

library(ggplot2)

#violin plots are density-like

ggplot( data=ddd, aes(x=pH, y=BC,group=interaction(type,pH), 
col=type))+geom_violin()

#boxplots are summary methods

ggplot( data=ddd, aes(x=pH, y=BC,group=interaction(type,pH), 
col=type))+geom_boxplot()


>
> All best wishes
>
> Troels Ring, MD
> Aalborg, Denmark
>
> PS: Windows 10,
>
> R version 4.0.5 (2021-03-31
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wjm1 @end|ng |rom c@@@co|umb|@@edu  Tue May 18 02:49:06 2021
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Mon, 17 May 2021 17:49:06 -0700
Subject: [R] series of densities
In-Reply-To: <3dab5b13-445d-88eb-134b-7a69870ac236@gvdnet.dk>
References: <3dab5b13-445d-88eb-134b-7a69870ac236@gvdnet.dk>
Message-ID: <CAA99HCx7Zg8gE6tyxsObi4Kg0B1CcarZ-SkjW3FO2H1xWW7hcQ@mail.gmail.com>

Hi Troels,

Have you considered using Lattice graphics?
Adapting from examples on the help page:

> ?histogram()
> histogram( ~ BC | pH, data = ddd, type = "density",
   xlab  = "BC", layout = c(1, 3), aspect = 0.618,
   strip = strip.custom(strip.levels=c(TRUE,TRUE)),
   panel = function(x, ...) {
   panel.histogram(x, ...)
   panel.mathdensity(dmath = dnorm, col = 1,
   args = list(mean=mean(x), sd=sd(x)) )
   } )


HTH, Bill.

W. Michels, Ph.D.






On Mon, May 17, 2021 at 8:12 AM Troels Ring <tring at gvdnet.dk> wrote:
>
> Dear friends
> I'm trying to plot in silico derived values of 3 types of
> buffer-capacities  over pH values and want densities of the three types
> together at each pH with the pH values on the abscissa.
>
> I have generated some data
>
> set.seed(2345)
> pHs <- c(7.2,7.4,7.6)
> pH <- rep(pHs,each=30)
> BC <- rep(rep(c(20,10,10),each=10),3)+rnorm(90,0,5)
> type <- rep(rep(c("TOT","NC","CA"),each=10),3)
>
> ddd <- data.frame(pH,BC,type)
>
> GG <- ggplot()
> for (i in 1:3) {
>    dd <- ddd[ddd$pH==pHs[i],]
>    GG <- GG + geom_density(data=dd,aes(x=BC,fill=type),alpha=0.1)
> }
> GG
>
> but here I only get all pH values  plotted together whereas I want 3
> series in the vertical direction at the three pH values.
>
> I wonder how this could be done?
>
> All best wishes
>
> Troels Ring, MD
> Aalborg, Denmark
>
> PS: Windows 10,
>
> R version 4.0.5 (2021-03-31
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tr|ng @end|ng |rom gvdnet@dk  Tue May 18 08:25:40 2021
From: tr|ng @end|ng |rom gvdnet@dk (Troels Ring)
Date: Tue, 18 May 2021 08:25:40 +0200
Subject: [R] series of densities
In-Reply-To: <3dab5b13-445d-88eb-134b-7a69870ac236@gvdnet.dk>
References: <3dab5b13-445d-88eb-134b-7a69870ac236@gvdnet.dk>
Message-ID: <978879f7-3748-9239-4800-6982040ef8f4@gvdnet.dk>

Thanks a lot to David and William - I think

ggplot( data=ddd, aes(x=pH, y=BC,group=interaction(type,pH), 
col=type))+geom_boxplot()

was very helpful!

All best

Troels

Den 18-05-2021 kl. 02:27 skrev David Winsemius:
> ggplot( data=ddd, aes(x=pH, y=BC,group=interaction(type,pH), 
> col=type))+geom_boxplot()


From petr@p|k@| @end|ng |rom prechez@@cz  Tue May 18 08:29:45 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 18 May 2021 06:29:45 +0000
Subject: [R] Wide to long format in R
In-Reply-To: <CAFfFd+tO_7O89BHyXBy_jeS9vz=UVXxtcLHABKcWjaBKHoxRVQ@mail.gmail.com>
References: <CAFfFd+tO_7O89BHyXBy_jeS9vz=UVXxtcLHABKcWjaBKHoxRVQ@mail.gmail.com>
Message-ID: <d8cd83f25e7d4e3e98279c5b12c24c37@SRVEXCHCM1302.precheza.cz>

Hi

Please do not post in HTML formating, your messages are then messy. Better
to show how your data frame look like is something like

dput(bop.df[1:10,]) 

Anyway, melt/cast functions from reshape2 package are quite handy for such
tasks.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Admire Tarisirayi
> Chirume
> Sent: Monday, May 17, 2021 9:44 AM
> To: r-help at r-project.org
> Subject: [R] Wide to long format in R
> 
> I need help on reshaping my data frame which is currently in wide format.
> 
> I ran the following codes to create panel ids based on the variable for
country
> names  "*Country"; *
> 
> *bop.df$id<-as.numeric(as.factor(bop.df$Country))*
> 
> then ran the code below to reshape from wide to long format;
> 
> *reshaped.bop <- pivot_longer(bop.df,3:17,names_to =  "year", values_to =
> "value")*
> 
> by running the code:  *print( reshaped.bop), the following table in long
> format came out;*
> 
> 
> Country year bank_ratio Reserve_ratio broad_money id Angola 2006 24 77
> 163 1 Angola 2007 25 59 188 1 Botswana 2008 38 64 317 1 Botswana 2009 34
65
> 361 1 Zimbabwe 2010 42 57 150 1 Zimbabwe 2006 49 86 288 2
> 
> 
> This, however, is not what i wanted. kindly help with the code that
formats
> my table in the following way?
> 
> Country Variables id year value
> Angola bank_ratio 1 2006 24
> Angola bank_ratio 1 2007 25
> Angola Reserve_ratio 1 2008 77
> Angola Reserve_ratio 1 2009 59
> Angola broad_money 1 2010 163
> Angola broad_money 1 2006 188
> Botswana bank_ratio 2 2006 38
> Botswana bank_ratio 2 2007 34
> Botswana Reserve_ratio 2 2008 64
> Botswana Reserve_ratio 2 2009 65
> Botswana broad_money 2 2010 317
> Botswana broad_money 2 2006 361
> Zimbabwe bank_ratio 3 2006 42
> Zimbabwe bank_ratio 3 2007 49
> Zimbabwe Reserve_ratio 3 2008 57
> Zimbabwe Reserve_ratio 3 2009 86
> Zimbabwe broad_money 3 2010 150
> Zimbabwe broad_money 3 2006 288
> 
> Thank you
> 
> Alternative email: addtarris at icloud.com/TChirume at rbz.co.zw
> Skype: admirechirume
> Call: +263773369884
> whatsapp: +818099861504
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue May 18 09:30:07 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 18 May 2021 09:30:07 +0200
Subject: [R] 
 Solving a quadratically constrained linear program with inital
 values
In-Reply-To: <CAGxFJbRK3Vv0XiswgVecFC4tfwBcctJVSS9Q1KtPyWWC6UubGQ@mail.gmail.com>
References: <98059e39-8b68-52f1-e30a-c1c09f92bcb5@bluewin.ch>
 <CAGxFJbRK3Vv0XiswgVecFC4tfwBcctJVSS9Q1KtPyWWC6UubGQ@mail.gmail.com>
Message-ID: <24739.27903.739678.911098@stat.math.ethz.ch>

>>>>> Bert Gunter 
>>>>>     on Mon, 17 May 2021 17:27:27 -0700 writes:

    > Have you looked here:
    > https://cran.r-project.org/web/views/Optimization.html

yes, he has .. and I've suggested to him to ask here ... 

    > (Warning: I have no idea whether your query even makes
    >  mathematical sense.)

Indeed, it *does* make sense; at least for the case of positive
(semi-)definite \Sigma  which we may well assume for the moment.

Martin Maechler


    > Bert Gunter

    > "The trouble with having an open mind is that people keep coming along and
    > sticking things into it."
    > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


    > On Mon, May 17, 2021 at 12:56 PM Pascal K?ndig <pascal.kuendig at bluewin.ch>
    > wrote:

    >> Hi everyone,
    >> I'm looking for an R-function that solves a quadratically constrained
    >> linear program of the form:
    >> 
    >> min(x) -\mu' x
    >> subject to
    >> x' \Sigma x <= s
    >> 1'x <= 1
    >> -1'x <= -1
    >> Ix <= u
    >> -Ix <= -b
    >> 
    >> while considering a given starting value for the vector x.
    >> The above problem results from a larger program of the same structure
    >> and by setting the constraint that some elements of the solution vector
    >> \tilde{x} of this larger program have to be 0 if they lie below a
    >> certain threshold. The starting value for the vector x is therefore a
    >> subvector of \tilde{x}. \Sigma is symmetric but not necessarily positive
    >> definite.
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide
    >> http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.
    >> 

    > [[alternative HTML version deleted]]

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Wed May 19 15:14:03 2021
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Wed, 19 May 2021 13:14:03 +0000 (UTC)
Subject: [R] Plot with some countries in red
References: <264051498.3487371.1621430043737.ref@mail.yahoo.com>
Message-ID: <264051498.3487371.1621430043737@mail.yahoo.com>

Dear R-experts,

Here below a toy R code example. I would like some countries (not all of them) "Italy", "Canada", "Greece" and "Norway" to appear in red color. The others remaining black. How can I do that without big changes in my R code ? Indeed, I would like my R code to remain like this as much as possible, for example, end of my R code, I want to keep the non-overlapping text label.

############
A<-c("Italy","Germany","USA","Canada","Turkey","Chile","Mexico","Japan","Norway","Finland","Greece")
B<-c(540,523,589,600,499,567,485,467,543,511,500)
C<-c(470,470,489,492,476,475,455,444,489,456,478)

mod1=loess(C~B,span=0.7)
Bfit=seq(from=min(C),to=max(C),length.out=100)
Afit1=predict(mod1,newdata=Bfit)
plot(B,C,main="Courbe de r?gression non param?trique entre ISQ 2015 et ISQ 2018", xlab="score ISQ 2015", ylab="score ISQ 2018 ",type="n")
points(Bfit,Afit1,type="l",lwd=2,col="red")

library(basicPlotteR) 
# Add non-overlapping text labels
addTextLabels(B, C, A, col.label="black")??????????
############

?

?

?


From petr@p|k@| @end|ng |rom prechez@@cz  Wed May 19 15:47:49 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 19 May 2021 13:47:49 +0000
Subject: [R] Plot with some countries in red
In-Reply-To: <264051498.3487371.1621430043737@mail.yahoo.com>
References: <264051498.3487371.1621430043737.ref@mail.yahoo.com>
 <264051498.3487371.1621430043737@mail.yahoo.com>
Message-ID: <362c5d5de0ee4919981766e472f2973a@SRVEXCHCM1302.precheza.cz>

Hi

For your example

sel <- c(1,4, 9, 11)
text(B, C, A, col=  c("black", "red")[(A %in% A[sel])+1])

gives you required colouring.Not sure if it works with basicPlotteR.

Cheers
Petr

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of varin sacha via R-help
Sent: Wednesday, May 19, 2021 3:14 PM
To: r-help at r-project.org
Subject: [R] Plot with some countries in red

Dear R-experts,

Here below a toy R code example. I would like some countries (not all of them) "Italy", "Canada", "Greece" and "Norway" to appear in red color. The others remaining black. How can I do that without big changes in my R code ? Indeed, I would like my R code to remain like this as much as possible, for example, end of my R code, I want to keep the non-overlapping text label.

############
A<-c("Italy","Germany","USA","Canada","Turkey","Chile","Mexico","Japan","Norway","Finland","Greece")
B<-c(540,523,589,600,499,567,485,467,543,511,500)
C<-c(470,470,489,492,476,475,455,444,489,456,478)

mod1=loess(C~B,span=0.7)
Bfit=seq(from=min(C),to=max(C),length.out=100)
Afit1=predict(mod1,newdata=Bfit)
plot(B,C,main="Courbe de r?gression non param?trique entre ISQ 2015 et ISQ 2018", xlab="score ISQ 2015", ylab="score ISQ 2018 ",type="n")
points(Bfit,Afit1,type="l",lwd=2,col="red")

library(basicPlotteR)
# Add non-overlapping text labels
addTextLabels(B, C, A, col.label="black")
############







______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From bh@@k@r@ko|k@t@ @end|ng |rom gm@||@com  Wed May 19 19:10:41 2021
From: bh@@k@r@ko|k@t@ @end|ng |rom gm@||@com (Bhaskar Mitra)
Date: Wed, 19 May 2021 10:10:41 -0700
Subject: [R] Help in modifying code to extract data from url
Message-ID: <CAEGXkYUynpgLAZ=Y9tUf0BOB1c9eAQmdrKpgE=tM2FEfP6hpAw@mail.gmail.com>

Hello Everyone,

I am trying to extract data from a url. The codes work well when the
data structure is as follows:

X Y
1 2
1 5
1 6
1 7
3 4

However, the code fails when the data structure has no number
under the 2nd column (shown below).I get the following error:

"Error in data.frame(..., check.names = FALSE) :
  arguments imply differing number of rows: 242, 241"


X Y
1 2
1
1
1 7
3 4

Can anyone please help me in how I can modify the codes ( shown below) to
adjust for the above mentioned condition
in the data structure.

library(rjson)

url <- "abcd.com"
json_data <- fromJSON(file= url)
d3 <- lapply(json_data[[2]], function(x) c(x["data"]))
d3 <- do.call(rbind, d3)
X_Dataframe = as.data.frame(unlist(d3[[1]]))
b <- do.call("cbind", split(X_Dataframe, rep(c(1, 2), length.out =
nrow(X_Dataframe))))


regards,
bhaskar

	[[alternative HTML version deleted]]


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Thu May 20 05:00:06 2021
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Thu, 20 May 2021 03:00:06 +0000
Subject: [R] COXPH:   How should weights be entered in coxph,
 as the log of the weight or as the weight on its original scale?
Message-ID: <MN2PR03MB51675E38DECE75C7F4D66A1FE22A9@MN2PR03MB5167.namprd03.prod.outlook.com>

When running a propensity score weighted analysis using coxph(), are the weights entered as the log of the weights, or as the weights on the original scale, i.e. coxph(Surv(time,status)~group,weights=weights       ,data=mydata) or
      coxph(Surv(time,status)~group,weights=log(weights),data=mydata)

I am creating weights using logistic regression as described below.

# Lalonde data from the MatchIt package is used in the pseudo code below
install.packages("MatchIt")
library("MatchIt")

#############################################
# Calculate propensity scores using logistic regression.#
#############################################
ps <- glm(treat ~ age + educ +nodegree +re74+ re75,data=lalonde,family=binomial())
summary(ps)
#PS on the scale of the dependent variable
# Add the propensity scores to the dataset
lalonde$psvalue <- predict(ps,type="response")
#################################################
# END Calculate propensity scores using logistic regression.#
#################################################

#################################
# Convert propensity scores to weights#
#################################
# Different weights for cases (1) and controls
lalonde$weight.ATE <- ifelse(lalonde$treat == 1, 1/lalonde$psvalue,1/(1-lalonde$psvalue))
summary(lalonde$weight.ATE)
#####################################
# END Convert propensity scores to weights#
#####################################

##########################################################
# Examples of two possible way  to enter weights in the coxph model. #
##########################################################
fit1 <- coxph(Surv(time,status)~group,weights=lalonde$weight,data=lalonde)
or
fit2 <- coxph(Surv(time,status)~group,weights=log(lalonde$weight),data=lalonde)
##########################################################
# Examples of two possible way  to enter weights in the coxph model. #
##########################################################


	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu May 20 07:23:35 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 19 May 2021 22:23:35 -0700
Subject: [R] COXPH:   How should weights be entered in coxph,
 as the log of the weight or as the weight on its original scale?
In-Reply-To: <MN2PR03MB51675E38DECE75C7F4D66A1FE22A9@MN2PR03MB5167.namprd03.prod.outlook.com>
References: <MN2PR03MB51675E38DECE75C7F4D66A1FE22A9@MN2PR03MB5167.namprd03.prod.outlook.com>
Message-ID: <2A69FC7A-F592-4F80-B694-50D69ACC61C5@comcast.net>

Perhaps this package could be considered

https://cran.r-project.org/web/packages/hrIPW/hrIPW.pdf

That packages author also has a 2016 article in Statistics in Medicine on the properties of estimates from such analyses that might be useful. 

? 
David Winsemius, MD, MPH

Sent from my iPhone

> On May 19, 2021, at 8:01 PM, Sorkin, John <jsorkin at som.umaryland.edu> wrote:
> 
> ?When running a propensity score weighted analysis using coxph(), are the weights entered as the log of the weights, or as the weights on the original scale, i.e. coxph(Surv(time,status)~group,weights=weights       ,data=mydata) or
>      coxph(Surv(time,status)~group,weights=log(weights),data=mydata)
> 
> I am creating weights using logistic regression as described below.
> 
> # Lalonde data from the MatchIt package is used in the pseudo code below
> install.packages("MatchIt")
> library("MatchIt")
> 
> #############################################
> # Calculate propensity scores using logistic regression.#
> #############################################
> ps <- glm(treat ~ age + educ +nodegree +re74+ re75,data=lalonde,family=binomial())
> summary(ps)
> #PS on the scale of the dependent variable
> # Add the propensity scores to the dataset
> lalonde$psvalue <- predict(ps,type="response")
> #################################################
> # END Calculate propensity scores using logistic regression.#
> #################################################
> 
> #################################
> # Convert propensity scores to weights#
> #################################
> # Different weights for cases (1) and controls
> lalonde$weight.ATE <- ifelse(lalonde$treat == 1, 1/lalonde$psvalue,1/(1-lalonde$psvalue))
> summary(lalonde$weight.ATE)
> #####################################
> # END Convert propensity scores to weights#
> #####################################
> 
> ##########################################################
> # Examples of two possible way  to enter weights in the coxph model. #
> ##########################################################
> fit1 <- coxph(Surv(time,status)~group,weights=lalonde$weight,data=lalonde)
> or
> fit2 <- coxph(Surv(time,status)~group,weights=log(lalonde$weight),data=lalonde)
> ##########################################################
> # Examples of two possible way  to enter weights in the coxph model. #
> ##########################################################
> 
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From pd@|gd @end|ng |rom gm@||@com  Tue May 18 10:06:24 2021
From: pd@|gd @end|ng |rom gm@||@com (Peter Dalgaard)
Date: Tue, 18 May 2021 10:06:24 +0200
Subject: [R] [Rd] R 4.1.0 is released
Message-ID: <9C835984-B6BF-439C-A01A-3E5906D720B6@gmail.com>


The build system rolled up R-4.1.0.tar.gz (codename "Camp Pontanezen") this morning.

This is a major update, notably containing the new native pipe operator "|>" and 
shorthand inline functions "\(x) x+1".

The list below details the changes in this release. 

You can get the source code from

https://cran.r-project.org/src/base/R-4/R-4.1.0.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard


These are the checksums (md5 and SHA-256) for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = b9c44f9f78cab3184ad9898bebc854b4
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 639fbbba9998cae70ef058be42b80a52
MD5 (INSTALL) = 7893f754308ca31f1ccf62055090ad7b
MD5 (NEWS) = b02805558a8315f1a93c7f7d7cd879c1
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = a767f7809324c73c49eaff47d14bce81
MD5 (NEWS.3) = e55ed2c8a547b827b46e08eb7137ba23
MD5 (R-latest.tar.gz) = bd80f97d0e46a71408f5bc25652a0203
MD5 (README) = f468f281c919665e276a1b691decbbe6
MD5 (RESOURCES) = 529223fd3ffef95731d0a87353108435
MD5 (THANKS) = 251d20510bfc3cc93b82c5a99f7efcc6
MD5 (VERSION-INFO.dcf) = 1f3cf39735afb48fea434bca2b7bf483
MD5 (R-4/R-4.1.0.tar.gz) = bd80f97d0e46a71408f5bc25652a0203

2cde824a7b18958e5f06b391c801c8288be0f84fa8934b7ddefef23c67e60c09  AUTHORS
e6d6a009505e345fe949e1310334fcb0747f28dae2856759de102ab66b722cb4  COPYING
6095e9ffa777dd22839f7801aa845b31c9ed07f3d6bf8a26dc5d2dec8ccc0ef3  COPYING.LIB
0dce85f38b9d6351a1b63f057dfbc7f572966245add12946482e57e60d41547c  FAQ
f87461be6cbaecc4dce44ac58e5bd52364b0491ccdadaf846cb9b452e9550f31  INSTALL
20e7185fb5af0f2ac825b27c16afd57ff206726117c6ac5cf7c6f230337af093  NEWS
4e21b62f515b749f80997063fceab626d7258c7d650e81a662ba8e0640f12f62  NEWS.0
12b30c724117b1b2b11484673906a6dcd48a361f69fc420b36194f9218692d01  NEWS.1
ba74618bc3f4c0e336dca13d472402a1863d12ba6f7f91a1782bc469ee986f6d  NEWS.2
1910a2405300b9bc7c76beeb0753a5249cf799afe175ce28f8d782fab723e012  NEWS.3
e8e68959d7282ca147360fc9644ada9bd161bab781bab14d33b8999a95182781  R-latest.tar.gz
2fdd3e90f23f32692d4b3a0c0452f2c219a10882033d1774f8cadf25886c3ddc  README
408737572ecc6e1135fdb2cf7a9dbb1a6cb27967c757f1771b8c39d1fd2f1ab9  RESOURCES
c9c7cb32308b4e560a22c858819ade9de524a602abd4e92d1c328c89f8037d73  THANKS
2f834a058dcfcdfb7eedf45aa0d897ea1a7c43a9460ffd22f73b60919cb1bf57  VERSION-INFO.dcf
e8e68959d7282ca147360fc9644ada9bd161bab781bab14d33b8999a95182781  R-4/R-4.1.0.tar.gz

This is the relevant part of the NEWS file

CHANGES IN R 4.1.0:

  FUTURE DIRECTIONS:

    * It is planned that the 4.1.x series will be the last to support
      32-bit Windows, with production of binary packages for that
      series continuing until early 2023.

  SIGNIFICANT USER-VISIBLE CHANGES:

    * Data set esoph in package datasets now provides the correct
      numbers of controls; previously it had the numbers of cases added
      to these.  (Reported by Alexander Fowler in PR#17964.)

  NEW FEATURES:

    * www.omegahat.net is no longer one of the repositories known by
      default to setRepositories().  (Nowadays it only provides source
      packages and is often unavailable.)

    * Function package_dependencies() (in package tools) can now use
      different dependency types for direct and recursive dependencies.

    * The checking of the size of tarball in R CMD check --as-cran
      <pkg> may be tweaked via the new environment variable
      _R_CHECK_CRAN_INCOMING_TARBALL_THRESHOLD_, as suggested in
      PR#17777 by Jan Gorecki.

    * Using c() to combine a factor with other factors now gives a
      factor, an ordered factor when combining ordered factors with
      identical levels.

    * apply() gains a simplify argument to allow disabling of
      simplification of results.

    * The format() method for class "ftable" gets a new option justify.
      (Suggested by Thomas Soeiro.)

    * New ...names() utility.  (Proposed by Neal Fultz in PR#17705.)

    * type.convert() now warns when its as.is argument is not
      specified, as the help file always said it _should_.  In that
      case, the default is changed to TRUE in line with its change in
      read.table() (related to stringsAsFactor) in R 4.0.0.

    * When printing list arrays, classed objects are now shown _via_
      their format() value if this is a short enough character string,
      or by giving the first elements of their class vector and their
      length.

    * capabilities() gets new entry "Rprof" which is TRUE when R has
      been configured with the equivalent of --enable-R-profiling (as
      it is by default).  (Related to Michael Orlitzky's report
      PR#17836.)

    * str(xS4) now also shows extraneous attributes of an S4 object
      xS4.

    * Rudimentary support for vi-style tags in rtags() and R CMD rtags
      has been added.  (Based on a patch from Neal Fultz in PR#17214.)

    * checkRdContents() is now exported from tools; it and also
      checkDocFiles() have a new option chkInternal allowing to check
      Rd files marked with keyword "internal" as well.  The latter can
      be activated for R CMD check via environment variable
      _R_CHECK_RD_INTERNAL_TOO_.

    * New functions numToBits() and numToInts() extend the raw
      conversion utilities to (double precision) numeric.

    * Functions URLencode() and URLdecode() in package utils now work
      on vectors of URIs.  (Based on patch from Bob Rudis submitted
      with PR#17873.)

    * path.expand() can expand ~user on most Unix-alikes even when
      readline is not in use.  It tries harder to expand ~, for example
      should environment variable HOME be unset.

    * For HTML help (both dynamic and static), Rd file links to help
      pages in external packages are now treated as references to
      topics rather than file names, and fall back to a file link only
      if the topic is not found in the target package. The earlier rule
      which prioritized file names over topics can be restored by
      setting the environment variable _R_HELP_LINKS_TO_TOPICS_ to a
      false value.

    * c() now removes NULL arguments before dispatching to methods,
      thus simplifying the implementation of c() methods, _but_ for
      back compatibility keeps NULL when it is the first argument.
      (From a report and patch proposal by Lionel Henry in PR#17900.)

    * Vectorize()'s result function's environment no longer keeps
      unneeded objects.

    * Function ...elt() now propagates visibility consistently with
      ..n.  (Thanks to Lionel Henry's PR#17905.)

    * capture.output() no longer uses non-standard evaluation to
      evaluate its arguments.  This makes evaluation of functions like
      parent.frame() more consistent.  (Thanks to Lionel Henry's
      PR#17907.)

    * packBits(bits, type="double") now works as inverse of
      numToBits().  (Thanks to Bill Dunlap's proposal in PR#17914.)

    * curlGetHeaders() has two new arguments, timeout to specify the
      timeout for that call (overriding getOption("timeout")) and TLS
      to specify the minimum TLS protocol version to be used for
      https:// URIs (_inter alia_ providing a means to check for sites
      using deprecated TLS versions 1.0 and 1.1).

    * For nls(), an optional constant scaleOffset may be added to the
      denominator of the relative offset convergence test for cases
      where the fit of a model is expected to be exact, thanks to a
      proposal by John Nash.  nls(*, trace=TRUE) now also shows the
      convergence criterion.

    * Numeric differentiation _via_ numericDeriv() gets new optional
      arguments eps and central, the latter for taking central divided
      differences.  The latter can be activated for nls() via
      nls.control(nDcentral = TRUE).

    * nls() now passes the trace and control arguments to getInitial(),
      notably for all self-starting models, so these can also be fit in
      zero-noise situations via a scaleOffset.  For this reason, the
      initial function of a selfStart model must now have ... in its
      argument list.

    * bquote(splice = TRUE) can now splice expression vectors with
      attributes: this makes it possible to splice the result of
      parse(keep.source = TRUE).  (Report and patch provided by Lionel
      Henry in PR#17869.)

    * textConnection() gets an optional name argument.

    * get(), exists(), and get0() now signal an error if the first
      argument has length greater than 1.  Previously additional
      elements were silently ignored.  (Suggested by Antoine Fabri on
      R-devel.)

    * R now provides a shorthand notation for creating functions, e.g.
      \(x) x + 1 is parsed as function(x) x + 1.

    * R now provides a simple native forward pipe syntax |>.  The
      simple form of the forward pipe inserts the left-hand side as the
      first argument in the right-hand side call.  The pipe
      implementation as a syntax transformation was motivated by
      suggestions from Jim Hester and Lionel Henry.

    * all.equal(f, g) for functions now by default also compares their
      environment(.)s, notably via new all.equal method for class
      function.  Comparison of nls() fits, e.g., may now need
      all.equal(m1, m2, check.environment = FALSE).

    * .libPaths() gets a new option include.site, allowing to _not_
      include the site library.  (Thanks to Dario Strbenac's suggestion
      and Gabe Becker's PR#18016.)

    * Lithuanian translations are now available.  (Thanks to Rimantas
      Zakauskas.)

    * names() now works for DOTSXP objects.  On the other hand, in
      R-lang, the R language manual, we now warn against relying on the
      structure or even existence of such dot-dot-dot objects.

    * all.equal() no longer gives an error on DOTSXP objects.

    * capabilities("cairo") now applies only to the file-based devices
      as it is now possible (if very unusual) to build R with Cairo
      support for those but not for X11().

    * There is optional support for tracing the progress of
      loadNamespace() - see its help.

    * (Not Windows.)  l10n_info() reports an additional element, the
      name of the encoding as reported by the OS (which may differ from
      the encoding part (if any) of the result from
      Sys.getlocale("LC_CTYPE").

    * New function gregexec() which generalizes regexec() to find _all_
      disjoint matches and well as all substrings corresponding to
      parenthesized subexpressions of the given regular expression.
      (Contributed by Brodie Gaslam.)

    * New function charClass() in package utils to query the
      wide-character classification functions in use (such as
      iswprint).

    * The names of quantile()'s result no longer depend on the global
      getOption("digits"), but quantile() gets a new optional argument
      digits = 7 instead.

    * grep(), sub(), regexp and variants work considerably faster for
      long factors with few levels.  (Thanks to Michael Chirico's
      PR#18063.)

    * Provide grouping of x11() graphics windows within a window
      manager such as Gnome or Unity; thanks to a patch by Ivan Krylov
      posted to R-devel.

    * The split() method for class data.frame now allows the f argument
      to be specified as a formula.

    * sprintf now warns on arguments unused by the format string.

    * New palettes "Rocket" and "Mako" for hcl.colors() (approximating
      palettes of the same name from the 'viridisLite' package).

      Contributed by Achim Zeileis.

    * The base environment and its namespace are now locked (so one can
      no longer add bindings to these or remove from these).

    * Rterm handling of multi-byte characters has been improved,
      allowing use of such characters when supported by the current
      locale.

    * Rterm now accepts ALT+ +xxxxxxxx sequences to enter Unicode
      characters as hex digits.

    * Environment variable LC_ALL on Windows now takes precedence over
      LC_CTYPE and variables for other supported categories, matching
      the POSIX behaviour.

    * duplicated() and anyDuplicated() are now optimized for integer
      and real vectors that are known to be sorted via the ALTREP
      framework. Contributed by Gabriel Becker via PR#17993.

  GRAPHICS:

    * The graphics engine version, R_GE_version, has been bumped to 14
      and so packages that provide graphics devices should be
      reinstalled.

    * Graphics devices should now specify deviceVersion to indicate
      what version of the graphics engine they support.

    * Graphics devices can now specify deviceClip.  If TRUE, the
      graphics engine will never perform any clipping of output itself.

      The clipping that the graphics engine does perform (for both
      canClip = TRUE and canClip = FALSE) has been improved to avoid
      producing unnecessary artifacts in clipped output.

    * The grid package now allows gpar(fill) to be a linearGradient(),
      a radialGradient(), or a pattern().  The viewport(clip) can now
      also be a grob, which defines a clipping path, and there is a new
      viewport(mask) that can also be a grob, which defines a mask.

      These new features are only supported so far on the Cairo-based
      graphics devices and on the pdf() device.

    * (Not Windows.)  A warning is given when a Cairo-based type is
      specified for a png(), jpeg(), tiff() or bmp() device but Cairo
      is unsupported (so type = "Xlib" is tried instead).

    * grSoftVersion() now reports the versions of FreeType and
      FontConfig if they are used directly (not _via_ Pango), as is
      most commonly done on macOS.

  C-LEVEL FACILITIES:

    * The _standalone_ libRmath math library and R's C API now provide
      log1pexp() again as documented, and gain log1mexp().

  INSTALLATION on a UNIX-ALIKE:

    * configure checks for a program pkgconf if program pkg-config is
      not found.  These are now only looked for on the path (like
      almost all other programs) so if needed specify a full path to
      the command in PKG_CONFIG, for example in file config.site.

    * C99 function iswblank is required - it was last seen missing ca
      2003 so the workaround has been removed.

    * There are new configure options --with-internal-iswxxxxx,
      --with-internal-towlower and --with-internal-wcwidth which allows
      the system functions for wide-character classification,
      case-switching and width (wcwidth and wcswidth) to be replaced by
      internal ones.  The first has long been used on macOS, AIX (and
      Windows) but this enables it to be unselected there and selected
      for other platforms (it is the new default on Solaris).  The
      second is new in this version of R and is selected by default on
      macOS and Solaris.  The third has long been the default and
      remains so as it contains customizations for East Asian
      languages.

      System versions of these functions are often minimally
      implemented (sometimes only for ASCII characters) and may not
      cover the full range of Unicode points: for example Solaris (and
      Windows) only cover the Basic Multilingual Plane.

    * Cairo installations without X11 are more likely to be detected by
      configure, when the file-based Cairo graphics devices will be
      available but not X11(type = "cairo").

    * There is a new configure option --with-static-cairo which is the
      default on macOS.  This should be used when only static cairo
      (and where relevant, Pango) libraries are available.

    * Cairo-based graphics devices on platforms without Pango but with
      FreeType/FontConfig will make use of the latter for font
      selection.

  LINK-TIME OPTIMIZATION on a UNIX-ALIKE:

    * Configuring with flag --enable-lto=R now also uses LTO when
      installing the recommended packages.

    * R CMD INSTALL and R CMD SHLIB have a new flag --use-LTO to use
      LTO when compiling code, for use with R configured with
      --enable-lto=R.  For R configured with --enable-lto, they have
      the new flag --no-use-LTO.

      Packages can opt in or out of LTO compilation _via_ a UseLTO
      field in the DESCRIPTION file.  (As usual this can be overridden
      by the command-line flags.)

  BUILDING R on Windows:

    * for GCC >= 8, FC_LEN_T is defined in config.h and hence character
      lengths are passed from C to Fortran in _inter alia_ BLAS and
      LAPACK calls.

    * There is a new text file src/gnuwin32/README.compilation, which
      outlines how C/Fortran code compilation is organized and
      documents new features:

        * R can be built with Link-Time Optimization with a suitable
          compiler - doing so with GCC 9.2 showed several
          inconsistencies which have been corrected.

        * There is support for cross-compiling the C and Fortran code
          in R and standard packages on suitable (Linux) platforms.
          This is mainly intended to allow developers to test later
          versions of compilers - for example using GCC 9.2 or 10.x has
          detected issues that GCC 8.3 in Rtools40 does not.

        * There is experimental support for cross-building R packages
          with C, C++ and/or Fortran code.

    * The R installer can now be optionally built to support a single
      architecture (only 64-bit or only 32-bit).

  PACKAGE INSTALLATION:

    * The default C++ standard has been changed to C++14 where
      available (which it is on all currently checked platforms): if
      not (as before) C++11 is used if available otherwise C++ is not
      supported.

      Packages which specify C++11 will still be installed using C++11.

      C++14 compilers may give deprecation warnings, most often for
      std::random_shuffle (deprecated in C++14 and removed in C++17).
      Either specify C++11 (see 'Writing R Extensions') or modernize
      the code and if needed specify C++14.  The latter has been
      supported since R 3.4.0 so the package's DESCRIPTION would need
      to include something like

           Depends: R (>= 3.4)
      
  PACKAGE INSTALLATION on Windows:

    * R CMD INSTALL and R CMD SHLIB make use of their flag --use-LTO
      when the LTO_OPT make macro is set in file etc/${R_ARCH}/Makeconf
      or in a personal/site Makevars file.  (For details see 'Writing R
      Extensions' SS4.5.)

      This provides a valuable check on code consistency.  It does work
      with GCC 8.3 as in Rtools40, but that does not detect everything
      the CRAN checks with current GCC do.

  PACKAGE INSTALLATION on macOS:

    * The default personal library directory on builds with
      --enable-aqua (including CRAN builds) now differs by CPU type,
      one of

            ~/Library/R/x86_64/x.y/library
            ~/Library/R/arm64/x.y/library
      
      This uses the CPU type R (and hence the packages) were built for,
      so when a x86_64 build of R is run under Rosetta emulation on an
      arm64 Mac, the first is used.

  UTILITIES:

    * R CMD check can now scan package functions for bogus return
      statements, which were possibly intended as return() calls (wish
      of PR#17180, patch by Sebastian Meyer). This check can be
      activated via the new environment variable
      _R_CHECK_BOGUS_RETURN_, true for --as-cran.

    * R CMD build omits tarballs and binaries of previous builds from
      the top-level package directory.  (PR#17828, patch by Sebastian
      Meyer.)

    * R CMD check now runs sanity checks on the use of LazyData, for
      example that a data directory is present and that
      LazyDataCompression is not specified without LazyData and has a
      documented value.  For packages with large LazyData databases
      without specifying LazyDataCompression, there is a reference to
      the code given in 'Writing R Extensions' SS1.1.6 to test the
      choice of compression (as in all the CRAN packages tested a
      non-default method was preferred).

    * R CMD build removes LazyData and LazyDataCompression fields from
      the DESCRIPTION file of packages without a data directory.

  ENCODING-RELATED CHANGES:

    * The parser now treats \Unnnnnnnn escapes larger than the upper
      limit for Unicode points (\U10FFFF) as an error as they cannot be
      represented by valid UTF-8.

      Where such escapes are used for outputting non-printable
      (including unassigned) characters, 6 hex digits are used (rather
      than 8 with leading zeros).  For clarity, braces are used, for
      example \U{0effff}.

    * The parser now looks for non-ASCII spaces on Solaris (as
      previously on most other OSes).

    * There are warnings (including from the parser) on the use of
      unpaired surrogate Unicode points such as \uD834.  (These cannot
      be converted to valid UTF-8.)

    * Functions nchar(), tolower(), toupper() and chartr() and those
      using regular expressions have more support for inputs with a
      marked Latin-1 encoding.

    * The character-classification functions used (by default) to
      replace the system iswxxxxx functions on Windows, macOS and AIX
      have been updated to Unicode 13.0.0.

      The character-width tables have been updated to include new
      assignments in Unicode 13.0.0.

    * The code for evaluating default (extended) regular expressions
      now uses the same character-classification functions as the rest
      of R (previously they differed on Windows, macOS and AIX).

    * There is a build-time option to replace the system's
      wide-character wctrans C function by tables shipped with R: use
      configure option --with-internal-towlower or (on Windows)
      -DUSE_RI18N_CASE in CFLAGS when building R.  This may be needed
      to allow tolower() and toupper() to work with Unicode characters
      beyond the Basic Multilingual Plane where not supported by system
      functions (e.g. on Solaris where it is the new default).

    * R is more careful when truncating UTF-8 and other multi-byte
      strings that are too long to be printed, passed to the system or
      libraries or placed into an internal buffer.  Truncation will no
      longer produce incomplete multibyte characters.

  DEPRECATED AND DEFUNCT:

    * Function plclust() from the package stats and
      package.dependencies(), pkgDepends(), getDepList(),
      installFoundDepends(), and vignetteDepends() from package tools
      are defunct.

    * Defunct functions checkNEWS() and readNEWS() from package tools
      and CRAN.packages() from utils have been removed.

    * R CMD config CXXCPP is defunct (it was deprecated in R 3.6.2).

    * parallel::detectCores() drops support for Irix (retired in 2013).

    * The LINPACK argument to chol.default(), chol2inv(),
      solve.default() and svd() has been defunct since R 3.1.0.  It was
      silently ignored up to R 4.0.3 but now gives an error.

    * Subsetting/indexing, such as ddd[*] or ddd$x on a DOTSXP
      (dot-dot-dot) object ddd has been disabled; it worked by accident
      only and was undocumented.

  BUG FIXES:

    * Many more C-level allocations (mainly by malloc and strdup) are
      checked for success with suitable alternative actions.

    * Bug fix for replayPlot(); this was turning off graphics engine
      display list recording if a recorded plot was replayed in the
      same session.  The impact of the bug became visible if resize the
      device after replay OR if attempted another savePlot() after
      replay (empty display list means empty screen on resize or empty
      saved plot).

    * R CMD check etc now warn when a package exports non-existing S4
      classes or methods, also in case of no "methods" presence.
      (Reported by Alex Bertram; reproducible example and patch by
      Sebastian Meyer in PR#16662.)

    * boxplot() now also accepts calls for labels such as ylab, the
      same as plot().  (Reported by Marius Hofert.)

    * The help page for xtabs() now correctly states that addNA is
      setting na.action = na.pass among others.  (Reported as PR#17770
      by Thomas Soeiro.)

    * The R CMD check <pkg> gives a longer and more comprehensible
      message when DESCRIPTION misses dependencies, e.g., in Imports:.
      (Thanks to the contributors of PR#17179.)

    * update.default() now calls the generic update() on the formula to
      work correctly for models with extended formulas.  (As reported
      and suggested by Neal Fultz in PR#17865.)

    * The horizontal position of leaves in a dendrogram is now correct
      also with center = FALSE.  (PR#14938, patch from Sebastian
      Meyer.)

    * all.equal.POSIXt() no longer warns about and subsequently ignores
      inconsistent "tzone" attributes, but describes the difference in
      its return value (PR#17277).  This check can be disabled _via_
      the new argument check.tzone = FALSE as suggested by Sebastian
      Meyer.

    * as.POSIXct() now populates the "tzone" attribute from its tz
      argument when x is a logical vector consisting entirely of NA
      values.

    * x[[2^31]] <- v now works.  (Thanks to the report and patch by
      Suharto Anggono in PR#17330.)

    * In log-scale graphics, axis() ticks and label positions are now
      computed more carefully and symmetrically in their range,
      typically providing _more_ ticks, fulfilling wishes in PR#17936.
      The change really corresponds to an improved axisTicks() (package
      grDevices), potentially influencing grid and lattice, for
      example.

    * qnorm(<very large negative>, log.p=TRUE) is now correct to at
      least five digits where it was catastrophically wrong,
      previously.

    * sum(df) and similar "Summary"- and "Math"-group member functions
      now work for data frames df with logical columns, notably also of
      zero rows.  (Reported to R-devel by Martin "b706".)

    * unsplit() had trouble with tibbles due to unsound use of rep(NA,
      len)-indexing, which should use NA_integer_ (Reported to R-devel
      by Mario Annau.)

    * pnorm(x, log.p = TRUE) underflows to -Inf slightly later.

    * show(<hidden S4 generic>) prints better and without quotes for
      non-hidden S4 generics.

    * read.table() and relatives treated an "NA" column name as missing
      when check.names = FALSE PR#18007.

    * Parsing strings containing UTF-16 surrogate pairs such as
      "\uD834\uDD1E" works better on some (uncommon) platforms.
      sprintf("%X", utf8ToInt("\uD834\uDD1E")) should now give "1D11E"
      on all platforms.

    * identical(x,y) is no longer true for differing DOTSXP objects,
      fixing PR#18032.

    * str() now works correctly for DOTSXP and related exotics, even
      when these are doomed.

      Additionally, it no longer fails for lists with a class and
      "irregular" method definitions such that e.g. lapply(*) will
      necessarily fail, as currently for different igraph objects.

    * Too long lines in environment files (e.g. Renviron) no longer
      crash R. This limit has been increased to 100,000 bytes.
      (PR#18001.)

    * There is a further workaround for FreeType giving incorrect
      italic font faces with cairo-based graphics devices on macOS.

    * add_datalist(*, force = TRUE) (from package tools) now actually
      updates an existing data/datalist file for new content.  (Thanks
      to a report and patch by Sebastian Meyer in PR#18048.)

    * cut.Date() and cut.POSIXt() could produce an empty last interval
      for breaks = "months" or breaks = "years".  (Reported as PR#18053
      by Christopher Carbone.)

    * Detection of the encoding of 'regular' macOS locales such as
      en_US (which is UTF-8) had been broken by a macOS change:
      fortunately these are now rarely used with en_US.UTF-8 being
      preferred.

    * sub() and gsub(pattern, repl, x, *) now keep attributes of x such
      as names() also when pattern is NA (PR#18079).

    * Time differences ("difftime" objects) get a replacement and a
      rep() method to keep "units" consistent.  (Thanks to a report and
      patch by Nicolas Bennett in PR#18066.)

    * The \RdOpts macro, setting defaults for \Sexpr options in an Rd
      file, had been ineffective since R 2.12.0: it now works again.
      (Thanks to a report and patch by Sebastian Meyer in PR#18073.)

    * mclapply and pvec no longer accidentally terminate parallel
      processes started before by mcparallel or related calls in
      package parallel (PR#18078).

    * grep and other functions for evaluating (extended) regular
      expressions handle in Unicode also strings not explicitly flagged
      UTF-8, but flagged native when running in UTF-8 locale.

    * Fixed a crash in fifo implementation on Windows (PR#18031).

    * Binary mode in fifo on Windows is now properly detected from
      argument open (PR#15600, PR#18031).

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From drj|m|emon @end|ng |rom gm@||@com  Thu May 20 11:19:57 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 20 May 2021 19:19:57 +1000
Subject: [R] Help in modifying code to extract data from url
In-Reply-To: <CAEGXkYUynpgLAZ=Y9tUf0BOB1c9eAQmdrKpgE=tM2FEfP6hpAw@mail.gmail.com>
References: <CAEGXkYUynpgLAZ=Y9tUf0BOB1c9eAQmdrKpgE=tM2FEfP6hpAw@mail.gmail.com>
Message-ID: <CA+8X3fV+mGCYa1naoebsuRknhUKsOrT_joDuihnR=zfzxeGfCA@mail.gmail.com>

Hi Bhaskar,
If you are using read.table or similar, see the "fill=" argument.

Jim

On Thu, May 20, 2021 at 9:54 AM Bhaskar Mitra <bhaskar.kolkata at gmail.com> wrote:
>
> Hello Everyone,
>
> I am trying to extract data from a url. The codes work well when the
> data structure is as follows:
>
> X Y
> 1 2
> 1 5
> 1 6
> 1 7
> 3 4
>
> However, the code fails when the data structure has no number
> under the 2nd column (shown below).I get the following error:
>
> "Error in data.frame(..., check.names = FALSE) :
>   arguments imply differing number of rows: 242, 241"
>
>
> X Y
> 1 2
> 1
> 1
> 1 7
> 3 4
>
> Can anyone please help me in how I can modify the codes ( shown below) to
> adjust for the above mentioned condition
> in the data structure.
>
> library(rjson)
>
> url <- "abcd.com"
> json_data <- fromJSON(file= url)
> d3 <- lapply(json_data[[2]], function(x) c(x["data"]))
> d3 <- do.call(rbind, d3)
> X_Dataframe = as.data.frame(unlist(d3[[1]]))
> b <- do.call("cbind", split(X_Dataframe, rep(c(1, 2), length.out =
> nrow(X_Dataframe))))
>
>
> regards,
> bhaskar
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@hmood@n@der@n @end|ng |rom ugent@be  Thu May 20 11:21:45 2021
From: m@hmood@n@der@n @end|ng |rom ugent@be (Mahmood Naderan-Tahan)
Date: Thu, 20 May 2021 09:21:45 +0000
Subject: [R] Incomplete violin chart representation
Message-ID: <98f02d1ec7e94417a1835a4360c40e57@ugent.be>


Hi

I use the following command to create a violin chart


p <- ggplot(mydata, aes(x=BENCH, y=V))

+ geom_violin(trim=FALSE)

+ geom_dotplot(binaxis='y', stackdir='center', dotsize=0.6)

+ scale_y_continuous(trans = scales::pseudo_log_trans(base = exp(1)))


However, in the output one of them are shown in dots only which is weird https://pasteboard.co/K2KeMZL.png

Any idea about that?



Regards,
Mahmood

	[[alternative HTML version deleted]]


From kev|n@thorpe @end|ng |rom utoronto@c@  Thu May 20 13:38:32 2021
From: kev|n@thorpe @end|ng |rom utoronto@c@ (Kevin Thorpe)
Date: Thu, 20 May 2021 11:38:32 +0000
Subject: [R] Incomplete violin chart representation
In-Reply-To: <98f02d1ec7e94417a1835a4360c40e57@ugent.be>
References: <98f02d1ec7e94417a1835a4360c40e57@ugent.be>
Message-ID: <3A52E583-9023-451D-AFCF-F7C109CDF003@utoronto.ca>

My guess would be there are only 2 observations contributing to that third plot, which is probably not enough to show anything else.

-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016

> On May 20, 2021, at 5:21 AM, Mahmood Naderan-Tahan <mahmood.naderan at ugent.be> wrote:
> 
> EXTERNAL EMAIL:
> 
> Hi
> 
> I use the following command to create a violin chart
> 
> 
> p <- ggplot(mydata, aes(x=BENCH, y=V))
> 
> + geom_violin(trim=FALSE)
> 
> + geom_dotplot(binaxis='y', stackdir='center', dotsize=0.6)
> 
> + scale_y_continuous(trans = scales::pseudo_log_trans(base = exp(1)))
> 
> 
> However, in the output one of them are shown in dots only which is weird https://pasteboard.co/K2KeMZL.png
> 
> Any idea about that?
> 
> 
> 
> Regards,
> Mahmood
> 
>        [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@hmood@n@der@n @end|ng |rom ugent@be  Thu May 20 14:34:24 2021
From: m@hmood@n@der@n @end|ng |rom ugent@be (Mahmood Naderan-Tahan)
Date: Thu, 20 May 2021 12:34:24 +0000
Subject: [R] Incomplete violin chart representation
In-Reply-To: <3A52E583-9023-451D-AFCF-F7C109CDF003@utoronto.ca>
References: <98f02d1ec7e94417a1835a4360c40e57@ugent.be>,
 <3A52E583-9023-451D-AFCF-F7C109CDF003@utoronto.ca>
Message-ID: <bc163e4a9202440a8e85132e97b14b01@ugent.be>

Yes it seems that it need more than 2 points to create the shape.

Thanks


Regards,
Mahmood

________________________________
From: Kevin Thorpe <kevin.thorpe at utoronto.ca>
Sent: Thursday, May 20, 2021 1:38:32 PM
To: Mahmood Naderan-Tahan
Cc: R Help Mailing List
Subject: Re: [R] Incomplete violin chart representation

My guess would be there are only 2 observations contributing to that third plot, which is probably not enough to show anything else.

--
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016

> On May 20, 2021, at 5:21 AM, Mahmood Naderan-Tahan <mahmood.naderan at ugent.be> wrote:
>
> EXTERNAL EMAIL:
>
> Hi
>
> I use the following command to create a violin chart
>
>
> p <- ggplot(mydata, aes(x=BENCH, y=V))
>
> + geom_violin(trim=FALSE)
>
> + geom_dotplot(binaxis='y', stackdir='center', dotsize=0.6)
>
> + scale_y_continuous(trans = scales::pseudo_log_trans(base = exp(1)))
>
>
> However, in the output one of them are shown in dots only which is weird https://pasteboard.co/K2KeMZL.png
>
> Any idea about that?
>
>
>
> Regards,
> Mahmood
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Thu May 20 18:07:16 2021
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Thu, 20 May 2021 18:07:16 +0200
Subject: [R] Error in identifying correlated metrics
Message-ID: <CA+nrPnuhHC5Vjnru9YM2g3DRBagw2twO4EbPj=Tah9HjZZmNeA@mail.gmail.com>

Hello everyone

While I am working to identify the correlated metrics on my data, I am
getting the following error? My data has no missing or Inf values as all
other operations (model training etc) could be done without any errors.

Error in hclust(as.dist(1 - abs(cor(data, method = cor_method))), method =
clust_method) :
  NA/NaN/Inf in foreign function call (arg 10)

	[[alternative HTML version deleted]]


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Thu May 20 19:28:20 2021
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Thu, 20 May 2021 17:28:20 +0000
Subject: [R] Plotting  Coxph model with an interaction.
Message-ID: <MN2PR03MB5167E20D38A3588DD736AABBE22A9@MN2PR03MB5167.namprd03.prod.outlook.com>

Colleagues,

I hope someone can tell me how to plot a cox model that contains an interaction term.

I know that plot(survfit(. . . . )) can be used to plot a Cox model, i.e.. 
coxfit <- coxph(Surv(futime, fustat) ~ age+rx, data = ovarian) 
plot(survfit(fit, newdata=data.frame(age=60,rx=2))) 

but I don't know how to plot a cox model with an interaction, i.e.

coxfit <- coxph(Surv(futime, fustat) ~ age+rx+age*rx, data = ovarian) 
plot(survfit(fit, newdata=data.frame(???????))) 

Thank you,
John

John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)



From bgunter@4567 @end|ng |rom gm@||@com  Thu May 20 21:15:55 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 20 May 2021 12:15:55 -0700
Subject: [R] Plotting Coxph model with an interaction.
In-Reply-To: <MN2PR03MB5167E20D38A3588DD736AABBE22A9@MN2PR03MB5167.namprd03.prod.outlook.com>
References: <MN2PR03MB5167E20D38A3588DD736AABBE22A9@MN2PR03MB5167.namprd03.prod.outlook.com>
Message-ID: <CAGxFJbTgKuM6BF3tJnc9aOLvuVvbQcyKVJghE1hNg3HDrvQbjA@mail.gmail.com>

Perhaps this might be useful:

https://rpubs.com/tf_peterson/interactionplotDemo

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, May 20, 2021 at 10:29 AM Sorkin, John <jsorkin at som.umaryland.edu>
wrote:

> Colleagues,
>
> I hope someone can tell me how to plot a cox model that contains an
> interaction term.
>
> I know that plot(survfit(. . . . )) can be used to plot a Cox model, i.e..
> coxfit <- coxph(Surv(futime, fustat) ~ age+rx, data = ovarian)
> plot(survfit(fit, newdata=data.frame(age=60,rx=2)))
>
> but I don't know how to plot a cox model with an interaction, i.e.
>
> coxfit <- coxph(Surv(futime, fustat) ~ age+rx+age*rx, data = ovarian)
> plot(survfit(fit, newdata=data.frame(???????)))
>
> Thank you,
> John
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de  Fri May 21 07:55:03 2021
From: gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de (Gerrit Eichner)
Date: Fri, 21 May 2021 07:55:03 +0200
Subject: [R] Plotting Coxph model with an interaction.
In-Reply-To: <CAGxFJbTgKuM6BF3tJnc9aOLvuVvbQcyKVJghE1hNg3HDrvQbjA@mail.gmail.com>
References: <MN2PR03MB5167E20D38A3588DD736AABBE22A9@MN2PR03MB5167.namprd03.prod.outlook.com>
 <CAGxFJbTgKuM6BF3tJnc9aOLvuVvbQcyKVJghE1hNg3HDrvQbjA@mail.gmail.com>
Message-ID: <008b2230-d4c6-84c9-1bf7-d2e30f10fd85@math.uni-giessen.de>

Hi, John,

it should work the same way as without interaction (but make sure
to use the fitted object "coxfit", not just "fit" in our call of
survfit, and note that age*rx already expands to age + rx + age:rx
so that age + rx is redundant in your formula):

coxfit <- coxph(Surv(futime, fustat) ~ age+rx+age*rx, data = ovarian)
plot(survfit(coxfit, newdata=data.frame(age=60,rx=2)))

Or do I missunderstand your question?

  Hth  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

Am 20.05.2021 um 21:15 schrieb Bert Gunter:
> Perhaps this might be useful:
> 
> https://rpubs.com/tf_peterson/interactionplotDemo
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Thu, May 20, 2021 at 10:29 AM Sorkin, John <jsorkin at som.umaryland.edu>
> wrote:
> 
>> Colleagues,
>>
>> I hope someone can tell me how to plot a cox model that contains an
>> interaction term.
>>
>> I know that plot(survfit(. . . . )) can be used to plot a Cox model, i.e..
>> coxfit <- coxph(Surv(futime, fustat) ~ age+rx, data = ovarian)
>> plot(survfit(fit, newdata=data.frame(age=60,rx=2)))
>>
>> but I don't know how to plot a cox model with an interaction, i.e.
>>
>> coxfit <- coxph(Surv(futime, fustat) ~ age+rx+age*rx, data = ovarian)
>> plot(survfit(fit, newdata=data.frame(???????)))
>>
>> Thank you,
>> John
>>
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and
>> Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From hwborcher@ @end|ng |rom gm@||@com  Fri May 21 17:03:19 2021
From: hwborcher@ @end|ng |rom gm@||@com (Hans W)
Date: Fri, 21 May 2021 17:03:19 +0200
Subject: [R] Testing optimization solvers with equality constraints
Message-ID: <CAML4n3MWBKg3vzxHN8yWzg=dfyijBvX_SLRZHwP-OetJyXb8Aw@mail.gmail.com>

Just by chance I came across the following example of minimizing
a simple function

    (x,y,z) --> 2 (x^2 - y z)

on the unit sphere, the only constraint present.
I tried it with two starting points, x1 = (1,0,0) and x2 = (0,0,1).

    #-- Problem definition in R
    f = function(x)  2 * (x[1]^2 - x[2]*x[3])   # (x,y,z) |-> 2(x^2 -yz)
    g = function(x)  c(4*x[1], 2*x[3], 2*x[2])  # its gradient

    x0 = c(1, 0, 0); x1 = c(0, 0, 1)            # starting points
    xmin = c(0, 1/sqrt(2), 1/sqrt(2))           # true minimum -1

    heq = function(x)  1-x[1]^2-x[2]^2-x[3]^2   # staying on the sphere
    conf = function(x) {                        # constraint function
        fun = x[1]^2 + x[2]^2 + x[3]^2 - 1
        return(list(ceq = fun, c = NULL))
    }

I tried all the nonlinear optimization solvers in R packages that
allow for equality constraints: 'auglag()' in alabama, 'solnl()' in
NlcOptim, 'auglag()' in nloptr, 'solnp()' in Rsolnp, or even 'donlp2()'
from the Rdonlp2 package (on R-Forge).

None of them worked from both starting points:

    # alabama
    alabama::auglag(x0, fn = f, gr = g, heq = heq)  # right (inaccurate)
    alabama::auglag(x1, fn = f, gr = g, heq = heq)  # wrong

    # NlcOptim
    NlcOptim::solnl(x0, objfun = f, confun = conf)  # wrong
    NlcOptim::solnl(x1, objfun = f, confun = conf)  # right

    # nloptr
    nloptr::auglag(x0, fn = f, heq = heq)           # wrong
    # nloptr::auglag(x1, fn = f, heq = heq)         # not returning

    # Rsolnp
    Rsolnp::solnp(x0, fun = f, eqfun = heq)         # wrong
    Rsolnp::solnp(x1, fun = f, eqfun = heq)         # wrong

    # Rdonlp2
    Rdonlp2::donlp2(x0, fn = f, nlin = list(heq),   # wrong
           nlin.lower = 0, nlin.upper = 0)
    Rdonlp2::donlp2(x1, fn = f, nlin = list(heq),   # right
           nlin.lower = 0, nlin.upper = 0)          # (fast and exact)

The problem with starting point x0 appears to be that the gradient at
that point, projected onto the unit sphere, is zero. Only alabama is
able to handle this somehow.

I do not know what problem most solvers have with starting point x1.
The fact that Rdonlp2 is the fastest and most accurate is no surprise.

If anyone with more experience with one or more of these packages can
give a hint of what I made wrong, or how to change calling the solver
to make it run correctly, please let me know.

Thanks  -- HW


From m@rk|eed@2 @end|ng |rom gm@||@com  Fri May 21 17:58:03 2021
From: m@rk|eed@2 @end|ng |rom gm@||@com (Mark Leeds)
Date: Fri, 21 May 2021 11:58:03 -0400
Subject: [R] Testing optimization solvers with equality constraints
In-Reply-To: <CAML4n3MWBKg3vzxHN8yWzg=dfyijBvX_SLRZHwP-OetJyXb8Aw@mail.gmail.com>
References: <CAML4n3MWBKg3vzxHN8yWzg=dfyijBvX_SLRZHwP-OetJyXb8Aw@mail.gmail.com>
Message-ID: <CAHz+bWZy9w0fyODfgLM8vaR6yKAB6B8q6BcrjG43O3dnewJcbQ@mail.gmail.com>

Hi Hans: I think  that you are missing minus signs in the 2nd and 3rd
elements of your gradient.
Also, I don't know how all of the optimixation functions work as far as
their arguments but it's best to supply
the gradient when possible. I hope it helps.






On Fri, May 21, 2021 at 11:01 AM Hans W <hwborchers at gmail.com> wrote:

> Just by chance I came across the following example of minimizing
> a simple function
>
>     (x,y,z) --> 2 (x^2 - y z)
>
> on the unit sphere, the only constraint present.
> I tried it with two starting points, x1 = (1,0,0) and x2 = (0,0,1).
>
>     #-- Problem definition in R
>     f = function(x)  2 * (x[1]^2 - x[2]*x[3])   # (x,y,z) |-> 2(x^2 -yz)
>     g = function(x)  c(4*x[1], 2*x[3], 2*x[2])  # its gradient
>
>     x0 = c(1, 0, 0); x1 = c(0, 0, 1)            # starting points
>     xmin = c(0, 1/sqrt(2), 1/sqrt(2))           # true minimum -1
>
>     heq = function(x)  1-x[1]^2-x[2]^2-x[3]^2   # staying on the sphere
>     conf = function(x) {                        # constraint function
>         fun = x[1]^2 + x[2]^2 + x[3]^2 - 1
>         return(list(ceq = fun, c = NULL))
>     }
>
> I tried all the nonlinear optimization solvers in R packages that
> allow for equality constraints: 'auglag()' in alabama, 'solnl()' in
> NlcOptim, 'auglag()' in nloptr, 'solnp()' in Rsolnp, or even 'donlp2()'
> from the Rdonlp2 package (on R-Forge).
>
> None of them worked from both starting points:
>
>     # alabama
>     alabama::auglag(x0, fn = f, gr = g, heq = heq)  # right (inaccurate)
>     alabama::auglag(x1, fn = f, gr = g, heq = heq)  # wrong
>
>     # NlcOptim
>     NlcOptim::solnl(x0, objfun = f, confun = conf)  # wrong
>     NlcOptim::solnl(x1, objfun = f, confun = conf)  # right
>
>     # nloptr
>     nloptr::auglag(x0, fn = f, heq = heq)           # wrong
>     # nloptr::auglag(x1, fn = f, heq = heq)         # not returning
>
>     # Rsolnp
>     Rsolnp::solnp(x0, fun = f, eqfun = heq)         # wrong
>     Rsolnp::solnp(x1, fun = f, eqfun = heq)         # wrong
>
>     # Rdonlp2
>     Rdonlp2::donlp2(x0, fn = f, nlin = list(heq),   # wrong
>            nlin.lower = 0, nlin.upper = 0)
>     Rdonlp2::donlp2(x1, fn = f, nlin = list(heq),   # right
>            nlin.lower = 0, nlin.upper = 0)          # (fast and exact)
>
> The problem with starting point x0 appears to be that the gradient at
> that point, projected onto the unit sphere, is zero. Only alabama is
> able to handle this somehow.
>
> I do not know what problem most solvers have with starting point x1.
> The fact that Rdonlp2 is the fastest and most accurate is no surprise.
>
> If anyone with more experience with one or more of these packages can
> give a hint of what I made wrong, or how to change calling the solver
> to make it run correctly, please let me know.
>
> Thanks  -- HW
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From hwborcher@ @end|ng |rom gm@||@com  Fri May 21 20:08:19 2021
From: hwborcher@ @end|ng |rom gm@||@com (Hans W)
Date: Fri, 21 May 2021 20:08:19 +0200
Subject: [R] Testing optimization solvers with equality constraints
In-Reply-To: <CAHz+bWZy9w0fyODfgLM8vaR6yKAB6B8q6BcrjG43O3dnewJcbQ@mail.gmail.com>
References: <CAML4n3MWBKg3vzxHN8yWzg=dfyijBvX_SLRZHwP-OetJyXb8Aw@mail.gmail.com>
 <CAHz+bWZy9w0fyODfgLM8vaR6yKAB6B8q6BcrjG43O3dnewJcbQ@mail.gmail.com>
Message-ID: <CAML4n3OKiZKpPdiRMbxxF27LTavF=ZS88rJpLE+BrxmdzBoqJQ@mail.gmail.com>

Mark, you're right, and it's a bit embarrassing as I thought I had
looked at it closely enough.

This solves the problem for 'alabama::auglag()' in both cases, but NOT for

  * NlcOptim::solnl     -- with x0
  * nloptr::auglag      -- both x0, x1
  * Rsolnp::solnp       -- with x0
  * Rdonlp::donlp2      -- with x0

as for these solver calls the gradient function g was *not* used.

Actually, 'solnl()' and 'solnp()' do not allow a gradient argument,
'nloptr::auglag()' says it does not use a supplied gradient, and
'donlp2' again does not provide it.
Gradients, if needed, are computed internally which in most cases is
sufficient, anyway.

So the question remains:
Is the fact that the projection of the gradient onto the constraint is
zero, is this the reason for the solvers not finding the minimum?

And how to avoid this? Except, maybe, checking the gradient for all
the given constraints

Thanks  --HW



On Fri, 21 May 2021 at 17:58, Mark Leeds <markleeds2 at gmail.com> wrote:
>
> Hi Hans: I think  that you are missing minus signs in the 2nd and 3rd elements of your gradient.
> Also, I don't know how all of the optimixation functions work as far as their arguments but it's best to supply
> the gradient when possible. I hope it helps.
>


From m@rk|eed@2 @end|ng |rom gm@||@com  Fri May 21 21:31:08 2021
From: m@rk|eed@2 @end|ng |rom gm@||@com (Mark Leeds)
Date: Fri, 21 May 2021 15:31:08 -0400
Subject: [R] Testing optimization solvers with equality constraints
In-Reply-To: <CAML4n3OKiZKpPdiRMbxxF27LTavF=ZS88rJpLE+BrxmdzBoqJQ@mail.gmail.com>
References: <CAML4n3MWBKg3vzxHN8yWzg=dfyijBvX_SLRZHwP-OetJyXb8Aw@mail.gmail.com>
 <CAHz+bWZy9w0fyODfgLM8vaR6yKAB6B8q6BcrjG43O3dnewJcbQ@mail.gmail.com>
 <CAML4n3OKiZKpPdiRMbxxF27LTavF=ZS88rJpLE+BrxmdzBoqJQ@mail.gmail.com>
Message-ID: <CAHz+bWb0h-V6fRsZHg1e3JdkW1e+PO3N9kkFVaUDozBCNKjm8w@mail.gmail.com>

Hi Hans: I can't help as far as the projection of the gradient onto the
constraint but it may give insight just to see what the value of
the gradient itself is when the optimization stops.

John Nash ( definitely one of THE expeRts when it comes to optimization in
R )
often strongly recommends  to supply gradients so I'm   not sure what those
functions are
doing that don't allow it as an argument. I guess some numerical
approximation.

Hopefully John or Ravi will chime in with their expertise when they see
this posting.


Mark

P.S: You may want to try Rvminb. John wrote that one and it allows for
constraints ( I remember it
working nicely  for me when I had problems with some other ones but I don't
remember which ones ) but
I'm not certain  whether it can handle equalities.






On Fri, May 21, 2021 at 2:06 PM Hans W <hwborchers at gmail.com> wrote:

> Mark, you're right, and it's a bit embarrassing as I thought I had
> looked at it closely enough.
>
> This solves the problem for 'alabama::auglag()' in both cases, but NOT for
>
>   * NlcOptim::solnl     -- with x0
>   * nloptr::auglag      -- both x0, x1
>   * Rsolnp::solnp       -- with x0
>   * Rdonlp::donlp2      -- with x0
>
> as for these solver calls the gradient function g was *not* used.
>
> Actually, 'solnl()' and 'solnp()' do not allow a gradient argument,
> 'nloptr::auglag()' says it does not use a supplied gradient, and
> 'donlp2' again does not provide it.
> Gradients, if needed, are computed internally which in most cases is
> sufficient, anyway.
>
> So the question remains:
> Is the fact that the projection of the gradient onto the constraint is
> zero, is this the reason for the solvers not finding the minimum?
>
> And how to avoid this? Except, maybe, checking the gradient for all
> the given constraints
>
> Thanks  --HW
>
>
>
> On Fri, 21 May 2021 at 17:58, Mark Leeds <markleeds2 at gmail.com> wrote:
> >
> > Hi Hans: I think  that you are missing minus signs in the 2nd and 3rd
> elements of your gradient.
> > Also, I don't know how all of the optimixation functions work as far as
> their arguments but it's best to supply
> > the gradient when possible. I hope it helps.
> >
>

	[[alternative HTML version deleted]]


From pro|jcn@@h @end|ng |rom gm@||@com  Sat May 22 03:55:24 2021
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Fri, 21 May 2021 21:55:24 -0400
Subject: [R] Testing optimization solvers with equality constraints
In-Reply-To: <CAHz+bWb0h-V6fRsZHg1e3JdkW1e+PO3N9kkFVaUDozBCNKjm8w@mail.gmail.com>
References: <CAML4n3MWBKg3vzxHN8yWzg=dfyijBvX_SLRZHwP-OetJyXb8Aw@mail.gmail.com>
 <CAHz+bWZy9w0fyODfgLM8vaR6yKAB6B8q6BcrjG43O3dnewJcbQ@mail.gmail.com>
 <CAML4n3OKiZKpPdiRMbxxF27LTavF=ZS88rJpLE+BrxmdzBoqJQ@mail.gmail.com>
 <CAHz+bWb0h-V6fRsZHg1e3JdkW1e+PO3N9kkFVaUDozBCNKjm8w@mail.gmail.com>
Message-ID: <a4168b77-9fbe-8a73-4f59-9b1786264178@gmail.com>

I might (and that could be a stretch) be expert in unconstrained problems,
but I've nowhere near HWB's experience in constrained ones.

My main reason for wanting gradients is to know when I'm at a solution.
In practice for getting to the solution, I've often found secant methods
work faster, though that is not universal nor even "mostly", but more
frequently than my intuition suggests.

Best, JN

On 2021-05-21 3:31 p.m., Mark Leeds wrote:
> Hi Hans: I can't help as far as the projection of the gradient onto the
> constraint but it may give insight just to see what the value of
> the gradient itself is when the optimization stops.
> 
> John Nash ( definitely one of THE expeRts when it comes to optimization in
> R )
> often strongly recommends  to supply gradients so I'm   not sure what those
> functions are
> doing that don't allow it as an argument. I guess some numerical
> approximation.
> 
> Hopefully John or Ravi will chime in with their expertise when they see
> this posting.
> 
> 
> Mark
> 
> P.S: You may want to try Rvminb. John wrote that one and it allows for
> constraints ( I remember it
> working nicely  for me when I had problems with some other ones but I don't
> remember which ones ) but
> I'm not certain  whether it can handle equalities.
> 
> 
> 
> 
> 
> 
> On Fri, May 21, 2021 at 2:06 PM Hans W <hwborchers at gmail.com> wrote:
> 
>> Mark, you're right, and it's a bit embarrassing as I thought I had
>> looked at it closely enough.
>>
>> This solves the problem for 'alabama::auglag()' in both cases, but NOT for
>>
>>   * NlcOptim::solnl     -- with x0
>>   * nloptr::auglag      -- both x0, x1
>>   * Rsolnp::solnp       -- with x0
>>   * Rdonlp::donlp2      -- with x0
>>
>> as for these solver calls the gradient function g was *not* used.
>>
>> Actually, 'solnl()' and 'solnp()' do not allow a gradient argument,
>> 'nloptr::auglag()' says it does not use a supplied gradient, and
>> 'donlp2' again does not provide it.
>> Gradients, if needed, are computed internally which in most cases is
>> sufficient, anyway.
>>
>> So the question remains:
>> Is the fact that the projection of the gradient onto the constraint is
>> zero, is this the reason for the solvers not finding the minimum?
>>
>> And how to avoid this? Except, maybe, checking the gradient for all
>> the given constraints
>>
>> Thanks  --HW
>>
>>
>>
>> On Fri, 21 May 2021 at 17:58, Mark Leeds <markleeds2 at gmail.com> wrote:
>>>
>>> Hi Hans: I think  that you are missing minus signs in the 2nd and 3rd
>> elements of your gradient.
>>> Also, I don't know how all of the optimixation functions work as far as
>> their arguments but it's best to supply
>>> the gradient when possible. I hope it helps.
>>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @purd|e@@ @end|ng |rom gm@||@com  Sat May 22 09:42:49 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sat, 22 May 2021 19:42:49 +1200
Subject: [R] Testing optimization solvers with equality constraints
In-Reply-To: <CAML4n3MWBKg3vzxHN8yWzg=dfyijBvX_SLRZHwP-OetJyXb8Aw@mail.gmail.com>
References: <CAML4n3MWBKg3vzxHN8yWzg=dfyijBvX_SLRZHwP-OetJyXb8Aw@mail.gmail.com>
Message-ID: <CAB8pepznXQuvLwN6ZYFiyVXqZofwbdwc76vvUYjxNu7qufG3_A@mail.gmail.com>

Sorry, this might sound like a poor question:
But by "on the unit sphere", do you mean on the ***surface*** of the sphere?

In which case, can't the surface of a sphere be projected onto a pair
of circles?
Where the cost function is reformulated as a function of two (rather
than three) variables.


On Sat, May 22, 2021 at 3:01 AM Hans W <hwborchers at gmail.com> wrote:
>
> Just by chance I came across the following example of minimizing
> a simple function
>
>     (x,y,z) --> 2 (x^2 - y z)
>
> on the unit sphere, the only constraint present.
> I tried it with two starting points, x1 = (1,0,0) and x2 = (0,0,1).
>
>     #-- Problem definition in R
>     f = function(x)  2 * (x[1]^2 - x[2]*x[3])   # (x,y,z) |-> 2(x^2 -yz)
>     g = function(x)  c(4*x[1], 2*x[3], 2*x[2])  # its gradient
>
>     x0 = c(1, 0, 0); x1 = c(0, 0, 1)            # starting points
>     xmin = c(0, 1/sqrt(2), 1/sqrt(2))           # true minimum -1
>
>     heq = function(x)  1-x[1]^2-x[2]^2-x[3]^2   # staying on the sphere
>     conf = function(x) {                        # constraint function
>         fun = x[1]^2 + x[2]^2 + x[3]^2 - 1
>         return(list(ceq = fun, c = NULL))
>     }
>
> I tried all the nonlinear optimization solvers in R packages that
> allow for equality constraints: 'auglag()' in alabama, 'solnl()' in
> NlcOptim, 'auglag()' in nloptr, 'solnp()' in Rsolnp, or even 'donlp2()'
> from the Rdonlp2 package (on R-Forge).
>
> None of them worked from both starting points:
>
>     # alabama
>     alabama::auglag(x0, fn = f, gr = g, heq = heq)  # right (inaccurate)
>     alabama::auglag(x1, fn = f, gr = g, heq = heq)  # wrong
>
>     # NlcOptim
>     NlcOptim::solnl(x0, objfun = f, confun = conf)  # wrong
>     NlcOptim::solnl(x1, objfun = f, confun = conf)  # right
>
>     # nloptr
>     nloptr::auglag(x0, fn = f, heq = heq)           # wrong
>     # nloptr::auglag(x1, fn = f, heq = heq)         # not returning
>
>     # Rsolnp
>     Rsolnp::solnp(x0, fun = f, eqfun = heq)         # wrong
>     Rsolnp::solnp(x1, fun = f, eqfun = heq)         # wrong
>
>     # Rdonlp2
>     Rdonlp2::donlp2(x0, fn = f, nlin = list(heq),   # wrong
>            nlin.lower = 0, nlin.upper = 0)
>     Rdonlp2::donlp2(x1, fn = f, nlin = list(heq),   # right
>            nlin.lower = 0, nlin.upper = 0)          # (fast and exact)
>
> The problem with starting point x0 appears to be that the gradient at
> that point, projected onto the unit sphere, is zero. Only alabama is
> able to handle this somehow.
>
> I do not know what problem most solvers have with starting point x1.
> The fact that Rdonlp2 is the fastest and most accurate is no surprise.
>
> If anyone with more experience with one or more of these packages can
> give a hint of what I made wrong, or how to change calling the solver
> to make it run correctly, please let me know.
>
> Thanks  -- HW
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hwborcher@ @end|ng |rom gm@||@com  Sat May 22 10:04:52 2021
From: hwborcher@ @end|ng |rom gm@||@com (Hans W)
Date: Sat, 22 May 2021 10:04:52 +0200
Subject: [R] Testing optimization solvers with equality constraints
In-Reply-To: <CAB8pepznXQuvLwN6ZYFiyVXqZofwbdwc76vvUYjxNu7qufG3_A@mail.gmail.com>
References: <CAML4n3MWBKg3vzxHN8yWzg=dfyijBvX_SLRZHwP-OetJyXb8Aw@mail.gmail.com>
 <CAB8pepznXQuvLwN6ZYFiyVXqZofwbdwc76vvUYjxNu7qufG3_A@mail.gmail.com>
Message-ID: <CAML4n3PgQaMt6aACjJRC+Bi5f98fnzLMH1CpdV5P3EpPYH58Xg@mail.gmail.com>

Yes. "*on* the unit sphere" means on the surface, as you can guess
from the equality constraint. And 'auglag()' does find the minimum, so
no need for a special approach.

I was/am interested in why all these other good solvers get stuck,
i.e., do not move away from the starting point. And how to avoid this
in general, not only for this specific example.


On Sat, 22 May 2021 at 09:44, Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> Sorry, this might sound like a poor question:
> But by "on the unit sphere", do you mean on the ***surface*** of the sphere?
> In which case, can't the surface of a sphere be projected onto a pair
> of circles?
> Where the cost function is reformulated as a function of two (rather
> than three) variables.
>


From vdem@rt @end|ng |rom gm@||@com  Sat May 22 11:47:23 2021
From: vdem@rt @end|ng |rom gm@||@com (Victor)
Date: Sat, 22 May 2021 11:47:23 +0200
Subject: [R] Ubuntu hirsute unable to receive the key to add the repository
Message-ID: <3e6fd5e8-3850-a84e-7951-81fec04608c0@gmail.com>

I followed the procedure indicated in https://cran.mirror.garr.it/CRAN/ 
step by step to? install R under ubuntu 21.04 hirsute but? the apt-key 
command failed:

vr at ubuntu:~$ apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 
E298A3A825C0D65DFD57CBB651716619E084DAB9
Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d 
instead (see apt-key(8)).
Executing: /tmp/apt-key-gpghome.gHJAZ9lYF3/gpg.1.sh --keyserver 
keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9
gpg: ricezione dal server di chiavi non riuscita: Server indicated a failure

Please help to solve this problem.

Ciao

Vittorio


	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Sat May 22 12:20:51 2021
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Sat, 22 May 2021 22:20:51 +1200
Subject: [R] Help in modifying code to extract data from url
In-Reply-To: <CAEGXkYUynpgLAZ=Y9tUf0BOB1c9eAQmdrKpgE=tM2FEfP6hpAw@mail.gmail.com>
References: <CAEGXkYUynpgLAZ=Y9tUf0BOB1c9eAQmdrKpgE=tM2FEfP6hpAw@mail.gmail.com>
Message-ID: <CABcYAdK9J0ZJx89KmppQMLgMaMx2FLzRNSgWQv888FrsMen_iA@mail.gmail.com>

The source being a URL is not important.
The important things are
 - what the structure of the JSON data is
 - what the MEANING of the JSON data is
 - what that meaning says about what SHOULD appear in the data
   from in these cases.
Arguably this isn't even an R question at all.  It's a question about your
data.
Since you have replaced the actual URL with a dummy (example.com is the
traditional
never-to-be-in-use host name), we cannot even guess these things by looking
at the
data ourselves.


On Thu, 20 May 2021 at 11:54, Bhaskar Mitra <bhaskar.kolkata at gmail.com>
wrote:

> Hello Everyone,
>
> I am trying to extract data from a url. The codes work well when the
> data structure is as follows:
>
> X Y
> 1 2
> 1 5
> 1 6
> 1 7
> 3 4
>
> However, the code fails when the data structure has no number
> under the 2nd column (shown below).I get the following error:
>
> "Error in data.frame(..., check.names = FALSE) :
>   arguments imply differing number of rows: 242, 241"
>
>
> X Y
> 1 2
> 1
> 1
> 1 7
> 3 4
>
> Can anyone please help me in how I can modify the codes ( shown below) to
> adjust for the above mentioned condition
> in the data structure.
>
> library(rjson)
>
> url <- "abcd.com"
> json_data <- fromJSON(file= url)
> d3 <- lapply(json_data[[2]], function(x) c(x["data"]))
> d3 <- do.call(rbind, d3)
> X_Dataframe = as.data.frame(unlist(d3[[1]]))
> b <- do.call("cbind", split(X_Dataframe, rep(c(1, 2), length.out =
> nrow(X_Dataframe))))
>
>
> regards,
> bhaskar
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Sat May 22 13:14:32 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sat, 22 May 2021 14:14:32 +0300
Subject: [R] 
 Ubuntu hirsute unable to receive the key to add the repository
In-Reply-To: <3e6fd5e8-3850-a84e-7951-81fec04608c0@gmail.com>
References: <3e6fd5e8-3850-a84e-7951-81fec04608c0@gmail.com>
Message-ID: <CAGgJW77U1p3ujeU+kwLP8J__VDfoeUPPGzEjTST+-QETVypX5Q@mail.gmail.com>

Hi Victor,
This issue has been raised in earlier entries in this list. I have not dug
into it myself but the following link was posted as being helpful.

https://askubuntu.com/questions/1286545/what-commands-exactly-should-replace-the-deprecated-apt-key/1307181#1307181

HTH,
Eric


On Sat, May 22, 2021 at 12:47 PM Victor <vdemart at gmail.com> wrote:

> I followed the procedure indicated in https://cran.mirror.garr.it/CRAN/
> step by step to  install R under ubuntu 21.04 hirsute but  the apt-key
> command failed:
>
> vr at ubuntu:~$ apt-key adv --keyserver keyserver.ubuntu.com --recv-keys
> E298A3A825C0D65DFD57CBB651716619E084DAB9
> Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d
> instead (see apt-key(8)).
> Executing: /tmp/apt-key-gpghome.gHJAZ9lYF3/gpg.1.sh --keyserver
> keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9
> gpg: ricezione dal server di chiavi non riuscita: Server indicated a
> failure
>
> Please help to solve this problem.
>
> Ciao
>
> Vittorio
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Sat May 22 20:56:11 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sat, 22 May 2021 11:56:11 -0700
Subject: [R] Help in modifying code to extract data from url
In-Reply-To: <CA+8X3fV+mGCYa1naoebsuRknhUKsOrT_joDuihnR=zfzxeGfCA@mail.gmail.com>
References: <CAEGXkYUynpgLAZ=Y9tUf0BOB1c9eAQmdrKpgE=tM2FEfP6hpAw@mail.gmail.com>
 <CA+8X3fV+mGCYa1naoebsuRknhUKsOrT_joDuihnR=zfzxeGfCA@mail.gmail.com>
Message-ID: <29bb1bc4-be95-b9c6-4a41-bcb5dbee3b87@comcast.net>

Several authors hav addressed this problem with names that resemble 
"rbindfill". In my machine I find four instances:

??rbindfill

Help pages:
ffbase::ffdfrbind.fill??? ??? rbind for ffdf where missing columns are 
added if not available in one of the ffdf objects
plyr::rbind.fill??? ??? Combine data.frames by row, filling in missing 
columns.
plyr::rbind.fill.matrix??? ??? Bind matrices by row, and fill missing 
columns with NA.
rockchalk::rbindFill??? ??? Stack together data frames


-- 

David.

On 5/20/21 2:19 AM, Jim Lemon wrote:
> Hi Bhaskar,
> If you are using read.table or similar, see the "fill=" argument.
>
> Jim
>
> On Thu, May 20, 2021 at 9:54 AM Bhaskar Mitra <bhaskar.kolkata at gmail.com> wrote:
>> Hello Everyone,
>>
>> I am trying to extract data from a url. The codes work well when the
>> data structure is as follows:
>>
>> X Y
>> 1 2
>> 1 5
>> 1 6
>> 1 7
>> 3 4
>>
>> However, the code fails when the data structure has no number
>> under the 2nd column (shown below).I get the following error:
>>
>> "Error in data.frame(..., check.names = FALSE) :
>>    arguments imply differing number of rows: 242, 241"
>>
>>
>> X Y
>> 1 2
>> 1
>> 1
>> 1 7
>> 3 4
>>
>> Can anyone please help me in how I can modify the codes ( shown below) to
>> adjust for the above mentioned condition
>> in the data structure.
>>
>> library(rjson)
>>
>> url <- "abcd.com"
>> json_data <- fromJSON(file= url)
>> d3 <- lapply(json_data[[2]], function(x) c(x["data"]))
>> d3 <- do.call(rbind, d3)
>> X_Dataframe = as.data.frame(unlist(d3[[1]]))
>> b <- do.call("cbind", split(X_Dataframe, rep(c(1, 2), length.out =
>> nrow(X_Dataframe))))
>>
>>
>> regards,
>> bhaskar
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun May 23 02:26:17 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 22 May 2021 17:26:17 -0700
Subject: [R] Pipe precedence
Message-ID: <1297E371-2781-420B-A1D2-21B3B8600F20@dcn.davis.ca.us>

What is the precedence of the new |> pipe operator? I don't see it mentioned in ?Syntax, nor does it come up when I search the R Language Definition document.
-- 
Sent from my phone. Please excuse my brevity.


From b|oprogr@mmer @end|ng |rom gm@||@com  Sun May 23 05:07:27 2021
From: b|oprogr@mmer @end|ng |rom gm@||@com (Caitlin Gibbons)
Date: Sat, 22 May 2021 20:07:27 -0700
Subject: [R] Pipe precedence
In-Reply-To: <1297E371-2781-420B-A1D2-21B3B8600F20@dcn.davis.ca.us>
References: <1297E371-2781-420B-A1D2-21B3B8600F20@dcn.davis.ca.us>
Message-ID: <EC35A1B1-5CB9-479C-A193-5FCB313AFC2A@gmail.com>

I didn?t know R had a new pipe operator, but I have seen ?|>? (without quotes) used in the Elixir language though. Are there now two? ?%>%? from the magrittr package and ?|>? which is built-in?

> On May 22, 2021, at 5:26 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> ?What is the precedence of the new |> pipe operator? I don't see it mentioned in ?Syntax, nor does it come up when I search the R Language Definition document.
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From er|cjberger @end|ng |rom gm@||@com  Sun May 23 05:15:15 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sun, 23 May 2021 06:15:15 +0300
Subject: [R] Pipe precedence
In-Reply-To: <EC35A1B1-5CB9-479C-A193-5FCB313AFC2A@gmail.com>
References: <1297E371-2781-420B-A1D2-21B3B8600F20@dcn.davis.ca.us>
 <EC35A1B1-5CB9-479C-A193-5FCB313AFC2A@gmail.com>
Message-ID: <CAGgJW74BY_8Ji_UzDjU4fhTVyav898nNXupSCn3BFtXRFUvgPw@mail.gmail.com>

This is part of the R-4.1.0 release which came out a few days ago.
See
1. https://stat.ethz.ch/pipermail/r-announce/2021/000670.html
2.
https://www.jumpingrivers.com/blog/new-features-r410-pipe-anonymous-functions/
3.
https://community.rstudio.com/t/psa-r-4-1-0-release-requires-rstudio-preview/105209

Eric


On Sun, May 23, 2021 at 6:07 AM Caitlin Gibbons <bioprogrammer at gmail.com>
wrote:

> I didn?t know R had a new pipe operator, but I have seen ?|>? (without
> quotes) used in the Elixir language though. Are there now two? ?%>%? from
> the magrittr package and ?|>? which is built-in?
>
> > On May 22, 2021, at 5:26 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> >
> > ?What is the precedence of the new |> pipe operator? I don't see it
> mentioned in ?Syntax, nor does it come up when I search the R Language
> Definition document.
> > --
> > Sent from my phone. Please excuse my brevity.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun May 23 05:42:28 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 22 May 2021 20:42:28 -0700
Subject: [R] Pipe precedence
In-Reply-To: <EC35A1B1-5CB9-479C-A193-5FCB313AFC2A@gmail.com>
References: <1297E371-2781-420B-A1D2-21B3B8600F20@dcn.davis.ca.us>
 <EC35A1B1-5CB9-479C-A193-5FCB313AFC2A@gmail.com>
Message-ID: <FED20CEB-7124-4886-9EDC-6FFDD0F274EB@dcn.davis.ca.us>

R 4.1.0 was released this week with a new pipe operator and a new anonymous function shorthand (\(x) x^2).

The pipe operator is not quite as flexible as the magrittr pipe, but it is faster (not that the magrittr pipe is noticably slow) and built-in.

On May 22, 2021 8:07:27 PM PDT, Caitlin Gibbons <bioprogrammer at gmail.com> wrote:
>I didn?t know R had a new pipe operator, but I have seen ?|>? (without
>quotes) used in the Elixir language though. Are there now two? ?%>%?
>from the magrittr package and ?|>? which is built-in?
>
>> On May 22, 2021, at 5:26 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>> 
>> ?What is the precedence of the new |> pipe operator? I don't see it
>mentioned in ?Syntax, nor does it come up when I search the R Language
>Definition document.
>> -- 
>> Sent from my phone. Please excuse my brevity.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @purd|e@@ @end|ng |rom gm@||@com  Sun May 23 07:25:47 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sun, 23 May 2021 17:25:47 +1200
Subject: [R] Testing optimization solvers with equality constraints
In-Reply-To: <CAML4n3PgQaMt6aACjJRC+Bi5f98fnzLMH1CpdV5P3EpPYH58Xg@mail.gmail.com>
References: <CAML4n3MWBKg3vzxHN8yWzg=dfyijBvX_SLRZHwP-OetJyXb8Aw@mail.gmail.com>
 <CAB8pepznXQuvLwN6ZYFiyVXqZofwbdwc76vvUYjxNu7qufG3_A@mail.gmail.com>
 <CAML4n3PgQaMt6aACjJRC+Bi5f98fnzLMH1CpdV5P3EpPYH58Xg@mail.gmail.com>
Message-ID: <CAB8pepxD2spsGRx0nLTGBJEE-aWjceowxtRC_OPY1gfw5rKs+Q@mail.gmail.com>

For a start, there's two local minima.

Add to that floating point errors.
And possible assumptions by the package authors.

----begin code----
f <- function (x, y, sign)
{   unsign.z <- sqrt (1 - x^2 - y^2)
    2 * (x^2 - sign * y * unsign.z)
}

north.f <- function (x, y) f (x, y, +1)
south.f <- function (x, y) f (x, y, -1)

N <- 100
p0 <- par (mfrow = c (1, 2) )
plotf_cfield (north.f, c (-1.1, 1.1),
    main="north",
    ncontours=10, n=N, raster=TRUE, hcv=TRUE)
plotf_cfield (south.f, c (-1.1, 1.1),
    main="south",
    ncontours=10, n=N, raster=TRUE, hcv=TRUE)
par (p0)
----end code ----

Please ignore R warnings.
I'm planning to reinvent this package soon.
And also, it wasn't designed for circular heatmaps.


On Sat, May 22, 2021 at 8:02 PM Hans W <hwborchers at gmail.com> wrote:
>
> Yes. "*on* the unit sphere" means on the surface, as you can guess
> from the equality constraint. And 'auglag()' does find the minimum, so
> no need for a special approach.
>
> I was/am interested in why all these other good solvers get stuck,
> i.e., do not move away from the starting point. And how to avoid this
> in general, not only for this specific example.
>
>
> On Sat, 22 May 2021 at 09:44, Abby Spurdle <spurdle.a at gmail.com> wrote:
> >
> > Sorry, this might sound like a poor question:
> > But by "on the unit sphere", do you mean on the ***surface*** of the sphere?
> > In which case, can't the surface of a sphere be projected onto a pair
> > of circles?
> > Where the cost function is reformulated as a function of two (rather
> > than three) variables.
> >

-------------- next part --------------
A non-text attachment was scrubbed...
Name: opt_sphere.png
Type: image/png
Size: 37702 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210523/d243b26a/attachment.png>

From @purd|e@@ @end|ng |rom gm@||@com  Sun May 23 07:38:25 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sun, 23 May 2021 17:38:25 +1200
Subject: [R] Testing optimization solvers with equality constraints
In-Reply-To: <CAB8pepxD2spsGRx0nLTGBJEE-aWjceowxtRC_OPY1gfw5rKs+Q@mail.gmail.com>
References: <CAML4n3MWBKg3vzxHN8yWzg=dfyijBvX_SLRZHwP-OetJyXb8Aw@mail.gmail.com>
 <CAB8pepznXQuvLwN6ZYFiyVXqZofwbdwc76vvUYjxNu7qufG3_A@mail.gmail.com>
 <CAML4n3PgQaMt6aACjJRC+Bi5f98fnzLMH1CpdV5P3EpPYH58Xg@mail.gmail.com>
 <CAB8pepxD2spsGRx0nLTGBJEE-aWjceowxtRC_OPY1gfw5rKs+Q@mail.gmail.com>
Message-ID: <CAB8pepxtv-RixPe9SsCGAnudLj3QVaAHsXh0eFgdNP+PnMPB1Q@mail.gmail.com>

Sorry, missed the top line of code.
library (barsurf)


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun May 23 11:34:27 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 23 May 2021 05:34:27 -0400
Subject: [R] Pipe precedence
In-Reply-To: <1297E371-2781-420B-A1D2-21B3B8600F20@dcn.davis.ca.us>
References: <1297E371-2781-420B-A1D2-21B3B8600F20@dcn.davis.ca.us>
Message-ID: <e2029c21-6f2a-db77-cc6c-f09e8edf6193@gmail.com>

On 22/05/2021 8:26 p.m., Jeff Newmiller wrote:
> What is the precedence of the new |> pipe operator? I don't see it mentioned in ?Syntax, nor does it come up when I search the R Language Definition document.
> 

It's the same precedence as the %any% operators listed in the ?Syntax 
table, so it matches the magrittr pipe priority.  You can see this in 
the source if you know how to read Bison, or determine it experimentally:

 > 2 * 3 |> print()
[1] 3
[1] 6

This is the same result as

2 * ( 3 |> print() )

so it has higher priority than * .

On the other hand,

 > 2 : 3 |> print()
[1] 2 3

is the same as

( 2 : 3 ) |> print()

so it has lower priority than : .

A difference with the magrittr operator is in debugging.  If an error 
happens in the middle of a pipe, I find the traceback a little easier to 
understand with the built-in pipe:

 > 2 |> print() |> stop() |> mean()
[1] 2
Error in mean(stop(print(2))) : 2
 > traceback()
2: stop(print(2))
1: mean(stop(print(2)))

versus

 > 2 %>% print() %>% stop() %>% mean()
[1] 2
Error in mean(.) : 2
 > traceback()
3: stop(.)
2: mean(.)
1: 2 %>% print() %>% stop() %>% mean()

Duncan Murdoch


From ne@py@n|thche@ @end|ng |rom gm@||@com  Sun May 23 18:27:17 2021
From: ne@py@n|thche@ @end|ng |rom gm@||@com (Neapyanith Chea)
Date: Sun, 23 May 2021 23:27:17 +0700
Subject: [R] AR(1) model simulation based on 2 variables
Message-ID: <CAFZ3rQbqm0EtbSMbpEUTdaGfXA90mmjhC+j1NguuRo=x0sgpnA@mail.gmail.com>

Hello there,
I am currently perform a simulation on an AR(1) model with variable changes
to sample size and population parameter (denoted as ?).
For example, assume that we are simulating an AR(1) model with sample
size ? {10,100} and ??{0.1,0.9} and repeat it 100 times.

This can be done with the help of a looping function (crudely made) below.

  library(readr)
  library(MASS)
  library(dynlm)
  set.seed(2000)
  reps=100
  nv <- c(10,100)
  phi.hat<- matrix(nrow=reps, ncol=length(nv))
  #Looping 100 repeated samples @phi=0.9
  for (i in 1:length(nv)){
    n=nv[i]
    for (j in 1:reps){
    Yi=V=ts(rnorm(n, mean=0, sd=1),start=1, end=n, frequency=1)
    Y=0+0.9*Yi[-1]+V
    eq1=dynlm(Y~L(Y,1))
    phi.hat[j,i]=eq1$coefficients[2]
    }
  }
#Looping 100 repeated samples @ phi=0.1
for (i in 1:length(nv)){
  n=nv[i]
  for (j in 1:reps){
    Yi=V=ts(rnorm(n, mean=0, sd=1),start=1, end=n, frequency=1)
    Y=0+0.1*Yi[-1]+V
    eq1=dynlm(Y~L(Y,1))
    phi.hat[j,i]=eq1$coefficients[2]
  }
}

Having done this, I have received a relatively similar sample coefficient
to population parameter (i.e., mean( phi_hat)  ? phi). However, for
phi=0.9, the value for mean(phi_hat) is not close to phi. I was wondering
why this is the case. Thank you for reading this!

Regards,
Yanith

	[[alternative HTML version deleted]]


From me @end|ng |rom n@nx@me  Sat May 22 17:13:01 2021
From: me @end|ng |rom n@nx@me (Nan Xiao)
Date: Sat, 22 May 2021 11:13:01 -0400
Subject: [R] [R-pkgs] pkglite 0.2.0 is released
Message-ID: <9ae2cb4e-576c-4243-b016-0eb71cc40077@www.fastmail.com>

Dear all,

A new version of pkglite (0.2.0) is now on CRAN (https://cran.r-project.org/package=pkglite). pkglite offers a tool, grammar, and standard to represent and exchange R package source code as text files.

This version brings new file specification templates and new methods to operate on file collections, with a few bug fixes and enhancements. Please see the changelog (https://merck.github.io/pkglite/news/) for details.

Thanks,
-Nan

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From roger@bo@ @end|ng |rom gm@||@com  Mon May 24 21:41:47 2021
From: roger@bo@ @end|ng |rom gm@||@com (Roger Bos)
Date: Mon, 24 May 2021 15:41:47 -0400
Subject: [R] CentOS 8: installing R
Message-ID: <CAPV07m97yB71xZ7kYzTx0YhjG5qd1EPpVg02B9jdNXhoP-cgTQ@mail.gmail.com>

Dear all,

I seem to be having an impossible time install R on my centos 8 virtual
machine (I know centos 8 is no longer maintained, but it is a work server
so I have no choice in the matter.).  I installed EPEL and enabled
PowerTools, but I cannot install R due to conflicts in the requirements for
openblas-devel.  Could some help me get past this issue?  Thanks in
advance, Roger

[RCOAdmin at usd1sapp101 ~]$ sudo dnf install R
CentOS-8 - PowerTools
                                                          14 kB/s | 4.3 kB
    00:00
Extra Packages for Enterprise Linux Modular 8 - x86_64
                                                           30 kB/s |  15 kB
    00:00
Extra Packages for Enterprise Linux 8 - x86_64
                                                           52 kB/s |  15 kB
    00:00
Error:
 Problem: package R-devel-4.0.5-1.el8.x86_64 requires R-core-devel =
4.0.5-1.el8, but none of the providers can be installed
  - package R-4.0.5-1.el8.x86_64 requires R-devel = 4.0.5-1.el8, but none
of the providers can be installed
  - package R-core-devel-4.0.5-1.el8.x86_64 requires openblas-devel, but
none of the providers can be installed
  - conflicting requests
  - nothing provides openblas(x86-32) = 0.3.3-5.el8 needed by
openblas-devel-0.3.3-5.el8.i686
  - nothing provides openblas-threads(x86-32) = 0.3.3-5.el8 needed by
openblas-devel-0.3.3-5.el8.i686
  - nothing provides openblas(x86-64) = 0.3.3-5.el8 needed by
openblas-devel-0.3.3-5.el8.x86_64
  - nothing provides openblas-threads(x86-64) = 0.3.3-5.el8 needed by
openblas-devel-0.3.3-5.el8.x86_64
(try to add '--skip-broken' to skip uninstallable packages or '--nobest' to
use not only best candidate packages)
[RCOAdmin at usd1sapp101 ~]$ sudo dnf install openblass-devel
Last metadata expiration check: 0:00:31 ago on Mon 24 May 2021 09:34:56 PM
CEST.
No match for argument: openblass-devel
Error: Unable to find a match: openblass-devel
[RCOAdmin at usd1sapp101 ~]$ sudo dnf install openblas-devel
Last metadata expiration check: 0:00:43 ago on Mon 24 May 2021 09:34:56 PM
CEST.
Error:
 Problem: cannot install the best candidate for the job
  - nothing provides openblas(x86-64) = 0.3.3-5.el8 needed by
openblas-devel-0.3.3-5.el8.x86_64
  - nothing provides openblas-threads(x86-64) = 0.3.3-5.el8 needed by
openblas-devel-0.3.3-5.el8.x86_64
(try to add '--skip-broken' to skip uninstallable packages or '--nobest' to
use not only best candidate packages)
[RCOAdmin at usd1sapp101 ~]$ sudo dnf install openblas-devel --nobest
Last metadata expiration check: 0:00:52 ago on Mon 24 May 2021 09:34:56 PM
CEST.
Error:
 Problem: conflicting requests
  - nothing provides openblas(x86-32) = 0.3.3-5.el8 needed by
openblas-devel-0.3.3-5.el8.i686
  - nothing provides openblas-threads(x86-32) = 0.3.3-5.el8 needed by
openblas-devel-0.3.3-5.el8.i686
  - nothing provides openblas(x86-64) = 0.3.3-5.el8 needed by
openblas-devel-0.3.3-5.el8.x86_64
  - nothing provides openblas-threads(x86-64) = 0.3.3-5.el8 needed by
openblas-devel-0.3.3-5.el8.x86_64
(try to add '--skip-broken' to skip uninstallable packages)
[RCOAdmin at usd1sapp101 ~]$

	[[alternative HTML version deleted]]


From m@rc_@chw@rtz @end|ng |rom me@com  Mon May 24 21:56:26 2021
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Mon, 24 May 2021 15:56:26 -0400
Subject: [R] CentOS 8: installing R
In-Reply-To: <CAPV07m97yB71xZ7kYzTx0YhjG5qd1EPpVg02B9jdNXhoP-cgTQ@mail.gmail.com>
References: <CAPV07m97yB71xZ7kYzTx0YhjG5qd1EPpVg02B9jdNXhoP-cgTQ@mail.gmail.com>
Message-ID: <6fe7475a-df9f-e0e7-e726-dd5b5ec3f998@me.com>

Hi Roger,

I can't speak to the details here, albeit, there was a thread back in 
April on R-Devel (also not the right list for this topic), where one of 
the Fedora maintainers provided some insights for CentOS 7.x, where 
there were missing/incompatible tool chain issues.

I would recommend re-posting this to r-sig-fedora, which is focused upon 
R on Red Hat and Fedora based Linux distributions, including CentOS:

   https://stat.ethz.ch/mailman/listinfo/r-sig-fedora

The Fedora/EPEL R maintainers do monitor and respond on that list, and 
can likely provide you with more informed replies.

Regards,

Marc Schwartz

Roger Bos wrote on 5/24/21 3:41 PM:
> Dear all,
> 
> I seem to be having an impossible time install R on my centos 8 virtual
> machine (I know centos 8 is no longer maintained, but it is a work server
> so I have no choice in the matter.).  I installed EPEL and enabled
> PowerTools, but I cannot install R due to conflicts in the requirements for
> openblas-devel.  Could some help me get past this issue?  Thanks in
> advance, Roger
> 
> [RCOAdmin at usd1sapp101 ~]$ sudo dnf install R
> CentOS-8 - PowerTools
>                                                            14 kB/s | 4.3 kB
>      00:00
> Extra Packages for Enterprise Linux Modular 8 - x86_64
>                                                             30 kB/s |  15 kB
>      00:00
> Extra Packages for Enterprise Linux 8 - x86_64
>                                                             52 kB/s |  15 kB
>      00:00
> Error:
>   Problem: package R-devel-4.0.5-1.el8.x86_64 requires R-core-devel =
> 4.0.5-1.el8, but none of the providers can be installed
>    - package R-4.0.5-1.el8.x86_64 requires R-devel = 4.0.5-1.el8, but none
> of the providers can be installed
>    - package R-core-devel-4.0.5-1.el8.x86_64 requires openblas-devel, but
> none of the providers can be installed
>    - conflicting requests
>    - nothing provides openblas(x86-32) = 0.3.3-5.el8 needed by
> openblas-devel-0.3.3-5.el8.i686
>    - nothing provides openblas-threads(x86-32) = 0.3.3-5.el8 needed by
> openblas-devel-0.3.3-5.el8.i686
>    - nothing provides openblas(x86-64) = 0.3.3-5.el8 needed by
> openblas-devel-0.3.3-5.el8.x86_64
>    - nothing provides openblas-threads(x86-64) = 0.3.3-5.el8 needed by
> openblas-devel-0.3.3-5.el8.x86_64
> (try to add '--skip-broken' to skip uninstallable packages or '--nobest' to
> use not only best candidate packages)
> [RCOAdmin at usd1sapp101 ~]$ sudo dnf install openblass-devel
> Last metadata expiration check: 0:00:31 ago on Mon 24 May 2021 09:34:56 PM
> CEST.
> No match for argument: openblass-devel
> Error: Unable to find a match: openblass-devel
> [RCOAdmin at usd1sapp101 ~]$ sudo dnf install openblas-devel
> Last metadata expiration check: 0:00:43 ago on Mon 24 May 2021 09:34:56 PM
> CEST.
> Error:
>   Problem: cannot install the best candidate for the job
>    - nothing provides openblas(x86-64) = 0.3.3-5.el8 needed by
> openblas-devel-0.3.3-5.el8.x86_64
>    - nothing provides openblas-threads(x86-64) = 0.3.3-5.el8 needed by
> openblas-devel-0.3.3-5.el8.x86_64
> (try to add '--skip-broken' to skip uninstallable packages or '--nobest' to
> use not only best candidate packages)
> [RCOAdmin at usd1sapp101 ~]$ sudo dnf install openblas-devel --nobest
> Last metadata expiration check: 0:00:52 ago on Mon 24 May 2021 09:34:56 PM
> CEST.
> Error:
>   Problem: conflicting requests
>    - nothing provides openblas(x86-32) = 0.3.3-5.el8 needed by
> openblas-devel-0.3.3-5.el8.i686
>    - nothing provides openblas-threads(x86-32) = 0.3.3-5.el8 needed by
> openblas-devel-0.3.3-5.el8.i686
>    - nothing provides openblas(x86-64) = 0.3.3-5.el8 needed by
> openblas-devel-0.3.3-5.el8.x86_64
>    - nothing provides openblas-threads(x86-64) = 0.3.3-5.el8 needed by
> openblas-devel-0.3.3-5.el8.x86_64
> (try to add '--skip-broken' to skip uninstallable packages)
> [RCOAdmin at usd1sapp101 ~]$
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From y@ngk@|9999 @end|ng |rom y@hoo@com  Tue May 25 01:53:22 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Mon, 24 May 2021 23:53:22 +0000 (UTC)
Subject: [R] help to correct the function problem
References: <580563500.2027798.1621900402362.ref@mail.yahoo.com>
Message-ID: <580563500.2027798.1621900402362@mail.yahoo.com>

Hello list,I want to translate some of the R code into function, but I got error message. I'm new for R. please point out where is my problem.thank you,Kai
the original working code:p1 <- select(raw? ? ? ? ? ? ?,Pedigree.name? ? ? ? ? ? ?,UPN?? ? ? ? ? ? ?,Test.Result.tr_Test.Result1? ? ? ? ? ? ?,Test.Result.tr_gene1? ? ? ? ? ? ?,Test.Result.tr_Variant..nucleotide.1? )p2 <- select(raw? ? ? ? ? ? ?,Pedigree.name? ? ? ? ? ? ?,UPN?? ? ? ? ? ? ?,Test.Result.tr_Test.Result2? ? ? ? ? ? ?,Test.Result.tr_gene2? ? ? ? ? ? ?,Test.Result.tr_Variant..nucleotide.2)p3 <- select(raw? ? ? ? ? ? ?,Pedigree.name? ? ? ? ? ? ?,UPN?? ? ? ? ? ? ?,Test.Result.tr_Test.Result3? ? ? ? ? ? ?,Test.Result.tr_gene3? ? ? ? ? ? ?,Test.Result.tr_Variant..nucleotide.3)p4 <- select(raw? ? ? ? ? ? ?,Pedigree.name? ? ? ? ? ? ?,UPN?? ? ? ? ? ? ?,Test.Result.tr_Test.Result4? ? ? ? ? ? ?,Test.Result.tr_gene4? ? ? ? ? ? ?,Test.Result.tr_Variant..nucleotide.4)p5 <- select(raw? ? ? ? ? ? ?,Pedigree.name? ? ? ? ? ? ?,UPN?? ? ? ? ? ? ?,Test.Result.tr_Test.Result5? ? ? ? ? ? ?,Test.Result.tr_gene5? ? ? ? ? ? ?,Test.Result.tr_Variant..nucleotide.5)

I tried to write a function to do this:k_subset <- function(pp, aa, bb, cc){? pp <- substitute(pp)? aa <- substitute(aa)??? bb <- substitute(bb)??? cc <- substitute(cc)??? pp? <- select(raw? ? ? ? ? ? ? ? ,Pedigree.name? ? ? ? ? ? ? ? ,UPN?? ? ? ? ? ? ? ? ,aa? ? ? ? ? ? ? ? ,bb? ? ? ? ? ? ? ? ,cc? )??}k_subset(p1, Test.Result.tr_Test.Result1, Result.tr_gene1, Test.Result.tr_Variant..nucleotide.1 )but I got error message:?Note: Using an external vector in selections is ambiguous.i Use `all_of(aa)` instead of `aa` to silence this message.i See <https://tidyselect.r-lib.org/reference/faq-external-vector.html>.This message is displayed once per session.Note: Using an external vector in selections is ambiguous.i Use `all_of(bb)` instead of `bb` to silence this message.i See <https://tidyselect.r-lib.org/reference/faq-external-vector.html>.This message is displayed once per session.?Error: Can't subset columns that don't existx Column `Result.tr_gene1` doesn't exist.




	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue May 25 04:00:39 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 24 May 2021 19:00:39 -0700
Subject: [R] help to correct the function problem
In-Reply-To: <580563500.2027798.1621900402362@mail.yahoo.com>
References: <580563500.2027798.1621900402362.ref@mail.yahoo.com>
 <580563500.2027798.1621900402362@mail.yahoo.com>
Message-ID: <CAGxFJbSfuuw5Jz+T25NcXEZMr0aWmK1-RKXRwCb-_CwWToGT8g@mail.gmail.com>

This is a *plain text* list. I find your HTML (below) unreadable. I suggest
you re-post to make it easier for others to help.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, May 24, 2021 at 4:53 PM Kai Yang via R-help <r-help at r-project.org>
wrote:

> Hello list,I want to translate some of the R code into function, but I got
> error message. I'm new for R. please point out where is my problem.thank
> you,Kai
> the original working code:p1 <- select(raw             ,Pedigree.name
>        ,UPN              ,Test.Result.tr_Test.Result1
>  ,Test.Result.tr_gene1             ,Test.Result.tr_Variant..nucleotide.1
> )p2 <- select(raw             ,Pedigree.name             ,UPN
>  ,Test.Result.tr_Test.Result2             ,Test.Result.tr_gene2
>  ,Test.Result.tr_Variant..nucleotide.2)p3 <- select(raw
>  ,Pedigree.name             ,UPN              ,Test.Result.tr_Test.Result3
>            ,Test.Result.tr_gene3
>  ,Test.Result.tr_Variant..nucleotide.3)p4 <- select(raw
>  ,Pedigree.name             ,UPN              ,Test.Result.tr_Test.Result4
>            ,Test.Result.tr_gene4
>  ,Test.Result.tr_Variant..nucleotide.4)p5 <- select(raw
>  ,Pedigree.name             ,UPN              ,Test.Result.tr_Test.Result5
>            ,Test.Result.tr_gene5
>  ,Test.Result.tr_Variant..nucleotide.5)
>
> I tried to write a function to do this:k_subset <- function(pp, aa, bb,
> cc){  pp <- substitute(pp)  aa <- substitute(aa)    bb <- substitute(bb)
> cc <- substitute(cc)    pp  <- select(raw                ,Pedigree.name
>             ,UPN                 ,aa                ,bb                ,cc
> )  }k_subset(p1, Test.Result.tr_Test.Result1, Result.tr_gene1,
> Test.Result.tr_Variant..nucleotide.1 )but I got error message: Note: Using
> an external vector in selections is ambiguous.i Use `all_of(aa)` instead of
> `aa` to silence this message.i See <
> https://tidyselect.r-lib.org/reference/faq-external-vector.html>.This
> message is displayed once per session.Note: Using an external vector in
> selections is ambiguous.i Use `all_of(bb)` instead of `bb` to silence this
> message.i See <
> https://tidyselect.r-lib.org/reference/faq-external-vector.html>.This
> message is displayed once per session. Error: Can't subset columns that
> don't existx Column `Result.tr_gene1` doesn't exist.
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Tue May 25 04:47:48 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Tue, 25 May 2021 14:47:48 +1200
Subject: [R] Testing optimization solvers with equality constraints
In-Reply-To: <CAB8pepxD2spsGRx0nLTGBJEE-aWjceowxtRC_OPY1gfw5rKs+Q@mail.gmail.com>
References: <CAML4n3MWBKg3vzxHN8yWzg=dfyijBvX_SLRZHwP-OetJyXb8Aw@mail.gmail.com>
 <CAB8pepznXQuvLwN6ZYFiyVXqZofwbdwc76vvUYjxNu7qufG3_A@mail.gmail.com>
 <CAML4n3PgQaMt6aACjJRC+Bi5f98fnzLMH1CpdV5P3EpPYH58Xg@mail.gmail.com>
 <CAB8pepxD2spsGRx0nLTGBJEE-aWjceowxtRC_OPY1gfw5rKs+Q@mail.gmail.com>
Message-ID: <CAB8pepxkARh8EbRBJyndoRhCcHV9XzUsO9xhy--oFSb7LhJghA@mail.gmail.com>

I received an off-list email, questioning the relevance of my post.
So, I thought I should clarify.

If an optimization algorithm is dependent on the starting point (or
other user-selected parameters), and then fails to find the "correct"
solution because the starting point (or other user-selected
parameters) are unsuitable, then that, in itself, does not indicate a
problem with the algorithm.

In other words, the R's packages listed in this thread appear to be
working fine.
(Or at least, there's no clear counter-evidence against).

One solution is to project the surface (here, equality constraints) on
to lower dimensions, as already suggested.
Another much simpler solution, is to use two algorithms, where one
selects one or more starting points.
(These could be the solution to an initial optimization, or chosen at
random, or a combination of both).

Both of these approaches generalize to a broader set of problems.
And I assume that there are other (possibly much better) approaches.
However, that's an off-list discussion...

All and all, I would say R has extremely good numerical capabilities.
Which are even more useful still, with the use of well chosen
mathematical and statistical graphics.


On Sun, May 23, 2021 at 5:25 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> For a start, there's two local minima.
>
> Add to that floating point errors.
> And possible assumptions by the package authors.
>
> ----begin code----
> f <- function (x, y, sign)
> {   unsign.z <- sqrt (1 - x^2 - y^2)
>     2 * (x^2 - sign * y * unsign.z)
> }
>
> north.f <- function (x, y) f (x, y, +1)
> south.f <- function (x, y) f (x, y, -1)
>
> N <- 100
> p0 <- par (mfrow = c (1, 2) )
> plotf_cfield (north.f, c (-1.1, 1.1),
>     main="north",
>     ncontours=10, n=N, raster=TRUE, hcv=TRUE)
> plotf_cfield (south.f, c (-1.1, 1.1),
>     main="south",
>     ncontours=10, n=N, raster=TRUE, hcv=TRUE)
> par (p0)
> ----end code ----
>
> Please ignore R warnings.
> I'm planning to reinvent this package soon.
> And also, it wasn't designed for circular heatmaps.
>
>
> On Sat, May 22, 2021 at 8:02 PM Hans W <hwborchers at gmail.com> wrote:
> >
> > Yes. "*on* the unit sphere" means on the surface, as you can guess
> > from the equality constraint. And 'auglag()' does find the minimum, so
> > no need for a special approach.
> >
> > I was/am interested in why all these other good solvers get stuck,
> > i.e., do not move away from the starting point. And how to avoid this
> > in general, not only for this specific example.
> >
> >
> > On Sat, 22 May 2021 at 09:44, Abby Spurdle <spurdle.a at gmail.com> wrote:
> > >
> > > Sorry, this might sound like a poor question:
> > > But by "on the unit sphere", do you mean on the ***surface*** of the sphere?
> > > In which case, can't the surface of a sphere be projected onto a pair
> > > of circles?
> > > Where the cost function is reformulated as a function of two (rather
> > > than three) variables.
> > >


From er|cjberger @end|ng |rom gm@||@com  Tue May 25 09:02:50 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 25 May 2021 10:02:50 +0300
Subject: [R] CentOS 8: installing R
In-Reply-To: <6fe7475a-df9f-e0e7-e726-dd5b5ec3f998@me.com>
References: <CAPV07m97yB71xZ7kYzTx0YhjG5qd1EPpVg02B9jdNXhoP-cgTQ@mail.gmail.com>
 <6fe7475a-df9f-e0e7-e726-dd5b5ec3f998@me.com>
Message-ID: <CAGgJW76LZqoaTbKFaESotdCc9XqwyAZV2WstPR-EnK5-5=YViQ@mail.gmail.com>

Hi Roger,
I have no experience with Centos 8 but I checked that it is possible to run
docker on it.
You might consider creating an ubuntu docker image with all the R tools
that you need, and then run the image on the Centos 8 machine.
You can specify a mount so that your docker image, including its R
sessions, have access to the file system on the Centos 8 machine.
Check out this link, for example:
https://kifarunix.com/install-and-use-docker-ce-on-centos-8/

HTH,
Eric


On Mon, May 24, 2021 at 10:56 PM Marc Schwartz via R-help <
r-help at r-project.org> wrote:

> Hi Roger,
>
> I can't speak to the details here, albeit, there was a thread back in
> April on R-Devel (also not the right list for this topic), where one of
> the Fedora maintainers provided some insights for CentOS 7.x, where
> there were missing/incompatible tool chain issues.
>
> I would recommend re-posting this to r-sig-fedora, which is focused upon
> R on Red Hat and Fedora based Linux distributions, including CentOS:
>
>    https://stat.ethz.ch/mailman/listinfo/r-sig-fedora
>
> The Fedora/EPEL R maintainers do monitor and respond on that list, and
> can likely provide you with more informed replies.
>
> Regards,
>
> Marc Schwartz
>
> Roger Bos wrote on 5/24/21 3:41 PM:
> > Dear all,
> >
> > I seem to be having an impossible time install R on my centos 8 virtual
> > machine (I know centos 8 is no longer maintained, but it is a work server
> > so I have no choice in the matter.).  I installed EPEL and enabled
> > PowerTools, but I cannot install R due to conflicts in the requirements
> for
> > openblas-devel.  Could some help me get past this issue?  Thanks in
> > advance, Roger
> >
> > [RCOAdmin at usd1sapp101 ~]$ sudo dnf install R
> > CentOS-8 - PowerTools
> >                                                            14 kB/s | 4.3
> kB
> >      00:00
> > Extra Packages for Enterprise Linux Modular 8 - x86_64
> >                                                             30 kB/s |
> 15 kB
> >      00:00
> > Extra Packages for Enterprise Linux 8 - x86_64
> >                                                             52 kB/s |
> 15 kB
> >      00:00
> > Error:
> >   Problem: package R-devel-4.0.5-1.el8.x86_64 requires R-core-devel =
> > 4.0.5-1.el8, but none of the providers can be installed
> >    - package R-4.0.5-1.el8.x86_64 requires R-devel = 4.0.5-1.el8, but
> none
> > of the providers can be installed
> >    - package R-core-devel-4.0.5-1.el8.x86_64 requires openblas-devel, but
> > none of the providers can be installed
> >    - conflicting requests
> >    - nothing provides openblas(x86-32) = 0.3.3-5.el8 needed by
> > openblas-devel-0.3.3-5.el8.i686
> >    - nothing provides openblas-threads(x86-32) = 0.3.3-5.el8 needed by
> > openblas-devel-0.3.3-5.el8.i686
> >    - nothing provides openblas(x86-64) = 0.3.3-5.el8 needed by
> > openblas-devel-0.3.3-5.el8.x86_64
> >    - nothing provides openblas-threads(x86-64) = 0.3.3-5.el8 needed by
> > openblas-devel-0.3.3-5.el8.x86_64
> > (try to add '--skip-broken' to skip uninstallable packages or '--nobest'
> to
> > use not only best candidate packages)
> > [RCOAdmin at usd1sapp101 ~]$ sudo dnf install openblass-devel
> > Last metadata expiration check: 0:00:31 ago on Mon 24 May 2021 09:34:56
> PM
> > CEST.
> > No match for argument: openblass-devel
> > Error: Unable to find a match: openblass-devel
> > [RCOAdmin at usd1sapp101 ~]$ sudo dnf install openblas-devel
> > Last metadata expiration check: 0:00:43 ago on Mon 24 May 2021 09:34:56
> PM
> > CEST.
> > Error:
> >   Problem: cannot install the best candidate for the job
> >    - nothing provides openblas(x86-64) = 0.3.3-5.el8 needed by
> > openblas-devel-0.3.3-5.el8.x86_64
> >    - nothing provides openblas-threads(x86-64) = 0.3.3-5.el8 needed by
> > openblas-devel-0.3.3-5.el8.x86_64
> > (try to add '--skip-broken' to skip uninstallable packages or '--nobest'
> to
> > use not only best candidate packages)
> > [RCOAdmin at usd1sapp101 ~]$ sudo dnf install openblas-devel --nobest
> > Last metadata expiration check: 0:00:52 ago on Mon 24 May 2021 09:34:56
> PM
> > CEST.
> > Error:
> >   Problem: conflicting requests
> >    - nothing provides openblas(x86-32) = 0.3.3-5.el8 needed by
> > openblas-devel-0.3.3-5.el8.i686
> >    - nothing provides openblas-threads(x86-32) = 0.3.3-5.el8 needed by
> > openblas-devel-0.3.3-5.el8.i686
> >    - nothing provides openblas(x86-64) = 0.3.3-5.el8 needed by
> > openblas-devel-0.3.3-5.el8.x86_64
> >    - nothing provides openblas-threads(x86-64) = 0.3.3-5.el8 needed by
> > openblas-devel-0.3.3-5.el8.x86_64
> > (try to add '--skip-broken' to skip uninstallable packages)
> > [RCOAdmin at usd1sapp101 ~]$
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From |@@u|o @end|ng |rom |@t@t@|t  Mon May 24 12:25:41 2021
From: |@@u|o @end|ng |rom |@t@t@|t (Andrea Fasulo)
Date: Mon, 24 May 2021 12:25:41 +0200 (CEST)
Subject: [R] [R-pkgs] mind 0.1.0
In-Reply-To: <1197766154.15579981.1611911877018.JavaMail.zimbra@istat.it>
References: <625278381.7227906.1610527875843.JavaMail.zimbra@istat.it>
 <1197766154.15579981.1611911877018.JavaMail.zimbra@istat.it>
Message-ID: <1265731484.66404806.1621851941567.JavaMail.zimbra@istat.it>

Dear R users: 
mind 0.1.0 is now available on CRAN. 
This package a llows users to produce estimates and MSE for multivariate variables using unit level Linear Mixed Model. 
The package follows the approach of Datta, Day and Basawa (1999). Hope this can be useful, 
Regards 
Andrea Fasulo 


	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From pro|jcn@@h @end|ng |rom gm@||@com  Tue May 25 15:51:29 2021
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Tue, 25 May 2021 09:51:29 -0400
Subject: [R] Testing optimization solvers with equality constraints
In-Reply-To: <CAB8pepxkARh8EbRBJyndoRhCcHV9XzUsO9xhy--oFSb7LhJghA@mail.gmail.com>
References: <CAML4n3MWBKg3vzxHN8yWzg=dfyijBvX_SLRZHwP-OetJyXb8Aw@mail.gmail.com>
 <CAB8pepznXQuvLwN6ZYFiyVXqZofwbdwc76vvUYjxNu7qufG3_A@mail.gmail.com>
 <CAML4n3PgQaMt6aACjJRC+Bi5f98fnzLMH1CpdV5P3EpPYH58Xg@mail.gmail.com>
 <CAB8pepxD2spsGRx0nLTGBJEE-aWjceowxtRC_OPY1gfw5rKs+Q@mail.gmail.com>
 <CAB8pepxkARh8EbRBJyndoRhCcHV9XzUsO9xhy--oFSb7LhJghA@mail.gmail.com>
Message-ID: <1dc89ac6-0f4b-00be-9076-8240c135f6d8@gmail.com>

As someone who works on trying to improve the optimization codes in R,
though mainly in the unconstrained and bounds-constrained area, I think my
experience is more akin to that of HWB. That is, for some problems -- and
the example in question does have a reparametrization that removes the
constraint, so it could be considered artificial -- there seem to be
many more "bad" starting points than "good" ones. Abby's experience may
be very different, which is more or less the way things are in this type
of work. Or things will work for several years with a class of problems,
then the alligator of an unanticipated "bad" result will take a chunk out
of your posterior.

R users often have advanced expertise in different areas, so I suspect
a lot of cases involve using a poor parameterization. To my mind, the
real issue is less "the program should just work" than "the program
should let the user know there may be issues with the proposed solution".
Such diagnostics are very tricky to devise, and even more awkward to
implement in a way that doesn't become intrusive and time-wasting.
For example, in the optimx package, we can compute the KKT conditions
(first and second derivative checks on proposed solutions), but that
can often take many times the computing effort of finding the solution.
And when there are constraints, KKT conditions are less useful, since
they are for optima "not on the constraint".

This is going to be an ongoing challenge, and it affects a lot of areas
of work now that very complicated calculations are being carried out in
the name of AI and ML (either machine learning or maximum likelihood --
your choice). I'll welcome off-list ideas and efforts to devise better
diagnostics for proposed optimization solutions. We'll need them.

Best, John Nash


On 2021-05-24 10:47 p.m., Abby Spurdle wrote:
> I received an off-list email, questioning the relevance of my post.
> So, I thought I should clarify.
> 
> If an optimization algorithm is dependent on the starting point (or
> other user-selected parameters), and then fails to find the "correct"
> solution because the starting point (or other user-selected
> parameters) are unsuitable, then that, in itself, does not indicate a
> problem with the algorithm.
> 
> In other words, the R's packages listed in this thread appear to be
> working fine.
> (Or at least, there's no clear counter-evidence against).
> 
> One solution is to project the surface (here, equality constraints) on
> to lower dimensions, as already suggested.
> Another much simpler solution, is to use two algorithms, where one
> selects one or more starting points.
> (These could be the solution to an initial optimization, or chosen at
> random, or a combination of both).
> 
> Both of these approaches generalize to a broader set of problems.
> And I assume that there are other (possibly much better) approaches.
> However, that's an off-list discussion...
> 
> All and all, I would say R has extremely good numerical capabilities.
> Which are even more useful still, with the use of well chosen
> mathematical and statistical graphics.
> 
> 
> On Sun, May 23, 2021 at 5:25 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
>>
>> For a start, there's two local minima.
>>
>> Add to that floating point errors.
>> And possible assumptions by the package authors.
>>
>> ----begin code----
>> f <- function (x, y, sign)
>> {   unsign.z <- sqrt (1 - x^2 - y^2)
>>     2 * (x^2 - sign * y * unsign.z)
>> }
>>
>> north.f <- function (x, y) f (x, y, +1)
>> south.f <- function (x, y) f (x, y, -1)
>>
>> N <- 100
>> p0 <- par (mfrow = c (1, 2) )
>> plotf_cfield (north.f, c (-1.1, 1.1),
>>     main="north",
>>     ncontours=10, n=N, raster=TRUE, hcv=TRUE)
>> plotf_cfield (south.f, c (-1.1, 1.1),
>>     main="south",
>>     ncontours=10, n=N, raster=TRUE, hcv=TRUE)
>> par (p0)
>> ----end code ----
>>
>> Please ignore R warnings.
>> I'm planning to reinvent this package soon.
>> And also, it wasn't designed for circular heatmaps.
>>
>>
>> On Sat, May 22, 2021 at 8:02 PM Hans W <hwborchers at gmail.com> wrote:
>>>
>>> Yes. "*on* the unit sphere" means on the surface, as you can guess
>>> from the equality constraint. And 'auglag()' does find the minimum, so
>>> no need for a special approach.
>>>
>>> I was/am interested in why all these other good solvers get stuck,
>>> i.e., do not move away from the starting point. And how to avoid this
>>> in general, not only for this specific example.
>>>
>>>
>>> On Sat, 22 May 2021 at 09:44, Abby Spurdle <spurdle.a at gmail.com> wrote:
>>>>
>>>> Sorry, this might sound like a poor question:
>>>> But by "on the unit sphere", do you mean on the ***surface*** of the sphere?
>>>> In which case, can't the surface of a sphere be projected onto a pair
>>>> of circles?
>>>> Where the cost function is reformulated as a function of two (rather
>>>> than three) variables.
>>>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r|@zb|b|b@|och @end|ng |rom gm@||@com  Tue May 25 14:28:12 2021
From: r|@zb|b|b@|och @end|ng |rom gm@||@com (Riaz Bibi)
Date: Tue, 25 May 2021 21:28:12 +0900
Subject: [R] Student request for help in Self Organizing Map (SOM)
Message-ID: <CAD+i1vWMKP97pFaaO=oLWotFXWP4jU6Or9f-ePtAatg9OePVFA@mail.gmail.com>

Dear

I am Bibi, a PhD student of Environmental Science in South Korea.  I am
currently writing my research paper and to deal with data I need to do Self
Organizing Map (SOM).

I am using R version 4.1.0 (2021-05-18) with kohonen package.

I was following this tutorial given
http://rstudio-pubs-static.s3.amazonaws.com/437468_136a369149e24f24a4d0c152860ab4c3.html
.

But I have a small confusion that I could not understand. To check the
efficiency of SOM model, I need to find out topographic error, which I
could not figure out.

I will be really thankful if you please tell me how I can calculate
topographic error or any alternative term or which one is the topographic
error in the given article.

Please accept my apology if I wrote or mentioned something inappropriate.

Looking forward to hearing back.

Kind regards

Bibi

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue May 25 17:56:31 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 25 May 2021 08:56:31 -0700
Subject: [R] Student request for help in Self Organizing Map (SOM)
In-Reply-To: <CAD+i1vWMKP97pFaaO=oLWotFXWP4jU6Or9f-ePtAatg9OePVFA@mail.gmail.com>
References: <CAD+i1vWMKP97pFaaO=oLWotFXWP4jU6Or9f-ePtAatg9OePVFA@mail.gmail.com>
Message-ID: <4A156E06-3B70-4A4F-AE5A-DBC0C1F7542A@dcn.davis.ca.us>

Well, this mailing list is about the R language itself, not specific packages or background theory. You may get an answer anyway, but you are likely to have better responses on the R-sig-geo mailing list or contacting the author of the contributed package you are using.

Also, do figure out how to configure your email program to send plain text... if you don't you gamble that your message (especially R code) becomes very hard to read after your formatting gets removed by the list.

On May 25, 2021 5:28:12 AM PDT, Riaz Bibi <riazbibibaloch at gmail.com> wrote:
>Dear
>
>I am Bibi, a PhD student of Environmental Science in South Korea.  I am
>currently writing my research paper and to deal with data I need to do
>Self
>Organizing Map (SOM).
>
>I am using R version 4.1.0 (2021-05-18) with kohonen package.
>
>I was following this tutorial given
>http://rstudio-pubs-static.s3.amazonaws.com/437468_136a369149e24f24a4d0c152860ab4c3.html
>.
>
>But I have a small confusion that I could not understand. To check the
>efficiency of SOM model, I need to find out topographic error, which I
>could not figure out.
>
>I will be really thankful if you please tell me how I can calculate
>topographic error or any alternative term or which one is the
>topographic
>error in the given article.
>
>Please accept my apology if I wrote or mentioned something
>inappropriate.
>
>Looking forward to hearing back.
>
>Kind regards
>
>Bibi
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bobby@kn|ght @end|ng |rom gm@||@com  Tue May 25 18:47:58 2021
From: bobby@kn|ght @end|ng |rom gm@||@com (Robert Knight)
Date: Tue, 25 May 2021 11:47:58 -0500
Subject: [R] CentOS 8: installing R
In-Reply-To: <6fe7475a-df9f-e0e7-e726-dd5b5ec3f998@me.com>
References: <CAPV07m97yB71xZ7kYzTx0YhjG5qd1EPpVg02B9jdNXhoP-cgTQ@mail.gmail.com>
 <6fe7475a-df9f-e0e7-e726-dd5b5ec3f998@me.com>
Message-ID: <CAKBFG3awUf=P9tOgs7xQ2QN5p2jaY0HGjgNFoviK54dRPGqaJA@mail.gmail.com>

Openblas-threads is in the appstream repository rather than power tools.

https://centos.pkgs.org/8/centos-appstream-x86_64/openblas-threads-0.3.3-5.el8.x86_64.rpm.html

On Mon, May 24, 2021, 2:56 PM Marc Schwartz via R-help <r-help at r-project.org>
wrote:

> Hi Roger,
>
> I can't speak to the details here, albeit, there was a thread back in
> April on R-Devel (also not the right list for this topic), where one of
> the Fedora maintainers provided some insights for CentOS 7.x, where
> there were missing/incompatible tool chain issues.
>
> I would recommend re-posting this to r-sig-fedora, which is focused upon
> R on Red Hat and Fedora based Linux distributions, including CentOS:
>
>    https://stat.ethz.ch/mailman/listinfo/r-sig-fedora
>
> The Fedora/EPEL R maintainers do monitor and respond on that list, and
> can likely provide you with more informed replies.
>
> Regards,
>
> Marc Schwartz
>
> Roger Bos wrote on 5/24/21 3:41 PM:
> > Dear all,
> >
> > I seem to be having an impossible time install R on my centos 8 virtual
> > machine (I know centos 8 is no longer maintained, but it is a work server
> > so I have no choice in the matter.).  I installed EPEL and enabled
> > PowerTools, but I cannot install R due to conflicts in the requirements
> for
> > openblas-devel.  Could some help me get past this issue?  Thanks in
> > advance, Roger
> >
> > [RCOAdmin at usd1sapp101 ~]$ sudo dnf install R
> > CentOS-8 - PowerTools
> >                                                            14 kB/s | 4.3
> kB
> >      00:00
> > Extra Packages for Enterprise Linux Modular 8 - x86_64
> >                                                             30 kB/s |
> 15 kB
> >      00:00
> > Extra Packages for Enterprise Linux 8 - x86_64
> >                                                             52 kB/s |
> 15 kB
> >      00:00
> > Error:
> >   Problem: package R-devel-4.0.5-1.el8.x86_64 requires R-core-devel =
> > 4.0.5-1.el8, but none of the providers can be installed
> >    - package R-4.0.5-1.el8.x86_64 requires R-devel = 4.0.5-1.el8, but
> none
> > of the providers can be installed
> >    - package R-core-devel-4.0.5-1.el8.x86_64 requires openblas-devel, but
> > none of the providers can be installed
> >    - conflicting requests
> >    - nothing provides openblas(x86-32) = 0.3.3-5.el8 needed by
> > openblas-devel-0.3.3-5.el8.i686
> >    - nothing provides openblas-threads(x86-32) = 0.3.3-5.el8 needed by
> > openblas-devel-0.3.3-5.el8.i686
> >    - nothing provides openblas(x86-64) = 0.3.3-5.el8 needed by
> > openblas-devel-0.3.3-5.el8.x86_64
> >    - nothing provides openblas-threads(x86-64) = 0.3.3-5.el8 needed by
> > openblas-devel-0.3.3-5.el8.x86_64
> > (try to add '--skip-broken' to skip uninstallable packages or '--nobest'
> to
> > use not only best candidate packages)
> > [RCOAdmin at usd1sapp101 ~]$ sudo dnf install openblass-devel
> > Last metadata expiration check: 0:00:31 ago on Mon 24 May 2021 09:34:56
> PM
> > CEST.
> > No match for argument: openblass-devel
> > Error: Unable to find a match: openblass-devel
> > [RCOAdmin at usd1sapp101 ~]$ sudo dnf install openblas-devel
> > Last metadata expiration check: 0:00:43 ago on Mon 24 May 2021 09:34:56
> PM
> > CEST.
> > Error:
> >   Problem: cannot install the best candidate for the job
> >    - nothing provides openblas(x86-64) = 0.3.3-5.el8 needed by
> > openblas-devel-0.3.3-5.el8.x86_64
> >    - nothing provides openblas-threads(x86-64) = 0.3.3-5.el8 needed by
> > openblas-devel-0.3.3-5.el8.x86_64
> > (try to add '--skip-broken' to skip uninstallable packages or '--nobest'
> to
> > use not only best candidate packages)
> > [RCOAdmin at usd1sapp101 ~]$ sudo dnf install openblas-devel --nobest
> > Last metadata expiration check: 0:00:52 ago on Mon 24 May 2021 09:34:56
> PM
> > CEST.
> > Error:
> >   Problem: conflicting requests
> >    - nothing provides openblas(x86-32) = 0.3.3-5.el8 needed by
> > openblas-devel-0.3.3-5.el8.i686
> >    - nothing provides openblas-threads(x86-32) = 0.3.3-5.el8 needed by
> > openblas-devel-0.3.3-5.el8.i686
> >    - nothing provides openblas(x86-64) = 0.3.3-5.el8 needed by
> > openblas-devel-0.3.3-5.el8.x86_64
> >    - nothing provides openblas-threads(x86-64) = 0.3.3-5.el8 needed by
> > openblas-devel-0.3.3-5.el8.x86_64
> > (try to add '--skip-broken' to skip uninstallable packages)
> > [RCOAdmin at usd1sapp101 ~]$
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ch@|@b|@e|@he @end|ng |rom y@hoo@de  Wed May 26 17:52:26 2021
From: ch@|@b|@e|@he @end|ng |rom y@hoo@de (Elahe chalabi)
Date: Wed, 26 May 2021 15:52:26 +0000 (UTC)
Subject: [R] Group by and add a constant value based on a condition dply
References: <354867589.557141.1622044346720.ref@mail.yahoo.com>
Message-ID: <354867589.557141.1622044346720@mail.yahoo.com>

Hi everyone,

I have the following dataframe:?



? ? ? structure(list(Department = c("A", "A", "A", "A", "A", "A", "A",?
? ? ?"A", "B", "B", "B", "B", "B", "B", "B", "B"), Class = c(1L, 1L,?
? ? 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L), Value = c(0L,?
? ? 100L, 800L, 800L, 0L, 300L, 1200L, 0L, 0L, 0L, 400L, 400L, 200L,?
? ? 800L, 1200L, 0L), Date = c("1.01.2020", "2.01.2020", "3.01.2020",?
? ? "4.01.2020", "1.01.2020", "2.01.2020", "3.01.2020", "4.01.2020",?
? ? "1.01.2020", "2.01.2020", "3.01.2020", "4.01.2020", "1.01.2020",?
? ? "2.01.2020", "3.01.2020", "4.01.2020")), class = "data.frame", row.names = c(NA,?
? ? ?-16L))

?using dplyr I need to group by "Depatment" and "Class" and then for all the dates that are "4.01.2020"? and have the "Value" greater than zero? add 5 to the "Value", meaning the desired dataframe will be (NewValue column) :?



? ?structure(list(Department = c("A", "A", "A", "A", "A", "A", "A",?
?"A", "B", "B", "B", "B", "B", "B", "B", "B"), Class = c(1L, 1L,?
?1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L), Value = c(0L,?
?100L, 800L, 800L, 0L, 300L, 1200L, 0L, 0L, 0L, 400L, 400L, 200L,?
?800L, 1200L, 0L), Date = c("1.01.2020", "2.01.2020", "3.01.2020",?
?"4.01.2020", "1.01.2020", "2.01.2020", "3.01.2020", "4.01.2020",?
?"1.01.2020", "2.01.2020", "3.01.2020", "4.01.2020", "1.01.2020",?
?"2.01.2020", "3.01.2020", "4.01.2020"), NewValue = c(0L, 100L,?
?800L, 805L, 0L, 300L, 1200L, 0L, 0L, 0L, 400L, 405L, 200L, 800L,?
?1200L, 0L)), class = "data.frame", row.names = c(NA, -16L))

? ?
Thanks a lot for any help!
Elahe


From cry@n @end|ng |rom b|ngh@mton@edu  Wed May 26 18:01:30 2021
From: cry@n @end|ng |rom b|ngh@mton@edu (Christopher W Ryan)
Date: Wed, 26 May 2021 12:01:30 -0400
Subject: [R] 
 [External Email] Group by and add a constant value based on a
 condition dply
In-Reply-To: <354867589.557141.1622044346720@mail.yahoo.com>
References: <354867589.557141.1622044346720.ref@mail.yahoo.com>
 <354867589.557141.1622044346720@mail.yahoo.com>
Message-ID: <CAM+rpYmPn4F_FerB+KqB6+T4MaohGH0C97+T24p00ZGm7eB-Yg@mail.gmail.com>

Is the grouping beforehand necessary? Could you simply, "for all the dates
that are "4.01.2020"  and have the "Value" greater than zero  add 5 to the
"Value" "?  I may be missing something.

--Chris Ryan

On Wed, May 26, 2021 at 11:53 AM Elahe chalabi via R-help <
r-help at r-project.org> wrote:

> Hi everyone,
>
> I have the following dataframe:
>
>
>
>       structure(list(Department = c("A", "A", "A", "A", "A", "A", "A",
>      "A", "B", "B", "B", "B", "B", "B", "B", "B"), Class = c(1L, 1L,
>     1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L), Value = c(0L,
>     100L, 800L, 800L, 0L, 300L, 1200L, 0L, 0L, 0L, 400L, 400L, 200L,
>     800L, 1200L, 0L), Date = c("1.01.2020", "2.01.2020", "3.01.2020",
>     "4.01.2020", "1.01.2020", "2.01.2020", "3.01.2020", "4.01.2020",
>     "1.01.2020", "2.01.2020", "3.01.2020", "4.01.2020", "1.01.2020",
>     "2.01.2020", "3.01.2020", "4.01.2020")), class = "data.frame",
> row.names = c(NA,
>      -16L))
>
>  using dplyr I need to group by "Depatment" and "Class" and then for all
> the dates that are "4.01.2020"  and have the "Value" greater than zero  add
> 5 to the "Value", meaning the desired dataframe will be (NewValue column) :
>
>
>
>    structure(list(Department = c("A", "A", "A", "A", "A", "A", "A",
>  "A", "B", "B", "B", "B", "B", "B", "B", "B"), Class = c(1L, 1L,
>  1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L), Value = c(0L,
>  100L, 800L, 800L, 0L, 300L, 1200L, 0L, 0L, 0L, 400L, 400L, 200L,
>  800L, 1200L, 0L), Date = c("1.01.2020", "2.01.2020", "3.01.2020",
>  "4.01.2020", "1.01.2020", "2.01.2020", "3.01.2020", "4.01.2020",
>  "1.01.2020", "2.01.2020", "3.01.2020", "4.01.2020", "1.01.2020",
>  "2.01.2020", "3.01.2020", "4.01.2020"), NewValue = c(0L, 100L,
>  800L, 805L, 0L, 300L, 1200L, 0L, 0L, 0L, 400L, 405L, 200L, 800L,
>  1200L, 0L)), class = "data.frame", row.names = c(NA, -16L))
>
>
> Thanks a lot for any help!
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed May 26 19:20:48 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 26 May 2021 18:20:48 +0100
Subject: [R] 
 [External Email] Group by and add a constant value based on a
 condition dply
In-Reply-To: <CAM+rpYmPn4F_FerB+KqB6+T4MaohGH0C97+T24p00ZGm7eB-Yg@mail.gmail.com>
References: <354867589.557141.1622044346720.ref@mail.yahoo.com>
 <354867589.557141.1622044346720@mail.yahoo.com>
 <CAM+rpYmPn4F_FerB+KqB6+T4MaohGH0C97+T24p00ZGm7eB-Yg@mail.gmail.com>
Message-ID: <a3e7d81c-9e9a-9a6f-13eb-9f3ca6235c28@sapo.pt>

Hello,

I too don't see why grouping is needed but here it goes.


df1 %>%
   group_by(Department, Class) %>%
   mutate(Value = Value + 5*(Date == "4.01.2020"))


Hope this helps,

Rui Barradas

?s 17:01 de 26/05/21, Christopher W Ryan via R-help escreveu:
> Is the grouping beforehand necessary? Could you simply, "for all the dates
> that are "4.01.2020"  and have the "Value" greater than zero  add 5 to the
> "Value" "?  I may be missing something.
> 
> --Chris Ryan
> 
> On Wed, May 26, 2021 at 11:53 AM Elahe chalabi via R-help <
> r-help at r-project.org> wrote:
> 
>> Hi everyone,
>>
>> I have the following dataframe:
>>
>>
>>
>>        structure(list(Department = c("A", "A", "A", "A", "A", "A", "A",
>>       "A", "B", "B", "B", "B", "B", "B", "B", "B"), Class = c(1L, 1L,
>>      1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L), Value = c(0L,
>>      100L, 800L, 800L, 0L, 300L, 1200L, 0L, 0L, 0L, 400L, 400L, 200L,
>>      800L, 1200L, 0L), Date = c("1.01.2020", "2.01.2020", "3.01.2020",
>>      "4.01.2020", "1.01.2020", "2.01.2020", "3.01.2020", "4.01.2020",
>>      "1.01.2020", "2.01.2020", "3.01.2020", "4.01.2020", "1.01.2020",
>>      "2.01.2020", "3.01.2020", "4.01.2020")), class = "data.frame",
>> row.names = c(NA,
>>       -16L))
>>
>>   using dplyr I need to group by "Depatment" and "Class" and then for all
>> the dates that are "4.01.2020"  and have the "Value" greater than zero  add
>> 5 to the "Value", meaning the desired dataframe will be (NewValue column) :
>>
>>
>>
>>     structure(list(Department = c("A", "A", "A", "A", "A", "A", "A",
>>   "A", "B", "B", "B", "B", "B", "B", "B", "B"), Class = c(1L, 1L,
>>   1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L), Value = c(0L,
>>   100L, 800L, 800L, 0L, 300L, 1200L, 0L, 0L, 0L, 400L, 400L, 200L,
>>   800L, 1200L, 0L), Date = c("1.01.2020", "2.01.2020", "3.01.2020",
>>   "4.01.2020", "1.01.2020", "2.01.2020", "3.01.2020", "4.01.2020",
>>   "1.01.2020", "2.01.2020", "3.01.2020", "4.01.2020", "1.01.2020",
>>   "2.01.2020", "3.01.2020", "4.01.2020"), NewValue = c(0L, 100L,
>>   800L, 805L, 0L, 300L, 1200L, 0L, 0L, 0L, 400L, 405L, 200L, 800L,
>>   1200L, 0L)), class = "data.frame", row.names = c(NA, -16L))
>>
>>
>> Thanks a lot for any help!
>> Elahe
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From or|o|eb@|t|more @end|ng |rom gm@||@com  Wed May 26 23:16:58 2021
From: or|o|eb@|t|more @end|ng |rom gm@||@com (Adrian Johnson)
Date: Wed, 26 May 2021 17:16:58 -0400
Subject: [R] Decompose df1 into another df2 based on values in df1
Message-ID: <CAL2fYnMTvViEdO7W49kwpO2e7tazBjfeJ37tWKZBKMHFEaE+Wg@mail.gmail.com>

Hello,

I am trying to convert a df (given below as d1) into df2 (given below as
res).

 I tried using loops for each row. I cannot get it right.  Moreover the df
is 250000 x 500 in dimension and I cannot get it to work.

Could anyone help me here please.

Thanks.
Adrian.

d1 <-
structure(list(S1 = c("a1|a2", "b1|b3", "w"), S2 = c("w", "b1",
"c2"), S3 = c("a2", "b3|b4|b1", "c1|c4"), S4 = c("w", "b4", "c4"
), S5 = c("a2/a3", "w", "w")), class = "data.frame", row.names = c("A",
"B", "C"))

res <-
structure(list(S1 = c(1L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 0L),
    S2 = c(0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L), S3 = c(0L,
    1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 1L), S4 = c(0L, 0L, 0L, 0L,
    0L, 0L, 1L, 0L, 0L, 1L), S5 = c(0L, 1L, 1L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L)), class = "data.frame", row.names = c("a1", "a2",
"a3", "b1", "b2", "b3", "b4", "c1", "c2", "c4"))

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu May 27 02:28:14 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 26 May 2021 17:28:14 -0700
Subject: [R] Decompose df1 into another df2 based on values in df1
In-Reply-To: <CAL2fYnMTvViEdO7W49kwpO2e7tazBjfeJ37tWKZBKMHFEaE+Wg@mail.gmail.com>
References: <CAL2fYnMTvViEdO7W49kwpO2e7tazBjfeJ37tWKZBKMHFEaE+Wg@mail.gmail.com>
Message-ID: <CAGxFJbQXdMh+ZaJVhLGw+M_HYikG5yb3ms1WAyFg=ECcwyfYvQ@mail.gmail.com>

Thank you for the reprex. However your specification was too vague for me
to know exactly what your data are like, so I tried to assume the most
general possibility, with the consequence that I may be giving you an
answer to the wrong question. Hopefully, you can adjust as needed to get
what you want.

I need also warn you that I am nearly certain there are more elegant,
cleverer, faster ways to do this. I just used simple tools. So you may wish
to wait a bit to see whether others can improve on my attempt.

First of all, I assumed the "a2/a3" in S5 in d1 is a typo and it should be
"a2|a3". If it is is not a typo then substitute "\\||\\/" for "\\|" in the
strsplit function in the code that follows.
Secondly, I assumed that your identifiers, "a1" for example, could occur
more than 1 time in your data. If the only possibilities are 0 or 1 times,
then the code I provided --in particular the last sapply-- is too
complicated. A faster approach in that case might be to use R's outer()
function; I leave that as an exercise for you or someone else to help you
with if so.

Here is my code for your reprex:

getall<- function(x){
   ul <-unlist(strsplit(x,"\\|"))
   ul[ul != "w"]
}
allvals <- lapply(d1, getall)
uneeks <- sort(unique(unlist(allvals)))
sapply(allvals, function(x)table(factor(x, levels = uneeks)))


## which gives
> sapply(allvals, function(x)table(factor(x, levels = uneeks)))
   S1 S2 S3 S4 S5
a1  1  0  0  0  0
a2  1  0  1  0  1
a3  0  0  0  0  1
b1  1  1  1  0  0
b3  1  0  1  0  0
b4  0  0  1  1  0
c1  0  0  1  0  0
c2  0  1  0  0  0
c4  0  0  1  1  0

Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, May 26, 2021 at 2:18 PM Adrian Johnson <oriolebaltimore at gmail.com>
wrote:

> Hello,
>
> I am trying to convert a df (given below as d1) into df2 (given below as
> res).
>
>  I tried using loops for each row. I cannot get it right.  Moreover the df
> is 250000 x 500 in dimension and I cannot get it to work.
>
> Could anyone help me here please.
>
> Thanks.
> Adrian.
>
> d1 <-
> structure(list(S1 = c("a1|a2", "b1|b3", "w"), S2 = c("w", "b1",
> "c2"), S3 = c("a2", "b3|b4|b1", "c1|c4"), S4 = c("w", "b4", "c4"
> ), S5 = c("a2/a3", "w", "w")), class = "data.frame", row.names = c("A",
> "B", "C"))
>
> res <-
> structure(list(S1 = c(1L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 0L),
>     S2 = c(0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L), S3 = c(0L,
>     1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 1L), S4 = c(0L, 0L, 0L, 0L,
>     0L, 0L, 1L, 0L, 0L, 1L), S5 = c(0L, 1L, 1L, 0L, 0L, 0L, 0L,
>     0L, 0L, 0L)), class = "data.frame", row.names = c("a1", "a2",
> "a3", "b1", "b2", "b3", "b4", "c1", "c2", "c4"))
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Thu May 27 05:27:03 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Thu, 27 May 2021 15:27:03 +1200
Subject: [R] Testing optimization solvers with equality constraints
In-Reply-To: <1dc89ac6-0f4b-00be-9076-8240c135f6d8@gmail.com>
References: <CAML4n3MWBKg3vzxHN8yWzg=dfyijBvX_SLRZHwP-OetJyXb8Aw@mail.gmail.com>
 <CAB8pepznXQuvLwN6ZYFiyVXqZofwbdwc76vvUYjxNu7qufG3_A@mail.gmail.com>
 <CAML4n3PgQaMt6aACjJRC+Bi5f98fnzLMH1CpdV5P3EpPYH58Xg@mail.gmail.com>
 <CAB8pepxD2spsGRx0nLTGBJEE-aWjceowxtRC_OPY1gfw5rKs+Q@mail.gmail.com>
 <CAB8pepxkARh8EbRBJyndoRhCcHV9XzUsO9xhy--oFSb7LhJghA@mail.gmail.com>
 <1dc89ac6-0f4b-00be-9076-8240c135f6d8@gmail.com>
Message-ID: <CAB8pepzKqf0kUdYFWUYOtsw77Ga5nSdo+hDiAEm6oNYv_pfXMA@mail.gmail.com>

I need to retract my previous post.
(Except the part that the R has extremely good numerical capabilities).

I ran some of the examples, and Hans W was correct.


From y@ngk@|9999 @end|ng |rom y@hoo@com  Thu May 27 06:29:10 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Thu, 27 May 2021 04:29:10 +0000 (UTC)
Subject: [R] R grep question
References: <1110804826.344460.1622089750541.ref@mail.yahoo.com>
Message-ID: <1110804826.344460.1622089750541@mail.yahoo.com>

Hi List,
I wrote the code to create a new variable:
CRC$MMR.gene<-ifelse(grep("MLH1"|"MSH2",CRC$gene.all,value=T),"Yes","No")
?

I need to create MMR.gene column in CRC data frame, ifgene.all column contenes MLH1 or MSH2, then the MMR.gene=Yes, if not,MMR.gene=No

But, the code doesn't work for me. Can anyone tell how to fix the code?

Thank you,

Kai
	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Thu May 27 08:00:14 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Thu, 27 May 2021 18:00:14 +1200
Subject: [R] Testing optimization solvers with equality constraints
In-Reply-To: <CAB8pepzKqf0kUdYFWUYOtsw77Ga5nSdo+hDiAEm6oNYv_pfXMA@mail.gmail.com>
References: <CAML4n3MWBKg3vzxHN8yWzg=dfyijBvX_SLRZHwP-OetJyXb8Aw@mail.gmail.com>
 <CAB8pepznXQuvLwN6ZYFiyVXqZofwbdwc76vvUYjxNu7qufG3_A@mail.gmail.com>
 <CAML4n3PgQaMt6aACjJRC+Bi5f98fnzLMH1CpdV5P3EpPYH58Xg@mail.gmail.com>
 <CAB8pepxD2spsGRx0nLTGBJEE-aWjceowxtRC_OPY1gfw5rKs+Q@mail.gmail.com>
 <CAB8pepxkARh8EbRBJyndoRhCcHV9XzUsO9xhy--oFSb7LhJghA@mail.gmail.com>
 <1dc89ac6-0f4b-00be-9076-8240c135f6d8@gmail.com>
 <CAB8pepzKqf0kUdYFWUYOtsw77Ga5nSdo+hDiAEm6oNYv_pfXMA@mail.gmail.com>
Message-ID: <CAB8pepwjVNYAyS24bSnCPw3JFxyu7cskXso5ckyiewX6fzqetg@mail.gmail.com>

If I can re-answer the original post:
There's a relatively simple solution.
(For these problems, at least).

#wrong
x0 = c (1, 0, 0)
NlcOptim::solnl(x0, objfun = f, confun = conf)$par
Rdonlp2::donlp2(x0, fn = f, nlin = list(heq), nlin.lower = 0,
nlin.upper = 0)$par

#right
x0 = c (1, 1e6, 0)
NlcOptim::solnl(x0, objfun = f, confun = conf)$par
Rdonlp2::donlp2(x0, fn = f, nlin = list(heq), nlin.lower = 0,
nlin.upper = 0)$par

So, problems with the starting point, appear to be very *specific*.
Hence, a small amount of intentional error resolves the problem.

Presumably, there are more efficient solutions, that the package
maintainers may (or may not) want to address.


On Thu, May 27, 2021 at 3:27 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> I need to retract my previous post.
> (Except the part that the R has extremely good numerical capabilities).
>
> I ran some of the examples, and Hans W was correct.


From @purd|e@@ @end|ng |rom gm@||@com  Thu May 27 08:03:52 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Thu, 27 May 2021 18:03:52 +1200
Subject: [R] Testing optimization solvers with equality constraints
In-Reply-To: <CAB8pepwjVNYAyS24bSnCPw3JFxyu7cskXso5ckyiewX6fzqetg@mail.gmail.com>
References: <CAML4n3MWBKg3vzxHN8yWzg=dfyijBvX_SLRZHwP-OetJyXb8Aw@mail.gmail.com>
 <CAB8pepznXQuvLwN6ZYFiyVXqZofwbdwc76vvUYjxNu7qufG3_A@mail.gmail.com>
 <CAML4n3PgQaMt6aACjJRC+Bi5f98fnzLMH1CpdV5P3EpPYH58Xg@mail.gmail.com>
 <CAB8pepxD2spsGRx0nLTGBJEE-aWjceowxtRC_OPY1gfw5rKs+Q@mail.gmail.com>
 <CAB8pepxkARh8EbRBJyndoRhCcHV9XzUsO9xhy--oFSb7LhJghA@mail.gmail.com>
 <1dc89ac6-0f4b-00be-9076-8240c135f6d8@gmail.com>
 <CAB8pepzKqf0kUdYFWUYOtsw77Ga5nSdo+hDiAEm6oNYv_pfXMA@mail.gmail.com>
 <CAB8pepwjVNYAyS24bSnCPw3JFxyu7cskXso5ckyiewX6fzqetg@mail.gmail.com>
Message-ID: <CAB8pepwb9Qk8ZAcL6zzYP8F9yO9EPSDP8djmyvjyia0N5E8ZtA@mail.gmail.com>

I meant:
x0 = c (1, 1e-3, 0)

Not:
x0 = c (1, 1e6, 0)

So, large intentional error may work too.
Possibly, better...?

On Thu, May 27, 2021 at 6:00 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> If I can re-answer the original post:
> There's a relatively simple solution.
> (For these problems, at least).
>
> #wrong
> x0 = c (1, 0, 0)
> NlcOptim::solnl(x0, objfun = f, confun = conf)$par
> Rdonlp2::donlp2(x0, fn = f, nlin = list(heq), nlin.lower = 0,
> nlin.upper = 0)$par
>
> #right
> x0 = c (1, 1e6, 0)
> NlcOptim::solnl(x0, objfun = f, confun = conf)$par
> Rdonlp2::donlp2(x0, fn = f, nlin = list(heq), nlin.lower = 0,
> nlin.upper = 0)$par
>
> So, problems with the starting point, appear to be very *specific*.
> Hence, a small amount of intentional error resolves the problem.
>
> Presumably, there are more efficient solutions, that the package
> maintainers may (or may not) want to address.
>
>
> On Thu, May 27, 2021 at 3:27 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
> >
> > I need to retract my previous post.
> > (Except the part that the R has extremely good numerical capabilities).
> >
> > I ran some of the examples, and Hans W was correct.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu May 27 08:17:54 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 26 May 2021 23:17:54 -0700
Subject: [R] R grep question
In-Reply-To: <1110804826.344460.1622089750541@mail.yahoo.com>
References: <1110804826.344460.1622089750541.ref@mail.yahoo.com>
 <1110804826.344460.1622089750541@mail.yahoo.com>
Message-ID: <789B0C4D-8C0A-417A-9C6E-C25AB4818A2C@dcn.davis.ca.us>

Post in plain text

Use grepl

On May 26, 2021 9:29:10 PM PDT, Kai Yang via R-help <r-help at r-project.org> wrote:
>Hi List,
>I wrote the code to create a new variable:
>CRC$MMR.gene<-ifelse(grep("MLH1"|"MSH2",CRC$gene.all,value=T),"Yes","No")
>?
>
>I need to create MMR.gene column in CRC data frame, ifgene.all column
>contenes MLH1 or MSH2, then the MMR.gene=Yes, if not,MMR.gene=No
>
>But, the code doesn't work for me. Can anyone tell how to fix the code?
>
>Thank you,
>
>Kai
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu May 27 10:37:48 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 27 May 2021 09:37:48 +0100
Subject: [R] R grep question
In-Reply-To: <1110804826.344460.1622089750541@mail.yahoo.com>
References: <1110804826.344460.1622089750541.ref@mail.yahoo.com>
 <1110804826.344460.1622089750541@mail.yahoo.com>
Message-ID: <7cf01e03-ac9f-0f2c-acb6-12d8ca412b49@sapo.pt>

Hello,

ifelse needs a logical condition, not the value. Try grepl.


CRC$MMR.gene <- ifelse(grepl("MLH1"|"MSH2",CRC$gene.all), "Yes", "No")


Hope this helps,

Rui Barradas

?s 05:29 de 27/05/21, Kai Yang via R-help escreveu:
> Hi List,
> I wrote the code to create a new variable:
> CRC$MMR.gene<-ifelse(grep("MLH1"|"MSH2",CRC$gene.all,value=T),"Yes","No")
>   
> 
> I need to create MMR.gene column in CRC data frame, ifgene.all column contenes MLH1 or MSH2, then the MMR.gene=Yes, if not,MMR.gene=No
> 
> But, the code doesn't work for me. Can anyone tell how to fix the code?
> 
> Thank you,
> 
> Kai
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From E@Vettor@zz| @end|ng |rom uke@de  Thu May 27 12:16:33 2021
From: E@Vettor@zz| @end|ng |rom uke@de (Eik Vettorazzi)
Date: Thu, 27 May 2021 12:16:33 +0200
Subject: [R] Decompose df1 into another df2 based on values in df1
In-Reply-To: <CAL2fYnMTvViEdO7W49kwpO2e7tazBjfeJ37tWKZBKMHFEaE+Wg@mail.gmail.com>
References: <CAL2fYnMTvViEdO7W49kwpO2e7tazBjfeJ37tWKZBKMHFEaE+Wg@mail.gmail.com>
Message-ID: <aaba25f8-e7e3-b0c2-ac04-860b0b65349b@uke.de>

A tidyverse-ish solution would be

library(dplyr)
library(tidyr)
library(tibble)

# max cols to split values into
seps<-max(stringr::str_count(unlist(d1),"[/|]"))+1

d1 %>% pivot_longer(S1:S5, names_to="S") %>% 
mutate(value=na_if(value,"w")) %>% separate(value,"[/|]", 
into=LETTERS[1:seps], fill="right") %>% pivot_longer(-S, names_to=NULL, 
values_to="rownames") %>% filter(!is.na(rownames)) %>% 
mutate(index=1L)%>%pivot_wider(names_from=S, values_from=index) %>% 
mutate_all(replace_na,0L) %>% column_to_rownames(var = "rownames")

Best, Eik
	
Am 26.05.2021 um 23:16 schrieb Adrian Johnson:
> Hello,
> 
> I am trying to convert a df (given below as d1) into df2 (given below as
> res).
> 
>   I tried using loops for each row. I cannot get it right.  Moreover the df
> is 250000 x 500 in dimension and I cannot get it to work.
> 
> Could anyone help me here please.
> 
> Thanks.
> Adrian.
> 
> d1 <-
> structure(list(S1 = c("a1|a2", "b1|b3", "w"), S2 = c("w", "b1",
> "c2"), S3 = c("a2", "b3|b4|b1", "c1|c4"), S4 = c("w", "b4", "c4"
> ), S5 = c("a2/a3", "w", "w")), class = "data.frame", row.names = c("A",
> "B", "C"))
> 
> res <-
> structure(list(S1 = c(1L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 0L),
>      S2 = c(0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L), S3 = c(0L,
>      1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 1L), S4 = c(0L, 0L, 0L, 0L,
>      0L, 0L, 1L, 0L, 0L, 1L), S5 = c(0L, 1L, 1L, 0L, 0L, 0L, 0L,
>      0L, 0L, 0L)), class = "data.frame", row.names = c("a1", "a2",
> "a3", "b1", "b2", "b3", "b4", "c1", "c2", "c4"))
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 




--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Joachim Pr?l?, Prof. Dr. Blanche Schwappach-Pignataro, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

From @gne@g2g @end|ng |rom hotm@||@com  Thu May 27 12:22:11 2021
From: @gne@g2g @end|ng |rom hotm@||@com (Agnes g2g)
Date: Thu, 27 May 2021 10:22:11 +0000
Subject: [R] multilabel classification XGBoost and hyperparameter tuning
Message-ID: <AM0PR0602MB34278DDA9450D72F950CF01283239@AM0PR0602MB3427.eurprd06.prod.outlook.com>

Hi all,

I want to do multilabel classification with XGBoost and tune hyperparameters.
With the mlr package this does not seem possible, see https://stackoverflow.com/questions/67640953/feature-names-stored-in-object-and-newdata-are-different-using-mlr-package?noredirect=1#comment119651508_67640953

Any ideas how to solve this?

What other packages support multilabel classification for XGBoost and has the possibility to tune hyperparameters?

Thanks in advance!

Bye,
Agnes

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu May 27 16:44:50 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 27 May 2021 07:44:50 -0700
Subject: [R] multilabel classification XGBoost and hyperparameter tuning
In-Reply-To: <AM0PR0602MB34278DDA9450D72F950CF01283239@AM0PR0602MB3427.eurprd06.prod.outlook.com>
References: <AM0PR0602MB34278DDA9450D72F950CF01283239@AM0PR0602MB3427.eurprd06.prod.outlook.com>
Message-ID: <CAGxFJbSC10C8WZmcWBwTgony6z8EuO8VMWD6SYFeLpLniaNohw@mail.gmail.com>

1. A web search on "xgboost R" brought up R package "xgboost" which you did
not mention. Did you not first try a web search or did you find that it did
not meet your needs?

2. Have you looked here:  https://cran.r-project.org/web/views/Cluster.html
or here: https://cran.r-project.org/web/views/MachineLearning.html

Cran's "task views" are a useful resource for such "does R have...?"
questions.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, May 27, 2021 at 7:29 AM Agnes g2g <agnesg2g at hotmail.com> wrote:

> Hi all,
>
> I want to do multilabel classification with XGBoost and tune
> hyperparameters.
> With the mlr package this does not seem possible, see
> https://stackoverflow.com/questions/67640953/feature-names-stored-in-object-and-newdata-are-different-using-mlr-package?noredirect=1#comment119651508_67640953
>
> Any ideas how to solve this?
>
> What other packages support multilabel classification for XGBoost and has
> the possibility to tune hyperparameters?
>
> Thanks in advance!
>
> Bye,
> Agnes
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From y@ngk@|9999 @end|ng |rom y@hoo@com  Thu May 27 17:23:59 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Thu, 27 May 2021 15:23:59 +0000 (UTC)
Subject: [R] R grep question
In-Reply-To: <7cf01e03-ac9f-0f2c-acb6-12d8ca412b49@sapo.pt>
References: <1110804826.344460.1622089750541.ref@mail.yahoo.com>
 <1110804826.344460.1622089750541@mail.yahoo.com>
 <7cf01e03-ac9f-0f2c-acb6-12d8ca412b49@sapo.pt>
Message-ID: <847153983.434217.1622129039547@mail.yahoo.com>

 Hi Rui,thank you for your suggestion.?
but when I try the solution, I got message below:

Error in "MLH1" | "MSH2" :?? operations are possible only for numeric, logical or complex types

does it mean, grepl can not work on character field?
Thanks,Kai    On Thursday, May 27, 2021, 01:37:58 AM PDT, Rui Barradas <ruipbarradas at sapo.pt> wrote:  
 
 Hello,

ifelse needs a logical condition, not the value. Try grepl.


CRC$MMR.gene <- ifelse(grepl("MLH1"|"MSH2",CRC$gene.all), "Yes", "No")


Hope this helps,

Rui Barradas

?s 05:29 de 27/05/21, Kai Yang via R-help escreveu:
> Hi List,
> I wrote the code to create a new variable:
> CRC$MMR.gene<-ifelse(grep("MLH1"|"MSH2",CRC$gene.all,value=T),"Yes","No")
>? 
> 
> I need to create MMR.gene column in CRC data frame, ifgene.all column contenes MLH1 or MSH2, then the MMR.gene=Yes, if not,MMR.gene=No
> 
> But, the code doesn't work for me. Can anyone tell how to fix the code?
> 
> Thank you,
> 
> Kai
> ??? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
  
	[[alternative HTML version deleted]]


From m@rc_@chw@rtz @end|ng |rom me@com  Thu May 27 17:56:51 2021
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Thu, 27 May 2021 11:56:51 -0400
Subject: [R] R grep question
In-Reply-To: <847153983.434217.1622129039547@mail.yahoo.com>
References: <1110804826.344460.1622089750541.ref@mail.yahoo.com>
 <1110804826.344460.1622089750541@mail.yahoo.com>
 <7cf01e03-ac9f-0f2c-acb6-12d8ca412b49@sapo.pt>
 <847153983.434217.1622129039547@mail.yahoo.com>
Message-ID: <04861b9e-718b-c49c-6573-357ea1ba2ad3@me.com>

Hi,

A quick clarification:

The regular expression is a single quoted character vector, not a 
character vector on either side of the | operator:

"MLH1|MSH2"

not:

"MLH1"|"MSH2"

The | is treated as a special character within the regular expression. 
See ?regex.

grep(), when value = FALSE, returns the index of the match within the 
source vector, while when value = TRUE, returns the found character 
entries themselves.

Thus, you need to be sure that your ifelse() incantation is matching the 
correct values.

In the case of grepl(), it returns TRUE or FALSE, as Rui noted, thus:

   CRC$MMR.gene <- ifelse(grepl("MLH1|MSH2",CRC$gene.all), "Yes", "No")

should work.

Regards,

Marc Schwartz


Kai Yang via R-help wrote on 5/27/21 11:23 AM:
>   Hi Rui,thank you for your suggestion.
> but when I try the solution, I got message below:
> 
> Error in "MLH1" | "MSH2" :?? operations are possible only for numeric, logical or complex types
> 
> does it mean, grepl can not work on character field?
> Thanks,Kai    On Thursday, May 27, 2021, 01:37:58 AM PDT, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>   
>   Hello,
> 
> ifelse needs a logical condition, not the value. Try grepl.
> 
> 
> CRC$MMR.gene <- ifelse(grepl("MLH1"|"MSH2",CRC$gene.all), "Yes", "No")
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 05:29 de 27/05/21, Kai Yang via R-help escreveu:
>> Hi List,
>> I wrote the code to create a new variable:
>> CRC$MMR.gene<-ifelse(grep("MLH1"|"MSH2",CRC$gene.all,value=T),"Yes","No")
>>    
>>
>> I need to create MMR.gene column in CRC data frame, ifgene.all column contenes MLH1 or MSH2, then the MMR.gene=Yes, if not,MMR.gene=No
>>
>> But, the code doesn't work for me. Can anyone tell how to fix the code?
>>
>> Thank you,
>>
>> Kai


From bgunter@4567 @end|ng |rom gm@||@com  Thu May 27 18:06:28 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 27 May 2021 09:06:28 -0700
Subject: [R] multilabel classification XGBoost and hyperparameter tuning
In-Reply-To: <AM0PR0602MB34274BBA07DFC3DCFB8BF8CB83239@AM0PR0602MB3427.eurprd06.prod.outlook.com>
References: <AM0PR0602MB34278DDA9450D72F950CF01283239@AM0PR0602MB3427.eurprd06.prod.outlook.com>
 <CAGxFJbSC10C8WZmcWBwTgony6z8EuO8VMWD6SYFeLpLniaNohw@mail.gmail.com>
 <AM0PR0602MB34274BBA07DFC3DCFB8BF8CB83239@AM0PR0602MB3427.eurprd06.prod.outlook.com>
Message-ID: <CAGxFJbSCQnLzE0fwC2_b8cpZjx2b7UJCBYGFuGm21s0gJycBTg@mail.gmail.com>

One other suggestion. Per the posting guide linked below, statistical
issues such as your query on "hyperparameter tuning" are off topic on this
list, as are questions about specific nonstandard packages. You might try
posting on stats.stackexchange.com instead for help on such matters.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, May 27, 2021 at 7:51 AM Agnes g2g <agnesg2g at hotmail.com> wrote:

> Thank you for your reply.
> As far as I can see xgboost package does not provide multilabel
> classification.
> The mlr package uses a wrapper for xgboost, so I have used the package
> xgboost. But I still have the problem with the hyperparameter tuning.
>
> Did I understand you correctly?
> Do you have any other suggestion?
>
> Bye,
> Agnes
>
> ------------------------------
> *Van:* Bert Gunter <bgunter.4567 at gmail.com>
> *Verzonden:* donderdag 27 mei 2021 16:44
> *Aan:* Agnes g2g <agnesg2g at hotmail.com>
> *CC:* r-help at r-project.org <r-help at r-project.org>
> *Onderwerp:* Re: [R] multilabel classification XGBoost and hyperparameter
> tuning
>
> 1. A web search on "xgboost R" brought up R package "xgboost" which you
> did not mention. Did you not first try a web search or did you find that it
> did not meet your needs?
>
> 2. Have you looked here:
> https://cran.r-project.org/web/views/Cluster.html
> or here: https://cran.r-project.org/web/views/MachineLearning.html
>
> Cran's "task views" are a useful resource for such "does R have...?"
> questions.
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, May 27, 2021 at 7:29 AM Agnes g2g <agnesg2g at hotmail.com> wrote:
>
> Hi all,
>
> I want to do multilabel classification with XGBoost and tune
> hyperparameters.
> With the mlr package this does not seem possible, see
> https://stackoverflow.com/questions/67640953/feature-names-stored-in-object-and-newdata-are-different-using-mlr-package?noredirect=1#comment119651508_67640953
>
> Any ideas how to solve this?
>
> What other packages support multilabel classification for XGBoost and has
> the possibility to tune hyperparameters?
>
> Thanks in advance!
>
> Bye,
> Agnes
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From @gne@g2g @end|ng |rom hotm@||@com  Thu May 27 16:51:18 2021
From: @gne@g2g @end|ng |rom hotm@||@com (Agnes g2g)
Date: Thu, 27 May 2021 14:51:18 +0000
Subject: [R] multilabel classification XGBoost and hyperparameter tuning
In-Reply-To: <CAGxFJbSC10C8WZmcWBwTgony6z8EuO8VMWD6SYFeLpLniaNohw@mail.gmail.com>
References: <AM0PR0602MB34278DDA9450D72F950CF01283239@AM0PR0602MB3427.eurprd06.prod.outlook.com>,
 <CAGxFJbSC10C8WZmcWBwTgony6z8EuO8VMWD6SYFeLpLniaNohw@mail.gmail.com>
Message-ID: <AM0PR0602MB34274BBA07DFC3DCFB8BF8CB83239@AM0PR0602MB3427.eurprd06.prod.outlook.com>

Thank you for your reply.
As far as I can see xgboost package does not provide multilabel classification.
The mlr package uses a wrapper for xgboost, so I have used the package xgboost. But I still have the problem with the hyperparameter tuning.

Did I understand you correctly?
Do you have any other suggestion?

Bye,
Agnes

________________________________
Van: Bert Gunter <bgunter.4567 at gmail.com>
Verzonden: donderdag 27 mei 2021 16:44
Aan: Agnes g2g <agnesg2g at hotmail.com>
CC: r-help at r-project.org <r-help at r-project.org>
Onderwerp: Re: [R] multilabel classification XGBoost and hyperparameter tuning

1. A web search on "xgboost R" brought up R package "xgboost" which you did not mention. Did you not first try a web search or did you find that it did not meet your needs?

2. Have you looked here:  https://cran.r-project.org/web/views/Cluster.html
or here: https://cran.r-project.org/web/views/MachineLearning.html

Cran's "task views" are a useful resource for such "does R have...?" questions.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, May 27, 2021 at 7:29 AM Agnes g2g <agnesg2g at hotmail.com<mailto:agnesg2g at hotmail.com>> wrote:
Hi all,

I want to do multilabel classification with XGBoost and tune hyperparameters.
With the mlr package this does not seem possible, see https://stackoverflow.com/questions/67640953/feature-names-stored-in-object-and-newdata-are-different-using-mlr-package?noredirect=1#comment119651508_67640953

Any ideas how to solve this?

What other packages support multilabel classification for XGBoost and has the possibility to tune hyperparameters?

Thanks in advance!

Bye,
Agnes

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From Ju@t|n@A||en @end|ng |rom bregroup@com  Thu May 27 12:27:31 2021
From: Ju@t|n@A||en @end|ng |rom bregroup@com (Allen, Justin)
Date: Thu, 27 May 2021 10:27:31 +0000
Subject: [R] foreign package read.spss() and NA levels
Message-ID: <LO2P265MB31178ADC394E34613C9212E5E4239@LO2P265MB3117.GBRP265.PROD.OUTLOOK.COM>

Hi All,

Wanted to report what may be a bug or possibly an oversight, but I am unsure, in the "foreign" packages in the read.spss() command, https://cran.r-project.org/web/packages/foreign/index.html. When running the following code,

input <- read.spss("[.sav file location]", to.data.frame = TRUE)
str(input)

The read.spss() seems to be applying addNA() to factors so NA is being set as a level, and there seems to be no way to get read.spss() to bring factors in without doing this. This seems to be a recent change as read.spss() was not doing this as of a few months ago. None of the arguments in read.spss() seem to also stop this behaviour. I am currently on the most recent version of both R and the package, as of 27/05/21, and am using RStudio Version 1.4.1106.

Any thoughts?

Many Thanks,

Justin Allen

p.s. your continued maintenance and additions to R and its packages have been infinitely useful in my work and life and thank for that.

Justin Allen
Housing Consultant, BRE<https://bregroup.com/>
T: 07807122647

________________________________
Follow BRE on Twitter: @BRE_Group<http://twitter.com/BRE_Group>
________________________________
Privileged and confidential information and/or copyright material may be contained in this e-mail. If you are not the intended addressee you may not copy or deliver it to anyone else or use it in any unauthorised manner. To do so is prohibited and may be unlawful. If you have received this e-mail by mistake, please advise the sender immediately by return e-mail and destroy all copies. Thank you.

Building Research Establishment Ltd, Registered under number 3319324 in England and Wales. VAT Registration No GB 689 9499 27 www.bregroup.com<http://www.bregroup.com>
BRE Global Limited, Registered under number 8961297 in England and Wales. www.breglobal.com<http://www.breglobal.com>
Building Research Establishment and BRE Global are subsidiaries of the BRE Trust.
BRE Trust is a company limited by guarantee, Registered under number 3282856 in England and Wales, and registered as a charity in England (no. 1092193) and in Scotland (no. SC039320). www.bretrust.org.uk<http://www.bretrust.org.uk>
Registered Offices: Bucknalls Lane, Garston, Watford, Hertfordshire WD25 9XX - Travelling to BRE: see www.bregroup.com/contact/directions/<http://www.bregroup.com/contact/directions/>
________________________________

	[[alternative HTML version deleted]]


From co|or|e @end|ng |rom gm@||@com  Thu May 27 22:33:04 2021
From: co|or|e @end|ng |rom gm@||@com (Carlos Ortega)
Date: Thu, 27 May 2021 22:33:04 +0200
Subject: [R] multilabel classification XGBoost and hyperparameter tuning
In-Reply-To: <AM0PR0602MB34274BBA07DFC3DCFB8BF8CB83239@AM0PR0602MB3427.eurprd06.prod.outlook.com>
References: <AM0PR0602MB34278DDA9450D72F950CF01283239@AM0PR0602MB3427.eurprd06.prod.outlook.com>
 <CAGxFJbSC10C8WZmcWBwTgony6z8EuO8VMWD6SYFeLpLniaNohw@mail.gmail.com>
 <AM0PR0602MB34274BBA07DFC3DCFB8BF8CB83239@AM0PR0602MB3427.eurprd06.prod.outlook.com>
Message-ID: <CAFKNbkK7ha0nkorkc6qjVgT7rRhLb-Rz38r8909075VkPsMMnQ@mail.gmail.com>

Hello Agnes,

Yes, it is true, "xgboost" is not oriented for a "multi-label"
classification. "xgboost" can handle "multi-class" but not "multi-label".

Bue in "mlr", you can handle "multi-class" problems although not with
"xgboost" a base learner algorithm. You can see here how you can handle
that with "mlr":


   - https://mlr.mlr-org.com/articles/tutorial/multilabel.html


Besides that, you can see if these other alternatives could work for your
problem:

   - "utiml" was one of them but now it's not avaialble on CRAN (
   https://github.com/rivolli/utiml).
   - And this other one "mldr" could help you out:
   https://cran.r-project.org/web/packages/mldr/vignettes/mldr.pdf.

Thanks,
Carlos.

On Thu, May 27, 2021 at 7:30 PM Agnes g2g <agnesg2g at hotmail.com> wrote:

> Thank you for your reply.
> As far as I can see xgboost package does not provide multilabel
> classification.
> The mlr package uses a wrapper for xgboost, so I have used the package
> xgboost. But I still have the problem with the hyperparameter tuning.
>
> Did I understand you correctly?
> Do you have any other suggestion?
>
> Bye,
> Agnes
>
> ________________________________
> Van: Bert Gunter <bgunter.4567 at gmail.com>
> Verzonden: donderdag 27 mei 2021 16:44
> Aan: Agnes g2g <agnesg2g at hotmail.com>
> CC: r-help at r-project.org <r-help at r-project.org>
> Onderwerp: Re: [R] multilabel classification XGBoost and hyperparameter
> tuning
>
> 1. A web search on "xgboost R" brought up R package "xgboost" which you
> did not mention. Did you not first try a web search or did you find that it
> did not meet your needs?
>
> 2. Have you looked here:
> https://cran.r-project.org/web/views/Cluster.html
> or here: https://cran.r-project.org/web/views/MachineLearning.html
>
> Cran's "task views" are a useful resource for such "does R have...?"
> questions.
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, May 27, 2021 at 7:29 AM Agnes g2g <agnesg2g at hotmail.com<mailto:
> agnesg2g at hotmail.com>> wrote:
> Hi all,
>
> I want to do multilabel classification with XGBoost and tune
> hyperparameters.
> With the mlr package this does not seem possible, see
> https://stackoverflow.com/questions/67640953/feature-names-stored-in-object-and-newdata-are-different-using-mlr-package?noredirect=1#comment119651508_67640953
>
> Any ideas how to solve this?
>
> What other packages support multilabel classification for XGBoost and has
> the possibility to tune hyperparameters?
>
> Thanks in advance!
>
> Bye,
> Agnes
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ggrothend|eck @end|ng |rom gm@||@com  Fri May 28 01:13:50 2021
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Thu, 27 May 2021 19:13:50 -0400
Subject: [R] Testing optimization solvers with equality constraints
In-Reply-To: <CAML4n3MWBKg3vzxHN8yWzg=dfyijBvX_SLRZHwP-OetJyXb8Aw@mail.gmail.com>
References: <CAML4n3MWBKg3vzxHN8yWzg=dfyijBvX_SLRZHwP-OetJyXb8Aw@mail.gmail.com>
Message-ID: <CAP01uRkBi-47r_v0GCaqZPT2Snae4h6hD1cZYa+6T5DvYM33kg@mail.gmail.com>

In case it is of interest this problem can be solved with an
unconstrained optimizer,
here optim, like this:

    proj <- function(x) x / sqrt(sum(x * x))
    opt <- optim(c(0, 0, 1), function(x) f(proj(x)))
    proj(opt$par)
    ## [1] 5.388907e-09 7.071068e-01 7.071068e-01

On Fri, May 21, 2021 at 11:01 AM Hans W <hwborchers at gmail.com> wrote:
>
> Just by chance I came across the following example of minimizing
> a simple function
>
>     (x,y,z) --> 2 (x^2 - y z)
>
> on the unit sphere, the only constraint present.
> I tried it with two starting points, x1 = (1,0,0) and x2 = (0,0,1).
>
>     #-- Problem definition in R
>     f = function(x)  2 * (x[1]^2 - x[2]*x[3])   # (x,y,z) |-> 2(x^2 -yz)
>     g = function(x)  c(4*x[1], 2*x[3], 2*x[2])  # its gradient
>
>     x0 = c(1, 0, 0); x1 = c(0, 0, 1)            # starting points
>     xmin = c(0, 1/sqrt(2), 1/sqrt(2))           # true minimum -1
>
>     heq = function(x)  1-x[1]^2-x[2]^2-x[3]^2   # staying on the sphere
>     conf = function(x) {                        # constraint function
>         fun = x[1]^2 + x[2]^2 + x[3]^2 - 1
>         return(list(ceq = fun, c = NULL))
>     }
>
> I tried all the nonlinear optimization solvers in R packages that
> allow for equality constraints: 'auglag()' in alabama, 'solnl()' in
> NlcOptim, 'auglag()' in nloptr, 'solnp()' in Rsolnp, or even 'donlp2()'
> from the Rdonlp2 package (on R-Forge).
>
> None of them worked from both starting points:
>
>     # alabama
>     alabama::auglag(x0, fn = f, gr = g, heq = heq)  # right (inaccurate)
>     alabama::auglag(x1, fn = f, gr = g, heq = heq)  # wrong
>
>     # NlcOptim
>     NlcOptim::solnl(x0, objfun = f, confun = conf)  # wrong
>     NlcOptim::solnl(x1, objfun = f, confun = conf)  # right
>
>     # nloptr
>     nloptr::auglag(x0, fn = f, heq = heq)           # wrong
>     # nloptr::auglag(x1, fn = f, heq = heq)         # not returning
>
>     # Rsolnp
>     Rsolnp::solnp(x0, fun = f, eqfun = heq)         # wrong
>     Rsolnp::solnp(x1, fun = f, eqfun = heq)         # wrong
>
>     # Rdonlp2
>     Rdonlp2::donlp2(x0, fn = f, nlin = list(heq),   # wrong
>            nlin.lower = 0, nlin.upper = 0)
>     Rdonlp2::donlp2(x1, fn = f, nlin = list(heq),   # right
>            nlin.lower = 0, nlin.upper = 0)          # (fast and exact)
>
> The problem with starting point x0 appears to be that the gradient at
> that point, projected onto the unit sphere, is zero. Only alabama is
> able to handle this somehow.
>
> I do not know what problem most solvers have with starting point x1.
> The fact that Rdonlp2 is the fastest and most accurate is no surprise.
>
> If anyone with more experience with one or more of these packages can
> give a hint of what I made wrong, or how to change calling the solver
> to make it run correctly, please let me know.
>
> Thanks  -- HW
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From drj|m|emon @end|ng |rom gm@||@com  Fri May 28 05:34:50 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 28 May 2021 13:34:50 +1000
Subject: [R] R grep question
In-Reply-To: <04861b9e-718b-c49c-6573-357ea1ba2ad3@me.com>
References: <1110804826.344460.1622089750541.ref@mail.yahoo.com>
 <1110804826.344460.1622089750541@mail.yahoo.com>
 <7cf01e03-ac9f-0f2c-acb6-12d8ca412b49@sapo.pt>
 <847153983.434217.1622129039547@mail.yahoo.com>
 <04861b9e-718b-c49c-6573-357ea1ba2ad3@me.com>
Message-ID: <CA+8X3fUPZLs_NsTio079e_UtHAe5y=P3-CXYMcNWf+oJBek=DQ@mail.gmail.com>

Hi Kai,
You may find %in% easier than grep when multiple matches are needed:

match_strings<-c("MLH1","MSH2")
CRC<-data.frame(gene.all=c("MLH1","MSL1","MSH2","MCC3"))
CRC$MMR.gene<-ifelse(CRC$gene.all %in% match_strings,"Yes","No")

Composing your match strings before applying %in% may be more flexible
if you have more than one selection to make.

On Fri, May 28, 2021 at 1:57 AM Marc Schwartz via R-help
<r-help at r-project.org> wrote:
>
> Hi,
>
> A quick clarification:
>
> The regular expression is a single quoted character vector, not a
> character vector on either side of the | operator:
>
> "MLH1|MSH2"
>
> not:
>
> "MLH1"|"MSH2"
>
> The | is treated as a special character within the regular expression.
> See ?regex.
>
> grep(), when value = FALSE, returns the index of the match within the
> source vector, while when value = TRUE, returns the found character
> entries themselves.
>
> Thus, you need to be sure that your ifelse() incantation is matching the
> correct values.
>
> In the case of grepl(), it returns TRUE or FALSE, as Rui noted, thus:
>
>    CRC$MMR.gene <- ifelse(grepl("MLH1|MSH2",CRC$gene.all), "Yes", "No")
>
> should work.
>
> Regards,
>
> Marc Schwartz
>
>
> Kai Yang via R-help wrote on 5/27/21 11:23 AM:
> >   Hi Rui,thank you for your suggestion.
> > but when I try the solution, I got message below:
> >
> > Error in "MLH1" | "MSH2" :   operations are possible only for numeric, logical or complex types
> >
> > does it mean, grepl can not work on character field?
> > Thanks,Kai    On Thursday, May 27, 2021, 01:37:58 AM PDT, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> >
> >   Hello,
> >
> > ifelse needs a logical condition, not the value. Try grepl.
> >
> >
> > CRC$MMR.gene <- ifelse(grepl("MLH1"|"MSH2",CRC$gene.all), "Yes", "No")
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > ?s 05:29 de 27/05/21, Kai Yang via R-help escreveu:
> >> Hi List,
> >> I wrote the code to create a new variable:
> >> CRC$MMR.gene<-ifelse(grep("MLH1"|"MSH2",CRC$gene.all,value=T),"Yes","No")
> >>
> >>
> >> I need to create MMR.gene column in CRC data frame, ifgene.all column contenes MLH1 or MSH2, then the MMR.gene=Yes, if not,MMR.gene=No
> >>
> >> But, the code doesn't work for me. Can anyone tell how to fix the code?
> >>
> >> Thank you,
> >>
> >> Kai
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Fri May 28 17:16:45 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 28 May 2021 08:16:45 -0700
Subject: [R] R grep question
In-Reply-To: <CA+8X3fUPZLs_NsTio079e_UtHAe5y=P3-CXYMcNWf+oJBek=DQ@mail.gmail.com>
References: <1110804826.344460.1622089750541.ref@mail.yahoo.com>
 <1110804826.344460.1622089750541@mail.yahoo.com>
 <7cf01e03-ac9f-0f2c-acb6-12d8ca412b49@sapo.pt>
 <847153983.434217.1622129039547@mail.yahoo.com>
 <04861b9e-718b-c49c-6573-357ea1ba2ad3@me.com>
 <CA+8X3fUPZLs_NsTio079e_UtHAe5y=P3-CXYMcNWf+oJBek=DQ@mail.gmail.com>
Message-ID: <CAGxFJbSWhmmpyp=ePX3vbczLuDUW=Dg=VTxeo_ViLq7UXyyhQw@mail.gmail.com>

FWIW:

I think Jim makes an excellent point -- regex's really aren't the right
tool for this sort of thing (imho); matching is.

Note also that if one is willing to live with a logical response (better,
again imho), then the ifelse() can of course be dispensed with:

> CRC$MMR.gene<-CRC$gene.all %in% match_strings
> CRC$MMR.gene
[1]  TRUE FALSE  TRUE FALSE

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, May 27, 2021 at 8:35 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Kai,
> You may find %in% easier than grep when multiple matches are needed:
>
> match_strings<-c("MLH1","MSH2")
> CRC<-data.frame(gene.all=c("MLH1","MSL1","MSH2","MCC3"))
> CRC$MMR.gene<-ifelse(CRC$gene.all %in% match_strings,"Yes","No")
>
> Composing your match strings before applying %in% may be more flexible
> if you have more than one selection to make.
>
> On Fri, May 28, 2021 at 1:57 AM Marc Schwartz via R-help
> <r-help at r-project.org> wrote:
> >
> > Hi,
> >
> > A quick clarification:
> >
> > The regular expression is a single quoted character vector, not a
> > character vector on either side of the | operator:
> >
> > "MLH1|MSH2"
> >
> > not:
> >
> > "MLH1"|"MSH2"
> >
> > The | is treated as a special character within the regular expression.
> > See ?regex.
> >
> > grep(), when value = FALSE, returns the index of the match within the
> > source vector, while when value = TRUE, returns the found character
> > entries themselves.
> >
> > Thus, you need to be sure that your ifelse() incantation is matching the
> > correct values.
> >
> > In the case of grepl(), it returns TRUE or FALSE, as Rui noted, thus:
> >
> >    CRC$MMR.gene <- ifelse(grepl("MLH1|MSH2",CRC$gene.all), "Yes", "No")
> >
> > should work.
> >
> > Regards,
> >
> > Marc Schwartz
> >
> >
> > Kai Yang via R-help wrote on 5/27/21 11:23 AM:
> > >   Hi Rui,thank you for your suggestion.
> > > but when I try the solution, I got message below:
> > >
> > > Error in "MLH1" | "MSH2" :   operations are possible only for numeric,
> logical or complex types
> > >
> > > does it mean, grepl can not work on character field?
> > > Thanks,Kai    On Thursday, May 27, 2021, 01:37:58 AM PDT, Rui Barradas
> <ruipbarradas at sapo.pt> wrote:
> > >
> > >   Hello,
> > >
> > > ifelse needs a logical condition, not the value. Try grepl.
> > >
> > >
> > > CRC$MMR.gene <- ifelse(grepl("MLH1"|"MSH2",CRC$gene.all), "Yes", "No")
> > >
> > >
> > > Hope this helps,
> > >
> > > Rui Barradas
> > >
> > > ?s 05:29 de 27/05/21, Kai Yang via R-help escreveu:
> > >> Hi List,
> > >> I wrote the code to create a new variable:
> > >>
> CRC$MMR.gene<-ifelse(grep("MLH1"|"MSH2",CRC$gene.all,value=T),"Yes","No")
> > >>
> > >>
> > >> I need to create MMR.gene column in CRC data frame, ifgene.all column
> contenes MLH1 or MSH2, then the MMR.gene=Yes, if not,MMR.gene=No
> > >>
> > >> But, the code doesn't work for me. Can anyone tell how to fix the
> code?
> > >>
> > >> Thank you,
> > >>
> > >> Kai
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From go@@@ye15 @end|ng |rom gm@||@com  Fri May 28 20:55:04 2021
From: go@@@ye15 @end|ng |rom gm@||@com (Gossaye Hailu)
Date: Sat, 29 May 2021 02:55:04 +0800
Subject: [R] Error: C stack usage 15924320 is too close to the limit
Message-ID: <CAEydAOTknnusJtJHVuwOMtqeErFZpqZqTCgOPwz=knn_Y68Jgg@mail.gmail.com>

I am doing phylogenetic analysis of ecological community data set using
Picante package to find out PD, MPD, MNTD
I have run the following arguments
library(picante)
>tree4.phylotree<-read.tree("phylojune2016.edit.phy")
>tree4.phy<-read.csv("june2016.matrix.csv",sep=",",header = TRUE,row.names
= 1)
>tree4.out<-pd(tree4.phy,tree4.phylotree,include.root = FALSE)
>tree4.out[,3]<-mpd(tree4.phy,cophenetic(tree4.phylotree))
>tree4.out[,4]<-mntd(tree4.phy,cophenetic(tree4.phylotree))
>names(tree4.out)[3:4]<-c("MPD","MNTD")

When I randomize the matrix 999 times the following Error term appears
>tree4.mpd<-ses.mpd(tree4.phy,cophenetic(tree4.phylotree),runs = 999)

Error: C stack usage  15923904 is too close to the limit

How can I solve this error please? I will highly appreciate your help!

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat May 29 21:55:49 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 29 May 2021 12:55:49 -0700
Subject: [R] Error: C stack usage 15924320 is too close to the limit
In-Reply-To: <CAEydAOTknnusJtJHVuwOMtqeErFZpqZqTCgOPwz=knn_Y68Jgg@mail.gmail.com>
References: <CAEydAOTknnusJtJHVuwOMtqeErFZpqZqTCgOPwz=knn_Y68Jgg@mail.gmail.com>
Message-ID: <CAGxFJbTToKuTm4XCNictL9mTpMV_XVExuttSEb+8PTsM51Y++A@mail.gmail.com>

Please see the posting guide linked below. Questions about nonstandard
packages are generally  off topic here. You should probably do as the pg
recommends and contact the maintainer, who you can find by the maintainer()
function.

Bert

On Sat, May 29, 2021, 10:16 AM Gossaye Hailu <gossaye15 at gmail.com> wrote:

> I am doing phylogenetic analysis of ecological community data set using
> Picante package to find out PD, MPD, MNTD
> I have run the following arguments
> library(picante)
> >tree4.phylotree<-read.tree("phylojune2016.edit.phy")
> >tree4.phy<-read.csv("june2016.matrix.csv",sep=",",header = TRUE,row.names
> = 1)
> >tree4.out<-pd(tree4.phy,tree4.phylotree,include.root = FALSE)
> >tree4.out[,3]<-mpd(tree4.phy,cophenetic(tree4.phylotree))
> >tree4.out[,4]<-mntd(tree4.phy,cophenetic(tree4.phylotree))
> >names(tree4.out)[3:4]<-c("MPD","MNTD")
>
> When I randomize the matrix 999 times the following Error term appears
> >tree4.mpd<-ses.mpd(tree4.phy,cophenetic(tree4.phylotree),runs = 999)
>
> Error: C stack usage  15923904 is too close to the limit
>
> How can I solve this error please? I will highly appreciate your help!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat May 29 22:07:22 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 29 May 2021 13:07:22 -0700
Subject: [R] Error: C stack usage 15924320 is too close to the limit
In-Reply-To: <CAEydAOTknnusJtJHVuwOMtqeErFZpqZqTCgOPwz=knn_Y68Jgg@mail.gmail.com>
References: <CAEydAOTknnusJtJHVuwOMtqeErFZpqZqTCgOPwz=knn_Y68Jgg@mail.gmail.com>
Message-ID: <0DA3AB01-0E8E-4079-AFFC-5C95E1147932@dcn.davis.ca.us>

You may need to use smaller data. Anyway, read the Posting Guide, which says for contributed packages to contact the package maintainer

?maintainer

On May 28, 2021 11:55:04 AM PDT, Gossaye Hailu <gossaye15 at gmail.com> wrote:
>I am doing phylogenetic analysis of ecological community data set using
>Picante package to find out PD, MPD, MNTD
>I have run the following arguments
>library(picante)
>>tree4.phylotree<-read.tree("phylojune2016.edit.phy")
>>tree4.phy<-read.csv("june2016.matrix.csv",sep=",",header =
>TRUE,row.names
>= 1)
>>tree4.out<-pd(tree4.phy,tree4.phylotree,include.root = FALSE)
>>tree4.out[,3]<-mpd(tree4.phy,cophenetic(tree4.phylotree))
>>tree4.out[,4]<-mntd(tree4.phy,cophenetic(tree4.phylotree))
>>names(tree4.out)[3:4]<-c("MPD","MNTD")
>
>When I randomize the matrix 999 times the following Error term appears
>>tree4.mpd<-ses.mpd(tree4.phy,cophenetic(tree4.phylotree),runs = 999)
>
>Error: C stack usage  15923904 is too close to the limit
>
>How can I solve this error please? I will highly appreciate your help!
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From m@hmood@n@der@n @end|ng |rom ugent@be  Sun May 30 18:18:22 2021
From: m@hmood@n@der@n @end|ng |rom ugent@be (Mahmood Naderan-Tahan)
Date: Sun, 30 May 2021 16:18:22 +0000
Subject: [R] About Pearson correlation functions
Message-ID: <abbf42efc8a14c8c988955f4252dd1ce@ugent.be>

Hi

Maybe this is not directly related to R, but I appreciate you can help me with an idea. I use the following ggscatter function to plot a Pearson correlation Coefficient and it works fine. In the chart I see both R-value and P-value.


    ggscatter(mydata, x = "V1", y = "V2", add = "reg.line", conf.int = TRUE, cor.coef = TRUE, cor.method = "pearson")


On the other hand, when I use this command


    res <- cor.test(mydata$V1, mydata$V2, method = "pearson")


The R and P values are different from ggscatter.


I would like to know:


1- Why they are different?

2- How to print P and R values of ggscatter on terminal?



Regards,
Mahmood

	[[alternative HTML version deleted]]


From y@ngk@|9999 @end|ng |rom y@hoo@com  Sun May 30 18:28:52 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Sun, 30 May 2021 16:28:52 +0000 (UTC)
Subject: [R] if statement and for loop question
References: <1141622248.909505.1622392132322.ref@mail.yahoo.com>
Message-ID: <1141622248.909505.1622392132322@mail.yahoo.com>

Hello List,I have a data frame which having the character columns:

| a1 | b1 | c1 | d1 |
| a2 | b2 | c2 | d2 |
| a3 | b3 | c3 | d3 |
| a4 | b4 | c4 | d4 |
| a5 | b5 | c5 | d5 |



I need to do: if a1 not = "Positive" and not = "VUS" then values of? b1, c1 and d1 will be zero out. And do the same thing for the a2 to a5 series.
I write the code below to do this. But it doesn't work. Would you please correct my code?
Thank you,
Kai


for (i in 1:5)?
{
? if (isTRUE(try$a[i] != "Positive" && try$a[i] != "VUS"))
? {
? ? try$b[i]== ''
? ? try$c[i] == ''
? ? try$d[i]== ''
? }
}


	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun May 30 18:56:41 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 30 May 2021 09:56:41 -0700
Subject: [R] if statement and for loop question
In-Reply-To: <1141622248.909505.1622392132322@mail.yahoo.com>
References: <1141622248.909505.1622392132322.ref@mail.yahoo.com>
 <1141622248.909505.1622392132322@mail.yahoo.com>
Message-ID: <F3D83ADC-35B1-4522-85A4-51219E286D78@dcn.davis.ca.us>

Can you make R code that creates an actual sample data frame that looks like you want the answer to look? say, just using the data.frame function and literal strings. Oh, and read the Posting Guide... you need to send your email using plain text format or it may get garbled when the list strips the HTML formatting.

On May 30, 2021 9:28:52 AM PDT, Kai Yang via R-help <r-help at r-project.org> wrote:
>Hello List,I have a data frame which having the character columns:
>
>| a1 | b1 | c1 | d1 |
>| a2 | b2 | c2 | d2 |
>| a3 | b3 | c3 | d3 |
>| a4 | b4 | c4 | d4 |
>| a5 | b5 | c5 | d5 |
>
>
>
>I need to do: if a1 not = "Positive" and not = "VUS" then values of?
>b1, c1 and d1 will be zero out. And do the same thing for the a2 to a5
>series.
>I write the code below to do this. But it doesn't work. Would you
>please correct my code?
>Thank you,
>Kai
>
>
>for (i in 1:5)?
>{
>? if (isTRUE(try$a[i] != "Positive" && try$a[i] != "VUS"))
>? {
>? ? try$b[i]== ''
>? ? try$c[i] == ''
>? ? try$d[i]== ''
>? }
>}
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From w||||@mwdun|@p @end|ng |rom gm@||@com  Sun May 30 19:00:52 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Sun, 30 May 2021 10:00:52 -0700
Subject: [R] About Pearson correlation functions
In-Reply-To: <abbf42efc8a14c8c988955f4252dd1ce@ugent.be>
References: <abbf42efc8a14c8c988955f4252dd1ce@ugent.be>
Message-ID: <CAHqSRuQY2gR=rEH0fQNYAwgJZ6ado+O6gpSRXE4FmNUeZTw9Og@mail.gmail.com>

You didn't say how the values differed.  If one in the plot is a rounded
version of the other then adding the ggpur::ggscatter() argument
   cor.coeff.args=list(digits=7)
will fix things up.

-Bill

On Sun, May 30, 2021 at 9:18 AM Mahmood Naderan-Tahan <
mahmood.naderan at ugent.be> wrote:

> Hi
>
> Maybe this is not directly related to R, but I appreciate you can help me
> with an idea. I use the following ggscatter function to plot a Pearson
> correlation Coefficient and it works fine. In the chart I see both R-value
> and P-value.
>
>
>     ggscatter(mydata, x = "V1", y = "V2", add = "reg.line", conf.int =
> TRUE, cor.coef = TRUE, cor.method = "pearson")
>
>
> On the other hand, when I use this command
>
>
>     res <- cor.test(mydata$V1, mydata$V2, method = "pearson")
>
>
> The R and P values are different from ggscatter.
>
>
> I would like to know:
>
>
> 1- Why they are different?
>
> 2- How to print P and R values of ggscatter on terminal?
>
>
>
> Regards,
> Mahmood
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ccberry @end|ng |rom he@|th@uc@d@edu  Sun May 30 20:08:18 2021
From: ccberry @end|ng |rom he@|th@uc@d@edu (Berry, Charles)
Date: Sun, 30 May 2021 18:08:18 +0000
Subject: [R] if statement and for loop question
In-Reply-To: <1141622248.909505.1622392132322@mail.yahoo.com>
References: <1141622248.909505.1622392132322.ref@mail.yahoo.com>
 <1141622248.909505.1622392132322@mail.yahoo.com>
Message-ID: <F66842D7-F750-4AA2-8968-FBFA12A280A9@health.ucsd.edu>

Kai,

You have made a simple mistake. And now you cannot see it.  I believe this is not uncommon among programmers.  It has happened to me more times than I want to recall.

> On May 30, 2021, at 9:28 AM, Kai Yang via R-help <r-help at r-project.org> wrote:
> 
> Hello List,I have a data frame which having the character columns:
> 
> | a1 | b1 | c1 | d1 |
> | a2 | b2 | c2 | d2 |
> | a3 | b3 | c3 | d3 |
> | a4 | b4 | c4 | d4 |
> | a5 | b5 | c5 | d5 |
> 
> 
> 
> I need to do: if a1 not = "Positive" and not = "VUS" then values of  b1, c1 and d1 will be zero out. And do the same thing for the a2 to a5 series.
> I write the code below to do this. But it doesn't work. Would you please correct my code?
> Thank you,
> Kai
> 
> 
> for (i in 1:5) 
> {
>   if (isTRUE(try$a[i] != "Positive" && try$a[i] != "VUS"))
>   {
>     try$b[i]== ''

What is the above line intended to do?

I think you need to read the line out loud stating the effect of each operator.

If you still do not see what gives, copy and paste each line to the R prompt after the loop has run (i.e. with `i' having value 5) paying attention to any results that are printed out.

>     try$c[i] == ''
>     try$d[i]== ''
>   }
> }
> 
> 
> 	[[alternative HTML version deleted]]
> 

HTH,

Chuck

p.s. It is highly recommended to use `<-' as the assignment operator.


From m@hmood@n@der@n @end|ng |rom ugent@be  Sun May 30 21:12:29 2021
From: m@hmood@n@der@n @end|ng |rom ugent@be (Mahmood Naderan-Tahan)
Date: Sun, 30 May 2021 19:12:29 +0000
Subject: [R] About Pearson correlation functions
In-Reply-To: <CAHqSRuQY2gR=rEH0fQNYAwgJZ6ado+O6gpSRXE4FmNUeZTw9Og@mail.gmail.com>
References: <abbf42efc8a14c8c988955f4252dd1ce@ugent.be>,
 <CAHqSRuQY2gR=rEH0fQNYAwgJZ6ado+O6gpSRXE4FmNUeZTw9Og@mail.gmail.com>
Message-ID: <360caa1459fc4539b4a0962c11bb67c1@ugent.be>

Thanks. It seems that the differences I saw in some of my data points were related to the number of digits and rounding.


Regards,
Mahmood

________________________________
From: Bill Dunlap <williamwdunlap at gmail.com>
Sent: Sunday, May 30, 2021 7:00:52 PM
To: Mahmood Naderan-Tahan
Cc: r-help at r-project.org
Subject: Re: [R] About Pearson correlation functions

You didn't say how the values differed.  If one in the plot is a rounded version of the other then adding the ggpur::ggscatter() argument
   cor.coeff.args=list(digits=7)
will fix things up.

-Bill

On Sun, May 30, 2021 at 9:18 AM Mahmood Naderan-Tahan <mahmood.naderan at ugent.be<mailto:mahmood.naderan at ugent.be>> wrote:
Hi

Maybe this is not directly related to R, but I appreciate you can help me with an idea. I use the following ggscatter function to plot a Pearson correlation Coefficient and it works fine. In the chart I see both R-value and P-value.


    ggscatter(mydata, x = "V1", y = "V2", add = "reg.line", conf.int<http://conf.int> = TRUE, cor.coef = TRUE, cor.method = "pearson")


On the other hand, when I use this command


    res <- cor.test(mydata$V1, mydata$V2, method = "pearson")


The R and P values are different from ggscatter.


I would like to know:


1- Why they are different?

2- How to print P and R values of ggscatter on terminal?



Regards,
Mahmood

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun May 30 21:57:09 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 30 May 2021 20:57:09 +0100
Subject: [R] if statement and for loop question
In-Reply-To: <1141622248.909505.1622392132322@mail.yahoo.com>
References: <1141622248.909505.1622392132322.ref@mail.yahoo.com>
 <1141622248.909505.1622392132322@mail.yahoo.com>
Message-ID: <a0c674aa-a5a9-fa50-40b8-f27f1c612a5a@sapo.pt>

Hello,

You don't need a loop, the R way is a vectorized solution and it's also 
clearer.
Create a logical index (note only one &) and assign b, c, d where it's TRUE.


i <- try$a != "Positive" & try$a != "VUS"
try <- within(try, {
   b[i] <- ''
   c[i] <- ''
   d[i] <- ''
})


Hope this helps,

Rui Barradas

?s 17:28 de 30/05/21, Kai Yang via R-help escreveu:
> Hello List,I have a data frame which having the character columns:
> 
> | a1 | b1 | c1 | d1 |
> | a2 | b2 | c2 | d2 |
> | a3 | b3 | c3 | d3 |
> | a4 | b4 | c4 | d4 |
> | a5 | b5 | c5 | d5 |
> 
> 
> 
> I need to do: if a1 not = "Positive" and not = "VUS" then values of? b1, c1 and d1 will be zero out. And do the same thing for the a2 to a5 series.
> I write the code below to do this. But it doesn't work. Would you please correct my code?
> Thank you,
> Kai
> 
> 
> for (i in 1:5)
> {
>  ? if (isTRUE(try$a[i] != "Positive" && try$a[i] != "VUS"))
>  ? {
>  ? ? try$b[i]== ''
>  ? ? try$c[i] == ''
>  ? ? try$d[i]== ''
>  ? }
> }
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From drj|m|emon @end|ng |rom gm@||@com  Mon May 31 07:44:29 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 31 May 2021 15:44:29 +1000
Subject: [R] if statement and for loop question
In-Reply-To: <1141622248.909505.1622392132322@mail.yahoo.com>
References: <1141622248.909505.1622392132322.ref@mail.yahoo.com>
 <1141622248.909505.1622392132322@mail.yahoo.com>
Message-ID: <CA+8X3fXWDUCvNe2ZHPORZoVyO=Md2K2vAiiBYOXsKnrSU6ahXw@mail.gmail.com>

Hi Kai,
You seem to be asking the same question again and again. This does not
give us the warm feeling that you know what you want.

testdf<-data.frame(a=c("Negative","Positive","Neutral","Random","VUS"),
 b=c("No","Yes","No","Maybe","Yes"),
 c=c("Off","On","Off","Off","On"),
 d=c("Bad","Good","Bad","Bad","Good"),
 stringsAsFactors=FALSE)
testdf
match_strings<-c("Positive","VUS")
testdf$b<-ifelse(testdf$a %in% match_strings,testdf$b,"")
testdf$c<-ifelse(testdf$a %in% match_strings,testdf$c,"")
testdf$d<-ifelse(testdf$a %in% match_strings,testdf$d,"")
testdf

I have assumed that you mean "zero length strings" rather than
"zeros". Also note that your initial code was producing logical values
that were never assigned to anything.

Jim

On Mon, May 31, 2021 at 2:29 AM Kai Yang via R-help
<r-help at r-project.org> wrote:
>
> Hello List,I have a data frame which having the character columns:
>
> | a1 | b1 | c1 | d1 |
> | a2 | b2 | c2 | d2 |
> | a3 | b3 | c3 | d3 |
> | a4 | b4 | c4 | d4 |
> | a5 | b5 | c5 | d5 |
>
>
>
> I need to do: if a1 not = "Positive" and not = "VUS" then values of  b1, c1 and d1 will be zero out. And do the same thing for the a2 to a5 series.
> I write the code below to do this. But it doesn't work. Would you please correct my code?
> Thank you,
> Kai
>
>
> for (i in 1:5)
> {
>   if (isTRUE(try$a[i] != "Positive" && try$a[i] != "VUS"))
>   {
>     try$b[i]== ''
>     try$c[i] == ''
>     try$d[i]== ''
>   }
> }
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From y@ngk@|9999 @end|ng |rom y@hoo@com  Mon May 31 18:26:51 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Mon, 31 May 2021 16:26:51 +0000 (UTC)
Subject: [R] if statement and for loop question
In-Reply-To: <CA+8X3fXWDUCvNe2ZHPORZoVyO=Md2K2vAiiBYOXsKnrSU6ahXw@mail.gmail.com>
References: <1141622248.909505.1622392132322.ref@mail.yahoo.com>
 <1141622248.909505.1622392132322@mail.yahoo.com>
 <CA+8X3fXWDUCvNe2ZHPORZoVyO=Md2K2vAiiBYOXsKnrSU6ahXw@mail.gmail.com>
Message-ID: <807993174.1064155.1622478411915@mail.yahoo.com>

  Hi Jim,
Sorry to post "same" question, because?
1. I was asking to use plain text format. I have to post my question again. But I don't know if it is working.
2. I'm a beginner for R (< 2 month). It may not easy for me to ask a "clear" R question. My current work is to transfer my SAS code into R, especially for data manipulation part.?
I'll do my best to ask a non."same" question later.
Thanks,
Kai
    On Sunday, May 30, 2021, 10:44:41 PM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:  
 
 Hi Kai,
You seem to be asking the same question again and again. This does not
give us the warm feeling that you know what you want.

testdf<-data.frame(a=c("Negative","Positive","Neutral","Random","VUS"),
 b=c("No","Yes","No","Maybe","Yes"),
 c=c("Off","On","Off","Off","On"),
 d=c("Bad","Good","Bad","Bad","Good"),
 stringsAsFactors=FALSE)
testdf
match_strings<-c("Positive","VUS")
testdf$b<-ifelse(testdf$a %in% match_strings,testdf$b,"")
testdf$c<-ifelse(testdf$a %in% match_strings,testdf$c,"")
testdf$d<-ifelse(testdf$a %in% match_strings,testdf$d,"")
testdf

I have assumed that you mean "zero length strings" rather than
"zeros". Also note that your initial code was producing logical values
that were never assigned to anything.

Jim

On Mon, May 31, 2021 at 2:29 AM Kai Yang via R-help
<r-help at r-project.org> wrote:
>
> Hello List,I have a data frame which having the character columns:
>
> | a1 | b1 | c1 | d1 |
> | a2 | b2 | c2 | d2 |
> | a3 | b3 | c3 | d3 |
> | a4 | b4 | c4 | d4 |
> | a5 | b5 | c5 | d5 |
>
>
>
> I need to do: if a1 not = "Positive" and not = "VUS" then values of? b1, c1 and d1 will be zero out. And do the same thing for the a2 to a5 series.
> I write the code below to do this. But it doesn't work. Would you please correct my code?
> Thank you,
> Kai
>
>
> for (i in 1:5)
> {
>? if (isTRUE(try$a[i] != "Positive" && try$a[i] != "VUS"))
>? {
>? ? try$b[i]== ''
>? ? try$c[i] == ''
>? ? try$d[i]== ''
>? }
> }
>
>
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
  
	[[alternative HTML version deleted]]


From n|ckmwr@y @end|ng |rom gm@||@com  Mon May 31 18:31:00 2021
From: n|ckmwr@y @end|ng |rom gm@||@com (Nick Wray)
Date: Mon, 31 May 2021 17:31:00 +0100
Subject: [R] DBDA2E-utilities.R file download
Message-ID: <CABxY9BOFo55L5unGckONr6swy7hDJUymsqCd-syjATp5Hh-tMQ@mail.gmail.com>

Hello I am trying to download the file "kyusque/DBDA2E-utilities.R" which
is used in following through John Krushke's book on Bayesian stats.
According to the net (kyusque/DBDA2E-utilities: Packaged One for
DBDA2E-utilities.R in 'Kruschke, J. K. (2015). Doing Bayesian Data
Analysis, Second Edition' version 0.1.0 from GitHub (rdrr.io)
<https://rdrr.io/github/kyusque/DBDA2E-utilities/>) I needed to

install.packages("remotes")
remotes::install_github("kyusque/DBDA2E-utilities")

which i have done, and seem to have done successfully

but I can't get hold of the utilities file.  Does anyone know what I
should now do?

Thanks Nick Wray

	[[alternative HTML version deleted]]


