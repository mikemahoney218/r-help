From |eo@m@d@ @end|ng |rom @yon|c@eu  Sat Jun  1 18:16:23 2024
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leo Mada)
Date: Sat, 1 Jun 2024 16:16:23 +0000
Subject: [R] Tools to modify highlighted areas in pdf documents?
Message-ID: <DBAP192MB095675B1E0FD76CD59E9155384FD2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>

Dear R-Users,

Are there any packages that enable the modifications of highlighted areas / annotations in pdf documents?

It seems feasible - I have explored some R code (see below). However, I would rather avoid to reinvent the wheel.

The problem:
When highlighting pdf-documents with Microsoft Edge, the bounding box is sometimes misplaced, and quite ugly so. It also lacks the ability to draw lines or arrows.

On the other hand, I did not get used to Acrobat Reader: it usually involves much more effort to add specific highlights. Lines can be drawn, but are NOT straight!

Are there tools to change the size/position of highlights?
Or to add highlights and underline words?
 Changing position/size manually by editing the data in the pdf-document is possible. Changing the color is more trickier (somehow possible in Microsoft Edger; though the direct approach to rewrite the actual stream is better). Maybe there are some tools to do it?

Some R code is below.

Sincerely,

Leonard
#########

library(zip)

con = file("_some_pdf_.pdf", "rb")

NL = 0
# - very dirty hack;
# - assumes Annotations are in the last fragment/chunk;
while(TRUE) {
    tmp = readBin(con, "raw", 1024*128 + 515);
??????if(length(tmp) == 0) break;
??????x = tmp;
??????# isNL = (x == 10) | (x == 13);
??????isNL = (x == 13);
??????isNL = isNL & (x[which(isNL) + 1] == 10);
    NL = NL + sum(isNL);
}

close(con)

idP = which(isNL)

idS = 935; # will vary with pdf and Annotations and ...;
nLast = 4; # usually 2 chunks
idx = idP[seq(idS, length.out = nLast)]

# Check: Right position?
# tmp = x[seq(idx[1] + 2, idx[1 + 2] - 1)]
# intToUtf8(tmp)

tmp = inflate(x[seq(idx[1] + 2, idx[nLast] - 1)])
intToUtf8(tmp$output)

# Output of inflate: an Example
# "/GS gs .56078434 .87058824 .97647059 rg\n
# 337.298 183.836 m 364.322 183.836 l 364.322 171.83 l 337.298 171.83 l h f\n"

# Note: /BBox[ 337.298 171.83 364.322 183.836]

The raw pdf data:

1948 0 obj
<</AP<</N 1949 0 R >>/C[ 0.560784 0.870588 0.976471]/CA 1/F 4/PDFIUM_HasGeneratedAP true/QuadPoints[ 337.298 186 364.322 186 337.298 174.6 364.322 174.6]/Rect[ 337.298 174.6 364.322 186]/Subtype/Highlight/Type/Annot>>
endobj
1949 0 obj
<</BBox[ 337.298 171.83 364.322 183.836]/Filter/FlateDecode/FormType 1/Length 86/Matrix[ 1 0 0 1 0 0]/Resources<</ExtGState<</GS<</AIS false/BM/Multiply/CA 1/Type/ExtGState/ca 1>>>>>>/Subtype/Form/Type/XObject>>stream
x?E??
?0 ??)~??
?????P@?K?"??t?????j?C???T#?B??z?
W?H??9(A????
K?????_i??mz dR?
endstream
endobj


	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Jun  1 20:23:28 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 1 Jun 2024 11:23:28 -0700
Subject: [R] Tools to modify highlighted areas in pdf documents?
In-Reply-To: <DBAP192MB095675B1E0FD76CD59E9155384FD2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
References: <DBAP192MB095675B1E0FD76CD59E9155384FD2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
Message-ID: <CAGxFJbTLa+NcvWd5eHzQCfxMrBU3pRnc=zQ33O8XhW9OzeKcUQ@mail.gmail.com>

Search!

on rseek.org, the query "modify pdf documents in R" brought up the staplr
package. A quick web search with the same query brought up the pdftools
package.

These were cursory efforts, so you may well find more. You will have to
determine whether and to what degree any meet your needs.

-- Bert

On Sat, Jun 1, 2024 at 9:16?AM Leo Mada via R-help <r-help at r-project.org>
wrote:

> Dear R-Users,
>
> Are there any packages that enable the modifications of highlighted areas
> / annotations in pdf documents?
>
> It seems feasible - I have explored some R code (see below). However, I
> would rather avoid to reinvent the wheel.
>
> The problem:
> When highlighting pdf-documents with Microsoft Edge, the bounding box is
> sometimes misplaced, and quite ugly so. It also lacks the ability to draw
> lines or arrows.
>
> On the other hand, I did not get used to Acrobat Reader: it usually
> involves much more effort to add specific highlights. Lines can be drawn,
> but are NOT straight!
>
> Are there tools to change the size/position of highlights?
> Or to add highlights and underline words?
>  Changing position/size manually by editing the data in the pdf-document
> is possible. Changing the color is more trickier (somehow possible in
> Microsoft Edger; though the direct approach to rewrite the actual stream is
> better). Maybe there are some tools to do it?
>
> Some R code is below.
>
> Sincerely,
>
> Leonard
> #########
>
> library(zip)
>
> con = file("_some_pdf_.pdf", "rb")
>
> NL = 0
> # - very dirty hack;
> # - assumes Annotations are in the last fragment/chunk;
> while(TRUE) {
>     tmp = readBin(con, "raw", 1024*128 + 515);
> if(length(tmp) == 0) break;
> x = tmp;
> # isNL = (x == 10) | (x == 13);
> isNL = (x == 13);
> isNL = isNL & (x[which(isNL) + 1] == 10);
>     NL = NL + sum(isNL);
> }
>
> close(con)
>
> idP = which(isNL)
>
> idS = 935; # will vary with pdf and Annotations and ...;
> nLast = 4; # usually 2 chunks
> idx = idP[seq(idS, length.out = nLast)]
>
> # Check: Right position?
> # tmp = x[seq(idx[1] + 2, idx[1 + 2] - 1)]
> # intToUtf8(tmp)
>
> tmp = inflate(x[seq(idx[1] + 2, idx[nLast] - 1)])
> intToUtf8(tmp$output)
>
> # Output of inflate: an Example
> # "/GS gs .56078434 .87058824 .97647059 rg\n
> # 337.298 183.836 m 364.322 183.836 l 364.322 171.83 l 337.298 171.83 l h
> f\n"
>
> # Note: /BBox[ 337.298 171.83 364.322 183.836]
>
> The raw pdf data:
>
> 1948 0 obj
> <</AP<</N 1949 0 R >>/C[ 0.560784 0.870588 0.976471]/CA 1/F
> 4/PDFIUM_HasGeneratedAP true/QuadPoints[ 337.298 186 364.322 186 337.298
> 174.6 364.322 174.6]/Rect[ 337.298 174.6 364.322
> 186]/Subtype/Highlight/Type/Annot>>
> endobj
> 1949 0 obj
> <</BBox[ 337.298 171.83 364.322 183.836]/Filter/FlateDecode/FormType
> 1/Length 86/Matrix[ 1 0 0 1 0 0]/Resources<</ExtGState<</GS<</AIS
> false/BM/Multiply/CA 1/Type/ExtGState/ca
> 1>>>>>>/Subtype/Form/Type/XObject>>stream
> x?E??
> ?0  ??)~ ?? ??? ? P@ ?K?"??t???? j?C? ?T#?B??z?
> W?H?? 9(A? ?
> K????? _ i??mz dR ?
> endstream
> endobj
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From |eo@m@d@ @end|ng |rom @yon|c@eu  Sun Jun  2 01:19:56 2024
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leo Mada)
Date: Sat, 1 Jun 2024 23:19:56 +0000
Subject: [R] Tools to modify highlighted areas in pdf documents?
In-Reply-To: <CAGxFJbTLa+NcvWd5eHzQCfxMrBU3pRnc=zQ33O8XhW9OzeKcUQ@mail.gmail.com>
References: <DBAP192MB095675B1E0FD76CD59E9155384FD2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
 <CAGxFJbTLa+NcvWd5eHzQCfxMrBU3pRnc=zQ33O8XhW9OzeKcUQ@mail.gmail.com>
Message-ID: <DBAP192MB09567BB9DA765EEB0649CDB784FD2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>

Dear Bert,

Thank you very much for the response.

I was aware of pdftools - but did not recall any such functionality. I have checked again (both pdftools, qpdf and the 3rd one): unfortunately, they do not implement such functionality. There might be other packages, which I missed.

However, the functionality is feasible. I will add a few more details - maybe someone picks up the task.

It is possible to edit manually the pdf-file, though it is quite cumbersome to find the right annotation.

1. One needs to edit the values both in the \QuadPoints and the \Rect in the \AP object.

2. Modifying the color is trickier:
\C() encodes the color and \CA the alpha channel (= 1): but neither Acrobat, nor MIcrosoft Edge update the color. The value of the color encoded in the stream is used instead.

It is possible to "trick" Edge: modify the \C color and set "\ca 1" (in the stream block) to a lower value (e.g. "\ca 0.99"). MS Edge will then accept the modified color (but Acrobat ignores it). Changing the value in the stream is the actual solution.

Note: non-rectangular shapes can be specified as well.

I hope that some of the referenced packages pick up this task.

Sincerely,

Leonard

________________________________
From: Bert Gunter <bgunter.4567 at gmail.com>
Sent: Saturday, June 1, 2024 9:23 PM
To: Leo Mada <leo.mada at syonic.eu>
Cc: r-help at r-project.org <r-help at r-project.org>
Subject: Re: [R] Tools to modify highlighted areas in pdf documents?

Search!

on rseek.org<http://rseek.org>, the query "modify pdf documents in R" brought up the staplr package. A quick web search with the same query brought up the pdftools package.

These were cursory efforts, so you may well find more. You will have to determine whether and to what degree any meet your needs.

-- Bert

On Sat, Jun 1, 2024 at 9:16?AM Leo Mada via R-help <r-help at r-project.org<mailto:r-help at r-project.org>> wrote:
Dear R-Users,

Are there any packages that enable the modifications of highlighted areas / annotations in pdf documents?

It seems feasible - I have explored some R code (see below). However, I would rather avoid to reinvent the wheel.

The problem:
When highlighting pdf-documents with Microsoft Edge, the bounding box is sometimes misplaced, and quite ugly so. It also lacks the ability to draw lines or arrows.

On the other hand, I did not get used to Acrobat Reader: it usually involves much more effort to add specific highlights. Lines can be drawn, but are NOT straight!

Are there tools to change the size/position of highlights?
Or to add highlights and underline words?
 Changing position/size manually by editing the data in the pdf-document is possible. Changing the color is more trickier (somehow possible in Microsoft Edger; though the direct approach to rewrite the actual stream is better). Maybe there are some tools to do it?

Some R code is below.

Sincerely,

Leonard
#########

library(zip)

con = file("_some_pdf_.pdf", "rb")

NL = 0
# - very dirty hack;
# - assumes Annotations are in the last fragment/chunk;
while(TRUE) {
    tmp = readBin(con, "raw", 1024*128 + 515);
if(length(tmp) == 0) break;
x = tmp;
# isNL = (x == 10) | (x == 13);
isNL = (x == 13);
isNL = isNL & (x[which(isNL) + 1] == 10);
    NL = NL + sum(isNL);
}

close(con)

idP = which(isNL)

idS = 935; # will vary with pdf and Annotations and ...;
nLast = 4; # usually 2 chunks
idx = idP[seq(idS, length.out = nLast)]

# Check: Right position?
# tmp = x[seq(idx[1] + 2, idx[1 + 2] - 1)]
# intToUtf8(tmp)

tmp = inflate(x[seq(idx[1] + 2, idx[nLast] - 1)])
intToUtf8(tmp$output)

# Output of inflate: an Example
# "/GS gs .56078434 .87058824 .97647059 rg\n
# 337.298 183.836 m 364.322 183.836 l 364.322 171.83 l 337.298 171.83 l h f\n"

# Note: /BBox[ 337.298 171.83 364.322 183.836]

The raw pdf data:

1948 0 obj
<</AP<</N 1949 0 R >>/C[ 0.560784 0.870588 0.976471]/CA 1/F 4/PDFIUM_HasGeneratedAP true/QuadPoints[ 337.298 186 364.322 186 337.298 174.6 364.322 174.6]/Rect[ 337.298 174.6 364.322 186]/Subtype/Highlight/Type/Annot>>
endobj
1949 0 obj
<</BBox[ 337.298 171.83 364.322 183.836]/Filter/FlateDecode/FormType 1/Length 86/Matrix[ 1 0 0 1 0 0]/Resources<</ExtGState<</GS<</AIS false/BM/Multiply/CA 1/Type/ExtGState/ca 1>>>>>>/Subtype/Form/Type/XObject>>stream
x?E??
?0  ??)~ ?? ??? ? P@ ?K?"??t???? j?C? ?T#?B??z?
W?H?? 9(A????
K????? _ i??mz dR ?
endstream
endobj


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From @h@dee@@@ht@r| @end|ng |rom gm@||@com  Sun Jun  2 00:31:27 2024
From: @h@dee@@@ht@r| @end|ng |rom gm@||@com (Shadee Ashtari)
Date: Sat, 1 Jun 2024 15:31:27 -0700
Subject: [R] R code for overlapping variables -- count
Message-ID: <CAFMWFxDjNSAwB21ZyZ4JSJ_CT96t438v24smX_qSkb7TNBjhhg@mail.gmail.com>

Hi!

I am trying to find the code for how to get counts for intersectional
variables. For example, I have three unique categorical variables --
"Female," "USA," and "MidIncome" -- and I'm trying to see how many people I
have at the intersection of the three.

Thank you so much,
Shadee

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Jun  2 11:55:28 2024
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 2 Jun 2024 05:55:28 -0400
Subject: [R] R code for overlapping variables -- count
In-Reply-To: <CAFMWFxDjNSAwB21ZyZ4JSJ_CT96t438v24smX_qSkb7TNBjhhg@mail.gmail.com>
References: <CAFMWFxDjNSAwB21ZyZ4JSJ_CT96t438v24smX_qSkb7TNBjhhg@mail.gmail.com>
Message-ID: <91c837fa-1c68-4766-888c-afda779f8b99@gmail.com>

On 2024-06-01 6:31 p.m., Shadee Ashtari wrote:
> Hi!
> 
> I am trying to find the code for how to get counts for intersectional
> variables. For example, I have three unique categorical variables --
> "Female," "USA," and "MidIncome" -- and I'm trying to see how many people I
> have at the intersection of the three.

It depends on how those are stored.  Could you put together a little 
dataframe containing sample data, run `dput()` on it, and post the 
result here?

Duncan Murdoch


From |kry|ov @end|ng |rom d|@root@org  Sun Jun  2 19:02:38 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Sun, 2 Jun 2024 20:02:38 +0300
Subject: [R] Tools to modify highlighted areas in pdf documents?
In-Reply-To: <DBAP192MB095675B1E0FD76CD59E9155384FD2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
References: <DBAP192MB095675B1E0FD76CD59E9155384FD2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
Message-ID: <20240602200238.1f57909d@Tarkus>

? Sat, 1 Jun 2024 16:16:23 +0000
Leo Mada via R-help <r-help at r-project.org> ?????:

> When highlighting pdf-documents with Microsoft Edge, the bounding box
> is sometimes misplaced, and quite ugly so. It also lacks the ability
> to draw lines or arrows.
> 
> On the other hand, I did not get used to Acrobat Reader: it usually
> involves much more effort to add specific highlights. Lines can be
> drawn, but are NOT straight!

Sorry for answering a different question, but have you considered using
a different PDF viewer + annotation application? Okular
<https://okular.kde.org/> is free and available on Windows (including
from outside Microsoft store). Its annotation features include all
kinds of highlights, arrows and lines, both straight and
arbitrarily-shaped, quickly available from the "annotations" panel.

-- 
Best regards,
Ivan


From |eo@m@d@ @end|ng |rom @yon|c@eu  Sun Jun  2 19:34:35 2024
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leo Mada)
Date: Sun, 2 Jun 2024 17:34:35 +0000
Subject: [R] R code for overlapping variables -- count
Message-ID: <DBAP192MB0956787CE5BE81D0A6FD4FA284FE2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>

Dear Shadee,

If you have a data.frame with the following columns:

n = 100; # population size
x = data.frame(
??????Sex = sample(c("M","F"), n, T),
??????Country = sample(c("AA", "BB", "US"), n, T),
??????Income  = as.factor(sample(1:3, n, T))
)

# Dummy variable
ONE = rep(1, nrow(x))

r = aggregate(ONE ~ Sex + Income + Country, length, data = x)
r = r[, c("Country", "Income", "Sex")]
print(r)

It is possible to write more simple code, if you need only the particular combination of variables (which you specified in your mail). But this is the more general approach.

Note: you may want to use "sum" instead of "length", e.g. if you have a column specifying the number of individuals in that category.


Hope this helps,

Leonard


	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Jun  2 19:40:51 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 2 Jun 2024 18:40:51 +0100
Subject: [R] R code for overlapping variables -- count
In-Reply-To: <DBAP192MB0956787CE5BE81D0A6FD4FA284FE2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
References: <DBAP192MB0956787CE5BE81D0A6FD4FA284FE2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
Message-ID: <6b70be1b-0688-443b-b6a8-4ff077734860@sapo.pt>

?s 18:34 de 02/06/2024, Leo Mada via R-help escreveu:
> Dear Shadee,
> 
> If you have a data.frame with the following columns:
> 
> n = 100; # population size
> x = data.frame(
> ??????Sex = sample(c("M","F"), n, T),
> ??????Country = sample(c("AA", "BB", "US"), n, T),
> ??????Income  = as.factor(sample(1:3, n, T))
> )
> 
> # Dummy variable
> ONE = rep(1, nrow(x))
> 
> r = aggregate(ONE ~ Sex + Income + Country, length, data = x)
> r = r[, c("Country", "Income", "Sex")]
> print(r)
> 
> It is possible to write more simple code, if you need only the particular combination of variables (which you specified in your mail). But this is the more general approach.
> 
> Note: you may want to use "sum" instead of "length", e.g. if you have a column specifying the number of individuals in that category.
> 
> 
> Hope this helps,
> 
> Leonard
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

The following is simpler.


r2 <- xtabs(~ ., x) |> as.data.frame()
r2[-4L] # or r2[names(r2) != "Freq"]


Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From |eo@m@d@ @end|ng |rom @yon|c@eu  Sun Jun  2 19:41:00 2024
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leo Mada)
Date: Sun, 2 Jun 2024 17:41:00 +0000
Subject: [R] R code for overlapping variables -- count
In-Reply-To: <DBAP192MB0956787CE5BE81D0A6FD4FA284FE2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
References: <DBAP192MB0956787CE5BE81D0A6FD4FA284FE2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
Message-ID: <DBAP192MB09562DB092CFE2F72559116584FE2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>

Correcting a small glitch - see new code.

________________________________
From: Leo Mada <leo.mada at syonic.eu>
Sent: Sunday, June 2, 2024 8:34 PM
To: Shadee Ashtari <shadee.ashtari at gmail.com>
Cc: r-help at r-project.org <r-help at r-project.org>
Subject: [R] R code for overlapping variables -- count

Dear Shadee,

If you have a data.frame with the following columns:

n = 100; # population size
x = data.frame(
??????Sex = sample(c("M","F"), n, T),
??????Country = sample(c("AA", "BB", "US"), n, T),
??????Income  = as.factor(sample(1:3, n, T))
)

# Dummy variable
ONE = rep(1, nrow(x))

# corrected
r = aggregate(ONE ~ Sex + Income + Country, length, data = x)
r = r[, c("Country", "Income", "Sex", "ONE")]
names(r)[4] = "Count"
print(r)

It is possible to write more simple code, if you need only the particular combination of variables (which you specified in your mail). But this is the more general approach.

Note: you may want to use "sum" instead of "length", e.g. if you have a column specifying the number of individuals in that category.


Hope this helps,

Leonard


	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Jun  2 19:47:18 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 2 Jun 2024 18:47:18 +0100
Subject: [R] R code for overlapping variables -- count
In-Reply-To: <6b70be1b-0688-443b-b6a8-4ff077734860@sapo.pt>
References: <DBAP192MB0956787CE5BE81D0A6FD4FA284FE2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
 <6b70be1b-0688-443b-b6a8-4ff077734860@sapo.pt>
Message-ID: <21a5c8f3-d914-45d4-aa7e-2fb5e7ef2b5a@sapo.pt>

?s 18:40 de 02/06/2024, Rui Barradas escreveu:
> ?s 18:34 de 02/06/2024, Leo Mada via R-help escreveu:
>> Dear Shadee,
>>
>> If you have a data.frame with the following columns:
>>
>> n = 100; # population size
>> x = data.frame(
>> ??????Sex = sample(c("M","F"), n, T),
>> ??????Country = sample(c("AA", "BB", "US"), n, T),
>> ??????Income? = as.factor(sample(1:3, n, T))
>> )
>>
>> # Dummy variable
>> ONE = rep(1, nrow(x))
>>
>> r = aggregate(ONE ~ Sex + Income + Country, length, data = x)
>> r = r[, c("Country", "Income", "Sex")]
>> print(r)
>>
>> It is possible to write more simple code, if you need only the 
>> particular combination of variables (which you specified in your 
>> mail). But this is the more general approach.
>>
>> Note: you may want to use "sum" instead of "length", e.g. if you have 
>> a column specifying the number of individuals in that category.
>>
>>
>> Hope this helps,
>>
>> Leonard
>>
>>
>> ????[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> Hello,
> 
> The following is simpler.
> 
> 
> r2 <- xtabs(~ ., x) |> as.data.frame()
> r2[-4L] # or r2[names(r2) != "Freq"]
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
Hello,

This is the same solution but the code to keep only the columns in the 
original data set is better. And it's a MRE.


n <- 100; # population size
x <- data.frame(
   Sex = sample(c("M","F"), n, T),
   Country = sample(c("AA", "BB", "US"), n, T),
   Income  = as.factor(sample(1:3, n, T))
)

r2 <- xtabs(~ ., x) |> as.data.frame()
# no need for constants, find the columns
# to keep from the data
r2[names(r2) %in% names(x)]


Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From pd@|gd @end|ng |rom gm@||@com  Mon Jun  3 11:01:52 2024
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Mon, 3 Jun 2024 11:01:52 +0200
Subject: [R] R code for overlapping variables -- count
In-Reply-To: <CAFMWFxDjNSAwB21ZyZ4JSJ_CT96t438v24smX_qSkb7TNBjhhg@mail.gmail.com>
References: <CAFMWFxDjNSAwB21ZyZ4JSJ_CT96t438v24smX_qSkb7TNBjhhg@mail.gmail.com>
Message-ID: <150215D9-317F-469C-A1A5-55F5BB571C50@gmail.com>

If they are binary (0/1 dummies), can't you just "&" them as in 

table(Female & USA & MidIncome)

(or sum() if you don't care about the number of 0s)

-pd

> On 2 Jun 2024, at 00:31 , Shadee Ashtari <shadee.ashtari at gmail.com> wrote:
> 
> Hi!
> 
> I am trying to find the code for how to get counts for intersectional
> variables. For example, I have three unique categorical variables --
> "Female," "USA," and "MidIncome" -- and I'm trying to see how many people I
> have at the intersection of the three.
> 
> Thank you so much,
> Shadee
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From tebert @end|ng |rom u||@edu  Mon Jun  3 13:12:41 2024
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Mon, 3 Jun 2024 11:12:41 +0000
Subject: [R] R code for overlapping variables -- count
In-Reply-To: <150215D9-317F-469C-A1A5-55F5BB571C50@gmail.com>
References: <CAFMWFxDjNSAwB21ZyZ4JSJ_CT96t438v24smX_qSkb7TNBjhhg@mail.gmail.com>
 <150215D9-317F-469C-A1A5-55F5BB571C50@gmail.com>
Message-ID: <CH3PR22MB4514EFC627EC55EF1E856B1CCFFF2@CH3PR22MB4514.namprd22.prod.outlook.com>

One could make dummy variables if the existing variables are otherwise. If Female is a variable that includes other options (no-response, non-binary, ...) then recode it using dummy.female and the others would be similarly named.

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of peter dalgaard
Sent: Monday, June 3, 2024 5:02 AM
To: Shadee Ashtari <shadee.ashtari at gmail.com>
Cc: r-help at r-project.org
Subject: Re: [R] R code for overlapping variables -- count

[External Email]

If they are binary (0/1 dummies), can't you just "&" them as in

table(Female & USA & MidIncome)

(or sum() if you don't care about the number of 0s)

-pd

> On 2 Jun 2024, at 00:31 , Shadee Ashtari <shadee.ashtari at gmail.com> wrote:
>
> Hi!
>
> I am trying to find the code for how to get counts for intersectional
> variables. For example, I have three unique categorical variables --
> "Female," "USA," and "MidIncome" -- and I'm trying to see how many
> people I have at the intersection of the three.
>
> Thank you so much,
> Shadee
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat/
> .ethz.ch%2Fmailman%2Flistinfo%2Fr-help&data=05%7C02%7Ctebert%40ufl.edu
> %7C66abf8af810348ed21b408dc83abdfd6%7C0d4da0f84a314d76ace60a62331e1b84
> %7C0%7C0%7C638530021430818928%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAw
> MDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&sdata=
> a2oUZzOdXDHnzPA3Oo98DIp%2BFIqpg5o1fT0fcE%2BvkQI%3D&reserved=0
> PLEASE do read the posting guide
> http://www.r/
> -project.org%2Fposting-guide.html&data=05%7C02%7Ctebert%40ufl.edu%7C66
> abf8af810348ed21b408dc83abdfd6%7C0d4da0f84a314d76ace60a62331e1b84%7C0%
> 7C0%7C638530021430825783%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiL
> CJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&sdata=L2I%2
> BxXV3kHZUwflUx0%2BGrakGbbOV6AWV7dul7%2FyuIBU%3D&reserved=0
> and provide commented, minimal, self-contained, reproducible code.

--
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From gb@rc@ro|| @end|ng |rom gm@||@com  Sat Jun  1 13:27:16 2024
From: gb@rc@ro|| @end|ng |rom gm@||@com (Giulio Barcaroli)
Date: Sat, 1 Jun 2024 13:27:16 +0200
Subject: [R] [R-pkgs] QGA 1.0 is released
Message-ID: <7ce4d41b-92e3-435c-a9e8-2e238f74c52e@gmail.com>

Dear R users,

I am pleased to announce that QGA 1.0 is now available on CRAN.

QGA implements the Quantum Genetic Algorithm, as proposed by Han and Kim 
in 2000, and is an R implementation derived from the Python one by 
Lahoz-Beltra in 2016.

Under this approach, each solution is represented as a sequence of 
(qu)bits. Simulating the quantum paradigm, these qubits are in a 
superposition state: when measuring them, they collapse in a 0 or 1 
state. After measurement, the solution's fitness is calculated as in 
usual genetic algorithms.

The evolution at each iteration is oriented by the application of two 
quantum gates to the amplitudes of the qubits: (1) a rotation gate 
(always); (2) a Pauli-X gate (optionally). The rotation is based on the 
theta angle values: higher values allow a quicker evolution, and lower 
values avoid local maxima. The Pauli-X gate is equivalent to the 
classical mutation operator and determines the swap between alfa and 
beta amplitudes of a given qubit.

The package has been developed in such a way as to permit a complete 
separation between the 'engine', and the particular problem subject to 
combinatorial optimization. This is evident in the available examples, 
that come with the package, illustrating the application of QGA to 
different problems: knapsack, traveler salesman, and clustering.

Thank you, kind regards,

Giulio Barcaroli

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From |eo@m@d@ @end|ng |rom @yon|c@eu  Mon Jun  3 20:50:19 2024
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leo Mada)
Date: Mon, 3 Jun 2024 18:50:19 +0000
Subject: [R] Tools to modify highlighted areas in pdf documents?
In-Reply-To: <20240602200238.1f57909d@Tarkus>
References: <DBAP192MB095675B1E0FD76CD59E9155384FD2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>
 <20240602200238.1f57909d@Tarkus>
Message-ID: <DBAP192MB09566488E091E5FCE6EB7B3C84FF2@DBAP192MB0956.EURP192.PROD.OUTLOOK.COM>

Dear Ivan,

Thank you very much for the hint. I have started to test it.

- it offers more colours and types of highlighting than MS Edge;
- it seems to have better word-boundary detection than MS Edge (but I haven't tested all the cases yet);


There are some nit-picks:
- I wish it had a better default color-pallet;
- the vertical positioning continues to be sometimes sub-optimal: editing manually the coordinates may be still useful;

Returning to R:
1. Some of the pdf-packages could implement some of the annotation-functionality as well.

2. It would be useful to be able to export the annotations and import/merge them in another document. I have spotted errors in various articles; such a functionality would be handy, if a new version of those articles gets published.

Sincerely,

Leonard
________________________________
From: Ivan Krylov <ikrylov at disroot.org>
Sent: Sunday, June 2, 2024 8:02 PM
To: Leo Mada via R-help <r-help at r-project.org>
Cc: Leo Mada <leo.mada at syonic.eu>
Subject: Re: [R] Tools to modify highlighted areas in pdf documents?

? Sat, 1 Jun 2024 16:16:23 +0000
Leo Mada via R-help <r-help at r-project.org> ?????:

> When highlighting pdf-documents with Microsoft Edge, the bounding box
> is sometimes misplaced, and quite ugly so. It also lacks the ability
> to draw lines or arrows.
>
> On the other hand, I did not get used to Acrobat Reader: it usually
> involves much more effort to add specific highlights. Lines can be
> drawn, but are NOT straight!

Sorry for answering a different question, but have you considered using
a different PDF viewer + annotation application? Okular
<https://eu01.z.antigena.com/l/iZmB5crNT773HTSUSt2S6McW6mdP5phHyzgXromFHINsN6Uo6BMnSdZK0kmSK~aLduXw-YpIAWy-DV9bac-5U3grBsLdYxuX7aMmbxQjKSLGCqTyJG54WQ2W7oaR2NEPTWiFotbkB4_eQTzHI3L-cAgOgsS4exJ4ie4BHLt > is free and available on Windows (including
from outside Microsoft store). Its annotation features include all
kinds of highlights, arrows and lines, both straight and
arbitrarily-shaped, quickly available from the "annotations" panel.

--
Best regards,
Ivan

	[[alternative HTML version deleted]]


From |@rz@dghoo@h| @end|ng |rom gm@||@com  Tue Jun  4 12:49:25 2024
From: |@rz@dghoo@h| @end|ng |rom gm@||@com (Farzad Ghooshi)
Date: Tue, 4 Jun 2024 14:19:25 +0330
Subject: [R] nc file
Message-ID: <CAJz8DZjHoSAd+isS=iydaNZq3KH+xedZBbK58s98bZyqHNcqwA@mail.gmail.com>

Hello
I am a PhD student in ecology.
The subject of my thesis is climate change and agricultural systems
modeling. One of the software used in this research is R.
As you know, nc files show climate variables by year in general for the
whole world.
With what command line can I isolate an nc file climate variable for a
specific location?

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Tue Jun  4 15:00:42 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 4 Jun 2024 09:00:42 -0400
Subject: [R] nc file
In-Reply-To: <CAJz8DZjHoSAd+isS=iydaNZq3KH+xedZBbK58s98bZyqHNcqwA@mail.gmail.com>
References: <CAJz8DZjHoSAd+isS=iydaNZq3KH+xedZBbK58s98bZyqHNcqwA@mail.gmail.com>
Message-ID: <db88b451-ae43-4ea4-a92d-c6f5e91fac96@gmail.com>

    This question is unfortunately too vague for us to help you.  A 
little bit of web-searching turned up this tutorial: maybe that will help?

https://rpubs.com/boyerag/297592

On 2024-06-04 6:49 a.m., Farzad Ghooshi wrote:
> Hello
> I am a PhD student in ecology.
> The subject of my thesis is climate change and agricultural systems
> modeling. One of the software used in this research is R.
> As you know, nc files show climate variables by year in general for the
> whole world.
> With what command line can I isolate an nc file climate variable for a
> specific location?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Roger@B|v@nd @end|ng |rom nhh@no  Wed Jun  5 14:20:35 2024
From: Roger@B|v@nd @end|ng |rom nhh@no (Roger Bivand)
Date: Wed, 5 Jun 2024 12:20:35 +0000
Subject: [R] nc file
Message-ID: <SV0P279MB0475FC860C2457917D12C1C1EEF92@SV0P279MB0475.NORP279.PROD.OUTLOOK.COM>

The link suggested by Ben is over 7 years old, so using the CRAN Task View: https://cran.r-project.org/web/views/Spatial.html, which is up-to-date, and https://rspatial.org/index.html, because the terra package has largely replaced the raster package. Please consider following up on the R-sig-geo mailing list: https://stat.ethz.ch/mailman/listinfo/r-sig-geo.

Hope this helps,

Roger

--
Roger Bivand
Emeritus Professor
Norwegian School of Economics
Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway
Roger.Bivand at nhh.no

From |b@rnh@rt055 @end|ng |rom gm@||@com  Thu Jun  6 02:07:19 2024
From: |b@rnh@rt055 @end|ng |rom gm@||@com (I B)
Date: Wed, 5 Jun 2024 19:07:19 -0500
Subject: [R] R Shiny Help - Trouble passing user input columns to emmeans
 after ANOVA analysis
Message-ID: <CAPJbgronjQqxC57TqRmWnd4VzmWtRs=qLdw1QxKRb1Boo-Zf=Q@mail.gmail.com>

Hello everybody,

I have experience coding with R, but am brand new to R Shiny. I am trying
to produce an application that will allow users to upload their own
dataset, select columns they want an ANOVA analysis run on, and generate
graphs that will allow users to view their results. However, I am getting
the following error: *"Argument is of length zero."*

Being new to Shiny, I am having trouble passing the user input column to an
emmeans argument in order to do a post hoc analysis, and using that
information to produce a graph. Can somebody help me with this? *The code
for my dataset and application are provided below; copying and pasting
directly into R should generate the reproducible example.*

In my application, the following columns should be selected after uploading
the dataset:

   - Select response variable: "ndvi"
   - Select first independent variable: "genotype"
   - Select second independent variable: "rate"
   - Select random variable: "rep"

For this example, the final two drop-down selections should be:

   - "Which variable would you like to graph? "genotype"
   - "Which ANOVA model do you want to graph? "Main effects model"

Any help would be great. Thank you so much!

Sincerely,
Isaac Barnhart, PhD


*Here is my dataset:*

data <- data.frame(rep =
c(1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3),
                   genotype =
c('a','a','a','a','b','b','b','b','c','c','c','c','a','a','a','a','b','b','b','b','c','c','c','c','a','a','a','a','b','b','b','b','c','c','c','c'),
                   rate =
c('1x','2x','4x','8x','1x','2x','4x','8x','1x','2x','4x','8x','1x','2x','4x','8x','1x','2x','4x','8x','1x','2x','4x','8x','1x','2x','4x','8x','1x','2x','4x','8x','1x','2x','4x','8x'),
                   ndvi =
c(0.584947811,0.642112121,0.654116902,0.785068313,0.79665163,0.674549249,0.958911611,0.547077528,0.613315552,0.768646411,0.97107949,0.680942649,0.520576242,0.723920266,0.868779972,0.834257732,0.554506685,0.520458208,0.617282262,0.80128067,0.875192693,0.572153151,0.850305042,0.500760522,0.796305833,0.643719779,0.590512435,0.522884966,0.905197544,0.663792758,0.690415735,0.975449466,0.621379163,0.734904647,0.812023395,0.928144532))


*Here is my code:*

library(shiny)
library(ggplot2)
library(tidyverse)
library(emmeans)
library(DHARMa)
library(lme4)

ui <- fluidPage(
  fileInput("file1", "Choose .csv or .xlsx file",
            accept = c("text/csv",
                       "text/comma-separated-values",
                       ".csv",
                       ".xlsx")),
  textOutput("data_info"),
  verbatimTextOutput("data_head"),
  uiOutput("column_selector_1"),
  uiOutput("column_selector_2"),
  uiOutput("column_selector_3"),
  uiOutput("column_selector_4"),
  textOutput("dist_info"),
  plotOutput("dist"),
  textOutput("str_info"),
  verbatimTextOutput("selected_columns"),
  textOutput("two_way_anova"),
  verbatimTextOutput("model_summary"),
  textOutput("main_effects"),
  verbatimTextOutput("model_summary_ME"),
  textOutput("mod_diagnostic"),
  plotOutput("diagnostic_plot"),
  uiOutput("graph"),
  uiOutput("model_selection"),
  plotOutput("graph_plot")
)

server <- function(input, output, session) {
  # Open file
  req(data <- reactive({
    infile <- input$file1
    if (is.null(infile)) {
      return(NULL)
    }
    read.csv(infile$datapath, header = TRUE)
  }))

  # Preview data
  output$data_info <- renderText({
    req(data())
    "Preview of the data uploaded:"
  })

  output$data_head <- renderPrint({
    req(data())
    head(data(), 20)
  })

  # Select response variable
  output$column_selector_1 <- renderUI({
    req(data())
    selectInput("column1","Select response variable", choices =
names(data()))
    })

  # Select first independent variable
  output$column_selector_2 <- renderUI({
    req(data())
    selectInput("column2", "Select first independent variable", choices =
names(data()))
  })

  # Select second independent variable
  output$column_selector_3 <- renderUI({
    req(data())
    selectInput("column3", "Select second independent variable", choices =
names(data()))
  })

  # Select random variable
  output$column_selector_4 <- renderUI({
    req(data())
    selectInput("column4", "Select random variable", choices =
names(data()))
  })

  # Assigning user inputs to correct variables
  selected_columns <- reactive({
    req(data(), input$column1, input$column2, input$column3, input$column4)
    list(
      dependent = data()[[input$column1]],
      independent1 = as.factor(data()[[input$column2]]),
      independent2 = as.factor(data()[[input$column3]]),
      random = as.factor(data()[[input$column4]]),

      # Define column names for later use
      column1 <- input$column1,
      column2 <- input$column2,
      column3 <- input$column3,
      column4 <- input$column4
    )
  })

  # Instructional text
  output$dist_info <- renderText({
    req(data())
    "The graph below shows the shape of response variable distribution"
  })


  # Distribution plot
  output$dist <- renderPlot({
    req(selected_columns())
    cols <- selected_columns()
    plot(density(cols$dependent), main = "Distribution Plot")
  })

  # Instructional text
  output$str_info <- renderText({
    req(data())
    "The code below verifies that our data are in the correct structure for
ANOVA analyses. All independent variables should be changed to 'Factor'. "
  })

  # Verifies that columns are in the correct structure
  output$selected_columns <- renderPrint({
    cols <- selected_columns()
    str(cols)
  })

  # Instructional text
  output$two_way_anova <- renderText({
    req(data())
    "Two-way ANOVA with interaction"
  })

  # Build ANOVA model with two-way interaction
  interaction_model <- reactive({
    cols <- selected_columns()
    req(cols)
    data <- data()
    data$dep <- cols$dependent
    data$indep1 <- cols$independent1
    data$indep2 <- cols$independent2
    data$rand <- cols$random
    lmer(dep ~ indep1 * indep2 + (1|rand), data = data)
  })

  # Run two-way ANOVA model with interaction
  output$model_summary <- renderPrint({
    req(interaction_model())
    Anova(interaction_model(), type = c("III"))
  })

  # Build main effects ANOVA model
  main_effects_model <- reactive({
    cols <- selected_columns()
    req(cols)
    data <- data()
    data$dep <- cols$dependent
    data$indep1 <- cols$independent1
    data$indep2 <- cols$independent2
    data$rand <- cols$random
    lmer(dep ~ indep1 + indep2 + (1|rand), data = data)
  })

  # Instructional text
  output$main_effects <- renderText({
    req(data())
    "Two-way ANOVA, main effects"
  })

  # Run two-way main effects model
  output$model_summary_ME <- renderPrint({
    req(main_effects_model())
    Anova(main_effects_model(), type = c("III"))
  })


  output$mod_diagnostic <- renderText({
    req(main_effects_model())
    "Below, the `DHARMa` package is used to check model assumptions. If
assumptions are not met, then data transformations may be needed before
proceeding."
  })

  output$diagnostic_plot <- renderPlot({
    req(interaction_model())
    plotQQunif(interaction_model())
  })

  output$graph <- renderUI({
    req(data(), input$column2, input$column3)
    selectInput("graph", "Which variable would you like to graph?", choices
= c(input$column2, input$column3, "interaction"))
  })

  output$model_selection <- renderUI({
    req(main_effects_model(), interaction_model())
    selectInput("model_selection", "Which ANOVA model do you want to
graph?", choices = c("Main effects model", "Interaction model"))
  })

  # Create a reactive expression to store the selected graph variable
  selected_graph <- reactive({
    input$graph
  })

  # Create a reactive expression to store the selected model
  selected_model <- reactive({
    input$model_selection
  })

  # Render the plot based on the selected variables
  output$graph_plot <- renderPlot({
    req(data(), selected_graph(), selected_model())
    cols <- selected_columns()

    if (selected_graph() == cols$column2 | selected_model() == "Main
effects model") {

      # Mean separation: First column
      mod_means_cotr1 <- emmeans(main_effects_model(), pairwise ~
cols$column2,
                                adjust = 'tukey',
                                type = 'response')

      mod_means1 <- multcomp::cld(object = mod_means_cotr1$emmeans,
                                 LETTERS = "letters")

      # Graph: First column
      ggplot(mod_means1, aes_string(x = cols$column2, y = cols_column1))+
        geom_bar(stat="identity", width = 0.6, position = "dodge", col =
"black", fill = "purple3")+
        geom_errorbar(aes(ymin = emmean, ymax = emmean + SE), width = 0.3,
position = position_dodge(0.6))+
        xlab(cols$column2)+
        ylab(cols$column1)+
        theme(plot.title=element_text(hjust=0.5, size = 20),
              plot.subtitle = element_text(hjust = 0.5, size = 15),
              axis.text = element_text(size = 17),
              axis.title = element_text(size = 20))+
        geom_text(aes(label=.group, y=emmean + SE), vjust = -0.9, size = 8)
+
        #ylim(0, 105)+
        scale_x_discrete(labels = function(x) str_wrap(x, width = 7))


    }
  })

}
shinyApp(ui, server)

	[[alternative HTML version deleted]]


From ju||en@jo|y @end|ng |rom |n@erm@|r  Thu Jun  6 10:45:20 2024
From: ju||en@jo|y @end|ng |rom |n@erm@|r (Julien JOLY)
Date: Thu, 6 Jun 2024 08:45:20 +0000
Subject: [R] Bug report for package foreign anf functon write.foreign
Message-ID: <faf69f4017b64e84aa6fa75f399c8e5d@inserm.fr>

Dear all,

First of all, I thank you for the creation of the package.

I write this message concerning the write.foreign() function from the foreign package and a bug that I discovered.
When we want to save our dataset as a .sas file, the limit of variable names character is 8 by default. In SAS this limit is 32 character and an argument in the function, validvarname, can theorically switch the default from 8 to 32 by selecting validvarname = "V7".

However, it did not work and show the error "Cannot uniquely abbreviate format names to conform to eight-character limit and not ending in a digit" that show the limit is still 8 characters.

By looking at the script at https://github.com/cran/foreign/blob/master/R/writeForeignSAS.R , I realized that the line 39, in the function make.SAS.formats, can be the reason of the nonfunctioning argument :
"if(any(nchar(x) > 8L) || any(duplicated(x)))" which is correct if the length of the variable has a limit of 8, but it does not take in consideration when the limit is at 32 defined by validvarnames = "V7".

A solution can be to add the argument validvarname in the definition of the function and add these few lines :
  validvarname <- match.arg(validvarname)
  nmax <- if(validvarname == "V7") 32L else 8L
  if(any(nchar(x) > nmax) || any(duplicated(x)))


I hope I send the message to the good place and that it will help you improve the package.

Kind regards,



Julien Joly

Biostatisticien et Data manager





	[[alternative HTML version deleted]]


From kev|n@thorpe @end|ng |rom utoronto@c@  Thu Jun  6 16:35:44 2024
From: kev|n@thorpe @end|ng |rom utoronto@c@ (Kevin Thorpe)
Date: Thu, 6 Jun 2024 14:35:44 +0000
Subject: [R] Bug report for package foreign anf functon write.foreign
In-Reply-To: <faf69f4017b64e84aa6fa75f399c8e5d@inserm.fr>
References: <faf69f4017b64e84aa6fa75f399c8e5d@inserm.fr>
Message-ID: <E299C946-CB74-4598-9FF3-0C2C03AA3191@utoronto.ca>

I haven?t used this function in a long time, but it sounds like the issue is the format names for the formats catalog, not the variable names.

You might try the haven package as it can create SAS datasets directly, although there are limitations (I think).

> On Jun 6, 2024, at 4:45?AM, Julien JOLY <julien.joly at inserm.fr> wrote:
> 
> [Vous ne recevez pas souvent de courriers de julien.joly at inserm.fr. D?couvrez pourquoi ceci est important ? https://aka.ms/LearnAboutSenderIdentification ]
> 
> Dear all,
> 
> First of all, I thank you for the creation of the package.
> 
> I write this message concerning the write.foreign() function from the foreign package and a bug that I discovered.
> When we want to save our dataset as a .sas file, the limit of variable names character is 8 by default. In SAS this limit is 32 character and an argument in the function, validvarname, can theorically switch the default from 8 to 32 by selecting validvarname = "V7".
> 
> However, it did not work and show the error "Cannot uniquely abbreviate format names to conform to eight-character limit and not ending in a digit" that show the limit is still 8 characters.
> 
> By looking at the script at https://github.com/cran/foreign/blob/master/R/writeForeignSAS.R , I realized that the line 39, in the function make.SAS.formats, can be the reason of the nonfunctioning argument :
> "if(any(nchar(x) > 8L) || any(duplicated(x)))" which is correct if the length of the variable has a limit of 8, but it does not take in consideration when the limit is at 32 defined by validvarnames = "V7".
> 
> A solution can be to add the argument validvarname in the definition of the function and add these few lines :
>  validvarname <- match.arg(validvarname)
>  nmax <- if(validvarname == "V7") 32L else 8L
>  if(any(nchar(x) > nmax) || any(duplicated(x)))
> 
> 
> I hope I send the message to the good place and that it will help you improve the package.
> 
> Kind regards,
> 
> 
> 
> Julien Joly
> 
> Biostatisticien et Data manager
> 
> 
> 
> 
> 
>        [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Kevin E. Thorpe
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416-946-8083



From yo@u@yurr@mend| @end|ng |rom gm@||@com  Thu Jun  6 10:37:38 2024
From: yo@u@yurr@mend| @end|ng |rom gm@||@com (Yosu Yurramendi)
Date: Thu, 6 Jun 2024 10:37:38 +0200
Subject: [R] What is the HEX code for "transparent" color?
Message-ID: <CADg5kN3dTkDWj6buW5FV2ujpu3JLF4YUFSbzj7_Rw=y2EkMoqA@mail.gmail.com>

What is the HEX code for "transparent" color?
I've tried "00000000" "FFFFFF00" "FFFFFFFF", but they don't work.
Thanks

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Jun  6 16:49:19 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 6 Jun 2024 07:49:19 -0700
Subject: [R] 
 R Shiny Help - Trouble passing user input columns to emmeans
 after ANOVA analysis
In-Reply-To: <CAPJbgronjQqxC57TqRmWnd4VzmWtRs=qLdw1QxKRb1Boo-Zf=Q@mail.gmail.com>
References: <CAPJbgronjQqxC57TqRmWnd4VzmWtRs=qLdw1QxKRb1Boo-Zf=Q@mail.gmail.com>
Message-ID: <CAGxFJbQnyNGAO5pQikOzNLC5OfsgkdL3d=Z-rxka35St_O==rA@mail.gmail.com>

Wrong list. Shiny is software from an external provider, POSIT (formerly
RStudio) and not part of R, itself. They have a community support site at:

https://forum.posit.co/?_gl=1*bh848i*_ga*MTY2NjcwNzQ4LjE3MTYyMzkzODQ.*_ga_2C0WZ1JHG0*MTcxNzY4NTExNi4yLjAuMTcxNzY4NTExNi4wLjAuMA
..

Cheers,
Bert

On Thu, Jun 6, 2024 at 12:09?AM I B <ibarnhart055 at gmail.com> wrote:

> Hello everybody,
>
> I have experience coding with R, but am brand new to R Shiny. I am trying
> to produce an application that will allow users to upload their own
> dataset, select columns they want an ANOVA analysis run on, and generate
> graphs that will allow users to view their results. However, I am getting
> the following error: *"Argument is of length zero."*
>
> Being new to Shiny, I am having trouble passing the user input column to an
> emmeans argument in order to do a post hoc analysis, and using that
> information to produce a graph. Can somebody help me with this? *The code
> for my dataset and application are provided below; copying and pasting
> directly into R should generate the reproducible example.*
>
> In my application, the following columns should be selected after uploading
> the dataset:
>
>    - Select response variable: "ndvi"
>    - Select first independent variable: "genotype"
>    - Select second independent variable: "rate"
>    - Select random variable: "rep"
>
> For this example, the final two drop-down selections should be:
>
>    - "Which variable would you like to graph? "genotype"
>    - "Which ANOVA model do you want to graph? "Main effects model"
>
> Any help would be great. Thank you so much!
>
> Sincerely,
> Isaac Barnhart, PhD
>
>
> *Here is my dataset:*
>
> data <- data.frame(rep =
> c(1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3),
>                    genotype =
>
> c('a','a','a','a','b','b','b','b','c','c','c','c','a','a','a','a','b','b','b','b','c','c','c','c','a','a','a','a','b','b','b','b','c','c','c','c'),
>                    rate =
>
> c('1x','2x','4x','8x','1x','2x','4x','8x','1x','2x','4x','8x','1x','2x','4x','8x','1x','2x','4x','8x','1x','2x','4x','8x','1x','2x','4x','8x','1x','2x','4x','8x','1x','2x','4x','8x'),
>                    ndvi =
>
> c(0.584947811,0.642112121,0.654116902,0.785068313,0.79665163,0.674549249,0.958911611,0.547077528,0.613315552,0.768646411,0.97107949,0.680942649,0.520576242,0.723920266,0.868779972,0.834257732,0.554506685,0.520458208,0.617282262,0.80128067,0.875192693,0.572153151,0.850305042,0.500760522,0.796305833,0.643719779,0.590512435,0.522884966,0.905197544,0.663792758,0.690415735,0.975449466,0.621379163,0.734904647,0.812023395,0.928144532))
>
>
> *Here is my code:*
>
> library(shiny)
> library(ggplot2)
> library(tidyverse)
> library(emmeans)
> library(DHARMa)
> library(lme4)
>
> ui <- fluidPage(
>   fileInput("file1", "Choose .csv or .xlsx file",
>             accept = c("text/csv",
>                        "text/comma-separated-values",
>                        ".csv",
>                        ".xlsx")),
>   textOutput("data_info"),
>   verbatimTextOutput("data_head"),
>   uiOutput("column_selector_1"),
>   uiOutput("column_selector_2"),
>   uiOutput("column_selector_3"),
>   uiOutput("column_selector_4"),
>   textOutput("dist_info"),
>   plotOutput("dist"),
>   textOutput("str_info"),
>   verbatimTextOutput("selected_columns"),
>   textOutput("two_way_anova"),
>   verbatimTextOutput("model_summary"),
>   textOutput("main_effects"),
>   verbatimTextOutput("model_summary_ME"),
>   textOutput("mod_diagnostic"),
>   plotOutput("diagnostic_plot"),
>   uiOutput("graph"),
>   uiOutput("model_selection"),
>   plotOutput("graph_plot")
> )
>
> server <- function(input, output, session) {
>   # Open file
>   req(data <- reactive({
>     infile <- input$file1
>     if (is.null(infile)) {
>       return(NULL)
>     }
>     read.csv(infile$datapath, header = TRUE)
>   }))
>
>   # Preview data
>   output$data_info <- renderText({
>     req(data())
>     "Preview of the data uploaded:"
>   })
>
>   output$data_head <- renderPrint({
>     req(data())
>     head(data(), 20)
>   })
>
>   # Select response variable
>   output$column_selector_1 <- renderUI({
>     req(data())
>     selectInput("column1","Select response variable", choices =
> names(data()))
>     })
>
>   # Select first independent variable
>   output$column_selector_2 <- renderUI({
>     req(data())
>     selectInput("column2", "Select first independent variable", choices =
> names(data()))
>   })
>
>   # Select second independent variable
>   output$column_selector_3 <- renderUI({
>     req(data())
>     selectInput("column3", "Select second independent variable", choices =
> names(data()))
>   })
>
>   # Select random variable
>   output$column_selector_4 <- renderUI({
>     req(data())
>     selectInput("column4", "Select random variable", choices =
> names(data()))
>   })
>
>   # Assigning user inputs to correct variables
>   selected_columns <- reactive({
>     req(data(), input$column1, input$column2, input$column3, input$column4)
>     list(
>       dependent = data()[[input$column1]],
>       independent1 = as.factor(data()[[input$column2]]),
>       independent2 = as.factor(data()[[input$column3]]),
>       random = as.factor(data()[[input$column4]]),
>
>       # Define column names for later use
>       column1 <- input$column1,
>       column2 <- input$column2,
>       column3 <- input$column3,
>       column4 <- input$column4
>     )
>   })
>
>   # Instructional text
>   output$dist_info <- renderText({
>     req(data())
>     "The graph below shows the shape of response variable distribution"
>   })
>
>
>   # Distribution plot
>   output$dist <- renderPlot({
>     req(selected_columns())
>     cols <- selected_columns()
>     plot(density(cols$dependent), main = "Distribution Plot")
>   })
>
>   # Instructional text
>   output$str_info <- renderText({
>     req(data())
>     "The code below verifies that our data are in the correct structure for
> ANOVA analyses. All independent variables should be changed to 'Factor'. "
>   })
>
>   # Verifies that columns are in the correct structure
>   output$selected_columns <- renderPrint({
>     cols <- selected_columns()
>     str(cols)
>   })
>
>   # Instructional text
>   output$two_way_anova <- renderText({
>     req(data())
>     "Two-way ANOVA with interaction"
>   })
>
>   # Build ANOVA model with two-way interaction
>   interaction_model <- reactive({
>     cols <- selected_columns()
>     req(cols)
>     data <- data()
>     data$dep <- cols$dependent
>     data$indep1 <- cols$independent1
>     data$indep2 <- cols$independent2
>     data$rand <- cols$random
>     lmer(dep ~ indep1 * indep2 + (1|rand), data = data)
>   })
>
>   # Run two-way ANOVA model with interaction
>   output$model_summary <- renderPrint({
>     req(interaction_model())
>     Anova(interaction_model(), type = c("III"))
>   })
>
>   # Build main effects ANOVA model
>   main_effects_model <- reactive({
>     cols <- selected_columns()
>     req(cols)
>     data <- data()
>     data$dep <- cols$dependent
>     data$indep1 <- cols$independent1
>     data$indep2 <- cols$independent2
>     data$rand <- cols$random
>     lmer(dep ~ indep1 + indep2 + (1|rand), data = data)
>   })
>
>   # Instructional text
>   output$main_effects <- renderText({
>     req(data())
>     "Two-way ANOVA, main effects"
>   })
>
>   # Run two-way main effects model
>   output$model_summary_ME <- renderPrint({
>     req(main_effects_model())
>     Anova(main_effects_model(), type = c("III"))
>   })
>
>
>   output$mod_diagnostic <- renderText({
>     req(main_effects_model())
>     "Below, the `DHARMa` package is used to check model assumptions. If
> assumptions are not met, then data transformations may be needed before
> proceeding."
>   })
>
>   output$diagnostic_plot <- renderPlot({
>     req(interaction_model())
>     plotQQunif(interaction_model())
>   })
>
>   output$graph <- renderUI({
>     req(data(), input$column2, input$column3)
>     selectInput("graph", "Which variable would you like to graph?", choices
> = c(input$column2, input$column3, "interaction"))
>   })
>
>   output$model_selection <- renderUI({
>     req(main_effects_model(), interaction_model())
>     selectInput("model_selection", "Which ANOVA model do you want to
> graph?", choices = c("Main effects model", "Interaction model"))
>   })
>
>   # Create a reactive expression to store the selected graph variable
>   selected_graph <- reactive({
>     input$graph
>   })
>
>   # Create a reactive expression to store the selected model
>   selected_model <- reactive({
>     input$model_selection
>   })
>
>   # Render the plot based on the selected variables
>   output$graph_plot <- renderPlot({
>     req(data(), selected_graph(), selected_model())
>     cols <- selected_columns()
>
>     if (selected_graph() == cols$column2 | selected_model() == "Main
> effects model") {
>
>       # Mean separation: First column
>       mod_means_cotr1 <- emmeans(main_effects_model(), pairwise ~
> cols$column2,
>                                 adjust = 'tukey',
>                                 type = 'response')
>
>       mod_means1 <- multcomp::cld(object = mod_means_cotr1$emmeans,
>                                  LETTERS = "letters")
>
>       # Graph: First column
>       ggplot(mod_means1, aes_string(x = cols$column2, y = cols_column1))+
>         geom_bar(stat="identity", width = 0.6, position = "dodge", col =
> "black", fill = "purple3")+
>         geom_errorbar(aes(ymin = emmean, ymax = emmean + SE), width = 0.3,
> position = position_dodge(0.6))+
>         xlab(cols$column2)+
>         ylab(cols$column1)+
>         theme(plot.title=element_text(hjust=0.5, size = 20),
>               plot.subtitle = element_text(hjust = 0.5, size = 15),
>               axis.text = element_text(size = 17),
>               axis.title = element_text(size = 20))+
>         geom_text(aes(label=.group, y=emmean + SE), vjust = -0.9, size = 8)
> +
>         #ylim(0, 105)+
>         scale_x_discrete(labels = function(x) str_wrap(x, width = 7))
>
>
>     }
>   })
>
> }
> shinyApp(ui, server)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From |kry|ov @end|ng |rom d|@root@org  Thu Jun  6 17:05:33 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Thu, 6 Jun 2024 18:05:33 +0300
Subject: [R] 
 R Shiny Help - Trouble passing user input columns to emmeans
 after ANOVA analysis
In-Reply-To: <CAPJbgronjQqxC57TqRmWnd4VzmWtRs=qLdw1QxKRb1Boo-Zf=Q@mail.gmail.com>
References: <CAPJbgronjQqxC57TqRmWnd4VzmWtRs=qLdw1QxKRb1Boo-Zf=Q@mail.gmail.com>
Message-ID: <20240606180533.17593520@arachnoid>

? Wed, 5 Jun 2024 19:07:19 -0500
I B <ibarnhart055 at gmail.com> ?????:

> However, I am getting the following error: *"Argument is of length
> zero."*

>     if (selected_graph() == cols$column2 | selected_model() == "Main
> effects model") {

The error must be coming from here.

At least one of selected_graph(), cols$column2, selected_model() is a
zero-length object (maybe NULL) at this point, which makes the result
of the whole expression zero-length too. if (...) only accepts logical
scalars, hence the error.

-- 
Best regards,
Ivan


From 538280 @end|ng |rom gm@||@com  Thu Jun  6 17:08:06 2024
From: 538280 @end|ng |rom gm@||@com (Greg Snow)
Date: Thu, 6 Jun 2024 09:08:06 -0600
Subject: [R] What is the HEX code for "transparent" color?
In-Reply-To: <CADg5kN3dTkDWj6buW5FV2ujpu3JLF4YUFSbzj7_Rw=y2EkMoqA@mail.gmail.com>
References: <CADg5kN3dTkDWj6buW5FV2ujpu3JLF4YUFSbzj7_Rw=y2EkMoqA@mail.gmail.com>
Message-ID: <CAFEqCdwvCV3ky2JxiXpuXnX6uokMOinkLzi7PZPjcBK2oeYKwQ@mail.gmail.com>

You need a "#" at the beginning of the string to specify that it is a
hex code for the color.  Try "#00000000".

On Thu, Jun 6, 2024 at 9:07?AM Yosu Yurramendi
<yosu.yurramendi at gmail.com> wrote:
>
> What is the HEX code for "transparent" color?
> I've tried "00000000" "FFFFFF00" "FFFFFFFF", but they don't work.
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From bobby@kn|ght @end|ng |rom gm@||@com  Thu Jun  6 17:34:43 2024
From: bobby@kn|ght @end|ng |rom gm@||@com (Robert Knight)
Date: Thu, 6 Jun 2024 11:34:43 -0400
Subject: [R] What is the HEX code for "transparent" color?
In-Reply-To: <CADg5kN3dTkDWj6buW5FV2ujpu3JLF4YUFSbzj7_Rw=y2EkMoqA@mail.gmail.com>
References: <CADg5kN3dTkDWj6buW5FV2ujpu3JLF4YUFSbzj7_Rw=y2EkMoqA@mail.gmail.com>
Message-ID: <CAKBFG3YutD714tUtt5nUFw96p368fLXWyve3nL_LO7iVvRUfyw@mail.gmail.com>

You would give an existing color a new name and modify the new name's
alpha.  Then refer to the color by the new name instead of using HEX.

On Thu, Jun 6, 2024, 11:07?AM Yosu Yurramendi <yosu.yurramendi at gmail.com>
wrote:

> What is the HEX code for "transparent" color?
> I've tried "00000000" "FFFFFF00" "FFFFFFFF", but they don't work.
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Jun  6 18:41:55 2024
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 6 Jun 2024 12:41:55 -0400
Subject: [R] What is the HEX code for "transparent" color?
In-Reply-To: <CADg5kN3dTkDWj6buW5FV2ujpu3JLF4YUFSbzj7_Rw=y2EkMoqA@mail.gmail.com>
References: <CADg5kN3dTkDWj6buW5FV2ujpu3JLF4YUFSbzj7_Rw=y2EkMoqA@mail.gmail.com>
Message-ID: <dc5818fe-ca44-4d24-903f-16a6cd96b9f4@gmail.com>

On 2024-06-06 4:37 a.m., Yosu Yurramendi wrote:
> What is the HEX code for "transparent" color?
> I've tried "00000000" "FFFFFF00" "FFFFFFFF", but they don't work.

If the other answers don't solve your problem, you should give us some 
context.  Not all graphics functions in R can handle transparency, so 
please show us some reproducible code for what you are trying.

Duncan Murdoch


From rk @end|ng |rom rk@|y|  Thu Jun  6 17:24:21 2024
From: rk @end|ng |rom rk@|y| (Robert Knight)
Date: Thu, 06 Jun 2024 11:24:21 -0400
Subject: [R] What is the HEX code for "transparent" color?
In-Reply-To: <CAFEqCdwvCV3ky2JxiXpuXnX6uokMOinkLzi7PZPjcBK2oeYKwQ@mail.gmail.com>
References: <CADg5kN3dTkDWj6buW5FV2ujpu3JLF4YUFSbzj7_Rw=y2EkMoqA@mail.gmail.com>
 <CAFEqCdwvCV3ky2JxiXpuXnX6uokMOinkLzi7PZPjcBK2oeYKwQ@mail.gmail.com>
Message-ID: <C419D04D-D029-4D77-9679-A0066202800A@rk.fyi>

You would set the alpha of an existing color and give it a new name and then refer to it by name rather than using HEX codes. 

On June 6, 2024 11:08:06 AM EDT, Greg Snow <538280 at gmail.com> wrote:
>You need a "#" at the beginning of the string to specify that it is a
>hex code for the color.  Try "#00000000".
>
>On Thu, Jun 6, 2024 at 9:07?AM Yosu Yurramendi
><yosu.yurramendi at gmail.com> wrote:
>>
>> What is the HEX code for "transparent" color?
>> I've tried "00000000" "FFFFFF00" "FFFFFFFF", but they don't work.
>> Thanks
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>-- 
>Gregory (Greg) L. Snow Ph.D.
>538280 at gmail.com
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Robert Knight
tel 270-306-1658
fax (270) 288-0474
rk at rk.fyi
	[[alternative HTML version deleted]]


From r@u @end|ng |rom demogr@mpg@de  Fri Jun  7 16:34:12 2024
From: r@u @end|ng |rom demogr@mpg@de (Roland Rau)
Date: Fri, 7 Jun 2024 16:34:12 +0200
Subject: [R] What is the HEX code for "transparent" color?
In-Reply-To: <dc5818fe-ca44-4d24-903f-16a6cd96b9f4@gmail.com>
References: <CADg5kN3dTkDWj6buW5FV2ujpu3JLF4YUFSbzj7_Rw=y2EkMoqA@mail.gmail.com>
 <dc5818fe-ca44-4d24-903f-16a6cd96b9f4@gmail.com>
Message-ID: <188970f1-3cfa-44f1-a7bf-3ec310722f6e@demogr.mpg.de>

On 6/6/24 18:41, Duncan Murdoch wrote:
> On 2024-06-06 4:37 a.m., Yosu Yurramendi wrote:
>> What is the HEX code for "transparent" color?
>> I've tried "00000000" "FFFFFF00" "FFFFFFFF", but they don't work.
> 
> If the other answers don't solve your problem, you should give us some 
> context.? Not all graphics functions in R can handle transparency, so 
> please show us some reproducible code for what you are trying.
> 
> Duncan Murdoch
> 

I usually use the alpha argument of the rgb() function for transparency.
Does this code snippet help to give you an idea how it works.

plot(1, 1, type="n", xlim=c(0,10), ylim=c(0,10))
rect(xleft=0, xright=7.5, ybottom=0, ytop=7.5,
      col=rgb(0, 0, 1, alpha=0.5))
rect(xleft=2.5, xright=10, ybottom=2.5, ytop=10,
      col=rgb(1, 0, 0, alpha=0.5))

Please check
?rgb
Especially the "Details" section should be helpful where you will find a 
list of devices which are supported or not supported.

I hope this helps a bit.

All the best,
Roland


--
This mail has been sent through the MPI for Demographic ...{{dropped:2}}


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Sat Jun  8 19:37:53 2024
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Sat, 8 Jun 2024 17:37:53 +0000
Subject: [R] Can't compute row means of two columns of a dataframe.
Message-ID: <DM6PR03MB50491504249460658C306971E2C42@DM6PR03MB5049.namprd03.prod.outlook.com>

I have a data frame with three columns, TotalInches, Low20, High20. For each row of the dataset, I am trying to compute the mean of Low20 and High20. 

xxxz <- structure(list(TotalInches = 
                 c(58, 59, 60, 61, 62, 63, 64, 65, 
                   66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76), Low20 = c(84, 87, 
                   90, 93, 96, 99, 102, 106, 109, 112, 116, 119, 122, 126, 129, 
                   133, 137, 141, 144), High20 = c(111, 115, 119, 123, 127, 131, 
                   135, 140, 144, 148, 153, 157, 162, 167, 171, 176, 181, 186, 191
                   )), class = "data.frame", row.names = c(NA, -19L))
xxxz
str(xxxz)
xxxz$Average20 <- by(xxxz[,c("Low20","High20")],xxxz[,"TotalInches"],mean)
warnings()

When I run the code above, I don't get the means by row. I get the following warning messages, one for each row of the dataframe.

Warning messages:
1: In mean.default(data[x, , drop = FALSE], ...) :
  argument is not numeric or logical: returning NA
2: In mean.default(data[x, , drop = FALSE], ...) :
  argument is not numeric or logical: returning NA

 Can someone tell my what I am doing wrong, and how I can compute the row means?

Thank you,
John

John David Sorkin M.D., Ph.D.
Professor of Medicine, University of Maryland School of Medicine;
Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;?
PI?Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;
Senior Statistician University of Maryland Center for Vascular Research;

Division of Gerontology and Paliative Care,
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
Cell phone 443-418-5382




From bgunter@4567 @end|ng |rom gm@||@com  Sat Jun  8 19:47:50 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 8 Jun 2024 10:47:50 -0700
Subject: [R] Can't compute row means of two columns of a dataframe.
In-Reply-To: <DM6PR03MB50491504249460658C306971E2C42@DM6PR03MB5049.namprd03.prod.outlook.com>
References: <DM6PR03MB50491504249460658C306971E2C42@DM6PR03MB5049.namprd03.prod.outlook.com>
Message-ID: <CAGxFJbTky3cF=JroVqC_3MWk2-1j2nRht4+hgq3nDkhk6kVF_A@mail.gmail.com>

Use apply(), not by().

xxxz$av20 <- apply(xxxz[,c("Low20","High20")],1, mean)

-- Bert

On Sat, Jun 8, 2024 at 10:38?AM Sorkin, John <jsorkin at som.umaryland.edu>
wrote:

> I have a data frame with three columns, TotalInches, Low20, High20. For
> each row of the dataset, I am trying to compute the mean of Low20 and
> High20.
>
> xxxz <- structure(list(TotalInches =
>                  c(58, 59, 60, 61, 62, 63, 64, 65,
>                    66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76), Low20 =
> c(84, 87,
>                    90, 93, 96, 99, 102, 106, 109, 112, 116, 119, 122, 126,
> 129,
>                    133, 137, 141, 144), High20 = c(111, 115, 119, 123,
> 127, 131,
>                    135, 140, 144, 148, 153, 157, 162, 167, 171, 176, 181,
> 186, 191
>                    )), class = "data.frame", row.names = c(NA, -19L))
> xxxz
> str(xxxz)
> xxxz$Average20 <- by(xxxz[,c("Low20","High20")],xxxz[,"TotalInches"],mean)
> warnings()
>
> When I run the code above, I don't get the means by row. I get the
> following warning messages, one for each row of the dataframe.
>
> Warning messages:
> 1: In mean.default(data[x, , drop = FALSE], ...) :
>   argument is not numeric or logical: returning NA
> 2: In mean.default(data[x, , drop = FALSE], ...) :
>   argument is not numeric or logical: returning NA
>
>  Can someone tell my what I am doing wrong, and how I can compute the row
> means?
>
> Thank you,
> John
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine, University of Maryland School of Medicine;
> Associate Director for Biostatistics and Informatics, Baltimore VA Medical
> Center Geriatrics Research, Education, and Clinical Center;
> PI Biostatistics and Informatics Core, University of Maryland School of
> Medicine Claude D. Pepper Older Americans Independence Center;
> Senior Statistician University of Maryland Center for Vascular Research;
>
> Division of Gerontology and Paliative Care,
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> Cell phone 443-418-5382
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Jun  8 19:57:55 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 8 Jun 2024 10:57:55 -0700
Subject: [R] Can't compute row means of two columns of a dataframe.
In-Reply-To: <CAGxFJbTky3cF=JroVqC_3MWk2-1j2nRht4+hgq3nDkhk6kVF_A@mail.gmail.com>
References: <DM6PR03MB50491504249460658C306971E2C42@DM6PR03MB5049.namprd03.prod.outlook.com>
 <CAGxFJbTky3cF=JroVqC_3MWk2-1j2nRht4+hgq3nDkhk6kVF_A@mail.gmail.com>
Message-ID: <CAGxFJbRpzHJh=2OhePypOyrUNhkB6YOaMH70W1SSc7DMGMXmfg@mail.gmail.com>

Incidentally, FWIW, for means, rowMeans() is a lot faster:

xxxz$av20 <- rowMeans(xxxz[,c("Low20","High20")])

Bert



On Sat, Jun 8, 2024 at 10:47?AM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Use apply(), not by().
>
> xxxz$av20 <- apply(xxxz[,c("Low20","High20")],1, mean)
>
> -- Bert
>
> On Sat, Jun 8, 2024 at 10:38?AM Sorkin, John <jsorkin at som.umaryland.edu>
> wrote:
>
>> I have a data frame with three columns, TotalInches, Low20, High20. For
>> each row of the dataset, I am trying to compute the mean of Low20 and
>> High20.
>>
>> xxxz <- structure(list(TotalInches =
>>                  c(58, 59, 60, 61, 62, 63, 64, 65,
>>                    66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76), Low20 =
>> c(84, 87,
>>                    90, 93, 96, 99, 102, 106, 109, 112, 116, 119, 122,
>> 126, 129,
>>                    133, 137, 141, 144), High20 = c(111, 115, 119, 123,
>> 127, 131,
>>                    135, 140, 144, 148, 153, 157, 162, 167, 171, 176, 181,
>> 186, 191
>>                    )), class = "data.frame", row.names = c(NA, -19L))
>> xxxz
>> str(xxxz)
>> xxxz$Average20 <- by(xxxz[,c("Low20","High20")],xxxz[,"TotalInches"],mean)
>> warnings()
>>
>> When I run the code above, I don't get the means by row. I get the
>> following warning messages, one for each row of the dataframe.
>>
>> Warning messages:
>> 1: In mean.default(data[x, , drop = FALSE], ...) :
>>   argument is not numeric or logical: returning NA
>> 2: In mean.default(data[x, , drop = FALSE], ...) :
>>   argument is not numeric or logical: returning NA
>>
>>  Can someone tell my what I am doing wrong, and how I can compute the row
>> means?
>>
>> Thank you,
>> John
>>
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine, University of Maryland School of Medicine;
>> Associate Director for Biostatistics and Informatics, Baltimore VA
>> Medical Center Geriatrics Research, Education, and Clinical Center;
>> PI Biostatistics and Informatics Core, University of Maryland School of
>> Medicine Claude D. Pepper Older Americans Independence Center;
>> Senior Statistician University of Maryland Center for Vascular Research;
>>
>> Division of Gerontology and Paliative Care,
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> Cell phone 443-418-5382
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From @vi@e@gross m@iii@g oii gm@ii@com  Sat Jun  8 20:15:46 2024
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Sat, 8 Jun 2024 14:15:46 -0400
Subject: [R] Can't compute row means of two columns of a dataframe.
In-Reply-To: <DM6PR03MB50491504249460658C306971E2C42@DM6PR03MB5049.namprd03.prod.outlook.com>
References: <DM6PR03MB50491504249460658C306971E2C42@DM6PR03MB5049.namprd03.prod.outlook.com>
Message-ID: <005001dab9cf$e2596850$a70c38f0$@gmail.com>

John,

Maybe you can clarify what you want the output to look like. It took me a
while to realize what you may want as it is NOT properly described as
wanting rowsums.

There is a standard function called rowMeans() that probably does what you
want if you want the mean of all rows as in:

> rowMeans(xxxz)
 [1]  84.33333  87.00000  89.66667  92.33333  95.00000  97.66667 100.33333
103.66667 106.33333 109.00000 112.33333 115.00000
[13] 118.00000 121.33333 124.00000 127.33333 130.66667 134.00000 137.00000

It does not add the means to the original data.frame if you wanted it there
but that is easy enough to do.

> xxxz$Average20 <-rowMeans(xxxz)
> head(xxxz)
  TotalInches Low20 High20 Average20
1          58    84    111  84.33333
2          59    87    115  87.00000
3          60    90    119  89.66667
4          61    93    123  92.33333
5          62    96    127  95.00000
6          63    99    131  97.66667

Your construct is more complex and it looks like you want to do this to a
subset of two columns. Again, straightforward:

xxxz$Average20 <-rowMeans(xxxz[, c("Low20", "High20")])

And I probably would do this using a dplyr mutate but that is outside the
scope.

This does not help explain your error, so let me look at what you are trying
to do.


What  did you expect to use by() for in the second argument? You seem to be
giving it INDICES of the first column entries. What is that for?

by(xxxz[,c("Low20","High20")],
   xxxz[,"TotalInches"],
   mean)

The documentation suggest this is for splitting by factors. I do not  see
there are multiple instances of some TotalInches so why is this needed for
some kind of grouping?

My guess is you are using the wrong function or the wrong way for your
needs. The warnings may relate to that.


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Sorkin, John
Sent: Saturday, June 8, 2024 1:38 PM
To: r-help at r-project.org (r-help at r-project.org) <r-help at r-project.org>
Subject: [R] Can't compute row means of two columns of a dataframe.

I have a data frame with three columns, TotalInches, Low20, High20. For each
row of the dataset, I am trying to compute the mean of Low20 and High20. 

xxxz <- structure(list(TotalInches = 
                 c(58, 59, 60, 61, 62, 63, 64, 65, 
                   66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76), Low20 =
c(84, 87, 
                   90, 93, 96, 99, 102, 106, 109, 112, 116, 119, 122, 126,
129, 
                   133, 137, 141, 144), High20 = c(111, 115, 119, 123, 127,
131, 
                   135, 140, 144, 148, 153, 157, 162, 167, 171, 176, 181,
186, 191
                   )), class = "data.frame", row.names = c(NA, -19L))
xxxz
str(xxxz)
xxxz$Average20 <- by(xxxz[,c("Low20","High20")],xxxz[,"TotalInches"],mean)
warnings()

When I run the code above, I don't get the means by row. I get the following
warning messages, one for each row of the dataframe.

Warning messages:
1: In mean.default(data[x, , drop = FALSE], ...) :
  argument is not numeric or logical: returning NA
2: In mean.default(data[x, , drop = FALSE], ...) :
  argument is not numeric or logical: returning NA

 Can someone tell my what I am doing wrong, and how I can compute the row
means?

Thank you,
John

John David Sorkin M.D., Ph.D.
Professor of Medicine, University of Maryland School of Medicine;
Associate Director for Biostatistics and Informatics, Baltimore VA Medical
Center Geriatrics Research, Education, and Clinical Center;?
PI?Biostatistics and Informatics Core, University of Maryland School of
Medicine Claude D. Pepper Older Americans Independence Center;
Senior Statistician University of Maryland Center for Vascular Research;

Division of Gerontology and Paliative Care,
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
Cell phone 443-418-5382



______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From tebert @end|ng |rom u||@edu  Sat Jun  8 22:05:48 2024
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Sat, 8 Jun 2024 20:05:48 +0000
Subject: [R] Can't compute row means of two columns of a dataframe.
In-Reply-To: <DM6PR03MB50491504249460658C306971E2C42@DM6PR03MB5049.namprd03.prod.outlook.com>
References: <DM6PR03MB50491504249460658C306971E2C42@DM6PR03MB5049.namprd03.prod.outlook.com>
Message-ID: <CH3PR22MB4514D97F81FDC8D9A3F73413CFC42@CH3PR22MB4514.namprd22.prod.outlook.com>

Can this problem be made more direct?

xxxz$Average.20 <- (xxxz$Low20 + xxxz$High20)/2

That is literally the mean of two columns. Functions can be useful if there will be more columns, but with just two this seems easier.

I will point out that the average daily temperature based on the midpoint between minimum and maximum contains a fair bit of error because that is only roughly how heating and cooling respond. I admit that sometimes there are no other choices and we work with available data.

Tim


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Sorkin, John
Sent: Saturday, June 8, 2024 1:38 PM
To: r-help at r-project.org (r-help at r-project.org) <r-help at r-project.org>
Subject: [R] Can't compute row means of two columns of a dataframe.

[External Email]

I have a data frame with three columns, TotalInches, Low20, High20. For each row of the dataset, I am trying to compute the mean of Low20 and High20.

xxxz <- structure(list(TotalInches =
                 c(58, 59, 60, 61, 62, 63, 64, 65,
                   66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76), Low20 = c(84, 87,
                   90, 93, 96, 99, 102, 106, 109, 112, 116, 119, 122, 126, 129,
                   133, 137, 141, 144), High20 = c(111, 115, 119, 123, 127, 131,
                   135, 140, 144, 148, 153, 157, 162, 167, 171, 176, 181, 186, 191
                   )), class = "data.frame", row.names = c(NA, -19L)) xxxz
str(xxxz)
xxxz$Average20 <- by(xxxz[,c("Low20","High20")],xxxz[,"TotalInches"],mean)
warnings()

When I run the code above, I don't get the means by row. I get the following warning messages, one for each row of the dataframe.

Warning messages:
1: In mean.default(data[x, , drop = FALSE], ...) :
  argument is not numeric or logical: returning NA
2: In mean.default(data[x, , drop = FALSE], ...) :
  argument is not numeric or logical: returning NA

 Can someone tell my what I am doing wrong, and how I can compute the row means?

Thank you,
John

John David Sorkin M.D., Ph.D.
Professor of Medicine, University of Maryland School of Medicine; Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center; PI Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center; Senior Statistician University of Maryland Center for Vascular Research;

Division of Gerontology and Paliative Care,
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
Cell phone 443-418-5382



______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From tebert @end|ng |rom u||@edu  Sun Jun  9 04:19:25 2024
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Sun, 9 Jun 2024 02:19:25 +0000
Subject: [R] Can't compute row means of two columns of a dataframe.
In-Reply-To: <005001dab9cf$e2596850$a70c38f0$@gmail.com>
References: <DM6PR03MB50491504249460658C306971E2C42@DM6PR03MB5049.namprd03.prod.outlook.com>
 <005001dab9cf$e2596850$a70c38f0$@gmail.com>
Message-ID: <CH3PR22MB451454252F08CDF63DB9B7E8CFC52@CH3PR22MB4514.namprd22.prod.outlook.com>

Would this work?

xxxz$Average20 <- (xxxz$Low20 + xxxz$High20)/2

I tried this earlier but it does not appear to have gone through.

Tim

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of avi.e.gross at gmail.com
Sent: Saturday, June 8, 2024 2:16 PM
To: 'Sorkin, John' <jsorkin at som.umaryland.edu>; r-help at r-project.org
Subject: Re: [R] Can't compute row means of two columns of a dataframe.

[External Email]

John,

Maybe you can clarify what you want the output to look like. It took me a while to realize what you may want as it is NOT properly described as wanting rowsums.

There is a standard function called rowMeans() that probably does what you want if you want the mean of all rows as in:

> rowMeans(xxxz)
 [1]  84.33333  87.00000  89.66667  92.33333  95.00000  97.66667 100.33333
103.66667 106.33333 109.00000 112.33333 115.00000 [13] 118.00000 121.33333 124.00000 127.33333 130.66667 134.00000 137.00000

It does not add the means to the original data.frame if you wanted it there but that is easy enough to do.

> xxxz$Average20 <-rowMeans(xxxz)
> head(xxxz)
  TotalInches Low20 High20 Average20
1          58    84    111  84.33333
2          59    87    115  87.00000
3          60    90    119  89.66667
4          61    93    123  92.33333
5          62    96    127  95.00000
6          63    99    131  97.66667

Your construct is more complex and it looks like you want to do this to a subset of two columns. Again, straightforward:

xxxz$Average20 <-rowMeans(xxxz[, c("Low20", "High20")])

And I probably would do this using a dplyr mutate but that is outside the scope.

This does not help explain your error, so let me look at what you are trying to do.


What  did you expect to use by() for in the second argument? You seem to be giving it INDICES of the first column entries. What is that for?

by(xxxz[,c("Low20","High20")],
   xxxz[,"TotalInches"],
   mean)

The documentation suggest this is for splitting by factors. I do not  see there are multiple instances of some TotalInches so why is this needed for some kind of grouping?

My guess is you are using the wrong function or the wrong way for your needs. The warnings may relate to that.


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Sorkin, John
Sent: Saturday, June 8, 2024 1:38 PM
To: r-help at r-project.org (r-help at r-project.org) <r-help at r-project.org>
Subject: [R] Can't compute row means of two columns of a dataframe.

I have a data frame with three columns, TotalInches, Low20, High20. For each row of the dataset, I am trying to compute the mean of Low20 and High20.

xxxz <- structure(list(TotalInches =
                 c(58, 59, 60, 61, 62, 63, 64, 65,
                   66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76), Low20 = c(84, 87,
                   90, 93, 96, 99, 102, 106, 109, 112, 116, 119, 122, 126, 129,
                   133, 137, 141, 144), High20 = c(111, 115, 119, 123, 127, 131,
                   135, 140, 144, 148, 153, 157, 162, 167, 171, 176, 181, 186, 191
                   )), class = "data.frame", row.names = c(NA, -19L)) xxxz
str(xxxz)
xxxz$Average20 <- by(xxxz[,c("Low20","High20")],xxxz[,"TotalInches"],mean)
warnings()

When I run the code above, I don't get the means by row. I get the following warning messages, one for each row of the dataframe.

Warning messages:
1: In mean.default(data[x, , drop = FALSE], ...) :
  argument is not numeric or logical: returning NA
2: In mean.default(data[x, , drop = FALSE], ...) :
  argument is not numeric or logical: returning NA

 Can someone tell my what I am doing wrong, and how I can compute the row means?

Thank you,
John

John David Sorkin M.D., Ph.D.
Professor of Medicine, University of Maryland School of Medicine; Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center; PI Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center; Senior Statistician University of Maryland Center for Vascular Research;

Division of Gerontology and Paliative Care,
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
Cell phone 443-418-5382



______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From v@|kremk @end|ng |rom gm@||@com  Sun Jun  9 22:39:19 2024
From: v@|kremk @end|ng |rom gm@||@com (Val)
Date: Sun, 9 Jun 2024 15:39:19 -0500
Subject: [R] Format
Message-ID: <CAJOiR6arjoEf27aW8u54so27Tx-PsYRvGvB1TAj8OiAwS9dB_A@mail.gmail.com>

HI all,

My
I am trying to convert character date (mm/dd/yy)  to YYYY-mm-dd date
format in one of the columns of my data file.

The first few lines of the data file looks like as follow

 head(Atest,10);dim(Atest)
      ddate
1  19/08/21
2  30/04/18
3  28/08/21
4  11/10/21
5  07/09/21
6  15/08/21
7  03/09/21
8  23/07/18
9  17/08/20
10 23/09/20
[1] 1270076       1

I am using the following different scenarios but none of them resulted
the desired result.

library(data.table)
library(stringr)
library(lubridate)
        Atest$ddate1 <- as.Date((Atest$ddate), format = "%m/%d/%y")
        Atest$ddate2 <- mdy((Atest$ddate))
        Atest$ddate3 <= as.Date(as.character(Atest$ddate),format="%m/%d/%y")
        Atest$ddate4 <- as.Date(as.character(Atest$ddate),"%m/%d/%y")
        Atest$ddate5 <- lubridate::mdy(Atest$ddate)

> head(Atest,3)
     ddate     ddate1 ddate2 ddate4 ddate5
1 19/08/21   <NA>   <NA>   <NA>   <NA>
2 30/04/18   <NA>   <NA>   <NA>   <NA>
3 28/08/21   <NA>   <NA>   <NA>   <NA>


Any help why I am not getting the desired result.
Thank you,


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Jun  9 22:45:26 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 9 Jun 2024 21:45:26 +0100
Subject: [R] Format
In-Reply-To: <CAJOiR6arjoEf27aW8u54so27Tx-PsYRvGvB1TAj8OiAwS9dB_A@mail.gmail.com>
References: <CAJOiR6arjoEf27aW8u54so27Tx-PsYRvGvB1TAj8OiAwS9dB_A@mail.gmail.com>
Message-ID: <e4e86e65-b628-4714-8d94-ae1a32e39f14@sapo.pt>

?s 21:39 de 09/06/2024, Val escreveu:
> HI all,
> 
> My
> I am trying to convert character date (mm/dd/yy)  to YYYY-mm-dd date
> format in one of the columns of my data file.
> 
> The first few lines of the data file looks like as follow
> 
>   head(Atest,10);dim(Atest)
>        ddate
> 1  19/08/21
> 2  30/04/18
> 3  28/08/21
> 4  11/10/21
> 5  07/09/21
> 6  15/08/21
> 7  03/09/21
> 8  23/07/18
> 9  17/08/20
> 10 23/09/20
> [1] 1270076       1
> 
> I am using the following different scenarios but none of them resulted
> the desired result.
> 
> library(data.table)
> library(stringr)
> library(lubridate)
>          Atest$ddate1 <- as.Date((Atest$ddate), format = "%m/%d/%y")
>          Atest$ddate2 <- mdy((Atest$ddate))
>          Atest$ddate3 <= as.Date(as.character(Atest$ddate),format="%m/%d/%y")
>          Atest$ddate4 <- as.Date(as.character(Atest$ddate),"%m/%d/%y")
>          Atest$ddate5 <- lubridate::mdy(Atest$ddate)
> 
>> head(Atest,3)
>       ddate     ddate1 ddate2 ddate4 ddate5
> 1 19/08/21   <NA>   <NA>   <NA>   <NA>
> 2 30/04/18   <NA>   <NA>   <NA>   <NA>
> 3 28/08/21   <NA>   <NA>   <NA>   <NA>
> 
> 
> Any help why I am not getting the desired result.
> Thank you,
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

Day is clearly first, format "%m/%d/%y" assumes a month 19 in 19/08/21.
Try

as.Date(Atest$ddate, format = "%d/%m/%y")


Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Jun  9 22:54:54 2024
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 9 Jun 2024 16:54:54 -0400
Subject: [R] Format
In-Reply-To: <CAJOiR6arjoEf27aW8u54so27Tx-PsYRvGvB1TAj8OiAwS9dB_A@mail.gmail.com>
References: <CAJOiR6arjoEf27aW8u54so27Tx-PsYRvGvB1TAj8OiAwS9dB_A@mail.gmail.com>
Message-ID: <3ac0b669-2c9e-4dc5-bcd8-2845e879bc77@gmail.com>

On 2024-06-09 4:39 p.m., Val wrote:
> HI all,
> 
> My
> I am trying to convert character date (mm/dd/yy)  to YYYY-mm-dd date
> format in one of the columns of my data file.
> 
> The first few lines of the data file looks like as follow
> 
>   head(Atest,10);dim(Atest)
>        ddate
> 1  19/08/21
> 2  30/04/18

Those aren't legal months in the first entry.  Your format looks like it 
should be "%d/%m/%y".

Duncan Murdoch


From er|cjberger @end|ng |rom gm@||@com  Mon Jun 10 10:02:25 2024
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Mon, 10 Jun 2024 11:02:25 +0300
Subject: [R] Format
In-Reply-To: <3ac0b669-2c9e-4dc5-bcd8-2845e879bc77@gmail.com>
References: <CAJOiR6arjoEf27aW8u54so27Tx-PsYRvGvB1TAj8OiAwS9dB_A@mail.gmail.com>
 <3ac0b669-2c9e-4dc5-bcd8-2845e879bc77@gmail.com>
Message-ID: <CAGgJW760FTEApEoK10cgC34UwS_Cax1xMvg0Qym7Mh3JgrDiMw@mail.gmail.com>

Since you are loading lubridate it is enough to do

Atest$ddate1 <- dmy(Atest$ddate)



On Sun, Jun 9, 2024 at 11:59?PM Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> On 2024-06-09 4:39 p.m., Val wrote:
> > HI all,
> >
> > My
> > I am trying to convert character date (mm/dd/yy)  to YYYY-mm-dd date
> > format in one of the columns of my data file.
> >
> > The first few lines of the data file looks like as follow
> >
> >   head(Atest,10);dim(Atest)
> >        ddate
> > 1  19/08/21
> > 2  30/04/18
>
> Those aren't legal months in the first entry.  Your format looks like it
> should be "%d/%m/%y".
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roy@mende|@@ohn @end|ng |rom no@@@gov  Tue Jun 11 15:32:53 2024
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Tue, 11 Jun 2024 06:32:53 -0700
Subject: [R] Fwd: Webinar: How to access ERDDAP data using R
References: <CAGtfGWShx9DQNjxLfNmHcHCdhbD=fgXz3Qo3B38MGC+zwrFcww@mail.gmail.com>
Message-ID: <65BC70C3-A27E-4411-8B1C-2EC28AE5810D@noaa.gov>



> 
>  	
>  
>  <https://goosocean.us15.list-manage.com/track/click?u=75c69bf185fb2be069850f6ee&id=fd7c35981e&e=3b244e9fac>
>  
> Note	 | 	June 2024
>  
>  
>  	
>  	
> Webinar announcement
>  
> How to access ERDDAP data using R
>  
>  
> 
>  
> 	 	20 June 2024 | 18:00 CEST
>  	See what time it is for you <https://goosocean.us15.list-manage.com/track/click?u=75c69bf185fb2be069850f6ee&id=dbf44ac3d6&e=3b244e9fac>
> 	 	Online
>  
> This seminar will demonstrating the use of ERDDAP? in R. Demonstrating the use of multiple ERDDAP? servers to pull together collocated datasets, extracting detailed metadata, and accessing ERDDAP? hosted data using R.
> 
> This webinar is a follow up from the webinar ?How to ERDDAP?? using python.
> 
> Future Seminars:
> July - Using ERDDAP to track usage metrics
> August - Abstracting across ERDDAP
> September - Writing Data into ERDDAP
> 
> Webinar registration <https://goosocean.us15.list-manage.com/track/click?u=75c69bf185fb2be069850f6ee&id=e9575a2093&e=3b244e9fac>
> Flyer <https://goosocean.us15.list-manage.com/track/click?u=75c69bf185fb2be069850f6ee&id=8717d0af8d&e=3b244e9fac>
> Access previous ERDDAP webinars here <https://goosocean.us15.list-manage.com/track/click?u=75c69bf185fb2be069850f6ee&id=e3b756ef29&e=3b244e9fac>.
>  	
>  
> Register
>  <https://goosocean.us15.list-manage.com/track/click?u=75c69bf185fb2be069850f6ee&id=f8b460fc54&e=3b244e9fac>
>  
>  
>  
>  
>  
>  	
> 
>  	
> 
>  	
> 
>  	
> 
>  
> The Global Ocean Observing System is sponsored by
> the Intergovernmental Oceanographic Commission of UNESCO,
> the World Meteorological Organization, the United Nations Environment 
> Programme, and the International Science Council.
> 
> Global Ocean Observing System 
> Intergovernmental Oceanographic Commission
> UNESCO
> 7 place de Fontenoy
> 75352 Paris 07-SP
> France
> 
> goos at unesco.org <mailto:goos at unesco.org>
> 
> For inquiries about the GOOS mailing list please contact 
> Laura Stukonyt? l.stukonyte at unesco.org <mailto:l.stukonyte at unesco.org>
>  
>  
> You are receiving this email because you are a member of the 
> Global Ocean Observing Community.
> 
> Unsubscribe <https://goosocean.us15.list-manage.com/unsubscribe?u=75c69bf185fb2be069850f6ee&id=7f482bccaa&t=b&e=3b244e9fac&c=e459de2052> ann-christine.zinkann at noaa.gov <mailto:ann-christine.zinkann at noaa.gov> from this list 
> Update subscription preferences <https://goosocean.us15.list-manage.com/profile?u=75c69bf185fb2be069850f6ee&id=7f482bccaa&e=3b244e9fac&c=e459de2052>
> View email in browser <https://mailchi.mp/goosocean/webinar-how-to-access-erddap-data-using-r?e=3b244e9fac>
> 
> ? 2024 Global Ocean Observing System. All rights reserved.
>  
>  
> 
> 
> 
> -- 
> 
> 
> 
> 
> Ann-Christine Zinkann, PhD (she/her)
> Program Manager
> National Oceanic and Atmospheric Administration <https://www.noaa.gov/>
> Global Ocean Monitoring & Observing Program <http://globalocean.noaa.gov/>
> and Cooperative Programs for the Advancement of Earth System Science <https://cpaess.ucar.edu/>, University Corporation for Atmospheric Research
> 803.904.8291 | ann-christine.zinkann at noaa.gov <mailto:email at noaa.gov>
**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


	[[alternative HTML version deleted]]


From m|ev|n@ @end|ng |rom purdue@edu  Tue Jun 11 20:44:08 2024
From: m|ev|n@ @end|ng |rom purdue@edu (Levine, Michael)
Date: Tue, 11 Jun 2024 18:44:08 +0000
Subject: [R] Integration of functions with a vector argument
Message-ID: <PH0PR22MB2860E3ABD206953D15F31EFAC5C72@PH0PR22MB2860.namprd22.prod.outlook.com>

Hello all,

I have a question concerning integration of a function of a multivariate argument with respect to one or more variables in r.  Let us say we have a function

F <- function(x){ body of the function}

Where x is, in general, a d by 1 vector with d>1.  Now I want to integrate out some of the coordinates of x, e.g. x[1] or x[2] or both of them etc. I'm well aware of how to integrate out e.g. y if a function is defined as f <- function (x,y) {body of the function} where y is a scalar.
However, it seems to be quite difficult to do the same if the function is defined with a vector argument x. At the very least, I haven't seen any good examples of this being done.
Any suggestions?

Yours sincerely,
Michael

Michael Levine
Associate Professor, Statistics

Department of Statistics
Purdue University
250 North University Street
West Lafayette, IN 47907 USA

email: mlevins at purdue.edu
Phone: +1-765-496-7571
Fax:   +1-765-494-0558
URL:   www.stat.purdue.edu/~mlevins

	[[alternative HTML version deleted]]


From |kry|ov @end|ng |rom d|@root@org  Wed Jun 12 12:41:19 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Wed, 12 Jun 2024 13:41:19 +0300
Subject: [R] Integration of functions with a vector argument
In-Reply-To: <PH0PR22MB2860E3ABD206953D15F31EFAC5C72@PH0PR22MB2860.namprd22.prod.outlook.com>
References: <PH0PR22MB2860E3ABD206953D15F31EFAC5C72@PH0PR22MB2860.namprd22.prod.outlook.com>
Message-ID: <20240612134119.72e4cab6@Tarkus>

? Tue, 11 Jun 2024 18:44:08 +0000
"Levine, Michael" <mlevins at purdue.edu> ?????:

> Let us say we have a function
> 
> F <- function(x){ body of the function}
> 
> Where x is, in general, a d by 1 vector with d>1.  Now I want to
> integrate out some of the coordinates of x, e.g. x[1] or x[2] or both
> of them etc. I'm well aware of how to integrate out e.g. y if a
> function is defined as f <- function (x,y) {body of the function}
> where y is a scalar.

The reason integrate() wants a separate function argument for the
integration coordinate is so that it could give the function a vector
of different values of the variable and receive a vector of the same
length containing the corresponding values of the function.

If the problem is small enough to make performance considerations
irrelevant, you can use Vectorize to make a function compatible with
integrate() from your function F:

x <- x0
z <- z0
Fiy <- Vectorize(function(y) F(c(x, y, z)))
integrate(Fiy, ymin, ymax)

The resulting function Fiy will accept a vector of values for y and
translate it into multiple calls to F with a three-element vector
argument as it expects.

Achieving better performance will require rewriting the function F to
be "vectorised", i.e. to accept vectors for arguments and return a
vector of the same length.

-- 
Best regards,
Ivan


From ycd|ng @end|ng |rom coh@org  Wed Jun 12 18:28:29 2024
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Wed, 12 Jun 2024 16:28:29 +0000
Subject: [R] my R code worked well when running the first 1000 lines of R
 code
In-Reply-To: <MN2PR02MB6911CD6439B0FAA8614FD204D4C02@MN2PR02MB6911.namprd02.prod.outlook.com>
References: <MN2PR02MB6911CD6439B0FAA8614FD204D4C02@MN2PR02MB6911.namprd02.prod.outlook.com>
Message-ID: <MN2PR02MB691189F9B5F75D42B81E2162D4C02@MN2PR02MB6911.namprd02.prod.outlook.com>

Hi R users,

The following code worked well to summarize four data groups in a dataframe for three variables (t_depth, t_alt_count, t_alt_ratio), 12 columns of summary, see attached.
However, after running another 2000 lines of R codes using functions from more than 10 other R  libraries, then it only generated one column of summary.
Do you know why?

Thank you,

Yuan Chun Ding

summary_anno1148ft <- anno1148ft %>%
  pivot_longer(c(t_depth, t_alt_count, t_alt_ratio), names_to = "measure") %>%
  group_by(dat, measure) %>%
  summarize(minimum = min(value,na.rm=T),
            q25 = quantile(value, probs = 0.25,na.rm=T),
            med = median(value,na.rm=T),
            q75 = quantile(value, probs = 0.75,na.rm=T),
            maximum = max(value,na.rm=T),
            average = mean(value,na.rm=T),
            #standard_deviation = sd(value),
            .groups = "drop"
  )
summary_anno1148ft <-t(summary_anno1148ft)



----------------------------------------------------------------------
------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-  

This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
------------------------------------------------------------

From bgunter@4567 @end|ng |rom gm@||@com  Wed Jun 12 19:49:13 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 12 Jun 2024 10:49:13 -0700
Subject: [R] 
 my R code worked well when running the first 1000 lines of R code
In-Reply-To: <MN2PR02MB691189F9B5F75D42B81E2162D4C02@MN2PR02MB6911.namprd02.prod.outlook.com>
References: <MN2PR02MB6911CD6439B0FAA8614FD204D4C02@MN2PR02MB6911.namprd02.prod.outlook.com>
 <MN2PR02MB691189F9B5F75D42B81E2162D4C02@MN2PR02MB6911.namprd02.prod.outlook.com>
Message-ID: <CAGxFJbQuZeozK-CAf2sARq-OAfP1YuTDHK3MhaK+MRa+Esf0+g@mail.gmail.com>

I am assuming from your message that *exactly* the same code you show was
rerun and yielded different results. If that be so, I doubt that this can
be answered without knowing what that other R code did -- and perhaps not
even then -- and/or whether any of that code changed your data frame.
Another guess is that one of those other R packages may have replaced the
summarize method you used with another (customized) method.

Hopefully, someone else may have more insight than I, though.

-- Bert

On Wed, Jun 12, 2024 at 9:28?AM Yuan Chun Ding via R-help <
r-help at r-project.org> wrote:

> Hi R users,
>
> The following code worked well to summarize four data groups in a
> dataframe for three variables (t_depth, t_alt_count, t_alt_ratio), 12
> columns of summary, see attached.
> However, after running another 2000 lines of R codes using functions from
> more than 10 other R  libraries, then it only generated one column of
> summary.
> Do you know why?
>
> Thank you,
>
> Yuan Chun Ding
>
> summary_anno1148ft <- anno1148ft %>%
>   pivot_longer(c(t_depth, t_alt_count, t_alt_ratio), names_to = "measure")
> %>%
>   group_by(dat, measure) %>%
>   summarize(minimum = min(value,na.rm=T),
>             q25 = quantile(value, probs = 0.25,na.rm=T),
>             med = median(value,na.rm=T),
>             q75 = quantile(value, probs = 0.75,na.rm=T),
>             maximum = max(value,na.rm=T),
>             average = mean(value,na.rm=T),
>             #standard_deviation = sd(value),
>             .groups = "drop"
>   )
> summary_anno1148ft <-t(summary_anno1148ft)
>
>
>
> ----------------------------------------------------------------------
> ------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
>
> This message and any attachments are intended solely for the individual or
> entity to which they are addressed. This communication may contain
> information that is privileged, confidential, or exempt from disclosure
> under applicable law (e.g., personal health information, research data,
> financial information). Because this e-mail has been sent without
> encryption, individuals other than the intended recipient may be able to
> view the information, forward it to others or tamper with the information
> without the knowledge or consent of the sender. If you are not the intended
> recipient, or the employee or person responsible for delivering the message
> to the intended recipient, any dissemination, distribution or copying of
> the communication is strictly prohibited. If you received the communication
> in error, please notify the sender immediately by replying to this message
> and deleting the message and any accompanying files from your system. If,
> due to the security risks, you do not wish to receive further
> communications via e-mail, please reply to this message and inform the
> sender that you do not wish to receive further e-mail from the sender.
> (LCP301)
> ------------------------------------------------------------
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tebert @end|ng |rom u||@edu  Wed Jun 12 19:51:15 2024
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Wed, 12 Jun 2024 17:51:15 +0000
Subject: [R] 
 my R code worked well when running the first 1000 lines of R code
In-Reply-To: <MN2PR02MB691189F9B5F75D42B81E2162D4C02@MN2PR02MB6911.namprd02.prod.outlook.com>
References: <MN2PR02MB6911CD6439B0FAA8614FD204D4C02@MN2PR02MB6911.namprd02.prod.outlook.com>
 <MN2PR02MB691189F9B5F75D42B81E2162D4C02@MN2PR02MB6911.namprd02.prod.outlook.com>
Message-ID: <CH3PR22MB4514F7E69519D18D94D7981DCFC02@CH3PR22MB4514.namprd22.prod.outlook.com>

Hi Yuan,
   When you load some packages do you get messages saying that some function is being masked? What can happen is that one package has a function with the same name as another package. The conflict is resolved by having one package mask the other. However, this can cause conflicts if your code uses the function in a way that is only supported in the masked package.

Tim

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Yuan Chun Ding via R-help
Sent: Wednesday, June 12, 2024 12:28 PM
To: r-help at R-project.org (r-help at r-project.org) <r-help at r-project.org>
Subject: [R] my R code worked well when running the first 1000 lines of R code

[External Email]

Hi R users,

The following code worked well to summarize four data groups in a dataframe for three variables (t_depth, t_alt_count, t_alt_ratio), 12 columns of summary, see attached.
However, after running another 2000 lines of R codes using functions from more than 10 other R  libraries, then it only generated one column of summary.
Do you know why?

Thank you,

Yuan Chun Ding

summary_anno1148ft <- anno1148ft %>%
  pivot_longer(c(t_depth, t_alt_count, t_alt_ratio), names_to = "measure") %>%
  group_by(dat, measure) %>%
  summarize(minimum = min(value,na.rm=T),
            q25 = quantile(value, probs = 0.25,na.rm=T),
            med = median(value,na.rm=T),
            q75 = quantile(value, probs = 0.75,na.rm=T),
            maximum = max(value,na.rm=T),
            average = mean(value,na.rm=T),
            #standard_deviation = sd(value),
            .groups = "drop"
  )
summary_anno1148ft <-t(summary_anno1148ft)



----------------------------------------------------------------------
------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-

This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
------------------------------------------------------------
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From po|c1410 @end|ng |rom gm@||@com  Wed Jun 12 19:52:27 2024
From: po|c1410 @end|ng |rom gm@||@com (CALUM POLWART)
Date: Wed, 12 Jun 2024 18:52:27 +0100
Subject: [R] 
 my R code worked well when running the first 1000 lines of R code
In-Reply-To: <MN2PR02MB691189F9B5F75D42B81E2162D4C02@MN2PR02MB6911.namprd02.prod.outlook.com>
References: <MN2PR02MB6911CD6439B0FAA8614FD204D4C02@MN2PR02MB6911.namprd02.prod.outlook.com>
 <MN2PR02MB691189F9B5F75D42B81E2162D4C02@MN2PR02MB6911.namprd02.prod.outlook.com>
Message-ID: <CA+etgPmKDa9Fn9DFVHmJyEBMiFF9JnkM27y1pwAvQ8N+nLEkTw@mail.gmail.com>

I sometimes think people on this list are quite rude to posters.

I'm afraid I'm likely to join in with some rudeness?

1. "Here is some code that works but also doesn't" is probably not going to
get you an answer
2. I provide no information about the data it works on or doesn't
3. I tell you I'm using a load of dependencies, but don't tell you what
4. I refer to 2000 lines of code but probably means 2000 lines of data?

So. Please post a question someone can actually answer.

If the question is "why might code fail on a 2000 line dataset when it
works on 1000 line dataset" then here are some thoughts:

* Is the 1000 lines being run as dataset[1:1000,] or is it dataset1 and
dataset2 ?
* Is there a structural difference in the datasets - i.e. numbers,
characters or factors as columns. Often import functions guess a column
type by reading the first 500/1000 lines. If the data has numbers in column
1 for 1-1000 but on line 1999 has a letter... The data type may vary.

On Wed, 12 Jun 2024, 17:28 Yuan Chun Ding via R-help, <r-help at r-project.org>
wrote:

> Hi R users,
>
> The following code worked well to summarize four data groups in a
> dataframe for three variables (t_depth, t_alt_count, t_alt_ratio), 12
> columns of summary, see attached.
> However, after running another 2000 lines of R codes using functions from
> more than 10 other R  libraries, then it only generated one column of
> summary.
> Do you know why?
>
> Thank you,
>
> Yuan Chun Ding
>
> summary_anno1148ft <- anno1148ft %>%
>   pivot_longer(c(t_depth, t_alt_count, t_alt_ratio), names_to = "measure")
> %>%
>   group_by(dat, measure) %>%
>   summarize(minimum = min(value,na.rm=T),
>             q25 = quantile(value, probs = 0.25,na.rm=T),
>             med = median(value,na.rm=T),
>             q75 = quantile(value, probs = 0.75,na.rm=T),
>             maximum = max(value,na.rm=T),
>             average = mean(value,na.rm=T),
>             #standard_deviation = sd(value),
>             .groups = "drop"
>   )
> summary_anno1148ft <-t(summary_anno1148ft)
>
>
>
> ----------------------------------------------------------------------
> ------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
>
> This message and any attachments are intended solely for the individual or
> entity to which they are addressed. This communication may contain
> information that is privileged, confidential, or exempt from disclosure
> under applicable law (e.g., personal health information, research data,
> financial information). Because this e-mail has been sent without
> encryption, individuals other than the intended recipient may be able to
> view the information, forward it to others or tamper with the information
> without the knowledge or consent of the sender. If you are not the intended
> recipient, or the employee or person responsible for delivering the message
> to the intended recipient, any dissemination, distribution or copying of
> the communication is strictly prohibited. If you received the communication
> in error, please notify the sender immediately by replying to this message
> and deleting the message and any accompanying files from your system. If,
> due to the security risks, you do not wish to receive further
> communications via e-mail, please reply to this message and inform the
> sender that you do not wish to receive further e-mail from the sender.
> (LCP301)
> ------------------------------------------------------------
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ycd|ng @end|ng |rom coh@org  Wed Jun 12 20:03:25 2024
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Wed, 12 Jun 2024 18:03:25 +0000
Subject: [R] 
 my R code worked well when running the first 1000 lines of R code
In-Reply-To: <CA+etgPmKDa9Fn9DFVHmJyEBMiFF9JnkM27y1pwAvQ8N+nLEkTw@mail.gmail.com>
References: <MN2PR02MB6911CD6439B0FAA8614FD204D4C02@MN2PR02MB6911.namprd02.prod.outlook.com>
 <MN2PR02MB691189F9B5F75D42B81E2162D4C02@MN2PR02MB6911.namprd02.prod.outlook.com>
 <CA+etgPmKDa9Fn9DFVHmJyEBMiFF9JnkM27y1pwAvQ8N+nLEkTw@mail.gmail.com>
Message-ID: <MN2PR02MB6911C2E5109A13CF47B39B7AD4C02@MN2PR02MB6911.namprd02.prod.outlook.com>

I am sorry that I know I should provide a dataset that allows to replicate my problem.

It is a research dataset and quite large, so I can not share.

Both Bert and Tim guessed my problem correctly.  I also thought about the conflicting issue between different packages and function masking.
I just hope to that someone has similar experience, so providing me suggestion.

For conflicting issue,

What I tried  was to add dplyr::pivot_longer or tidyr:: pivot_longer, but still not resolved the problem.



I will restart from the first line my code, it will work again and then I will track down.



Thank you,

Ding


From: CALUM POLWART <polc1410 at gmail.com>
Sent: Wednesday, June 12, 2024 10:52 AM
To: Yuan Chun Ding <ycding at coh.org>
Cc: r-help at r-project.org
Subject: Re: [R] my R code worked well when running the first 1000 lines of R code

I sometimes think people on this list are quite rude to posters. I'm afraid I'm likely to join in with some rudeness? 1. "Here is some code that works but also doesn't" is probably not going to get you an answer 2. I provide


I sometimes think people on this list are quite rude to posters.

I'm afraid I'm likely to join in with some rudeness?

1. "Here is some code that works but also doesn't" is probably not going to get you an answer
2. I provide no information about the data it works on or doesn't
3. I tell you I'm using a load of dependencies, but don't tell you what
4. I refer to 2000 lines of code but probably means 2000 lines of data?

So. Please post a question someone can actually answer.

If the question is "why might code fail on a 2000 line dataset when it works on 1000 line dataset" then here are some thoughts:

* Is the 1000 lines being run as dataset[1:1000,] or is it dataset1 and dataset2 ?
* Is there a structural difference in the datasets - i.e. numbers, characters or factors as columns. Often import functions guess a column type by reading the first 500/1000 lines. If the data has numbers in column 1 for 1-1000 but on line 1999 has a letter... The data type may vary.

On Wed, 12 Jun 2024, 17:28 Yuan Chun Ding via R-help, <r-help at r-project.org<mailto:r-help at r-project.org>> wrote:
Hi R users,

The following code worked well to summarize four data groups in a dataframe for three variables (t_depth, t_alt_count, t_alt_ratio), 12 columns of summary, see attached.
However, after running another 2000 lines of R codes using functions from more than 10 other R  libraries, then it only generated one column of summary.
Do you know why?

Thank you,

Yuan Chun Ding

summary_anno1148ft <- anno1148ft %>%
  pivot_longer(c(t_depth, t_alt_count, t_alt_ratio), names_to = "measure") %>%
  group_by(dat, measure) %>%
  summarize(minimum = min(value,na.rm=T),
            q25 = quantile(value, probs = 0.25,na.rm=T),
            med = median(value,na.rm=T),
            q75 = quantile(value, probs = 0.75,na.rm=T),
            maximum = max(value,na.rm=T),
            average = mean(value,na.rm=T),
            #standard_deviation = sd(value),
            .groups = "drop"
  )
summary_anno1148ft <-t(summary_anno1148ft)



----------------------------------------------------------------------
------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-

This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
------------------------------------------------------------
______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!p3fE1cCl7_IxAOT0Fvr1vPWF3xDeYl1FCDaqXi4Z6HH7tOMmDULawS8DAa7XcG5s5PrfqmeMC0XA$>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!p3fE1cCl7_IxAOT0Fvr1vPWF3xDeYl1FCDaqXi4Z6HH7tOMmDULawS8DAa7XcG5s5Prfqhxs3su7$>
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Jun 12 20:29:19 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 12 Jun 2024 19:29:19 +0100
Subject: [R] 
 my R code worked well when running the first 1000 lines of R code
In-Reply-To: <MN2PR02MB6911C2E5109A13CF47B39B7AD4C02@MN2PR02MB6911.namprd02.prod.outlook.com>
References: <MN2PR02MB6911CD6439B0FAA8614FD204D4C02@MN2PR02MB6911.namprd02.prod.outlook.com>
 <MN2PR02MB691189F9B5F75D42B81E2162D4C02@MN2PR02MB6911.namprd02.prod.outlook.com>
 <CA+etgPmKDa9Fn9DFVHmJyEBMiFF9JnkM27y1pwAvQ8N+nLEkTw@mail.gmail.com>
 <MN2PR02MB6911C2E5109A13CF47B39B7AD4C02@MN2PR02MB6911.namprd02.prod.outlook.com>
Message-ID: <a546c235-40f0-423a-b31e-35189ac3436a@sapo.pt>

Hello,

Inline.

?s 19:03 de 12/06/2024, Yuan Chun Ding via R-help escreveu:
> I am sorry that I know I should provide a dataset that allows to replicate my problem.
> 
> It is a research dataset and quite large, so I can not share.
> 
> Both Bert and Tim guessed my problem correctly.  I also thought about the conflicting issue between different packages and function masking.
> I just hope to that someone has similar experience, so providing me suggestion.
> 
> For conflicting issue,
> 
> What I tried  was to add dplyr::pivot_longer or tidyr:: pivot_longer, 


Do that to all functions comming from contributed packages. At least to 
those.


summary_anno1148ft <- anno1148ft %>%
   tidyr::pivot_longer(c(t_depth, t_alt_count, t_alt_ratio), names_to = 
"measure") %>%
   dplyr::group_by(dat, measure) %>%
   dplyr::summarize(minimum = min(value,na.rm=T),
                    q25 = quantile(value, probs = 0.25,na.rm=T),
                    med = median(value,na.rm=T),
                    q75 = quantile(value, probs = 0.75,na.rm=T),
                    maximum = max(value,na.rm=T),
                    average = mean(value,na.rm=T),
                    #standard_deviation = sd(value),
                    .groups = "drop"
   )


Or, simpler, no need to group_by anymore. It can be done in summarise.


summary_anno1148ft <- anno1148ft %>%
   tidyr::pivot_longer(c(t_depth, t_alt_count, t_alt_ratio), names_to = 
"measure") %>%
   dplyr::summarize(minimum = min(value,na.rm=T),
                    q25 = quantile(value, probs = 0.25,na.rm=T),
                    med = median(value,na.rm=T),
                    q75 = quantile(value, probs = 0.75,na.rm=T),
                    maximum = max(value,na.rm=T),
                    average = mean(value,na.rm=T),
                    #standard_deviation = sd(value),
                    .by = c(dat, measure),
                    .groups = "drop"
   )



This is only a guess, the question cannot really be answered.


Hope this helps,

Rui Barradas

but still not resolved the problem.
> 
> 
> 
> I will restart from the first line my code, it will work again and then I will track down.
> 
> 
> 
> Thank you,
> 
> Ding
> 
> 
> From: CALUM POLWART <polc1410 at gmail.com>
> Sent: Wednesday, June 12, 2024 10:52 AM
> To: Yuan Chun Ding <ycding at coh.org>
> Cc: r-help at r-project.org
> Subject: Re: [R] my R code worked well when running the first 1000 lines of R code
> 
> I sometimes think people on this list are quite rude to posters. I'm afraid I'm likely to join in with some rudeness? 1. "Here is some code that works but also doesn't" is probably not going to get you an answer 2. I provide
> 
> 
> I sometimes think people on this list are quite rude to posters.
> 
> I'm afraid I'm likely to join in with some rudeness?
> 
> 1. "Here is some code that works but also doesn't" is probably not going to get you an answer
> 2. I provide no information about the data it works on or doesn't
> 3. I tell you I'm using a load of dependencies, but don't tell you what
> 4. I refer to 2000 lines of code but probably means 2000 lines of data?
> 
> So. Please post a question someone can actually answer.
> 
> If the question is "why might code fail on a 2000 line dataset when it works on 1000 line dataset" then here are some thoughts:
> 
> * Is the 1000 lines being run as dataset[1:1000,] or is it dataset1 and dataset2 ?
> * Is there a structural difference in the datasets - i.e. numbers, characters or factors as columns. Often import functions guess a column type by reading the first 500/1000 lines. If the data has numbers in column 1 for 1-1000 but on line 1999 has a letter... The data type may vary.
> 
> On Wed, 12 Jun 2024, 17:28 Yuan Chun Ding via R-help, <r-help at r-project.org<mailto:r-help at r-project.org>> wrote:
> Hi R users,
> 
> The following code worked well to summarize four data groups in a dataframe for three variables (t_depth, t_alt_count, t_alt_ratio), 12 columns of summary, see attached.
> However, after running another 2000 lines of R codes using functions from more than 10 other R  libraries, then it only generated one column of summary.
> Do you know why?
> 
> Thank you,
> 
> Yuan Chun Ding
> 
> summary_anno1148ft <- anno1148ft %>%
>    pivot_longer(c(t_depth, t_alt_count, t_alt_ratio), names_to = "measure") %>%
>    group_by(dat, measure) %>%
>    summarize(minimum = min(value,na.rm=T),
>              q25 = quantile(value, probs = 0.25,na.rm=T),
>              med = median(value,na.rm=T),
>              q75 = quantile(value, probs = 0.75,na.rm=T),
>              maximum = max(value,na.rm=T),
>              average = mean(value,na.rm=T),
>              #standard_deviation = sd(value),
>              .groups = "drop"
>    )
> summary_anno1148ft <-t(summary_anno1148ft)
> 
> 
> 
> ----------------------------------------------------------------------
> ------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
> 
> This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to rec
>   eive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
> ------------------------------------------------------------
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!p3fE1cCl7_IxAOT0Fvr1vPWF3xDeYl1FCDaqXi4Z6HH7tOMmDULawS8DAa7XcG5s5PrfqmeMC0XA$>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!p3fE1cCl7_IxAOT0Fvr1vPWF3xDeYl1FCDaqXi4Z6HH7tOMmDULawS8DAa7XcG5s5Prfqhxs3su7$>
> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com

From ycd|ng @end|ng |rom coh@org  Wed Jun 12 21:44:42 2024
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Wed, 12 Jun 2024 19:44:42 +0000
Subject: [R] 
 my R code worked well when running the first 1000 lines of R code
In-Reply-To: <a546c235-40f0-423a-b31e-35189ac3436a@sapo.pt>
References: <MN2PR02MB6911CD6439B0FAA8614FD204D4C02@MN2PR02MB6911.namprd02.prod.outlook.com>
 <MN2PR02MB691189F9B5F75D42B81E2162D4C02@MN2PR02MB6911.namprd02.prod.outlook.com>
 <CA+etgPmKDa9Fn9DFVHmJyEBMiFF9JnkM27y1pwAvQ8N+nLEkTw@mail.gmail.com>
 <MN2PR02MB6911C2E5109A13CF47B39B7AD4C02@MN2PR02MB6911.namprd02.prod.outlook.com>
 <a546c235-40f0-423a-b31e-35189ac3436a@sapo.pt>
Message-ID: <MN2PR02MB6911011387ED3D5FEFE1FA40D4C02@MN2PR02MB6911.namprd02.prod.outlook.com>

Hi Rui,

Thank you very much!


Yes, I verified using real data, it worked correctly as expected after adding tidyr:: to the pivot_longer function and dplyr:: to the group_by and summarize
Function.

I did not know how to assign the tidyr and dplyr to the three functions because I do not really understand well the three functions and just got the code from a google search.

I also tried your simplified code, but got the following error
Error in `dplyr::summarize()`:
! Can't supply both `.by` and `.groups`.
Run `rlang::last_trace()` to see where the error occurred.

Ding

From: Rui Barradas <ruipbarradas at sapo.pt>
Sent: Wednesday, June 12, 2024 11:29 AM
To: Yuan Chun Ding <ycding at coh.org>; CALUM POLWART <polc1410 at gmail.com>
Cc: r-help at r-project.org
Subject: Re: [R] my R code worked well when running the first 1000 lines of R code

Hello, Inline. ?s 19:?03 de 12/06/2024, Yuan Chun Ding via R-help escreveu: > I am sorry that I know I should provide a dataset that allows to replicate my problem. > > It is a research dataset and quite large, so I can not share. >


Hello,



Inline.



?s 19:03 de 12/06/2024, Yuan Chun Ding via R-help escreveu:

> I am sorry that I know I should provide a dataset that allows to replicate my problem.

>

> It is a research dataset and quite large, so I can not share.

>

> Both Bert and Tim guessed my problem correctly.  I also thought about the conflicting issue between different packages and function masking.

> I just hope to that someone has similar experience, so providing me suggestion.

>

> For conflicting issue,

>

> What I tried  was to add dplyr::pivot_longer or tidyr:: pivot_longer,





Do that to all functions comming from contributed packages. At least to

those.





summary_anno1148ft <- anno1148ft %>%

   tidyr::pivot_longer(c(t_depth, t_alt_count, t_alt_ratio), names_to =

"measure") %>%

   dplyr::group_by(dat, measure) %>%

   dplyr::summarize(minimum = min(value,na.rm=T),

                    q25 = quantile(value, probs = 0.25,na.rm=T),

                    med = median(value,na.rm=T),

                    q75 = quantile(value, probs = 0.75,na.rm=T),

                    maximum = max(value,na.rm=T),

                    average = mean(value,na.rm=T),

                    #standard_deviation = sd(value),

                    .groups = "drop"

   )





Or, simpler, no need to group_by anymore. It can be done in summarise.





summary_anno1148ft <- anno1148ft %>%

   tidyr::pivot_longer(c(t_depth, t_alt_count, t_alt_ratio), names_to =

"measure") %>%

   dplyr::summarize(minimum = min(value,na.rm=T),

                    q25 = quantile(value, probs = 0.25,na.rm=T),

                    med = median(value,na.rm=T),

                    q75 = quantile(value, probs = 0.75,na.rm=T),

                    maximum = max(value,na.rm=T),

                    average = mean(value,na.rm=T),

                    #standard_deviation = sd(value),

                    .by = c(dat, measure),

                    .groups = "drop"

   )







This is only a guess, the question cannot really be answered.





Hope this helps,



Rui Barradas



but still not resolved the problem.

>

>

>

> I will restart from the first line my code, it will work again and then I will track down.

>

>

>

> Thank you,

>

> Ding

>

>

> From: CALUM POLWART <polc1410 at gmail.com<mailto:polc1410 at gmail.com>>

> Sent: Wednesday, June 12, 2024 10:52 AM

> To: Yuan Chun Ding <ycding at coh.org<mailto:ycding at coh.org>>

> Cc: r-help at r-project.org<mailto:r-help at r-project.org>

> Subject: Re: [R] my R code worked well when running the first 1000 lines of R code

>

> I sometimes think people on this list are quite rude to posters. I'm afraid I'm likely to join in with some rudeness? 1. "Here is some code that works but also doesn't" is probably not going to get you an answer 2. I provide

>

>

> I sometimes think people on this list are quite rude to posters.

>

> I'm afraid I'm likely to join in with some rudeness?

>

> 1. "Here is some code that works but also doesn't" is probably not going to get you an answer

> 2. I provide no information about the data it works on or doesn't

> 3. I tell you I'm using a load of dependencies, but don't tell you what

> 4. I refer to 2000 lines of code but probably means 2000 lines of data?

>

> So. Please post a question someone can actually answer.

>

> If the question is "why might code fail on a 2000 line dataset when it works on 1000 line dataset" then here are some thoughts:

>

> * Is the 1000 lines being run as dataset[1:1000,] or is it dataset1 and dataset2 ?

> * Is there a structural difference in the datasets - i.e. numbers, characters or factors as columns. Often import functions guess a column type by reading the first 500/1000 lines. If the data has numbers in column 1 for 1-1000 but on line 1999 has a letter... The data type may vary.

>

> On Wed, 12 Jun 2024, 17:28 Yuan Chun Ding via R-help, <r-help at r-project.org<mailto:r-help at r-project.org<mailto:r-help at r-project.org%3cmailto:r-help at r-project.org>>> wrote:

> Hi R users,

>

> The following code worked well to summarize four data groups in a dataframe for three variables (t_depth, t_alt_count, t_alt_ratio), 12 columns of summary, see attached.

> However, after running another 2000 lines of R codes using functions from more than 10 other R  libraries, then it only generated one column of summary.

> Do you know why?

>

> Thank you,

>

> Yuan Chun Ding

>

> summary_anno1148ft <- anno1148ft %>%

>    pivot_longer(c(t_depth, t_alt_count, t_alt_ratio), names_to = "measure") %>%

>    group_by(dat, measure) %>%

>    summarize(minimum = min(value,na.rm=T),

>              q25 = quantile(value, probs = 0.25,na.rm=T),

>              med = median(value,na.rm=T),

>              q75 = quantile(value, probs = 0.75,na.rm=T),

>              maximum = max(value,na.rm=T),

>              average = mean(value,na.rm=T),

>              #standard_deviation = sd(value),

>              .groups = "drop"

>    )

> summary_anno1148ft <-t(summary_anno1148ft)

>

>

>

> ----------------------------------------------------------------------

> ------------------------------------------------------------

> -SECURITY/CONFIDENTIALITY WARNING-

>

> This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to rec

>   eive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)

> ------------------------------------------------------------

> ______________________________________________

> R-help at r-project.org<mailto:R-help at r-project.org<mailto:R-help at r-project.org%3cmailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and more, see

> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!qBSbNdG-bXB3-5NwyJJVkk858HEh8_gmTcZHf_3vfKCIqyMknkkQfhlzNv_fE08UMpxyjkKoih96oo-fbT4$<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!qBSbNdG-bXB3-5NwyJJVkk858HEh8_gmTcZHf_3vfKCIqyMknkkQfhlzNv_fE08UMpxyjkKoih96oo-fbT4$><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!p3fE1cCl7_IxAOT0Fvr1vPWF3xDeYl1FCDaqXi4Z6HH7tOMmDULawS8DAa7XcG5s5PrfqmeMC0XA$><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!p3fE1cCl7_IxAOT0Fvr1vPWF3xDeYl1FCDaqXi4Z6HH7tOMmDULawS8DAa7XcG5s5PrfqmeMC0XA$%3e%3e>

><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!p3fE1cCl7_IxAOT0Fvr1vPWF3xDeYl1FCDaqXi4Z6HH7tOMmDULawS8DAa7XcG5s5PrfqmeMC0XA$%3e%3e>PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!qBSbNdG-bXB3-5NwyJJVkk858HEh8_gmTcZHf_3vfKCIqyMknkkQfhlzNv_fE08UMpxyjkKoih96vULyBu0$<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!qBSbNdG-bXB3-5NwyJJVkk858HEh8_gmTcZHf_3vfKCIqyMknkkQfhlzNv_fE08UMpxyjkKoih96vULyBu0$><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!p3fE1cCl7_IxAOT0Fvr1vPWF3xDeYl1FCDaqXi4Z6HH7tOMmDULawS8DAa7XcG5s5Prfqhxs3su7$><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!p3fE1cCl7_IxAOT0Fvr1vPWF3xDeYl1FCDaqXi4Z6HH7tOMmDULawS8DAa7XcG5s5Prfqhxs3su7$%3e%3e>

><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!p3fE1cCl7_IxAOT0Fvr1vPWF3xDeYl1FCDaqXi4Z6HH7tOMmDULawS8DAa7XcG5s5Prfqhxs3su7$%3e%3e>and provide commented, minimal, self-contained, reproducible code.

>

>             [[alternative HTML version deleted]]

>

> ______________________________________________

> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see

> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!qBSbNdG-bXB3-5NwyJJVkk858HEh8_gmTcZHf_3vfKCIqyMknkkQfhlzNv_fE08UMpxyjkKoih96oo-fbT4$<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!qBSbNdG-bXB3-5NwyJJVkk858HEh8_gmTcZHf_3vfKCIqyMknkkQfhlzNv_fE08UMpxyjkKoih96oo-fbT4$>

> PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!qBSbNdG-bXB3-5NwyJJVkk858HEh8_gmTcZHf_3vfKCIqyMknkkQfhlzNv_fE08UMpxyjkKoih96vULyBu0$<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!qBSbNdG-bXB3-5NwyJJVkk858HEh8_gmTcZHf_3vfKCIqyMknkkQfhlzNv_fE08UMpxyjkKoih96vULyBu0$>

> and provide commented, minimal, self-contained, reproducible code.







--

Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.

https://urldefense.com/v3/__http://www.avg.com__;!!Fou38LsQmgU!qBSbNdG-bXB3-5NwyJJVkk858HEh8_gmTcZHf_3vfKCIqyMknkkQfhlzNv_fE08UMpxyjkKoih96HZLrJxM$<https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!qBSbNdG-bXB3-5NwyJJVkk858HEh8_gmTcZHf_3vfKCIqyMknkkQfhlzNv_fE08UMpxyjkKoih96HZLrJxM$>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Jun 12 23:05:28 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 12 Jun 2024 22:05:28 +0100
Subject: [R] 
 my R code worked well when running the first 1000 lines of R code
In-Reply-To: <MN2PR02MB6911011387ED3D5FEFE1FA40D4C02@MN2PR02MB6911.namprd02.prod.outlook.com>
References: <MN2PR02MB6911CD6439B0FAA8614FD204D4C02@MN2PR02MB6911.namprd02.prod.outlook.com>
 <MN2PR02MB691189F9B5F75D42B81E2162D4C02@MN2PR02MB6911.namprd02.prod.outlook.com>
 <CA+etgPmKDa9Fn9DFVHmJyEBMiFF9JnkM27y1pwAvQ8N+nLEkTw@mail.gmail.com>
 <MN2PR02MB6911C2E5109A13CF47B39B7AD4C02@MN2PR02MB6911.namprd02.prod.outlook.com>
 <a546c235-40f0-423a-b31e-35189ac3436a@sapo.pt>
 <MN2PR02MB6911011387ED3D5FEFE1FA40D4C02@MN2PR02MB6911.namprd02.prod.outlook.com>
Message-ID: <3c450436-237c-44b7-ae8f-b6a21dead3b6@sapo.pt>

?s 20:44 de 12/06/2024, Yuan Chun Ding escreveu:
> Hi Rui,
> 
> Thank you very much!
> 
> 
> Yes, I verified using real data, it worked correctly as expected after adding tidyr:: to the pivot_longer function and dplyr:: to the group_by and summarize
> Function.
> 
> I did not know how to assign the tidyr and dplyr to the three functions because I do not really understand well the three functions and just got the code from a google search.
> 
> I also tried your simplified code, but got the following error
> Error in `dplyr::summarize()`:
> ! Can't supply both `.by` and `.groups`.
> Run `rlang::last_trace()` to see where the error occurred.
> 
> Ding
> 
> From: Rui Barradas <ruipbarradas at sapo.pt>
> Sent: Wednesday, June 12, 2024 11:29 AM
> To: Yuan Chun Ding <ycding at coh.org>; CALUM POLWART <polc1410 at gmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] my R code worked well when running the first 1000 lines of R code
> 
> Hello, Inline. ?s 19:?03 de 12/06/2024, Yuan Chun Ding via R-help escreveu: > I am sorry that I know I should provide a dataset that allows to replicate my problem. > > It is a research dataset and quite large, so I can not share. >
> 
> 
> Hello,
> 
> 
> 
> Inline.
> 
> 
> 
> ?s 19:03 de 12/06/2024, Yuan Chun Ding via R-help escreveu:
> 
>> I am sorry that I know I should provide a dataset that allows to replicate my problem.
> 
>>
> 
>> It is a research dataset and quite large, so I can not share.
> 
>>
> 
>> Both Bert and Tim guessed my problem correctly.  I also thought about the conflicting issue between different packages and function masking.
> 
>> I just hope to that someone has similar experience, so providing me suggestion.
> 
>>
> 
>> For conflicting issue,
> 
>>
> 
>> What I tried  was to add dplyr::pivot_longer or tidyr:: pivot_longer,
> 
> 
> 
> 
> 
> Do that to all functions comming from contributed packages. At least to
> 
> those.
> 
> 
> 
> 
> 
> summary_anno1148ft <- anno1148ft %>%
> 
>     tidyr::pivot_longer(c(t_depth, t_alt_count, t_alt_ratio), names_to =
> 
> "measure") %>%
> 
>     dplyr::group_by(dat, measure) %>%
> 
>     dplyr::summarize(minimum = min(value,na.rm=T),
> 
>                      q25 = quantile(value, probs = 0.25,na.rm=T),
> 
>                      med = median(value,na.rm=T),
> 
>                      q75 = quantile(value, probs = 0.75,na.rm=T),
> 
>                      maximum = max(value,na.rm=T),
> 
>                      average = mean(value,na.rm=T),
> 
>                      #standard_deviation = sd(value),
> 
>                      .groups = "drop"
> 
>     )
> 
> 
> 
> 
> 
> Or, simpler, no need to group_by anymore. It can be done in summarise.
> 
> 
> 
> 
> 
> summary_anno1148ft <- anno1148ft %>%
> 
>     tidyr::pivot_longer(c(t_depth, t_alt_count, t_alt_ratio), names_to =
> 
> "measure") %>%
> 
>     dplyr::summarize(minimum = min(value,na.rm=T),
> 
>                      q25 = quantile(value, probs = 0.25,na.rm=T),
> 
>                      med = median(value,na.rm=T),
> 
>                      q75 = quantile(value, probs = 0.75,na.rm=T),
> 
>                      maximum = max(value,na.rm=T),
> 
>                      average = mean(value,na.rm=T),
> 
>                      #standard_deviation = sd(value),
> 
>                      .by = c(dat, measure),
> 
>                      .groups = "drop"
> 
>     )
> 
> 
> 
> 
> 
> 
> 
> This is only a guess, the question cannot really be answered.
> 
> 
> 
> 
> 
> Hope this helps,
> 
> 
> 
> Rui Barradas
> 
> 
> 
> but still not resolved the problem.
> 
>>
> 
>>
> 
>>
> 
>> I will restart from the first line my code, it will work again and then I will track down.
> 
>>
> 
>>
> 
>>
> 
>> Thank you,
> 
>>
> 
>> Ding
> 
>>
> 
>>
> 
>> From: CALUM POLWART <polc1410 at gmail.com<mailto:polc1410 at gmail.com>>
> 
>> Sent: Wednesday, June 12, 2024 10:52 AM
> 
>> To: Yuan Chun Ding <ycding at coh.org<mailto:ycding at coh.org>>
> 
>> Cc: r-help at r-project.org<mailto:r-help at r-project.org>
> 
>> Subject: Re: [R] my R code worked well when running the first 1000 lines of R code
> 
>>
> 
>> I sometimes think people on this list are quite rude to posters. I'm afraid I'm likely to join in with some rudeness? 1. "Here is some code that works but also doesn't" is probably not going to get you an answer 2. I provide
> 
>>
> 
>>
> 
>> I sometimes think people on this list are quite rude to posters.
> 
>>
> 
>> I'm afraid I'm likely to join in with some rudeness?
> 
>>
> 
>> 1. "Here is some code that works but also doesn't" is probably not going to get you an answer
> 
>> 2. I provide no information about the data it works on or doesn't
> 
>> 3. I tell you I'm using a load of dependencies, but don't tell you what
> 
>> 4. I refer to 2000 lines of code but probably means 2000 lines of data?
> 
>>
> 
>> So. Please post a question someone can actually answer.
> 
>>
> 
>> If the question is "why might code fail on a 2000 line dataset when it works on 1000 line dataset" then here are some thoughts:
> 
>>
> 
>> * Is the 1000 lines being run as dataset[1:1000,] or is it dataset1 and dataset2 ?
> 
>> * Is there a structural difference in the datasets - i.e. numbers, characters or factors as columns. Often import functions guess a column type by reading the first 500/1000 lines. If the data has numbers in column 1 for 1-1000 but on line 1999 has a letter... The data type may vary.
> 
>>
> 
>> On Wed, 12 Jun 2024, 17:28 Yuan Chun Ding via R-help, <r-help at r-project.org<mailto:r-help at r-project.org<mailto:r-help at r-project.org%3cmailto:r-help at r-project.org>>> wrote:
> 
>> Hi R users,
> 
>>
> 
>> The following code worked well to summarize four data groups in a dataframe for three variables (t_depth, t_alt_count, t_alt_ratio), 12 columns of summary, see attached.
> 
>> However, after running another 2000 lines of R codes using functions from more than 10 other R  libraries, then it only generated one column of summary.
> 
>> Do you know why?
> 
>>
> 
>> Thank you,
> 
>>
> 
>> Yuan Chun Ding
> 
>>
> 
>> summary_anno1148ft <- anno1148ft %>%
> 
>>     pivot_longer(c(t_depth, t_alt_count, t_alt_ratio), names_to = "measure") %>%
> 
>>     group_by(dat, measure) %>%
> 
>>     summarize(minimum = min(value,na.rm=T),
> 
>>               q25 = quantile(value, probs = 0.25,na.rm=T),
> 
>>               med = median(value,na.rm=T),
> 
>>               q75 = quantile(value, probs = 0.75,na.rm=T),
> 
>>               maximum = max(value,na.rm=T),
> 
>>               average = mean(value,na.rm=T),
> 
>>               #standard_deviation = sd(value),
> 
>>               .groups = "drop"
> 
>>     )
> 
>> summary_anno1148ft <-t(summary_anno1148ft)
> 
>>
> 
>>
> 
>>
> 
>> ----------------------------------------------------------------------
> 
>> ------------------------------------------------------------
> 
>> -SECURITY/CONFIDENTIALITY WARNING-
> 
>>
> 
>> This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to rec
> 
>>    eive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
> 
>> ------------------------------------------------------------
> 
>> ______________________________________________
> 
>> R-help at r-project.org<mailto:R-help at r-project.org<mailto:R-help at r-project.org%3cmailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and more, see
> 
>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!qBSbNdG-bXB3-5NwyJJVkk858HEh8_gmTcZHf_3vfKCIqyMknkkQfhlzNv_fE08UMpxyjkKoih96oo-fbT4$<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!qBSbNdG-bXB3-5NwyJJVkk858HEh8_gmTcZHf_3vfKCIqyMknkkQfhlzNv_fE08UMpxyjkKoih96oo-fbT4$><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!p3fE1cCl7_IxAOT0Fvr1vPWF3xDeYl1FCDaqXi4Z6HH7tOMmDULawS8DAa7XcG5s5PrfqmeMC0XA$><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!p3fE1cCl7_IxAOT0Fvr1vPWF3xDeYl1FCDaqXi4Z6HH7tOMmDULawS8DAa7XcG5s5PrfqmeMC0XA$%3e%3e>
> 
>> <https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!p3fE1cCl7_IxAOT0Fvr1vPWF3xDeYl1FCDaqXi4Z6HH7tOMmDULawS8DAa7XcG5s5PrfqmeMC0XA$%3e%3e>PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!qBSbNdG-bXB3-5NwyJJVkk858HEh8_gmTcZHf_3vfKCIqyMknkkQfhlzNv_fE08UMpxyjkKoih96vULyBu0$<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!qBSbNdG-bXB3-5NwyJJVkk858HEh8_gmTcZHf_3vfKCIqyMknkkQfhlzNv_fE08UMpxyjkKoih96vULyBu0$><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!p3fE1cCl7_IxAOT0Fvr1vPWF3xDeYl1FCDaqXi4Z6HH7tOMmDULawS8DAa7XcG5s5Prfqhxs3su7$><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!p3fE1cCl7_IxAOT0Fvr1vPWF3xDeYl1FCDaqXi4Z6HH7tOMmDULawS8DAa7XcG5s5Prfqhxs3su7$%3e%3e>
> 
>> <https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!p3fE1cCl7_IxAOT0Fvr1vPWF3xDeYl1FCDaqXi4Z6HH7tOMmDULawS8DAa7XcG5s5Prfqhxs3su7$%3e%3e>and provide commented, minimal, self-contained, reproducible code.
> 
>>
> 
>>              [[alternative HTML version deleted]]
> 
>>
> 
>> ______________________________________________
> 
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> 
>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!qBSbNdG-bXB3-5NwyJJVkk858HEh8_gmTcZHf_3vfKCIqyMknkkQfhlzNv_fE08UMpxyjkKoih96oo-fbT4$<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!qBSbNdG-bXB3-5NwyJJVkk858HEh8_gmTcZHf_3vfKCIqyMknkkQfhlzNv_fE08UMpxyjkKoih96oo-fbT4$>
> 
>> PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!qBSbNdG-bXB3-5NwyJJVkk858HEh8_gmTcZHf_3vfKCIqyMknkkQfhlzNv_fE08UMpxyjkKoih96vULyBu0$<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!qBSbNdG-bXB3-5NwyJJVkk858HEh8_gmTcZHf_3vfKCIqyMknkkQfhlzNv_fE08UMpxyjkKoih96vULyBu0$>
> 
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> 
> 
> 
> 
> --
> 
> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
> 
> https://urldefense.com/v3/__http://www.avg.com__;!!Fou38LsQmgU!qBSbNdG-bXB3-5NwyJJVkk858HEh8_gmTcZHf_3vfKCIqyMknkkQfhlzNv_fE08UMpxyjkKoih96HZLrJxM$<https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!qBSbNdG-bXB3-5NwyJJVkk858HEh8_gmTcZHf_3vfKCIqyMknkkQfhlzNv_fE08UMpxyjkKoih96HZLrJxM$>
> 
Hello,

Remove .groups from summarise and it should work, .groups is only needed 
if you group the data with group_by, not used in the 2nd example.

Hope this helps,

Rui Barradas


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jun 12 12:14:23 2024
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 12 Jun 2024 03:14:23 -0700
Subject: [R] Integration of functions with a vector argument
In-Reply-To: <PH0PR22MB2860E3ABD206953D15F31EFAC5C72@PH0PR22MB2860.namprd22.prod.outlook.com>
References: <PH0PR22MB2860E3ABD206953D15F31EFAC5C72@PH0PR22MB2860.namprd22.prod.outlook.com>
Message-ID: <483F442F-5229-4645-883D-15A796F83FC6@dcn.davis.ca.us>

How do you integrate perpendicular to a plane if you don't have a concept of 3d? In that direction the plane is just a point.

Vectors in R do not have any concept of "n by 1"... they are like a string of beads. When you take a column out of a matrix `a` using indexing b <- a[,j] the resulting vector can only be indexed along its length as b[i]. Such a vector is indistinguishable in structure from a[i,] which originated from a row.

So I would say you are tilting at windmills. If you want you can write a[, j, drop=FALSE] to end up with an n by 1 matrix... but that is not a vector, it is a matrix. I have reservations about the value of "integrating out" along a row in an n by 1 matrix... seems like a degenerate case and you would be better off not creating the n by 1 matrix in the first place. But then I left Matlab behind a long time ago.


On June 11, 2024 11:44:08 AM PDT, "Levine, Michael" <mlevins at purdue.edu> wrote:
>Hello all,
>
>I have a question concerning integration of a function of a multivariate argument with respect to one or more variables in r.  Let us say we have a function
>
>F <- function(x){ body of the function}
>
>Where x is, in general, a d by 1 vector with d>1.  Now I want to integrate out some of the coordinates of x, e.g. x[1] or x[2] or both of them etc. I'm well aware of how to integrate out e.g. y if a function is defined as f <- function (x,y) {body of the function} where y is a scalar.
>However, it seems to be quite difficult to do the same if the function is defined with a vector argument x. At the very least, I haven't seen any good examples of this being done.
>Any suggestions?
>
>Yours sincerely,
>Michael
>
>Michael Levine
>Associate Professor, Statistics
>
>Department of Statistics
>Purdue University
>250 North University Street
>West Lafayette, IN 47907 USA
>
>email: mlevins at purdue.edu
>Phone: +1-765-496-7571
>Fax:   +1-765-494-0558
>URL:   www.stat.purdue.edu/~mlevins
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From |kry|ov @end|ng |rom d|@root@org  Thu Jun 13 12:21:21 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Thu, 13 Jun 2024 13:21:21 +0300
Subject: [R] Integration of functions with a vector argument
In-Reply-To: <PH0PR22MB28605CCF2898AD2EC336DCCBC5C02@PH0PR22MB2860.namprd22.prod.outlook.com>
References: <PH0PR22MB2860E3ABD206953D15F31EFAC5C72@PH0PR22MB2860.namprd22.prod.outlook.com>
 <20240612134119.72e4cab6@Tarkus>
 <PH0PR22MB28605CCF2898AD2EC336DCCBC5C02@PH0PR22MB2860.namprd22.prod.outlook.com>
Message-ID: <20240613132121.1847edee@arachnoid>

? Wed, 12 Jun 2024 23:42:18 +0000
"Levine, Michael" <mlevins at purdue.edu> ?????:

> f.int1 <- function(x,y) {Vectorize (function(y) f(c(x,y),H=H,j=j))}

Vectorize returns a callable function(y), so wrapping it in a
function(x,y) will not work. Since you'd like to integrate over y, we
can perform the same transformation manually using vapply:

# A version of f(...) that can be integrated over y
f.int1 <- function(y, x, H, j)
 vapply(y, function(y) f(c(x,y), H = H, j = j), numeric(1))

The same transformation can be performed using Vectorize as follows:

f.int1 <- Vectorize(
 function(y, x, H, j) f(c(x,y), H = H, j = j),
 vectorize.args = 'y'
)

>     mrg.d1 <- function(x){
>     integrate(f.int1,lower=-3,upper=3)$value
>     }

We can then integrate f.int1 over y, making sure to pass the remaining
scalar parameters to the function:

# mrg.d1(x, H, j) = ? f(y,x,H,j) dy from -3 to 3
mrg.d1 <- function(x, H, j)
 integrate(f.int1, lower=-3, upper=3, x = x, H = H, j = j)$value

> mrg.cdf1 <- function(x){
>     integrate(mrg.d1,lower=-Inf,upper=x)$value
>     }

Unfortunately, mrg.d1 is once again not vectorised and may give wrong
answers or raise exceptions with non-scalar x. We can now perform the
same transformation so that the function would work with integrate():

# Version of mrg.d1 integratable over x
mrg.d1.int <- function(x, H, j)
 vapply(x, mrg.d1, numeric(1), H = H, j = j)

Here, instead of having to combine arguments like in f.int1, we can
just use vapply() to call the original mrg.d1 for every scalar element
inside the vector x given to mrg.d1.int. Alternatively,

mrg.d1.int <- Vectorize(mrg.d1, 'x')

A vectorised function can then be integrated:

# mrg.cdf1(x, H, j) = ? mrg.d1(x', H, j) dx' from -? to x
mrg.cdf1 <- function(x, H, j)
 integrate(mrg.d1.int, lower=-Inf, upper=x, H = H, j = j)$value

This double nested loop (produced by Vectorize() and mapply() or
manually with vapply()) may be not very fast. If you rewrite your
function f to accept matrices containing values of (x, y) for many
evaluations of the function and to return vectors of the resulting
values, you'll be able to use the CRAN package 'cubature'
<https://CRAN.R-project.org/package=cubature> to integrate it over
multiple variables at once.

-- 
Best regards,
Ivan


From m|ev|n@ @end|ng |rom purdue@edu  Thu Jun 13 01:42:18 2024
From: m|ev|n@ @end|ng |rom purdue@edu (Levine, Michael)
Date: Wed, 12 Jun 2024 23:42:18 +0000
Subject: [R] Integration of functions with a vector argument
In-Reply-To: <20240612134119.72e4cab6@Tarkus>
References: <PH0PR22MB2860E3ABD206953D15F31EFAC5C72@PH0PR22MB2860.namprd22.prod.outlook.com>
 <20240612134119.72e4cab6@Tarkus>
Message-ID: <PH0PR22MB28605CCF2898AD2EC336DCCBC5C02@PH0PR22MB2860.namprd22.prod.outlook.com>

Dear Ivan,

Thank you very much for your suggestions. I understand what you are saying. I am afraid I didn't explain well enough what was needed, however.  Let us again restrict ourselves to the case of two dimensions. Then, what I have is a bivariate density function f(x,y) and my intention is to obtain f(x) by integrating out y. However, I don't only need to know the value of the marginal density f(x) at one point - I need to integrate it again to obtain the marginal cumulative density function F(x) as a next step. Thus, I also need to pass x as an additional parameter before integration, and this is what makes the problem more difficult.

I tried to do the following (here H and j are additional arguments needed to obtain the estimated bivariate density function):

f.int1 <- function(x,y) {Vectorize (function(y) f(c(x,y),H=H,j=j))}
    mrg.d1 <- function(x){
    integrate(f.int1,lower=-3,upper=3)$value
    }
mrg.cdf1 <- function(x){
    integrate(mrg.d1,lower=-Inf,upper=x)$value
    }

I received the following error message:


Error in integrate(f.int1, lower = -3, upper = 3) :
  evaluation of function gave a result of wrong length


How would you go about performing this task?

Yours sincerely,
Michael

Michael Levine
Associate Professor, Statistics

Department of Statistics
Purdue University
250 North University Street
West Lafayette, IN 47907 USA

email: mlevins at purdue.edu
Phone: +1-765-496-7571
Fax:   +1-765-494-0558
URL:   www.stat.purdue.edu/~mlevins
________________________________
From: Ivan Krylov <ikrylov at disroot.org>
Sent: Wednesday, June 12, 2024 6:41 AM
To: Levine, Michael <mlevins at purdue.edu>
Cc: r-help at r-project.org <r-help at r-project.org>
Subject: Re: [R] Integration of functions with a vector argument

[You don't often get email from ikrylov at disroot.org. Learn why this is important at https://aka.ms/LearnAboutSenderIdentification ]

---- External Email: Use caution with attachments, links, or sharing data ----


? Tue, 11 Jun 2024 18:44:08 +0000
"Levine, Michael" <mlevins at purdue.edu> ?????:

> Let us say we have a function
>
> F <- function(x){ body of the function}
>
> Where x is, in general, a d by 1 vector with d>1.  Now I want to
> integrate out some of the coordinates of x, e.g. x[1] or x[2] or both
> of them etc. I'm well aware of how to integrate out e.g. y if a
> function is defined as f <- function (x,y) {body of the function}
> where y is a scalar.

The reason integrate() wants a separate function argument for the
integration coordinate is so that it could give the function a vector
of different values of the variable and receive a vector of the same
length containing the corresponding values of the function.

If the problem is small enough to make performance considerations
irrelevant, you can use Vectorize to make a function compatible with
integrate() from your function F:

x <- x0
z <- z0
Fiy <- Vectorize(function(y) F(c(x, y, z)))
integrate(Fiy, ymin, ymax)

The resulting function Fiy will accept a vector of values for y and
translate it into multiple calls to F with a three-element vector
argument as it expects.

Achieving better performance will require rewriting the function F to
be "vectorised", i.e. to accept vectors for arguments and return a
vector of the same length.

--
Best regards,
Ivan

	[[alternative HTML version deleted]]


From |r@nce@c@@p@ncotto @end|ng |rom un|more@|t  Thu Jun 13 16:42:19 2024
From: |r@nce@c@@p@ncotto @end|ng |rom un|more@|t (Francesca PANCOTTO)
Date: Thu, 13 Jun 2024 16:42:19 +0200
Subject: [R] Create a numeric series in an efficient way
Message-ID: <CAMXoJ=+0go0uA1NKJ+0HaW5v7HcxsmGBJ8o0v=7RNJX_uHv3bA@mail.gmail.com>

Dear Contributors
I am trying to create a numeric series with repeated numbers, not difficult
task, but I do not seem to find an efficient way.

This is my solution

blocB <- c(rep(x = 1, times = 84), rep(x = 2, times = 84), rep(x = 3, times
= 84), rep(x = 4, times = 84), rep(x = 5, times = 84), rep(x = 6, times =
84), rep(x = 7, times = 84), rep(x = 8, times = 84), rep(x = 9, times =
84), rep(x = 10, times = 84), rep(x = 11, times = 84), rep(x = 12, times =
84), rep(x = 13, times = 84))

which works but it is super silly and I need to create different variables
similar to this, changing the value of the repetition, 84 in this case.
Thanks for any help.


F.

	[[alternative HTML version deleted]]


From |r@nce@c@@p@ncotto @end|ng |rom un|more@|t  Thu Jun 13 20:21:58 2024
From: |r@nce@c@@p@ncotto @end|ng |rom un|more@|t (Francesca PANCOTTO)
Date: Thu, 13 Jun 2024 20:21:58 +0200
Subject: [R] Create a numeric series in an efficient way
In-Reply-To: <CAMXoJ=+0go0uA1NKJ+0HaW5v7HcxsmGBJ8o0v=7RNJX_uHv3bA@mail.gmail.com>
References: <CAMXoJ=+0go0uA1NKJ+0HaW5v7HcxsmGBJ8o0v=7RNJX_uHv3bA@mail.gmail.com>
Message-ID: <CAMXoJ=JhO4gg900tNxcCVas7uWA7q3JZa2+rVJLv+kq-XavHYg@mail.gmail.com>

I apologize, I solved the problem, sorry for that.
f.



Il giorno gio 13 giu 2024 alle ore 16:42 Francesca PANCOTTO <
francesca.pancotto at unimore.it> ha scritto:

> Dear Contributors
> I am trying to create a numeric series with repeated numbers, not
> difficult task, but I do not seem to find an efficient way.
>
> This is my solution
>
> blocB <- c(rep(x = 1, times = 84), rep(x = 2, times = 84), rep(x = 3,
> times = 84), rep(x = 4, times = 84), rep(x = 5, times = 84), rep(x = 6,
> times = 84), rep(x = 7, times = 84), rep(x = 8, times = 84), rep(x = 9,
> times = 84), rep(x = 10, times = 84), rep(x = 11, times = 84), rep(x = 12,
> times = 84), rep(x = 13, times = 84))
>
> which works but it is super silly and I need to create different variables
> similar to this, changing the value of the repetition, 84 in this case.
> Thanks for any help.
>
>
> F.
>

	[[alternative HTML version deleted]]


From tebert @end|ng |rom u||@edu  Fri Jun 14 00:54:37 2024
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Thu, 13 Jun 2024 22:54:37 +0000
Subject: [R] Create a numeric series in an efficient way
In-Reply-To: <CAMXoJ=JhO4gg900tNxcCVas7uWA7q3JZa2+rVJLv+kq-XavHYg@mail.gmail.com>
References: <CAMXoJ=+0go0uA1NKJ+0HaW5v7HcxsmGBJ8o0v=7RNJX_uHv3bA@mail.gmail.com>
 <CAMXoJ=JhO4gg900tNxcCVas7uWA7q3JZa2+rVJLv+kq-XavHYg@mail.gmail.com>
Message-ID: <CH3PR22MB451402988381A3792FAD5073CFC12@CH3PR22MB4514.namprd22.prod.outlook.com>

Maybe this was your solution?

blocC <- c(rep(x=c(1:13), times=84))
blocC <- arrange(.data = data.frame(blocC), blocC)

The second line sorts, but that may not be needed depending on application. The object class is also different in the sorted solution.

Tim
-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Francesca PANCOTTO via R-help
Sent: Thursday, June 13, 2024 2:22 PM
To: r-help at r-project.org
Subject: Re: [R] Create a numeric series in an efficient way

[External Email]

I apologize, I solved the problem, sorry for that.
f.



Il giorno gio 13 giu 2024 alle ore 16:42 Francesca PANCOTTO < francesca.pancotto at unimore.it> ha scritto:

> Dear Contributors
> I am trying to create a numeric series with repeated numbers, not
> difficult task, but I do not seem to find an efficient way.
>
> This is my solution
>
> blocB <- c(rep(x = 1, times = 84), rep(x = 2, times = 84), rep(x = 3,
> times = 84), rep(x = 4, times = 84), rep(x = 5, times = 84), rep(x =
> 6, times = 84), rep(x = 7, times = 84), rep(x = 8, times = 84), rep(x
> = 9, times = 84), rep(x = 10, times = 84), rep(x = 11, times = 84),
> rep(x = 12, times = 84), rep(x = 13, times = 84))
>
> which works but it is super silly and I need to create different
> variables similar to this, changing the value of the repetition, 84 in this case.
> Thanks for any help.
>
>
> F.
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Fri Jun 14 03:13:00 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 13 Jun 2024 18:13:00 -0700
Subject: [R] Create a numeric series in an efficient way
In-Reply-To: <CH3PR22MB451402988381A3792FAD5073CFC12@CH3PR22MB4514.namprd22.prod.outlook.com>
References: <CAMXoJ=+0go0uA1NKJ+0HaW5v7HcxsmGBJ8o0v=7RNJX_uHv3bA@mail.gmail.com>
 <CAMXoJ=JhO4gg900tNxcCVas7uWA7q3JZa2+rVJLv+kq-XavHYg@mail.gmail.com>
 <CH3PR22MB451402988381A3792FAD5073CFC12@CH3PR22MB4514.namprd22.prod.outlook.com>
Message-ID: <CAGxFJbTnA0n=s+YAwmQs1zcDRPJHqCRaEN0rgkt5WoXLb5-3wg@mail.gmail.com>

Nope. She would have wanted the 'each' argument = 84. See ?rep.

-- Bert



On Thu, Jun 13, 2024 at 3:54?PM Ebert,Timothy Aaron <tebert at ufl.edu> wrote:

> Maybe this was your solution?
>
> blocC <- c(rep(x=c(1:13), times=84))
> blocC <- arrange(.data = data.frame(blocC), blocC)
>
> The second line sorts, but that may not be needed depending on
> application. The object class is also different in the sorted solution.
>
> Tim
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Francesca
> PANCOTTO via R-help
> Sent: Thursday, June 13, 2024 2:22 PM
> To: r-help at r-project.org
> Subject: Re: [R] Create a numeric series in an efficient way
>
> [External Email]
>
> I apologize, I solved the problem, sorry for that.
> f.
>
>
>
> Il giorno gio 13 giu 2024 alle ore 16:42 Francesca PANCOTTO <
> francesca.pancotto at unimore.it> ha scritto:
>
> > Dear Contributors
> > I am trying to create a numeric series with repeated numbers, not
> > difficult task, but I do not seem to find an efficient way.
> >
> > This is my solution
> >
> > blocB <- c(rep(x = 1, times = 84), rep(x = 2, times = 84), rep(x = 3,
> > times = 84), rep(x = 4, times = 84), rep(x = 5, times = 84), rep(x =
> > 6, times = 84), rep(x = 7, times = 84), rep(x = 8, times = 84), rep(x
> > = 9, times = 84), rep(x = 10, times = 84), rep(x = 11, times = 84),
> > rep(x = 12, times = 84), rep(x = 13, times = 84))
> >
> > which works but it is super silly and I need to create different
> > variables similar to this, changing the value of the repetition, 84 in
> this case.
> > Thanks for any help.
> >
> >
> > F.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.r-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tebert @end|ng |rom u||@edu  Fri Jun 14 03:46:35 2024
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Fri, 14 Jun 2024 01:46:35 +0000
Subject: [R] Create a numeric series in an efficient way
In-Reply-To: <CAGxFJbTnA0n=s+YAwmQs1zcDRPJHqCRaEN0rgkt5WoXLb5-3wg@mail.gmail.com>
References: <CAMXoJ=+0go0uA1NKJ+0HaW5v7HcxsmGBJ8o0v=7RNJX_uHv3bA@mail.gmail.com>
 <CAMXoJ=JhO4gg900tNxcCVas7uWA7q3JZa2+rVJLv+kq-XavHYg@mail.gmail.com>
 <CH3PR22MB451402988381A3792FAD5073CFC12@CH3PR22MB4514.namprd22.prod.outlook.com>
 <CAGxFJbTnA0n=s+YAwmQs1zcDRPJHqCRaEN0rgkt5WoXLb5-3wg@mail.gmail.com>
Message-ID: <CH3PR22MB4514237A09BDBBF0781F55F1CFC22@CH3PR22MB4514.namprd22.prod.outlook.com>

Thank you. Using ?each? is shorter code, so better if the requested order was important versus being an initial solution.

blocC <- c(rep(x=c(1:13), times=84)) #it makes 84 copies of the numbers 1:13
blocC <- arrange(.data = data.frame(blocC), blocC) #sort to get requested order.

blocD <- c(rep(x=c(1:13), each=84)) #it makes 84 copies of 1, then 84 copies of 2 ?
blocD <- data.frame(blocC=blocD) #give the column the same name.
identical(blocC, blocD)
all.equal(blocC, blocD)

and both identical() and all.equal() return TRUE. Either way gives the same end product.

Tim

From: Bert Gunter <bgunter.4567 at gmail.com>
Sent: Thursday, June 13, 2024 9:13 PM
To: Ebert,Timothy Aaron <tebert at ufl.edu>
Cc: Francesca PANCOTTO <francesca.pancotto at unimore.it>; r-help at r-project.org
Subject: Re: [R] Create a numeric series in an efficient way

[External Email]
Nope. She would have wanted the 'each' argument = 84. See ?rep.

-- Bert



On Thu, Jun 13, 2024 at 3:54?PM Ebert,Timothy Aaron <tebert at ufl.edu<mailto:tebert at ufl.edu>> wrote:
Maybe this was your solution?

blocC <- c(rep(x=c(1:13), times=84))
blocC <- arrange(.data = data.frame(blocC), blocC)

The second line sorts, but that may not be needed depending on application. The object class is also different in the sorted solution.

Tim
-----Original Message-----
From: R-help <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>> On Behalf Of Francesca PANCOTTO via R-help
Sent: Thursday, June 13, 2024 2:22 PM
To: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] Create a numeric series in an efficient way

[External Email]

I apologize, I solved the problem, sorry for that.
f.



Il giorno gio 13 giu 2024 alle ore 16:42 Francesca PANCOTTO < francesca.pancotto at unimore.it<mailto:francesca.pancotto at unimore.it>> ha scritto:

> Dear Contributors
> I am trying to create a numeric series with repeated numbers, not
> difficult task, but I do not seem to find an efficient way.
>
> This is my solution
>
> blocB <- c(rep(x = 1, times = 84), rep(x = 2, times = 84), rep(x = 3,
> times = 84), rep(x = 4, times = 84), rep(x = 5, times = 84), rep(x =
> 6, times = 84), rep(x = 7, times = 84), rep(x = 8, times = 84), rep(x
> = 9, times = 84), rep(x = 10, times = 84), rep(x = 11, times = 84),
> rep(x = 12, times = 84), rep(x = 13, times = 84))
>
> which works but it is super silly and I need to create different
> variables similar to this, changing the value of the repetition, 84 in this case.
> Thanks for any help.
>
>
> F.
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.r-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From @vi@e@gross m@iii@g oii gm@ii@com  Fri Jun 14 04:03:46 2024
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Thu, 13 Jun 2024 22:03:46 -0400
Subject: [R] Create a numeric series in an efficient way
In-Reply-To: <CAMXoJ=+0go0uA1NKJ+0HaW5v7HcxsmGBJ8o0v=7RNJX_uHv3bA@mail.gmail.com>
References: <CAMXoJ=+0go0uA1NKJ+0HaW5v7HcxsmGBJ8o0v=7RNJX_uHv3bA@mail.gmail.com>
Message-ID: <047d01dabdff$1776c220$46644660$@gmail.com>

For the particular example you asked for, consider the "each" you can use
with rep()

rep(1:13, each=84)

This is what it does for a shorter version of 4 each:

> rep(1:13, each=4)
 [1]  1  1  1  1  2  2  2  2  3  3  3  3  4  4  4  4  5  5  5  5  6  6  6  6
7  7  7  7  8  8  8  8  9  9  9  9 10 10 10 10
[41] 11 11 11 11 12 12 12 12 13 13 13 13


For another variant, make 84 copies of 1:13 and sort that as you happen to
want the numbers in order.

sort(rep(1:13, each=84))

The output is the same.

If you want a much more compact solution that handles arbitrary pairs of
"what to copy", number_of_copies, you can write a function  that evaluates
two arguments at a time or takes two vectors as arguments like this one I
wrote quickly and crudely:

rep_many <- function(items, counts) {
  result <- c()
  for (index in 1:length(items)) {
    result <- c(result, rep(items[index], counts[index]))
  }
  return(result)
  }
   
rep_many(1:13, rep(84,13))


The same ideas can be used using a data.frame or functional programming
methods but the above is simple enough to flexibly create two vectors
specifying how much of each.

You said you found a solution, so you may want to share what you chose
already.




-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Francesca PANCOTTO
via R-help
Sent: Thursday, June 13, 2024 10:42 AM
To: r-help at r-project.org
Subject: [R] Create a numeric series in an efficient way

Dear Contributors
I am trying to create a numeric series with repeated numbers, not difficult
task, but I do not seem to find an efficient way.

This is my solution

blocB <- c(rep(x = 1, times = 84), rep(x = 2, times = 84), rep(x = 3, times
= 84), rep(x = 4, times = 84), rep(x = 5, times = 84), rep(x = 6, times =
84), rep(x = 7, times = 84), rep(x = 8, times = 84), rep(x = 9, times =
84), rep(x = 10, times = 84), rep(x = 11, times = 84), rep(x = 12, times =
84), rep(x = 13, times = 84))

which works but it is super silly and I need to create different variables
similar to this, changing the value of the repetition, 84 in this case.
Thanks for any help.


F.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Fri Jun 14 04:41:46 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 13 Jun 2024 19:41:46 -0700
Subject: [R] Create a numeric series in an efficient way
In-Reply-To: <047d01dabdff$1776c220$46644660$@gmail.com>
References: <CAMXoJ=+0go0uA1NKJ+0HaW5v7HcxsmGBJ8o0v=7RNJX_uHv3bA@mail.gmail.com>
 <047d01dabdff$1776c220$46644660$@gmail.com>
Message-ID: <CAGxFJbTfYQKeq5iieByXaa8AF0Y8UQNy=N61aHYvxs4B+EoS4g@mail.gmail.com>

"If you want a much more compact solution that handles arbitrary pairs of
"what to copy", number_of_copies, you can write a function  that evaluates
two arguments at a time or takes two vectors as arguments like this one I
wrote quickly and crudely:"

Please! -- The "times" argument of rep can be a vector that does exactly this:

times
an integer-valued vector giving the (non-negative) number of times to
repeat each element if of length length(x), or to repeat the whole
vector if of length 1.

In future, please read the Help files carefully before dispensing such "advice."

-- Bert


On Thu, Jun 13, 2024 at 7:04?PM <avi.e.gross at gmail.com> wrote:
>
> For the particular example you asked for, consider the "each" you can use
> with rep()
>
> rep(1:13, each=84)
>
> This is what it does for a shorter version of 4 each:
>
> > rep(1:13, each=4)
>  [1]  1  1  1  1  2  2  2  2  3  3  3  3  4  4  4  4  5  5  5  5  6  6  6  6
> 7  7  7  7  8  8  8  8  9  9  9  9 10 10 10 10
> [41] 11 11 11 11 12 12 12 12 13 13 13 13
>
>
> For another variant, make 84 copies of 1:13 and sort that as you happen to
> want the numbers in order.
>
> sort(rep(1:13, each=84))
>
> The output is the same.
>
> If you want a much more compact solution that handles arbitrary pairs of
> "what to copy", number_of_copies, you can write a function  that evaluates
> two arguments at a time or takes two vectors as arguments like this one I
> wrote quickly and crudely:
>
> rep_many <- function(items, counts) {
>   result <- c()
>   for (index in 1:length(items)) {
>     result <- c(result, rep(items[index], counts[index]))
>   }
>   return(result)
>   }
>
> rep_many(1:13, rep(84,13))
>
>
> The same ideas can be used using a data.frame or functional programming
> methods but the above is simple enough to flexibly create two vectors
> specifying how much of each.
>
> You said you found a solution, so you may want to share what you chose
> already.
>
>
>
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Francesca PANCOTTO
> via R-help
> Sent: Thursday, June 13, 2024 10:42 AM
> To: r-help at r-project.org
> Subject: [R] Create a numeric series in an efficient way
>
> Dear Contributors
> I am trying to create a numeric series with repeated numbers, not difficult
> task, but I do not seem to find an efficient way.
>
> This is my solution
>
> blocB <- c(rep(x = 1, times = 84), rep(x = 2, times = 84), rep(x = 3, times
> = 84), rep(x = 4, times = 84), rep(x = 5, times = 84), rep(x = 6, times =
> 84), rep(x = 7, times = 84), rep(x = 8, times = 84), rep(x = 9, times =
> 84), rep(x = 10, times = 84), rep(x = 11, times = 84), rep(x = 12, times =
> 84), rep(x = 13, times = 84))
>
> which works but it is super silly and I need to create different variables
> similar to this, changing the value of the repetition, 84 in this case.
> Thanks for any help.
>
>
> F.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @vi@e@gross m@iii@g oii gm@ii@com  Fri Jun 14 06:03:58 2024
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Fri, 14 Jun 2024 00:03:58 -0400
Subject: [R] Create a numeric series in an efficient way
In-Reply-To: <CAGxFJbTfYQKeq5iieByXaa8AF0Y8UQNy=N61aHYvxs4B+EoS4g@mail.gmail.com>
References: <CAMXoJ=+0go0uA1NKJ+0HaW5v7HcxsmGBJ8o0v=7RNJX_uHv3bA@mail.gmail.com>
 <047d01dabdff$1776c220$46644660$@gmail.com>
 <CAGxFJbTfYQKeq5iieByXaa8AF0Y8UQNy=N61aHYvxs4B+EoS4g@mail.gmail.com>
Message-ID: <048d01dabe0f$e20caf80$a6260e80$@gmail.com>

Bert,

I think you read my message differently than I expected. I approached the request as an exercise in evaluating various ways something can be done and maybe choosing a simple one or choosing a more general one as needed.

I provided some solutions along the lines you mentioned and THEN also suggested that there can be a general purpose way to use or write a function that will take one of several way to specify what you want and do a calculation. This would be needed for really miscellaneous data with no logic or ordering such as an analysis of how many people in some mailing list had each last name in that population.

If you had a vector like:
Names <- c("Smith", "Jones", "Gunter")

And another like:

Counts <- c(5, 3, 1)

Then calling a function you created with a name like:

Mult_repeat(Names, Counts)

Should output something like c("Smith", "Smith","Smith","Smith","Smith","Jones","Jones","Jones","Gunter",)

The innards of such a function would work for such a completely general case and need not be discussed but obviously some form of loop, perhaps implicit, could do it. And, it could also do the simpler case shown as an example, albeit there are short elegant ways to do that. But a sorted deck of cards that is shuffled, would not ...

The other solution I alluded to might be to make a function with a ... specification that takes any number of arguments and could be called as in:

Mult_repeat("Smith", 5,  "Jones",3, "Gunter", 1)

It would simply look at something like unlist(list(...)) and take two arguments at a time and call rep() with those and keep appending it to an empty list or if needed a vector.

What I offered was a set of APPROACHES to consider depending on what you needed.

One I did not mention but considered was using one of the "map" functions in the purr package to do this by effectively taking two vectors as described above and calling rep() repeatedly on pairs and consolidating the results:

The following one liner handles the case mentioned with me substituting a 4 for the 84 for brevity:

> unlist(purrr::map2(.x=1:13, .y=rep(4,13), .f=rep))
 [1]  1  1  1  1  2  2  2  2  3  3  3  3  4  4  4  4  5  5  5  5  6  6  6  6  7  7  7  7  8  8  8  8  9  9  9  9 10 10 10 10
[41] 11 11 11 11 12 12 12 12 13 13 13 13

It would work as easily on my example from above:

> Names <- c("Smith", "Jones", "Gunter")
> Counts <- c(5, 3, 1)
> unlist(purrr::map2(.x=Names, .y=Counts, .f=rep))
[1] "Smith"  "Smith"  "Smith"  "Smith"  "Smith"  "Jones"  "Jones"  "Jones"  "Gunter"

If that remains unclear, I am doing something wrong today.

It is nice to see alternatives but some people just want one answer. Read my first message and see I also gave ones like yours.

-----Original Message-----
From: Bert Gunter <bgunter.4567 at gmail.com> 
Sent: Thursday, June 13, 2024 10:42 PM
To: avi.e.gross at gmail.com
Cc: Francesca PANCOTTO <francesca.pancotto at unimore.it>; r-help at r-project.org
Subject: Re: [R] Create a numeric series in an efficient way

"If you want a much more compact solution that handles arbitrary pairs of
"what to copy", number_of_copies, you can write a function  that evaluates
two arguments at a time or takes two vectors as arguments like this one I
wrote quickly and crudely:"

Please! -- The "times" argument of rep can be a vector that does exactly this:

times
an integer-valued vector giving the (non-negative) number of times to
repeat each element if of length length(x), or to repeat the whole
vector if of length 1.

In future, please read the Help files carefully before dispensing such "advice."

-- Bert


On Thu, Jun 13, 2024 at 7:04?PM <avi.e.gross at gmail.com> wrote:
>
> For the particular example you asked for, consider the "each" you can use
> with rep()
>
> rep(1:13, each=84)
>
> This is what it does for a shorter version of 4 each:
>
> > rep(1:13, each=4)
>  [1]  1  1  1  1  2  2  2  2  3  3  3  3  4  4  4  4  5  5  5  5  6  6  6  6
> 7  7  7  7  8  8  8  8  9  9  9  9 10 10 10 10
> [41] 11 11 11 11 12 12 12 12 13 13 13 13
>
>
> For another variant, make 84 copies of 1:13 and sort that as you happen to
> want the numbers in order.
>
> sort(rep(1:13, each=84))
>
> The output is the same.
>
> If you want a much more compact solution that handles arbitrary pairs of
> "what to copy", number_of_copies, you can write a function  that evaluates
> two arguments at a time or takes two vectors as arguments like this one I
> wrote quickly and crudely:
>
> rep_many <- function(items, counts) {
>   result <- c()
>   for (index in 1:length(items)) {
>     result <- c(result, rep(items[index], counts[index]))
>   }
>   return(result)
>   }
>
> rep_many(1:13, rep(84,13))
>
>
> The same ideas can be used using a data.frame or functional programming
> methods but the above is simple enough to flexibly create two vectors
> specifying how much of each.
>
> You said you found a solution, so you may want to share what you chose
> already.
>
>
>
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Francesca PANCOTTO
> via R-help
> Sent: Thursday, June 13, 2024 10:42 AM
> To: r-help at r-project.org
> Subject: [R] Create a numeric series in an efficient way
>
> Dear Contributors
> I am trying to create a numeric series with repeated numbers, not difficult
> task, but I do not seem to find an efficient way.
>
> This is my solution
>
> blocB <- c(rep(x = 1, times = 84), rep(x = 2, times = 84), rep(x = 3, times
> = 84), rep(x = 4, times = 84), rep(x = 5, times = 84), rep(x = 6, times =
> 84), rep(x = 7, times = 84), rep(x = 8, times = 84), rep(x = 9, times =
> 84), rep(x = 10, times = 84), rep(x = 11, times = 84), rep(x = 12, times =
> 84), rep(x = 13, times = 84))
>
> which works but it is super silly and I need to create different variables
> similar to this, changing the value of the repetition, 84 in this case.
> Thanks for any help.
>
>
> F.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dut@ngc @end|ng |rom gm@||@com  Fri Jun 14 08:12:23 2024
From: dut@ngc @end|ng |rom gm@||@com (Christophe Dutang)
Date: Fri, 14 Jun 2024 08:12:23 +0200
Subject: [R] Column names of model.matrix's output with contrast.arg
Message-ID: <2F05BA60-78A6-4FE0-B8CD-14105A2F9BF8@gmail.com>

Dear list,

Changing the default contrasts used in glm() makes me aware how model.matrix() set column names.

With default contrasts, model.matrix() use the level values to name the columns. However with other contrasts, model.matrix() use the level indexes. In the documentation, I don?t see anything in the documentation related to this ? It does not seem natural to have such a behavior?

Any comment is welcome.

An example is below.

Kind regards, Christophe  


#example from ?glm
counts <- c(18,17,15,20,10,20,25,13,12)
outcome <- paste0("O", gl(3,1,9))
treatment <- paste0("T", gl(3,3))

X3 <- model.matrix(counts ~ outcome + treatment)
X4 <- model.matrix(counts ~ outcome + treatment, contrasts = list("outcome"="contr.sum"))
X5 <- model.matrix(counts ~ outcome + treatment, contrasts = list("outcome"="contr.helmert"))

#check with original factor
cbind.data.frame(X3, outcome)
cbind.data.frame(X4, outcome)
cbind.data.frame(X5, outcome)

#same issue with glm
glm.D93 <- glm(counts ~ outcome + treatment, family = poisson())
glm.D94 <- glm(counts ~ outcome + treatment, family = poisson(), contrasts = list("outcome"="contr.sum"))
glm.D95 <- glm(counts ~ outcome + treatment, family = poisson(), contrasts = list("outcome"="contr.helmert"))

coef(glm.D93)
coef(glm.D94)
coef(glm.D95)

#check linear predictor
cbind(X3 %*% coef(glm.D93), predict(glm.D93))
cbind(X4 %*% coef(glm.D94), predict(glm.D94))

-------------------------------------------------
Christophe DUTANG
LJK, Ensimag, Grenoble INP, UGA, France
ILB research fellow
Web: http://dutangc.free.fr


From pd@|gd @end|ng |rom gm@||@com  Fri Jun 14 09:58:58 2024
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Fri, 14 Jun 2024 09:58:58 +0200
Subject: [R] [Rd] R 4.4.1 is released
Message-ID: <0C27FF17-6635-4898-A480-BFCCAA4AB177@gmail.com>

The build system rolled up R-4.4.1.tar.gz (codename "Race for Your Life") this morning.

===============================================================================
This release is dedicated to the memory of Friedrich (Fritz) Leisch, 1968-2024.
===============================================================================

This is a minor update, with a few bug fixes.

The list below details the changes in this release. 

You can get the source code from

https://cran.r-project.org/src/base/R-4/R-4.4.1.tar.gz
https://cran.r-project.org/src/base/R-4/R-4.4.1.tar.xz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course. 
(The Mac binaries will be delayed for a couple of days because the maintainer is traveling.)



For the R Core Team,

Peter Dalgaard


These are the checksums (md5 and SHA-256) for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = 0ba932825aefae5566dc44822916b266
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = b3c330c22effc753f0b6fdf3a9612ff5
MD5 (INSTALL) = 7893f754308ca31f1ccf62055090ad7b
MD5 (NEWS) = 3b5b817ed476957d84b35984fd1aaa40
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = f8466e418dec6b958b4ce484a13f9a9d
MD5 (NEWS.2) = b38d94569700664205a76a7de836ba83
MD5 (NEWS.3) = 307e75ba323c08b8694f916e45886aa4
MD5 (R-latest.tar.gz) = cfe520ea9fbca4f3c3d8462aaee7af46
MD5 (R-latest.tar.xz) = 7e8bce91f0ed90931cf9b73d6ac64aeb
MD5 (README) = f468f281c919665e276a1b691decbbe6
MD5 (RESOURCES) = a79b9b338cab09bd665f6b62ac6f455b
MD5 (THANKS) = 45b6d2e88a6ecb5b24fa33a781351cd5
MD5 (VERSION-INFO.dcf) = d52fde03caf726a4339a6079911a80e7
MD5 (R-4/R-4.4.1.tar.gz) = cfe520ea9fbca4f3c3d8462aaee7af46
MD5 (R-4/R-4.4.1.tar.xz) = 7e8bce91f0ed90931cf9b73d6ac64aeb

4cc9dcdfa46a2e2cff45c27df8f3a9f851ec97b44b8647ab8a9fbf844f37937f  AUTHORS
e6d6a009505e345fe949e1310334fcb0747f28dae2856759de102ab66b722cb4  COPYING
6095e9ffa777dd22839f7801aa845b31c9ed07f3d6bf8a26dc5d2dec8ccc0ef3  COPYING.LIB
f7703fe28f81edc79b4201665d69b5b41fda4241e832a03acaf7c2cafdf5f939  FAQ
f87461be6cbaecc4dce44ac58e5bd52364b0491ccdadaf846cb9b452e9550f31  INSTALL
59232c66854ee8e09f215a71f5a532ab23422a653a90196b5c1af744ce0c6053  NEWS
4e21b62f515b749f80997063fceab626d7258c7d650e81a662ba8e0640f12f62  NEWS.0
602f3a40ef759c7b2a6c485a33dc674af34249644ac5fb53b21283d4e12e808d  NEWS.1
cde079b6beab7d700d3d4ecda494e2681ad3b7f8fab13b68be090f949393ec62  NEWS.2
05f3f9fc664b845bb3dcc6492503860df72c63b3f179ab241c095e25bb7628f9  NEWS.3
b4cb675deaaeb7299d3b265d218cde43f192951ce5b89b7bb1a5148a36b2d94d  R-latest.tar.gz
fbd755314a5cc08c57aabff839ff791fb43a9052a2c6524ec3be96075fd34dde  R-latest.tar.xz
2fdd3e90f23f32692d4b3a0c0452f2c219a10882033d1774f8cadf25886c3ddc  README
8b7d3856100220f4555d4d57140829f2e81c27eccec5b441f5dce616e9ec9061  RESOURCES
8319c5415de58ee10d4bc058d79c370fd8e6b2ad09e25d7a1e04b74ca5f380a6  THANKS
74f11ad0053b5a7b2a3a8eccebcd58dfce69d61980b937966687710ab0d77dae  VERSION-INFO.dcf
b4cb675deaaeb7299d3b265d218cde43f192951ce5b89b7bb1a5148a36b2d94d  R-4/R-4.4.1.tar.gz
fbd755314a5cc08c57aabff839ff791fb43a9052a2c6524ec3be96075fd34dde  R-4/R-4.4.1.tar.xz


This is the relevant part of the NEWS file

CHANGES IN R 4.4.1:

  C-LEVEL FACILITIES:

    * Functions R_atof and R_strtod declared in header R_ext/Utils.h
      are now documented in 'Writing R Extensions' and so formally part
      of the API.

    * The non-API entry points Rf_setSVector, Rf_StringFalse,
      Rf_StringTrue and Rf_isBlankString have been added to those
      reported by R CMD check.

    * The new function Rf_allocLang is now available. This provides an
      alternative to the idiom of calling Rf_allocList followed by
      SET_TYPEOF.

  UTILITIES:

    * R CMD check now reports as warnings what gfortran calls 'Fortran
      2018 deleted features', all of which have long been marked as
      'obsolescent' and some of which were deleted in Fortran 2008 or
      earlier.  Fortran compilers are no longer required to support
      these.

  BUG FIXES:

    * as.numeric(), scan(), type.convert() and other places which use
      the internal C function R_strtod now require a _non-empty_ digit
      sequence in a decimal or binary exponent.  This aligns with the
      C/POSIX standard for strtod and with ?NumericConstants.

    * as.data.frame(m, make.names=NA) now works correctly for a matrix
      m with NA's in row names.

    * The error message from <POSIXlt>[["hour"]] and similar now
      mentions *[[, "hour"]], as wished for in PR#17409 and proposed by
      Michael Chirico.

    * qbinom() and potentially qpois(), qnbinom(), no longer sometimes
      fail accurate inversion (of pbinom(), etc), thanks to Christopher
      Chang's report and patch in PR#18711.

    * The internal help server on Windows can again serve requests sent
      in quick succession, fixing a regression in R 4.4.0.

    * debugcall(<S3Generic>()) now also works when a corresponding
      S4-generic version is in the methods cache (PR#18143).

    * Package tools' toTitleCase(ch0) now returns character(0) when ch0
      is of zero length; fixing PR#18724, reported by David Hugh Jones.

    * R CMD check is no longer broken (without a check result and no
      explanation in 00check.log) for a package which declares an
      invalid VignetteBuilder in DESCRIPTION but has no vignettes.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From pd@|gd @end|ng |rom gm@||@com  Fri Jun 14 11:45:32 2024
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Fri, 14 Jun 2024 11:45:32 +0200
Subject: [R] Column names of model.matrix's output with contrast.arg
In-Reply-To: <2F05BA60-78A6-4FE0-B8CD-14105A2F9BF8@gmail.com>
References: <2F05BA60-78A6-4FE0-B8CD-14105A2F9BF8@gmail.com>
Message-ID: <054F7F8A-5406-4A16-A434-43C13C109492@gmail.com>

You're at the mercy of the various contr.XXX functions. They may or may not set the colnames on the matrices that they generate. 

The rationales for (not) setting them is not perfectly transparent, but you obviously cannot use level names on contr.poly, so it uses .L, .Q, etc. 

In MASS, contr.sdif is careful about labeling the columns with the levels that are being diff'ed. 

For contr.treatment, there is a straightforward connection to 0/1 dummy variables, so level names there are natural.

One could use levels in contr.sum and contr.helmert, but it might confuse users that comparisons are with the average of all levels or preceding levels. (It can be quite confusing when coding is +1 for male and -1 for female, so that the gender difference is twice the coefficient.)

-pd

> On 14 Jun 2024, at 08:12 , Christophe Dutang <dutangc at gmail.com> wrote:
> 
> Dear list,
> 
> Changing the default contrasts used in glm() makes me aware how model.matrix() set column names.
> 
> With default contrasts, model.matrix() use the level values to name the columns. However with other contrasts, model.matrix() use the level indexes. In the documentation, I don?t see anything in the documentation related to this ? It does not seem natural to have such a behavior?
> 
> Any comment is welcome.
> 
> An example is below.
> 
> Kind regards, Christophe  
> 
> 
> #example from ?glm
> counts <- c(18,17,15,20,10,20,25,13,12)
> outcome <- paste0("O", gl(3,1,9))
> treatment <- paste0("T", gl(3,3))
> 
> X3 <- model.matrix(counts ~ outcome + treatment)
> X4 <- model.matrix(counts ~ outcome + treatment, contrasts = list("outcome"="contr.sum"))
> X5 <- model.matrix(counts ~ outcome + treatment, contrasts = list("outcome"="contr.helmert"))
> 
> #check with original factor
> cbind.data.frame(X3, outcome)
> cbind.data.frame(X4, outcome)
> cbind.data.frame(X5, outcome)
> 
> #same issue with glm
> glm.D93 <- glm(counts ~ outcome + treatment, family = poisson())
> glm.D94 <- glm(counts ~ outcome + treatment, family = poisson(), contrasts = list("outcome"="contr.sum"))
> glm.D95 <- glm(counts ~ outcome + treatment, family = poisson(), contrasts = list("outcome"="contr.helmert"))
> 
> coef(glm.D93)
> coef(glm.D94)
> coef(glm.D95)
> 
> #check linear predictor
> cbind(X3 %*% coef(glm.D93), predict(glm.D93))
> cbind(X4 %*% coef(glm.D94), predict(glm.D94))
> 
> -------------------------------------------------
> Christophe DUTANG
> LJK, Ensimag, Grenoble INP, UGA, France
> ILB research fellow
> Web: http://dutangc.free.fr
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng  Sat Jun 15 21:00:47 2024
From: j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng (Jibrin Alhassan)
Date: Sat, 15 Jun 2024 20:00:47 +0100
Subject: [R] code for year month day hr format
Message-ID: <CAEGeL+EDsd2LnZ0v5cY-0S7ofE_qxKi-QGV2+WnSzODywRZ9MQ@mail.gmail.com>

I have solar-geophysical data e.g as blow:
YEAR DOY HR   IMF  SW   SSN    Dst f10.7
2012 214  0   3.4  403. 132    -9 154.6
2012 214  1   3.7  388. 132   -10 154.6
2012 214  2   3.7  383. 132   -10 154.6
2012 214  3   3.7  391. 132    -9 154.6
2012 214  4   4.2  399. 132    -7 154.6
2012 214  5   4.1  411. 132    -6 154.6
2012 214  6   4.0  407. 132    -6 154.6
2012 214  7   4.2  404. 132    -4 154.6
2012 214  8   4.3  405. 132    -6 154.6
2012 214  9   4.4  409. 132    -6 154.6
2012 214 10   4.4  401. 132    -6 154.6
2012 214 11   4.5  385. 132    -7 154.6
2012 214 12   4.7  377. 132    -8 154.6
2012 214 13   4.7  382. 132    -6 154.6
2012 214 14   4.3  396. 132    -4 154.6
2012 214 15   4.1  384. 132    -2 154.6
2012 214 16   4.0  382. 132    -1 154.6
2012 214 17   3.9  397. 132     0 154.6
2012 214 18   3.8  390. 132     1 154.6
2012 214 19   4.2  400. 132     2 154.6
2012 214 20   4.6  408. 132     1 154.6
2012 214 21   4.8  401. 132    -3 154.6
2012 214 22   4.9  395. 132    -5 154.6
2012 214 23   5.0  386. 132    -1 154.6
2012 215  0   5.0  377. 143    -1 138.6
2012 215  1   4.9  384. 143    -2 138.6
2012 215  2   4.9  390. 143    -4 138.6
2012 215  3   4.9  372. 143    -6 138.6
2012 215  4   5.1  371. 143    -4 138.6
I want to process it to be of the format as shown below
 y   m  d  hr imf  sws  ssn    Dst f10.7
2012-08-01 10 3.4  403. 132    -9 154.6
2012-08-01 12 3.7  388. 132   -10 154.6
2012-08-01 15 3.7  383. 132   -10 154.6
2012-08-01 17 3.7  391. 132    -9 154.6
I want to request an R code to accomplish this task. Thanks for your time.
*Jibrin Adejoh Alhassan (Ph.D)*
Department of Physics and Astronomy,
University of Nigeria, Nsukka

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Jun 15 21:34:19 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 15 Jun 2024 20:34:19 +0100
Subject: [R] code for year month day hr format
In-Reply-To: <CAEGeL+EDsd2LnZ0v5cY-0S7ofE_qxKi-QGV2+WnSzODywRZ9MQ@mail.gmail.com>
References: <CAEGeL+EDsd2LnZ0v5cY-0S7ofE_qxKi-QGV2+WnSzODywRZ9MQ@mail.gmail.com>
Message-ID: <474f21f7-7a41-403f-826f-853f6589ec52@sapo.pt>

?s 20:00 de 15/06/2024, Jibrin Alhassan escreveu:
> I have solar-geophysical data e.g as blow:
> YEAR DOY HR   IMF  SW   SSN    Dst f10.7
> 2012 214  0   3.4  403. 132    -9 154.6
> 2012 214  1   3.7  388. 132   -10 154.6
> 2012 214  2   3.7  383. 132   -10 154.6
> 2012 214  3   3.7  391. 132    -9 154.6
> 2012 214  4   4.2  399. 132    -7 154.6
> 2012 214  5   4.1  411. 132    -6 154.6
> 2012 214  6   4.0  407. 132    -6 154.6
> 2012 214  7   4.2  404. 132    -4 154.6
> 2012 214  8   4.3  405. 132    -6 154.6
> 2012 214  9   4.4  409. 132    -6 154.6
> 2012 214 10   4.4  401. 132    -6 154.6
> 2012 214 11   4.5  385. 132    -7 154.6
> 2012 214 12   4.7  377. 132    -8 154.6
> 2012 214 13   4.7  382. 132    -6 154.6
> 2012 214 14   4.3  396. 132    -4 154.6
> 2012 214 15   4.1  384. 132    -2 154.6
> 2012 214 16   4.0  382. 132    -1 154.6
> 2012 214 17   3.9  397. 132     0 154.6
> 2012 214 18   3.8  390. 132     1 154.6
> 2012 214 19   4.2  400. 132     2 154.6
> 2012 214 20   4.6  408. 132     1 154.6
> 2012 214 21   4.8  401. 132    -3 154.6
> 2012 214 22   4.9  395. 132    -5 154.6
> 2012 214 23   5.0  386. 132    -1 154.6
> 2012 215  0   5.0  377. 143    -1 138.6
> 2012 215  1   4.9  384. 143    -2 138.6
> 2012 215  2   4.9  390. 143    -4 138.6
> 2012 215  3   4.9  372. 143    -6 138.6
> 2012 215  4   5.1  371. 143    -4 138.6
> I want to process it to be of the format as shown below
>   y   m  d  hr imf  sws  ssn    Dst f10.7
> 2012-08-01 10 3.4  403. 132    -9 154.6
> 2012-08-01 12 3.7  388. 132   -10 154.6
> 2012-08-01 15 3.7  383. 132   -10 154.6
> 2012-08-01 17 3.7  391. 132    -9 154.6
> I want to request an R code to accomplish this task. Thanks for your time.
> *Jibrin Adejoh Alhassan (Ph.D)*
> Department of Physics and Astronomy,
> University of Nigeria, Nsukka
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

To create a date column, paste the first two columns and coerce to class 
"Date" with conversion specifications %Y for the 4 digit year and %j for 
the day of year. See

help("strptime")



df1 <- read.table(text = "YEAR DOY HR   IMF  SW   SSN    Dst f10.7
2012 214  0   3.4  403. 132    -9 154.6
2012 214  1   3.7  388. 132   -10 154.6
2012 214  2   3.7  383. 132   -10 154.6
2012 214  3   3.7  391. 132    -9 154.6
2012 214  4   4.2  399. 132    -7 154.6
2012 214  5   4.1  411. 132    -6 154.6
2012 214  6   4.0  407. 132    -6 154.6
2012 214  7   4.2  404. 132    -4 154.6
2012 214  8   4.3  405. 132    -6 154.6
2012 214  9   4.4  409. 132    -6 154.6
2012 214 10   4.4  401. 132    -6 154.6
2012 214 11   4.5  385. 132    -7 154.6
2012 214 12   4.7  377. 132    -8 154.6
2012 214 13   4.7  382. 132    -6 154.6
2012 214 14   4.3  396. 132    -4 154.6
2012 214 15   4.1  384. 132    -2 154.6
2012 214 16   4.0  382. 132    -1 154.6
2012 214 17   3.9  397. 132     0 154.6
2012 214 18   3.8  390. 132     1 154.6
2012 214 19   4.2  400. 132     2 154.6
2012 214 20   4.6  408. 132     1 154.6
2012 214 21   4.8  401. 132    -3 154.6
2012 214 22   4.9  395. 132    -5 154.6
2012 214 23   5.0  386. 132    -1 154.6
2012 215  0   5.0  377. 143    -1 138.6
2012 215  1   4.9  384. 143    -2 138.6
2012 215  2   4.9  390. 143    -4 138.6
2012 215  3   4.9  372. 143    -6 138.6
2012 215  4   5.1  371. 143    -4 138.6", header = TRUE)


with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
#>  [1] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
#>  [6] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
#> [11] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
#> [16] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
#> [21] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-02"
#> [26] "2012-08-02" "2012-08-02" "2012-08-02" "2012-08-02"

# now create the column
df1$Date <- with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
# remove the columns no longer needed
df1 <- df1[-(1:2)]
# relocate the new date column
df1 <- df1[c(ncol(df1), 1:(ncol(df1) - 1L))]
head(df1)
#>         Date HR IMF  SW SSN Dst f10.7
#> 1 2012-08-01  0 3.4 403 132  -9 154.6
#> 2 2012-08-01  1 3.7 388 132 -10 154.6
#> 3 2012-08-01  2 3.7 383 132 -10 154.6
#> 4 2012-08-01  3 3.7 391 132  -9 154.6
#> 5 2012-08-01  4 4.2 399 132  -7 154.6
#> 6 2012-08-01  5 4.1 411 132  -6 154.6


Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From tebert @end|ng |rom u||@edu  Sat Jun 15 22:33:32 2024
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Sat, 15 Jun 2024 20:33:32 +0000
Subject: [R] code for year month day hr format
In-Reply-To: <CAEGeL+EDsd2LnZ0v5cY-0S7ofE_qxKi-QGV2+WnSzODywRZ9MQ@mail.gmail.com>
References: <CAEGeL+EDsd2LnZ0v5cY-0S7ofE_qxKi-QGV2+WnSzODywRZ9MQ@mail.gmail.com>
Message-ID: <CH3PR22MB451493E8EEB3071D33CBFF95CFC32@CH3PR22MB4514.namprd22.prod.outlook.com>

library(lubridate)
library(dplyr)
df1 <- read.table(text = "YEAR DOY HR   IMF  SW   SSN    Dst f10.7
2012 214  0   3.4  403. 132    -9 154.6
2012 214  1   3.7  388. 132   -10 154.6
2012 214  2   3.7  383. 132   -10 154.6
2012 214  3   3.7  391. 132    -9 154.6
2012 215  4   5.1  371. 143    -4 138.6", header = TRUE)

df_date <- df1 |>
  mutate(
    date_date = as.Date(DOY-1, origin=paste0(YEAR, "-01-01")),
    date_chr = format(date_date, "%Y-%m-%d")
  )
df_date <- df_date[,-c(1:2,9)]
df_date <- df_date[c(ncol(df_date), 1:(ncol(df_date) - 1L))]

# That is the form of the data in the example.
# But there may be a conflict in the column names versus the data shown where Y, M, and D were separate versus "Y_M_D" which would be the name of one column indicating the desired order.
# If you want Y, M, and D in different columns then this could work:
df_date2 <- df1 |>
  mutate(
    date_date = as.Date(DOY-1, origin=paste0(YEAR, "-01-01")),
    date_chr = format(date_date, "%Y-%m-%d")
  )
df_date2$M <- month(df_date2$date_date)
df_date2$D <- day(df_date2$date_date)
# drop unused columns
df_date2 <- df_date2[ , -c(2, 9, 10)]
# Reorganize columns to desired locations
df_date2 <- df_date2[, c("YEAR", "M", "D", "IMF", "SW", "SSN", "Dst", "f10.7")]
# Rename "Year" to "Y"
names(df_date2)[names(df_date2) == "YEAR"] <- "Y"


Tim
-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Jibrin Alhassan
Sent: Saturday, June 15, 2024 3:01 PM
To: R-help <R-help at r-project.org>
Subject: [R] code for year month day hr format

[External Email]

I have solar-geophysical data e.g as blow:
YEAR DOY HR   IMF  SW   SSN    Dst f10.7
2012 214  0   3.4  403. 132    -9 154.6
2012 214  1   3.7  388. 132   -10 154.6
2012 214  2   3.7  383. 132   -10 154.6
2012 214  3   3.7  391. 132    -9 154.6
2012 214  4   4.2  399. 132    -7 154.6
2012 214  5   4.1  411. 132    -6 154.6
2012 214  6   4.0  407. 132    -6 154.6
2012 214  7   4.2  404. 132    -4 154.6
2012 214  8   4.3  405. 132    -6 154.6
2012 214  9   4.4  409. 132    -6 154.6
2012 214 10   4.4  401. 132    -6 154.6
2012 214 11   4.5  385. 132    -7 154.6
2012 214 12   4.7  377. 132    -8 154.6
2012 214 13   4.7  382. 132    -6 154.6
2012 214 14   4.3  396. 132    -4 154.6
2012 214 15   4.1  384. 132    -2 154.6
2012 214 16   4.0  382. 132    -1 154.6
2012 214 17   3.9  397. 132     0 154.6
2012 214 18   3.8  390. 132     1 154.6
2012 214 19   4.2  400. 132     2 154.6
2012 214 20   4.6  408. 132     1 154.6
2012 214 21   4.8  401. 132    -3 154.6
2012 214 22   4.9  395. 132    -5 154.6
2012 214 23   5.0  386. 132    -1 154.6
2012 215  0   5.0  377. 143    -1 138.6
2012 215  1   4.9  384. 143    -2 138.6
2012 215  2   4.9  390. 143    -4 138.6
2012 215  3   4.9  372. 143    -6 138.6
2012 215  4   5.1  371. 143    -4 138.6
I want to process it to be of the format as shown below
 y   m  d  hr imf  sws  ssn    Dst f10.7
2012-08-01 10 3.4  403. 132    -9 154.6
2012-08-01 12 3.7  388. 132   -10 154.6
2012-08-01 15 3.7  383. 132   -10 154.6
2012-08-01 17 3.7  391. 132    -9 154.6
I want to request an R code to accomplish this task. Thanks for your time.
*Jibrin Adejoh Alhassan (Ph.D)*
Department of Physics and Astronomy,
University of Nigeria, Nsukka

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng  Sat Jun 15 22:42:45 2024
From: j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng (Jibrin Alhassan)
Date: Sat, 15 Jun 2024 21:42:45 +0100
Subject: [R] code for year month day hr format
In-Reply-To: <474f21f7-7a41-403f-826f-853f6589ec52@sapo.pt>
References: <CAEGeL+EDsd2LnZ0v5cY-0S7ofE_qxKi-QGV2+WnSzODywRZ9MQ@mail.gmail.com>
 <474f21f7-7a41-403f-826f-853f6589ec52@sapo.pt>
Message-ID: <CAEGeL+H_eukBiQKyDb1GOGo5K2kcyM7S6n167ukBWoGrQUgLyg@mail.gmail.com>

Thank you Rui. I ran the following script
df1 <- read.table("solar_hour", header = TRUE)
df1$date <- as.Date(paste(df1$year, df1$hour),
 format = "%Y %j",
origin = "2012-08-01-0")
df2 <- df1[c("date", "IMF", "SWS", "SSN", "Dst", "f10")]
head(df1)
#To display all the rows
 print(df2).
It gave me this error message
> source ("script.R")
Error in `$<-.data.frame`(`*tmp*`, date, value = numeric(0)) :
  replacement has 0 rows, data has 38735
> print(df2)
Error: object 'df2' not found
> My data is an hourly data but desire to have the date as
year    month    day   hour
2012   08         01     01
2012   08         01     02
2012   08        01      03 etc
Thanks.

*Jibrin Adejoh Alhassan (Ph.D)*
Department of Physics and Astronomy,
University of Nigeria, Nsukka


On Sat, Jun 15, 2024 at 8:34?PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> ?s 20:00 de 15/06/2024, Jibrin Alhassan escreveu:
> > I have solar-geophysical data e.g as blow:
> > YEAR DOY HR   IMF  SW   SSN    Dst f10.7
> > 2012 214  0   3.4  403. 132    -9 154.6
> > 2012 214  1   3.7  388. 132   -10 154.6
> > 2012 214  2   3.7  383. 132   -10 154.6
> > 2012 214  3   3.7  391. 132    -9 154.6
> > 2012 214  4   4.2  399. 132    -7 154.6
> > 2012 214  5   4.1  411. 132    -6 154.6
> > 2012 214  6   4.0  407. 132    -6 154.6
> > 2012 214  7   4.2  404. 132    -4 154.6
> > 2012 214  8   4.3  405. 132    -6 154.6
> > 2012 214  9   4.4  409. 132    -6 154.6
> > 2012 214 10   4.4  401. 132    -6 154.6
> > 2012 214 11   4.5  385. 132    -7 154.6
> > 2012 214 12   4.7  377. 132    -8 154.6
> > 2012 214 13   4.7  382. 132    -6 154.6
> > 2012 214 14   4.3  396. 132    -4 154.6
> > 2012 214 15   4.1  384. 132    -2 154.6
> > 2012 214 16   4.0  382. 132    -1 154.6
> > 2012 214 17   3.9  397. 132     0 154.6
> > 2012 214 18   3.8  390. 132     1 154.6
> > 2012 214 19   4.2  400. 132     2 154.6
> > 2012 214 20   4.6  408. 132     1 154.6
> > 2012 214 21   4.8  401. 132    -3 154.6
> > 2012 214 22   4.9  395. 132    -5 154.6
> > 2012 214 23   5.0  386. 132    -1 154.6
> > 2012 215  0   5.0  377. 143    -1 138.6
> > 2012 215  1   4.9  384. 143    -2 138.6
> > 2012 215  2   4.9  390. 143    -4 138.6
> > 2012 215  3   4.9  372. 143    -6 138.6
> > 2012 215  4   5.1  371. 143    -4 138.6
> > I want to process it to be of the format as shown below
> >   y   m  d  hr imf  sws  ssn    Dst f10.7
> > 2012-08-01 10 3.4  403. 132    -9 154.6
> > 2012-08-01 12 3.7  388. 132   -10 154.6
> > 2012-08-01 15 3.7  383. 132   -10 154.6
> > 2012-08-01 17 3.7  391. 132    -9 154.6
> > I want to request an R code to accomplish this task. Thanks for your
> time.
> > *Jibrin Adejoh Alhassan (Ph.D)*
> > Department of Physics and Astronomy,
> > University of Nigeria, Nsukka
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> Hello,
>
> To create a date column, paste the first two columns and coerce to class
> "Date" with conversion specifications %Y for the 4 digit year and %j for
> the day of year. See
>
> help("strptime")
>
>
>
> df1 <- read.table(text = "YEAR DOY HR   IMF  SW   SSN    Dst f10.7
> 2012 214  0   3.4  403. 132    -9 154.6
> 2012 214  1   3.7  388. 132   -10 154.6
> 2012 214  2   3.7  383. 132   -10 154.6
> 2012 214  3   3.7  391. 132    -9 154.6
> 2012 214  4   4.2  399. 132    -7 154.6
> 2012 214  5   4.1  411. 132    -6 154.6
> 2012 214  6   4.0  407. 132    -6 154.6
> 2012 214  7   4.2  404. 132    -4 154.6
> 2012 214  8   4.3  405. 132    -6 154.6
> 2012 214  9   4.4  409. 132    -6 154.6
> 2012 214 10   4.4  401. 132    -6 154.6
> 2012 214 11   4.5  385. 132    -7 154.6
> 2012 214 12   4.7  377. 132    -8 154.6
> 2012 214 13   4.7  382. 132    -6 154.6
> 2012 214 14   4.3  396. 132    -4 154.6
> 2012 214 15   4.1  384. 132    -2 154.6
> 2012 214 16   4.0  382. 132    -1 154.6
> 2012 214 17   3.9  397. 132     0 154.6
> 2012 214 18   3.8  390. 132     1 154.6
> 2012 214 19   4.2  400. 132     2 154.6
> 2012 214 20   4.6  408. 132     1 154.6
> 2012 214 21   4.8  401. 132    -3 154.6
> 2012 214 22   4.9  395. 132    -5 154.6
> 2012 214 23   5.0  386. 132    -1 154.6
> 2012 215  0   5.0  377. 143    -1 138.6
> 2012 215  1   4.9  384. 143    -2 138.6
> 2012 215  2   4.9  390. 143    -4 138.6
> 2012 215  3   4.9  372. 143    -6 138.6
> 2012 215  4   5.1  371. 143    -4 138.6", header = TRUE)
>
>
> with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
> #>  [1] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
> #>  [6] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
> #> [11] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
> #> [16] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
> #> [21] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-02"
> #> [26] "2012-08-02" "2012-08-02" "2012-08-02" "2012-08-02"
>
> # now create the column
> df1$Date <- with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
> # remove the columns no longer needed
> df1 <- df1[-(1:2)]
> # relocate the new date column
> df1 <- df1[c(ncol(df1), 1:(ncol(df1) - 1L))]
> head(df1)
> #>         Date HR IMF  SW SSN Dst f10.7
> #> 1 2012-08-01  0 3.4 403 132  -9 154.6
> #> 2 2012-08-01  1 3.7 388 132 -10 154.6
> #> 3 2012-08-01  2 3.7 383 132 -10 154.6
> #> 4 2012-08-01  3 3.7 391 132  -9 154.6
> #> 5 2012-08-01  4 4.2 399 132  -7 154.6
> #> 6 2012-08-01  5 4.1 411 132  -6 154.6
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> --
> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
> presen?a de v?rus.
> www.avg.com
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Jun 15 23:06:48 2024
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 15 Jun 2024 14:06:48 -0700
Subject: [R] code for year month day hr format
In-Reply-To: <CAEGeL+H_eukBiQKyDb1GOGo5K2kcyM7S6n167ukBWoGrQUgLyg@mail.gmail.com>
References: <CAEGeL+EDsd2LnZ0v5cY-0S7ofE_qxKi-QGV2+WnSzODywRZ9MQ@mail.gmail.com>
 <474f21f7-7a41-403f-826f-853f6589ec52@sapo.pt>
 <CAEGeL+H_eukBiQKyDb1GOGo5K2kcyM7S6n167ukBWoGrQUgLyg@mail.gmail.com>
Message-ID: <18839591-A56C-4E61-BD63-8E151DBE0158@dcn.davis.ca.us>

Please run your sequence of R statements one at a time so you can tell where the problem is. Only "run a script" after the code works one line at a time. There are too many places where things can go wrong otherwise.

Is your file being read in properly? Is the filename correct? was the header properly recognized?

I see something odd about the input you are providing to the "origin" argument to the as.Date function.

On June 15, 2024 1:42:45 PM PDT, Jibrin Alhassan <jibrin.alhassan at unn.edu.ng> wrote:
>Thank you Rui. I ran the following script
>df1 <- read.table("solar_hour", header = TRUE)
>df1$date <- as.Date(paste(df1$year, df1$hour),
> format = "%Y %j",
>origin = "2012-08-01-0")
>df2 <- df1[c("date", "IMF", "SWS", "SSN", "Dst", "f10")]
>head(df1)
>#To display all the rows
> print(df2).
>It gave me this error message
>> source ("script.R")
>Error in `$<-.data.frame`(`*tmp*`, date, value = numeric(0)) :
>  replacement has 0 rows, data has 38735
>> print(df2)
>Error: object 'df2' not found
>> My data is an hourly data but desire to have the date as
>year    month    day   hour
>2012   08         01     01
>2012   08         01     02
>2012   08        01      03 etc
>Thanks.
>
>*Jibrin Adejoh Alhassan (Ph.D)*
>Department of Physics and Astronomy,
>University of Nigeria, Nsukka
>
>
>On Sat, Jun 15, 2024 at 8:34?PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
>> ?s 20:00 de 15/06/2024, Jibrin Alhassan escreveu:
>> > I have solar-geophysical data e.g as blow:
>> > YEAR DOY HR   IMF  SW   SSN    Dst f10.7
>> > 2012 214  0   3.4  403. 132    -9 154.6
>> > 2012 214  1   3.7  388. 132   -10 154.6
>> > 2012 214  2   3.7  383. 132   -10 154.6
>> > 2012 214  3   3.7  391. 132    -9 154.6
>> > 2012 214  4   4.2  399. 132    -7 154.6
>> > 2012 214  5   4.1  411. 132    -6 154.6
>> > 2012 214  6   4.0  407. 132    -6 154.6
>> > 2012 214  7   4.2  404. 132    -4 154.6
>> > 2012 214  8   4.3  405. 132    -6 154.6
>> > 2012 214  9   4.4  409. 132    -6 154.6
>> > 2012 214 10   4.4  401. 132    -6 154.6
>> > 2012 214 11   4.5  385. 132    -7 154.6
>> > 2012 214 12   4.7  377. 132    -8 154.6
>> > 2012 214 13   4.7  382. 132    -6 154.6
>> > 2012 214 14   4.3  396. 132    -4 154.6
>> > 2012 214 15   4.1  384. 132    -2 154.6
>> > 2012 214 16   4.0  382. 132    -1 154.6
>> > 2012 214 17   3.9  397. 132     0 154.6
>> > 2012 214 18   3.8  390. 132     1 154.6
>> > 2012 214 19   4.2  400. 132     2 154.6
>> > 2012 214 20   4.6  408. 132     1 154.6
>> > 2012 214 21   4.8  401. 132    -3 154.6
>> > 2012 214 22   4.9  395. 132    -5 154.6
>> > 2012 214 23   5.0  386. 132    -1 154.6
>> > 2012 215  0   5.0  377. 143    -1 138.6
>> > 2012 215  1   4.9  384. 143    -2 138.6
>> > 2012 215  2   4.9  390. 143    -4 138.6
>> > 2012 215  3   4.9  372. 143    -6 138.6
>> > 2012 215  4   5.1  371. 143    -4 138.6
>> > I want to process it to be of the format as shown below
>> >   y   m  d  hr imf  sws  ssn    Dst f10.7
>> > 2012-08-01 10 3.4  403. 132    -9 154.6
>> > 2012-08-01 12 3.7  388. 132   -10 154.6
>> > 2012-08-01 15 3.7  383. 132   -10 154.6
>> > 2012-08-01 17 3.7  391. 132    -9 154.6
>> > I want to request an R code to accomplish this task. Thanks for your
>> time.
>> > *Jibrin Adejoh Alhassan (Ph.D)*
>> > Department of Physics and Astronomy,
>> > University of Nigeria, Nsukka
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> Hello,
>>
>> To create a date column, paste the first two columns and coerce to class
>> "Date" with conversion specifications %Y for the 4 digit year and %j for
>> the day of year. See
>>
>> help("strptime")
>>
>>
>>
>> df1 <- read.table(text = "YEAR DOY HR   IMF  SW   SSN    Dst f10.7
>> 2012 214  0   3.4  403. 132    -9 154.6
>> 2012 214  1   3.7  388. 132   -10 154.6
>> 2012 214  2   3.7  383. 132   -10 154.6
>> 2012 214  3   3.7  391. 132    -9 154.6
>> 2012 214  4   4.2  399. 132    -7 154.6
>> 2012 214  5   4.1  411. 132    -6 154.6
>> 2012 214  6   4.0  407. 132    -6 154.6
>> 2012 214  7   4.2  404. 132    -4 154.6
>> 2012 214  8   4.3  405. 132    -6 154.6
>> 2012 214  9   4.4  409. 132    -6 154.6
>> 2012 214 10   4.4  401. 132    -6 154.6
>> 2012 214 11   4.5  385. 132    -7 154.6
>> 2012 214 12   4.7  377. 132    -8 154.6
>> 2012 214 13   4.7  382. 132    -6 154.6
>> 2012 214 14   4.3  396. 132    -4 154.6
>> 2012 214 15   4.1  384. 132    -2 154.6
>> 2012 214 16   4.0  382. 132    -1 154.6
>> 2012 214 17   3.9  397. 132     0 154.6
>> 2012 214 18   3.8  390. 132     1 154.6
>> 2012 214 19   4.2  400. 132     2 154.6
>> 2012 214 20   4.6  408. 132     1 154.6
>> 2012 214 21   4.8  401. 132    -3 154.6
>> 2012 214 22   4.9  395. 132    -5 154.6
>> 2012 214 23   5.0  386. 132    -1 154.6
>> 2012 215  0   5.0  377. 143    -1 138.6
>> 2012 215  1   4.9  384. 143    -2 138.6
>> 2012 215  2   4.9  390. 143    -4 138.6
>> 2012 215  3   4.9  372. 143    -6 138.6
>> 2012 215  4   5.1  371. 143    -4 138.6", header = TRUE)
>>
>>
>> with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
>> #>  [1] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>> #>  [6] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>> #> [11] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>> #> [16] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>> #> [21] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-02"
>> #> [26] "2012-08-02" "2012-08-02" "2012-08-02" "2012-08-02"
>>
>> # now create the column
>> df1$Date <- with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
>> # remove the columns no longer needed
>> df1 <- df1[-(1:2)]
>> # relocate the new date column
>> df1 <- df1[c(ncol(df1), 1:(ncol(df1) - 1L))]
>> head(df1)
>> #>         Date HR IMF  SW SSN Dst f10.7
>> #> 1 2012-08-01  0 3.4 403 132  -9 154.6
>> #> 2 2012-08-01  1 3.7 388 132 -10 154.6
>> #> 3 2012-08-01  2 3.7 383 132 -10 154.6
>> #> 4 2012-08-01  3 3.7 391 132  -9 154.6
>> #> 5 2012-08-01  4 4.2 399 132  -7 154.6
>> #> 6 2012-08-01  5 4.1 411 132  -6 154.6
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>> --
>> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
>> presen?a de v?rus.
>> www.avg.com
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Jun 16 09:33:03 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 16 Jun 2024 08:33:03 +0100
Subject: [R] code for year month day hr format
In-Reply-To: <CAEGeL+H_eukBiQKyDb1GOGo5K2kcyM7S6n167ukBWoGrQUgLyg@mail.gmail.com>
References: <CAEGeL+EDsd2LnZ0v5cY-0S7ofE_qxKi-QGV2+WnSzODywRZ9MQ@mail.gmail.com>
 <474f21f7-7a41-403f-826f-853f6589ec52@sapo.pt>
 <CAEGeL+H_eukBiQKyDb1GOGo5K2kcyM7S6n167ukBWoGrQUgLyg@mail.gmail.com>
Message-ID: <9347708a-d116-4879-8809-e2b5abadff25@sapo.pt>

?s 21:42 de 15/06/2024, Jibrin Alhassan escreveu:
> Thank you Rui. I ran the following script
> df1 <- read.table("solar_hour", header = TRUE)
> df1$date <- as.Date(paste(df1$year, df1$hour),
>   format = "%Y %j",
> origin = "2012-08-01-0")
> df2 <- df1[c("date", "IMF", "SWS", "SSN", "Dst", "f10")]
> head(df1)
> #To display all the rows
>   print(df2).
> It gave me this error message
>> source ("script.R")
> Error in `$<-.data.frame`(`*tmp*`, date, value = numeric(0)) :
>    replacement has 0 rows, data has 38735
>> print(df2)
> Error: object 'df2' not found
>> My data is an hourly data but desire to have the date as
> year    month    day   hour
> 2012   08         01     01
> 2012   08         01     02
> 2012   08        01      03 etc
> Thanks.
> 
> *Jibrin Adejoh Alhassan (Ph.D)*
> Department of Physics and Astronomy,
> University of Nigeria, Nsukka
> 
> 
> On Sat, Jun 15, 2024 at 8:34?PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
> 
>> ?s 20:00 de 15/06/2024, Jibrin Alhassan escreveu:
>>> I have solar-geophysical data e.g as blow:
>>> YEAR DOY HR   IMF  SW   SSN    Dst f10.7
>>> 2012 214  0   3.4  403. 132    -9 154.6
>>> 2012 214  1   3.7  388. 132   -10 154.6
>>> 2012 214  2   3.7  383. 132   -10 154.6
>>> 2012 214  3   3.7  391. 132    -9 154.6
>>> 2012 214  4   4.2  399. 132    -7 154.6
>>> 2012 214  5   4.1  411. 132    -6 154.6
>>> 2012 214  6   4.0  407. 132    -6 154.6
>>> 2012 214  7   4.2  404. 132    -4 154.6
>>> 2012 214  8   4.3  405. 132    -6 154.6
>>> 2012 214  9   4.4  409. 132    -6 154.6
>>> 2012 214 10   4.4  401. 132    -6 154.6
>>> 2012 214 11   4.5  385. 132    -7 154.6
>>> 2012 214 12   4.7  377. 132    -8 154.6
>>> 2012 214 13   4.7  382. 132    -6 154.6
>>> 2012 214 14   4.3  396. 132    -4 154.6
>>> 2012 214 15   4.1  384. 132    -2 154.6
>>> 2012 214 16   4.0  382. 132    -1 154.6
>>> 2012 214 17   3.9  397. 132     0 154.6
>>> 2012 214 18   3.8  390. 132     1 154.6
>>> 2012 214 19   4.2  400. 132     2 154.6
>>> 2012 214 20   4.6  408. 132     1 154.6
>>> 2012 214 21   4.8  401. 132    -3 154.6
>>> 2012 214 22   4.9  395. 132    -5 154.6
>>> 2012 214 23   5.0  386. 132    -1 154.6
>>> 2012 215  0   5.0  377. 143    -1 138.6
>>> 2012 215  1   4.9  384. 143    -2 138.6
>>> 2012 215  2   4.9  390. 143    -4 138.6
>>> 2012 215  3   4.9  372. 143    -6 138.6
>>> 2012 215  4   5.1  371. 143    -4 138.6
>>> I want to process it to be of the format as shown below
>>>    y   m  d  hr imf  sws  ssn    Dst f10.7
>>> 2012-08-01 10 3.4  403. 132    -9 154.6
>>> 2012-08-01 12 3.7  388. 132   -10 154.6
>>> 2012-08-01 15 3.7  383. 132   -10 154.6
>>> 2012-08-01 17 3.7  391. 132    -9 154.6
>>> I want to request an R code to accomplish this task. Thanks for your
>> time.
>>> *Jibrin Adejoh Alhassan (Ph.D)*
>>> Department of Physics and Astronomy,
>>> University of Nigeria, Nsukka
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> Hello,
>>
>> To create a date column, paste the first two columns and coerce to class
>> "Date" with conversion specifications %Y for the 4 digit year and %j for
>> the day of year. See
>>
>> help("strptime")
>>
>>
>>
>> df1 <- read.table(text = "YEAR DOY HR   IMF  SW   SSN    Dst f10.7
>> 2012 214  0   3.4  403. 132    -9 154.6
>> 2012 214  1   3.7  388. 132   -10 154.6
>> 2012 214  2   3.7  383. 132   -10 154.6
>> 2012 214  3   3.7  391. 132    -9 154.6
>> 2012 214  4   4.2  399. 132    -7 154.6
>> 2012 214  5   4.1  411. 132    -6 154.6
>> 2012 214  6   4.0  407. 132    -6 154.6
>> 2012 214  7   4.2  404. 132    -4 154.6
>> 2012 214  8   4.3  405. 132    -6 154.6
>> 2012 214  9   4.4  409. 132    -6 154.6
>> 2012 214 10   4.4  401. 132    -6 154.6
>> 2012 214 11   4.5  385. 132    -7 154.6
>> 2012 214 12   4.7  377. 132    -8 154.6
>> 2012 214 13   4.7  382. 132    -6 154.6
>> 2012 214 14   4.3  396. 132    -4 154.6
>> 2012 214 15   4.1  384. 132    -2 154.6
>> 2012 214 16   4.0  382. 132    -1 154.6
>> 2012 214 17   3.9  397. 132     0 154.6
>> 2012 214 18   3.8  390. 132     1 154.6
>> 2012 214 19   4.2  400. 132     2 154.6
>> 2012 214 20   4.6  408. 132     1 154.6
>> 2012 214 21   4.8  401. 132    -3 154.6
>> 2012 214 22   4.9  395. 132    -5 154.6
>> 2012 214 23   5.0  386. 132    -1 154.6
>> 2012 215  0   5.0  377. 143    -1 138.6
>> 2012 215  1   4.9  384. 143    -2 138.6
>> 2012 215  2   4.9  390. 143    -4 138.6
>> 2012 215  3   4.9  372. 143    -6 138.6
>> 2012 215  4   5.1  371. 143    -4 138.6", header = TRUE)
>>
>>
>> with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
>> #>  [1] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>> #>  [6] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>> #> [11] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>> #> [16] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>> #> [21] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-02"
>> #> [26] "2012-08-02" "2012-08-02" "2012-08-02" "2012-08-02"
>>
>> # now create the column
>> df1$Date <- with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
>> # remove the columns no longer needed
>> df1 <- df1[-(1:2)]
>> # relocate the new date column
>> df1 <- df1[c(ncol(df1), 1:(ncol(df1) - 1L))]
>> head(df1)
>> #>         Date HR IMF  SW SSN Dst f10.7
>> #> 1 2012-08-01  0 3.4 403 132  -9 154.6
>> #> 2 2012-08-01  1 3.7 388 132 -10 154.6
>> #> 3 2012-08-01  2 3.7 383 132 -10 154.6
>> #> 4 2012-08-01  3 3.7 391 132  -9 154.6
>> #> 5 2012-08-01  4 4.2 399 132  -7 154.6
>> #> 6 2012-08-01  5 4.1 411 132  -6 154.6
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>> --
>> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
>> presen?a de v?rus.
>> www.avg.com
>>
> 
Hello,

There is an error in your new code:


paste YEAR with DOY, not with HR.


As for the rest, is your real data like the one you posted before?
If it is then I don't see anything wrong with my (tested) solution.


Hope this helps,

Rui Barradas



-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From ro||turner @end|ng |rom po@teo@net  Sun Jun 16 12:37:56 2024
From: ro||turner @end|ng |rom po@teo@net (Rolf Turner)
Date: Sun, 16 Jun 2024 10:37:56 +0000
Subject: [R] code for year month day hr format
In-Reply-To: <9347708a-d116-4879-8809-e2b5abadff25@sapo.pt>
References: <CAEGeL+EDsd2LnZ0v5cY-0S7ofE_qxKi-QGV2+WnSzODywRZ9MQ@mail.gmail.com>
 <474f21f7-7a41-403f-826f-853f6589ec52@sapo.pt>
 <CAEGeL+H_eukBiQKyDb1GOGo5K2kcyM7S6n167ukBWoGrQUgLyg@mail.gmail.com>
 <9347708a-d116-4879-8809-e2b5abadff25@sapo.pt>
Message-ID: <20240616223756.37f98a3b@elderly-dell>


On Sun, 16 Jun 2024 08:33:03 +0100
Rui Barradas <ruipbarradas at sapo.pt> wrote:

<SNIP>

> Hello,
> 
> There is an error in your new code:
> 
> 
> paste YEAR with DOY, not with HR.
> 
> 
> As for the rest, is your real data like the one you posted before?
> If it is then I don't see anything wrong with my (tested) solution.
> 
> 
> Hope this helps,
> 
> Rui Barradas

I never cease to be impressed and indeed amazed by Rui's apparently
inexhaustible patience.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Stats. Dep't. (secretaries) phone:
         +64-9-373-7599 ext. 89622
Home phone: +64-9-480-4619


From |@urentRHe|p @end|ng |rom |ree@|r  Sun Jun 16 17:27:34 2024
From: |@urentRHe|p @end|ng |rom |ree@|r (Laurent Rhelp)
Date: Sun, 16 Jun 2024 17:27:34 +0200
Subject: [R] slowness when I use a list comprehension
Message-ID: <9e2ac30f-7b4e-4db7-a56d-b40f51d65c0e@free.fr>

Dear RHelp-list,

 ?? I try to use the package comprehenr to replace a for loop by a list 
comprehension.

 ?I wrote the code but I certainly miss something because it is very 
slower compared to the for loops. May you please explain to me why the 
list comprehension is slower in my case.

Here is my example. I do the calculation of the square difference 
between the values of two vectors vec1 and vec2, the ratio sampling 
between vec1 and vec2 is equal to ratio_sampling. I have to use only the 
500th value of the first serie before doing the difference with the 
value of the second serie (vec2).

Thank you

Best regards

Laurent

library(tictoc)
library(comprehenr)

ratio_sampling <- 500
## size of the first serie
N1 <- 70000
## size of the second serie
N2 <- 100
## mock data
set.seed(123)
vec1 <- rnorm(N1)
vec2 <- runif(N2)


## 1. with the "for" loops

## the square differences will be stored in a vector
S_diff2 <- numeric((N1-(N2-1)*ratio_sampling))
tic()
for( j in 1:length(S_diff2)){
 ? sum_squares <- 0
 ? for( i in 1:length(vec2)){
 ??? sum_squares = sum_squares + ((vec1[(i-1)*ratio_sampling+j] - 
vec2[i])**2)
 ? }
 ? S_diff2[j] <- sum_squares
}
toc()
## 0.22 sec elapsed
which.max(S_diff2)
## 7857

## 2. with the lists comprehension
tic()
S_diff2 <- to_vec(for( j in 1:length(S_diff2)) sum(to_vec(for( i in 
1:length(vec2)) ((vec1[(i-1)*ratio_sampling+j] - vec2[i])**2))))
toc()
## 25.09 sec elapsed
which.max(S_diff2)
## 7857


From @vi@e@gross m@iii@g oii gm@ii@com  Sun Jun 16 18:33:54 2024
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Sun, 16 Jun 2024 12:33:54 -0400
Subject: [R] slowness when I use a list comprehension
In-Reply-To: <9e2ac30f-7b4e-4db7-a56d-b40f51d65c0e@free.fr>
References: <9e2ac30f-7b4e-4db7-a56d-b40f51d65c0e@free.fr>
Message-ID: <006c01dac00a$fa8e59d0$efab0d70$@gmail.com>

Laurent,

Thank you for introducing me to a package I did not know existed as I use features like list comprehension in python all the time and could see using it in R now that I know it is available.

As to why you see your example as slow, I see you used a fairly complex and nested expression and wonder if it was a better way to go. As you are dealing with an interpreter doing delayed evaluation, I can imagine reasons it can be slow. But note the package comprehenr may not be designed to be more efficient than loops or of the more built-in functional methods that can be faster. The package is there perhaps more as a compatibility helper that allows you to write closer to the python style and perhaps re-shapes what you wrote into a set of instructions in more native R.

Just for comparison, in python, things like comprehensions for list or dictionaries or tuples often are syntactic sugar and the interpreter may simply rewrite them more like the first program you typed and evaluates that. The comprehensions are more designed for users who can think another way and write things more compactly as one-liners. Depending on implementations, they may be faster or slower on some examples.

I am not saying there is nothing else that is slowing it down for you. I am suggesting that using the feature as currently implemented may not be an advantage except in your thought process. It may be it could be improved, such as by replacing more functionality out of R and into compiled languages as has been done for many packages.

Avi

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Laurent Rhelp
Sent: Sunday, June 16, 2024 11:28 AM
To: r-help at r-project.org
Subject: [R] slowness when I use a list comprehension

Dear RHelp-list,

    I try to use the package comprehenr to replace a for loop by a list 
comprehension.

  I wrote the code but I certainly miss something because it is very 
slower compared to the for loops. May you please explain to me why the 
list comprehension is slower in my case.

Here is my example. I do the calculation of the square difference 
between the values of two vectors vec1 and vec2, the ratio sampling 
between vec1 and vec2 is equal to ratio_sampling. I have to use only the 
500th value of the first serie before doing the difference with the 
value of the second serie (vec2).

Thank you

Best regards

Laurent

library(tictoc)
library(comprehenr)

ratio_sampling <- 500
## size of the first serie
N1 <- 70000
## size of the second serie
N2 <- 100
## mock data
set.seed(123)
vec1 <- rnorm(N1)
vec2 <- runif(N2)


## 1. with the "for" loops

## the square differences will be stored in a vector
S_diff2 <- numeric((N1-(N2-1)*ratio_sampling))
tic()
for( j in 1:length(S_diff2)){
   sum_squares <- 0
   for( i in 1:length(vec2)){
     sum_squares = sum_squares + ((vec1[(i-1)*ratio_sampling+j] - 
vec2[i])**2)
   }
   S_diff2[j] <- sum_squares
}
toc()
## 0.22 sec elapsed
which.max(S_diff2)
## 7857

## 2. with the lists comprehension
tic()
S_diff2 <- to_vec(for( j in 1:length(S_diff2)) sum(to_vec(for( i in 
1:length(vec2)) ((vec1[(i-1)*ratio_sampling+j] - vec2[i])**2))))
toc()
## 25.09 sec elapsed
which.max(S_diff2)
## 7857

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Jun 16 19:12:59 2024
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 16 Jun 2024 10:12:59 -0700
Subject: [R] slowness when I use a list comprehension
In-Reply-To: <006c01dac00a$fa8e59d0$efab0d70$@gmail.com>
References: <9e2ac30f-7b4e-4db7-a56d-b40f51d65c0e@free.fr>
 <006c01dac00a$fa8e59d0$efab0d70$@gmail.com>
Message-ID: <56692691-6412-43FB-B637-3B83DAA406F4@dcn.davis.ca.us>

I would be more strong on this advice: learn to think in R, rather than thinking in Python, when programming in R. R has atomic vectors... Python does not (until you import a package that implements them). I find that while it is possible to import R thinking into Python, Python programmers seem to object for stylistic reasons even though such thinking speeds up Python also.

A key step in that direction is to stop using lists directly for numeric calculations... use them to manage numeric vactors. In some cases you can switch to matrices or arrays to remove even more list manipulations from the script.

library(microbenchmark)

ratio_sampling <- 500
## size of the first serie
N1 <- 70000
## size of the second serie
N2 <- 100
## mock data
set.seed(123)
vec1 <- rnorm(N1)
vec2 <- runif(N2)

dloop <- function( N1, M2, ratio_sampling, vec1, vec2 ) {
  S_diff2 <- numeric(
    N1-(N2-1)*ratio_sampling
  )
  for( j in 1:length(S_diff2) ) {
    sum_squares <- 0
    for( i in 1:length(vec2)){
      sum_squares <- (
        sum_squares
        + (
          vec1[ (i-1)*ratio_sampling+j ]
          - vec2[i]
        )**2
      )
    }
    S_diff2[j] <- sum_squares
  }
  S_diff2
}

vloop <- function( N1, M2, ratio_sampling, vec1, vec2 ) {
  S_diff3 <- numeric(
    N1-(N2-1)*ratio_sampling
  )
  i <- seq_along( vec2 )
  k <- (i-1)*ratio_sampling
  for( j in seq_along( S_diff3 ) ) {
    S_diff3[j] <- sum(
      (
        vec1[ j + k ]
        - vec2
      )^2
    )
  }
  S_diff3
}

microbenchmark(
  S_diff2 <- dloop( N1, M2, ratio_sampling, vec1, vec2 )
  , S_diff3 <- vloop( N1, M2, ratio_sampling, vec1, vec2 )
  , times = 20
)

all.equal( S_diff2, S_diff3 )


On June 16, 2024 9:33:54 AM PDT, avi.e.gross at gmail.com wrote:
>Laurent,
>
>Thank you for introducing me to a package I did not know existed as I use features like list comprehension in python all the time and could see using it in R now that I know it is available.
>
>As to why you see your example as slow, I see you used a fairly complex and nested expression and wonder if it was a better way to go. As you are dealing with an interpreter doing delayed evaluation, I can imagine reasons it can be slow. But note the package comprehenr may not be designed to be more efficient than loops or of the more built-in functional methods that can be faster. The package is there perhaps more as a compatibility helper that allows you to write closer to the python style and perhaps re-shapes what you wrote into a set of instructions in more native R.
>
>Just for comparison, in python, things like comprehensions for list or dictionaries or tuples often are syntactic sugar and the interpreter may simply rewrite them more like the first program you typed and evaluates that. The comprehensions are more designed for users who can think another way and write things more compactly as one-liners. Depending on implementations, they may be faster or slower on some examples.
>
>I am not saying there is nothing else that is slowing it down for you. I am suggesting that using the feature as currently implemented may not be an advantage except in your thought process. It may be it could be improved, such as by replacing more functionality out of R and into compiled languages as has been done for many packages.
>
>Avi
>
>-----Original Message-----
>From: R-help <r-help-bounces at r-project.org> On Behalf Of Laurent Rhelp
>Sent: Sunday, June 16, 2024 11:28 AM
>To: r-help at r-project.org
>Subject: [R] slowness when I use a list comprehension
>
>Dear RHelp-list,
>
>    I try to use the package comprehenr to replace a for loop by a list 
>comprehension.
>
>  I wrote the code but I certainly miss something because it is very 
>slower compared to the for loops. May you please explain to me why the 
>list comprehension is slower in my case.
>
>Here is my example. I do the calculation of the square difference 
>between the values of two vectors vec1 and vec2, the ratio sampling 
>between vec1 and vec2 is equal to ratio_sampling. I have to use only the 
>500th value of the first serie before doing the difference with the 
>value of the second serie (vec2).
>
>Thank you
>
>Best regards
>
>Laurent
>
>library(tictoc)
>library(comprehenr)
>
>ratio_sampling <- 500
>## size of the first serie
>N1 <- 70000
>## size of the second serie
>N2 <- 100
>## mock data
>set.seed(123)
>vec1 <- rnorm(N1)
>vec2 <- runif(N2)
>
>
>## 1. with the "for" loops
>
>## the square differences will be stored in a vector
>S_diff2 <- numeric((N1-(N2-1)*ratio_sampling))
>tic()
>for( j in 1:length(S_diff2)){
>   sum_squares <- 0
>   for( i in 1:length(vec2)){
>     sum_squares = sum_squares + ((vec1[(i-1)*ratio_sampling+j] - 
>vec2[i])**2)
>   }
>   S_diff2[j] <- sum_squares
>}
>toc()
>## 0.22 sec elapsed
>which.max(S_diff2)
>## 7857
>
>## 2. with the lists comprehension
>tic()
>S_diff2 <- to_vec(for( j in 1:length(S_diff2)) sum(to_vec(for( i in 
>1:length(vec2)) ((vec1[(i-1)*ratio_sampling+j] - vec2[i])**2))))
>toc()
>## 25.09 sec elapsed
>which.max(S_diff2)
>## 7857
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @vi@e@gross m@iii@g oii gm@ii@com  Sun Jun 16 19:44:47 2024
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Sun, 16 Jun 2024 13:44:47 -0400
Subject: [R] slowness when I use a list comprehension
In-Reply-To: <56692691-6412-43FB-B637-3B83DAA406F4@dcn.davis.ca.us>
References: <9e2ac30f-7b4e-4db7-a56d-b40f51d65c0e@free.fr>
 <006c01dac00a$fa8e59d0$efab0d70$@gmail.com>
 <56692691-6412-43FB-B637-3B83DAA406F4@dcn.davis.ca.us>
Message-ID: <008201dac014$e1d73fb0$a585bf10$@gmail.com>

I fully agree with Jeff that the best way to use ANY language is to evaluate
the language in terms of not just the capabilities it offers but also the
philosophy behind what it was created for and how people do things and just
grok it and use it mostly in the way intended. I do that with all the
languages I learn, whether for computers or humans.

Bringing in something you like from another language often gets in the way
of actually using what you have. But realistically, many languages that were
designed for one purpose will then evolve to suit many other purposes and
lose their direction and often their focus and even efficiency. S was
designed for statistical computing of some sorts and that meant a vectorized
approach could take you far. Python had other design goals and the original
designers wanted elements of genrality that a list provides more than a
vector does. R has lists too, but note if you want to use the kind of
dictionary or set used in python, which definitely can have advanatages and
disadvantages, you can find add-ons in R packages that give you something
like that too. And, note, many, myself included, really appreciate alternate
ways to do things and heavily use tidyverse packages that mostly are not
base R but sort of a grafted-on other language. So what? Purists don't
necessarily do well in the real world.

On the topic at hand and speed, I went an looked at the comprehenr package
and it is no wonder it is slower.

Here is the code Laurent used in calling to_vec:

> to_vec
function (expr, recursive = TRUE, use.names = FALSE) 
{
    res = eval.parent(substitute(comprehenr::to_list(expr)))
    unlist(res, recursive = recursive, use.names = use.names)
}'

It does a few things and then calls to_list() to do the actual work. This
extra layer may slow it down a tad.

So what does to_list() do?

> to_list
function (expr) 
{
    expr = substitute(expr)
    is_loop(expr) || stop(paste("argument should be expression with 'for',
'while' or 'repeat' but we have: ", 
        deparse(expr, width.cutoff = 500)[1]))
    expr = expand_loop_variables(expr)
    expr = add_assignment_to_final_loops(expr)
    expr = substitute(local({
        .___res <- list()
        .___counter <- 0
        expr
        .___res
    }))
    eval.parent(expr)
}

I won't follow the entire chain, but it seems to take the code supplied and
isolate various parts needed and, in effect, build up some other code and
evaluates it in the context of the parent.

Obviously, had you written similar (or different using loops or whatever)
code directly, it might execute faster.

As I mentioned, this is largely syntactic sugar. A reasonable use of this is
if you are given python code and asked to translate it into R code that does
the same thing. You could spend time thinking and designing and come up with
the kind of R code an R expert might have done, or skip that and just make
slight changes needed for R and for the package being used and it should
work, but not necessarily the way a native polished version works. Later, if
time and finances permit, and you want it faster, rewrite it.

I note the package, with a vignetter here:
https://cran.r-project.org/web//packages/comprehenr/vignettes/Introduction.h
tml

Does make some changes so translating is not trivial. For example, the
python syntax such as:

[ f(x) for x in iterable if condition]

Is not able to be used in quite that order. It loosely translates to:

to_vec(for x in iterable if condition f(x))

with the result at the end rather than beginning. And, since R has not
chosen to return multiple things from a function like python does and just
unpack them, they had to come up with interesting workarounds like `x, y`
and frankly, quite a few things I can do in python in this context are
simply not supported by this code, nor can be expected to.

I think if someone using python was used to using the extended version by
loading modules like numpy and pandas and using them heavily, they might
find it a tad easier to then port the code to R and use vectorized
functionality better.

So, are packages like comprehend a crutch or are they helpful or even evil?
My view is to not be a religious fanatic and assume any language was really
designed perfectly. Some ideas and implementations can be a useful way to
formulate a problem for a programmer who thinks in that way, at least until
they learn to also think in another. An example would be the R way to do
sets is probably not as useful as the python way. If I needed heavy duty
usage, I might load a package that lets me think about it the way I want,
and the same for a dictionary.

But, if I am writing code for others to maintain and change later, the
closer I stick to the main language or accepted packages, the better.

 

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Newmiller via
R-help
Sent: Sunday, June 16, 2024 1:13 PM
To: r-help at r-project.org
Subject: Re: [R] slowness when I use a list comprehension

I would be more strong on this advice: learn to think in R, rather than
thinking in Python, when programming in R. R has atomic vectors... Python
does not (until you import a package that implements them). I find that
while it is possible to import R thinking into Python, Python programmers
seem to object for stylistic reasons even though such thinking speeds up
Python also.

A key step in that direction is to stop using lists directly for numeric
calculations... use them to manage numeric vactors. In some cases you can
switch to matrices or arrays to remove even more list manipulations from the
script.

library(microbenchmark)

ratio_sampling <- 500
## size of the first serie
N1 <- 70000
## size of the second serie
N2 <- 100
## mock data
set.seed(123)
vec1 <- rnorm(N1)
vec2 <- runif(N2)

dloop <- function( N1, M2, ratio_sampling, vec1, vec2 ) {
  S_diff2 <- numeric(
    N1-(N2-1)*ratio_sampling
  )
  for( j in 1:length(S_diff2) ) {
    sum_squares <- 0
    for( i in 1:length(vec2)){
      sum_squares <- (
        sum_squares
        + (
          vec1[ (i-1)*ratio_sampling+j ]
          - vec2[i]
        )**2
      )
    }
    S_diff2[j] <- sum_squares
  }
  S_diff2
}

vloop <- function( N1, M2, ratio_sampling, vec1, vec2 ) {
  S_diff3 <- numeric(
    N1-(N2-1)*ratio_sampling
  )
  i <- seq_along( vec2 )
  k <- (i-1)*ratio_sampling
  for( j in seq_along( S_diff3 ) ) {
    S_diff3[j] <- sum(
      (
        vec1[ j + k ]
        - vec2
      )^2
    )
  }
  S_diff3
}

microbenchmark(
  S_diff2 <- dloop( N1, M2, ratio_sampling, vec1, vec2 )
  , S_diff3 <- vloop( N1, M2, ratio_sampling, vec1, vec2 )
  , times = 20
)

all.equal( S_diff2, S_diff3 )


On June 16, 2024 9:33:54 AM PDT, avi.e.gross at gmail.com wrote:
>Laurent,
>
>Thank you for introducing me to a package I did not know existed as I use
features like list comprehension in python all the time and could see using
it in R now that I know it is available.
>
>As to why you see your example as slow, I see you used a fairly complex and
nested expression and wonder if it was a better way to go. As you are
dealing with an interpreter doing delayed evaluation, I can imagine reasons
it can be slow. But note the package comprehenr may not be designed to be
more efficient than loops or of the more built-in functional methods that
can be faster. The package is there perhaps more as a compatibility helper
that allows you to write closer to the python style and perhaps re-shapes
what you wrote into a set of instructions in more native R.
>
>Just for comparison, in python, things like comprehensions for list or
dictionaries or tuples often are syntactic sugar and the interpreter may
simply rewrite them more like the first program you typed and evaluates
that. The comprehensions are more designed for users who can think another
way and write things more compactly as one-liners. Depending on
implementations, they may be faster or slower on some examples.
>
>I am not saying there is nothing else that is slowing it down for you. I am
suggesting that using the feature as currently implemented may not be an
advantage except in your thought process. It may be it could be improved,
such as by replacing more functionality out of R and into compiled languages
as has been done for many packages.
>
>Avi
>
>-----Original Message-----
>From: R-help <r-help-bounces at r-project.org> On Behalf Of Laurent Rhelp
>Sent: Sunday, June 16, 2024 11:28 AM
>To: r-help at r-project.org
>Subject: [R] slowness when I use a list comprehension
>
>Dear RHelp-list,
>
>    I try to use the package comprehenr to replace a for loop by a list 
>comprehension.
>
>  I wrote the code but I certainly miss something because it is very 
>slower compared to the for loops. May you please explain to me why the 
>list comprehension is slower in my case.
>
>Here is my example. I do the calculation of the square difference 
>between the values of two vectors vec1 and vec2, the ratio sampling 
>between vec1 and vec2 is equal to ratio_sampling. I have to use only the 
>500th value of the first serie before doing the difference with the 
>value of the second serie (vec2).
>
>Thank you
>
>Best regards
>
>Laurent
>
>library(tictoc)
>library(comprehenr)
>
>ratio_sampling <- 500
>## size of the first serie
>N1 <- 70000
>## size of the second serie
>N2 <- 100
>## mock data
>set.seed(123)
>vec1 <- rnorm(N1)
>vec2 <- runif(N2)
>
>
>## 1. with the "for" loops
>
>## the square differences will be stored in a vector
>S_diff2 <- numeric((N1-(N2-1)*ratio_sampling))
>tic()
>for( j in 1:length(S_diff2)){
>   sum_squares <- 0
>   for( i in 1:length(vec2)){
>     sum_squares = sum_squares + ((vec1[(i-1)*ratio_sampling+j] - 
>vec2[i])**2)
>   }
>   S_diff2[j] <- sum_squares
>}
>toc()
>## 0.22 sec elapsed
>which.max(S_diff2)
>## 7857
>
>## 2. with the lists comprehension
>tic()
>S_diff2 <- to_vec(for( j in 1:length(S_diff2)) sum(to_vec(for( i in 
>1:length(vec2)) ((vec1[(i-1)*ratio_sampling+j] - vec2[i])**2))))
>toc()
>## 25.09 sec elapsed
>which.max(S_diff2)
>## 7857
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From |@urentRHe|p @end|ng |rom |ree@|r  Sun Jun 16 20:40:03 2024
From: |@urentRHe|p @end|ng |rom |ree@|r (Laurent Rhelp)
Date: Sun, 16 Jun 2024 20:40:03 +0200
Subject: [R] slowness when I use a list comprehension
In-Reply-To: <008201dac014$e1d73fb0$a585bf10$@gmail.com>
References: <9e2ac30f-7b4e-4db7-a56d-b40f51d65c0e@free.fr>
 <006c01dac00a$fa8e59d0$efab0d70$@gmail.com>
 <56692691-6412-43FB-B637-3B83DAA406F4@dcn.davis.ca.us>
 <008201dac014$e1d73fb0$a585bf10$@gmail.com>
Message-ID: <c5cf72fa-0c9f-4a42-b70a-13fdca16fc12@free.fr>

Avi and Jeff,

Thank you very much for your answers. I did not think I would get such 
an interessing answer when I asked my question.

In fact, I discovered recently the list comprehension reading some 
python code and I was seduced but the compact notation so I decided to 
do an exercice on an example.

Now I know why the use of the comprehenr use is slow (cf. avi answer) 
and I was impressed by the jeff?s function which uses the vertorization.

Unit: milliseconds
expr min lq mean median
S_diff2 <- dloop(N1, M2, ratio_sampling, vec1, vec2) 205.0905 212.86080 
226.80683 221.3820
S_diff3 <- vloop(N1, M2, ratio_sampling, vec1, vec2) 49.8971 57.05555 
64.25502 58.9455
uq max neval cld
227.57695 297.9974 20 a
63.15645 113.4106 20 b

I did not have the idea to transform the second loop with a vectorize 
approach.

Hence, the good direction is to think more in terms of vectorization.

I will search for some exercices on the web.


Le 16/06/2024 ? 19:44, avi.e.gross at gmail.com a ?crit?:
> I fully agree with Jeff that the best way to use ANY language is to evaluate
> the language in terms of not just the capabilities it offers but also the
> philosophy behind what it was created for and how people do things and just
> grok it and use it mostly in the way intended. I do that with all the
> languages I learn, whether for computers or humans.
>
> Bringing in something you like from another language often gets in the way
> of actually using what you have. But realistically, many languages that were
> designed for one purpose will then evolve to suit many other purposes and
> lose their direction and often their focus and even efficiency. S was
> designed for statistical computing of some sorts and that meant a vectorized
> approach could take you far. Python had other design goals and the original
> designers wanted elements of genrality that a list provides more than a
> vector does. R has lists too, but note if you want to use the kind of
> dictionary or set used in python, which definitely can have advanatages and
> disadvantages, you can find add-ons in R packages that give you something
> like that too. And, note, many, myself included, really appreciate alternate
> ways to do things and heavily use tidyverse packages that mostly are not
> base R but sort of a grafted-on other language. So what? Purists don't
> necessarily do well in the real world.
>
> On the topic at hand and speed, I went an looked at the comprehenr package
> and it is no wonder it is slower.
>
> Here is the code Laurent used in calling to_vec:
>
>> to_vec
> function (expr, recursive = TRUE, use.names = FALSE)
> {
>      res = eval.parent(substitute(comprehenr::to_list(expr)))
>      unlist(res, recursive = recursive, use.names = use.names)
> }'
>
> It does a few things and then calls to_list() to do the actual work. This
> extra layer may slow it down a tad.
>
> So what does to_list() do?
>
>> to_list
> function (expr)
> {
>      expr = substitute(expr)
>      is_loop(expr) || stop(paste("argument should be expression with 'for',
> 'while' or 'repeat' but we have: ",
>          deparse(expr, width.cutoff = 500)[1]))
>      expr = expand_loop_variables(expr)
>      expr = add_assignment_to_final_loops(expr)
>      expr = substitute(local({
>          .___res <- list()
>          .___counter <- 0
>          expr
>          .___res
>      }))
>      eval.parent(expr)
> }
>
> I won't follow the entire chain, but it seems to take the code supplied and
> isolate various parts needed and, in effect, build up some other code and
> evaluates it in the context of the parent.
>
> Obviously, had you written similar (or different using loops or whatever)
> code directly, it might execute faster.
>
> As I mentioned, this is largely syntactic sugar. A reasonable use of this is
> if you are given python code and asked to translate it into R code that does
> the same thing. You could spend time thinking and designing and come up with
> the kind of R code an R expert might have done, or skip that and just make
> slight changes needed for R and for the package being used and it should
> work, but not necessarily the way a native polished version works. Later, if
> time and finances permit, and you want it faster, rewrite it.
>
> I note the package, with a vignetter here:
> https://cran.r-project.org/web//packages/comprehenr/vignettes/Introduction.h
> tml
>
> Does make some changes so translating is not trivial. For example, the
> python syntax such as:
>
> [ f(x) for x in iterable if condition]
>
> Is not able to be used in quite that order. It loosely translates to:
>
> to_vec(for x in iterable if condition f(x))
>
> with the result at the end rather than beginning. And, since R has not
> chosen to return multiple things from a function like python does and just
> unpack them, they had to come up with interesting workarounds like `x, y`
> and frankly, quite a few things I can do in python in this context are
> simply not supported by this code, nor can be expected to.
>
> I think if someone using python was used to using the extended version by
> loading modules like numpy and pandas and using them heavily, they might
> find it a tad easier to then port the code to R and use vectorized
> functionality better.
>
> So, are packages like comprehend a crutch or are they helpful or even evil?
> My view is to not be a religious fanatic and assume any language was really
> designed perfectly. Some ideas and implementations can be a useful way to
> formulate a problem for a programmer who thinks in that way, at least until
> they learn to also think in another. An example would be the R way to do
> sets is probably not as useful as the python way. If I needed heavy duty
> usage, I might load a package that lets me think about it the way I want,
> and the same for a dictionary.
>
> But, if I am writing code for others to maintain and change later, the
> closer I stick to the main language or accepted packages, the better.
>
>   
>
> -----Original Message-----
> From: R-help<r-help-bounces at r-project.org>  On Behalf Of Jeff Newmiller via
> R-help
> Sent: Sunday, June 16, 2024 1:13 PM
> To:r-help at r-project.org
> Subject: Re: [R] slowness when I use a list comprehension
>
> I would be more strong on this advice: learn to think in R, rather than
> thinking in Python, when programming in R. R has atomic vectors... Python
> does not (until you import a package that implements them). I find that
> while it is possible to import R thinking into Python, Python programmers
> seem to object for stylistic reasons even though such thinking speeds up
> Python also.
>
> A key step in that direction is to stop using lists directly for numeric
> calculations... use them to manage numeric vactors. In some cases you can
> switch to matrices or arrays to remove even more list manipulations from the
> script.
>
> library(microbenchmark)
>
> ratio_sampling <- 500
> ## size of the first serie
> N1 <- 70000
> ## size of the second serie
> N2 <- 100
> ## mock data
> set.seed(123)
> vec1 <- rnorm(N1)
> vec2 <- runif(N2)
>
> dloop <- function( N1, M2, ratio_sampling, vec1, vec2 ) {
>    S_diff2 <- numeric(
>      N1-(N2-1)*ratio_sampling
>    )
>    for( j in 1:length(S_diff2) ) {
>      sum_squares <- 0
>      for( i in 1:length(vec2)){
>        sum_squares <- (
>          sum_squares
>          + (
>            vec1[ (i-1)*ratio_sampling+j ]
>            - vec2[i]
>          )**2
>        )
>      }
>      S_diff2[j] <- sum_squares
>    }
>    S_diff2
> }
>
> vloop <- function( N1, M2, ratio_sampling, vec1, vec2 ) {
>    S_diff3 <- numeric(
>      N1-(N2-1)*ratio_sampling
>    )
>    i <- seq_along( vec2 )
>    k <- (i-1)*ratio_sampling
>    for( j in seq_along( S_diff3 ) ) {
>      S_diff3[j] <- sum(
>        (
>          vec1[ j + k ]
>          - vec2
>        )^2
>      )
>    }
>    S_diff3
> }
>
> microbenchmark(
>    S_diff2 <- dloop( N1, M2, ratio_sampling, vec1, vec2 )
>    , S_diff3 <- vloop( N1, M2, ratio_sampling, vec1, vec2 )
>    , times = 20
> )
>
> all.equal( S_diff2, S_diff3 )
>
>
> On June 16, 2024 9:33:54 AM PDT,avi.e.gross at gmail.com  wrote:
>> Laurent,
>>
>> Thank you for introducing me to a package I did not know existed as I use
> features like list comprehension in python all the time and could see using
> it in R now that I know it is available.
>> As to why you see your example as slow, I see you used a fairly complex and
> nested expression and wonder if it was a better way to go. As you are
> dealing with an interpreter doing delayed evaluation, I can imagine reasons
> it can be slow. But note the package comprehenr may not be designed to be
> more efficient than loops or of the more built-in functional methods that
> can be faster. The package is there perhaps more as a compatibility helper
> that allows you to write closer to the python style and perhaps re-shapes
> what you wrote into a set of instructions in more native R.
>> Just for comparison, in python, things like comprehensions for list or
> dictionaries or tuples often are syntactic sugar and the interpreter may
> simply rewrite them more like the first program you typed and evaluates
> that. The comprehensions are more designed for users who can think another
> way and write things more compactly as one-liners. Depending on
> implementations, they may be faster or slower on some examples.
>> I am not saying there is nothing else that is slowing it down for you. I am
> suggesting that using the feature as currently implemented may not be an
> advantage except in your thought process. It may be it could be improved,
> such as by replacing more functionality out of R and into compiled languages
> as has been done for many packages.
>> Avi
>>
>> -----Original Message-----
>> From: R-help<r-help-bounces at r-project.org>  On Behalf Of Laurent Rhelp
>> Sent: Sunday, June 16, 2024 11:28 AM
>> To:r-help at r-project.org
>> Subject: [R] slowness when I use a list comprehension
>>
>> Dear RHelp-list,
>>
>>     I try to use the package comprehenr to replace a for loop by a list
>> comprehension.
>>
>>   I wrote the code but I certainly miss something because it is very
>> slower compared to the for loops. May you please explain to me why the
>> list comprehension is slower in my case.
>>
>> Here is my example. I do the calculation of the square difference
>> between the values of two vectors vec1 and vec2, the ratio sampling
>> between vec1 and vec2 is equal to ratio_sampling. I have to use only the
>> 500th value of the first serie before doing the difference with the
>> value of the second serie (vec2).
>>
>> Thank you
>>
>> Best regards
>>
>> Laurent
>>
>> library(tictoc)
>> library(comprehenr)
>>
>> ratio_sampling <- 500
>> ## size of the first serie
>> N1 <- 70000
>> ## size of the second serie
>> N2 <- 100
>> ## mock data
>> set.seed(123)
>> vec1 <- rnorm(N1)
>> vec2 <- runif(N2)
>>
>>
>> ## 1. with the "for" loops
>>
>> ## the square differences will be stored in a vector
>> S_diff2 <- numeric((N1-(N2-1)*ratio_sampling))
>> tic()
>> for( j in 1:length(S_diff2)){
>>    sum_squares <- 0
>>    for( i in 1:length(vec2)){
>>      sum_squares = sum_squares + ((vec1[(i-1)*ratio_sampling+j] -
>> vec2[i])**2)
>>    }
>>    S_diff2[j] <- sum_squares
>> }
>> toc()
>> ## 0.22 sec elapsed
>> which.max(S_diff2)
>> ## 7857
>>
>> ## 2. with the lists comprehension
>> tic()
>> S_diff2 <- to_vec(for( j in 1:length(S_diff2)) sum(to_vec(for( i in
>> 1:length(vec2)) ((vec1[(i-1)*ratio_sampling+j] - vec2[i])**2))))
>> toc()
>> ## 25.09 sec elapsed
>> which.max(S_diff2)
>> ## 7857
>>
>> ______________________________________________
>> R-help at r-project.org  mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org  mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From ggrothend|eck @end|ng |rom gm@||@com  Sun Jun 16 20:54:26 2024
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Sun, 16 Jun 2024 14:54:26 -0400
Subject: [R] slowness when I use a list comprehension
In-Reply-To: <9e2ac30f-7b4e-4db7-a56d-b40f51d65c0e@free.fr>
References: <9e2ac30f-7b4e-4db7-a56d-b40f51d65c0e@free.fr>
Message-ID: <CAP01uRnUhr=agNcWKqRxLLaJLcuzxWv1=gaLioV89z072LoTNQ@mail.gmail.com>

This can be vectorized.  Try

ix <- seq_along(vec2)
S_diff2 <- sapply(seq_len(N1-(N2-1)*ratio_sampling), \(j)
sum((vec1[(ix-1)*ratio_sampling+j] - vec2[ix])**2))

On Sun, Jun 16, 2024 at 11:27?AM Laurent Rhelp <laurentRHelp at free.fr> wrote:
>
> Dear RHelp-list,
>
>     I try to use the package comprehenr to replace a for loop by a list
> comprehension.
>
>   I wrote the code but I certainly miss something because it is very
> slower compared to the for loops. May you please explain to me why the
> list comprehension is slower in my case.
>
> Here is my example. I do the calculation of the square difference
> between the values of two vectors vec1 and vec2, the ratio sampling
> between vec1 and vec2 is equal to ratio_sampling. I have to use only the
> 500th value of the first serie before doing the difference with the
> value of the second serie (vec2).
>
> Thank you
>
> Best regards
>
> Laurent
>
> library(tictoc)
> library(comprehenr)
>
> ratio_sampling <- 500
> ## size of the first serie
> N1 <- 70000
> ## size of the second serie
> N2 <- 100
> ## mock data
> set.seed(123)
> vec1 <- rnorm(N1)
> vec2 <- runif(N2)
>
>
> ## 1. with the "for" loops
>
> ## the square differences will be stored in a vector
> S_diff2 <- numeric((N1-(N2-1)*ratio_sampling))
> tic()
> for( j in 1:length(S_diff2)){
>    sum_squares <- 0
>    for( i in 1:length(vec2)){
>      sum_squares = sum_squares + ((vec1[(i-1)*ratio_sampling+j] -
> vec2[i])**2)
>    }
>    S_diff2[j] <- sum_squares
> }
> toc()
> ## 0.22 sec elapsed
> which.max(S_diff2)
> ## 7857
>
> ## 2. with the lists comprehension
> tic()
> S_diff2 <- to_vec(for( j in 1:length(S_diff2)) sum(to_vec(for( i in
> 1:length(vec2)) ((vec1[(i-1)*ratio_sampling+j] - vec2[i])**2))))
> toc()
> ## 25.09 sec elapsed
> which.max(S_diff2)
> ## 7857
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From |@urentRHe|p @end|ng |rom |ree@|r  Sun Jun 16 21:29:59 2024
From: |@urentRHe|p @end|ng |rom |ree@|r (Laurent Rhelp)
Date: Sun, 16 Jun 2024 21:29:59 +0200
Subject: [R] slowness when I use a list comprehension
In-Reply-To: <CAP01uRnUhr=agNcWKqRxLLaJLcuzxWv1=gaLioV89z072LoTNQ@mail.gmail.com>
References: <9e2ac30f-7b4e-4db7-a56d-b40f51d65c0e@free.fr>
 <CAP01uRnUhr=agNcWKqRxLLaJLcuzxWv1=gaLioV89z072LoTNQ@mail.gmail.com>
Message-ID: <b28229ed-f939-4531-8a5b-c8a8f27fe25b@free.fr>

Thank you for this solution which is faster than the two for loops.

gloop <- function(N1,N2,ratio_sampling,vec1,vec2){

 ? ix <- seq_along(vec2)
 ? S_diff2 <- sapply(seq_len(N1-(N2-1)*ratio_sampling), \(j)
 ??????????????????? sum((vec1[(ix-1)*ratio_sampling+j] - vec2[ix])**2))
 ? return(S_diff2)
}

microbenchmark(
 ? S_diff2 <- dloop( N1, N2, ratio_sampling, vec1, vec2 )
 ? , S_diff3 <- vloop( N1, N2, ratio_sampling, vec1, vec2 )
 ? , S_diff4 <- gloop( N1, N2, ratio_sampling, vec1, vec2)
 ? , times = 20
)

Unit: milliseconds expr min lq mean median S_diff2 <- dloop(N1, N2, 
ratio_sampling, vec1, vec2) 200.1107 218.10100 230.36871 222.3080 
S_diff3 <- vloop(N1, N2, ratio_sampling, vec1, vec2) 42.6878 46.65425 
73.83425 58.6626 S_diff4 <- gloop(N1, N2, ratio_sampling, vec1, vec2) 
80.4895 91.24735 133.74064 110.9142 uq max neval cld 228.7683 303.8214 
20 a 105.4257 145.2059 20 b 166.4094 233.7112 20 c


Le 16/06/2024 ? 20:54, Gabor Grothendieck a ?crit?:
> This can be vectorized.  Try
>
> ix <- seq_along(vec2)
> S_diff2 <- sapply(seq_len(N1-(N2-1)*ratio_sampling), \(j)
> sum((vec1[(ix-1)*ratio_sampling+j] - vec2[ix])**2))
>
> On Sun, Jun 16, 2024 at 11:27?AM Laurent Rhelp<laurentRHelp at free.fr>  wrote:
>> Dear RHelp-list,
>>
>>      I try to use the package comprehenr to replace a for loop by a list
>> comprehension.
>>
>>    I wrote the code but I certainly miss something because it is very
>> slower compared to the for loops. May you please explain to me why the
>> list comprehension is slower in my case.
>>
>> Here is my example. I do the calculation of the square difference
>> between the values of two vectors vec1 and vec2, the ratio sampling
>> between vec1 and vec2 is equal to ratio_sampling. I have to use only the
>> 500th value of the first serie before doing the difference with the
>> value of the second serie (vec2).
>>
>> Thank you
>>
>> Best regards
>>
>> Laurent
>>
>> library(tictoc)
>> library(comprehenr)
>>
>> ratio_sampling <- 500
>> ## size of the first serie
>> N1 <- 70000
>> ## size of the second serie
>> N2 <- 100
>> ## mock data
>> set.seed(123)
>> vec1 <- rnorm(N1)
>> vec2 <- runif(N2)
>>
>>
>> ## 1. with the "for" loops
>>
>> ## the square differences will be stored in a vector
>> S_diff2 <- numeric((N1-(N2-1)*ratio_sampling))
>> tic()
>> for( j in 1:length(S_diff2)){
>>     sum_squares <- 0
>>     for( i in 1:length(vec2)){
>>       sum_squares = sum_squares + ((vec1[(i-1)*ratio_sampling+j] -
>> vec2[i])**2)
>>     }
>>     S_diff2[j] <- sum_squares
>> }
>> toc()
>> ## 0.22 sec elapsed
>> which.max(S_diff2)
>> ## 7857
>>
>> ## 2. with the lists comprehension
>> tic()
>> S_diff2 <- to_vec(for( j in 1:length(S_diff2)) sum(to_vec(for( i in
>> 1:length(vec2)) ((vec1[(i-1)*ratio_sampling+j] - vec2[i])**2))))
>> toc()
>> ## 25.09 sec elapsed
>> which.max(S_diff2)
>> ## 7857
>>
>> ______________________________________________
>> R-help at r-project.org  mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guidehttp://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
	[[alternative HTML version deleted]]


From j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng  Mon Jun 17 08:50:33 2024
From: j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng (Jibrin Alhassan)
Date: Mon, 17 Jun 2024 07:50:33 +0100
Subject: [R] code for year month day hr format
In-Reply-To: <9347708a-d116-4879-8809-e2b5abadff25@sapo.pt>
References: <CAEGeL+EDsd2LnZ0v5cY-0S7ofE_qxKi-QGV2+WnSzODywRZ9MQ@mail.gmail.com>
 <474f21f7-7a41-403f-826f-853f6589ec52@sapo.pt>
 <CAEGeL+H_eukBiQKyDb1GOGo5K2kcyM7S6n167ukBWoGrQUgLyg@mail.gmail.com>
 <9347708a-d116-4879-8809-e2b5abadff25@sapo.pt>
Message-ID: <CAEGeL+Hv5vXMo8yqeTTXpjXMVicSpEzk9W0pM0jd0gWRMiVsqQ@mail.gmail.com>

Hello Rui,
Your patience is indeed amazing. Your script tested as shown below worked
perfectly well.
df1 <- read.table(text = "YEAR DOY HR   IMF  SW   SSN    Dst f10.7
2012 215  4   5.1  371. 143    -4 138.6 ", header = TRUE)
with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
df1$Date <- with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
df1 <- df1[-(1:2)]
df1 <- df1[c(ncol(df1), 1:(ncol(df1) - 1L))]
head(df1).
But  I have 43,849 data points. Your script only generated one. Help me
with a script that can handle the whole data points. I have tried following
your tested solution but was unsuccessful. My regards.
*Jibrin Adejoh Alhassan (Ph.D)*
Department of Physics and Astronomy,
University of Nigeria, Nsukka


On Sun, Jun 16, 2024 at 8:33?AM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> ?s 21:42 de 15/06/2024, Jibrin Alhassan escreveu:
> > Thank you Rui. I ran the following script
> > df1 <- read.table("solar_hour", header = TRUE)
> > df1$date <- as.Date(paste(df1$year, df1$hour),
> >   format = "%Y %j",
> > origin = "2012-08-01-0")
> > df2 <- df1[c("date", "IMF", "SWS", "SSN", "Dst", "f10")]
> > head(df1)
> > #To display all the rows
> >   print(df2).
> > It gave me this error message
> >> source ("script.R")
> > Error in `$<-.data.frame`(`*tmp*`, date, value = numeric(0)) :
> >    replacement has 0 rows, data has 38735
> >> print(df2)
> > Error: object 'df2' not found
> >> My data is an hourly data but desire to have the date as
> > year    month    day   hour
> > 2012   08         01     01
> > 2012   08         01     02
> > 2012   08        01      03 etc
> > Thanks.
> >
> > *Jibrin Adejoh Alhassan (Ph.D)*
> > Department of Physics and Astronomy,
> > University of Nigeria, Nsukka
> >
> >
> > On Sat, Jun 15, 2024 at 8:34?PM Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
> >
> >> ?s 20:00 de 15/06/2024, Jibrin Alhassan escreveu:
> >>> I have solar-geophysical data e.g as blow:
> >>> YEAR DOY HR   IMF  SW   SSN    Dst f10.7
> >>> 2012 214  0   3.4  403. 132    -9 154.6
> >>> 2012 214  1   3.7  388. 132   -10 154.6
> >>> 2012 214  2   3.7  383. 132   -10 154.6
> >>> 2012 214  3   3.7  391. 132    -9 154.6
> >>> 2012 214  4   4.2  399. 132    -7 154.6
> >>> 2012 214  5   4.1  411. 132    -6 154.6
> >>> 2012 214  6   4.0  407. 132    -6 154.6
> >>> 2012 214  7   4.2  404. 132    -4 154.6
> >>> 2012 214  8   4.3  405. 132    -6 154.6
> >>> 2012 214  9   4.4  409. 132    -6 154.6
> >>> 2012 214 10   4.4  401. 132    -6 154.6
> >>> 2012 214 11   4.5  385. 132    -7 154.6
> >>> 2012 214 12   4.7  377. 132    -8 154.6
> >>> 2012 214 13   4.7  382. 132    -6 154.6
> >>> 2012 214 14   4.3  396. 132    -4 154.6
> >>> 2012 214 15   4.1  384. 132    -2 154.6
> >>> 2012 214 16   4.0  382. 132    -1 154.6
> >>> 2012 214 17   3.9  397. 132     0 154.6
> >>> 2012 214 18   3.8  390. 132     1 154.6
> >>> 2012 214 19   4.2  400. 132     2 154.6
> >>> 2012 214 20   4.6  408. 132     1 154.6
> >>> 2012 214 21   4.8  401. 132    -3 154.6
> >>> 2012 214 22   4.9  395. 132    -5 154.6
> >>> 2012 214 23   5.0  386. 132    -1 154.6
> >>> 2012 215  0   5.0  377. 143    -1 138.6
> >>> 2012 215  1   4.9  384. 143    -2 138.6
> >>> 2012 215  2   4.9  390. 143    -4 138.6
> >>> 2012 215  3   4.9  372. 143    -6 138.6
> >>> 2012 215  4   5.1  371. 143    -4 138.6
> >>> I want to process it to be of the format as shown below
> >>>    y   m  d  hr imf  sws  ssn    Dst f10.7
> >>> 2012-08-01 10 3.4  403. 132    -9 154.6
> >>> 2012-08-01 12 3.7  388. 132   -10 154.6
> >>> 2012-08-01 15 3.7  383. 132   -10 154.6
> >>> 2012-08-01 17 3.7  391. 132    -9 154.6
> >>> I want to request an R code to accomplish this task. Thanks for your
> >> time.
> >>> *Jibrin Adejoh Alhassan (Ph.D)*
> >>> Department of Physics and Astronomy,
> >>> University of Nigeria, Nsukka
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >> Hello,
> >>
> >> To create a date column, paste the first two columns and coerce to class
> >> "Date" with conversion specifications %Y for the 4 digit year and %j for
> >> the day of year. See
> >>
> >> help("strptime")
> >>
> >>
> >>
> >> df1 <- read.table(text = "YEAR DOY HR   IMF  SW   SSN    Dst f10.7
> >> 2012 214  0   3.4  403. 132    -9 154.6
> >> 2012 214  1   3.7  388. 132   -10 154.6
> >> 2012 214  2   3.7  383. 132   -10 154.6
> >> 2012 214  3   3.7  391. 132    -9 154.6
> >> 2012 214  4   4.2  399. 132    -7 154.6
> >> 2012 214  5   4.1  411. 132    -6 154.6
> >> 2012 214  6   4.0  407. 132    -6 154.6
> >> 2012 214  7   4.2  404. 132    -4 154.6
> >> 2012 214  8   4.3  405. 132    -6 154.6
> >> 2012 214  9   4.4  409. 132    -6 154.6
> >> 2012 214 10   4.4  401. 132    -6 154.6
> >> 2012 214 11   4.5  385. 132    -7 154.6
> >> 2012 214 12   4.7  377. 132    -8 154.6
> >> 2012 214 13   4.7  382. 132    -6 154.6
> >> 2012 214 14   4.3  396. 132    -4 154.6
> >> 2012 214 15   4.1  384. 132    -2 154.6
> >> 2012 214 16   4.0  382. 132    -1 154.6
> >> 2012 214 17   3.9  397. 132     0 154.6
> >> 2012 214 18   3.8  390. 132     1 154.6
> >> 2012 214 19   4.2  400. 132     2 154.6
> >> 2012 214 20   4.6  408. 132     1 154.6
> >> 2012 214 21   4.8  401. 132    -3 154.6
> >> 2012 214 22   4.9  395. 132    -5 154.6
> >> 2012 214 23   5.0  386. 132    -1 154.6
> >> 2012 215  0   5.0  377. 143    -1 138.6
> >> 2012 215  1   4.9  384. 143    -2 138.6
> >> 2012 215  2   4.9  390. 143    -4 138.6
> >> 2012 215  3   4.9  372. 143    -6 138.6
> >> 2012 215  4   5.1  371. 143    -4 138.6", header = TRUE)
> >>
> >>
> >> with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
> >> #>  [1] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
> >> #>  [6] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
> >> #> [11] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
> >> #> [16] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
> >> #> [21] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-02"
> >> #> [26] "2012-08-02" "2012-08-02" "2012-08-02" "2012-08-02"
> >>
> >> # now create the column
> >> df1$Date <- with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
> >> # remove the columns no longer needed
> >> df1 <- df1[-(1:2)]
> >> # relocate the new date column
> >> df1 <- df1[c(ncol(df1), 1:(ncol(df1) - 1L))]
> >> head(df1)
> >> #>         Date HR IMF  SW SSN Dst f10.7
> >> #> 1 2012-08-01  0 3.4 403 132  -9 154.6
> >> #> 2 2012-08-01  1 3.7 388 132 -10 154.6
> >> #> 3 2012-08-01  2 3.7 383 132 -10 154.6
> >> #> 4 2012-08-01  3 3.7 391 132  -9 154.6
> >> #> 5 2012-08-01  4 4.2 399 132  -7 154.6
> >> #> 6 2012-08-01  5 4.1 411 132  -6 154.6
> >>
> >>
> >> Hope this helps,
> >>
> >> Rui Barradas
> >>
> >>
> >> --
> >> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
> >> presen?a de v?rus.
> >> www.avg.com
> >>
> >
> Hello,
>
> There is an error in your new code:
>
>
> paste YEAR with DOY, not with HR.
>
>
> As for the rest, is your real data like the one you posted before?
> If it is then I don't see anything wrong with my (tested) solution.
>
>
> Hope this helps,
>
> Rui Barradas
>
>
>
> --
> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
> presen?a de v?rus.
> www.avg.com
>

	[[alternative HTML version deleted]]


From j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng  Mon Jun 17 08:53:00 2024
From: j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng (Jibrin Alhassan)
Date: Mon, 17 Jun 2024 07:53:00 +0100
Subject: [R] code for year month day hr format
In-Reply-To: <CAEGeL+Hv5vXMo8yqeTTXpjXMVicSpEzk9W0pM0jd0gWRMiVsqQ@mail.gmail.com>
References: <CAEGeL+EDsd2LnZ0v5cY-0S7ofE_qxKi-QGV2+WnSzODywRZ9MQ@mail.gmail.com>
 <474f21f7-7a41-403f-826f-853f6589ec52@sapo.pt>
 <CAEGeL+H_eukBiQKyDb1GOGo5K2kcyM7S6n167ukBWoGrQUgLyg@mail.gmail.com>
 <9347708a-d116-4879-8809-e2b5abadff25@sapo.pt>
 <CAEGeL+Hv5vXMo8yqeTTXpjXMVicSpEzk9W0pM0jd0gWRMiVsqQ@mail.gmail.com>
Message-ID: <CAEGeL+FS6hN7OJqh=6NveMTMVA8Ct_mpRdGdqdezVBoXiTRe6g@mail.gmail.com>

Part of it is pasted below
YEAR DOY HR    IMF SWS   SSN   Dst f10.7
2012   1  0   4.0  379.  71    -8 999.9
2012   1  1   4.4  386.  71    -3 999.9
2012   1  2   4.8  380.  71    -4 999.9
2012   1  3   5.4  374.  71    -5 999.9
2012   1  4   4.5  369.  71    -9 999.9
2012   1  5   4.2  368.  71    -7 999.9
2012   1  6   4.7  367.  71    -6 999.9
2012   1  7   4.1  361.  71   -10 999.9
2012   1  8   3.2  362.  71    -7 999.9
2012   1  9   4.3  367.  71    -3 999.9
2012   1 10   4.5  365.  71    -6 999.9
2012   1 11   5.6  369.  71    -8 999.9
2012   1 12   5.2  366.  71    -8 999.9
2012   1 13   4.4  370.  71    -7 999.9
2012   1 14   4.8  357.  71    -5 999.9
2012   1 15   4.6  354.  71    -8 999.9
2012   1 16   3.7  382.  71    -7 999.9
2012   1 17   3.2  376.  71    -2 999.9
2012   1 18   2.8  368.  71     2 999.9
2012   1 19   3.2  361.  71     2 999.9
2012   1 20   3.2  361.  71    -3 999.9
2012   1 21   3.5  365.  71    -5 999.9
2012   1 22   3.6  364.  71    -3 999.9
2012   1 23   3.0  362.  71    -3 999.9
2012   2  0   3.2  359.  92    -5 130.3
2012   2  1   3.0  361.  92    -4 130.3
2012   2  2   4.5  374.  92     3 130.3
2012   2  3   4.5  364.  92     5 130.3
2012   2  4   5.1  352.  92     3 130.3
2012   2  5   4.9  358.  92     3 130.3
2012   2  6   4.4  346.  92     4 130.3
2012   2  7   4.2  349.  92     7 130.3
2012   2  8   4.5  346.  92     8 130.3
2012   2  9   5.2  345.  92     7 130.3
2012   2 10   5.0  349.  92     5 130.3
2012   2 11   4.8  345.  92     0 130.3
2012   2 12   5.3  347.  92     0 130.3
2012   2 13   5.5  342.  92     0 130.3
2012   2 14   6.1  359.  92     1 130.3
2012   2 15   6.2  393.  92     8 130.3
2012   2 16   6.7  390.  92    10 130.3
2012   2 17   7.7  369.  92    10 130.3
2012   2 18   9.4  380.  92    14 130.3
2012   2 19  10.6  386.  92    12 130.3
2012   2 20  10.2  378.  92    11 130.3
2012   2 21  11.6  369.  92     7 130.3
2012   2 22  12.0  369.  92     8 130.3
2012   2 23  10.5  361.  92     1 130.3
2012   3  0  11.3  403. 120    -7 130.2
2012   3  1  10.3  412. 120   -14 130.2
2012   3  2   8.8  419. 120   -18 130.2
2012   3  3   8.3  412. 120   -23 130.2
2012   3  4   8.0  408. 120   -25 130.2
2012   3  5   7.0  380. 120   -28 130.2
2012   3  6   6.9  374. 120   -29 130.2
2012   3  7   6.9  372. 120   -30 130.2
2012   3  8   7.1  365. 120   -32 130.2
2012   3  9   6.8  376. 120   -35 130.2
2012   3 10   6.7  380. 120   -35 130.2
2012   3 11   6.4  381. 120   -30 130.2
2012   3 12   5.9  401. 120   -26 130.2
2012   3 13   5.9  405. 120   -23 130.2
2012   3 14   5.9  413. 120   -20 130.2
2012   3 15   5.9  406. 120   -20 130.2
2012   3 16   6.3  427. 120   -20 130.2
2012   3 17   5.9  424. 120   -19 130.2
2012   3 18   4.8  390. 120   -16 130.2
2012   3 19   4.8  374. 120   -15 130.2
2012   3 20   4.8  374. 120   -15 130.2
2012   3 21   5.1  378. 120   -18 130.2
2012   3 22   4.9  375. 120   -19 130.2
2012   3 23   4.7  364. 120   -17 130.2
2012   4  0   4.3  359. 126   -17 131.6
2012   4  1   4.3  359. 126   -15 131.6
2012   4  2   4.2  358. 126   -13 131.6
2012   4  3   3.8  359. 126   -13 131.6
2012   4  4   3.8  358. 126   -13 131.6
2012   4  5   3.7  359. 126   -14 131.6
2012   4  6   3.9  361. 126   -13 131.6
2012   4  7   3.7  364. 126   -13 131.6
2012   4  8   3.7  366. 126   -12 131.6
2012   4  9   3.8  363. 126   -10 131.6
2012   4 10   3.5  363. 126    -8 131.6
2012   4 11   3.0  352. 126   -10 131.6
2012   4 12   3.1  348. 126   -12 131.6
2012   4 13   3.3  340. 126    -9 131.6
2012   4 14   4.0  343. 126    -8 131.6
2012   4 15   4.2  343. 126    -7 131.6
2012   4 16   3.8  336. 126    -5 131.6
2012   4 17   3.9  334. 126    -6 131.6
2012   4 18   3.8  329. 126    -5 131.6
2012   4 19   3.8  326. 126    -4 131.6
2012   4 20   4.3  337. 126    -3 131.6
2012   4 21   3.9  331. 126     0 131.6
2012   4 22   3.8  322. 126    -1 131.6
2012   4 23   3.5  331. 126    -1 131.6
2012   5  0   3.9  312. 109    -3 136.6
2012   5  1   3.6  311. 109    -1 136.6
2012   5  2   3.7  312. 109     0 136.6
2012   5  3   3.8  308. 109     0 136.6
2012   5  4   4.0  305. 109     2 136.6
2012   5  5   4.5  309. 109     2 136.6
2012   5  6   3.5  314. 109     3 136.6
2012   5  7   3.6  305. 109     2 136.6
2012   5  8   4.3  307. 109     2 136.6
2012   5  9   4.6  316. 109     1 136.6
2012   5 10   5.0  321. 109    -4 136.6
2012   5 11   5.1  321. 109    -6 136.6
2012   5 12   4.6  326. 109    -4 136.6
2012   5 13   5.7  321. 109    -2 136.6
2012   5 14   5.0  316. 109     1 136.6
2012   5 15   4.6  315. 109     2 136.6
2012   5 16   5.5  321. 109     7 136.6
2012   5 17   7.2  327. 109     7 136.6
2012   5 18   9.2  329. 109     3 136.6
2012   5 19   9.4  341. 109     3 136.6
2012   5 20   9.2  345. 109     8 136.6
2012   5 21   9.8  344. 109     9 136.6
2012   5 22   9.8  341. 109    10 136.6
2012   5 23  10.0  351. 109    15 136.6
2012   6  0  10.4  356. 113    12 131.0
2012   6  1   9.1  360. 113    10 131.0
2012   6  2   6.6  392. 113    10 131.0
2012   6  3   6.9  418. 113     7 131.0
2012   6  4   6.5  408. 113     4 131.0
2012   6  5   6.6  413. 113     7 131.0
2012   6  6   7.3  428. 113     6 131.0
2012   6  7   7.3  416. 113     4 131.0
2012   6  8   7.0  411. 113     1 131.0
2012   6  9   7.2  415. 113     1 131.0
2012   6 10   7.2  426. 113     0 131.0
2012   6 11   6.5  431. 113    -2 131.0
2012   6 12   6.4  431. 113    -2 131.0
2012   6 13   6.6  435. 113     0 131.0
2012   6 14   6.2  425. 113     2 131.0
2012   6 15   5.7  431. 113     4 131.0
2012   6 16   6.1  431. 113     1 131.0
2012   6 17   5.7  425. 113    -3 131.0
2012   6 18   5.8  431. 113    -1 131.0
2012   6 19   6.4  425. 113     2 131.0
2012   6 20   6.0  434. 113     1 131.0
2012   6 21   6.3  420. 113     0 131.0
2012   6 22   6.3  440. 113    -3 131.0
2012   6 23   6.5  456. 113    -3 131.0
2012   7  0   6.3  435. 113    -5 135.9
2012   7  1   5.9  428. 113    -1 135.9
2012   7  2   5.7  434. 113     1 135.9
2012   7  3   5.3  423. 113     0 135.9
2012   7  4   4.3  417. 113     1 135.9
2012   7  5   5.4  420. 113     0 135.9
2012   7  6   5.7  434. 113     1 135.9
2012   7  7   5.5  423. 113     1 135.9
2012   7  8   4.8  419. 113    -2 135.9
2012   7  9   5.8  421. 113    -6 135.9
2012   7 10   5.3  412. 113    -9 135.9
2012   7 11   4.6  424. 113    -7 135.9
2012   7 12   4.0  439. 113    -3 135.9
2012   7 13   4.8  431. 113    -1 135.9
2012   7 14   5.1  431. 113    -1 135.9
2012   7 15   4.8  427. 113    -1 135.9
2012   7 16   4.7  429. 113    -5 135.9
2012   7 17   5.3  436. 113    -6 135.9
2012   7 18   5.1  426. 113    -5 135.9
2012   7 19   5.2  427. 113    -4 135.9
2012   7 20   4.5  416. 113    -5 135.9
2012   7 21   4.9  409. 113    -4 135.9
2012   7 22   5.0  417. 113    -4 135.9
2012   7 23   5.0  426. 113    -4 135.9
2012   8  0   5.0  433. 104    -2 131.4
2012   8  1   4.9  426. 104    -2 131.4
2012   8  2   4.7  421. 104    -4 131.4
2012   8  3   4.4  417. 104    -5 131.4
2012   8  4   4.3  416. 104    -8 131.4
2012   8  5   4.5  416. 104    -8 131.4
2012   8  6   5.0  419. 104    -6 131.4
2012   8  7   5.4  446. 104    -1 131.4
2012   8  8   5.3  439. 104    -2 131.4
2012   8  9   5.3  432. 104    -4 131.4
2012   8 10   5.4  434. 104    -4 131.4
2012   8 11   5.4  435. 104    -3 131.4
2012   8 12   4.5  421. 104    -4 131.4
2012   8 13   4.5  422. 104    -4 131.4
2012   8 14   5.1  425. 104    -2 131.4
2012   8 15   5.3  429. 104     1 131.4
2012   8 16   5.5  433. 104    -2 131.4
2012   8 17   5.9  440. 104    -2 131.4
2012   8 18   6.6  445. 104    -1 131.4
2012   8 19   6.4  442. 104    -4 131.4
2012   8 20   5.9  434. 104    -6 131.4
2012   8 21   5.3  429. 104    -7 131.4
2012   8 22   4.8  438. 104    -2 131.4
2012   8 23   5.3  427. 104     4 131.4
2012   9  0   5.5  433.  79     8 137.6
2012   9  1   5.2  445.  79     9 137.6
2012   9  2   5.4  439.  79    10 137.6
2012   9  3   5.3  430.  79     7 137.6
2012   9  4   5.1  426.  79    -3 137.6
2012   9  5   4.7  415.  79    -6 137.6
2012   9  6   5.0  412.  79    -4 137.6
2012   9  7   5.2  418.  79    -2 137.6
2012   9  8   5.5  441.  79     2 137.6
2012   9  9   5.1  441.  79     2 137.6
2012   9 10   5.4  430.  79    -2 137.6
2012   9 11   5.3  433.  79    -1 137.6
2012   9 12   5.5  438.  79     5 137.6
2012   9 13   5.4  436.  79     6 137.6
2012   9 14   5.7  440.  79     9 137.6
2012   9 15   5.9  430.  79     9 137.6
2012   9 16   5.8  437.  79     4 137.6
2012   9 17   4.9  431.  79    -3 137.6
2012   9 18   5.3  424.  79    -3 137.6
2012   9 19   5.7  437.  79    -2 137.6
2012   9 20   6.1  427.  79    -4 137.6
2012   9 21   6.0  409.  79    -7 137.6
2012   9 22   6.6  410.  79    -4 137.6
2012   9 23   6.4  432.  79    -1 137.6
2012  10  0   5.9  434.  70     2 124.6
2012  10  1   5.6  424.  70     4 124.6
2012  10  2   4.8  435.  70     7 124.6
2012  10  3   4.6  425.  70     4 124.6
2012  10  4   4.3  424.  70     3 124.6
2012  10  5   5.4  426.  70     2 124.6
2012  10  6   5.5  434.  70     2 124.6
2012  10  7   6.4  435.  70     4 124.6
2012  10  8   6.3  436.  70     1 124.6
2012  10  9   5.2  431.  70    -6 124.6
2012  10 10   4.5  426.  70   -10 124.6
2012  10 11   4.6  435.  70    -9 124.6
2012  10 12   3.4  425.  70    -5 124.6
2012  10 13   4.2  427.  70    -4 124.6
2012  10 14   4.0  432.  70     2 124.6
2012  10 15   5.5  450.  70     7 124.6
2012  10 16   5.9  451.  70     2 124.6
2012  10 17   5.5  445.  70    -3 124.6
2012  10 18   5.8  442.  70    -2 124.6
2012  10 19   5.4  430.  70    -1 124.6
2012  10 20   4.9  427.  70    -1 124.6
2012  10 21   4.0  436.  70     0 124.6
2012  10 22   3.4  445.  70    -1 124.6
2012  10 23   4.5  453.  70     0 124.6
2012  11  0   5.3  438.  63     1 116.1
2012  11  1   5.0  438.  63     3 116.1
2012  11  2   5.3  445.  63     3 116.1
2012  11  3   4.5  451.  63     2 116.1
2012  11  4   5.0  456.  63    -1 116.1
2012  11  5   4.6  459.  63     0 116.1
2012  11  6   5.1  459.  63     1 116.1
2012  11  7   4.0  466.  63     3 116.1
2012  11  8   5.0  478.  63    -1 116.1
2012  11  9   4.6  489.  63    -2 116.1
2012  11 10   4.5  493.  63    -4 116.1
2012  11 11   4.5  494.  63    -1 116.1
2012  11 12   3.6  504.  63     3 116.1
2012  11 13   3.5  496.  63     5 116.1
2012  11 14   3.3  497.  63     7 116.1
2012  11 15   3.0  498.  63     7 116.1
2012  11 16   2.1  503.  63     3 116.1
2012  11 17   2.0  495.  63     0 116.1
2012  11 18   2.5  492.  63    -2 116.1
2012  11 19   2.2  496.  63    -1 116.1
2012  11 20   2.4  489.  63     1 116.1
2012  11 21   2.6  489.  63     3 116.1
2012  11 22   2.6  483.  63     2 116.1
2012  11 23   2.6  478.  63     2 116.1
2012  12  0   2.9  453.  52     3 113.0
2012  12  1   2.2  446.  52     4 113.0
2012  12  2   2.4  442.  52     8 113.0
2012  12  3   2.6  440.  52    10 113.0
2012  12  4   2.2  438.  52    11 113.0
2012  12  5   2.8  438.  52     9 113.0
2012  12  6   2.0  437.  52     8 113.0
2012  12  7   2.4  426.  52     7 113.0
2012  12  8   3.0  423.  52     5 113.0
2012  12  9   3.3  420.  52     4 113.0
2012  12 10   4.0  419.  52     2 113.0
2012  12 11   3.8  412.  52     5 113.0
2012  12 12   4.2  409.  52     4 113.0
2012  12 13   3.5  408.  52     2 113.0
2012  12 14   3.7  404.  52     9 113.0
2012  12 15   4.5  402.  52    15 113.0
2012  12 16   3.6  395.  52    14 113.0
2012  12 17   2.4  392.  52    16 113.0
2012  12 18   5.8  403.  52    27 113.0
2012  12 19   7.6  400.  52    27 113.0
2012  12 20   6.9  418.  52    17 113.0
2012  12 21   6.9  463.  52    10 113.0
2012  12 22   7.3  469.  52     9 113.0
2012  12 23   5.5  482.  52    12 113.0
2012  13  0   7.7  500.  71    10 120.0
2012  13  1   8.7  492.  71    14 120.0
2012  13  2   7.8  513.  71    16 120.0
2012  13  3   7.5  530.  71    11 120.0
2012  13  4   7.1  518.  71     8 120.0
2012  13  5   7.0  524.  71     6 120.0
2012  13  6   5.9  536.  71     8 120.0
2012  13  7   3.6  529.  71     5 120.0
2012  13  8   4.1  510.  71     4 120.0
2012  13  9   3.9  497.  71     3 120.0
2012  13 10   2.4  492.  71     3 120.0
2012  13 11   2.6  485.  71     5 120.0
2012  13 12   2.9  492.  71     5 120.0
2012  13 13   2.6  487.  71     3 120.0
2012  13 14   2.3  478.  71     6 120.0
2012  13 15   3.2  467.  71    11 120.0
2012  13 16   3.4  453.  71    10 120.0
2012  13 17   3.2  452.  71     6 120.0
2012  13 18   3.0  452.  71     2 120.0
2012  13 19   2.8  447.  71     1 120.0
2012  13 20   2.5  439.  71     0 120.0
2012  13 21   2.5  443.  71    -2 120.0
2012  13 22   2.7  442.  71    -3 120.0
2012  13 23   3.0  447.  71    -4 120.0
2012  14  0   3.5  445. 118    -3 128.0
2012  14  1   3.3  440. 118    -1 128.0
2012  14  2   3.1  440. 118     1 128.0
2012  14  3   2.7  446. 118     0 128.0
2012  14  4   2.9  442. 118    -1 128.0
2012  14  5   2.9  437. 118    -2 128.0
2012  14  6   3.3  431. 118    -3 128.0
2012  14  7   2.8  420. 118    -2 128.0
2012  14  8   2.3  409. 118    -2 128.0
2012  14  9   2.2  407. 118     1 128.0
2012  14 10   2.6  405. 118     3 128.0
2012  14 11   2.8  401. 118     4 128.0
2012  14 12   3.2  398. 118     4 128.0
2012  14 13   2.7  400. 118     4 128.0
2012  14 14   1.9  399. 118     5 128.0
2012  14 15   2.4  395. 118     3 128.0
2012  14 16   2.7  389. 118     2 128.0
2012  14 17   2.9  385. 118     0 128.0
2012  14 18   3.2  384. 118     1 128.0
2012  14 19   2.6  380. 118     2 128.0
2012  14 20   2.3  378. 118     1 128.0
2012  14 21   2.1  374. 118     0 128.0
2012  14 22   3.1  367. 118     0 128.0
2012  14 23   4.0  366. 118    -1 128.0
2012  15  0   4.8  363. 149     0 129.2
2012  15  1   4.0  359. 149     2 129.2
2012  15  2   3.4  354. 149     2 129.2
2012  15  3   3.0  349. 149     5 129.2
2012  15  4   2.7  344. 149     7 129.2
2012  15  5   2.4  349. 149    11 129.2
2012  15  6   2.9  343. 149    12 129.2
2012  15  7   3.5  333. 149     7 129.2
2012  15  8   3.6  341. 149     4 129.2
2012  15  9   3.7  345. 149     1 129.2
2012  15 10   3.6  343. 149     2 129.2
2012  15 11   3.6  342. 149     3 129.2
2012  15 12   3.7  340. 149     7 129.2
2012  15 13   3.7  342. 149     8 129.2
2012  15 14   4.1  344. 149     9 129.2
2012  15 15   3.9  345. 149     4 129.2
2012  15 16   4.4  355. 149     8 129.2
2012  15 17   4.7  360. 149    11 129.2
2012  15 18   5.4  359. 149    12 129.2
2012  15 19   6.8  353. 149     8 129.2
2012  15 20   6.6  349. 149     6 129.2
2012  15 21   5.9  364. 149     2 129.2
2012  15 22   5.2  394. 149     1 129.2
2012  15 23   6.3  395. 149     5 129.2
2012  16  0   6.3  385. 154     6 135.1
2012  16  1   6.6  397. 154     2 135.1
2012  16  2   6.7  400. 154     4 135.1
2012  16  3   6.9  396. 154     5 135.1
2012  16  4   7.9  392. 154     5 135.1
2012  16  5   4.6  379. 154    10 135.1
2012  16  6   8.0  365. 154    13 135.1
2012  16  7   6.3  358. 154    16 135.1
2012  16  8   7.9  380. 154    12 135.1
2012  16  9  10.2  391. 154    10 135.1
2012  16 10   8.1  394. 154     8 135.1
2012  16 11  12.1  412. 154    -8 135.1
2012  16 12  13.2  424. 154   -10 135.1
2012  16 13  12.9  433. 154    -8 135.1
2012  16 14   9.3  461. 154    -7 135.1
2012  16 15   6.6  466. 154   -14 135.1
2012  16 16   6.6  493. 154   -11 135.1
2012  16 17   7.4  496. 154    -7 135.1
2012  16 18   6.2  493. 154    -7 135.1
2012  16 19   6.9  492. 154   -13 135.1
2012  16 20   6.8  486. 154   -19 135.1
2012  16 21   5.6  488. 154   -14 135.1
2012  16 22   6.4  464. 154   -11 135.1
2012  16 23   6.0  459. 154   -10 135.1
2012  17  0   4.9  476. 141   -14 134.5
2012  17  1   4.6  460. 141   -20 134.5
2012  17  2   4.1  467. 141   -17 134.5
2012  17  3   3.7  469. 141   -13 134.5
2012  17  4   3.3  472. 141   -12 134.5
2012  17  5   2.7  472. 141    -8 134.5
2012  17  6   3.5  459. 141    -6 134.5
2012  17  7   3.9  459. 141    -6 134.5
2012  17  8   4.1  463. 141    -7 134.5
2012  17  9   4.1  443. 141   -10 134.5
2012  17 10   4.1  446. 141   -14 134.5
2012  17 11   4.1  442. 141   -13 134.5
2012  17 12   3.6  436. 141   -10 134.5
2012  17 13   3.6  433. 141    -6 134.5
2012  17 14   4.2  421. 141    -1 134.5
2012  17 15   3.7  416. 141    -2 134.5
2012  17 16   4.2  410. 141    -1 134.5
2012  17 17   4.6  396. 141    -1 134.5
2012  17 18   4.5  398. 141    -2 134.5
2012  17 19   4.4  397. 141    -6 134.5
2012  17 20   4.5  396. 141    -8 134.5
2012  17 21   3.5  411. 141    -5 134.5
2012  17 22   3.9  425. 141    -5 134.5
2012  17 23   4.7  418. 141    -6 134.5
2012  18  0   4.6  400. 126    -7 143.4
2012  18  1   4.5  413. 126    -3 143.4
2012  18  2   4.4  418. 126     2 143.4
2012  18  3   4.2  420. 126     2 143.4
2012  18  4   4.0  401. 126    -2 143.4
2012  18  5   3.8  399. 126    -1 143.4
2012  18  6   3.5  388. 126    -1 143.4
2012  18  7   4.4  393. 126    -2 143.4
2012  18  8   4.7  405. 126    -3 143.4
2012  18  9   4.8  409. 126    -4 143.4
2012  18 10   4.9  409. 126    -3 143.4
2012  18 11   5.0  411. 126    -5 143.4
2012  18 12   5.1  405. 126    -5 143.4
2012  18 13   5.2  403. 126    -6 143.4
2012  18 14   5.1  394. 126    -4 143.4
2012  18 15   5.0  391. 126    -5 143.4
2012  18 16   4.6  387. 126    -4 143.4
2012  18 17   4.7  376. 126    -2 143.4
2012  18 18   4.7  381. 126    -1 143.4
2012  18 19   4.5  382. 126    -2 143.4
2012  18 20   4.9  386. 126    -5 143.4
2012  18 21   4.8  375. 126    -5 143.4
2012  18 22   4.7  385. 126    -6 143.4
2012  18 23   4.7  381. 126    -5 143.4
2012  19  0   4.3  372. 105    -3 152.0
2012  19  1   4.2  361. 105    -4 152.0
2012  19  2   4.0  360. 105    -5 152.0
2012  19  3   3.9  362. 105    -4 152.0
*Jibrin Adejoh Alhassan (Ph.D)*
Department of Physics and Astronomy,
University of Nigeria, Nsukka


On Mon, Jun 17, 2024 at 7:50?AM Jibrin Alhassan <jibrin.alhassan at unn.edu.ng>
wrote:

> Hello Rui,
> Your patience is indeed amazing. Your script tested as shown below worked
> perfectly well.
> df1 <- read.table(text = "YEAR DOY HR   IMF  SW   SSN    Dst f10.7
> 2012 215  4   5.1  371. 143    -4 138.6 ", header = TRUE)
> with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
> df1$Date <- with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
> df1 <- df1[-(1:2)]
> df1 <- df1[c(ncol(df1), 1:(ncol(df1) - 1L))]
> head(df1).
> But  I have 43,849 data points. Your script only generated one. Help me
> with a script that can handle the whole data points. I have tried following
> your tested solution but was unsuccessful. My regards.
> *Jibrin Adejoh Alhassan (Ph.D)*
> Department of Physics and Astronomy,
> University of Nigeria, Nsukka
>
>
> On Sun, Jun 16, 2024 at 8:33?AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
>> ?s 21:42 de 15/06/2024, Jibrin Alhassan escreveu:
>> > Thank you Rui. I ran the following script
>> > df1 <- read.table("solar_hour", header = TRUE)
>> > df1$date <- as.Date(paste(df1$year, df1$hour),
>> >   format = "%Y %j",
>> > origin = "2012-08-01-0")
>> > df2 <- df1[c("date", "IMF", "SWS", "SSN", "Dst", "f10")]
>> > head(df1)
>> > #To display all the rows
>> >   print(df2).
>> > It gave me this error message
>> >> source ("script.R")
>> > Error in `$<-.data.frame`(`*tmp*`, date, value = numeric(0)) :
>> >    replacement has 0 rows, data has 38735
>> >> print(df2)
>> > Error: object 'df2' not found
>> >> My data is an hourly data but desire to have the date as
>> > year    month    day   hour
>> > 2012   08         01     01
>> > 2012   08         01     02
>> > 2012   08        01      03 etc
>> > Thanks.
>> >
>> > *Jibrin Adejoh Alhassan (Ph.D)*
>> > Department of Physics and Astronomy,
>> > University of Nigeria, Nsukka
>> >
>> >
>> > On Sat, Jun 15, 2024 at 8:34?PM Rui Barradas <ruipbarradas at sapo.pt>
>> wrote:
>> >
>> >> ?s 20:00 de 15/06/2024, Jibrin Alhassan escreveu:
>> >>> I have solar-geophysical data e.g as blow:
>> >>> YEAR DOY HR   IMF  SW   SSN    Dst f10.7
>> >>> 2012 214  0   3.4  403. 132    -9 154.6
>> >>> 2012 214  1   3.7  388. 132   -10 154.6
>> >>> 2012 214  2   3.7  383. 132   -10 154.6
>> >>> 2012 214  3   3.7  391. 132    -9 154.6
>> >>> 2012 214  4   4.2  399. 132    -7 154.6
>> >>> 2012 214  5   4.1  411. 132    -6 154.6
>> >>> 2012 214  6   4.0  407. 132    -6 154.6
>> >>> 2012 214  7   4.2  404. 132    -4 154.6
>> >>> 2012 214  8   4.3  405. 132    -6 154.6
>> >>> 2012 214  9   4.4  409. 132    -6 154.6
>> >>> 2012 214 10   4.4  401. 132    -6 154.6
>> >>> 2012 214 11   4.5  385. 132    -7 154.6
>> >>> 2012 214 12   4.7  377. 132    -8 154.6
>> >>> 2012 214 13   4.7  382. 132    -6 154.6
>> >>> 2012 214 14   4.3  396. 132    -4 154.6
>> >>> 2012 214 15   4.1  384. 132    -2 154.6
>> >>> 2012 214 16   4.0  382. 132    -1 154.6
>> >>> 2012 214 17   3.9  397. 132     0 154.6
>> >>> 2012 214 18   3.8  390. 132     1 154.6
>> >>> 2012 214 19   4.2  400. 132     2 154.6
>> >>> 2012 214 20   4.6  408. 132     1 154.6
>> >>> 2012 214 21   4.8  401. 132    -3 154.6
>> >>> 2012 214 22   4.9  395. 132    -5 154.6
>> >>> 2012 214 23   5.0  386. 132    -1 154.6
>> >>> 2012 215  0   5.0  377. 143    -1 138.6
>> >>> 2012 215  1   4.9  384. 143    -2 138.6
>> >>> 2012 215  2   4.9  390. 143    -4 138.6
>> >>> 2012 215  3   4.9  372. 143    -6 138.6
>> >>> 2012 215  4   5.1  371. 143    -4 138.6
>> >>> I want to process it to be of the format as shown below
>> >>>    y   m  d  hr imf  sws  ssn    Dst f10.7
>> >>> 2012-08-01 10 3.4  403. 132    -9 154.6
>> >>> 2012-08-01 12 3.7  388. 132   -10 154.6
>> >>> 2012-08-01 15 3.7  383. 132   -10 154.6
>> >>> 2012-08-01 17 3.7  391. 132    -9 154.6
>> >>> I want to request an R code to accomplish this task. Thanks for your
>> >> time.
>> >>> *Jibrin Adejoh Alhassan (Ph.D)*
>> >>> Department of Physics and Astronomy,
>> >>> University of Nigeria, Nsukka
>> >>>
>> >>>        [[alternative HTML version deleted]]
>> >>>
>> >>> ______________________________________________
>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible code.
>> >> Hello,
>> >>
>> >> To create a date column, paste the first two columns and coerce to
>> class
>> >> "Date" with conversion specifications %Y for the 4 digit year and %j
>> for
>> >> the day of year. See
>> >>
>> >> help("strptime")
>> >>
>> >>
>> >>
>> >> df1 <- read.table(text = "YEAR DOY HR   IMF  SW   SSN    Dst f10.7
>> >> 2012 214  0   3.4  403. 132    -9 154.6
>> >> 2012 214  1   3.7  388. 132   -10 154.6
>> >> 2012 214  2   3.7  383. 132   -10 154.6
>> >> 2012 214  3   3.7  391. 132    -9 154.6
>> >> 2012 214  4   4.2  399. 132    -7 154.6
>> >> 2012 214  5   4.1  411. 132    -6 154.6
>> >> 2012 214  6   4.0  407. 132    -6 154.6
>> >> 2012 214  7   4.2  404. 132    -4 154.6
>> >> 2012 214  8   4.3  405. 132    -6 154.6
>> >> 2012 214  9   4.4  409. 132    -6 154.6
>> >> 2012 214 10   4.4  401. 132    -6 154.6
>> >> 2012 214 11   4.5  385. 132    -7 154.6
>> >> 2012 214 12   4.7  377. 132    -8 154.6
>> >> 2012 214 13   4.7  382. 132    -6 154.6
>> >> 2012 214 14   4.3  396. 132    -4 154.6
>> >> 2012 214 15   4.1  384. 132    -2 154.6
>> >> 2012 214 16   4.0  382. 132    -1 154.6
>> >> 2012 214 17   3.9  397. 132     0 154.6
>> >> 2012 214 18   3.8  390. 132     1 154.6
>> >> 2012 214 19   4.2  400. 132     2 154.6
>> >> 2012 214 20   4.6  408. 132     1 154.6
>> >> 2012 214 21   4.8  401. 132    -3 154.6
>> >> 2012 214 22   4.9  395. 132    -5 154.6
>> >> 2012 214 23   5.0  386. 132    -1 154.6
>> >> 2012 215  0   5.0  377. 143    -1 138.6
>> >> 2012 215  1   4.9  384. 143    -2 138.6
>> >> 2012 215  2   4.9  390. 143    -4 138.6
>> >> 2012 215  3   4.9  372. 143    -6 138.6
>> >> 2012 215  4   5.1  371. 143    -4 138.6", header = TRUE)
>> >>
>> >>
>> >> with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
>> >> #>  [1] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>> "2012-08-01"
>> >> #>  [6] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>> "2012-08-01"
>> >> #> [11] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>> "2012-08-01"
>> >> #> [16] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>> "2012-08-01"
>> >> #> [21] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>> "2012-08-02"
>> >> #> [26] "2012-08-02" "2012-08-02" "2012-08-02" "2012-08-02"
>> >>
>> >> # now create the column
>> >> df1$Date <- with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
>> >> # remove the columns no longer needed
>> >> df1 <- df1[-(1:2)]
>> >> # relocate the new date column
>> >> df1 <- df1[c(ncol(df1), 1:(ncol(df1) - 1L))]
>> >> head(df1)
>> >> #>         Date HR IMF  SW SSN Dst f10.7
>> >> #> 1 2012-08-01  0 3.4 403 132  -9 154.6
>> >> #> 2 2012-08-01  1 3.7 388 132 -10 154.6
>> >> #> 3 2012-08-01  2 3.7 383 132 -10 154.6
>> >> #> 4 2012-08-01  3 3.7 391 132  -9 154.6
>> >> #> 5 2012-08-01  4 4.2 399 132  -7 154.6
>> >> #> 6 2012-08-01  5 4.1 411 132  -6 154.6
>> >>
>> >>
>> >> Hope this helps,
>> >>
>> >> Rui Barradas
>> >>
>> >>
>> >> --
>> >> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
>> >> presen?a de v?rus.
>> >> www.avg.com
>> >>
>> >
>> Hello,
>>
>> There is an error in your new code:
>>
>>
>> paste YEAR with DOY, not with HR.
>>
>>
>> As for the rest, is your real data like the one you posted before?
>> If it is then I don't see anything wrong with my (tested) solution.
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>>
>> --
>> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
>> presen?a de v?rus.
>> www.avg.com
>>
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Jun 17 09:14:36 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 17 Jun 2024 08:14:36 +0100
Subject: [R] code for year month day hr format
In-Reply-To: <CAEGeL+FS6hN7OJqh=6NveMTMVA8Ct_mpRdGdqdezVBoXiTRe6g@mail.gmail.com>
References: <CAEGeL+EDsd2LnZ0v5cY-0S7ofE_qxKi-QGV2+WnSzODywRZ9MQ@mail.gmail.com>
 <474f21f7-7a41-403f-826f-853f6589ec52@sapo.pt>
 <CAEGeL+H_eukBiQKyDb1GOGo5K2kcyM7S6n167ukBWoGrQUgLyg@mail.gmail.com>
 <9347708a-d116-4879-8809-e2b5abadff25@sapo.pt>
 <CAEGeL+Hv5vXMo8yqeTTXpjXMVicSpEzk9W0pM0jd0gWRMiVsqQ@mail.gmail.com>
 <CAEGeL+FS6hN7OJqh=6NveMTMVA8Ct_mpRdGdqdezVBoXiTRe6g@mail.gmail.com>
Message-ID: <053e2864-deb4-42bb-a505-555c8f9c7360@sapo.pt>

?s 07:53 de 17/06/2024, Jibrin Alhassan escreveu:
> Part of it is pasted below
> YEAR DOY HR    IMF SWS   SSN   Dst f10.7
> 2012   1  0   4.0  379.  71    -8 999.9
> 2012   1  1   4.4  386.  71    -3 999.9
> 2012   1  2   4.8  380.  71    -4 999.9
> 2012   1  3   5.4  374.  71    -5 999.9
> 2012   1  4   4.5  369.  71    -9 999.9
> 2012   1  5   4.2  368.  71    -7 999.9
> 2012   1  6   4.7  367.  71    -6 999.9
> 2012   1  7   4.1  361.  71   -10 999.9
> 2012   1  8   3.2  362.  71    -7 999.9
> 2012   1  9   4.3  367.  71    -3 999.9
> 2012   1 10   4.5  365.  71    -6 999.9
> 2012   1 11   5.6  369.  71    -8 999.9
> 2012   1 12   5.2  366.  71    -8 999.9
> 2012   1 13   4.4  370.  71    -7 999.9
> 2012   1 14   4.8  357.  71    -5 999.9
> 2012   1 15   4.6  354.  71    -8 999.9
> 2012   1 16   3.7  382.  71    -7 999.9
> 2012   1 17   3.2  376.  71    -2 999.9
> 2012   1 18   2.8  368.  71     2 999.9
> 2012   1 19   3.2  361.  71     2 999.9
> 2012   1 20   3.2  361.  71    -3 999.9
> 2012   1 21   3.5  365.  71    -5 999.9
> 2012   1 22   3.6  364.  71    -3 999.9
> 2012   1 23   3.0  362.  71    -3 999.9
> 2012   2  0   3.2  359.  92    -5 130.3
> 2012   2  1   3.0  361.  92    -4 130.3
> 2012   2  2   4.5  374.  92     3 130.3
> 2012   2  3   4.5  364.  92     5 130.3
> 2012   2  4   5.1  352.  92     3 130.3
> 2012   2  5   4.9  358.  92     3 130.3
> 2012   2  6   4.4  346.  92     4 130.3
> 2012   2  7   4.2  349.  92     7 130.3
> 2012   2  8   4.5  346.  92     8 130.3
> 2012   2  9   5.2  345.  92     7 130.3
> 2012   2 10   5.0  349.  92     5 130.3
> 2012   2 11   4.8  345.  92     0 130.3
> 2012   2 12   5.3  347.  92     0 130.3
> 2012   2 13   5.5  342.  92     0 130.3
> 2012   2 14   6.1  359.  92     1 130.3
> 2012   2 15   6.2  393.  92     8 130.3
> 2012   2 16   6.7  390.  92    10 130.3
> 2012   2 17   7.7  369.  92    10 130.3
> 2012   2 18   9.4  380.  92    14 130.3
> 2012   2 19  10.6  386.  92    12 130.3
> 2012   2 20  10.2  378.  92    11 130.3
> 2012   2 21  11.6  369.  92     7 130.3
> 2012   2 22  12.0  369.  92     8 130.3
> 2012   2 23  10.5  361.  92     1 130.3
> 2012   3  0  11.3  403. 120    -7 130.2
> 2012   3  1  10.3  412. 120   -14 130.2
> 2012   3  2   8.8  419. 120   -18 130.2
> 2012   3  3   8.3  412. 120   -23 130.2
> 2012   3  4   8.0  408. 120   -25 130.2
> 2012   3  5   7.0  380. 120   -28 130.2
> 2012   3  6   6.9  374. 120   -29 130.2
> 2012   3  7   6.9  372. 120   -30 130.2
> 2012   3  8   7.1  365. 120   -32 130.2
> 2012   3  9   6.8  376. 120   -35 130.2
> 2012   3 10   6.7  380. 120   -35 130.2
> 2012   3 11   6.4  381. 120   -30 130.2
> 2012   3 12   5.9  401. 120   -26 130.2
> 2012   3 13   5.9  405. 120   -23 130.2
> 2012   3 14   5.9  413. 120   -20 130.2
> 2012   3 15   5.9  406. 120   -20 130.2
> 2012   3 16   6.3  427. 120   -20 130.2
> 2012   3 17   5.9  424. 120   -19 130.2
> 2012   3 18   4.8  390. 120   -16 130.2
> 2012   3 19   4.8  374. 120   -15 130.2
> 2012   3 20   4.8  374. 120   -15 130.2
> 2012   3 21   5.1  378. 120   -18 130.2
> 2012   3 22   4.9  375. 120   -19 130.2
> 2012   3 23   4.7  364. 120   -17 130.2
> 2012   4  0   4.3  359. 126   -17 131.6
> 2012   4  1   4.3  359. 126   -15 131.6
> 2012   4  2   4.2  358. 126   -13 131.6
> 2012   4  3   3.8  359. 126   -13 131.6
> 2012   4  4   3.8  358. 126   -13 131.6
> 2012   4  5   3.7  359. 126   -14 131.6
> 2012   4  6   3.9  361. 126   -13 131.6
> 2012   4  7   3.7  364. 126   -13 131.6
> 2012   4  8   3.7  366. 126   -12 131.6
> 2012   4  9   3.8  363. 126   -10 131.6
> 2012   4 10   3.5  363. 126    -8 131.6
> 2012   4 11   3.0  352. 126   -10 131.6
> 2012   4 12   3.1  348. 126   -12 131.6
> 2012   4 13   3.3  340. 126    -9 131.6
> 2012   4 14   4.0  343. 126    -8 131.6
> 2012   4 15   4.2  343. 126    -7 131.6
> 2012   4 16   3.8  336. 126    -5 131.6
> 2012   4 17   3.9  334. 126    -6 131.6
> 2012   4 18   3.8  329. 126    -5 131.6
> 2012   4 19   3.8  326. 126    -4 131.6
> 2012   4 20   4.3  337. 126    -3 131.6
> 2012   4 21   3.9  331. 126     0 131.6
> 2012   4 22   3.8  322. 126    -1 131.6
> 2012   4 23   3.5  331. 126    -1 131.6
> 2012   5  0   3.9  312. 109    -3 136.6
> 2012   5  1   3.6  311. 109    -1 136.6
> 2012   5  2   3.7  312. 109     0 136.6
> 2012   5  3   3.8  308. 109     0 136.6
> 2012   5  4   4.0  305. 109     2 136.6
> 2012   5  5   4.5  309. 109     2 136.6
> 2012   5  6   3.5  314. 109     3 136.6
> 2012   5  7   3.6  305. 109     2 136.6
> 2012   5  8   4.3  307. 109     2 136.6
> 2012   5  9   4.6  316. 109     1 136.6
> 2012   5 10   5.0  321. 109    -4 136.6
> 2012   5 11   5.1  321. 109    -6 136.6
> 2012   5 12   4.6  326. 109    -4 136.6
> 2012   5 13   5.7  321. 109    -2 136.6
> 2012   5 14   5.0  316. 109     1 136.6
> 2012   5 15   4.6  315. 109     2 136.6
> 2012   5 16   5.5  321. 109     7 136.6
> 2012   5 17   7.2  327. 109     7 136.6
> 2012   5 18   9.2  329. 109     3 136.6
> 2012   5 19   9.4  341. 109     3 136.6
> 2012   5 20   9.2  345. 109     8 136.6
> 2012   5 21   9.8  344. 109     9 136.6
> 2012   5 22   9.8  341. 109    10 136.6
> 2012   5 23  10.0  351. 109    15 136.6
> 2012   6  0  10.4  356. 113    12 131.0
> 2012   6  1   9.1  360. 113    10 131.0
> 2012   6  2   6.6  392. 113    10 131.0
> 2012   6  3   6.9  418. 113     7 131.0
> 2012   6  4   6.5  408. 113     4 131.0
> 2012   6  5   6.6  413. 113     7 131.0
> 2012   6  6   7.3  428. 113     6 131.0
> 2012   6  7   7.3  416. 113     4 131.0
> 2012   6  8   7.0  411. 113     1 131.0
> 2012   6  9   7.2  415. 113     1 131.0
> 2012   6 10   7.2  426. 113     0 131.0
> 2012   6 11   6.5  431. 113    -2 131.0
> 2012   6 12   6.4  431. 113    -2 131.0
> 2012   6 13   6.6  435. 113     0 131.0
> 2012   6 14   6.2  425. 113     2 131.0
> 2012   6 15   5.7  431. 113     4 131.0
> 2012   6 16   6.1  431. 113     1 131.0
> 2012   6 17   5.7  425. 113    -3 131.0
> 2012   6 18   5.8  431. 113    -1 131.0
> 2012   6 19   6.4  425. 113     2 131.0
> 2012   6 20   6.0  434. 113     1 131.0
> 2012   6 21   6.3  420. 113     0 131.0
> 2012   6 22   6.3  440. 113    -3 131.0
> 2012   6 23   6.5  456. 113    -3 131.0
> 2012   7  0   6.3  435. 113    -5 135.9
> 2012   7  1   5.9  428. 113    -1 135.9
> 2012   7  2   5.7  434. 113     1 135.9
> 2012   7  3   5.3  423. 113     0 135.9
> 2012   7  4   4.3  417. 113     1 135.9
> 2012   7  5   5.4  420. 113     0 135.9
> 2012   7  6   5.7  434. 113     1 135.9
> 2012   7  7   5.5  423. 113     1 135.9
> 2012   7  8   4.8  419. 113    -2 135.9
> 2012   7  9   5.8  421. 113    -6 135.9
> 2012   7 10   5.3  412. 113    -9 135.9
> 2012   7 11   4.6  424. 113    -7 135.9
> 2012   7 12   4.0  439. 113    -3 135.9
> 2012   7 13   4.8  431. 113    -1 135.9
> 2012   7 14   5.1  431. 113    -1 135.9
> 2012   7 15   4.8  427. 113    -1 135.9
> 2012   7 16   4.7  429. 113    -5 135.9
> 2012   7 17   5.3  436. 113    -6 135.9
> 2012   7 18   5.1  426. 113    -5 135.9
> 2012   7 19   5.2  427. 113    -4 135.9
> 2012   7 20   4.5  416. 113    -5 135.9
> 2012   7 21   4.9  409. 113    -4 135.9
> 2012   7 22   5.0  417. 113    -4 135.9
> 2012   7 23   5.0  426. 113    -4 135.9
> 2012   8  0   5.0  433. 104    -2 131.4
> 2012   8  1   4.9  426. 104    -2 131.4
> 2012   8  2   4.7  421. 104    -4 131.4
> 2012   8  3   4.4  417. 104    -5 131.4
> 2012   8  4   4.3  416. 104    -8 131.4
> 2012   8  5   4.5  416. 104    -8 131.4
> 2012   8  6   5.0  419. 104    -6 131.4
> 2012   8  7   5.4  446. 104    -1 131.4
> 2012   8  8   5.3  439. 104    -2 131.4
> 2012   8  9   5.3  432. 104    -4 131.4
> 2012   8 10   5.4  434. 104    -4 131.4
> 2012   8 11   5.4  435. 104    -3 131.4
> 2012   8 12   4.5  421. 104    -4 131.4
> 2012   8 13   4.5  422. 104    -4 131.4
> 2012   8 14   5.1  425. 104    -2 131.4
> 2012   8 15   5.3  429. 104     1 131.4
> 2012   8 16   5.5  433. 104    -2 131.4
> 2012   8 17   5.9  440. 104    -2 131.4
> 2012   8 18   6.6  445. 104    -1 131.4
> 2012   8 19   6.4  442. 104    -4 131.4
> 2012   8 20   5.9  434. 104    -6 131.4
> 2012   8 21   5.3  429. 104    -7 131.4
> 2012   8 22   4.8  438. 104    -2 131.4
> 2012   8 23   5.3  427. 104     4 131.4
> 2012   9  0   5.5  433.  79     8 137.6
> 2012   9  1   5.2  445.  79     9 137.6
> 2012   9  2   5.4  439.  79    10 137.6
> 2012   9  3   5.3  430.  79     7 137.6
> 2012   9  4   5.1  426.  79    -3 137.6
> 2012   9  5   4.7  415.  79    -6 137.6
> 2012   9  6   5.0  412.  79    -4 137.6
> 2012   9  7   5.2  418.  79    -2 137.6
> 2012   9  8   5.5  441.  79     2 137.6
> 2012   9  9   5.1  441.  79     2 137.6
> 2012   9 10   5.4  430.  79    -2 137.6
> 2012   9 11   5.3  433.  79    -1 137.6
> 2012   9 12   5.5  438.  79     5 137.6
> 2012   9 13   5.4  436.  79     6 137.6
> 2012   9 14   5.7  440.  79     9 137.6
> 2012   9 15   5.9  430.  79     9 137.6
> 2012   9 16   5.8  437.  79     4 137.6
> 2012   9 17   4.9  431.  79    -3 137.6
> 2012   9 18   5.3  424.  79    -3 137.6
> 2012   9 19   5.7  437.  79    -2 137.6
> 2012   9 20   6.1  427.  79    -4 137.6
> 2012   9 21   6.0  409.  79    -7 137.6
> 2012   9 22   6.6  410.  79    -4 137.6
> 2012   9 23   6.4  432.  79    -1 137.6
> 2012  10  0   5.9  434.  70     2 124.6
> 2012  10  1   5.6  424.  70     4 124.6
> 2012  10  2   4.8  435.  70     7 124.6
> 2012  10  3   4.6  425.  70     4 124.6
> 2012  10  4   4.3  424.  70     3 124.6
> 2012  10  5   5.4  426.  70     2 124.6
> 2012  10  6   5.5  434.  70     2 124.6
> 2012  10  7   6.4  435.  70     4 124.6
> 2012  10  8   6.3  436.  70     1 124.6
> 2012  10  9   5.2  431.  70    -6 124.6
> 2012  10 10   4.5  426.  70   -10 124.6
> 2012  10 11   4.6  435.  70    -9 124.6
> 2012  10 12   3.4  425.  70    -5 124.6
> 2012  10 13   4.2  427.  70    -4 124.6
> 2012  10 14   4.0  432.  70     2 124.6
> 2012  10 15   5.5  450.  70     7 124.6
> 2012  10 16   5.9  451.  70     2 124.6
> 2012  10 17   5.5  445.  70    -3 124.6
> 2012  10 18   5.8  442.  70    -2 124.6
> 2012  10 19   5.4  430.  70    -1 124.6
> 2012  10 20   4.9  427.  70    -1 124.6
> 2012  10 21   4.0  436.  70     0 124.6
> 2012  10 22   3.4  445.  70    -1 124.6
> 2012  10 23   4.5  453.  70     0 124.6
> 2012  11  0   5.3  438.  63     1 116.1
> 2012  11  1   5.0  438.  63     3 116.1
> 2012  11  2   5.3  445.  63     3 116.1
> 2012  11  3   4.5  451.  63     2 116.1
> 2012  11  4   5.0  456.  63    -1 116.1
> 2012  11  5   4.6  459.  63     0 116.1
> 2012  11  6   5.1  459.  63     1 116.1
> 2012  11  7   4.0  466.  63     3 116.1
> 2012  11  8   5.0  478.  63    -1 116.1
> 2012  11  9   4.6  489.  63    -2 116.1
> 2012  11 10   4.5  493.  63    -4 116.1
> 2012  11 11   4.5  494.  63    -1 116.1
> 2012  11 12   3.6  504.  63     3 116.1
> 2012  11 13   3.5  496.  63     5 116.1
> 2012  11 14   3.3  497.  63     7 116.1
> 2012  11 15   3.0  498.  63     7 116.1
> 2012  11 16   2.1  503.  63     3 116.1
> 2012  11 17   2.0  495.  63     0 116.1
> 2012  11 18   2.5  492.  63    -2 116.1
> 2012  11 19   2.2  496.  63    -1 116.1
> 2012  11 20   2.4  489.  63     1 116.1
> 2012  11 21   2.6  489.  63     3 116.1
> 2012  11 22   2.6  483.  63     2 116.1
> 2012  11 23   2.6  478.  63     2 116.1
> 2012  12  0   2.9  453.  52     3 113.0
> 2012  12  1   2.2  446.  52     4 113.0
> 2012  12  2   2.4  442.  52     8 113.0
> 2012  12  3   2.6  440.  52    10 113.0
> 2012  12  4   2.2  438.  52    11 113.0
> 2012  12  5   2.8  438.  52     9 113.0
> 2012  12  6   2.0  437.  52     8 113.0
> 2012  12  7   2.4  426.  52     7 113.0
> 2012  12  8   3.0  423.  52     5 113.0
> 2012  12  9   3.3  420.  52     4 113.0
> 2012  12 10   4.0  419.  52     2 113.0
> 2012  12 11   3.8  412.  52     5 113.0
> 2012  12 12   4.2  409.  52     4 113.0
> 2012  12 13   3.5  408.  52     2 113.0
> 2012  12 14   3.7  404.  52     9 113.0
> 2012  12 15   4.5  402.  52    15 113.0
> 2012  12 16   3.6  395.  52    14 113.0
> 2012  12 17   2.4  392.  52    16 113.0
> 2012  12 18   5.8  403.  52    27 113.0
> 2012  12 19   7.6  400.  52    27 113.0
> 2012  12 20   6.9  418.  52    17 113.0
> 2012  12 21   6.9  463.  52    10 113.0
> 2012  12 22   7.3  469.  52     9 113.0
> 2012  12 23   5.5  482.  52    12 113.0
> 2012  13  0   7.7  500.  71    10 120.0
> 2012  13  1   8.7  492.  71    14 120.0
> 2012  13  2   7.8  513.  71    16 120.0
> 2012  13  3   7.5  530.  71    11 120.0
> 2012  13  4   7.1  518.  71     8 120.0
> 2012  13  5   7.0  524.  71     6 120.0
> 2012  13  6   5.9  536.  71     8 120.0
> 2012  13  7   3.6  529.  71     5 120.0
> 2012  13  8   4.1  510.  71     4 120.0
> 2012  13  9   3.9  497.  71     3 120.0
> 2012  13 10   2.4  492.  71     3 120.0
> 2012  13 11   2.6  485.  71     5 120.0
> 2012  13 12   2.9  492.  71     5 120.0
> 2012  13 13   2.6  487.  71     3 120.0
> 2012  13 14   2.3  478.  71     6 120.0
> 2012  13 15   3.2  467.  71    11 120.0
> 2012  13 16   3.4  453.  71    10 120.0
> 2012  13 17   3.2  452.  71     6 120.0
> 2012  13 18   3.0  452.  71     2 120.0
> 2012  13 19   2.8  447.  71     1 120.0
> 2012  13 20   2.5  439.  71     0 120.0
> 2012  13 21   2.5  443.  71    -2 120.0
> 2012  13 22   2.7  442.  71    -3 120.0
> 2012  13 23   3.0  447.  71    -4 120.0
> 2012  14  0   3.5  445. 118    -3 128.0
> 2012  14  1   3.3  440. 118    -1 128.0
> 2012  14  2   3.1  440. 118     1 128.0
> 2012  14  3   2.7  446. 118     0 128.0
> 2012  14  4   2.9  442. 118    -1 128.0
> 2012  14  5   2.9  437. 118    -2 128.0
> 2012  14  6   3.3  431. 118    -3 128.0
> 2012  14  7   2.8  420. 118    -2 128.0
> 2012  14  8   2.3  409. 118    -2 128.0
> 2012  14  9   2.2  407. 118     1 128.0
> 2012  14 10   2.6  405. 118     3 128.0
> 2012  14 11   2.8  401. 118     4 128.0
> 2012  14 12   3.2  398. 118     4 128.0
> 2012  14 13   2.7  400. 118     4 128.0
> 2012  14 14   1.9  399. 118     5 128.0
> 2012  14 15   2.4  395. 118     3 128.0
> 2012  14 16   2.7  389. 118     2 128.0
> 2012  14 17   2.9  385. 118     0 128.0
> 2012  14 18   3.2  384. 118     1 128.0
> 2012  14 19   2.6  380. 118     2 128.0
> 2012  14 20   2.3  378. 118     1 128.0
> 2012  14 21   2.1  374. 118     0 128.0
> 2012  14 22   3.1  367. 118     0 128.0
> 2012  14 23   4.0  366. 118    -1 128.0
> 2012  15  0   4.8  363. 149     0 129.2
> 2012  15  1   4.0  359. 149     2 129.2
> 2012  15  2   3.4  354. 149     2 129.2
> 2012  15  3   3.0  349. 149     5 129.2
> 2012  15  4   2.7  344. 149     7 129.2
> 2012  15  5   2.4  349. 149    11 129.2
> 2012  15  6   2.9  343. 149    12 129.2
> 2012  15  7   3.5  333. 149     7 129.2
> 2012  15  8   3.6  341. 149     4 129.2
> 2012  15  9   3.7  345. 149     1 129.2
> 2012  15 10   3.6  343. 149     2 129.2
> 2012  15 11   3.6  342. 149     3 129.2
> 2012  15 12   3.7  340. 149     7 129.2
> 2012  15 13   3.7  342. 149     8 129.2
> 2012  15 14   4.1  344. 149     9 129.2
> 2012  15 15   3.9  345. 149     4 129.2
> 2012  15 16   4.4  355. 149     8 129.2
> 2012  15 17   4.7  360. 149    11 129.2
> 2012  15 18   5.4  359. 149    12 129.2
> 2012  15 19   6.8  353. 149     8 129.2
> 2012  15 20   6.6  349. 149     6 129.2
> 2012  15 21   5.9  364. 149     2 129.2
> 2012  15 22   5.2  394. 149     1 129.2
> 2012  15 23   6.3  395. 149     5 129.2
> 2012  16  0   6.3  385. 154     6 135.1
> 2012  16  1   6.6  397. 154     2 135.1
> 2012  16  2   6.7  400. 154     4 135.1
> 2012  16  3   6.9  396. 154     5 135.1
> 2012  16  4   7.9  392. 154     5 135.1
> 2012  16  5   4.6  379. 154    10 135.1
> 2012  16  6   8.0  365. 154    13 135.1
> 2012  16  7   6.3  358. 154    16 135.1
> 2012  16  8   7.9  380. 154    12 135.1
> 2012  16  9  10.2  391. 154    10 135.1
> 2012  16 10   8.1  394. 154     8 135.1
> 2012  16 11  12.1  412. 154    -8 135.1
> 2012  16 12  13.2  424. 154   -10 135.1
> 2012  16 13  12.9  433. 154    -8 135.1
> 2012  16 14   9.3  461. 154    -7 135.1
> 2012  16 15   6.6  466. 154   -14 135.1
> 2012  16 16   6.6  493. 154   -11 135.1
> 2012  16 17   7.4  496. 154    -7 135.1
> 2012  16 18   6.2  493. 154    -7 135.1
> 2012  16 19   6.9  492. 154   -13 135.1
> 2012  16 20   6.8  486. 154   -19 135.1
> 2012  16 21   5.6  488. 154   -14 135.1
> 2012  16 22   6.4  464. 154   -11 135.1
> 2012  16 23   6.0  459. 154   -10 135.1
> 2012  17  0   4.9  476. 141   -14 134.5
> 2012  17  1   4.6  460. 141   -20 134.5
> 2012  17  2   4.1  467. 141   -17 134.5
> 2012  17  3   3.7  469. 141   -13 134.5
> 2012  17  4   3.3  472. 141   -12 134.5
> 2012  17  5   2.7  472. 141    -8 134.5
> 2012  17  6   3.5  459. 141    -6 134.5
> 2012  17  7   3.9  459. 141    -6 134.5
> 2012  17  8   4.1  463. 141    -7 134.5
> 2012  17  9   4.1  443. 141   -10 134.5
> 2012  17 10   4.1  446. 141   -14 134.5
> 2012  17 11   4.1  442. 141   -13 134.5
> 2012  17 12   3.6  436. 141   -10 134.5
> 2012  17 13   3.6  433. 141    -6 134.5
> 2012  17 14   4.2  421. 141    -1 134.5
> 2012  17 15   3.7  416. 141    -2 134.5
> 2012  17 16   4.2  410. 141    -1 134.5
> 2012  17 17   4.6  396. 141    -1 134.5
> 2012  17 18   4.5  398. 141    -2 134.5
> 2012  17 19   4.4  397. 141    -6 134.5
> 2012  17 20   4.5  396. 141    -8 134.5
> 2012  17 21   3.5  411. 141    -5 134.5
> 2012  17 22   3.9  425. 141    -5 134.5
> 2012  17 23   4.7  418. 141    -6 134.5
> 2012  18  0   4.6  400. 126    -7 143.4
> 2012  18  1   4.5  413. 126    -3 143.4
> 2012  18  2   4.4  418. 126     2 143.4
> 2012  18  3   4.2  420. 126     2 143.4
> 2012  18  4   4.0  401. 126    -2 143.4
> 2012  18  5   3.8  399. 126    -1 143.4
> 2012  18  6   3.5  388. 126    -1 143.4
> 2012  18  7   4.4  393. 126    -2 143.4
> 2012  18  8   4.7  405. 126    -3 143.4
> 2012  18  9   4.8  409. 126    -4 143.4
> 2012  18 10   4.9  409. 126    -3 143.4
> 2012  18 11   5.0  411. 126    -5 143.4
> 2012  18 12   5.1  405. 126    -5 143.4
> 2012  18 13   5.2  403. 126    -6 143.4
> 2012  18 14   5.1  394. 126    -4 143.4
> 2012  18 15   5.0  391. 126    -5 143.4
> 2012  18 16   4.6  387. 126    -4 143.4
> 2012  18 17   4.7  376. 126    -2 143.4
> 2012  18 18   4.7  381. 126    -1 143.4
> 2012  18 19   4.5  382. 126    -2 143.4
> 2012  18 20   4.9  386. 126    -5 143.4
> 2012  18 21   4.8  375. 126    -5 143.4
> 2012  18 22   4.7  385. 126    -6 143.4
> 2012  18 23   4.7  381. 126    -5 143.4
> 2012  19  0   4.3  372. 105    -3 152.0
> 2012  19  1   4.2  361. 105    -4 152.0
> 2012  19  2   4.0  360. 105    -5 152.0
> 2012  19  3   3.9  362. 105    -4 152.0
> *Jibrin Adejoh Alhassan (Ph.D)*
> Department of Physics and Astronomy,
> University of Nigeria, Nsukka
> 
> 
> On Mon, Jun 17, 2024 at 7:50?AM Jibrin Alhassan <jibrin.alhassan at unn.edu.ng>
> wrote:
> 
>> Hello Rui,
>> Your patience is indeed amazing. Your script tested as shown below worked
>> perfectly well.
>> df1 <- read.table(text = "YEAR DOY HR   IMF  SW   SSN    Dst f10.7
>> 2012 215  4   5.1  371. 143    -4 138.6 ", header = TRUE)
>> with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
>> df1$Date <- with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
>> df1 <- df1[-(1:2)]
>> df1 <- df1[c(ncol(df1), 1:(ncol(df1) - 1L))]
>> head(df1).
>> But  I have 43,849 data points. Your script only generated one. Help me
>> with a script that can handle the whole data points. I have tried following
>> your tested solution but was unsuccessful. My regards.
>> *Jibrin Adejoh Alhassan (Ph.D)*
>> Department of Physics and Astronomy,
>> University of Nigeria, Nsukka
>>
>>
>> On Sun, Jun 16, 2024 at 8:33?AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>
>>> ?s 21:42 de 15/06/2024, Jibrin Alhassan escreveu:
>>>> Thank you Rui. I ran the following script
>>>> df1 <- read.table("solar_hour", header = TRUE)
>>>> df1$date <- as.Date(paste(df1$year, df1$hour),
>>>>    format = "%Y %j",
>>>> origin = "2012-08-01-0")
>>>> df2 <- df1[c("date", "IMF", "SWS", "SSN", "Dst", "f10")]
>>>> head(df1)
>>>> #To display all the rows
>>>>    print(df2).
>>>> It gave me this error message
>>>>> source ("script.R")
>>>> Error in `$<-.data.frame`(`*tmp*`, date, value = numeric(0)) :
>>>>     replacement has 0 rows, data has 38735
>>>>> print(df2)
>>>> Error: object 'df2' not found
>>>>> My data is an hourly data but desire to have the date as
>>>> year    month    day   hour
>>>> 2012   08         01     01
>>>> 2012   08         01     02
>>>> 2012   08        01      03 etc
>>>> Thanks.
>>>>
>>>> *Jibrin Adejoh Alhassan (Ph.D)*
>>>> Department of Physics and Astronomy,
>>>> University of Nigeria, Nsukka
>>>>
>>>>
>>>> On Sat, Jun 15, 2024 at 8:34?PM Rui Barradas <ruipbarradas at sapo.pt>
>>> wrote:
>>>>
>>>>> ?s 20:00 de 15/06/2024, Jibrin Alhassan escreveu:
>>>>>> I have solar-geophysical data e.g as blow:
>>>>>> YEAR DOY HR   IMF  SW   SSN    Dst f10.7
>>>>>> 2012 214  0   3.4  403. 132    -9 154.6
>>>>>> 2012 214  1   3.7  388. 132   -10 154.6
>>>>>> 2012 214  2   3.7  383. 132   -10 154.6
>>>>>> 2012 214  3   3.7  391. 132    -9 154.6
>>>>>> 2012 214  4   4.2  399. 132    -7 154.6
>>>>>> 2012 214  5   4.1  411. 132    -6 154.6
>>>>>> 2012 214  6   4.0  407. 132    -6 154.6
>>>>>> 2012 214  7   4.2  404. 132    -4 154.6
>>>>>> 2012 214  8   4.3  405. 132    -6 154.6
>>>>>> 2012 214  9   4.4  409. 132    -6 154.6
>>>>>> 2012 214 10   4.4  401. 132    -6 154.6
>>>>>> 2012 214 11   4.5  385. 132    -7 154.6
>>>>>> 2012 214 12   4.7  377. 132    -8 154.6
>>>>>> 2012 214 13   4.7  382. 132    -6 154.6
>>>>>> 2012 214 14   4.3  396. 132    -4 154.6
>>>>>> 2012 214 15   4.1  384. 132    -2 154.6
>>>>>> 2012 214 16   4.0  382. 132    -1 154.6
>>>>>> 2012 214 17   3.9  397. 132     0 154.6
>>>>>> 2012 214 18   3.8  390. 132     1 154.6
>>>>>> 2012 214 19   4.2  400. 132     2 154.6
>>>>>> 2012 214 20   4.6  408. 132     1 154.6
>>>>>> 2012 214 21   4.8  401. 132    -3 154.6
>>>>>> 2012 214 22   4.9  395. 132    -5 154.6
>>>>>> 2012 214 23   5.0  386. 132    -1 154.6
>>>>>> 2012 215  0   5.0  377. 143    -1 138.6
>>>>>> 2012 215  1   4.9  384. 143    -2 138.6
>>>>>> 2012 215  2   4.9  390. 143    -4 138.6
>>>>>> 2012 215  3   4.9  372. 143    -6 138.6
>>>>>> 2012 215  4   5.1  371. 143    -4 138.6
>>>>>> I want to process it to be of the format as shown below
>>>>>>     y   m  d  hr imf  sws  ssn    Dst f10.7
>>>>>> 2012-08-01 10 3.4  403. 132    -9 154.6
>>>>>> 2012-08-01 12 3.7  388. 132   -10 154.6
>>>>>> 2012-08-01 15 3.7  383. 132   -10 154.6
>>>>>> 2012-08-01 17 3.7  391. 132    -9 154.6
>>>>>> I want to request an R code to accomplish this task. Thanks for your
>>>>> time.
>>>>>> *Jibrin Adejoh Alhassan (Ph.D)*
>>>>>> Department of Physics and Astronomy,
>>>>>> University of Nigeria, Nsukka
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> Hello,
>>>>>
>>>>> To create a date column, paste the first two columns and coerce to
>>> class
>>>>> "Date" with conversion specifications %Y for the 4 digit year and %j
>>> for
>>>>> the day of year. See
>>>>>
>>>>> help("strptime")
>>>>>
>>>>>
>>>>>
>>>>> df1 <- read.table(text = "YEAR DOY HR   IMF  SW   SSN    Dst f10.7
>>>>> 2012 214  0   3.4  403. 132    -9 154.6
>>>>> 2012 214  1   3.7  388. 132   -10 154.6
>>>>> 2012 214  2   3.7  383. 132   -10 154.6
>>>>> 2012 214  3   3.7  391. 132    -9 154.6
>>>>> 2012 214  4   4.2  399. 132    -7 154.6
>>>>> 2012 214  5   4.1  411. 132    -6 154.6
>>>>> 2012 214  6   4.0  407. 132    -6 154.6
>>>>> 2012 214  7   4.2  404. 132    -4 154.6
>>>>> 2012 214  8   4.3  405. 132    -6 154.6
>>>>> 2012 214  9   4.4  409. 132    -6 154.6
>>>>> 2012 214 10   4.4  401. 132    -6 154.6
>>>>> 2012 214 11   4.5  385. 132    -7 154.6
>>>>> 2012 214 12   4.7  377. 132    -8 154.6
>>>>> 2012 214 13   4.7  382. 132    -6 154.6
>>>>> 2012 214 14   4.3  396. 132    -4 154.6
>>>>> 2012 214 15   4.1  384. 132    -2 154.6
>>>>> 2012 214 16   4.0  382. 132    -1 154.6
>>>>> 2012 214 17   3.9  397. 132     0 154.6
>>>>> 2012 214 18   3.8  390. 132     1 154.6
>>>>> 2012 214 19   4.2  400. 132     2 154.6
>>>>> 2012 214 20   4.6  408. 132     1 154.6
>>>>> 2012 214 21   4.8  401. 132    -3 154.6
>>>>> 2012 214 22   4.9  395. 132    -5 154.6
>>>>> 2012 214 23   5.0  386. 132    -1 154.6
>>>>> 2012 215  0   5.0  377. 143    -1 138.6
>>>>> 2012 215  1   4.9  384. 143    -2 138.6
>>>>> 2012 215  2   4.9  390. 143    -4 138.6
>>>>> 2012 215  3   4.9  372. 143    -6 138.6
>>>>> 2012 215  4   5.1  371. 143    -4 138.6", header = TRUE)
>>>>>
>>>>>
>>>>> with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
>>>>> #>  [1] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>>> "2012-08-01"
>>>>> #>  [6] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>>> "2012-08-01"
>>>>> #> [11] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>>> "2012-08-01"
>>>>> #> [16] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>>> "2012-08-01"
>>>>> #> [21] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>>> "2012-08-02"
>>>>> #> [26] "2012-08-02" "2012-08-02" "2012-08-02" "2012-08-02"
>>>>>
>>>>> # now create the column
>>>>> df1$Date <- with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
>>>>> # remove the columns no longer needed
>>>>> df1 <- df1[-(1:2)]
>>>>> # relocate the new date column
>>>>> df1 <- df1[c(ncol(df1), 1:(ncol(df1) - 1L))]
>>>>> head(df1)
>>>>> #>         Date HR IMF  SW SSN Dst f10.7
>>>>> #> 1 2012-08-01  0 3.4 403 132  -9 154.6
>>>>> #> 2 2012-08-01  1 3.7 388 132 -10 154.6
>>>>> #> 3 2012-08-01  2 3.7 383 132 -10 154.6
>>>>> #> 4 2012-08-01  3 3.7 391 132  -9 154.6
>>>>> #> 5 2012-08-01  4 4.2 399 132  -7 154.6
>>>>> #> 6 2012-08-01  5 4.1 411 132  -6 154.6
>>>>>
>>>>>
>>>>> Hope this helps,
>>>>>
>>>>> Rui Barradas
>>>>>
>>>>>
>>>>> --
>>>>> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
>>>>> presen?a de v?rus.
>>>>> www.avg.com
>>>>>
>>>>
>>> Hello,
>>>
>>> There is an error in your new code:
>>>
>>>
>>> paste YEAR with DOY, not with HR.
>>>
>>>
>>> As for the rest, is your real data like the one you posted before?
>>> If it is then I don't see anything wrong with my (tested) solution.
>>>
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>>
>>>
>>> --
>>> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
>>> presen?a de v?rus.
>>> www.avg.com
>>>
>>
> 
Hello,

I cannot reproduce any error. T is vectorized so I am not understanding 
what you mean by the script only generated one data point.
Here is the same code ran on your new data set, the result is as expected.
Note the output of str(). It days that the 1st column is of class "Date" 
so it was created from YEAR and DOY and relocated to the 1st position.

Can you post the output of your final df1? Please post

head(df1)



# new data
df1 <- read.table("~/rhelp.txt", header = TRUE)

df1$Date <- with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
df1 <- df1[-(1:2)]
df1 <- df1[c(ncol(df1), 1:(ncol(df1) - 1L))]
str(df1)
#> 'data.frame':    436 obs. of  7 variables:
#>  $ Date : Date, format: "2012-01-01" "2012-01-01" ...
#>  $ HR   : int  0 1 2 3 4 5 6 7 8 9 ...
#>  $ IMF  : num  4 4.4 4.8 5.4 4.5 4.2 4.7 4.1 3.2 4.3 ...
#>  $ SWS  : num  379 386 380 374 369 368 367 361 362 367 ...
#>  $ SSN  : int  71 71 71 71 71 71 71 71 71 71 ...
#>  $ Dst  : int  -8 -3 -4 -5 -9 -7 -6 -10 -7 -3 ...
#>  $ f10.7: num  1000 1000 1000 1000 1000 ...
head(df1)
#>         Date HR IMF SWS SSN Dst f10.7
#> 1 2012-01-01  0 4.0 379  71  -8 999.9
#> 2 2012-01-01  1 4.4 386  71  -3 999.9
#> 3 2012-01-01  2 4.8 380  71  -4 999.9
#> 4 2012-01-01  3 5.4 374  71  -5 999.9
#> 5 2012-01-01  4 4.5 369  71  -9 999.9
#> 6 2012-01-01  5 4.2 368  71  -7 999.9


Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From |@go@g|ne @end|ng |rom @jd@e@  Mon Jun 17 09:51:27 2024
From: |@go@g|ne @end|ng |rom @jd@e@ (=?iso-8859-1?Q?Iago_Gin=E9_V=E1zquez?=)
Date: Mon, 17 Jun 2024 07:51:27 +0000
Subject: [R] Help trying to understand R documentation on libraries paths
Message-ID: <AM6PR02MB44239432A7BE1B54503E943F94CD2@AM6PR02MB4423.eurprd02.prod.outlook.com>

Hi,

1 - On help(".libPaths", help_type = "text") one can read:

 First, '.Library.site' is initialized from 'R_LIBS_SITE'.

However, I have

> Sys.getenv("R_LIBS_SITE")
[1] "c:/Users/i.gine/AppData/Local/Programs/R/R-4.4.1/site-library"
> .Library.site
character(0)

Is this consistent?

2 - Next, on the same help document, one can read:

 Then, '.libPaths()' is called with the combination
     of the directories given by 'R_LIBS' and 'R_LIBS_USER'.


This time, I get
> Sys.getenv("R_LIBS")
[1] ""
> Sys.getenv("R_LIBS_USER")
[1] "c:/Users/i.gine/AppData/Local/Programs/R/R-4.4.0/library"
> .libPaths()
[1] "C:/Users/i.gine/AppData/Local/Programs/R/R-4.4.0/library" "C:/Users/i.gine/AppData/Local/Programs/R/R-4.4.1/library"


Later is written:

Function '.libPaths' always uses the values of '.Library' and
     '.Library.site' in the base namespace.

and indeed

> .Library
[1] "c:/Users/i.gine/AppData/Local/Programs/R/R-4.4.1/library"


Then, shouldn't be this specified above together with "directories given by 'R_LIBS' and 'R_LIBS_USER'"?


Am I understanding it wrongly? Otherwise, what do you think on the current way this help page is explained?

Thank you for your help and time.

Best regards,

Iago

	[[alternative HTML version deleted]]


From j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng  Mon Jun 17 10:12:33 2024
From: j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng (Jibrin Alhassan)
Date: Mon, 17 Jun 2024 09:12:33 +0100
Subject: [R] code for year month day hr format
In-Reply-To: <053e2864-deb4-42bb-a505-555c8f9c7360@sapo.pt>
References: <CAEGeL+EDsd2LnZ0v5cY-0S7ofE_qxKi-QGV2+WnSzODywRZ9MQ@mail.gmail.com>
 <474f21f7-7a41-403f-826f-853f6589ec52@sapo.pt>
 <CAEGeL+H_eukBiQKyDb1GOGo5K2kcyM7S6n167ukBWoGrQUgLyg@mail.gmail.com>
 <9347708a-d116-4879-8809-e2b5abadff25@sapo.pt>
 <CAEGeL+Hv5vXMo8yqeTTXpjXMVicSpEzk9W0pM0jd0gWRMiVsqQ@mail.gmail.com>
 <CAEGeL+FS6hN7OJqh=6NveMTMVA8Ct_mpRdGdqdezVBoXiTRe6g@mail.gmail.com>
 <053e2864-deb4-42bb-a505-555c8f9c7360@sapo.pt>
Message-ID: <CAEGeL+HEUOq=VxCF0q_sD2qoDht00OvNhSNnBTXcr9dcSqxWyQ@mail.gmail.com>

Hello Rui,
Here is the head(df1) output
Date HR IMF SWS SSN Dst f10.7
1 2012-01-01  0 4.0 379  71  -8 999.9
2 2012-01-01  1 4.4 386  71  -3 999.9
3 2012-01-01  2 4.8 380  71  -4 999.9
4 2012-01-01  3 5.4 374  71  -5 999.9
5 2012-01-01  4 4.5 369  71  -9 999.9
6 2012-01-01  5 4.2 368  71  -7 999.9
Many thanks.
*Jibrin Adejoh Alhassan (Ph.D)*
Department of Physics and Astronomy,
University of Nigeria, Nsukka


On Mon, Jun 17, 2024 at 8:14?AM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> ?s 07:53 de 17/06/2024, Jibrin Alhassan escreveu:
> > Part of it is pasted below
> > YEAR DOY HR    IMF SWS   SSN   Dst f10.7
> > 2012   1  0   4.0  379.  71    -8 999.9
> > 2012   1  1   4.4  386.  71    -3 999.9
> > 2012   1  2   4.8  380.  71    -4 999.9
> > 2012   1  3   5.4  374.  71    -5 999.9
> > 2012   1  4   4.5  369.  71    -9 999.9
> > 2012   1  5   4.2  368.  71    -7 999.9
> > 2012   1  6   4.7  367.  71    -6 999.9
> > 2012   1  7   4.1  361.  71   -10 999.9
> > 2012   1  8   3.2  362.  71    -7 999.9
> > 2012   1  9   4.3  367.  71    -3 999.9
> > 2012   1 10   4.5  365.  71    -6 999.9
> > 2012   1 11   5.6  369.  71    -8 999.9
> > 2012   1 12   5.2  366.  71    -8 999.9
> > 2012   1 13   4.4  370.  71    -7 999.9
> > 2012   1 14   4.8  357.  71    -5 999.9
> > 2012   1 15   4.6  354.  71    -8 999.9
> > 2012   1 16   3.7  382.  71    -7 999.9
> > 2012   1 17   3.2  376.  71    -2 999.9
> > 2012   1 18   2.8  368.  71     2 999.9
> > 2012   1 19   3.2  361.  71     2 999.9
> > 2012   1 20   3.2  361.  71    -3 999.9
> > 2012   1 21   3.5  365.  71    -5 999.9
> > 2012   1 22   3.6  364.  71    -3 999.9
> > 2012   1 23   3.0  362.  71    -3 999.9
> > 2012   2  0   3.2  359.  92    -5 130.3
> > 2012   2  1   3.0  361.  92    -4 130.3
> > 2012   2  2   4.5  374.  92     3 130.3
> > 2012   2  3   4.5  364.  92     5 130.3
> > 2012   2  4   5.1  352.  92     3 130.3
> > 2012   2  5   4.9  358.  92     3 130.3
> > 2012   2  6   4.4  346.  92     4 130.3
> > 2012   2  7   4.2  349.  92     7 130.3
> > 2012   2  8   4.5  346.  92     8 130.3
> > 2012   2  9   5.2  345.  92     7 130.3
> > 2012   2 10   5.0  349.  92     5 130.3
> > 2012   2 11   4.8  345.  92     0 130.3
> > 2012   2 12   5.3  347.  92     0 130.3
> > 2012   2 13   5.5  342.  92     0 130.3
> > 2012   2 14   6.1  359.  92     1 130.3
> > 2012   2 15   6.2  393.  92     8 130.3
> > 2012   2 16   6.7  390.  92    10 130.3
> > 2012   2 17   7.7  369.  92    10 130.3
> > 2012   2 18   9.4  380.  92    14 130.3
> > 2012   2 19  10.6  386.  92    12 130.3
> > 2012   2 20  10.2  378.  92    11 130.3
> > 2012   2 21  11.6  369.  92     7 130.3
> > 2012   2 22  12.0  369.  92     8 130.3
> > 2012   2 23  10.5  361.  92     1 130.3
> > 2012   3  0  11.3  403. 120    -7 130.2
> > 2012   3  1  10.3  412. 120   -14 130.2
> > 2012   3  2   8.8  419. 120   -18 130.2
> > 2012   3  3   8.3  412. 120   -23 130.2
> > 2012   3  4   8.0  408. 120   -25 130.2
> > 2012   3  5   7.0  380. 120   -28 130.2
> > 2012   3  6   6.9  374. 120   -29 130.2
> > 2012   3  7   6.9  372. 120   -30 130.2
> > 2012   3  8   7.1  365. 120   -32 130.2
> > 2012   3  9   6.8  376. 120   -35 130.2
> > 2012   3 10   6.7  380. 120   -35 130.2
> > 2012   3 11   6.4  381. 120   -30 130.2
> > 2012   3 12   5.9  401. 120   -26 130.2
> > 2012   3 13   5.9  405. 120   -23 130.2
> > 2012   3 14   5.9  413. 120   -20 130.2
> > 2012   3 15   5.9  406. 120   -20 130.2
> > 2012   3 16   6.3  427. 120   -20 130.2
> > 2012   3 17   5.9  424. 120   -19 130.2
> > 2012   3 18   4.8  390. 120   -16 130.2
> > 2012   3 19   4.8  374. 120   -15 130.2
> > 2012   3 20   4.8  374. 120   -15 130.2
> > 2012   3 21   5.1  378. 120   -18 130.2
> > 2012   3 22   4.9  375. 120   -19 130.2
> > 2012   3 23   4.7  364. 120   -17 130.2
> > 2012   4  0   4.3  359. 126   -17 131.6
> > 2012   4  1   4.3  359. 126   -15 131.6
> > 2012   4  2   4.2  358. 126   -13 131.6
> > 2012   4  3   3.8  359. 126   -13 131.6
> > 2012   4  4   3.8  358. 126   -13 131.6
> > 2012   4  5   3.7  359. 126   -14 131.6
> > 2012   4  6   3.9  361. 126   -13 131.6
> > 2012   4  7   3.7  364. 126   -13 131.6
> > 2012   4  8   3.7  366. 126   -12 131.6
> > 2012   4  9   3.8  363. 126   -10 131.6
> > 2012   4 10   3.5  363. 126    -8 131.6
> > 2012   4 11   3.0  352. 126   -10 131.6
> > 2012   4 12   3.1  348. 126   -12 131.6
> > 2012   4 13   3.3  340. 126    -9 131.6
> > 2012   4 14   4.0  343. 126    -8 131.6
> > 2012   4 15   4.2  343. 126    -7 131.6
> > 2012   4 16   3.8  336. 126    -5 131.6
> > 2012   4 17   3.9  334. 126    -6 131.6
> > 2012   4 18   3.8  329. 126    -5 131.6
> > 2012   4 19   3.8  326. 126    -4 131.6
> > 2012   4 20   4.3  337. 126    -3 131.6
> > 2012   4 21   3.9  331. 126     0 131.6
> > 2012   4 22   3.8  322. 126    -1 131.6
> > 2012   4 23   3.5  331. 126    -1 131.6
> > 2012   5  0   3.9  312. 109    -3 136.6
> > 2012   5  1   3.6  311. 109    -1 136.6
> > 2012   5  2   3.7  312. 109     0 136.6
> > 2012   5  3   3.8  308. 109     0 136.6
> > 2012   5  4   4.0  305. 109     2 136.6
> > 2012   5  5   4.5  309. 109     2 136.6
> > 2012   5  6   3.5  314. 109     3 136.6
> > 2012   5  7   3.6  305. 109     2 136.6
> > 2012   5  8   4.3  307. 109     2 136.6
> > 2012   5  9   4.6  316. 109     1 136.6
> > 2012   5 10   5.0  321. 109    -4 136.6
> > 2012   5 11   5.1  321. 109    -6 136.6
> > 2012   5 12   4.6  326. 109    -4 136.6
> > 2012   5 13   5.7  321. 109    -2 136.6
> > 2012   5 14   5.0  316. 109     1 136.6
> > 2012   5 15   4.6  315. 109     2 136.6
> > 2012   5 16   5.5  321. 109     7 136.6
> > 2012   5 17   7.2  327. 109     7 136.6
> > 2012   5 18   9.2  329. 109     3 136.6
> > 2012   5 19   9.4  341. 109     3 136.6
> > 2012   5 20   9.2  345. 109     8 136.6
> > 2012   5 21   9.8  344. 109     9 136.6
> > 2012   5 22   9.8  341. 109    10 136.6
> > 2012   5 23  10.0  351. 109    15 136.6
> > 2012   6  0  10.4  356. 113    12 131.0
> > 2012   6  1   9.1  360. 113    10 131.0
> > 2012   6  2   6.6  392. 113    10 131.0
> > 2012   6  3   6.9  418. 113     7 131.0
> > 2012   6  4   6.5  408. 113     4 131.0
> > 2012   6  5   6.6  413. 113     7 131.0
> > 2012   6  6   7.3  428. 113     6 131.0
> > 2012   6  7   7.3  416. 113     4 131.0
> > 2012   6  8   7.0  411. 113     1 131.0
> > 2012   6  9   7.2  415. 113     1 131.0
> > 2012   6 10   7.2  426. 113     0 131.0
> > 2012   6 11   6.5  431. 113    -2 131.0
> > 2012   6 12   6.4  431. 113    -2 131.0
> > 2012   6 13   6.6  435. 113     0 131.0
> > 2012   6 14   6.2  425. 113     2 131.0
> > 2012   6 15   5.7  431. 113     4 131.0
> > 2012   6 16   6.1  431. 113     1 131.0
> > 2012   6 17   5.7  425. 113    -3 131.0
> > 2012   6 18   5.8  431. 113    -1 131.0
> > 2012   6 19   6.4  425. 113     2 131.0
> > 2012   6 20   6.0  434. 113     1 131.0
> > 2012   6 21   6.3  420. 113     0 131.0
> > 2012   6 22   6.3  440. 113    -3 131.0
> > 2012   6 23   6.5  456. 113    -3 131.0
> > 2012   7  0   6.3  435. 113    -5 135.9
> > 2012   7  1   5.9  428. 113    -1 135.9
> > 2012   7  2   5.7  434. 113     1 135.9
> > 2012   7  3   5.3  423. 113     0 135.9
> > 2012   7  4   4.3  417. 113     1 135.9
> > 2012   7  5   5.4  420. 113     0 135.9
> > 2012   7  6   5.7  434. 113     1 135.9
> > 2012   7  7   5.5  423. 113     1 135.9
> > 2012   7  8   4.8  419. 113    -2 135.9
> > 2012   7  9   5.8  421. 113    -6 135.9
> > 2012   7 10   5.3  412. 113    -9 135.9
> > 2012   7 11   4.6  424. 113    -7 135.9
> > 2012   7 12   4.0  439. 113    -3 135.9
> > 2012   7 13   4.8  431. 113    -1 135.9
> > 2012   7 14   5.1  431. 113    -1 135.9
> > 2012   7 15   4.8  427. 113    -1 135.9
> > 2012   7 16   4.7  429. 113    -5 135.9
> > 2012   7 17   5.3  436. 113    -6 135.9
> > 2012   7 18   5.1  426. 113    -5 135.9
> > 2012   7 19   5.2  427. 113    -4 135.9
> > 2012   7 20   4.5  416. 113    -5 135.9
> > 2012   7 21   4.9  409. 113    -4 135.9
> > 2012   7 22   5.0  417. 113    -4 135.9
> > 2012   7 23   5.0  426. 113    -4 135.9
> > 2012   8  0   5.0  433. 104    -2 131.4
> > 2012   8  1   4.9  426. 104    -2 131.4
> > 2012   8  2   4.7  421. 104    -4 131.4
> > 2012   8  3   4.4  417. 104    -5 131.4
> > 2012   8  4   4.3  416. 104    -8 131.4
> > 2012   8  5   4.5  416. 104    -8 131.4
> > 2012   8  6   5.0  419. 104    -6 131.4
> > 2012   8  7   5.4  446. 104    -1 131.4
> > 2012   8  8   5.3  439. 104    -2 131.4
> > 2012   8  9   5.3  432. 104    -4 131.4
> > 2012   8 10   5.4  434. 104    -4 131.4
> > 2012   8 11   5.4  435. 104    -3 131.4
> > 2012   8 12   4.5  421. 104    -4 131.4
> > 2012   8 13   4.5  422. 104    -4 131.4
> > 2012   8 14   5.1  425. 104    -2 131.4
> > 2012   8 15   5.3  429. 104     1 131.4
> > 2012   8 16   5.5  433. 104    -2 131.4
> > 2012   8 17   5.9  440. 104    -2 131.4
> > 2012   8 18   6.6  445. 104    -1 131.4
> > 2012   8 19   6.4  442. 104    -4 131.4
> > 2012   8 20   5.9  434. 104    -6 131.4
> > 2012   8 21   5.3  429. 104    -7 131.4
> > 2012   8 22   4.8  438. 104    -2 131.4
> > 2012   8 23   5.3  427. 104     4 131.4
> > 2012   9  0   5.5  433.  79     8 137.6
> > 2012   9  1   5.2  445.  79     9 137.6
> > 2012   9  2   5.4  439.  79    10 137.6
> > 2012   9  3   5.3  430.  79     7 137.6
> > 2012   9  4   5.1  426.  79    -3 137.6
> > 2012   9  5   4.7  415.  79    -6 137.6
> > 2012   9  6   5.0  412.  79    -4 137.6
> > 2012   9  7   5.2  418.  79    -2 137.6
> > 2012   9  8   5.5  441.  79     2 137.6
> > 2012   9  9   5.1  441.  79     2 137.6
> > 2012   9 10   5.4  430.  79    -2 137.6
> > 2012   9 11   5.3  433.  79    -1 137.6
> > 2012   9 12   5.5  438.  79     5 137.6
> > 2012   9 13   5.4  436.  79     6 137.6
> > 2012   9 14   5.7  440.  79     9 137.6
> > 2012   9 15   5.9  430.  79     9 137.6
> > 2012   9 16   5.8  437.  79     4 137.6
> > 2012   9 17   4.9  431.  79    -3 137.6
> > 2012   9 18   5.3  424.  79    -3 137.6
> > 2012   9 19   5.7  437.  79    -2 137.6
> > 2012   9 20   6.1  427.  79    -4 137.6
> > 2012   9 21   6.0  409.  79    -7 137.6
> > 2012   9 22   6.6  410.  79    -4 137.6
> > 2012   9 23   6.4  432.  79    -1 137.6
> > 2012  10  0   5.9  434.  70     2 124.6
> > 2012  10  1   5.6  424.  70     4 124.6
> > 2012  10  2   4.8  435.  70     7 124.6
> > 2012  10  3   4.6  425.  70     4 124.6
> > 2012  10  4   4.3  424.  70     3 124.6
> > 2012  10  5   5.4  426.  70     2 124.6
> > 2012  10  6   5.5  434.  70     2 124.6
> > 2012  10  7   6.4  435.  70     4 124.6
> > 2012  10  8   6.3  436.  70     1 124.6
> > 2012  10  9   5.2  431.  70    -6 124.6
> > 2012  10 10   4.5  426.  70   -10 124.6
> > 2012  10 11   4.6  435.  70    -9 124.6
> > 2012  10 12   3.4  425.  70    -5 124.6
> > 2012  10 13   4.2  427.  70    -4 124.6
> > 2012  10 14   4.0  432.  70     2 124.6
> > 2012  10 15   5.5  450.  70     7 124.6
> > 2012  10 16   5.9  451.  70     2 124.6
> > 2012  10 17   5.5  445.  70    -3 124.6
> > 2012  10 18   5.8  442.  70    -2 124.6
> > 2012  10 19   5.4  430.  70    -1 124.6
> > 2012  10 20   4.9  427.  70    -1 124.6
> > 2012  10 21   4.0  436.  70     0 124.6
> > 2012  10 22   3.4  445.  70    -1 124.6
> > 2012  10 23   4.5  453.  70     0 124.6
> > 2012  11  0   5.3  438.  63     1 116.1
> > 2012  11  1   5.0  438.  63     3 116.1
> > 2012  11  2   5.3  445.  63     3 116.1
> > 2012  11  3   4.5  451.  63     2 116.1
> > 2012  11  4   5.0  456.  63    -1 116.1
> > 2012  11  5   4.6  459.  63     0 116.1
> > 2012  11  6   5.1  459.  63     1 116.1
> > 2012  11  7   4.0  466.  63     3 116.1
> > 2012  11  8   5.0  478.  63    -1 116.1
> > 2012  11  9   4.6  489.  63    -2 116.1
> > 2012  11 10   4.5  493.  63    -4 116.1
> > 2012  11 11   4.5  494.  63    -1 116.1
> > 2012  11 12   3.6  504.  63     3 116.1
> > 2012  11 13   3.5  496.  63     5 116.1
> > 2012  11 14   3.3  497.  63     7 116.1
> > 2012  11 15   3.0  498.  63     7 116.1
> > 2012  11 16   2.1  503.  63     3 116.1
> > 2012  11 17   2.0  495.  63     0 116.1
> > 2012  11 18   2.5  492.  63    -2 116.1
> > 2012  11 19   2.2  496.  63    -1 116.1
> > 2012  11 20   2.4  489.  63     1 116.1
> > 2012  11 21   2.6  489.  63     3 116.1
> > 2012  11 22   2.6  483.  63     2 116.1
> > 2012  11 23   2.6  478.  63     2 116.1
> > 2012  12  0   2.9  453.  52     3 113.0
> > 2012  12  1   2.2  446.  52     4 113.0
> > 2012  12  2   2.4  442.  52     8 113.0
> > 2012  12  3   2.6  440.  52    10 113.0
> > 2012  12  4   2.2  438.  52    11 113.0
> > 2012  12  5   2.8  438.  52     9 113.0
> > 2012  12  6   2.0  437.  52     8 113.0
> > 2012  12  7   2.4  426.  52     7 113.0
> > 2012  12  8   3.0  423.  52     5 113.0
> > 2012  12  9   3.3  420.  52     4 113.0
> > 2012  12 10   4.0  419.  52     2 113.0
> > 2012  12 11   3.8  412.  52     5 113.0
> > 2012  12 12   4.2  409.  52     4 113.0
> > 2012  12 13   3.5  408.  52     2 113.0
> > 2012  12 14   3.7  404.  52     9 113.0
> > 2012  12 15   4.5  402.  52    15 113.0
> > 2012  12 16   3.6  395.  52    14 113.0
> > 2012  12 17   2.4  392.  52    16 113.0
> > 2012  12 18   5.8  403.  52    27 113.0
> > 2012  12 19   7.6  400.  52    27 113.0
> > 2012  12 20   6.9  418.  52    17 113.0
> > 2012  12 21   6.9  463.  52    10 113.0
> > 2012  12 22   7.3  469.  52     9 113.0
> > 2012  12 23   5.5  482.  52    12 113.0
> > 2012  13  0   7.7  500.  71    10 120.0
> > 2012  13  1   8.7  492.  71    14 120.0
> > 2012  13  2   7.8  513.  71    16 120.0
> > 2012  13  3   7.5  530.  71    11 120.0
> > 2012  13  4   7.1  518.  71     8 120.0
> > 2012  13  5   7.0  524.  71     6 120.0
> > 2012  13  6   5.9  536.  71     8 120.0
> > 2012  13  7   3.6  529.  71     5 120.0
> > 2012  13  8   4.1  510.  71     4 120.0
> > 2012  13  9   3.9  497.  71     3 120.0
> > 2012  13 10   2.4  492.  71     3 120.0
> > 2012  13 11   2.6  485.  71     5 120.0
> > 2012  13 12   2.9  492.  71     5 120.0
> > 2012  13 13   2.6  487.  71     3 120.0
> > 2012  13 14   2.3  478.  71     6 120.0
> > 2012  13 15   3.2  467.  71    11 120.0
> > 2012  13 16   3.4  453.  71    10 120.0
> > 2012  13 17   3.2  452.  71     6 120.0
> > 2012  13 18   3.0  452.  71     2 120.0
> > 2012  13 19   2.8  447.  71     1 120.0
> > 2012  13 20   2.5  439.  71     0 120.0
> > 2012  13 21   2.5  443.  71    -2 120.0
> > 2012  13 22   2.7  442.  71    -3 120.0
> > 2012  13 23   3.0  447.  71    -4 120.0
> > 2012  14  0   3.5  445. 118    -3 128.0
> > 2012  14  1   3.3  440. 118    -1 128.0
> > 2012  14  2   3.1  440. 118     1 128.0
> > 2012  14  3   2.7  446. 118     0 128.0
> > 2012  14  4   2.9  442. 118    -1 128.0
> > 2012  14  5   2.9  437. 118    -2 128.0
> > 2012  14  6   3.3  431. 118    -3 128.0
> > 2012  14  7   2.8  420. 118    -2 128.0
> > 2012  14  8   2.3  409. 118    -2 128.0
> > 2012  14  9   2.2  407. 118     1 128.0
> > 2012  14 10   2.6  405. 118     3 128.0
> > 2012  14 11   2.8  401. 118     4 128.0
> > 2012  14 12   3.2  398. 118     4 128.0
> > 2012  14 13   2.7  400. 118     4 128.0
> > 2012  14 14   1.9  399. 118     5 128.0
> > 2012  14 15   2.4  395. 118     3 128.0
> > 2012  14 16   2.7  389. 118     2 128.0
> > 2012  14 17   2.9  385. 118     0 128.0
> > 2012  14 18   3.2  384. 118     1 128.0
> > 2012  14 19   2.6  380. 118     2 128.0
> > 2012  14 20   2.3  378. 118     1 128.0
> > 2012  14 21   2.1  374. 118     0 128.0
> > 2012  14 22   3.1  367. 118     0 128.0
> > 2012  14 23   4.0  366. 118    -1 128.0
> > 2012  15  0   4.8  363. 149     0 129.2
> > 2012  15  1   4.0  359. 149     2 129.2
> > 2012  15  2   3.4  354. 149     2 129.2
> > 2012  15  3   3.0  349. 149     5 129.2
> > 2012  15  4   2.7  344. 149     7 129.2
> > 2012  15  5   2.4  349. 149    11 129.2
> > 2012  15  6   2.9  343. 149    12 129.2
> > 2012  15  7   3.5  333. 149     7 129.2
> > 2012  15  8   3.6  341. 149     4 129.2
> > 2012  15  9   3.7  345. 149     1 129.2
> > 2012  15 10   3.6  343. 149     2 129.2
> > 2012  15 11   3.6  342. 149     3 129.2
> > 2012  15 12   3.7  340. 149     7 129.2
> > 2012  15 13   3.7  342. 149     8 129.2
> > 2012  15 14   4.1  344. 149     9 129.2
> > 2012  15 15   3.9  345. 149     4 129.2
> > 2012  15 16   4.4  355. 149     8 129.2
> > 2012  15 17   4.7  360. 149    11 129.2
> > 2012  15 18   5.4  359. 149    12 129.2
> > 2012  15 19   6.8  353. 149     8 129.2
> > 2012  15 20   6.6  349. 149     6 129.2
> > 2012  15 21   5.9  364. 149     2 129.2
> > 2012  15 22   5.2  394. 149     1 129.2
> > 2012  15 23   6.3  395. 149     5 129.2
> > 2012  16  0   6.3  385. 154     6 135.1
> > 2012  16  1   6.6  397. 154     2 135.1
> > 2012  16  2   6.7  400. 154     4 135.1
> > 2012  16  3   6.9  396. 154     5 135.1
> > 2012  16  4   7.9  392. 154     5 135.1
> > 2012  16  5   4.6  379. 154    10 135.1
> > 2012  16  6   8.0  365. 154    13 135.1
> > 2012  16  7   6.3  358. 154    16 135.1
> > 2012  16  8   7.9  380. 154    12 135.1
> > 2012  16  9  10.2  391. 154    10 135.1
> > 2012  16 10   8.1  394. 154     8 135.1
> > 2012  16 11  12.1  412. 154    -8 135.1
> > 2012  16 12  13.2  424. 154   -10 135.1
> > 2012  16 13  12.9  433. 154    -8 135.1
> > 2012  16 14   9.3  461. 154    -7 135.1
> > 2012  16 15   6.6  466. 154   -14 135.1
> > 2012  16 16   6.6  493. 154   -11 135.1
> > 2012  16 17   7.4  496. 154    -7 135.1
> > 2012  16 18   6.2  493. 154    -7 135.1
> > 2012  16 19   6.9  492. 154   -13 135.1
> > 2012  16 20   6.8  486. 154   -19 135.1
> > 2012  16 21   5.6  488. 154   -14 135.1
> > 2012  16 22   6.4  464. 154   -11 135.1
> > 2012  16 23   6.0  459. 154   -10 135.1
> > 2012  17  0   4.9  476. 141   -14 134.5
> > 2012  17  1   4.6  460. 141   -20 134.5
> > 2012  17  2   4.1  467. 141   -17 134.5
> > 2012  17  3   3.7  469. 141   -13 134.5
> > 2012  17  4   3.3  472. 141   -12 134.5
> > 2012  17  5   2.7  472. 141    -8 134.5
> > 2012  17  6   3.5  459. 141    -6 134.5
> > 2012  17  7   3.9  459. 141    -6 134.5
> > 2012  17  8   4.1  463. 141    -7 134.5
> > 2012  17  9   4.1  443. 141   -10 134.5
> > 2012  17 10   4.1  446. 141   -14 134.5
> > 2012  17 11   4.1  442. 141   -13 134.5
> > 2012  17 12   3.6  436. 141   -10 134.5
> > 2012  17 13   3.6  433. 141    -6 134.5
> > 2012  17 14   4.2  421. 141    -1 134.5
> > 2012  17 15   3.7  416. 141    -2 134.5
> > 2012  17 16   4.2  410. 141    -1 134.5
> > 2012  17 17   4.6  396. 141    -1 134.5
> > 2012  17 18   4.5  398. 141    -2 134.5
> > 2012  17 19   4.4  397. 141    -6 134.5
> > 2012  17 20   4.5  396. 141    -8 134.5
> > 2012  17 21   3.5  411. 141    -5 134.5
> > 2012  17 22   3.9  425. 141    -5 134.5
> > 2012  17 23   4.7  418. 141    -6 134.5
> > 2012  18  0   4.6  400. 126    -7 143.4
> > 2012  18  1   4.5  413. 126    -3 143.4
> > 2012  18  2   4.4  418. 126     2 143.4
> > 2012  18  3   4.2  420. 126     2 143.4
> > 2012  18  4   4.0  401. 126    -2 143.4
> > 2012  18  5   3.8  399. 126    -1 143.4
> > 2012  18  6   3.5  388. 126    -1 143.4
> > 2012  18  7   4.4  393. 126    -2 143.4
> > 2012  18  8   4.7  405. 126    -3 143.4
> > 2012  18  9   4.8  409. 126    -4 143.4
> > 2012  18 10   4.9  409. 126    -3 143.4
> > 2012  18 11   5.0  411. 126    -5 143.4
> > 2012  18 12   5.1  405. 126    -5 143.4
> > 2012  18 13   5.2  403. 126    -6 143.4
> > 2012  18 14   5.1  394. 126    -4 143.4
> > 2012  18 15   5.0  391. 126    -5 143.4
> > 2012  18 16   4.6  387. 126    -4 143.4
> > 2012  18 17   4.7  376. 126    -2 143.4
> > 2012  18 18   4.7  381. 126    -1 143.4
> > 2012  18 19   4.5  382. 126    -2 143.4
> > 2012  18 20   4.9  386. 126    -5 143.4
> > 2012  18 21   4.8  375. 126    -5 143.4
> > 2012  18 22   4.7  385. 126    -6 143.4
> > 2012  18 23   4.7  381. 126    -5 143.4
> > 2012  19  0   4.3  372. 105    -3 152.0
> > 2012  19  1   4.2  361. 105    -4 152.0
> > 2012  19  2   4.0  360. 105    -5 152.0
> > 2012  19  3   3.9  362. 105    -4 152.0
> > *Jibrin Adejoh Alhassan (Ph.D)*
> > Department of Physics and Astronomy,
> > University of Nigeria, Nsukka
> >
> >
> > On Mon, Jun 17, 2024 at 7:50?AM Jibrin Alhassan <
> jibrin.alhassan at unn.edu.ng>
> > wrote:
> >
> >> Hello Rui,
> >> Your patience is indeed amazing. Your script tested as shown below
> worked
> >> perfectly well.
> >> df1 <- read.table(text = "YEAR DOY HR   IMF  SW   SSN    Dst f10.7
> >> 2012 215  4   5.1  371. 143    -4 138.6 ", header = TRUE)
> >> with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
> >> df1$Date <- with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
> >> df1 <- df1[-(1:2)]
> >> df1 <- df1[c(ncol(df1), 1:(ncol(df1) - 1L))]
> >> head(df1).
> >> But  I have 43,849 data points. Your script only generated one. Help me
> >> with a script that can handle the whole data points. I have tried
> following
> >> your tested solution but was unsuccessful. My regards.
> >> *Jibrin Adejoh Alhassan (Ph.D)*
> >> Department of Physics and Astronomy,
> >> University of Nigeria, Nsukka
> >>
> >>
> >> On Sun, Jun 16, 2024 at 8:33?AM Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
> >>
> >>> ?s 21:42 de 15/06/2024, Jibrin Alhassan escreveu:
> >>>> Thank you Rui. I ran the following script
> >>>> df1 <- read.table("solar_hour", header = TRUE)
> >>>> df1$date <- as.Date(paste(df1$year, df1$hour),
> >>>>    format = "%Y %j",
> >>>> origin = "2012-08-01-0")
> >>>> df2 <- df1[c("date", "IMF", "SWS", "SSN", "Dst", "f10")]
> >>>> head(df1)
> >>>> #To display all the rows
> >>>>    print(df2).
> >>>> It gave me this error message
> >>>>> source ("script.R")
> >>>> Error in `$<-.data.frame`(`*tmp*`, date, value = numeric(0)) :
> >>>>     replacement has 0 rows, data has 38735
> >>>>> print(df2)
> >>>> Error: object 'df2' not found
> >>>>> My data is an hourly data but desire to have the date as
> >>>> year    month    day   hour
> >>>> 2012   08         01     01
> >>>> 2012   08         01     02
> >>>> 2012   08        01      03 etc
> >>>> Thanks.
> >>>>
> >>>> *Jibrin Adejoh Alhassan (Ph.D)*
> >>>> Department of Physics and Astronomy,
> >>>> University of Nigeria, Nsukka
> >>>>
> >>>>
> >>>> On Sat, Jun 15, 2024 at 8:34?PM Rui Barradas <ruipbarradas at sapo.pt>
> >>> wrote:
> >>>>
> >>>>> ?s 20:00 de 15/06/2024, Jibrin Alhassan escreveu:
> >>>>>> I have solar-geophysical data e.g as blow:
> >>>>>> YEAR DOY HR   IMF  SW   SSN    Dst f10.7
> >>>>>> 2012 214  0   3.4  403. 132    -9 154.6
> >>>>>> 2012 214  1   3.7  388. 132   -10 154.6
> >>>>>> 2012 214  2   3.7  383. 132   -10 154.6
> >>>>>> 2012 214  3   3.7  391. 132    -9 154.6
> >>>>>> 2012 214  4   4.2  399. 132    -7 154.6
> >>>>>> 2012 214  5   4.1  411. 132    -6 154.6
> >>>>>> 2012 214  6   4.0  407. 132    -6 154.6
> >>>>>> 2012 214  7   4.2  404. 132    -4 154.6
> >>>>>> 2012 214  8   4.3  405. 132    -6 154.6
> >>>>>> 2012 214  9   4.4  409. 132    -6 154.6
> >>>>>> 2012 214 10   4.4  401. 132    -6 154.6
> >>>>>> 2012 214 11   4.5  385. 132    -7 154.6
> >>>>>> 2012 214 12   4.7  377. 132    -8 154.6
> >>>>>> 2012 214 13   4.7  382. 132    -6 154.6
> >>>>>> 2012 214 14   4.3  396. 132    -4 154.6
> >>>>>> 2012 214 15   4.1  384. 132    -2 154.6
> >>>>>> 2012 214 16   4.0  382. 132    -1 154.6
> >>>>>> 2012 214 17   3.9  397. 132     0 154.6
> >>>>>> 2012 214 18   3.8  390. 132     1 154.6
> >>>>>> 2012 214 19   4.2  400. 132     2 154.6
> >>>>>> 2012 214 20   4.6  408. 132     1 154.6
> >>>>>> 2012 214 21   4.8  401. 132    -3 154.6
> >>>>>> 2012 214 22   4.9  395. 132    -5 154.6
> >>>>>> 2012 214 23   5.0  386. 132    -1 154.6
> >>>>>> 2012 215  0   5.0  377. 143    -1 138.6
> >>>>>> 2012 215  1   4.9  384. 143    -2 138.6
> >>>>>> 2012 215  2   4.9  390. 143    -4 138.6
> >>>>>> 2012 215  3   4.9  372. 143    -6 138.6
> >>>>>> 2012 215  4   5.1  371. 143    -4 138.6
> >>>>>> I want to process it to be of the format as shown below
> >>>>>>     y   m  d  hr imf  sws  ssn    Dst f10.7
> >>>>>> 2012-08-01 10 3.4  403. 132    -9 154.6
> >>>>>> 2012-08-01 12 3.7  388. 132   -10 154.6
> >>>>>> 2012-08-01 15 3.7  383. 132   -10 154.6
> >>>>>> 2012-08-01 17 3.7  391. 132    -9 154.6
> >>>>>> I want to request an R code to accomplish this task. Thanks for your
> >>>>> time.
> >>>>>> *Jibrin Adejoh Alhassan (Ph.D)*
> >>>>>> Department of Physics and Astronomy,
> >>>>>> University of Nigeria, Nsukka
> >>>>>>
> >>>>>>         [[alternative HTML version deleted]]
> >>>>>>
> >>>>>> ______________________________________________
> >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>> PLEASE do read the posting guide
> >>>>> http://www.R-project.org/posting-guide.html
> >>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>> Hello,
> >>>>>
> >>>>> To create a date column, paste the first two columns and coerce to
> >>> class
> >>>>> "Date" with conversion specifications %Y for the 4 digit year and %j
> >>> for
> >>>>> the day of year. See
> >>>>>
> >>>>> help("strptime")
> >>>>>
> >>>>>
> >>>>>
> >>>>> df1 <- read.table(text = "YEAR DOY HR   IMF  SW   SSN    Dst f10.7
> >>>>> 2012 214  0   3.4  403. 132    -9 154.6
> >>>>> 2012 214  1   3.7  388. 132   -10 154.6
> >>>>> 2012 214  2   3.7  383. 132   -10 154.6
> >>>>> 2012 214  3   3.7  391. 132    -9 154.6
> >>>>> 2012 214  4   4.2  399. 132    -7 154.6
> >>>>> 2012 214  5   4.1  411. 132    -6 154.6
> >>>>> 2012 214  6   4.0  407. 132    -6 154.6
> >>>>> 2012 214  7   4.2  404. 132    -4 154.6
> >>>>> 2012 214  8   4.3  405. 132    -6 154.6
> >>>>> 2012 214  9   4.4  409. 132    -6 154.6
> >>>>> 2012 214 10   4.4  401. 132    -6 154.6
> >>>>> 2012 214 11   4.5  385. 132    -7 154.6
> >>>>> 2012 214 12   4.7  377. 132    -8 154.6
> >>>>> 2012 214 13   4.7  382. 132    -6 154.6
> >>>>> 2012 214 14   4.3  396. 132    -4 154.6
> >>>>> 2012 214 15   4.1  384. 132    -2 154.6
> >>>>> 2012 214 16   4.0  382. 132    -1 154.6
> >>>>> 2012 214 17   3.9  397. 132     0 154.6
> >>>>> 2012 214 18   3.8  390. 132     1 154.6
> >>>>> 2012 214 19   4.2  400. 132     2 154.6
> >>>>> 2012 214 20   4.6  408. 132     1 154.6
> >>>>> 2012 214 21   4.8  401. 132    -3 154.6
> >>>>> 2012 214 22   4.9  395. 132    -5 154.6
> >>>>> 2012 214 23   5.0  386. 132    -1 154.6
> >>>>> 2012 215  0   5.0  377. 143    -1 138.6
> >>>>> 2012 215  1   4.9  384. 143    -2 138.6
> >>>>> 2012 215  2   4.9  390. 143    -4 138.6
> >>>>> 2012 215  3   4.9  372. 143    -6 138.6
> >>>>> 2012 215  4   5.1  371. 143    -4 138.6", header = TRUE)
> >>>>>
> >>>>>
> >>>>> with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
> >>>>> #>  [1] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
> >>> "2012-08-01"
> >>>>> #>  [6] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
> >>> "2012-08-01"
> >>>>> #> [11] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
> >>> "2012-08-01"
> >>>>> #> [16] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
> >>> "2012-08-01"
> >>>>> #> [21] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
> >>> "2012-08-02"
> >>>>> #> [26] "2012-08-02" "2012-08-02" "2012-08-02" "2012-08-02"
> >>>>>
> >>>>> # now create the column
> >>>>> df1$Date <- with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
> >>>>> # remove the columns no longer needed
> >>>>> df1 <- df1[-(1:2)]
> >>>>> # relocate the new date column
> >>>>> df1 <- df1[c(ncol(df1), 1:(ncol(df1) - 1L))]
> >>>>> head(df1)
> >>>>> #>         Date HR IMF  SW SSN Dst f10.7
> >>>>> #> 1 2012-08-01  0 3.4 403 132  -9 154.6
> >>>>> #> 2 2012-08-01  1 3.7 388 132 -10 154.6
> >>>>> #> 3 2012-08-01  2 3.7 383 132 -10 154.6
> >>>>> #> 4 2012-08-01  3 3.7 391 132  -9 154.6
> >>>>> #> 5 2012-08-01  4 4.2 399 132  -7 154.6
> >>>>> #> 6 2012-08-01  5 4.1 411 132  -6 154.6
> >>>>>
> >>>>>
> >>>>> Hope this helps,
> >>>>>
> >>>>> Rui Barradas
> >>>>>
> >>>>>
> >>>>> --
> >>>>> Este e-mail foi analisado pelo software antiv?rus AVG para verificar
> a
> >>>>> presen?a de v?rus.
> >>>>> www.avg.com
> >>>>>
> >>>>
> >>> Hello,
> >>>
> >>> There is an error in your new code:
> >>>
> >>>
> >>> paste YEAR with DOY, not with HR.
> >>>
> >>>
> >>> As for the rest, is your real data like the one you posted before?
> >>> If it is then I don't see anything wrong with my (tested) solution.
> >>>
> >>>
> >>> Hope this helps,
> >>>
> >>> Rui Barradas
> >>>
> >>>
> >>>
> >>> --
> >>> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
> >>> presen?a de v?rus.
> >>> www.avg.com
> >>>
> >>
> >
> Hello,
>
> I cannot reproduce any error. T is vectorized so I am not understanding
> what you mean by the script only generated one data point.
> Here is the same code ran on your new data set, the result is as expected.
> Note the output of str(). It days that the 1st column is of class "Date"
> so it was created from YEAR and DOY and relocated to the 1st position.
>
> Can you post the output of your final df1? Please post
>
> head(df1)
>
>
>
> # new data
> df1 <- read.table("~/rhelp.txt", header = TRUE)
>
> df1$Date <- with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
> df1 <- df1[-(1:2)]
> df1 <- df1[c(ncol(df1), 1:(ncol(df1) - 1L))]
> str(df1)
> #> 'data.frame':    436 obs. of  7 variables:
> #>  $ Date : Date, format: "2012-01-01" "2012-01-01" ...
> #>  $ HR   : int  0 1 2 3 4 5 6 7 8 9 ...
> #>  $ IMF  : num  4 4.4 4.8 5.4 4.5 4.2 4.7 4.1 3.2 4.3 ...
> #>  $ SWS  : num  379 386 380 374 369 368 367 361 362 367 ...
> #>  $ SSN  : int  71 71 71 71 71 71 71 71 71 71 ...
> #>  $ Dst  : int  -8 -3 -4 -5 -9 -7 -6 -10 -7 -3 ...
> #>  $ f10.7: num  1000 1000 1000 1000 1000 ...
> head(df1)
> #>         Date HR IMF SWS SSN Dst f10.7
> #> 1 2012-01-01  0 4.0 379  71  -8 999.9
> #> 2 2012-01-01  1 4.4 386  71  -3 999.9
> #> 3 2012-01-01  2 4.8 380  71  -4 999.9
> #> 4 2012-01-01  3 5.4 374  71  -5 999.9
> #> 5 2012-01-01  4 4.5 369  71  -9 999.9
> #> 6 2012-01-01  5 4.2 368  71  -7 999.9
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> --
> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
> presen?a de v?rus.
> www.avg.com
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Jun 17 10:23:53 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 17 Jun 2024 09:23:53 +0100
Subject: [R] code for year month day hr format
In-Reply-To: <CAEGeL+HEUOq=VxCF0q_sD2qoDht00OvNhSNnBTXcr9dcSqxWyQ@mail.gmail.com>
References: <CAEGeL+EDsd2LnZ0v5cY-0S7ofE_qxKi-QGV2+WnSzODywRZ9MQ@mail.gmail.com>
 <474f21f7-7a41-403f-826f-853f6589ec52@sapo.pt>
 <CAEGeL+H_eukBiQKyDb1GOGo5K2kcyM7S6n167ukBWoGrQUgLyg@mail.gmail.com>
 <9347708a-d116-4879-8809-e2b5abadff25@sapo.pt>
 <CAEGeL+Hv5vXMo8yqeTTXpjXMVicSpEzk9W0pM0jd0gWRMiVsqQ@mail.gmail.com>
 <CAEGeL+FS6hN7OJqh=6NveMTMVA8Ct_mpRdGdqdezVBoXiTRe6g@mail.gmail.com>
 <053e2864-deb4-42bb-a505-555c8f9c7360@sapo.pt>
 <CAEGeL+HEUOq=VxCF0q_sD2qoDht00OvNhSNnBTXcr9dcSqxWyQ@mail.gmail.com>
Message-ID: <36b96f57-b034-43df-81d3-33e5c9a0c389@sapo.pt>

?s 09:12 de 17/06/2024, Jibrin Alhassan escreveu:
> Hello Rui,
> Here is the head(df1) output
> Date HR IMF SWS SSN Dst f10.7
> 1 2012-01-01  0 4.0 379  71  -8 999.9
> 2 2012-01-01  1 4.4 386  71  -3 999.9
> 3 2012-01-01  2 4.8 380  71  -4 999.9
> 4 2012-01-01  3 5.4 374  71  -5 999.9
> 5 2012-01-01  4 4.5 369  71  -9 999.9
> 6 2012-01-01  5 4.2 368  71  -7 999.9
> Many thanks.
> *Jibrin Adejoh Alhassan (Ph.D)*
> Department of Physics and Astronomy,
> University of Nigeria, Nsukka
> 
> 
> On Mon, Jun 17, 2024 at 8:14?AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
> 
>> ?s 07:53 de 17/06/2024, Jibrin Alhassan escreveu:
>>> Part of it is pasted below
>>> YEAR DOY HR    IMF SWS   SSN   Dst f10.7
>>> 2012   1  0   4.0  379.  71    -8 999.9
>>> 2012   1  1   4.4  386.  71    -3 999.9
>>> 2012   1  2   4.8  380.  71    -4 999.9
>>> 2012   1  3   5.4  374.  71    -5 999.9
>>> 2012   1  4   4.5  369.  71    -9 999.9
>>> 2012   1  5   4.2  368.  71    -7 999.9
>>> 2012   1  6   4.7  367.  71    -6 999.9
>>> 2012   1  7   4.1  361.  71   -10 999.9
>>> 2012   1  8   3.2  362.  71    -7 999.9
>>> 2012   1  9   4.3  367.  71    -3 999.9
>>> 2012   1 10   4.5  365.  71    -6 999.9
>>> 2012   1 11   5.6  369.  71    -8 999.9
>>> 2012   1 12   5.2  366.  71    -8 999.9
>>> 2012   1 13   4.4  370.  71    -7 999.9
>>> 2012   1 14   4.8  357.  71    -5 999.9
>>> 2012   1 15   4.6  354.  71    -8 999.9
>>> 2012   1 16   3.7  382.  71    -7 999.9
>>> 2012   1 17   3.2  376.  71    -2 999.9
>>> 2012   1 18   2.8  368.  71     2 999.9
>>> 2012   1 19   3.2  361.  71     2 999.9
>>> 2012   1 20   3.2  361.  71    -3 999.9
>>> 2012   1 21   3.5  365.  71    -5 999.9
>>> 2012   1 22   3.6  364.  71    -3 999.9
>>> 2012   1 23   3.0  362.  71    -3 999.9
>>> 2012   2  0   3.2  359.  92    -5 130.3
>>> 2012   2  1   3.0  361.  92    -4 130.3
>>> 2012   2  2   4.5  374.  92     3 130.3
>>> 2012   2  3   4.5  364.  92     5 130.3
>>> 2012   2  4   5.1  352.  92     3 130.3
>>> 2012   2  5   4.9  358.  92     3 130.3
>>> 2012   2  6   4.4  346.  92     4 130.3
>>> 2012   2  7   4.2  349.  92     7 130.3
>>> 2012   2  8   4.5  346.  92     8 130.3
>>> 2012   2  9   5.2  345.  92     7 130.3
>>> 2012   2 10   5.0  349.  92     5 130.3
>>> 2012   2 11   4.8  345.  92     0 130.3
>>> 2012   2 12   5.3  347.  92     0 130.3
>>> 2012   2 13   5.5  342.  92     0 130.3
>>> 2012   2 14   6.1  359.  92     1 130.3
>>> 2012   2 15   6.2  393.  92     8 130.3
>>> 2012   2 16   6.7  390.  92    10 130.3
>>> 2012   2 17   7.7  369.  92    10 130.3
>>> 2012   2 18   9.4  380.  92    14 130.3
>>> 2012   2 19  10.6  386.  92    12 130.3
>>> 2012   2 20  10.2  378.  92    11 130.3
>>> 2012   2 21  11.6  369.  92     7 130.3
>>> 2012   2 22  12.0  369.  92     8 130.3
>>> 2012   2 23  10.5  361.  92     1 130.3
>>> 2012   3  0  11.3  403. 120    -7 130.2
>>> 2012   3  1  10.3  412. 120   -14 130.2
>>> 2012   3  2   8.8  419. 120   -18 130.2
>>> 2012   3  3   8.3  412. 120   -23 130.2
>>> 2012   3  4   8.0  408. 120   -25 130.2
>>> 2012   3  5   7.0  380. 120   -28 130.2
>>> 2012   3  6   6.9  374. 120   -29 130.2
>>> 2012   3  7   6.9  372. 120   -30 130.2
>>> 2012   3  8   7.1  365. 120   -32 130.2
>>> 2012   3  9   6.8  376. 120   -35 130.2
>>> 2012   3 10   6.7  380. 120   -35 130.2
>>> 2012   3 11   6.4  381. 120   -30 130.2
>>> 2012   3 12   5.9  401. 120   -26 130.2
>>> 2012   3 13   5.9  405. 120   -23 130.2
>>> 2012   3 14   5.9  413. 120   -20 130.2
>>> 2012   3 15   5.9  406. 120   -20 130.2
>>> 2012   3 16   6.3  427. 120   -20 130.2
>>> 2012   3 17   5.9  424. 120   -19 130.2
>>> 2012   3 18   4.8  390. 120   -16 130.2
>>> 2012   3 19   4.8  374. 120   -15 130.2
>>> 2012   3 20   4.8  374. 120   -15 130.2
>>> 2012   3 21   5.1  378. 120   -18 130.2
>>> 2012   3 22   4.9  375. 120   -19 130.2
>>> 2012   3 23   4.7  364. 120   -17 130.2
>>> 2012   4  0   4.3  359. 126   -17 131.6
>>> 2012   4  1   4.3  359. 126   -15 131.6
>>> 2012   4  2   4.2  358. 126   -13 131.6
>>> 2012   4  3   3.8  359. 126   -13 131.6
>>> 2012   4  4   3.8  358. 126   -13 131.6
>>> 2012   4  5   3.7  359. 126   -14 131.6
>>> 2012   4  6   3.9  361. 126   -13 131.6
>>> 2012   4  7   3.7  364. 126   -13 131.6
>>> 2012   4  8   3.7  366. 126   -12 131.6
>>> 2012   4  9   3.8  363. 126   -10 131.6
>>> 2012   4 10   3.5  363. 126    -8 131.6
>>> 2012   4 11   3.0  352. 126   -10 131.6
>>> 2012   4 12   3.1  348. 126   -12 131.6
>>> 2012   4 13   3.3  340. 126    -9 131.6
>>> 2012   4 14   4.0  343. 126    -8 131.6
>>> 2012   4 15   4.2  343. 126    -7 131.6
>>> 2012   4 16   3.8  336. 126    -5 131.6
>>> 2012   4 17   3.9  334. 126    -6 131.6
>>> 2012   4 18   3.8  329. 126    -5 131.6
>>> 2012   4 19   3.8  326. 126    -4 131.6
>>> 2012   4 20   4.3  337. 126    -3 131.6
>>> 2012   4 21   3.9  331. 126     0 131.6
>>> 2012   4 22   3.8  322. 126    -1 131.6
>>> 2012   4 23   3.5  331. 126    -1 131.6
>>> 2012   5  0   3.9  312. 109    -3 136.6
>>> 2012   5  1   3.6  311. 109    -1 136.6
>>> 2012   5  2   3.7  312. 109     0 136.6
>>> 2012   5  3   3.8  308. 109     0 136.6
>>> 2012   5  4   4.0  305. 109     2 136.6
>>> 2012   5  5   4.5  309. 109     2 136.6
>>> 2012   5  6   3.5  314. 109     3 136.6
>>> 2012   5  7   3.6  305. 109     2 136.6
>>> 2012   5  8   4.3  307. 109     2 136.6
>>> 2012   5  9   4.6  316. 109     1 136.6
>>> 2012   5 10   5.0  321. 109    -4 136.6
>>> 2012   5 11   5.1  321. 109    -6 136.6
>>> 2012   5 12   4.6  326. 109    -4 136.6
>>> 2012   5 13   5.7  321. 109    -2 136.6
>>> 2012   5 14   5.0  316. 109     1 136.6
>>> 2012   5 15   4.6  315. 109     2 136.6
>>> 2012   5 16   5.5  321. 109     7 136.6
>>> 2012   5 17   7.2  327. 109     7 136.6
>>> 2012   5 18   9.2  329. 109     3 136.6
>>> 2012   5 19   9.4  341. 109     3 136.6
>>> 2012   5 20   9.2  345. 109     8 136.6
>>> 2012   5 21   9.8  344. 109     9 136.6
>>> 2012   5 22   9.8  341. 109    10 136.6
>>> 2012   5 23  10.0  351. 109    15 136.6
>>> 2012   6  0  10.4  356. 113    12 131.0
>>> 2012   6  1   9.1  360. 113    10 131.0
>>> 2012   6  2   6.6  392. 113    10 131.0
>>> 2012   6  3   6.9  418. 113     7 131.0
>>> 2012   6  4   6.5  408. 113     4 131.0
>>> 2012   6  5   6.6  413. 113     7 131.0
>>> 2012   6  6   7.3  428. 113     6 131.0
>>> 2012   6  7   7.3  416. 113     4 131.0
>>> 2012   6  8   7.0  411. 113     1 131.0
>>> 2012   6  9   7.2  415. 113     1 131.0
>>> 2012   6 10   7.2  426. 113     0 131.0
>>> 2012   6 11   6.5  431. 113    -2 131.0
>>> 2012   6 12   6.4  431. 113    -2 131.0
>>> 2012   6 13   6.6  435. 113     0 131.0
>>> 2012   6 14   6.2  425. 113     2 131.0
>>> 2012   6 15   5.7  431. 113     4 131.0
>>> 2012   6 16   6.1  431. 113     1 131.0
>>> 2012   6 17   5.7  425. 113    -3 131.0
>>> 2012   6 18   5.8  431. 113    -1 131.0
>>> 2012   6 19   6.4  425. 113     2 131.0
>>> 2012   6 20   6.0  434. 113     1 131.0
>>> 2012   6 21   6.3  420. 113     0 131.0
>>> 2012   6 22   6.3  440. 113    -3 131.0
>>> 2012   6 23   6.5  456. 113    -3 131.0
>>> 2012   7  0   6.3  435. 113    -5 135.9
>>> 2012   7  1   5.9  428. 113    -1 135.9
>>> 2012   7  2   5.7  434. 113     1 135.9
>>> 2012   7  3   5.3  423. 113     0 135.9
>>> 2012   7  4   4.3  417. 113     1 135.9
>>> 2012   7  5   5.4  420. 113     0 135.9
>>> 2012   7  6   5.7  434. 113     1 135.9
>>> 2012   7  7   5.5  423. 113     1 135.9
>>> 2012   7  8   4.8  419. 113    -2 135.9
>>> 2012   7  9   5.8  421. 113    -6 135.9
>>> 2012   7 10   5.3  412. 113    -9 135.9
>>> 2012   7 11   4.6  424. 113    -7 135.9
>>> 2012   7 12   4.0  439. 113    -3 135.9
>>> 2012   7 13   4.8  431. 113    -1 135.9
>>> 2012   7 14   5.1  431. 113    -1 135.9
>>> 2012   7 15   4.8  427. 113    -1 135.9
>>> 2012   7 16   4.7  429. 113    -5 135.9
>>> 2012   7 17   5.3  436. 113    -6 135.9
>>> 2012   7 18   5.1  426. 113    -5 135.9
>>> 2012   7 19   5.2  427. 113    -4 135.9
>>> 2012   7 20   4.5  416. 113    -5 135.9
>>> 2012   7 21   4.9  409. 113    -4 135.9
>>> 2012   7 22   5.0  417. 113    -4 135.9
>>> 2012   7 23   5.0  426. 113    -4 135.9
>>> 2012   8  0   5.0  433. 104    -2 131.4
>>> 2012   8  1   4.9  426. 104    -2 131.4
>>> 2012   8  2   4.7  421. 104    -4 131.4
>>> 2012   8  3   4.4  417. 104    -5 131.4
>>> 2012   8  4   4.3  416. 104    -8 131.4
>>> 2012   8  5   4.5  416. 104    -8 131.4
>>> 2012   8  6   5.0  419. 104    -6 131.4
>>> 2012   8  7   5.4  446. 104    -1 131.4
>>> 2012   8  8   5.3  439. 104    -2 131.4
>>> 2012   8  9   5.3  432. 104    -4 131.4
>>> 2012   8 10   5.4  434. 104    -4 131.4
>>> 2012   8 11   5.4  435. 104    -3 131.4
>>> 2012   8 12   4.5  421. 104    -4 131.4
>>> 2012   8 13   4.5  422. 104    -4 131.4
>>> 2012   8 14   5.1  425. 104    -2 131.4
>>> 2012   8 15   5.3  429. 104     1 131.4
>>> 2012   8 16   5.5  433. 104    -2 131.4
>>> 2012   8 17   5.9  440. 104    -2 131.4
>>> 2012   8 18   6.6  445. 104    -1 131.4
>>> 2012   8 19   6.4  442. 104    -4 131.4
>>> 2012   8 20   5.9  434. 104    -6 131.4
>>> 2012   8 21   5.3  429. 104    -7 131.4
>>> 2012   8 22   4.8  438. 104    -2 131.4
>>> 2012   8 23   5.3  427. 104     4 131.4
>>> 2012   9  0   5.5  433.  79     8 137.6
>>> 2012   9  1   5.2  445.  79     9 137.6
>>> 2012   9  2   5.4  439.  79    10 137.6
>>> 2012   9  3   5.3  430.  79     7 137.6
>>> 2012   9  4   5.1  426.  79    -3 137.6
>>> 2012   9  5   4.7  415.  79    -6 137.6
>>> 2012   9  6   5.0  412.  79    -4 137.6
>>> 2012   9  7   5.2  418.  79    -2 137.6
>>> 2012   9  8   5.5  441.  79     2 137.6
>>> 2012   9  9   5.1  441.  79     2 137.6
>>> 2012   9 10   5.4  430.  79    -2 137.6
>>> 2012   9 11   5.3  433.  79    -1 137.6
>>> 2012   9 12   5.5  438.  79     5 137.6
>>> 2012   9 13   5.4  436.  79     6 137.6
>>> 2012   9 14   5.7  440.  79     9 137.6
>>> 2012   9 15   5.9  430.  79     9 137.6
>>> 2012   9 16   5.8  437.  79     4 137.6
>>> 2012   9 17   4.9  431.  79    -3 137.6
>>> 2012   9 18   5.3  424.  79    -3 137.6
>>> 2012   9 19   5.7  437.  79    -2 137.6
>>> 2012   9 20   6.1  427.  79    -4 137.6
>>> 2012   9 21   6.0  409.  79    -7 137.6
>>> 2012   9 22   6.6  410.  79    -4 137.6
>>> 2012   9 23   6.4  432.  79    -1 137.6
>>> 2012  10  0   5.9  434.  70     2 124.6
>>> 2012  10  1   5.6  424.  70     4 124.6
>>> 2012  10  2   4.8  435.  70     7 124.6
>>> 2012  10  3   4.6  425.  70     4 124.6
>>> 2012  10  4   4.3  424.  70     3 124.6
>>> 2012  10  5   5.4  426.  70     2 124.6
>>> 2012  10  6   5.5  434.  70     2 124.6
>>> 2012  10  7   6.4  435.  70     4 124.6
>>> 2012  10  8   6.3  436.  70     1 124.6
>>> 2012  10  9   5.2  431.  70    -6 124.6
>>> 2012  10 10   4.5  426.  70   -10 124.6
>>> 2012  10 11   4.6  435.  70    -9 124.6
>>> 2012  10 12   3.4  425.  70    -5 124.6
>>> 2012  10 13   4.2  427.  70    -4 124.6
>>> 2012  10 14   4.0  432.  70     2 124.6
>>> 2012  10 15   5.5  450.  70     7 124.6
>>> 2012  10 16   5.9  451.  70     2 124.6
>>> 2012  10 17   5.5  445.  70    -3 124.6
>>> 2012  10 18   5.8  442.  70    -2 124.6
>>> 2012  10 19   5.4  430.  70    -1 124.6
>>> 2012  10 20   4.9  427.  70    -1 124.6
>>> 2012  10 21   4.0  436.  70     0 124.6
>>> 2012  10 22   3.4  445.  70    -1 124.6
>>> 2012  10 23   4.5  453.  70     0 124.6
>>> 2012  11  0   5.3  438.  63     1 116.1
>>> 2012  11  1   5.0  438.  63     3 116.1
>>> 2012  11  2   5.3  445.  63     3 116.1
>>> 2012  11  3   4.5  451.  63     2 116.1
>>> 2012  11  4   5.0  456.  63    -1 116.1
>>> 2012  11  5   4.6  459.  63     0 116.1
>>> 2012  11  6   5.1  459.  63     1 116.1
>>> 2012  11  7   4.0  466.  63     3 116.1
>>> 2012  11  8   5.0  478.  63    -1 116.1
>>> 2012  11  9   4.6  489.  63    -2 116.1
>>> 2012  11 10   4.5  493.  63    -4 116.1
>>> 2012  11 11   4.5  494.  63    -1 116.1
>>> 2012  11 12   3.6  504.  63     3 116.1
>>> 2012  11 13   3.5  496.  63     5 116.1
>>> 2012  11 14   3.3  497.  63     7 116.1
>>> 2012  11 15   3.0  498.  63     7 116.1
>>> 2012  11 16   2.1  503.  63     3 116.1
>>> 2012  11 17   2.0  495.  63     0 116.1
>>> 2012  11 18   2.5  492.  63    -2 116.1
>>> 2012  11 19   2.2  496.  63    -1 116.1
>>> 2012  11 20   2.4  489.  63     1 116.1
>>> 2012  11 21   2.6  489.  63     3 116.1
>>> 2012  11 22   2.6  483.  63     2 116.1
>>> 2012  11 23   2.6  478.  63     2 116.1
>>> 2012  12  0   2.9  453.  52     3 113.0
>>> 2012  12  1   2.2  446.  52     4 113.0
>>> 2012  12  2   2.4  442.  52     8 113.0
>>> 2012  12  3   2.6  440.  52    10 113.0
>>> 2012  12  4   2.2  438.  52    11 113.0
>>> 2012  12  5   2.8  438.  52     9 113.0
>>> 2012  12  6   2.0  437.  52     8 113.0
>>> 2012  12  7   2.4  426.  52     7 113.0
>>> 2012  12  8   3.0  423.  52     5 113.0
>>> 2012  12  9   3.3  420.  52     4 113.0
>>> 2012  12 10   4.0  419.  52     2 113.0
>>> 2012  12 11   3.8  412.  52     5 113.0
>>> 2012  12 12   4.2  409.  52     4 113.0
>>> 2012  12 13   3.5  408.  52     2 113.0
>>> 2012  12 14   3.7  404.  52     9 113.0
>>> 2012  12 15   4.5  402.  52    15 113.0
>>> 2012  12 16   3.6  395.  52    14 113.0
>>> 2012  12 17   2.4  392.  52    16 113.0
>>> 2012  12 18   5.8  403.  52    27 113.0
>>> 2012  12 19   7.6  400.  52    27 113.0
>>> 2012  12 20   6.9  418.  52    17 113.0
>>> 2012  12 21   6.9  463.  52    10 113.0
>>> 2012  12 22   7.3  469.  52     9 113.0
>>> 2012  12 23   5.5  482.  52    12 113.0
>>> 2012  13  0   7.7  500.  71    10 120.0
>>> 2012  13  1   8.7  492.  71    14 120.0
>>> 2012  13  2   7.8  513.  71    16 120.0
>>> 2012  13  3   7.5  530.  71    11 120.0
>>> 2012  13  4   7.1  518.  71     8 120.0
>>> 2012  13  5   7.0  524.  71     6 120.0
>>> 2012  13  6   5.9  536.  71     8 120.0
>>> 2012  13  7   3.6  529.  71     5 120.0
>>> 2012  13  8   4.1  510.  71     4 120.0
>>> 2012  13  9   3.9  497.  71     3 120.0
>>> 2012  13 10   2.4  492.  71     3 120.0
>>> 2012  13 11   2.6  485.  71     5 120.0
>>> 2012  13 12   2.9  492.  71     5 120.0
>>> 2012  13 13   2.6  487.  71     3 120.0
>>> 2012  13 14   2.3  478.  71     6 120.0
>>> 2012  13 15   3.2  467.  71    11 120.0
>>> 2012  13 16   3.4  453.  71    10 120.0
>>> 2012  13 17   3.2  452.  71     6 120.0
>>> 2012  13 18   3.0  452.  71     2 120.0
>>> 2012  13 19   2.8  447.  71     1 120.0
>>> 2012  13 20   2.5  439.  71     0 120.0
>>> 2012  13 21   2.5  443.  71    -2 120.0
>>> 2012  13 22   2.7  442.  71    -3 120.0
>>> 2012  13 23   3.0  447.  71    -4 120.0
>>> 2012  14  0   3.5  445. 118    -3 128.0
>>> 2012  14  1   3.3  440. 118    -1 128.0
>>> 2012  14  2   3.1  440. 118     1 128.0
>>> 2012  14  3   2.7  446. 118     0 128.0
>>> 2012  14  4   2.9  442. 118    -1 128.0
>>> 2012  14  5   2.9  437. 118    -2 128.0
>>> 2012  14  6   3.3  431. 118    -3 128.0
>>> 2012  14  7   2.8  420. 118    -2 128.0
>>> 2012  14  8   2.3  409. 118    -2 128.0
>>> 2012  14  9   2.2  407. 118     1 128.0
>>> 2012  14 10   2.6  405. 118     3 128.0
>>> 2012  14 11   2.8  401. 118     4 128.0
>>> 2012  14 12   3.2  398. 118     4 128.0
>>> 2012  14 13   2.7  400. 118     4 128.0
>>> 2012  14 14   1.9  399. 118     5 128.0
>>> 2012  14 15   2.4  395. 118     3 128.0
>>> 2012  14 16   2.7  389. 118     2 128.0
>>> 2012  14 17   2.9  385. 118     0 128.0
>>> 2012  14 18   3.2  384. 118     1 128.0
>>> 2012  14 19   2.6  380. 118     2 128.0
>>> 2012  14 20   2.3  378. 118     1 128.0
>>> 2012  14 21   2.1  374. 118     0 128.0
>>> 2012  14 22   3.1  367. 118     0 128.0
>>> 2012  14 23   4.0  366. 118    -1 128.0
>>> 2012  15  0   4.8  363. 149     0 129.2
>>> 2012  15  1   4.0  359. 149     2 129.2
>>> 2012  15  2   3.4  354. 149     2 129.2
>>> 2012  15  3   3.0  349. 149     5 129.2
>>> 2012  15  4   2.7  344. 149     7 129.2
>>> 2012  15  5   2.4  349. 149    11 129.2
>>> 2012  15  6   2.9  343. 149    12 129.2
>>> 2012  15  7   3.5  333. 149     7 129.2
>>> 2012  15  8   3.6  341. 149     4 129.2
>>> 2012  15  9   3.7  345. 149     1 129.2
>>> 2012  15 10   3.6  343. 149     2 129.2
>>> 2012  15 11   3.6  342. 149     3 129.2
>>> 2012  15 12   3.7  340. 149     7 129.2
>>> 2012  15 13   3.7  342. 149     8 129.2
>>> 2012  15 14   4.1  344. 149     9 129.2
>>> 2012  15 15   3.9  345. 149     4 129.2
>>> 2012  15 16   4.4  355. 149     8 129.2
>>> 2012  15 17   4.7  360. 149    11 129.2
>>> 2012  15 18   5.4  359. 149    12 129.2
>>> 2012  15 19   6.8  353. 149     8 129.2
>>> 2012  15 20   6.6  349. 149     6 129.2
>>> 2012  15 21   5.9  364. 149     2 129.2
>>> 2012  15 22   5.2  394. 149     1 129.2
>>> 2012  15 23   6.3  395. 149     5 129.2
>>> 2012  16  0   6.3  385. 154     6 135.1
>>> 2012  16  1   6.6  397. 154     2 135.1
>>> 2012  16  2   6.7  400. 154     4 135.1
>>> 2012  16  3   6.9  396. 154     5 135.1
>>> 2012  16  4   7.9  392. 154     5 135.1
>>> 2012  16  5   4.6  379. 154    10 135.1
>>> 2012  16  6   8.0  365. 154    13 135.1
>>> 2012  16  7   6.3  358. 154    16 135.1
>>> 2012  16  8   7.9  380. 154    12 135.1
>>> 2012  16  9  10.2  391. 154    10 135.1
>>> 2012  16 10   8.1  394. 154     8 135.1
>>> 2012  16 11  12.1  412. 154    -8 135.1
>>> 2012  16 12  13.2  424. 154   -10 135.1
>>> 2012  16 13  12.9  433. 154    -8 135.1
>>> 2012  16 14   9.3  461. 154    -7 135.1
>>> 2012  16 15   6.6  466. 154   -14 135.1
>>> 2012  16 16   6.6  493. 154   -11 135.1
>>> 2012  16 17   7.4  496. 154    -7 135.1
>>> 2012  16 18   6.2  493. 154    -7 135.1
>>> 2012  16 19   6.9  492. 154   -13 135.1
>>> 2012  16 20   6.8  486. 154   -19 135.1
>>> 2012  16 21   5.6  488. 154   -14 135.1
>>> 2012  16 22   6.4  464. 154   -11 135.1
>>> 2012  16 23   6.0  459. 154   -10 135.1
>>> 2012  17  0   4.9  476. 141   -14 134.5
>>> 2012  17  1   4.6  460. 141   -20 134.5
>>> 2012  17  2   4.1  467. 141   -17 134.5
>>> 2012  17  3   3.7  469. 141   -13 134.5
>>> 2012  17  4   3.3  472. 141   -12 134.5
>>> 2012  17  5   2.7  472. 141    -8 134.5
>>> 2012  17  6   3.5  459. 141    -6 134.5
>>> 2012  17  7   3.9  459. 141    -6 134.5
>>> 2012  17  8   4.1  463. 141    -7 134.5
>>> 2012  17  9   4.1  443. 141   -10 134.5
>>> 2012  17 10   4.1  446. 141   -14 134.5
>>> 2012  17 11   4.1  442. 141   -13 134.5
>>> 2012  17 12   3.6  436. 141   -10 134.5
>>> 2012  17 13   3.6  433. 141    -6 134.5
>>> 2012  17 14   4.2  421. 141    -1 134.5
>>> 2012  17 15   3.7  416. 141    -2 134.5
>>> 2012  17 16   4.2  410. 141    -1 134.5
>>> 2012  17 17   4.6  396. 141    -1 134.5
>>> 2012  17 18   4.5  398. 141    -2 134.5
>>> 2012  17 19   4.4  397. 141    -6 134.5
>>> 2012  17 20   4.5  396. 141    -8 134.5
>>> 2012  17 21   3.5  411. 141    -5 134.5
>>> 2012  17 22   3.9  425. 141    -5 134.5
>>> 2012  17 23   4.7  418. 141    -6 134.5
>>> 2012  18  0   4.6  400. 126    -7 143.4
>>> 2012  18  1   4.5  413. 126    -3 143.4
>>> 2012  18  2   4.4  418. 126     2 143.4
>>> 2012  18  3   4.2  420. 126     2 143.4
>>> 2012  18  4   4.0  401. 126    -2 143.4
>>> 2012  18  5   3.8  399. 126    -1 143.4
>>> 2012  18  6   3.5  388. 126    -1 143.4
>>> 2012  18  7   4.4  393. 126    -2 143.4
>>> 2012  18  8   4.7  405. 126    -3 143.4
>>> 2012  18  9   4.8  409. 126    -4 143.4
>>> 2012  18 10   4.9  409. 126    -3 143.4
>>> 2012  18 11   5.0  411. 126    -5 143.4
>>> 2012  18 12   5.1  405. 126    -5 143.4
>>> 2012  18 13   5.2  403. 126    -6 143.4
>>> 2012  18 14   5.1  394. 126    -4 143.4
>>> 2012  18 15   5.0  391. 126    -5 143.4
>>> 2012  18 16   4.6  387. 126    -4 143.4
>>> 2012  18 17   4.7  376. 126    -2 143.4
>>> 2012  18 18   4.7  381. 126    -1 143.4
>>> 2012  18 19   4.5  382. 126    -2 143.4
>>> 2012  18 20   4.9  386. 126    -5 143.4
>>> 2012  18 21   4.8  375. 126    -5 143.4
>>> 2012  18 22   4.7  385. 126    -6 143.4
>>> 2012  18 23   4.7  381. 126    -5 143.4
>>> 2012  19  0   4.3  372. 105    -3 152.0
>>> 2012  19  1   4.2  361. 105    -4 152.0
>>> 2012  19  2   4.0  360. 105    -5 152.0
>>> 2012  19  3   3.9  362. 105    -4 152.0
>>> *Jibrin Adejoh Alhassan (Ph.D)*
>>> Department of Physics and Astronomy,
>>> University of Nigeria, Nsukka
>>>
>>>
>>> On Mon, Jun 17, 2024 at 7:50?AM Jibrin Alhassan <
>> jibrin.alhassan at unn.edu.ng>
>>> wrote:
>>>
>>>> Hello Rui,
>>>> Your patience is indeed amazing. Your script tested as shown below
>> worked
>>>> perfectly well.
>>>> df1 <- read.table(text = "YEAR DOY HR   IMF  SW   SSN    Dst f10.7
>>>> 2012 215  4   5.1  371. 143    -4 138.6 ", header = TRUE)
>>>> with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
>>>> df1$Date <- with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
>>>> df1 <- df1[-(1:2)]
>>>> df1 <- df1[c(ncol(df1), 1:(ncol(df1) - 1L))]
>>>> head(df1).
>>>> But  I have 43,849 data points. Your script only generated one. Help me
>>>> with a script that can handle the whole data points. I have tried
>> following
>>>> your tested solution but was unsuccessful. My regards.
>>>> *Jibrin Adejoh Alhassan (Ph.D)*
>>>> Department of Physics and Astronomy,
>>>> University of Nigeria, Nsukka
>>>>
>>>>
>>>> On Sun, Jun 16, 2024 at 8:33?AM Rui Barradas <ruipbarradas at sapo.pt>
>> wrote:
>>>>
>>>>> ?s 21:42 de 15/06/2024, Jibrin Alhassan escreveu:
>>>>>> Thank you Rui. I ran the following script
>>>>>> df1 <- read.table("solar_hour", header = TRUE)
>>>>>> df1$date <- as.Date(paste(df1$year, df1$hour),
>>>>>>     format = "%Y %j",
>>>>>> origin = "2012-08-01-0")
>>>>>> df2 <- df1[c("date", "IMF", "SWS", "SSN", "Dst", "f10")]
>>>>>> head(df1)
>>>>>> #To display all the rows
>>>>>>     print(df2).
>>>>>> It gave me this error message
>>>>>>> source ("script.R")
>>>>>> Error in `$<-.data.frame`(`*tmp*`, date, value = numeric(0)) :
>>>>>>      replacement has 0 rows, data has 38735
>>>>>>> print(df2)
>>>>>> Error: object 'df2' not found
>>>>>>> My data is an hourly data but desire to have the date as
>>>>>> year    month    day   hour
>>>>>> 2012   08         01     01
>>>>>> 2012   08         01     02
>>>>>> 2012   08        01      03 etc
>>>>>> Thanks.
>>>>>>
>>>>>> *Jibrin Adejoh Alhassan (Ph.D)*
>>>>>> Department of Physics and Astronomy,
>>>>>> University of Nigeria, Nsukka
>>>>>>
>>>>>>
>>>>>> On Sat, Jun 15, 2024 at 8:34?PM Rui Barradas <ruipbarradas at sapo.pt>
>>>>> wrote:
>>>>>>
>>>>>>> ?s 20:00 de 15/06/2024, Jibrin Alhassan escreveu:
>>>>>>>> I have solar-geophysical data e.g as blow:
>>>>>>>> YEAR DOY HR   IMF  SW   SSN    Dst f10.7
>>>>>>>> 2012 214  0   3.4  403. 132    -9 154.6
>>>>>>>> 2012 214  1   3.7  388. 132   -10 154.6
>>>>>>>> 2012 214  2   3.7  383. 132   -10 154.6
>>>>>>>> 2012 214  3   3.7  391. 132    -9 154.6
>>>>>>>> 2012 214  4   4.2  399. 132    -7 154.6
>>>>>>>> 2012 214  5   4.1  411. 132    -6 154.6
>>>>>>>> 2012 214  6   4.0  407. 132    -6 154.6
>>>>>>>> 2012 214  7   4.2  404. 132    -4 154.6
>>>>>>>> 2012 214  8   4.3  405. 132    -6 154.6
>>>>>>>> 2012 214  9   4.4  409. 132    -6 154.6
>>>>>>>> 2012 214 10   4.4  401. 132    -6 154.6
>>>>>>>> 2012 214 11   4.5  385. 132    -7 154.6
>>>>>>>> 2012 214 12   4.7  377. 132    -8 154.6
>>>>>>>> 2012 214 13   4.7  382. 132    -6 154.6
>>>>>>>> 2012 214 14   4.3  396. 132    -4 154.6
>>>>>>>> 2012 214 15   4.1  384. 132    -2 154.6
>>>>>>>> 2012 214 16   4.0  382. 132    -1 154.6
>>>>>>>> 2012 214 17   3.9  397. 132     0 154.6
>>>>>>>> 2012 214 18   3.8  390. 132     1 154.6
>>>>>>>> 2012 214 19   4.2  400. 132     2 154.6
>>>>>>>> 2012 214 20   4.6  408. 132     1 154.6
>>>>>>>> 2012 214 21   4.8  401. 132    -3 154.6
>>>>>>>> 2012 214 22   4.9  395. 132    -5 154.6
>>>>>>>> 2012 214 23   5.0  386. 132    -1 154.6
>>>>>>>> 2012 215  0   5.0  377. 143    -1 138.6
>>>>>>>> 2012 215  1   4.9  384. 143    -2 138.6
>>>>>>>> 2012 215  2   4.9  390. 143    -4 138.6
>>>>>>>> 2012 215  3   4.9  372. 143    -6 138.6
>>>>>>>> 2012 215  4   5.1  371. 143    -4 138.6
>>>>>>>> I want to process it to be of the format as shown below
>>>>>>>>      y   m  d  hr imf  sws  ssn    Dst f10.7
>>>>>>>> 2012-08-01 10 3.4  403. 132    -9 154.6
>>>>>>>> 2012-08-01 12 3.7  388. 132   -10 154.6
>>>>>>>> 2012-08-01 15 3.7  383. 132   -10 154.6
>>>>>>>> 2012-08-01 17 3.7  391. 132    -9 154.6
>>>>>>>> I want to request an R code to accomplish this task. Thanks for your
>>>>>>> time.
>>>>>>>> *Jibrin Adejoh Alhassan (Ph.D)*
>>>>>>>> Department of Physics and Astronomy,
>>>>>>>> University of Nigeria, Nsukka
>>>>>>>>
>>>>>>>>          [[alternative HTML version deleted]]
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>> Hello,
>>>>>>>
>>>>>>> To create a date column, paste the first two columns and coerce to
>>>>> class
>>>>>>> "Date" with conversion specifications %Y for the 4 digit year and %j
>>>>> for
>>>>>>> the day of year. See
>>>>>>>
>>>>>>> help("strptime")
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> df1 <- read.table(text = "YEAR DOY HR   IMF  SW   SSN    Dst f10.7
>>>>>>> 2012 214  0   3.4  403. 132    -9 154.6
>>>>>>> 2012 214  1   3.7  388. 132   -10 154.6
>>>>>>> 2012 214  2   3.7  383. 132   -10 154.6
>>>>>>> 2012 214  3   3.7  391. 132    -9 154.6
>>>>>>> 2012 214  4   4.2  399. 132    -7 154.6
>>>>>>> 2012 214  5   4.1  411. 132    -6 154.6
>>>>>>> 2012 214  6   4.0  407. 132    -6 154.6
>>>>>>> 2012 214  7   4.2  404. 132    -4 154.6
>>>>>>> 2012 214  8   4.3  405. 132    -6 154.6
>>>>>>> 2012 214  9   4.4  409. 132    -6 154.6
>>>>>>> 2012 214 10   4.4  401. 132    -6 154.6
>>>>>>> 2012 214 11   4.5  385. 132    -7 154.6
>>>>>>> 2012 214 12   4.7  377. 132    -8 154.6
>>>>>>> 2012 214 13   4.7  382. 132    -6 154.6
>>>>>>> 2012 214 14   4.3  396. 132    -4 154.6
>>>>>>> 2012 214 15   4.1  384. 132    -2 154.6
>>>>>>> 2012 214 16   4.0  382. 132    -1 154.6
>>>>>>> 2012 214 17   3.9  397. 132     0 154.6
>>>>>>> 2012 214 18   3.8  390. 132     1 154.6
>>>>>>> 2012 214 19   4.2  400. 132     2 154.6
>>>>>>> 2012 214 20   4.6  408. 132     1 154.6
>>>>>>> 2012 214 21   4.8  401. 132    -3 154.6
>>>>>>> 2012 214 22   4.9  395. 132    -5 154.6
>>>>>>> 2012 214 23   5.0  386. 132    -1 154.6
>>>>>>> 2012 215  0   5.0  377. 143    -1 138.6
>>>>>>> 2012 215  1   4.9  384. 143    -2 138.6
>>>>>>> 2012 215  2   4.9  390. 143    -4 138.6
>>>>>>> 2012 215  3   4.9  372. 143    -6 138.6
>>>>>>> 2012 215  4   5.1  371. 143    -4 138.6", header = TRUE)
>>>>>>>
>>>>>>>
>>>>>>> with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
>>>>>>> #>  [1] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>>>>> "2012-08-01"
>>>>>>> #>  [6] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>>>>> "2012-08-01"
>>>>>>> #> [11] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>>>>> "2012-08-01"
>>>>>>> #> [16] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>>>>> "2012-08-01"
>>>>>>> #> [21] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>>>>> "2012-08-02"
>>>>>>> #> [26] "2012-08-02" "2012-08-02" "2012-08-02" "2012-08-02"
>>>>>>>
>>>>>>> # now create the column
>>>>>>> df1$Date <- with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
>>>>>>> # remove the columns no longer needed
>>>>>>> df1 <- df1[-(1:2)]
>>>>>>> # relocate the new date column
>>>>>>> df1 <- df1[c(ncol(df1), 1:(ncol(df1) - 1L))]
>>>>>>> head(df1)
>>>>>>> #>         Date HR IMF  SW SSN Dst f10.7
>>>>>>> #> 1 2012-08-01  0 3.4 403 132  -9 154.6
>>>>>>> #> 2 2012-08-01  1 3.7 388 132 -10 154.6
>>>>>>> #> 3 2012-08-01  2 3.7 383 132 -10 154.6
>>>>>>> #> 4 2012-08-01  3 3.7 391 132  -9 154.6
>>>>>>> #> 5 2012-08-01  4 4.2 399 132  -7 154.6
>>>>>>> #> 6 2012-08-01  5 4.1 411 132  -6 154.6
>>>>>>>
>>>>>>>
>>>>>>> Hope this helps,
>>>>>>>
>>>>>>> Rui Barradas
>>>>>>>
>>>>>>>
>>>>>>> --
>>>>>>> Este e-mail foi analisado pelo software antiv?rus AVG para verificar
>> a
>>>>>>> presen?a de v?rus.
>>>>>>> www.avg.com
>>>>>>>
>>>>>>
>>>>> Hello,
>>>>>
>>>>> There is an error in your new code:
>>>>>
>>>>>
>>>>> paste YEAR with DOY, not with HR.
>>>>>
>>>>>
>>>>> As for the rest, is your real data like the one you posted before?
>>>>> If it is then I don't see anything wrong with my (tested) solution.
>>>>>
>>>>>
>>>>> Hope this helps,
>>>>>
>>>>> Rui Barradas
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
>>>>> presen?a de v?rus.
>>>>> www.avg.com
>>>>>
>>>>
>>>
>> Hello,
>>
>> I cannot reproduce any error. T is vectorized so I am not understanding
>> what you mean by the script only generated one data point.
>> Here is the same code ran on your new data set, the result is as expected.
>> Note the output of str(). It days that the 1st column is of class "Date"
>> so it was created from YEAR and DOY and relocated to the 1st position.
>>
>> Can you post the output of your final df1? Please post
>>
>> head(df1)
>>
>>
>>
>> # new data
>> df1 <- read.table("~/rhelp.txt", header = TRUE)
>>
>> df1$Date <- with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
>> df1 <- df1[-(1:2)]
>> df1 <- df1[c(ncol(df1), 1:(ncol(df1) - 1L))]
>> str(df1)
>> #> 'data.frame':    436 obs. of  7 variables:
>> #>  $ Date : Date, format: "2012-01-01" "2012-01-01" ...
>> #>  $ HR   : int  0 1 2 3 4 5 6 7 8 9 ...
>> #>  $ IMF  : num  4 4.4 4.8 5.4 4.5 4.2 4.7 4.1 3.2 4.3 ...
>> #>  $ SWS  : num  379 386 380 374 369 368 367 361 362 367 ...
>> #>  $ SSN  : int  71 71 71 71 71 71 71 71 71 71 ...
>> #>  $ Dst  : int  -8 -3 -4 -5 -9 -7 -6 -10 -7 -3 ...
>> #>  $ f10.7: num  1000 1000 1000 1000 1000 ...
>> head(df1)
>> #>         Date HR IMF SWS SSN Dst f10.7
>> #> 1 2012-01-01  0 4.0 379  71  -8 999.9
>> #> 2 2012-01-01  1 4.4 386  71  -3 999.9
>> #> 3 2012-01-01  2 4.8 380  71  -4 999.9
>> #> 4 2012-01-01  3 5.4 374  71  -5 999.9
>> #> 5 2012-01-01  4 4.5 369  71  -9 999.9
>> #> 6 2012-01-01  5 4.2 368  71  -7 999.9
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>> --
>> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
>> presen?a de v?rus.
>> www.avg.com
>>
> 
Hello,

So what's the error? Your output is identical to mine. If the output of 
str(df1) is also identical to what I have posted, then everything works 
as expected.

Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng  Mon Jun 17 10:44:39 2024
From: j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng (Jibrin Alhassan)
Date: Mon, 17 Jun 2024 09:44:39 +0100
Subject: [R] code for year month day hr format
In-Reply-To: <36b96f57-b034-43df-81d3-33e5c9a0c389@sapo.pt>
References: <CAEGeL+EDsd2LnZ0v5cY-0S7ofE_qxKi-QGV2+WnSzODywRZ9MQ@mail.gmail.com>
 <474f21f7-7a41-403f-826f-853f6589ec52@sapo.pt>
 <CAEGeL+H_eukBiQKyDb1GOGo5K2kcyM7S6n167ukBWoGrQUgLyg@mail.gmail.com>
 <9347708a-d116-4879-8809-e2b5abadff25@sapo.pt>
 <CAEGeL+Hv5vXMo8yqeTTXpjXMVicSpEzk9W0pM0jd0gWRMiVsqQ@mail.gmail.com>
 <CAEGeL+FS6hN7OJqh=6NveMTMVA8Ct_mpRdGdqdezVBoXiTRe6g@mail.gmail.com>
 <053e2864-deb4-42bb-a505-555c8f9c7360@sapo.pt>
 <CAEGeL+HEUOq=VxCF0q_sD2qoDht00OvNhSNnBTXcr9dcSqxWyQ@mail.gmail.com>
 <36b96f57-b034-43df-81d3-33e5c9a0c389@sapo.pt>
Message-ID: <CAEGeL+FNxaFVkh=SwNhUEaEeGAEXWDv8DwmjEeGp0SRC-9Sw4w@mail.gmail.com>

Hello Rui,
The df1 output printed from June instead of January .Here is part of it.
4288  2012-06-27 15  6.2  420  70   -7 109.9
4289  2012-06-27 16  6.5  442  70   -9 109.9
4290  2012-06-27 17  6.3  450  70   -6 109.9
4291  2012-06-27 18  6.0  453  70    0 109.9
4292  2012-06-27 19  6.7  473  70    2 109.9
4293  2012-06-27 20  5.7  460  70    2 109.9
4294  2012-06-27 21  5.4  469  70    0 109.9
4295  2012-06-27 22  4.5  485  70   -2 109.9
4296  2012-06-27 23  4.9  497  70    1 109.9
4297  2012-06-28  0  4.6  500  87    3 123.7
4298  2012-06-28  1  4.7  503  87    2 123.7
4299  2012-06-28  2  4.3  488  87    1 123.7
4300  2012-06-28  3  4.9  479  87    0 123.7
4301  2012-06-28  4  5.1  459  87    0 123.7
4302  2012-06-28  5  4.9  458  87    0 123.7
4303  2012-06-28  6  5.1  460  87    0 123.7
4304  2012-06-28  7  5.0  451  87   -3 123.7
4305  2012-06-28  8  5.2  452  87   -5 123.7
4306  2012-06-28  9  5.2  445  87   -6 123.7
4307  2012-06-28 10  5.0  430  87   -7 123.7
4308  2012-06-28 11  4.6  434  87   -8 123.7
4309  2012-06-28 12  4.1  442  87   -7 123.7
4310  2012-06-28 13  3.9  433  87   -7 123.7
4311  2012-06-28 14  3.5  421  87   -9 123.7
4312  2012-06-28 15  4.4  420  87   -8 123.7
4313  2012-06-28 16  4.6  421  87   -9 123.7
4314  2012-06-28 17  3.2  417  87   -7 123.7
4315  2012-06-28 18  3.5  415  87   -3 123.7
4316  2012-06-28 19  3.9  394  87   -2 123.7
4317  2012-06-28 20  4.2  407  87    0 123.7
4318  2012-06-28 21  3.9  411  87   -3 123.7
4319  2012-06-28 22  3.6  420  87   -5 123.7
4320  2012-06-28 23  4.0  423  87    0 123.7
4321  2012-06-29  0  3.2  418 103    5 121.3
4322  2012-06-29  1  3.3  421 103    7 121.3
4323  2012-06-29  2  3.7  411 103    9 121.3
4324  2012-06-29  3  3.8  413 103    9 121.3
4325  2012-06-29  4  3.3  413 103    6 121.3
4326  2012-06-29  5  3.2  417 103    2 121.3
4327  2012-06-29  6  3.4  414 103    2 121.3
4328  2012-06-29  7  3.7  405 103    1 121.3
4329  2012-06-29  8  3.9  393 103    1 121.3
4330  2012-06-29  9  4.2  385 103    2 121.3
4331  2012-06-29 10  4.4  381 103    2 121.3
4332  2012-06-29 11  4.0  386 103    3 121.3
4333  2012-06-29 12  4.7  386 103    5 121.3
4334  2012-06-29 13  5.2  378 103    7 121.3
4335  2012-06-29 14  5.1  376 103    5 121.3
4336  2012-06-29 15  4.7  366 103    2 121.3
4337  2012-06-29 16  4.5  378 103    0 121.3
4338  2012-06-29 17  4.8  369 103    0 121.3
4339  2012-06-29 18  5.4  365 103    0 121.3
4340  2012-06-29 19  5.7  369 103    1 121.3
4341  2012-06-29 20  5.8  373 103    3 121.3
4342  2012-06-29 21  4.9  392 103   10 121.3
4343  2012-06-29 22  4.0  406 103   19 121.3
4344  2012-06-29 23  7.1  402 103   19 121.3
4345  2012-06-30  0  6.5  398 104   18 128.2
4346  2012-06-30  1  7.6  397 104   12 128.2
4347  2012-06-30  2  8.8  407 104   10 128.2
4348  2012-06-30  3 11.2  404 104   -1 128.2
4349  2012-06-30  4 11.2  410 104    1 128.2
4350  2012-06-30  5  8.8  410 104    1 128.2
4351  2012-06-30  6  9.7  417 104   -6 128.2
4352  2012-06-30  7 12.3  446 104  -14 128.2
4353  2012-06-30  8  9.5  476 104  -10 128.2
4354  2012-06-30  9  8.7  496 104  -13 128.2
4355  2012-06-30 10 12.6  560 104  -17 128.2
4356  2012-06-30 11 11.4  600 104  -13 128.2
4357  2012-06-30 12 11.4  607 104  -12 128.2
4358  2012-06-30 13 11.1  603 104   -8 128.2
4359  2012-06-30 14 11.1  616 104  -14 128.2
4360  2012-06-30 15  9.7  616 104  -13 128.2
4361  2012-06-30 16  9.7  629 104  -15 128.2
4362  2012-06-30 17  6.6  654 104  -24 128.2
4363  2012-06-30 18  6.5  660 104  -24 128.2
4364  2012-06-30 19  6.8  676 104  -31 128.2
4365  2012-06-30 20  7.2  675 104  -37 128.2
4366  2012-06-30 21  7.0  657 104  -32 128.2
4367  2012-06-30 22  6.4  634 104  -31 128.2
4368  2012-06-30 23  7.6  640 104  -29 128.2
4369  2012-07-01  0  6.9  650 126  -23 137.9
4370  2012-07-01  1  7.0  635 126  -18 137.9
4371  2012-07-01  2  6.9  651 126  -17 137.9
4372  2012-07-01  3  6.3  661 126  -25 137.9
4373  2012-07-01  4  5.6  663 126  -26 137.9
4374  2012-07-01  5  5.4  655 126  -26 137.9
4375  2012-07-01  6  5.1  656 126  -33 137.9
4376  2012-07-01  7  4.9  658 126  -30 137.9
4377  2012-07-01  8  5.1  648 126  -24 137.9
4378  2012-07-01  9  5.0  643 126  -24 137.9
4379  2012-07-01 10  5.0  633 126  -20 137.9
4380  2012-07-01 11  5.1  650 126  -17 137.9
4381  2012-07-01 12  5.2  687 126  -13 137.9
4382  2012-07-01 13  5.0  653 126   -8 137.9
4383  2012-07-01 14  4.9  648 126  -12 137.9
4384  2012-07-01 15  5.7  661 126  -11 137.9
4385  2012-07-01 16  5.7  665 126  -10 137.9
4386  2012-07-01 17  5.9  655 126  -12 137.9
4387  2012-07-01 18  5.1  647 126  -10 137.9
4388  2012-07-01 19  4.9  638 126  -16 137.9
4389  2012-07-01 20  5.1  633 126  -17 137.9
4390  2012-07-01 21  5.8  642 126  -16 137.9
4391  2012-07-01 22  5.8  635 126  -18 137.9
4392  2012-07-01 23  5.6  639 126  -16 137.9
4393  2012-07-02  0  5.2  653 128  -15 171.4
4394  2012-07-02  1  6.0  642 128  -12 171.4
4395  2012-07-02  2  5.3  664 128  -16 171.4
4396  2012-07-02  3  5.2  676 128  -13 171.4
4397  2012-07-02  4  5.0  662 128  -22 171.4
4398  2012-07-02  5  5.2  650 128  -28 171.4
4399  2012-07-02  6  5.0  650 128  -35 171.4
4400  2012-07-02  7  5.1  644 128  -32 171.4
4401  2012-07-02  8  4.9  653 128  -31 171.4
4402  2012-07-02  9  4.5  649 128  -26 171.4
4403  2012-07-02 10  4.3  640 128  -25 171.4
4404  2012-07-02 11  4.2  635 128  -20 171.4
4405  2012-07-02 12  4.8  636 128  -17 171.4
4406  2012-07-02 13  5.2  619 128  -16 171.4
4407  2012-07-02 14  4.9  649 128  -25 171.4
4408  2012-07-02 15  4.9  652 128  -31 171.4
4409  2012-07-02 16  5.1  649 128  -36 171.4
4410  2012-07-02 17  4.6  628 128  -37 171.4
4411  2012-07-02 18  4.2  633 128  -31 171.4
4412  2012-07-02 19  4.0  642 128  -29 171.4
4413  2012-07-02 20  3.8  643 128  -30 171.4
4414  2012-07-02 21  3.7  631 128  -32 171.4
4415  2012-07-02 22  3.7  626 128  -32 171.4
4416  2012-07-02 23  3.1  642 128  -31 171.4
4417  2012-07-03  0  3.3  634 125  -25 150.7
4418  2012-07-03  1  3.7  618 125  -19 150.7
4419  2012-07-03  2  3.9  593 125  -17 150.7
4420  2012-07-03  3  3.8  589 125  -16 150.7
4421  2012-07-03  4  3.8  576 125  -16 150.7
4422  2012-07-03  5  4.1  580 125  -20 150.7
4423  2012-07-03  6  3.9  580 125  -18 150.7
4424  2012-07-03  7  3.8  572 125  -19 150.7
4425  2012-07-03  8  4.1  562 125  -18 150.7
4426  2012-07-03  9  4.0  561 125  -15 150.7
4427  2012-07-03 10  4.1  558 125  -18 150.7
4428  2012-07-03 11  4.0  550 125  -20 150.7
4429  2012-07-03 12  4.1  548 125  -22 150.7
4430  2012-07-03 13  3.9  549 125  -21 150.7
4431  2012-07-03 14  4.1  532 125  -19 150.7
4432  2012-07-03 15  4.2  546 125  -19 150.7
4433  2012-07-03 16  4.1  547 125  -19 150.7
4434  2012-07-03 17  4.1  525 125  -23 150.7
4435  2012-07-03 18  4.0  514 125  -25 150.7
4436  2012-07-03 19  3.7  534 125  -22 150.7
4437  2012-07-03 20  3.7  541 125  -18 150.7
4438  2012-07-03 21  3.6  533 125  -19 150.7
4439  2012-07-03 22  4.3  548 125  -16 150.7
4440  2012-07-03 23  4.9  534 125  -12 150.7
4441  2012-07-04  0  4.6  538 131  -11 168.6
4442  2012-07-04  1  4.6  558 131  -10 168.6
4443  2012-07-04  2  4.1  568 131   -8 168.6
4444  2012-07-04  3  4.8  578 131   -5 168.6
4445  2012-07-04  4  5.1  580 131  -10 168.6
4446  2012-07-04  5  5.2  573 131  -17 168.6
4447  2012-07-04  6  5.1  565 131  -19 168.6
4448  2012-07-04  7  4.5  560 131  -18 168.6
4449  2012-07-04  8  4.7  555 131  -18 168.6
4450  2012-07-04  9  4.2  531 131  -19 168.6
4451  2012-07-04 10  4.1  521 131  -17 168.6
4452  2012-07-04 11  4.2  525 131  -18 168.6
4453  2012-07-04 12  3.9  526 131  -15 168.6
4454  2012-07-04 13  4.1  518 131  -10 168.6
4455  2012-07-04 14  4.5  506 131   -7 168.6
4456  2012-07-04 15  4.9  497 131   -6 168.6
4457  2012-07-04 16  4.9  498 131   -5 168.6
4458  2012-07-04 17  4.8  489 131   -5 168.6
4459  2012-07-04 18  4.5  518 131   -6 168.6
4460  2012-07-04 19  5.2  521 131   -6 168.6
4461  2012-07-04 20  6.1  535 131   -8 168.6
4462  2012-07-04 21  6.3  537 131  -14 168.6
4463  2012-07-04 22  6.4  519 131  -18 168.6
4464  2012-07-04 23  6.1  512 131  -19 168.6
4465  2012-07-05  0  5.9  500 129  -12 170.1
4466  2012-07-05  1  5.7  493 129   -1 170.1
4467  2012-07-05  2  5.8  486 129    4 170.1
4468  2012-07-05  3  5.8  487 129    4 170.1
4469  2012-07-05  4  5.4  478 129    5 170.1
4470  2012-07-05  5  5.4  478 129    2 170.1
4471  2012-07-05  6  5.9  483 129   -3 170.1
4472  2012-07-05  7  6.3  495 129   -7 170.1
4473  2012-07-05  8  6.1  503 129   -7 170.1
4474  2012-07-05  9  6.2  499 129   -2 170.1
4475  2012-07-05 10  5.9  495 129    3 170.1
4476  2012-07-05 11  4.1  499 129   21 170.1
4477  2012-07-05 12  6.8  491 129   16 170.1
4478  2012-07-05 13  6.9  489 129   11 170.1
4479  2012-07-05 14  6.5  486 129   31 170.1
4480  2012-07-05 15  8.2  478 129   11 170.1
4481  2012-07-05 16  8.1  472 129   11 170.1
4482  2012-07-05 17  9.8  486 129   11 170.1
4483  2012-07-05 18 10.0  489 129    9 170.1
4484  2012-07-05 19 10.0  489 129    8 170.1
4485  2012-07-05 20  9.8  488 129   12 170.1
4486  2012-07-05 21  9.8  485 129   13 170.1
4487  2012-07-05 22 10.3  473 129    6 170.1
4488  2012-07-05 23  9.4  460 129    7 170.1
4489  2012-07-06  0  9.4  457 132    4 163.0
4490  2012-07-06  1  9.3  448 132    6 163.0
4491  2012-07-06  2  8.8  437 132    7 163.0
4492  2012-07-06  3  7.4  435 132   -1 163.0
4493  2012-07-06  4  8.2  431 132   -3 163.0
4494  2012-07-06  5  8.2  424 132    1 163.0
4495  2012-07-06  6  7.8  429 132   -2 163.0
4496  2012-07-06  7  7.8  429 132  -10 163.0
4497  2012-07-06  8  7.6  436 132  -13 163.0
4498  2012-07-06  9  6.9  442 132   -9 163.0
4499  2012-07-06 10  5.7  458 132   -2 163.0
4500  2012-07-06 11  6.3  453 132   -3 163.0
4501  2012-07-06 12  5.0  447 132   -4 163.0
4502  2012-07-06 13  5.2  430 132   -4 163.0
4503  2012-07-06 14  5.9  417 132   -5 163.0
4504  2012-07-06 15  6.3  421 132   -7 163.0
4505  2012-07-06 16  8.7  447 132    2 163.0
4506  2012-07-06 17  9.8  453 132    4 163.0
4507  2012-07-06 18 10.1  484 132   -4 163.0
4508  2012-07-06 19  9.9  484 132  -17 163.0
4509  2012-07-06 20 10.0  485 132  -27 163.0
4510  2012-07-06 21 10.5  457 132  -36 163.0
4511  2012-07-06 22  9.9  459 132  -25 163.0
4512  2012-07-06 23  8.3  483 132   -9 163.0
4513  2012-07-07  0  8.1  486 146  -12 163.7
4514  2012-07-07  1  6.9  485 146   -6 163.7
4515  2012-07-07  2  7.1  484 146    0 163.7
4516  2012-07-07  3  5.6  480 146    4 163.7
4517  2012-07-07  4  5.2  480 146    3 163.7
4518  2012-07-07  5  5.3  493 146    1 163.7
4519  2012-07-07  6  5.1  494 146    1 163.7
4520  2012-07-07  7  4.7  469 146   -3 163.7
4521  2012-07-07  8  4.9  484 146   -7 163.7
4522  2012-07-07  9  4.3  482 146  -10 163.7
4523  2012-07-07 10  4.3  477 146   -7 163.7
4524  2012-07-07 11  4.1  467 146   -6 163.7
4525  2012-07-07 12  4.1  462 146  -10 163.7
4526  2012-07-07 13  3.8  448 146  -13 163.7
4527  2012-07-07 14  3.9  442 146  -14 163.7
4528  2012-07-07 15  3.8  443 146  -14 163.7
4529  2012-07-07 16  3.8  439 146  -12 163.7
4530  2012-07-07 17  3.4  435 146   -7 163.7
4531  2012-07-07 18  3.7  434 146   -9 163.7
4532  2012-07-07 19  3.5  428 146   -6 163.7
4533  2012-07-07 20  3.1  427 146   -3 163.7
4534  2012-07-07 21  3.2  429 146   -2 163.7
4535  2012-07-07 22  3.3  427 146   -6 163.7
4536  2012-07-07 23  3.5  434 146  -12 163.7
4537  2012-07-08  0  3.1  441 117   -9 183.7
4538  2012-07-08  1  3.1  436 117   -7 183.7
4539  2012-07-08  2  3.8  427 117   -4 183.7
4540  2012-07-08  3  3.4  418 117    3 183.7
4541  2012-07-08  4  3.6  417 117   13 183.7
4542  2012-07-08  5  4.6  413 117   15 183.7
4543  2012-07-08  6  4.3  404 117   15 183.7
4544  2012-07-08  7  4.0  394 117   11 183.7
4545  2012-07-08  8  5.5  405 117   12 183.7
4546  2012-07-08  9  9.2  423 117   14 183.7
4547  2012-07-08 10  8.8  418 117   18 183.7
4548  2012-07-08 11  9.2  407 117   11 183.7
4549  2012-07-08 12  9.2  401 117   10 183.7
4550  2012-07-08 13 10.6  412 117   18 183.7
4551  2012-07-08 14 11.1  414 117   17 183.7
4552  2012-07-08 15 11.1  458 117   13 183.7
4553  2012-07-08 16 11.3  441 117   14 183.7
4554  2012-07-08 17 11.0  439 117   15 183.7
4555  2012-07-08 18  9.8  443 117   13 183.7
4556  2012-07-08 19  8.1  439 117   10 183.7
4557  2012-07-08 20  5.1  453 117   12 183.7
4558  2012-07-08 21  8.4  462 117   16 183.7
4559  2012-07-08 22  9.0  447 117    6 183.7
4560  2012-07-08 23  9.8  436 117  -10 183.7
4561  2012-07-09  0 10.1  438 122  -27 179.6
4562  2012-07-09  1 11.6  441 122  -37 179.6
4563  2012-07-09  2 11.6  434 122  -30 179.6
4564  2012-07-09  3 11.8  421 122  -29 179.6
4565  2012-07-09  4 11.8  419 122  -33 179.6
4566  2012-07-09  5 11.6  419 122  -36 179.6
4567  2012-07-09  6 11.7  420 122  -34 179.6
4568  2012-07-09  7 12.2  415 122  -43 179.6
4569  2012-07-09  8 12.2  412 122  -49 179.6
4570  2012-07-09  9 12.3  405 122  -58 179.6
4571  2012-07-09 10 12.3  398 122  -61 179.6
4572  2012-07-09 11 12.0  392 122  -62 179.6
4573  2012-07-09 12 12.0  392 122  -78 179.6
4574  2012-07-09 13 11.9  390 122  -73 179.6
4575  2012-07-09 14 11.4  394 122  -64 179.6
4576  2012-07-09 15 10.6  400 122  -61 179.6
4577  2012-07-09 16 10.9  400 122  -71 179.6
4578  2012-07-09 17 10.7  396 122  -69 179.6
4579  2012-07-09 18 10.7  394 122  -67 179.6
4580  2012-07-09 19 10.3  395 122  -64 179.6
4581  2012-07-09 20 11.0  395 122  -64 179.6
4582  2012-07-09 21 10.8  397 122  -70 179.6
4583  2012-07-09 22 11.5  401 122  -78 179.6
4584  2012-07-09 23 11.1  401 122  -70 179.6
4585  2012-07-10  0 11.1  389 107  -65 179.2
4586  2012-07-10  1 11.8  403 107  -55 179.2
4587  2012-07-10  2 10.1  416 107  -45 179.2
4588  2012-07-10  3 11.0  406 107  -42 179.2
4589  2012-07-10  4 10.8  419 107  -42 179.2
4590  2012-07-10  5 10.6  410 107  -39 179.2
4591  2012-07-10  6 10.3  408 107  -36 179.2
4592  2012-07-10  7  9.4  417 107  -35 179.2
4593  2012-07-10  8  8.2  405 107  -38 179.2
4594  2012-07-10  9  8.3  404 107  -38 179.2
4595  2012-07-10 10  8.0  424 107  -34 179.2
4596  2012-07-10 11  7.3  433 107  -31 179.2
4597  2012-07-10 12  7.5  465 107  -28 179.2
4598  2012-07-10 13  7.3  450 107  -25 179.2
4599  2012-07-10 14  6.5  454 107  -25 179.2
4600  2012-07-10 15  6.6  472 107  -27 179.2
4601  2012-07-10 16  6.7  461 107  -28 179.2
4602  2012-07-10 17  6.5  462 107  -29 179.2
4603  2012-07-10 18  6.5  461 107  -28 179.2
4604  2012-07-10 19  5.4  483 107  -27 179.2
4605  2012-07-10 20  4.9  490 107  -24 179.2
4606  2012-07-10 21  5.6  482 107  -23 179.2
4607  2012-07-10 22  5.7  484 107  -25 179.2
4608  2012-07-10 23  5.8  484 107  -26 179.2
4609  2012-07-11  0  6.6  489 110  -27 167.1
4610  2012-07-11  1  6.7  489 110  -25 167.1
4611  2012-07-11  2  7.1  503 110  -24 167.1
4612  2012-07-11  3  5.7  494 110  -29 167.1
4613  2012-07-11  4  5.5  509 110  -30 167.1
4614  2012-07-11  5  5.3  522 110  -24 167.1
4615  2012-07-11  6  5.2  518 110  -23 167.1
4616  2012-07-11  7  6.5  516 110  -30 167.1
4617  2012-07-11  8  6.3  526 110  -36 167.1
4618  2012-07-11  9  6.2  523 110  -34 167.1
4619  2012-07-11 10  5.5  527 110  -25 167.1
4620  2012-07-11 11  6.0  527 110  -22 167.1
4621  2012-07-11 12  5.8  518 110  -22 167.1
4622  2012-07-11 13  5.4  515 110  -19 167.1
4623  2012-07-11 14  5.3  513 110  -21 167.1
4624  2012-07-11 15  5.5  512 110  -21 167.1
4625  2012-07-11 16  5.2  505 110  -21 167.1
4626  2012-07-11 17  4.9  512 110  -18 167.1
4627  2012-07-11 18  5.1  514 110  -17 167.1
4628  2012-07-11 19  6.2  520 110  -13 167.1
4629  2012-07-11 20  6.6  510 110  -17 167.1
4630  2012-07-11 21  6.2  516 110  -18 167.1
4631  2012-07-11 22  5.8  512 110  -24 167.1
4632  2012-07-11 23  5.9  509 110  -31 167.1
4633  2012-07-12  0  6.1  502 125  -34 170.9
4634  2012-07-12  1  6.6  506 125  -34 170.9
4635  2012-07-12  2  6.1  502 125  -22 170.9
4636  2012-07-12  3  5.8  480 125  -18 170.9
4637  2012-07-12  4  5.7  474 125  -15 170.9
4638  2012-07-12  5  5.4  474 125  -23 170.9
4639  2012-07-12  6  6.1  466 125  -28 170.9
4640  2012-07-12  7  5.4  460 125  -32 170.9
4641  2012-07-12  8  4.8  453 125  -32 170.9
4642  2012-07-12  9  4.7  445 125  -28 170.9
4643  2012-07-12 10  4.9  436 125  -29 170.9
4644  2012-07-12 11  4.9  441 125  -23 170.9
4645  2012-07-12 12  4.9  440 125  -18 170.9
4646  2012-07-12 13  4.2  417 125  -15 170.9
4647  2012-07-12 14  3.5  414 125  -16 170.9
4648  2012-07-12 15  3.9  418 125  -14 170.9
4649  2012-07-12 16  4.2  419 125  -11 170.9
4650  2012-07-12 17  3.9  416 125  -11 170.9
4651  2012-07-12 18  4.0  416 125  -12 170.9
4652  2012-07-12 19  3.8  415 125  -13 170.9
4653  2012-07-12 20  3.9  410 125  -16 170.9
4654  2012-07-12 21  3.8  402 125  -20 170.9
4655  2012-07-12 22  3.8  395 125  -19 170.9
4656  2012-07-12 23  3.9  394 125  -19 170.9
4657  2012-07-13  0  3.9  395 129  -20 152.1
4658  2012-07-13  1  3.8  395 129  -19 152.1
4659  2012-07-13  2  3.8  391 129  -17 152.1
4660  2012-07-13  3  3.8  385 129  -16 152.1
4661  2012-07-13  4  3.7  376 129  -15 152.1
4662  2012-07-13  5  3.8  371 129  -15 152.1
4663  2012-07-13  6  3.8  365 129  -14 152.1
4664  2012-07-13  7  3.9  357 129  -15 152.1
4665  2012-07-13  8  4.0  354 129  -18 152.1
4666  2012-07-13  9  3.9  355 129  -20 152.1
4667  2012-07-13 10  3.9  353 129  -19 152.1
4668  2012-07-13 11  3.7  357 129  -18 152.1
4669  2012-07-13 12  3.8  357 129  -18 152.1
4670  2012-07-13 13  3.8  355 129  -18 152.1
4671  2012-07-13 14  3.7  347 129  -17 152.1
4672  2012-07-13 15  3.7  350 129  -15 152.1
4673  2012-07-13 16  3.7  346 129  -13 152.1
4674  2012-07-13 17  3.7  341 129  -10 152.1
4675  2012-07-13 18  3.3  340 129   -8 152.1
4676  2012-07-13 19  3.2  338 129   -9 152.1
4677  2012-07-13 20  3.3  333 129  -10 152.1
4678  2012-07-13 21  3.4  329 129   -9 152.1
4679  2012-07-13 22  3.9  326 129   -7 152.1
4680  2012-07-13 23  4.0  324 129   -8 152.1
4681  2012-07-14  0  4.0  324 125   -9 152.8
4682  2012-07-14  1  4.0  325 125   -9 152.8
4683  2012-07-14  2  3.9  329 125   -7 152.8
4684  2012-07-14  3  4.1  326 125   -5 152.8
4685  2012-07-14  4  4.4  325 125   -6 152.8
4686  2012-07-14  5  4.5  323 125   -5 152.8
4687  2012-07-14  6  5.0  319 125   -5 152.8
4688  2012-07-14  7  5.2  317 125   -8 152.8
4689  2012-07-14  8  5.4  323 125   -7 152.8
4690  2012-07-14  9  5.4  318 125   -6 152.8
4691  2012-07-14 10  5.2  316 125   -8 152.8
4692  2012-07-14 11  5.2  326 125   -5 152.8
4693  2012-07-14 12  4.6  335 125   -5 152.8
4694  2012-07-14 13  4.2  340 125   -5 152.8
4695  2012-07-14 14  5.0  350 125   -5 152.8
4696  2012-07-14 15  4.9  366 125   -1 152.8
4697  2012-07-14 16  3.9  355 125   -5 152.8
4698  2012-07-14 17  5.1  369 125   -5 152.8
4699  2012-07-14 18 11.0  419 125   15 152.8
4700  2012-07-14 19 14.6  574 125    4 152.8
4701  2012-07-14 20 11.2  569 125   -7 152.8
4702  2012-07-14 21 13.9  568 125   -5 152.8
4703  2012-07-14 22 15.3  574 125    1 152.8
4704  2012-07-14 23 19.2  644 125   -2 152.8
4705  2012-07-15  0 11.4  665 117    9 145.1
4706  2012-07-15  1  9.7  657 117    0 145.1
*Jibrin Adejoh Alhassan (Ph.D)*
Department of Physics and Astronomy,
University of Nigeria, Nsukka


On Mon, Jun 17, 2024 at 9:23?AM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> ?s 09:12 de 17/06/2024, Jibrin Alhassan escreveu:
> > Hello Rui,
> > Here is the head(df1) output
> > Date HR IMF SWS SSN Dst f10.7
> > 1 2012-01-01  0 4.0 379  71  -8 999.9
> > 2 2012-01-01  1 4.4 386  71  -3 999.9
> > 3 2012-01-01  2 4.8 380  71  -4 999.9
> > 4 2012-01-01  3 5.4 374  71  -5 999.9
> > 5 2012-01-01  4 4.5 369  71  -9 999.9
> > 6 2012-01-01  5 4.2 368  71  -7 999.9
> > Many thanks.
> > *Jibrin Adejoh Alhassan (Ph.D)*
> > Department of Physics and Astronomy,
> > University of Nigeria, Nsukka
> >
> >
> > On Mon, Jun 17, 2024 at 8:14?AM Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
> >
> >> ?s 07:53 de 17/06/2024, Jibrin Alhassan escreveu:
> >>> Part of it is pasted below
> >>> YEAR DOY HR    IMF SWS   SSN   Dst f10.7
> >>> 2012   1  0   4.0  379.  71    -8 999.9
> >>> 2012   1  1   4.4  386.  71    -3 999.9
> >>> 2012   1  2   4.8  380.  71    -4 999.9
> >>> 2012   1  3   5.4  374.  71    -5 999.9
> >>> 2012   1  4   4.5  369.  71    -9 999.9
> >>> 2012   1  5   4.2  368.  71    -7 999.9
> >>> 2012   1  6   4.7  367.  71    -6 999.9
> >>> 2012   1  7   4.1  361.  71   -10 999.9
> >>> 2012   1  8   3.2  362.  71    -7 999.9
> >>> 2012   1  9   4.3  367.  71    -3 999.9
> >>> 2012   1 10   4.5  365.  71    -6 999.9
> >>> 2012   1 11   5.6  369.  71    -8 999.9
> >>> 2012   1 12   5.2  366.  71    -8 999.9
> >>> 2012   1 13   4.4  370.  71    -7 999.9
> >>> 2012   1 14   4.8  357.  71    -5 999.9
> >>> 2012   1 15   4.6  354.  71    -8 999.9
> >>> 2012   1 16   3.7  382.  71    -7 999.9
> >>> 2012   1 17   3.2  376.  71    -2 999.9
> >>> 2012   1 18   2.8  368.  71     2 999.9
> >>> 2012   1 19   3.2  361.  71     2 999.9
> >>> 2012   1 20   3.2  361.  71    -3 999.9
> >>> 2012   1 21   3.5  365.  71    -5 999.9
> >>> 2012   1 22   3.6  364.  71    -3 999.9
> >>> 2012   1 23   3.0  362.  71    -3 999.9
> >>> 2012   2  0   3.2  359.  92    -5 130.3
> >>> 2012   2  1   3.0  361.  92    -4 130.3
> >>> 2012   2  2   4.5  374.  92     3 130.3
> >>> 2012   2  3   4.5  364.  92     5 130.3
> >>> 2012   2  4   5.1  352.  92     3 130.3
> >>> 2012   2  5   4.9  358.  92     3 130.3
> >>> 2012   2  6   4.4  346.  92     4 130.3
> >>> 2012   2  7   4.2  349.  92     7 130.3
> >>> 2012   2  8   4.5  346.  92     8 130.3
> >>> 2012   2  9   5.2  345.  92     7 130.3
> >>> 2012   2 10   5.0  349.  92     5 130.3
> >>> 2012   2 11   4.8  345.  92     0 130.3
> >>> 2012   2 12   5.3  347.  92     0 130.3
> >>> 2012   2 13   5.5  342.  92     0 130.3
> >>> 2012   2 14   6.1  359.  92     1 130.3
> >>> 2012   2 15   6.2  393.  92     8 130.3
> >>> 2012   2 16   6.7  390.  92    10 130.3
> >>> 2012   2 17   7.7  369.  92    10 130.3
> >>> 2012   2 18   9.4  380.  92    14 130.3
> >>> 2012   2 19  10.6  386.  92    12 130.3
> >>> 2012   2 20  10.2  378.  92    11 130.3
> >>> 2012   2 21  11.6  369.  92     7 130.3
> >>> 2012   2 22  12.0  369.  92     8 130.3
> >>> 2012   2 23  10.5  361.  92     1 130.3
> >>> 2012   3  0  11.3  403. 120    -7 130.2
> >>> 2012   3  1  10.3  412. 120   -14 130.2
> >>> 2012   3  2   8.8  419. 120   -18 130.2
> >>> 2012   3  3   8.3  412. 120   -23 130.2
> >>> 2012   3  4   8.0  408. 120   -25 130.2
> >>> 2012   3  5   7.0  380. 120   -28 130.2
> >>> 2012   3  6   6.9  374. 120   -29 130.2
> >>> 2012   3  7   6.9  372. 120   -30 130.2
> >>> 2012   3  8   7.1  365. 120   -32 130.2
> >>> 2012   3  9   6.8  376. 120   -35 130.2
> >>> 2012   3 10   6.7  380. 120   -35 130.2
> >>> 2012   3 11   6.4  381. 120   -30 130.2
> >>> 2012   3 12   5.9  401. 120   -26 130.2
> >>> 2012   3 13   5.9  405. 120   -23 130.2
> >>> 2012   3 14   5.9  413. 120   -20 130.2
> >>> 2012   3 15   5.9  406. 120   -20 130.2
> >>> 2012   3 16   6.3  427. 120   -20 130.2
> >>> 2012   3 17   5.9  424. 120   -19 130.2
> >>> 2012   3 18   4.8  390. 120   -16 130.2
> >>> 2012   3 19   4.8  374. 120   -15 130.2
> >>> 2012   3 20   4.8  374. 120   -15 130.2
> >>> 2012   3 21   5.1  378. 120   -18 130.2
> >>> 2012   3 22   4.9  375. 120   -19 130.2
> >>> 2012   3 23   4.7  364. 120   -17 130.2
> >>> 2012   4  0   4.3  359. 126   -17 131.6
> >>> 2012   4  1   4.3  359. 126   -15 131.6
> >>> 2012   4  2   4.2  358. 126   -13 131.6
> >>> 2012   4  3   3.8  359. 126   -13 131.6
> >>> 2012   4  4   3.8  358. 126   -13 131.6
> >>> 2012   4  5   3.7  359. 126   -14 131.6
> >>> 2012   4  6   3.9  361. 126   -13 131.6
> >>> 2012   4  7   3.7  364. 126   -13 131.6
> >>> 2012   4  8   3.7  366. 126   -12 131.6
> >>> 2012   4  9   3.8  363. 126   -10 131.6
> >>> 2012   4 10   3.5  363. 126    -8 131.6
> >>> 2012   4 11   3.0  352. 126   -10 131.6
> >>> 2012   4 12   3.1  348. 126   -12 131.6
> >>> 2012   4 13   3.3  340. 126    -9 131.6
> >>> 2012   4 14   4.0  343. 126    -8 131.6
> >>> 2012   4 15   4.2  343. 126    -7 131.6
> >>> 2012   4 16   3.8  336. 126    -5 131.6
> >>> 2012   4 17   3.9  334. 126    -6 131.6
> >>> 2012   4 18   3.8  329. 126    -5 131.6
> >>> 2012   4 19   3.8  326. 126    -4 131.6
> >>> 2012   4 20   4.3  337. 126    -3 131.6
> >>> 2012   4 21   3.9  331. 126     0 131.6
> >>> 2012   4 22   3.8  322. 126    -1 131.6
> >>> 2012   4 23   3.5  331. 126    -1 131.6
> >>> 2012   5  0   3.9  312. 109    -3 136.6
> >>> 2012   5  1   3.6  311. 109    -1 136.6
> >>> 2012   5  2   3.7  312. 109     0 136.6
> >>> 2012   5  3   3.8  308. 109     0 136.6
> >>> 2012   5  4   4.0  305. 109     2 136.6
> >>> 2012   5  5   4.5  309. 109     2 136.6
> >>> 2012   5  6   3.5  314. 109     3 136.6
> >>> 2012   5  7   3.6  305. 109     2 136.6
> >>> 2012   5  8   4.3  307. 109     2 136.6
> >>> 2012   5  9   4.6  316. 109     1 136.6
> >>> 2012   5 10   5.0  321. 109    -4 136.6
> >>> 2012   5 11   5.1  321. 109    -6 136.6
> >>> 2012   5 12   4.6  326. 109    -4 136.6
> >>> 2012   5 13   5.7  321. 109    -2 136.6
> >>> 2012   5 14   5.0  316. 109     1 136.6
> >>> 2012   5 15   4.6  315. 109     2 136.6
> >>> 2012   5 16   5.5  321. 109     7 136.6
> >>> 2012   5 17   7.2  327. 109     7 136.6
> >>> 2012   5 18   9.2  329. 109     3 136.6
> >>> 2012   5 19   9.4  341. 109     3 136.6
> >>> 2012   5 20   9.2  345. 109     8 136.6
> >>> 2012   5 21   9.8  344. 109     9 136.6
> >>> 2012   5 22   9.8  341. 109    10 136.6
> >>> 2012   5 23  10.0  351. 109    15 136.6
> >>> 2012   6  0  10.4  356. 113    12 131.0
> >>> 2012   6  1   9.1  360. 113    10 131.0
> >>> 2012   6  2   6.6  392. 113    10 131.0
> >>> 2012   6  3   6.9  418. 113     7 131.0
> >>> 2012   6  4   6.5  408. 113     4 131.0
> >>> 2012   6  5   6.6  413. 113     7 131.0
> >>> 2012   6  6   7.3  428. 113     6 131.0
> >>> 2012   6  7   7.3  416. 113     4 131.0
> >>> 2012   6  8   7.0  411. 113     1 131.0
> >>> 2012   6  9   7.2  415. 113     1 131.0
> >>> 2012   6 10   7.2  426. 113     0 131.0
> >>> 2012   6 11   6.5  431. 113    -2 131.0
> >>> 2012   6 12   6.4  431. 113    -2 131.0
> >>> 2012   6 13   6.6  435. 113     0 131.0
> >>> 2012   6 14   6.2  425. 113     2 131.0
> >>> 2012   6 15   5.7  431. 113     4 131.0
> >>> 2012   6 16   6.1  431. 113     1 131.0
> >>> 2012   6 17   5.7  425. 113    -3 131.0
> >>> 2012   6 18   5.8  431. 113    -1 131.0
> >>> 2012   6 19   6.4  425. 113     2 131.0
> >>> 2012   6 20   6.0  434. 113     1 131.0
> >>> 2012   6 21   6.3  420. 113     0 131.0
> >>> 2012   6 22   6.3  440. 113    -3 131.0
> >>> 2012   6 23   6.5  456. 113    -3 131.0
> >>> 2012   7  0   6.3  435. 113    -5 135.9
> >>> 2012   7  1   5.9  428. 113    -1 135.9
> >>> 2012   7  2   5.7  434. 113     1 135.9
> >>> 2012   7  3   5.3  423. 113     0 135.9
> >>> 2012   7  4   4.3  417. 113     1 135.9
> >>> 2012   7  5   5.4  420. 113     0 135.9
> >>> 2012   7  6   5.7  434. 113     1 135.9
> >>> 2012   7  7   5.5  423. 113     1 135.9
> >>> 2012   7  8   4.8  419. 113    -2 135.9
> >>> 2012   7  9   5.8  421. 113    -6 135.9
> >>> 2012   7 10   5.3  412. 113    -9 135.9
> >>> 2012   7 11   4.6  424. 113    -7 135.9
> >>> 2012   7 12   4.0  439. 113    -3 135.9
> >>> 2012   7 13   4.8  431. 113    -1 135.9
> >>> 2012   7 14   5.1  431. 113    -1 135.9
> >>> 2012   7 15   4.8  427. 113    -1 135.9
> >>> 2012   7 16   4.7  429. 113    -5 135.9
> >>> 2012   7 17   5.3  436. 113    -6 135.9
> >>> 2012   7 18   5.1  426. 113    -5 135.9
> >>> 2012   7 19   5.2  427. 113    -4 135.9
> >>> 2012   7 20   4.5  416. 113    -5 135.9
> >>> 2012   7 21   4.9  409. 113    -4 135.9
> >>> 2012   7 22   5.0  417. 113    -4 135.9
> >>> 2012   7 23   5.0  426. 113    -4 135.9
> >>> 2012   8  0   5.0  433. 104    -2 131.4
> >>> 2012   8  1   4.9  426. 104    -2 131.4
> >>> 2012   8  2   4.7  421. 104    -4 131.4
> >>> 2012   8  3   4.4  417. 104    -5 131.4
> >>> 2012   8  4   4.3  416. 104    -8 131.4
> >>> 2012   8  5   4.5  416. 104    -8 131.4
> >>> 2012   8  6   5.0  419. 104    -6 131.4
> >>> 2012   8  7   5.4  446. 104    -1 131.4
> >>> 2012   8  8   5.3  439. 104    -2 131.4
> >>> 2012   8  9   5.3  432. 104    -4 131.4
> >>> 2012   8 10   5.4  434. 104    -4 131.4
> >>> 2012   8 11   5.4  435. 104    -3 131.4
> >>> 2012   8 12   4.5  421. 104    -4 131.4
> >>> 2012   8 13   4.5  422. 104    -4 131.4
> >>> 2012   8 14   5.1  425. 104    -2 131.4
> >>> 2012   8 15   5.3  429. 104     1 131.4
> >>> 2012   8 16   5.5  433. 104    -2 131.4
> >>> 2012   8 17   5.9  440. 104    -2 131.4
> >>> 2012   8 18   6.6  445. 104    -1 131.4
> >>> 2012   8 19   6.4  442. 104    -4 131.4
> >>> 2012   8 20   5.9  434. 104    -6 131.4
> >>> 2012   8 21   5.3  429. 104    -7 131.4
> >>> 2012   8 22   4.8  438. 104    -2 131.4
> >>> 2012   8 23   5.3  427. 104     4 131.4
> >>> 2012   9  0   5.5  433.  79     8 137.6
> >>> 2012   9  1   5.2  445.  79     9 137.6
> >>> 2012   9  2   5.4  439.  79    10 137.6
> >>> 2012   9  3   5.3  430.  79     7 137.6
> >>> 2012   9  4   5.1  426.  79    -3 137.6
> >>> 2012   9  5   4.7  415.  79    -6 137.6
> >>> 2012   9  6   5.0  412.  79    -4 137.6
> >>> 2012   9  7   5.2  418.  79    -2 137.6
> >>> 2012   9  8   5.5  441.  79     2 137.6
> >>> 2012   9  9   5.1  441.  79     2 137.6
> >>> 2012   9 10   5.4  430.  79    -2 137.6
> >>> 2012   9 11   5.3  433.  79    -1 137.6
> >>> 2012   9 12   5.5  438.  79     5 137.6
> >>> 2012   9 13   5.4  436.  79     6 137.6
> >>> 2012   9 14   5.7  440.  79     9 137.6
> >>> 2012   9 15   5.9  430.  79     9 137.6
> >>> 2012   9 16   5.8  437.  79     4 137.6
> >>> 2012   9 17   4.9  431.  79    -3 137.6
> >>> 2012   9 18   5.3  424.  79    -3 137.6
> >>> 2012   9 19   5.7  437.  79    -2 137.6
> >>> 2012   9 20   6.1  427.  79    -4 137.6
> >>> 2012   9 21   6.0  409.  79    -7 137.6
> >>> 2012   9 22   6.6  410.  79    -4 137.6
> >>> 2012   9 23   6.4  432.  79    -1 137.6
> >>> 2012  10  0   5.9  434.  70     2 124.6
> >>> 2012  10  1   5.6  424.  70     4 124.6
> >>> 2012  10  2   4.8  435.  70     7 124.6
> >>> 2012  10  3   4.6  425.  70     4 124.6
> >>> 2012  10  4   4.3  424.  70     3 124.6
> >>> 2012  10  5   5.4  426.  70     2 124.6
> >>> 2012  10  6   5.5  434.  70     2 124.6
> >>> 2012  10  7   6.4  435.  70     4 124.6
> >>> 2012  10  8   6.3  436.  70     1 124.6
> >>> 2012  10  9   5.2  431.  70    -6 124.6
> >>> 2012  10 10   4.5  426.  70   -10 124.6
> >>> 2012  10 11   4.6  435.  70    -9 124.6
> >>> 2012  10 12   3.4  425.  70    -5 124.6
> >>> 2012  10 13   4.2  427.  70    -4 124.6
> >>> 2012  10 14   4.0  432.  70     2 124.6
> >>> 2012  10 15   5.5  450.  70     7 124.6
> >>> 2012  10 16   5.9  451.  70     2 124.6
> >>> 2012  10 17   5.5  445.  70    -3 124.6
> >>> 2012  10 18   5.8  442.  70    -2 124.6
> >>> 2012  10 19   5.4  430.  70    -1 124.6
> >>> 2012  10 20   4.9  427.  70    -1 124.6
> >>> 2012  10 21   4.0  436.  70     0 124.6
> >>> 2012  10 22   3.4  445.  70    -1 124.6
> >>> 2012  10 23   4.5  453.  70     0 124.6
> >>> 2012  11  0   5.3  438.  63     1 116.1
> >>> 2012  11  1   5.0  438.  63     3 116.1
> >>> 2012  11  2   5.3  445.  63     3 116.1
> >>> 2012  11  3   4.5  451.  63     2 116.1
> >>> 2012  11  4   5.0  456.  63    -1 116.1
> >>> 2012  11  5   4.6  459.  63     0 116.1
> >>> 2012  11  6   5.1  459.  63     1 116.1
> >>> 2012  11  7   4.0  466.  63     3 116.1
> >>> 2012  11  8   5.0  478.  63    -1 116.1
> >>> 2012  11  9   4.6  489.  63    -2 116.1
> >>> 2012  11 10   4.5  493.  63    -4 116.1
> >>> 2012  11 11   4.5  494.  63    -1 116.1
> >>> 2012  11 12   3.6  504.  63     3 116.1
> >>> 2012  11 13   3.5  496.  63     5 116.1
> >>> 2012  11 14   3.3  497.  63     7 116.1
> >>> 2012  11 15   3.0  498.  63     7 116.1
> >>> 2012  11 16   2.1  503.  63     3 116.1
> >>> 2012  11 17   2.0  495.  63     0 116.1
> >>> 2012  11 18   2.5  492.  63    -2 116.1
> >>> 2012  11 19   2.2  496.  63    -1 116.1
> >>> 2012  11 20   2.4  489.  63     1 116.1
> >>> 2012  11 21   2.6  489.  63     3 116.1
> >>> 2012  11 22   2.6  483.  63     2 116.1
> >>> 2012  11 23   2.6  478.  63     2 116.1
> >>> 2012  12  0   2.9  453.  52     3 113.0
> >>> 2012  12  1   2.2  446.  52     4 113.0
> >>> 2012  12  2   2.4  442.  52     8 113.0
> >>> 2012  12  3   2.6  440.  52    10 113.0
> >>> 2012  12  4   2.2  438.  52    11 113.0
> >>> 2012  12  5   2.8  438.  52     9 113.0
> >>> 2012  12  6   2.0  437.  52     8 113.0
> >>> 2012  12  7   2.4  426.  52     7 113.0
> >>> 2012  12  8   3.0  423.  52     5 113.0
> >>> 2012  12  9   3.3  420.  52     4 113.0
> >>> 2012  12 10   4.0  419.  52     2 113.0
> >>> 2012  12 11   3.8  412.  52     5 113.0
> >>> 2012  12 12   4.2  409.  52     4 113.0
> >>> 2012  12 13   3.5  408.  52     2 113.0
> >>> 2012  12 14   3.7  404.  52     9 113.0
> >>> 2012  12 15   4.5  402.  52    15 113.0
> >>> 2012  12 16   3.6  395.  52    14 113.0
> >>> 2012  12 17   2.4  392.  52    16 113.0
> >>> 2012  12 18   5.8  403.  52    27 113.0
> >>> 2012  12 19   7.6  400.  52    27 113.0
> >>> 2012  12 20   6.9  418.  52    17 113.0
> >>> 2012  12 21   6.9  463.  52    10 113.0
> >>> 2012  12 22   7.3  469.  52     9 113.0
> >>> 2012  12 23   5.5  482.  52    12 113.0
> >>> 2012  13  0   7.7  500.  71    10 120.0
> >>> 2012  13  1   8.7  492.  71    14 120.0
> >>> 2012  13  2   7.8  513.  71    16 120.0
> >>> 2012  13  3   7.5  530.  71    11 120.0
> >>> 2012  13  4   7.1  518.  71     8 120.0
> >>> 2012  13  5   7.0  524.  71     6 120.0
> >>> 2012  13  6   5.9  536.  71     8 120.0
> >>> 2012  13  7   3.6  529.  71     5 120.0
> >>> 2012  13  8   4.1  510.  71     4 120.0
> >>> 2012  13  9   3.9  497.  71     3 120.0
> >>> 2012  13 10   2.4  492.  71     3 120.0
> >>> 2012  13 11   2.6  485.  71     5 120.0
> >>> 2012  13 12   2.9  492.  71     5 120.0
> >>> 2012  13 13   2.6  487.  71     3 120.0
> >>> 2012  13 14   2.3  478.  71     6 120.0
> >>> 2012  13 15   3.2  467.  71    11 120.0
> >>> 2012  13 16   3.4  453.  71    10 120.0
> >>> 2012  13 17   3.2  452.  71     6 120.0
> >>> 2012  13 18   3.0  452.  71     2 120.0
> >>> 2012  13 19   2.8  447.  71     1 120.0
> >>> 2012  13 20   2.5  439.  71     0 120.0
> >>> 2012  13 21   2.5  443.  71    -2 120.0
> >>> 2012  13 22   2.7  442.  71    -3 120.0
> >>> 2012  13 23   3.0  447.  71    -4 120.0
> >>> 2012  14  0   3.5  445. 118    -3 128.0
> >>> 2012  14  1   3.3  440. 118    -1 128.0
> >>> 2012  14  2   3.1  440. 118     1 128.0
> >>> 2012  14  3   2.7  446. 118     0 128.0
> >>> 2012  14  4   2.9  442. 118    -1 128.0
> >>> 2012  14  5   2.9  437. 118    -2 128.0
> >>> 2012  14  6   3.3  431. 118    -3 128.0
> >>> 2012  14  7   2.8  420. 118    -2 128.0
> >>> 2012  14  8   2.3  409. 118    -2 128.0
> >>> 2012  14  9   2.2  407. 118     1 128.0
> >>> 2012  14 10   2.6  405. 118     3 128.0
> >>> 2012  14 11   2.8  401. 118     4 128.0
> >>> 2012  14 12   3.2  398. 118     4 128.0
> >>> 2012  14 13   2.7  400. 118     4 128.0
> >>> 2012  14 14   1.9  399. 118     5 128.0
> >>> 2012  14 15   2.4  395. 118     3 128.0
> >>> 2012  14 16   2.7  389. 118     2 128.0
> >>> 2012  14 17   2.9  385. 118     0 128.0
> >>> 2012  14 18   3.2  384. 118     1 128.0
> >>> 2012  14 19   2.6  380. 118     2 128.0
> >>> 2012  14 20   2.3  378. 118     1 128.0
> >>> 2012  14 21   2.1  374. 118     0 128.0
> >>> 2012  14 22   3.1  367. 118     0 128.0
> >>> 2012  14 23   4.0  366. 118    -1 128.0
> >>> 2012  15  0   4.8  363. 149     0 129.2
> >>> 2012  15  1   4.0  359. 149     2 129.2
> >>> 2012  15  2   3.4  354. 149     2 129.2
> >>> 2012  15  3   3.0  349. 149     5 129.2
> >>> 2012  15  4   2.7  344. 149     7 129.2
> >>> 2012  15  5   2.4  349. 149    11 129.2
> >>> 2012  15  6   2.9  343. 149    12 129.2
> >>> 2012  15  7   3.5  333. 149     7 129.2
> >>> 2012  15  8   3.6  341. 149     4 129.2
> >>> 2012  15  9   3.7  345. 149     1 129.2
> >>> 2012  15 10   3.6  343. 149     2 129.2
> >>> 2012  15 11   3.6  342. 149     3 129.2
> >>> 2012  15 12   3.7  340. 149     7 129.2
> >>> 2012  15 13   3.7  342. 149     8 129.2
> >>> 2012  15 14   4.1  344. 149     9 129.2
> >>> 2012  15 15   3.9  345. 149     4 129.2
> >>> 2012  15 16   4.4  355. 149     8 129.2
> >>> 2012  15 17   4.7  360. 149    11 129.2
> >>> 2012  15 18   5.4  359. 149    12 129.2
> >>> 2012  15 19   6.8  353. 149     8 129.2
> >>> 2012  15 20   6.6  349. 149     6 129.2
> >>> 2012  15 21   5.9  364. 149     2 129.2
> >>> 2012  15 22   5.2  394. 149     1 129.2
> >>> 2012  15 23   6.3  395. 149     5 129.2
> >>> 2012  16  0   6.3  385. 154     6 135.1
> >>> 2012  16  1   6.6  397. 154     2 135.1
> >>> 2012  16  2   6.7  400. 154     4 135.1
> >>> 2012  16  3   6.9  396. 154     5 135.1
> >>> 2012  16  4   7.9  392. 154     5 135.1
> >>> 2012  16  5   4.6  379. 154    10 135.1
> >>> 2012  16  6   8.0  365. 154    13 135.1
> >>> 2012  16  7   6.3  358. 154    16 135.1
> >>> 2012  16  8   7.9  380. 154    12 135.1
> >>> 2012  16  9  10.2  391. 154    10 135.1
> >>> 2012  16 10   8.1  394. 154     8 135.1
> >>> 2012  16 11  12.1  412. 154    -8 135.1
> >>> 2012  16 12  13.2  424. 154   -10 135.1
> >>> 2012  16 13  12.9  433. 154    -8 135.1
> >>> 2012  16 14   9.3  461. 154    -7 135.1
> >>> 2012  16 15   6.6  466. 154   -14 135.1
> >>> 2012  16 16   6.6  493. 154   -11 135.1
> >>> 2012  16 17   7.4  496. 154    -7 135.1
> >>> 2012  16 18   6.2  493. 154    -7 135.1
> >>> 2012  16 19   6.9  492. 154   -13 135.1
> >>> 2012  16 20   6.8  486. 154   -19 135.1
> >>> 2012  16 21   5.6  488. 154   -14 135.1
> >>> 2012  16 22   6.4  464. 154   -11 135.1
> >>> 2012  16 23   6.0  459. 154   -10 135.1
> >>> 2012  17  0   4.9  476. 141   -14 134.5
> >>> 2012  17  1   4.6  460. 141   -20 134.5
> >>> 2012  17  2   4.1  467. 141   -17 134.5
> >>> 2012  17  3   3.7  469. 141   -13 134.5
> >>> 2012  17  4   3.3  472. 141   -12 134.5
> >>> 2012  17  5   2.7  472. 141    -8 134.5
> >>> 2012  17  6   3.5  459. 141    -6 134.5
> >>> 2012  17  7   3.9  459. 141    -6 134.5
> >>> 2012  17  8   4.1  463. 141    -7 134.5
> >>> 2012  17  9   4.1  443. 141   -10 134.5
> >>> 2012  17 10   4.1  446. 141   -14 134.5
> >>> 2012  17 11   4.1  442. 141   -13 134.5
> >>> 2012  17 12   3.6  436. 141   -10 134.5
> >>> 2012  17 13   3.6  433. 141    -6 134.5
> >>> 2012  17 14   4.2  421. 141    -1 134.5
> >>> 2012  17 15   3.7  416. 141    -2 134.5
> >>> 2012  17 16   4.2  410. 141    -1 134.5
> >>> 2012  17 17   4.6  396. 141    -1 134.5
> >>> 2012  17 18   4.5  398. 141    -2 134.5
> >>> 2012  17 19   4.4  397. 141    -6 134.5
> >>> 2012  17 20   4.5  396. 141    -8 134.5
> >>> 2012  17 21   3.5  411. 141    -5 134.5
> >>> 2012  17 22   3.9  425. 141    -5 134.5
> >>> 2012  17 23   4.7  418. 141    -6 134.5
> >>> 2012  18  0   4.6  400. 126    -7 143.4
> >>> 2012  18  1   4.5  413. 126    -3 143.4
> >>> 2012  18  2   4.4  418. 126     2 143.4
> >>> 2012  18  3   4.2  420. 126     2 143.4
> >>> 2012  18  4   4.0  401. 126    -2 143.4
> >>> 2012  18  5   3.8  399. 126    -1 143.4
> >>> 2012  18  6   3.5  388. 126    -1 143.4
> >>> 2012  18  7   4.4  393. 126    -2 143.4
> >>> 2012  18  8   4.7  405. 126    -3 143.4
> >>> 2012  18  9   4.8  409. 126    -4 143.4
> >>> 2012  18 10   4.9  409. 126    -3 143.4
> >>> 2012  18 11   5.0  411. 126    -5 143.4
> >>> 2012  18 12   5.1  405. 126    -5 143.4
> >>> 2012  18 13   5.2  403. 126    -6 143.4
> >>> 2012  18 14   5.1  394. 126    -4 143.4
> >>> 2012  18 15   5.0  391. 126    -5 143.4
> >>> 2012  18 16   4.6  387. 126    -4 143.4
> >>> 2012  18 17   4.7  376. 126    -2 143.4
> >>> 2012  18 18   4.7  381. 126    -1 143.4
> >>> 2012  18 19   4.5  382. 126    -2 143.4
> >>> 2012  18 20   4.9  386. 126    -5 143.4
> >>> 2012  18 21   4.8  375. 126    -5 143.4
> >>> 2012  18 22   4.7  385. 126    -6 143.4
> >>> 2012  18 23   4.7  381. 126    -5 143.4
> >>> 2012  19  0   4.3  372. 105    -3 152.0
> >>> 2012  19  1   4.2  361. 105    -4 152.0
> >>> 2012  19  2   4.0  360. 105    -5 152.0
> >>> 2012  19  3   3.9  362. 105    -4 152.0
> >>> *Jibrin Adejoh Alhassan (Ph.D)*
> >>> Department of Physics and Astronomy,
> >>> University of Nigeria, Nsukka
> >>>
> >>>
> >>> On Mon, Jun 17, 2024 at 7:50?AM Jibrin Alhassan <
> >> jibrin.alhassan at unn.edu.ng>
> >>> wrote:
> >>>
> >>>> Hello Rui,
> >>>> Your patience is indeed amazing. Your script tested as shown below
> >> worked
> >>>> perfectly well.
> >>>> df1 <- read.table(text = "YEAR DOY HR   IMF  SW   SSN    Dst f10.7
> >>>> 2012 215  4   5.1  371. 143    -4 138.6 ", header = TRUE)
> >>>> with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
> >>>> df1$Date <- with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
> >>>> df1 <- df1[-(1:2)]
> >>>> df1 <- df1[c(ncol(df1), 1:(ncol(df1) - 1L))]
> >>>> head(df1).
> >>>> But  I have 43,849 data points. Your script only generated one. Help
> me
> >>>> with a script that can handle the whole data points. I have tried
> >> following
> >>>> your tested solution but was unsuccessful. My regards.
> >>>> *Jibrin Adejoh Alhassan (Ph.D)*
> >>>> Department of Physics and Astronomy,
> >>>> University of Nigeria, Nsukka
> >>>>
> >>>>
> >>>> On Sun, Jun 16, 2024 at 8:33?AM Rui Barradas <ruipbarradas at sapo.pt>
> >> wrote:
> >>>>
> >>>>> ?s 21:42 de 15/06/2024, Jibrin Alhassan escreveu:
> >>>>>> Thank you Rui. I ran the following script
> >>>>>> df1 <- read.table("solar_hour", header = TRUE)
> >>>>>> df1$date <- as.Date(paste(df1$year, df1$hour),
> >>>>>>     format = "%Y %j",
> >>>>>> origin = "2012-08-01-0")
> >>>>>> df2 <- df1[c("date", "IMF", "SWS", "SSN", "Dst", "f10")]
> >>>>>> head(df1)
> >>>>>> #To display all the rows
> >>>>>>     print(df2).
> >>>>>> It gave me this error message
> >>>>>>> source ("script.R")
> >>>>>> Error in `$<-.data.frame`(`*tmp*`, date, value = numeric(0)) :
> >>>>>>      replacement has 0 rows, data has 38735
> >>>>>>> print(df2)
> >>>>>> Error: object 'df2' not found
> >>>>>>> My data is an hourly data but desire to have the date as
> >>>>>> year    month    day   hour
> >>>>>> 2012   08         01     01
> >>>>>> 2012   08         01     02
> >>>>>> 2012   08        01      03 etc
> >>>>>> Thanks.
> >>>>>>
> >>>>>> *Jibrin Adejoh Alhassan (Ph.D)*
> >>>>>> Department of Physics and Astronomy,
> >>>>>> University of Nigeria, Nsukka
> >>>>>>
> >>>>>>
> >>>>>> On Sat, Jun 15, 2024 at 8:34?PM Rui Barradas <ruipbarradas at sapo.pt>
> >>>>> wrote:
> >>>>>>
> >>>>>>> ?s 20:00 de 15/06/2024, Jibrin Alhassan escreveu:
> >>>>>>>> I have solar-geophysical data e.g as blow:
> >>>>>>>> YEAR DOY HR   IMF  SW   SSN    Dst f10.7
> >>>>>>>> 2012 214  0   3.4  403. 132    -9 154.6
> >>>>>>>> 2012 214  1   3.7  388. 132   -10 154.6
> >>>>>>>> 2012 214  2   3.7  383. 132   -10 154.6
> >>>>>>>> 2012 214  3   3.7  391. 132    -9 154.6
> >>>>>>>> 2012 214  4   4.2  399. 132    -7 154.6
> >>>>>>>> 2012 214  5   4.1  411. 132    -6 154.6
> >>>>>>>> 2012 214  6   4.0  407. 132    -6 154.6
> >>>>>>>> 2012 214  7   4.2  404. 132    -4 154.6
> >>>>>>>> 2012 214  8   4.3  405. 132    -6 154.6
> >>>>>>>> 2012 214  9   4.4  409. 132    -6 154.6
> >>>>>>>> 2012 214 10   4.4  401. 132    -6 154.6
> >>>>>>>> 2012 214 11   4.5  385. 132    -7 154.6
> >>>>>>>> 2012 214 12   4.7  377. 132    -8 154.6
> >>>>>>>> 2012 214 13   4.7  382. 132    -6 154.6
> >>>>>>>> 2012 214 14   4.3  396. 132    -4 154.6
> >>>>>>>> 2012 214 15   4.1  384. 132    -2 154.6
> >>>>>>>> 2012 214 16   4.0  382. 132    -1 154.6
> >>>>>>>> 2012 214 17   3.9  397. 132     0 154.6
> >>>>>>>> 2012 214 18   3.8  390. 132     1 154.6
> >>>>>>>> 2012 214 19   4.2  400. 132     2 154.6
> >>>>>>>> 2012 214 20   4.6  408. 132     1 154.6
> >>>>>>>> 2012 214 21   4.8  401. 132    -3 154.6
> >>>>>>>> 2012 214 22   4.9  395. 132    -5 154.6
> >>>>>>>> 2012 214 23   5.0  386. 132    -1 154.6
> >>>>>>>> 2012 215  0   5.0  377. 143    -1 138.6
> >>>>>>>> 2012 215  1   4.9  384. 143    -2 138.6
> >>>>>>>> 2012 215  2   4.9  390. 143    -4 138.6
> >>>>>>>> 2012 215  3   4.9  372. 143    -6 138.6
> >>>>>>>> 2012 215  4   5.1  371. 143    -4 138.6
> >>>>>>>> I want to process it to be of the format as shown below
> >>>>>>>>      y   m  d  hr imf  sws  ssn    Dst f10.7
> >>>>>>>> 2012-08-01 10 3.4  403. 132    -9 154.6
> >>>>>>>> 2012-08-01 12 3.7  388. 132   -10 154.6
> >>>>>>>> 2012-08-01 15 3.7  383. 132   -10 154.6
> >>>>>>>> 2012-08-01 17 3.7  391. 132    -9 154.6
> >>>>>>>> I want to request an R code to accomplish this task. Thanks for
> your
> >>>>>>> time.
> >>>>>>>> *Jibrin Adejoh Alhassan (Ph.D)*
> >>>>>>>> Department of Physics and Astronomy,
> >>>>>>>> University of Nigeria, Nsukka
> >>>>>>>>
> >>>>>>>>          [[alternative HTML version deleted]]
> >>>>>>>>
> >>>>>>>> ______________________________________________
> >>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>> PLEASE do read the posting guide
> >>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>>> Hello,
> >>>>>>>
> >>>>>>> To create a date column, paste the first two columns and coerce to
> >>>>> class
> >>>>>>> "Date" with conversion specifications %Y for the 4 digit year and
> %j
> >>>>> for
> >>>>>>> the day of year. See
> >>>>>>>
> >>>>>>> help("strptime")
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>> df1 <- read.table(text = "YEAR DOY HR   IMF  SW   SSN    Dst f10.7
> >>>>>>> 2012 214  0   3.4  403. 132    -9 154.6
> >>>>>>> 2012 214  1   3.7  388. 132   -10 154.6
> >>>>>>> 2012 214  2   3.7  383. 132   -10 154.6
> >>>>>>> 2012 214  3   3.7  391. 132    -9 154.6
> >>>>>>> 2012 214  4   4.2  399. 132    -7 154.6
> >>>>>>> 2012 214  5   4.1  411. 132    -6 154.6
> >>>>>>> 2012 214  6   4.0  407. 132    -6 154.6
> >>>>>>> 2012 214  7   4.2  404. 132    -4 154.6
> >>>>>>> 2012 214  8   4.3  405. 132    -6 154.6
> >>>>>>> 2012 214  9   4.4  409. 132    -6 154.6
> >>>>>>> 2012 214 10   4.4  401. 132    -6 154.6
> >>>>>>> 2012 214 11   4.5  385. 132    -7 154.6
> >>>>>>> 2012 214 12   4.7  377. 132    -8 154.6
> >>>>>>> 2012 214 13   4.7  382. 132    -6 154.6
> >>>>>>> 2012 214 14   4.3  396. 132    -4 154.6
> >>>>>>> 2012 214 15   4.1  384. 132    -2 154.6
> >>>>>>> 2012 214 16   4.0  382. 132    -1 154.6
> >>>>>>> 2012 214 17   3.9  397. 132     0 154.6
> >>>>>>> 2012 214 18   3.8  390. 132     1 154.6
> >>>>>>> 2012 214 19   4.2  400. 132     2 154.6
> >>>>>>> 2012 214 20   4.6  408. 132     1 154.6
> >>>>>>> 2012 214 21   4.8  401. 132    -3 154.6
> >>>>>>> 2012 214 22   4.9  395. 132    -5 154.6
> >>>>>>> 2012 214 23   5.0  386. 132    -1 154.6
> >>>>>>> 2012 215  0   5.0  377. 143    -1 138.6
> >>>>>>> 2012 215  1   4.9  384. 143    -2 138.6
> >>>>>>> 2012 215  2   4.9  390. 143    -4 138.6
> >>>>>>> 2012 215  3   4.9  372. 143    -6 138.6
> >>>>>>> 2012 215  4   5.1  371. 143    -4 138.6", header = TRUE)
> >>>>>>>
> >>>>>>>
> >>>>>>> with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
> >>>>>>> #>  [1] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
> >>>>> "2012-08-01"
> >>>>>>> #>  [6] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
> >>>>> "2012-08-01"
> >>>>>>> #> [11] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
> >>>>> "2012-08-01"
> >>>>>>> #> [16] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
> >>>>> "2012-08-01"
> >>>>>>> #> [21] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
> >>>>> "2012-08-02"
> >>>>>>> #> [26] "2012-08-02" "2012-08-02" "2012-08-02" "2012-08-02"
> >>>>>>>
> >>>>>>> # now create the column
> >>>>>>> df1$Date <- with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y
> %j")
> >>>>>>> # remove the columns no longer needed
> >>>>>>> df1 <- df1[-(1:2)]
> >>>>>>> # relocate the new date column
> >>>>>>> df1 <- df1[c(ncol(df1), 1:(ncol(df1) - 1L))]
> >>>>>>> head(df1)
> >>>>>>> #>         Date HR IMF  SW SSN Dst f10.7
> >>>>>>> #> 1 2012-08-01  0 3.4 403 132  -9 154.6
> >>>>>>> #> 2 2012-08-01  1 3.7 388 132 -10 154.6
> >>>>>>> #> 3 2012-08-01  2 3.7 383 132 -10 154.6
> >>>>>>> #> 4 2012-08-01  3 3.7 391 132  -9 154.6
> >>>>>>> #> 5 2012-08-01  4 4.2 399 132  -7 154.6
> >>>>>>> #> 6 2012-08-01  5 4.1 411 132  -6 154.6
> >>>>>>>
> >>>>>>>
> >>>>>>> Hope this helps,
> >>>>>>>
> >>>>>>> Rui Barradas
> >>>>>>>
> >>>>>>>
> >>>>>>> --
> >>>>>>> Este e-mail foi analisado pelo software antiv?rus AVG para
> verificar
> >> a
> >>>>>>> presen?a de v?rus.
> >>>>>>> www.avg.com
> >>>>>>>
> >>>>>>
> >>>>> Hello,
> >>>>>
> >>>>> There is an error in your new code:
> >>>>>
> >>>>>
> >>>>> paste YEAR with DOY, not with HR.
> >>>>>
> >>>>>
> >>>>> As for the rest, is your real data like the one you posted before?
> >>>>> If it is then I don't see anything wrong with my (tested) solution.
> >>>>>
> >>>>>
> >>>>> Hope this helps,
> >>>>>
> >>>>> Rui Barradas
> >>>>>
> >>>>>
> >>>>>
> >>>>> --
> >>>>> Este e-mail foi analisado pelo software antiv?rus AVG para verificar
> a
> >>>>> presen?a de v?rus.
> >>>>> www.avg.com
> >>>>>
> >>>>
> >>>
> >> Hello,
> >>
> >> I cannot reproduce any error. T is vectorized so I am not understanding
> >> what you mean by the script only generated one data point.
> >> Here is the same code ran on your new data set, the result is as
> expected.
> >> Note the output of str(). It days that the 1st column is of class "Date"
> >> so it was created from YEAR and DOY and relocated to the 1st position.
> >>
> >> Can you post the output of your final df1? Please post
> >>
> >> head(df1)
> >>
> >>
> >>
> >> # new data
> >> df1 <- read.table("~/rhelp.txt", header = TRUE)
> >>
> >> df1$Date <- with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
> >> df1 <- df1[-(1:2)]
> >> df1 <- df1[c(ncol(df1), 1:(ncol(df1) - 1L))]
> >> str(df1)
> >> #> 'data.frame':    436 obs. of  7 variables:
> >> #>  $ Date : Date, format: "2012-01-01" "2012-01-01" ...
> >> #>  $ HR   : int  0 1 2 3 4 5 6 7 8 9 ...
> >> #>  $ IMF  : num  4 4.4 4.8 5.4 4.5 4.2 4.7 4.1 3.2 4.3 ...
> >> #>  $ SWS  : num  379 386 380 374 369 368 367 361 362 367 ...
> >> #>  $ SSN  : int  71 71 71 71 71 71 71 71 71 71 ...
> >> #>  $ Dst  : int  -8 -3 -4 -5 -9 -7 -6 -10 -7 -3 ...
> >> #>  $ f10.7: num  1000 1000 1000 1000 1000 ...
> >> head(df1)
> >> #>         Date HR IMF SWS SSN Dst f10.7
> >> #> 1 2012-01-01  0 4.0 379  71  -8 999.9
> >> #> 2 2012-01-01  1 4.4 386  71  -3 999.9
> >> #> 3 2012-01-01  2 4.8 380  71  -4 999.9
> >> #> 4 2012-01-01  3 5.4 374  71  -5 999.9
> >> #> 5 2012-01-01  4 4.5 369  71  -9 999.9
> >> #> 6 2012-01-01  5 4.2 368  71  -7 999.9
> >>
> >>
> >> Hope this helps,
> >>
> >> Rui Barradas
> >>
> >>
> >> --
> >> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
> >> presen?a de v?rus.
> >> www.avg.com
> >>
> >
> Hello,
>
> So what's the error? Your output is identical to mine. If the output of
> str(df1) is also identical to what I have posted, then everything works
> as expected.
>
> Hope this helps,
>
> Rui Barradas
>
>
> --
> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
> presen?a de v?rus.
> www.avg.com
>

	[[alternative HTML version deleted]]


From pd@|gd @end|ng |rom gm@||@com  Mon Jun 17 13:26:10 2024
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Mon, 17 Jun 2024 13:26:10 +0200
Subject: [R] 
 Help trying to understand R documentation on libraries paths
In-Reply-To: <AM6PR02MB44239432A7BE1B54503E943F94CD2@AM6PR02MB4423.eurprd02.prod.outlook.com>
References: <AM6PR02MB44239432A7BE1B54503E943F94CD2@AM6PR02MB4423.eurprd02.prod.outlook.com>
Message-ID: <8EF9BC10-357E-4BAD-9D51-6868A60F5877@gmail.com>

(Inline)

> On 17 Jun 2024, at 09:51 , Iago Gin? V?zquez <iago.gine at sjd.es> wrote:
> 
> Hi,
> 
> 1 - On help(".libPaths", help_type = "text") one can read:
> 
> First, '.Library.site' is initialized from 'R_LIBS_SITE'.
> 
> However, I have
> 
>> Sys.getenv("R_LIBS_SITE")
> [1] "c:/Users/i.gine/AppData/Local/Programs/R/R-4.4.1/site-library"
>> .Library.site
> character(0)
> 
> Is this consistent?

It is implied that R_LIBS_SITE should point to an existing directory. I see the same thing on Mac:

> .Library.site
character(0)
> Sys.getenv("R_LIBS_SITE")
[1] "/Library/Frameworks/R.framework/Resources/site-library"
> list.files(Sys.getenv("R_LIBS_SITE"))
character(0)

I.e., R_LIBS_SITE is where a site library _if any_ should live. If it is not there, there is no poin in searching it. Unless you actually have a site-library, I don't think there is a problem.

> 
> 2 - Next, on the same help document, one can read:
> 
> Then, '.libPaths()' is called with the combination
>     of the directories given by 'R_LIBS' and 'R_LIBS_USER'.
> 
> 
> This time, I get
>> Sys.getenv("R_LIBS")
> [1] ""
>> Sys.getenv("R_LIBS_USER")
> [1] "c:/Users/i.gine/AppData/Local/Programs/R/R-4.4.0/library"
>> .libPaths()
> [1] "C:/Users/i.gine/AppData/Local/Programs/R/R-4.4.0/library" "C:/Users/i.gine/AppData/Local/Programs/R/R-4.4.1/library"
> 
> 
> Later is written:
> 
> Function '.libPaths' always uses the values of '.Library' and
>     '.Library.site' in the base namespace.
> 
> and indeed
> 
>> .Library
> [1] "c:/Users/i.gine/AppData/Local/Programs/R/R-4.4.1/library"
> 
> 
> Then, shouldn't be this specified above together with "directories given by 'R_LIBS' and 'R_LIBS_USER'"?
> 

The logic of .libPath() is 

> .libPaths
function (new, include.site = TRUE) 
{
    if (!missing(new)) {
        new <- Sys.glob(path.expand(new))
        paths <- c(new, if (include.site) .Library.site, .Library)
        paths <- paths[dir.exists(paths)]
        .lib.loc <<- unique(normalizePath(paths, "/"))
    }
    else .lib.loc
}

so if you "call it with" new=something, then (.Library.site, .Library) is automagically appended, unless you expressly tell it not to. 

-pd

> 
> Am I understanding it wrongly? Otherwise, what do you think on the current way this help page is explained?
> 
> Thank you for your help and time.
> 
> Best regards,
> 
> Iago
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From |@go@g|ne @end|ng |rom @jd@e@  Mon Jun 17 13:40:06 2024
From: |@go@g|ne @end|ng |rom @jd@e@ (=?iso-8859-1?Q?Iago_Gin=E9_V=E1zquez?=)
Date: Mon, 17 Jun 2024 11:40:06 +0000
Subject: [R] 
 Help trying to understand R documentation on libraries paths
In-Reply-To: <8EF9BC10-357E-4BAD-9D51-6868A60F5877@gmail.com>
References: <AM6PR02MB44239432A7BE1B54503E943F94CD2@AM6PR02MB4423.eurprd02.prod.outlook.com>
 <8EF9BC10-357E-4BAD-9D51-6868A60F5877@gmail.com>
Message-ID: <AM6PR02MB4423583395131769FE083D5F94CD2@AM6PR02MB4423.eurprd02.prod.outlook.com>

Thanks,

Regarding .libPaths, I am asking for the call to `.libPaths()`, so I understand there is no `new` in the call, as in the documentation I cited.

Iago

________________________________
De: peter dalgaard <pdalgd at gmail.com>
Enviat el: dilluns, 17 de juny de 2024 13:26
Per a: Iago Gin? V?zquez <iago.gine at sjd.es>
A/c: r-help at r-project.org <r-help at r-project.org>
Tema: Re: [R] Help trying to understand R documentation on libraries paths

(Inline)

> On 17 Jun 2024, at 09:51 , Iago Gin? V?zquez <iago.gine at sjd.es> wrote:
>
> Hi,
>
> 1 - On help(".libPaths", help_type = "text") one can read:
>
> First, '.Library.site' is initialized from 'R_LIBS_SITE'.
>
> However, I have
>
>> Sys.getenv("R_LIBS_SITE")
> [1] "c:/Users/i.gine/AppData/Local/Programs/R/R-4.4.1/site-library"
>> .Library.site
> character(0)
>
> Is this consistent?

It is implied that R_LIBS_SITE should point to an existing directory. I see the same thing on Mac:

> .Library.site
character(0)
> Sys.getenv("R_LIBS_SITE")
[1] "/Library/Frameworks/R.framework/Resources/site-library"
> list.files(Sys.getenv("R_LIBS_SITE"))
character(0)

I.e., R_LIBS_SITE is where a site library _if any_ should live. If it is not there, there is no poin in searching it. Unless you actually have a site-library, I don't think there is a problem.

>
> 2 - Next, on the same help document, one can read:
>
> Then, '.libPaths()' is called with the combination
>     of the directories given by 'R_LIBS' and 'R_LIBS_USER'.
>
>
> This time, I get
>> Sys.getenv("R_LIBS")
> [1] ""
>> Sys.getenv("R_LIBS_USER")
> [1] "c:/Users/i.gine/AppData/Local/Programs/R/R-4.4.0/library"
>> .libPaths()
> [1] "C:/Users/i.gine/AppData/Local/Programs/R/R-4.4.0/library" "C:/Users/i.gine/AppData/Local/Programs/R/R-4.4.1/library"
>
>
> Later is written:
>
> Function '.libPaths' always uses the values of '.Library' and
>     '.Library.site' in the base namespace.
>
> and indeed
>
>> .Library
> [1] "c:/Users/i.gine/AppData/Local/Programs/R/R-4.4.1/library"
>
>
> Then, shouldn't be this specified above together with "directories given by 'R_LIBS' and 'R_LIBS_USER'"?
>

The logic of .libPath() is

> .libPaths
function (new, include.site = TRUE)
{
    if (!missing(new)) {
        new <- Sys.glob(path.expand(new))
        paths <- c(new, if (include.site) .Library.site, .Library)
        paths <- paths[dir.exists(paths)]
        .lib.loc <<- unique(normalizePath(paths, "/"))
    }
    else .lib.loc
}

so if you "call it with" new=something, then (.Library.site, .Library) is automagically appended, unless you expressly tell it not to.

-pd

>
> Am I understanding it wrongly? Otherwise, what do you think on the current way this help page is explained?
>
> Thank you for your help and time.
>
> Best regards,
>
> Iago
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


	[[alternative HTML version deleted]]


From pd@|gd @end|ng |rom gm@||@com  Mon Jun 17 15:05:56 2024
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Mon, 17 Jun 2024 15:05:56 +0200
Subject: [R] 
 Help trying to understand R documentation on libraries paths
In-Reply-To: <AM6PR02MB4423583395131769FE083D5F94CD2@AM6PR02MB4423.eurprd02.prod.outlook.com>
References: <AM6PR02MB44239432A7BE1B54503E943F94CD2@AM6PR02MB4423.eurprd02.prod.outlook.com>
 <8EF9BC10-357E-4BAD-9D51-6868A60F5877@gmail.com>
 <AM6PR02MB4423583395131769FE083D5F94CD2@AM6PR02MB4423.eurprd02.prod.outlook.com>
Message-ID: <B26735B7-776E-4E94-A617-DAA0DFFB5D98@gmail.com>

I am not going to search the sources for it (your problem, your work ;-) ), but the wording would be consistent with a call like

.libPaths(c(Sys.getenv("R_LIBS"), Sys.getenv("R_LIBS_USER")))

-pd

> On 17 Jun 2024, at 13:40 , Iago Gin? V?zquez <iago.gine at sjd.es> wrote:
> 
> Thanks,
> 
> Regarding .libPaths, I am asking for the call to `.libPaths()`, so I understand there is no `new` in the call, as in the documentation I cited.
> 
> Iago
> 
> De: peter dalgaard <pdalgd at gmail.com>
> Enviat el: dilluns, 17 de juny de 2024 13:26
> Per a: Iago Gin? V?zquez <iago.gine at sjd.es>
> A/c: r-help at r-project.org <r-help at r-project.org>
> Tema: Re: [R] Help trying to understand R documentation on libraries paths
>  
> (Inline)
> 
> > On 17 Jun 2024, at 09:51 , Iago Gin? V?zquez <iago.gine at sjd.es> wrote:
> > 
> > Hi,
> > 
> > 1 - On help(".libPaths", help_type = "text") one can read:
> > 
> > First, '.Library.site' is initialized from 'R_LIBS_SITE'.
> > 
> > However, I have
> > 
> >> Sys.getenv("R_LIBS_SITE")
> > [1] "c:/Users/i.gine/AppData/Local/Programs/R/R-4.4.1/site-library"
> >> .Library.site
> > character(0)
> > 
> > Is this consistent?
> 
> It is implied that R_LIBS_SITE should point to an existing directory. I see the same thing on Mac:
> 
> > .Library.site
> character(0)
> > Sys.getenv("R_LIBS_SITE")
> [1] "/Library/Frameworks/R.framework/Resources/site-library"
> > list.files(Sys.getenv("R_LIBS_SITE"))
> character(0)
> 
> I.e., R_LIBS_SITE is where a site library _if any_ should live. If it is not there, there is no poin in searching it. Unless you actually have a site-library, I don't think there is a problem.
> 
> > 
> > 2 - Next, on the same help document, one can read:
> > 
> > Then, '.libPaths()' is called with the combination
> >     of the directories given by 'R_LIBS' and 'R_LIBS_USER'.
> > 
> > 
> > This time, I get
> >> Sys.getenv("R_LIBS")
> > [1] ""
> >> Sys.getenv("R_LIBS_USER")
> > [1] "c:/Users/i.gine/AppData/Local/Programs/R/R-4.4.0/library"
> >> .libPaths()
> > [1] "C:/Users/i.gine/AppData/Local/Programs/R/R-4.4.0/library" "C:/Users/i.gine/AppData/Local/Programs/R/R-4.4.1/library"
> > 
> > 
> > Later is written:
> > 
> > Function '.libPaths' always uses the values of '.Library' and
> >     '.Library.site' in the base namespace.
> > 
> > and indeed
> > 
> >> .Library
> > [1] "c:/Users/i.gine/AppData/Local/Programs/R/R-4.4.1/library"
> > 
> > 
> > Then, shouldn't be this specified above together with "directories given by 'R_LIBS' and 'R_LIBS_USER'"?
> > 
> 
> The logic of .libPath() is 
> 
> > .libPaths
> function (new, include.site = TRUE) 
> {
>     if (!missing(new)) {
>         new <- Sys.glob(path.expand(new))
>         paths <- c(new, if (include.site) .Library.site, .Library)
>         paths <- paths[dir.exists(paths)]
>         .lib.loc <<- unique(normalizePath(paths, "/"))
>     }
>     else .lib.loc
> }
> 
> so if you "call it with" new=something, then (.Library.site, .Library) is automagically appended, unless you expressly tell it not to. 
> 
> -pd
> 
> > 
> > Am I understanding it wrongly? Otherwise, what do you think on the current way this help page is explained?
> > 
> > Thank you for your help and time.
> > 
> > Best regards,
> > 
> > Iago
> > 
> >        [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From yo@u@yurr@mend| @end|ng |rom gm@||@com  Mon Jun 17 19:38:21 2024
From: yo@u@yurr@mend| @end|ng |rom gm@||@com (Yosu Yurramendi)
Date: Mon, 17 Jun 2024 19:38:21 +0200
Subject: [R] What is the HEX code for "transparent" color?
In-Reply-To: <CADg5kN3dTkDWj6buW5FV2ujpu3JLF4YUFSbzj7_Rw=y2EkMoqA@mail.gmail.com>
References: <CADg5kN3dTkDWj6buW5FV2ujpu3JLF4YUFSbzj7_Rw=y2EkMoqA@mail.gmail.com>
Message-ID: <CADg5kN1MTSnWe2QqC=Lujv61EXct2U0os_UBsv06-Dj+rXWK7g@mail.gmail.com>

Thank you all very much for the answers given (Greg, Robert, Duncan,
Roland).

Actually, I had tried with "#00000000" and "#FFFFFF00" (I had a mistake in
the message). For example it works with:

numrows <- 3; numcols <- 3
a <- c(1,0,1,1,1,1,1,0,1)
(pattern <- matrix(a, numrows, numcols, byrow=TRUE))
#
png(filename="transparency.00.png")
par(bg="#00000000")
palette <- c("#00000000", "black")
image(t(pattern), col = palette, axes = FALSE)
dev.off()

I took into account Duncan's answer: 'If the other answers don't solve your
problem, you should give us some context.  Not all graphics functions in R
can handle transparency, so please show us some reproducible code for what
you are trying.'

But it doesn't work on Shiny.
library(shiny)

# Define UI for application that draws a histogram
ui <- fluidPage(
   titlePanel(h3("Binary pattern (r,c)-rectangular grid", align =
"center")),
   sidebarLayout(
     sidebarPanel(
       numericInput("r", "Number of rows:", 3),
       numericInput("c", "Number of columns:", 3)
     ),
    mainPanel(plotOutput("distPlot"))
  )
)
server <- function(input, output) {
  output$distPlot <- renderPlot({
    numrows <- 3; numcols <- 3
    a <- c(1,0,1,1,1,1,1,0,1)
    pattern <- matrix(a, numrows, numcols, byrow=TRUE)
        palette <- c("#00000000", "black")
        par(bg="#00000000")
    #
    image(t(pattern), col = palette, axes = FALSE)
  })
}
shinyApp(ui = ui, server = server)

Any explanation? Any help?

Thanks


Hau idatzi du Yosu Yurramendi (yosu.yurramendi at gmail.com) erabiltzaileak
(2024 eka. 6(a), og. (10:37)):

> What is the HEX code for "transparent" color?
> I've tried "00000000" "FFFFFF00" "FFFFFFFF", but they don't work.
> Thanks
>

	[[alternative HTML version deleted]]


From ggrothend|eck @end|ng |rom gm@||@com  Mon Jun 17 20:14:28 2024
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Mon, 17 Jun 2024 14:14:28 -0400
Subject: [R] What is the HEX code for "transparent" color?
In-Reply-To: <CADg5kN3dTkDWj6buW5FV2ujpu3JLF4YUFSbzj7_Rw=y2EkMoqA@mail.gmail.com>
References: <CADg5kN3dTkDWj6buW5FV2ujpu3JLF4YUFSbzj7_Rw=y2EkMoqA@mail.gmail.com>
Message-ID: <CAP01uRm9ApF+kFbnduks8JqczWAGeUbrccUHnUFqse_vqE3wDA@mail.gmail.com>

adjustcolor("#123456", alpha = 0.5) will return the indicated color
with an alpha transparency of 50% .

On Thu, Jun 6, 2024 at 11:07?AM Yosu Yurramendi
<yosu.yurramendi at gmail.com> wrote:
>
> What is the HEX code for "transparent" color?
> I've tried "00000000" "FFFFFF00" "FFFFFFFF", but they don't work.
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From cry@n @end|ng |rom b|ngh@mton@edu  Mon Jun 17 21:53:16 2024
From: cry@n @end|ng |rom b|ngh@mton@edu (Christopher W. Ryan)
Date: Mon, 17 Jun 2024 15:53:16 -0400
Subject: [R] unable to get barchart of censored subjects from ggsurvplot()
 in survminer package, if there is no predcitor
Message-ID: <05b1b5bb-2938-274a-9841-450ca3095355@binghamton.edu>

Hello. Running R 4.2.3 on Windows 10. Using survimer package version
survminer_0.4.9 published 2021-03-09.

I'm encountering an error with ggsurvplot() in the survminer package.
Email to the author/maintainer about 2 weeks ago has not yet resulted in
a reply.

I seem unable to produce a n.censor.table for
an unconditional (no predictor) survival curve. See code below.

Any advice?

Thanks.

--Chris Ryan, MD, MS, MSPH


library(survival)
library(survminer)
data(lung)

fit <- survfit(Surv(time, status) ~ 1, data = lung)


ggsurvplot(
           fit,
           data = lung,
           xlab = "Time in days",
           ncensor.plot = TRUE
                  )

## produces error "Error:
! Problem while converting geom to grob.
? Error occurred in the 1st layer.
Caused by error:
! Unknown colour name: strata"
about "uknown colour name strata"
## but there are no strata



## omit ncensor.plot, and no error

ggsurvplot(
           fit,
           data = lung,
           xlab = "Time in days",
       #   ncensor.plot = TRUE
                  )

## restore ncensor.plot = TRUE, but use a predictor in the model,
## and no error.

fit.2 <- survfit(Surv(time, status) ~ sex, data = lung)
ggsurvplot(
           fit.2,
           data = lung,
           xlab = "Time in days",
           ncensor.plot = TRUE
                  )


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Jun 17 21:53:29 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 17 Jun 2024 20:53:29 +0100
Subject: [R] code for year month day hr format
In-Reply-To: <CAEGeL+FNxaFVkh=SwNhUEaEeGAEXWDv8DwmjEeGp0SRC-9Sw4w@mail.gmail.com>
References: <CAEGeL+EDsd2LnZ0v5cY-0S7ofE_qxKi-QGV2+WnSzODywRZ9MQ@mail.gmail.com>
 <474f21f7-7a41-403f-826f-853f6589ec52@sapo.pt>
 <CAEGeL+H_eukBiQKyDb1GOGo5K2kcyM7S6n167ukBWoGrQUgLyg@mail.gmail.com>
 <9347708a-d116-4879-8809-e2b5abadff25@sapo.pt>
 <CAEGeL+Hv5vXMo8yqeTTXpjXMVicSpEzk9W0pM0jd0gWRMiVsqQ@mail.gmail.com>
 <CAEGeL+FS6hN7OJqh=6NveMTMVA8Ct_mpRdGdqdezVBoXiTRe6g@mail.gmail.com>
 <053e2864-deb4-42bb-a505-555c8f9c7360@sapo.pt>
 <CAEGeL+HEUOq=VxCF0q_sD2qoDht00OvNhSNnBTXcr9dcSqxWyQ@mail.gmail.com>
 <36b96f57-b034-43df-81d3-33e5c9a0c389@sapo.pt>
 <CAEGeL+FNxaFVkh=SwNhUEaEeGAEXWDv8DwmjEeGp0SRC-9Sw4w@mail.gmail.com>
Message-ID: <77401bf4-4982-42dd-9f65-06fdd1ae1022@sapo.pt>

?s 09:44 de 17/06/2024, Jibrin Alhassan escreveu:
> Hello Rui,
> The df1 output printed from June instead of January .Here is part of it.
> 4288  2012-06-27 15  6.2  420  70   -7 109.9
> 4289  2012-06-27 16  6.5  442  70   -9 109.9
> 4290  2012-06-27 17  6.3  450  70   -6 109.9
> 4291  2012-06-27 18  6.0  453  70    0 109.9
> 4292  2012-06-27 19  6.7  473  70    2 109.9
> 4293  2012-06-27 20  5.7  460  70    2 109.9
> 4294  2012-06-27 21  5.4  469  70    0 109.9
> 4295  2012-06-27 22  4.5  485  70   -2 109.9
> 4296  2012-06-27 23  4.9  497  70    1 109.9
> 4297  2012-06-28  0  4.6  500  87    3 123.7
> 4298  2012-06-28  1  4.7  503  87    2 123.7
> 4299  2012-06-28  2  4.3  488  87    1 123.7
> 4300  2012-06-28  3  4.9  479  87    0 123.7
> 4301  2012-06-28  4  5.1  459  87    0 123.7
> 4302  2012-06-28  5  4.9  458  87    0 123.7
> 4303  2012-06-28  6  5.1  460  87    0 123.7
> 4304  2012-06-28  7  5.0  451  87   -3 123.7
> 4305  2012-06-28  8  5.2  452  87   -5 123.7
> 4306  2012-06-28  9  5.2  445  87   -6 123.7
> 4307  2012-06-28 10  5.0  430  87   -7 123.7
> 4308  2012-06-28 11  4.6  434  87   -8 123.7
> 4309  2012-06-28 12  4.1  442  87   -7 123.7
> 4310  2012-06-28 13  3.9  433  87   -7 123.7
> 4311  2012-06-28 14  3.5  421  87   -9 123.7
> 4312  2012-06-28 15  4.4  420  87   -8 123.7
> 4313  2012-06-28 16  4.6  421  87   -9 123.7
> 4314  2012-06-28 17  3.2  417  87   -7 123.7
> 4315  2012-06-28 18  3.5  415  87   -3 123.7
> 4316  2012-06-28 19  3.9  394  87   -2 123.7
> 4317  2012-06-28 20  4.2  407  87    0 123.7
> 4318  2012-06-28 21  3.9  411  87   -3 123.7
> 4319  2012-06-28 22  3.6  420  87   -5 123.7
> 4320  2012-06-28 23  4.0  423  87    0 123.7
> 4321  2012-06-29  0  3.2  418 103    5 121.3
> 4322  2012-06-29  1  3.3  421 103    7 121.3
> 4323  2012-06-29  2  3.7  411 103    9 121.3
> 4324  2012-06-29  3  3.8  413 103    9 121.3
> 4325  2012-06-29  4  3.3  413 103    6 121.3
> 4326  2012-06-29  5  3.2  417 103    2 121.3
> 4327  2012-06-29  6  3.4  414 103    2 121.3
> 4328  2012-06-29  7  3.7  405 103    1 121.3
> 4329  2012-06-29  8  3.9  393 103    1 121.3
> 4330  2012-06-29  9  4.2  385 103    2 121.3
> 4331  2012-06-29 10  4.4  381 103    2 121.3
> 4332  2012-06-29 11  4.0  386 103    3 121.3
> 4333  2012-06-29 12  4.7  386 103    5 121.3
> 4334  2012-06-29 13  5.2  378 103    7 121.3
> 4335  2012-06-29 14  5.1  376 103    5 121.3
> 4336  2012-06-29 15  4.7  366 103    2 121.3
> 4337  2012-06-29 16  4.5  378 103    0 121.3
> 4338  2012-06-29 17  4.8  369 103    0 121.3
> 4339  2012-06-29 18  5.4  365 103    0 121.3
> 4340  2012-06-29 19  5.7  369 103    1 121.3
> 4341  2012-06-29 20  5.8  373 103    3 121.3
> 4342  2012-06-29 21  4.9  392 103   10 121.3
> 4343  2012-06-29 22  4.0  406 103   19 121.3
> 4344  2012-06-29 23  7.1  402 103   19 121.3
> 4345  2012-06-30  0  6.5  398 104   18 128.2
> 4346  2012-06-30  1  7.6  397 104   12 128.2
> 4347  2012-06-30  2  8.8  407 104   10 128.2
> 4348  2012-06-30  3 11.2  404 104   -1 128.2
> 4349  2012-06-30  4 11.2  410 104    1 128.2
> 4350  2012-06-30  5  8.8  410 104    1 128.2
> 4351  2012-06-30  6  9.7  417 104   -6 128.2
> 4352  2012-06-30  7 12.3  446 104  -14 128.2
> 4353  2012-06-30  8  9.5  476 104  -10 128.2
> 4354  2012-06-30  9  8.7  496 104  -13 128.2
> 4355  2012-06-30 10 12.6  560 104  -17 128.2
> 4356  2012-06-30 11 11.4  600 104  -13 128.2
> 4357  2012-06-30 12 11.4  607 104  -12 128.2
> 4358  2012-06-30 13 11.1  603 104   -8 128.2
> 4359  2012-06-30 14 11.1  616 104  -14 128.2
> 4360  2012-06-30 15  9.7  616 104  -13 128.2
> 4361  2012-06-30 16  9.7  629 104  -15 128.2
> 4362  2012-06-30 17  6.6  654 104  -24 128.2
> 4363  2012-06-30 18  6.5  660 104  -24 128.2
> 4364  2012-06-30 19  6.8  676 104  -31 128.2
> 4365  2012-06-30 20  7.2  675 104  -37 128.2
> 4366  2012-06-30 21  7.0  657 104  -32 128.2
> 4367  2012-06-30 22  6.4  634 104  -31 128.2
> 4368  2012-06-30 23  7.6  640 104  -29 128.2
> 4369  2012-07-01  0  6.9  650 126  -23 137.9
> 4370  2012-07-01  1  7.0  635 126  -18 137.9
> 4371  2012-07-01  2  6.9  651 126  -17 137.9
> 4372  2012-07-01  3  6.3  661 126  -25 137.9
> 4373  2012-07-01  4  5.6  663 126  -26 137.9
> 4374  2012-07-01  5  5.4  655 126  -26 137.9
> 4375  2012-07-01  6  5.1  656 126  -33 137.9
> 4376  2012-07-01  7  4.9  658 126  -30 137.9
> 4377  2012-07-01  8  5.1  648 126  -24 137.9
> 4378  2012-07-01  9  5.0  643 126  -24 137.9
> 4379  2012-07-01 10  5.0  633 126  -20 137.9
> 4380  2012-07-01 11  5.1  650 126  -17 137.9
> 4381  2012-07-01 12  5.2  687 126  -13 137.9
> 4382  2012-07-01 13  5.0  653 126   -8 137.9
> 4383  2012-07-01 14  4.9  648 126  -12 137.9
> 4384  2012-07-01 15  5.7  661 126  -11 137.9
> 4385  2012-07-01 16  5.7  665 126  -10 137.9
> 4386  2012-07-01 17  5.9  655 126  -12 137.9
> 4387  2012-07-01 18  5.1  647 126  -10 137.9
> 4388  2012-07-01 19  4.9  638 126  -16 137.9
> 4389  2012-07-01 20  5.1  633 126  -17 137.9
> 4390  2012-07-01 21  5.8  642 126  -16 137.9
> 4391  2012-07-01 22  5.8  635 126  -18 137.9
> 4392  2012-07-01 23  5.6  639 126  -16 137.9
> 4393  2012-07-02  0  5.2  653 128  -15 171.4
> 4394  2012-07-02  1  6.0  642 128  -12 171.4
> 4395  2012-07-02  2  5.3  664 128  -16 171.4
> 4396  2012-07-02  3  5.2  676 128  -13 171.4
> 4397  2012-07-02  4  5.0  662 128  -22 171.4
> 4398  2012-07-02  5  5.2  650 128  -28 171.4
> 4399  2012-07-02  6  5.0  650 128  -35 171.4
> 4400  2012-07-02  7  5.1  644 128  -32 171.4
> 4401  2012-07-02  8  4.9  653 128  -31 171.4
> 4402  2012-07-02  9  4.5  649 128  -26 171.4
> 4403  2012-07-02 10  4.3  640 128  -25 171.4
> 4404  2012-07-02 11  4.2  635 128  -20 171.4
> 4405  2012-07-02 12  4.8  636 128  -17 171.4
> 4406  2012-07-02 13  5.2  619 128  -16 171.4
> 4407  2012-07-02 14  4.9  649 128  -25 171.4
> 4408  2012-07-02 15  4.9  652 128  -31 171.4
> 4409  2012-07-02 16  5.1  649 128  -36 171.4
> 4410  2012-07-02 17  4.6  628 128  -37 171.4
> 4411  2012-07-02 18  4.2  633 128  -31 171.4
> 4412  2012-07-02 19  4.0  642 128  -29 171.4
> 4413  2012-07-02 20  3.8  643 128  -30 171.4
> 4414  2012-07-02 21  3.7  631 128  -32 171.4
> 4415  2012-07-02 22  3.7  626 128  -32 171.4
> 4416  2012-07-02 23  3.1  642 128  -31 171.4
> 4417  2012-07-03  0  3.3  634 125  -25 150.7
> 4418  2012-07-03  1  3.7  618 125  -19 150.7
> 4419  2012-07-03  2  3.9  593 125  -17 150.7
> 4420  2012-07-03  3  3.8  589 125  -16 150.7
> 4421  2012-07-03  4  3.8  576 125  -16 150.7
> 4422  2012-07-03  5  4.1  580 125  -20 150.7
> 4423  2012-07-03  6  3.9  580 125  -18 150.7
> 4424  2012-07-03  7  3.8  572 125  -19 150.7
> 4425  2012-07-03  8  4.1  562 125  -18 150.7
> 4426  2012-07-03  9  4.0  561 125  -15 150.7
> 4427  2012-07-03 10  4.1  558 125  -18 150.7
> 4428  2012-07-03 11  4.0  550 125  -20 150.7
> 4429  2012-07-03 12  4.1  548 125  -22 150.7
> 4430  2012-07-03 13  3.9  549 125  -21 150.7
> 4431  2012-07-03 14  4.1  532 125  -19 150.7
> 4432  2012-07-03 15  4.2  546 125  -19 150.7
> 4433  2012-07-03 16  4.1  547 125  -19 150.7
> 4434  2012-07-03 17  4.1  525 125  -23 150.7
> 4435  2012-07-03 18  4.0  514 125  -25 150.7
> 4436  2012-07-03 19  3.7  534 125  -22 150.7
> 4437  2012-07-03 20  3.7  541 125  -18 150.7
> 4438  2012-07-03 21  3.6  533 125  -19 150.7
> 4439  2012-07-03 22  4.3  548 125  -16 150.7
> 4440  2012-07-03 23  4.9  534 125  -12 150.7
> 4441  2012-07-04  0  4.6  538 131  -11 168.6
> 4442  2012-07-04  1  4.6  558 131  -10 168.6
> 4443  2012-07-04  2  4.1  568 131   -8 168.6
> 4444  2012-07-04  3  4.8  578 131   -5 168.6
> 4445  2012-07-04  4  5.1  580 131  -10 168.6
> 4446  2012-07-04  5  5.2  573 131  -17 168.6
> 4447  2012-07-04  6  5.1  565 131  -19 168.6
> 4448  2012-07-04  7  4.5  560 131  -18 168.6
> 4449  2012-07-04  8  4.7  555 131  -18 168.6
> 4450  2012-07-04  9  4.2  531 131  -19 168.6
> 4451  2012-07-04 10  4.1  521 131  -17 168.6
> 4452  2012-07-04 11  4.2  525 131  -18 168.6
> 4453  2012-07-04 12  3.9  526 131  -15 168.6
> 4454  2012-07-04 13  4.1  518 131  -10 168.6
> 4455  2012-07-04 14  4.5  506 131   -7 168.6
> 4456  2012-07-04 15  4.9  497 131   -6 168.6
> 4457  2012-07-04 16  4.9  498 131   -5 168.6
> 4458  2012-07-04 17  4.8  489 131   -5 168.6
> 4459  2012-07-04 18  4.5  518 131   -6 168.6
> 4460  2012-07-04 19  5.2  521 131   -6 168.6
> 4461  2012-07-04 20  6.1  535 131   -8 168.6
> 4462  2012-07-04 21  6.3  537 131  -14 168.6
> 4463  2012-07-04 22  6.4  519 131  -18 168.6
> 4464  2012-07-04 23  6.1  512 131  -19 168.6
> 4465  2012-07-05  0  5.9  500 129  -12 170.1
> 4466  2012-07-05  1  5.7  493 129   -1 170.1
> 4467  2012-07-05  2  5.8  486 129    4 170.1
> 4468  2012-07-05  3  5.8  487 129    4 170.1
> 4469  2012-07-05  4  5.4  478 129    5 170.1
> 4470  2012-07-05  5  5.4  478 129    2 170.1
> 4471  2012-07-05  6  5.9  483 129   -3 170.1
> 4472  2012-07-05  7  6.3  495 129   -7 170.1
> 4473  2012-07-05  8  6.1  503 129   -7 170.1
> 4474  2012-07-05  9  6.2  499 129   -2 170.1
> 4475  2012-07-05 10  5.9  495 129    3 170.1
> 4476  2012-07-05 11  4.1  499 129   21 170.1
> 4477  2012-07-05 12  6.8  491 129   16 170.1
> 4478  2012-07-05 13  6.9  489 129   11 170.1
> 4479  2012-07-05 14  6.5  486 129   31 170.1
> 4480  2012-07-05 15  8.2  478 129   11 170.1
> 4481  2012-07-05 16  8.1  472 129   11 170.1
> 4482  2012-07-05 17  9.8  486 129   11 170.1
> 4483  2012-07-05 18 10.0  489 129    9 170.1
> 4484  2012-07-05 19 10.0  489 129    8 170.1
> 4485  2012-07-05 20  9.8  488 129   12 170.1
> 4486  2012-07-05 21  9.8  485 129   13 170.1
> 4487  2012-07-05 22 10.3  473 129    6 170.1
> 4488  2012-07-05 23  9.4  460 129    7 170.1
> 4489  2012-07-06  0  9.4  457 132    4 163.0
> 4490  2012-07-06  1  9.3  448 132    6 163.0
> 4491  2012-07-06  2  8.8  437 132    7 163.0
> 4492  2012-07-06  3  7.4  435 132   -1 163.0
> 4493  2012-07-06  4  8.2  431 132   -3 163.0
> 4494  2012-07-06  5  8.2  424 132    1 163.0
> 4495  2012-07-06  6  7.8  429 132   -2 163.0
> 4496  2012-07-06  7  7.8  429 132  -10 163.0
> 4497  2012-07-06  8  7.6  436 132  -13 163.0
> 4498  2012-07-06  9  6.9  442 132   -9 163.0
> 4499  2012-07-06 10  5.7  458 132   -2 163.0
> 4500  2012-07-06 11  6.3  453 132   -3 163.0
> 4501  2012-07-06 12  5.0  447 132   -4 163.0
> 4502  2012-07-06 13  5.2  430 132   -4 163.0
> 4503  2012-07-06 14  5.9  417 132   -5 163.0
> 4504  2012-07-06 15  6.3  421 132   -7 163.0
> 4505  2012-07-06 16  8.7  447 132    2 163.0
> 4506  2012-07-06 17  9.8  453 132    4 163.0
> 4507  2012-07-06 18 10.1  484 132   -4 163.0
> 4508  2012-07-06 19  9.9  484 132  -17 163.0
> 4509  2012-07-06 20 10.0  485 132  -27 163.0
> 4510  2012-07-06 21 10.5  457 132  -36 163.0
> 4511  2012-07-06 22  9.9  459 132  -25 163.0
> 4512  2012-07-06 23  8.3  483 132   -9 163.0
> 4513  2012-07-07  0  8.1  486 146  -12 163.7
> 4514  2012-07-07  1  6.9  485 146   -6 163.7
> 4515  2012-07-07  2  7.1  484 146    0 163.7
> 4516  2012-07-07  3  5.6  480 146    4 163.7
> 4517  2012-07-07  4  5.2  480 146    3 163.7
> 4518  2012-07-07  5  5.3  493 146    1 163.7
> 4519  2012-07-07  6  5.1  494 146    1 163.7
> 4520  2012-07-07  7  4.7  469 146   -3 163.7
> 4521  2012-07-07  8  4.9  484 146   -7 163.7
> 4522  2012-07-07  9  4.3  482 146  -10 163.7
> 4523  2012-07-07 10  4.3  477 146   -7 163.7
> 4524  2012-07-07 11  4.1  467 146   -6 163.7
> 4525  2012-07-07 12  4.1  462 146  -10 163.7
> 4526  2012-07-07 13  3.8  448 146  -13 163.7
> 4527  2012-07-07 14  3.9  442 146  -14 163.7
> 4528  2012-07-07 15  3.8  443 146  -14 163.7
> 4529  2012-07-07 16  3.8  439 146  -12 163.7
> 4530  2012-07-07 17  3.4  435 146   -7 163.7
> 4531  2012-07-07 18  3.7  434 146   -9 163.7
> 4532  2012-07-07 19  3.5  428 146   -6 163.7
> 4533  2012-07-07 20  3.1  427 146   -3 163.7
> 4534  2012-07-07 21  3.2  429 146   -2 163.7
> 4535  2012-07-07 22  3.3  427 146   -6 163.7
> 4536  2012-07-07 23  3.5  434 146  -12 163.7
> 4537  2012-07-08  0  3.1  441 117   -9 183.7
> 4538  2012-07-08  1  3.1  436 117   -7 183.7
> 4539  2012-07-08  2  3.8  427 117   -4 183.7
> 4540  2012-07-08  3  3.4  418 117    3 183.7
> 4541  2012-07-08  4  3.6  417 117   13 183.7
> 4542  2012-07-08  5  4.6  413 117   15 183.7
> 4543  2012-07-08  6  4.3  404 117   15 183.7
> 4544  2012-07-08  7  4.0  394 117   11 183.7
> 4545  2012-07-08  8  5.5  405 117   12 183.7
> 4546  2012-07-08  9  9.2  423 117   14 183.7
> 4547  2012-07-08 10  8.8  418 117   18 183.7
> 4548  2012-07-08 11  9.2  407 117   11 183.7
> 4549  2012-07-08 12  9.2  401 117   10 183.7
> 4550  2012-07-08 13 10.6  412 117   18 183.7
> 4551  2012-07-08 14 11.1  414 117   17 183.7
> 4552  2012-07-08 15 11.1  458 117   13 183.7
> 4553  2012-07-08 16 11.3  441 117   14 183.7
> 4554  2012-07-08 17 11.0  439 117   15 183.7
> 4555  2012-07-08 18  9.8  443 117   13 183.7
> 4556  2012-07-08 19  8.1  439 117   10 183.7
> 4557  2012-07-08 20  5.1  453 117   12 183.7
> 4558  2012-07-08 21  8.4  462 117   16 183.7
> 4559  2012-07-08 22  9.0  447 117    6 183.7
> 4560  2012-07-08 23  9.8  436 117  -10 183.7
> 4561  2012-07-09  0 10.1  438 122  -27 179.6
> 4562  2012-07-09  1 11.6  441 122  -37 179.6
> 4563  2012-07-09  2 11.6  434 122  -30 179.6
> 4564  2012-07-09  3 11.8  421 122  -29 179.6
> 4565  2012-07-09  4 11.8  419 122  -33 179.6
> 4566  2012-07-09  5 11.6  419 122  -36 179.6
> 4567  2012-07-09  6 11.7  420 122  -34 179.6
> 4568  2012-07-09  7 12.2  415 122  -43 179.6
> 4569  2012-07-09  8 12.2  412 122  -49 179.6
> 4570  2012-07-09  9 12.3  405 122  -58 179.6
> 4571  2012-07-09 10 12.3  398 122  -61 179.6
> 4572  2012-07-09 11 12.0  392 122  -62 179.6
> 4573  2012-07-09 12 12.0  392 122  -78 179.6
> 4574  2012-07-09 13 11.9  390 122  -73 179.6
> 4575  2012-07-09 14 11.4  394 122  -64 179.6
> 4576  2012-07-09 15 10.6  400 122  -61 179.6
> 4577  2012-07-09 16 10.9  400 122  -71 179.6
> 4578  2012-07-09 17 10.7  396 122  -69 179.6
> 4579  2012-07-09 18 10.7  394 122  -67 179.6
> 4580  2012-07-09 19 10.3  395 122  -64 179.6
> 4581  2012-07-09 20 11.0  395 122  -64 179.6
> 4582  2012-07-09 21 10.8  397 122  -70 179.6
> 4583  2012-07-09 22 11.5  401 122  -78 179.6
> 4584  2012-07-09 23 11.1  401 122  -70 179.6
> 4585  2012-07-10  0 11.1  389 107  -65 179.2
> 4586  2012-07-10  1 11.8  403 107  -55 179.2
> 4587  2012-07-10  2 10.1  416 107  -45 179.2
> 4588  2012-07-10  3 11.0  406 107  -42 179.2
> 4589  2012-07-10  4 10.8  419 107  -42 179.2
> 4590  2012-07-10  5 10.6  410 107  -39 179.2
> 4591  2012-07-10  6 10.3  408 107  -36 179.2
> 4592  2012-07-10  7  9.4  417 107  -35 179.2
> 4593  2012-07-10  8  8.2  405 107  -38 179.2
> 4594  2012-07-10  9  8.3  404 107  -38 179.2
> 4595  2012-07-10 10  8.0  424 107  -34 179.2
> 4596  2012-07-10 11  7.3  433 107  -31 179.2
> 4597  2012-07-10 12  7.5  465 107  -28 179.2
> 4598  2012-07-10 13  7.3  450 107  -25 179.2
> 4599  2012-07-10 14  6.5  454 107  -25 179.2
> 4600  2012-07-10 15  6.6  472 107  -27 179.2
> 4601  2012-07-10 16  6.7  461 107  -28 179.2
> 4602  2012-07-10 17  6.5  462 107  -29 179.2
> 4603  2012-07-10 18  6.5  461 107  -28 179.2
> 4604  2012-07-10 19  5.4  483 107  -27 179.2
> 4605  2012-07-10 20  4.9  490 107  -24 179.2
> 4606  2012-07-10 21  5.6  482 107  -23 179.2
> 4607  2012-07-10 22  5.7  484 107  -25 179.2
> 4608  2012-07-10 23  5.8  484 107  -26 179.2
> 4609  2012-07-11  0  6.6  489 110  -27 167.1
> 4610  2012-07-11  1  6.7  489 110  -25 167.1
> 4611  2012-07-11  2  7.1  503 110  -24 167.1
> 4612  2012-07-11  3  5.7  494 110  -29 167.1
> 4613  2012-07-11  4  5.5  509 110  -30 167.1
> 4614  2012-07-11  5  5.3  522 110  -24 167.1
> 4615  2012-07-11  6  5.2  518 110  -23 167.1
> 4616  2012-07-11  7  6.5  516 110  -30 167.1
> 4617  2012-07-11  8  6.3  526 110  -36 167.1
> 4618  2012-07-11  9  6.2  523 110  -34 167.1
> 4619  2012-07-11 10  5.5  527 110  -25 167.1
> 4620  2012-07-11 11  6.0  527 110  -22 167.1
> 4621  2012-07-11 12  5.8  518 110  -22 167.1
> 4622  2012-07-11 13  5.4  515 110  -19 167.1
> 4623  2012-07-11 14  5.3  513 110  -21 167.1
> 4624  2012-07-11 15  5.5  512 110  -21 167.1
> 4625  2012-07-11 16  5.2  505 110  -21 167.1
> 4626  2012-07-11 17  4.9  512 110  -18 167.1
> 4627  2012-07-11 18  5.1  514 110  -17 167.1
> 4628  2012-07-11 19  6.2  520 110  -13 167.1
> 4629  2012-07-11 20  6.6  510 110  -17 167.1
> 4630  2012-07-11 21  6.2  516 110  -18 167.1
> 4631  2012-07-11 22  5.8  512 110  -24 167.1
> 4632  2012-07-11 23  5.9  509 110  -31 167.1
> 4633  2012-07-12  0  6.1  502 125  -34 170.9
> 4634  2012-07-12  1  6.6  506 125  -34 170.9
> 4635  2012-07-12  2  6.1  502 125  -22 170.9
> 4636  2012-07-12  3  5.8  480 125  -18 170.9
> 4637  2012-07-12  4  5.7  474 125  -15 170.9
> 4638  2012-07-12  5  5.4  474 125  -23 170.9
> 4639  2012-07-12  6  6.1  466 125  -28 170.9
> 4640  2012-07-12  7  5.4  460 125  -32 170.9
> 4641  2012-07-12  8  4.8  453 125  -32 170.9
> 4642  2012-07-12  9  4.7  445 125  -28 170.9
> 4643  2012-07-12 10  4.9  436 125  -29 170.9
> 4644  2012-07-12 11  4.9  441 125  -23 170.9
> 4645  2012-07-12 12  4.9  440 125  -18 170.9
> 4646  2012-07-12 13  4.2  417 125  -15 170.9
> 4647  2012-07-12 14  3.5  414 125  -16 170.9
> 4648  2012-07-12 15  3.9  418 125  -14 170.9
> 4649  2012-07-12 16  4.2  419 125  -11 170.9
> 4650  2012-07-12 17  3.9  416 125  -11 170.9
> 4651  2012-07-12 18  4.0  416 125  -12 170.9
> 4652  2012-07-12 19  3.8  415 125  -13 170.9
> 4653  2012-07-12 20  3.9  410 125  -16 170.9
> 4654  2012-07-12 21  3.8  402 125  -20 170.9
> 4655  2012-07-12 22  3.8  395 125  -19 170.9
> 4656  2012-07-12 23  3.9  394 125  -19 170.9
> 4657  2012-07-13  0  3.9  395 129  -20 152.1
> 4658  2012-07-13  1  3.8  395 129  -19 152.1
> 4659  2012-07-13  2  3.8  391 129  -17 152.1
> 4660  2012-07-13  3  3.8  385 129  -16 152.1
> 4661  2012-07-13  4  3.7  376 129  -15 152.1
> 4662  2012-07-13  5  3.8  371 129  -15 152.1
> 4663  2012-07-13  6  3.8  365 129  -14 152.1
> 4664  2012-07-13  7  3.9  357 129  -15 152.1
> 4665  2012-07-13  8  4.0  354 129  -18 152.1
> 4666  2012-07-13  9  3.9  355 129  -20 152.1
> 4667  2012-07-13 10  3.9  353 129  -19 152.1
> 4668  2012-07-13 11  3.7  357 129  -18 152.1
> 4669  2012-07-13 12  3.8  357 129  -18 152.1
> 4670  2012-07-13 13  3.8  355 129  -18 152.1
> 4671  2012-07-13 14  3.7  347 129  -17 152.1
> 4672  2012-07-13 15  3.7  350 129  -15 152.1
> 4673  2012-07-13 16  3.7  346 129  -13 152.1
> 4674  2012-07-13 17  3.7  341 129  -10 152.1
> 4675  2012-07-13 18  3.3  340 129   -8 152.1
> 4676  2012-07-13 19  3.2  338 129   -9 152.1
> 4677  2012-07-13 20  3.3  333 129  -10 152.1
> 4678  2012-07-13 21  3.4  329 129   -9 152.1
> 4679  2012-07-13 22  3.9  326 129   -7 152.1
> 4680  2012-07-13 23  4.0  324 129   -8 152.1
> 4681  2012-07-14  0  4.0  324 125   -9 152.8
> 4682  2012-07-14  1  4.0  325 125   -9 152.8
> 4683  2012-07-14  2  3.9  329 125   -7 152.8
> 4684  2012-07-14  3  4.1  326 125   -5 152.8
> 4685  2012-07-14  4  4.4  325 125   -6 152.8
> 4686  2012-07-14  5  4.5  323 125   -5 152.8
> 4687  2012-07-14  6  5.0  319 125   -5 152.8
> 4688  2012-07-14  7  5.2  317 125   -8 152.8
> 4689  2012-07-14  8  5.4  323 125   -7 152.8
> 4690  2012-07-14  9  5.4  318 125   -6 152.8
> 4691  2012-07-14 10  5.2  316 125   -8 152.8
> 4692  2012-07-14 11  5.2  326 125   -5 152.8
> 4693  2012-07-14 12  4.6  335 125   -5 152.8
> 4694  2012-07-14 13  4.2  340 125   -5 152.8
> 4695  2012-07-14 14  5.0  350 125   -5 152.8
> 4696  2012-07-14 15  4.9  366 125   -1 152.8
> 4697  2012-07-14 16  3.9  355 125   -5 152.8
> 4698  2012-07-14 17  5.1  369 125   -5 152.8
> 4699  2012-07-14 18 11.0  419 125   15 152.8
> 4700  2012-07-14 19 14.6  574 125    4 152.8
> 4701  2012-07-14 20 11.2  569 125   -7 152.8
> 4702  2012-07-14 21 13.9  568 125   -5 152.8
> 4703  2012-07-14 22 15.3  574 125    1 152.8
> 4704  2012-07-14 23 19.2  644 125   -2 152.8
> 4705  2012-07-15  0 11.4  665 117    9 145.1
> 4706  2012-07-15  1  9.7  657 117    0 145.1
> *Jibrin Adejoh Alhassan (Ph.D)*
> Department of Physics and Astronomy,
> University of Nigeria, Nsukka
> 
> 
> On Mon, Jun 17, 2024 at 9:23?AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
> 
>> ?s 09:12 de 17/06/2024, Jibrin Alhassan escreveu:
>>> Hello Rui,
>>> Here is the head(df1) output
>>> Date HR IMF SWS SSN Dst f10.7
>>> 1 2012-01-01  0 4.0 379  71  -8 999.9
>>> 2 2012-01-01  1 4.4 386  71  -3 999.9
>>> 3 2012-01-01  2 4.8 380  71  -4 999.9
>>> 4 2012-01-01  3 5.4 374  71  -5 999.9
>>> 5 2012-01-01  4 4.5 369  71  -9 999.9
>>> 6 2012-01-01  5 4.2 368  71  -7 999.9
>>> Many thanks.
>>> *Jibrin Adejoh Alhassan (Ph.D)*
>>> Department of Physics and Astronomy,
>>> University of Nigeria, Nsukka
>>>
>>>
>>> On Mon, Jun 17, 2024 at 8:14?AM Rui Barradas <ruipbarradas at sapo.pt>
>> wrote:
>>>
>>>> ?s 07:53 de 17/06/2024, Jibrin Alhassan escreveu:
>>>>> Part of it is pasted below
>>>>> YEAR DOY HR    IMF SWS   SSN   Dst f10.7
>>>>> 2012   1  0   4.0  379.  71    -8 999.9
>>>>> 2012   1  1   4.4  386.  71    -3 999.9
>>>>> 2012   1  2   4.8  380.  71    -4 999.9
>>>>> 2012   1  3   5.4  374.  71    -5 999.9
>>>>> 2012   1  4   4.5  369.  71    -9 999.9
>>>>> 2012   1  5   4.2  368.  71    -7 999.9
>>>>> 2012   1  6   4.7  367.  71    -6 999.9
>>>>> 2012   1  7   4.1  361.  71   -10 999.9
>>>>> 2012   1  8   3.2  362.  71    -7 999.9
>>>>> 2012   1  9   4.3  367.  71    -3 999.9
>>>>> 2012   1 10   4.5  365.  71    -6 999.9
>>>>> 2012   1 11   5.6  369.  71    -8 999.9
>>>>> 2012   1 12   5.2  366.  71    -8 999.9
>>>>> 2012   1 13   4.4  370.  71    -7 999.9
>>>>> 2012   1 14   4.8  357.  71    -5 999.9
>>>>> 2012   1 15   4.6  354.  71    -8 999.9
>>>>> 2012   1 16   3.7  382.  71    -7 999.9
>>>>> 2012   1 17   3.2  376.  71    -2 999.9
>>>>> 2012   1 18   2.8  368.  71     2 999.9
>>>>> 2012   1 19   3.2  361.  71     2 999.9
>>>>> 2012   1 20   3.2  361.  71    -3 999.9
>>>>> 2012   1 21   3.5  365.  71    -5 999.9
>>>>> 2012   1 22   3.6  364.  71    -3 999.9
>>>>> 2012   1 23   3.0  362.  71    -3 999.9
>>>>> 2012   2  0   3.2  359.  92    -5 130.3
>>>>> 2012   2  1   3.0  361.  92    -4 130.3
>>>>> 2012   2  2   4.5  374.  92     3 130.3
>>>>> 2012   2  3   4.5  364.  92     5 130.3
>>>>> 2012   2  4   5.1  352.  92     3 130.3
>>>>> 2012   2  5   4.9  358.  92     3 130.3
>>>>> 2012   2  6   4.4  346.  92     4 130.3
>>>>> 2012   2  7   4.2  349.  92     7 130.3
>>>>> 2012   2  8   4.5  346.  92     8 130.3
>>>>> 2012   2  9   5.2  345.  92     7 130.3
>>>>> 2012   2 10   5.0  349.  92     5 130.3
>>>>> 2012   2 11   4.8  345.  92     0 130.3
>>>>> 2012   2 12   5.3  347.  92     0 130.3
>>>>> 2012   2 13   5.5  342.  92     0 130.3
>>>>> 2012   2 14   6.1  359.  92     1 130.3
>>>>> 2012   2 15   6.2  393.  92     8 130.3
>>>>> 2012   2 16   6.7  390.  92    10 130.3
>>>>> 2012   2 17   7.7  369.  92    10 130.3
>>>>> 2012   2 18   9.4  380.  92    14 130.3
>>>>> 2012   2 19  10.6  386.  92    12 130.3
>>>>> 2012   2 20  10.2  378.  92    11 130.3
>>>>> 2012   2 21  11.6  369.  92     7 130.3
>>>>> 2012   2 22  12.0  369.  92     8 130.3
>>>>> 2012   2 23  10.5  361.  92     1 130.3
>>>>> 2012   3  0  11.3  403. 120    -7 130.2
>>>>> 2012   3  1  10.3  412. 120   -14 130.2
>>>>> 2012   3  2   8.8  419. 120   -18 130.2
>>>>> 2012   3  3   8.3  412. 120   -23 130.2
>>>>> 2012   3  4   8.0  408. 120   -25 130.2
>>>>> 2012   3  5   7.0  380. 120   -28 130.2
>>>>> 2012   3  6   6.9  374. 120   -29 130.2
>>>>> 2012   3  7   6.9  372. 120   -30 130.2
>>>>> 2012   3  8   7.1  365. 120   -32 130.2
>>>>> 2012   3  9   6.8  376. 120   -35 130.2
>>>>> 2012   3 10   6.7  380. 120   -35 130.2
>>>>> 2012   3 11   6.4  381. 120   -30 130.2
>>>>> 2012   3 12   5.9  401. 120   -26 130.2
>>>>> 2012   3 13   5.9  405. 120   -23 130.2
>>>>> 2012   3 14   5.9  413. 120   -20 130.2
>>>>> 2012   3 15   5.9  406. 120   -20 130.2
>>>>> 2012   3 16   6.3  427. 120   -20 130.2
>>>>> 2012   3 17   5.9  424. 120   -19 130.2
>>>>> 2012   3 18   4.8  390. 120   -16 130.2
>>>>> 2012   3 19   4.8  374. 120   -15 130.2
>>>>> 2012   3 20   4.8  374. 120   -15 130.2
>>>>> 2012   3 21   5.1  378. 120   -18 130.2
>>>>> 2012   3 22   4.9  375. 120   -19 130.2
>>>>> 2012   3 23   4.7  364. 120   -17 130.2
>>>>> 2012   4  0   4.3  359. 126   -17 131.6
>>>>> 2012   4  1   4.3  359. 126   -15 131.6
>>>>> 2012   4  2   4.2  358. 126   -13 131.6
>>>>> 2012   4  3   3.8  359. 126   -13 131.6
>>>>> 2012   4  4   3.8  358. 126   -13 131.6
>>>>> 2012   4  5   3.7  359. 126   -14 131.6
>>>>> 2012   4  6   3.9  361. 126   -13 131.6
>>>>> 2012   4  7   3.7  364. 126   -13 131.6
>>>>> 2012   4  8   3.7  366. 126   -12 131.6
>>>>> 2012   4  9   3.8  363. 126   -10 131.6
>>>>> 2012   4 10   3.5  363. 126    -8 131.6
>>>>> 2012   4 11   3.0  352. 126   -10 131.6
>>>>> 2012   4 12   3.1  348. 126   -12 131.6
>>>>> 2012   4 13   3.3  340. 126    -9 131.6
>>>>> 2012   4 14   4.0  343. 126    -8 131.6
>>>>> 2012   4 15   4.2  343. 126    -7 131.6
>>>>> 2012   4 16   3.8  336. 126    -5 131.6
>>>>> 2012   4 17   3.9  334. 126    -6 131.6
>>>>> 2012   4 18   3.8  329. 126    -5 131.6
>>>>> 2012   4 19   3.8  326. 126    -4 131.6
>>>>> 2012   4 20   4.3  337. 126    -3 131.6
>>>>> 2012   4 21   3.9  331. 126     0 131.6
>>>>> 2012   4 22   3.8  322. 126    -1 131.6
>>>>> 2012   4 23   3.5  331. 126    -1 131.6
>>>>> 2012   5  0   3.9  312. 109    -3 136.6
>>>>> 2012   5  1   3.6  311. 109    -1 136.6
>>>>> 2012   5  2   3.7  312. 109     0 136.6
>>>>> 2012   5  3   3.8  308. 109     0 136.6
>>>>> 2012   5  4   4.0  305. 109     2 136.6
>>>>> 2012   5  5   4.5  309. 109     2 136.6
>>>>> 2012   5  6   3.5  314. 109     3 136.6
>>>>> 2012   5  7   3.6  305. 109     2 136.6
>>>>> 2012   5  8   4.3  307. 109     2 136.6
>>>>> 2012   5  9   4.6  316. 109     1 136.6
>>>>> 2012   5 10   5.0  321. 109    -4 136.6
>>>>> 2012   5 11   5.1  321. 109    -6 136.6
>>>>> 2012   5 12   4.6  326. 109    -4 136.6
>>>>> 2012   5 13   5.7  321. 109    -2 136.6
>>>>> 2012   5 14   5.0  316. 109     1 136.6
>>>>> 2012   5 15   4.6  315. 109     2 136.6
>>>>> 2012   5 16   5.5  321. 109     7 136.6
>>>>> 2012   5 17   7.2  327. 109     7 136.6
>>>>> 2012   5 18   9.2  329. 109     3 136.6
>>>>> 2012   5 19   9.4  341. 109     3 136.6
>>>>> 2012   5 20   9.2  345. 109     8 136.6
>>>>> 2012   5 21   9.8  344. 109     9 136.6
>>>>> 2012   5 22   9.8  341. 109    10 136.6
>>>>> 2012   5 23  10.0  351. 109    15 136.6
>>>>> 2012   6  0  10.4  356. 113    12 131.0
>>>>> 2012   6  1   9.1  360. 113    10 131.0
>>>>> 2012   6  2   6.6  392. 113    10 131.0
>>>>> 2012   6  3   6.9  418. 113     7 131.0
>>>>> 2012   6  4   6.5  408. 113     4 131.0
>>>>> 2012   6  5   6.6  413. 113     7 131.0
>>>>> 2012   6  6   7.3  428. 113     6 131.0
>>>>> 2012   6  7   7.3  416. 113     4 131.0
>>>>> 2012   6  8   7.0  411. 113     1 131.0
>>>>> 2012   6  9   7.2  415. 113     1 131.0
>>>>> 2012   6 10   7.2  426. 113     0 131.0
>>>>> 2012   6 11   6.5  431. 113    -2 131.0
>>>>> 2012   6 12   6.4  431. 113    -2 131.0
>>>>> 2012   6 13   6.6  435. 113     0 131.0
>>>>> 2012   6 14   6.2  425. 113     2 131.0
>>>>> 2012   6 15   5.7  431. 113     4 131.0
>>>>> 2012   6 16   6.1  431. 113     1 131.0
>>>>> 2012   6 17   5.7  425. 113    -3 131.0
>>>>> 2012   6 18   5.8  431. 113    -1 131.0
>>>>> 2012   6 19   6.4  425. 113     2 131.0
>>>>> 2012   6 20   6.0  434. 113     1 131.0
>>>>> 2012   6 21   6.3  420. 113     0 131.0
>>>>> 2012   6 22   6.3  440. 113    -3 131.0
>>>>> 2012   6 23   6.5  456. 113    -3 131.0
>>>>> 2012   7  0   6.3  435. 113    -5 135.9
>>>>> 2012   7  1   5.9  428. 113    -1 135.9
>>>>> 2012   7  2   5.7  434. 113     1 135.9
>>>>> 2012   7  3   5.3  423. 113     0 135.9
>>>>> 2012   7  4   4.3  417. 113     1 135.9
>>>>> 2012   7  5   5.4  420. 113     0 135.9
>>>>> 2012   7  6   5.7  434. 113     1 135.9
>>>>> 2012   7  7   5.5  423. 113     1 135.9
>>>>> 2012   7  8   4.8  419. 113    -2 135.9
>>>>> 2012   7  9   5.8  421. 113    -6 135.9
>>>>> 2012   7 10   5.3  412. 113    -9 135.9
>>>>> 2012   7 11   4.6  424. 113    -7 135.9
>>>>> 2012   7 12   4.0  439. 113    -3 135.9
>>>>> 2012   7 13   4.8  431. 113    -1 135.9
>>>>> 2012   7 14   5.1  431. 113    -1 135.9
>>>>> 2012   7 15   4.8  427. 113    -1 135.9
>>>>> 2012   7 16   4.7  429. 113    -5 135.9
>>>>> 2012   7 17   5.3  436. 113    -6 135.9
>>>>> 2012   7 18   5.1  426. 113    -5 135.9
>>>>> 2012   7 19   5.2  427. 113    -4 135.9
>>>>> 2012   7 20   4.5  416. 113    -5 135.9
>>>>> 2012   7 21   4.9  409. 113    -4 135.9
>>>>> 2012   7 22   5.0  417. 113    -4 135.9
>>>>> 2012   7 23   5.0  426. 113    -4 135.9
>>>>> 2012   8  0   5.0  433. 104    -2 131.4
>>>>> 2012   8  1   4.9  426. 104    -2 131.4
>>>>> 2012   8  2   4.7  421. 104    -4 131.4
>>>>> 2012   8  3   4.4  417. 104    -5 131.4
>>>>> 2012   8  4   4.3  416. 104    -8 131.4
>>>>> 2012   8  5   4.5  416. 104    -8 131.4
>>>>> 2012   8  6   5.0  419. 104    -6 131.4
>>>>> 2012   8  7   5.4  446. 104    -1 131.4
>>>>> 2012   8  8   5.3  439. 104    -2 131.4
>>>>> 2012   8  9   5.3  432. 104    -4 131.4
>>>>> 2012   8 10   5.4  434. 104    -4 131.4
>>>>> 2012   8 11   5.4  435. 104    -3 131.4
>>>>> 2012   8 12   4.5  421. 104    -4 131.4
>>>>> 2012   8 13   4.5  422. 104    -4 131.4
>>>>> 2012   8 14   5.1  425. 104    -2 131.4
>>>>> 2012   8 15   5.3  429. 104     1 131.4
>>>>> 2012   8 16   5.5  433. 104    -2 131.4
>>>>> 2012   8 17   5.9  440. 104    -2 131.4
>>>>> 2012   8 18   6.6  445. 104    -1 131.4
>>>>> 2012   8 19   6.4  442. 104    -4 131.4
>>>>> 2012   8 20   5.9  434. 104    -6 131.4
>>>>> 2012   8 21   5.3  429. 104    -7 131.4
>>>>> 2012   8 22   4.8  438. 104    -2 131.4
>>>>> 2012   8 23   5.3  427. 104     4 131.4
>>>>> 2012   9  0   5.5  433.  79     8 137.6
>>>>> 2012   9  1   5.2  445.  79     9 137.6
>>>>> 2012   9  2   5.4  439.  79    10 137.6
>>>>> 2012   9  3   5.3  430.  79     7 137.6
>>>>> 2012   9  4   5.1  426.  79    -3 137.6
>>>>> 2012   9  5   4.7  415.  79    -6 137.6
>>>>> 2012   9  6   5.0  412.  79    -4 137.6
>>>>> 2012   9  7   5.2  418.  79    -2 137.6
>>>>> 2012   9  8   5.5  441.  79     2 137.6
>>>>> 2012   9  9   5.1  441.  79     2 137.6
>>>>> 2012   9 10   5.4  430.  79    -2 137.6
>>>>> 2012   9 11   5.3  433.  79    -1 137.6
>>>>> 2012   9 12   5.5  438.  79     5 137.6
>>>>> 2012   9 13   5.4  436.  79     6 137.6
>>>>> 2012   9 14   5.7  440.  79     9 137.6
>>>>> 2012   9 15   5.9  430.  79     9 137.6
>>>>> 2012   9 16   5.8  437.  79     4 137.6
>>>>> 2012   9 17   4.9  431.  79    -3 137.6
>>>>> 2012   9 18   5.3  424.  79    -3 137.6
>>>>> 2012   9 19   5.7  437.  79    -2 137.6
>>>>> 2012   9 20   6.1  427.  79    -4 137.6
>>>>> 2012   9 21   6.0  409.  79    -7 137.6
>>>>> 2012   9 22   6.6  410.  79    -4 137.6
>>>>> 2012   9 23   6.4  432.  79    -1 137.6
>>>>> 2012  10  0   5.9  434.  70     2 124.6
>>>>> 2012  10  1   5.6  424.  70     4 124.6
>>>>> 2012  10  2   4.8  435.  70     7 124.6
>>>>> 2012  10  3   4.6  425.  70     4 124.6
>>>>> 2012  10  4   4.3  424.  70     3 124.6
>>>>> 2012  10  5   5.4  426.  70     2 124.6
>>>>> 2012  10  6   5.5  434.  70     2 124.6
>>>>> 2012  10  7   6.4  435.  70     4 124.6
>>>>> 2012  10  8   6.3  436.  70     1 124.6
>>>>> 2012  10  9   5.2  431.  70    -6 124.6
>>>>> 2012  10 10   4.5  426.  70   -10 124.6
>>>>> 2012  10 11   4.6  435.  70    -9 124.6
>>>>> 2012  10 12   3.4  425.  70    -5 124.6
>>>>> 2012  10 13   4.2  427.  70    -4 124.6
>>>>> 2012  10 14   4.0  432.  70     2 124.6
>>>>> 2012  10 15   5.5  450.  70     7 124.6
>>>>> 2012  10 16   5.9  451.  70     2 124.6
>>>>> 2012  10 17   5.5  445.  70    -3 124.6
>>>>> 2012  10 18   5.8  442.  70    -2 124.6
>>>>> 2012  10 19   5.4  430.  70    -1 124.6
>>>>> 2012  10 20   4.9  427.  70    -1 124.6
>>>>> 2012  10 21   4.0  436.  70     0 124.6
>>>>> 2012  10 22   3.4  445.  70    -1 124.6
>>>>> 2012  10 23   4.5  453.  70     0 124.6
>>>>> 2012  11  0   5.3  438.  63     1 116.1
>>>>> 2012  11  1   5.0  438.  63     3 116.1
>>>>> 2012  11  2   5.3  445.  63     3 116.1
>>>>> 2012  11  3   4.5  451.  63     2 116.1
>>>>> 2012  11  4   5.0  456.  63    -1 116.1
>>>>> 2012  11  5   4.6  459.  63     0 116.1
>>>>> 2012  11  6   5.1  459.  63     1 116.1
>>>>> 2012  11  7   4.0  466.  63     3 116.1
>>>>> 2012  11  8   5.0  478.  63    -1 116.1
>>>>> 2012  11  9   4.6  489.  63    -2 116.1
>>>>> 2012  11 10   4.5  493.  63    -4 116.1
>>>>> 2012  11 11   4.5  494.  63    -1 116.1
>>>>> 2012  11 12   3.6  504.  63     3 116.1
>>>>> 2012  11 13   3.5  496.  63     5 116.1
>>>>> 2012  11 14   3.3  497.  63     7 116.1
>>>>> 2012  11 15   3.0  498.  63     7 116.1
>>>>> 2012  11 16   2.1  503.  63     3 116.1
>>>>> 2012  11 17   2.0  495.  63     0 116.1
>>>>> 2012  11 18   2.5  492.  63    -2 116.1
>>>>> 2012  11 19   2.2  496.  63    -1 116.1
>>>>> 2012  11 20   2.4  489.  63     1 116.1
>>>>> 2012  11 21   2.6  489.  63     3 116.1
>>>>> 2012  11 22   2.6  483.  63     2 116.1
>>>>> 2012  11 23   2.6  478.  63     2 116.1
>>>>> 2012  12  0   2.9  453.  52     3 113.0
>>>>> 2012  12  1   2.2  446.  52     4 113.0
>>>>> 2012  12  2   2.4  442.  52     8 113.0
>>>>> 2012  12  3   2.6  440.  52    10 113.0
>>>>> 2012  12  4   2.2  438.  52    11 113.0
>>>>> 2012  12  5   2.8  438.  52     9 113.0
>>>>> 2012  12  6   2.0  437.  52     8 113.0
>>>>> 2012  12  7   2.4  426.  52     7 113.0
>>>>> 2012  12  8   3.0  423.  52     5 113.0
>>>>> 2012  12  9   3.3  420.  52     4 113.0
>>>>> 2012  12 10   4.0  419.  52     2 113.0
>>>>> 2012  12 11   3.8  412.  52     5 113.0
>>>>> 2012  12 12   4.2  409.  52     4 113.0
>>>>> 2012  12 13   3.5  408.  52     2 113.0
>>>>> 2012  12 14   3.7  404.  52     9 113.0
>>>>> 2012  12 15   4.5  402.  52    15 113.0
>>>>> 2012  12 16   3.6  395.  52    14 113.0
>>>>> 2012  12 17   2.4  392.  52    16 113.0
>>>>> 2012  12 18   5.8  403.  52    27 113.0
>>>>> 2012  12 19   7.6  400.  52    27 113.0
>>>>> 2012  12 20   6.9  418.  52    17 113.0
>>>>> 2012  12 21   6.9  463.  52    10 113.0
>>>>> 2012  12 22   7.3  469.  52     9 113.0
>>>>> 2012  12 23   5.5  482.  52    12 113.0
>>>>> 2012  13  0   7.7  500.  71    10 120.0
>>>>> 2012  13  1   8.7  492.  71    14 120.0
>>>>> 2012  13  2   7.8  513.  71    16 120.0
>>>>> 2012  13  3   7.5  530.  71    11 120.0
>>>>> 2012  13  4   7.1  518.  71     8 120.0
>>>>> 2012  13  5   7.0  524.  71     6 120.0
>>>>> 2012  13  6   5.9  536.  71     8 120.0
>>>>> 2012  13  7   3.6  529.  71     5 120.0
>>>>> 2012  13  8   4.1  510.  71     4 120.0
>>>>> 2012  13  9   3.9  497.  71     3 120.0
>>>>> 2012  13 10   2.4  492.  71     3 120.0
>>>>> 2012  13 11   2.6  485.  71     5 120.0
>>>>> 2012  13 12   2.9  492.  71     5 120.0
>>>>> 2012  13 13   2.6  487.  71     3 120.0
>>>>> 2012  13 14   2.3  478.  71     6 120.0
>>>>> 2012  13 15   3.2  467.  71    11 120.0
>>>>> 2012  13 16   3.4  453.  71    10 120.0
>>>>> 2012  13 17   3.2  452.  71     6 120.0
>>>>> 2012  13 18   3.0  452.  71     2 120.0
>>>>> 2012  13 19   2.8  447.  71     1 120.0
>>>>> 2012  13 20   2.5  439.  71     0 120.0
>>>>> 2012  13 21   2.5  443.  71    -2 120.0
>>>>> 2012  13 22   2.7  442.  71    -3 120.0
>>>>> 2012  13 23   3.0  447.  71    -4 120.0
>>>>> 2012  14  0   3.5  445. 118    -3 128.0
>>>>> 2012  14  1   3.3  440. 118    -1 128.0
>>>>> 2012  14  2   3.1  440. 118     1 128.0
>>>>> 2012  14  3   2.7  446. 118     0 128.0
>>>>> 2012  14  4   2.9  442. 118    -1 128.0
>>>>> 2012  14  5   2.9  437. 118    -2 128.0
>>>>> 2012  14  6   3.3  431. 118    -3 128.0
>>>>> 2012  14  7   2.8  420. 118    -2 128.0
>>>>> 2012  14  8   2.3  409. 118    -2 128.0
>>>>> 2012  14  9   2.2  407. 118     1 128.0
>>>>> 2012  14 10   2.6  405. 118     3 128.0
>>>>> 2012  14 11   2.8  401. 118     4 128.0
>>>>> 2012  14 12   3.2  398. 118     4 128.0
>>>>> 2012  14 13   2.7  400. 118     4 128.0
>>>>> 2012  14 14   1.9  399. 118     5 128.0
>>>>> 2012  14 15   2.4  395. 118     3 128.0
>>>>> 2012  14 16   2.7  389. 118     2 128.0
>>>>> 2012  14 17   2.9  385. 118     0 128.0
>>>>> 2012  14 18   3.2  384. 118     1 128.0
>>>>> 2012  14 19   2.6  380. 118     2 128.0
>>>>> 2012  14 20   2.3  378. 118     1 128.0
>>>>> 2012  14 21   2.1  374. 118     0 128.0
>>>>> 2012  14 22   3.1  367. 118     0 128.0
>>>>> 2012  14 23   4.0  366. 118    -1 128.0
>>>>> 2012  15  0   4.8  363. 149     0 129.2
>>>>> 2012  15  1   4.0  359. 149     2 129.2
>>>>> 2012  15  2   3.4  354. 149     2 129.2
>>>>> 2012  15  3   3.0  349. 149     5 129.2
>>>>> 2012  15  4   2.7  344. 149     7 129.2
>>>>> 2012  15  5   2.4  349. 149    11 129.2
>>>>> 2012  15  6   2.9  343. 149    12 129.2
>>>>> 2012  15  7   3.5  333. 149     7 129.2
>>>>> 2012  15  8   3.6  341. 149     4 129.2
>>>>> 2012  15  9   3.7  345. 149     1 129.2
>>>>> 2012  15 10   3.6  343. 149     2 129.2
>>>>> 2012  15 11   3.6  342. 149     3 129.2
>>>>> 2012  15 12   3.7  340. 149     7 129.2
>>>>> 2012  15 13   3.7  342. 149     8 129.2
>>>>> 2012  15 14   4.1  344. 149     9 129.2
>>>>> 2012  15 15   3.9  345. 149     4 129.2
>>>>> 2012  15 16   4.4  355. 149     8 129.2
>>>>> 2012  15 17   4.7  360. 149    11 129.2
>>>>> 2012  15 18   5.4  359. 149    12 129.2
>>>>> 2012  15 19   6.8  353. 149     8 129.2
>>>>> 2012  15 20   6.6  349. 149     6 129.2
>>>>> 2012  15 21   5.9  364. 149     2 129.2
>>>>> 2012  15 22   5.2  394. 149     1 129.2
>>>>> 2012  15 23   6.3  395. 149     5 129.2
>>>>> 2012  16  0   6.3  385. 154     6 135.1
>>>>> 2012  16  1   6.6  397. 154     2 135.1
>>>>> 2012  16  2   6.7  400. 154     4 135.1
>>>>> 2012  16  3   6.9  396. 154     5 135.1
>>>>> 2012  16  4   7.9  392. 154     5 135.1
>>>>> 2012  16  5   4.6  379. 154    10 135.1
>>>>> 2012  16  6   8.0  365. 154    13 135.1
>>>>> 2012  16  7   6.3  358. 154    16 135.1
>>>>> 2012  16  8   7.9  380. 154    12 135.1
>>>>> 2012  16  9  10.2  391. 154    10 135.1
>>>>> 2012  16 10   8.1  394. 154     8 135.1
>>>>> 2012  16 11  12.1  412. 154    -8 135.1
>>>>> 2012  16 12  13.2  424. 154   -10 135.1
>>>>> 2012  16 13  12.9  433. 154    -8 135.1
>>>>> 2012  16 14   9.3  461. 154    -7 135.1
>>>>> 2012  16 15   6.6  466. 154   -14 135.1
>>>>> 2012  16 16   6.6  493. 154   -11 135.1
>>>>> 2012  16 17   7.4  496. 154    -7 135.1
>>>>> 2012  16 18   6.2  493. 154    -7 135.1
>>>>> 2012  16 19   6.9  492. 154   -13 135.1
>>>>> 2012  16 20   6.8  486. 154   -19 135.1
>>>>> 2012  16 21   5.6  488. 154   -14 135.1
>>>>> 2012  16 22   6.4  464. 154   -11 135.1
>>>>> 2012  16 23   6.0  459. 154   -10 135.1
>>>>> 2012  17  0   4.9  476. 141   -14 134.5
>>>>> 2012  17  1   4.6  460. 141   -20 134.5
>>>>> 2012  17  2   4.1  467. 141   -17 134.5
>>>>> 2012  17  3   3.7  469. 141   -13 134.5
>>>>> 2012  17  4   3.3  472. 141   -12 134.5
>>>>> 2012  17  5   2.7  472. 141    -8 134.5
>>>>> 2012  17  6   3.5  459. 141    -6 134.5
>>>>> 2012  17  7   3.9  459. 141    -6 134.5
>>>>> 2012  17  8   4.1  463. 141    -7 134.5
>>>>> 2012  17  9   4.1  443. 141   -10 134.5
>>>>> 2012  17 10   4.1  446. 141   -14 134.5
>>>>> 2012  17 11   4.1  442. 141   -13 134.5
>>>>> 2012  17 12   3.6  436. 141   -10 134.5
>>>>> 2012  17 13   3.6  433. 141    -6 134.5
>>>>> 2012  17 14   4.2  421. 141    -1 134.5
>>>>> 2012  17 15   3.7  416. 141    -2 134.5
>>>>> 2012  17 16   4.2  410. 141    -1 134.5
>>>>> 2012  17 17   4.6  396. 141    -1 134.5
>>>>> 2012  17 18   4.5  398. 141    -2 134.5
>>>>> 2012  17 19   4.4  397. 141    -6 134.5
>>>>> 2012  17 20   4.5  396. 141    -8 134.5
>>>>> 2012  17 21   3.5  411. 141    -5 134.5
>>>>> 2012  17 22   3.9  425. 141    -5 134.5
>>>>> 2012  17 23   4.7  418. 141    -6 134.5
>>>>> 2012  18  0   4.6  400. 126    -7 143.4
>>>>> 2012  18  1   4.5  413. 126    -3 143.4
>>>>> 2012  18  2   4.4  418. 126     2 143.4
>>>>> 2012  18  3   4.2  420. 126     2 143.4
>>>>> 2012  18  4   4.0  401. 126    -2 143.4
>>>>> 2012  18  5   3.8  399. 126    -1 143.4
>>>>> 2012  18  6   3.5  388. 126    -1 143.4
>>>>> 2012  18  7   4.4  393. 126    -2 143.4
>>>>> 2012  18  8   4.7  405. 126    -3 143.4
>>>>> 2012  18  9   4.8  409. 126    -4 143.4
>>>>> 2012  18 10   4.9  409. 126    -3 143.4
>>>>> 2012  18 11   5.0  411. 126    -5 143.4
>>>>> 2012  18 12   5.1  405. 126    -5 143.4
>>>>> 2012  18 13   5.2  403. 126    -6 143.4
>>>>> 2012  18 14   5.1  394. 126    -4 143.4
>>>>> 2012  18 15   5.0  391. 126    -5 143.4
>>>>> 2012  18 16   4.6  387. 126    -4 143.4
>>>>> 2012  18 17   4.7  376. 126    -2 143.4
>>>>> 2012  18 18   4.7  381. 126    -1 143.4
>>>>> 2012  18 19   4.5  382. 126    -2 143.4
>>>>> 2012  18 20   4.9  386. 126    -5 143.4
>>>>> 2012  18 21   4.8  375. 126    -5 143.4
>>>>> 2012  18 22   4.7  385. 126    -6 143.4
>>>>> 2012  18 23   4.7  381. 126    -5 143.4
>>>>> 2012  19  0   4.3  372. 105    -3 152.0
>>>>> 2012  19  1   4.2  361. 105    -4 152.0
>>>>> 2012  19  2   4.0  360. 105    -5 152.0
>>>>> 2012  19  3   3.9  362. 105    -4 152.0
>>>>> *Jibrin Adejoh Alhassan (Ph.D)*
>>>>> Department of Physics and Astronomy,
>>>>> University of Nigeria, Nsukka
>>>>>
>>>>>
>>>>> On Mon, Jun 17, 2024 at 7:50?AM Jibrin Alhassan <
>>>> jibrin.alhassan at unn.edu.ng>
>>>>> wrote:
>>>>>
>>>>>> Hello Rui,
>>>>>> Your patience is indeed amazing. Your script tested as shown below
>>>> worked
>>>>>> perfectly well.
>>>>>> df1 <- read.table(text = "YEAR DOY HR   IMF  SW   SSN    Dst f10.7
>>>>>> 2012 215  4   5.1  371. 143    -4 138.6 ", header = TRUE)
>>>>>> with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
>>>>>> df1$Date <- with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
>>>>>> df1 <- df1[-(1:2)]
>>>>>> df1 <- df1[c(ncol(df1), 1:(ncol(df1) - 1L))]
>>>>>> head(df1).
>>>>>> But  I have 43,849 data points. Your script only generated one. Help
>> me
>>>>>> with a script that can handle the whole data points. I have tried
>>>> following
>>>>>> your tested solution but was unsuccessful. My regards.
>>>>>> *Jibrin Adejoh Alhassan (Ph.D)*
>>>>>> Department of Physics and Astronomy,
>>>>>> University of Nigeria, Nsukka
>>>>>>
>>>>>>
>>>>>> On Sun, Jun 16, 2024 at 8:33?AM Rui Barradas <ruipbarradas at sapo.pt>
>>>> wrote:
>>>>>>
>>>>>>> ?s 21:42 de 15/06/2024, Jibrin Alhassan escreveu:
>>>>>>>> Thank you Rui. I ran the following script
>>>>>>>> df1 <- read.table("solar_hour", header = TRUE)
>>>>>>>> df1$date <- as.Date(paste(df1$year, df1$hour),
>>>>>>>>      format = "%Y %j",
>>>>>>>> origin = "2012-08-01-0")
>>>>>>>> df2 <- df1[c("date", "IMF", "SWS", "SSN", "Dst", "f10")]
>>>>>>>> head(df1)
>>>>>>>> #To display all the rows
>>>>>>>>      print(df2).
>>>>>>>> It gave me this error message
>>>>>>>>> source ("script.R")
>>>>>>>> Error in `$<-.data.frame`(`*tmp*`, date, value = numeric(0)) :
>>>>>>>>       replacement has 0 rows, data has 38735
>>>>>>>>> print(df2)
>>>>>>>> Error: object 'df2' not found
>>>>>>>>> My data is an hourly data but desire to have the date as
>>>>>>>> year    month    day   hour
>>>>>>>> 2012   08         01     01
>>>>>>>> 2012   08         01     02
>>>>>>>> 2012   08        01      03 etc
>>>>>>>> Thanks.
>>>>>>>>
>>>>>>>> *Jibrin Adejoh Alhassan (Ph.D)*
>>>>>>>> Department of Physics and Astronomy,
>>>>>>>> University of Nigeria, Nsukka
>>>>>>>>
>>>>>>>>
>>>>>>>> On Sat, Jun 15, 2024 at 8:34?PM Rui Barradas <ruipbarradas at sapo.pt>
>>>>>>> wrote:
>>>>>>>>
>>>>>>>>> ?s 20:00 de 15/06/2024, Jibrin Alhassan escreveu:
>>>>>>>>>> I have solar-geophysical data e.g as blow:
>>>>>>>>>> YEAR DOY HR   IMF  SW   SSN    Dst f10.7
>>>>>>>>>> 2012 214  0   3.4  403. 132    -9 154.6
>>>>>>>>>> 2012 214  1   3.7  388. 132   -10 154.6
>>>>>>>>>> 2012 214  2   3.7  383. 132   -10 154.6
>>>>>>>>>> 2012 214  3   3.7  391. 132    -9 154.6
>>>>>>>>>> 2012 214  4   4.2  399. 132    -7 154.6
>>>>>>>>>> 2012 214  5   4.1  411. 132    -6 154.6
>>>>>>>>>> 2012 214  6   4.0  407. 132    -6 154.6
>>>>>>>>>> 2012 214  7   4.2  404. 132    -4 154.6
>>>>>>>>>> 2012 214  8   4.3  405. 132    -6 154.6
>>>>>>>>>> 2012 214  9   4.4  409. 132    -6 154.6
>>>>>>>>>> 2012 214 10   4.4  401. 132    -6 154.6
>>>>>>>>>> 2012 214 11   4.5  385. 132    -7 154.6
>>>>>>>>>> 2012 214 12   4.7  377. 132    -8 154.6
>>>>>>>>>> 2012 214 13   4.7  382. 132    -6 154.6
>>>>>>>>>> 2012 214 14   4.3  396. 132    -4 154.6
>>>>>>>>>> 2012 214 15   4.1  384. 132    -2 154.6
>>>>>>>>>> 2012 214 16   4.0  382. 132    -1 154.6
>>>>>>>>>> 2012 214 17   3.9  397. 132     0 154.6
>>>>>>>>>> 2012 214 18   3.8  390. 132     1 154.6
>>>>>>>>>> 2012 214 19   4.2  400. 132     2 154.6
>>>>>>>>>> 2012 214 20   4.6  408. 132     1 154.6
>>>>>>>>>> 2012 214 21   4.8  401. 132    -3 154.6
>>>>>>>>>> 2012 214 22   4.9  395. 132    -5 154.6
>>>>>>>>>> 2012 214 23   5.0  386. 132    -1 154.6
>>>>>>>>>> 2012 215  0   5.0  377. 143    -1 138.6
>>>>>>>>>> 2012 215  1   4.9  384. 143    -2 138.6
>>>>>>>>>> 2012 215  2   4.9  390. 143    -4 138.6
>>>>>>>>>> 2012 215  3   4.9  372. 143    -6 138.6
>>>>>>>>>> 2012 215  4   5.1  371. 143    -4 138.6
>>>>>>>>>> I want to process it to be of the format as shown below
>>>>>>>>>>       y   m  d  hr imf  sws  ssn    Dst f10.7
>>>>>>>>>> 2012-08-01 10 3.4  403. 132    -9 154.6
>>>>>>>>>> 2012-08-01 12 3.7  388. 132   -10 154.6
>>>>>>>>>> 2012-08-01 15 3.7  383. 132   -10 154.6
>>>>>>>>>> 2012-08-01 17 3.7  391. 132    -9 154.6
>>>>>>>>>> I want to request an R code to accomplish this task. Thanks for
>> your
>>>>>>>>> time.
>>>>>>>>>> *Jibrin Adejoh Alhassan (Ph.D)*
>>>>>>>>>> Department of Physics and Astronomy,
>>>>>>>>>> University of Nigeria, Nsukka
>>>>>>>>>>
>>>>>>>>>>           [[alternative HTML version deleted]]
>>>>>>>>>>
>>>>>>>>>> ______________________________________________
>>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>>> PLEASE do read the posting guide
>>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>>> Hello,
>>>>>>>>>
>>>>>>>>> To create a date column, paste the first two columns and coerce to
>>>>>>> class
>>>>>>>>> "Date" with conversion specifications %Y for the 4 digit year and
>> %j
>>>>>>> for
>>>>>>>>> the day of year. See
>>>>>>>>>
>>>>>>>>> help("strptime")
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> df1 <- read.table(text = "YEAR DOY HR   IMF  SW   SSN    Dst f10.7
>>>>>>>>> 2012 214  0   3.4  403. 132    -9 154.6
>>>>>>>>> 2012 214  1   3.7  388. 132   -10 154.6
>>>>>>>>> 2012 214  2   3.7  383. 132   -10 154.6
>>>>>>>>> 2012 214  3   3.7  391. 132    -9 154.6
>>>>>>>>> 2012 214  4   4.2  399. 132    -7 154.6
>>>>>>>>> 2012 214  5   4.1  411. 132    -6 154.6
>>>>>>>>> 2012 214  6   4.0  407. 132    -6 154.6
>>>>>>>>> 2012 214  7   4.2  404. 132    -4 154.6
>>>>>>>>> 2012 214  8   4.3  405. 132    -6 154.6
>>>>>>>>> 2012 214  9   4.4  409. 132    -6 154.6
>>>>>>>>> 2012 214 10   4.4  401. 132    -6 154.6
>>>>>>>>> 2012 214 11   4.5  385. 132    -7 154.6
>>>>>>>>> 2012 214 12   4.7  377. 132    -8 154.6
>>>>>>>>> 2012 214 13   4.7  382. 132    -6 154.6
>>>>>>>>> 2012 214 14   4.3  396. 132    -4 154.6
>>>>>>>>> 2012 214 15   4.1  384. 132    -2 154.6
>>>>>>>>> 2012 214 16   4.0  382. 132    -1 154.6
>>>>>>>>> 2012 214 17   3.9  397. 132     0 154.6
>>>>>>>>> 2012 214 18   3.8  390. 132     1 154.6
>>>>>>>>> 2012 214 19   4.2  400. 132     2 154.6
>>>>>>>>> 2012 214 20   4.6  408. 132     1 154.6
>>>>>>>>> 2012 214 21   4.8  401. 132    -3 154.6
>>>>>>>>> 2012 214 22   4.9  395. 132    -5 154.6
>>>>>>>>> 2012 214 23   5.0  386. 132    -1 154.6
>>>>>>>>> 2012 215  0   5.0  377. 143    -1 138.6
>>>>>>>>> 2012 215  1   4.9  384. 143    -2 138.6
>>>>>>>>> 2012 215  2   4.9  390. 143    -4 138.6
>>>>>>>>> 2012 215  3   4.9  372. 143    -6 138.6
>>>>>>>>> 2012 215  4   5.1  371. 143    -4 138.6", header = TRUE)
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
>>>>>>>>> #>  [1] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>>>>>>> "2012-08-01"
>>>>>>>>> #>  [6] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>>>>>>> "2012-08-01"
>>>>>>>>> #> [11] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>>>>>>> "2012-08-01"
>>>>>>>>> #> [16] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>>>>>>> "2012-08-01"
>>>>>>>>> #> [21] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>>>>>>> "2012-08-02"
>>>>>>>>> #> [26] "2012-08-02" "2012-08-02" "2012-08-02" "2012-08-02"
>>>>>>>>>
>>>>>>>>> # now create the column
>>>>>>>>> df1$Date <- with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y
>> %j")
>>>>>>>>> # remove the columns no longer needed
>>>>>>>>> df1 <- df1[-(1:2)]
>>>>>>>>> # relocate the new date column
>>>>>>>>> df1 <- df1[c(ncol(df1), 1:(ncol(df1) - 1L))]
>>>>>>>>> head(df1)
>>>>>>>>> #>         Date HR IMF  SW SSN Dst f10.7
>>>>>>>>> #> 1 2012-08-01  0 3.4 403 132  -9 154.6
>>>>>>>>> #> 2 2012-08-01  1 3.7 388 132 -10 154.6
>>>>>>>>> #> 3 2012-08-01  2 3.7 383 132 -10 154.6
>>>>>>>>> #> 4 2012-08-01  3 3.7 391 132  -9 154.6
>>>>>>>>> #> 5 2012-08-01  4 4.2 399 132  -7 154.6
>>>>>>>>> #> 6 2012-08-01  5 4.1 411 132  -6 154.6
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> Hope this helps,
>>>>>>>>>
>>>>>>>>> Rui Barradas
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> --
>>>>>>>>> Este e-mail foi analisado pelo software antiv?rus AVG para
>> verificar
>>>> a
>>>>>>>>> presen?a de v?rus.
>>>>>>>>> www.avg.com
>>>>>>>>>
>>>>>>>>
>>>>>>> Hello,
>>>>>>>
>>>>>>> There is an error in your new code:
>>>>>>>
>>>>>>>
>>>>>>> paste YEAR with DOY, not with HR.
>>>>>>>
>>>>>>>
>>>>>>> As for the rest, is your real data like the one you posted before?
>>>>>>> If it is then I don't see anything wrong with my (tested) solution.
>>>>>>>
>>>>>>>
>>>>>>> Hope this helps,
>>>>>>>
>>>>>>> Rui Barradas
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> --
>>>>>>> Este e-mail foi analisado pelo software antiv?rus AVG para verificar
>> a
>>>>>>> presen?a de v?rus.
>>>>>>> www.avg.com
>>>>>>>
>>>>>>
>>>>>
>>>> Hello,
>>>>
>>>> I cannot reproduce any error. T is vectorized so I am not understanding
>>>> what you mean by the script only generated one data point.
>>>> Here is the same code ran on your new data set, the result is as
>> expected.
>>>> Note the output of str(). It days that the 1st column is of class "Date"
>>>> so it was created from YEAR and DOY and relocated to the 1st position.
>>>>
>>>> Can you post the output of your final df1? Please post
>>>>
>>>> head(df1)
>>>>
>>>>
>>>>
>>>> # new data
>>>> df1 <- read.table("~/rhelp.txt", header = TRUE)
>>>>
>>>> df1$Date <- with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
>>>> df1 <- df1[-(1:2)]
>>>> df1 <- df1[c(ncol(df1), 1:(ncol(df1) - 1L))]
>>>> str(df1)
>>>> #> 'data.frame':    436 obs. of  7 variables:
>>>> #>  $ Date : Date, format: "2012-01-01" "2012-01-01" ...
>>>> #>  $ HR   : int  0 1 2 3 4 5 6 7 8 9 ...
>>>> #>  $ IMF  : num  4 4.4 4.8 5.4 4.5 4.2 4.7 4.1 3.2 4.3 ...
>>>> #>  $ SWS  : num  379 386 380 374 369 368 367 361 362 367 ...
>>>> #>  $ SSN  : int  71 71 71 71 71 71 71 71 71 71 ...
>>>> #>  $ Dst  : int  -8 -3 -4 -5 -9 -7 -6 -10 -7 -3 ...
>>>> #>  $ f10.7: num  1000 1000 1000 1000 1000 ...
>>>> head(df1)
>>>> #>         Date HR IMF SWS SSN Dst f10.7
>>>> #> 1 2012-01-01  0 4.0 379  71  -8 999.9
>>>> #> 2 2012-01-01  1 4.4 386  71  -3 999.9
>>>> #> 3 2012-01-01  2 4.8 380  71  -4 999.9
>>>> #> 4 2012-01-01  3 5.4 374  71  -5 999.9
>>>> #> 5 2012-01-01  4 4.5 369  71  -9 999.9
>>>> #> 6 2012-01-01  5 4.2 368  71  -7 999.9
>>>>
>>>>
>>>> Hope this helps,
>>>>
>>>> Rui Barradas
>>>>
>>>>
>>>> --
>>>> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
>>>> presen?a de v?rus.
>>>> www.avg.com
>>>>
>>>
>> Hello,
>>
>> So what's the error? Your output is identical to mine. If the output of
>> str(df1) is also identical to what I have posted, then everything works
>> as expected.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>> --
>> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
>> presen?a de v?rus.
>> www.avg.com
>>
> 
Hello,

"2012-06-27" is YEAR == 2012 and DOY == 179.
If that's what you have in the file then there's nothing wrong with that 
output.

And in your last post the df starts in row 4288, is this the problem? 
The code works, so there must be something with the data.

Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From dut@ngc @end|ng |rom gm@||@com  Mon Jun 17 22:25:38 2024
From: dut@ngc @end|ng |rom gm@||@com (Christophe Dutang)
Date: Mon, 17 Jun 2024 22:25:38 +0200
Subject: [R] Column names of model.matrix's output with contrast.arg
In-Reply-To: <054F7F8A-5406-4A16-A434-43C13C109492@gmail.com>
References: <2F05BA60-78A6-4FE0-B8CD-14105A2F9BF8@gmail.com>
 <054F7F8A-5406-4A16-A434-43C13C109492@gmail.com>
Message-ID: <BF9A5B2B-EE32-409D-BDCD-8CFB85C41054@gmail.com>

Thanks for your reply.

It might good to document the naming convention in ?contrasts. It is hard to understand .L for linear, .Q for quadratic, .C for cubic and ^n for other degrees.

For contr.sum, we could have used .Sum<level1>, .Sum<level2>?

Maybe the examples ?model.matrix should use names in dd objects so that we observe when names are dropped.

Kind regards, Christophe


> Le 14 juin 2024 ? 11:45, peter dalgaard <pdalgd at gmail.com> a ?crit :
> 
> You're at the mercy of the various contr.XXX functions. They may or may not set the colnames on the matrices that they generate. 
> 
> The rationales for (not) setting them is not perfectly transparent, but you obviously cannot use level names on contr.poly, so it uses .L, .Q, etc. 
> 
> In MASS, contr.sdif is careful about labeling the columns with the levels that are being diff'ed. 
> 
> For contr.treatment, there is a straightforward connection to 0/1 dummy variables, so level names there are natural.
> 
> One could use levels in contr.sum and contr.helmert, but it might confuse users that comparisons are with the average of all levels or preceding levels. (It can be quite confusing when coding is +1 for male and -1 for female, so that the gender difference is twice the coefficient.)
> 
> -pd
> 
>> On 14 Jun 2024, at 08:12 , Christophe Dutang <dutangc at gmail.com> wrote:
>> 
>> Dear list,
>> 
>> Changing the default contrasts used in glm() makes me aware how model.matrix() set column names.
>> 
>> With default contrasts, model.matrix() use the level values to name the columns. However with other contrasts, model.matrix() use the level indexes. In the documentation, I don?t see anything in the documentation related to this ? It does not seem natural to have such a behavior?
>> 
>> Any comment is welcome.
>> 
>> An example is below.
>> 
>> Kind regards, Christophe  
>> 
>> 
>> #example from ?glm
>> counts <- c(18,17,15,20,10,20,25,13,12)
>> outcome <- paste0("O", gl(3,1,9))
>> treatment <- paste0("T", gl(3,3))
>> 
>> X3 <- model.matrix(counts ~ outcome + treatment)
>> X4 <- model.matrix(counts ~ outcome + treatment, contrasts = list("outcome"="contr.sum"))
>> X5 <- model.matrix(counts ~ outcome + treatment, contrasts = list("outcome"="contr.helmert"))
>> 
>> #check with original factor
>> cbind.data.frame(X3, outcome)
>> cbind.data.frame(X4, outcome)
>> cbind.data.frame(X5, outcome)
>> 
>> #same issue with glm
>> glm.D93 <- glm(counts ~ outcome + treatment, family = poisson())
>> glm.D94 <- glm(counts ~ outcome + treatment, family = poisson(), contrasts = list("outcome"="contr.sum"))
>> glm.D95 <- glm(counts ~ outcome + treatment, family = poisson(), contrasts = list("outcome"="contr.helmert"))
>> 
>> coef(glm.D93)
>> coef(glm.D94)
>> coef(glm.D95)
>> 
>> #check linear predictor
>> cbind(X3 %*% coef(glm.D93), predict(glm.D93))
>> cbind(X4 %*% coef(glm.D94), predict(glm.D94))
>> 
>> -------------------------------------------------
>> Christophe DUTANG
>> LJK, Ensimag, Grenoble INP, UGA, France
>> ILB research fellow
>> Web: http://dutangc.free.fr
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 


From j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng  Mon Jun 17 22:26:04 2024
From: j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng (Jibrin Alhassan)
Date: Mon, 17 Jun 2024 21:26:04 +0100
Subject: [R] code for year month day hr format
In-Reply-To: <77401bf4-4982-42dd-9f65-06fdd1ae1022@sapo.pt>
References: <CAEGeL+EDsd2LnZ0v5cY-0S7ofE_qxKi-QGV2+WnSzODywRZ9MQ@mail.gmail.com>
 <474f21f7-7a41-403f-826f-853f6589ec52@sapo.pt>
 <CAEGeL+H_eukBiQKyDb1GOGo5K2kcyM7S6n167ukBWoGrQUgLyg@mail.gmail.com>
 <9347708a-d116-4879-8809-e2b5abadff25@sapo.pt>
 <CAEGeL+Hv5vXMo8yqeTTXpjXMVicSpEzk9W0pM0jd0gWRMiVsqQ@mail.gmail.com>
 <CAEGeL+FS6hN7OJqh=6NveMTMVA8Ct_mpRdGdqdezVBoXiTRe6g@mail.gmail.com>
 <053e2864-deb4-42bb-a505-555c8f9c7360@sapo.pt>
 <CAEGeL+HEUOq=VxCF0q_sD2qoDht00OvNhSNnBTXcr9dcSqxWyQ@mail.gmail.com>
 <36b96f57-b034-43df-81d3-33e5c9a0c389@sapo.pt>
 <CAEGeL+FNxaFVkh=SwNhUEaEeGAEXWDv8DwmjEeGp0SRC-9Sw4w@mail.gmail.com>
 <77401bf4-4982-42dd-9f65-06fdd1ae1022@sapo.pt>
Message-ID: <CAEGeL+GWp-kCiT8vwJgYD33b5ONU==iDYSybQi56Km_qkLAyWQ@mail.gmail.com>

Hello Rui,
Thanks for your kind and unrelenting help. The code works actually. I will
see what to do to sort things out. Please, accept my indebtedness.
*Jibrin Adejoh Alhassan (Ph.D)*
Department of Physics and Astronomy,
University of Nigeria, Nsukka


On Mon, Jun 17, 2024 at 8:53?PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> ?s 09:44 de 17/06/2024, Jibrin Alhassan escreveu:
> > Hello Rui,
> > The df1 output printed from June instead of January .Here is part of it.
> > 4288  2012-06-27 15  6.2  420  70   -7 109.9
> > 4289  2012-06-27 16  6.5  442  70   -9 109.9
> > 4290  2012-06-27 17  6.3  450  70   -6 109.9
> > 4291  2012-06-27 18  6.0  453  70    0 109.9
> > 4292  2012-06-27 19  6.7  473  70    2 109.9
> > 4293  2012-06-27 20  5.7  460  70    2 109.9
> > 4294  2012-06-27 21  5.4  469  70    0 109.9
> > 4295  2012-06-27 22  4.5  485  70   -2 109.9
> > 4296  2012-06-27 23  4.9  497  70    1 109.9
> > 4297  2012-06-28  0  4.6  500  87    3 123.7
> > 4298  2012-06-28  1  4.7  503  87    2 123.7
> > 4299  2012-06-28  2  4.3  488  87    1 123.7
> > 4300  2012-06-28  3  4.9  479  87    0 123.7
> > 4301  2012-06-28  4  5.1  459  87    0 123.7
> > 4302  2012-06-28  5  4.9  458  87    0 123.7
> > 4303  2012-06-28  6  5.1  460  87    0 123.7
> > 4304  2012-06-28  7  5.0  451  87   -3 123.7
> > 4305  2012-06-28  8  5.2  452  87   -5 123.7
> > 4306  2012-06-28  9  5.2  445  87   -6 123.7
> > 4307  2012-06-28 10  5.0  430  87   -7 123.7
> > 4308  2012-06-28 11  4.6  434  87   -8 123.7
> > 4309  2012-06-28 12  4.1  442  87   -7 123.7
> > 4310  2012-06-28 13  3.9  433  87   -7 123.7
> > 4311  2012-06-28 14  3.5  421  87   -9 123.7
> > 4312  2012-06-28 15  4.4  420  87   -8 123.7
> > 4313  2012-06-28 16  4.6  421  87   -9 123.7
> > 4314  2012-06-28 17  3.2  417  87   -7 123.7
> > 4315  2012-06-28 18  3.5  415  87   -3 123.7
> > 4316  2012-06-28 19  3.9  394  87   -2 123.7
> > 4317  2012-06-28 20  4.2  407  87    0 123.7
> > 4318  2012-06-28 21  3.9  411  87   -3 123.7
> > 4319  2012-06-28 22  3.6  420  87   -5 123.7
> > 4320  2012-06-28 23  4.0  423  87    0 123.7
> > 4321  2012-06-29  0  3.2  418 103    5 121.3
> > 4322  2012-06-29  1  3.3  421 103    7 121.3
> > 4323  2012-06-29  2  3.7  411 103    9 121.3
> > 4324  2012-06-29  3  3.8  413 103    9 121.3
> > 4325  2012-06-29  4  3.3  413 103    6 121.3
> > 4326  2012-06-29  5  3.2  417 103    2 121.3
> > 4327  2012-06-29  6  3.4  414 103    2 121.3
> > 4328  2012-06-29  7  3.7  405 103    1 121.3
> > 4329  2012-06-29  8  3.9  393 103    1 121.3
> > 4330  2012-06-29  9  4.2  385 103    2 121.3
> > 4331  2012-06-29 10  4.4  381 103    2 121.3
> > 4332  2012-06-29 11  4.0  386 103    3 121.3
> > 4333  2012-06-29 12  4.7  386 103    5 121.3
> > 4334  2012-06-29 13  5.2  378 103    7 121.3
> > 4335  2012-06-29 14  5.1  376 103    5 121.3
> > 4336  2012-06-29 15  4.7  366 103    2 121.3
> > 4337  2012-06-29 16  4.5  378 103    0 121.3
> > 4338  2012-06-29 17  4.8  369 103    0 121.3
> > 4339  2012-06-29 18  5.4  365 103    0 121.3
> > 4340  2012-06-29 19  5.7  369 103    1 121.3
> > 4341  2012-06-29 20  5.8  373 103    3 121.3
> > 4342  2012-06-29 21  4.9  392 103   10 121.3
> > 4343  2012-06-29 22  4.0  406 103   19 121.3
> > 4344  2012-06-29 23  7.1  402 103   19 121.3
> > 4345  2012-06-30  0  6.5  398 104   18 128.2
> > 4346  2012-06-30  1  7.6  397 104   12 128.2
> > 4347  2012-06-30  2  8.8  407 104   10 128.2
> > 4348  2012-06-30  3 11.2  404 104   -1 128.2
> > 4349  2012-06-30  4 11.2  410 104    1 128.2
> > 4350  2012-06-30  5  8.8  410 104    1 128.2
> > 4351  2012-06-30  6  9.7  417 104   -6 128.2
> > 4352  2012-06-30  7 12.3  446 104  -14 128.2
> > 4353  2012-06-30  8  9.5  476 104  -10 128.2
> > 4354  2012-06-30  9  8.7  496 104  -13 128.2
> > 4355  2012-06-30 10 12.6  560 104  -17 128.2
> > 4356  2012-06-30 11 11.4  600 104  -13 128.2
> > 4357  2012-06-30 12 11.4  607 104  -12 128.2
> > 4358  2012-06-30 13 11.1  603 104   -8 128.2
> > 4359  2012-06-30 14 11.1  616 104  -14 128.2
> > 4360  2012-06-30 15  9.7  616 104  -13 128.2
> > 4361  2012-06-30 16  9.7  629 104  -15 128.2
> > 4362  2012-06-30 17  6.6  654 104  -24 128.2
> > 4363  2012-06-30 18  6.5  660 104  -24 128.2
> > 4364  2012-06-30 19  6.8  676 104  -31 128.2
> > 4365  2012-06-30 20  7.2  675 104  -37 128.2
> > 4366  2012-06-30 21  7.0  657 104  -32 128.2
> > 4367  2012-06-30 22  6.4  634 104  -31 128.2
> > 4368  2012-06-30 23  7.6  640 104  -29 128.2
> > 4369  2012-07-01  0  6.9  650 126  -23 137.9
> > 4370  2012-07-01  1  7.0  635 126  -18 137.9
> > 4371  2012-07-01  2  6.9  651 126  -17 137.9
> > 4372  2012-07-01  3  6.3  661 126  -25 137.9
> > 4373  2012-07-01  4  5.6  663 126  -26 137.9
> > 4374  2012-07-01  5  5.4  655 126  -26 137.9
> > 4375  2012-07-01  6  5.1  656 126  -33 137.9
> > 4376  2012-07-01  7  4.9  658 126  -30 137.9
> > 4377  2012-07-01  8  5.1  648 126  -24 137.9
> > 4378  2012-07-01  9  5.0  643 126  -24 137.9
> > 4379  2012-07-01 10  5.0  633 126  -20 137.9
> > 4380  2012-07-01 11  5.1  650 126  -17 137.9
> > 4381  2012-07-01 12  5.2  687 126  -13 137.9
> > 4382  2012-07-01 13  5.0  653 126   -8 137.9
> > 4383  2012-07-01 14  4.9  648 126  -12 137.9
> > 4384  2012-07-01 15  5.7  661 126  -11 137.9
> > 4385  2012-07-01 16  5.7  665 126  -10 137.9
> > 4386  2012-07-01 17  5.9  655 126  -12 137.9
> > 4387  2012-07-01 18  5.1  647 126  -10 137.9
> > 4388  2012-07-01 19  4.9  638 126  -16 137.9
> > 4389  2012-07-01 20  5.1  633 126  -17 137.9
> > 4390  2012-07-01 21  5.8  642 126  -16 137.9
> > 4391  2012-07-01 22  5.8  635 126  -18 137.9
> > 4392  2012-07-01 23  5.6  639 126  -16 137.9
> > 4393  2012-07-02  0  5.2  653 128  -15 171.4
> > 4394  2012-07-02  1  6.0  642 128  -12 171.4
> > 4395  2012-07-02  2  5.3  664 128  -16 171.4
> > 4396  2012-07-02  3  5.2  676 128  -13 171.4
> > 4397  2012-07-02  4  5.0  662 128  -22 171.4
> > 4398  2012-07-02  5  5.2  650 128  -28 171.4
> > 4399  2012-07-02  6  5.0  650 128  -35 171.4
> > 4400  2012-07-02  7  5.1  644 128  -32 171.4
> > 4401  2012-07-02  8  4.9  653 128  -31 171.4
> > 4402  2012-07-02  9  4.5  649 128  -26 171.4
> > 4403  2012-07-02 10  4.3  640 128  -25 171.4
> > 4404  2012-07-02 11  4.2  635 128  -20 171.4
> > 4405  2012-07-02 12  4.8  636 128  -17 171.4
> > 4406  2012-07-02 13  5.2  619 128  -16 171.4
> > 4407  2012-07-02 14  4.9  649 128  -25 171.4
> > 4408  2012-07-02 15  4.9  652 128  -31 171.4
> > 4409  2012-07-02 16  5.1  649 128  -36 171.4
> > 4410  2012-07-02 17  4.6  628 128  -37 171.4
> > 4411  2012-07-02 18  4.2  633 128  -31 171.4
> > 4412  2012-07-02 19  4.0  642 128  -29 171.4
> > 4413  2012-07-02 20  3.8  643 128  -30 171.4
> > 4414  2012-07-02 21  3.7  631 128  -32 171.4
> > 4415  2012-07-02 22  3.7  626 128  -32 171.4
> > 4416  2012-07-02 23  3.1  642 128  -31 171.4
> > 4417  2012-07-03  0  3.3  634 125  -25 150.7
> > 4418  2012-07-03  1  3.7  618 125  -19 150.7
> > 4419  2012-07-03  2  3.9  593 125  -17 150.7
> > 4420  2012-07-03  3  3.8  589 125  -16 150.7
> > 4421  2012-07-03  4  3.8  576 125  -16 150.7
> > 4422  2012-07-03  5  4.1  580 125  -20 150.7
> > 4423  2012-07-03  6  3.9  580 125  -18 150.7
> > 4424  2012-07-03  7  3.8  572 125  -19 150.7
> > 4425  2012-07-03  8  4.1  562 125  -18 150.7
> > 4426  2012-07-03  9  4.0  561 125  -15 150.7
> > 4427  2012-07-03 10  4.1  558 125  -18 150.7
> > 4428  2012-07-03 11  4.0  550 125  -20 150.7
> > 4429  2012-07-03 12  4.1  548 125  -22 150.7
> > 4430  2012-07-03 13  3.9  549 125  -21 150.7
> > 4431  2012-07-03 14  4.1  532 125  -19 150.7
> > 4432  2012-07-03 15  4.2  546 125  -19 150.7
> > 4433  2012-07-03 16  4.1  547 125  -19 150.7
> > 4434  2012-07-03 17  4.1  525 125  -23 150.7
> > 4435  2012-07-03 18  4.0  514 125  -25 150.7
> > 4436  2012-07-03 19  3.7  534 125  -22 150.7
> > 4437  2012-07-03 20  3.7  541 125  -18 150.7
> > 4438  2012-07-03 21  3.6  533 125  -19 150.7
> > 4439  2012-07-03 22  4.3  548 125  -16 150.7
> > 4440  2012-07-03 23  4.9  534 125  -12 150.7
> > 4441  2012-07-04  0  4.6  538 131  -11 168.6
> > 4442  2012-07-04  1  4.6  558 131  -10 168.6
> > 4443  2012-07-04  2  4.1  568 131   -8 168.6
> > 4444  2012-07-04  3  4.8  578 131   -5 168.6
> > 4445  2012-07-04  4  5.1  580 131  -10 168.6
> > 4446  2012-07-04  5  5.2  573 131  -17 168.6
> > 4447  2012-07-04  6  5.1  565 131  -19 168.6
> > 4448  2012-07-04  7  4.5  560 131  -18 168.6
> > 4449  2012-07-04  8  4.7  555 131  -18 168.6
> > 4450  2012-07-04  9  4.2  531 131  -19 168.6
> > 4451  2012-07-04 10  4.1  521 131  -17 168.6
> > 4452  2012-07-04 11  4.2  525 131  -18 168.6
> > 4453  2012-07-04 12  3.9  526 131  -15 168.6
> > 4454  2012-07-04 13  4.1  518 131  -10 168.6
> > 4455  2012-07-04 14  4.5  506 131   -7 168.6
> > 4456  2012-07-04 15  4.9  497 131   -6 168.6
> > 4457  2012-07-04 16  4.9  498 131   -5 168.6
> > 4458  2012-07-04 17  4.8  489 131   -5 168.6
> > 4459  2012-07-04 18  4.5  518 131   -6 168.6
> > 4460  2012-07-04 19  5.2  521 131   -6 168.6
> > 4461  2012-07-04 20  6.1  535 131   -8 168.6
> > 4462  2012-07-04 21  6.3  537 131  -14 168.6
> > 4463  2012-07-04 22  6.4  519 131  -18 168.6
> > 4464  2012-07-04 23  6.1  512 131  -19 168.6
> > 4465  2012-07-05  0  5.9  500 129  -12 170.1
> > 4466  2012-07-05  1  5.7  493 129   -1 170.1
> > 4467  2012-07-05  2  5.8  486 129    4 170.1
> > 4468  2012-07-05  3  5.8  487 129    4 170.1
> > 4469  2012-07-05  4  5.4  478 129    5 170.1
> > 4470  2012-07-05  5  5.4  478 129    2 170.1
> > 4471  2012-07-05  6  5.9  483 129   -3 170.1
> > 4472  2012-07-05  7  6.3  495 129   -7 170.1
> > 4473  2012-07-05  8  6.1  503 129   -7 170.1
> > 4474  2012-07-05  9  6.2  499 129   -2 170.1
> > 4475  2012-07-05 10  5.9  495 129    3 170.1
> > 4476  2012-07-05 11  4.1  499 129   21 170.1
> > 4477  2012-07-05 12  6.8  491 129   16 170.1
> > 4478  2012-07-05 13  6.9  489 129   11 170.1
> > 4479  2012-07-05 14  6.5  486 129   31 170.1
> > 4480  2012-07-05 15  8.2  478 129   11 170.1
> > 4481  2012-07-05 16  8.1  472 129   11 170.1
> > 4482  2012-07-05 17  9.8  486 129   11 170.1
> > 4483  2012-07-05 18 10.0  489 129    9 170.1
> > 4484  2012-07-05 19 10.0  489 129    8 170.1
> > 4485  2012-07-05 20  9.8  488 129   12 170.1
> > 4486  2012-07-05 21  9.8  485 129   13 170.1
> > 4487  2012-07-05 22 10.3  473 129    6 170.1
> > 4488  2012-07-05 23  9.4  460 129    7 170.1
> > 4489  2012-07-06  0  9.4  457 132    4 163.0
> > 4490  2012-07-06  1  9.3  448 132    6 163.0
> > 4491  2012-07-06  2  8.8  437 132    7 163.0
> > 4492  2012-07-06  3  7.4  435 132   -1 163.0
> > 4493  2012-07-06  4  8.2  431 132   -3 163.0
> > 4494  2012-07-06  5  8.2  424 132    1 163.0
> > 4495  2012-07-06  6  7.8  429 132   -2 163.0
> > 4496  2012-07-06  7  7.8  429 132  -10 163.0
> > 4497  2012-07-06  8  7.6  436 132  -13 163.0
> > 4498  2012-07-06  9  6.9  442 132   -9 163.0
> > 4499  2012-07-06 10  5.7  458 132   -2 163.0
> > 4500  2012-07-06 11  6.3  453 132   -3 163.0
> > 4501  2012-07-06 12  5.0  447 132   -4 163.0
> > 4502  2012-07-06 13  5.2  430 132   -4 163.0
> > 4503  2012-07-06 14  5.9  417 132   -5 163.0
> > 4504  2012-07-06 15  6.3  421 132   -7 163.0
> > 4505  2012-07-06 16  8.7  447 132    2 163.0
> > 4506  2012-07-06 17  9.8  453 132    4 163.0
> > 4507  2012-07-06 18 10.1  484 132   -4 163.0
> > 4508  2012-07-06 19  9.9  484 132  -17 163.0
> > 4509  2012-07-06 20 10.0  485 132  -27 163.0
> > 4510  2012-07-06 21 10.5  457 132  -36 163.0
> > 4511  2012-07-06 22  9.9  459 132  -25 163.0
> > 4512  2012-07-06 23  8.3  483 132   -9 163.0
> > 4513  2012-07-07  0  8.1  486 146  -12 163.7
> > 4514  2012-07-07  1  6.9  485 146   -6 163.7
> > 4515  2012-07-07  2  7.1  484 146    0 163.7
> > 4516  2012-07-07  3  5.6  480 146    4 163.7
> > 4517  2012-07-07  4  5.2  480 146    3 163.7
> > 4518  2012-07-07  5  5.3  493 146    1 163.7
> > 4519  2012-07-07  6  5.1  494 146    1 163.7
> > 4520  2012-07-07  7  4.7  469 146   -3 163.7
> > 4521  2012-07-07  8  4.9  484 146   -7 163.7
> > 4522  2012-07-07  9  4.3  482 146  -10 163.7
> > 4523  2012-07-07 10  4.3  477 146   -7 163.7
> > 4524  2012-07-07 11  4.1  467 146   -6 163.7
> > 4525  2012-07-07 12  4.1  462 146  -10 163.7
> > 4526  2012-07-07 13  3.8  448 146  -13 163.7
> > 4527  2012-07-07 14  3.9  442 146  -14 163.7
> > 4528  2012-07-07 15  3.8  443 146  -14 163.7
> > 4529  2012-07-07 16  3.8  439 146  -12 163.7
> > 4530  2012-07-07 17  3.4  435 146   -7 163.7
> > 4531  2012-07-07 18  3.7  434 146   -9 163.7
> > 4532  2012-07-07 19  3.5  428 146   -6 163.7
> > 4533  2012-07-07 20  3.1  427 146   -3 163.7
> > 4534  2012-07-07 21  3.2  429 146   -2 163.7
> > 4535  2012-07-07 22  3.3  427 146   -6 163.7
> > 4536  2012-07-07 23  3.5  434 146  -12 163.7
> > 4537  2012-07-08  0  3.1  441 117   -9 183.7
> > 4538  2012-07-08  1  3.1  436 117   -7 183.7
> > 4539  2012-07-08  2  3.8  427 117   -4 183.7
> > 4540  2012-07-08  3  3.4  418 117    3 183.7
> > 4541  2012-07-08  4  3.6  417 117   13 183.7
> > 4542  2012-07-08  5  4.6  413 117   15 183.7
> > 4543  2012-07-08  6  4.3  404 117   15 183.7
> > 4544  2012-07-08  7  4.0  394 117   11 183.7
> > 4545  2012-07-08  8  5.5  405 117   12 183.7
> > 4546  2012-07-08  9  9.2  423 117   14 183.7
> > 4547  2012-07-08 10  8.8  418 117   18 183.7
> > 4548  2012-07-08 11  9.2  407 117   11 183.7
> > 4549  2012-07-08 12  9.2  401 117   10 183.7
> > 4550  2012-07-08 13 10.6  412 117   18 183.7
> > 4551  2012-07-08 14 11.1  414 117   17 183.7
> > 4552  2012-07-08 15 11.1  458 117   13 183.7
> > 4553  2012-07-08 16 11.3  441 117   14 183.7
> > 4554  2012-07-08 17 11.0  439 117   15 183.7
> > 4555  2012-07-08 18  9.8  443 117   13 183.7
> > 4556  2012-07-08 19  8.1  439 117   10 183.7
> > 4557  2012-07-08 20  5.1  453 117   12 183.7
> > 4558  2012-07-08 21  8.4  462 117   16 183.7
> > 4559  2012-07-08 22  9.0  447 117    6 183.7
> > 4560  2012-07-08 23  9.8  436 117  -10 183.7
> > 4561  2012-07-09  0 10.1  438 122  -27 179.6
> > 4562  2012-07-09  1 11.6  441 122  -37 179.6
> > 4563  2012-07-09  2 11.6  434 122  -30 179.6
> > 4564  2012-07-09  3 11.8  421 122  -29 179.6
> > 4565  2012-07-09  4 11.8  419 122  -33 179.6
> > 4566  2012-07-09  5 11.6  419 122  -36 179.6
> > 4567  2012-07-09  6 11.7  420 122  -34 179.6
> > 4568  2012-07-09  7 12.2  415 122  -43 179.6
> > 4569  2012-07-09  8 12.2  412 122  -49 179.6
> > 4570  2012-07-09  9 12.3  405 122  -58 179.6
> > 4571  2012-07-09 10 12.3  398 122  -61 179.6
> > 4572  2012-07-09 11 12.0  392 122  -62 179.6
> > 4573  2012-07-09 12 12.0  392 122  -78 179.6
> > 4574  2012-07-09 13 11.9  390 122  -73 179.6
> > 4575  2012-07-09 14 11.4  394 122  -64 179.6
> > 4576  2012-07-09 15 10.6  400 122  -61 179.6
> > 4577  2012-07-09 16 10.9  400 122  -71 179.6
> > 4578  2012-07-09 17 10.7  396 122  -69 179.6
> > 4579  2012-07-09 18 10.7  394 122  -67 179.6
> > 4580  2012-07-09 19 10.3  395 122  -64 179.6
> > 4581  2012-07-09 20 11.0  395 122  -64 179.6
> > 4582  2012-07-09 21 10.8  397 122  -70 179.6
> > 4583  2012-07-09 22 11.5  401 122  -78 179.6
> > 4584  2012-07-09 23 11.1  401 122  -70 179.6
> > 4585  2012-07-10  0 11.1  389 107  -65 179.2
> > 4586  2012-07-10  1 11.8  403 107  -55 179.2
> > 4587  2012-07-10  2 10.1  416 107  -45 179.2
> > 4588  2012-07-10  3 11.0  406 107  -42 179.2
> > 4589  2012-07-10  4 10.8  419 107  -42 179.2
> > 4590  2012-07-10  5 10.6  410 107  -39 179.2
> > 4591  2012-07-10  6 10.3  408 107  -36 179.2
> > 4592  2012-07-10  7  9.4  417 107  -35 179.2
> > 4593  2012-07-10  8  8.2  405 107  -38 179.2
> > 4594  2012-07-10  9  8.3  404 107  -38 179.2
> > 4595  2012-07-10 10  8.0  424 107  -34 179.2
> > 4596  2012-07-10 11  7.3  433 107  -31 179.2
> > 4597  2012-07-10 12  7.5  465 107  -28 179.2
> > 4598  2012-07-10 13  7.3  450 107  -25 179.2
> > 4599  2012-07-10 14  6.5  454 107  -25 179.2
> > 4600  2012-07-10 15  6.6  472 107  -27 179.2
> > 4601  2012-07-10 16  6.7  461 107  -28 179.2
> > 4602  2012-07-10 17  6.5  462 107  -29 179.2
> > 4603  2012-07-10 18  6.5  461 107  -28 179.2
> > 4604  2012-07-10 19  5.4  483 107  -27 179.2
> > 4605  2012-07-10 20  4.9  490 107  -24 179.2
> > 4606  2012-07-10 21  5.6  482 107  -23 179.2
> > 4607  2012-07-10 22  5.7  484 107  -25 179.2
> > 4608  2012-07-10 23  5.8  484 107  -26 179.2
> > 4609  2012-07-11  0  6.6  489 110  -27 167.1
> > 4610  2012-07-11  1  6.7  489 110  -25 167.1
> > 4611  2012-07-11  2  7.1  503 110  -24 167.1
> > 4612  2012-07-11  3  5.7  494 110  -29 167.1
> > 4613  2012-07-11  4  5.5  509 110  -30 167.1
> > 4614  2012-07-11  5  5.3  522 110  -24 167.1
> > 4615  2012-07-11  6  5.2  518 110  -23 167.1
> > 4616  2012-07-11  7  6.5  516 110  -30 167.1
> > 4617  2012-07-11  8  6.3  526 110  -36 167.1
> > 4618  2012-07-11  9  6.2  523 110  -34 167.1
> > 4619  2012-07-11 10  5.5  527 110  -25 167.1
> > 4620  2012-07-11 11  6.0  527 110  -22 167.1
> > 4621  2012-07-11 12  5.8  518 110  -22 167.1
> > 4622  2012-07-11 13  5.4  515 110  -19 167.1
> > 4623  2012-07-11 14  5.3  513 110  -21 167.1
> > 4624  2012-07-11 15  5.5  512 110  -21 167.1
> > 4625  2012-07-11 16  5.2  505 110  -21 167.1
> > 4626  2012-07-11 17  4.9  512 110  -18 167.1
> > 4627  2012-07-11 18  5.1  514 110  -17 167.1
> > 4628  2012-07-11 19  6.2  520 110  -13 167.1
> > 4629  2012-07-11 20  6.6  510 110  -17 167.1
> > 4630  2012-07-11 21  6.2  516 110  -18 167.1
> > 4631  2012-07-11 22  5.8  512 110  -24 167.1
> > 4632  2012-07-11 23  5.9  509 110  -31 167.1
> > 4633  2012-07-12  0  6.1  502 125  -34 170.9
> > 4634  2012-07-12  1  6.6  506 125  -34 170.9
> > 4635  2012-07-12  2  6.1  502 125  -22 170.9
> > 4636  2012-07-12  3  5.8  480 125  -18 170.9
> > 4637  2012-07-12  4  5.7  474 125  -15 170.9
> > 4638  2012-07-12  5  5.4  474 125  -23 170.9
> > 4639  2012-07-12  6  6.1  466 125  -28 170.9
> > 4640  2012-07-12  7  5.4  460 125  -32 170.9
> > 4641  2012-07-12  8  4.8  453 125  -32 170.9
> > 4642  2012-07-12  9  4.7  445 125  -28 170.9
> > 4643  2012-07-12 10  4.9  436 125  -29 170.9
> > 4644  2012-07-12 11  4.9  441 125  -23 170.9
> > 4645  2012-07-12 12  4.9  440 125  -18 170.9
> > 4646  2012-07-12 13  4.2  417 125  -15 170.9
> > 4647  2012-07-12 14  3.5  414 125  -16 170.9
> > 4648  2012-07-12 15  3.9  418 125  -14 170.9
> > 4649  2012-07-12 16  4.2  419 125  -11 170.9
> > 4650  2012-07-12 17  3.9  416 125  -11 170.9
> > 4651  2012-07-12 18  4.0  416 125  -12 170.9
> > 4652  2012-07-12 19  3.8  415 125  -13 170.9
> > 4653  2012-07-12 20  3.9  410 125  -16 170.9
> > 4654  2012-07-12 21  3.8  402 125  -20 170.9
> > 4655  2012-07-12 22  3.8  395 125  -19 170.9
> > 4656  2012-07-12 23  3.9  394 125  -19 170.9
> > 4657  2012-07-13  0  3.9  395 129  -20 152.1
> > 4658  2012-07-13  1  3.8  395 129  -19 152.1
> > 4659  2012-07-13  2  3.8  391 129  -17 152.1
> > 4660  2012-07-13  3  3.8  385 129  -16 152.1
> > 4661  2012-07-13  4  3.7  376 129  -15 152.1
> > 4662  2012-07-13  5  3.8  371 129  -15 152.1
> > 4663  2012-07-13  6  3.8  365 129  -14 152.1
> > 4664  2012-07-13  7  3.9  357 129  -15 152.1
> > 4665  2012-07-13  8  4.0  354 129  -18 152.1
> > 4666  2012-07-13  9  3.9  355 129  -20 152.1
> > 4667  2012-07-13 10  3.9  353 129  -19 152.1
> > 4668  2012-07-13 11  3.7  357 129  -18 152.1
> > 4669  2012-07-13 12  3.8  357 129  -18 152.1
> > 4670  2012-07-13 13  3.8  355 129  -18 152.1
> > 4671  2012-07-13 14  3.7  347 129  -17 152.1
> > 4672  2012-07-13 15  3.7  350 129  -15 152.1
> > 4673  2012-07-13 16  3.7  346 129  -13 152.1
> > 4674  2012-07-13 17  3.7  341 129  -10 152.1
> > 4675  2012-07-13 18  3.3  340 129   -8 152.1
> > 4676  2012-07-13 19  3.2  338 129   -9 152.1
> > 4677  2012-07-13 20  3.3  333 129  -10 152.1
> > 4678  2012-07-13 21  3.4  329 129   -9 152.1
> > 4679  2012-07-13 22  3.9  326 129   -7 152.1
> > 4680  2012-07-13 23  4.0  324 129   -8 152.1
> > 4681  2012-07-14  0  4.0  324 125   -9 152.8
> > 4682  2012-07-14  1  4.0  325 125   -9 152.8
> > 4683  2012-07-14  2  3.9  329 125   -7 152.8
> > 4684  2012-07-14  3  4.1  326 125   -5 152.8
> > 4685  2012-07-14  4  4.4  325 125   -6 152.8
> > 4686  2012-07-14  5  4.5  323 125   -5 152.8
> > 4687  2012-07-14  6  5.0  319 125   -5 152.8
> > 4688  2012-07-14  7  5.2  317 125   -8 152.8
> > 4689  2012-07-14  8  5.4  323 125   -7 152.8
> > 4690  2012-07-14  9  5.4  318 125   -6 152.8
> > 4691  2012-07-14 10  5.2  316 125   -8 152.8
> > 4692  2012-07-14 11  5.2  326 125   -5 152.8
> > 4693  2012-07-14 12  4.6  335 125   -5 152.8
> > 4694  2012-07-14 13  4.2  340 125   -5 152.8
> > 4695  2012-07-14 14  5.0  350 125   -5 152.8
> > 4696  2012-07-14 15  4.9  366 125   -1 152.8
> > 4697  2012-07-14 16  3.9  355 125   -5 152.8
> > 4698  2012-07-14 17  5.1  369 125   -5 152.8
> > 4699  2012-07-14 18 11.0  419 125   15 152.8
> > 4700  2012-07-14 19 14.6  574 125    4 152.8
> > 4701  2012-07-14 20 11.2  569 125   -7 152.8
> > 4702  2012-07-14 21 13.9  568 125   -5 152.8
> > 4703  2012-07-14 22 15.3  574 125    1 152.8
> > 4704  2012-07-14 23 19.2  644 125   -2 152.8
> > 4705  2012-07-15  0 11.4  665 117    9 145.1
> > 4706  2012-07-15  1  9.7  657 117    0 145.1
> > *Jibrin Adejoh Alhassan (Ph.D)*
> > Department of Physics and Astronomy,
> > University of Nigeria, Nsukka
> >
> >
> > On Mon, Jun 17, 2024 at 9:23?AM Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
> >
> >> ?s 09:12 de 17/06/2024, Jibrin Alhassan escreveu:
> >>> Hello Rui,
> >>> Here is the head(df1) output
> >>> Date HR IMF SWS SSN Dst f10.7
> >>> 1 2012-01-01  0 4.0 379  71  -8 999.9
> >>> 2 2012-01-01  1 4.4 386  71  -3 999.9
> >>> 3 2012-01-01  2 4.8 380  71  -4 999.9
> >>> 4 2012-01-01  3 5.4 374  71  -5 999.9
> >>> 5 2012-01-01  4 4.5 369  71  -9 999.9
> >>> 6 2012-01-01  5 4.2 368  71  -7 999.9
> >>> Many thanks.
> >>> *Jibrin Adejoh Alhassan (Ph.D)*
> >>> Department of Physics and Astronomy,
> >>> University of Nigeria, Nsukka
> >>>
> >>>
> >>> On Mon, Jun 17, 2024 at 8:14?AM Rui Barradas <ruipbarradas at sapo.pt>
> >> wrote:
> >>>
> >>>> ?s 07:53 de 17/06/2024, Jibrin Alhassan escreveu:
> >>>>> Part of it is pasted below
> >>>>> YEAR DOY HR    IMF SWS   SSN   Dst f10.7
> >>>>> 2012   1  0   4.0  379.  71    -8 999.9
> >>>>> 2012   1  1   4.4  386.  71    -3 999.9
> >>>>> 2012   1  2   4.8  380.  71    -4 999.9
> >>>>> 2012   1  3   5.4  374.  71    -5 999.9
> >>>>> 2012   1  4   4.5  369.  71    -9 999.9
> >>>>> 2012   1  5   4.2  368.  71    -7 999.9
> >>>>> 2012   1  6   4.7  367.  71    -6 999.9
> >>>>> 2012   1  7   4.1  361.  71   -10 999.9
> >>>>> 2012   1  8   3.2  362.  71    -7 999.9
> >>>>> 2012   1  9   4.3  367.  71    -3 999.9
> >>>>> 2012   1 10   4.5  365.  71    -6 999.9
> >>>>> 2012   1 11   5.6  369.  71    -8 999.9
> >>>>> 2012   1 12   5.2  366.  71    -8 999.9
> >>>>> 2012   1 13   4.4  370.  71    -7 999.9
> >>>>> 2012   1 14   4.8  357.  71    -5 999.9
> >>>>> 2012   1 15   4.6  354.  71    -8 999.9
> >>>>> 2012   1 16   3.7  382.  71    -7 999.9
> >>>>> 2012   1 17   3.2  376.  71    -2 999.9
> >>>>> 2012   1 18   2.8  368.  71     2 999.9
> >>>>> 2012   1 19   3.2  361.  71     2 999.9
> >>>>> 2012   1 20   3.2  361.  71    -3 999.9
> >>>>> 2012   1 21   3.5  365.  71    -5 999.9
> >>>>> 2012   1 22   3.6  364.  71    -3 999.9
> >>>>> 2012   1 23   3.0  362.  71    -3 999.9
> >>>>> 2012   2  0   3.2  359.  92    -5 130.3
> >>>>> 2012   2  1   3.0  361.  92    -4 130.3
> >>>>> 2012   2  2   4.5  374.  92     3 130.3
> >>>>> 2012   2  3   4.5  364.  92     5 130.3
> >>>>> 2012   2  4   5.1  352.  92     3 130.3
> >>>>> 2012   2  5   4.9  358.  92     3 130.3
> >>>>> 2012   2  6   4.4  346.  92     4 130.3
> >>>>> 2012   2  7   4.2  349.  92     7 130.3
> >>>>> 2012   2  8   4.5  346.  92     8 130.3
> >>>>> 2012   2  9   5.2  345.  92     7 130.3
> >>>>> 2012   2 10   5.0  349.  92     5 130.3
> >>>>> 2012   2 11   4.8  345.  92     0 130.3
> >>>>> 2012   2 12   5.3  347.  92     0 130.3
> >>>>> 2012   2 13   5.5  342.  92     0 130.3
> >>>>> 2012   2 14   6.1  359.  92     1 130.3
> >>>>> 2012   2 15   6.2  393.  92     8 130.3
> >>>>> 2012   2 16   6.7  390.  92    10 130.3
> >>>>> 2012   2 17   7.7  369.  92    10 130.3
> >>>>> 2012   2 18   9.4  380.  92    14 130.3
> >>>>> 2012   2 19  10.6  386.  92    12 130.3
> >>>>> 2012   2 20  10.2  378.  92    11 130.3
> >>>>> 2012   2 21  11.6  369.  92     7 130.3
> >>>>> 2012   2 22  12.0  369.  92     8 130.3
> >>>>> 2012   2 23  10.5  361.  92     1 130.3
> >>>>> 2012   3  0  11.3  403. 120    -7 130.2
> >>>>> 2012   3  1  10.3  412. 120   -14 130.2
> >>>>> 2012   3  2   8.8  419. 120   -18 130.2
> >>>>> 2012   3  3   8.3  412. 120   -23 130.2
> >>>>> 2012   3  4   8.0  408. 120   -25 130.2
> >>>>> 2012   3  5   7.0  380. 120   -28 130.2
> >>>>> 2012   3  6   6.9  374. 120   -29 130.2
> >>>>> 2012   3  7   6.9  372. 120   -30 130.2
> >>>>> 2012   3  8   7.1  365. 120   -32 130.2
> >>>>> 2012   3  9   6.8  376. 120   -35 130.2
> >>>>> 2012   3 10   6.7  380. 120   -35 130.2
> >>>>> 2012   3 11   6.4  381. 120   -30 130.2
> >>>>> 2012   3 12   5.9  401. 120   -26 130.2
> >>>>> 2012   3 13   5.9  405. 120   -23 130.2
> >>>>> 2012   3 14   5.9  413. 120   -20 130.2
> >>>>> 2012   3 15   5.9  406. 120   -20 130.2
> >>>>> 2012   3 16   6.3  427. 120   -20 130.2
> >>>>> 2012   3 17   5.9  424. 120   -19 130.2
> >>>>> 2012   3 18   4.8  390. 120   -16 130.2
> >>>>> 2012   3 19   4.8  374. 120   -15 130.2
> >>>>> 2012   3 20   4.8  374. 120   -15 130.2
> >>>>> 2012   3 21   5.1  378. 120   -18 130.2
> >>>>> 2012   3 22   4.9  375. 120   -19 130.2
> >>>>> 2012   3 23   4.7  364. 120   -17 130.2
> >>>>> 2012   4  0   4.3  359. 126   -17 131.6
> >>>>> 2012   4  1   4.3  359. 126   -15 131.6
> >>>>> 2012   4  2   4.2  358. 126   -13 131.6
> >>>>> 2012   4  3   3.8  359. 126   -13 131.6
> >>>>> 2012   4  4   3.8  358. 126   -13 131.6
> >>>>> 2012   4  5   3.7  359. 126   -14 131.6
> >>>>> 2012   4  6   3.9  361. 126   -13 131.6
> >>>>> 2012   4  7   3.7  364. 126   -13 131.6
> >>>>> 2012   4  8   3.7  366. 126   -12 131.6
> >>>>> 2012   4  9   3.8  363. 126   -10 131.6
> >>>>> 2012   4 10   3.5  363. 126    -8 131.6
> >>>>> 2012   4 11   3.0  352. 126   -10 131.6
> >>>>> 2012   4 12   3.1  348. 126   -12 131.6
> >>>>> 2012   4 13   3.3  340. 126    -9 131.6
> >>>>> 2012   4 14   4.0  343. 126    -8 131.6
> >>>>> 2012   4 15   4.2  343. 126    -7 131.6
> >>>>> 2012   4 16   3.8  336. 126    -5 131.6
> >>>>> 2012   4 17   3.9  334. 126    -6 131.6
> >>>>> 2012   4 18   3.8  329. 126    -5 131.6
> >>>>> 2012   4 19   3.8  326. 126    -4 131.6
> >>>>> 2012   4 20   4.3  337. 126    -3 131.6
> >>>>> 2012   4 21   3.9  331. 126     0 131.6
> >>>>> 2012   4 22   3.8  322. 126    -1 131.6
> >>>>> 2012   4 23   3.5  331. 126    -1 131.6
> >>>>> 2012   5  0   3.9  312. 109    -3 136.6
> >>>>> 2012   5  1   3.6  311. 109    -1 136.6
> >>>>> 2012   5  2   3.7  312. 109     0 136.6
> >>>>> 2012   5  3   3.8  308. 109     0 136.6
> >>>>> 2012   5  4   4.0  305. 109     2 136.6
> >>>>> 2012   5  5   4.5  309. 109     2 136.6
> >>>>> 2012   5  6   3.5  314. 109     3 136.6
> >>>>> 2012   5  7   3.6  305. 109     2 136.6
> >>>>> 2012   5  8   4.3  307. 109     2 136.6
> >>>>> 2012   5  9   4.6  316. 109     1 136.6
> >>>>> 2012   5 10   5.0  321. 109    -4 136.6
> >>>>> 2012   5 11   5.1  321. 109    -6 136.6
> >>>>> 2012   5 12   4.6  326. 109    -4 136.6
> >>>>> 2012   5 13   5.7  321. 109    -2 136.6
> >>>>> 2012   5 14   5.0  316. 109     1 136.6
> >>>>> 2012   5 15   4.6  315. 109     2 136.6
> >>>>> 2012   5 16   5.5  321. 109     7 136.6
> >>>>> 2012   5 17   7.2  327. 109     7 136.6
> >>>>> 2012   5 18   9.2  329. 109     3 136.6
> >>>>> 2012   5 19   9.4  341. 109     3 136.6
> >>>>> 2012   5 20   9.2  345. 109     8 136.6
> >>>>> 2012   5 21   9.8  344. 109     9 136.6
> >>>>> 2012   5 22   9.8  341. 109    10 136.6
> >>>>> 2012   5 23  10.0  351. 109    15 136.6
> >>>>> 2012   6  0  10.4  356. 113    12 131.0
> >>>>> 2012   6  1   9.1  360. 113    10 131.0
> >>>>> 2012   6  2   6.6  392. 113    10 131.0
> >>>>> 2012   6  3   6.9  418. 113     7 131.0
> >>>>> 2012   6  4   6.5  408. 113     4 131.0
> >>>>> 2012   6  5   6.6  413. 113     7 131.0
> >>>>> 2012   6  6   7.3  428. 113     6 131.0
> >>>>> 2012   6  7   7.3  416. 113     4 131.0
> >>>>> 2012   6  8   7.0  411. 113     1 131.0
> >>>>> 2012   6  9   7.2  415. 113     1 131.0
> >>>>> 2012   6 10   7.2  426. 113     0 131.0
> >>>>> 2012   6 11   6.5  431. 113    -2 131.0
> >>>>> 2012   6 12   6.4  431. 113    -2 131.0
> >>>>> 2012   6 13   6.6  435. 113     0 131.0
> >>>>> 2012   6 14   6.2  425. 113     2 131.0
> >>>>> 2012   6 15   5.7  431. 113     4 131.0
> >>>>> 2012   6 16   6.1  431. 113     1 131.0
> >>>>> 2012   6 17   5.7  425. 113    -3 131.0
> >>>>> 2012   6 18   5.8  431. 113    -1 131.0
> >>>>> 2012   6 19   6.4  425. 113     2 131.0
> >>>>> 2012   6 20   6.0  434. 113     1 131.0
> >>>>> 2012   6 21   6.3  420. 113     0 131.0
> >>>>> 2012   6 22   6.3  440. 113    -3 131.0
> >>>>> 2012   6 23   6.5  456. 113    -3 131.0
> >>>>> 2012   7  0   6.3  435. 113    -5 135.9
> >>>>> 2012   7  1   5.9  428. 113    -1 135.9
> >>>>> 2012   7  2   5.7  434. 113     1 135.9
> >>>>> 2012   7  3   5.3  423. 113     0 135.9
> >>>>> 2012   7  4   4.3  417. 113     1 135.9
> >>>>> 2012   7  5   5.4  420. 113     0 135.9
> >>>>> 2012   7  6   5.7  434. 113     1 135.9
> >>>>> 2012   7  7   5.5  423. 113     1 135.9
> >>>>> 2012   7  8   4.8  419. 113    -2 135.9
> >>>>> 2012   7  9   5.8  421. 113    -6 135.9
> >>>>> 2012   7 10   5.3  412. 113    -9 135.9
> >>>>> 2012   7 11   4.6  424. 113    -7 135.9
> >>>>> 2012   7 12   4.0  439. 113    -3 135.9
> >>>>> 2012   7 13   4.8  431. 113    -1 135.9
> >>>>> 2012   7 14   5.1  431. 113    -1 135.9
> >>>>> 2012   7 15   4.8  427. 113    -1 135.9
> >>>>> 2012   7 16   4.7  429. 113    -5 135.9
> >>>>> 2012   7 17   5.3  436. 113    -6 135.9
> >>>>> 2012   7 18   5.1  426. 113    -5 135.9
> >>>>> 2012   7 19   5.2  427. 113    -4 135.9
> >>>>> 2012   7 20   4.5  416. 113    -5 135.9
> >>>>> 2012   7 21   4.9  409. 113    -4 135.9
> >>>>> 2012   7 22   5.0  417. 113    -4 135.9
> >>>>> 2012   7 23   5.0  426. 113    -4 135.9
> >>>>> 2012   8  0   5.0  433. 104    -2 131.4
> >>>>> 2012   8  1   4.9  426. 104    -2 131.4
> >>>>> 2012   8  2   4.7  421. 104    -4 131.4
> >>>>> 2012   8  3   4.4  417. 104    -5 131.4
> >>>>> 2012   8  4   4.3  416. 104    -8 131.4
> >>>>> 2012   8  5   4.5  416. 104    -8 131.4
> >>>>> 2012   8  6   5.0  419. 104    -6 131.4
> >>>>> 2012   8  7   5.4  446. 104    -1 131.4
> >>>>> 2012   8  8   5.3  439. 104    -2 131.4
> >>>>> 2012   8  9   5.3  432. 104    -4 131.4
> >>>>> 2012   8 10   5.4  434. 104    -4 131.4
> >>>>> 2012   8 11   5.4  435. 104    -3 131.4
> >>>>> 2012   8 12   4.5  421. 104    -4 131.4
> >>>>> 2012   8 13   4.5  422. 104    -4 131.4
> >>>>> 2012   8 14   5.1  425. 104    -2 131.4
> >>>>> 2012   8 15   5.3  429. 104     1 131.4
> >>>>> 2012   8 16   5.5  433. 104    -2 131.4
> >>>>> 2012   8 17   5.9  440. 104    -2 131.4
> >>>>> 2012   8 18   6.6  445. 104    -1 131.4
> >>>>> 2012   8 19   6.4  442. 104    -4 131.4
> >>>>> 2012   8 20   5.9  434. 104    -6 131.4
> >>>>> 2012   8 21   5.3  429. 104    -7 131.4
> >>>>> 2012   8 22   4.8  438. 104    -2 131.4
> >>>>> 2012   8 23   5.3  427. 104     4 131.4
> >>>>> 2012   9  0   5.5  433.  79     8 137.6
> >>>>> 2012   9  1   5.2  445.  79     9 137.6
> >>>>> 2012   9  2   5.4  439.  79    10 137.6
> >>>>> 2012   9  3   5.3  430.  79     7 137.6
> >>>>> 2012   9  4   5.1  426.  79    -3 137.6
> >>>>> 2012   9  5   4.7  415.  79    -6 137.6
> >>>>> 2012   9  6   5.0  412.  79    -4 137.6
> >>>>> 2012   9  7   5.2  418.  79    -2 137.6
> >>>>> 2012   9  8   5.5  441.  79     2 137.6
> >>>>> 2012   9  9   5.1  441.  79     2 137.6
> >>>>> 2012   9 10   5.4  430.  79    -2 137.6
> >>>>> 2012   9 11   5.3  433.  79    -1 137.6
> >>>>> 2012   9 12   5.5  438.  79     5 137.6
> >>>>> 2012   9 13   5.4  436.  79     6 137.6
> >>>>> 2012   9 14   5.7  440.  79     9 137.6
> >>>>> 2012   9 15   5.9  430.  79     9 137.6
> >>>>> 2012   9 16   5.8  437.  79     4 137.6
> >>>>> 2012   9 17   4.9  431.  79    -3 137.6
> >>>>> 2012   9 18   5.3  424.  79    -3 137.6
> >>>>> 2012   9 19   5.7  437.  79    -2 137.6
> >>>>> 2012   9 20   6.1  427.  79    -4 137.6
> >>>>> 2012   9 21   6.0  409.  79    -7 137.6
> >>>>> 2012   9 22   6.6  410.  79    -4 137.6
> >>>>> 2012   9 23   6.4  432.  79    -1 137.6
> >>>>> 2012  10  0   5.9  434.  70     2 124.6
> >>>>> 2012  10  1   5.6  424.  70     4 124.6
> >>>>> 2012  10  2   4.8  435.  70     7 124.6
> >>>>> 2012  10  3   4.6  425.  70     4 124.6
> >>>>> 2012  10  4   4.3  424.  70     3 124.6
> >>>>> 2012  10  5   5.4  426.  70     2 124.6
> >>>>> 2012  10  6   5.5  434.  70     2 124.6
> >>>>> 2012  10  7   6.4  435.  70     4 124.6
> >>>>> 2012  10  8   6.3  436.  70     1 124.6
> >>>>> 2012  10  9   5.2  431.  70    -6 124.6
> >>>>> 2012  10 10   4.5  426.  70   -10 124.6
> >>>>> 2012  10 11   4.6  435.  70    -9 124.6
> >>>>> 2012  10 12   3.4  425.  70    -5 124.6
> >>>>> 2012  10 13   4.2  427.  70    -4 124.6
> >>>>> 2012  10 14   4.0  432.  70     2 124.6
> >>>>> 2012  10 15   5.5  450.  70     7 124.6
> >>>>> 2012  10 16   5.9  451.  70     2 124.6
> >>>>> 2012  10 17   5.5  445.  70    -3 124.6
> >>>>> 2012  10 18   5.8  442.  70    -2 124.6
> >>>>> 2012  10 19   5.4  430.  70    -1 124.6
> >>>>> 2012  10 20   4.9  427.  70    -1 124.6
> >>>>> 2012  10 21   4.0  436.  70     0 124.6
> >>>>> 2012  10 22   3.4  445.  70    -1 124.6
> >>>>> 2012  10 23   4.5  453.  70     0 124.6
> >>>>> 2012  11  0   5.3  438.  63     1 116.1
> >>>>> 2012  11  1   5.0  438.  63     3 116.1
> >>>>> 2012  11  2   5.3  445.  63     3 116.1
> >>>>> 2012  11  3   4.5  451.  63     2 116.1
> >>>>> 2012  11  4   5.0  456.  63    -1 116.1
> >>>>> 2012  11  5   4.6  459.  63     0 116.1
> >>>>> 2012  11  6   5.1  459.  63     1 116.1
> >>>>> 2012  11  7   4.0  466.  63     3 116.1
> >>>>> 2012  11  8   5.0  478.  63    -1 116.1
> >>>>> 2012  11  9   4.6  489.  63    -2 116.1
> >>>>> 2012  11 10   4.5  493.  63    -4 116.1
> >>>>> 2012  11 11   4.5  494.  63    -1 116.1
> >>>>> 2012  11 12   3.6  504.  63     3 116.1
> >>>>> 2012  11 13   3.5  496.  63     5 116.1
> >>>>> 2012  11 14   3.3  497.  63     7 116.1
> >>>>> 2012  11 15   3.0  498.  63     7 116.1
> >>>>> 2012  11 16   2.1  503.  63     3 116.1
> >>>>> 2012  11 17   2.0  495.  63     0 116.1
> >>>>> 2012  11 18   2.5  492.  63    -2 116.1
> >>>>> 2012  11 19   2.2  496.  63    -1 116.1
> >>>>> 2012  11 20   2.4  489.  63     1 116.1
> >>>>> 2012  11 21   2.6  489.  63     3 116.1
> >>>>> 2012  11 22   2.6  483.  63     2 116.1
> >>>>> 2012  11 23   2.6  478.  63     2 116.1
> >>>>> 2012  12  0   2.9  453.  52     3 113.0
> >>>>> 2012  12  1   2.2  446.  52     4 113.0
> >>>>> 2012  12  2   2.4  442.  52     8 113.0
> >>>>> 2012  12  3   2.6  440.  52    10 113.0
> >>>>> 2012  12  4   2.2  438.  52    11 113.0
> >>>>> 2012  12  5   2.8  438.  52     9 113.0
> >>>>> 2012  12  6   2.0  437.  52     8 113.0
> >>>>> 2012  12  7   2.4  426.  52     7 113.0
> >>>>> 2012  12  8   3.0  423.  52     5 113.0
> >>>>> 2012  12  9   3.3  420.  52     4 113.0
> >>>>> 2012  12 10   4.0  419.  52     2 113.0
> >>>>> 2012  12 11   3.8  412.  52     5 113.0
> >>>>> 2012  12 12   4.2  409.  52     4 113.0
> >>>>> 2012  12 13   3.5  408.  52     2 113.0
> >>>>> 2012  12 14   3.7  404.  52     9 113.0
> >>>>> 2012  12 15   4.5  402.  52    15 113.0
> >>>>> 2012  12 16   3.6  395.  52    14 113.0
> >>>>> 2012  12 17   2.4  392.  52    16 113.0
> >>>>> 2012  12 18   5.8  403.  52    27 113.0
> >>>>> 2012  12 19   7.6  400.  52    27 113.0
> >>>>> 2012  12 20   6.9  418.  52    17 113.0
> >>>>> 2012  12 21   6.9  463.  52    10 113.0
> >>>>> 2012  12 22   7.3  469.  52     9 113.0
> >>>>> 2012  12 23   5.5  482.  52    12 113.0
> >>>>> 2012  13  0   7.7  500.  71    10 120.0
> >>>>> 2012  13  1   8.7  492.  71    14 120.0
> >>>>> 2012  13  2   7.8  513.  71    16 120.0
> >>>>> 2012  13  3   7.5  530.  71    11 120.0
> >>>>> 2012  13  4   7.1  518.  71     8 120.0
> >>>>> 2012  13  5   7.0  524.  71     6 120.0
> >>>>> 2012  13  6   5.9  536.  71     8 120.0
> >>>>> 2012  13  7   3.6  529.  71     5 120.0
> >>>>> 2012  13  8   4.1  510.  71     4 120.0
> >>>>> 2012  13  9   3.9  497.  71     3 120.0
> >>>>> 2012  13 10   2.4  492.  71     3 120.0
> >>>>> 2012  13 11   2.6  485.  71     5 120.0
> >>>>> 2012  13 12   2.9  492.  71     5 120.0
> >>>>> 2012  13 13   2.6  487.  71     3 120.0
> >>>>> 2012  13 14   2.3  478.  71     6 120.0
> >>>>> 2012  13 15   3.2  467.  71    11 120.0
> >>>>> 2012  13 16   3.4  453.  71    10 120.0
> >>>>> 2012  13 17   3.2  452.  71     6 120.0
> >>>>> 2012  13 18   3.0  452.  71     2 120.0
> >>>>> 2012  13 19   2.8  447.  71     1 120.0
> >>>>> 2012  13 20   2.5  439.  71     0 120.0
> >>>>> 2012  13 21   2.5  443.  71    -2 120.0
> >>>>> 2012  13 22   2.7  442.  71    -3 120.0
> >>>>> 2012  13 23   3.0  447.  71    -4 120.0
> >>>>> 2012  14  0   3.5  445. 118    -3 128.0
> >>>>> 2012  14  1   3.3  440. 118    -1 128.0
> >>>>> 2012  14  2   3.1  440. 118     1 128.0
> >>>>> 2012  14  3   2.7  446. 118     0 128.0
> >>>>> 2012  14  4   2.9  442. 118    -1 128.0
> >>>>> 2012  14  5   2.9  437. 118    -2 128.0
> >>>>> 2012  14  6   3.3  431. 118    -3 128.0
> >>>>> 2012  14  7   2.8  420. 118    -2 128.0
> >>>>> 2012  14  8   2.3  409. 118    -2 128.0
> >>>>> 2012  14  9   2.2  407. 118     1 128.0
> >>>>> 2012  14 10   2.6  405. 118     3 128.0
> >>>>> 2012  14 11   2.8  401. 118     4 128.0
> >>>>> 2012  14 12   3.2  398. 118     4 128.0
> >>>>> 2012  14 13   2.7  400. 118     4 128.0
> >>>>> 2012  14 14   1.9  399. 118     5 128.0
> >>>>> 2012  14 15   2.4  395. 118     3 128.0
> >>>>> 2012  14 16   2.7  389. 118     2 128.0
> >>>>> 2012  14 17   2.9  385. 118     0 128.0
> >>>>> 2012  14 18   3.2  384. 118     1 128.0
> >>>>> 2012  14 19   2.6  380. 118     2 128.0
> >>>>> 2012  14 20   2.3  378. 118     1 128.0
> >>>>> 2012  14 21   2.1  374. 118     0 128.0
> >>>>> 2012  14 22   3.1  367. 118     0 128.0
> >>>>> 2012  14 23   4.0  366. 118    -1 128.0
> >>>>> 2012  15  0   4.8  363. 149     0 129.2
> >>>>> 2012  15  1   4.0  359. 149     2 129.2
> >>>>> 2012  15  2   3.4  354. 149     2 129.2
> >>>>> 2012  15  3   3.0  349. 149     5 129.2
> >>>>> 2012  15  4   2.7  344. 149     7 129.2
> >>>>> 2012  15  5   2.4  349. 149    11 129.2
> >>>>> 2012  15  6   2.9  343. 149    12 129.2
> >>>>> 2012  15  7   3.5  333. 149     7 129.2
> >>>>> 2012  15  8   3.6  341. 149     4 129.2
> >>>>> 2012  15  9   3.7  345. 149     1 129.2
> >>>>> 2012  15 10   3.6  343. 149     2 129.2
> >>>>> 2012  15 11   3.6  342. 149     3 129.2
> >>>>> 2012  15 12   3.7  340. 149     7 129.2
> >>>>> 2012  15 13   3.7  342. 149     8 129.2
> >>>>> 2012  15 14   4.1  344. 149     9 129.2
> >>>>> 2012  15 15   3.9  345. 149     4 129.2
> >>>>> 2012  15 16   4.4  355. 149     8 129.2
> >>>>> 2012  15 17   4.7  360. 149    11 129.2
> >>>>> 2012  15 18   5.4  359. 149    12 129.2
> >>>>> 2012  15 19   6.8  353. 149     8 129.2
> >>>>> 2012  15 20   6.6  349. 149     6 129.2
> >>>>> 2012  15 21   5.9  364. 149     2 129.2
> >>>>> 2012  15 22   5.2  394. 149     1 129.2
> >>>>> 2012  15 23   6.3  395. 149     5 129.2
> >>>>> 2012  16  0   6.3  385. 154     6 135.1
> >>>>> 2012  16  1   6.6  397. 154     2 135.1
> >>>>> 2012  16  2   6.7  400. 154     4 135.1
> >>>>> 2012  16  3   6.9  396. 154     5 135.1
> >>>>> 2012  16  4   7.9  392. 154     5 135.1
> >>>>> 2012  16  5   4.6  379. 154    10 135.1
> >>>>> 2012  16  6   8.0  365. 154    13 135.1
> >>>>> 2012  16  7   6.3  358. 154    16 135.1
> >>>>> 2012  16  8   7.9  380. 154    12 135.1
> >>>>> 2012  16  9  10.2  391. 154    10 135.1
> >>>>> 2012  16 10   8.1  394. 154     8 135.1
> >>>>> 2012  16 11  12.1  412. 154    -8 135.1
> >>>>> 2012  16 12  13.2  424. 154   -10 135.1
> >>>>> 2012  16 13  12.9  433. 154    -8 135.1
> >>>>> 2012  16 14   9.3  461. 154    -7 135.1
> >>>>> 2012  16 15   6.6  466. 154   -14 135.1
> >>>>> 2012  16 16   6.6  493. 154   -11 135.1
> >>>>> 2012  16 17   7.4  496. 154    -7 135.1
> >>>>> 2012  16 18   6.2  493. 154    -7 135.1
> >>>>> 2012  16 19   6.9  492. 154   -13 135.1
> >>>>> 2012  16 20   6.8  486. 154   -19 135.1
> >>>>> 2012  16 21   5.6  488. 154   -14 135.1
> >>>>> 2012  16 22   6.4  464. 154   -11 135.1
> >>>>> 2012  16 23   6.0  459. 154   -10 135.1
> >>>>> 2012  17  0   4.9  476. 141   -14 134.5
> >>>>> 2012  17  1   4.6  460. 141   -20 134.5
> >>>>> 2012  17  2   4.1  467. 141   -17 134.5
> >>>>> 2012  17  3   3.7  469. 141   -13 134.5
> >>>>> 2012  17  4   3.3  472. 141   -12 134.5
> >>>>> 2012  17  5   2.7  472. 141    -8 134.5
> >>>>> 2012  17  6   3.5  459. 141    -6 134.5
> >>>>> 2012  17  7   3.9  459. 141    -6 134.5
> >>>>> 2012  17  8   4.1  463. 141    -7 134.5
> >>>>> 2012  17  9   4.1  443. 141   -10 134.5
> >>>>> 2012  17 10   4.1  446. 141   -14 134.5
> >>>>> 2012  17 11   4.1  442. 141   -13 134.5
> >>>>> 2012  17 12   3.6  436. 141   -10 134.5
> >>>>> 2012  17 13   3.6  433. 141    -6 134.5
> >>>>> 2012  17 14   4.2  421. 141    -1 134.5
> >>>>> 2012  17 15   3.7  416. 141    -2 134.5
> >>>>> 2012  17 16   4.2  410. 141    -1 134.5
> >>>>> 2012  17 17   4.6  396. 141    -1 134.5
> >>>>> 2012  17 18   4.5  398. 141    -2 134.5
> >>>>> 2012  17 19   4.4  397. 141    -6 134.5
> >>>>> 2012  17 20   4.5  396. 141    -8 134.5
> >>>>> 2012  17 21   3.5  411. 141    -5 134.5
> >>>>> 2012  17 22   3.9  425. 141    -5 134.5
> >>>>> 2012  17 23   4.7  418. 141    -6 134.5
> >>>>> 2012  18  0   4.6  400. 126    -7 143.4
> >>>>> 2012  18  1   4.5  413. 126    -3 143.4
> >>>>> 2012  18  2   4.4  418. 126     2 143.4
> >>>>> 2012  18  3   4.2  420. 126     2 143.4
> >>>>> 2012  18  4   4.0  401. 126    -2 143.4
> >>>>> 2012  18  5   3.8  399. 126    -1 143.4
> >>>>> 2012  18  6   3.5  388. 126    -1 143.4
> >>>>> 2012  18  7   4.4  393. 126    -2 143.4
> >>>>> 2012  18  8   4.7  405. 126    -3 143.4
> >>>>> 2012  18  9   4.8  409. 126    -4 143.4
> >>>>> 2012  18 10   4.9  409. 126    -3 143.4
> >>>>> 2012  18 11   5.0  411. 126    -5 143.4
> >>>>> 2012  18 12   5.1  405. 126    -5 143.4
> >>>>> 2012  18 13   5.2  403. 126    -6 143.4
> >>>>> 2012  18 14   5.1  394. 126    -4 143.4
> >>>>> 2012  18 15   5.0  391. 126    -5 143.4
> >>>>> 2012  18 16   4.6  387. 126    -4 143.4
> >>>>> 2012  18 17   4.7  376. 126    -2 143.4
> >>>>> 2012  18 18   4.7  381. 126    -1 143.4
> >>>>> 2012  18 19   4.5  382. 126    -2 143.4
> >>>>> 2012  18 20   4.9  386. 126    -5 143.4
> >>>>> 2012  18 21   4.8  375. 126    -5 143.4
> >>>>> 2012  18 22   4.7  385. 126    -6 143.4
> >>>>> 2012  18 23   4.7  381. 126    -5 143.4
> >>>>> 2012  19  0   4.3  372. 105    -3 152.0
> >>>>> 2012  19  1   4.2  361. 105    -4 152.0
> >>>>> 2012  19  2   4.0  360. 105    -5 152.0
> >>>>> 2012  19  3   3.9  362. 105    -4 152.0
> >>>>> *Jibrin Adejoh Alhassan (Ph.D)*
> >>>>> Department of Physics and Astronomy,
> >>>>> University of Nigeria, Nsukka
> >>>>>
> >>>>>
> >>>>> On Mon, Jun 17, 2024 at 7:50?AM Jibrin Alhassan <
> >>>> jibrin.alhassan at unn.edu.ng>
> >>>>> wrote:
> >>>>>
> >>>>>> Hello Rui,
> >>>>>> Your patience is indeed amazing. Your script tested as shown below
> >>>> worked
> >>>>>> perfectly well.
> >>>>>> df1 <- read.table(text = "YEAR DOY HR   IMF  SW   SSN    Dst f10.7
> >>>>>> 2012 215  4   5.1  371. 143    -4 138.6 ", header = TRUE)
> >>>>>> with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
> >>>>>> df1$Date <- with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
> >>>>>> df1 <- df1[-(1:2)]
> >>>>>> df1 <- df1[c(ncol(df1), 1:(ncol(df1) - 1L))]
> >>>>>> head(df1).
> >>>>>> But  I have 43,849 data points. Your script only generated one. Help
> >> me
> >>>>>> with a script that can handle the whole data points. I have tried
> >>>> following
> >>>>>> your tested solution but was unsuccessful. My regards.
> >>>>>> *Jibrin Adejoh Alhassan (Ph.D)*
> >>>>>> Department of Physics and Astronomy,
> >>>>>> University of Nigeria, Nsukka
> >>>>>>
> >>>>>>
> >>>>>> On Sun, Jun 16, 2024 at 8:33?AM Rui Barradas <ruipbarradas at sapo.pt>
> >>>> wrote:
> >>>>>>
> >>>>>>> ?s 21:42 de 15/06/2024, Jibrin Alhassan escreveu:
> >>>>>>>> Thank you Rui. I ran the following script
> >>>>>>>> df1 <- read.table("solar_hour", header = TRUE)
> >>>>>>>> df1$date <- as.Date(paste(df1$year, df1$hour),
> >>>>>>>>      format = "%Y %j",
> >>>>>>>> origin = "2012-08-01-0")
> >>>>>>>> df2 <- df1[c("date", "IMF", "SWS", "SSN", "Dst", "f10")]
> >>>>>>>> head(df1)
> >>>>>>>> #To display all the rows
> >>>>>>>>      print(df2).
> >>>>>>>> It gave me this error message
> >>>>>>>>> source ("script.R")
> >>>>>>>> Error in `$<-.data.frame`(`*tmp*`, date, value = numeric(0)) :
> >>>>>>>>       replacement has 0 rows, data has 38735
> >>>>>>>>> print(df2)
> >>>>>>>> Error: object 'df2' not found
> >>>>>>>>> My data is an hourly data but desire to have the date as
> >>>>>>>> year    month    day   hour
> >>>>>>>> 2012   08         01     01
> >>>>>>>> 2012   08         01     02
> >>>>>>>> 2012   08        01      03 etc
> >>>>>>>> Thanks.
> >>>>>>>>
> >>>>>>>> *Jibrin Adejoh Alhassan (Ph.D)*
> >>>>>>>> Department of Physics and Astronomy,
> >>>>>>>> University of Nigeria, Nsukka
> >>>>>>>>
> >>>>>>>>
> >>>>>>>> On Sat, Jun 15, 2024 at 8:34?PM Rui Barradas <
> ruipbarradas at sapo.pt>
> >>>>>>> wrote:
> >>>>>>>>
> >>>>>>>>> ?s 20:00 de 15/06/2024, Jibrin Alhassan escreveu:
> >>>>>>>>>> I have solar-geophysical data e.g as blow:
> >>>>>>>>>> YEAR DOY HR   IMF  SW   SSN    Dst f10.7
> >>>>>>>>>> 2012 214  0   3.4  403. 132    -9 154.6
> >>>>>>>>>> 2012 214  1   3.7  388. 132   -10 154.6
> >>>>>>>>>> 2012 214  2   3.7  383. 132   -10 154.6
> >>>>>>>>>> 2012 214  3   3.7  391. 132    -9 154.6
> >>>>>>>>>> 2012 214  4   4.2  399. 132    -7 154.6
> >>>>>>>>>> 2012 214  5   4.1  411. 132    -6 154.6
> >>>>>>>>>> 2012 214  6   4.0  407. 132    -6 154.6
> >>>>>>>>>> 2012 214  7   4.2  404. 132    -4 154.6
> >>>>>>>>>> 2012 214  8   4.3  405. 132    -6 154.6
> >>>>>>>>>> 2012 214  9   4.4  409. 132    -6 154.6
> >>>>>>>>>> 2012 214 10   4.4  401. 132    -6 154.6
> >>>>>>>>>> 2012 214 11   4.5  385. 132    -7 154.6
> >>>>>>>>>> 2012 214 12   4.7  377. 132    -8 154.6
> >>>>>>>>>> 2012 214 13   4.7  382. 132    -6 154.6
> >>>>>>>>>> 2012 214 14   4.3  396. 132    -4 154.6
> >>>>>>>>>> 2012 214 15   4.1  384. 132    -2 154.6
> >>>>>>>>>> 2012 214 16   4.0  382. 132    -1 154.6
> >>>>>>>>>> 2012 214 17   3.9  397. 132     0 154.6
> >>>>>>>>>> 2012 214 18   3.8  390. 132     1 154.6
> >>>>>>>>>> 2012 214 19   4.2  400. 132     2 154.6
> >>>>>>>>>> 2012 214 20   4.6  408. 132     1 154.6
> >>>>>>>>>> 2012 214 21   4.8  401. 132    -3 154.6
> >>>>>>>>>> 2012 214 22   4.9  395. 132    -5 154.6
> >>>>>>>>>> 2012 214 23   5.0  386. 132    -1 154.6
> >>>>>>>>>> 2012 215  0   5.0  377. 143    -1 138.6
> >>>>>>>>>> 2012 215  1   4.9  384. 143    -2 138.6
> >>>>>>>>>> 2012 215  2   4.9  390. 143    -4 138.6
> >>>>>>>>>> 2012 215  3   4.9  372. 143    -6 138.6
> >>>>>>>>>> 2012 215  4   5.1  371. 143    -4 138.6
> >>>>>>>>>> I want to process it to be of the format as shown below
> >>>>>>>>>>       y   m  d  hr imf  sws  ssn    Dst f10.7
> >>>>>>>>>> 2012-08-01 10 3.4  403. 132    -9 154.6
> >>>>>>>>>> 2012-08-01 12 3.7  388. 132   -10 154.6
> >>>>>>>>>> 2012-08-01 15 3.7  383. 132   -10 154.6
> >>>>>>>>>> 2012-08-01 17 3.7  391. 132    -9 154.6
> >>>>>>>>>> I want to request an R code to accomplish this task. Thanks for
> >> your
> >>>>>>>>> time.
> >>>>>>>>>> *Jibrin Adejoh Alhassan (Ph.D)*
> >>>>>>>>>> Department of Physics and Astronomy,
> >>>>>>>>>> University of Nigeria, Nsukka
> >>>>>>>>>>
> >>>>>>>>>>           [[alternative HTML version deleted]]
> >>>>>>>>>>
> >>>>>>>>>> ______________________________________________
> >>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> >>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>>>> PLEASE do read the posting guide
> >>>>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>>>>> and provide commented, minimal, self-contained, reproducible
> code.
> >>>>>>>>> Hello,
> >>>>>>>>>
> >>>>>>>>> To create a date column, paste the first two columns and coerce
> to
> >>>>>>> class
> >>>>>>>>> "Date" with conversion specifications %Y for the 4 digit year and
> >> %j
> >>>>>>> for
> >>>>>>>>> the day of year. See
> >>>>>>>>>
> >>>>>>>>> help("strptime")
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>> df1 <- read.table(text = "YEAR DOY HR   IMF  SW   SSN    Dst
> f10.7
> >>>>>>>>> 2012 214  0   3.4  403. 132    -9 154.6
> >>>>>>>>> 2012 214  1   3.7  388. 132   -10 154.6
> >>>>>>>>> 2012 214  2   3.7  383. 132   -10 154.6
> >>>>>>>>> 2012 214  3   3.7  391. 132    -9 154.6
> >>>>>>>>> 2012 214  4   4.2  399. 132    -7 154.6
> >>>>>>>>> 2012 214  5   4.1  411. 132    -6 154.6
> >>>>>>>>> 2012 214  6   4.0  407. 132    -6 154.6
> >>>>>>>>> 2012 214  7   4.2  404. 132    -4 154.6
> >>>>>>>>> 2012 214  8   4.3  405. 132    -6 154.6
> >>>>>>>>> 2012 214  9   4.4  409. 132    -6 154.6
> >>>>>>>>> 2012 214 10   4.4  401. 132    -6 154.6
> >>>>>>>>> 2012 214 11   4.5  385. 132    -7 154.6
> >>>>>>>>> 2012 214 12   4.7  377. 132    -8 154.6
> >>>>>>>>> 2012 214 13   4.7  382. 132    -6 154.6
> >>>>>>>>> 2012 214 14   4.3  396. 132    -4 154.6
> >>>>>>>>> 2012 214 15   4.1  384. 132    -2 154.6
> >>>>>>>>> 2012 214 16   4.0  382. 132    -1 154.6
> >>>>>>>>> 2012 214 17   3.9  397. 132     0 154.6
> >>>>>>>>> 2012 214 18   3.8  390. 132     1 154.6
> >>>>>>>>> 2012 214 19   4.2  400. 132     2 154.6
> >>>>>>>>> 2012 214 20   4.6  408. 132     1 154.6
> >>>>>>>>> 2012 214 21   4.8  401. 132    -3 154.6
> >>>>>>>>> 2012 214 22   4.9  395. 132    -5 154.6
> >>>>>>>>> 2012 214 23   5.0  386. 132    -1 154.6
> >>>>>>>>> 2012 215  0   5.0  377. 143    -1 138.6
> >>>>>>>>> 2012 215  1   4.9  384. 143    -2 138.6
> >>>>>>>>> 2012 215  2   4.9  390. 143    -4 138.6
> >>>>>>>>> 2012 215  3   4.9  372. 143    -6 138.6
> >>>>>>>>> 2012 215  4   5.1  371. 143    -4 138.6", header = TRUE)
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>> with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
> >>>>>>>>> #>  [1] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
> >>>>>>> "2012-08-01"
> >>>>>>>>> #>  [6] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
> >>>>>>> "2012-08-01"
> >>>>>>>>> #> [11] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
> >>>>>>> "2012-08-01"
> >>>>>>>>> #> [16] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
> >>>>>>> "2012-08-01"
> >>>>>>>>> #> [21] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
> >>>>>>> "2012-08-02"
> >>>>>>>>> #> [26] "2012-08-02" "2012-08-02" "2012-08-02" "2012-08-02"
> >>>>>>>>>
> >>>>>>>>> # now create the column
> >>>>>>>>> df1$Date <- with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y
> >> %j")
> >>>>>>>>> # remove the columns no longer needed
> >>>>>>>>> df1 <- df1[-(1:2)]
> >>>>>>>>> # relocate the new date column
> >>>>>>>>> df1 <- df1[c(ncol(df1), 1:(ncol(df1) - 1L))]
> >>>>>>>>> head(df1)
> >>>>>>>>> #>         Date HR IMF  SW SSN Dst f10.7
> >>>>>>>>> #> 1 2012-08-01  0 3.4 403 132  -9 154.6
> >>>>>>>>> #> 2 2012-08-01  1 3.7 388 132 -10 154.6
> >>>>>>>>> #> 3 2012-08-01  2 3.7 383 132 -10 154.6
> >>>>>>>>> #> 4 2012-08-01  3 3.7 391 132  -9 154.6
> >>>>>>>>> #> 5 2012-08-01  4 4.2 399 132  -7 154.6
> >>>>>>>>> #> 6 2012-08-01  5 4.1 411 132  -6 154.6
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>> Hope this helps,
> >>>>>>>>>
> >>>>>>>>> Rui Barradas
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>> --
> >>>>>>>>> Este e-mail foi analisado pelo software antiv?rus AVG para
> >> verificar
> >>>> a
> >>>>>>>>> presen?a de v?rus.
> >>>>>>>>> www.avg.com
> >>>>>>>>>
> >>>>>>>>
> >>>>>>> Hello,
> >>>>>>>
> >>>>>>> There is an error in your new code:
> >>>>>>>
> >>>>>>>
> >>>>>>> paste YEAR with DOY, not with HR.
> >>>>>>>
> >>>>>>>
> >>>>>>> As for the rest, is your real data like the one you posted before?
> >>>>>>> If it is then I don't see anything wrong with my (tested) solution.
> >>>>>>>
> >>>>>>>
> >>>>>>> Hope this helps,
> >>>>>>>
> >>>>>>> Rui Barradas
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>> --
> >>>>>>> Este e-mail foi analisado pelo software antiv?rus AVG para
> verificar
> >> a
> >>>>>>> presen?a de v?rus.
> >>>>>>> www.avg.com
> >>>>>>>
> >>>>>>
> >>>>>
> >>>> Hello,
> >>>>
> >>>> I cannot reproduce any error. T is vectorized so I am not
> understanding
> >>>> what you mean by the script only generated one data point.
> >>>> Here is the same code ran on your new data set, the result is as
> >> expected.
> >>>> Note the output of str(). It days that the 1st column is of class
> "Date"
> >>>> so it was created from YEAR and DOY and relocated to the 1st position.
> >>>>
> >>>> Can you post the output of your final df1? Please post
> >>>>
> >>>> head(df1)
> >>>>
> >>>>
> >>>>
> >>>> # new data
> >>>> df1 <- read.table("~/rhelp.txt", header = TRUE)
> >>>>
> >>>> df1$Date <- with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
> >>>> df1 <- df1[-(1:2)]
> >>>> df1 <- df1[c(ncol(df1), 1:(ncol(df1) - 1L))]
> >>>> str(df1)
> >>>> #> 'data.frame':    436 obs. of  7 variables:
> >>>> #>  $ Date : Date, format: "2012-01-01" "2012-01-01" ...
> >>>> #>  $ HR   : int  0 1 2 3 4 5 6 7 8 9 ...
> >>>> #>  $ IMF  : num  4 4.4 4.8 5.4 4.5 4.2 4.7 4.1 3.2 4.3 ...
> >>>> #>  $ SWS  : num  379 386 380 374 369 368 367 361 362 367 ...
> >>>> #>  $ SSN  : int  71 71 71 71 71 71 71 71 71 71 ...
> >>>> #>  $ Dst  : int  -8 -3 -4 -5 -9 -7 -6 -10 -7 -3 ...
> >>>> #>  $ f10.7: num  1000 1000 1000 1000 1000 ...
> >>>> head(df1)
> >>>> #>         Date HR IMF SWS SSN Dst f10.7
> >>>> #> 1 2012-01-01  0 4.0 379  71  -8 999.9
> >>>> #> 2 2012-01-01  1 4.4 386  71  -3 999.9
> >>>> #> 3 2012-01-01  2 4.8 380  71  -4 999.9
> >>>> #> 4 2012-01-01  3 5.4 374  71  -5 999.9
> >>>> #> 5 2012-01-01  4 4.5 369  71  -9 999.9
> >>>> #> 6 2012-01-01  5 4.2 368  71  -7 999.9
> >>>>
> >>>>
> >>>> Hope this helps,
> >>>>
> >>>> Rui Barradas
> >>>>
> >>>>
> >>>> --
> >>>> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
> >>>> presen?a de v?rus.
> >>>> www.avg.com
> >>>>
> >>>
> >> Hello,
> >>
> >> So what's the error? Your output is identical to mine. If the output of
> >> str(df1) is also identical to what I have posted, then everything works
> >> as expected.
> >>
> >> Hope this helps,
> >>
> >> Rui Barradas
> >>
> >>
> >> --
> >> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
> >> presen?a de v?rus.
> >> www.avg.com
> >>
> >
> Hello,
>
> "2012-06-27" is YEAR == 2012 and DOY == 179.
> If that's what you have in the file then there's nothing wrong with that
> output.
>
> And in your last post the df starts in row 4288, is this the problem?
> The code works, so there must be something with the data.
>
> Hope this helps,
>
> Rui Barradas
>
>
> --
> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
> presen?a de v?rus.
> www.avg.com
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Jun 17 22:29:08 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 17 Jun 2024 16:29:08 -0400
Subject: [R] Column names of model.matrix's output with contrast.arg
In-Reply-To: <BF9A5B2B-EE32-409D-BDCD-8CFB85C41054@gmail.com>
References: <2F05BA60-78A6-4FE0-B8CD-14105A2F9BF8@gmail.com>
 <054F7F8A-5406-4A16-A434-43C13C109492@gmail.com>
 <BF9A5B2B-EE32-409D-BDCD-8CFB85C41054@gmail.com>
Message-ID: <5f512f43-8118-4e79-bd28-ab6a59aa9741@gmail.com>

   It's sorta-kinda-obliquely-partially documented in the examples:

zapsmall(cP <- contr.poly(3)) # Linear and Quadratic

output:

             .L         .Q
[1,] -0.7071068  0.4082483
[2,]  0.0000000 -0.8164966
[3,]  0.7071068  0.4082483

FWIW the faux package provides better-named alternatives.


On 2024-06-17 4:25 p.m., Christophe Dutang wrote:
> Thanks for your reply.
> 
> It might good to document the naming convention in ?contrasts. It is hard to understand .L for linear, .Q for quadratic, .C for cubic and ^n for other degrees.
> 
> For contr.sum, we could have used .Sum<level1>, .Sum<level2>?
> 
> Maybe the examples ?model.matrix should use names in dd objects so that we observe when names are dropped.
> 
> Kind regards, Christophe
> 
> 
>> Le 14 juin 2024 ? 11:45, peter dalgaard <pdalgd at gmail.com> a ?crit :
>>
>> You're at the mercy of the various contr.XXX functions. They may or may not set the colnames on the matrices that they generate.
>>
>> The rationales for (not) setting them is not perfectly transparent, but you obviously cannot use level names on contr.poly, so it uses .L, .Q, etc.
>>
>> In MASS, contr.sdif is careful about labeling the columns with the levels that are being diff'ed.
>>
>> For contr.treatment, there is a straightforward connection to 0/1 dummy variables, so level names there are natural.
>>
>> One could use levels in contr.sum and contr.helmert, but it might confuse users that comparisons are with the average of all levels or preceding levels. (It can be quite confusing when coding is +1 for male and -1 for female, so that the gender difference is twice the coefficient.)
>>
>> -pd
>>
>>> On 14 Jun 2024, at 08:12 , Christophe Dutang <dutangc at gmail.com> wrote:
>>>
>>> Dear list,
>>>
>>> Changing the default contrasts used in glm() makes me aware how model.matrix() set column names.
>>>
>>> With default contrasts, model.matrix() use the level values to name the columns. However with other contrasts, model.matrix() use the level indexes. In the documentation, I don?t see anything in the documentation related to this ? It does not seem natural to have such a behavior?
>>>
>>> Any comment is welcome.
>>>
>>> An example is below.
>>>
>>> Kind regards, Christophe
>>>
>>>
>>> #example from ?glm
>>> counts <- c(18,17,15,20,10,20,25,13,12)
>>> outcome <- paste0("O", gl(3,1,9))
>>> treatment <- paste0("T", gl(3,3))
>>>
>>> X3 <- model.matrix(counts ~ outcome + treatment)
>>> X4 <- model.matrix(counts ~ outcome + treatment, contrasts = list("outcome"="contr.sum"))
>>> X5 <- model.matrix(counts ~ outcome + treatment, contrasts = list("outcome"="contr.helmert"))
>>>
>>> #check with original factor
>>> cbind.data.frame(X3, outcome)
>>> cbind.data.frame(X4, outcome)
>>> cbind.data.frame(X5, outcome)
>>>
>>> #same issue with glm
>>> glm.D93 <- glm(counts ~ outcome + treatment, family = poisson())
>>> glm.D94 <- glm(counts ~ outcome + treatment, family = poisson(), contrasts = list("outcome"="contr.sum"))
>>> glm.D95 <- glm(counts ~ outcome + treatment, family = poisson(), contrasts = list("outcome"="contr.helmert"))
>>>
>>> coef(glm.D93)
>>> coef(glm.D94)
>>> coef(glm.D95)
>>>
>>> #check linear predictor
>>> cbind(X3 %*% coef(glm.D93), predict(glm.D93))
>>> cbind(X4 %*% coef(glm.D94), predict(glm.D94))
>>>
>>> -------------------------------------------------
>>> Christophe DUTANG
>>> LJK, Ensimag, Grenoble INP, UGA, France
>>> ILB research fellow
>>> Web: http://dutangc.free.fr
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> -- 
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics
 > E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From j|ox @end|ng |rom mcm@@ter@c@  Mon Jun 17 23:34:07 2024
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Mon, 17 Jun 2024 17:34:07 -0400
Subject: [R] Column names of model.matrix's output with contrast.arg
In-Reply-To: <5f512f43-8118-4e79-bd28-ab6a59aa9741@gmail.com>
References: <2F05BA60-78A6-4FE0-B8CD-14105A2F9BF8@gmail.com>
 <054F7F8A-5406-4A16-A434-43C13C109492@gmail.com>
 <BF9A5B2B-EE32-409D-BDCD-8CFB85C41054@gmail.com>
 <5f512f43-8118-4e79-bd28-ab6a59aa9741@gmail.com>
Message-ID: <80c37b16-1412-4364-b110-c585017c5dab@mcmaster.ca>

Dear Christophe and Ben,

Also see the car package for replacements for contr.treatment(), 
contr.sum(), and contr.helmert() -- e.g., help("contr.Sum", package="car").

These functions have been in the car package for more than two decades, 
and AFAIK, no one uses them (including myself). I didn't write a 
replacement for contr.poly() because the current coefficient labeling 
seemed reasonably transparent.

Best,
  John

-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://www.john-fox.ca/

--
On 2024-06-17 4:29 p.m., Ben Bolker wrote:
> Caution: External email.
> 
> 
>  ? It's sorta-kinda-obliquely-partially documented in the examples:
> 
> zapsmall(cP <- contr.poly(3)) # Linear and Quadratic
> 
> output:
> 
>  ??????????? .L???????? .Q
> [1,] -0.7071068? 0.4082483
> [2,]? 0.0000000 -0.8164966
> [3,]? 0.7071068? 0.4082483
> 
> FWIW the faux package provides better-named alternatives.
> 
> 
> On 2024-06-17 4:25 p.m., Christophe Dutang wrote:
>> Thanks for your reply.
>>
>> It might good to document the naming convention in ?contrasts. It is 
>> hard to understand .L for linear, .Q for quadratic, .C for cubic and 
>> ^n for other degrees.
>>
>> For contr.sum, we could have used .Sum<level1>, .Sum<level2>?
>>
>> Maybe the examples ?model.matrix should use names in dd objects so 
>> that we observe when names are dropped.
>>
>> Kind regards, Christophe
>>
>>
>>> Le 14 juin 2024 ? 11:45, peter dalgaard <pdalgd at gmail.com> a ?crit :
>>>
>>> You're at the mercy of the various contr.XXX functions. They may or 
>>> may not set the colnames on the matrices that they generate.
>>>
>>> The rationales for (not) setting them is not perfectly transparent, 
>>> but you obviously cannot use level names on contr.poly, so it uses 
>>> .L, .Q, etc.
>>>
>>> In MASS, contr.sdif is careful about labeling the columns with the 
>>> levels that are being diff'ed.
>>>
>>> For contr.treatment, there is a straightforward connection to 0/1 
>>> dummy variables, so level names there are natural.
>>>
>>> One could use levels in contr.sum and contr.helmert, but it might 
>>> confuse users that comparisons are with the average of all levels or 
>>> preceding levels. (It can be quite confusing when coding is +1 for 
>>> male and -1 for female, so that the gender difference is twice the 
>>> coefficient.)
>>>
>>> -pd
>>>
>>>> On 14 Jun 2024, at 08:12 , Christophe Dutang <dutangc at gmail.com> wrote:
>>>>
>>>> Dear list,
>>>>
>>>> Changing the default contrasts used in glm() makes me aware how 
>>>> model.matrix() set column names.
>>>>
>>>> With default contrasts, model.matrix() use the level values to name 
>>>> the columns. However with other contrasts, model.matrix() use the 
>>>> level indexes. In the documentation, I don?t see anything in the 
>>>> documentation related to this ? It does not seem natural to have 
>>>> such a behavior?
>>>>
>>>> Any comment is welcome.
>>>>
>>>> An example is below.
>>>>
>>>> Kind regards, Christophe
>>>>
>>>>
>>>> #example from ?glm
>>>> counts <- c(18,17,15,20,10,20,25,13,12)
>>>> outcome <- paste0("O", gl(3,1,9))
>>>> treatment <- paste0("T", gl(3,3))
>>>>
>>>> X3 <- model.matrix(counts ~ outcome + treatment)
>>>> X4 <- model.matrix(counts ~ outcome + treatment, contrasts = 
>>>> list("outcome"="contr.sum"))
>>>> X5 <- model.matrix(counts ~ outcome + treatment, contrasts = 
>>>> list("outcome"="contr.helmert"))
>>>>
>>>> #check with original factor
>>>> cbind.data.frame(X3, outcome)
>>>> cbind.data.frame(X4, outcome)
>>>> cbind.data.frame(X5, outcome)
>>>>
>>>> #same issue with glm
>>>> glm.D93 <- glm(counts ~ outcome + treatment, family = poisson())
>>>> glm.D94 <- glm(counts ~ outcome + treatment, family = poisson(), 
>>>> contrasts = list("outcome"="contr.sum"))
>>>> glm.D95 <- glm(counts ~ outcome + treatment, family = poisson(), 
>>>> contrasts = list("outcome"="contr.helmert"))
>>>>
>>>> coef(glm.D93)
>>>> coef(glm.D94)
>>>> coef(glm.D95)
>>>>
>>>> #check linear predictor
>>>> cbind(X3 %*% coef(glm.D93), predict(glm.D93))
>>>> cbind(X4 %*% coef(glm.D94), predict(glm.D94))
>>>>
>>>> -------------------------------------------------
>>>> Christophe DUTANG
>>>> LJK, Ensimag, Grenoble INP, UGA, France
>>>> ILB research fellow
>>>> Web: http://dutangc.free.fr
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide 
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> -- 
>>> Peter Dalgaard, Professor,
>>> Center for Statistics, Copenhagen Business School
>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>> Phone: (+45)38153501
>>> Office: A 4.23
>>> Email: pd.mes at cbs.dk? Priv: PDalgd at gmail.com
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> (Acting) Graduate chair, Mathematics & Statistics
>  > E-mail is sent at my convenience; I don't expect replies outside of
> working hours.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From g||ted|||e2014 @end|ng |rom gm@||@com  Tue Jun 18 18:13:43 2024
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Tue, 18 Jun 2024 17:13:43 +0100
Subject: [R] I have Problem using the Pipe Command
Message-ID: <CAC8ss33VCxRNb7iQ+6gKpcGu2hiKqqenMAZQ4UAhvaiuHQZVQg@mail.gmail.com>

Greetings to everyone and thank you for your readiness to help.

I have problems using the pipe command (|>).

Once I have it in any script on my system, it won't.

The error message will say:

unexpected '>'
I loaded the two packages below to see if it would handle it. But the
problem remains.
library(magrittr)
library(dplyr)

I searched to see if there was a way to install the command. But I was not
successful.

Please tell me what to do to be able to use the pipe command on my system.
I would be grateful for any help.
Thank you.

Sincerely yours
Ogbos

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Tue Jun 18 18:17:49 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 18 Jun 2024 12:17:49 -0400
Subject: [R] I have Problem using the Pipe Command
In-Reply-To: <CAC8ss33VCxRNb7iQ+6gKpcGu2hiKqqenMAZQ4UAhvaiuHQZVQg@mail.gmail.com>
References: <CAC8ss33VCxRNb7iQ+6gKpcGu2hiKqqenMAZQ4UAhvaiuHQZVQg@mail.gmail.com>
Message-ID: <280fb618-7dfc-475d-b381-5565e0a492fb@gmail.com>

   You probably have to update your R version. The native pipe |> wasn't 
introduced until R version 4.4.  R.version.string (among others) will 
tell you what version you have.

   If you don't want to do that, install and load the 'magrittr' package 
and change |> to %>% everywhere.

On 2024-06-18 12:13 p.m., Ogbos Okike wrote:
> Greetings to everyone and thank you for your readiness to help.
> 
> I have problems using the pipe command (|>).
> 
> Once I have it in any script on my system, it won't.
> 
> The error message will say:
> 
> unexpected '>'
> I loaded the two packages below to see if it would handle it. But the
> problem remains.
> library(magrittr)
> library(dplyr)
> 
> I searched to see if there was a way to install the command. But I was not
> successful.
> 
> Please tell me what to do to be able to use the pipe command on my system.
> I would be grateful for any help.
> Thank you.
> 
> Sincerely yours
> Ogbos
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |kw@|mmo @end|ng |rom gm@||@com  Tue Jun 18 18:17:44 2024
From: |kw@|mmo @end|ng |rom gm@||@com (Iris Simmons)
Date: Tue, 18 Jun 2024 12:17:44 -0400
Subject: [R] I have Problem using the Pipe Command
In-Reply-To: <CAC8ss33VCxRNb7iQ+6gKpcGu2hiKqqenMAZQ4UAhvaiuHQZVQg@mail.gmail.com>
References: <CAC8ss33VCxRNb7iQ+6gKpcGu2hiKqqenMAZQ4UAhvaiuHQZVQg@mail.gmail.com>
Message-ID: <CADNULg9pyDoqG_rWjwQbqCnVA06JuXrouL4ZdX_irSux2qBhGQ@mail.gmail.com>

My guess would be that you're using an older version of R. The pipe was
added in R 4.1. It cannot be used in earlier versions as the syntax is
invalid. You could use the dplyr pipe if you want further back
compatibility.

On Tue, Jun 18, 2024, 12:14 Ogbos Okike <giftedlife2014 at gmail.com> wrote:

> Greetings to everyone and thank you for your readiness to help.
>
> I have problems using the pipe command (|>).
>
> Once I have it in any script on my system, it won't.
>
> The error message will say:
>
> unexpected '>'
> I loaded the two packages below to see if it would handle it. But the
> problem remains.
> library(magrittr)
> library(dplyr)
>
> I searched to see if there was a way to install the command. But I was not
> successful.
>
> Please tell me what to do to be able to use the pipe command on my system.
> I would be grateful for any help.
> Thank you.
>
> Sincerely yours
> Ogbos
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Jun 18 18:25:49 2024
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 18 Jun 2024 12:25:49 -0400
Subject: [R] I have Problem using the Pipe Command
In-Reply-To: <280fb618-7dfc-475d-b381-5565e0a492fb@gmail.com>
References: <CAC8ss33VCxRNb7iQ+6gKpcGu2hiKqqenMAZQ4UAhvaiuHQZVQg@mail.gmail.com>
 <280fb618-7dfc-475d-b381-5565e0a492fb@gmail.com>
Message-ID: <87d69a81-708e-4cf9-8d77-ba8936874099@gmail.com>

On 2024-06-18 12:17 p.m., Ben Bolker wrote:
>     You probably have to update your R version. The native pipe |> wasn't
> introduced until R version 4.4.  R.version.string (among others) will
> tell you what version you have.

Typo: it was introduced in R 4.1.0.

Another possible problem is with line breaks.  This works:

  1:10 |>
  mean()

but this fails:

  1:10
  |> mean()

Duncan Murdoch

> 
>     If you don't want to do that, install and load the 'magrittr' package
> and change |> to %>% everywhere.
> 
> On 2024-06-18 12:13 p.m., Ogbos Okike wrote:
>> Greetings to everyone and thank you for your readiness to help.
>>
>> I have problems using the pipe command (|>).
>>
>> Once I have it in any script on my system, it won't.
>>
>> The error message will say:
>>
>> unexpected '>'
>> I loaded the two packages below to see if it would handle it. But the
>> problem remains.
>> library(magrittr)
>> library(dplyr)
>>
>> I searched to see if there was a way to install the command. But I was not
>> successful.
>>
>> Please tell me what to do to be able to use the pipe command on my system.
>> I would be grateful for any help.
>> Thank you.
>>
>> Sincerely yours
>> Ogbos
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From g||ted|||e2014 @end|ng |rom gm@||@com  Tue Jun 18 18:39:01 2024
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Tue, 18 Jun 2024 17:39:01 +0100
Subject: [R] I have Problem using the Pipe Command
In-Reply-To: <280fb618-7dfc-475d-b381-5565e0a492fb@gmail.com>
References: <CAC8ss33VCxRNb7iQ+6gKpcGu2hiKqqenMAZQ4UAhvaiuHQZVQg@mail.gmail.com>
 <280fb618-7dfc-475d-b381-5565e0a492fb@gmail.com>
Message-ID: <CAC8ss33cCsK+6n9mzEpbr=7Gz3JUpKTxU5=__ckt9gXOK3xzmg@mail.gmail.com>

Yes, Ben and others. Many thanks for your swift response. I have quickly
installed the 'magrittr' package. It was installed successfully.

But I tried to edit it using EDIT(magrittr). But it didn't work.

Please, guide me further on how to edit it.

Thank you very much.
Ogbos

On Tue, Jun 18, 2024 at 5:18?PM Ben Bolker <bbolker at gmail.com> wrote:

>    You probably have to update your R version. The native pipe |> wasn't
> introduced until R version 4.4.  R.version.string (among others) will
> tell you what version you have.
>
>    If you don't want to do that, install and load the 'magrittr' package
> and change |> to %>% everywhere.
>
> On 2024-06-18 12:13 p.m., Ogbos Okike wrote:
> > Greetings to everyone and thank you for your readiness to help.
> >
> > I have problems using the pipe command (|>).
> >
> > Once I have it in any script on my system, it won't.
> >
> > The error message will say:
> >
> > unexpected '>'
> > I loaded the two packages below to see if it would handle it. But the
> > problem remains.
> > library(magrittr)
> > library(dplyr)
> >
> > I searched to see if there was a way to install the command. But I was
> not
> > successful.
> >
> > Please tell me what to do to be able to use the pipe command on my
> system.
> > I would be grateful for any help.
> > Thank you.
> >
> > Sincerely yours
> > Ogbos
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From g||ted|||e2014 @end|ng |rom gm@||@com  Tue Jun 18 18:43:49 2024
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Tue, 18 Jun 2024 17:43:49 +0100
Subject: [R] I have Problem using the Pipe Command
In-Reply-To: <87d69a81-708e-4cf9-8d77-ba8936874099@gmail.com>
References: <CAC8ss33VCxRNb7iQ+6gKpcGu2hiKqqenMAZQ4UAhvaiuHQZVQg@mail.gmail.com>
 <280fb618-7dfc-475d-b381-5565e0a492fb@gmail.com>
 <87d69a81-708e-4cf9-8d77-ba8936874099@gmail.com>
Message-ID: <CAC8ss31j9YvT+aPZOr5YNqpN0hgq17e4q2q6xKZqoULKU=vMow@mail.gmail.com>

Thanks, Duncan for contributing. I quickly tried entering the command on a
new line. But the error pointed specifically to the point. It didn't run.
Best regards
Ogbos

On Tue, Jun 18, 2024 at 5:38?PM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 2024-06-18 12:17 p.m., Ben Bolker wrote:
> >     You probably have to update your R version. The native pipe |> wasn't
> > introduced until R version 4.4.  R.version.string (among others) will
> > tell you what version you have.
>
> Typo: it was introduced in R 4.1.0.
>
> Another possible problem is with line breaks.  This works:
>
>   1:10 |>
>   mean()
>
> but this fails:
>
>   1:10
>   |> mean()
>
> Duncan Murdoch
>
> >
> >     If you don't want to do that, install and load the 'magrittr' package
> > and change |> to %>% everywhere.
> >
> > On 2024-06-18 12:13 p.m., Ogbos Okike wrote:
> >> Greetings to everyone and thank you for your readiness to help.
> >>
> >> I have problems using the pipe command (|>).
> >>
> >> Once I have it in any script on my system, it won't.
> >>
> >> The error message will say:
> >>
> >> unexpected '>'
> >> I loaded the two packages below to see if it would handle it. But the
> >> problem remains.
> >> library(magrittr)
> >> library(dplyr)
> >>
> >> I searched to see if there was a way to install the command. But I was
> not
> >> successful.
> >>
> >> Please tell me what to do to be able to use the pipe command on my
> system.
> >> I would be grateful for any help.
> >> Thank you.
> >>
> >> Sincerely yours
> >> Ogbos
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Tue Jun 18 21:30:33 2024
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 18 Jun 2024 22:30:33 +0300
Subject: [R] I have Problem using the Pipe Command
In-Reply-To: <CAC8ss31j9YvT+aPZOr5YNqpN0hgq17e4q2q6xKZqoULKU=vMow@mail.gmail.com>
References: <CAC8ss33VCxRNb7iQ+6gKpcGu2hiKqqenMAZQ4UAhvaiuHQZVQg@mail.gmail.com>
 <280fb618-7dfc-475d-b381-5565e0a492fb@gmail.com>
 <87d69a81-708e-4cf9-8d77-ba8936874099@gmail.com>
 <CAC8ss31j9YvT+aPZOr5YNqpN0hgq17e4q2q6xKZqoULKU=vMow@mail.gmail.com>
Message-ID: <CAGgJW76FWrOBJpOpB1cy3c551YTgbEFgGtaTa3ojkZpSVE3u_w@mail.gmail.com>

Please show the output of
> sessionInfo()


On Tue, Jun 18, 2024 at 7:49?PM Ogbos Okike <giftedlife2014 at gmail.com>
wrote:

> Thanks, Duncan for contributing. I quickly tried entering the command on a
> new line. But the error pointed specifically to the point. It didn't run.
> Best regards
> Ogbos
>
> On Tue, Jun 18, 2024 at 5:38?PM Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>
> > On 2024-06-18 12:17 p.m., Ben Bolker wrote:
> > >     You probably have to update your R version. The native pipe |>
> wasn't
> > > introduced until R version 4.4.  R.version.string (among others) will
> > > tell you what version you have.
> >
> > Typo: it was introduced in R 4.1.0.
> >
> > Another possible problem is with line breaks.  This works:
> >
> >   1:10 |>
> >   mean()
> >
> > but this fails:
> >
> >   1:10
> >   |> mean()
> >
> > Duncan Murdoch
> >
> > >
> > >     If you don't want to do that, install and load the 'magrittr'
> package
> > > and change |> to %>% everywhere.
> > >
> > > On 2024-06-18 12:13 p.m., Ogbos Okike wrote:
> > >> Greetings to everyone and thank you for your readiness to help.
> > >>
> > >> I have problems using the pipe command (|>).
> > >>
> > >> Once I have it in any script on my system, it won't.
> > >>
> > >> The error message will say:
> > >>
> > >> unexpected '>'
> > >> I loaded the two packages below to see if it would handle it. But the
> > >> problem remains.
> > >> library(magrittr)
> > >> library(dplyr)
> > >>
> > >> I searched to see if there was a way to install the command. But I was
> > not
> > >> successful.
> > >>
> > >> Please tell me what to do to be able to use the pipe command on my
> > system.
> > >> I would be grateful for any help.
> > >> Thank you.
> > >>
> > >> Sincerely yours
> > >> Ogbos
> > >>
> > >>      [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Wed Jun 19 08:52:03 2024
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 19 Jun 2024 09:52:03 +0300
Subject: [R] I have Problem using the Pipe Command
In-Reply-To: <CAC8ss30x8x4v2_zzoDaaFzrz5b-9XDq8YTzATjV_wKysF_rASA@mail.gmail.com>
References: <CAC8ss33VCxRNb7iQ+6gKpcGu2hiKqqenMAZQ4UAhvaiuHQZVQg@mail.gmail.com>
 <280fb618-7dfc-475d-b381-5565e0a492fb@gmail.com>
 <87d69a81-708e-4cf9-8d77-ba8936874099@gmail.com>
 <CAC8ss31j9YvT+aPZOr5YNqpN0hgq17e4q2q6xKZqoULKU=vMow@mail.gmail.com>
 <CAGgJW76FWrOBJpOpB1cy3c551YTgbEFgGtaTa3ojkZpSVE3u_w@mail.gmail.com>
 <CAC8ss30x8x4v2_zzoDaaFzrz5b-9XDq8YTzATjV_wKysF_rASA@mail.gmail.com>
Message-ID: <CAGgJW75MUAG9zOsV-WxK+L6VKVw5kWVhX=S592oN_GWZoYCP6A@mail.gmail.com>

In your R session do

library(magrittr)
1:10 %>% sum()

This should output 55.
If that does not work send the results, include the output of sessionInfo()
showing that you have loaded magrittr.



On Wed, Jun 19, 2024 at 9:43?AM Ogbos Okike <giftedlife2014 at gmail.com>
wrote:

> Dear Eric,
> Good morning from Nigeria.
>
> Please, see the output of the session below:
>
> > sessionInfo()
> R version 3.4.4 (2018-03-15)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 18.04.6 LTS
>
> Matrix products: default
> BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.7.1
> LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.7.1
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.4.4
>
> On Tue, Jun 18, 2024 at 8:31?PM Eric Berger <ericjberger at gmail.com> wrote:
>
>> Please show the output of
>> > sessionInfo()
>>
>>
>> On Tue, Jun 18, 2024 at 7:49?PM Ogbos Okike <giftedlife2014 at gmail.com>
>> wrote:
>>
>>> Thanks, Duncan for contributing. I quickly tried entering the command on
>>> a
>>> new line. But the error pointed specifically to the point. It didn't run.
>>> Best regards
>>> Ogbos
>>>
>>> On Tue, Jun 18, 2024 at 5:38?PM Duncan Murdoch <murdoch.duncan at gmail.com
>>> >
>>> wrote:
>>>
>>> > On 2024-06-18 12:17 p.m., Ben Bolker wrote:
>>> > >     You probably have to update your R version. The native pipe |>
>>> wasn't
>>> > > introduced until R version 4.4.  R.version.string (among others) will
>>> > > tell you what version you have.
>>> >
>>> > Typo: it was introduced in R 4.1.0.
>>> >
>>> > Another possible problem is with line breaks.  This works:
>>> >
>>> >   1:10 |>
>>> >   mean()
>>> >
>>> > but this fails:
>>> >
>>> >   1:10
>>> >   |> mean()
>>> >
>>> > Duncan Murdoch
>>> >
>>> > >
>>> > >     If you don't want to do that, install and load the 'magrittr'
>>> package
>>> > > and change |> to %>% everywhere.
>>> > >
>>> > > On 2024-06-18 12:13 p.m., Ogbos Okike wrote:
>>> > >> Greetings to everyone and thank you for your readiness to help.
>>> > >>
>>> > >> I have problems using the pipe command (|>).
>>> > >>
>>> > >> Once I have it in any script on my system, it won't.
>>> > >>
>>> > >> The error message will say:
>>> > >>
>>> > >> unexpected '>'
>>> > >> I loaded the two packages below to see if it would handle it. But
>>> the
>>> > >> problem remains.
>>> > >> library(magrittr)
>>> > >> library(dplyr)
>>> > >>
>>> > >> I searched to see if there was a way to install the command. But I
>>> was
>>> > not
>>> > >> successful.
>>> > >>
>>> > >> Please tell me what to do to be able to use the pipe command on my
>>> > system.
>>> > >> I would be grateful for any help.
>>> > >> Thank you.
>>> > >>
>>> > >> Sincerely yours
>>> > >> Ogbos
>>> > >>
>>> > >>      [[alternative HTML version deleted]]
>>> > >>
>>> > >> ______________________________________________
>>> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > >> https://stat.ethz.ch/mailman/listinfo/r-help
>>> > >> PLEASE do read the posting guide
>>> > http://www.R-project.org/posting-guide.html
>>> > >> and provide commented, minimal, self-contained, reproducible code.
>>> > >
>>> > > ______________________________________________
>>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > > PLEASE do read the posting guide
>>> > http://www.R-project.org/posting-guide.html
>>> > > and provide commented, minimal, self-contained, reproducible code.
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> > http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Wed Jun 19 09:27:39 2024
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 19 Jun 2024 10:27:39 +0300
Subject: [R] I have Problem using the Pipe Command
In-Reply-To: <CAC8ss30ZPKzesiAZFkWa4+3bpzU6B7ikjqxjSa+Yoe4RJWc-WA@mail.gmail.com>
References: <CAC8ss33VCxRNb7iQ+6gKpcGu2hiKqqenMAZQ4UAhvaiuHQZVQg@mail.gmail.com>
 <280fb618-7dfc-475d-b381-5565e0a492fb@gmail.com>
 <87d69a81-708e-4cf9-8d77-ba8936874099@gmail.com>
 <CAC8ss31j9YvT+aPZOr5YNqpN0hgq17e4q2q6xKZqoULKU=vMow@mail.gmail.com>
 <CAGgJW76FWrOBJpOpB1cy3c551YTgbEFgGtaTa3ojkZpSVE3u_w@mail.gmail.com>
 <CAC8ss30x8x4v2_zzoDaaFzrz5b-9XDq8YTzATjV_wKysF_rASA@mail.gmail.com>
 <CAGgJW75MUAG9zOsV-WxK+L6VKVw5kWVhX=S592oN_GWZoYCP6A@mail.gmail.com>
 <CAC8ss30ZPKzesiAZFkWa4+3bpzU6B7ikjqxjSa+Yoe4RJWc-WA@mail.gmail.com>
Message-ID: <CAGgJW77XvqT6PuxfteJ+EtNqp1TwPiQoMcQZNRvSjcdTaL2dGQ@mail.gmail.com>

So all is good. You are successfully using the R pipe %>%  (before it
became part of R).
If you want to use the newer pipe that is part of R, i.e. |> instead of %>%
you will have to install a more recent version of R.
Your previous email with sessionInfo() showed that you are using R version
3.4.4 from 2018.
As other people have already told you, you will need to install R version
4.1.0 or later.

Good luck


On Wed, Jun 19, 2024 at 10:00?AM Ogbos Okike <giftedlife2014 at gmail.com>
wrote:

> The output of the command is, indeed, 55. See below:
>
> > library(magrittr)
> > 1:10 %>% sum()
> [1] 55
>
> On Wed, Jun 19, 2024 at 7:52?AM Eric Berger <ericjberger at gmail.com> wrote:
>
>> In your R session do
>>
>> library(magrittr)
>> 1:10 %>% sum()
>>
>> This should output 55.
>> If that does not work send the results, include the output of
>> sessionInfo() showing that you have loaded magrittr.
>>
>>
>>
>> On Wed, Jun 19, 2024 at 9:43?AM Ogbos Okike <giftedlife2014 at gmail.com>
>> wrote:
>>
>>> Dear Eric,
>>> Good morning from Nigeria.
>>>
>>> Please, see the output of the session below:
>>>
>>> > sessionInfo()
>>> R version 3.4.4 (2018-03-15)
>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>> Running under: Ubuntu 18.04.6 LTS
>>>
>>> Matrix products: default
>>> BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.7.1
>>> LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.7.1
>>>
>>> locale:
>>>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> loaded via a namespace (and not attached):
>>> [1] compiler_3.4.4
>>>
>>> On Tue, Jun 18, 2024 at 8:31?PM Eric Berger <ericjberger at gmail.com>
>>> wrote:
>>>
>>>> Please show the output of
>>>> > sessionInfo()
>>>>
>>>>
>>>> On Tue, Jun 18, 2024 at 7:49?PM Ogbos Okike <giftedlife2014 at gmail.com>
>>>> wrote:
>>>>
>>>>> Thanks, Duncan for contributing. I quickly tried entering the command
>>>>> on a
>>>>> new line. But the error pointed specifically to the point. It didn't
>>>>> run.
>>>>> Best regards
>>>>> Ogbos
>>>>>
>>>>> On Tue, Jun 18, 2024 at 5:38?PM Duncan Murdoch <
>>>>> murdoch.duncan at gmail.com>
>>>>> wrote:
>>>>>
>>>>> > On 2024-06-18 12:17 p.m., Ben Bolker wrote:
>>>>> > >     You probably have to update your R version. The native pipe |>
>>>>> wasn't
>>>>> > > introduced until R version 4.4.  R.version.string (among others)
>>>>> will
>>>>> > > tell you what version you have.
>>>>> >
>>>>> > Typo: it was introduced in R 4.1.0.
>>>>> >
>>>>> > Another possible problem is with line breaks.  This works:
>>>>> >
>>>>> >   1:10 |>
>>>>> >   mean()
>>>>> >
>>>>> > but this fails:
>>>>> >
>>>>> >   1:10
>>>>> >   |> mean()
>>>>> >
>>>>> > Duncan Murdoch
>>>>> >
>>>>> > >
>>>>> > >     If you don't want to do that, install and load the 'magrittr'
>>>>> package
>>>>> > > and change |> to %>% everywhere.
>>>>> > >
>>>>> > > On 2024-06-18 12:13 p.m., Ogbos Okike wrote:
>>>>> > >> Greetings to everyone and thank you for your readiness to help.
>>>>> > >>
>>>>> > >> I have problems using the pipe command (|>).
>>>>> > >>
>>>>> > >> Once I have it in any script on my system, it won't.
>>>>> > >>
>>>>> > >> The error message will say:
>>>>> > >>
>>>>> > >> unexpected '>'
>>>>> > >> I loaded the two packages below to see if it would handle it. But
>>>>> the
>>>>> > >> problem remains.
>>>>> > >> library(magrittr)
>>>>> > >> library(dplyr)
>>>>> > >>
>>>>> > >> I searched to see if there was a way to install the command. But
>>>>> I was
>>>>> > not
>>>>> > >> successful.
>>>>> > >>
>>>>> > >> Please tell me what to do to be able to use the pipe command on my
>>>>> > system.
>>>>> > >> I would be grateful for any help.
>>>>> > >> Thank you.
>>>>> > >>
>>>>> > >> Sincerely yours
>>>>> > >> Ogbos
>>>>> > >>
>>>>> > >>      [[alternative HTML version deleted]]
>>>>> > >>
>>>>> > >> ______________________________________________
>>>>> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> > >> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> > >> PLEASE do read the posting guide
>>>>> > http://www.R-project.org/posting-guide.html
>>>>> > >> and provide commented, minimal, self-contained, reproducible code.
>>>>> > >
>>>>> > > ______________________________________________
>>>>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> > > PLEASE do read the posting guide
>>>>> > http://www.R-project.org/posting-guide.html
>>>>> > > and provide commented, minimal, self-contained, reproducible code.
>>>>> >
>>>>> > ______________________________________________
>>>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> > PLEASE do read the posting guide
>>>>> > http://www.R-project.org/posting-guide.html
>>>>> > and provide commented, minimal, self-contained, reproducible code.
>>>>> >
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>

	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Wed Jun 19 09:32:19 2024
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Wed, 19 Jun 2024 09:32:19 +0200
Subject: [R] I have Problem using the Pipe Command
In-Reply-To: <87d69a81-708e-4cf9-8d77-ba8936874099@gmail.com>
References: <CAC8ss33VCxRNb7iQ+6gKpcGu2hiKqqenMAZQ4UAhvaiuHQZVQg@mail.gmail.com>
 <280fb618-7dfc-475d-b381-5565e0a492fb@gmail.com>
 <87d69a81-708e-4cf9-8d77-ba8936874099@gmail.com>
Message-ID: <26226.35203.8166.862725@stat.math.ethz.ch>

>>>>> Duncan Murdoch 
>>>>>     on Tue, 18 Jun 2024 12:25:49 -0400 writes:

    > On 2024-06-18 12:17 p.m., Ben Bolker wrote:
    >> You probably have to update your R version. The native pipe |> wasn't
    >> introduced until R version 4.4.  R.version.string (among others) will
    >> tell you what version you have.

    > Typo: it was introduced in R 4.1.0.

    > Another possible problem is with line breaks.  This works:

    > 1:10 |>
    > mean()

    > but this fails:

    > 1:10
    > |> mean()

    > Duncan Murdoch

Yes, of course (as I know you know), the same way that

    >  1:10
    >  + 1

does "not" work.



    >> If you don't want to do that, install and load the 'magrittr' package
    >> and change |> to %>% everywhere.

I really think that in June 2024  you (Ogbos) should not run
"productively" an R version that is older than May 2021 (where R
4.1.0 was released) :

  $ R-4.1.0 --version | head 1
  R version 4.1.0 (2021-05-18) -- "Camp Pontanezen"

  $ R-4.1.0 --vanilla -s -e '1:10|>sum()' 
  [1] 55
  $ 

So upgrading your R to current (R 4.4.1)  is *very* much recommended.

Martin Maechler


    >> On 2024-06-18 12:13 p.m., Ogbos Okike wrote:
    >>> Greetings to everyone and thank you for your readiness to help.
    >>> 
    >>> I have problems using the pipe command (|>).
    >>> 
    >>> Once I have it in any script on my system, it won't.
    >>> 
    >>> The error message will say:
    >>> 
    >>> unexpected '>'
    >>> I loaded the two packages below to see if it would handle it. But the
    >>> problem remains.
    >>> library(magrittr)
    >>> library(dplyr)
    >>> 
    >>> I searched to see if there was a way to install the command. But I was not
    >>> successful.
    >>> 
    >>> Please tell me what to do to be able to use the pipe command on my system.
    >>> I would be grateful for any help.
    >>> Thank you.
    >>> 
    >>> Sincerely yours
    >>> Ogbos
    >>> 
    >>> [[alternative HTML version deleted]]
    >>> 
    >>> ______________________________________________
    >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >>> https://stat.ethz.ch/mailman/listinfo/r-help
    >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >>> and provide commented, minimal, self-contained, reproducible code.
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From g||ted|||e2014 @end|ng |rom gm@||@com  Wed Jun 19 09:38:05 2024
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Wed, 19 Jun 2024 08:38:05 +0100
Subject: [R] I have Problem using the Pipe Command: PROBLEM SOLVED!
In-Reply-To: <CAGgJW77XvqT6PuxfteJ+EtNqp1TwPiQoMcQZNRvSjcdTaL2dGQ@mail.gmail.com>
References: <CAC8ss33VCxRNb7iQ+6gKpcGu2hiKqqenMAZQ4UAhvaiuHQZVQg@mail.gmail.com>
 <280fb618-7dfc-475d-b381-5565e0a492fb@gmail.com>
 <87d69a81-708e-4cf9-8d77-ba8936874099@gmail.com>
 <CAC8ss31j9YvT+aPZOr5YNqpN0hgq17e4q2q6xKZqoULKU=vMow@mail.gmail.com>
 <CAGgJW76FWrOBJpOpB1cy3c551YTgbEFgGtaTa3ojkZpSVE3u_w@mail.gmail.com>
 <CAC8ss30x8x4v2_zzoDaaFzrz5b-9XDq8YTzATjV_wKysF_rASA@mail.gmail.com>
 <CAGgJW75MUAG9zOsV-WxK+L6VKVw5kWVhX=S592oN_GWZoYCP6A@mail.gmail.com>
 <CAC8ss30ZPKzesiAZFkWa4+3bpzU6B7ikjqxjSa+Yoe4RJWc-WA@mail.gmail.com>
 <CAGgJW77XvqT6PuxfteJ+EtNqp1TwPiQoMcQZNRvSjcdTaL2dGQ@mail.gmail.com>
Message-ID: <CAC8ss30jHojTj+kXCAEvkR-F9Y_ZNicZhEzhg2+qi7rvcUuxWQ@mail.gmail.com>

Dear Eric,
This is too great! I quickly changed |> to %>% and it worked like margic.
Ben suggested that earlier but I thought I had to open the installed
'magrittr' with gedit in order to edit it.

Following your pointers now, I simply changed the |> in my code to %>% to I
have great success and peace.

Thank you very much.

Thanks too to all others who assisted.

Best regards
Ogbos

On Wed, Jun 19, 2024 at 8:28?AM Eric Berger <ericjberger at gmail.com> wrote:

> So all is good. You are successfully using the R pipe %>%  (before it
> became part of R).
> If you want to use the newer pipe that is part of R, i.e. |> instead of
> %>% you will have to install a more recent version of R.
> Your previous email with sessionInfo() showed that you are using R version
> 3.4.4 from 2018.
> As other people have already told you, you will need to install R version
> 4.1.0 or later.
>
> Good luck
>
>
> On Wed, Jun 19, 2024 at 10:00?AM Ogbos Okike <giftedlife2014 at gmail.com>
> wrote:
>
>> The output of the command is, indeed, 55. See below:
>>
>> > library(magrittr)
>> > 1:10 %>% sum()
>> [1] 55
>>
>> On Wed, Jun 19, 2024 at 7:52?AM Eric Berger <ericjberger at gmail.com>
>> wrote:
>>
>>> In your R session do
>>>
>>> library(magrittr)
>>> 1:10 %>% sum()
>>>
>>> This should output 55.
>>> If that does not work send the results, include the output of
>>> sessionInfo() showing that you have loaded magrittr.
>>>
>>>
>>>
>>> On Wed, Jun 19, 2024 at 9:43?AM Ogbos Okike <giftedlife2014 at gmail.com>
>>> wrote:
>>>
>>>> Dear Eric,
>>>> Good morning from Nigeria.
>>>>
>>>> Please, see the output of the session below:
>>>>
>>>> > sessionInfo()
>>>> R version 3.4.4 (2018-03-15)
>>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>>> Running under: Ubuntu 18.04.6 LTS
>>>>
>>>> Matrix products: default
>>>> BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.7.1
>>>> LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.7.1
>>>>
>>>> locale:
>>>>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>>>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>>>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>>>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] compiler_3.4.4
>>>>
>>>> On Tue, Jun 18, 2024 at 8:31?PM Eric Berger <ericjberger at gmail.com>
>>>> wrote:
>>>>
>>>>> Please show the output of
>>>>> > sessionInfo()
>>>>>
>>>>>
>>>>> On Tue, Jun 18, 2024 at 7:49?PM Ogbos Okike <giftedlife2014 at gmail.com>
>>>>> wrote:
>>>>>
>>>>>> Thanks, Duncan for contributing. I quickly tried entering the command
>>>>>> on a
>>>>>> new line. But the error pointed specifically to the point. It didn't
>>>>>> run.
>>>>>> Best regards
>>>>>> Ogbos
>>>>>>
>>>>>> On Tue, Jun 18, 2024 at 5:38?PM Duncan Murdoch <
>>>>>> murdoch.duncan at gmail.com>
>>>>>> wrote:
>>>>>>
>>>>>> > On 2024-06-18 12:17 p.m., Ben Bolker wrote:
>>>>>> > >     You probably have to update your R version. The native pipe
>>>>>> |> wasn't
>>>>>> > > introduced until R version 4.4.  R.version.string (among others)
>>>>>> will
>>>>>> > > tell you what version you have.
>>>>>> >
>>>>>> > Typo: it was introduced in R 4.1.0.
>>>>>> >
>>>>>> > Another possible problem is with line breaks.  This works:
>>>>>> >
>>>>>> >   1:10 |>
>>>>>> >   mean()
>>>>>> >
>>>>>> > but this fails:
>>>>>> >
>>>>>> >   1:10
>>>>>> >   |> mean()
>>>>>> >
>>>>>> > Duncan Murdoch
>>>>>> >
>>>>>> > >
>>>>>> > >     If you don't want to do that, install and load the 'magrittr'
>>>>>> package
>>>>>> > > and change |> to %>% everywhere.
>>>>>> > >
>>>>>> > > On 2024-06-18 12:13 p.m., Ogbos Okike wrote:
>>>>>> > >> Greetings to everyone and thank you for your readiness to help.
>>>>>> > >>
>>>>>> > >> I have problems using the pipe command (|>).
>>>>>> > >>
>>>>>> > >> Once I have it in any script on my system, it won't.
>>>>>> > >>
>>>>>> > >> The error message will say:
>>>>>> > >>
>>>>>> > >> unexpected '>'
>>>>>> > >> I loaded the two packages below to see if it would handle it.
>>>>>> But the
>>>>>> > >> problem remains.
>>>>>> > >> library(magrittr)
>>>>>> > >> library(dplyr)
>>>>>> > >>
>>>>>> > >> I searched to see if there was a way to install the command. But
>>>>>> I was
>>>>>> > not
>>>>>> > >> successful.
>>>>>> > >>
>>>>>> > >> Please tell me what to do to be able to use the pipe command on
>>>>>> my
>>>>>> > system.
>>>>>> > >> I would be grateful for any help.
>>>>>> > >> Thank you.
>>>>>> > >>
>>>>>> > >> Sincerely yours
>>>>>> > >> Ogbos
>>>>>> > >>
>>>>>> > >>      [[alternative HTML version deleted]]
>>>>>> > >>
>>>>>> > >> ______________________________________________
>>>>>> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>>>>> see
>>>>>> > >> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> > >> PLEASE do read the posting guide
>>>>>> > http://www.R-project.org/posting-guide.html
>>>>>> > >> and provide commented, minimal, self-contained, reproducible
>>>>>> code.
>>>>>> > >
>>>>>> > > ______________________________________________
>>>>>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> > > PLEASE do read the posting guide
>>>>>> > http://www.R-project.org/posting-guide.html
>>>>>> > > and provide commented, minimal, self-contained, reproducible code.
>>>>>> >
>>>>>> > ______________________________________________
>>>>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> > PLEASE do read the posting guide
>>>>>> > http://www.R-project.org/posting-guide.html
>>>>>> > and provide commented, minimal, self-contained, reproducible code.
>>>>>> >
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>

	[[alternative HTML version deleted]]


From g||ted|||e2014 @end|ng |rom gm@||@com  Wed Jun 19 09:48:35 2024
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Wed, 19 Jun 2024 08:48:35 +0100
Subject: [R] I have Problem using the Pipe Command
In-Reply-To: <26226.35203.8166.862725@stat.math.ethz.ch>
References: <CAC8ss33VCxRNb7iQ+6gKpcGu2hiKqqenMAZQ4UAhvaiuHQZVQg@mail.gmail.com>
 <280fb618-7dfc-475d-b381-5565e0a492fb@gmail.com>
 <87d69a81-708e-4cf9-8d77-ba8936874099@gmail.com>
 <26226.35203.8166.862725@stat.math.ethz.ch>
Message-ID: <CAC8ss3015wumsvaffr6DVcmDuh-cCJaQrT2czwtvAFZ0UbPMkA@mail.gmail.com>

Dear Martin,
I agree with you. I am anxious to upgrade. But I am afraid of losing some
data on my only one system. I do not have enough backup.

I am planning to buy a backup laptop before venturing to upgrade.

But if there is any possibility of upgrading without losing my
documents/data, I would gladly go with that.

Please let me know whether it is possible.

Many thanks for your time.

Warm regards
Ogbos

On Wed, Jun 19, 2024 at 8:38?AM Martin Maechler <maechler at stat.math.ethz.ch>
wrote:

> >>>>> Duncan Murdoch
> >>>>>     on Tue, 18 Jun 2024 12:25:49 -0400 writes:
>
>     > On 2024-06-18 12:17 p.m., Ben Bolker wrote:
>     >> You probably have to update your R version. The native pipe |>
> wasn't
>     >> introduced until R version 4.4.  R.version.string (among others)
> will
>     >> tell you what version you have.
>
>     > Typo: it was introduced in R 4.1.0.
>
>     > Another possible problem is with line breaks.  This works:
>
>     > 1:10 |>
>     > mean()
>
>     > but this fails:
>
>     > 1:10
>     > |> mean()
>
>     > Duncan Murdoch
>
> Yes, of course (as I know you know), the same way that
>
>     >  1:10
>     >  + 1
>
> does "not" work.
>
>
>
>     >> If you don't want to do that, install and load the 'magrittr'
> package
>     >> and change |> to %>% everywhere.
>
> I really think that in June 2024  you (Ogbos) should not run
> "productively" an R version that is older than May 2021 (where R
> 4.1.0 was released) :
>
>   $ R-4.1.0 --version | head 1
>   R version 4.1.0 (2021-05-18) -- "Camp Pontanezen"
>
>   $ R-4.1.0 --vanilla -s -e '1:10|>sum()'
>   [1] 55
>   $
>
> So upgrading your R to current (R 4.4.1)  is *very* much recommended.
>
> Martin Maechler
>
>
>     >> On 2024-06-18 12:13 p.m., Ogbos Okike wrote:
>     >>> Greetings to everyone and thank you for your readiness to help.
>     >>>
>     >>> I have problems using the pipe command (|>).
>     >>>
>     >>> Once I have it in any script on my system, it won't.
>     >>>
>     >>> The error message will say:
>     >>>
>     >>> unexpected '>'
>     >>> I loaded the two packages below to see if it would handle it. But
> the
>     >>> problem remains.
>     >>> library(magrittr)
>     >>> library(dplyr)
>     >>>
>     >>> I searched to see if there was a way to install the command. But I
> was not
>     >>> successful.
>     >>>
>     >>> Please tell me what to do to be able to use the pipe command on my
> system.
>     >>> I would be grateful for any help.
>     >>> Thank you.
>     >>>
>     >>> Sincerely yours
>     >>> Ogbos
>     >>>
>     >>> [[alternative HTML version deleted]]
>     >>>
>     >>> ______________________________________________
>     >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     >>> https://stat.ethz.ch/mailman/listinfo/r-help
>     >>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>     >>> and provide commented, minimal, self-contained, reproducible code.
>     >>
>     >> ______________________________________________
>     >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     >> https://stat.ethz.ch/mailman/listinfo/r-help
>     >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>     >> and provide commented, minimal, self-contained, reproducible code.
>
>     > ______________________________________________
>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m|ev|n@ @end|ng |rom purdue@edu  Wed Jun 19 01:12:03 2024
From: m|ev|n@ @end|ng |rom purdue@edu (Levine, Michael)
Date: Tue, 18 Jun 2024 23:12:03 +0000
Subject: [R] Integration of functions with a vector argument
In-Reply-To: <20240613132121.1847edee@arachnoid>
References: <PH0PR22MB2860E3ABD206953D15F31EFAC5C72@PH0PR22MB2860.namprd22.prod.outlook.com>
 <20240612134119.72e4cab6@Tarkus>
 <PH0PR22MB28605CCF2898AD2EC336DCCBC5C02@PH0PR22MB2860.namprd22.prod.outlook.com>
 <20240613132121.1847edee@arachnoid>
Message-ID: <PH0PR22MB28606A4C8C09D6738A403F19C5CE2@PH0PR22MB2860.namprd22.prod.outlook.com>

Dear Ivan,

Sorry for my slow response. Your advice works well; however, as you predicted, the time it takes to obtain any results is completely unacceptable (for example, a sequence of integrations we discussed is done once per iteration and even one iteration takes about 2 hours to complete).

I have one more question for you - hope you don't mind. I have heard of several packages used for numerical integration in R - cubature that you mentioned, mvQuad, and pracma.  My impression is that you think that Cubature is the best in your opinion. Is that so? If yes, do you know of any detailed discussion of this package beyond the two vignettes available on CRAN?

Thank you very much again for your help!

Yours sincerely,
Michael

Michael Levine
Associate Professor, Statistics

Department of Statistics
Purdue University
250 North University Street
West Lafayette, IN 47907 USA

email: mlevins at purdue.edu
Phone: +1-765-496-7571
Fax:   +1-765-494-0558
URL:   www.stat.purdue.edu/~mlevins
________________________________
From: Ivan Krylov <ikrylov at disroot.org>
Sent: Thursday, June 13, 2024 6:21 AM
To: Levine, Michael <mlevins at purdue.edu>
Cc: r-help at r-project.org <r-help at r-project.org>
Subject: Re: [R] Integration of functions with a vector argument

[You don't often get email from ikrylov at disroot.org. Learn why this is important at https://aka.ms/LearnAboutSenderIdentification ]

---- External Email: Use caution with attachments, links, or sharing data ----


?? Wed, 12 Jun 2024 23:42:18 +0000
"Levine, Michael" <mlevins at purdue.edu> ??????:

> f.int1 <- function(x,y) {Vectorize (function(y) f(c(x,y),H=H,j=j))}

Vectorize returns a callable function(y), so wrapping it in a
function(x,y) will not work. Since you'd like to integrate over y, we
can perform the same transformation manually using vapply:

# A version of f(...) that can be integrated over y
f.int1 <- function(y, x, H, j)
 vapply(y, function(y) f(c(x,y), H = H, j = j), numeric(1))

The same transformation can be performed using Vectorize as follows:

f.int1 <- Vectorize(
 function(y, x, H, j) f(c(x,y), H = H, j = j),
 vectorize.args = 'y'
)

>     mrg.d1 <- function(x){
>     integrate(f.int1,lower=-3,upper=3)$value
>     }

We can then integrate f.int1 over y, making sure to pass the remaining
scalar parameters to the function:

# mrg.d1(x, H, j) = ?? f(y,x,H,j) dy from -3 to 3
mrg.d1 <- function(x, H, j)
 integrate(f.int1, lower=-3, upper=3, x = x, H = H, j = j)$value

> mrg.cdf1 <- function(x){
>     integrate(mrg.d1,lower=-Inf,upper=x)$value
>     }

Unfortunately, mrg.d1 is once again not vectorised and may give wrong
answers or raise exceptions with non-scalar x. We can now perform the
same transformation so that the function would work with integrate():

# Version of mrg.d1 integratable over x
mrg.d1.int <- function(x, H, j)
 vapply(x, mrg.d1, numeric(1), H = H, j = j)

Here, instead of having to combine arguments like in f.int1, we can
just use vapply() to call the original mrg.d1 for every scalar element
inside the vector x given to mrg.d1.int. Alternatively,

mrg.d1.int <- Vectorize(mrg.d1, 'x')

A vectorised function can then be integrated:

# mrg.cdf1(x, H, j) = ?? mrg.d1(x', H, j) dx' from -?? to x
mrg.cdf1 <- function(x, H, j)
 integrate(mrg.d1.int, lower=-Inf, upper=x, H = H, j = j)$value

This double nested loop (produced by Vectorize() and mapply() or
manually with vapply()) may be not very fast. If you rewrite your
function f to accept matrices containing values of (x, y) for many
evaluations of the function and to return vectors of the resulting
values, you'll be able to use the CRAN package 'cubature'
<https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fcran.r-project.org%2Fpackage%3Dcubature&data=05%7C02%7Cmlevins%40purdue.edu%7C9753b609c1d34745311908dc8b9296b9%7C4130bd397c53419cb1e58758d6d63f21%7C0%7C0%7C638538708933465815%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&sdata=uCwVWSrsLemT4j1nT9UiEt%2BQxH99Z8erBorg0LEYmWI%3D&reserved=0<https://cran.r-project.org/package=cubature>> to integrate it over
multiple variables at once.

--
Best regards,
Ivan

	[[alternative HTML version deleted]]


From j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng  Wed Jun 19 11:52:21 2024
From: j|br|n@@|h@@@@n @end|ng |rom unn@edu@ng (Jibrin Alhassan)
Date: Wed, 19 Jun 2024 10:52:21 +0100
Subject: [R] PROBLEM RESOLED::code for year month day hr format
In-Reply-To: <CAEGeL+GWp-kCiT8vwJgYD33b5ONU==iDYSybQi56Km_qkLAyWQ@mail.gmail.com>
References: <CAEGeL+EDsd2LnZ0v5cY-0S7ofE_qxKi-QGV2+WnSzODywRZ9MQ@mail.gmail.com>
 <474f21f7-7a41-403f-826f-853f6589ec52@sapo.pt>
 <CAEGeL+H_eukBiQKyDb1GOGo5K2kcyM7S6n167ukBWoGrQUgLyg@mail.gmail.com>
 <9347708a-d116-4879-8809-e2b5abadff25@sapo.pt>
 <CAEGeL+Hv5vXMo8yqeTTXpjXMVicSpEzk9W0pM0jd0gWRMiVsqQ@mail.gmail.com>
 <CAEGeL+FS6hN7OJqh=6NveMTMVA8Ct_mpRdGdqdezVBoXiTRe6g@mail.gmail.com>
 <053e2864-deb4-42bb-a505-555c8f9c7360@sapo.pt>
 <CAEGeL+HEUOq=VxCF0q_sD2qoDht00OvNhSNnBTXcr9dcSqxWyQ@mail.gmail.com>
 <36b96f57-b034-43df-81d3-33e5c9a0c389@sapo.pt>
 <CAEGeL+FNxaFVkh=SwNhUEaEeGAEXWDv8DwmjEeGp0SRC-9Sw4w@mail.gmail.com>
 <77401bf4-4982-42dd-9f65-06fdd1ae1022@sapo.pt>
 <CAEGeL+GWp-kCiT8vwJgYD33b5ONU==iDYSybQi56Km_qkLAyWQ@mail.gmail.com>
Message-ID: <CAEGeL+H+hkPM_mZmeYmYAuabYgg8Pwt2hB0e8yaw1p+CRh0y8g@mail.gmail.com>

The help  I sought on code for year month day and hr format for solar wind
hourly data  has been resolved. Thank you all for your time, patience and
wonderful contributions.
Jibrin Alhassan.

On Mon, Jun 17, 2024, 9:26 PM Jibrin Alhassan <jibrin.alhassan at unn.edu.ng>
wrote:

> Hello Rui,
> Thanks for your kind and unrelenting help. The code works actually. I will
> see what to do to sort things out. Please, accept my indebtedness.
> *Jibrin Adejoh Alhassan (Ph.D)*
> Department of Physics and Astronomy,
> University of Nigeria, Nsukka
>
>
> On Mon, Jun 17, 2024 at 8:53?PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
>> ?s 09:44 de 17/06/2024, Jibrin Alhassan escreveu:
>> > Hello Rui,
>> > The df1 output printed from June instead of January .Here is part of it.
>> > 4288  2012-06-27 15  6.2  420  70   -7 109.9
>> > 4289  2012-06-27 16  6.5  442  70   -9 109.9
>> > 4290  2012-06-27 17  6.3  450  70   -6 109.9
>> > 4291  2012-06-27 18  6.0  453  70    0 109.9
>> > 4292  2012-06-27 19  6.7  473  70    2 109.9
>> > 4293  2012-06-27 20  5.7  460  70    2 109.9
>> > 4294  2012-06-27 21  5.4  469  70    0 109.9
>> > 4295  2012-06-27 22  4.5  485  70   -2 109.9
>> > 4296  2012-06-27 23  4.9  497  70    1 109.9
>> > 4297  2012-06-28  0  4.6  500  87    3 123.7
>> > 4298  2012-06-28  1  4.7  503  87    2 123.7
>> > 4299  2012-06-28  2  4.3  488  87    1 123.7
>> > 4300  2012-06-28  3  4.9  479  87    0 123.7
>> > 4301  2012-06-28  4  5.1  459  87    0 123.7
>> > 4302  2012-06-28  5  4.9  458  87    0 123.7
>> > 4303  2012-06-28  6  5.1  460  87    0 123.7
>> > 4304  2012-06-28  7  5.0  451  87   -3 123.7
>> > 4305  2012-06-28  8  5.2  452  87   -5 123.7
>> > 4306  2012-06-28  9  5.2  445  87   -6 123.7
>> > 4307  2012-06-28 10  5.0  430  87   -7 123.7
>> > 4308  2012-06-28 11  4.6  434  87   -8 123.7
>> > 4309  2012-06-28 12  4.1  442  87   -7 123.7
>> > 4310  2012-06-28 13  3.9  433  87   -7 123.7
>> > 4311  2012-06-28 14  3.5  421  87   -9 123.7
>> > 4312  2012-06-28 15  4.4  420  87   -8 123.7
>> > 4313  2012-06-28 16  4.6  421  87   -9 123.7
>> > 4314  2012-06-28 17  3.2  417  87   -7 123.7
>> > 4315  2012-06-28 18  3.5  415  87   -3 123.7
>> > 4316  2012-06-28 19  3.9  394  87   -2 123.7
>> > 4317  2012-06-28 20  4.2  407  87    0 123.7
>> > 4318  2012-06-28 21  3.9  411  87   -3 123.7
>> > 4319  2012-06-28 22  3.6  420  87   -5 123.7
>> > 4320  2012-06-28 23  4.0  423  87    0 123.7
>> > 4321  2012-06-29  0  3.2  418 103    5 121.3
>> > 4322  2012-06-29  1  3.3  421 103    7 121.3
>> > 4323  2012-06-29  2  3.7  411 103    9 121.3
>> > 4324  2012-06-29  3  3.8  413 103    9 121.3
>> > 4325  2012-06-29  4  3.3  413 103    6 121.3
>> > 4326  2012-06-29  5  3.2  417 103    2 121.3
>> > 4327  2012-06-29  6  3.4  414 103    2 121.3
>> > 4328  2012-06-29  7  3.7  405 103    1 121.3
>> > 4329  2012-06-29  8  3.9  393 103    1 121.3
>> > 4330  2012-06-29  9  4.2  385 103    2 121.3
>> > 4331  2012-06-29 10  4.4  381 103    2 121.3
>> > 4332  2012-06-29 11  4.0  386 103    3 121.3
>> > 4333  2012-06-29 12  4.7  386 103    5 121.3
>> > 4334  2012-06-29 13  5.2  378 103    7 121.3
>> > 4335  2012-06-29 14  5.1  376 103    5 121.3
>> > 4336  2012-06-29 15  4.7  366 103    2 121.3
>> > 4337  2012-06-29 16  4.5  378 103    0 121.3
>> > 4338  2012-06-29 17  4.8  369 103    0 121.3
>> > 4339  2012-06-29 18  5.4  365 103    0 121.3
>> > 4340  2012-06-29 19  5.7  369 103    1 121.3
>> > 4341  2012-06-29 20  5.8  373 103    3 121.3
>> > 4342  2012-06-29 21  4.9  392 103   10 121.3
>> > 4343  2012-06-29 22  4.0  406 103   19 121.3
>> > 4344  2012-06-29 23  7.1  402 103   19 121.3
>> > 4345  2012-06-30  0  6.5  398 104   18 128.2
>> > 4346  2012-06-30  1  7.6  397 104   12 128.2
>> > 4347  2012-06-30  2  8.8  407 104   10 128.2
>> > 4348  2012-06-30  3 11.2  404 104   -1 128.2
>> > 4349  2012-06-30  4 11.2  410 104    1 128.2
>> > 4350  2012-06-30  5  8.8  410 104    1 128.2
>> > 4351  2012-06-30  6  9.7  417 104   -6 128.2
>> > 4352  2012-06-30  7 12.3  446 104  -14 128.2
>> > 4353  2012-06-30  8  9.5  476 104  -10 128.2
>> > 4354  2012-06-30  9  8.7  496 104  -13 128.2
>> > 4355  2012-06-30 10 12.6  560 104  -17 128.2
>> > 4356  2012-06-30 11 11.4  600 104  -13 128.2
>> > 4357  2012-06-30 12 11.4  607 104  -12 128.2
>> > 4358  2012-06-30 13 11.1  603 104   -8 128.2
>> > 4359  2012-06-30 14 11.1  616 104  -14 128.2
>> > 4360  2012-06-30 15  9.7  616 104  -13 128.2
>> > 4361  2012-06-30 16  9.7  629 104  -15 128.2
>> > 4362  2012-06-30 17  6.6  654 104  -24 128.2
>> > 4363  2012-06-30 18  6.5  660 104  -24 128.2
>> > 4364  2012-06-30 19  6.8  676 104  -31 128.2
>> > 4365  2012-06-30 20  7.2  675 104  -37 128.2
>> > 4366  2012-06-30 21  7.0  657 104  -32 128.2
>> > 4367  2012-06-30 22  6.4  634 104  -31 128.2
>> > 4368  2012-06-30 23  7.6  640 104  -29 128.2
>> > 4369  2012-07-01  0  6.9  650 126  -23 137.9
>> > 4370  2012-07-01  1  7.0  635 126  -18 137.9
>> > 4371  2012-07-01  2  6.9  651 126  -17 137.9
>> > 4372  2012-07-01  3  6.3  661 126  -25 137.9
>> > 4373  2012-07-01  4  5.6  663 126  -26 137.9
>> > 4374  2012-07-01  5  5.4  655 126  -26 137.9
>> > 4375  2012-07-01  6  5.1  656 126  -33 137.9
>> > 4376  2012-07-01  7  4.9  658 126  -30 137.9
>> > 4377  2012-07-01  8  5.1  648 126  -24 137.9
>> > 4378  2012-07-01  9  5.0  643 126  -24 137.9
>> > 4379  2012-07-01 10  5.0  633 126  -20 137.9
>> > 4380  2012-07-01 11  5.1  650 126  -17 137.9
>> > 4381  2012-07-01 12  5.2  687 126  -13 137.9
>> > 4382  2012-07-01 13  5.0  653 126   -8 137.9
>> > 4383  2012-07-01 14  4.9  648 126  -12 137.9
>> > 4384  2012-07-01 15  5.7  661 126  -11 137.9
>> > 4385  2012-07-01 16  5.7  665 126  -10 137.9
>> > 4386  2012-07-01 17  5.9  655 126  -12 137.9
>> > 4387  2012-07-01 18  5.1  647 126  -10 137.9
>> > 4388  2012-07-01 19  4.9  638 126  -16 137.9
>> > 4389  2012-07-01 20  5.1  633 126  -17 137.9
>> > 4390  2012-07-01 21  5.8  642 126  -16 137.9
>> > 4391  2012-07-01 22  5.8  635 126  -18 137.9
>> > 4392  2012-07-01 23  5.6  639 126  -16 137.9
>> > 4393  2012-07-02  0  5.2  653 128  -15 171.4
>> > 4394  2012-07-02  1  6.0  642 128  -12 171.4
>> > 4395  2012-07-02  2  5.3  664 128  -16 171.4
>> > 4396  2012-07-02  3  5.2  676 128  -13 171.4
>> > 4397  2012-07-02  4  5.0  662 128  -22 171.4
>> > 4398  2012-07-02  5  5.2  650 128  -28 171.4
>> > 4399  2012-07-02  6  5.0  650 128  -35 171.4
>> > 4400  2012-07-02  7  5.1  644 128  -32 171.4
>> > 4401  2012-07-02  8  4.9  653 128  -31 171.4
>> > 4402  2012-07-02  9  4.5  649 128  -26 171.4
>> > 4403  2012-07-02 10  4.3  640 128  -25 171.4
>> > 4404  2012-07-02 11  4.2  635 128  -20 171.4
>> > 4405  2012-07-02 12  4.8  636 128  -17 171.4
>> > 4406  2012-07-02 13  5.2  619 128  -16 171.4
>> > 4407  2012-07-02 14  4.9  649 128  -25 171.4
>> > 4408  2012-07-02 15  4.9  652 128  -31 171.4
>> > 4409  2012-07-02 16  5.1  649 128  -36 171.4
>> > 4410  2012-07-02 17  4.6  628 128  -37 171.4
>> > 4411  2012-07-02 18  4.2  633 128  -31 171.4
>> > 4412  2012-07-02 19  4.0  642 128  -29 171.4
>> > 4413  2012-07-02 20  3.8  643 128  -30 171.4
>> > 4414  2012-07-02 21  3.7  631 128  -32 171.4
>> > 4415  2012-07-02 22  3.7  626 128  -32 171.4
>> > 4416  2012-07-02 23  3.1  642 128  -31 171.4
>> > 4417  2012-07-03  0  3.3  634 125  -25 150.7
>> > 4418  2012-07-03  1  3.7  618 125  -19 150.7
>> > 4419  2012-07-03  2  3.9  593 125  -17 150.7
>> > 4420  2012-07-03  3  3.8  589 125  -16 150.7
>> > 4421  2012-07-03  4  3.8  576 125  -16 150.7
>> > 4422  2012-07-03  5  4.1  580 125  -20 150.7
>> > 4423  2012-07-03  6  3.9  580 125  -18 150.7
>> > 4424  2012-07-03  7  3.8  572 125  -19 150.7
>> > 4425  2012-07-03  8  4.1  562 125  -18 150.7
>> > 4426  2012-07-03  9  4.0  561 125  -15 150.7
>> > 4427  2012-07-03 10  4.1  558 125  -18 150.7
>> > 4428  2012-07-03 11  4.0  550 125  -20 150.7
>> > 4429  2012-07-03 12  4.1  548 125  -22 150.7
>> > 4430  2012-07-03 13  3.9  549 125  -21 150.7
>> > 4431  2012-07-03 14  4.1  532 125  -19 150.7
>> > 4432  2012-07-03 15  4.2  546 125  -19 150.7
>> > 4433  2012-07-03 16  4.1  547 125  -19 150.7
>> > 4434  2012-07-03 17  4.1  525 125  -23 150.7
>> > 4435  2012-07-03 18  4.0  514 125  -25 150.7
>> > 4436  2012-07-03 19  3.7  534 125  -22 150.7
>> > 4437  2012-07-03 20  3.7  541 125  -18 150.7
>> > 4438  2012-07-03 21  3.6  533 125  -19 150.7
>> > 4439  2012-07-03 22  4.3  548 125  -16 150.7
>> > 4440  2012-07-03 23  4.9  534 125  -12 150.7
>> > 4441  2012-07-04  0  4.6  538 131  -11 168.6
>> > 4442  2012-07-04  1  4.6  558 131  -10 168.6
>> > 4443  2012-07-04  2  4.1  568 131   -8 168.6
>> > 4444  2012-07-04  3  4.8  578 131   -5 168.6
>> > 4445  2012-07-04  4  5.1  580 131  -10 168.6
>> > 4446  2012-07-04  5  5.2  573 131  -17 168.6
>> > 4447  2012-07-04  6  5.1  565 131  -19 168.6
>> > 4448  2012-07-04  7  4.5  560 131  -18 168.6
>> > 4449  2012-07-04  8  4.7  555 131  -18 168.6
>> > 4450  2012-07-04  9  4.2  531 131  -19 168.6
>> > 4451  2012-07-04 10  4.1  521 131  -17 168.6
>> > 4452  2012-07-04 11  4.2  525 131  -18 168.6
>> > 4453  2012-07-04 12  3.9  526 131  -15 168.6
>> > 4454  2012-07-04 13  4.1  518 131  -10 168.6
>> > 4455  2012-07-04 14  4.5  506 131   -7 168.6
>> > 4456  2012-07-04 15  4.9  497 131   -6 168.6
>> > 4457  2012-07-04 16  4.9  498 131   -5 168.6
>> > 4458  2012-07-04 17  4.8  489 131   -5 168.6
>> > 4459  2012-07-04 18  4.5  518 131   -6 168.6
>> > 4460  2012-07-04 19  5.2  521 131   -6 168.6
>> > 4461  2012-07-04 20  6.1  535 131   -8 168.6
>> > 4462  2012-07-04 21  6.3  537 131  -14 168.6
>> > 4463  2012-07-04 22  6.4  519 131  -18 168.6
>> > 4464  2012-07-04 23  6.1  512 131  -19 168.6
>> > 4465  2012-07-05  0  5.9  500 129  -12 170.1
>> > 4466  2012-07-05  1  5.7  493 129   -1 170.1
>> > 4467  2012-07-05  2  5.8  486 129    4 170.1
>> > 4468  2012-07-05  3  5.8  487 129    4 170.1
>> > 4469  2012-07-05  4  5.4  478 129    5 170.1
>> > 4470  2012-07-05  5  5.4  478 129    2 170.1
>> > 4471  2012-07-05  6  5.9  483 129   -3 170.1
>> > 4472  2012-07-05  7  6.3  495 129   -7 170.1
>> > 4473  2012-07-05  8  6.1  503 129   -7 170.1
>> > 4474  2012-07-05  9  6.2  499 129   -2 170.1
>> > 4475  2012-07-05 10  5.9  495 129    3 170.1
>> > 4476  2012-07-05 11  4.1  499 129   21 170.1
>> > 4477  2012-07-05 12  6.8  491 129   16 170.1
>> > 4478  2012-07-05 13  6.9  489 129   11 170.1
>> > 4479  2012-07-05 14  6.5  486 129   31 170.1
>> > 4480  2012-07-05 15  8.2  478 129   11 170.1
>> > 4481  2012-07-05 16  8.1  472 129   11 170.1
>> > 4482  2012-07-05 17  9.8  486 129   11 170.1
>> > 4483  2012-07-05 18 10.0  489 129    9 170.1
>> > 4484  2012-07-05 19 10.0  489 129    8 170.1
>> > 4485  2012-07-05 20  9.8  488 129   12 170.1
>> > 4486  2012-07-05 21  9.8  485 129   13 170.1
>> > 4487  2012-07-05 22 10.3  473 129    6 170.1
>> > 4488  2012-07-05 23  9.4  460 129    7 170.1
>> > 4489  2012-07-06  0  9.4  457 132    4 163.0
>> > 4490  2012-07-06  1  9.3  448 132    6 163.0
>> > 4491  2012-07-06  2  8.8  437 132    7 163.0
>> > 4492  2012-07-06  3  7.4  435 132   -1 163.0
>> > 4493  2012-07-06  4  8.2  431 132   -3 163.0
>> > 4494  2012-07-06  5  8.2  424 132    1 163.0
>> > 4495  2012-07-06  6  7.8  429 132   -2 163.0
>> > 4496  2012-07-06  7  7.8  429 132  -10 163.0
>> > 4497  2012-07-06  8  7.6  436 132  -13 163.0
>> > 4498  2012-07-06  9  6.9  442 132   -9 163.0
>> > 4499  2012-07-06 10  5.7  458 132   -2 163.0
>> > 4500  2012-07-06 11  6.3  453 132   -3 163.0
>> > 4501  2012-07-06 12  5.0  447 132   -4 163.0
>> > 4502  2012-07-06 13  5.2  430 132   -4 163.0
>> > 4503  2012-07-06 14  5.9  417 132   -5 163.0
>> > 4504  2012-07-06 15  6.3  421 132   -7 163.0
>> > 4505  2012-07-06 16  8.7  447 132    2 163.0
>> > 4506  2012-07-06 17  9.8  453 132    4 163.0
>> > 4507  2012-07-06 18 10.1  484 132   -4 163.0
>> > 4508  2012-07-06 19  9.9  484 132  -17 163.0
>> > 4509  2012-07-06 20 10.0  485 132  -27 163.0
>> > 4510  2012-07-06 21 10.5  457 132  -36 163.0
>> > 4511  2012-07-06 22  9.9  459 132  -25 163.0
>> > 4512  2012-07-06 23  8.3  483 132   -9 163.0
>> > 4513  2012-07-07  0  8.1  486 146  -12 163.7
>> > 4514  2012-07-07  1  6.9  485 146   -6 163.7
>> > 4515  2012-07-07  2  7.1  484 146    0 163.7
>> > 4516  2012-07-07  3  5.6  480 146    4 163.7
>> > 4517  2012-07-07  4  5.2  480 146    3 163.7
>> > 4518  2012-07-07  5  5.3  493 146    1 163.7
>> > 4519  2012-07-07  6  5.1  494 146    1 163.7
>> > 4520  2012-07-07  7  4.7  469 146   -3 163.7
>> > 4521  2012-07-07  8  4.9  484 146   -7 163.7
>> > 4522  2012-07-07  9  4.3  482 146  -10 163.7
>> > 4523  2012-07-07 10  4.3  477 146   -7 163.7
>> > 4524  2012-07-07 11  4.1  467 146   -6 163.7
>> > 4525  2012-07-07 12  4.1  462 146  -10 163.7
>> > 4526  2012-07-07 13  3.8  448 146  -13 163.7
>> > 4527  2012-07-07 14  3.9  442 146  -14 163.7
>> > 4528  2012-07-07 15  3.8  443 146  -14 163.7
>> > 4529  2012-07-07 16  3.8  439 146  -12 163.7
>> > 4530  2012-07-07 17  3.4  435 146   -7 163.7
>> > 4531  2012-07-07 18  3.7  434 146   -9 163.7
>> > 4532  2012-07-07 19  3.5  428 146   -6 163.7
>> > 4533  2012-07-07 20  3.1  427 146   -3 163.7
>> > 4534  2012-07-07 21  3.2  429 146   -2 163.7
>> > 4535  2012-07-07 22  3.3  427 146   -6 163.7
>> > 4536  2012-07-07 23  3.5  434 146  -12 163.7
>> > 4537  2012-07-08  0  3.1  441 117   -9 183.7
>> > 4538  2012-07-08  1  3.1  436 117   -7 183.7
>> > 4539  2012-07-08  2  3.8  427 117   -4 183.7
>> > 4540  2012-07-08  3  3.4  418 117    3 183.7
>> > 4541  2012-07-08  4  3.6  417 117   13 183.7
>> > 4542  2012-07-08  5  4.6  413 117   15 183.7
>> > 4543  2012-07-08  6  4.3  404 117   15 183.7
>> > 4544  2012-07-08  7  4.0  394 117   11 183.7
>> > 4545  2012-07-08  8  5.5  405 117   12 183.7
>> > 4546  2012-07-08  9  9.2  423 117   14 183.7
>> > 4547  2012-07-08 10  8.8  418 117   18 183.7
>> > 4548  2012-07-08 11  9.2  407 117   11 183.7
>> > 4549  2012-07-08 12  9.2  401 117   10 183.7
>> > 4550  2012-07-08 13 10.6  412 117   18 183.7
>> > 4551  2012-07-08 14 11.1  414 117   17 183.7
>> > 4552  2012-07-08 15 11.1  458 117   13 183.7
>> > 4553  2012-07-08 16 11.3  441 117   14 183.7
>> > 4554  2012-07-08 17 11.0  439 117   15 183.7
>> > 4555  2012-07-08 18  9.8  443 117   13 183.7
>> > 4556  2012-07-08 19  8.1  439 117   10 183.7
>> > 4557  2012-07-08 20  5.1  453 117   12 183.7
>> > 4558  2012-07-08 21  8.4  462 117   16 183.7
>> > 4559  2012-07-08 22  9.0  447 117    6 183.7
>> > 4560  2012-07-08 23  9.8  436 117  -10 183.7
>> > 4561  2012-07-09  0 10.1  438 122  -27 179.6
>> > 4562  2012-07-09  1 11.6  441 122  -37 179.6
>> > 4563  2012-07-09  2 11.6  434 122  -30 179.6
>> > 4564  2012-07-09  3 11.8  421 122  -29 179.6
>> > 4565  2012-07-09  4 11.8  419 122  -33 179.6
>> > 4566  2012-07-09  5 11.6  419 122  -36 179.6
>> > 4567  2012-07-09  6 11.7  420 122  -34 179.6
>> > 4568  2012-07-09  7 12.2  415 122  -43 179.6
>> > 4569  2012-07-09  8 12.2  412 122  -49 179.6
>> > 4570  2012-07-09  9 12.3  405 122  -58 179.6
>> > 4571  2012-07-09 10 12.3  398 122  -61 179.6
>> > 4572  2012-07-09 11 12.0  392 122  -62 179.6
>> > 4573  2012-07-09 12 12.0  392 122  -78 179.6
>> > 4574  2012-07-09 13 11.9  390 122  -73 179.6
>> > 4575  2012-07-09 14 11.4  394 122  -64 179.6
>> > 4576  2012-07-09 15 10.6  400 122  -61 179.6
>> > 4577  2012-07-09 16 10.9  400 122  -71 179.6
>> > 4578  2012-07-09 17 10.7  396 122  -69 179.6
>> > 4579  2012-07-09 18 10.7  394 122  -67 179.6
>> > 4580  2012-07-09 19 10.3  395 122  -64 179.6
>> > 4581  2012-07-09 20 11.0  395 122  -64 179.6
>> > 4582  2012-07-09 21 10.8  397 122  -70 179.6
>> > 4583  2012-07-09 22 11.5  401 122  -78 179.6
>> > 4584  2012-07-09 23 11.1  401 122  -70 179.6
>> > 4585  2012-07-10  0 11.1  389 107  -65 179.2
>> > 4586  2012-07-10  1 11.8  403 107  -55 179.2
>> > 4587  2012-07-10  2 10.1  416 107  -45 179.2
>> > 4588  2012-07-10  3 11.0  406 107  -42 179.2
>> > 4589  2012-07-10  4 10.8  419 107  -42 179.2
>> > 4590  2012-07-10  5 10.6  410 107  -39 179.2
>> > 4591  2012-07-10  6 10.3  408 107  -36 179.2
>> > 4592  2012-07-10  7  9.4  417 107  -35 179.2
>> > 4593  2012-07-10  8  8.2  405 107  -38 179.2
>> > 4594  2012-07-10  9  8.3  404 107  -38 179.2
>> > 4595  2012-07-10 10  8.0  424 107  -34 179.2
>> > 4596  2012-07-10 11  7.3  433 107  -31 179.2
>> > 4597  2012-07-10 12  7.5  465 107  -28 179.2
>> > 4598  2012-07-10 13  7.3  450 107  -25 179.2
>> > 4599  2012-07-10 14  6.5  454 107  -25 179.2
>> > 4600  2012-07-10 15  6.6  472 107  -27 179.2
>> > 4601  2012-07-10 16  6.7  461 107  -28 179.2
>> > 4602  2012-07-10 17  6.5  462 107  -29 179.2
>> > 4603  2012-07-10 18  6.5  461 107  -28 179.2
>> > 4604  2012-07-10 19  5.4  483 107  -27 179.2
>> > 4605  2012-07-10 20  4.9  490 107  -24 179.2
>> > 4606  2012-07-10 21  5.6  482 107  -23 179.2
>> > 4607  2012-07-10 22  5.7  484 107  -25 179.2
>> > 4608  2012-07-10 23  5.8  484 107  -26 179.2
>> > 4609  2012-07-11  0  6.6  489 110  -27 167.1
>> > 4610  2012-07-11  1  6.7  489 110  -25 167.1
>> > 4611  2012-07-11  2  7.1  503 110  -24 167.1
>> > 4612  2012-07-11  3  5.7  494 110  -29 167.1
>> > 4613  2012-07-11  4  5.5  509 110  -30 167.1
>> > 4614  2012-07-11  5  5.3  522 110  -24 167.1
>> > 4615  2012-07-11  6  5.2  518 110  -23 167.1
>> > 4616  2012-07-11  7  6.5  516 110  -30 167.1
>> > 4617  2012-07-11  8  6.3  526 110  -36 167.1
>> > 4618  2012-07-11  9  6.2  523 110  -34 167.1
>> > 4619  2012-07-11 10  5.5  527 110  -25 167.1
>> > 4620  2012-07-11 11  6.0  527 110  -22 167.1
>> > 4621  2012-07-11 12  5.8  518 110  -22 167.1
>> > 4622  2012-07-11 13  5.4  515 110  -19 167.1
>> > 4623  2012-07-11 14  5.3  513 110  -21 167.1
>> > 4624  2012-07-11 15  5.5  512 110  -21 167.1
>> > 4625  2012-07-11 16  5.2  505 110  -21 167.1
>> > 4626  2012-07-11 17  4.9  512 110  -18 167.1
>> > 4627  2012-07-11 18  5.1  514 110  -17 167.1
>> > 4628  2012-07-11 19  6.2  520 110  -13 167.1
>> > 4629  2012-07-11 20  6.6  510 110  -17 167.1
>> > 4630  2012-07-11 21  6.2  516 110  -18 167.1
>> > 4631  2012-07-11 22  5.8  512 110  -24 167.1
>> > 4632  2012-07-11 23  5.9  509 110  -31 167.1
>> > 4633  2012-07-12  0  6.1  502 125  -34 170.9
>> > 4634  2012-07-12  1  6.6  506 125  -34 170.9
>> > 4635  2012-07-12  2  6.1  502 125  -22 170.9
>> > 4636  2012-07-12  3  5.8  480 125  -18 170.9
>> > 4637  2012-07-12  4  5.7  474 125  -15 170.9
>> > 4638  2012-07-12  5  5.4  474 125  -23 170.9
>> > 4639  2012-07-12  6  6.1  466 125  -28 170.9
>> > 4640  2012-07-12  7  5.4  460 125  -32 170.9
>> > 4641  2012-07-12  8  4.8  453 125  -32 170.9
>> > 4642  2012-07-12  9  4.7  445 125  -28 170.9
>> > 4643  2012-07-12 10  4.9  436 125  -29 170.9
>> > 4644  2012-07-12 11  4.9  441 125  -23 170.9
>> > 4645  2012-07-12 12  4.9  440 125  -18 170.9
>> > 4646  2012-07-12 13  4.2  417 125  -15 170.9
>> > 4647  2012-07-12 14  3.5  414 125  -16 170.9
>> > 4648  2012-07-12 15  3.9  418 125  -14 170.9
>> > 4649  2012-07-12 16  4.2  419 125  -11 170.9
>> > 4650  2012-07-12 17  3.9  416 125  -11 170.9
>> > 4651  2012-07-12 18  4.0  416 125  -12 170.9
>> > 4652  2012-07-12 19  3.8  415 125  -13 170.9
>> > 4653  2012-07-12 20  3.9  410 125  -16 170.9
>> > 4654  2012-07-12 21  3.8  402 125  -20 170.9
>> > 4655  2012-07-12 22  3.8  395 125  -19 170.9
>> > 4656  2012-07-12 23  3.9  394 125  -19 170.9
>> > 4657  2012-07-13  0  3.9  395 129  -20 152.1
>> > 4658  2012-07-13  1  3.8  395 129  -19 152.1
>> > 4659  2012-07-13  2  3.8  391 129  -17 152.1
>> > 4660  2012-07-13  3  3.8  385 129  -16 152.1
>> > 4661  2012-07-13  4  3.7  376 129  -15 152.1
>> > 4662  2012-07-13  5  3.8  371 129  -15 152.1
>> > 4663  2012-07-13  6  3.8  365 129  -14 152.1
>> > 4664  2012-07-13  7  3.9  357 129  -15 152.1
>> > 4665  2012-07-13  8  4.0  354 129  -18 152.1
>> > 4666  2012-07-13  9  3.9  355 129  -20 152.1
>> > 4667  2012-07-13 10  3.9  353 129  -19 152.1
>> > 4668  2012-07-13 11  3.7  357 129  -18 152.1
>> > 4669  2012-07-13 12  3.8  357 129  -18 152.1
>> > 4670  2012-07-13 13  3.8  355 129  -18 152.1
>> > 4671  2012-07-13 14  3.7  347 129  -17 152.1
>> > 4672  2012-07-13 15  3.7  350 129  -15 152.1
>> > 4673  2012-07-13 16  3.7  346 129  -13 152.1
>> > 4674  2012-07-13 17  3.7  341 129  -10 152.1
>> > 4675  2012-07-13 18  3.3  340 129   -8 152.1
>> > 4676  2012-07-13 19  3.2  338 129   -9 152.1
>> > 4677  2012-07-13 20  3.3  333 129  -10 152.1
>> > 4678  2012-07-13 21  3.4  329 129   -9 152.1
>> > 4679  2012-07-13 22  3.9  326 129   -7 152.1
>> > 4680  2012-07-13 23  4.0  324 129   -8 152.1
>> > 4681  2012-07-14  0  4.0  324 125   -9 152.8
>> > 4682  2012-07-14  1  4.0  325 125   -9 152.8
>> > 4683  2012-07-14  2  3.9  329 125   -7 152.8
>> > 4684  2012-07-14  3  4.1  326 125   -5 152.8
>> > 4685  2012-07-14  4  4.4  325 125   -6 152.8
>> > 4686  2012-07-14  5  4.5  323 125   -5 152.8
>> > 4687  2012-07-14  6  5.0  319 125   -5 152.8
>> > 4688  2012-07-14  7  5.2  317 125   -8 152.8
>> > 4689  2012-07-14  8  5.4  323 125   -7 152.8
>> > 4690  2012-07-14  9  5.4  318 125   -6 152.8
>> > 4691  2012-07-14 10  5.2  316 125   -8 152.8
>> > 4692  2012-07-14 11  5.2  326 125   -5 152.8
>> > 4693  2012-07-14 12  4.6  335 125   -5 152.8
>> > 4694  2012-07-14 13  4.2  340 125   -5 152.8
>> > 4695  2012-07-14 14  5.0  350 125   -5 152.8
>> > 4696  2012-07-14 15  4.9  366 125   -1 152.8
>> > 4697  2012-07-14 16  3.9  355 125   -5 152.8
>> > 4698  2012-07-14 17  5.1  369 125   -5 152.8
>> > 4699  2012-07-14 18 11.0  419 125   15 152.8
>> > 4700  2012-07-14 19 14.6  574 125    4 152.8
>> > 4701  2012-07-14 20 11.2  569 125   -7 152.8
>> > 4702  2012-07-14 21 13.9  568 125   -5 152.8
>> > 4703  2012-07-14 22 15.3  574 125    1 152.8
>> > 4704  2012-07-14 23 19.2  644 125   -2 152.8
>> > 4705  2012-07-15  0 11.4  665 117    9 145.1
>> > 4706  2012-07-15  1  9.7  657 117    0 145.1
>> > *Jibrin Adejoh Alhassan (Ph.D)*
>> > Department of Physics and Astronomy,
>> > University of Nigeria, Nsukka
>> >
>> >
>> > On Mon, Jun 17, 2024 at 9:23?AM Rui Barradas <ruipbarradas at sapo.pt>
>> wrote:
>> >
>> >> ?s 09:12 de 17/06/2024, Jibrin Alhassan escreveu:
>> >>> Hello Rui,
>> >>> Here is the head(df1) output
>> >>> Date HR IMF SWS SSN Dst f10.7
>> >>> 1 2012-01-01  0 4.0 379  71  -8 999.9
>> >>> 2 2012-01-01  1 4.4 386  71  -3 999.9
>> >>> 3 2012-01-01  2 4.8 380  71  -4 999.9
>> >>> 4 2012-01-01  3 5.4 374  71  -5 999.9
>> >>> 5 2012-01-01  4 4.5 369  71  -9 999.9
>> >>> 6 2012-01-01  5 4.2 368  71  -7 999.9
>> >>> Many thanks.
>> >>> *Jibrin Adejoh Alhassan (Ph.D)*
>> >>> Department of Physics and Astronomy,
>> >>> University of Nigeria, Nsukka
>> >>>
>> >>>
>> >>> On Mon, Jun 17, 2024 at 8:14?AM Rui Barradas <ruipbarradas at sapo.pt>
>> >> wrote:
>> >>>
>> >>>> ?s 07:53 de 17/06/2024, Jibrin Alhassan escreveu:
>> >>>>> Part of it is pasted below
>> >>>>> YEAR DOY HR    IMF SWS   SSN   Dst f10.7
>> >>>>> 2012   1  0   4.0  379.  71    -8 999.9
>> >>>>> 2012   1  1   4.4  386.  71    -3 999.9
>> >>>>> 2012   1  2   4.8  380.  71    -4 999.9
>> >>>>> 2012   1  3   5.4  374.  71    -5 999.9
>> >>>>> 2012   1  4   4.5  369.  71    -9 999.9
>> >>>>> 2012   1  5   4.2  368.  71    -7 999.9
>> >>>>> 2012   1  6   4.7  367.  71    -6 999.9
>> >>>>> 2012   1  7   4.1  361.  71   -10 999.9
>> >>>>> 2012   1  8   3.2  362.  71    -7 999.9
>> >>>>> 2012   1  9   4.3  367.  71    -3 999.9
>> >>>>> 2012   1 10   4.5  365.  71    -6 999.9
>> >>>>> 2012   1 11   5.6  369.  71    -8 999.9
>> >>>>> 2012   1 12   5.2  366.  71    -8 999.9
>> >>>>> 2012   1 13   4.4  370.  71    -7 999.9
>> >>>>> 2012   1 14   4.8  357.  71    -5 999.9
>> >>>>> 2012   1 15   4.6  354.  71    -8 999.9
>> >>>>> 2012   1 16   3.7  382.  71    -7 999.9
>> >>>>> 2012   1 17   3.2  376.  71    -2 999.9
>> >>>>> 2012   1 18   2.8  368.  71     2 999.9
>> >>>>> 2012   1 19   3.2  361.  71     2 999.9
>> >>>>> 2012   1 20   3.2  361.  71    -3 999.9
>> >>>>> 2012   1 21   3.5  365.  71    -5 999.9
>> >>>>> 2012   1 22   3.6  364.  71    -3 999.9
>> >>>>> 2012   1 23   3.0  362.  71    -3 999.9
>> >>>>> 2012   2  0   3.2  359.  92    -5 130.3
>> >>>>> 2012   2  1   3.0  361.  92    -4 130.3
>> >>>>> 2012   2  2   4.5  374.  92     3 130.3
>> >>>>> 2012   2  3   4.5  364.  92     5 130.3
>> >>>>> 2012   2  4   5.1  352.  92     3 130.3
>> >>>>> 2012   2  5   4.9  358.  92     3 130.3
>> >>>>> 2012   2  6   4.4  346.  92     4 130.3
>> >>>>> 2012   2  7   4.2  349.  92     7 130.3
>> >>>>> 2012   2  8   4.5  346.  92     8 130.3
>> >>>>> 2012   2  9   5.2  345.  92     7 130.3
>> >>>>> 2012   2 10   5.0  349.  92     5 130.3
>> >>>>> 2012   2 11   4.8  345.  92     0 130.3
>> >>>>> 2012   2 12   5.3  347.  92     0 130.3
>> >>>>> 2012   2 13   5.5  342.  92     0 130.3
>> >>>>> 2012   2 14   6.1  359.  92     1 130.3
>> >>>>> 2012   2 15   6.2  393.  92     8 130.3
>> >>>>> 2012   2 16   6.7  390.  92    10 130.3
>> >>>>> 2012   2 17   7.7  369.  92    10 130.3
>> >>>>> 2012   2 18   9.4  380.  92    14 130.3
>> >>>>> 2012   2 19  10.6  386.  92    12 130.3
>> >>>>> 2012   2 20  10.2  378.  92    11 130.3
>> >>>>> 2012   2 21  11.6  369.  92     7 130.3
>> >>>>> 2012   2 22  12.0  369.  92     8 130.3
>> >>>>> 2012   2 23  10.5  361.  92     1 130.3
>> >>>>> 2012   3  0  11.3  403. 120    -7 130.2
>> >>>>> 2012   3  1  10.3  412. 120   -14 130.2
>> >>>>> 2012   3  2   8.8  419. 120   -18 130.2
>> >>>>> 2012   3  3   8.3  412. 120   -23 130.2
>> >>>>> 2012   3  4   8.0  408. 120   -25 130.2
>> >>>>> 2012   3  5   7.0  380. 120   -28 130.2
>> >>>>> 2012   3  6   6.9  374. 120   -29 130.2
>> >>>>> 2012   3  7   6.9  372. 120   -30 130.2
>> >>>>> 2012   3  8   7.1  365. 120   -32 130.2
>> >>>>> 2012   3  9   6.8  376. 120   -35 130.2
>> >>>>> 2012   3 10   6.7  380. 120   -35 130.2
>> >>>>> 2012   3 11   6.4  381. 120   -30 130.2
>> >>>>> 2012   3 12   5.9  401. 120   -26 130.2
>> >>>>> 2012   3 13   5.9  405. 120   -23 130.2
>> >>>>> 2012   3 14   5.9  413. 120   -20 130.2
>> >>>>> 2012   3 15   5.9  406. 120   -20 130.2
>> >>>>> 2012   3 16   6.3  427. 120   -20 130.2
>> >>>>> 2012   3 17   5.9  424. 120   -19 130.2
>> >>>>> 2012   3 18   4.8  390. 120   -16 130.2
>> >>>>> 2012   3 19   4.8  374. 120   -15 130.2
>> >>>>> 2012   3 20   4.8  374. 120   -15 130.2
>> >>>>> 2012   3 21   5.1  378. 120   -18 130.2
>> >>>>> 2012   3 22   4.9  375. 120   -19 130.2
>> >>>>> 2012   3 23   4.7  364. 120   -17 130.2
>> >>>>> 2012   4  0   4.3  359. 126   -17 131.6
>> >>>>> 2012   4  1   4.3  359. 126   -15 131.6
>> >>>>> 2012   4  2   4.2  358. 126   -13 131.6
>> >>>>> 2012   4  3   3.8  359. 126   -13 131.6
>> >>>>> 2012   4  4   3.8  358. 126   -13 131.6
>> >>>>> 2012   4  5   3.7  359. 126   -14 131.6
>> >>>>> 2012   4  6   3.9  361. 126   -13 131.6
>> >>>>> 2012   4  7   3.7  364. 126   -13 131.6
>> >>>>> 2012   4  8   3.7  366. 126   -12 131.6
>> >>>>> 2012   4  9   3.8  363. 126   -10 131.6
>> >>>>> 2012   4 10   3.5  363. 126    -8 131.6
>> >>>>> 2012   4 11   3.0  352. 126   -10 131.6
>> >>>>> 2012   4 12   3.1  348. 126   -12 131.6
>> >>>>> 2012   4 13   3.3  340. 126    -9 131.6
>> >>>>> 2012   4 14   4.0  343. 126    -8 131.6
>> >>>>> 2012   4 15   4.2  343. 126    -7 131.6
>> >>>>> 2012   4 16   3.8  336. 126    -5 131.6
>> >>>>> 2012   4 17   3.9  334. 126    -6 131.6
>> >>>>> 2012   4 18   3.8  329. 126    -5 131.6
>> >>>>> 2012   4 19   3.8  326. 126    -4 131.6
>> >>>>> 2012   4 20   4.3  337. 126    -3 131.6
>> >>>>> 2012   4 21   3.9  331. 126     0 131.6
>> >>>>> 2012   4 22   3.8  322. 126    -1 131.6
>> >>>>> 2012   4 23   3.5  331. 126    -1 131.6
>> >>>>> 2012   5  0   3.9  312. 109    -3 136.6
>> >>>>> 2012   5  1   3.6  311. 109    -1 136.6
>> >>>>> 2012   5  2   3.7  312. 109     0 136.6
>> >>>>> 2012   5  3   3.8  308. 109     0 136.6
>> >>>>> 2012   5  4   4.0  305. 109     2 136.6
>> >>>>> 2012   5  5   4.5  309. 109     2 136.6
>> >>>>> 2012   5  6   3.5  314. 109     3 136.6
>> >>>>> 2012   5  7   3.6  305. 109     2 136.6
>> >>>>> 2012   5  8   4.3  307. 109     2 136.6
>> >>>>> 2012   5  9   4.6  316. 109     1 136.6
>> >>>>> 2012   5 10   5.0  321. 109    -4 136.6
>> >>>>> 2012   5 11   5.1  321. 109    -6 136.6
>> >>>>> 2012   5 12   4.6  326. 109    -4 136.6
>> >>>>> 2012   5 13   5.7  321. 109    -2 136.6
>> >>>>> 2012   5 14   5.0  316. 109     1 136.6
>> >>>>> 2012   5 15   4.6  315. 109     2 136.6
>> >>>>> 2012   5 16   5.5  321. 109     7 136.6
>> >>>>> 2012   5 17   7.2  327. 109     7 136.6
>> >>>>> 2012   5 18   9.2  329. 109     3 136.6
>> >>>>> 2012   5 19   9.4  341. 109     3 136.6
>> >>>>> 2012   5 20   9.2  345. 109     8 136.6
>> >>>>> 2012   5 21   9.8  344. 109     9 136.6
>> >>>>> 2012   5 22   9.8  341. 109    10 136.6
>> >>>>> 2012   5 23  10.0  351. 109    15 136.6
>> >>>>> 2012   6  0  10.4  356. 113    12 131.0
>> >>>>> 2012   6  1   9.1  360. 113    10 131.0
>> >>>>> 2012   6  2   6.6  392. 113    10 131.0
>> >>>>> 2012   6  3   6.9  418. 113     7 131.0
>> >>>>> 2012   6  4   6.5  408. 113     4 131.0
>> >>>>> 2012   6  5   6.6  413. 113     7 131.0
>> >>>>> 2012   6  6   7.3  428. 113     6 131.0
>> >>>>> 2012   6  7   7.3  416. 113     4 131.0
>> >>>>> 2012   6  8   7.0  411. 113     1 131.0
>> >>>>> 2012   6  9   7.2  415. 113     1 131.0
>> >>>>> 2012   6 10   7.2  426. 113     0 131.0
>> >>>>> 2012   6 11   6.5  431. 113    -2 131.0
>> >>>>> 2012   6 12   6.4  431. 113    -2 131.0
>> >>>>> 2012   6 13   6.6  435. 113     0 131.0
>> >>>>> 2012   6 14   6.2  425. 113     2 131.0
>> >>>>> 2012   6 15   5.7  431. 113     4 131.0
>> >>>>> 2012   6 16   6.1  431. 113     1 131.0
>> >>>>> 2012   6 17   5.7  425. 113    -3 131.0
>> >>>>> 2012   6 18   5.8  431. 113    -1 131.0
>> >>>>> 2012   6 19   6.4  425. 113     2 131.0
>> >>>>> 2012   6 20   6.0  434. 113     1 131.0
>> >>>>> 2012   6 21   6.3  420. 113     0 131.0
>> >>>>> 2012   6 22   6.3  440. 113    -3 131.0
>> >>>>> 2012   6 23   6.5  456. 113    -3 131.0
>> >>>>> 2012   7  0   6.3  435. 113    -5 135.9
>> >>>>> 2012   7  1   5.9  428. 113    -1 135.9
>> >>>>> 2012   7  2   5.7  434. 113     1 135.9
>> >>>>> 2012   7  3   5.3  423. 113     0 135.9
>> >>>>> 2012   7  4   4.3  417. 113     1 135.9
>> >>>>> 2012   7  5   5.4  420. 113     0 135.9
>> >>>>> 2012   7  6   5.7  434. 113     1 135.9
>> >>>>> 2012   7  7   5.5  423. 113     1 135.9
>> >>>>> 2012   7  8   4.8  419. 113    -2 135.9
>> >>>>> 2012   7  9   5.8  421. 113    -6 135.9
>> >>>>> 2012   7 10   5.3  412. 113    -9 135.9
>> >>>>> 2012   7 11   4.6  424. 113    -7 135.9
>> >>>>> 2012   7 12   4.0  439. 113    -3 135.9
>> >>>>> 2012   7 13   4.8  431. 113    -1 135.9
>> >>>>> 2012   7 14   5.1  431. 113    -1 135.9
>> >>>>> 2012   7 15   4.8  427. 113    -1 135.9
>> >>>>> 2012   7 16   4.7  429. 113    -5 135.9
>> >>>>> 2012   7 17   5.3  436. 113    -6 135.9
>> >>>>> 2012   7 18   5.1  426. 113    -5 135.9
>> >>>>> 2012   7 19   5.2  427. 113    -4 135.9
>> >>>>> 2012   7 20   4.5  416. 113    -5 135.9
>> >>>>> 2012   7 21   4.9  409. 113    -4 135.9
>> >>>>> 2012   7 22   5.0  417. 113    -4 135.9
>> >>>>> 2012   7 23   5.0  426. 113    -4 135.9
>> >>>>> 2012   8  0   5.0  433. 104    -2 131.4
>> >>>>> 2012   8  1   4.9  426. 104    -2 131.4
>> >>>>> 2012   8  2   4.7  421. 104    -4 131.4
>> >>>>> 2012   8  3   4.4  417. 104    -5 131.4
>> >>>>> 2012   8  4   4.3  416. 104    -8 131.4
>> >>>>> 2012   8  5   4.5  416. 104    -8 131.4
>> >>>>> 2012   8  6   5.0  419. 104    -6 131.4
>> >>>>> 2012   8  7   5.4  446. 104    -1 131.4
>> >>>>> 2012   8  8   5.3  439. 104    -2 131.4
>> >>>>> 2012   8  9   5.3  432. 104    -4 131.4
>> >>>>> 2012   8 10   5.4  434. 104    -4 131.4
>> >>>>> 2012   8 11   5.4  435. 104    -3 131.4
>> >>>>> 2012   8 12   4.5  421. 104    -4 131.4
>> >>>>> 2012   8 13   4.5  422. 104    -4 131.4
>> >>>>> 2012   8 14   5.1  425. 104    -2 131.4
>> >>>>> 2012   8 15   5.3  429. 104     1 131.4
>> >>>>> 2012   8 16   5.5  433. 104    -2 131.4
>> >>>>> 2012   8 17   5.9  440. 104    -2 131.4
>> >>>>> 2012   8 18   6.6  445. 104    -1 131.4
>> >>>>> 2012   8 19   6.4  442. 104    -4 131.4
>> >>>>> 2012   8 20   5.9  434. 104    -6 131.4
>> >>>>> 2012   8 21   5.3  429. 104    -7 131.4
>> >>>>> 2012   8 22   4.8  438. 104    -2 131.4
>> >>>>> 2012   8 23   5.3  427. 104     4 131.4
>> >>>>> 2012   9  0   5.5  433.  79     8 137.6
>> >>>>> 2012   9  1   5.2  445.  79     9 137.6
>> >>>>> 2012   9  2   5.4  439.  79    10 137.6
>> >>>>> 2012   9  3   5.3  430.  79     7 137.6
>> >>>>> 2012   9  4   5.1  426.  79    -3 137.6
>> >>>>> 2012   9  5   4.7  415.  79    -6 137.6
>> >>>>> 2012   9  6   5.0  412.  79    -4 137.6
>> >>>>> 2012   9  7   5.2  418.  79    -2 137.6
>> >>>>> 2012   9  8   5.5  441.  79     2 137.6
>> >>>>> 2012   9  9   5.1  441.  79     2 137.6
>> >>>>> 2012   9 10   5.4  430.  79    -2 137.6
>> >>>>> 2012   9 11   5.3  433.  79    -1 137.6
>> >>>>> 2012   9 12   5.5  438.  79     5 137.6
>> >>>>> 2012   9 13   5.4  436.  79     6 137.6
>> >>>>> 2012   9 14   5.7  440.  79     9 137.6
>> >>>>> 2012   9 15   5.9  430.  79     9 137.6
>> >>>>> 2012   9 16   5.8  437.  79     4 137.6
>> >>>>> 2012   9 17   4.9  431.  79    -3 137.6
>> >>>>> 2012   9 18   5.3  424.  79    -3 137.6
>> >>>>> 2012   9 19   5.7  437.  79    -2 137.6
>> >>>>> 2012   9 20   6.1  427.  79    -4 137.6
>> >>>>> 2012   9 21   6.0  409.  79    -7 137.6
>> >>>>> 2012   9 22   6.6  410.  79    -4 137.6
>> >>>>> 2012   9 23   6.4  432.  79    -1 137.6
>> >>>>> 2012  10  0   5.9  434.  70     2 124.6
>> >>>>> 2012  10  1   5.6  424.  70     4 124.6
>> >>>>> 2012  10  2   4.8  435.  70     7 124.6
>> >>>>> 2012  10  3   4.6  425.  70     4 124.6
>> >>>>> 2012  10  4   4.3  424.  70     3 124.6
>> >>>>> 2012  10  5   5.4  426.  70     2 124.6
>> >>>>> 2012  10  6   5.5  434.  70     2 124.6
>> >>>>> 2012  10  7   6.4  435.  70     4 124.6
>> >>>>> 2012  10  8   6.3  436.  70     1 124.6
>> >>>>> 2012  10  9   5.2  431.  70    -6 124.6
>> >>>>> 2012  10 10   4.5  426.  70   -10 124.6
>> >>>>> 2012  10 11   4.6  435.  70    -9 124.6
>> >>>>> 2012  10 12   3.4  425.  70    -5 124.6
>> >>>>> 2012  10 13   4.2  427.  70    -4 124.6
>> >>>>> 2012  10 14   4.0  432.  70     2 124.6
>> >>>>> 2012  10 15   5.5  450.  70     7 124.6
>> >>>>> 2012  10 16   5.9  451.  70     2 124.6
>> >>>>> 2012  10 17   5.5  445.  70    -3 124.6
>> >>>>> 2012  10 18   5.8  442.  70    -2 124.6
>> >>>>> 2012  10 19   5.4  430.  70    -1 124.6
>> >>>>> 2012  10 20   4.9  427.  70    -1 124.6
>> >>>>> 2012  10 21   4.0  436.  70     0 124.6
>> >>>>> 2012  10 22   3.4  445.  70    -1 124.6
>> >>>>> 2012  10 23   4.5  453.  70     0 124.6
>> >>>>> 2012  11  0   5.3  438.  63     1 116.1
>> >>>>> 2012  11  1   5.0  438.  63     3 116.1
>> >>>>> 2012  11  2   5.3  445.  63     3 116.1
>> >>>>> 2012  11  3   4.5  451.  63     2 116.1
>> >>>>> 2012  11  4   5.0  456.  63    -1 116.1
>> >>>>> 2012  11  5   4.6  459.  63     0 116.1
>> >>>>> 2012  11  6   5.1  459.  63     1 116.1
>> >>>>> 2012  11  7   4.0  466.  63     3 116.1
>> >>>>> 2012  11  8   5.0  478.  63    -1 116.1
>> >>>>> 2012  11  9   4.6  489.  63    -2 116.1
>> >>>>> 2012  11 10   4.5  493.  63    -4 116.1
>> >>>>> 2012  11 11   4.5  494.  63    -1 116.1
>> >>>>> 2012  11 12   3.6  504.  63     3 116.1
>> >>>>> 2012  11 13   3.5  496.  63     5 116.1
>> >>>>> 2012  11 14   3.3  497.  63     7 116.1
>> >>>>> 2012  11 15   3.0  498.  63     7 116.1
>> >>>>> 2012  11 16   2.1  503.  63     3 116.1
>> >>>>> 2012  11 17   2.0  495.  63     0 116.1
>> >>>>> 2012  11 18   2.5  492.  63    -2 116.1
>> >>>>> 2012  11 19   2.2  496.  63    -1 116.1
>> >>>>> 2012  11 20   2.4  489.  63     1 116.1
>> >>>>> 2012  11 21   2.6  489.  63     3 116.1
>> >>>>> 2012  11 22   2.6  483.  63     2 116.1
>> >>>>> 2012  11 23   2.6  478.  63     2 116.1
>> >>>>> 2012  12  0   2.9  453.  52     3 113.0
>> >>>>> 2012  12  1   2.2  446.  52     4 113.0
>> >>>>> 2012  12  2   2.4  442.  52     8 113.0
>> >>>>> 2012  12  3   2.6  440.  52    10 113.0
>> >>>>> 2012  12  4   2.2  438.  52    11 113.0
>> >>>>> 2012  12  5   2.8  438.  52     9 113.0
>> >>>>> 2012  12  6   2.0  437.  52     8 113.0
>> >>>>> 2012  12  7   2.4  426.  52     7 113.0
>> >>>>> 2012  12  8   3.0  423.  52     5 113.0
>> >>>>> 2012  12  9   3.3  420.  52     4 113.0
>> >>>>> 2012  12 10   4.0  419.  52     2 113.0
>> >>>>> 2012  12 11   3.8  412.  52     5 113.0
>> >>>>> 2012  12 12   4.2  409.  52     4 113.0
>> >>>>> 2012  12 13   3.5  408.  52     2 113.0
>> >>>>> 2012  12 14   3.7  404.  52     9 113.0
>> >>>>> 2012  12 15   4.5  402.  52    15 113.0
>> >>>>> 2012  12 16   3.6  395.  52    14 113.0
>> >>>>> 2012  12 17   2.4  392.  52    16 113.0
>> >>>>> 2012  12 18   5.8  403.  52    27 113.0
>> >>>>> 2012  12 19   7.6  400.  52    27 113.0
>> >>>>> 2012  12 20   6.9  418.  52    17 113.0
>> >>>>> 2012  12 21   6.9  463.  52    10 113.0
>> >>>>> 2012  12 22   7.3  469.  52     9 113.0
>> >>>>> 2012  12 23   5.5  482.  52    12 113.0
>> >>>>> 2012  13  0   7.7  500.  71    10 120.0
>> >>>>> 2012  13  1   8.7  492.  71    14 120.0
>> >>>>> 2012  13  2   7.8  513.  71    16 120.0
>> >>>>> 2012  13  3   7.5  530.  71    11 120.0
>> >>>>> 2012  13  4   7.1  518.  71     8 120.0
>> >>>>> 2012  13  5   7.0  524.  71     6 120.0
>> >>>>> 2012  13  6   5.9  536.  71     8 120.0
>> >>>>> 2012  13  7   3.6  529.  71     5 120.0
>> >>>>> 2012  13  8   4.1  510.  71     4 120.0
>> >>>>> 2012  13  9   3.9  497.  71     3 120.0
>> >>>>> 2012  13 10   2.4  492.  71     3 120.0
>> >>>>> 2012  13 11   2.6  485.  71     5 120.0
>> >>>>> 2012  13 12   2.9  492.  71     5 120.0
>> >>>>> 2012  13 13   2.6  487.  71     3 120.0
>> >>>>> 2012  13 14   2.3  478.  71     6 120.0
>> >>>>> 2012  13 15   3.2  467.  71    11 120.0
>> >>>>> 2012  13 16   3.4  453.  71    10 120.0
>> >>>>> 2012  13 17   3.2  452.  71     6 120.0
>> >>>>> 2012  13 18   3.0  452.  71     2 120.0
>> >>>>> 2012  13 19   2.8  447.  71     1 120.0
>> >>>>> 2012  13 20   2.5  439.  71     0 120.0
>> >>>>> 2012  13 21   2.5  443.  71    -2 120.0
>> >>>>> 2012  13 22   2.7  442.  71    -3 120.0
>> >>>>> 2012  13 23   3.0  447.  71    -4 120.0
>> >>>>> 2012  14  0   3.5  445. 118    -3 128.0
>> >>>>> 2012  14  1   3.3  440. 118    -1 128.0
>> >>>>> 2012  14  2   3.1  440. 118     1 128.0
>> >>>>> 2012  14  3   2.7  446. 118     0 128.0
>> >>>>> 2012  14  4   2.9  442. 118    -1 128.0
>> >>>>> 2012  14  5   2.9  437. 118    -2 128.0
>> >>>>> 2012  14  6   3.3  431. 118    -3 128.0
>> >>>>> 2012  14  7   2.8  420. 118    -2 128.0
>> >>>>> 2012  14  8   2.3  409. 118    -2 128.0
>> >>>>> 2012  14  9   2.2  407. 118     1 128.0
>> >>>>> 2012  14 10   2.6  405. 118     3 128.0
>> >>>>> 2012  14 11   2.8  401. 118     4 128.0
>> >>>>> 2012  14 12   3.2  398. 118     4 128.0
>> >>>>> 2012  14 13   2.7  400. 118     4 128.0
>> >>>>> 2012  14 14   1.9  399. 118     5 128.0
>> >>>>> 2012  14 15   2.4  395. 118     3 128.0
>> >>>>> 2012  14 16   2.7  389. 118     2 128.0
>> >>>>> 2012  14 17   2.9  385. 118     0 128.0
>> >>>>> 2012  14 18   3.2  384. 118     1 128.0
>> >>>>> 2012  14 19   2.6  380. 118     2 128.0
>> >>>>> 2012  14 20   2.3  378. 118     1 128.0
>> >>>>> 2012  14 21   2.1  374. 118     0 128.0
>> >>>>> 2012  14 22   3.1  367. 118     0 128.0
>> >>>>> 2012  14 23   4.0  366. 118    -1 128.0
>> >>>>> 2012  15  0   4.8  363. 149     0 129.2
>> >>>>> 2012  15  1   4.0  359. 149     2 129.2
>> >>>>> 2012  15  2   3.4  354. 149     2 129.2
>> >>>>> 2012  15  3   3.0  349. 149     5 129.2
>> >>>>> 2012  15  4   2.7  344. 149     7 129.2
>> >>>>> 2012  15  5   2.4  349. 149    11 129.2
>> >>>>> 2012  15  6   2.9  343. 149    12 129.2
>> >>>>> 2012  15  7   3.5  333. 149     7 129.2
>> >>>>> 2012  15  8   3.6  341. 149     4 129.2
>> >>>>> 2012  15  9   3.7  345. 149     1 129.2
>> >>>>> 2012  15 10   3.6  343. 149     2 129.2
>> >>>>> 2012  15 11   3.6  342. 149     3 129.2
>> >>>>> 2012  15 12   3.7  340. 149     7 129.2
>> >>>>> 2012  15 13   3.7  342. 149     8 129.2
>> >>>>> 2012  15 14   4.1  344. 149     9 129.2
>> >>>>> 2012  15 15   3.9  345. 149     4 129.2
>> >>>>> 2012  15 16   4.4  355. 149     8 129.2
>> >>>>> 2012  15 17   4.7  360. 149    11 129.2
>> >>>>> 2012  15 18   5.4  359. 149    12 129.2
>> >>>>> 2012  15 19   6.8  353. 149     8 129.2
>> >>>>> 2012  15 20   6.6  349. 149     6 129.2
>> >>>>> 2012  15 21   5.9  364. 149     2 129.2
>> >>>>> 2012  15 22   5.2  394. 149     1 129.2
>> >>>>> 2012  15 23   6.3  395. 149     5 129.2
>> >>>>> 2012  16  0   6.3  385. 154     6 135.1
>> >>>>> 2012  16  1   6.6  397. 154     2 135.1
>> >>>>> 2012  16  2   6.7  400. 154     4 135.1
>> >>>>> 2012  16  3   6.9  396. 154     5 135.1
>> >>>>> 2012  16  4   7.9  392. 154     5 135.1
>> >>>>> 2012  16  5   4.6  379. 154    10 135.1
>> >>>>> 2012  16  6   8.0  365. 154    13 135.1
>> >>>>> 2012  16  7   6.3  358. 154    16 135.1
>> >>>>> 2012  16  8   7.9  380. 154    12 135.1
>> >>>>> 2012  16  9  10.2  391. 154    10 135.1
>> >>>>> 2012  16 10   8.1  394. 154     8 135.1
>> >>>>> 2012  16 11  12.1  412. 154    -8 135.1
>> >>>>> 2012  16 12  13.2  424. 154   -10 135.1
>> >>>>> 2012  16 13  12.9  433. 154    -8 135.1
>> >>>>> 2012  16 14   9.3  461. 154    -7 135.1
>> >>>>> 2012  16 15   6.6  466. 154   -14 135.1
>> >>>>> 2012  16 16   6.6  493. 154   -11 135.1
>> >>>>> 2012  16 17   7.4  496. 154    -7 135.1
>> >>>>> 2012  16 18   6.2  493. 154    -7 135.1
>> >>>>> 2012  16 19   6.9  492. 154   -13 135.1
>> >>>>> 2012  16 20   6.8  486. 154   -19 135.1
>> >>>>> 2012  16 21   5.6  488. 154   -14 135.1
>> >>>>> 2012  16 22   6.4  464. 154   -11 135.1
>> >>>>> 2012  16 23   6.0  459. 154   -10 135.1
>> >>>>> 2012  17  0   4.9  476. 141   -14 134.5
>> >>>>> 2012  17  1   4.6  460. 141   -20 134.5
>> >>>>> 2012  17  2   4.1  467. 141   -17 134.5
>> >>>>> 2012  17  3   3.7  469. 141   -13 134.5
>> >>>>> 2012  17  4   3.3  472. 141   -12 134.5
>> >>>>> 2012  17  5   2.7  472. 141    -8 134.5
>> >>>>> 2012  17  6   3.5  459. 141    -6 134.5
>> >>>>> 2012  17  7   3.9  459. 141    -6 134.5
>> >>>>> 2012  17  8   4.1  463. 141    -7 134.5
>> >>>>> 2012  17  9   4.1  443. 141   -10 134.5
>> >>>>> 2012  17 10   4.1  446. 141   -14 134.5
>> >>>>> 2012  17 11   4.1  442. 141   -13 134.5
>> >>>>> 2012  17 12   3.6  436. 141   -10 134.5
>> >>>>> 2012  17 13   3.6  433. 141    -6 134.5
>> >>>>> 2012  17 14   4.2  421. 141    -1 134.5
>> >>>>> 2012  17 15   3.7  416. 141    -2 134.5
>> >>>>> 2012  17 16   4.2  410. 141    -1 134.5
>> >>>>> 2012  17 17   4.6  396. 141    -1 134.5
>> >>>>> 2012  17 18   4.5  398. 141    -2 134.5
>> >>>>> 2012  17 19   4.4  397. 141    -6 134.5
>> >>>>> 2012  17 20   4.5  396. 141    -8 134.5
>> >>>>> 2012  17 21   3.5  411. 141    -5 134.5
>> >>>>> 2012  17 22   3.9  425. 141    -5 134.5
>> >>>>> 2012  17 23   4.7  418. 141    -6 134.5
>> >>>>> 2012  18  0   4.6  400. 126    -7 143.4
>> >>>>> 2012  18  1   4.5  413. 126    -3 143.4
>> >>>>> 2012  18  2   4.4  418. 126     2 143.4
>> >>>>> 2012  18  3   4.2  420. 126     2 143.4
>> >>>>> 2012  18  4   4.0  401. 126    -2 143.4
>> >>>>> 2012  18  5   3.8  399. 126    -1 143.4
>> >>>>> 2012  18  6   3.5  388. 126    -1 143.4
>> >>>>> 2012  18  7   4.4  393. 126    -2 143.4
>> >>>>> 2012  18  8   4.7  405. 126    -3 143.4
>> >>>>> 2012  18  9   4.8  409. 126    -4 143.4
>> >>>>> 2012  18 10   4.9  409. 126    -3 143.4
>> >>>>> 2012  18 11   5.0  411. 126    -5 143.4
>> >>>>> 2012  18 12   5.1  405. 126    -5 143.4
>> >>>>> 2012  18 13   5.2  403. 126    -6 143.4
>> >>>>> 2012  18 14   5.1  394. 126    -4 143.4
>> >>>>> 2012  18 15   5.0  391. 126    -5 143.4
>> >>>>> 2012  18 16   4.6  387. 126    -4 143.4
>> >>>>> 2012  18 17   4.7  376. 126    -2 143.4
>> >>>>> 2012  18 18   4.7  381. 126    -1 143.4
>> >>>>> 2012  18 19   4.5  382. 126    -2 143.4
>> >>>>> 2012  18 20   4.9  386. 126    -5 143.4
>> >>>>> 2012  18 21   4.8  375. 126    -5 143.4
>> >>>>> 2012  18 22   4.7  385. 126    -6 143.4
>> >>>>> 2012  18 23   4.7  381. 126    -5 143.4
>> >>>>> 2012  19  0   4.3  372. 105    -3 152.0
>> >>>>> 2012  19  1   4.2  361. 105    -4 152.0
>> >>>>> 2012  19  2   4.0  360. 105    -5 152.0
>> >>>>> 2012  19  3   3.9  362. 105    -4 152.0
>> >>>>> *Jibrin Adejoh Alhassan (Ph.D)*
>> >>>>> Department of Physics and Astronomy,
>> >>>>> University of Nigeria, Nsukka
>> >>>>>
>> >>>>>
>> >>>>> On Mon, Jun 17, 2024 at 7:50?AM Jibrin Alhassan <
>> >>>> jibrin.alhassan at unn.edu.ng>
>> >>>>> wrote:
>> >>>>>
>> >>>>>> Hello Rui,
>> >>>>>> Your patience is indeed amazing. Your script tested as shown below
>> >>>> worked
>> >>>>>> perfectly well.
>> >>>>>> df1 <- read.table(text = "YEAR DOY HR   IMF  SW   SSN    Dst f10.7
>> >>>>>> 2012 215  4   5.1  371. 143    -4 138.6 ", header = TRUE)
>> >>>>>> with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
>> >>>>>> df1$Date <- with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y
>> %j")
>> >>>>>> df1 <- df1[-(1:2)]
>> >>>>>> df1 <- df1[c(ncol(df1), 1:(ncol(df1) - 1L))]
>> >>>>>> head(df1).
>> >>>>>> But  I have 43,849 data points. Your script only generated one.
>> Help
>> >> me
>> >>>>>> with a script that can handle the whole data points. I have tried
>> >>>> following
>> >>>>>> your tested solution but was unsuccessful. My regards.
>> >>>>>> *Jibrin Adejoh Alhassan (Ph.D)*
>> >>>>>> Department of Physics and Astronomy,
>> >>>>>> University of Nigeria, Nsukka
>> >>>>>>
>> >>>>>>
>> >>>>>> On Sun, Jun 16, 2024 at 8:33?AM Rui Barradas <ruipbarradas at sapo.pt
>> >
>> >>>> wrote:
>> >>>>>>
>> >>>>>>> ?s 21:42 de 15/06/2024, Jibrin Alhassan escreveu:
>> >>>>>>>> Thank you Rui. I ran the following script
>> >>>>>>>> df1 <- read.table("solar_hour", header = TRUE)
>> >>>>>>>> df1$date <- as.Date(paste(df1$year, df1$hour),
>> >>>>>>>>      format = "%Y %j",
>> >>>>>>>> origin = "2012-08-01-0")
>> >>>>>>>> df2 <- df1[c("date", "IMF", "SWS", "SSN", "Dst", "f10")]
>> >>>>>>>> head(df1)
>> >>>>>>>> #To display all the rows
>> >>>>>>>>      print(df2).
>> >>>>>>>> It gave me this error message
>> >>>>>>>>> source ("script.R")
>> >>>>>>>> Error in `$<-.data.frame`(`*tmp*`, date, value = numeric(0)) :
>> >>>>>>>>       replacement has 0 rows, data has 38735
>> >>>>>>>>> print(df2)
>> >>>>>>>> Error: object 'df2' not found
>> >>>>>>>>> My data is an hourly data but desire to have the date as
>> >>>>>>>> year    month    day   hour
>> >>>>>>>> 2012   08         01     01
>> >>>>>>>> 2012   08         01     02
>> >>>>>>>> 2012   08        01      03 etc
>> >>>>>>>> Thanks.
>> >>>>>>>>
>> >>>>>>>> *Jibrin Adejoh Alhassan (Ph.D)*
>> >>>>>>>> Department of Physics and Astronomy,
>> >>>>>>>> University of Nigeria, Nsukka
>> >>>>>>>>
>> >>>>>>>>
>> >>>>>>>> On Sat, Jun 15, 2024 at 8:34?PM Rui Barradas <
>> ruipbarradas at sapo.pt>
>> >>>>>>> wrote:
>> >>>>>>>>
>> >>>>>>>>> ?s 20:00 de 15/06/2024, Jibrin Alhassan escreveu:
>> >>>>>>>>>> I have solar-geophysical data e.g as blow:
>> >>>>>>>>>> YEAR DOY HR   IMF  SW   SSN    Dst f10.7
>> >>>>>>>>>> 2012 214  0   3.4  403. 132    -9 154.6
>> >>>>>>>>>> 2012 214  1   3.7  388. 132   -10 154.6
>> >>>>>>>>>> 2012 214  2   3.7  383. 132   -10 154.6
>> >>>>>>>>>> 2012 214  3   3.7  391. 132    -9 154.6
>> >>>>>>>>>> 2012 214  4   4.2  399. 132    -7 154.6
>> >>>>>>>>>> 2012 214  5   4.1  411. 132    -6 154.6
>> >>>>>>>>>> 2012 214  6   4.0  407. 132    -6 154.6
>> >>>>>>>>>> 2012 214  7   4.2  404. 132    -4 154.6
>> >>>>>>>>>> 2012 214  8   4.3  405. 132    -6 154.6
>> >>>>>>>>>> 2012 214  9   4.4  409. 132    -6 154.6
>> >>>>>>>>>> 2012 214 10   4.4  401. 132    -6 154.6
>> >>>>>>>>>> 2012 214 11   4.5  385. 132    -7 154.6
>> >>>>>>>>>> 2012 214 12   4.7  377. 132    -8 154.6
>> >>>>>>>>>> 2012 214 13   4.7  382. 132    -6 154.6
>> >>>>>>>>>> 2012 214 14   4.3  396. 132    -4 154.6
>> >>>>>>>>>> 2012 214 15   4.1  384. 132    -2 154.6
>> >>>>>>>>>> 2012 214 16   4.0  382. 132    -1 154.6
>> >>>>>>>>>> 2012 214 17   3.9  397. 132     0 154.6
>> >>>>>>>>>> 2012 214 18   3.8  390. 132     1 154.6
>> >>>>>>>>>> 2012 214 19   4.2  400. 132     2 154.6
>> >>>>>>>>>> 2012 214 20   4.6  408. 132     1 154.6
>> >>>>>>>>>> 2012 214 21   4.8  401. 132    -3 154.6
>> >>>>>>>>>> 2012 214 22   4.9  395. 132    -5 154.6
>> >>>>>>>>>> 2012 214 23   5.0  386. 132    -1 154.6
>> >>>>>>>>>> 2012 215  0   5.0  377. 143    -1 138.6
>> >>>>>>>>>> 2012 215  1   4.9  384. 143    -2 138.6
>> >>>>>>>>>> 2012 215  2   4.9  390. 143    -4 138.6
>> >>>>>>>>>> 2012 215  3   4.9  372. 143    -6 138.6
>> >>>>>>>>>> 2012 215  4   5.1  371. 143    -4 138.6
>> >>>>>>>>>> I want to process it to be of the format as shown below
>> >>>>>>>>>>       y   m  d  hr imf  sws  ssn    Dst f10.7
>> >>>>>>>>>> 2012-08-01 10 3.4  403. 132    -9 154.6
>> >>>>>>>>>> 2012-08-01 12 3.7  388. 132   -10 154.6
>> >>>>>>>>>> 2012-08-01 15 3.7  383. 132   -10 154.6
>> >>>>>>>>>> 2012-08-01 17 3.7  391. 132    -9 154.6
>> >>>>>>>>>> I want to request an R code to accomplish this task. Thanks for
>> >> your
>> >>>>>>>>> time.
>> >>>>>>>>>> *Jibrin Adejoh Alhassan (Ph.D)*
>> >>>>>>>>>> Department of Physics and Astronomy,
>> >>>>>>>>>> University of Nigeria, Nsukka
>> >>>>>>>>>>
>> >>>>>>>>>>           [[alternative HTML version deleted]]
>> >>>>>>>>>>
>> >>>>>>>>>> ______________________________________________
>> >>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> see
>> >>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>>>>>>>> PLEASE do read the posting guide
>> >>>>>>>>> http://www.R-project.org/posting-guide.html
>> >>>>>>>>>> and provide commented, minimal, self-contained, reproducible
>> code.
>> >>>>>>>>> Hello,
>> >>>>>>>>>
>> >>>>>>>>> To create a date column, paste the first two columns and coerce
>> to
>> >>>>>>> class
>> >>>>>>>>> "Date" with conversion specifications %Y for the 4 digit year
>> and
>> >> %j
>> >>>>>>> for
>> >>>>>>>>> the day of year. See
>> >>>>>>>>>
>> >>>>>>>>> help("strptime")
>> >>>>>>>>>
>> >>>>>>>>>
>> >>>>>>>>>
>> >>>>>>>>> df1 <- read.table(text = "YEAR DOY HR   IMF  SW   SSN    Dst
>> f10.7
>> >>>>>>>>> 2012 214  0   3.4  403. 132    -9 154.6
>> >>>>>>>>> 2012 214  1   3.7  388. 132   -10 154.6
>> >>>>>>>>> 2012 214  2   3.7  383. 132   -10 154.6
>> >>>>>>>>> 2012 214  3   3.7  391. 132    -9 154.6
>> >>>>>>>>> 2012 214  4   4.2  399. 132    -7 154.6
>> >>>>>>>>> 2012 214  5   4.1  411. 132    -6 154.6
>> >>>>>>>>> 2012 214  6   4.0  407. 132    -6 154.6
>> >>>>>>>>> 2012 214  7   4.2  404. 132    -4 154.6
>> >>>>>>>>> 2012 214  8   4.3  405. 132    -6 154.6
>> >>>>>>>>> 2012 214  9   4.4  409. 132    -6 154.6
>> >>>>>>>>> 2012 214 10   4.4  401. 132    -6 154.6
>> >>>>>>>>> 2012 214 11   4.5  385. 132    -7 154.6
>> >>>>>>>>> 2012 214 12   4.7  377. 132    -8 154.6
>> >>>>>>>>> 2012 214 13   4.7  382. 132    -6 154.6
>> >>>>>>>>> 2012 214 14   4.3  396. 132    -4 154.6
>> >>>>>>>>> 2012 214 15   4.1  384. 132    -2 154.6
>> >>>>>>>>> 2012 214 16   4.0  382. 132    -1 154.6
>> >>>>>>>>> 2012 214 17   3.9  397. 132     0 154.6
>> >>>>>>>>> 2012 214 18   3.8  390. 132     1 154.6
>> >>>>>>>>> 2012 214 19   4.2  400. 132     2 154.6
>> >>>>>>>>> 2012 214 20   4.6  408. 132     1 154.6
>> >>>>>>>>> 2012 214 21   4.8  401. 132    -3 154.6
>> >>>>>>>>> 2012 214 22   4.9  395. 132    -5 154.6
>> >>>>>>>>> 2012 214 23   5.0  386. 132    -1 154.6
>> >>>>>>>>> 2012 215  0   5.0  377. 143    -1 138.6
>> >>>>>>>>> 2012 215  1   4.9  384. 143    -2 138.6
>> >>>>>>>>> 2012 215  2   4.9  390. 143    -4 138.6
>> >>>>>>>>> 2012 215  3   4.9  372. 143    -6 138.6
>> >>>>>>>>> 2012 215  4   5.1  371. 143    -4 138.6", header = TRUE)
>> >>>>>>>>>
>> >>>>>>>>>
>> >>>>>>>>> with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
>> >>>>>>>>> #>  [1] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>> >>>>>>> "2012-08-01"
>> >>>>>>>>> #>  [6] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>> >>>>>>> "2012-08-01"
>> >>>>>>>>> #> [11] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>> >>>>>>> "2012-08-01"
>> >>>>>>>>> #> [16] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>> >>>>>>> "2012-08-01"
>> >>>>>>>>> #> [21] "2012-08-01" "2012-08-01" "2012-08-01" "2012-08-01"
>> >>>>>>> "2012-08-02"
>> >>>>>>>>> #> [26] "2012-08-02" "2012-08-02" "2012-08-02" "2012-08-02"
>> >>>>>>>>>
>> >>>>>>>>> # now create the column
>> >>>>>>>>> df1$Date <- with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y
>> >> %j")
>> >>>>>>>>> # remove the columns no longer needed
>> >>>>>>>>> df1 <- df1[-(1:2)]
>> >>>>>>>>> # relocate the new date column
>> >>>>>>>>> df1 <- df1[c(ncol(df1), 1:(ncol(df1) - 1L))]
>> >>>>>>>>> head(df1)
>> >>>>>>>>> #>         Date HR IMF  SW SSN Dst f10.7
>> >>>>>>>>> #> 1 2012-08-01  0 3.4 403 132  -9 154.6
>> >>>>>>>>> #> 2 2012-08-01  1 3.7 388 132 -10 154.6
>> >>>>>>>>> #> 3 2012-08-01  2 3.7 383 132 -10 154.6
>> >>>>>>>>> #> 4 2012-08-01  3 3.7 391 132  -9 154.6
>> >>>>>>>>> #> 5 2012-08-01  4 4.2 399 132  -7 154.6
>> >>>>>>>>> #> 6 2012-08-01  5 4.1 411 132  -6 154.6
>> >>>>>>>>>
>> >>>>>>>>>
>> >>>>>>>>> Hope this helps,
>> >>>>>>>>>
>> >>>>>>>>> Rui Barradas
>> >>>>>>>>>
>> >>>>>>>>>
>> >>>>>>>>> --
>> >>>>>>>>> Este e-mail foi analisado pelo software antiv?rus AVG para
>> >> verificar
>> >>>> a
>> >>>>>>>>> presen?a de v?rus.
>> >>>>>>>>> www.avg.com
>> >>>>>>>>>
>> >>>>>>>>
>> >>>>>>> Hello,
>> >>>>>>>
>> >>>>>>> There is an error in your new code:
>> >>>>>>>
>> >>>>>>>
>> >>>>>>> paste YEAR with DOY, not with HR.
>> >>>>>>>
>> >>>>>>>
>> >>>>>>> As for the rest, is your real data like the one you posted before?
>> >>>>>>> If it is then I don't see anything wrong with my (tested)
>> solution.
>> >>>>>>>
>> >>>>>>>
>> >>>>>>> Hope this helps,
>> >>>>>>>
>> >>>>>>> Rui Barradas
>> >>>>>>>
>> >>>>>>>
>> >>>>>>>
>> >>>>>>> --
>> >>>>>>> Este e-mail foi analisado pelo software antiv?rus AVG para
>> verificar
>> >> a
>> >>>>>>> presen?a de v?rus.
>> >>>>>>> www.avg.com
>> >>>>>>>
>> >>>>>>
>> >>>>>
>> >>>> Hello,
>> >>>>
>> >>>> I cannot reproduce any error. T is vectorized so I am not
>> understanding
>> >>>> what you mean by the script only generated one data point.
>> >>>> Here is the same code ran on your new data set, the result is as
>> >> expected.
>> >>>> Note the output of str(). It days that the 1st column is of class
>> "Date"
>> >>>> so it was created from YEAR and DOY and relocated to the 1st
>> position.
>> >>>>
>> >>>> Can you post the output of your final df1? Please post
>> >>>>
>> >>>> head(df1)
>> >>>>
>> >>>>
>> >>>>
>> >>>> # new data
>> >>>> df1 <- read.table("~/rhelp.txt", header = TRUE)
>> >>>>
>> >>>> df1$Date <- with(df1, paste(YEAR, DOY)) |> as.Date(format = "%Y %j")
>> >>>> df1 <- df1[-(1:2)]
>> >>>> df1 <- df1[c(ncol(df1), 1:(ncol(df1) - 1L))]
>> >>>> str(df1)
>> >>>> #> 'data.frame':    436 obs. of  7 variables:
>> >>>> #>  $ Date : Date, format: "2012-01-01" "2012-01-01" ...
>> >>>> #>  $ HR   : int  0 1 2 3 4 5 6 7 8 9 ...
>> >>>> #>  $ IMF  : num  4 4.4 4.8 5.4 4.5 4.2 4.7 4.1 3.2 4.3 ...
>> >>>> #>  $ SWS  : num  379 386 380 374 369 368 367 361 362 367 ...
>> >>>> #>  $ SSN  : int  71 71 71 71 71 71 71 71 71 71 ...
>> >>>> #>  $ Dst  : int  -8 -3 -4 -5 -9 -7 -6 -10 -7 -3 ...
>> >>>> #>  $ f10.7: num  1000 1000 1000 1000 1000 ...
>> >>>> head(df1)
>> >>>> #>         Date HR IMF SWS SSN Dst f10.7
>> >>>> #> 1 2012-01-01  0 4.0 379  71  -8 999.9
>> >>>> #> 2 2012-01-01  1 4.4 386  71  -3 999.9
>> >>>> #> 3 2012-01-01  2 4.8 380  71  -4 999.9
>> >>>> #> 4 2012-01-01  3 5.4 374  71  -5 999.9
>> >>>> #> 5 2012-01-01  4 4.5 369  71  -9 999.9
>> >>>> #> 6 2012-01-01  5 4.2 368  71  -7 999.9
>> >>>>
>> >>>>
>> >>>> Hope this helps,
>> >>>>
>> >>>> Rui Barradas
>> >>>>
>> >>>>
>> >>>> --
>> >>>> Este e-mail foi analisado pelo software antiv?rus AVG para verificar
>> a
>> >>>> presen?a de v?rus.
>> >>>> www.avg.com
>> >>>>
>> >>>
>> >> Hello,
>> >>
>> >> So what's the error? Your output is identical to mine. If the output of
>> >> str(df1) is also identical to what I have posted, then everything works
>> >> as expected.
>> >>
>> >> Hope this helps,
>> >>
>> >> Rui Barradas
>> >>
>> >>
>> >> --
>> >> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
>> >> presen?a de v?rus.
>> >> www.avg.com
>> >>
>> >
>> Hello,
>>
>> "2012-06-27" is YEAR == 2012 and DOY == 179.
>> If that's what you have in the file then there's nothing wrong with that
>> output.
>>
>> And in your last post the df starts in row 4288, is this the problem?
>> The code works, so there must be something with the data.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>> --
>> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
>> presen?a de v?rus.
>> www.avg.com
>>
>

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Wed Jun 19 12:23:17 2024
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Wed, 19 Jun 2024 22:23:17 +1200
Subject: [R] I have Problem using the Pipe Command
In-Reply-To: <CAC8ss3015wumsvaffr6DVcmDuh-cCJaQrT2czwtvAFZ0UbPMkA@mail.gmail.com>
References: <CAC8ss33VCxRNb7iQ+6gKpcGu2hiKqqenMAZQ4UAhvaiuHQZVQg@mail.gmail.com>
 <280fb618-7dfc-475d-b381-5565e0a492fb@gmail.com>
 <87d69a81-708e-4cf9-8d77-ba8936874099@gmail.com>
 <26226.35203.8166.862725@stat.math.ethz.ch>
 <CAC8ss3015wumsvaffr6DVcmDuh-cCJaQrT2czwtvAFZ0UbPMkA@mail.gmail.com>
Message-ID: <CABcYAdKvfBmHxEr1bi76ia6kMc07qo1h-bj2vNKM++42w3GJjw@mail.gmail.com>

You can get an external 1TB hard drive for NZD 60 if you shop around.
That's USD 37 or GBP 29.
How much data do you have and how valuable?
You don't need a whole 'nother laptop to backup!
If you did, you could get a 2nd-hand laptop adequate for the purpose
for NZD 150 (USD 92, GBP 72).
Again, how much data do you have and how valuable?
A new 64 GB memory stick is just NZD 8 (I'll let you do your own
currency conversion).

R works very well with data held outside R in formats that are not R-specific.
I would expect (the master copies of) your documents and data to be held
outside the directory where R is installed and in formats (like .csv)
that are the
same no matter which version of R you use to read them, so it's not clear why
upgrading R should put your documents and data at risk.

In any case:
 - which files should be backed up?  All of them.
 - when is the right time to back them up?  Now.
 - what should it cost me to take backups?   A lot less than losing your data.
   And even if you buy another 2nd-hand laptop to do it, less than a day's pay.

On Wed, 19 Jun 2024 at 20:08, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
>
> Dear Martin,
> I agree with you. I am anxious to upgrade. But I am afraid of losing some
> data on my only one system. I do not have enough backup.
>
> I am planning to buy a backup laptop before venturing to upgrade.
>
> But if there is any possibility of upgrading without losing my
> documents/data, I would gladly go with that.
>
> Please let me know whether it is possible.
>
> Many thanks for your time.
>
> Warm regards
> Ogbos
>
> On Wed, Jun 19, 2024 at 8:38?AM Martin Maechler <maechler at stat.math.ethz.ch>
> wrote:
>
> > >>>>> Duncan Murdoch
> > >>>>>     on Tue, 18 Jun 2024 12:25:49 -0400 writes:
> >
> >     > On 2024-06-18 12:17 p.m., Ben Bolker wrote:
> >     >> You probably have to update your R version. The native pipe |>
> > wasn't
> >     >> introduced until R version 4.4.  R.version.string (among others)
> > will
> >     >> tell you what version you have.
> >
> >     > Typo: it was introduced in R 4.1.0.
> >
> >     > Another possible problem is with line breaks.  This works:
> >
> >     > 1:10 |>
> >     > mean()
> >
> >     > but this fails:
> >
> >     > 1:10
> >     > |> mean()
> >
> >     > Duncan Murdoch
> >
> > Yes, of course (as I know you know), the same way that
> >
> >     >  1:10
> >     >  + 1
> >
> > does "not" work.
> >
> >
> >
> >     >> If you don't want to do that, install and load the 'magrittr'
> > package
> >     >> and change |> to %>% everywhere.
> >
> > I really think that in June 2024  you (Ogbos) should not run
> > "productively" an R version that is older than May 2021 (where R
> > 4.1.0 was released) :
> >
> >   $ R-4.1.0 --version | head 1
> >   R version 4.1.0 (2021-05-18) -- "Camp Pontanezen"
> >
> >   $ R-4.1.0 --vanilla -s -e '1:10|>sum()'
> >   [1] 55
> >   $
> >
> > So upgrading your R to current (R 4.4.1)  is *very* much recommended.
> >
> > Martin Maechler
> >
> >
> >     >> On 2024-06-18 12:13 p.m., Ogbos Okike wrote:
> >     >>> Greetings to everyone and thank you for your readiness to help.
> >     >>>
> >     >>> I have problems using the pipe command (|>).
> >     >>>
> >     >>> Once I have it in any script on my system, it won't.
> >     >>>
> >     >>> The error message will say:
> >     >>>
> >     >>> unexpected '>'
> >     >>> I loaded the two packages below to see if it would handle it. But
> > the
> >     >>> problem remains.
> >     >>> library(magrittr)
> >     >>> library(dplyr)
> >     >>>
> >     >>> I searched to see if there was a way to install the command. But I
> > was not
> >     >>> successful.
> >     >>>
> >     >>> Please tell me what to do to be able to use the pipe command on my
> > system.
> >     >>> I would be grateful for any help.
> >     >>> Thank you.
> >     >>>
> >     >>> Sincerely yours
> >     >>> Ogbos
> >     >>>
> >     >>> [[alternative HTML version deleted]]
> >     >>>
> >     >>> ______________________________________________
> >     >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >     >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >     >>> PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> >     >>> and provide commented, minimal, self-contained, reproducible code.
> >     >>
> >     >> ______________________________________________
> >     >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >     >> https://stat.ethz.ch/mailman/listinfo/r-help
> >     >> PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> >     >> and provide commented, minimal, self-contained, reproducible code.
> >
> >     > ______________________________________________
> >     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >     > https://stat.ethz.ch/mailman/listinfo/r-help
> >     > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> >     > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From t@nguy@b@rthe|emy @end|ng |rom |n@ee@|r  Tue Jun 18 12:12:04 2024
From: t@nguy@b@rthe|emy @end|ng |rom |n@ee@|r (Barthelemy Tanguy)
Date: Tue, 18 Jun 2024 10:12:04 +0000
Subject: [R] Bug with writeClipboard in {utils}
Message-ID: <ecb5eeea68b64461a09b416c68d0a0d1@insee.fr>

Hello,

I'm encountering what seems to be a bug when using the `writeClipboard()` function in the R {utils} package.
When I try to copy text to the clipboard, I notice that I get extra characters when I try to paste it (by hand with CTRL+V or with the `readClipboard()` function from R packages {utils}).

Here's my example:

``` r
utils::writeClipboard("plot(AirPassengers)")
for (k in 1:10) {
    print(utils::readClipboard())
}
#> [1] "plot(AirPassengers)" "??"
#> [1] "plot(AirPassengers)" "\u0a00"
#> [1] "plot(AirPassengers)" "\xed\xb0\x80?"
#> [1] "plot(AirPassengers)"
#> [1] "plot(AirPassengers)"
#> [1] "plot(AirPassengers)"
#> [1] "plot(AirPassengers)"
#> [1] "plot(AirPassengers)"
#> [1] "plot(AirPassengers)" "?"
#> [1] "plot(AirPassengers)"
Message d'avis :
Dans utils::readClipboard() : unpaired surrogate Unicode point dc00
```

So I don't always get the same result.
I opened a problem in the {clipr} GitHub repository before realizing it's a {tools} problem: https://github.com/mdlincoln/clipr/issues/68

Is this a bug or something I haven't configured properly?


Thank you very much


Tanguy BARTHELEMY


	[[alternative HTML version deleted]]


From |kry|ov @end|ng |rom d|@root@org  Wed Jun 19 16:07:07 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Wed, 19 Jun 2024 17:07:07 +0300
Subject: [R] Bug with writeClipboard in {utils}
In-Reply-To: <ecb5eeea68b64461a09b416c68d0a0d1@insee.fr>
References: <ecb5eeea68b64461a09b416c68d0a0d1@insee.fr>
Message-ID: <20240619170707.096d4aad@arachnoid>

? Tue, 18 Jun 2024 10:12:04 +0000
Barthelemy Tanguy via R-help <r-help at r-project.org> ?????:

> #> [1] "plot(AirPassengers)" "??"
> #> [1] "plot(AirPassengers)" "\u0a00"
> #> [1] "plot(AirPassengers)" "\xed\xb0\x80?"

Thanks for showing an example!

I was able to reproduce it both with R-4.3.1 on Windows 7 and with a
fresh R-devel build on Windows 10. Bug reported at
<https://bugs.r-project.org/show_bug.cgi?id=18747>.

-- 
Best regards,
Ivan


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Jun 19 19:26:16 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 19 Jun 2024 18:26:16 +0100
Subject: [R] Bug with writeClipboard in {utils}
In-Reply-To: <ecb5eeea68b64461a09b416c68d0a0d1@insee.fr>
References: <ecb5eeea68b64461a09b416c68d0a0d1@insee.fr>
Message-ID: <d006e769-a856-4965-9d1a-1cd2aa4d5f03@sapo.pt>

?s 11:12 de 18/06/2024, Barthelemy Tanguy via R-help escreveu:
> Hello,
> 
> I'm encountering what seems to be a bug when using the `writeClipboard()` function in the R {utils} package.
> When I try to copy text to the clipboard, I notice that I get extra characters when I try to paste it (by hand with CTRL+V or with the `readClipboard()` function from R packages {utils}).
> 
> Here's my example:
> 
> ``` r
> utils::writeClipboard("plot(AirPassengers)")
> for (k in 1:10) {
>      print(utils::readClipboard())
> }
> #> [1] "plot(AirPassengers)" "??"
> #> [1] "plot(AirPassengers)" "\u0a00"
> #> [1] "plot(AirPassengers)" "\xed\xb0\x80?"
> #> [1] "plot(AirPassengers)"
> #> [1] "plot(AirPassengers)"
> #> [1] "plot(AirPassengers)"
> #> [1] "plot(AirPassengers)"
> #> [1] "plot(AirPassengers)"
> #> [1] "plot(AirPassengers)" "?"
> #> [1] "plot(AirPassengers)"
> Message d'avis :
> Dans utils::readClipboard() : unpaired surrogate Unicode point dc00
> ```
> 
> So I don't always get the same result.
> I opened a problem in the {clipr} GitHub repository before realizing it's a {tools} problem: https://github.com/mdlincoln/clipr/issues/68
> 
> Is this a bug or something I haven't configured properly?
> 
> 
> Thank you very much
> 
> 
> Tanguy BARTHELEMY
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

I have reproduced part of the behavior in the OP but it will depend on 
the GUI or command line used.

With Rscript or with R I haven't found any errors.
With Rgui or with RStudio, yes, the output was not the expected output.

All code run in R 4.4.0 on Windows 11.

The script rscript.R is


utils::capture.output({
utils::writeClipboard("plot(AirPassengers)")
for (k in 1:10) {
   print(utils::readClipboard())
}
sessionInfo()
}, file = "rhelp.txt")


---

Here are the results I got.

1) Command:

Rscript rscript.R

Output:

[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
R version 4.4.0 (2024-04-24 ucrt)
Platform: x86_64-w64-mingw32/x64
Running under: Windows 11 x64 (build 22631)

Matrix products: default


locale:
[1] LC_COLLATE=Portuguese_Portugal.utf8 
LC_CTYPE=Portuguese_Portugal.utf8
[3] LC_MONETARY=Portuguese_Portugal.utf8 LC_NUMERIC=C 

[5] LC_TIME=Portuguese_Portugal.utf8

time zone: Europe/Lisbon
tzcode source: internal

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_4.4.0

---

2) Command:
R -q -f rscript.R

Output:

 > utils::writeClipboard("plot(AirPassengers)")
 > for (k in 1:10) {
+     print(utils::readClipboard())
+ }
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)" "??\005"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
 > sessionInfo()
R version 4.4.0 (2024-04-24 ucrt)
Platform: x86_64-w64-mingw32/x64
Running under: Windows 11 x64 (build 22631)

Matrix products: default


locale:
[1] LC_COLLATE=Portuguese_Portugal.utf8 
LC_CTYPE=Portuguese_Portugal.utf8
[3] LC_MONETARY=Portuguese_Portugal.utf8 LC_NUMERIC=C 

[5] LC_TIME=Portuguese_Portugal.utf8

time zone: Europe/Lisbon
tzcode source: internal

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_4.4.0
 >

---

3) GUI: RStudio
Output:

[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)" "?????e"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)" "??"
[1] "plot(AirPassengers)" "?????e"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[2] "?????eX???????????????????????"
[1] "plot(AirPassengers)" "??"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
R version 4.4.0 (2024-04-24 ucrt)
Platform: x86_64-w64-mingw32/x64
Running under: Windows 11 x64 (build 22631)

Matrix products: default


locale:
[1] LC_COLLATE=Portuguese_Portugal.utf8 
LC_CTYPE=Portuguese_Portugal.utf8
[3] LC_MONETARY=Portuguese_Portugal.utf8 LC_NUMERIC=C 

[5] LC_TIME=Portuguese_Portugal.utf8

time zone: Europe/Lisbon
tzcode source: internal

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
  [1] gtable_0.3.4         tensorA_0.36.2.1     ggplot2_3.5.0
  [4] QuickJSR_1.1.3       processx_3.8.3       inline_0.3.19
  [7] lattice_0.22-5       tzdb_0.4.0           callr_3.7.5
[10] vctrs_0.6.5          tools_4.4.0          ps_1.7.6
[13] generics_0.1.3       stats4_4.4.0         curl_5.2.1
[16] parallel_4.4.0       sandwich_3.1-0       tibble_3.2.1
[19] fansi_1.0.6          chron_2.3-61         pkgconfig_2.0.3
[22] brms_2.21.0          Matrix_1.6-5         checkmate_2.3.1
[25] distributional_0.4.0 RcppParallel_5.1.7   lifecycle_1.0.4
[28] compiler_4.4.0       stringr_1.5.1        Brobdingnag_1.2-9
[31] munsell_0.5.0        codetools_0.2-19     bayesplot_1.11.1
[34] pillar_1.9.0         crayon_1.5.2         MASS_7.3-60.0.1
[37] StanHeaders_2.32.6   bridgesampling_1.1-2 abind_1.4-5
[40] multcomp_1.4-25      nlme_3.1-164         posterior_1.5.0
[43] rstan_2.32.5         tidyselect_1.2.0     mvtnorm_1.2-3
[46] stringi_1.7.12       dplyr_1.1.4          splines_4.4.0
[49] grid_4.4.0           colorspace_2.1-0     cli_3.6.2
[52] magrittr_2.0.3       loo_2.6.0            survival_3.5-8
[55] pkgbuild_1.4.2       utf8_1.2.4           TH.data_1.1-2
[58] readr_2.1.4          prettyunits_1.2.0    scales_1.3.0
[61] backports_1.4.1      estimability_1.5     httr_1.4.7
[64] matrixStats_1.0.0    emmeans_1.10.0       gridExtra_2.3
[67] hms_1.1.3            zoo_1.8-12           coda_0.19-4.1
[70] V8_4.4.2             rstantools_2.3.1.1   rlang_1.1.3
[73] Rcpp_1.0.12          xtable_1.8-4         glue_1.7.0
[76] ppcor_1.1            rstudioapi_0.15.0    jsonlite_1.8.8
[79] R6_2.5.1

---

4) GUI: Rgui
Output:

[1] "plot(AirPassengers)" "??\005???"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
R version 4.4.0 (2024-04-24 ucrt)
Platform: x86_64-w64-mingw32/x64
Running under: Windows 11 x64 (build 22631)

Matrix products: default


locale:
[1] LC_COLLATE=Portuguese_Portugal.utf8 
LC_CTYPE=Portuguese_Portugal.utf8
[3] LC_MONETARY=Portuguese_Portugal.utf8 LC_NUMERIC=C 

[5] LC_TIME=Portuguese_Portugal.utf8

time zone: Europe/Lisbon
tzcode source: internal

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_4.4.0



Hope this helps,

Rui Barradas




-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From dynvec @end|ng |rom gm@||@com  Thu Jun 20 08:01:16 2024
From: dynvec @end|ng |rom gm@||@com (DynV Montrealer)
Date: Thu, 20 Jun 2024 02:01:16 -0400
Subject: [R] plot(aov, which=1) with different labels?
Message-ID: <CAGYhDoM=z_iuarce8szQrLQAgGKkvDuNOxXfF189h0QVLiDZ0A@mail.gmail.com>

I need to do a non-English report including the red line from plot(aov,
which=1), which I don't know how to reproduce. I'm thinking that if I
replace the labels that it would be good (so no English remains). What I
have so far is almost what I need, the only thing that needs to change is
what's right above the plot: Residuals vs Fitted; I'd like it to either be
changed to "R?sidus vs Valeurs pr?dites" or not be displayed. Covering up
"Residuals vs Fitted" seems like a good alternative, perhaps to do so would
require plot(aov, which=1) to be assigned in an object then modify that
object then display it. How I got to where I am:
my_aov <- aov(...) plot(my_aov, which=1, ann=FALSE) title(main="Mon titre",
xlab="Valeurs pr?dites", ylab="R?sidus")

Thank you kindly for your help

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Jun 20 10:37:35 2024
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 20 Jun 2024 04:37:35 -0400
Subject: [R] plot(aov, which=1) with different labels?
In-Reply-To: <CAGYhDoM=z_iuarce8szQrLQAgGKkvDuNOxXfF189h0QVLiDZ0A@mail.gmail.com>
References: <CAGYhDoM=z_iuarce8szQrLQAgGKkvDuNOxXfF189h0QVLiDZ0A@mail.gmail.com>
Message-ID: <f00ba172-3ed3-4860-b328-b8b3953a93d0@gmail.com>

On 2024-06-20 2:01 a.m., DynV Montrealer wrote:
> I need to do a non-English report including the red line from plot(aov,
> which=1), which I don't know how to reproduce. I'm thinking that if I
> replace the labels that it would be good (so no English remains). What I
> have so far is almost what I need, the only thing that needs to change is
> what's right above the plot: Residuals vs Fitted; I'd like it to either be
> changed to "R?sidus vs Valeurs pr?dites" or not be displayed. Covering up
> "Residuals vs Fitted" seems like a good alternative, perhaps to do so would
> require plot(aov, which=1) to be assigned in an object then modify that
> object then display it. How I got to where I am:
> my_aov <- aov(...) plot(my_aov, which=1, ann=FALSE) title(main="Mon titre",
> xlab="Valeurs pr?dites", ylab="R?sidus")
> 
> Thank you kindly for your help

Plotting an aov object is done by stats:::plot.lm.  From the help page 
?plot.lm, I think the value that you want to change is the "caption" 
argument, i.e.


  plot(my_aov, which=1, ann=FALSE,
        caption = "R?sidus vs Valeurs pr?dites")
  title(xlab="Valeurs pr?dites", ylab="R?sidus", main="Mon titre")

You can use `caption = NA` to suppress it.

Duncan Murdoch


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Jun 20 16:44:30 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 20 Jun 2024 15:44:30 +0100
Subject: [R] Bug with writeClipboard in {utils}
In-Reply-To: <844b5fbe711b4865ba96d0c9ace03f12@insee.fr>
References: <ecb5eeea68b64461a09b416c68d0a0d1@insee.fr>
 <d006e769-a856-4965-9d1a-1cd2aa4d5f03@sapo.pt>
 <844b5fbe711b4865ba96d0c9ace03f12@insee.fr>
Message-ID: <bfc0d0ae-cf48-47c2-b00e-c2b966618f4e@sapo.pt>

Hello,

Inline.

?s 14:15 de 20/06/2024, Barthelemy Tanguy escreveu:
> Hello,
> 
> Thank you for your different tests.
> 
> You have that you didn't find any errors with Rscript or with R but I have the impression that your test with R (second test) showed additional and unwanted characters (second line of the output)?

You are right, in the case I posted there were unwanted characters.
Most of the tests I ran there were no additional, unwanted charcters, 
though.
This is definitely unstable, that's all I can say.

Hope this helps,

Rui Barradas
> 
> Thank you again
> 
> Tanguy BARTHELEMY
> 
> 
> ________________________________
> De : Rui Barradas <ruipbarradas at sapo.pt>
> Envoy? : mercredi 19 juin 2024 19:26
> ? : Barthelemy Tanguy; r-help at r-project.org
> Objet : Re: [R] Bug with writeClipboard in {utils}
> 
> ? Ce courriel provient d?un exp?diteur ext?rieur ? l?Insee. Compte tenu du contexte de menace cyber actuel il convient d??tre extr?mement vigilant sur l??metteur et son contenu avant d?ouvrir une pi?ce jointe, de cliquer sur un lien internet pr?sent dans ce message ou d'y r?pondre. ?
> 
> 
> ?s 11:12 de 18/06/2024, Barthelemy Tanguy via R-help escreveu:
>> Hello,
>>
>> I'm encountering what seems to be a bug when using the `writeClipboard()` function in the R {utils} package.
>> When I try to copy text to the clipboard, I notice that I get extra characters when I try to paste it (by hand with CTRL+V or with the `readClipboard()` function from R packages {utils}).
>>
>> Here's my example:
>>
>> ``` r
>> utils::writeClipboard("plot(AirPassengers)")
>> for (k in 1:10) {
>>       print(utils::readClipboard())
>> }
>> #> [1] "plot(AirPassengers)" "??"
>> #> [1] "plot(AirPassengers)" "\u0a00"
>> #> [1] "plot(AirPassengers)" "\xed\xb0\x80?"
>> #> [1] "plot(AirPassengers)"
>> #> [1] "plot(AirPassengers)"
>> #> [1] "plot(AirPassengers)"
>> #> [1] "plot(AirPassengers)"
>> #> [1] "plot(AirPassengers)"
>> #> [1] "plot(AirPassengers)" "?"
>> #> [1] "plot(AirPassengers)"
>> Message d'avis :
>> Dans utils::readClipboard() : unpaired surrogate Unicode point dc00
>> ```
>>
>> So I don't always get the same result.
>> I opened a problem in the {clipr} GitHub repository before realizing it's a {tools} problem: https://github.com/mdlincoln/clipr/issues/68
>>
>> Is this a bug or something I haven't configured properly?
>>
>>
>> Thank you very much
>>
>>
>> Tanguy BARTHELEMY
>>
>>
>>        [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> Hello,
> 
> I have reproduced part of the behavior in the OP but it will depend on
> the GUI or command line used.
> 
> With Rscript or with R I haven't found any errors.
> With Rgui or with RStudio, yes, the output was not the expected output.
> 
> All code run in R 4.4.0 on Windows 11.
> 
> The script rscript.R is
> 
> 
> utils::capture.output({
> utils::writeClipboard("plot(AirPassengers)")
> for (k in 1:10) {
>     print(utils::readClipboard())
> }
> sessionInfo()
> }, file = "rhelp.txt")
> 
> 
> ---
> 
> Here are the results I got.
> 
> 1) Command:
> 
> Rscript rscript.R
> 
> Output:
> 
> [1] "plot(AirPassengers)"
> [1] "plot(AirPassengers)"
> [1] "plot(AirPassengers)"
> [1] "plot(AirPassengers)"
> [1] "plot(AirPassengers)"
> [1] "plot(AirPassengers)"
> [1] "plot(AirPassengers)"
> [1] "plot(AirPassengers)"
> [1] "plot(AirPassengers)"
> [1] "plot(AirPassengers)"
> R version 4.4.0 (2024-04-24 ucrt)
> Platform: x86_64-w64-mingw32/x64
> Running under: Windows 11 x64 (build 22631)
> 
> Matrix products: default
> 
> 
> locale:
> [1] LC_COLLATE=Portuguese_Portugal.utf8
> LC_CTYPE=Portuguese_Portugal.utf8
> [3] LC_MONETARY=Portuguese_Portugal.utf8 LC_NUMERIC=C
> 
> [5] LC_TIME=Portuguese_Portugal.utf8
> 
> time zone: Europe/Lisbon
> tzcode source: internal
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] compiler_4.4.0
> 
> ---
> 
> 2) Command:
> R -q -f rscript.R
> 
> Output:
> 
>   > utils::writeClipboard("plot(AirPassengers)")
>   > for (k in 1:10) {
> +     print(utils::readClipboard())
> + }
> [1] "plot(AirPassengers)"
> [1] "plot(AirPassengers)" "??\005"
> [1] "plot(AirPassengers)"
> [1] "plot(AirPassengers)"
> [1] "plot(AirPassengers)"
> [1] "plot(AirPassengers)"
> [1] "plot(AirPassengers)"
> [1] "plot(AirPassengers)"
> [1] "plot(AirPassengers)"
> [1] "plot(AirPassengers)"
>   > sessionInfo()
> R version 4.4.0 (2024-04-24 ucrt)
> Platform: x86_64-w64-mingw32/x64
> Running under: Windows 11 x64 (build 22631)
> 
> Matrix products: default
> 
> 
> locale:
> [1] LC_COLLATE=Portuguese_Portugal.utf8
> LC_CTYPE=Portuguese_Portugal.utf8
> [3] LC_MONETARY=Portuguese_Portugal.utf8 LC_NUMERIC=C
> 
> [5] LC_TIME=Portuguese_Portugal.utf8
> 
> time zone: Europe/Lisbon
> tzcode source: internal
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] compiler_4.4.0
>   >
> 
> ---
> 
> 3) GUI: RStudio
> Output:
> 
> [1] "plot(AirPassengers)"
> [1] "plot(AirPassengers)" "?????e"
> [1] "plot(AirPassengers)"
> [1] "plot(AirPassengers)" "??"
> [1] "plot(AirPassengers)" "?????e"
> [1] "plot(AirPassengers)"
> [1] "plot(AirPassengers)"
> [2] "?????eX???????????????????????"
> [1] "plot(AirPassengers)" "??"
> [1] "plot(AirPassengers)"
> [1] "plot(AirPassengers)"
> R version 4.4.0 (2024-04-24 ucrt)
> Platform: x86_64-w64-mingw32/x64
> Running under: Windows 11 x64 (build 22631)
> 
> Matrix products: default
> 
> 
> locale:
> [1] LC_COLLATE=Portuguese_Portugal.utf8
> LC_CTYPE=Portuguese_Portugal.utf8
> [3] LC_MONETARY=Portuguese_Portugal.utf8 LC_NUMERIC=C
> 
> [5] LC_TIME=Portuguese_Portugal.utf8
> 
> time zone: Europe/Lisbon
> tzcode source: internal
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
>    [1] gtable_0.3.4         tensorA_0.36.2.1     ggplot2_3.5.0
>    [4] QuickJSR_1.1.3       processx_3.8.3       inline_0.3.19
>    [7] lattice_0.22-5       tzdb_0.4.0           callr_3.7.5
> [10] vctrs_0.6.5          tools_4.4.0          ps_1.7.6
> [13] generics_0.1.3       stats4_4.4.0         curl_5.2.1
> [16] parallel_4.4.0       sandwich_3.1-0       tibble_3.2.1
> [19] fansi_1.0.6          chron_2.3-61         pkgconfig_2.0.3
> [22] brms_2.21.0          Matrix_1.6-5         checkmate_2.3.1
> [25] distributional_0.4.0 RcppParallel_5.1.7   lifecycle_1.0.4
> [28] compiler_4.4.0       stringr_1.5.1        Brobdingnag_1.2-9
> [31] munsell_0.5.0        codetools_0.2-19     bayesplot_1.11.1
> [34] pillar_1.9.0         crayon_1.5.2         MASS_7.3-60.0.1
> [37] StanHeaders_2.32.6   bridgesampling_1.1-2 abind_1.4-5
> [40] multcomp_1.4-25      nlme_3.1-164         posterior_1.5.0
> [43] rstan_2.32.5         tidyselect_1.2.0     mvtnorm_1.2-3
> [46] stringi_1.7.12       dplyr_1.1.4          splines_4.4.0
> [49] grid_4.4.0           colorspace_2.1-0     cli_3.6.2
> [52] magrittr_2.0.3       loo_2.6.0            survival_3.5-8
> [55] pkgbuild_1.4.2       utf8_1.2.4           TH.data_1.1-2
> [58] readr_2.1.4          prettyunits_1.2.0    scales_1.3.0
> [61] backports_1.4.1      estimability_1.5     httr_1.4.7
> [64] matrixStats_1.0.0    emmeans_1.10.0       gridExtra_2.3
> [67] hms_1.1.3            zoo_1.8-12           coda_0.19-4.1
> [70] V8_4.4.2             rstantools_2.3.1.1   rlang_1.1.3
> [73] Rcpp_1.0.12          xtable_1.8-4         glue_1.7.0
> [76] ppcor_1.1            rstudioapi_0.15.0    jsonlite_1.8.8
> [79] R6_2.5.1
> 
> ---
> 
> 4) GUI: Rgui
> Output:
> 
> [1] "plot(AirPassengers)" "??\005???"
> [1] "plot(AirPassengers)"
> [1] "plot(AirPassengers)"
> [1] "plot(AirPassengers)"
> [1] "plot(AirPassengers)"
> [1] "plot(AirPassengers)"
> [1] "plot(AirPassengers)"
> [1] "plot(AirPassengers)"
> [1] "plot(AirPassengers)"
> [1] "plot(AirPassengers)"
> R version 4.4.0 (2024-04-24 ucrt)
> Platform: x86_64-w64-mingw32/x64
> Running under: Windows 11 x64 (build 22631)
> 
> Matrix products: default
> 
> 
> locale:
> [1] LC_COLLATE=Portuguese_Portugal.utf8
> LC_CTYPE=Portuguese_Portugal.utf8
> [3] LC_MONETARY=Portuguese_Portugal.utf8 LC_NUMERIC=C
> 
> [5] LC_TIME=Portuguese_Portugal.utf8
> 
> time zone: Europe/Lisbon
> tzcode source: internal
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] compiler_4.4.0
> 
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
> 
> 
> --
> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
> www.avg.com<http://www.avg.com>


From |kry|ov @end|ng |rom d|@root@org  Thu Jun 20 17:37:39 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Thu, 20 Jun 2024 18:37:39 +0300
Subject: [R] Integration of functions with a vector argument
In-Reply-To: <PH0PR22MB28606A4C8C09D6738A403F19C5CE2@PH0PR22MB2860.namprd22.prod.outlook.com>
References: <PH0PR22MB2860E3ABD206953D15F31EFAC5C72@PH0PR22MB2860.namprd22.prod.outlook.com>
 <20240612134119.72e4cab6@Tarkus>
 <PH0PR22MB28605CCF2898AD2EC336DCCBC5C02@PH0PR22MB2860.namprd22.prod.outlook.com>
 <20240613132121.1847edee@arachnoid>
 <PH0PR22MB28606A4C8C09D6738A403F19C5CE2@PH0PR22MB2860.namprd22.prod.outlook.com>
Message-ID: <20240620183739.19266eb1@arachnoid>

? Tue, 18 Jun 2024 23:12:03 +0000
"Levine, Michael" <mlevins at purdue.edu> ?????:

> I have heard of several packages used for numerical integration in R -
> cubature that you mentioned, mvQuad, and pracma.  My impression is
> that you think that Cubature is the best in your opinion. Is that so?

Yes, but the preference is not very strong. My own numerical
integration experience is limited to using QUADPACK in a project where
everything had to be rewritten in Fortran for speed.

I trust the code of the 'cubature' library by Steven G. Johnson (whose
work includes FFTW and NLopt) and the 'Cuba' library by Thomas Hahn.
The 'cubature' R package wraps these two libraries. Unfortunately, as
you see, its documentation can be lacking.

Like 'cubature', the 'mvQuad' package won't require a significant
rewrite of the integrand because it expects its functions to take
matrices of arguments. Unfortunately, the two packages differ in the
meanings they assign to the matrices: in 'cubature', individual
arguments of the function correspond to the rows of the first argument,
while in 'mvQuad', they must be in the columns.

The 'mvQuad' package requires manual adjustments to the generated
quadratures using rescale(...), which may be not very convenient.

The 'pracma' package contains implementations of a lot of excellent
methods (I've trusted it before for its other functions), but the (two-
or three-argument) integrand will have to be rewritten to accept
separate arrays (of arbitrary shape?) instead of a single matrix.

> If yes, do you know of any detailed discussion of this package beyond
> the two vignettes available on CRAN?

I don't know how much it can help, but more information about the
underlying code for 'cubature' can be found at
<https://github.com/stevengj/cubature> and <https://feynarts.de/cuba/>.

-- 
Best regards,
Ivan


From |kry|ov @end|ng |rom d|@root@org  Thu Jun 20 17:39:34 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Thu, 20 Jun 2024 18:39:34 +0300
Subject: [R] Bug with writeClipboard in {utils}
In-Reply-To: <a016cb321bbc448ea1d7a0a233d0b0c8@insee.fr>
References: <ecb5eeea68b64461a09b416c68d0a0d1@insee.fr>
 <20240619170707.096d4aad@arachnoid>
 <a016cb321bbc448ea1d7a0a233d0b0c8@insee.fr>
Message-ID: <20240620183934.62a58154@arachnoid>

? Thu, 20 Jun 2024 13:21:38 +0000
Barthelemy Tanguy <tanguy.barthelemy at insee.fr> ?????:

> Is there a way to test this patch or will there soon be a published
> patched R version available for download?

Not directly. If you're willing to follow the partially manual process
yourself, the instructions at [1] describe how to download R-devel and
compile the program. It's not spelled out anywhere how to apply patches
(some work is in progress at [2]), so feel free to ask additional
questions about `svn patch` if you would like to go this way.

Alternatively, taking a patch and submitting it as a pull request to
https://github.com/r-devel/r-svn will result in several checks being
run on it, one of which builds an R installer (e.g. see the artifacts
at [3]).

The remaining option is to wait for the bug to be fixed. Allocating
enough space for the terminator is probably necessary, but the R
developers may also decide to make readClipboard() more robust against
missing terminators.

Some fixes can be backported to R-patched; snapshots of R-patched
compiled for Windows are available from CRAN. R-patched may eventually
become R-4.4.2. If not backported, the fix will appear in the next
version of R.

-- 
Best regards,
Ivan

[1]
https://cran.r-project.org/bin/windows/base/howto-R-devel.html#building-r-from-source-using-rtools44

[2]
https://github.com/r-devel/rdevguide/issues/170

[3]
https://github.com/r-devel/r-svn/actions/runs/8749727418


From |kry|ov @end|ng |rom d|@root@org  Thu Jun 20 18:07:50 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Thu, 20 Jun 2024 19:07:50 +0300
Subject: [R] What is the HEX code for "transparent" color?
In-Reply-To: <CADg5kN1MTSnWe2QqC=Lujv61EXct2U0os_UBsv06-Dj+rXWK7g@mail.gmail.com>
References: <CADg5kN3dTkDWj6buW5FV2ujpu3JLF4YUFSbzj7_Rw=y2EkMoqA@mail.gmail.com>
 <CADg5kN1MTSnWe2QqC=Lujv61EXct2U0os_UBsv06-Dj+rXWK7g@mail.gmail.com>
Message-ID: <20240620190750.09ef4944@arachnoid>

? Mon, 17 Jun 2024 19:38:21 +0200
Yosu Yurramendi <yosu.yurramendi at gmail.com> ?????:

>   output$distPlot <- renderPlot({
>     numrows <- 3; numcols <- 3
>     a <- c(1,0,1,1,1,1,1,0,1)
>     pattern <- matrix(a, numrows, numcols, byrow=TRUE)
>         palette <- c("#00000000", "black")
>         par(bg="#00000000")
>     #
>     image(t(pattern), col = palette, axes = FALSE)
>   })

Shiny is a bit different.

First of all, try to use the Web Developer toolbar in your browser to
look at the plot image that gets served to you. It could be that the
image has transparent background, but some other element that
encompasses the image may have a non-transparent background. You may
need to style the rest of the output somehow.

If the image does have a non-transparent background, try passing the
argument bg = 'transparent' to renderPlot. The documentation [*] says
that the arguments are passed to plotPNG(...) and, eventually, to
ragg::agg_png(...) / png(...) / Cairo::CairoPNG(), all of which should
support the parameter.

-- 
Best regards,
Ivan

[*] https://search.r-project.org/CRAN/refmans/shiny/html/renderPlot.html


From |kry|ov @end|ng |rom d|@root@org  Thu Jun 20 18:49:23 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Thu, 20 Jun 2024 19:49:23 +0300
Subject: [R] 
 unable to get barchart of censored subjects from ggsurvplot()
 in survminer package, if there is no predcitor
In-Reply-To: <05b1b5bb-2938-274a-9841-450ca3095355@binghamton.edu>
References: <05b1b5bb-2938-274a-9841-450ca3095355@binghamton.edu>
Message-ID: <20240620194923.6d0530e6@arachnoid>

? Mon, 17 Jun 2024 15:53:16 -0400
"Christopher W. Ryan via R-help" <r-help at r-project.org> ?????:

> Caused by error:
> ! Unknown colour name: strata"
> about "uknown colour name strata"
> ## but there are no strata

rlang::last_trace() demonstrates that the error happens because some
code receives a string 'strata' and tries to decode it as a name of a
colour:

farver::decode_colour('strata')
# Error: Unknown colour name: strata

This appears to originate from the first layer of the ncensor.plot:

p <- ggsurvplot(
 fit,
 data = lung,
 xlab = "Time in days",
 ncensor.plot = TRUE
)
p$ncensor.plot$layers[[1]]$aes_params
# $colour
# [1] "strata"
# 
# $fill
# [1] "strata"

This can be traced further but I'm not sure how to fix the bug without
strata. Giving an explicit argument color = 'black' to ggsurvplot()
results in a warning but at least doesn't raise an error while drawing
the plot.

-- 
Best regards,
Ivan


From bgunter@4567 @end|ng |rom gm@||@com  Thu Jun 20 19:01:54 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 20 Jun 2024 10:01:54 -0700
Subject: [R] Integration of functions with a vector argument
In-Reply-To: <20240620183739.19266eb1@arachnoid>
References: <PH0PR22MB2860E3ABD206953D15F31EFAC5C72@PH0PR22MB2860.namprd22.prod.outlook.com>
 <20240612134119.72e4cab6@Tarkus>
 <PH0PR22MB28605CCF2898AD2EC336DCCBC5C02@PH0PR22MB2860.namprd22.prod.outlook.com>
 <20240613132121.1847edee@arachnoid>
 <PH0PR22MB28606A4C8C09D6738A403F19C5CE2@PH0PR22MB2860.namprd22.prod.outlook.com>
 <20240620183739.19266eb1@arachnoid>
Message-ID: <CAGxFJbQ4TVjaV+AJc7fx+i=h7BsNSwH9oyfMa95AR=t7DzJFzg@mail.gmail.com>

If you haven't already done so, you may wish to have a look here:

https://cran.r-project.org/web/views/NumericalMathematics.html#differentiation-and-integration

(Or perhaps in other related subtopics in the Numerical Math task view)

Cheers,
Bert

On Thu, Jun 20, 2024 at 8:37?AM Ivan Krylov via R-help <r-help at r-project.org>
wrote:

> ? Tue, 18 Jun 2024 23:12:03 +0000
> "Levine, Michael" <mlevins at purdue.edu> ?????:
>
> > I have heard of several packages used for numerical integration in R -
> > cubature that you mentioned, mvQuad, and pracma.  My impression is
> > that you think that Cubature is the best in your opinion. Is that so?
>
> Yes, but the preference is not very strong. My own numerical
> integration experience is limited to using QUADPACK in a project where
> everything had to be rewritten in Fortran for speed.
>
> I trust the code of the 'cubature' library by Steven G. Johnson (whose
> work includes FFTW and NLopt) and the 'Cuba' library by Thomas Hahn.
> The 'cubature' R package wraps these two libraries. Unfortunately, as
> you see, its documentation can be lacking.
>
> Like 'cubature', the 'mvQuad' package won't require a significant
> rewrite of the integrand because it expects its functions to take
> matrices of arguments. Unfortunately, the two packages differ in the
> meanings they assign to the matrices: in 'cubature', individual
> arguments of the function correspond to the rows of the first argument,
> while in 'mvQuad', they must be in the columns.
>
> The 'mvQuad' package requires manual adjustments to the generated
> quadratures using rescale(...), which may be not very convenient.
>
> The 'pracma' package contains implementations of a lot of excellent
> methods (I've trusted it before for its other functions), but the (two-
> or three-argument) integrand will have to be rewritten to accept
> separate arrays (of arbitrary shape?) instead of a single matrix.
>
> > If yes, do you know of any detailed discussion of this package beyond
> > the two vignettes available on CRAN?
>
> I don't know how much it can help, but more information about the
> underlying code for 'cubature' can be found at
> <https://github.com/stevengj/cubature> and <https://feynarts.de/cuba/>.
>
> --
> Best regards,
> Ivan
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Jun 20 19:09:54 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 20 Jun 2024 10:09:54 -0700
Subject: [R] Integration of functions with a vector argument
In-Reply-To: <CAGxFJbQ4TVjaV+AJc7fx+i=h7BsNSwH9oyfMa95AR=t7DzJFzg@mail.gmail.com>
References: <PH0PR22MB2860E3ABD206953D15F31EFAC5C72@PH0PR22MB2860.namprd22.prod.outlook.com>
 <20240612134119.72e4cab6@Tarkus>
 <PH0PR22MB28605CCF2898AD2EC336DCCBC5C02@PH0PR22MB2860.namprd22.prod.outlook.com>
 <20240613132121.1847edee@arachnoid>
 <PH0PR22MB28606A4C8C09D6738A403F19C5CE2@PH0PR22MB2860.namprd22.prod.outlook.com>
 <20240620183739.19266eb1@arachnoid>
 <CAGxFJbQ4TVjaV+AJc7fx+i=h7BsNSwH9oyfMa95AR=t7DzJFzg@mail.gmail.com>
Message-ID: <CAGxFJbRpGXQtnZAW9rTFrw71keagHXSrMZbSco97ySPVUZOOfg@mail.gmail.com>

The calculus package might also be relevant (not sure if it was in the Task
View):

https://cran.r-project.org/web/packages/calculus/index.html

-- Bert

On Thu, Jun 20, 2024 at 10:01?AM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> If you haven't already done so, you may wish to have a look here:
>
>
> https://cran.r-project.org/web/views/NumericalMathematics.html#differentiation-and-integration
>
> (Or perhaps in other related subtopics in the Numerical Math task view)
>
> Cheers,
> Bert
>
> On Thu, Jun 20, 2024 at 8:37?AM Ivan Krylov via R-help <
> r-help at r-project.org> wrote:
>
>> ? Tue, 18 Jun 2024 23:12:03 +0000
>> "Levine, Michael" <mlevins at purdue.edu> ?????:
>>
>> > I have heard of several packages used for numerical integration in R -
>> > cubature that you mentioned, mvQuad, and pracma.  My impression is
>> > that you think that Cubature is the best in your opinion. Is that so?
>>
>> Yes, but the preference is not very strong. My own numerical
>> integration experience is limited to using QUADPACK in a project where
>> everything had to be rewritten in Fortran for speed.
>>
>> I trust the code of the 'cubature' library by Steven G. Johnson (whose
>> work includes FFTW and NLopt) and the 'Cuba' library by Thomas Hahn.
>> The 'cubature' R package wraps these two libraries. Unfortunately, as
>> you see, its documentation can be lacking.
>>
>> Like 'cubature', the 'mvQuad' package won't require a significant
>> rewrite of the integrand because it expects its functions to take
>> matrices of arguments. Unfortunately, the two packages differ in the
>> meanings they assign to the matrices: in 'cubature', individual
>> arguments of the function correspond to the rows of the first argument,
>> while in 'mvQuad', they must be in the columns.
>>
>> The 'mvQuad' package requires manual adjustments to the generated
>> quadratures using rescale(...), which may be not very convenient.
>>
>> The 'pracma' package contains implementations of a lot of excellent
>> methods (I've trusted it before for its other functions), but the (two-
>> or three-argument) integrand will have to be rewritten to accept
>> separate arrays (of arbitrary shape?) instead of a single matrix.
>>
>> > If yes, do you know of any detailed discussion of this package beyond
>> > the two vignettes available on CRAN?
>>
>> I don't know how much it can help, but more information about the
>> underlying code for 'cubature' can be found at
>> <https://github.com/stevengj/cubature> and <https://feynarts.de/cuba/>.
>>
>> --
>> Best regards,
>> Ivan
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From rb@er @end|ng |rom @t@u@edu  Fri Jun 21 00:16:55 2024
From: rb@er @end|ng |rom @t@u@edu (Robert Baer)
Date: Thu, 20 Jun 2024 17:16:55 -0500
Subject: [R] devtools - bad credentials R4.4.1
Message-ID: <408963b6-941b-4f96-a479-554ab846a639@atsu.edu>

I am trying to install a package from github which has worked fine in 
the past, but now seems to be stuck on some new authentication issues.? 
Does anyone know how I can straighten myself out?? In theory, this is a 
public repository so I'm not sure why I even need authenticating for 
installation.

Thanks,

Rob

The code:

 > devtools::install_github("DillonHammill/CytoExploreR")
Using GitHub PAT from the git credential store.
Error: Failed to install 'unknown package' from GitHub:
 ? HTTP error 401.
 ? Bad credentials

 ? Rate limit remaining: 50/60
 ? Rate limit reset at: 2024-06-20 22:19:33 UTC


 > Using GitHub PAT from the git credential store.
Error: unexpected symbol in "Using GitHub"
 > Error: Failed to install 'unknown package' from GitHub:
Error: unexpected symbol in "Error: Failed to"
 >?? HTTP error 401.
Error: unexpected symbol in "? HTTP error"
 >?? Bad credentials
Error: unexpected symbol in "? Bad credentials"
 >
 >?? Rate limit remaining: 55/60
Error: unexpected symbol in "? Rate limit"
 >?? Rate limit reset at: 2024-06-20 21:12:27 UTC```
Error: unexpected symbol in "? Rate limit"
 >
 > **Include any associated screenshots or images here:**


SESSIONINFO

 > sessionInfo()
R version 4.4.1 (2024-06-14 ucrt)
Platform: x86_64-w64-mingw32/x64
Running under: Windows 11 x64 (build 26120)

Matrix products: default


locale:
[1] LC_COLLATE=English_United States.utf8
[2] LC_CTYPE=English_United States.utf8
[3] LC_MONETARY=English_United States.utf8
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.utf8

time zone: America/Chicago
tzcode source: internal

attached base packages:
[1] stats???? graphics? grDevices utils???? datasets? methods base

loaded via a namespace (and not attached):
 ?[1] vctrs_0.6.5?????? cli_3.6.2???????? rlang_1.1.4 stringi_1.8.4
 ?[5] purrr_1.0.2?????? pkgload_1.3.4???? promises_1.3.0 shiny_1.8.1.1
 ?[9] xtable_1.8-4????? glue_1.7.0??????? htmltools_0.5.8.1 httpuv_1.6.15
[13] pkgbuild_1.4.4??? ellipsis_0.3.2??? fastmap_1.2.0 lifecycle_1.0.4
[17] memoise_2.0.1???? stringr_1.5.1???? compiler_4.4.1 miniUI_0.1.1.1
[21] sessioninfo_1.2.2 fs_1.6.4????????? htmlwidgets_1.6.4 Rcpp_1.0.12
[25] urlchecker_1.0.1? later_1.3.2?????? digest_0.6.35 R6_2.5.1
[29] curl_5.2.1??????? usethis_2.2.3???? magrittr_2.0.3 tools_4.4.1
[33] mime_0.12???????? devtools_2.4.5??? profvis_0.3.8 remotes_2.5.0
[37] cachem_1.1.0


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Jun 21 00:41:48 2024
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 20 Jun 2024 15:41:48 -0700
Subject: [R] devtools - bad credentials R4.4.1
In-Reply-To: <408963b6-941b-4f96-a479-554ab846a639@atsu.edu>
References: <408963b6-941b-4f96-a479-554ab846a639@atsu.edu>
Message-ID: <29078A20-C91B-430B-9895-DE3335A91585@dcn.davis.ca.us>

My guess is that this is related to you saving an expired Personal Access Token in your global git options or credentials store? Git is perfectly capable of using per-repo credentials... don't configure a credential in your global configuration and it won't fall back on using it to access random new repositories.

On June 20, 2024 3:16:55 PM PDT, Robert Baer <rbaer at atsu.edu> wrote:
>I am trying to install a package from github which has worked fine in the past, but now seems to be stuck on some new authentication issues.? Does anyone know how I can straighten myself out?? In theory, this is a public repository so I'm not sure why I even need authenticating for installation.
>
>Thanks,
>
>Rob
>
>The code:
>
>> devtools::install_github("DillonHammill/CytoExploreR")
>Using GitHub PAT from the git credential store.
>Error: Failed to install 'unknown package' from GitHub:
>? HTTP error 401.
>? Bad credentials
>
>? Rate limit remaining: 50/60
>? Rate limit reset at: 2024-06-20 22:19:33 UTC
>
>
>> Using GitHub PAT from the git credential store.
>Error: unexpected symbol in "Using GitHub"
>> Error: Failed to install 'unknown package' from GitHub:
>Error: unexpected symbol in "Error: Failed to"
>>?? HTTP error 401.
>Error: unexpected symbol in "? HTTP error"
>>?? Bad credentials
>Error: unexpected symbol in "? Bad credentials"
>>
>>?? Rate limit remaining: 55/60
>Error: unexpected symbol in "? Rate limit"
>>?? Rate limit reset at: 2024-06-20 21:12:27 UTC```
>Error: unexpected symbol in "? Rate limit"
>>
>> **Include any associated screenshots or images here:**
>
>
>SESSIONINFO
>
>> sessionInfo()
>R version 4.4.1 (2024-06-14 ucrt)
>Platform: x86_64-w64-mingw32/x64
>Running under: Windows 11 x64 (build 26120)
>
>Matrix products: default
>
>
>locale:
>[1] LC_COLLATE=English_United States.utf8
>[2] LC_CTYPE=English_United States.utf8
>[3] LC_MONETARY=English_United States.utf8
>[4] LC_NUMERIC=C
>[5] LC_TIME=English_United States.utf8
>
>time zone: America/Chicago
>tzcode source: internal
>
>attached base packages:
>[1] stats???? graphics? grDevices utils???? datasets? methods base
>
>loaded via a namespace (and not attached):
>?[1] vctrs_0.6.5?????? cli_3.6.2???????? rlang_1.1.4 stringi_1.8.4
>?[5] purrr_1.0.2?????? pkgload_1.3.4???? promises_1.3.0 shiny_1.8.1.1
>?[9] xtable_1.8-4????? glue_1.7.0??????? htmltools_0.5.8.1 httpuv_1.6.15
>[13] pkgbuild_1.4.4??? ellipsis_0.3.2??? fastmap_1.2.0 lifecycle_1.0.4
>[17] memoise_2.0.1???? stringr_1.5.1???? compiler_4.4.1 miniUI_0.1.1.1
>[21] sessioninfo_1.2.2 fs_1.6.4????????? htmlwidgets_1.6.4 Rcpp_1.0.12
>[25] urlchecker_1.0.1? later_1.3.2?????? digest_0.6.35 R6_2.5.1
>[29] curl_5.2.1??????? usethis_2.2.3???? magrittr_2.0.3 tools_4.4.1
>[33] mime_0.12???????? devtools_2.4.5??? profvis_0.3.8 remotes_2.5.0
>[37] cachem_1.1.0
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From rb@er @end|ng |rom @t@u@edu  Fri Jun 21 01:26:34 2024
From: rb@er @end|ng |rom @t@u@edu (Robert Baer)
Date: Thu, 20 Jun 2024 18:26:34 -0500
Subject: [R] devtools - bad credentials R4.4.1
In-Reply-To: <29078A20-C91B-430B-9895-DE3335A91585@dcn.davis.ca.us>
References: <408963b6-941b-4f96-a479-554ab846a639@atsu.edu>
 <29078A20-C91B-430B-9895-DE3335A91585@dcn.davis.ca.us>
Message-ID: <b0a67a88-636f-4e77-ba5d-ecb0ed35b2e4@atsu.edu>

Not being a developer, I have limited uderstanding of PATs and global 
git options, but here is what I was able to cobble together to start 
looking at my situation:

 > Sys.getenv("GITHUB_PAT")
[1] ""
 > Sys.unsetenv("GITHUB_PAT")
 > Sys.getenv("GITHUB_PAT")
[1] ""
 > devtools::install_github("DillonHammill/CytoExploreRData")
Using GitHub PAT from the git credential store.
Error: Failed to install 'CytoExploreRData' from GitHub:
 ? HTTP error 401.
 ? Bad credentials

 ? Rate limit remaining: 59/60
 ? Rate limit reset at: 2024-06-21 00:17:47 UTC


 > usethis::git_sitrep()

?? Git global (user)
? Name: 'Rob Baer'
? Email: 'rwbaer at gmail.com'
? Global (user-level) gitignore file: 'C:/Users/rbaer/.gitignore'
? Vaccinated: TRUE
? Defaulting to 'https' Git protocol
? Default Git protocol: 'https'
? Default initial branch name: 'master'

?? GitHub user
? Default GitHub host: 'https://github.com'
? Personal access token for 'https://github.com': '<discovered>'
? Can't get user information for this token.
 ? The token may no longer be valid or perhaps it lacks the 'user' scope.
Error in `gh()`:
! GitHub API error (401): Bad credentials
? Read more at <https://docs.github.com/rest>

? No active usethis project

I'm not sure where I go from here. Any hints on what other diagnostics 
are useful?



On 6/20/2024 5:41 PM, Jeff Newmiller wrote:
> My guess is that this is related to you saving an expired Personal Access Token in your global git options or credentials store? Git is perfectly capable of using per-repo credentials... don't configure a credential in your global configuration and it won't fall back on using it to access random new repositories.
>
> On June 20, 2024 3:16:55 PM PDT, Robert Baer <rbaer at atsu.edu> wrote:
>> I am trying to install a package from github which has worked fine in the past, but now seems to be stuck on some new authentication issues.? Does anyone know how I can straighten myself out?? In theory, this is a public repository so I'm not sure why I even need authenticating for installation.
>>
>> Thanks,
>>
>> Rob
>>
>> The code:
>>
>>> devtools::install_github("DillonHammill/CytoExploreR")
>> Using GitHub PAT from the git credential store.
>> Error: Failed to install 'unknown package' from GitHub:
>>  ? HTTP error 401.
>>  ? Bad credentials
>>
>>  ? Rate limit remaining: 50/60
>>  ? Rate limit reset at: 2024-06-20 22:19:33 UTC
>>
>>
>>> Using GitHub PAT from the git credential store.
>> Error: unexpected symbol in "Using GitHub"
>>> Error: Failed to install 'unknown package' from GitHub:
>> Error: unexpected symbol in "Error: Failed to"
>>>  ?? HTTP error 401.
>> Error: unexpected symbol in "? HTTP error"
>>>  ?? Bad credentials
>> Error: unexpected symbol in "? Bad credentials"
>>>  ?? Rate limit remaining: 55/60
>> Error: unexpected symbol in "? Rate limit"
>>>  ?? Rate limit reset at: 2024-06-20 21:12:27 UTC```
>> Error: unexpected symbol in "? Rate limit"
>>> **Include any associated screenshots or images here:**
>>
>> SESSIONINFO
>>
>>> sessionInfo()
>> R version 4.4.1 (2024-06-14 ucrt)
>> Platform: x86_64-w64-mingw32/x64
>> Running under: Windows 11 x64 (build 26120)
>>
>> Matrix products: default
>>
>>
>> locale:
>> [1] LC_COLLATE=English_United States.utf8
>> [2] LC_CTYPE=English_United States.utf8
>> [3] LC_MONETARY=English_United States.utf8
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.utf8
>>
>> time zone: America/Chicago
>> tzcode source: internal
>>
>> attached base packages:
>> [1] stats???? graphics? grDevices utils???? datasets? methods base
>>
>> loaded via a namespace (and not attached):
>>  ?[1] vctrs_0.6.5?????? cli_3.6.2???????? rlang_1.1.4 stringi_1.8.4
>>  ?[5] purrr_1.0.2?????? pkgload_1.3.4???? promises_1.3.0 shiny_1.8.1.1
>>  ?[9] xtable_1.8-4????? glue_1.7.0??????? htmltools_0.5.8.1 httpuv_1.6.15
>> [13] pkgbuild_1.4.4??? ellipsis_0.3.2??? fastmap_1.2.0 lifecycle_1.0.4
>> [17] memoise_2.0.1???? stringr_1.5.1???? compiler_4.4.1 miniUI_0.1.1.1
>> [21] sessioninfo_1.2.2 fs_1.6.4????????? htmlwidgets_1.6.4 Rcpp_1.0.12
>> [25] urlchecker_1.0.1? later_1.3.2?????? digest_0.6.35 R6_2.5.1
>> [29] curl_5.2.1??????? usethis_2.2.3???? magrittr_2.0.3 tools_4.4.1
>> [33] mime_0.12???????? devtools_2.4.5??? profvis_0.3.8 remotes_2.5.0
>> [37] cachem_1.1.0
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Jun 21 04:45:32 2024
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 20 Jun 2024 19:45:32 -0700
Subject: [R] devtools - bad credentials R4.4.1
In-Reply-To: <b0a67a88-636f-4e77-ba5d-ecb0ed35b2e4@atsu.edu>
References: <408963b6-941b-4f96-a479-554ab846a639@atsu.edu>
 <29078A20-C91B-430B-9895-DE3335A91585@dcn.davis.ca.us>
 <b0a67a88-636f-4e77-ba5d-ecb0ed35b2e4@atsu.edu>
Message-ID: <F7DE22DC-4553-4F43-AA8C-EE35C37E29A6@dcn.davis.ca.us>

I would delete the PAT from the credential manager since it seems to be timed out anyway... <https://support.microsoft.com/en-us/windows/accessing-credential-manager-1b5c916a-6a16-889f-8581-fc16e8165ac0>

I don't know my way around the Windows Credential Manager very well, but it seems to me that it ought to be possible to tell it not to match the entire host but only to apply to one repo. If not, git supports configuration settings related to specific repositories using git config from the connand line without the --global option.

<https://docs.github.com/en/enterprise-server at 3.9/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens>

<https://stackoverflow.com/questions/52222046/how-do-i-store-credentials-per-repository-in-git-credential-manager-for-windows>

On June 20, 2024 4:26:34 PM PDT, Robert Baer <rbaer at atsu.edu> wrote:
>Not being a developer, I have limited uderstanding of PATs and global git options, but here is what I was able to cobble together to start looking at my situation:
>
>> Sys.getenv("GITHUB_PAT")
>[1] ""
>> Sys.unsetenv("GITHUB_PAT")
>> Sys.getenv("GITHUB_PAT")
>[1] ""
>> devtools::install_github("DillonHammill/CytoExploreRData")
>Using GitHub PAT from the git credential store.
>Error: Failed to install 'CytoExploreRData' from GitHub:
>? HTTP error 401.
>? Bad credentials
>
>? Rate limit remaining: 59/60
>? Rate limit reset at: 2024-06-21 00:17:47 UTC
>
>
>> usethis::git_sitrep()
>
>?? Git global (user)
>? Name: 'Rob Baer'
>? Email: 'rwbaer at gmail.com'
>? Global (user-level) gitignore file: 'C:/Users/rbaer/.gitignore'
>? Vaccinated: TRUE
>? Defaulting to 'https' Git protocol
>? Default Git protocol: 'https'
>? Default initial branch name: 'master'
>
>?? GitHub user
>? Default GitHub host: 'https://github.com'
>? Personal access token for 'https://github.com': '<discovered>'
>? Can't get user information for this token.
>? The token may no longer be valid or perhaps it lacks the 'user' scope.
>Error in `gh()`:
>! GitHub API error (401): Bad credentials
>? Read more at <https://docs.github.com/rest>
>
>? No active usethis project
>
>I'm not sure where I go from here. Any hints on what other diagnostics are useful?
>
>
>
>On 6/20/2024 5:41 PM, Jeff Newmiller wrote:
>> My guess is that this is related to you saving an expired Personal Access Token in your global git options or credentials store? Git is perfectly capable of using per-repo credentials... don't configure a credential in your global configuration and it won't fall back on using it to access random new repositories.
>> 
>> On June 20, 2024 3:16:55 PM PDT, Robert Baer <rbaer at atsu.edu> wrote:
>>> I am trying to install a package from github which has worked fine in the past, but now seems to be stuck on some new authentication issues.? Does anyone know how I can straighten myself out?? In theory, this is a public repository so I'm not sure why I even need authenticating for installation.
>>> 
>>> Thanks,
>>> 
>>> Rob
>>> 
>>> The code:
>>> 
>>>> devtools::install_github("DillonHammill/CytoExploreR")
>>> Using GitHub PAT from the git credential store.
>>> Error: Failed to install 'unknown package' from GitHub:
>>>  ? HTTP error 401.
>>>  ? Bad credentials
>>> 
>>>  ? Rate limit remaining: 50/60
>>>  ? Rate limit reset at: 2024-06-20 22:19:33 UTC
>>> 
>>> 
>>>> Using GitHub PAT from the git credential store.
>>> Error: unexpected symbol in "Using GitHub"
>>>> Error: Failed to install 'unknown package' from GitHub:
>>> Error: unexpected symbol in "Error: Failed to"
>>>>  ?? HTTP error 401.
>>> Error: unexpected symbol in "? HTTP error"
>>>>  ?? Bad credentials
>>> Error: unexpected symbol in "? Bad credentials"
>>>>  ?? Rate limit remaining: 55/60
>>> Error: unexpected symbol in "? Rate limit"
>>>>  ?? Rate limit reset at: 2024-06-20 21:12:27 UTC```
>>> Error: unexpected symbol in "? Rate limit"
>>>> **Include any associated screenshots or images here:**
>>> 
>>> SESSIONINFO
>>> 
>>>> sessionInfo()
>>> R version 4.4.1 (2024-06-14 ucrt)
>>> Platform: x86_64-w64-mingw32/x64
>>> Running under: Windows 11 x64 (build 26120)
>>> 
>>> Matrix products: default
>>> 
>>> 
>>> locale:
>>> [1] LC_COLLATE=English_United States.utf8
>>> [2] LC_CTYPE=English_United States.utf8
>>> [3] LC_MONETARY=English_United States.utf8
>>> [4] LC_NUMERIC=C
>>> [5] LC_TIME=English_United States.utf8
>>> 
>>> time zone: America/Chicago
>>> tzcode source: internal
>>> 
>>> attached base packages:
>>> [1] stats???? graphics? grDevices utils???? datasets? methods base
>>> 
>>> loaded via a namespace (and not attached):
>>>  ?[1] vctrs_0.6.5?????? cli_3.6.2???????? rlang_1.1.4 stringi_1.8.4
>>>  ?[5] purrr_1.0.2?????? pkgload_1.3.4???? promises_1.3.0 shiny_1.8.1.1
>>>  ?[9] xtable_1.8-4????? glue_1.7.0??????? htmltools_0.5.8.1 httpuv_1.6.15
>>> [13] pkgbuild_1.4.4??? ellipsis_0.3.2??? fastmap_1.2.0 lifecycle_1.0.4
>>> [17] memoise_2.0.1???? stringr_1.5.1???? compiler_4.4.1 miniUI_0.1.1.1
>>> [21] sessioninfo_1.2.2 fs_1.6.4????????? htmlwidgets_1.6.4 Rcpp_1.0.12
>>> [25] urlchecker_1.0.1? later_1.3.2?????? digest_0.6.35 R6_2.5.1
>>> [29] curl_5.2.1??????? usethis_2.2.3???? magrittr_2.0.3 tools_4.4.1
>>> [33] mime_0.12???????? devtools_2.4.5??? profvis_0.3.8 remotes_2.5.0
>>> [37] cachem_1.1.0
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Sent from my phone. Please excuse my brevity.


From t@nguy@b@rthe|emy @end|ng |rom |n@ee@|r  Thu Jun 20 15:15:50 2024
From: t@nguy@b@rthe|emy @end|ng |rom |n@ee@|r (Barthelemy Tanguy)
Date: Thu, 20 Jun 2024 13:15:50 +0000
Subject: [R] Bug with writeClipboard in {utils}
In-Reply-To: <d006e769-a856-4965-9d1a-1cd2aa4d5f03@sapo.pt>
References: <ecb5eeea68b64461a09b416c68d0a0d1@insee.fr>,
 <d006e769-a856-4965-9d1a-1cd2aa4d5f03@sapo.pt>
Message-ID: <844b5fbe711b4865ba96d0c9ace03f12@insee.fr>

Hello,

Thank you for your different tests.

You have that you didn't find any errors with Rscript or with R but I have the impression that your test with R (second test) showed additional and unwanted characters (second line of the output)?

Thank you again

Tanguy BARTHELEMY


________________________________
De : Rui Barradas <ruipbarradas at sapo.pt>
Envoy? : mercredi 19 juin 2024 19:26
? : Barthelemy Tanguy; r-help at r-project.org
Objet : Re: [R] Bug with writeClipboard in {utils}

? Ce courriel provient d?un exp?diteur ext?rieur ? l?Insee. Compte tenu du contexte de menace cyber actuel il convient d??tre extr?mement vigilant sur l??metteur et son contenu avant d?ouvrir une pi?ce jointe, de cliquer sur un lien internet pr?sent dans ce message ou d'y r?pondre. ?


?s 11:12 de 18/06/2024, Barthelemy Tanguy via R-help escreveu:
> Hello,
>
> I'm encountering what seems to be a bug when using the `writeClipboard()` function in the R {utils} package.
> When I try to copy text to the clipboard, I notice that I get extra characters when I try to paste it (by hand with CTRL+V or with the `readClipboard()` function from R packages {utils}).
>
> Here's my example:
>
> ``` r
> utils::writeClipboard("plot(AirPassengers)")
> for (k in 1:10) {
>      print(utils::readClipboard())
> }
> #> [1] "plot(AirPassengers)" "??"
> #> [1] "plot(AirPassengers)" "\u0a00"
> #> [1] "plot(AirPassengers)" "\xed\xb0\x80?"
> #> [1] "plot(AirPassengers)"
> #> [1] "plot(AirPassengers)"
> #> [1] "plot(AirPassengers)"
> #> [1] "plot(AirPassengers)"
> #> [1] "plot(AirPassengers)"
> #> [1] "plot(AirPassengers)" "?"
> #> [1] "plot(AirPassengers)"
> Message d'avis :
> Dans utils::readClipboard() : unpaired surrogate Unicode point dc00
> ```
>
> So I don't always get the same result.
> I opened a problem in the {clipr} GitHub repository before realizing it's a {tools} problem: https://github.com/mdlincoln/clipr/issues/68
>
> Is this a bug or something I haven't configured properly?
>
>
> Thank you very much
>
>
> Tanguy BARTHELEMY
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

I have reproduced part of the behavior in the OP but it will depend on
the GUI or command line used.

With Rscript or with R I haven't found any errors.
With Rgui or with RStudio, yes, the output was not the expected output.

All code run in R 4.4.0 on Windows 11.

The script rscript.R is


utils::capture.output({
utils::writeClipboard("plot(AirPassengers)")
for (k in 1:10) {
   print(utils::readClipboard())
}
sessionInfo()
}, file = "rhelp.txt")


---

Here are the results I got.

1) Command:

Rscript rscript.R

Output:

[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
R version 4.4.0 (2024-04-24 ucrt)
Platform: x86_64-w64-mingw32/x64
Running under: Windows 11 x64 (build 22631)

Matrix products: default


locale:
[1] LC_COLLATE=Portuguese_Portugal.utf8
LC_CTYPE=Portuguese_Portugal.utf8
[3] LC_MONETARY=Portuguese_Portugal.utf8 LC_NUMERIC=C

[5] LC_TIME=Portuguese_Portugal.utf8

time zone: Europe/Lisbon
tzcode source: internal

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_4.4.0

---

2) Command:
R -q -f rscript.R

Output:

 > utils::writeClipboard("plot(AirPassengers)")
 > for (k in 1:10) {
+     print(utils::readClipboard())
+ }
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)" "??\005"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
 > sessionInfo()
R version 4.4.0 (2024-04-24 ucrt)
Platform: x86_64-w64-mingw32/x64
Running under: Windows 11 x64 (build 22631)

Matrix products: default


locale:
[1] LC_COLLATE=Portuguese_Portugal.utf8
LC_CTYPE=Portuguese_Portugal.utf8
[3] LC_MONETARY=Portuguese_Portugal.utf8 LC_NUMERIC=C

[5] LC_TIME=Portuguese_Portugal.utf8

time zone: Europe/Lisbon
tzcode source: internal

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_4.4.0
 >

---

3) GUI: RStudio
Output:

[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)" "?????e"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)" "??"
[1] "plot(AirPassengers)" "?????e"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[2] "?????eX???????????????????????"
[1] "plot(AirPassengers)" "??"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
R version 4.4.0 (2024-04-24 ucrt)
Platform: x86_64-w64-mingw32/x64
Running under: Windows 11 x64 (build 22631)

Matrix products: default


locale:
[1] LC_COLLATE=Portuguese_Portugal.utf8
LC_CTYPE=Portuguese_Portugal.utf8
[3] LC_MONETARY=Portuguese_Portugal.utf8 LC_NUMERIC=C

[5] LC_TIME=Portuguese_Portugal.utf8

time zone: Europe/Lisbon
tzcode source: internal

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
  [1] gtable_0.3.4         tensorA_0.36.2.1     ggplot2_3.5.0
  [4] QuickJSR_1.1.3       processx_3.8.3       inline_0.3.19
  [7] lattice_0.22-5       tzdb_0.4.0           callr_3.7.5
[10] vctrs_0.6.5          tools_4.4.0          ps_1.7.6
[13] generics_0.1.3       stats4_4.4.0         curl_5.2.1
[16] parallel_4.4.0       sandwich_3.1-0       tibble_3.2.1
[19] fansi_1.0.6          chron_2.3-61         pkgconfig_2.0.3
[22] brms_2.21.0          Matrix_1.6-5         checkmate_2.3.1
[25] distributional_0.4.0 RcppParallel_5.1.7   lifecycle_1.0.4
[28] compiler_4.4.0       stringr_1.5.1        Brobdingnag_1.2-9
[31] munsell_0.5.0        codetools_0.2-19     bayesplot_1.11.1
[34] pillar_1.9.0         crayon_1.5.2         MASS_7.3-60.0.1
[37] StanHeaders_2.32.6   bridgesampling_1.1-2 abind_1.4-5
[40] multcomp_1.4-25      nlme_3.1-164         posterior_1.5.0
[43] rstan_2.32.5         tidyselect_1.2.0     mvtnorm_1.2-3
[46] stringi_1.7.12       dplyr_1.1.4          splines_4.4.0
[49] grid_4.4.0           colorspace_2.1-0     cli_3.6.2
[52] magrittr_2.0.3       loo_2.6.0            survival_3.5-8
[55] pkgbuild_1.4.2       utf8_1.2.4           TH.data_1.1-2
[58] readr_2.1.4          prettyunits_1.2.0    scales_1.3.0
[61] backports_1.4.1      estimability_1.5     httr_1.4.7
[64] matrixStats_1.0.0    emmeans_1.10.0       gridExtra_2.3
[67] hms_1.1.3            zoo_1.8-12           coda_0.19-4.1
[70] V8_4.4.2             rstantools_2.3.1.1   rlang_1.1.3
[73] Rcpp_1.0.12          xtable_1.8-4         glue_1.7.0
[76] ppcor_1.1            rstudioapi_0.15.0    jsonlite_1.8.8
[79] R6_2.5.1

---

4) GUI: Rgui
Output:

[1] "plot(AirPassengers)" "??\005???"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
[1] "plot(AirPassengers)"
R version 4.4.0 (2024-04-24 ucrt)
Platform: x86_64-w64-mingw32/x64
Running under: Windows 11 x64 (build 22631)

Matrix products: default


locale:
[1] LC_COLLATE=Portuguese_Portugal.utf8
LC_CTYPE=Portuguese_Portugal.utf8
[3] LC_MONETARY=Portuguese_Portugal.utf8 LC_NUMERIC=C

[5] LC_TIME=Portuguese_Portugal.utf8

time zone: Europe/Lisbon
tzcode source: internal

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_4.4.0



Hope this helps,

Rui Barradas




--
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com<http://www.avg.com>

	[[alternative HTML version deleted]]


From t@nguy@b@rthe|emy @end|ng |rom |n@ee@|r  Thu Jun 20 15:21:38 2024
From: t@nguy@b@rthe|emy @end|ng |rom |n@ee@|r (Barthelemy Tanguy)
Date: Thu, 20 Jun 2024 13:21:38 +0000
Subject: [R] Bug with writeClipboard in {utils}
In-Reply-To: <20240619170707.096d4aad@arachnoid>
References: <ecb5eeea68b64461a09b416c68d0a0d1@insee.fr>,
 <20240619170707.096d4aad@arachnoid>
Message-ID: <a016cb321bbc448ea1d7a0a233d0b0c8@insee.fr>

Hello,

Thank you for your research and your bug report.
At the end of your bug report (https://bugs.r-project.org/show_bug.cgi?id=18747) you mentioned that "the problem doesn't reappear with the attached patch".

Is there a way to test this patch or will there soon be a published patched R version available for download?

Thank you again

Tanguy BARTHELEMY



________________________________
De : Ivan Krylov <ikrylov at disroot.org>
Envoy? : mercredi 19 juin 2024 16:07
? : r-help at r-project.org
Cc : Barthelemy Tanguy
Objet : Re: [R] Bug with writeClipboard in {utils}

? Ce courriel provient d?un exp?diteur ext?rieur ? l?Insee. Compte tenu du contexte de menace cyber actuel il convient d??tre extr?mement vigilant sur l??metteur et son contenu avant d?ouvrir une pi?ce jointe, de cliquer sur un lien internet pr?sent dans ce message ou d'y r?pondre. ?


? Tue, 18 Jun 2024 10:12:04 +0000
Barthelemy Tanguy via R-help <r-help at r-project.org> ?????:

> #> [1] "plot(AirPassengers)" "??"
> #> [1] "plot(AirPassengers)" "\u0a00"
> #> [1] "plot(AirPassengers)" "\xed\xb0\x80?"

Thanks for showing an example!

I was able to reproduce it both with R-4.3.1 on Windows 7 and with a
fresh R-devel build on Windows 10. Bug reported at
<https://bugs.r-project.org/show_bug.cgi?id=18747>.

--
Best regards,
Ivan

	[[alternative HTML version deleted]]


From h@w|ckh@m @end|ng |rom gm@||@com  Fri Jun 21 11:53:15 2024
From: h@w|ckh@m @end|ng |rom gm@||@com (Hadley Wickham)
Date: Fri, 21 Jun 2024 10:53:15 +0100
Subject: [R] devtools - bad credentials R4.4.1
In-Reply-To: <408963b6-941b-4f96-a479-554ab846a639@atsu.edu>
References: <408963b6-941b-4f96-a479-554ab846a639@atsu.edu>
Message-ID: <CABdHhvFAn7ROHTNcLqZezNCNPrkXnPNUb-pCGeSit088nWwHOw@mail.gmail.com>

The place to start for such problems is always usethis::git_sitrep()
Hadley

On Thu, Jun 20, 2024 at 11:17?PM Robert Baer <rbaer at atsu.edu> wrote:

> I am trying to install a package from github which has worked fine in
> the past, but now seems to be stuck on some new authentication issues.
> Does anyone know how I can straighten myself out?  In theory, this is a
> public repository so I'm not sure why I even need authenticating for
> installation.
>
> Thanks,
>
> Rob
>
> The code:
>
>  > devtools::install_github("DillonHammill/CytoExploreR")
> Using GitHub PAT from the git credential store.
> Error: Failed to install 'unknown package' from GitHub:
>    HTTP error 401.
>    Bad credentials
>
>    Rate limit remaining: 50/60
>    Rate limit reset at: 2024-06-20 22:19:33 UTC
>
>
>  > Using GitHub PAT from the git credential store.
> Error: unexpected symbol in "Using GitHub"
>  > Error: Failed to install 'unknown package' from GitHub:
> Error: unexpected symbol in "Error: Failed to"
>  >   HTTP error 401.
> Error: unexpected symbol in "  HTTP error"
>  >   Bad credentials
> Error: unexpected symbol in "  Bad credentials"
>  >
>  >   Rate limit remaining: 55/60
> Error: unexpected symbol in "  Rate limit"
>  >   Rate limit reset at: 2024-06-20 21:12:27 UTC```
> Error: unexpected symbol in "  Rate limit"
>  >
>  > **Include any associated screenshots or images here:**
>
>
> SESSIONINFO
>
>  > sessionInfo()
> R version 4.4.1 (2024-06-14 ucrt)
> Platform: x86_64-w64-mingw32/x64
> Running under: Windows 11 x64 (build 26120)
>
> Matrix products: default
>
>
> locale:
> [1] LC_COLLATE=English_United States.utf8
> [2] LC_CTYPE=English_United States.utf8
> [3] LC_MONETARY=English_United States.utf8
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.utf8
>
> time zone: America/Chicago
> tzcode source: internal
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
>
> loaded via a namespace (and not attached):
>   [1] vctrs_0.6.5       cli_3.6.2         rlang_1.1.4 stringi_1.8.4
>   [5] purrr_1.0.2       pkgload_1.3.4     promises_1.3.0 shiny_1.8.1.1
>   [9] xtable_1.8-4      glue_1.7.0        htmltools_0.5.8.1 httpuv_1.6.15
> [13] pkgbuild_1.4.4    ellipsis_0.3.2    fastmap_1.2.0 lifecycle_1.0.4
> [17] memoise_2.0.1     stringr_1.5.1     compiler_4.4.1 miniUI_0.1.1.1
> [21] sessioninfo_1.2.2 fs_1.6.4          htmlwidgets_1.6.4 Rcpp_1.0.12
> [25] urlchecker_1.0.1  later_1.3.2       digest_0.6.35 R6_2.5.1
> [29] curl_5.2.1        usethis_2.2.3     magrittr_2.0.3 tools_4.4.1
> [33] mime_0.12         devtools_2.4.5    profvis_0.3.8 remotes_2.5.0
> [37] cachem_1.1.0
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
http://hadley.nz

	[[alternative HTML version deleted]]


From |kry|ov @end|ng |rom d|@root@org  Fri Jun 21 15:38:22 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Fri, 21 Jun 2024 16:38:22 +0300
Subject: [R] Bug with writeClipboard in {utils}
In-Reply-To: <20240620183934.62a58154@arachnoid>
References: <ecb5eeea68b64461a09b416c68d0a0d1@insee.fr>
 <20240619170707.096d4aad@arachnoid>
 <a016cb321bbc448ea1d7a0a233d0b0c8@insee.fr>
 <20240620183934.62a58154@arachnoid>
Message-ID: <20240621163822.57fede59@arachnoid>

? Thu, 20 Jun 2024 18:39:34 +0300
Ivan Krylov via R-help <r-help at r-project.org> ?????:

> > Is there a way to test this patch or will there soon be a published
> > patched R version available for download?  
> 
> Not directly.

Now that the bug is fixed in R-devel (thanks Tomas!), a Windows build
of the development version of R with the fix is available:
https://cran.r-project.org/bin/windows/base/rdevel.html

-- 
Best regards,
Ivan


From Len|@Koehnen @end|ng |rom gmx@de  Fri Jun 21 12:59:22 2024
From: Len|@Koehnen @end|ng |rom gmx@de (Leni Koehnen)
Date: Fri, 21 Jun 2024 12:59:22 +0200
Subject: [R] Problem with combining monthly nc files into a yearly file
 (era5 climate data)
Message-ID: <trinity-6b428587-39f7-4908-a770-8749f84f16da-1718967562004@3c-app-gmx-bs08>

Dear R-help List,?

I am currently trying to run a code which is available on Zenodo  (https://zenodo.org/records/10997880  - 02_MicroClimModel.R).

The code downloads yearly era5 climate data. Unfortunately, the limit to download these nc-files was recently reduced to 60000. Therefore, I can not download the yearly file anymore. I have solved this by rewriting the code, so that it downloads 12 monthly files. 

However, I have not been able to combine these 12 monthly nc-files into one yearly file. The code gives me errors if I continue running it. I assume that the combination was not successful and might have messed up the format. I would greatly appreciate any advice on how to convert these monthly nc-files into one yearly file.

Thank you very much in advance!

Here is the full code: 


' *****************************************************************
#' ~~ STEP 01 DOWNLOADING & PROCESSING HOURLY CLIMATE DATA 

# Install the remotes package if not already installed
if (!requireNamespace("remotes", quietly = TRUE)) {
  install.packages("remotes")
}
# Install packages from CRAN
install.packages(c("terra", "raster", "ncdf4", "lubridate"))
install.packages("lutz")
#install dependencies for microclima
remotes::install_github("ropensci/rnoaa")

# Install packages from GitHub
remotes::install_github("dklinges9/mcera5")
remotes::install_github("ilyamaclean/microclima")
remotes::install_github("ilyamaclean/microclimf")

#' ~~ Required libraries:
require(terra)
require(raster)
require(mcera5) # https://github.com/dklinges9/mcera5
require(ncdf4)
require(microclima) # https://github.com/ilyamaclean/microclima
require(microclimf) # https://github.com/ilyamaclean/microclimf
require(ecmwfr)
require(lutz)
require(lubridate)

# Set paths and year of interest
pathtodata <- "F:/Dat/"
pathtoera5 <- paste0(pathtodata, "era5/")
year <- 2019

# Set user credentials for CDS API (you have to first register and insert here your UID and API key at https://cds.climate.copernicus.eu/user/register and allow downloads)
uid <- "xxx"
cds_api_key <- "xxx"
ecmwfr::wf_set_key(user = uid, key = cds_api_key, service = "cds")

# Define the spatial extent for your tile
xmn <- 18.125
xmx <- 22.875
ymn <- -1.625
ymx <- 1.875

#HERE STARTS THE SECTION WHERE I AM DOWNLOADING MONTHLY FILES 

# Define the temporal extent of the run
start_time <- lubridate::ymd(paste0(year, "-01-01"))
end_time <- lubridate::ymd(paste0(year, "-12-31"))

# Function to build and send requests for each month
request_era5_monthly <- function(year, month, uid, xmn, xmx, ymn, ymx, out_path) {
  # Define the start and end times for the month
  st_time <- lubridate::ymd(paste0(year, "-", sprintf("%02d", month), "-01"))
  en_time <- st_time + months(1) - days(1)
  
  # Create the file prefix and request
  file_prefix <- paste0("era5_reanalysis_", year, "_", sprintf("%02d", month))
  req <- build_era5_request(xmin = xmn, xmax = xmx, ymin = ymn, ymax = ymx, 
                            start_time = st_time, end_time = en_time, outfile_name = file_prefix)
  
  # Send the request and save the data
  request_era5(request = req, uid = uid, out_path = out_path, overwrite = TRUE)
}

# Loop over each month and request data
for (month in 1:12) {
  request_era5_monthly(year, month, uid, xmn, xmx, ymn, ymx, pathtoera5)
}

#HERE I AM EXPLORING ONE EXEMPLARY MONTHLY NC FILE

file_path <- paste0(pathtoera5, "era5_reanalysis_2019_01_2019.nc")
nc <- nc_open(file_path)

# List all variables
print(nc)

# List all variable names in the NetCDF file
var_names <- names(nc$var)
print(var_names)

checkJan <- raster(paste0(pathtoera5, "era5_reanalysis_2019_01_2019.nc"))
print(checkJan)  
opencheckJan <- getValues(checkJan)
opencheckJan

#HERE IS THE PROBLEM, I AM TRYING TO COMBINE THESE MONTHL NC FILES 

combine_era5_yearly <- function(year, pathtoera5, outfile) {
  # List of monthly files
  monthly_files <- list.files(pathtoera5, pattern = paste0("era5_reanalysis_", year, "_\\d{2}_", year, "\\.nc"), full.names = TRUE)
  
  if (length(monthly_files) == 0) {
    stop("No monthly files found")
  }
  
  # Initialize lists to store data
  lons <- NULL
  lats <- NULL
  time <- NULL
  t2m <- list()
  d2m <- list()
  sp <- list()
  u10 <- list()
  v10 <- list()
  tp <- list()
  tcc <- list()
  msnlwrf <- list()
  msdwlwrf <- list()
  fdir <- list()
  ssrd <- list()
  lsm <- list()
  
  # Read each monthly file and extract variables
  for (file in monthly_files) {
    nc <- nc_open(file)
    
    if (is.null(lons)) {
      lons <- ncvar_get(nc, "longitude")
      lats <- ncvar_get(nc, "latitude")
      time <- ncvar_get(nc, "time")
    } else {
      time <- c(time, ncvar_get(nc, "time"))
    }
    
    t2m <- c(t2m, list(ncvar_get(nc, "t2m")))
    d2m <- c(d2m, list(ncvar_get(nc, "d2m")))
    sp <- c(sp, list(ncvar_get(nc, "sp")))
    u10 <- c(u10, list(ncvar_get(nc, "u10")))
    v10 <- c(v10, list(ncvar_get(nc, "v10")))
    tp <- c(tp, list(ncvar_get(nc, "tp")))
    tcc <- c(tcc, list(ncvar_get(nc, "tcc")))
    msnlwrf <- c(msnlwrf, list(ncvar_get(nc, "msnlwrf")))
    msdwlwrf <- c(msdwlwrf, list(ncvar_get(nc, "msdwlwrf")))
    fdir <- c(fdir, list(ncvar_get(nc, "fdir")))
    ssrd <- c(ssrd, list(ncvar_get(nc, "ssrd")))
    lsm <- c(lsm, list(ncvar_get(nc, "lsm")))
    
    nc_close(nc)
  }
  
  # Combine the data for each variable
  t2m <- do.call(c, t2m)
  d2m <- do.call(c, d2m)
  sp <- do.call(c, sp)
  u10 <- do.call(c, u10)
  v10 <- do.call(c, v10)
  tp <- do.call(c, tp)
  tcc <- do.call(c, tcc)
  msnlwrf <- do.call(c, msnlwrf)
  msdwlwrf <- do.call(c, msdwlwrf)
  fdir <- do.call(c, fdir)
  ssrd <- do.call(c, ssrd)
  lsm <- do.call(c, lsm)
  
  # Create a new NetCDF file for the entire year
  outfile <- paste0(pathtoera5, "era5_reanalysis_", year, ".nc")
  dim_lon <- ncdim_def("longitude", "degrees_east", lons)
  dim_lat <- ncdim_def("latitude", "degrees_north", lats)
  dim_time <- ncdim_def("time", "hours since 1900-01-01 00:00:00", time, unlim=TRUE)
  
  # Define variables
  var_t2m <- ncvar_def("t2m", "K", list(dim_lon, dim_lat, dim_time), -9999)
  var_d2m <- ncvar_def("d2m", "K", list(dim_lon, dim_lat, dim_time), -9999)
  var_sp <- ncvar_def("sp", "Pa", list(dim_lon, dim_lat, dim_time), -9999)
  var_u10 <- ncvar_def("u10", "m/s", list(dim_lon, dim_lat, dim_time), -9999)
  var_v10 <- ncvar_def("v10", "m/s", list(dim_lon, dim_lat, dim_time), -9999)
  var_tp <- ncvar_def("tp", "m", list(dim_lon, dim_lat, dim_time), -9999)
  var_tcc <- ncvar_def("tcc", "1", list(dim_lon, dim_lat, dim_time), -9999)
  var_msnlwrf <- ncvar_def("msnlwrf", "W/m^2", list(dim_lon, dim_lat, dim_time), -9999)
  var_msdwlwrf <- ncvar_def("msdwlwrf", "W/m^2", list(dim_lon, dim_lat, dim_time), -9999)
  var_fdir <- ncvar_def("fdir", "J/m^2", list(dim_lon, dim_lat, dim_time), -9999)
  var_ssrd <- ncvar_def("ssrd", "J/m^2", list(dim_lon, dim_lat, dim_time), -9999)
  var_lsm <- ncvar_def("lsm", "1", list(dim_lon, dim_lat, dim_time), -9999)
  
  # Create the file
  ncout <- nc_create(outfile, list(var_t2m, var_d2m, var_sp, var_u10, var_v10, var_tp, var_tcc, var_msnlwrf, var_msdwlwrf, var_fdir, var_ssrd, var_lsm))
  
  # Write data to the new file
  ncvar_put(ncout, var_t2m, t2m)
  ncvar_put(ncout, var_d2m, d2m)
  ncvar_put(ncout, var_sp, sp)
  ncvar_put(ncout, var_u10, u10)
  ncvar_put(ncout, var_v10, v10)
  ncvar_put(ncout, var_tp, tp)
  ncvar_put(ncout, var_tcc, tcc)
  ncvar_put(ncout, var_msnlwrf, msnlwrf)
  ncvar_put(ncout, var_msdwlwrf, msdwlwrf)
  ncvar_put(ncout, var_fdir, fdir)
  ncvar_put(ncout, var_ssrd, ssrd)
  ncvar_put(ncout, var_lsm, lsm)
  
  # Define and write longitude and latitude variables
  ncvar_put(ncout, "longitude", lons)
  ncvar_put(ncout, "latitude", lats)
  ncatt_put(ncout, "longitude", "units", "degrees_east")
  ncatt_put(ncout, "latitude", "units", "degrees_north")
  
  # Define and write time variable
  ncvar_put(ncout, "time", time)
  ncatt_put(ncout, "time", "units", "hours since 1900-01-01 00:00:00")
  ncatt_put(ncout, "time", "calendar", "gregorian")
  
  # Global attributes
  ncatt_put(ncout, 0, "title", paste0("ERA5 reanalysis data for ", year))
  ncatt_put(ncout, 0, "source", "ECMWF ERA5")
  
  # Close the NetCDF file
  nc_close(ncout)
}

# Example usage:
outfile <- paste0(pathtoera5, "era5_reanalysis_", year, ".nc")
combine_era5_yearly(year, pathtoera5, outfile)




#HERE IS THE REST OF THE CODE WHICH REQUIRES THE YEARLY FILE


#' Process Hourly Climate Data >>>
file <- paste0(pathtoera5,"era5_reanalysis_",year,".nc")
clim <- nc_open(file)

#' create a template to crop input dataset to for step 2: '02_VegParms.R'
test <- raster::brick(file, varname = "t2m")
t_array <- as.array(test[[1]])
ext_r <- ext(raster::extent(test))
r <- rast(t_array, crs = "EPSG:4326", ext = ext_r)

#' Get coordinates & time:
lons <- ncdf4::ncvar_get(clim, varid = "longitude")
lats <- ncdf4::ncvar_get(clim, varid = "latitude")
time <- ncdf4::ncvar_get(clim, "time")

x_dim <- length(lons)
y_dim <- length(lats)
z_dim <- length(time)

#' Assign a local timezone:
tmz <- lutz::tz_lookup_coords(lats[length(lats)/2], lons[length(lons)/2], method = 'fast')

origin <- as.POSIXlt("1900-01-01 00:00:00", tz = "UTC")
UTC_tme <- origin + as.difftime(time, units = "hours")
UTC_tme <- as.POSIXlt(UTC_tme, tz = "UTC")
local_tme <- lubridate::with_tz(UTC_tme, tzone = tmz)

jd <- microctools::jday(tme = UTC_tme)
lt <- local_tme$hour + local_tme$min/60 + local_tme$sec/3600

#' Create empty climate variable arrays:
#' These are 3-D arrays with time (hours) in the 3rd dimension.
t_a <- array(data = NA, c(y_dim, x_dim, z_dim))
t_sh <- array(data = NA, c(y_dim, x_dim, z_dim))
t_pa <- array(data = NA, c(y_dim, x_dim, z_dim))
t_ws <- array(data = NA, c(y_dim, x_dim, z_dim))
t_wd <- array(data = NA, c(y_dim, x_dim, z_dim))
t_se <- array(data = NA, c(y_dim, x_dim, z_dim))
t_nl <- array(data = NA, c(y_dim, x_dim, z_dim))
t_ul <- array(data = NA, c(y_dim, x_dim, z_dim))
t_dl <- array(data = NA, c(y_dim, x_dim, z_dim))
t_rd <- array(data = NA, c(y_dim, x_dim, z_dim))
t_rdf <- array(data = NA, c(y_dim, x_dim, z_dim))
t_sz <- array(data = NA, c(y_dim, x_dim, z_dim))
p_a <- array(data = NA, c(y_dim, x_dim, length(local_tme)/24)) # note: rainfall recorded daily.

#' Fill empty arrays with processed era5 data:
#' Use the 'extract_clim' function from the mcera5 package to convert era5 data to microclimf-ready data. 
for(i in 1:y_dim){ # for each row in the new array.
  for(j in 1:x_dim){ # for each column in the new array.
    long <- lons[j]
    lat <- lats[i]
    climate <- extract_clim(file, long, lat, start_time = UTC_tme[1], end_time = UTC_tme[length(UTC_tme)])
    t_a[i,j,] <- climate$temperature
    t_sh[i,j,] <- climate$humidity
    t_pa[i,j,] <- climate$pressure
    t_ws[i,j,] <- climate$windspeed
    t_wd[i,j,] <- climate$winddir
    t_se[i,j,] <- climate$emissivity
    t_nl[i,j,] <- climate$netlong
    t_ul[i,j,] <- climate$uplong
    t_dl[i,j,] <- climate$downlong
    t_rd[i,j,] <- climate$rad_dni
    t_rdf[i,j,] <- climate$rad_dif
    t_sz[i,j,] <- climate$szenith
  } # end column j
} # end row i

#' Repeat for daily rainfall:
#' Use the 'extract_precip' function from the mcera5 package to convert era5 data to microclimf-ready data. 
for(i in 1:y_dim){ # for each row in the new array.
  for(j in 1:x_dim){ # for each column in the new array.
    long <- lons[j]
    lat <- lats[i]
    precip <- extract_precip(file, long, lat, start_time = UTC_tme[1], end_time = UTC_tme[length(UTC_tme)])
    p_a[i,j,] <- precip
  } # end column j
} # end row i


#' Additional processing for microclimf inputs:
#' Calculate Solar Index...
si <- array(data = NA, dim = c(y_dim, x_dim, z_dim))
for(a in 1:nrow(si)){
  for(b in 1:ncol(si)){
    x <- lons[b]
    y <- lats[a]
    s = microclima::siflat(lubridate::hour(local_tme), y, x, jd)    
    si[a,b,] <- s
  }
}  
#' Calculate Global Horizontal Irradiance (GHI) from Direct Normal Irradiance (DNI)
#' and convert units from MJh/m^2 to kWh/m^2
raddr <- (t_rd * si)/0.0036
difrad <- t_rdf/0.0036

#' Cap diffuse radiation data (Cannot be less than 0) 
difrad[difrad < 0] <- 0

#' Calculate shortwave radiation:
#' Sum Global Horizontal Irradiance (GHI) and Diffuse Radiation. 
swrad <- raddr + difrad

#' Cap shortwave radiation between 0 > sw < 1350 (lower than the solar constant)
swrad[swrad < 0] <- 0
swrad[swrad > 1350] <- 1350

#' Calculate relative humidity
#' Using specific humidity, temperature and pressure. 
t_rh <- array(data = NA, c(y_dim, x_dim, z_dim))
for(i in 1:nrow(t_rh)){ 
  for(j in 1:ncol(t_rh)){ 
    rh <- microclima::humidityconvert(t_sh[i,j,],intype = "specific", tc = t_a[i,j,], p = t_pa[i,j,])
    rh <- rh$relative
    rh[rh > 100] <- 100
    t_rh[i,j,] <- rh
  } 
} 

#' Convert pressure untis from Pa to kPa:
t_pr <- t_pa/1000


#' Create final climate data set to drive microclimate model:
#' Note: keep the nomenclature as shown here for microclimf, see microclimf::climdat for example names.
climdat <- list(tme = local_tme, obs_time = UTC_tme, 
                temp = t_a, relhum = t_rh, 
                pres = t_pr, swrad = swrad,
                difrad = difrad, skyem = t_se,
                windspeed = t_ws, winddir = t_wd)

#' Save data:
pathout <- "F:/Dat/era5/"
saveRDS(climdat, paste0(pathout,"climdat_",year,".RDS"))
saveRDS(p_a, paste0(pathout,"rainfall_",year,".RDS"))
tile_no <- "01"
writeRaster(r, paste0(pathout,"tile_",tile_no,".tif"))


#HERE IS ADDITIONAL INFORMATION ON ONE MONTHLY NC FILE:

12 variables (excluding dimension variables):
        short t2m[longitude,latitude,time]   
            scale_factor: 0.000250859493618673
            add_offset: 301.508114316347
            _FillValue: -32767
            missing_value: -32767
            units: K
            long_name: 2 metre temperature
        short d2m[longitude,latitude,time]   
            scale_factor: 0.000189842033307647
            add_offset: 296.056545703983
            _FillValue: -32767
            missing_value: -32767
            units: K
            long_name: 2 metre dewpoint temperature
        short sp[longitude,latitude,time]   
            scale_factor: 0.0470135275357454
            add_offset: 96477.3202432362
            _FillValue: -32767
            missing_value: -32767
            units: Pa
            long_name: Surface pressure
            standard_name: surface_air_pressure
        short u10[longitude,latitude,time]   
            scale_factor: 0.000152449582891444
            add_offset: 0.590744087708554
            _FillValue: -32767
            missing_value: -32767
            units: m s**-1
            long_name: 10 metre U wind component
        short v10[longitude,latitude,time]   
            scale_factor: 0.00013693746249206
            add_offset: 0.66616840871016
            _FillValue: -32767
            missing_value: -32767
            units: m s**-1
            long_name: 10 metre V wind component
        short tp[longitude,latitude,time]   
            scale_factor: 2.85070516901134e-07
            add_offset: 0.00934062055678257
            _FillValue: -32767
            missing_value: -32767
            units: m
            long_name: Total precipitation
        short tcc[longitude,latitude,time]   
            scale_factor: 1.52594875864068e-05
            add_offset: 0.499992370256207
            _FillValue: -32767
            missing_value: -32767
            units: (0 - 1)
            long_name: Total cloud cover
            standard_name: cloud_area_fraction
        short msnlwrf[longitude,latitude,time]   
            scale_factor: 0.00173717121168915
            add_offset: -56.7456195621683
            _FillValue: -32767
            missing_value: -32767
            units: W m**-2
            long_name: Mean surface net long-wave radiation flux
        short msdwlwrf[longitude,latitude,time]   
            scale_factor: 0.0012878582820392
            add_offset: 410.789761344296
            _FillValue: -32767
            missing_value: -32767
            units: W m**-2
            long_name: Mean surface downward long-wave radiation flux
        short fdir[longitude,latitude,time]   
            scale_factor: 46.9767598004059
            add_offset: 1539240.5116201
            _FillValue: -32767
            missing_value: -32767
            units: J m**-2
            long_name: Total sky direct solar radiation at surface
        short ssrd[longitude,latitude,time]   
            scale_factor: 54.2183022294111
            add_offset: 1776516.89084889
            _FillValue: -32767
            missing_value: -32767
            units: J m**-2
            long_name: Surface short-wave (solar) radiation downwards
            standard_name: surface_downwelling_shortwave_flux_in_air
        short lsm[longitude,latitude,time]   
            scale_factor: 9.55416624213488e-06
            add_offset: 0.686938634743966
            _FillValue: -32767
            missing_value: -32767
            units: (0 - 1)
            long_name: Land-sea mask
            standard_name: land_binary_mask

     3 dimensions:
        longitude  Size:21 
            units: degrees_east
            long_name: longitude
        latitude  Size:16 
            units: degrees_north
            long_name: latitude
        time  Size:744 
            units: hours since 1900-01-01 00:00:00.0
            long_name: time
            calendar: gregorian

    2 global attributes:...


From roy@mende|@@ohn @end|ng |rom no@@@gov  Fri Jun 21 16:14:37 2024
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Fri, 21 Jun 2024 07:14:37 -0700
Subject: [R] Problem with combining monthly nc files into a yearly file
 (era5 climate data)
In-Reply-To: <trinity-6b428587-39f7-4908-a770-8749f84f16da-1718967562004@3c-app-gmx-bs08>
References: <trinity-6b428587-39f7-4908-a770-8749f84f16da-1718967562004@3c-app-gmx-bs08>
Message-ID: <856DF54D-9E79-4FA8-AA11-57B51A75FB4A@noaa.gov>

Hi Leni:

You forget to post the important part - the errors you have been getting and if you have the errors isolated to particular lines in the code.

HTH,

-Roy


> On Jun 21, 2024, at 3:59?AM, Leni Koehnen via R-help <r-help at r-project.org> wrote:
> 
> Dear R-help List, 
> 
> I am currently trying to run a code which is available on Zenodo  (https://zenodo.org/records/10997880  - 02_MicroClimModel.R).
> 
> The code downloads yearly era5 climate data. Unfortunately, the limit to download these nc-files was recently reduced to 60000. Therefore, I can not download the yearly file anymore. I have solved this by rewriting the code, so that it downloads 12 monthly files. 
> 
> However, I have not been able to combine these 12 monthly nc-files into one yearly file. The code gives me errors if I continue running it. I assume that the combination was not successful and might have messed up the format. I would greatly appreciate any advice on how to convert these monthly nc-files into one yearly file.
> 
> Thank you very much in advance!
> 
> Here is the full code: 
> 
> 
> ' *****************************************************************
> #' ~~ STEP 01 DOWNLOADING & PROCESSING HOURLY CLIMATE DATA 
> 
> # Install the remotes package if not already installed
> if (!requireNamespace("remotes", quietly = TRUE)) {
>  install.packages("remotes")
> }
> # Install packages from CRAN
> install.packages(c("terra", "raster", "ncdf4", "lubridate"))
> install.packages("lutz")
> #install dependencies for microclima
> remotes::install_github("ropensci/rnoaa")
> 
> # Install packages from GitHub
> remotes::install_github("dklinges9/mcera5")
> remotes::install_github("ilyamaclean/microclima")
> remotes::install_github("ilyamaclean/microclimf")
> 
> #' ~~ Required libraries:
> require(terra)
> require(raster)
> require(mcera5) # https://github.com/dklinges9/mcera5
> require(ncdf4)
> require(microclima) # https://github.com/ilyamaclean/microclima
> require(microclimf) # https://github.com/ilyamaclean/microclimf
> require(ecmwfr)
> require(lutz)
> require(lubridate)
> 
> # Set paths and year of interest
> pathtodata <- "F:/Dat/"
> pathtoera5 <- paste0(pathtodata, "era5/")
> year <- 2019
> 
> # Set user credentials for CDS API (you have to first register and insert here your UID and API key at https://cds.climate.copernicus.eu/user/register and allow downloads)
> uid <- "xxx"
> cds_api_key <- "xxx"
> ecmwfr::wf_set_key(user = uid, key = cds_api_key, service = "cds")
> 
> # Define the spatial extent for your tile
> xmn <- 18.125
> xmx <- 22.875
> ymn <- -1.625
> ymx <- 1.875
> 
> #HERE STARTS THE SECTION WHERE I AM DOWNLOADING MONTHLY FILES 
> 
> # Define the temporal extent of the run
> start_time <- lubridate::ymd(paste0(year, "-01-01"))
> end_time <- lubridate::ymd(paste0(year, "-12-31"))
> 
> # Function to build and send requests for each month
> request_era5_monthly <- function(year, month, uid, xmn, xmx, ymn, ymx, out_path) {
>  # Define the start and end times for the month
>  st_time <- lubridate::ymd(paste0(year, "-", sprintf("%02d", month), "-01"))
>  en_time <- st_time + months(1) - days(1)
> 
>  # Create the file prefix and request
>  file_prefix <- paste0("era5_reanalysis_", year, "_", sprintf("%02d", month))
>  req <- build_era5_request(xmin = xmn, xmax = xmx, ymin = ymn, ymax = ymx, 
>                            start_time = st_time, end_time = en_time, outfile_name = file_prefix)
> 
>  # Send the request and save the data
>  request_era5(request = req, uid = uid, out_path = out_path, overwrite = TRUE)
> }
> 
> # Loop over each month and request data
> for (month in 1:12) {
>  request_era5_monthly(year, month, uid, xmn, xmx, ymn, ymx, pathtoera5)
> }
> 
> #HERE I AM EXPLORING ONE EXEMPLARY MONTHLY NC FILE
> 
> file_path <- paste0(pathtoera5, "era5_reanalysis_2019_01_2019.nc")
> nc <- nc_open(file_path)
> 
> # List all variables
> print(nc)
> 
> # List all variable names in the NetCDF file
> var_names <- names(nc$var)
> print(var_names)
> 
> checkJan <- raster(paste0(pathtoera5, "era5_reanalysis_2019_01_2019.nc"))
> print(checkJan)  
> opencheckJan <- getValues(checkJan)
> opencheckJan
> 
> #HERE IS THE PROBLEM, I AM TRYING TO COMBINE THESE MONTHL NC FILES 
> 
> combine_era5_yearly <- function(year, pathtoera5, outfile) {
>  # List of monthly files
>  monthly_files <- list.files(pathtoera5, pattern = paste0("era5_reanalysis_", year, "_\\d{2}_", year, "\\.nc"), full.names = TRUE)
> 
>  if (length(monthly_files) == 0) {
>    stop("No monthly files found")
>  }
> 
>  # Initialize lists to store data
>  lons <- NULL
>  lats <- NULL
>  time <- NULL
>  t2m <- list()
>  d2m <- list()
>  sp <- list()
>  u10 <- list()
>  v10 <- list()
>  tp <- list()
>  tcc <- list()
>  msnlwrf <- list()
>  msdwlwrf <- list()
>  fdir <- list()
>  ssrd <- list()
>  lsm <- list()
> 
>  # Read each monthly file and extract variables
>  for (file in monthly_files) {
>    nc <- nc_open(file)
> 
>    if (is.null(lons)) {
>      lons <- ncvar_get(nc, "longitude")
>      lats <- ncvar_get(nc, "latitude")
>      time <- ncvar_get(nc, "time")
>    } else {
>      time <- c(time, ncvar_get(nc, "time"))
>    }
> 
>    t2m <- c(t2m, list(ncvar_get(nc, "t2m")))
>    d2m <- c(d2m, list(ncvar_get(nc, "d2m")))
>    sp <- c(sp, list(ncvar_get(nc, "sp")))
>    u10 <- c(u10, list(ncvar_get(nc, "u10")))
>    v10 <- c(v10, list(ncvar_get(nc, "v10")))
>    tp <- c(tp, list(ncvar_get(nc, "tp")))
>    tcc <- c(tcc, list(ncvar_get(nc, "tcc")))
>    msnlwrf <- c(msnlwrf, list(ncvar_get(nc, "msnlwrf")))
>    msdwlwrf <- c(msdwlwrf, list(ncvar_get(nc, "msdwlwrf")))
>    fdir <- c(fdir, list(ncvar_get(nc, "fdir")))
>    ssrd <- c(ssrd, list(ncvar_get(nc, "ssrd")))
>    lsm <- c(lsm, list(ncvar_get(nc, "lsm")))
> 
>    nc_close(nc)
>  }
> 
>  # Combine the data for each variable
>  t2m <- do.call(c, t2m)
>  d2m <- do.call(c, d2m)
>  sp <- do.call(c, sp)
>  u10 <- do.call(c, u10)
>  v10 <- do.call(c, v10)
>  tp <- do.call(c, tp)
>  tcc <- do.call(c, tcc)
>  msnlwrf <- do.call(c, msnlwrf)
>  msdwlwrf <- do.call(c, msdwlwrf)
>  fdir <- do.call(c, fdir)
>  ssrd <- do.call(c, ssrd)
>  lsm <- do.call(c, lsm)
> 
>  # Create a new NetCDF file for the entire year
>  outfile <- paste0(pathtoera5, "era5_reanalysis_", year, ".nc")
>  dim_lon <- ncdim_def("longitude", "degrees_east", lons)
>  dim_lat <- ncdim_def("latitude", "degrees_north", lats)
>  dim_time <- ncdim_def("time", "hours since 1900-01-01 00:00:00", time, unlim=TRUE)
> 
>  # Define variables
>  var_t2m <- ncvar_def("t2m", "K", list(dim_lon, dim_lat, dim_time), -9999)
>  var_d2m <- ncvar_def("d2m", "K", list(dim_lon, dim_lat, dim_time), -9999)
>  var_sp <- ncvar_def("sp", "Pa", list(dim_lon, dim_lat, dim_time), -9999)
>  var_u10 <- ncvar_def("u10", "m/s", list(dim_lon, dim_lat, dim_time), -9999)
>  var_v10 <- ncvar_def("v10", "m/s", list(dim_lon, dim_lat, dim_time), -9999)
>  var_tp <- ncvar_def("tp", "m", list(dim_lon, dim_lat, dim_time), -9999)
>  var_tcc <- ncvar_def("tcc", "1", list(dim_lon, dim_lat, dim_time), -9999)
>  var_msnlwrf <- ncvar_def("msnlwrf", "W/m^2", list(dim_lon, dim_lat, dim_time), -9999)
>  var_msdwlwrf <- ncvar_def("msdwlwrf", "W/m^2", list(dim_lon, dim_lat, dim_time), -9999)
>  var_fdir <- ncvar_def("fdir", "J/m^2", list(dim_lon, dim_lat, dim_time), -9999)
>  var_ssrd <- ncvar_def("ssrd", "J/m^2", list(dim_lon, dim_lat, dim_time), -9999)
>  var_lsm <- ncvar_def("lsm", "1", list(dim_lon, dim_lat, dim_time), -9999)
> 
>  # Create the file
>  ncout <- nc_create(outfile, list(var_t2m, var_d2m, var_sp, var_u10, var_v10, var_tp, var_tcc, var_msnlwrf, var_msdwlwrf, var_fdir, var_ssrd, var_lsm))
> 
>  # Write data to the new file
>  ncvar_put(ncout, var_t2m, t2m)
>  ncvar_put(ncout, var_d2m, d2m)
>  ncvar_put(ncout, var_sp, sp)
>  ncvar_put(ncout, var_u10, u10)
>  ncvar_put(ncout, var_v10, v10)
>  ncvar_put(ncout, var_tp, tp)
>  ncvar_put(ncout, var_tcc, tcc)
>  ncvar_put(ncout, var_msnlwrf, msnlwrf)
>  ncvar_put(ncout, var_msdwlwrf, msdwlwrf)
>  ncvar_put(ncout, var_fdir, fdir)
>  ncvar_put(ncout, var_ssrd, ssrd)
>  ncvar_put(ncout, var_lsm, lsm)
> 
>  # Define and write longitude and latitude variables
>  ncvar_put(ncout, "longitude", lons)
>  ncvar_put(ncout, "latitude", lats)
>  ncatt_put(ncout, "longitude", "units", "degrees_east")
>  ncatt_put(ncout, "latitude", "units", "degrees_north")
> 
>  # Define and write time variable
>  ncvar_put(ncout, "time", time)
>  ncatt_put(ncout, "time", "units", "hours since 1900-01-01 00:00:00")
>  ncatt_put(ncout, "time", "calendar", "gregorian")
> 
>  # Global attributes
>  ncatt_put(ncout, 0, "title", paste0("ERA5 reanalysis data for ", year))
>  ncatt_put(ncout, 0, "source", "ECMWF ERA5")
> 
>  # Close the NetCDF file
>  nc_close(ncout)
> }
> 
> # Example usage:
> outfile <- paste0(pathtoera5, "era5_reanalysis_", year, ".nc")
> combine_era5_yearly(year, pathtoera5, outfile)
> 
> 
> 
> 
> #HERE IS THE REST OF THE CODE WHICH REQUIRES THE YEARLY FILE
> 
> 
> #' Process Hourly Climate Data >>>
> file <- paste0(pathtoera5,"era5_reanalysis_",year,".nc")
> clim <- nc_open(file)
> 
> #' create a template to crop input dataset to for step 2: '02_VegParms.R'
> test <- raster::brick(file, varname = "t2m")
> t_array <- as.array(test[[1]])
> ext_r <- ext(raster::extent(test))
> r <- rast(t_array, crs = "EPSG:4326", ext = ext_r)
> 
> #' Get coordinates & time:
> lons <- ncdf4::ncvar_get(clim, varid = "longitude")
> lats <- ncdf4::ncvar_get(clim, varid = "latitude")
> time <- ncdf4::ncvar_get(clim, "time")
> 
> x_dim <- length(lons)
> y_dim <- length(lats)
> z_dim <- length(time)
> 
> #' Assign a local timezone:
> tmz <- lutz::tz_lookup_coords(lats[length(lats)/2], lons[length(lons)/2], method = 'fast')
> 
> origin <- as.POSIXlt("1900-01-01 00:00:00", tz = "UTC")
> UTC_tme <- origin + as.difftime(time, units = "hours")
> UTC_tme <- as.POSIXlt(UTC_tme, tz = "UTC")
> local_tme <- lubridate::with_tz(UTC_tme, tzone = tmz)
> 
> jd <- microctools::jday(tme = UTC_tme)
> lt <- local_tme$hour + local_tme$min/60 + local_tme$sec/3600
> 
> #' Create empty climate variable arrays:
> #' These are 3-D arrays with time (hours) in the 3rd dimension.
> t_a <- array(data = NA, c(y_dim, x_dim, z_dim))
> t_sh <- array(data = NA, c(y_dim, x_dim, z_dim))
> t_pa <- array(data = NA, c(y_dim, x_dim, z_dim))
> t_ws <- array(data = NA, c(y_dim, x_dim, z_dim))
> t_wd <- array(data = NA, c(y_dim, x_dim, z_dim))
> t_se <- array(data = NA, c(y_dim, x_dim, z_dim))
> t_nl <- array(data = NA, c(y_dim, x_dim, z_dim))
> t_ul <- array(data = NA, c(y_dim, x_dim, z_dim))
> t_dl <- array(data = NA, c(y_dim, x_dim, z_dim))
> t_rd <- array(data = NA, c(y_dim, x_dim, z_dim))
> t_rdf <- array(data = NA, c(y_dim, x_dim, z_dim))
> t_sz <- array(data = NA, c(y_dim, x_dim, z_dim))
> p_a <- array(data = NA, c(y_dim, x_dim, length(local_tme)/24)) # note: rainfall recorded daily.
> 
> #' Fill empty arrays with processed era5 data:
> #' Use the 'extract_clim' function from the mcera5 package to convert era5 data to microclimf-ready data. 
> for(i in 1:y_dim){ # for each row in the new array.
>  for(j in 1:x_dim){ # for each column in the new array.
>    long <- lons[j]
>    lat <- lats[i]
>    climate <- extract_clim(file, long, lat, start_time = UTC_tme[1], end_time = UTC_tme[length(UTC_tme)])
>    t_a[i,j,] <- climate$temperature
>    t_sh[i,j,] <- climate$humidity
>    t_pa[i,j,] <- climate$pressure
>    t_ws[i,j,] <- climate$windspeed
>    t_wd[i,j,] <- climate$winddir
>    t_se[i,j,] <- climate$emissivity
>    t_nl[i,j,] <- climate$netlong
>    t_ul[i,j,] <- climate$uplong
>    t_dl[i,j,] <- climate$downlong
>    t_rd[i,j,] <- climate$rad_dni
>    t_rdf[i,j,] <- climate$rad_dif
>    t_sz[i,j,] <- climate$szenith
>  } # end column j
> } # end row i
> 
> #' Repeat for daily rainfall:
> #' Use the 'extract_precip' function from the mcera5 package to convert era5 data to microclimf-ready data. 
> for(i in 1:y_dim){ # for each row in the new array.
>  for(j in 1:x_dim){ # for each column in the new array.
>    long <- lons[j]
>    lat <- lats[i]
>    precip <- extract_precip(file, long, lat, start_time = UTC_tme[1], end_time = UTC_tme[length(UTC_tme)])
>    p_a[i,j,] <- precip
>  } # end column j
> } # end row i
> 
> 
> #' Additional processing for microclimf inputs:
> #' Calculate Solar Index...
> si <- array(data = NA, dim = c(y_dim, x_dim, z_dim))
> for(a in 1:nrow(si)){
>  for(b in 1:ncol(si)){
>    x <- lons[b]
>    y <- lats[a]
>    s = microclima::siflat(lubridate::hour(local_tme), y, x, jd)    
>    si[a,b,] <- s
>  }
> }  
> #' Calculate Global Horizontal Irradiance (GHI) from Direct Normal Irradiance (DNI)
> #' and convert units from MJh/m^2 to kWh/m^2
> raddr <- (t_rd * si)/0.0036
> difrad <- t_rdf/0.0036
> 
> #' Cap diffuse radiation data (Cannot be less than 0) 
> difrad[difrad < 0] <- 0
> 
> #' Calculate shortwave radiation:
> #' Sum Global Horizontal Irradiance (GHI) and Diffuse Radiation. 
> swrad <- raddr + difrad
> 
> #' Cap shortwave radiation between 0 > sw < 1350 (lower than the solar constant)
> swrad[swrad < 0] <- 0
> swrad[swrad > 1350] <- 1350
> 
> #' Calculate relative humidity
> #' Using specific humidity, temperature and pressure. 
> t_rh <- array(data = NA, c(y_dim, x_dim, z_dim))
> for(i in 1:nrow(t_rh)){ 
>  for(j in 1:ncol(t_rh)){ 
>    rh <- microclima::humidityconvert(t_sh[i,j,],intype = "specific", tc = t_a[i,j,], p = t_pa[i,j,])
>    rh <- rh$relative
>    rh[rh > 100] <- 100
>    t_rh[i,j,] <- rh
>  } 
> } 
> 
> #' Convert pressure untis from Pa to kPa:
> t_pr <- t_pa/1000
> 
> 
> #' Create final climate data set to drive microclimate model:
> #' Note: keep the nomenclature as shown here for microclimf, see microclimf::climdat for example names.
> climdat <- list(tme = local_tme, obs_time = UTC_tme, 
>                temp = t_a, relhum = t_rh, 
>                pres = t_pr, swrad = swrad,
>                difrad = difrad, skyem = t_se,
>                windspeed = t_ws, winddir = t_wd)
> 
> #' Save data:
> pathout <- "F:/Dat/era5/"
> saveRDS(climdat, paste0(pathout,"climdat_",year,".RDS"))
> saveRDS(p_a, paste0(pathout,"rainfall_",year,".RDS"))
> tile_no <- "01"
> writeRaster(r, paste0(pathout,"tile_",tile_no,".tif"))
> 
> 
> #HERE IS ADDITIONAL INFORMATION ON ONE MONTHLY NC FILE:
> 
> 12 variables (excluding dimension variables):
>        short t2m[longitude,latitude,time]   
>            scale_factor: 0.000250859493618673
>            add_offset: 301.508114316347
>            _FillValue: -32767
>            missing_value: -32767
>            units: K
>            long_name: 2 metre temperature
>        short d2m[longitude,latitude,time]   
>            scale_factor: 0.000189842033307647
>            add_offset: 296.056545703983
>            _FillValue: -32767
>            missing_value: -32767
>            units: K
>            long_name: 2 metre dewpoint temperature
>        short sp[longitude,latitude,time]   
>            scale_factor: 0.0470135275357454
>            add_offset: 96477.3202432362
>            _FillValue: -32767
>            missing_value: -32767
>            units: Pa
>            long_name: Surface pressure
>            standard_name: surface_air_pressure
>        short u10[longitude,latitude,time]   
>            scale_factor: 0.000152449582891444
>            add_offset: 0.590744087708554
>            _FillValue: -32767
>            missing_value: -32767
>            units: m s**-1
>            long_name: 10 metre U wind component
>        short v10[longitude,latitude,time]   
>            scale_factor: 0.00013693746249206
>            add_offset: 0.66616840871016
>            _FillValue: -32767
>            missing_value: -32767
>            units: m s**-1
>            long_name: 10 metre V wind component
>        short tp[longitude,latitude,time]   
>            scale_factor: 2.85070516901134e-07
>            add_offset: 0.00934062055678257
>            _FillValue: -32767
>            missing_value: -32767
>            units: m
>            long_name: Total precipitation
>        short tcc[longitude,latitude,time]   
>            scale_factor: 1.52594875864068e-05
>            add_offset: 0.499992370256207
>            _FillValue: -32767
>            missing_value: -32767
>            units: (0 - 1)
>            long_name: Total cloud cover
>            standard_name: cloud_area_fraction
>        short msnlwrf[longitude,latitude,time]   
>            scale_factor: 0.00173717121168915
>            add_offset: -56.7456195621683
>            _FillValue: -32767
>            missing_value: -32767
>            units: W m**-2
>            long_name: Mean surface net long-wave radiation flux
>        short msdwlwrf[longitude,latitude,time]   
>            scale_factor: 0.0012878582820392
>            add_offset: 410.789761344296
>            _FillValue: -32767
>            missing_value: -32767
>            units: W m**-2
>            long_name: Mean surface downward long-wave radiation flux
>        short fdir[longitude,latitude,time]   
>            scale_factor: 46.9767598004059
>            add_offset: 1539240.5116201
>            _FillValue: -32767
>            missing_value: -32767
>            units: J m**-2
>            long_name: Total sky direct solar radiation at surface
>        short ssrd[longitude,latitude,time]   
>            scale_factor: 54.2183022294111
>            add_offset: 1776516.89084889
>            _FillValue: -32767
>            missing_value: -32767
>            units: J m**-2
>            long_name: Surface short-wave (solar) radiation downwards
>            standard_name: surface_downwelling_shortwave_flux_in_air
>        short lsm[longitude,latitude,time]   
>            scale_factor: 9.55416624213488e-06
>            add_offset: 0.686938634743966
>            _FillValue: -32767
>            missing_value: -32767
>            units: (0 - 1)
>            long_name: Land-sea mask
>            standard_name: land_binary_mask
> 
>     3 dimensions:
>        longitude  Size:21 
>            units: degrees_east
>            long_name: longitude
>        latitude  Size:16 
>            units: degrees_north
>            long_name: latitude
>        time  Size:744 
>            units: hours since 1900-01-01 00:00:00.0
>            long_name: time
>            calendar: gregorian
> 
>    2 global attributes:...
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From c@buhtz m@iii@g oii posteo@jp  Fri Jun 21 16:38:58 2024
From: c@buhtz m@iii@g oii posteo@jp (c@buhtz m@iii@g oii posteo@jp)
Date: Fri, 21 Jun 2024 14:38:58 +0000
Subject: [R] Regression performance when using summary() twice
Message-ID: <15127bbd5c705fadb3a86fa8f6bd8dba@posteo.de>

Hello,

I am not a regular R user but coming from Python. But I use R for 
several special task.

Doing a regression analysis does cost some compute time. But I wonder 
when this big time consuming algorithm is executed and if it is done 
twice in my sepcial case.

It seems that calling "glm()" or similar does not execute the time 
consuming part of the regression code.
It seems it is done when calling "summary(model)".
Am I right so far?

If this is correct I would say that in my case the regression is down 
twice with the identical formula and data. Which of course is 
inefficient. See this code:

my_function <- function(formula_string, data) {
             formula <- as.formula(formula_string)
             model <- glm.nb(formula, data = data)

             result = cbind(summary(model)$coefficients, confint(model))
             result = as.data.frame(result)

             string_result = capture.output(summary(model))

             return(list(result, string_result))
         }

I do call summary() once to get the "$coefficents" and a second time 
when capturing its output as a string.

If this really result in computing the regression twice I ask myself if 
there is a R-way to make this more efficent?

Best regards,
Christian Buhtz


From rb@er @end|ng |rom @t@u@edu  Fri Jun 21 17:39:48 2024
From: rb@er @end|ng |rom @t@u@edu (Robert Baer)
Date: Fri, 21 Jun 2024 10:39:48 -0500
Subject: [R] devtools - bad credentials R4.4.1
In-Reply-To: <F7DE22DC-4553-4F43-AA8C-EE35C37E29A6@dcn.davis.ca.us>
References: <408963b6-941b-4f96-a479-554ab846a639@atsu.edu>
 <29078A20-C91B-430B-9895-DE3335A91585@dcn.davis.ca.us>
 <b0a67a88-636f-4e77-ba5d-ecb0ed35b2e4@atsu.edu>
 <F7DE22DC-4553-4F43-AA8C-EE35C37E29A6@dcn.davis.ca.us>
Message-ID: <f42dacb9-2032-4aa1-a601-59d90c809064@atsu.edu>

Thank? you Jeff.? I did not know Windows Credential Manager, but I used 
it and found something that looked like a reference to a GIT PAT and 
removed it. Now devtools::install_github() is once again installing my 
package without complaining.

Appreciate the direction and links.


On 6/20/2024 9:45 PM, Jeff Newmiller wrote:
> I would delete the PAT from the credential manager since it seems to be timed out anyway...<https://support.microsoft.com/en-us/windows/accessing-credential-manager-1b5c916a-6a16-889f-8581-fc16e8165ac0>
>
> I don't know my way around the Windows Credential Manager very well, but it seems to me that it ought to be possible to tell it not to match the entire host but only to apply to one repo. If not, git supports configuration settings related to specific repositories using git config from the connand line without the --global option.
>
> <https://docs.github.com/en/enterprise-server at 3.9/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens>
>
> <https://stackoverflow.com/questions/52222046/how-do-i-store-credentials-per-repository-in-git-credential-manager-for-windows>
>
> On June 20, 2024 4:26:34 PM PDT, Robert Baer<rbaer at atsu.edu>  wrote:
>> Not being a developer, I have limited uderstanding of PATs and global git options, but here is what I was able to cobble together to start looking at my situation:
>>
>>> Sys.getenv("GITHUB_PAT")
>> [1] ""
>>> Sys.unsetenv("GITHUB_PAT")
>>> Sys.getenv("GITHUB_PAT")
>> [1] ""
>>> devtools::install_github("DillonHammill/CytoExploreRData")
>> Using GitHub PAT from the git credential store.
>> Error: Failed to install 'CytoExploreRData' from GitHub:
>>  ? HTTP error 401.
>>  ? Bad credentials
>>
>>  ? Rate limit remaining: 59/60
>>  ? Rate limit reset at: 2024-06-21 00:17:47 UTC
>>
>>
>>> usethis::git_sitrep()
>> ?? Git global (user)
>> ? Name: 'Rob Baer'
>> ? Email: 'rwbaer at gmail.com'
>> ? Global (user-level) gitignore file: 'C:/Users/rbaer/.gitignore'
>> ? Vaccinated: TRUE
>> ? Defaulting to 'https' Git protocol
>> ? Default Git protocol: 'https'
>> ? Default initial branch name: 'master'
>>
>> ?? GitHub user
>> ? Default GitHub host: 'https://github.com'
>> ? Personal access token for 'https://github.com': '<discovered>'
>> ? Can't get user information for this token.
>>  ? The token may no longer be valid or perhaps it lacks the 'user' scope.
>> Error in `gh()`:
>> ! GitHub API error (401): Bad credentials
>> ? Read more at<https://docs.github.com/rest>
>>
>> ? No active usethis project
>>
>> I'm not sure where I go from here. Any hints on what other diagnostics are useful?
>>
>>
>>
>> On 6/20/2024 5:41 PM, Jeff Newmiller wrote:
>>> My guess is that this is related to you saving an expired Personal Access Token in your global git options or credentials store? Git is perfectly capable of using per-repo credentials... don't configure a credential in your global configuration and it won't fall back on using it to access random new repositories.
>>>
>>> On June 20, 2024 3:16:55 PM PDT, Robert Baer<rbaer at atsu.edu>  wrote:
>>>> I am trying to install a package from github which has worked fine in the past, but now seems to be stuck on some new authentication issues.? Does anyone know how I can straighten myself out?? In theory, this is a public repository so I'm not sure why I even need authenticating for installation.
>>>>
>>>> Thanks,
>>>>
>>>> Rob
>>>>
>>>> The code:
>>>>
>>>>> devtools::install_github("DillonHammill/CytoExploreR")
>>>> Using GitHub PAT from the git credential store.
>>>> Error: Failed to install 'unknown package' from GitHub:
>>>>   ? HTTP error 401.
>>>>   ? Bad credentials
>>>>
>>>>   ? Rate limit remaining: 50/60
>>>>   ? Rate limit reset at: 2024-06-20 22:19:33 UTC
>>>>
>>>>
>>>>> Using GitHub PAT from the git credential store.
>>>> Error: unexpected symbol in "Using GitHub"
>>>>> Error: Failed to install 'unknown package' from GitHub:
>>>> Error: unexpected symbol in "Error: Failed to"
>>>>>   ?? HTTP error 401.
>>>> Error: unexpected symbol in "? HTTP error"
>>>>>   ?? Bad credentials
>>>> Error: unexpected symbol in "? Bad credentials"
>>>>>   ?? Rate limit remaining: 55/60
>>>> Error: unexpected symbol in "? Rate limit"
>>>>>   ?? Rate limit reset at: 2024-06-20 21:12:27 UTC```
>>>> Error: unexpected symbol in "? Rate limit"
>>>>> **Include any associated screenshots or images here:**
>>>> SESSIONINFO
>>>>
>>>>> sessionInfo()
>>>> R version 4.4.1 (2024-06-14 ucrt)
>>>> Platform: x86_64-w64-mingw32/x64
>>>> Running under: Windows 11 x64 (build 26120)
>>>>
>>>> Matrix products: default
>>>>
>>>>
>>>> locale:
>>>> [1] LC_COLLATE=English_United States.utf8
>>>> [2] LC_CTYPE=English_United States.utf8
>>>> [3] LC_MONETARY=English_United States.utf8
>>>> [4] LC_NUMERIC=C
>>>> [5] LC_TIME=English_United States.utf8
>>>>
>>>> time zone: America/Chicago
>>>> tzcode source: internal
>>>>
>>>> attached base packages:
>>>> [1] stats???? graphics? grDevices utils???? datasets? methods base
>>>>
>>>> loaded via a namespace (and not attached):
>>>>   ?[1] vctrs_0.6.5?????? cli_3.6.2???????? rlang_1.1.4 stringi_1.8.4
>>>>   ?[5] purrr_1.0.2?????? pkgload_1.3.4???? promises_1.3.0 shiny_1.8.1.1
>>>>   ?[9] xtable_1.8-4????? glue_1.7.0??????? htmltools_0.5.8.1 httpuv_1.6.15
>>>> [13] pkgbuild_1.4.4??? ellipsis_0.3.2??? fastmap_1.2.0 lifecycle_1.0.4
>>>> [17] memoise_2.0.1???? stringr_1.5.1???? compiler_4.4.1 miniUI_0.1.1.1
>>>> [21] sessioninfo_1.2.2 fs_1.6.4????????? htmlwidgets_1.6.4 Rcpp_1.0.12
>>>> [25] urlchecker_1.0.1? later_1.3.2?????? digest_0.6.35 R6_2.5.1
>>>> [29] curl_5.2.1??????? usethis_2.2.3???? magrittr_2.0.3 tools_4.4.1
>>>> [33] mime_0.12???????? devtools_2.4.5??? profvis_0.3.8 remotes_2.5.0
>>>> [37] cachem_1.1.0
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org  mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guidehttp://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Fri Jun 21 18:04:51 2024
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Fri, 21 Jun 2024 17:04:51 +0100
Subject: [R] Regression performance when using summary() twice
In-Reply-To: <15127bbd5c705fadb3a86fa8f6bd8dba@posteo.de>
References: <15127bbd5c705fadb3a86fa8f6bd8dba@posteo.de>
Message-ID: <03a7a37d-1a81-747d-c8ce-8a3b18769290@dewey.myzen.co.uk>

Dear Christian

Without knowing how big your datset is it is hard to be sure but 
confint() can take some time.

Have you thought of calling summary once
summ <- summary(model)
and then replace all subsequent calls to summary with summ

Michael

On 21/06/2024 15:38, c.buhtz at posteo.jp wrote:
> Hello,
> 
> I am not a regular R user but coming from Python. But I use R for 
> several special task.
> 
> Doing a regression analysis does cost some compute time. But I wonder 
> when this big time consuming algorithm is executed and if it is done 
> twice in my sepcial case.
> 
> It seems that calling "glm()" or similar does not execute the time 
> consuming part of the regression code.
> It seems it is done when calling "summary(model)".
> Am I right so far?
> 
> If this is correct I would say that in my case the regression is down 
> twice with the identical formula and data. Which of course is 
> inefficient. See this code:
> 
> my_function <- function(formula_string, data) {
>  ??????????? formula <- as.formula(formula_string)
>  ??????????? model <- glm.nb(formula, data = data)
> 
>  ??????????? result = cbind(summary(model)$coefficients, confint(model))
>  ??????????? result = as.data.frame(result)
> 
>  ??????????? string_result = capture.output(summary(model))
> 
>  ??????????? return(list(result, string_result))
>  ??????? }
> 
> I do call summary() once to get the "$coefficents" and a second time 
> when capturing its output as a string.
> 
> If this really result in computing the regression twice I ask myself if 
> there is a R-way to make this more efficent?
> 
> Best regards,
> Christian Buhtz
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael


From j|ox @end|ng |rom mcm@@ter@c@  Fri Jun 21 18:14:37 2024
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Fri, 21 Jun 2024 12:14:37 -0400
Subject: [R] Regression performance when using summary() twice
In-Reply-To: <15127bbd5c705fadb3a86fa8f6bd8dba@posteo.de>
References: <15127bbd5c705fadb3a86fa8f6bd8dba@posteo.de>
Message-ID: <cb42082d-6ddf-4a62-a30f-97e31fcdc742@mcmaster.ca>

Dear Christian,

You're apparently using the glm.nb() function in the MASS package.

Your function is peculiar in several respects. For example, you specify 
the model formula as a character string and then convert it into a 
formula, but you could just pass the formula to the function -- the 
conversion seems unnecessary. Similarly, you compute the summary for the 
model twice rather than just saving it in a local variable in your 
function. And the form of the function output is a bit strange, but I 
suppose you have reasons for that.

The primary reason that your function is slow, however, is that the 
confidence intervals computed by confint() profile the likelihood, which 
requires refitting the model a number of times. If you're willing to use 
possibly less accurate Wald-based rather than likelihood-based 
confidence intervals, computed, e.g., by the Confint() function in the 
car package, then you could speed up the computation considerably,

Using a model fit by example(glm.nb),

	library(MASS)
	example(glm.nb)
	microbenchmark::microbenchmark(
	  Wald = car::Confint(quine.nb1, vcov.=vcov(quine.nb1),
	               estimate=FALSE),
	  LR = confint(quine.nb1)
	)

which produces

Unit: microseconds
  expr       min       lq       mean    median       uq        max
  Wald   136.366   161.13   222.0872   184.541   283.72    386.466
    LR 87223.031 88757.09 95162.8733 95761.568 97672.23 182734.048
  neval
    100
    100


I hope this helps,
  Johm
-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://www.john-fox.ca/
--
On 2024-06-21 10:38 a.m., c.buhtz at posteo.jp wrote:
> [You don't often get email from c.buhtz at posteo.jp. Learn why this is 
> important at https://aka.ms/LearnAboutSenderIdentification ]
> 
> Caution: External email.
> 
> 
> Hello,
> 
> I am not a regular R user but coming from Python. But I use R for
> several special task.
> 
> Doing a regression analysis does cost some compute time. But I wonder
> when this big time consuming algorithm is executed and if it is done
> twice in my sepcial case.
> 
> It seems that calling "glm()" or similar does not execute the time
> consuming part of the regression code.
> It seems it is done when calling "summary(model)".
> Am I right so far?
> 
> If this is correct I would say that in my case the regression is down
> twice with the identical formula and data. Which of course is
> inefficient. See this code:
> 
> my_function <- function(formula_string, data) {
>  ??????????? formula <- as.formula(formula_string)
>  ??????????? model <- glm.nb(formula, data = data)
> 
>  ??????????? result = cbind(summary(model)$coefficients, confint(model))
>  ??????????? result = as.data.frame(result)
> 
>  ??????????? string_result = capture.output(summary(model))
> 
>  ??????????? return(list(result, string_result))
>  ??????? }
> 
> I do call summary() once to get the "$coefficents" and a second time
> when capturing its output as a string.
> 
> If this really result in computing the regression twice I ask myself if
> there is a R-way to make this more efficent?
> 
> Best regards,
> Christian Buhtz
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @tyen @end|ng |rom ntu@edu@tw  Mon Jun 24 13:41:10 2024
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Mon, 24 Jun 2024 19:41:10 +0800
Subject: [R] Naming output file
Message-ID: <77836dc7-0680-42e6-b26f-2ba2e743b83f@ntu.edu.tw>

I would like a loop to

(1) read data files 2010midata1,2010midata2,2010midata3; and

(2)? name OUTPUT bop1,bop2,bop3.

I succeeded in line 3 of the code below,

BUT not line 4. The error message says:

Error in paste0("bop", im) <- boprobit(eqs, mydata, wt = weight, method 
= "NR", : target of assignment expands to non-language object Please 
help. Thanks.

m<-3
for (im in 1:m) {
mydata<-read.csv(paste0("2010midata",im,".csv"))
paste0("bop",im)<-boprobit(eqs,mydata,wt=weight,method="BHHH",tol=0,reltol=0,gradtol=1e-5,Fisher=TRUE)
}



	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Mon Jun 24 13:51:14 2024
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Mon, 24 Jun 2024 14:51:14 +0300
Subject: [R] Naming output file
In-Reply-To: <77836dc7-0680-42e6-b26f-2ba2e743b83f@ntu.edu.tw>
References: <77836dc7-0680-42e6-b26f-2ba2e743b83f@ntu.edu.tw>
Message-ID: <CAGgJW75ycGXsBwkZdmS_01RLRtHH3RGT2d8uo2rCzRRcOSXMCA@mail.gmail.com>

How about

assign(paste0("bop",im), boprobit( etc ))



On Mon, Jun 24, 2024 at 2:41?PM Steven Yen <styen at ntu.edu.tw> wrote:

> I would like a loop to
>
> (1) read data files 2010midata1,2010midata2,2010midata3; and
>
> (2)  name OUTPUT bop1,bop2,bop3.
>
> I succeeded in line 3 of the code below,
>
> BUT not line 4. The error message says:
>
> Error in paste0("bop", im) <- boprobit(eqs, mydata, wt = weight, method
> = "NR", : target of assignment expands to non-language object Please
> help. Thanks.
>
> m<-3
> for (im in 1:m) {
> mydata<-read.csv(paste0("2010midata",im,".csv"))
>
> paste0("bop",im)<-boprobit(eqs,mydata,wt=weight,method="BHHH",tol=0,reltol=0,gradtol=1e-5,Fisher=TRUE)
> }
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Jun 24 13:55:32 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 24 Jun 2024 12:55:32 +0100
Subject: [R] Naming output file
In-Reply-To: <77836dc7-0680-42e6-b26f-2ba2e743b83f@ntu.edu.tw>
References: <77836dc7-0680-42e6-b26f-2ba2e743b83f@ntu.edu.tw>
Message-ID: <cd5fbeda-f1b4-4ab8-bd9b-04e187ff2733@sapo.pt>

?s 12:41 de 24/06/2024, Steven Yen escreveu:
> I would like a loop to
> 
> (1) read data files 2010midata1,2010midata2,2010midata3; and
> 
> (2)? name OUTPUT bop1,bop2,bop3.
> 
> I succeeded in line 3 of the code below,
> 
> BUT not line 4. The error message says:
> 
> Error in paste0("bop", im) <- boprobit(eqs, mydata, wt = weight, method
> = "NR", : target of assignment expands to non-language object Please
> help. Thanks.
> 
> m<-3
> for (im in 1:m) {
> mydata<-read.csv(paste0("2010midata",im,".csv"))
> paste0("bop",im)<-boprobit(eqs,mydata,wt=weight,method="BHHH",tol=0,reltol=0,gradtol=1e-5,Fisher=TRUE)
> }
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

Here are two ways, with a for loop and with a lapply loop.


# for loop
m <- 3
# create the input filenames in one instruction
INPUT <- paste0("2010midata", seq.int(m), ".csv")
# create a named list with m elements to store the output
OUTPUT <- vector("list", length = m) |> setNames(paste0("bop", seq.int(m)))
for(i in seq.int(m)) {
   mydata <- read.csv(INPUT[[i]])
   OUTPUT[[i]] <- boprobit(eqs, mydata, wt=weight, method="BHHH",
                           tol=0, reltol=0, gradtol=1e-5, Fisher=TRUE)
}



# lapply loop
m <- 3
# create the input filenames in one instruction
INPUT <- paste0("2010midata", seq.int(m), ".csv")
# no need to create the output list, it will be the
# return value of lapply
OUTPUT <- lapply(INPUT, \(f) {
   mydata <- read.csv(f)
   boprobit(eqs, mydata, wt=weight, method="BHHH",
            tol=0, reltol=0, gradtol=1e-5, Fisher=TRUE)
})
# assign the output list's names
names(OUTPUT) <- paste0("bop", seq.int(m))


Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From @tyen @end|ng |rom ntu@edu@tw  Mon Jun 24 13:55:58 2024
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Mon, 24 Jun 2024 19:55:58 +0800
Subject: [R] Naming output file
In-Reply-To: <CAGgJW75ycGXsBwkZdmS_01RLRtHH3RGT2d8uo2rCzRRcOSXMCA@mail.gmail.com>
References: <77836dc7-0680-42e6-b26f-2ba2e743b83f@ntu.edu.tw>
 <CAGgJW75ycGXsBwkZdmS_01RLRtHH3RGT2d8uo2rCzRRcOSXMCA@mail.gmail.com>
Message-ID: <53a022f3-fbc9-429f-88bb-afc2369d2fbe@ntu.edu.tw>

Thanks Eric. I am not following your suggested line. Would you just edit 
my line 4? Thanks.

On 6/24/2024 7:51 PM, Eric Berger wrote:
> How about
>
> assign(paste0("bop",im), boprobit( etc ))
>
>
>
> On Mon, Jun 24, 2024 at 2:41?PM Steven Yen <styen at ntu.edu.tw> wrote:
>
>     I would like a loop to
>
>     (1) read data files 2010midata1,2010midata2,2010midata3; and
>
>     (2)? name OUTPUT bop1,bop2,bop3.
>
>     I succeeded in line 3 of the code below,
>
>     BUT not line 4. The error message says:
>
>     Error in paste0("bop", im) <- boprobit(eqs, mydata, wt = weight,
>     method
>     = "NR", : target of assignment expands to non-language object Please
>     help. Thanks.
>
>     m<-3
>     for (im in 1:m) {
>     mydata<-read.csv(paste0("2010midata",im,".csv"))
>     paste0("bop",im)<-boprobit(eqs,mydata,wt=weight,method="BHHH",tol=0,reltol=0,gradtol=1e-5,Fisher=TRUE)
>     }
>
>
>
>     ? ? ? ? [[alternative HTML version deleted]]
>
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>
	[[alternative HTML version deleted]]


From |kry|ov @end|ng |rom d|@root@org  Mon Jun 24 13:57:28 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Mon, 24 Jun 2024 14:57:28 +0300
Subject: [R] Naming output file
In-Reply-To: <77836dc7-0680-42e6-b26f-2ba2e743b83f@ntu.edu.tw>
References: <77836dc7-0680-42e6-b26f-2ba2e743b83f@ntu.edu.tw>
Message-ID: <20240624145728.39926673@Tarkus>

? Mon, 24 Jun 2024 19:41:10 +0800
Steven Yen <styen at ntu.edu.tw> ?????:

> (2)? name OUTPUT bop1,bop2,bop3.
> 
> I succeeded in line 3 of the code below,
> 
> BUT not line 4. The error message says:
> 
> Error in paste0("bop", im) <- boprobit(eqs, mydata, wt = weight,
> method = "NR", : target of assignment expands to non-language object
> Please help. Thanks.

If you really want to generate variable names and assign then in the
global environment programmatically, you can use assign(paste0("bop",
im), boprobit(...)), but I wouldn't recommend to do this. When there's
a thousand of these files, would you really want to have 1000 variables
and access them in a similarly awkward fashion using get(variablename)?

Your analysis results are clearly related and form a sequence. Why not
put them in a list?

bop <- list()
# or: be a good citizen and preallocate the list
bop <- vector('list', 3)

# instead of assign(...):
bop[[im]] <- boprobit(...)

This way you can still address the individual elements of the sequence
using bop[[1]], bop[[2]], bop[[3]], but you can also operate on the
whole sequence, e.g., save it to a file using saveRDS(bop, 'bop.rds').
Lists also compose better with lapply(), parLapply(), and many other
functions that operate on collections of R objects.

-- 
Best regards,
Ivan


From er|cjberger @end|ng |rom gm@||@com  Mon Jun 24 13:57:02 2024
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Mon, 24 Jun 2024 14:57:02 +0300
Subject: [R] Naming output file
In-Reply-To: <53a022f3-fbc9-429f-88bb-afc2369d2fbe@ntu.edu.tw>
References: <77836dc7-0680-42e6-b26f-2ba2e743b83f@ntu.edu.tw>
 <CAGgJW75ycGXsBwkZdmS_01RLRtHH3RGT2d8uo2rCzRRcOSXMCA@mail.gmail.com>
 <53a022f3-fbc9-429f-88bb-afc2369d2fbe@ntu.edu.tw>
Message-ID: <CAGgJW747+jGWrcw_qd__Ttc+O8Vxfp-MbmmskfH3pPXY-rv-og@mail.gmail.com>

assign(paste0("bop",im),boprobit(eqs,mydata,wt=weight,method="BHHH",tol=0,reltol=0,gradtol=1e-5,Fisher=TRUE))


On Mon, Jun 24, 2024 at 2:56?PM Steven Yen <styen at ntu.edu.tw> wrote:

> Thanks Eric. I am not following your suggested line. Would you just edit
> my line 4? Thanks.
> On 6/24/2024 7:51 PM, Eric Berger wrote:
>
> How about
>
> assign(paste0("bop",im), boprobit( etc ))
>
>
>
> On Mon, Jun 24, 2024 at 2:41?PM Steven Yen <styen at ntu.edu.tw> wrote:
>
>> I would like a loop to
>>
>> (1) read data files 2010midata1,2010midata2,2010midata3; and
>>
>> (2)  name OUTPUT bop1,bop2,bop3.
>>
>> I succeeded in line 3 of the code below,
>>
>> BUT not line 4. The error message says:
>>
>> Error in paste0("bop", im) <- boprobit(eqs, mydata, wt = weight, method
>> = "NR", : target of assignment expands to non-language object Please
>> help. Thanks.
>>
>> m<-3
>> for (im in 1:m) {
>> mydata<-read.csv(paste0("2010midata",im,".csv"))
>>
>> paste0("bop",im)<-boprobit(eqs,mydata,wt=weight,method="BHHH",tol=0,reltol=0,gradtol=1e-5,Fisher=TRUE)
>> }
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From @tyen @end|ng |rom ntu@edu@tw  Mon Jun 24 14:16:46 2024
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Mon, 24 Jun 2024 20:16:46 +0800
Subject: [R] Naming output file
In-Reply-To: <CAGgJW747+jGWrcw_qd__Ttc+O8Vxfp-MbmmskfH3pPXY-rv-og@mail.gmail.com>
References: <77836dc7-0680-42e6-b26f-2ba2e743b83f@ntu.edu.tw>
 <CAGgJW75ycGXsBwkZdmS_01RLRtHH3RGT2d8uo2rCzRRcOSXMCA@mail.gmail.com>
 <53a022f3-fbc9-429f-88bb-afc2369d2fbe@ntu.edu.tw>
 <CAGgJW747+jGWrcw_qd__Ttc+O8Vxfp-MbmmskfH3pPXY-rv-og@mail.gmail.com>
Message-ID: <e338fffd-1648-4630-8b90-11d7780015db@ntu.edu.tw>

Great, thanks. Eric's suggestion is the most simple. Here's a resulting 
problem. In the call to ame.bopa in a loop, I like inputs in the call to 
ame.bopa to be bop1, bop2, bop3,... Thanks.

for (im in 1:m) {
ame<-ame.bopa(bop,y1.level=y1value,y2.level=y2value,jindex=jindex1,vb.method="invH",joint12=TRUE,
 ??????????????? printing=FALSE,testing=TRUE)
}

On 6/24/2024 7:57 PM, Eric Berger wrote:
> assign(paste0("bop",im),boprobit(eqs,mydata,wt=weight,method="BHHH",tol=0,reltol=0,gradtol=1e-5,Fisher=TRUE))
>
>
> On Mon, Jun 24, 2024 at 2:56?PM Steven Yen <styen at ntu.edu.tw> wrote:
>
>     Thanks Eric. I am not following your suggested line. Would you
>     just edit my line 4? Thanks.
>
>     On 6/24/2024 7:51 PM, Eric Berger wrote:
>>     How about
>>
>>     assign(paste0("bop",im), boprobit( etc ))
>>
>>
>>
>>     On Mon, Jun 24, 2024 at 2:41?PM Steven Yen <styen at ntu.edu.tw> wrote:
>>
>>         I would like a loop to
>>
>>         (1) read data files 2010midata1,2010midata2,2010midata3; and
>>
>>         (2)? name OUTPUT bop1,bop2,bop3.
>>
>>         I succeeded in line 3 of the code below,
>>
>>         BUT not line 4. The error message says:
>>
>>         Error in paste0("bop", im) <- boprobit(eqs, mydata, wt =
>>         weight, method
>>         = "NR", : target of assignment expands to non-language object
>>         Please
>>         help. Thanks.
>>
>>         m<-3
>>         for (im in 1:m) {
>>         mydata<-read.csv(paste0("2010midata",im,".csv"))
>>         paste0("bop",im)<-boprobit(eqs,mydata,wt=weight,method="BHHH",tol=0,reltol=0,gradtol=1e-5,Fisher=TRUE)
>>         }
>>
>>
>>
>>         ? ? ? ? [[alternative HTML version deleted]]
>>
>>         ______________________________________________
>>         R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>         https://stat.ethz.ch/mailman/listinfo/r-help
>>         PLEASE do read the posting guide
>>         http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>
>>         and provide commented, minimal, self-contained, reproducible
>>         code.
>>
	[[alternative HTML version deleted]]


From |kry|ov @end|ng |rom d|@root@org  Mon Jun 24 15:00:49 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Mon, 24 Jun 2024 16:00:49 +0300
Subject: [R] Naming output file
In-Reply-To: <e338fffd-1648-4630-8b90-11d7780015db@ntu.edu.tw>
References: <77836dc7-0680-42e6-b26f-2ba2e743b83f@ntu.edu.tw>
 <CAGgJW75ycGXsBwkZdmS_01RLRtHH3RGT2d8uo2rCzRRcOSXMCA@mail.gmail.com>
 <53a022f3-fbc9-429f-88bb-afc2369d2fbe@ntu.edu.tw>
 <CAGgJW747+jGWrcw_qd__Ttc+O8Vxfp-MbmmskfH3pPXY-rv-og@mail.gmail.com>
 <e338fffd-1648-4630-8b90-11d7780015db@ntu.edu.tw>
Message-ID: <20240624160049.7b15a8f6@arachnoid>

? Mon, 24 Jun 2024 20:16:46 +0800
Steven Yen <styen at ntu.edu.tw> ?????:

> In the call to ame.bopa in a loop, I like inputs in the call to 
> ame.bopa to be bop1, bop2, bop3,... Thanks.
> 
> for (im in 1:m) {
> ame<-ame.bopa(bop,y1.level=y1value,y2.level=y2value,jindex=jindex1,vb.method="invH",joint12=TRUE,
>  ??????????????? printing=FALSE,testing=TRUE)
> }

Use get(paste0('bop', im)) to read a variable named paste0('bop', im).

If you used a list like suggested by Rui, you would be able to use the
same syntax for read and write access, namely, bop[[im]], instead of
manually assigning variables using assign(name, value) and manually
reading variables using get(name).

-- 
Best regards,
Ivan


From bbo|ker @end|ng |rom gm@||@com  Mon Jun 24 15:07:03 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 24 Jun 2024 09:07:03 -0400
Subject: [R] Naming output file
In-Reply-To: <e338fffd-1648-4630-8b90-11d7780015db@ntu.edu.tw>
References: <77836dc7-0680-42e6-b26f-2ba2e743b83f@ntu.edu.tw>
 <CAGgJW75ycGXsBwkZdmS_01RLRtHH3RGT2d8uo2rCzRRcOSXMCA@mail.gmail.com>
 <53a022f3-fbc9-429f-88bb-afc2369d2fbe@ntu.edu.tw>
 <CAGgJW747+jGWrcw_qd__Ttc+O8Vxfp-MbmmskfH3pPXY-rv-og@mail.gmail.com>
 <e338fffd-1648-4630-8b90-11d7780015db@ntu.edu.tw>
Message-ID: <a672d1ae-ebd4-4677-8d57-add1b4a68597@gmail.com>

   As stated earlier in the thread, this is where you would need to use 
get(paste0("bop", im)) [the analogue of assign].  This unwieldiness is 
the exact reason that several posters are encouraging you to change your 
approach and store these objects in a list ...


On 2024-06-24 8:16 a.m., Steven Yen wrote:
> Great, thanks. Eric's suggestion is the most simple. Here's a resulting
> problem. In the call to ame.bopa in a loop, I like inputs in the call to
> ame.bopa to be bop1, bop2, bop3,... Thanks.
> 
> for (im in 1:m) {
> ame<-ame.bopa(bop,y1.level=y1value,y2.level=y2value,jindex=jindex1,vb.method="invH",joint12=TRUE,
>   ??????????????? printing=FALSE,testing=TRUE)
> }
> 
> On 6/24/2024 7:57 PM, Eric Berger wrote:
>> assign(paste0("bop",im),boprobit(eqs,mydata,wt=weight,method="BHHH",tol=0,reltol=0,gradtol=1e-5,Fisher=TRUE))
>>
>>
>> On Mon, Jun 24, 2024 at 2:56?PM Steven Yen <styen at ntu.edu.tw> wrote:
>>
>>      Thanks Eric. I am not following your suggested line. Would you
>>      just edit my line 4? Thanks.
>>
>>      On 6/24/2024 7:51 PM, Eric Berger wrote:
>>>      How about
>>>
>>>      assign(paste0("bop",im), boprobit( etc ))
>>>
>>>
>>>
>>>      On Mon, Jun 24, 2024 at 2:41?PM Steven Yen <styen at ntu.edu.tw> wrote:
>>>
>>>          I would like a loop to
>>>
>>>          (1) read data files 2010midata1,2010midata2,2010midata3; and
>>>
>>>          (2)? name OUTPUT bop1,bop2,bop3.
>>>
>>>          I succeeded in line 3 of the code below,
>>>
>>>          BUT not line 4. The error message says:
>>>
>>>          Error in paste0("bop", im) <- boprobit(eqs, mydata, wt =
>>>          weight, method
>>>          = "NR", : target of assignment expands to non-language object
>>>          Please
>>>          help. Thanks.
>>>
>>>          m<-3
>>>          for (im in 1:m) {
>>>          mydata<-read.csv(paste0("2010midata",im,".csv"))
>>>          paste0("bop",im)<-boprobit(eqs,mydata,wt=weight,method="BHHH",tol=0,reltol=0,gradtol=1e-5,Fisher=TRUE)
>>>          }
>>>
>>>
>>>
>>>          ? ? ? ? [[alternative HTML version deleted]]
>>>
>>>          ______________________________________________
>>>          R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>          https://stat.ethz.ch/mailman/listinfo/r-help
>>>          PLEASE do read the posting guide
>>>          http://www.R-project.org/posting-guide.html
>>>          <http://www.R-project.org/posting-guide.html>
>>>          and provide commented, minimal, self-contained, reproducible
>>>          code.
>>>
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics
 > E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From @tyen @end|ng |rom ntu@edu@tw  Mon Jun 24 15:23:11 2024
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Mon, 24 Jun 2024 21:23:11 +0800
Subject: [R] Naming output file
In-Reply-To: <20240624160049.7b15a8f6@arachnoid>
References: <77836dc7-0680-42e6-b26f-2ba2e743b83f@ntu.edu.tw>
 <CAGgJW75ycGXsBwkZdmS_01RLRtHH3RGT2d8uo2rCzRRcOSXMCA@mail.gmail.com>
 <53a022f3-fbc9-429f-88bb-afc2369d2fbe@ntu.edu.tw>
 <CAGgJW747+jGWrcw_qd__Ttc+O8Vxfp-MbmmskfH3pPXY-rv-og@mail.gmail.com>
 <e338fffd-1648-4630-8b90-11d7780015db@ntu.edu.tw>
 <20240624160049.7b15a8f6@arachnoid>
Message-ID: <d92ba755-3ab1-4f61-a334-5827789ce4c0@ntu.edu.tw>

Thanks to all. Editing the line to the following worked:

ame<-ame.bopa(get(paste0("bop",im)),y1.level=y1value,y2.level=y2value,jindex=jindex1,vb.method="invH",joint12=TRUE,
 ??????????????? printing=FALSE,testing=TRUE)

On 6/24/2024 9:00 PM, Ivan Krylov wrote:
> ? Mon, 24 Jun 2024 20:16:46 +0800
> Steven Yen <styen at ntu.edu.tw> ?????:
>
>> In the call to ame.bopa in a loop, I like inputs in the call to
>> ame.bopa to be bop1, bop2, bop3,... Thanks.
>>
>> for (im in 1:m) {
>> ame<-ame.bopa(bop,y1.level=y1value,y2.level=y2value,jindex=jindex1,vb.method="invH",joint12=TRUE,
>>   ??????????????? printing=FALSE,testing=TRUE)
>> }
> Use get(paste0('bop', im)) to read a variable named paste0('bop', im).
>
> If you used a list like suggested by Rui, you would be able to use the
> same syntax for read and write access, namely, bop[[im]], instead of
> manually assigning variables using assign(name, value) and manually
> reading variables using get(name).
>


From m|ev|n@ @end|ng |rom purdue@edu  Sun Jun 23 23:31:14 2024
From: m|ev|n@ @end|ng |rom purdue@edu (Levine, Michael)
Date: Sun, 23 Jun 2024 21:31:14 +0000
Subject: [R] Integration of functions with a vector argument
In-Reply-To: <20240620183739.19266eb1@arachnoid>
References: <PH0PR22MB2860E3ABD206953D15F31EFAC5C72@PH0PR22MB2860.namprd22.prod.outlook.com>
 <20240612134119.72e4cab6@Tarkus>
 <PH0PR22MB28605CCF2898AD2EC336DCCBC5C02@PH0PR22MB2860.namprd22.prod.outlook.com>
 <20240613132121.1847edee@arachnoid>
 <PH0PR22MB28606A4C8C09D6738A403F19C5CE2@PH0PR22MB2860.namprd22.prod.outlook.com>
 <20240620183739.19266eb1@arachnoid>
Message-ID: <PH0PR22MB28608040797037621AFFBD4CC5CB2@PH0PR22MB2860.namprd22.prod.outlook.com>

Dear Ivan,

Thank you very much again for your suggestions! I will try to use Cubature, then.

yours sincerely,
Michael

Michael Levine
Associate Professor, Statistics

Department of Statistics
Purdue University
250 North University Street
West Lafayette, IN 47907 USA

email: mlevins at purdue.edu
Phone: +1-765-496-7571
Fax:   +1-765-494-0558
URL:   www.stat.purdue.edu/~mlevins

________________________________
From: Ivan Krylov <ikrylov at disroot.org>
Sent: Thursday, June 20, 2024 11:37 AM
To: Levine, Michael <mlevins at purdue.edu>
Cc: r-help at r-project.org <r-help at r-project.org>
Subject: Re: [R] Integration of functions with a vector argument

---- External Email: Use caution with attachments, links, or sharing data ----


? Tue, 18 Jun 2024 23:12:03 +0000
"Levine, Michael" <mlevins at purdue.edu> ?????:

> I have heard of several packages used for numerical integration in R -
> cubature that you mentioned, mvQuad, and pracma.  My impression is
> that you think that Cubature is the best in your opinion. Is that so?

Yes, but the preference is not very strong. My own numerical
integration experience is limited to using QUADPACK in a project where
everything had to be rewritten in Fortran for speed.

I trust the code of the 'cubature' library by Steven G. Johnson (whose
work includes FFTW and NLopt) and the 'Cuba' library by Thomas Hahn.
The 'cubature' R package wraps these two libraries. Unfortunately, as
you see, its documentation can be lacking.

Like 'cubature', the 'mvQuad' package won't require a significant
rewrite of the integrand because it expects its functions to take
matrices of arguments. Unfortunately, the two packages differ in the
meanings they assign to the matrices: in 'cubature', individual
arguments of the function correspond to the rows of the first argument,
while in 'mvQuad', they must be in the columns.

The 'mvQuad' package requires manual adjustments to the generated
quadratures using rescale(...), which may be not very convenient.

The 'pracma' package contains implementations of a lot of excellent
methods (I've trusted it before for its other functions), but the (two-
or three-argument) integrand will have to be rewritten to accept
separate arrays (of arbitrary shape?) instead of a single matrix.

> If yes, do you know of any detailed discussion of this package beyond
> the two vignettes available on CRAN?

I don't know how much it can help, but more information about the
underlying code for 'cubature' can be found at
<https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fstevengj%2Fcubature&data=05%7C02%7Cmlevins%40purdue.edu%7Cebdca9b21fa14410c84308dc913eed65%7C4130bd397c53419cb1e58758d6d63f21%7C0%7C0%7C638544946662774955%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&sdata=jflgsS7UUtmkgKyWyYuKxHtJNBpWA0eSbPQRWxEHOTk%3D&reserved=0<https://github.com/stevengj/cubature>> and <https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Ffeynarts.de%2Fcuba%2F&data=05%7C02%7Cmlevins%40purdue.edu%7Cebdca9b21fa14410c84308dc913eed65%7C4130bd397c53419cb1e58758d6d63f21%7C0%7C0%7C638544946662793433%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&sdata=kRblrnUyftzdC7SKqJrVQ9rLjpSX3ySWJK%2FCzhWYAvE%3D&reserved=0<https://feynarts.de/cuba/>>.

--
Best regards,
Ivan

	[[alternative HTML version deleted]]


From m|ev|n@ @end|ng |rom purdue@edu  Sun Jun 23 23:31:41 2024
From: m|ev|n@ @end|ng |rom purdue@edu (Levine, Michael)
Date: Sun, 23 Jun 2024 21:31:41 +0000
Subject: [R] Integration of functions with a vector argument
In-Reply-To: <CAGxFJbRpGXQtnZAW9rTFrw71keagHXSrMZbSco97ySPVUZOOfg@mail.gmail.com>
References: <PH0PR22MB2860E3ABD206953D15F31EFAC5C72@PH0PR22MB2860.namprd22.prod.outlook.com>
 <20240612134119.72e4cab6@Tarkus>
 <PH0PR22MB28605CCF2898AD2EC336DCCBC5C02@PH0PR22MB2860.namprd22.prod.outlook.com>
 <20240613132121.1847edee@arachnoid>
 <PH0PR22MB28606A4C8C09D6738A403F19C5CE2@PH0PR22MB2860.namprd22.prod.outlook.com>
 <20240620183739.19266eb1@arachnoid>
 <CAGxFJbQ4TVjaV+AJc7fx+i=h7BsNSwH9oyfMa95AR=t7DzJFzg@mail.gmail.com>
 <CAGxFJbRpGXQtnZAW9rTFrw71keagHXSrMZbSco97ySPVUZOOfg@mail.gmail.com>
Message-ID: <PH0PR22MB2860493DB1F6D90A823FFC7AC5CB2@PH0PR22MB2860.namprd22.prod.outlook.com>

Dear Bert,

Thank you very much for your suggestions!

Yours sincerely,
Michael

Michael Levine
Associate Professor, Statistics

Department of Statistics
Purdue University
250 North University Street
West Lafayette, IN 47907 USA

email: mlevins at purdue.edu
Phone: +1-765-496-7571
Fax:   +1-765-494-0558
URL:   www.stat.purdue.edu/~mlevins
________________________________
From: Bert Gunter <bgunter.4567 at gmail.com>
Sent: Thursday, June 20, 2024 1:09 PM
To: Ivan Krylov <ikrylov at disroot.org>
Cc: Levine, Michael <mlevins at purdue.edu>; r-help at r-project.org <r-help at r-project.org>
Subject: Re: [R] Integration of functions with a vector argument

You don't often get email from bgunter.4567 at gmail.com. Learn why this is important<https://aka.ms/LearnAboutSenderIdentification>
---- External Email: Use caution with attachments, links, or sharing data ----

The calculus package might also be relevant (not sure if it was in the Task View):

https://cran.r-project.org/web/packages/calculus/index.html

-- Bert

On Thu, Jun 20, 2024 at 10:01?AM Bert Gunter <bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>> wrote:
If you haven't already done so, you may wish to have a look here:

https://cran.r-project.org/web/views/NumericalMathematics.html#differentiation-and-integration

(Or perhaps in other related subtopics in the Numerical Math task view)

Cheers,
Bert

On Thu, Jun 20, 2024 at 8:37?AM Ivan Krylov via R-help <r-help at r-project.org<mailto:r-help at r-project.org>> wrote:
? Tue, 18 Jun 2024 23:12:03 +0000
"Levine, Michael" <mlevins at purdue.edu<mailto:mlevins at purdue.edu>> ?????:

> I have heard of several packages used for numerical integration in R -
> cubature that you mentioned, mvQuad, and pracma.  My impression is
> that you think that Cubature is the best in your opinion. Is that so?

Yes, but the preference is not very strong. My own numerical
integration experience is limited to using QUADPACK in a project where
everything had to be rewritten in Fortran for speed.

I trust the code of the 'cubature' library by Steven G. Johnson (whose
work includes FFTW and NLopt) and the 'Cuba' library by Thomas Hahn.
The 'cubature' R package wraps these two libraries. Unfortunately, as
you see, its documentation can be lacking.

Like 'cubature', the 'mvQuad' package won't require a significant
rewrite of the integrand because it expects its functions to take
matrices of arguments. Unfortunately, the two packages differ in the
meanings they assign to the matrices: in 'cubature', individual
arguments of the function correspond to the rows of the first argument,
while in 'mvQuad', they must be in the columns.

The 'mvQuad' package requires manual adjustments to the generated
quadratures using rescale(...), which may be not very convenient.

The 'pracma' package contains implementations of a lot of excellent
methods (I've trusted it before for its other functions), but the (two-
or three-argument) integrand will have to be rewritten to accept
separate arrays (of arbitrary shape?) instead of a single matrix.

> If yes, do you know of any detailed discussion of this package beyond
> the two vignettes available on CRAN?

I don't know how much it can help, but more information about the
underlying code for 'cubature' can be found at
<https://github.com/stevengj/cubature> and <https://feynarts.de/cuba/>.

--
Best regards,
Ivan

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.r-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From |ern@nd_@rce @end|ng |rom y@hoo@e@  Mon Jun 24 13:50:05 2024
From: |ern@nd_@rce @end|ng |rom y@hoo@e@ (Fer Arce)
Date: Mon, 24 Jun 2024 06:50:05 -0500
Subject: [R] Naming output file
In-Reply-To: <77836dc7-0680-42e6-b26f-2ba2e743b83f@ntu.edu.tw>
References: <77836dc7-0680-42e6-b26f-2ba2e743b83f@ntu.edu.tw>
Message-ID: <44d527f6-d654-4378-a577-5d4a3b78d93f@yahoo.es>

Hi, try with:


m<-3
for (im in 1:m) {
mydata<-read.csv(paste0("2010midata",im,".csv"))
assign(paste0("bop",im),boprobit(eqs,mydata,wt=weight,method="BHHH",tol=0,reltol=0,gradtol=1e-5, 
Fisher=TRUE)
}

cheers
F.

On 6/24/24 06:41, Steven Yen wrote:
> I would like a loop to
> 
> (1) read data files 2010midata1,2010midata2,2010midata3; and
> 
> (2)? name OUTPUT bop1,bop2,bop3.
> 
> I succeeded in line 3 of the code below,
> 
> BUT not line 4. The error message says:
> 
> Error in paste0("bop", im) <- boprobit(eqs, mydata, wt = weight, method
> = "NR", : target of assignment expands to non-language object Please
> help. Thanks.
> 
> m<-3
> for (im in 1:m) {
> mydata<-read.csv(paste0("2010midata",im,".csv"))
> paste0("bop",im)<-boprobit(eqs,mydata,wt=weight,method="BHHH",tol=0,reltol=0,gradtol=1e-5,Fisher=TRUE)
> }
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@oknz @end|ng |rom gm@||@com  Tue Jun 25 03:04:42 2024
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Tue, 25 Jun 2024 13:04:42 +1200
Subject: [R] Naming output file
In-Reply-To: <77836dc7-0680-42e6-b26f-2ba2e743b83f@ntu.edu.tw>
References: <77836dc7-0680-42e6-b26f-2ba2e743b83f@ntu.edu.tw>
Message-ID: <CABcYAdJKbZcZc8jW=01R4NSeDQGetqUZ=zOZguc3HgwogcGMHg@mail.gmail.com>

The subject line says (capitalisation changed) "name output FILE"
but I see no attempt in the sample code to create an output FILE.
I was expecting to see something like
  write(<whatever>, file = paste0("bop",im))

On Mon, 24 Jun 2024 at 23:41, Steven Yen <styen at ntu.edu.tw> wrote:
>
> I would like a loop to
>
> (1) read data files 2010midata1,2010midata2,2010midata3; and
>
> (2)  name OUTPUT bop1,bop2,bop3.
>
> I succeeded in line 3 of the code below,
>
> BUT not line 4. The error message says:
>
> Error in paste0("bop", im) <- boprobit(eqs, mydata, wt = weight, method
> = "NR", : target of assignment expands to non-language object Please
> help. Thanks.
>
> m<-3
> for (im in 1:m) {
> mydata<-read.csv(paste0("2010midata",im,".csv"))
> paste0("bop",im)<-boprobit(eqs,mydata,wt=weight,method="BHHH",tol=0,reltol=0,gradtol=1e-5,Fisher=TRUE)
> }
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @vi@e@gross m@iii@g oii gm@ii@com  Tue Jun 25 04:59:29 2024
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Mon, 24 Jun 2024 22:59:29 -0400
Subject: [R] Naming output file
References: <77836dc7-0680-42e6-b26f-2ba2e743b83f@ntu.edu.tw>
 <CABcYAdJKbZcZc8jW=01R4NSeDQGetqUZ=zOZguc3HgwogcGMHg@mail.gmail.com> 
Message-ID: <009701dac6ab$b29e0a60$17da1f20$@gmail.com>

I had the same FIRST impression which could have made sense as in writing
the data back out to a file with a similar name and that would have been
trivial. I mean if you had exactly three, a loop would not even be
particularly useful versus writing two lines, copying them and editing the
latter two sets.

But the OP could have done a better job explaining what they wanted it all
FOR. Just writing out the same file contents would be nonsensical unless
some change was made such as writing in a different format. But I noted the
output names were not something like NAME.csv and although the code looked
wrong, it soon became clear they wanted to create not files but clearly a
data.frame as that is produced by read.csv. The language usage was simply
sloppy.

The names chosen made it easier as all you needed to do was replace
"2010midata" with "bop" and easy enough to do in a loop or several other
ways but what the OP missed was how to do something that is doable in an
interpreted language like R but possibly not in many compiled languages.

So, as others pointed out, sometimes the person doing this has become wedded
to ONE WAY of doing something rather than considering if some other way is a
better choice. In this case, a consensus is that a data structure such as a
list of data.frames would be a better choice and even that it could be done
without an explicit loop such as this version where you can set N to any
value, and it will get files with a suffix ranging from 1 to N, albeit this
does not allow you to find something like 007 without modification:

N <- 3
list_of_df <- lapply(paste0("2010midata", 1:N, ".csv"), read.csv)

An individual data.frame can be accessed using [[]] notation as in:

> class(list_of_df[[1]])
[1] "data.frame"

Of course if you have additional values to pass in to read.csv, add them in
the ... after the first args and so on. 

The next part, badly written as:

paste0("bop",im)<-boprobit(eqs,mydata,wt=weight,method="BHHH",tol=0,reltol=0
,gradtol=1e-5,Fisher=TRUE)

Not can use a similar construction in which the 1:N is replaced by
list_of_df and the function by boprobit and then the remaining arguments in
the ...

But that is not the way many initially think. Let alone thinking in nested
fashion as in:

Results <- lapply(X=lapply(X=paste0("2010midata", 1:N, ".csv"),
FUN=read.csv), FUN=boprobit,
,wt=weight,method="BHHH",tol=0,reltol=0,gradtol=1e-5,Fisher=TRUE))

Unfortunately, the latter is WRONG as boprobit seems to take a second
argument of the data.frame with whatever "eqs" is as the first argument.
This slightly nonstandard version would require some gimmick such as an
accessory function that rearranges what it gets as arguments and then calls
boprobit.

But, as noted, this is one of many examples where the user comes up with a
"solution" that is fairly rarely needed even if it can be done, rather than
one that is a bit more abstract and yet powerful. 

Yet, as noted, R can do things we often have no need for and this is an
example. Never mind how it can be a tad dangerous to assign to extra
variable names that might step on existing names as compared to creating
anonymous data structures with few or no names as everything is largely
positional.

I will end with a slight variant. Imagine making a named list, perhaps
extended in each part of the loop used, so that you it looks like

Mylist <- list(name1=value, name2=value, name3=value)

This could then be addressed using Mylist[[1]] or Mylist$name1
interchangeably. But as all names would be internal to the list, it is
name-safe.


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Richard O'Keefe
Sent: Monday, June 24, 2024 9:05 PM
To: Steven Yen <styen at ntu.edu.tw>
Cc: R-help Mailing List <r-help at r-project.org>; Steven Yen
<syen04 at gmail.com>
Subject: Re: [R] Naming output file

The subject line says (capitalisation changed) "name output FILE"
but I see no attempt in the sample code to create an output FILE.
I was expecting to see something like
  write(<whatever>, file = paste0("bop",im))

On Mon, 24 Jun 2024 at 23:41, Steven Yen <styen at ntu.edu.tw> wrote:
>
> I would like a loop to
>
> (1) read data files 2010midata1,2010midata2,2010midata3; and
>
> (2)  name OUTPUT bop1,bop2,bop3.
>
> I succeeded in line 3 of the code below,
>
> BUT not line 4. The error message says:
>
> Error in paste0("bop", im) <- boprobit(eqs, mydata, wt = weight, method
> = "NR", : target of assignment expands to non-language object Please
> help. Thanks.
>
> m<-3
> for (im in 1:m) {
> mydata<-read.csv(paste0("2010midata",im,".csv"))
>
paste0("bop",im)<-boprobit(eqs,mydata,wt=weight,method="BHHH",tol=0,reltol=0
,gradtol=1e-5,Fisher=TRUE)
> }
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From du@@@@dr|@n @end|ng |rom un|buc@ro  Tue Jun 25 09:56:07 2024
From: du@@@@dr|@n @end|ng |rom un|buc@ro (Adrian Dusa)
Date: Tue, 25 Jun 2024 10:56:07 +0300
Subject: [R] "--" < 0
Message-ID: <CAA1TD3oNyp+PTGu-mFJJ=HauB4iAd3z7OTLAKL3Y9MvUic0tpw@mail.gmail.com>

Dear R fellows,

>From time to time, just when I thought I knew my R, I get bitten by some
small things that reminds one to constantly return to the basics.

I knew for instance that "-1" < 0 is TRUE, presumably because R first
coerces to numeric before comparing with 0.

But I did not expect that "--" < 0 is a TRUE statement.
(and the same holds for any string prepended by a minus sign, e.g. "-a" < 0)

I would be grateful for an explanation, I'm sure that something very
obvious escapes me but it sure does seem counter intuitive to me.

Best wishes,
Adrian

	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue Jun 25 10:02:10 2024
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 25 Jun 2024 10:02:10 +0200
Subject: [R] "--" < 0
In-Reply-To: <CAA1TD3oNyp+PTGu-mFJJ=HauB4iAd3z7OTLAKL3Y9MvUic0tpw@mail.gmail.com>
References: <CAA1TD3oNyp+PTGu-mFJJ=HauB4iAd3z7OTLAKL3Y9MvUic0tpw@mail.gmail.com>
Message-ID: <26234.31106.206576.399864@stat.math.ethz.ch>

>>>>> Adrian Dusa 
>>>>>     on Tue, 25 Jun 2024 10:56:07 +0300 writes:

    > Dear R fellows,

    >> From time to time, just when I thought I knew my R, I get
    >> bitten by some
    > small things that reminds one to constantly return to the
    > basics.

    > I knew for instance that "-1" < 0 is TRUE, presumably
    > because R first coerces to numeric before comparing with
    > 0.

    > But I did not expect that "--" < 0 is a TRUE statement.
    > (and the same holds for any string prepended by a minus
    > sign, e.g. "-a" < 0)

    > I would be grateful for an explanation, I'm sure that
    > something very obvious escapes me but it sure does seem
    > counter intuitive to me.

    > Best wishes, Adrian

    > 	[[alternative HTML version deleted]]

Nice, quiz, yes.

You must have forgotten that all Op's (+,-, <= , &, | ..)
must coerce to common type.

... and so does  c()  where coercion is defined a bit more.

-->  does  c("--", 0)   give you a clue, now ?


From j@b@y@t194 @end|ng |rom gm@||@com  Mon Jun 24 13:55:20 2024
From: j@b@y@t194 @end|ng |rom gm@||@com (javad bayat)
Date: Mon, 24 Jun 2024 15:25:20 +0330
Subject: [R] Converting .grib to excel file
Message-ID: <CANTxAm+JMF-z9T6X-Ra5dF6OMRfcYfzWUX43XB=w=X3iftcR5g@mail.gmail.com>

Dear all;
I have downloaded meteorology data from "
https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=form"
as .grib format. It has hourly data of a complete year (every hour of every
day of 12 months) and has 6 meteorology parameters. The file has been
attached.
I am trying to convert it to an excel file that puts every parameter in a
separated column. For instance, the first col represents Date, 2nd
represents Temperature and so on.
Is there any way to do it?
I used these codes but did not work:
# install.packages("rNOMADS")

library(rNOMADS)

# Read GRIB data
grib_data <- ReadGrib("C:/Users/admin/Downloads/Met.grib")

# Convert to a data frame
grib_df <- as.data.frame(grib_data)

# Write the data frame to a CSV file
write.csv(grib_df, file = "output.csv")


I would be more than happy if anyone could help me.
Sincerely

-- 
Best Regards
Javad Bayat
M.Sc. Environment Engineering
Alternative Mail: bayat194 at yahoo.com

From pd@|gd @end|ng |rom gm@||@com  Tue Jun 25 10:36:20 2024
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Tue, 25 Jun 2024 10:36:20 +0200
Subject: [R] "--" < 0
In-Reply-To: <26234.31106.206576.399864@stat.math.ethz.ch>
References: <CAA1TD3oNyp+PTGu-mFJJ=HauB4iAd3z7OTLAKL3Y9MvUic0tpw@mail.gmail.com>
 <26234.31106.206576.399864@stat.math.ethz.ch>
Message-ID: <AB74C7D9-89B1-4536-B961-FEF5803DF75A@gmail.com>

Also notice that

> "+5" < 0
[1] TRUE

> as.numeric("+5") < 0
[1] FALSE

So the presumption is wrong. It is really about

> sort(c(0:3, "+", "-"))
[1] "-" "+" "0" "1" "2" "3"

-pd

> On 25 Jun 2024, at 10:02 , Martin Maechler <maechler at stat.math.ethz.ch> wrote:
> 
>>>>>> Adrian Dusa 
>>>>>>    on Tue, 25 Jun 2024 10:56:07 +0300 writes:
> 
>> Dear R fellows,
> 
>>> From time to time, just when I thought I knew my R, I get
>>> bitten by some
>> small things that reminds one to constantly return to the
>> basics.
> 
>> I knew for instance that "-1" < 0 is TRUE, presumably
>> because R first coerces to numeric before comparing with
>> 0.
> 
>> But I did not expect that "--" < 0 is a TRUE statement.
>> (and the same holds for any string prepended by a minus
>> sign, e.g. "-a" < 0)
> 
>> I would be grateful for an explanation, I'm sure that
>> something very obvious escapes me but it sure does seem
>> counter intuitive to me.
> 
>> Best wishes, Adrian
> 
>> 	[[alternative HTML version deleted]]
> 
> Nice, quiz, yes.
> 
> You must have forgotten that all Op's (+,-, <= , &, | ..)
> must coerce to common type.
> 
> ... and so does  c()  where coercion is defined a bit more.
> 
> -->  does  c("--", 0)   give you a clue, now ?
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From du@@@@dr|@n @end|ng |rom un|buc@ro  Tue Jun 25 10:58:32 2024
From: du@@@@dr|@n @end|ng |rom un|buc@ro (Adrian Dusa)
Date: Tue, 25 Jun 2024 11:58:32 +0300
Subject: [R] "--" < 0
In-Reply-To: <26234.31106.206576.399864@stat.math.ethz.ch>
References: <CAA1TD3oNyp+PTGu-mFJJ=HauB4iAd3z7OTLAKL3Y9MvUic0tpw@mail.gmail.com>
 <26234.31106.206576.399864@stat.math.ethz.ch>
Message-ID: <CAA1TD3oQK0LJTh12DueG446ZO+bggSPVBPVFEqRFjdfGXy5kdg@mail.gmail.com>

Oh I see...
It's not that "-7" gets coerced to numeric, but 0 gets coerced to "0".
Of course...

On Tue, Jun 25, 2024 at 11:02?AM Martin Maechler <maechler at stat.math.ethz.ch>
wrote:

> >>>>> Adrian Dusa
> >>>>>     on Tue, 25 Jun 2024 10:56:07 +0300 writes:
>
>     > Dear R fellows,
>
>     >> From time to time, just when I thought I knew my R, I get
>     >> bitten by some
>     > small things that reminds one to constantly return to the
>     > basics.
>
>     > I knew for instance that "-1" < 0 is TRUE, presumably
>     > because R first coerces to numeric before comparing with
>     > 0.
>
>     > But I did not expect that "--" < 0 is a TRUE statement.
>     > (and the same holds for any string prepended by a minus
>     > sign, e.g. "-a" < 0)
>
>     > I would be grateful for an explanation, I'm sure that
>     > something very obvious escapes me but it sure does seem
>     > counter intuitive to me.
>
>     > Best wishes, Adrian
>
>     >   [[alternative HTML version deleted]]
>
> Nice, quiz, yes.
>
> You must have forgotten that all Op's (+,-, <= , &, | ..)
> must coerce to common type.
>
> ... and so does  c()  where coercion is defined a bit more.
>
> -->  does  c("--", 0)   give you a clue, now ?
>

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Tue Jun 25 13:23:55 2024
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Tue, 25 Jun 2024 23:23:55 +1200
Subject: [R] Converting .grib to excel file
In-Reply-To: <CANTxAm+JMF-z9T6X-Ra5dF6OMRfcYfzWUX43XB=w=X3iftcR5g@mail.gmail.com>
References: <CANTxAm+JMF-z9T6X-Ra5dF6OMRfcYfzWUX43XB=w=X3iftcR5g@mail.gmail.com>
Message-ID: <CABcYAdLq4i3GoF2d2mVGdMDg2fd7=is_HOzF5evvKaWzGQfcfg@mail.gmail.com>

Your message referred to an attached file but there was no attachment,
I have no account at that service, so could not download a sample for
myself.  Does the licence for the data even allow you to send some of
it in a message?  Which parameters are you extracting?  When you say
"it didn't work", what actually happened?  Which step went wrong and how?


On Tue, 25 Jun 2024 at 20:33, javad bayat <j.bayat194 at gmail.com> wrote:
>
> Dear all;
> I have downloaded meteorology data from "
> https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=form"
> as .grib format. It has hourly data of a complete year (every hour of every
> day of 12 months) and has 6 meteorology parameters. The file has been
> attached.
> I am trying to convert it to an excel file that puts every parameter in a
> separated column. For instance, the first col represents Date, 2nd
> represents Temperature and so on.
> Is there any way to do it?
> I used these codes but did not work:
> # install.packages("rNOMADS")
>
> library(rNOMADS)
>
> # Read GRIB data
> grib_data <- ReadGrib("C:/Users/admin/Downloads/Met.grib")
>
> # Convert to a data frame
> grib_df <- as.data.frame(grib_data)
>
> # Write the data frame to a CSV file
> write.csv(grib_df, file = "output.csv")
>
>
> I would be more than happy if anyone could help me.
> Sincerely
>
> --
> Best Regards
> Javad Bayat
> M.Sc. Environment Engineering
> Alternative Mail: bayat194 at yahoo.com
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Tue Jun 25 16:17:34 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 25 Jun 2024 07:17:34 -0700
Subject: [R] Converting .grib to excel file
In-Reply-To: <CANTxAm+JMF-z9T6X-Ra5dF6OMRfcYfzWUX43XB=w=X3iftcR5g@mail.gmail.com>
References: <CANTxAm+JMF-z9T6X-Ra5dF6OMRfcYfzWUX43XB=w=X3iftcR5g@mail.gmail.com>
Message-ID: <CAGxFJbR5azhJbQ4Q2v-pSAF4WvMmH2ny=S2Wkcu-uRd3n3C7tg@mail.gmail.com>

Do a web search on "convert grib data to csv".  You will get many hits. You
probably don't need R to do this.

-- Bert

On Tue, Jun 25, 2024 at 1:33?AM javad bayat <j.bayat194 at gmail.com> wrote:

> Dear all;
> I have downloaded meteorology data from "
>
> https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=form
> "
> as .grib format. It has hourly data of a complete year (every hour of every
> day of 12 months) and has 6 meteorology parameters. The file has been
> attached.
> I am trying to convert it to an excel file that puts every parameter in a
> separated column. For instance, the first col represents Date, 2nd
> represents Temperature and so on.
> Is there any way to do it?
> I used these codes but did not work:
> # install.packages("rNOMADS")
>
> library(rNOMADS)
>
> # Read GRIB data
> grib_data <- ReadGrib("C:/Users/admin/Downloads/Met.grib")
>
> # Convert to a data frame
> grib_df <- as.data.frame(grib_data)
>
> # Write the data frame to a CSV file
> write.csv(grib_df, file = "output.csv")
>
>
> I would be more than happy if anyone could help me.
> Sincerely
>
> --
> Best Regards
> Javad Bayat
> M.Sc. Environment Engineering
> Alternative Mail: bayat194 at yahoo.com
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @vi@e@gross m@iii@g oii gm@ii@com  Tue Jun 25 16:42:42 2024
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Tue, 25 Jun 2024 10:42:42 -0400
Subject: [R] "--" < 0
In-Reply-To: <CAA1TD3oQK0LJTh12DueG446ZO+bggSPVBPVFEqRFjdfGXy5kdg@mail.gmail.com>
References: <CAA1TD3oNyp+PTGu-mFJJ=HauB4iAd3z7OTLAKL3Y9MvUic0tpw@mail.gmail.com>
 <26234.31106.206576.399864@stat.math.ethz.ch>
 <CAA1TD3oQK0LJTh12DueG446ZO+bggSPVBPVFEqRFjdfGXy5kdg@mail.gmail.com>
Message-ID: <004301dac70d$ef6e81b0$ce4b8510$@gmail.com>

Unfortunately, Adrian, even trying to coerce a string like "--" to numeric just produces an NA and comparison fails:

> as.numeric("--") < 0 
[1] NA
Warning message:
NAs introduced by coercion

The same is true of anything that is character as it cannot be coerced.

> as.numeric("anything") < 0 
[1] NA
Warning message:
NAs introduced by coercion

So, the only rational thing R can do is convert the zero to a character string and that has the usual problem as in:

> as.character(20) < as.character(9)
[1] TRUE

Can you suggest if there is any valid result in some cases like these? I mean, if we wrote a function like greater(first, second) and set it up so it analyzed the types of the arguments and tried various combinations of converting things to one of several possible types such as integer/numeric/character/logical/raw and examined the results of each while catching errors, what would be a right answer it could get?

My guess is that it may not be possible in some cases to give an answer other than that the two being compared are incompatible. The result of greater() could be neither TRUE, nor FALSE but something like one of the NA family or maybe a NaN or maybe the function would simply throw an error and fail.

I can picture many other scenarios such as asking it to compare two objects, perhaps the same type or different types, such as a list versus a matrix. Realistically, the ">" operator and other such operators are not designed to do deep analyses and be able to compare complex-objects component by component and recursively. 

So the result you show, is in some sense nonsense. It is so wrong that it is not even wrong. My intuition is that it is similar to this:

> NA + 5
[1] NA

Any computation containing a crucial NA, typically ends up with an NA result because once you introduce uncertainty, it propagates. So the result of comparing things that cannot be compared may well also be polluted and should come back as an NA, probably the default logical form, not something like NA_integer_ 

Since comparisons between random objects are something that can happen, I suspect there are functions already part of the R distribution or in some packages that behave better and can safely be used to ask if things can even be compared. But there may yet remain edge cases because of things like character strings that can be evaluated as numeric but may not be evaluated correctly if they are written in some way as in hexadecimal notation or scientific notation.


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Adrian Dusa
Sent: Tuesday, June 25, 2024 4:59 AM
To: Martin Maechler <maechler at stat.math.ethz.ch>
Cc: r-help at r-project.org
Subject: Re: [R] "--" < 0

Oh I see...
It's not that "-7" gets coerced to numeric, but 0 gets coerced to "0".
Of course...

On Tue, Jun 25, 2024 at 11:02?AM Martin Maechler <maechler at stat.math.ethz.ch>
wrote:

> >>>>> Adrian Dusa
> >>>>>     on Tue, 25 Jun 2024 10:56:07 +0300 writes:
>
>     > Dear R fellows,
>
>     >> From time to time, just when I thought I knew my R, I get
>     >> bitten by some
>     > small things that reminds one to constantly return to the
>     > basics.
>
>     > I knew for instance that "-1" < 0 is TRUE, presumably
>     > because R first coerces to numeric before comparing with
>     > 0.
>
>     > But I did not expect that "--" < 0 is a TRUE statement.
>     > (and the same holds for any string prepended by a minus
>     > sign, e.g. "-a" < 0)
>
>     > I would be grateful for an explanation, I'm sure that
>     > something very obvious escapes me but it sure does seem
>     > counter intuitive to me.
>
>     > Best wishes, Adrian
>
>     >   [[alternative HTML version deleted]]
>
> Nice, quiz, yes.
>
> You must have forgotten that all Op's (+,-, <= , &, | ..)
> must coerce to common type.
>
> ... and so does  c()  where coercion is defined a bit more.
>
> -->  does  c("--", 0)   give you a clue, now ?
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From @@r@h@go@|ee @end|ng |rom gm@||@com  Tue Jun 25 18:17:14 2024
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Tue, 25 Jun 2024 12:17:14 -0400
Subject: [R] Converting .grib to excel file
In-Reply-To: <CANTxAm+JMF-z9T6X-Ra5dF6OMRfcYfzWUX43XB=w=X3iftcR5g@mail.gmail.com>
References: <CANTxAm+JMF-z9T6X-Ra5dF6OMRfcYfzWUX43XB=w=X3iftcR5g@mail.gmail.com>
Message-ID: <CAM_vjukFAAmYQ-0ctC=4Qm9DzPknzPqjEV_dN+d9rbT74kypSA@mail.gmail.com>

Hi,

While Bert is correct that there are plenty of tools, my preferred approach
is to use the terra package to load a grib as a raster stack.

From there, it's straightforward to use all the spatial tools with the
data, or to extract it in whatever form and with whatever dimensions you
wish.

GIven the multidimensional nature of the data, "straightforward" may
require some fiddling to get the format and variables you want in the way
you want them.

Sarah

On Tue, Jun 25, 2024 at 4:33?AM javad bayat <j.bayat194 at gmail.com> wrote:

> Dear all;
> I have downloaded meteorology data from "
>
> https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=form
> "
> as .grib format. It has hourly data of a complete year (every hour of every
> day of 12 months) and has 6 meteorology parameters. The file has been
> attached.
> I am trying to convert it to an excel file that puts every parameter in a
> separated column. For instance, the first col represents Date, 2nd
> represents Temperature and so on.
> Is there any way to do it?
> I used these codes but did not work:
> # install.packages("rNOMADS")
>
> library(rNOMADS)
>
> # Read GRIB data
> grib_data <- ReadGrib("C:/Users/admin/Downloads/Met.grib")
>
> # Convert to a data frame
> grib_df <- as.data.frame(grib_data)
>
> # Write the data frame to a CSV file
> write.csv(grib_df, file = "output.csv")
>
>
> I would be more than happy if anyone could help me.
> Sincerely
>
> --
> Best Regards
> Javad Bayat
> M.Sc. Environment Engineering
> Alternative Mail: bayat194 at yahoo.com
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Sarah Goslee (she/her)
http://www.sarahgoslee.com

	[[alternative HTML version deleted]]


From j@b@y@t194 @end|ng |rom gm@||@com  Tue Jun 25 12:45:15 2024
From: j@b@y@t194 @end|ng |rom gm@||@com (javad bayat)
Date: Tue, 25 Jun 2024 14:15:15 +0330
Subject: [R] Converting .grib to excel file
In-Reply-To: <CABcYAdLq4i3GoF2d2mVGdMDg2fd7=is_HOzF5evvKaWzGQfcfg@mail.gmail.com>
References: <CANTxAm+JMF-z9T6X-Ra5dF6OMRfcYfzWUX43XB=w=X3iftcR5g@mail.gmail.com>
 <CABcYAdLq4i3GoF2d2mVGdMDg2fd7=is_HOzF5evvKaWzGQfcfg@mail.gmail.com>
Message-ID: <CANTxAmK1DrHTNaUD74+uNN2YNMUQj8xeFC2Pk8v+Lq9P5W=YTA@mail.gmail.com>

Richard,
Many thanks for your email.
I had attached the grib file to the original email to R help team but it
seems you did not receive it.
Unfortunately, I do not know how to reduce the volume or extract some of
the grib file data to send it for you. The file has the volume of 6
Megabyte.
I can send it by email.
The file has 6 met parameters and Date (day/month/year hour:minute).
I want the exported file as excel contains 7 columns (Date + 6 met
parameters).


On Tue, 25 Jun 2024, 15:54 Richard O'Keefe, <raoknz at gmail.com> wrote:

> Your message referred to an attached file but there was no attachment,
> I have no account at that service, so could not download a sample for
> myself.  Does the licence for the data even allow you to send some of
> it in a message?  Which parameters are you extracting?  When you say
> "it didn't work", what actually happened?  Which step went wrong and how?
>
>
> On Tue, 25 Jun 2024 at 20:33, javad bayat <j.bayat194 at gmail.com> wrote:
> >
> > Dear all;
> > I have downloaded meteorology data from "
> >
> https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=form
> "
> > as .grib format. It has hourly data of a complete year (every hour of
> every
> > day of 12 months) and has 6 meteorology parameters. The file has been
> > attached.
> > I am trying to convert it to an excel file that puts every parameter in a
> > separated column. For instance, the first col represents Date, 2nd
> > represents Temperature and so on.
> > Is there any way to do it?
> > I used these codes but did not work:
> > # install.packages("rNOMADS")
> >
> > library(rNOMADS)
> >
> > # Read GRIB data
> > grib_data <- ReadGrib("C:/Users/admin/Downloads/Met.grib")
> >
> > # Convert to a data frame
> > grib_df <- as.data.frame(grib_data)
> >
> > # Write the data frame to a CSV file
> > write.csv(grib_df, file = "output.csv")
> >
> >
> > I would be more than happy if anyone could help me.
> > Sincerely
> >
> > --
> > Best Regards
> > Javad Bayat
> > M.Sc. Environment Engineering
> > Alternative Mail: bayat194 at yahoo.com
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From j@b@y@t194 @end|ng |rom gm@||@com  Tue Jun 25 19:08:15 2024
From: j@b@y@t194 @end|ng |rom gm@||@com (javad bayat)
Date: Tue, 25 Jun 2024 20:38:15 +0330
Subject: [R] Converting .grib to excel file
In-Reply-To: <CANTxAmK1DrHTNaUD74+uNN2YNMUQj8xeFC2Pk8v+Lq9P5W=YTA@mail.gmail.com>
References: <CANTxAm+JMF-z9T6X-Ra5dF6OMRfcYfzWUX43XB=w=X3iftcR5g@mail.gmail.com>
 <CABcYAdLq4i3GoF2d2mVGdMDg2fd7=is_HOzF5evvKaWzGQfcfg@mail.gmail.com>
 <CANTxAmK1DrHTNaUD74+uNN2YNMUQj8xeFC2Pk8v+Lq9P5W=YTA@mail.gmail.com>
Message-ID: <CANTxAmJ1_o61Oasp9mfoDZ2LGXmyKWfr_0iACwrYhz+f7P+4Gw@mail.gmail.com>

Dear Bert and Sara;
I have searched on the internet and found some way to do this like python.
But python is so complicated to me as it needs many steps to be done for
reading and converting it.
I will try terra package to convert it.


On Tue, 25 Jun 2024, 15:15 javad bayat, <j.bayat194 at gmail.com> wrote:

> Richard,
> Many thanks for your email.
> I had attached the grib file to the original email to R help team but it
> seems you did not receive it.
> Unfortunately, I do not know how to reduce the volume or extract some of
> the grib file data to send it for you. The file has the volume of 6
> Megabyte.
> I can send it by email.
> The file has 6 met parameters and Date (day/month/year hour:minute).
> I want the exported file as excel contains 7 columns (Date + 6 met
> parameters).
>
>
> On Tue, 25 Jun 2024, 15:54 Richard O'Keefe, <raoknz at gmail.com> wrote:
>
>> Your message referred to an attached file but there was no attachment,
>> I have no account at that service, so could not download a sample for
>> myself.  Does the licence for the data even allow you to send some of
>> it in a message?  Which parameters are you extracting?  When you say
>> "it didn't work", what actually happened?  Which step went wrong and how?
>>
>>
>> On Tue, 25 Jun 2024 at 20:33, javad bayat <j.bayat194 at gmail.com> wrote:
>> >
>> > Dear all;
>> > I have downloaded meteorology data from "
>> >
>> https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=form
>> "
>> > as .grib format. It has hourly data of a complete year (every hour of
>> every
>> > day of 12 months) and has 6 meteorology parameters. The file has been
>> > attached.
>> > I am trying to convert it to an excel file that puts every parameter in
>> a
>> > separated column. For instance, the first col represents Date, 2nd
>> > represents Temperature and so on.
>> > Is there any way to do it?
>> > I used these codes but did not work:
>> > # install.packages("rNOMADS")
>> >
>> > library(rNOMADS)
>> >
>> > # Read GRIB data
>> > grib_data <- ReadGrib("C:/Users/admin/Downloads/Met.grib")
>> >
>> > # Convert to a data frame
>> > grib_df <- as.data.frame(grib_data)
>> >
>> > # Write the data frame to a CSV file
>> > write.csv(grib_df, file = "output.csv")
>> >
>> >
>> > I would be more than happy if anyone could help me.
>> > Sincerely
>> >
>> > --
>> > Best Regards
>> > Javad Bayat
>> > M.Sc. Environment Engineering
>> > Alternative Mail: bayat194 at yahoo.com
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From j@b@y@t194 @end|ng |rom gm@||@com  Wed Jun 26 09:36:20 2024
From: j@b@y@t194 @end|ng |rom gm@||@com (javad bayat)
Date: Wed, 26 Jun 2024 11:06:20 +0330
Subject: [R] Converting .grib to excel file
In-Reply-To: <CANTxAmJ1_o61Oasp9mfoDZ2LGXmyKWfr_0iACwrYhz+f7P+4Gw@mail.gmail.com>
References: <CANTxAm+JMF-z9T6X-Ra5dF6OMRfcYfzWUX43XB=w=X3iftcR5g@mail.gmail.com>
 <CABcYAdLq4i3GoF2d2mVGdMDg2fd7=is_HOzF5evvKaWzGQfcfg@mail.gmail.com>
 <CANTxAmK1DrHTNaUD74+uNN2YNMUQj8xeFC2Pk8v+Lq9P5W=YTA@mail.gmail.com>
 <CANTxAmJ1_o61Oasp9mfoDZ2LGXmyKWfr_0iACwrYhz+f7P+4Gw@mail.gmail.com>
Message-ID: <CANTxAmLinC-+Rtbo4y_ogJd_o6Nt26NdNjv+RDy1rd=_9JaVvQ@mail.gmail.com>

Dear all;
I used the terra package to export .grib data as an excel file but I could
not do it.
The grib file is readed and converted to raster correctly. It contains
hourly data of a complete year for 6 met parameters (365 * 24 * 6 =
52,560). In the "raster_data" it can be seen as "nlyr" ( dimensions  : 1,
1, 52560  (nrow, ncol, nlyr) ).
It also contains the Date values which start from 01/01/2019 00:00 to
31/12/2019 23:00.
What I am trying to do is:
Export the data as an Excel file, ensuring that the met parameters are
placed in separate columns and sorted from the first hour on the first day
to the end of the date (31/12/2019 23:00).
Here are the codes:

> library(terra)
> grib_file <- "C:/Users/admin/Downloads/Met.grib"
> raster_data <- rast(grib_file)
> raster_data
class       : SpatRaster
dimensions  : 1, 1, 52560  (nrow, ncol, nlyr)
resolution  : 0.25, 0.25  (x, y)
extent      : 49.725, 49.975, 33.965, 34.215  (xmin, xmax, ymin, ymax)
coord. ref. : lon/lat Coordinate System imported from GRIB file
source      : Met.grib
names       : SFC (~[m/s], SFC (~[m/s], SFC (~e [C], SFC (~ [Pa], SFC (~)
[-], SFC (~n [m], ...
unit        :         m/s,         m/s,           C,          Pa,
-,           m, ...
time        : 2019-01-01 to 2019-12-31 23:00:00 UTC

> raster_data[[1]]
class       : SpatRaster
dimensions  : 1, 1, 1  (nrow, ncol, nlyr)
resolution  : 0.25, 0.25  (x, y)
extent      : 49.725, 49.975, 33.965, 34.215  (xmin, xmax, ymin, ymax)
coord. ref. : lon/lat Coordinate System imported from GRIB file
source      : Met.grib
name        : SFC (Ground or water surface); 10 metre u wind component
[m/s]
unit        :
 m/s
time        : 2019-01-01 UTC

> raster_data[[52560]]
class       : SpatRaster
dimensions  : 1, 1, 1  (nrow, ncol, nlyr)
resolution  : 0.25, 0.25  (x, y)
extent      : 49.725, 49.975, 33.965, 34.215  (xmin, xmax, ymin, ymax)
coord. ref. : lon/lat Coordinate System imported from GRIB file
source      : Met.grib
name        : SFC (Ground or water surface); Total precipitation [m]
unit        :                                                      m
time        : 2019-12-31 23:00:00 UTC


# Extracting data for each parameter
> param_names <- c("param1", "param2", "param3", "param4", "param5",
"param6")
> extracted_data <- extract(raster_data, param_names, df = TRUE)
 #Error in (function (classes, fdef, mtable)  :
 #unable to find an inherited method for function ?extract? for signature
?"SpatRaster", "character"?

> param_values <- lapply(raster_data, param_names)
#Error: std::bad_alloc

How can I do this?
I have no idea how to extract some of the .grib file to attach it.
Sincerely



On Tue, Jun 25, 2024 at 8:38?PM javad bayat <j.bayat194 at gmail.com> wrote:

> Dear Bert and Sara;
> I have searched on the internet and found some way to do this like python.
> But python is so complicated to me as it needs many steps to be done for
> reading and converting it.
> I will try terra package to convert it.
>
>
> On Tue, 25 Jun 2024, 15:15 javad bayat, <j.bayat194 at gmail.com> wrote:
>
>> Richard,
>> Many thanks for your email.
>> I had attached the grib file to the original email to R help team but it
>> seems you did not receive it.
>> Unfortunately, I do not know how to reduce the volume or extract some of
>> the grib file data to send it for you. The file has the volume of 6
>> Megabyte.
>> I can send it by email.
>> The file has 6 met parameters and Date (day/month/year hour:minute).
>> I want the exported file as excel contains 7 columns (Date + 6 met
>> parameters).
>>
>>
>> On Tue, 25 Jun 2024, 15:54 Richard O'Keefe, <raoknz at gmail.com> wrote:
>>
>>> Your message referred to an attached file but there was no attachment,
>>> I have no account at that service, so could not download a sample for
>>> myself.  Does the licence for the data even allow you to send some of
>>> it in a message?  Which parameters are you extracting?  When you say
>>> "it didn't work", what actually happened?  Which step went wrong and how?
>>>
>>>
>>> On Tue, 25 Jun 2024 at 20:33, javad bayat <j.bayat194 at gmail.com> wrote:
>>> >
>>> > Dear all;
>>> > I have downloaded meteorology data from "
>>> >
>>> https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=form
>>> "
>>> > as .grib format. It has hourly data of a complete year (every hour of
>>> every
>>> > day of 12 months) and has 6 meteorology parameters. The file has been
>>> > attached.
>>> > I am trying to convert it to an excel file that puts every parameter
>>> in a
>>> > separated column. For instance, the first col represents Date, 2nd
>>> > represents Temperature and so on.
>>> > Is there any way to do it?
>>> > I used these codes but did not work:
>>> > # install.packages("rNOMADS")
>>> >
>>> > library(rNOMADS)
>>> >
>>> > # Read GRIB data
>>> > grib_data <- ReadGrib("C:/Users/admin/Downloads/Met.grib")
>>> >
>>> > # Convert to a data frame
>>> > grib_df <- as.data.frame(grib_data)
>>> >
>>> > # Write the data frame to a CSV file
>>> > write.csv(grib_df, file = "output.csv")
>>> >
>>> >
>>> > I would be more than happy if anyone could help me.
>>> > Sincerely
>>> >
>>> > --
>>> > Best Regards
>>> > Javad Bayat
>>> > M.Sc. Environment Engineering
>>> > Alternative Mail: bayat194 at yahoo.com
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>

-- 
Best Regards
Javad Bayat
M.Sc. Environment Engineering
Alternative Mail: bayat194 at yahoo.com

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Wed Jun 26 10:05:47 2024
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Wed, 26 Jun 2024 20:05:47 +1200
Subject: [R] Converting .grib to excel file
In-Reply-To: <CANTxAmK1DrHTNaUD74+uNN2YNMUQj8xeFC2Pk8v+Lq9P5W=YTA@mail.gmail.com>
References: <CANTxAm+JMF-z9T6X-Ra5dF6OMRfcYfzWUX43XB=w=X3iftcR5g@mail.gmail.com>
 <CABcYAdLq4i3GoF2d2mVGdMDg2fd7=is_HOzF5evvKaWzGQfcfg@mail.gmail.com>
 <CANTxAmK1DrHTNaUD74+uNN2YNMUQj8xeFC2Pk8v+Lq9P5W=YTA@mail.gmail.com>
Message-ID: <CABcYAdKethqbtJMmvF=eoJS+YHCrpskZegTi1Y00=m11qoiYqA@mail.gmail.com>

I'm now inclined to go with 'search for "convert GRIB to CSV".
https://confluence.ecmwf.int/display/CKB/How+to+convert+GRIB+to+CSV
is the first line.  I know that's not an R solution, but using software
specifically developed for encoding, decoding, extracting, &c GRIB file by the
European Centre for Medium-Range Weather Forecasts and actively
maintained, with an example page showing how to do it, sounds like a
good approach.

One of the major things about R is that from the very beginnings of S
it was intended to be used with other tools.  We have R communicating
with Python and Tcl and dear knows what.  Getting a specialised tool
to do its thing is very much part of the R "way".
Or there's gribr https://rdrr.io/github/nawendt/gribr/man/gribr.html
which wraps ecCodes in R.

I still don't understand what "doesn't work" means.  Which step goes
wrong and how does it misbehave?


On Wed, 26 Jun 2024 at 06:02, javad bayat <j.bayat194 at gmail.com> wrote:
>
> Richard,
> Many thanks for your email.
> I had attached the grib file to the original email to R help team but it seems you did not receive it.
> Unfortunately, I do not know how to reduce the volume or extract some of the grib file data to send it for you. The file has the volume of 6 Megabyte.
> I can send it by email.
> The file has 6 met parameters and Date (day/month/year hour:minute).
> I want the exported file as excel contains 7 columns (Date + 6 met parameters).
>
>
> On Tue, 25 Jun 2024, 15:54 Richard O'Keefe, <raoknz at gmail.com> wrote:
>>
>> Your message referred to an attached file but there was no attachment,
>> I have no account at that service, so could not download a sample for
>> myself.  Does the licence for the data even allow you to send some of
>> it in a message?  Which parameters are you extracting?  When you say
>> "it didn't work", what actually happened?  Which step went wrong and how?
>>
>>
>> On Tue, 25 Jun 2024 at 20:33, javad bayat <j.bayat194 at gmail.com> wrote:
>> >
>> > Dear all;
>> > I have downloaded meteorology data from "
>> > https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=form"
>> > as .grib format. It has hourly data of a complete year (every hour of every
>> > day of 12 months) and has 6 meteorology parameters. The file has been
>> > attached.
>> > I am trying to convert it to an excel file that puts every parameter in a
>> > separated column. For instance, the first col represents Date, 2nd
>> > represents Temperature and so on.
>> > Is there any way to do it?
>> > I used these codes but did not work:
>> > # install.packages("rNOMADS")
>> >
>> > library(rNOMADS)
>> >
>> > # Read GRIB data
>> > grib_data <- ReadGrib("C:/Users/admin/Downloads/Met.grib")
>> >
>> > # Convert to a data frame
>> > grib_df <- as.data.frame(grib_data)
>> >
>> > # Write the data frame to a CSV file
>> > write.csv(grib_df, file = "output.csv")
>> >
>> >
>> > I would be more than happy if anyone could help me.
>> > Sincerely
>> >
>> > --
>> > Best Regards
>> > Javad Bayat
>> > M.Sc. Environment Engineering
>> > Alternative Mail: bayat194 at yahoo.com
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.


From r@oknz @end|ng |rom gm@||@com  Wed Jun 26 10:13:51 2024
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Wed, 26 Jun 2024 20:13:51 +1200
Subject: [R] Converting .grib to excel file
In-Reply-To: <CABcYAdKethqbtJMmvF=eoJS+YHCrpskZegTi1Y00=m11qoiYqA@mail.gmail.com>
References: <CANTxAm+JMF-z9T6X-Ra5dF6OMRfcYfzWUX43XB=w=X3iftcR5g@mail.gmail.com>
 <CABcYAdLq4i3GoF2d2mVGdMDg2fd7=is_HOzF5evvKaWzGQfcfg@mail.gmail.com>
 <CANTxAmK1DrHTNaUD74+uNN2YNMUQj8xeFC2Pk8v+Lq9P5W=YTA@mail.gmail.com>
 <CABcYAdKethqbtJMmvF=eoJS+YHCrpskZegTi1Y00=m11qoiYqA@mail.gmail.com>
Message-ID: <CABcYAdJS9Ju6FGTB6aU=qJ8n8yvWwhMRLOXbEZjLcod_uwCzNQ@mail.gmail.com>

Whoops, sorry, you *did* answer "what went wrong".
> param_names <- c("param1", "param2", "param3", "param4", "param5", "param6")
> extracted_data <- extract(raster_data, param_names, df = TRUE)
 #Error in (function (classes, fdef, mtable)  :
 #unable to find an inherited method for function ?extract? for
signature ?"SpatRaster", "character"?

OK.  The problem is that the extract() function didn't know what to do.
What does the documentation for 'extract' say?
The error message seems to say that it is not defined for first argument being
a SpatRaster and second argument being of type character.

(By the way, I'm having trouble updating the terra package in Ubuntu 22.04.
That's why I'm not trying any of this out.)

Here's what ?extract starts with:

Extract values from a SpatRaster for a set of locations. The
     locations can be a SpatVector (points, lines, polygons), a
     data.frame or matrix with (x, y) or (longitude, latitude - in that
     order!) coordinates, or a vector with cell numbers.

It does NOT say that the set of locations can be a vector of strings.


On Wed, 26 Jun 2024 at 20:05, Richard O'Keefe <raoknz at gmail.com> wrote:
>
> I'm now inclined to go with 'search for "convert GRIB to CSV".
> https://confluence.ecmwf.int/display/CKB/How+to+convert+GRIB+to+CSV
> is the first line.  I know that's not an R solution, but using software
> specifically developed for encoding, decoding, extracting, &c GRIB file by the
> European Centre for Medium-Range Weather Forecasts and actively
> maintained, with an example page showing how to do it, sounds like a
> good approach.
>
> One of the major things about R is that from the very beginnings of S
> it was intended to be used with other tools.  We have R communicating
> with Python and Tcl and dear knows what.  Getting a specialised tool
> to do its thing is very much part of the R "way".
> Or there's gribr https://rdrr.io/github/nawendt/gribr/man/gribr.html
> which wraps ecCodes in R.
>
> I still don't understand what "doesn't work" means.  Which step goes
> wrong and how does it misbehave?
>
>
> On Wed, 26 Jun 2024 at 06:02, javad bayat <j.bayat194 at gmail.com> wrote:
> >
> > Richard,
> > Many thanks for your email.
> > I had attached the grib file to the original email to R help team but it seems you did not receive it.
> > Unfortunately, I do not know how to reduce the volume or extract some of the grib file data to send it for you. The file has the volume of 6 Megabyte.
> > I can send it by email.
> > The file has 6 met parameters and Date (day/month/year hour:minute).
> > I want the exported file as excel contains 7 columns (Date + 6 met parameters).
> >
> >
> > On Tue, 25 Jun 2024, 15:54 Richard O'Keefe, <raoknz at gmail.com> wrote:
> >>
> >> Your message referred to an attached file but there was no attachment,
> >> I have no account at that service, so could not download a sample for
> >> myself.  Does the licence for the data even allow you to send some of
> >> it in a message?  Which parameters are you extracting?  When you say
> >> "it didn't work", what actually happened?  Which step went wrong and how?
> >>
> >>
> >> On Tue, 25 Jun 2024 at 20:33, javad bayat <j.bayat194 at gmail.com> wrote:
> >> >
> >> > Dear all;
> >> > I have downloaded meteorology data from "
> >> > https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=form"
> >> > as .grib format. It has hourly data of a complete year (every hour of every
> >> > day of 12 months) and has 6 meteorology parameters. The file has been
> >> > attached.
> >> > I am trying to convert it to an excel file that puts every parameter in a
> >> > separated column. For instance, the first col represents Date, 2nd
> >> > represents Temperature and so on.
> >> > Is there any way to do it?
> >> > I used these codes but did not work:
> >> > # install.packages("rNOMADS")
> >> >
> >> > library(rNOMADS)
> >> >
> >> > # Read GRIB data
> >> > grib_data <- ReadGrib("C:/Users/admin/Downloads/Met.grib")
> >> >
> >> > # Convert to a data frame
> >> > grib_df <- as.data.frame(grib_data)
> >> >
> >> > # Write the data frame to a CSV file
> >> > write.csv(grib_df, file = "output.csv")
> >> >
> >> >
> >> > I would be more than happy if anyone could help me.
> >> > Sincerely
> >> >
> >> > --
> >> > Best Regards
> >> > Javad Bayat
> >> > M.Sc. Environment Engineering
> >> > Alternative Mail: bayat194 at yahoo.com
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.


From A|@hw@ry@@Pr|y@ @end|ng |rom de||@com  Wed Jun 26 19:03:37 2024
From: A|@hw@ry@@Pr|y@ @end|ng |rom de||@com (Priya, Aishwarya)
Date: Wed, 26 Jun 2024 17:03:37 +0000
Subject: [R] Regarding the Security Vulnerability CVE 2024 - 27322
Message-ID: <MW4PR19MB6772269B26892EF405E5E0D6F7D62@MW4PR19MB6772.namprd19.prod.outlook.com>

Dear R Foundation Team,

I hope this message finds you well.
I am reaching out to seek your guidance on addressing the security vulnerability CVE-2024-27322. As I understand, a security fix for this vulnerability has been available starting from v4.4.0. This issue affects all versions from 1.4.0 to 4.3.3.

During our testing phase, we encountered a challenge while attempting to upgrade to the secure version. Our devices were running version 4.3.3 and below, and we tried to install version 4.4.0, hoping the installer would detect the older version and perform an in-place upgrade. However, we observed that the new version was installed alongside the older version rather than replacing it. Consequently, this approach did not mitigate the security vulnerability.

To address this issue effectively, it appears that we need to first uninstall the existing older version before installing the latest version. This process should ensure that the security vulnerability is adequately resolved.

Could you please confirm if this is the recommended approach for handling this specific security issue? Additionally, if there are any alternative methods or best practices you could suggest for performing this upgrade seamlessly, we would greatly appreciate your insights.

Thank you for your support and assistance in this matter.


Thanks & Regards,
Aishwarya Priyadarshini
TMX Software Delivery, Virtualization & Telemetry
Dell Digital | Team Member eXperience
Aishwarya_Priya at Dell.com<mailto:Aishwarya_Priya at Dell.com>



Internal Use - Confidential

	[[alternative HTML version deleted]]


From |kry|ov @end|ng |rom d|@root@org  Wed Jun 26 22:25:18 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Wed, 26 Jun 2024 23:25:18 +0300
Subject: [R] Regarding the Security Vulnerability CVE 2024 - 27322
In-Reply-To: <MW4PR19MB6772269B26892EF405E5E0D6F7D62@MW4PR19MB6772.namprd19.prod.outlook.com>
References: <MW4PR19MB6772269B26892EF405E5E0D6F7D62@MW4PR19MB6772.namprd19.prod.outlook.com>
Message-ID: <20240626232518.16667613@Tarkus>

Dear Aishwarya Priyadarshini,

Welcome to R-help! Most people here aren't affiliated with R Foundation.

? Wed, 26 Jun 2024 17:03:37 +0000
"Priya, Aishwarya via R-help" <r-help at r-project.org> ?????:

> I am reaching out to seek your guidance on addressing the security
> vulnerability CVE-2024-27322.

> To address this issue effectively, it appears that we need to first
> uninstall the existing older version before installing the latest
> version. This process should ensure that the security vulnerability
> is adequately resolved.

What's your threat model?

If you need the CVE fix purely because you are required to install it
by some sort of regulations, installing R-4.4.0 and removing all older
versions of R is definitely the right thing to do.

If you actually need to be secure against untrusted *.rds or *.rda
files, R-4.4.0 or any other version of R will be of no help to you.
There are too many ways to make an R object dangerous to use, and the
*.rds and *.rda files will faithfully represent the trapped R object
even in the absence of any vulnerabilities in the parser:
https://aitap.github.io/2024/05/02/unserialize.html

If you only process *.rds and *.rda files you trust, you've never been
in danger from this so-called vulnerability. Feel free to keep running
older versions of R.

-- 
Best regards,
Ivan


From bbo|ker @end|ng |rom gm@||@com  Wed Jun 26 22:36:51 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 26 Jun 2024 16:36:51 -0400
Subject: [R] Regarding the Security Vulnerability CVE 2024 - 27322
In-Reply-To: <20240626232518.16667613@Tarkus>
References: <MW4PR19MB6772269B26892EF405E5E0D6F7D62@MW4PR19MB6772.namprd19.prod.outlook.com>
 <20240626232518.16667613@Tarkus>
Message-ID: <bd6d7aab-a79e-4bd1-9e27-751fb16e988d@gmail.com>



On 2024-06-26 4:25 p.m., Ivan Krylov via R-help wrote:
> Dear Aishwarya Priyadarshini,
> 
> Welcome to R-help! Most people here aren't affiliated with R Foundation.
> 
> ? Wed, 26 Jun 2024 17:03:37 +0000
> "Priya, Aishwarya via R-help" <r-help at r-project.org> ?????:
> 
>> I am reaching out to seek your guidance on addressing the security
>> vulnerability CVE-2024-27322.
> 
>> To address this issue effectively, it appears that we need to first
>> uninstall the existing older version before installing the latest
>> version. This process should ensure that the security vulnerability
>> is adequately resolved.
> 
> What's your threat model?
> 
> If you need the CVE fix purely because you are required to install it
> by some sort of regulations, installing R-4.4.0 and removing all older
> versions of R is definitely the right thing to do.
> 
> If you actually need to be secure against untrusted *.rds or *.rda
> files, R-4.4.0 or any other version of R will be of no help to you.
> There are too many ways to make an R object dangerous to use, and the
> *.rds and *.rda files will faithfully represent the trapped R object
> even in the absence of any vulnerabilities in the parser:
> https://aitap.github.io/2024/05/02/unserialize.html
> 
> If you only process *.rds and *.rda files you trust, you've never been
> in danger from this so-called vulnerability. Feel free to keep running
> older versions of R.
> 

   I spent a little while working in a secure data centre where they 
wouldn't allow us shell access "for security reasons", but they did 
allow us to use R. It would have made things very inconvenient if I had 
told them about the system() command, so I didn't bother ...

   Ben Bolker


From c@deb @end|ng |rom u@g@@gov  Thu Jun 27 00:24:30 2024
From: c@deb @end|ng |rom u@g@@gov (Cade, Brian S)
Date: Wed, 26 Jun 2024 22:24:30 +0000
Subject: [R] emmeans (component = " response", type = "response")
Message-ID: <SJ0PR09MB1106252693D5EF6D44BA8A67ED9D62@SJ0PR09MB11062.namprd09.prod.outlook.com>

I am estimating fairly simple zero-inflated negative binomial models in glmmTMB.  The models have just two factors and their interaction, a total of 4 levels.  I was trying to use emmeans() to obtain estimates and 95% CI for these four levels.  However, when I use emmeans() with the arguments component="response", type ="response", I do not get estimates that look like the negative binomial (conditional) part of the model multiplied by 1 - zero-inflation probability.  Not sure what I am getting and have not found documentation yet.  I can get the negative binomial part with arguments response = "cond" , type = "response" and the zero-inflated parts with arguments response="zi", type = "response" and easily relate these back to parameter estimates.  How do I get the zero-inflated mean negative binomial counts estimated in emmeans?  I was led to believe that components="response" , type = "response" would do that but that does not seem to be the case.

Thank you

Brian


Brian S. Cade, PhD

U. S. Geological Survey (emeritus)
Fort Collins Science Center
2150 Centre Ave., Bldg. C
Fort Collins, CO  80526-8818

email:  cadeb at usgs.gov<mailto:brian_cade at usgs.gov>
tel:  970 404-0447


	[[alternative HTML version deleted]]


