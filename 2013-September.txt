From jim at bitwrit.com.au  Sun Sep  1 00:04:16 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sun, 01 Sep 2013 08:04:16 +1000
Subject: [R] How to plot a pretty heatmap with uneven distributed data?
In-Reply-To: <CAJTpEX7OMb=cywrRVbPuCPwCnmrOpCsCLrmmLoUBVeo17vUcAg@mail.gmail.com>
References: <CAJTpEX7OMb=cywrRVbPuCPwCnmrOpCsCLrmmLoUBVeo17vUcAg@mail.gmail.com>
Message-ID: <52226860.9080309@bitwrit.com.au>

On 08/31/2013 07:29 PM, Wei Liu wrote:
> Dear All,
>
> I want to plot a heatmap with R, but my data  distributed unevenly, for
> example, my data range from 10 to 1500, but most of the data smaller than
> 200, when I plot a heatmap, the colour is also distributed unevenly, most
> part of the heatmap is one colour, so the heatmap is ugly and meaningless.
>
> So can anybody help me plot a pretty heatmap for me with the attached data.
> I am looking forward your reply! Thansk very much.
>
Hi Wei Liu,
You would have to explain the transformation of your variables, but 
perhaps something like:

library(plotrix)
color2D.matplot(log(example_data+0.01),extremes=c("red","blue"))

would do what you want.

Jim


From smartpink111 at yahoo.com  Sun Sep  1 03:25:19 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 31 Aug 2013 18:25:19 -0700 (PDT)
Subject: [R] Insert null columns and rows into a matrix to make it square
Message-ID: <1377998719.29983.YahooMailNeo@web142605.mail.bf1.yahoo.com>

HI,
You could try this:

dat1<- read.table(text="
A? B? C? D
A 1? 2? 3? 4
E 5? 6? 7? 8
F 9 10 11 12
",sep="",header=TRUE,stringsAsFactors=FALSE)


dat1$ID<-row.names(dat1)
library(reshape2)
dat1New<-melt(dat1,id.var="ID")
dat2<- data.frame(expand.grid(ID=LETTERS[1:6],variable=LETTERS[1:6]),value=0)
datM<-merge(dat1New,dat2,all=TRUE)


?res<-xtabs(value~ID+variable,data=datM)

?names(attr(res,"dimnames"))<-NULL
?res
#?? A? B? C? D? E? F
#A? 1? 2? 3? 4? 0? 0
#B? 0? 0? 0? 0? 0? 0
#C? 0? 0? 0? 0? 0? 0
#D? 0? 0? 0? 0? 0? 0
#E? 5? 6? 7? 8? 0? 0
#F? 9 10 11 12? 0? 0

#or
res2<-dcast(datM,ID~variable,value.var="value",sum)
row.names(res2)<- res2[,1]
res2New<- res2[,-1]
?res2New
#? A? B? C? D E F
#A 1? 2? 3? 4 0 0
#B 0? 0? 0? 0 0 0
#C 0? 0? 0? 0 0 0
#D 0? 0? 0? 0 0 0
#E 5? 6? 7? 8 0 0
#F 9 10 11 12 0 0



#or

dat2<- expand.grid(ID=LETTERS[1:6],variable=LETTERS[1:6])
datM<-merge(dat1New,dat2,all=TRUE)
?dcast(datM,ID~variable,value.var="value",fill=0)
#? ID A? B? C? D E F
#1? A 1? 2? 3? 4 0 0
#2? B 0? 0? 0? 0 0 0
#3? C 0? 0? 0? 0 0 0
#4? D 0? 0? 0? 0 0 0
#5? E 5? 6? 7? 8 0 0
#6? F 9 10 11 12 0 0

A.K.


Hi, 
I wish to convert rectangular matrices such as this: 
? A ?B ?C ?D 
A 1 ?2 ?3 ?4 
E 5 ?6 ?7 ?8 
F 9 10 11 12 
into square ones with null rows and columns named with the missing names such as this: 
? A ?B ?C ?D ?E ?F 
A 1 ?2 ?3 ?4 ?0 ?0 
B 0 ?0 ?0 ?0 ?0 ?0 
C 0 ?0 ?0 ?0 ?0 ?0 
D 0 ?0 ?0 ?0 ?0 ?0 
E 5 ?6 ?7 ?8 ?0 ?0 
F 9 10 11 12 ?0 ?0 
Could anyone give me a hand please. 
Thanks 
Mariki


From smartpink111 at yahoo.com  Sun Sep  1 03:44:48 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 31 Aug 2013 18:44:48 -0700 (PDT)
Subject: [R] Insert null columns and rows into a matrix to make it square
In-Reply-To: <1377998719.29983.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1377998719.29983.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1377999888.56895.YahooMailNeo@web142605.mail.bf1.yahoo.com>

HI,

Without converting to data.frame, you can also try:


dat1<- read.table(text="
A? B? C? D
A 1? 2? 3? 4
E 5? 6? 7? 8
F 9 10 11 12
",sep="",header=TRUE,stringsAsFactors=FALSE)
mat1<- as.matrix(dat1)
names1<-unique(c(colnames(mat1),rownames(mat1)))
mat2<- matrix(0,length(names1),length(names1),dimnames=list(names1,names1))
?vec1<-paste0(colnames(mat1)[col(mat1)],rownames(mat1)[row(mat1)])
?vec2<- paste0(colnames(mat2)[col(mat2)],colnames(mat2)[row(mat2)])

?mat2[match(vec1,vec2)]<- mat1
?mat2
#? A? B? C? D E F
#A 1? 2? 3? 4 0 0
#B 0? 0? 0? 0 0 0
#C 0? 0? 0? 0 0 0
#D 0? 0? 0? 0 0 0
#E 5? 6? 7? 8 0 0
#F 9 10 11 12 0 0
A.K.



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Saturday, August 31, 2013 9:25 PM
Subject: Re: Insert null columns and rows into a matrix to make it square

HI,
You could try this:

dat1<- read.table(text="
A? B? C? D
A 1? 2? 3? 4
E 5? 6? 7? 8
F 9 10 11 12
",sep="",header=TRUE,stringsAsFactors=FALSE)


dat1$ID<-row.names(dat1)
library(reshape2)
dat1New<-melt(dat1,id.var="ID")
dat2<- data.frame(expand.grid(ID=LETTERS[1:6],variable=LETTERS[1:6]),value=0)
datM<-merge(dat1New,dat2,all=TRUE)


?res<-xtabs(value~ID+variable,data=datM)

?names(attr(res,"dimnames"))<-NULL
?res
#?? A? B? C? D? E? F
#A? 1? 2? 3? 4? 0? 0
#B? 0? 0? 0? 0? 0? 0
#C? 0? 0? 0? 0? 0? 0
#D? 0? 0? 0? 0? 0? 0
#E? 5? 6? 7? 8? 0? 0
#F? 9 10 11 12? 0? 0

#or
res2<-dcast(datM,ID~variable,value.var="value",sum)
row.names(res2)<- res2[,1]
res2New<- res2[,-1]
?res2New
#? A? B? C? D E F
#A 1? 2? 3? 4 0 0
#B 0? 0? 0? 0 0 0
#C 0? 0? 0? 0 0 0
#D 0? 0? 0? 0 0 0
#E 5? 6? 7? 8 0 0
#F 9 10 11 12 0 0



#or

dat2<- expand.grid(ID=LETTERS[1:6],variable=LETTERS[1:6])
datM<-merge(dat1New,dat2,all=TRUE)
?dcast(datM,ID~variable,value.var="value",fill=0)
#? ID A? B? C? D E F
#1? A 1? 2? 3? 4 0 0
#2? B 0? 0? 0? 0 0 0
#3? C 0? 0? 0? 0 0 0
#4? D 0? 0? 0? 0 0 0
#5? E 5? 6? 7? 8 0 0
#6? F 9 10 11 12 0 0

A.K.


Hi, 
I wish to convert rectangular matrices such as this: 
? A ?B ?C ?D 
A 1 ?2 ?3 ?4 
E 5 ?6 ?7 ?8 
F 9 10 11 12 
into square ones with null rows and columns named with the missing names such as this: 
? A ?B ?C ?D ?E ?F 
A 1 ?2 ?3 ?4 ?0 ?0 
B 0 ?0 ?0 ?0 ?0 ?0 
C 0 ?0 ?0 ?0 ?0 ?0 
D 0 ?0 ?0 ?0 ?0 ?0 
E 5 ?6 ?7 ?8 ?0 ?0 
F 9 10 11 12 ?0 ?0 
Could anyone give me a hand please. 
Thanks 
Mariki


From simona.augyte at uconn.edu  Sun Sep  1 00:30:54 2013
From: simona.augyte at uconn.edu (Simona Augyte)
Date: Sat, 31 Aug 2013 18:30:54 -0400
Subject: [R] NMDS QUESTION
Message-ID: <CAHh0FZDurOw4F2smRjChy-g+TCew7rdxyosfrRR5HCWfMEm_SA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130831/d088d39e/attachment.pl>

From michel.arnaud at cirad.fr  Sun Sep  1 07:18:57 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Sun, 01 Sep 2013 07:18:57 +0200
Subject: [R] To represent on the same plot the relation (y1, x) and (y2,
 x)
In-Reply-To: <1377977251.50857.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <52222E75.3050108@cirad.fr>
	<1377977251.50857.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <5222CE41.1000204@cirad.fr>

Thank you Arun
But have you a solution if y1 and y2 have not the same unit (ex : the 
unit of y1 is meter and the unit of y2 is Kg)  and if I want the axe of 
y1 at the left of the plot and the axe of y2 at the rigth of the plot....
Michel

Le 31/08/2013 21:27, arun a ?crit :
> Hi,
> May be this helps:
>   x<- 1:10
>   set.seed(28)
>   y1<- rnorm(10)
> set.seed(485)
>   y2<- rnorm(10)
>   plot(x,y1,col="red",type="b",ylab="y1:y2")
> lines(y2,col="blue",type="b")
> legend("topleft", legend = c("y1", "y2"),text.col=c("red","blue"))
>
>
>
> #or
> library(ggplot2)
> dat1<- data.frame(x,y1,y2)
> ggplot(dat1,aes(x))+geom_line(aes(y=y1,colour="y1"))+
>    geom_line(aes(y=y2,colour="y2")) +ylab("y1:y2")
>
> A.K.
>
>
>
>
>
> ----- Original Message -----
> From: Arnaud Michel <michel.arnaud at cirad.fr>
> To: R help <r-help at r-project.org>
> Cc:
> Sent: Saturday, August 31, 2013 1:57 PM
> Subject: [R] To represent on the same plot the relation (y1, x) and (y2, x)
>
> Hello,
> I have 3 vectors x, y1 and y2
> I would like to represent on the same plot the two graph (y1, x) and
> (y2, x).
> Is it possible with ggplot ? other package ?
> Thanks for your help
>

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From smartpink111 at yahoo.com  Sun Sep  1 07:36:08 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 31 Aug 2013 22:36:08 -0700 (PDT)
Subject: [R] To represent on the same plot the relation (y1, x) and (y2,
	x)
In-Reply-To: <5222CE41.1000204@cirad.fr>
References: <52222E75.3050108@cirad.fr>
	<1377977251.50857.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<5222CE41.1000204@cirad.fr>
Message-ID: <1378013768.80574.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi Arnaud,
No problem.
Try,
x<- 1:10
?set.seed(28)
?y1<- rnorm(10)
set.seed(485)
?y2<- rnorm(10,25)
library(plotrix)
?twoord.plot(x,y1,y2,lylim=c(-2,2),rylim=c(20,30),ylab="y1",rylab="y2",lcol=2,rcol=4,main="y1, y2 vs. x")

A.K.




----- Original Message -----
From: Arnaud Michel <michel.arnaud at cirad.fr>
To: arun <smartpink111 at yahoo.com>
Cc: R help <r-help at r-project.org>
Sent: Sunday, September 1, 2013 1:18 AM
Subject: Re: [R] To represent on the same plot the relation (y1, x) and (y2, x)

Thank you Arun
But have you a solution if y1 and y2 have not the same unit (ex : the 
unit of y1 is meter and the unit of y2 is Kg)? and if I want the axe of 
y1 at the left of the plot and the axe of y2 at the rigth of the plot....
Michel

Le 31/08/2013 21:27, arun a ?crit :
> Hi,
> May be this helps:
>?  x<- 1:10
>?  set.seed(28)
>?  y1<- rnorm(10)
> set.seed(485)
>?  y2<- rnorm(10)
>?  plot(x,y1,col="red",type="b",ylab="y1:y2")
> lines(y2,col="blue",type="b")
> legend("topleft", legend = c("y1", "y2"),text.col=c("red","blue"))
>
>
>
> #or
> library(ggplot2)
> dat1<- data.frame(x,y1,y2)
> ggplot(dat1,aes(x))+geom_line(aes(y=y1,colour="y1"))+
>? ? geom_line(aes(y=y2,colour="y2")) +ylab("y1:y2")
>
> A.K.
>
>
>
>
>
> ----- Original Message -----
> From: Arnaud Michel <michel.arnaud at cirad.fr>
> To: R help <r-help at r-project.org>
> Cc:
> Sent: Saturday, August 31, 2013 1:57 PM
> Subject: [R] To represent on the same plot the relation (y1, x) and (y2, x)
>
> Hello,
> I have 3 vectors x, y1 and y2
> I would like to represent on the same plot the two graph (y1, x) and
> (y2, x).
> Is it possible with ggplot ? other package ?
> Thanks for your help
>

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From michel.arnaud at cirad.fr  Sun Sep  1 07:58:58 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Sun, 01 Sep 2013 07:58:58 +0200
Subject: [R] To represent on the same plot the relation (y1, x) and (y2,
 x)
In-Reply-To: <1378013768.80574.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <52222E75.3050108@cirad.fr>
	<1377977251.50857.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<5222CE41.1000204@cirad.fr>
	<1378013768.80574.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <5222D7A2.6020709@cirad.fr>

Thank you Arun
Michel
Le 01/09/2013 07:36, arun a ?crit :
> Hi Arnaud,
> No problem.
> Try,
> x<- 1:10
>   set.seed(28)
>   y1<- rnorm(10)
> set.seed(485)
>   y2<- rnorm(10,25)
> library(plotrix)
>   twoord.plot(x,y1,y2,lylim=c(-2,2),rylim=c(20,30),ylab="y1",rylab="y2",lcol=2,rcol=4,main="y1, y2 vs. x")
>
> A.K.
>
>
>
>
> ----- Original Message -----
> From: Arnaud Michel <michel.arnaud at cirad.fr>
> To: arun <smartpink111 at yahoo.com>
> Cc: R help <r-help at r-project.org>
> Sent: Sunday, September 1, 2013 1:18 AM
> Subject: Re: [R] To represent on the same plot the relation (y1, x) and (y2, x)
>
> Thank you Arun
> But have you a solution if y1 and y2 have not the same unit (ex : the
> unit of y1 is meter and the unit of y2 is Kg)  and if I want the axe of
> y1 at the left of the plot and the axe of y2 at the rigth of the plot....
> Michel
>
> Le 31/08/2013 21:27, arun a ?crit :
>> Hi,
>> May be this helps:
>>     x<- 1:10
>>     set.seed(28)
>>     y1<- rnorm(10)
>> set.seed(485)
>>     y2<- rnorm(10)
>>     plot(x,y1,col="red",type="b",ylab="y1:y2")
>> lines(y2,col="blue",type="b")
>> legend("topleft", legend = c("y1", "y2"),text.col=c("red","blue"))
>>
>>
>>
>> #or
>> library(ggplot2)
>> dat1<- data.frame(x,y1,y2)
>> ggplot(dat1,aes(x))+geom_line(aes(y=y1,colour="y1"))+
>>      geom_line(aes(y=y2,colour="y2")) +ylab("y1:y2")
>>
>> A.K.
>>
>>
>>
>>
>>
>> ----- Original Message -----
>> From: Arnaud Michel <michel.arnaud at cirad.fr>
>> To: R help <r-help at r-project.org>
>> Cc:
>> Sent: Saturday, August 31, 2013 1:57 PM
>> Subject: [R] To represent on the same plot the relation (y1, x) and (y2, x)
>>
>> Hello,
>> I have 3 vectors x, y1 and y2
>> I would like to represent on the same plot the two graph (y1, x) and
>> (y2, x).
>> Is it possible with ggplot ? other package ?
>> Thanks for your help
>>

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From smartpink111 at yahoo.com  Sun Sep  1 08:41:25 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 31 Aug 2013 23:41:25 -0700 (PDT)
Subject: [R] NMDS QUESTION
In-Reply-To: <CAHh0FZDurOw4F2smRjChy-g+TCew7rdxyosfrRR5HCWfMEm_SA@mail.gmail.com>
References: <CAHh0FZDurOw4F2smRjChy-g+TCew7rdxyosfrRR5HCWfMEm_SA@mail.gmail.com>
Message-ID: <1378017685.76572.YahooMailNeo@web142604.mail.bf1.yahoo.com>

HI,
coma<- read.table(text="
gr T C M B
arcor 6 4 6 5
corfo 24 21 23 24
corma 25 15 26 17
crust 3 2 6 5
fil 15 12 15 15
fol 11 9 6 8
leat 10 11 13 13
seag 2 2 2 2
",sep="",header=TRUE)

?coma.x<- as.matrix(coma)

str(coma.x)
# chr [1:8, 1:5] "arcor" "corfo" "corma" "crust" "fil" "fol" ...
# - attr(*, "dimnames")=List of 2
#? ..$ : NULL
#? ..$ : chr [1:5] "gr" "T" "C" "M" ...


coma.dist<- dist(coma.x)
#Warning message:
#In dist(coma.x) : NAs introduced by coercion


?dist() #documentation
# dist(x, method = "euclidean", diag = FALSE, upper = FALSE, p = 2)
# x: a numeric matrix, data frame or ?"dist"? object.



?coma.x<- as.matrix(coma[,-1]) #####
?str(coma.x)
# int [1:8, 1:4] 6 24 25 3 15 11 10 2 4 21 ...
# - attr(*, "dimnames")=List of 2
?# ..$ : NULL
?# ..$ : chr [1:4] "T" "C" "M" "B"


?coma.dist<- dist(coma.x)
A.K.



----- Original Message -----
From: Simona Augyte <simona.augyte at uconn.edu>
To: r-help at r-project.org
Cc: 
Sent: Saturday, August 31, 2013 6:30 PM
Subject: [R] NMDS QUESTION

I'm trying to run a very simple non-metric multidimensional scaling code on
a 8x5 character matrix.
gr T C M B
arcor 6 4 6 5
corfo 24 21 23 24
corma 25 15 26 17
crust 3 2 6 5
fil 15 12 15 15
fol 11 9 6 8
leat 10 11 13 13
seag 2 2 2 2

My code is as follows;
coma<-read.csv("coma.csv",header=TRUE)
coma.x<-as.matrix(coma)
coma.dist <- dist(coma.x) # right here I get a warning message -> In
dist(coma.x) : NAs introduced by coercion

WHAT DOES THAT MEAN??? the table has values and there are not NAs. Could
this be a by product of the way I inserted the data?

Please help.

-- 

Simona Augyte, MS
PhD student
Ecology and Evolutionary Biology
University of Connecticut
cell 707-832-7007

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From bhh at xs4all.nl  Sun Sep  1 09:03:23 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 1 Sep 2013 09:03:23 +0200
Subject: [R] NMDS QUESTION
In-Reply-To: <CAHh0FZDurOw4F2smRjChy-g+TCew7rdxyosfrRR5HCWfMEm_SA@mail.gmail.com>
References: <CAHh0FZDurOw4F2smRjChy-g+TCew7rdxyosfrRR5HCWfMEm_SA@mail.gmail.com>
Message-ID: <C4C0296A-1D6C-4395-8B80-90E849CDD72E@xs4all.nl>


On 01-09-2013, at 00:30, Simona Augyte <simona.augyte at uconn.edu> wrote:

> I'm trying to run a very simple non-metric multidimensional scaling code on
> a 8x5 character matrix.
> gr T C M B
> arcor 6 4 6 5
> corfo 24 21 23 24
> corma 25 15 26 17
> crust 3 2 6 5
> fil 15 12 15 15
> fol 11 9 6 8
> leat 10 11 13 13
> seag 2 2 2 2
> 
> My code is as follows;
> coma<-read.csv("coma.csv",header=TRUE)
> coma.x<-as.matrix(coma)
> coma.dist <- dist(coma.x) # right here I get a warning message -> In
> dist(coma.x) : NAs introduced by coercion
> 
> WHAT DOES THAT MEAN??? the table has values and there are not NAs. Could
> this be a by product of the way I inserted the data?
> 

Yes.
Your table contains characters and not numbers.

Tell read.csv that the first column contains row names (assuming that that is indeed the case).

coma<- read.csv(text="
gr T C M B
arcor 6 4 6 5
corfo 24 21 23 24
corma 25 15 26 17
crust 3 2 6 5
fil 15 12 15 15
fol 11 9 6 8
leat 10 11 13 13
seag 2 2 2 2
",sep="",row.names=1,header=TRUE)

coma
str(coma)
dist(coma)     

Berend


> Please help.
> 
> -- 
> 
> Simona Augyte, MS
> PhD student
> Ecology and Evolutionary Biology
> University of Connecticut
> cell 707-832-7007
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Petrus.Heemskerk at xs4all.nl  Sun Sep  1 10:48:58 2013
From: Petrus.Heemskerk at xs4all.nl (Piet Heemskerk)
Date: Sun, 1 Sep 2013 10:48:58 +0200
Subject: [R] cannot install RExcel
Message-ID: <000301cea6f0$1bc8cf30$535a6d90$@Heemskerk@xs4all.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130901/68c5f0df/attachment.pl>

From info at aghmed.fsnet.co.uk  Sun Sep  1 13:26:16 2013
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Sun, 01 Sep 2013 12:26:16 +0100
Subject: [R] Packaging
In-Reply-To: <1377846825.21126.YahooMailNeo@web171503.mail.ir2.yahoo.com
 >
References: <1377846825.21126.YahooMailNeo@web171503.mail.ir2.yahoo.com>
Message-ID: <Zen-1VG5nT-0000IR-SG@smarthost01b.mail.zen.net.uk>

At 08:13 30/08/2013, Eva Prieto Castro wrote:
>Hi,
>
>I have a problem when I try to generate the Documentation pdf (from 
>.rda files)in Spanish during the package creation. Could you tell me 
>the way I can do it?.

Eva
It would be usual to have the documentation in a file of type .Rd not 
.rda which would usually contain a dataset.

1 - was that a typo, .rda for .Rd
2 - if you do have your documentation in a .rda file please think again
3 - if you have a dataset and do not know how to document it try ?promptData

If none of those works try giving us more information like
1 - what did you do
2 - what did you think was going to happen
3 - what actually happened

>Thanks in advance.
>
>Regards.
>
>Eva
>         [[alternative HTML version deleted]]

Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html


From economics.vikram at gmail.com  Sun Sep  1 15:06:59 2013
From: economics.vikram at gmail.com (Vikram Bahure)
Date: Sun, 1 Sep 2013 18:36:59 +0530
Subject: [R] Blur and not readable text, using geom_text in ggplot
Message-ID: <CAEfYxiWpQ_k3GXeGfZfZOqar3YDcQ=fcTn_9p0byYuHrg6QjjQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130901/fb4a8ab7/attachment.pl>

From helensawaya at hotmail.com  Sun Sep  1 15:13:57 2013
From: helensawaya at hotmail.com (Helen Sawaya)
Date: Sun, 1 Sep 2013 16:13:57 +0300
Subject: [R] outliers for Likert scale data
Message-ID: <DUB122-W1D3EA277442D1836CC4F6B9370@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130901/6ce906fc/attachment.pl>

From bhh at xs4all.nl  Sun Sep  1 15:54:47 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 1 Sep 2013 15:54:47 +0200
Subject: [R] NMDS QUESTION
In-Reply-To: <CAHh0FZBjrTPD6FX7OwwdKBkxecLhZSd4TRk=wDzpdqoj6m-fWg@mail.gmail.com>
References: <CAHh0FZDurOw4F2smRjChy-g+TCew7rdxyosfrRR5HCWfMEm_SA@mail.gmail.com>
	<C4C0296A-1D6C-4395-8B80-90E849CDD72E@xs4all.nl>
	<CAHh0FZBjrTPD6FX7OwwdKBkxecLhZSd4TRk=wDzpdqoj6m-fWg@mail.gmail.com>
Message-ID: <4405F12A-34F4-41E1-91F6-ED5CC3344BE9@xs4all.nl>


On 01-09-2013, at 15:34, Simona Augyte <simona.augyte at uconn.edu> wrote:

> Ok, thanks, that helps. 
> 
> What about running the same code on a bit of a different set of data, ex.;
> korma<- read.csv(text="
> GR  T	C	M	B
> 1	0	0	0	1
> 2	0	1	0	0
> 3	1	1	0	1
> 4	1	0	1	1
> 5	0	0	0	1
> 6	1	0	1	1?

Is the ? part of your data?
It makes column 5 a factor. Is tha
> ",sep="",row.names=1,header=TRUE)
> 
> str(korma)
> dist(korma)
> korma.dist<- dist(korma)
>  korma.mds <- isoMDS(korma.dist)
> #Error in isoMDS(korma.dist) :   zero or negative distance between objects 1 and 5
> # What do I need to do to my data to avoid the error message?

I don't know. Maybe remove ? from column 5?  Where does isoMDS come from?

Berend


From istazahn at gmail.com  Sun Sep  1 15:59:28 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Sun, 1 Sep 2013 09:59:28 -0400
Subject: [R] Blur and not readable text, using geom_text in ggplot
In-Reply-To: <CAEfYxiWpQ_k3GXeGfZfZOqar3YDcQ=fcTn_9p0byYuHrg6QjjQ@mail.gmail.com>
References: <CAEfYxiWpQ_k3GXeGfZfZOqar3YDcQ=fcTn_9p0byYuHrg6QjjQ@mail.gmail.com>
Message-ID: <CA+vqiLFJruRCe+sDcRbVprVQvzP6TWjrUEB9L0=0=Zi2sML_8g@mail.gmail.com>

Hi Vikram,

It looks like you are plotting multiple text values at the same x and
y coordinates. It's not clear from your code what exactly you are
trying to do; please create a reproducible example and explain what
the desired result is.

Best,
Ista



On Sun, Sep 1, 2013 at 9:06 AM, Vikram Bahure
<economics.vikram at gmail.com> wrote:
> Dear R Users,
>
> I am new to ggplot. I am using geom_text to inscribe values on my ggplot
> but it is giving me values which are unreadable and blur.
>
> Please let me know if there is any way out.
>
> ----------------- Code -----------------
> *es <- es3 + geom_text(data=tmp.cor, aes(x=2, y=min(infer.df$value),*
> *                          label=text.bottom), colour="black",*
> *                        inherit.aes=FALSE, parse=FALSE, size=4.5)*
> *
> *
> *> str(tmp.cor)*
> *'data.frame': 198 obs. of  3 variables:*
> * $ var        : Factor w/ 6 levels "All","Large",..: 2 2 2 2 2 2 2 2 2 2
> ...*
> * $ text.top   : chr  "Size (INR bln):  287" "Size (INR bln):  287" "Size
> (INR bln):  287" "Size (INR bln):  287" ...*
> * $ text.bottom: chr  "Extreme (%):  5.74" "Extreme (%):  5.74" "Extreme
> (%):  5.74" "Extreme (%):  5.74" ...*
> *-------------------*
> *
> *
> Regards
> Vikram
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ignacio82 at gmail.com  Sun Sep  1 16:00:00 2013
From: ignacio82 at gmail.com (Ignacio Martinez)
Date: Sun, 1 Sep 2013 10:00:00 -0400
Subject: [R] lapply to multivariate function?
Message-ID: <CAJA1VFwdu3G7CyeQb3dvUpXS-NXxNG2SK-y59peC4K33F81eUQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130901/d869fd08/attachment.pl>

From ruipbarradas at sapo.pt  Sun Sep  1 16:31:05 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 01 Sep 2013 15:31:05 +0100
Subject: [R] lapply to multivariate function?
In-Reply-To: <CAJA1VFwdu3G7CyeQb3dvUpXS-NXxNG2SK-y59peC4K33F81eUQ@mail.gmail.com>
References: <CAJA1VFwdu3G7CyeQb3dvUpXS-NXxNG2SK-y59peC4K33F81eUQ@mail.gmail.com>
Message-ID: <52234FA9.3080703@sapo.pt>

Hello,

Maybe you need apply, not lapply. It seems you want to apply() a 
function to the first dimension of your data.frame, something like

apply(dat, 1, fun)  #apply by rows


Hope this helps,

Rui Barradas

Em 01-09-2013 15:00, Ignacio Martinez escreveu:
> I have a Data Frame that contains, between other things, the following
> fields: userX, Time1, Time2, Time3. The number of observations is 2000.
>
> I have a function that has as inputs userX, Time1, Time2, Time3 and return
> a data frame with 1 observation and 19 variables.
>
> I want to apply that function to all the observations of the first data
> frame to make a new data frame with 2000 observations and 19 variables.
>
> I thought about using lapply, but if I understand correctly, it only takes
> one variable.
>
> Can somebody point me in the right direction?
>
> Thanks!
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From lorenzo.isella at gmail.com  Sun Sep  1 16:36:13 2013
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Sun, 1 Sep 2013 16:36:13 +0200
Subject: [R] Question About Markov Models
Message-ID: <op.w2qlinbvzqkd1e@nirvana>

Dear All,
I am a bit struggling with the many packages for Markov models available  
in R.
Apologies for now posting a code snippet, but I am looking for some  
guidance here.
Please consider a set like the one below (which you can get with

data<-read.csv('http://dl.dropboxusercontent.com/u/5685598/data_table.csv')      
).

    ID      therapy   age1 age2 EFS
   7308   ormo_lunga   78   84  73
   7308   ormo_medio   78   84  73
   7308   ormo_lunga   78   84  73
   4902 chemio_lunga   46   56 120
   4902   ormo_lunga   46   56 120
   4902   ormo_lunga   46   56 120
   4902   ormo_breve   46   56 120
   4902 chemio_lunga   46   56 120
   4902   ormo_breve   46   56 120
   5299   ormo_lunga   61   70 100
   5299   ormo_breve   61   70 100
   5299 chemio_breve   61   70 100
   5299 chemio_lunga   61   70 100
   5926   ormo_lunga   66   67   3
   5926   ormo_lunga   66   67   3
   5926   ormo_breve   66   67   3
   5926   ormo_medio   66   67   3
   5926 chemio_lunga   66   67   3
   5926   ormo_breve   66   67   3
   5374   ormo_lunga   39   59 242
   5374   ormo_lunga   39   59 242
   5374   ormo_lunga   39   59 242
   4912   ormo_medio   40   50 124
   4912 chemio_lunga   40   50 124
   4912 chemio_lunga   40   50 124
   4912   ormo_breve   40   50 124
   4912 chemio_lunga   40   50 124
   4532   ormo_breve   61   63  26
   4532   ormo_breve   61   63  26
   4532 chemio_lunga   61   63  26

I have a list of (short) series of states identified by the ID of the  
patient who undergoes several therapies.
I then have other info about each patient (for instance its age when the  
disease was first detected and so on).
The point is to calculate the transition matrix for the sequence of  
therapies undergone by the patients and then possibly use the  
complementary information available for the patients.
The purpose is not so much to understand whether the patient will be alive  
or dead (this info is not available for all the patients after its last  
therapy), but to try to guess the next therapy one is likely to undergo at  
some stage using a Markovian model.
Let us assume that all patients are given the i-th therapy cycle at the  
same time.
I did some experiments with the mcm package  
(http://cran.r-project.org/web/packages/msm/index.html), but I am banging  
a bit my head against the wall.
In general, I do not have a death state and time does not play a  
particular role here (I could say that the i-th therapy is given at time  
i, but this is arbitrary). Later on this may change, though, a time  
sequence may be introduced for the therapies of each patient (varying from  
patient to patient).
Any suggestion is appreciated.
Cheers

Lorenzo


From l_rohner at gmx.ch  Sun Sep  1 16:57:20 2013
From: l_rohner at gmx.ch (laro)
Date: Sun, 1 Sep 2013 07:57:20 -0700 (PDT)
Subject: [R] calculate with different columns from different datasets
In-Reply-To: <1377886156.25988.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1377803996679-4674918.post@n4.nabble.com>
	<1377805769.15234.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1377808674.38886.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1377881575410-4675034.post@n4.nabble.com>
	<1377886156.25988.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1378047440853-4675116.post@n4.nabble.com>

Thank you, it worked!



--
View this message in context: http://r.789695.n4.nabble.com/calculate-with-different-columns-from-different-datasets-tp4674918p4675116.html
Sent from the R help mailing list archive at Nabble.com.


From szehnder at uni-bonn.de  Sun Sep  1 17:09:35 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Sun, 1 Sep 2013 17:09:35 +0200
Subject: [R] How to catch errors regarding the hessian in 'optim'
Message-ID: <EB37670E-8544-4C89-9172-245EB6CC596A@uni-bonn.de>

Dear R-Users and R-Developers,

in a comparison between two different estimation approaches I would like to catch errors from optim regarding the hessian matrix.

I use optim with method = "L-BFGS-B" thereby relying on numerical differentiation for the hessian matrix. I do know, that the estimation approach that uses numerical optimization has sometimes problems with singular hessian matrices and I consider it as one of its disadvantages of this method. To show the frequency of such problems in my simulation study I have to set 'hessian = TRUE' and to collect the errors from optim regarding the hessian.

Now I am a little stucked how I could catch specifically errors from the hessian matrix in 'optim'. I do know that such errors are thrown most certainly from function 'La_solve' in Lapack.c. Does anyone has an idea how I could solve this task (clearly with tryCatch but how to choose only errors for the hessian)?


Best 

Simon
 

From gunter.berton at gene.com  Sun Sep  1 17:30:28 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 1 Sep 2013 08:30:28 -0700
Subject: [R] lapply to multivariate function?
In-Reply-To: <52234FA9.3080703@sapo.pt>
References: <CAJA1VFwdu3G7CyeQb3dvUpXS-NXxNG2SK-y59peC4K33F81eUQ@mail.gmail.com>
	<52234FA9.3080703@sapo.pt>
Message-ID: <CACk-te0ji5M_kou303fb0wuGQ2=TPNWPdUb_9tA_LKdfPfsJ1g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130901/be46750b/attachment.pl>

From gunter.berton at gene.com  Sun Sep  1 17:33:32 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 1 Sep 2013 08:33:32 -0700
Subject: [R] lapply to multivariate function?
In-Reply-To: <CACk-te0ji5M_kou303fb0wuGQ2=TPNWPdUb_9tA_LKdfPfsJ1g@mail.gmail.com>
References: <CAJA1VFwdu3G7CyeQb3dvUpXS-NXxNG2SK-y59peC4K33F81eUQ@mail.gmail.com>
	<52234FA9.3080703@sapo.pt>
	<CACk-te0ji5M_kou303fb0wuGQ2=TPNWPdUb_9tA_LKdfPfsJ1g@mail.gmail.com>
Message-ID: <CACk-te1f=ENZKxc=+DRmA2yV0KDEp_TbhuDJy=R3d9O-Dk=b8w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130901/45bde23e/attachment.pl>

From smartpink111 at yahoo.com  Sun Sep  1 17:34:09 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 1 Sep 2013 08:34:09 -0700 (PDT)
Subject: [R] NMDS QUESTION
In-Reply-To: <CAHh0FZBjrTPD6FX7OwwdKBkxecLhZSd4TRk=wDzpdqoj6m-fWg@mail.gmail.com>
References: <CAHh0FZDurOw4F2smRjChy-g+TCew7rdxyosfrRR5HCWfMEm_SA@mail.gmail.com>	<C4C0296A-1D6C-4395-8B80-90E849CDD72E@xs4all.nl>
	<CAHh0FZBjrTPD6FX7OwwdKBkxecLhZSd4TRk=wDzpdqoj6m-fWg@mail.gmail.com>
Message-ID: <1378049649.79690.YahooMailNeo@web142601.mail.bf1.yahoo.com>



HI,
It is better to use ?dput() to show the reproducible example.? 

dput(korma)
structure(list(T = c(0L, 0L, 1L, 1L, 0L, 1L), C = c(0L, 1L, 1L, 
0L, 0L, 0L), M = c(0L, 0L, 0L, 1L, 0L, 1L), B = c(1L, 0L, 1L, 
1L, 1L, 1L)), .Names = c("T", "C", "M", "B"), class = "data.frame", row.names = c("1", 
"2", "3", "4", "5", "6"))


korma<- 

structure(list(T = c(0L, 0L, 1L, 1L, 0L, 1L), C = c(0L, 1L, 1L, 
0L, 0L, 0L), M = c(0L, 0L, 0L, 1L, 0L, 1L), B = c(1L, 0L, 1L, 
1L, 1L, 1L)), .Names = c("T", "C", "M", "B"), class = "data.frame", row.names = c("1", 
"2", "3", "4", "5", "6"))
korma.dist<- dist(korma)

Assuming that ?isoMDS() is from library(MASS)

library(MASS)
isoMDS(korma.dist)
#Error in isoMDS(korma.dist) : 
?# zero or negative distance between objects 1 and 5

?korma.dist
???????? 1??????? 2??????? 3??????? 4??????? 5
#2 1.414214??????????????????????????????????? 
#3 1.414214 1.414214?????????????????????????? 
#4 1.414214 2.000000 1.414214????????????????? 
#5 0.000000 1.414214 1.414214 1.414214???????? 
#6 1.414214 2.000000 1.414214 0.000000 1.414214 ###0 distance.

#changing some values with 0 distance to?

?korma.dist[4]<- 1.854
?korma.dist[14]<- 1.854




korma.MDS<- isoMDS(korma.dist) #works
#initial? value 21.518932 
#iter?? 5 value 15.443139
#iter? 10 value 14.291766
#final? value 13.701871 #converged

So, it would be better to do:


korma.dist<- dist(unique(korma))
?korma.dist
#???????? 1??????? 2??????? 3
#2 1.414214????????????????? 
#3 1.414214 1.414214???????? 
#4 1.414214 2.000000 1.414214

korma.MDS<- isoMDS(korma.dist) #works
#initial? value 4.736717 
#iter?? 5 value 0.140638
#iter?? 5 value 0.000000
#iter?? 5 value 0.000000
#final? value 0.000000 
#converged
A.K.



_______________________________
From: Simona Augyte <simona.augyte at uconn.edu>
To: Berend Hasselman <bhh at xs4all.nl>; smartpink111 at yahoo.com 
Cc: r-help at r-project.org 
Sent: Sunday, September 1, 2013 9:34 AM
Subject: Re: [R] NMDS QUESTION



Ok, thanks, that helps.?

What about running the same code on a bit of a different set of data, ex.;
korma<- read.csv(text="
GR ?TCMB
10001
20100
31101
41011
50001
61011...
",sep="",row.names=1,header=TRUE)


str(korma)
dist(korma)
korma.dist<- dist(korma)
?korma.mds <- isoMDS(korma.dist)
#Error in isoMDS(korma.dist) : ? zero or negative distance between objects 1 and 5
# What do I need to do to my data to avoid the error message?





On Sun, Sep 1, 2013 at 3:03 AM, Berend Hasselman <bhh at xs4all.nl> wrote:


>On 01-09-2013, at 00:30, Simona Augyte <simona.augyte at uconn.edu> wrote:
>
>> I'm trying to run a very simple non-metric multidimensional scaling code on
>> a 8x5 character matrix.
>> gr T C M B
>> arcor 6 4 6 5
>> corfo 24 21 23 24
>> corma 25 15 26 17
>> crust 3 2 6 5
>> fil 15 12 15 15
>> fol 11 9 6 8
>> leat 10 11 13 13
>> seag 2 2 2 2
>>
>> My code is as follows;
>> coma<-read.csv("coma.csv",header=TRUE)
>> coma.x<-as.matrix(coma)
>> coma.dist <- dist(coma.x) # right here I get a warning message -> In
>> dist(coma.x) : NAs introduced by coercion
>>
>> WHAT DOES THAT MEAN??? the table has values and there are not NAs. Could
>> this be a by product of the way I inserted the data?
>>
>
>Yes.
>Your table contains characters and not numbers.
>
>Tell read.csv that the first column contains row names (assuming that that is indeed the case).
>
>coma<- read.csv(text="
>
>gr T C M B
>arcor 6 4 6 5
>corfo 24 21 23 24
>corma 25 15 26 17
>crust 3 2 6 5
>fil 15 12 15 15
>fol 11 9 6 8
>leat 10 11 13 13
>seag 2 2 2 2
>",sep="",row.names=1,header=TRUE)
>
>coma
>str(coma)
>dist(coma)
>
>Berend
>
>
>
>> Please help.
>>
>> --
>>
>> Simona Augyte, MS
>> PhD student
>> Ecology and Evolutionary Biology
>> University of Connecticut
>> cell 707-832-7007
>>
>
>> ? ? ? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


-- 

Simona Augyte, MS
PhD student
Ecology and Evolutionary Biology
University of Connecticut
cell 707-832-7007


From ignacio82 at gmail.com  Sun Sep  1 18:40:23 2013
From: ignacio82 at gmail.com (Ignacio Martinez)
Date: Sun, 1 Sep 2013 12:40:23 -0400
Subject: [R] lapply to multivariate function?
In-Reply-To: <CACk-te1f=ENZKxc=+DRmA2yV0KDEp_TbhuDJy=R3d9O-Dk=b8w@mail.gmail.com>
References: <CAJA1VFwdu3G7CyeQb3dvUpXS-NXxNG2SK-y59peC4K33F81eUQ@mail.gmail.com>
	<52234FA9.3080703@sapo.pt>
	<CACk-te0ji5M_kou303fb0wuGQ2=TPNWPdUb_9tA_LKdfPfsJ1g@mail.gmail.com>
	<CACk-te1f=ENZKxc=+DRmA2yV0KDEp_TbhuDJy=R3d9O-Dk=b8w@mail.gmail.com>
Message-ID: <CAJA1VFzXV-yRp4UBevi65SpooTAaojGu5Oj2oFJ3abDV2S-SLg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130901/3dcc8d3b/attachment.pl>

From rguy at 123mail.org  Sun Sep  1 18:46:15 2013
From: rguy at 123mail.org (Rguy)
Date: Sun, 1 Sep 2013 17:46:15 +0100
Subject: [R] remove failure
Message-ID: <CAEorq2N8JFx7GvRND1Vjk8=95wJ_63VhgmUuMD7TyH_TnM20Jg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130901/b0e3a780/attachment.pl>

From hh132 at leicester.ac.uk  Sun Sep  1 18:35:31 2013
From: hh132 at leicester.ac.uk (Haghpanahan, Houra)
Date: Sun, 1 Sep 2013 17:35:31 +0100
Subject: [R] help
Message-ID: <008E7D31724B9840842441597DFED96A0306AC42FA29@EXC-MBX2.cfs.le.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130901/a31cd8ab/attachment.pl>

From prakash.dev-kumar at hp.com  Sun Sep  1 12:29:05 2013
From: prakash.dev-kumar at hp.com (Balakrishnan, Prakash Devkumar (Global Analytics))
Date: Sun, 1 Sep 2013 10:29:05 +0000
Subject: [R] Issue with R libraries
In-Reply-To: <4184CD4AE3F.0000009Djrkrideau@inbox.com>
References: <1377945337592-4675074.post@n4.nabble.com>
	<4184CD4AE3F.0000009Djrkrideau@inbox.com>
Message-ID: <73B6EBF346C57B4398A17213D9FDB5497CFB20E9@G9W0727.americas.hpqcorp.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130901/1eaa81bf/attachment.pl>

From prakash.dev-kumar at hp.com  Sun Sep  1 12:29:30 2013
From: prakash.dev-kumar at hp.com (Balakrishnan, Prakash Devkumar (Global Analytics))
Date: Sun, 1 Sep 2013 10:29:30 +0000
Subject: [R] Issue with R libraries
In-Reply-To: <CAAcyNCwi3_orgfT9QdSANcKc2pZjD=xaq4jeTLeou4O1PoyprQ@mail.gmail.com>
References: <1377945337592-4675074.post@n4.nabble.com>
	<CAAcyNCwi3_orgfT9QdSANcKc2pZjD=xaq4jeTLeou4O1PoyprQ@mail.gmail.com>
Message-ID: <73B6EBF346C57B4398A17213D9FDB5497CFB20F3@G9W0727.americas.hpqcorp.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130901/bd50defd/attachment.pl>

From simona.augyte at uconn.edu  Sun Sep  1 15:34:11 2013
From: simona.augyte at uconn.edu (Simona Augyte)
Date: Sun, 1 Sep 2013 09:34:11 -0400
Subject: [R] NMDS QUESTION
In-Reply-To: <C4C0296A-1D6C-4395-8B80-90E849CDD72E@xs4all.nl>
References: <CAHh0FZDurOw4F2smRjChy-g+TCew7rdxyosfrRR5HCWfMEm_SA@mail.gmail.com>
	<C4C0296A-1D6C-4395-8B80-90E849CDD72E@xs4all.nl>
Message-ID: <CAHh0FZBjrTPD6FX7OwwdKBkxecLhZSd4TRk=wDzpdqoj6m-fWg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130901/b8908351/attachment.pl>

From smartpink111 at yahoo.com  Sun Sep  1 19:13:35 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 1 Sep 2013 10:13:35 -0700 (PDT)
Subject: [R] help
In-Reply-To: <008E7D31724B9840842441597DFED96A0306AC42FA29@EXC-MBX2.cfs.le.ac.uk>
References: <008E7D31724B9840842441597DFED96A0306AC42FA29@EXC-MBX2.cfs.le.ac.uk>
Message-ID: <1378055615.63846.YahooMailNeo@web142606.mail.bf1.yahoo.com>



HI,

It is better to provide a reproducible example.? From the nature of the error, it looks like the problem is similar to the one in the link below:

http://r.789695.n4.nabble.com/mlogit-error-td4663601.html

A.K.


----- Original Message -----
From: "Haghpanahan, Houra" <hh132 at leicester.ac.uk>
To: "'r-help at r-project.org'" <r-help at r-project.org>
Cc: 
Sent: Sunday, September 1, 2013 12:35 PM
Subject: [R] help

Hi there,

I am trying to apply mlogit for a panel data set. I have 22 individuals (countries), for a 228 points in time domain, and 8 variables. I set my data in Excel in long format (I think!). I am trying to write a command to prepare data for mlogit by applying the following code.

mdat<- mlogit.data (dat ,choice = "y", id="id", shape = "long", alt.var = "y")
But I get the error below;

Error in `row.names<-.data.frame`(`*tmp*`, value = c("1.0", "1.0", "1.0",? :???duplicate 'row.names' are not allowed
In addition: Warning message:
non-unique values when setting 'row.names': '1.0', '100.1', '1000.0', '1001.1', '1002.0', '1003.0', '1004.0', '1005.0', '1006.0', '1007.0', '1008.0', '1009.0', '1010.0', '1011.1', '1012.2', '1013.1', '1015.0', '1016.0', '102.1', '1020.0', '1021.1', '1023.1', '1024.1', '1025.1', '1026.2', '1027.1', '103.1', '1030.1', '1034.1', '1036.0', '1037.1', '1038.0', '1039.0', '1040.1', '1042.2', '1043.1', '1044.2', '1045.1', '1046.1', '1048.1', '1049.0', '105.1', '1050.0', '1051.0', '1053.0', '1054.1', '1055.0', '1056.0', '1057.1', '1059.0', '106.1', '1061.1', '1062.1', '1063.0', '1064.0', '1065.0', '1066.0', '1067.0', '1068.0', '1069.0', '107.1', '1070.0', '1071.0', '1072.0', '1073.0', '1074.0', '1075.0', '1076.0', '1077.0', '1078.0', '1079.1', '1080.0', '1081.0', '1082.0', '1083.0', '1085.0', '1086.0', '1087.0', '1088.0', '1089.0', '109.1', '1090.0', '1091.0', '1092.0', '1093.0', '1095.0', '1096.0', '1097.1', '1098.2', '1099.1', '11.1', '110.0', '1101.1',
 '1102.0', '1103.0', '1104.1'!
, '1105.0', [... truncated]

I would say 'y' is an independent variable that takes 3 states i.e. 0,1,2.

By the way, when I run the following command, it seems every thin is fine without any error but in 'mdat' data,? 'chid' and 'alt' would not appear! I think there is something wrong with that.
mdat <- mlogit.data(dat, id="id", choice="y",
shape = "long", varying = NULL, alt.levels=c("0", "1", "2"),sep = "")

Any help would be appreciated in advance.
Regards,
Houra


??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From l_rohner at gmx.ch  Sun Sep  1 20:34:44 2013
From: l_rohner at gmx.ch (laro)
Date: Sun, 1 Sep 2013 11:34:44 -0700 (PDT)
Subject: [R] Time lag Regression and Standard Error
Message-ID: <1378060484604-4675130.post@n4.nabble.com>

Hi R Team

I've got the following problem

I'd like to run a time series regression of the following form

Regression1:

At = ? + ?1 * Bt + ?2 * Bt-1 + ?3 [(Bt-2 + Bt-3 + Bt-4)/3] + ?t

The B's are the input values and the A's are the output values, the
subscript stands for the lag.
The real Beta of this regression is ?real = ?1 + ?2 + ?3

First: How can I run the regression without manually laging the B's?
And second: I need the standard error for ?real. How can I calculate it with
the information given from the lm(Regression1)? (I read something about the
deltamethod?)

Thank you a lot!
Kind regards




--
View this message in context: http://r.789695.n4.nabble.com/Time-lag-Regression-and-Standard-Error-tp4675130.html
Sent from the R help mailing list archive at Nabble.com.


From ruipbarradas at sapo.pt  Sun Sep  1 21:00:03 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 01 Sep 2013 20:00:03 +0100
Subject: [R] lapply to multivariate function?
In-Reply-To: <CAJA1VFzXV-yRp4UBevi65SpooTAaojGu5Oj2oFJ3abDV2S-SLg@mail.gmail.com>
References: <CAJA1VFwdu3G7CyeQb3dvUpXS-NXxNG2SK-y59peC4K33F81eUQ@mail.gmail.com>
	<52234FA9.3080703@sapo.pt>
	<CACk-te0ji5M_kou303fb0wuGQ2=TPNWPdUb_9tA_LKdfPfsJ1g@mail.gmail.com>
	<CACk-te1f=ENZKxc=+DRmA2yV0KDEp_TbhuDJy=R3d9O-Dk=b8w@mail.gmail.com>
	<CAJA1VFzXV-yRp4UBevi65SpooTAaojGu5Oj2oFJ3abDV2S-SLg@mail.gmail.com>
Message-ID: <52238EB3.2020300@sapo.pt>

Hello,

Your example doesn't really run, but for what I've seen, if your second 
data frame is named dat2, something along the lines of

n <- nrow(dat2)
res <- list("vector", n)
for(i in 1:n){
	res[[i]] <- with(dat2, DataVideoActionT(anon_ID[i], Time1[i], TimeM[i], 
TimeL[i]))
}

do.call(rbind, res)


Rui Barradas

Em 01-09-2013 17:40, Ignacio Martinez escreveu:
> I hope this reproduceble example helps understand what I'm trying to do.
>
> This is the function:
>
> # Make Data Frame for video actions between given times for user X
> DataVideoActionT <- function (userX, Time1, Time2, Time3){
>    #Get data for user X
>    videoActionsX<-subset(videoLectureActions, username==userX)
>    #Time1 = before first attempt
>    videoActionsX_T1<-subset(videoActionsX, eventTimestamp<Time1)
>    #Time2 = before best attemp
>    videoActionsX_T2<-subset(videoActionsX, eventTimestamp<Time2 &
> eventTimestamp>Time1)
>    #Time3= before last attemp
>    videoActionsX_T3<-subset(videoActionsX, eventTimestamp<Time3 &
> eventTimestamp>Time1)
>
>    error1 = sum(videoActionsX_T1$type==" error ")
>    pause1 = sum(videoActionsX_T1$type==" pause ")
>    play1 = sum(videoActionsX_T1$type==" play ")
>    ratechange1 = sum(videoActionsX_T1$type==" ratechange ")
>    seeked1 = sum(videoActionsX_T1$type==" seeked ")
>    stalled1 = sum(videoActionsX_T1$type==" stalled ")
>
>    error2 = sum(videoActionsX_T2$type==" error ")
>    pause2 = sum(videoActionsX_T2$type==" pause ")
>    play2 = sum(videoActionsX_T2$type==" play ")
>    ratechange2 = sum(videoActionsX_T2$type==" ratechange ")
>    seeked2 = sum(videoActionsX_T2$type==" seeked ")
>    stalled2 = sum(videoActionsX_T2$type==" stalled ")
>
>    error3 = sum(videoActionsX_T3$type==" error ")
>    pause3 = sum(videoActionsX_T3$type==" pause ")
>    play3 = sum(videoActionsX_T3$type==" play ")
>    ratechange3 = sum(videoActionsX_T3$type==" ratechange ")
>    seeked3 = sum(videoActionsX_T3$type==" seeked ")
>    stalled3 = sum(videoActionsX_T3$type==" stalled ")
>
>    data<-data.frame(anon_ID=userX,
>                     error1 = error1,
>                     pause1 = pause1,
>                     play1 = play1,
>                     ratechange1 = ratechange1,
>                     seeked1=seeked1,
>                     stalled1=stalled1,
>                     error2 = error2,
>                     pause2 = pause2,
>                     play2 = play2,
>                     ratechange2 = ratechange2,
>                     seeked2 =seeked2,
>                     stalled2 = stalled2,
>                     error3 = error3,
>                     pause3 = pause3,
>                     play3 = play3,
>                     ratechange3 = ratechange3,
>                     seeked3 = seeked3,
>                     stalled3 = stalled3)
>    return(data)
> }
>
> This is the videoActionsX  dataframe:
>
> structure(list(username = c("exampleID1", "exampleID1", "exampleID1",
>                              "exampleID2", "exampleID2", "exampleID2",
> "exampleID3", "exampleID3",
>                              "exampleID3", "exampleID3"), currentTime =
> c("103.701247", "103.701247",
>
>   "107.543877", "107.543877", "116.456507", "116.456507", "119.987188",
>
>   "177.816693", "183.417124", "183.417124"), playbackRate = c("null",
>
>                                                           "null", "null",
> "null", "null", "null", "null", "null", "null",
>
>                                                           "null"), pause =
> c("true", "false", "true", "false", "true",
>
>
> "false", "true", "false", "true", "false"), error = c("null",
>
>
>                                                        "null", "null",
> "null", "null", "null", "null", "null", "null",
>
>
>                                                        "null"), networkState
> = c("1", "1", "1", "1", "1", "1", "1",
>
>
>
>      "1", "1", "1"), readyState = c("4", "4", "4", "4", "4", "4",
>
>
>
>                                     "4", "4", "4", "4"), lectureID =
> c("exampleLectureID1", "exampleLectureID1",
>
>
>
>
> "exampleLectureID1", "exampleLectureID1", "exampleLectureID1",
>
>
>
>
> "exampleLectureID1", "exampleLectureID1", "exampleLectureID1",
>
>
>
>
> "exampleLectureID1", "exampleLectureID1"), eventTimestamp = c("2013-03-04
> 18:51:49",
>
>
>
>
>                                                          "2013-03-04
> 18:51:50", "2013-03-04 18:51:54", "2013-03-04 18:51:56",
>
>
>
>
>                                                          "2013-03-04
> 18:52:05", "2013-03-04 18:52:07", "2013-03-04 18:52:11",
>
>
>
>
>                                                          "2013-03-04
> 18:59:17", "2013-03-04 18:59:23", "2013-03-04 18:59:31"
>
>
>
>                                                                        ),
> initTimestamp = c("2013-03-04 18:44:15", "2013-03-04 18:44:15",
>
>
>
>
>                 "2013-03-04 18:44:15", "2013-03-04 18:44:15", "2013-03-04
> 18:44:15",
>
>
>
>
>                 "2013-03-04 18:44:15", "2013-03-04 18:44:15", "2013-03-04
> 18:44:15",
>
>
>
>
>                 "2013-03-04 18:44:15", "2013-03-04 18:44:15"), type = c("
> pause ",
>
>
>
>
>                                                                         "
> play ", " pause ", " play ", " pause ", " play ", " pause ",
>
>
>
>
>                                                                         "
> play ", " pause ", " play "), prevTime = c("103.701247 ", "103.701247 ",
>
>
>
>
>
>                                          "107.543877 ", "107.543877 ",
> "116.456507 ", "116.456507 ", "119.987188 ",
>
>
>
>
>
>                                          "177.816693 ", "183.417124 ",
> "183.417124 ")), .Names = c("username",
>
>
>
>
>
>
>                        "currentTime", "playbackRate", "pause", "error",
> "networkState",
>
>
>
>
>
>
>                        "readyState", "lectureID", "eventTimestamp",
> "initTimestamp",
>
>
>
>
>
>
>                        "type", "prevTime"), row.names = c(1L, 2L, 5L, 6L,
> 17L, 21L,
>
>
>
>
>
>
>                                                           28L, 936L, 957L,
> 988L), class = "data.frame")
>
>
>
> But with over 2000 observation.
>
> And this is the other data frame
>
> structure(list(anon_ID = c("exampleID1", "exampleID2", "exampleID3" ),
> maxGrade = c(10, 5, 10), firstGrade = c(10, 5, 8), lastGrade = c(10,
> 5, 10), total_submissions = c(1L, 1L, 3L), Time1 =
> structure(c(1361993741, 1362356090, 1362357401), class = c("POSIXct",
> "POSIXt"), tzone = ""), TimeM = structure(c(1361993741, 1362356090,
> 1362492744), class = c("POSIXct", "POSIXt"), tzone = ""), TimeL =
> structure(c(1361993741, 1362356090, 1362492744), class = c("POSIXct",
> "POSIXt"), tzone = "")), .Names = c("anon_ID", "maxGrade",
> "firstGrade", "lastGrade", "total_submissions", "Time1", "TimeM",
> "TimeL"), row.names = c(NA, 3L), class = "data.frame")
>
>
> But with a lot more observations.
>
>
> What I want to do is to call  function (userX, Time1, Time2, Time3)
> for all the user in the second data frame where Time1=Time1,
> Time2=TimeM, Time3=TimeL
>
>
> I hope that is more clear.
>
>
> Thanks a lot for all the help!
>
>
>
> On Sun, Sep 1, 2013 at 11:33 AM, Bert Gunter <gunter.berton at gene.com> wrote:
>
>> Oh, another possibility is ?mapply, which I should have pointed out in my
>> previous reply. Sorry.
>>
>> -- Bert
>>
>>
>> On Sun, Sep 1, 2013 at 8:30 AM, Bert Gunter <bgunter at gene.com> wrote:
>>
>>> Rui et.al.:
>>>
>>> But apply will not work if the data frame has columns of different
>>> classes/types, as appears to be the case here. Viz, from ?apply:
>>>
>>> "If X is not an array but an object of a class with a non-null dim<http://127.0.0.1:12824/help/library/base/help/dim>
>>>   value (such as a data frame),apply attempts to coerce it to an array via
>>>   as.matrix if it is two-dimensional (e.g., a data frame) or via as.array.
>>> "
>>>
>>> Simply looping by rows (via for() ) appears to be the simplest and
>>> probably fastest solution. There are other ways via tapply() and friends,
>>> but these are also essentially loops and are likely to incur some
>>> additional overhead.
>>>
>>> All assuming I understand what the OP has requested, of course.
>>>
>>> Cheers,
>>>
>>> Bert
>>>
>>>
>>> On Sun, Sep 1, 2013 at 7:31 AM, Rui Barradas <ruipbarradas at sapo.pt>wrote:
>>>
>>>> Hello,
>>>>
>>>> Maybe you need apply, not lapply. It seems you want to apply() a
>>>> function to the first dimension of your data.frame, something like
>>>>
>>>> apply(dat, 1, fun)  #apply by rows
>>>>
>>>>
>>>> Hope this helps,
>>>>
>>>> Rui Barradas
>>>>
>>>> Em 01-09-2013 15:00, Ignacio Martinez escreveu:
>>>>
>>>>> I have a Data Frame that contains, between other things, the following
>>>>> fields: userX, Time1, Time2, Time3. The number of observations is 2000.
>>>>>
>>>>> I have a function that has as inputs userX, Time1, Time2, Time3 and
>>>>> return
>>>>> a data frame with 1 observation and 19 variables.
>>>>>
>>>>> I want to apply that function to all the observations of the first data
>>>>> frame to make a new data frame with 2000 observations and 19 variables.
>>>>>
>>>>> I thought about using lapply, but if I understand correctly, it only
>>>>> takes
>>>>> one variable.
>>>>>
>>>>> Can somebody point me in the right direction?
>>>>>
>>>>> Thanks!
>>>>>
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________**________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>> PLEASE do read the posting guide http://www.R-project.org/**
>>>>> posting-guide.html <http://www.R-project.org/posting-guide.html>
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>
>>>> ______________________________**________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>>>> PLEASE do read the posting guide http://www.R-project.org/**
>>>> posting-guide.html <http://www.R-project.org/posting-guide.html>
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>>
>>> --
>>>
>>> Bert Gunter
>>> Genentech Nonclinical Biostatistics
>>>
>>> Internal Contact Info:
>>> Phone: 467-7374
>>> Website:
>>>
>>> http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm
>>>
>>>
>>
>>
>>
>> --
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>>
>> Internal Contact Info:
>> Phone: 467-7374
>> Website:
>>
>> http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm
>>
>>
>


From murdoch.duncan at gmail.com  Sun Sep  1 21:30:33 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 01 Sep 2013 15:30:33 -0400
Subject: [R] remove failure
In-Reply-To: <CAEorq2N8JFx7GvRND1Vjk8=95wJ_63VhgmUuMD7TyH_TnM20Jg@mail.gmail.com>
References: <CAEorq2N8JFx7GvRND1Vjk8=95wJ_63VhgmUuMD7TyH_TnM20Jg@mail.gmail.com>
Message-ID: <522395D9.90402@gmail.com>

On 13-09-01 12:46 PM, Rguy wrote:
> Platform: Windows 7, "R version 3.0.1 Patched (2013-06-19 r62992)"
>
> I have been running the following code (part of a larger program) for many
> months without problem:
>
>   if ((gname %in% ls(envir=.GlobalEnv)) & !is.null(cols)) {
>   if (!identical(cols, names(get(gname, envir=.GlobalEnv)))) remove(gname,
> envir=.GlobalEnv)
> }
>
> For some reason today I started to get the following error:
>
> Error in remove(gname, envir = .GlobalEnv) :
>    (converted from warning) object 'gname' not found

That tries to remove gname, not the variable whose name is stored in 
gname.  Use list=gname in the call to get what you want.

Duncan Murdoch

>
> The error is illogical as the call to remove can only occur if gname is in
> the global environment. Furthermore, when I go into the debugger and run
> gname %in% ls(envir=.GlobalEnv) manually the expression returns TRUE. When
> I manually inspect the output of ls(envir=.GlobalEnv) I find that the value
> of gname is, indeed, present.
>
> I have tried re-booting my machine, but the error recurs even after a
> re-boot.
>
> Any insight on this error would be appreciated.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From noahsilverman at ucla.edu  Sun Sep  1 22:40:52 2013
From: noahsilverman at ucla.edu (Noah Silverman)
Date: Sun, 1 Sep 2013 13:40:52 -0700
Subject: [R] Trouble with Slidify and Latex
Message-ID: <522D051E-36E3-4778-A7F2-6175B39DF3B4@ucla.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130901/fa62c957/attachment.pl>

From robert.b.lynch at gmail.com  Sun Sep  1 22:41:33 2013
From: robert.b.lynch at gmail.com (Robert Lynch)
Date: Sun, 1 Sep 2013 13:41:33 -0700
Subject: [R] string processing(regular expressions)
Message-ID: <CACYeG1ihmLHAZRZPKR5CfSQzaY-kr44UWcDxTNDVmDR_E+XGYQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130901/e29a6381/attachment.pl>

From tyler_rinker at hotmail.com  Sun Sep  1 22:49:53 2013
From: tyler_rinker at hotmail.com (Tyler Rinker)
Date: Sun, 1 Sep 2013 16:49:53 -0400
Subject: [R] Trouble with Slidify and Latex
In-Reply-To: <522D051E-36E3-4778-A7F2-6175B39DF3B4@ucla.edu>
References: <522D051E-36E3-4778-A7F2-6175B39DF3B4@ucla.edu>
Message-ID: <BLU170-W219D6469C918CB8CCBB04EF370@phx.gbl>

Is there a reason not to contact the package author directly and ask him? ?slidify isn't on CRAN so likely you got it from GitHub which is where you discuss package problems, particularly, a beta package's problems. ?Here is the link to the issues page for slidify:?<a href="https&#58;&#47;&#47;github.com&#47;ramnathv&#47;slidify&#47;issues&#63;state&#61;open" target="_blank" class="newlyinsertedlink">https&#58;&#47;&#47;github.com&#47;ramnathv&#47;slidify&#47;issues&#63;state&#61;open</a>

Tyler Rinker?


----------------------------------------
> From: noahsilverman at ucla.edu
> Date: Sun, 1 Sep 2013 13:40:52 -0700
> To: r-help at r-project.org
> Subject: [R] Trouble with Slidify and Latex
>
> Hi,
>
> (Re-submitting as the original doesn't look like it made it to the list.)
>
> Just starting to play around with the awesome Slidify package.
>
> For some reason, I can't get it to render any Latex in the presentation. Have reviews all the docs and think I'm doing things correctly. Is there something possibly broken with my installation, or am I misunderstanding the markdown syntax?
>
> I have, on a single slide:
>
> Test $A = 1+2$ and some text after
>
> What I see in the Presentation:
>
>
> Test \(A = 1+2\) and some text after
>
>
> Note: This is literally a "slash" followed by a "parenthesis" in the final HTML slide.
>
>
> Any ideas on what's wrong here?
>
> Thanks.
>
> --
> Noah Silverman, C.Phil
> UCLA Department of Statistics
> 8117 Math Sciences Building
> Los Angeles, CA 90095
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code. 		 	   		  

From ruipbarradas at sapo.pt  Sun Sep  1 22:54:30 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 01 Sep 2013 21:54:30 +0100
Subject: [R] string processing(regular expressions)
In-Reply-To: <CACYeG1ihmLHAZRZPKR5CfSQzaY-kr44UWcDxTNDVmDR_E+XGYQ@mail.gmail.com>
References: <CACYeG1ihmLHAZRZPKR5CfSQzaY-kr44UWcDxTNDVmDR_E+XGYQ@mail.gmail.com>
Message-ID: <5223A986.7090306@sapo.pt>

Hello,

Try the following.

gsub("^0+", "", as.character(nCourse))


Hope this helps,

Rui Barradas

Em 01-09-2013 21:41, Robert Lynch escreveu:
> I have a variable that is course #
> nCourse <-
> as.factor(c("002A","002B","002C","007A","007B","007C","101","118A","118B","118C"))
>
> And I would like to get rid of the leading zeros, and have the following
> set
> ("2A","2B","2C","7A","7B","7C","101","118A","118B","118C") to paste()
> together with the department, "B","P","C" (bio, phys, & chem etc)
>
> I am stuck trying to figure out regular expressions, they are new to me.
>
> Thank You very much
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Sun Sep  1 23:18:29 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 1 Sep 2013 14:18:29 -0700 (PDT)
Subject: [R] string processing(regular expressions)
In-Reply-To: <CACYeG1ihmLHAZRZPKR5CfSQzaY-kr44UWcDxTNDVmDR_E+XGYQ@mail.gmail.com>
References: <CACYeG1ihmLHAZRZPKR5CfSQzaY-kr44UWcDxTNDVmDR_E+XGYQ@mail.gmail.com>
Message-ID: <1378070309.78450.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
?levels(nCourse)<-gsub("^0+","",levels(nCourse))
?nCourse
# [1] 2A?? 2B?? 2C?? 7A?? 7B?? 7C?? 101? 118A 118B 118C
#Levels: 2A 2B 2C 7A 7B 7C 101 118A 118B 118C

#The second part is not very clear.
res<-setNames(data.frame(lapply(c("B","P","C"),function(x) paste0(levels(nCourse),x)),stringsAsFactors=FALSE),c("B","P","C"))
head(res)
#??? B?? P?? C
#1 2AB 2AP 2AC
#2 2BB 2BP 2BC
#3 2CB 2CP 2CC
#4 7AB 7AP 7AC
#5 7BB 7BP 7BC
#6 7CB 7CP 7CC
A.K.




----- Original Message -----
From: Robert Lynch <robert.b.lynch at gmail.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Sunday, September 1, 2013 4:41 PM
Subject: [R] string processing(regular expressions)

I have a variable that is course #
nCourse <-
as.factor(c("002A","002B","002C","007A","007B","007C","101","118A","118B","118C"))

And I would like to get rid of the leading zeros, and have the following
set
("2A","2B","2C","7A","7B","7C","101","118A","118B","118C") to paste()
together with the department, "B","P","C" (bio, phys, & chem etc)

I am stuck trying to figure out regular expressions, they are new to me.

Thank You very much

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ignacio82 at gmail.com  Sun Sep  1 23:21:32 2013
From: ignacio82 at gmail.com (Ignacio Martinez)
Date: Sun, 1 Sep 2013 17:21:32 -0400
Subject: [R] lapply to multivariate function?
In-Reply-To: <52238EB3.2020300@sapo.pt>
References: <CAJA1VFwdu3G7CyeQb3dvUpXS-NXxNG2SK-y59peC4K33F81eUQ@mail.gmail.com>
	<52234FA9.3080703@sapo.pt>
	<CACk-te0ji5M_kou303fb0wuGQ2=TPNWPdUb_9tA_LKdfPfsJ1g@mail.gmail.com>
	<CACk-te1f=ENZKxc=+DRmA2yV0KDEp_TbhuDJy=R3d9O-Dk=b8w@mail.gmail.com>
	<CAJA1VFzXV-yRp4UBevi65SpooTAaojGu5Oj2oFJ3abDV2S-SLg@mail.gmail.com>
	<52238EB3.2020300@sapo.pt>
Message-ID: <CAJA1VFyMq_+Gd-YusgV9DOhViwx+veJVb9cv+GnP__dn+uiOTw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130901/bbc441f6/attachment.pl>

From smartpink111 at yahoo.com  Sun Sep  1 23:45:20 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 1 Sep 2013 14:45:20 -0700 (PDT)
Subject: [R] Intersect 2 lists+bring extra columns
Message-ID: <1378071920.11284.YahooMailNeo@web142603.mail.bf1.yahoo.com>

HI,

If I understand it correctly:

fruit<- read.csv("example.csv",header=TRUE,stringsAsFactors=FALSE,sep="\t")
?res<-merge(fruit["reference"],fruit[,-1],by.x="reference",by.y="list")
?res
#?? reference information
#1 grapefruit??????? pink
#2????? lemon????? yellow
#3?????? pear?????? green

If the dataset have duplicate entries in the second and third columns.? For example:
?fruit1<- fruit
?fruit1[4,2]<- "lemon"
fruit1[4,3]<- "yellow"
?res2<- merge(fruit1["reference"],fruit1[,-1],by.x="reference",by.y="list")
res2
#?? reference information
#1 grapefruit??????? pink
#2????? lemon????? yellow
#3????? lemon????? yellow
#4?????? pear?????? green

unique(res2)
#?? reference information
#1 grapefruit??????? pink
#2????? lemon????? yellow
#4?????? pear?????? green
A.K.



Hi everyone, 

I am pretty new to R, so be patient. 

I am trying to intersect 2 columns and in the rows that 
intersect, I want information from the 3rd column to be brought with it.
 I think it will be easier to explain with an example example.csv. 

In my example, I have a reference list of fruit (first column), 
and my fruit of interest (second column), and then in the third column, I
 have color information about the fruit of interest in the second 
column. 

Currently to find the intersection between column 1 and 2, I use 
>fruit<-read.csv("//Users//J//Desktop//example.csv", header=TRUE) 
>output<-intersect(fruit[,1],fruit[,2]) 
>write.table(data.frame(fruit),"output.xls", col.names=TRUE, row.names=FALSE) 

However, it would save me a lot of time if I could have the 
color information from column 3 be saved with the overlap. I normally 
have reference list of several hundred and lists of interest in the 
several thousand, and bringing over the information column would be hard
 manually. 

Is there some sort of If function I could be using? I would 
really like something like If row x, column 2 intersects with row x, 
column 1, then row x column 3 is stored with it. I can think through the
 logic, but not sure how to do it in R. 

Any help would be much appreciated!   



From ruipbarradas at sapo.pt  Sun Sep  1 23:45:46 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 01 Sep 2013 22:45:46 +0100
Subject: [R] lapply to multivariate function?
In-Reply-To: <CAJA1VFyMq_+Gd-YusgV9DOhViwx+veJVb9cv+GnP__dn+uiOTw@mail.gmail.com>
References: <CAJA1VFwdu3G7CyeQb3dvUpXS-NXxNG2SK-y59peC4K33F81eUQ@mail.gmail.com>
	<52234FA9.3080703@sapo.pt>
	<CACk-te0ji5M_kou303fb0wuGQ2=TPNWPdUb_9tA_LKdfPfsJ1g@mail.gmail.com>
	<CACk-te1f=ENZKxc=+DRmA2yV0KDEp_TbhuDJy=R3d9O-Dk=b8w@mail.gmail.com>
	<CAJA1VFzXV-yRp4UBevi65SpooTAaojGu5Oj2oFJ3abDV2S-SLg@mail.gmail.com>
	<52238EB3.2020300@sapo.pt>
	<CAJA1VFyMq_+Gd-YusgV9DOhViwx+veJVb9cv+GnP__dn+uiOTw@mail.gmail.com>
Message-ID: <5223B58A.90706@sapo.pt>

Hello,

I have no experience with packages foreach and doMC.
But I believe that paralel computing only pays if the datasets are 
really large, due to the setup time. Maybe "thousands of observations" 
is not that large.

Rui Barradas

Em 01-09-2013 22:21, Ignacio Martinez escreveu:
> Thanks a lot Rui. Loops make sense to me. I made one modification to your
> code. I have thousands of observation, so I would like to run it in
> parallel. This is my reproducible example:
>
> # Make Data Frame for video actions between given times for user X
> DataVideoActionT <- function (userX, Time1, Time2, Time3){
>    #Get data for user X
>    videoActionsX<-subset(videoLectureActions, username==userX)
>    #Time1 = before first attempt
>    videoActionsX_T1<-subset(videoActionsX, eventTimestamp<Time1)
>    #Time2 = before best attemp
>    videoActionsX_T2<-subset(videoActionsX, eventTimestamp<Time2 &
> eventTimestamp>Time1)
>    #Time3= before last attemp
>    videoActionsX_T3<-subset(videoActionsX, eventTimestamp<Time3 &
> eventTimestamp>Time1)
>
>    error1 = sum(videoActionsX_T1$type==" error ")
>    pause1 = sum(videoActionsX_T1$type==" pause ")
>    play1 = sum(videoActionsX_T1$type==" play ")
>    ratechange1 = sum(videoActionsX_T1$type==" ratechange ")
>    seeked1 = sum(videoActionsX_T1$type==" seeked ")
>    stalled1 = sum(videoActionsX_T1$type==" stalled ")
>
>    error2 = sum(videoActionsX_T2$type==" error ")
>    pause2 = sum(videoActionsX_T2$type==" pause ")
>    play2 = sum(videoActionsX_T2$type==" play ")
>    ratechange2 = sum(videoActionsX_T2$type==" ratechange ")
>    seeked2 = sum(videoActionsX_T2$type==" seeked ")
>    stalled2 = sum(videoActionsX_T2$type==" stalled ")
>
>    error3 = sum(videoActionsX_T3$type==" error ")
>    pause3 = sum(videoActionsX_T3$type==" pause ")
>    play3 = sum(videoActionsX_T3$type==" play ")
>    ratechange3 = sum(videoActionsX_T3$type==" ratechange ")
>    seeked3 = sum(videoActionsX_T3$type==" seeked ")
>    stalled3 = sum(videoActionsX_T3$type==" stalled ")
>
>    data<-data.frame(anon_ID=userX,
>                     error1 = error1,
>                     pause1 = pause1,
>                     play1 = play1,
>                     ratechange1 = ratechange1,
>                     seeked1=seeked1,
>                     stalled1=stalled1,
>                     error2 = error2,
>                     pause2 = pause2,
>                     play2 = play2,
>                     ratechange2 = ratechange2,
>                     seeked2 =seeked2,
>                     stalled2 = stalled2,
>                     error3 = error3,
>                     pause3 = pause3,
>                     play3 = play3,
>                     ratechange3 = ratechange3,
>                     seeked3 = seeked3,
>                     stalled3 = stalled3)
>    return(data)
> }
>
> videoLectureActions<-structure(list(username = c("exampleID1",
> "exampleID1", "exampleID1",
>                                                   "exampleID2",
> "exampleID2", "exampleID2", "exampleID3", "exampleID3",
>                                                   "exampleID3",
> "exampleID3"), currentTime = c("103.701247", "103.701247",
>
>                    "107.543877", "107.543877", "116.456507", "116.456507",
> "119.987188",
>
>                    "177.816693", "183.417124", "183.417124"), playbackRate =
> c("null",
>
>
>    "null", "null", "null", "null", "null", "null", "null", "null",
>
>
>    "null"), pause = c("true", "false", "true", "false", "true",
>
>
>                       "false", "true", "false", "true", "false"), error =
> c("null",
>
>
>
>   "null", "null", "null", "null", "null", "null", "null", "null",
>
>
>
>   "null"), networkState = c("1", "1", "1", "1", "1", "1", "1",
>
>
>
>                           "1", "1", "1"), readyState = c("4", "4", "4", "4",
> "4", "4",
>
>
>
>                                                          "4", "4", "4",
> "4"), lectureID = c("exampleLectureID1", "exampleLectureID1",
>
>
>
>
>                 "exampleLectureID1", "exampleLectureID1",
> "exampleLectureID1",
>
>
>
>
>                 "exampleLectureID1", "exampleLectureID1",
> "exampleLectureID1",
>
>
>
>
>                 "exampleLectureID1", "exampleLectureID1"), eventTimestamp =
> c("2013-03-04 18:51:49",
>
>
>
>
>
>   "2013-03-04 18:51:50", "2013-03-04 18:51:54", "2013-03-04 18:51:56",
>
>
>
>
>
>   "2013-03-04 18:52:05", "2013-03-04 18:52:07", "2013-03-04 18:52:11",
>
>
>
>
>
>   "2013-03-04 18:59:17", "2013-03-04 18:59:23", "2013-03-04 18:59:31"
>
>
>
>
>                 ), initTimestamp = c("2013-03-04 18:44:15", "2013-03-04
> 18:44:15",
>
>
>
>
>                                      "2013-03-04 18:44:15", "2013-03-04
> 18:44:15", "2013-03-04 18:44:15",
>
>
>
>
>                                      "2013-03-04 18:44:15", "2013-03-04
> 18:44:15", "2013-03-04 18:44:15",
>
>
>
>
>                                      "2013-03-04 18:44:15", "2013-03-04
> 18:44:15"), type = c(" pause ",
>
>
>
>
>
>                  " play ", " pause ", " play ", " pause ", " play ", " pause
> ",
>
>
>
>
>
>                  " play ", " pause ", " play "), prevTime = c("103.701247 ",
> "103.701247 ",
>
>
>
>
>
>                                                               "107.543877 ",
> "107.543877 ", "116.456507 ", "116.456507 ", "119.987188 ",
>
>
>
>
>
>                                                               "177.816693 ",
> "183.417124 ", "183.417124 ")), .Names = c("username",
>
>
>
>
>
>
>                                             "currentTime", "playbackRate",
> "pause", "error", "networkState",
>
>
>
>
>
>
>                                             "readyState", "lectureID",
> "eventTimestamp", "initTimestamp",
>
>
>
>
>
>
>                                             "type", "prevTime"), row.names =
> c(1L, 2L, 5L, 6L, 17L, 21L,
>
>
>
>
>
>
>
>    28L, 936L, 957L, 988L), class = "data.frame")
> data<-structure(list(anon_ID = c("exampleID1", "exampleID2", "exampleID3"
> ), maxGrade = c(10, 5, 10), firstGrade = c(10, 5, 8), lastGrade = c(10, 5,
> 10), total_submissions = c(1L, 1L, 3L), Time1 = structure(c(1361993741,
> 1362356090, 1362357401), class = c("POSIXct", "POSIXt"), tzone = ""), TimeM
> = structure(c(1361993741, 1362356090, 1362492744), class = c("POSIXct",
> "POSIXt"), tzone = ""), TimeL = structure(c(1361993741, 1362356090,
> 1362492744), class = c("POSIXct", "POSIXt"), tzone = "")), .Names =
> c("anon_ID", "maxGrade", "firstGrade", "lastGrade", "total_submissions",
> "Time1", "TimeM", "TimeL"), row.names = c(NA, 3L), class = "data.frame")
>
> library(foreach)
> library(doMC)
> registerDoMC(2)  #change the 2 to your number of CPU cores
>
> n <- nrow(data)
> res <- list("vector", n)
> foreach(i=1:n, .verbose=FALSE, .combine=rbind) %do% {
>    res[[i]] <- with(data, DataVideoActionT(anon_ID[i], Time1[i], TimeM[i],
> TimeL[i]))
> }
> test<-do.call(rbind, res)
>
> I have 2 questions.
>
> 1. How can I make foreach not print to the console?
>
> 2. I want to run this in parallel, I i change the %do% for %dopar% the code
> stop working. Instead of getting test with 3 observations and 19 variables
> I get a 2x1 character matrix
>
>
> Thanks!
>
>
>
> On Sun, Sep 1, 2013 at 3:00 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
>> Hello,
>>
>> Your example doesn't really run, but for what I've seen, if your second
>> data frame is named dat2, something along the lines of
>>
>> n <- nrow(dat2)
>> res <- list("vector", n)
>> for(i in 1:n){
>>          res[[i]] <- with(dat2, DataVideoActionT(anon_ID[i], Time1[i],
>> TimeM[i], TimeL[i]))
>> }
>>
>> do.call(rbind, res)
>>
>>
>> Rui Barradas
>>
>> Em 01-09-2013 17:40, Ignacio Martinez escreveu:
>>
>>> I hope this reproduceble example helps understand what I'm trying to do.
>>>
>>> This is the function:
>>>
>>> # Make Data Frame for video actions between given times for user X
>>> DataVideoActionT <- function (userX, Time1, Time2, Time3){
>>>     #Get data for user X
>>>     videoActionsX<-subset(**videoLectureActions, username==userX)
>>>     #Time1 = before first attempt
>>>     videoActionsX_T1<-subset(**videoActionsX, eventTimestamp<Time1)
>>>     #Time2 = before best attemp
>>>     videoActionsX_T2<-subset(**videoActionsX, eventTimestamp<Time2 &
>>> eventTimestamp>Time1)
>>>     #Time3= before last attemp
>>>     videoActionsX_T3<-subset(**videoActionsX, eventTimestamp<Time3 &
>>> eventTimestamp>Time1)
>>>
>>>     error1 = sum(videoActionsX_T1$type==" error ")
>>>     pause1 = sum(videoActionsX_T1$type==" pause ")
>>>     play1 = sum(videoActionsX_T1$type==" play ")
>>>     ratechange1 = sum(videoActionsX_T1$type==" ratechange ")
>>>     seeked1 = sum(videoActionsX_T1$type==" seeked ")
>>>     stalled1 = sum(videoActionsX_T1$type==" stalled ")
>>>
>>>     error2 = sum(videoActionsX_T2$type==" error ")
>>>     pause2 = sum(videoActionsX_T2$type==" pause ")
>>>     play2 = sum(videoActionsX_T2$type==" play ")
>>>     ratechange2 = sum(videoActionsX_T2$type==" ratechange ")
>>>     seeked2 = sum(videoActionsX_T2$type==" seeked ")
>>>     stalled2 = sum(videoActionsX_T2$type==" stalled ")
>>>
>>>     error3 = sum(videoActionsX_T3$type==" error ")
>>>     pause3 = sum(videoActionsX_T3$type==" pause ")
>>>     play3 = sum(videoActionsX_T3$type==" play ")
>>>     ratechange3 = sum(videoActionsX_T3$type==" ratechange ")
>>>     seeked3 = sum(videoActionsX_T3$type==" seeked ")
>>>     stalled3 = sum(videoActionsX_T3$type==" stalled ")
>>>
>>>     data<-data.frame(anon_ID=**userX,
>>>                      error1 = error1,
>>>                      pause1 = pause1,
>>>                      play1 = play1,
>>>                      ratechange1 = ratechange1,
>>>                      seeked1=seeked1,
>>>                      stalled1=stalled1,
>>>                      error2 = error2,
>>>                      pause2 = pause2,
>>>                      play2 = play2,
>>>                      ratechange2 = ratechange2,
>>>                      seeked2 =seeked2,
>>>                      stalled2 = stalled2,
>>>                      error3 = error3,
>>>                      pause3 = pause3,
>>>                      play3 = play3,
>>>                      ratechange3 = ratechange3,
>>>                      seeked3 = seeked3,
>>>                      stalled3 = stalled3)
>>>     return(data)
>>> }
>>>
>>> This is the videoActionsX  dataframe:
>>>
>>> structure(list(username = c("exampleID1", "exampleID1", "exampleID1",
>>>                               "exampleID2", "exampleID2", "exampleID2",
>>> "exampleID3", "exampleID3",
>>>                               "exampleID3", "exampleID3"), currentTime =
>>> c("103.701247", "103.701247",
>>>
>>>    "107.543877", "107.543877", "116.456507", "116.456507", "119.987188",
>>>
>>>    "177.816693", "183.417124", "183.417124"), playbackRate = c("null",
>>>
>>>                                                            "null", "null",
>>> "null", "null", "null", "null", "null", "null",
>>>
>>>                                                            "null"), pause =
>>> c("true", "false", "true", "false", "true",
>>>
>>>
>>> "false", "true", "false", "true", "false"), error = c("null",
>>>
>>>
>>>                                                         "null", "null",
>>> "null", "null", "null", "null", "null", "null",
>>>
>>>
>>>                                                         "null"),
>>> networkState
>>> = c("1", "1", "1", "1", "1", "1", "1",
>>>
>>>
>>>
>>>       "1", "1", "1"), readyState = c("4", "4", "4", "4", "4", "4",
>>>
>>>
>>>
>>>                                      "4", "4", "4", "4"), lectureID =
>>> c("exampleLectureID1", "exampleLectureID1",
>>>
>>>
>>>
>>>
>>> "exampleLectureID1", "exampleLectureID1", "exampleLectureID1",
>>>
>>>
>>>
>>>
>>> "exampleLectureID1", "exampleLectureID1", "exampleLectureID1",
>>>
>>>
>>>
>>>
>>> "exampleLectureID1", "exampleLectureID1"), eventTimestamp = c("2013-03-04
>>> 18:51:49",
>>>
>>>
>>>
>>>
>>>                                                           "2013-03-04
>>> 18:51:50", "2013-03-04 18:51:54", "2013-03-04 18:51:56",
>>>
>>>
>>>
>>>
>>>                                                           "2013-03-04
>>> 18:52:05", "2013-03-04 18:52:07", "2013-03-04 18:52:11",
>>>
>>>
>>>
>>>
>>>                                                           "2013-03-04
>>> 18:59:17", "2013-03-04 18:59:23", "2013-03-04 18:59:31"
>>>
>>>
>>>
>>>                                                                         ),
>>> initTimestamp = c("2013-03-04 18:44:15", "2013-03-04 18:44:15",
>>>
>>>
>>>
>>>
>>>                  "2013-03-04 18:44:15", "2013-03-04 18:44:15", "2013-03-04
>>> 18:44:15",
>>>
>>>
>>>
>>>
>>>                  "2013-03-04 18:44:15", "2013-03-04 18:44:15", "2013-03-04
>>> 18:44:15",
>>>
>>>
>>>
>>>
>>>                  "2013-03-04 18:44:15", "2013-03-04 18:44:15"), type = c("
>>> pause ",
>>>
>>>
>>>
>>>
>>>                                                                          "
>>> play ", " pause ", " play ", " pause ", " play ", " pause ",
>>>
>>>
>>>
>>>
>>>                                                                          "
>>> play ", " pause ", " play "), prevTime = c("103.701247 ", "103.701247 ",
>>>
>>>
>>>
>>>
>>>
>>>                                           "107.543877 ", "107.543877 ",
>>> "116.456507 ", "116.456507 ", "119.987188 ",
>>>
>>>
>>>
>>>
>>>
>>>                                           "177.816693 ", "183.417124 ",
>>> "183.417124 ")), .Names = c("username",
>>>
>>>
>>>
>>>
>>>
>>>
>>>                         "currentTime", "playbackRate", "pause", "error",
>>> "networkState",
>>>
>>>
>>>
>>>
>>>
>>>
>>>                         "readyState", "lectureID", "eventTimestamp",
>>> "initTimestamp",
>>>
>>>
>>>
>>>
>>>
>>>
>>>                         "type", "prevTime"), row.names = c(1L, 2L, 5L, 6L,
>>> 17L, 21L,
>>>
>>>
>>>
>>>
>>>
>>>
>>>                                                            28L, 936L, 957L,
>>> 988L), class = "data.frame")
>>>
>>>
>>>
>>> But with over 2000 observation.
>>>
>>> And this is the other data frame
>>>
>>> structure(list(anon_ID = c("exampleID1", "exampleID2", "exampleID3" ),
>>> maxGrade = c(10, 5, 10), firstGrade = c(10, 5, 8), lastGrade = c(10,
>>> 5, 10), total_submissions = c(1L, 1L, 3L), Time1 =
>>> structure(c(1361993741, 1362356090, 1362357401), class = c("POSIXct",
>>> "POSIXt"), tzone = ""), TimeM = structure(c(1361993741, 1362356090,
>>> 1362492744), class = c("POSIXct", "POSIXt"), tzone = ""), TimeL =
>>> structure(c(1361993741, 1362356090, 1362492744), class = c("POSIXct",
>>> "POSIXt"), tzone = "")), .Names = c("anon_ID", "maxGrade",
>>> "firstGrade", "lastGrade", "total_submissions", "Time1", "TimeM",
>>> "TimeL"), row.names = c(NA, 3L), class = "data.frame")
>>>
>>>
>>> But with a lot more observations.
>>>
>>>
>>> What I want to do is to call  function (userX, Time1, Time2, Time3)
>>> for all the user in the second data frame where Time1=Time1,
>>> Time2=TimeM, Time3=TimeL
>>>
>>>
>>> I hope that is more clear.
>>>
>>>
>>> Thanks a lot for all the help!
>>>
>>>
>>>
>>> On Sun, Sep 1, 2013 at 11:33 AM, Bert Gunter <gunter.berton at gene.com>
>>> wrote:
>>>
>>>   Oh, another possibility is ?mapply, which I should have pointed out in my
>>>> previous reply. Sorry.
>>>>
>>>> -- Bert
>>>>
>>>>
>>>> On Sun, Sep 1, 2013 at 8:30 AM, Bert Gunter <bgunter at gene.com> wrote:
>>>>
>>>>   Rui et.al.:
>>>>>
>>>>> But apply will not work if the data frame has columns of different
>>>>> classes/types, as appears to be the case here. Viz, from ?apply:
>>>>>
>>>>> "If X is not an array but an object of a class with a non-null dim<
>>>>> http://127.0.0.1:12824/**help/library/base/help/dim<http://127.0.0.1:12824/help/library/base/help/dim>
>>>>>>
>>>>>
>>>>>    value (such as a data frame),apply attempts to coerce it to an array
>>>>> via
>>>>>    as.matrix if it is two-dimensional (e.g., a data frame) or via
>>>>> as.array.
>>>>> "
>>>>>
>>>>> Simply looping by rows (via for() ) appears to be the simplest and
>>>>> probably fastest solution. There are other ways via tapply() and
>>>>> friends,
>>>>> but these are also essentially loops and are likely to incur some
>>>>> additional overhead.
>>>>>
>>>>> All assuming I understand what the OP has requested, of course.
>>>>>
>>>>> Cheers,
>>>>>
>>>>> Bert
>>>>>
>>>>>
>>>>> On Sun, Sep 1, 2013 at 7:31 AM, Rui Barradas <ruipbarradas at sapo.pt
>>>>>> wrote:
>>>>>
>>>>>   Hello,
>>>>>>
>>>>>> Maybe you need apply, not lapply. It seems you want to apply() a
>>>>>> function to the first dimension of your data.frame, something like
>>>>>>
>>>>>> apply(dat, 1, fun)  #apply by rows
>>>>>>
>>>>>>
>>>>>> Hope this helps,
>>>>>>
>>>>>> Rui Barradas
>>>>>>
>>>>>> Em 01-09-2013 15:00, Ignacio Martinez escreveu:
>>>>>>
>>>>>>   I have a Data Frame that contains, between other things, the following
>>>>>>> fields: userX, Time1, Time2, Time3. The number of observations is
>>>>>>> 2000.
>>>>>>>
>>>>>>> I have a function that has as inputs userX, Time1, Time2, Time3 and
>>>>>>> return
>>>>>>> a data frame with 1 observation and 19 variables.
>>>>>>>
>>>>>>> I want to apply that function to all the observations of the first
>>>>>>> data
>>>>>>> frame to make a new data frame with 2000 observations and 19
>>>>>>> variables.
>>>>>>>
>>>>>>> I thought about using lapply, but if I understand correctly, it only
>>>>>>> takes
>>>>>>> one variable.
>>>>>>>
>>>>>>> Can somebody point me in the right direction?
>>>>>>>
>>>>>>> Thanks!
>>>>>>>
>>>>>>>           [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> ______________________________****________________
>>>>>>> R-help at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/****listinfo/r-help<https://stat.ethz.ch/mailman/**listinfo/r-help>
>>>>>>> <https://stat.**ethz.ch/mailman/listinfo/r-**help<https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>>>>
>>>>>>> PLEASE do read the posting guide http://www.R-project.org/**
>>>>>>> posting-guide.html <http://www.R-project.org/**posting-guide.html<http://www.R-project.org/posting-guide.html>
>>>>>>>>
>>>>>>>
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>
>>>>>>>
>>>>>>>   ______________________________****________________
>>>>>> R-help at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/****listinfo/r-help<https://stat.ethz.ch/mailman/**listinfo/r-help>
>>>>>> <https://stat.**ethz.ch/mailman/listinfo/r-**help<https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>>>
>>>>>> PLEASE do read the posting guide http://www.R-project.org/**
>>>>>> posting-guide.html <http://www.R-project.org/**posting-guide.html<http://www.R-project.org/posting-guide.html>
>>>>>>>
>>>>>>
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>> --
>>>>>
>>>>> Bert Gunter
>>>>> Genentech Nonclinical Biostatistics
>>>>>
>>>>> Internal Contact Info:
>>>>> Phone: 467-7374
>>>>> Website:
>>>>>
>>>>> http://pharmadevelopment.**roche.com/index/pdb/pdb-**
>>>>> functional-groups/pdb-**biostatistics/pdb-ncb-home.htm<http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm>
>>>>>
>>>>>
>>>>>
>>>>
>>>>
>>>> --
>>>>
>>>> Bert Gunter
>>>> Genentech Nonclinical Biostatistics
>>>>
>>>> Internal Contact Info:
>>>> Phone: 467-7374
>>>> Website:
>>>>
>>>> http://pharmadevelopment.**roche.com/index/pdb/pdb-**
>>>> functional-groups/pdb-**biostatistics/pdb-ncb-home.htm<http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm>
>>>>
>>>>
>>>>
>>>
>


From jsteimle at uchicago.edu  Sun Sep  1 22:18:50 2013
From: jsteimle at uchicago.edu (jsteimle)
Date: Sun, 1 Sep 2013 13:18:50 -0700 (PDT)
Subject: [R] Intersect 2 lists+bring extra columns
Message-ID: <1378066730084-4675136.post@n4.nabble.com>

Hi everyone,

I am pretty new to R, so be patient. 

I am trying to intersect 2 columns and in the rows that intersect, I want
information from the 3rd column to be brought with it. I think it will be
easier to explain with an example  example.csv
<http://r.789695.n4.nabble.com/file/n4675136/example.csv>  . 

In my example, I have a reference list of fruit (first column), and my fruit
of interest (second column), and then in the third column, I have color
information about the fruit of interest in the second column. 

Currently to find the intersection between column 1 and 2, I use 
>fruit<-read.csv("//Users//J//Desktop//example.csv", header=TRUE)
>output<-intersect(fruit[,1],fruit[,2])
>write.table(data.frame(fruit),"output.xls", col.names=TRUE,
row.names=FALSE)

However, it would save me a lot of time if I could have the color
information from column 3 be saved with the overlap. I normally have
reference list of several hundred and lists of interest in the several
thousand, and bringing over the information column would be hard manually.

Is there some sort of If function I could be using? I would really like
something like If row x, column 2 intersects with row x, column 1, then row
x column 3 is stored with it. I can think through the logic, but not sure
how to do it in R. 

Any help would be much appreciated!



--
View this message in context: http://r.789695.n4.nabble.com/Intersect-2-lists-bring-extra-columns-tp4675136.html
Sent from the R help mailing list archive at Nabble.com.


From jsteimle at uchicago.edu  Mon Sep  2 00:01:28 2013
From: jsteimle at uchicago.edu (jsteimle)
Date: Sun, 1 Sep 2013 15:01:28 -0700 (PDT)
Subject: [R] Intersect 2 lists+bring extra columns
In-Reply-To: <1378071920.11284.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1378066730084-4675136.post@n4.nabble.com>
	<1378071920.11284.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <1378072888183-4675145.post@n4.nabble.com>

Hi A.K.

That is exactly what I was hoping to do. If you have the time, can you
explain what the fruit[,-1] term means in the merge? 

Also, if I wanted to expand the number of columns to report to include a 4th
column, let's call it flavor, how would I go about doing that?

J.S.



--
View this message in context: http://r.789695.n4.nabble.com/Intersect-2-lists-bring-extra-columns-tp4675136p4675145.html
Sent from the R help mailing list archive at Nabble.com.


From jsteimle at uchicago.edu  Mon Sep  2 00:27:11 2013
From: jsteimle at uchicago.edu (jsteimle)
Date: Sun, 1 Sep 2013 15:27:11 -0700 (PDT)
Subject: [R] Intersect 2 lists+bring extra columns
In-Reply-To: <1378072888183-4675145.post@n4.nabble.com>
References: <1378066730084-4675136.post@n4.nabble.com>
	<1378071920.11284.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1378072888183-4675145.post@n4.nabble.com>
Message-ID: <1378074431611-4675146.post@n4.nabble.com>

I see how merge works now, and to answer my own question, I can have any
number of columns of miscellaneous information I want. 



--
View this message in context: http://r.789695.n4.nabble.com/Intersect-2-lists-bring-extra-columns-tp4675136p4675146.html
Sent from the R help mailing list archive at Nabble.com.


From msuzen at gmail.com  Mon Sep  2 00:29:51 2013
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Mon, 2 Sep 2013 00:29:51 +0200
Subject: [R] Validating data type
In-Reply-To: <AF3F085B-8A38-45AD-BDD5-1C4F04080662@WorldVision.org>
References: <AF3F085B-8A38-45AD-BDD5-1C4F04080662@WorldVision.org>
Message-ID: <CAPtbhHwffvfbMpgTM47Xtq8ahEyAJVpTKqc=r+8_AVctkU=CSw@mail.gmail.com>

R is weakly typed language. I have asked similar question previously:

http://r.789695.n4.nabble.com/count-appearence-of-zero-in-a-vector-td4654591.html

It is advised to me to use S4 classes,  if you want to enforce type
checking automatically. Excellent
reference on this is by the ACM award holder Prof. John Chamber's
book, Software for Data Analysis.



On 30 August 2013 05:29,  <jeffjohn at worldvision.org> wrote:
>
>
> I'm very new to R. I have a data file that I have read in via read.csv. I
> expect one of the "columns" to be of type date for example. However at
> least one value in that column is not of date type. I know this because
> another program I am trying to process the file with is erroring, yet it
> doesn't tell me what row/value is erroring. Does R have a way to: treat
> column x as date type, and print out all values/row numbers do not conform
> to that type for that specified column?
>
> Many thanks!
> Jeff
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From noahsilverman at ucla.edu  Mon Sep  2 02:07:43 2013
From: noahsilverman at ucla.edu (Noah Silverman)
Date: Sun, 1 Sep 2013 17:07:43 -0700
Subject: [R] Trouble with Slidify and Latex
In-Reply-To: <BLU170-W219D6469C918CB8CCBB04EF370@phx.gbl>
References: <522D051E-36E3-4778-A7F2-6175B39DF3B4@ucla.edu>
	<BLU170-W219D6469C918CB8CCBB04EF370@phx.gbl>
Message-ID: <5A013197-5AF6-423B-8128-EF66E48DE245@ucla.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130901/138126b7/attachment.pl>

From jwiley.psych at gmail.com  Mon Sep  2 06:48:29 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sun, 1 Sep 2013 21:48:29 -0700
Subject: [R] Trouble with Slidify and Latex
In-Reply-To: <522D051E-36E3-4778-A7F2-6175B39DF3B4@ucla.edu>
References: <522D051E-36E3-4778-A7F2-6175B39DF3B4@ucla.edu>
Message-ID: <CANz9Z_Jw6kuvpeRrX4Rq6W+a_qHjkkz=yLGGjeg=wk9wskp38w@mail.gmail.com>

Hi Noah,

Looks like mathjax --- \( is the inline escape for mathjax
(http://www.mathjax.org/download/)

As an example, checkout slide 20
(http://elkhartgroup.com/tutorials/psychometrics.html)

Cheers,

Josh


On Sun, Sep 1, 2013 at 1:40 PM, Noah Silverman <noahsilverman at ucla.edu> wrote:
> Hi,
>
> (Re-submitting as the original doesn't look like it made it to the list.)
>
> Just starting to play around with the awesome Slidify package.
>
> For some reason, I can't get it to render any Latex in the presentation.  Have reviews all the docs and think I'm doing things correctly.  Is there something possibly broken with my installation, or am I misunderstanding the markdown syntax?
>
> I have, on a single slide:
>
> Test $A = 1+2$ and some text after
>
> What I see in the Presentation:
>
>
> Test \(A = 1+2\) and some text after
>
>
> Note:  This is literally a "slash" followed by a "parenthesis" in the final HTML slide.
>
>
> Any ideas on what's wrong here?
>
> Thanks.
>
> --
> Noah Silverman, C.Phil
> UCLA Department of Statistics
> 8117 Math Sciences Building
> Los Angeles, CA 90095
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://joshuawiley.com/
Senior Analyst - Elkhart Group Ltd.
http://elkhartgroup.com


From suparna.mitra.sm at gmail.com  Mon Sep  2 15:01:00 2013
From: suparna.mitra.sm at gmail.com (Suparna Mitra)
Date: Mon, 2 Sep 2013 21:01:00 +0800
Subject: [R] package seriation- how to manage font size and label margin
Message-ID: <CAFdg=fUP9QoLTT1hfTdNdzJsr5RCbFTYUToXb_F-NtPXYn_B6w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130902/5667d729/attachment.pl>

From smartpink111 at yahoo.com  Mon Sep  2 15:39:15 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 2 Sep 2013 06:39:15 -0700 (PDT)
Subject: [R] Ordering a matrix (and not losing the rownames)
In-Reply-To: <1377869272.40660.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <1377869272.40660.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <1378129155.77331.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi  Ram?n,

It is for the column index.
For ex:
tags_totals[order(tags_totals[,1],decreasing=TRUE),1,drop=FALSE] #same as previous solution as there is only one column.? 
#?????????????? [,1]
#Grupos?????????? 23
#Wikis??????????? 15
#Glosarios??????? 11
#Bases de datos??? 7
#Taller??????????? 5

order(tags_totals[,1],decreasing=TRUE) #creates the row index

#If you don't specify the column index, it will select all the columns.


?tags_totals[1,1] 
#Wikis 
?#? 15 
tags_totals[1,1,drop=FALSE] 
#????? [,1]
#Wikis?? 15

tags_totals[1,,drop=FALSE] 
#????? [,1]
#Wikis?? 15


is.matrix(tags_totals[1,1])
#[1] FALSE
is.matrix(tags_totals[1,1,drop=FALSE])
#[1] TRUE



A.K.


Many thanks Arun, 
This is important for me because I will need to do this operation 
many times. However, there is one thing that intrigues me. Why it is 
necessary to put two commas in a row? 

> tags_totals[order(tags_totals[,1],decreasing=TRUE),,drop=FALSE] 
? ? ? ? ? ? ? ?[,1] 
Grupos ? ? ? ? ? 23 
Wikis ? ? ? ? ? ?15 
Glosarios ? ? ? ?11 
Bases de datos ? ?7 
Taller ? ? ? ? ? ?5 
> tags_totals[order(tags_totals[,1],decreasing=TRUE),drop=FALSE] 
[1] 23 15 11 ?7 ?5 

I've been reading around trrying to undestand it, but I can't see the logic. 

Many thanks 


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Friday, August 30, 2013 9:27 AM
Subject: Re: Ordering a matrix (and not losing the rownames)

Hi Ram?n,
May be this helps:
tags_totals<-matrix(c(15,11,23,7,5),ncol=1,dimnames=list(c("Wikis","Glosarios","Grupos","Bases de datos","Taller"),NULL))

tags_totals[order(tags_totals[,1],decreasing=TRUE),,drop=FALSE]
#?????????????? [,1]
#Grupos?????????? 23
#Wikis??????????? 15
#Glosarios??????? 11
#Bases de datos??? 7
#Taller??????????? 5

A.K.



Hello, 

I have a matrix like this: 

> tags_totals 
? ? ? ? ? ? ? ?[,1] 
Wikis ? ? ? ? ? ?15 
Glosarios ? ? ? ?11 
Grupos ? ? ? ? ? 23 
Bases de datos ? ?7 
Taller ? ? ? ? ? ?5 

And I want to order by the value of the first column. I do this: 

ordered_matrix <- as.matrix(tags_totals[order(tags_totals[,1],decreasing=TRUE)]) 

It orders alright, but I lose the rownames, that I need for the graphics 
> ordered_matrix 
? ? ?[,1] 
[1,] ? 23 
[2,] ? 15 
[3,] ? 11 
[4,] ? ?7 
[5,] ? ?5 

> rownames(ordered_matrix) 
NULL 

If I try to do it after converting to a dataframe I get an error that I don't understand: 

> tags_totals_frame <- as.data.frame(tags_totals) 
> tags_totals_frame[,1] 
[1] 15 11 23 ?7 ?5 
> ordered_frame <- tags_totals_frame[order(tags_totals_frame[,1],decreasing=TRUE)] 
Error en `[.data.frame`(tags_totals_frame, order(tags_totals_frame[, 1], ?: 
? undefined columns selected 

Thanks on any help, 

-- 
================================== 
Ram?n Ovelar 
Campus Virtual Birtuala UPV/EHU 
Tel: (34) 94 601 3407 
http://campusvirtual.ehu.es



From smartpink111 at yahoo.com  Mon Sep  2 16:25:07 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 2 Sep 2013 07:25:07 -0700 (PDT)
Subject: [R] Product of certain rows in a matrix
Message-ID: <1378131907.99820.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
You could try:

A<- matrix(unlist(read.table(text="
1 2 3
4 5 6
7 8 9
9 8 7
6 5 4
3 2 1
",sep="",header=FALSE)),ncol=3,byrow=FALSE,dimnames=NULL)

library(matrixStats)
?res1<-t(sapply(split(as.data.frame(A),as.numeric(gl(nrow(A),2,6))),colProds))
?res1
#? [,1] [,2] [,3]
#1??? 4?? 10?? 18
#2?? 63?? 64?? 63
#3?? 18?? 10??? 4


?res2<-t(sapply(split(as.data.frame(A),((seq_len(nrow(A))-1)%/%2)+1),colProds)) 
?identical(res1,res2)
#[1] TRUE

#or
?t(sapply(split(as.data.frame(A),as.numeric(gl(nrow(A),2,6))),function(x) apply(x,2,prod)))

#or
library(plyr)
?as.matrix(ddply(as.data.frame(A),.(as.numeric(gl(nrow(A),2,6))),colProds)[,-1])
#???? V1 V2 V3
#[1,]? 4 10 18
#[2,] 63 64 63
#[3,] 18 10? 4

#or
do.call(rbind,tapply(seq_len(nrow(A)),list(as.numeric(gl(nrow(A),2,6))),FUN=function(x) colProds(A[x,])))
#or
A1<- data.frame(A,ID=as.numeric(gl(nrow(At),2,6)))
?aggregate(A1[,-4],list(A1[,4]),colProds)[,-1]
#? X1 X2 X3
#1? 4 10 18
#2 63 64 63
#3 18 10? 4

#or
library(data.table)
At<- data.table(A1,key='ID')
subset(At[,lapply(.SD,colProds),by=ID],select=-1)
#?? X1 X2 X3
#1:? 4 10 18
#2: 63 64 63
#3: 18 10? 4

A.K. 




Hello, 

I have this matrix : 
A = 
1 2 3 
4 5 6 
7 8 9 
9 8 7 
6 5 4 
3 2 1 

I would like to have this matrix (product of rows 2 by 2) : 
A = 
4 10 18 
63 64 63 
18 10 4 

Is it possible to do that without a loop ? 

Thank you in advance !


From mrahmankufmrt at gmail.com  Mon Sep  2 16:30:32 2013
From: mrahmankufmrt at gmail.com (Moshiur Rahman)
Date: Mon, 2 Sep 2013 22:30:32 +0800
Subject: [R] Legend position
Message-ID: <CAGNSkSmYsCaV7xJEGzaTQPKk+df102oqKFtxaZGHi3-p8herSg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130902/92a45142/attachment.pl>

From nashjc at uottawa.ca  Mon Sep  2 16:42:01 2013
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Mon, 02 Sep 2013 10:42:01 -0400
Subject: [R] How to catch errors regarding the hessian in 'optim'
In-Reply-To: <mailman.11.1378116005.20733.r-help@r-project.org>
References: <mailman.11.1378116005.20733.r-help@r-project.org>
Message-ID: <5224A3B9.8030408@uottawa.ca>

This may be one of the many mysteries of the internals of L-BFGS-B, 
which I have found fails from time to time. That is one of the reasons 
for Rvmmin and Rcgmin (and hopefully sooner rather than later Rtn - a 
truncated Newton method, currently working for unconstrained problems, 
but still glitchy for bounds constraints). These are all-R codes so that 
users and developers can get inside to control special situations.

If you have a test problem -- the infamous reproducible example -- there 
are several of us who can likely help to sort out your troubles.

JN


On 13-09-02 06:00 AM, r-help-request at r-project.org wrote:
> Message: 10
> Date: Sun, 1 Sep 2013 17:09:35 +0200
> From: Simon Zehnder<szehnder at uni-bonn.de>
> To: R-help help<r-help at r-project.org>
> Subject: [R] How to catch errors regarding the hessian in 'optim'
> Message-ID:<EB37670E-8544-4C89-9172-245EB6CC596A at uni-bonn.de>
> Content-Type: text/plain; charset=us-ascii
>
> Dear R-Users and R-Developers,
>
> in a comparison between two different estimation approaches I would like to catch errors from optim regarding the hessian matrix.
>
> I use optim with method = "L-BFGS-B" thereby relying on numerical differentiation for the hessian matrix. I do know, that the estimation approach that uses numerical optimization has sometimes problems with singular hessian matrices and I consider it as one of its disadvantages of this method. To show the frequency of such problems in my simulation study I have to set 'hessian = TRUE' and to collect the errors from optim regarding the hessian.
>
> Now I am a little stucked how I could catch specifically errors from the hessian matrix in 'optim'. I do know that such errors are thrown most certainly from function 'La_solve' in Lapack.c. Does anyone has an idea how I could solve this task (clearly with tryCatch but how to choose only errors for the hessian)?
>
>
> Best
>
> Simon


From claus.orourke at gmail.com  Mon Sep  2 16:47:06 2013
From: claus.orourke at gmail.com (Claus O'Rourke)
Date: Mon, 2 Sep 2013 15:47:06 +0100
Subject: [R] Multivariate discrete HMMs
Message-ID: <CAAsww2hU5RQaDcBZ1_CB1G8vjR1GmL9vzNxtBoGHdmC9kowopw@mail.gmail.com>

Hi r-help,

I have been using your RHmm package for some time and have recently
had to try using the package for a new dataset.

Basically I have a dataset with a number of discrete observation
variables that change over time, and I would love to try modeling them
using a HMM.

Basically I was wondering if RHmm can be used to model a multivariate
discrete HMM, i.e., the observations are a vector of discrete
measurements? From what I see in the documentation and from playing
around with examples, it seems like this may not be possible. My
understand of the mathematics behind multivariate HMMs is limited, so
I would appreciate any advance you might be able to give.

Thanks for any help anyone can give


From gunter.berton at gene.com  Mon Sep  2 16:55:05 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 2 Sep 2013 07:55:05 -0700
Subject: [R] Product of certain rows in a matrix
In-Reply-To: <1378131907.99820.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1378131907.99820.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <CACk-te16jF6r192tcANN6KPN2ig60WgGpR=q+o_1POe2ns2GrA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130902/90472a3a/attachment.pl>

From smartpink111 at yahoo.com  Mon Sep  2 17:26:49 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 2 Sep 2013 08:26:49 -0700 (PDT)
Subject: [R] Product of certain rows in a matrix
In-Reply-To: <CACk-te16jF6r192tcANN6KPN2ig60WgGpR=q+o_1POe2ns2GrA@mail.gmail.com>
References: <1378131907.99820.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CACk-te16jF6r192tcANN6KPN2ig60WgGpR=q+o_1POe2ns2GrA@mail.gmail.com>
Message-ID: <1378135609.35393.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi Bert,
Thanks.? It is a better solution.

If nrow() is not even.

Anew<- rbind(A,c(1,3,5))
j<-seq_len(nrow(Anew)/2)###
?Anew[j,]*Anew[j-1,]
#Error in Anew[j, ] * Anew[j - 1, ] : non-conformable arrays

t(sapply(split(as.data.frame(Anew),as.numeric(gl(nrow(Anew),2,7))),colProds))
? [,1] [,2] [,3]
1??? 4?? 10?? 18
2?? 63?? 64?? 63
3?? 18?? 10??? 4
4??? 1??? 3??? 5

A.K.






________________________________
From: Bert Gunter <gunter.berton at gene.com>
To: arun <smartpink111 at yahoo.com> 
Cc: R help <r-help at r-project.org> 
Sent: Monday, September 2, 2013 10:55 AM
Subject: Re: [R] Product of certain rows in a matrix



These elaborate manipulations are unnecessary and inefficient. Use indexing instead:

j <- 2*seq_len(nrow(A)/2)
b <- A[j,]*A[j-1,]
b
[,1] [,2] [,3]
[1,]??? 4?? 10?? 18
[2,]?? 63?? 64?? 63
[3,]?? 18?? 10??? 4

[,1] [,2] [,3]
[1,]????4?? 10?? 18
[2,]?? 63?? 64?? 63
[3,]?? 18?? 10????4
[,1] [,2] [,3]
[1,]????4?? 10?? 18
[2,]?? 63?? 64?? 63
[3,]?? 18?? 10????4[,1] [,2] [,3]
[1,]????4?? 10?? 18
[2,]?? 63?? 64?? 63
[3,]?? 18?? 10????4
[,1] [,2] [,3]
[1,]????4?? 10?? 18
[2,]?? 63?? 64?? 63
[3,]?? 18?? 10????4





On Mon, Sep 2, 2013 at 7:25 AM, arun <smartpink111 at yahoo.com> wrote:

Hi,
>You could try:
>
>A<- matrix(unlist(read.table(text="
>1 2 3
>4 5 6
>7 8 9
>9 8 7
>6 5 4
>3 2 1
>",sep="",header=FALSE)),ncol=3,byrow=FALSE,dimnames=NULL)
>
>library(matrixStats)
>?res1<-t(sapply(split(as.data.frame(A),as.numeric(gl(nrow(A),2,6))),colProds))
>?res1
>#? [,1] [,2] [,3]
>#1??? 4?? 10?? 18
>#2?? 63?? 64?? 63
>#3?? 18?? 10??? 4
>
>
>?res2<-t(sapply(split(as.data.frame(A),((seq_len(nrow(A))-1)%/%2)+1),colProds))
>?identical(res1,res2)
>#[1] TRUE
>
>#or
>?t(sapply(split(as.data.frame(A),as.numeric(gl(nrow(A),2,6))),function(x) apply(x,2,prod)))
>
>#or
>library(plyr)
>?as.matrix(ddply(as.data.frame(A),.(as.numeric(gl(nrow(A),2,6))),colProds)[,-1])
>#???? V1 V2 V3
>#[1,]? 4 10 18
>#[2,] 63 64 63
>#[3,] 18 10? 4
>
>#or
>do.call(rbind,tapply(seq_len(nrow(A)),list(as.numeric(gl(nrow(A),2,6))),FUN=function(x) colProds(A[x,])))
>#or
>A1<- data.frame(A,ID=as.numeric(gl(nrow(At),2,6)))
>?aggregate(A1[,-4],list(A1[,4]),colProds)[,-1]
>#? X1 X2 X3
>#1? 4 10 18
>#2 63 64 63
>#3 18 10? 4
>
>#or
>library(data.table)
>At<- data.table(A1,key='ID')
>subset(At[,lapply(.SD,colProds),by=ID],select=-1)
>#?? X1 X2 X3
>#1:? 4 10 18
>#2: 63 64 63
>#3: 18 10? 4
>
>A.K.
>
>
>
>
>Hello,
>
>I have this matrix :
>A =
>1 2 3
>4 5 6
>7 8 9
>9 8 7
>6 5 4
>3 2 1
>
>I would like to have this matrix (product of rows 2 by 2) :
>A =
>4 10 18
>63 64 63
>18 10 4
>
>Is it possible to do that without a loop ?
>
>Thank you in advance !
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>


-- 


Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:

http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From David.Epstein at warwick.ac.uk  Mon Sep  2 17:38:19 2013
From: David.Epstein at warwick.ac.uk (David Epstein)
Date: Mon, 2 Sep 2013 16:38:19 +0100
Subject: [R] Sweave: printing an underscore in the output from an R command
Message-ID: <8AAFC6A6-757E-4E74-A4BB-4D0A55037290@warwick.ac.uk>

I am working with Sweave and would like to print out into my latex document the result of the R command
version$platform
So what I first tried in my .Rnw document was \Sexpr{print(version$platform)}.

However, the output from this command is the string "x86_64-apple-darwin10.8.0" (without the quotes). This contains an underscore, which is a special character in tex and so I get an error message from latex.

I can get round this by using sub to replace underscore with a space, but I would like to know how to print the underscore if I really wanted to do so.


From David.Epstein at warwick.ac.uk  Mon Sep  2 17:42:13 2013
From: David.Epstein at warwick.ac.uk (David Epstein)
Date: Mon, 2 Sep 2013 16:42:13 +0100
Subject: [R] Meaning of "Integer,19"
Message-ID: <834A888E-38CF-4CB9-9557-0219D9217265@warwick.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130902/93bca3d0/attachment.pl>

From smartpink111 at yahoo.com  Mon Sep  2 17:43:39 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 2 Sep 2013 08:43:39 -0700 (PDT)
Subject: [R] Product of certain rows in a matrix
In-Reply-To: <1378135609.35393.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1378131907.99820.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CACk-te16jF6r192tcANN6KPN2ig60WgGpR=q+o_1POe2ns2GrA@mail.gmail.com>
	<1378135609.35393.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1378136619.88673.YahooMailNeo@web142603.mail.bf1.yahoo.com>

I guess in such situations,


fun1<- function(mat){
?if(nrow(mat)%%2==0){
?j<- 2*seq_len(nrow(mat)/2)
?b<- mat[j,]* mat[j-1,]
?}
?else {mat1<- mat[-nrow(mat),]
?j<- 2*seq_len(nrow(mat1)/2)
?b<- rbind(mat1[j,]*mat1[j-1,],mat[nrow(mat),])
? }
b
}
fun1(A)
#???? [,1] [,2] [,3]
#[1,]??? 4?? 10?? 18
#[2,]?? 63?? 64?? 63
#[3,]?? 18?? 10??? 4
?fun1(Anew)
#???? [,1] [,2] [,3]
#[1,]??? 4?? 10?? 18
#[2,]?? 63?? 64?? 63
#[3,]?? 18?? 10??? 4
#[4,]??? 1??? 3??? 5


A.K.



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Bert Gunter <gunter.berton at gene.com>
Cc: R help <r-help at r-project.org>
Sent: Monday, September 2, 2013 11:26 AM
Subject: Re: [R] Product of certain rows in a matrix

Hi Bert,
Thanks.? It is a better solution.

If nrow() is not even.

Anew<- rbind(A,c(1,3,5))
j<-seq_len(nrow(Anew)/2)###
?Anew[j,]*Anew[j-1,]
#Error in Anew[j, ] * Anew[j - 1, ] : non-conformable arrays

t(sapply(split(as.data.frame(Anew),as.numeric(gl(nrow(Anew),2,7))),colProds))
? [,1] [,2] [,3]
1??? 4?? 10?? 18
2?? 63?? 64?? 63
3?? 18?? 10??? 4
4??? 1??? 3??? 5

A.K.






________________________________
From: Bert Gunter <gunter.berton at gene.com>
To: arun <smartpink111 at yahoo.com> 
Cc: R help <r-help at r-project.org> 
Sent: Monday, September 2, 2013 10:55 AM
Subject: Re: [R] Product of certain rows in a matrix



These elaborate manipulations are unnecessary and inefficient. Use indexing instead:

j <- 2*seq_len(nrow(A)/2)
b <- A[j,]*A[j-1,]
b
[,1] [,2] [,3]
[1,]??? 4?? 10?? 18
[2,]?? 63?? 64?? 63
[3,]?? 18?? 10??? 4

[,1] [,2] [,3]
[1,]????4?? 10?? 18
[2,]?? 63?? 64?? 63
[3,]?? 18?? 10????4
[,1] [,2] [,3]
[1,]????4?? 10?? 18
[2,]?? 63?? 64?? 63
[3,]?? 18?? 10????4[,1] [,2] [,3]
[1,]????4?? 10?? 18
[2,]?? 63?? 64?? 63
[3,]?? 18?? 10????4
[,1] [,2] [,3]
[1,]????4?? 10?? 18
[2,]?? 63?? 64?? 63
[3,]?? 18?? 10????4





On Mon, Sep 2, 2013 at 7:25 AM, arun <smartpink111 at yahoo.com> wrote:

Hi,
>You could try:
>
>A<- matrix(unlist(read.table(text="
>1 2 3
>4 5 6
>7 8 9
>9 8 7
>6 5 4
>3 2 1
>",sep="",header=FALSE)),ncol=3,byrow=FALSE,dimnames=NULL)
>
>library(matrixStats)
>?res1<-t(sapply(split(as.data.frame(A),as.numeric(gl(nrow(A),2,6))),colProds))
>?res1
>#? [,1] [,2] [,3]
>#1??? 4?? 10?? 18
>#2?? 63?? 64?? 63
>#3?? 18?? 10??? 4
>
>
>?res2<-t(sapply(split(as.data.frame(A),((seq_len(nrow(A))-1)%/%2)+1),colProds))
>?identical(res1,res2)
>#[1] TRUE
>
>#or
>?t(sapply(split(as.data.frame(A),as.numeric(gl(nrow(A),2,6))),function(x) apply(x,2,prod)))
>
>#or
>library(plyr)
>?as.matrix(ddply(as.data.frame(A),.(as.numeric(gl(nrow(A),2,6))),colProds)[,-1])
>#???? V1 V2 V3
>#[1,]? 4 10 18
>#[2,] 63 64 63
>#[3,] 18 10? 4
>
>#or
>do.call(rbind,tapply(seq_len(nrow(A)),list(as.numeric(gl(nrow(A),2,6))),FUN=function(x) colProds(A[x,])))
>#or
>A1<- data.frame(A,ID=as.numeric(gl(nrow(At),2,6)))
>?aggregate(A1[,-4],list(A1[,4]),colProds)[,-1]
>#? X1 X2 X3
>#1? 4 10 18
>#2 63 64 63
>#3 18 10? 4
>
>#or
>library(data.table)
>At<- data.table(A1,key='ID')
>subset(At[,lapply(.SD,colProds),by=ID],select=-1)
>#?? X1 X2 X3
>#1:? 4 10 18
>#2: 63 64 63
>#3: 18 10? 4
>
>A.K.
>
>
>
>
>Hello,
>
>I have this matrix :
>A =
>1 2 3
>4 5 6
>7 8 9
>9 8 7
>6 5 4
>3 2 1
>
>I would like to have this matrix (product of rows 2 by 2) :
>A =
>4 10 18
>63 64 63
>18 10 4
>
>Is it possible to do that without a loop ?
>
>Thank you in advance !
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>


-- 


Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:

http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From Thierry.ONKELINX at inbo.be  Mon Sep  2 17:47:29 2013
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 2 Sep 2013 15:47:29 +0000
Subject: [R] Sweave: printing an underscore in the output from an R
 command
In-Reply-To: <8AAFC6A6-757E-4E74-A4BB-4D0A55037290@warwick.ac.uk>
References: <8AAFC6A6-757E-4E74-A4BB-4D0A55037290@warwick.ac.uk>
Message-ID: <AA818EAD2576BC488B4F623941DA7427CD351B5F@inbomail.inbo.be>

You have to escape the underscore

\Sexpr{gsub("_", "\_", print(version$platform))}

Best regards,

Thierry

________________________________________
Van: r-help-bounces at r-project.org [r-help-bounces at r-project.org] namens David Epstein [David.Epstein at warwick.ac.uk]
Verzonden: maandag 2 september 2013 17:38
Aan: r-help at r-project.org
Onderwerp: [R] Sweave: printing an underscore in the output from an R command

I am working with Sweave and would like to print out into my latex document the result of the R command
version$platform
So what I first tried in my .Rnw document was \Sexpr{print(version$platform)}.

However, the output from this command is the string "x86_64-apple-darwin10.8.0" (without the quotes). This contains an underscore, which is a special character in tex and so I get an error message from latex.

I can get round this by using sub to replace underscore with a space, but I would like to know how to print the underscore if I really wanted to do so.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From smartpink111 at yahoo.com  Mon Sep  2 17:56:35 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 2 Sep 2013 08:56:35 -0700 (PDT)
Subject: [R] Product of certain rows in a matrix
In-Reply-To: <CAFsztN6R39vUhW9-NLS8eLvRmvXPjGXHmDFO8Jb7=8g1CnEaWA@mail.gmail.com>
References: <1378131907.99820.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CACk-te16jF6r192tcANN6KPN2ig60WgGpR=q+o_1POe2ns2GrA@mail.gmail.com>
	<1378135609.35393.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1378136619.88673.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CAFsztN6R39vUhW9-NLS8eLvRmvXPjGXHmDFO8Jb7=8g1CnEaWA@mail.gmail.com>
Message-ID: <1378137395.55129.YahooMailNeo@web142606.mail.bf1.yahoo.com>



HI,
In my first solutions:
?n<-3
?t(sapply(split(as.data.frame(Anew),as.numeric(gl(nrow(Anew),n,nrow(Anew)))),colProds))
#? [,1] [,2] [,3]
#1?? 28?? 80? 162
#2? 162?? 80?? 28
#3??? 1??? 3??? 5
?n<-4
?t(sapply(split(as.data.frame(Anew),as.numeric(gl(nrow(Anew),n,nrow(Anew)))),colProds))
#? [,1] [,2] [,3]
#1? 252? 640 1134
#2?? 18?? 30?? 20

A.K.
________________________________
From: Edouard Hardy <hardy.edouard at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Cc: Bert Gunter <gunter.berton at gene.com>; R help <r-help at r-project.org> 
Sent: Monday, September 2, 2013 11:46 AM
Subject: Re: [R] Product of certain rows in a matrix



Thank you all for your responses.
The real problem is that all your answer work for products 2 by 2.
I now have to do the product n by n row.
Do you have a solution ?
Thank you in advance,
E.H.?



Edouard Hardy



On Mon, Sep 2, 2013 at 5:43 PM, arun <smartpink111 at yahoo.com> wrote:

I guess in such situations,
>
>
>fun1<- function(mat){
>?if(nrow(mat)%%2==0){
>?j<- 2*seq_len(nrow(mat)/2)
>?b<- mat[j,]* mat[j-1,]
>?}
>?else {mat1<- mat[-nrow(mat),]
>?j<- 2*seq_len(nrow(mat1)/2)
>?b<- rbind(mat1[j,]*mat1[j-1,],mat[nrow(mat),])
>? }
>b
>}
>fun1(A)
>#???? [,1] [,2] [,3]
>
>#[1,]??? 4?? 10?? 18
>#[2,]?? 63?? 64?? 63
>#[3,]?? 18?? 10??? 4
>?fun1(Anew)
>#???? [,1] [,2] [,3]
>
>#[1,]??? 4?? 10?? 18
>#[2,]?? 63?? 64?? 63
>#[3,]?? 18?? 10??? 4
>#[4,]??? 1??? 3??? 5
>
>
>A.K.
>
>
>
>
>----- Original Message -----
>From: arun <smartpink111 at yahoo.com>
>To: Bert Gunter <gunter.berton at gene.com>
>Cc: R help <r-help at r-project.org>
>
>Sent: Monday, September 2, 2013 11:26 AM
>Subject: Re: [R] Product of certain rows in a matrix
>
>Hi Bert,
>Thanks.? It is a better solution.
>
>If nrow() is not even.
>
>Anew<- rbind(A,c(1,3,5))
>j<-seq_len(nrow(Anew)/2)###
>?Anew[j,]*Anew[j-1,]
>#Error in Anew[j, ] * Anew[j - 1, ] : non-conformable arrays
>
>t(sapply(split(as.data.frame(Anew),as.numeric(gl(nrow(Anew),2,7))),colProds))
>? [,1] [,2] [,3]
>1??? 4?? 10?? 18
>2?? 63?? 64?? 63
>3?? 18?? 10??? 4
>4??? 1??? 3??? 5
>
>A.K.
>
>
>
>
>
>
>________________________________
>From: Bert Gunter <gunter.berton at gene.com>
>To: arun <smartpink111 at yahoo.com>
>Cc: R help <r-help at r-project.org>
>Sent: Monday, September 2, 2013 10:55 AM
>Subject: Re: [R] Product of certain rows in a matrix
>
>
>
>These elaborate manipulations are unnecessary and inefficient. Use indexing instead:
>
>j <- 2*seq_len(nrow(A)/2)
>b <- A[j,]*A[j-1,]
>b
>[,1] [,2] [,3]
>[1,]??? 4?? 10?? 18
>[2,]?? 63?? 64?? 63
>[3,]?? 18?? 10??? 4
>
>[,1] [,2] [,3]
>[1,]????4?? 10?? 18
>[2,]?? 63?? 64?? 63
>[3,]?? 18?? 10????4
>[,1] [,2] [,3]
>[1,]????4?? 10?? 18
>[2,]?? 63?? 64?? 63
>[3,]?? 18?? 10????4[,1] [,2] [,3]
>[1,]????4?? 10?? 18
>[2,]?? 63?? 64?? 63
>[3,]?? 18?? 10????4
>[,1] [,2] [,3]
>[1,]????4?? 10?? 18
>[2,]?? 63?? 64?? 63
>[3,]?? 18?? 10????4
>
>
>
>
>
>On Mon, Sep 2, 2013 at 7:25 AM, arun <smartpink111 at yahoo.com> wrote:
>
>Hi,
>>You could try:
>>
>>A<- matrix(unlist(read.table(text="
>>1 2 3
>>4 5 6
>>7 8 9
>>9 8 7
>>6 5 4
>>3 2 1
>>",sep="",header=FALSE)),ncol=3,byrow=FALSE,dimnames=NULL)
>>
>>library(matrixStats)
>>?res1<-t(sapply(split(as.data.frame(A),as.numeric(gl(nrow(A),2,6))),colProds))
>>?res1
>>#? [,1] [,2] [,3]
>>#1??? 4?? 10?? 18
>>#2?? 63?? 64?? 63
>>#3?? 18?? 10??? 4
>>
>>
>>?res2<-t(sapply(split(as.data.frame(A),((seq_len(nrow(A))-1)%/%2)+1),colProds))
>>?identical(res1,res2)
>>#[1] TRUE
>>
>>#or
>>?t(sapply(split(as.data.frame(A),as.numeric(gl(nrow(A),2,6))),function(x) apply(x,2,prod)))
>>
>>#or
>>library(plyr)
>>?as.matrix(ddply(as.data.frame(A),.(as.numeric(gl(nrow(A),2,6))),colProds)[,-1])
>>#???? V1 V2 V3
>>#[1,]? 4 10 18
>>#[2,] 63 64 63
>>#[3,] 18 10? 4
>>
>>#or
>>do.call(rbind,tapply(seq_len(nrow(A)),list(as.numeric(gl(nrow(A),2,6))),FUN=function(x) colProds(A[x,])))
>>#or
>>A1<- data.frame(A,ID=as.numeric(gl(nrow(At),2,6)))
>>?aggregate(A1[,-4],list(A1[,4]),colProds)[,-1]
>>#? X1 X2 X3
>>#1? 4 10 18
>>#2 63 64 63
>>#3 18 10? 4
>>
>>#or
>>library(data.table)
>>At<- data.table(A1,key='ID')
>>subset(At[,lapply(.SD,colProds),by=ID],select=-1)
>>#?? X1 X2 X3
>>#1:? 4 10 18
>>#2: 63 64 63
>>#3: 18 10? 4
>>
>>A.K.
>>
>>
>>
>>
>>Hello,
>>
>>I have this matrix :
>>A =
>>1 2 3
>>4 5 6
>>7 8 9
>>9 8 7
>>6 5 4
>>3 2 1
>>
>>I would like to have this matrix (product of rows 2 by 2) :
>>A =
>>4 10 18
>>63 64 63
>>18 10 4
>>
>>Is it possible to do that without a loop ?
>>
>>Thank you in advance !
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>--
>
>
>Bert Gunter
>Genentech Nonclinical Biostatistics
>
>Internal Contact Info:
>Phone: 467-7374
>Website:
>
>http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>


From nashjc at uottawa.ca  Mon Sep  2 17:57:47 2013
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Mon, 02 Sep 2013 11:57:47 -0400
Subject: [R] quoted expressions in microbenchmark
Message-ID: <5224B57B.9010001@uottawa.ca>

I use microbenchmark to time various of my code segments and find it 
very useful. However, by accident I called it with the expression I 
wanted to time quoted. This simply measured the time to evaluate the 
quote. The following illustrates the difference. When explained, the 
issue is obvious, but I spun some wheels for a while and the example may 
help others.

 > rm(list=ls()) # clear workspace
 > genrose.g <- function(x, gs=100){
 > # vectorized gradient for genrose.f
 > n <- length(x)
 > gg <- as.vector(rep(0, n))
 > tn <- 2:n
 > tn1 <- tn - 1
 > z1 <- x[tn] - x[tn1]^2
 > z2 <- 1 - x[tn]
 > gg[tn] <- 2 * (gs * z1 - z2)
 > gg[tn1] <- gg[tn1] - 4 * gs * x[tn1] * z1
 > return(gg)
 > }
 > require(microbenchmark)
 > trep=1000
 > xx<-rep(pi/2,20)
 > atq<-microbenchmark("genrose.g(xx)", times=trep)
 > print(atq)
 > at<-microbenchmark(genrose.g(xx), times=trep)
 > print(at)

which gives

 > source("tmbench.R")
Unit: nanoseconds
             expr min  lq median  uq   max neval
  "genrose.g(xx)"  70 420    489 489 12851  1000
Unit: microseconds
           expr    min     lq median     uq      max neval
  genrose.g(xx) 47.982 49.868 50.426 51.404 3523.566  1000

Thanks to Olaf Mersmann for a quick response to set me straight. He 
pointed out that sometimes one wants to measure the time to evaluate a 
character string, as in the following.

   > microbenchmark(NULL, "", "asdf", "12345678901234567890", times=1000L)
   Unit: nanoseconds
                      expr min lq median uq max neval
                      NULL  24 25     28 29 161  1000
                        ""  24 25     28 29 121  1000
                    "asdf"  24 25     28 29 161  1000
    "12345678901234567890"  24 28     28 29 542  1000


John Nash


From smartpink111 at yahoo.com  Mon Sep  2 18:07:00 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 2 Sep 2013 09:07:00 -0700 (PDT)
Subject: [R] Product of certain rows in a matrix
In-Reply-To: <CAFsztN4qYoGHvqJOZoz0uYnUm=QnRVt=hP7SDSE5L2ugjL1skA@mail.gmail.com>
References: <1378131907.99820.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CACk-te16jF6r192tcANN6KPN2ig60WgGpR=q+o_1POe2ns2GrA@mail.gmail.com>
	<1378135609.35393.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1378136619.88673.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CAFsztN6R39vUhW9-NLS8eLvRmvXPjGXHmDFO8Jb7=8g1CnEaWA@mail.gmail.com>
	<1378137395.55129.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<CAFsztN4qYoGHvqJOZoz0uYnUm=QnRVt=hP7SDSE5L2ugjL1skA@mail.gmail.com>
Message-ID: <1378138020.41945.YahooMailNeo@web142602.mail.bf1.yahoo.com>



Hi,
No problem.
n<- 4

t(sapply(split(as.data.frame(Anew),as.numeric(gl(nrow(Anew),n,nrow(Anew)))),function(x) apply(x,2,prod)))? 

#? V1? V2?? V3
#1 252 640 1134
#2? 18? 30?? 20


This could be a bit slow if you have big dataset.


A.K.



________________________________
From: Edouard Hardy <hardy.edouard at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Cc: R help <r-help at r-project.org> 
Sent: Monday, September 2, 2013 11:58 AM
Subject: Re: [R] Product of certain rows in a matrix



Thank you A.K.
And do you have a solution without installing any package ?
Thank you in advance.
E.H.



Edouard Hardy



On Mon, Sep 2, 2013 at 5:56 PM, arun <smartpink111 at yahoo.com> wrote:


>
>HI,
>In my first solutions:
>?n<-3
>?t(sapply(split(as.data.frame(Anew),as.numeric(gl(nrow(Anew),n,nrow(Anew)))),colProds))
>#? [,1] [,2] [,3]
>#1?? 28?? 80? 162
>#2? 162?? 80?? 28
>#3??? 1??? 3??? 5
>?n<-4
>?t(sapply(split(as.data.frame(Anew),as.numeric(gl(nrow(Anew),n,nrow(Anew)))),colProds))
>#? [,1] [,2] [,3]
>#1? 252? 640 1134
>#2?? 18?? 30?? 20
>
>A.K.
>
>________________________________
>From: Edouard Hardy <hardy.edouard at gmail.com>
>To: arun <smartpink111 at yahoo.com>
>Cc: Bert Gunter <gunter.berton at gene.com>; R help <r-help at r-project.org>
>Sent: Monday, September 2, 2013 11:46 AM
>
>Subject: Re: [R] Product of certain rows in a matrix
>
>
>
>Thank you all for your responses.
>The real problem is that all your answer work for products 2 by 2.
>I now have to do the product n by n row.
>Do you have a solution ?
>Thank you in advance,
>E.H.?
>
>
>
>Edouard Hardy
>
>
>
>On Mon, Sep 2, 2013 at 5:43 PM, arun <smartpink111 at yahoo.com> wrote:
>
>I guess in such situations,
>>
>>
>>fun1<- function(mat){
>>?if(nrow(mat)%%2==0){
>>?j<- 2*seq_len(nrow(mat)/2)
>>?b<- mat[j,]* mat[j-1,]
>>?}
>>?else {mat1<- mat[-nrow(mat),]
>>?j<- 2*seq_len(nrow(mat1)/2)
>>?b<- rbind(mat1[j,]*mat1[j-1,],mat[nrow(mat),])
>>? }
>>b
>>}
>>fun1(A)
>>#???? [,1] [,2] [,3]
>>
>>#[1,]??? 4?? 10?? 18
>>#[2,]?? 63?? 64?? 63
>>#[3,]?? 18?? 10??? 4
>>?fun1(Anew)
>>#???? [,1] [,2] [,3]
>>
>>#[1,]??? 4?? 10?? 18
>>#[2,]?? 63?? 64?? 63
>>#[3,]?? 18?? 10??? 4
>>#[4,]??? 1??? 3??? 5
>>
>>
>>A.K.
>>
>>
>>
>>
>>----- Original Message -----
>>From: arun <smartpink111 at yahoo.com>
>>To: Bert Gunter <gunter.berton at gene.com>
>>Cc: R help <r-help at r-project.org>
>>
>>Sent: Monday, September 2, 2013 11:26 AM
>>Subject: Re: [R] Product of certain rows in a matrix
>>
>>Hi Bert,
>>Thanks.? It is a better solution.
>>
>>If nrow() is not even.
>>
>>Anew<- rbind(A,c(1,3,5))
>>j<-seq_len(nrow(Anew)/2)###
>>?Anew[j,]*Anew[j-1,]
>>#Error in Anew[j, ] * Anew[j - 1, ] : non-conformable arrays
>>
>>t(sapply(split(as.data.frame(Anew),as.numeric(gl(nrow(Anew),2,7))),colProds))
>>? [,1] [,2] [,3]
>>1??? 4?? 10?? 18
>>2?? 63?? 64?? 63
>>3?? 18?? 10??? 4
>>4??? 1??? 3??? 5
>>
>>A.K.
>>
>>
>>
>>
>>
>>
>>________________________________
>>From: Bert Gunter <gunter.berton at gene.com>
>>To: arun <smartpink111 at yahoo.com>
>>Cc: R help <r-help at r-project.org>
>>Sent: Monday, September 2, 2013 10:55 AM
>>Subject: Re: [R] Product of certain rows in a matrix
>>
>>
>>
>>These elaborate manipulations are unnecessary and inefficient. Use indexing instead:
>>
>>j <- 2*seq_len(nrow(A)/2)
>>b <- A[j,]*A[j-1,]
>>b
>>[,1] [,2] [,3]
>>[1,]??? 4?? 10?? 18
>>[2,]?? 63?? 64?? 63
>>[3,]?? 18?? 10??? 4
>>
>>[,1] [,2] [,3]
>>[1,]????4?? 10?? 18
>>[2,]?? 63?? 64?? 63
>>[3,]?? 18?? 10????4
>>[,1] [,2] [,3]
>>[1,]????4?? 10?? 18
>>[2,]?? 63?? 64?? 63
>>[3,]?? 18?? 10????4[,1] [,2] [,3]
>>[1,]????4?? 10?? 18
>>[2,]?? 63?? 64?? 63
>>[3,]?? 18?? 10????4
>>[,1] [,2] [,3]
>>[1,]????4?? 10?? 18
>>[2,]?? 63?? 64?? 63
>>[3,]?? 18?? 10????4
>>
>>
>>
>>
>>
>>On Mon, Sep 2, 2013 at 7:25 AM, arun <smartpink111 at yahoo.com> wrote:
>>
>>Hi,
>>>You could try:
>>>
>>>A<- matrix(unlist(read.table(text="
>>>1 2 3
>>>4 5 6
>>>7 8 9
>>>9 8 7
>>>6 5 4
>>>3 2 1
>>>",sep="",header=FALSE)),ncol=3,byrow=FALSE,dimnames=NULL)
>>>
>>>library(matrixStats)
>>>?res1<-t(sapply(split(as.data.frame(A),as.numeric(gl(nrow(A),2,6))),colProds))
>>>?res1
>>>#? [,1] [,2] [,3]
>>>#1??? 4?? 10?? 18
>>>#2?? 63?? 64?? 63
>>>#3?? 18?? 10??? 4
>>>
>>>
>>>?res2<-t(sapply(split(as.data.frame(A),((seq_len(nrow(A))-1)%/%2)+1),colProds))
>>>?identical(res1,res2)
>>>#[1] TRUE
>>>
>>>#or
>>>?t(sapply(split(as.data.frame(A),as.numeric(gl(nrow(A),2,6))),function(x) apply(x,2,prod)))
>>>
>>>#or
>>>library(plyr)
>>>?as.matrix(ddply(as.data.frame(A),.(as.numeric(gl(nrow(A),2,6))),colProds)[,-1])
>>>#???? V1 V2 V3
>>>#[1,]? 4 10 18
>>>#[2,] 63 64 63
>>>#[3,] 18 10? 4
>>>
>>>#or
>>>do.call(rbind,tapply(seq_len(nrow(A)),list(as.numeric(gl(nrow(A),2,6))),FUN=function(x) colProds(A[x,])))
>>>#or
>>>A1<- data.frame(A,ID=as.numeric(gl(nrow(At),2,6)))
>>>?aggregate(A1[,-4],list(A1[,4]),colProds)[,-1]
>>>#? X1 X2 X3
>>>#1? 4 10 18
>>>#2 63 64 63
>>>#3 18 10? 4
>>>
>>>#or
>>>library(data.table)
>>>At<- data.table(A1,key='ID')
>>>subset(At[,lapply(.SD,colProds),by=ID],select=-1)
>>>#?? X1 X2 X3
>>>#1:? 4 10 18
>>>#2: 63 64 63
>>>#3: 18 10? 4
>>>
>>>A.K.
>>>
>>>
>>>
>>>
>>>Hello,
>>>
>>>I have this matrix :
>>>A =
>>>1 2 3
>>>4 5 6
>>>7 8 9
>>>9 8 7
>>>6 5 4
>>>3 2 1
>>>
>>>I would like to have this matrix (product of rows 2 by 2) :
>>>A =
>>>4 10 18
>>>63 64 63
>>>18 10 4
>>>
>>>Is it possible to do that without a loop ?
>>>
>>>Thank you in advance !
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>>--
>>
>>
>>Bert Gunter
>>Genentech Nonclinical Biostatistics
>>
>>Internal Contact Info:
>>Phone: 467-7374
>>Website:
>>
>>http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>>
>


From smartpink111 at yahoo.com  Mon Sep  2 18:22:52 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 2 Sep 2013 09:22:52 -0700 (PDT)
Subject: [R] Meaning of "Integer,19"
In-Reply-To: <834A888E-38CF-4CB9-9557-0219D9217265@warwick.ac.uk>
References: <834A888E-38CF-4CB9-9557-0219D9217265@warwick.ac.uk>
Message-ID: <1378138972.82838.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,

If you check ?str()
str(zseq)
#List of 6
# $ : int [1:19] 1 2 3 4 5 6 7 8 9 10 ...
# $ : int [1:20] 1 2 3 4 5 6 7 8 9 10 ...
# $ : int [1:21] 1 2 3 4 5 6 7 8 9 10 ...
# $ : int [1:22] 1 2 3 4 5 6 7 8 9 10 ...
# $ : int [1:23] 1 2 3 4 5 6 7 8 9 10 ...
# $ : int [1:24] 1 2 3 4 5 6 7 8 9 10 ...
# - attr(*, "dim")= int [1:2] 2 3


Can access each list element by:
zseq[[1]]
# [1]? 1? 2? 3? 4? 5? 6? 7? 8? 9 10 11 12 13 14 15 16 17 18 19


#Integer is the class and 19, 20, 21,... are the total number of elements

? lapply(zseq,unlist)
[[1]]
?[1]? 1? 2? 3? 4? 5? 6? 7? 8? 9 10 11 12 13 14 15 16 17 18 19

[[2]]
?[1]? 1? 2? 3? 4? 5? 6? 7? 8? 9 10 11 12 13 14 15 16 17 18 19 20

[[3]]
?[1]? 1? 2? 3? 4? 5? 6? 7? 8? 9 10 11 12 13 14 15 16 17 18 19 20 21

[[4]]
?[1]? 1? 2? 3? 4? 5? 6? 7? 8? 9 10 11 12 13 14 15 16 17 18 19 20 21 22

[[5]]
?[1]? 1? 2? 3? 4? 5? 6? 7? 8? 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23

[[6]]
?[1]? 1? 2? 3? 4? 5? 6? 7? 8? 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24


A.K.

----- Original Message -----
From: David Epstein <David.Epstein at warwick.ac.uk>
To: r-help at r-project.org
Cc: 
Sent: Monday, September 2, 2013 11:42 AM
Subject: [R] Meaning of "Integer,19"

I tried example('apply'). Among the various examples, there was the following:

apply> z <- array(1:24, dim = 2:4)
apply> zseq <- apply(z, 1:2, function(x) seq_len(max(x)))
apply> zseq? ? ? ?  ## a 2 x 3 matrix
? ?  [,1]? ? ?  [,2]? ? ?  [,3]
[1,] Integer,19 Integer,21 Integer,23
[2,] Integer,20 Integer,22 Integer,24

The entry "Integer,19" seems to mean the list of integers [1:19], though I'm just guessing. Possibly it means some list of 19 integers.

Questions:
Is the notation "Integer,19" documented somewhere? I can't find it.
How might one proceed to find out the meaning of this notation if one didn't know it before?
The actual substance of my question is a request for advice on how, in general, to look for documentation in R.

I know about help.start(), help.search() and RSiteSearch(). Also, I know how to search the archives of r-help. Are there other methods of searching R that I should try?
Usually I get more hits than I can cope with.
Thanks










??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Mon Sep  2 19:57:20 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 2 Sep 2013 10:57:20 -0700 (PDT)
Subject: [R] Product of certain rows in a matrix
In-Reply-To: <1378138020.41945.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1378131907.99820.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CACk-te16jF6r192tcANN6KPN2ig60WgGpR=q+o_1POe2ns2GrA@mail.gmail.com>
	<1378135609.35393.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1378136619.88673.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CAFsztN6R39vUhW9-NLS8eLvRmvXPjGXHmDFO8Jb7=8g1CnEaWA@mail.gmail.com>
	<1378137395.55129.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<CAFsztN4qYoGHvqJOZoz0uYnUm=QnRVt=hP7SDSE5L2ugjL1skA@mail.gmail.com>
	<1378138020.41945.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1378144640.20493.YahooMailNeo@web142603.mail.bf1.yahoo.com>

HI,
You could modify Bert's solution:
n<-3

j3<-n*seq_len(nrow(A)/n)
A[j3,]*A[j3-1,]*A[j3-2,]? ##assuming that nrow(dataset)%%n==0
#???? [,1] [,2] [,3]
#[1,]?? 28?? 80? 162
#[2,]? 162?? 80?? 28


#Speed comparison


set.seed(28)
mat1<- matrix(sample(1:20,1e5*3,replace=TRUE),ncol=3)

n<-4
system.time({res1<- t(sapply(split(as.data.frame(mat1),as.numeric(gl(nrow(mat1),n,nrow(mat1)))),function(x) apply(x,2,prod))) })
#? user? system elapsed 
#? 8.508?? 0.620?? 9.146 
system.time({res2<- t(sapply(split(as.data.frame(mat1),as.numeric(gl(nrow(mat1),n,nrow(mat1)))),function(x) Reduce("*",as.data.frame(t(x))))) })
# user? system elapsed 
#? 8.556?? 0.000?? 8.566 

A1<- data.frame(mat1,ID=as.numeric(gl(nrow(mat1),n,nrow(mat1))))
?system.time({res3<- aggregate(A1[,-4],list(A1[,4]),colProds)[,-1]})
# user? system elapsed 
# 11.536?? 0.000? 11.553 


nrow(mat1)%%n
#[1] 0
system.time({j4<- n*seq_len(nrow(mat1)/n)
??? ??? res5<- mat1[j4,]*mat1[j4-1,]*mat1[j4-2,]*mat1[j4-3,]
??? ? })

# user? system elapsed 
#? 0.004?? 0.000?? 0.004 

?dimnames(res2)<- dimnames(res5)
identical(res2,res5)
#[1] TRUE


#if
n<-6
?nrow(mat1)%%6
#[1] 4


system.time({
?mat2<-mat1[seq(nrow(mat1)-4),]
j6<- n*seq_len(nrow(mat2)/n)
?res6<- mat2[j6,]*mat2[j6-1,]*mat2[j6-2,]*mat2[j6-3,]*mat2[j6-4,]*mat2[j6-5,]
res6New<-rbind(res6,apply(tail(mat1,4),2,prod)
)})

#? user? system elapsed 
?# 0.004?? 0.000?? 0.006 



system.time({res6Alt<- 
t(sapply(split(as.data.frame(mat1),as.numeric(gl(nrow(mat1),n,nrow(mat1)))),function(x) Reduce("*",as.data.frame(t(x))))) })
#user? system elapsed 
?# 5.576?? 0.000?? 5.583 
dimnames(res6Alt)<- dimnames(res6New)


all.equal(res6New,res6Alt)
#[1] TRUE


A.K.



As you said, this is very loooong. 
Do you have a better solution on big data ? 



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Edouard Hardy <hardy.edouard at gmail.com>
Cc: R help <r-help at r-project.org>; Bert Gunter <gunter.berton at gene.com>
Sent: Monday, September 2, 2013 12:07 PM
Subject: Re: [R] Product of certain rows in a matrix



Hi,
No problem.
n<- 4

t(sapply(split(as.data.frame(Anew),as.numeric(gl(nrow(Anew),n,nrow(Anew)))),function(x) apply(x,2,prod)))? 

#? V1? V2?? V3
#1 252 640 1134
#2? 18? 30?? 20


This could be a bit slow if you have big dataset.


A.K.



________________________________
From: Edouard Hardy <hardy.edouard at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Cc: R help <r-help at r-project.org> 
Sent: Monday, September 2, 2013 11:58 AM
Subject: Re: [R] Product of certain rows in a matrix



Thank you A.K.
And do you have a solution without installing any package ?
Thank you in advance.
E.H.



Edouard Hardy



On Mon, Sep 2, 2013 at 5:56 PM, arun <smartpink111 at yahoo.com> wrote:


>
>HI,
>In my first solutions:
>?n<-3
>?t(sapply(split(as.data.frame(Anew),as.numeric(gl(nrow(Anew),n,nrow(Anew)))),colProds))
>#? [,1] [,2] [,3]
>#1?? 28?? 80? 162
>#2? 162?? 80?? 28
>#3??? 1??? 3??? 5
>?n<-4
>?t(sapply(split(as.data.frame(Anew),as.numeric(gl(nrow(Anew),n,nrow(Anew)))),colProds))
>#? [,1] [,2] [,3]
>#1? 252? 640 1134
>#2?? 18?? 30?? 20
>
>A.K.
>
>________________________________
>From: Edouard Hardy <hardy.edouard at gmail.com>
>To: arun <smartpink111 at yahoo.com>
>Cc: Bert Gunter <gunter.berton at gene.com>; R help <r-help at r-project.org>
>Sent: Monday, September 2, 2013 11:46 AM
>
>Subject: Re: [R] Product of certain rows in a matrix
>
>
>
>Thank you all for your responses.
>The real problem is that all your answer work for products 2 by 2.
>I now have to do the product n by n row.
>Do you have a solution ?
>Thank you in advance,
>E.H.?
>
>
>
>Edouard Hardy
>
>
>
>On Mon, Sep 2, 2013 at 5:43 PM, arun <smartpink111 at yahoo.com> wrote:
>
>I guess in such situations,
>>
>>
>>fun1<- function(mat){
>>?if(nrow(mat)%%2==0){
>>?j<- 2*seq_len(nrow(mat)/2)
>>?b<- mat[j,]* mat[j-1,]
>>?}
>>?else {mat1<- mat[-nrow(mat),]
>>?j<- 2*seq_len(nrow(mat1)/2)
>>?b<- rbind(mat1[j,]*mat1[j-1,],mat[nrow(mat),])
>>? }
>>b
>>}
>>fun1(A)
>>#???? [,1] [,2] [,3]
>>
>>#[1,]??? 4?? 10?? 18
>>#[2,]?? 63?? 64?? 63
>>#[3,]?? 18?? 10??? 4
>>?fun1(Anew)
>>#???? [,1] [,2] [,3]
>>
>>#[1,]??? 4?? 10?? 18
>>#[2,]?? 63?? 64?? 63
>>#[3,]?? 18?? 10??? 4
>>#[4,]??? 1??? 3??? 5
>>
>>
>>A.K.
>>
>>
>>
>>
>>----- Original Message -----
>>From: arun <smartpink111 at yahoo.com>
>>To: Bert Gunter <gunter.berton at gene.com>
>>Cc: R help <r-help at r-project.org>
>>
>>Sent: Monday, September 2, 2013 11:26 AM
>>Subject: Re: [R] Product of certain rows in a matrix
>>
>>Hi Bert,
>>Thanks.? It is a better solution.
>>
>>If nrow() is not even.
>>
>>Anew<- rbind(A,c(1,3,5))
>>j<-seq_len(nrow(Anew)/2)###
>>?Anew[j,]*Anew[j-1,]
>>#Error in Anew[j, ] * Anew[j - 1, ] : non-conformable arrays
>>
>>t(sapply(split(as.data.frame(Anew),as.numeric(gl(nrow(Anew),2,7))),colProds))
>>? [,1] [,2] [,3]
>>1??? 4?? 10?? 18
>>2?? 63?? 64?? 63
>>3?? 18?? 10??? 4
>>4??? 1??? 3??? 5
>>
>>A.K.
>>
>>
>>
>>
>>
>>
>>________________________________
>>From: Bert Gunter <gunter.berton at gene.com>
>>To: arun <smartpink111 at yahoo.com>
>>Cc: R help <r-help at r-project.org>
>>Sent: Monday, September 2, 2013 10:55 AM
>>Subject: Re: [R] Product of certain rows in a matrix
>>
>>
>>
>>These elaborate manipulations are unnecessary and inefficient. Use indexing instead:
>>
>>j <- 2*seq_len(nrow(A)/2)
>>b <- A[j,]*A[j-1,]
>>b
>>[,1] [,2] [,3]
>>[1,]??? 4?? 10?? 18
>>[2,]?? 63?? 64?? 63
>>[3,]?? 18?? 10??? 4
>>
>>[,1] [,2] [,3]
>>[1,]????4?? 10?? 18
>>[2,]?? 63?? 64?? 63
>>[3,]?? 18?? 10????4
>>[,1] [,2] [,3]
>>[1,]????4?? 10?? 18
>>[2,]?? 63?? 64?? 63
>>[3,]?? 18?? 10????4[,1] [,2] [,3]
>>[1,]????4?? 10?? 18
>>[2,]?? 63?? 64?? 63
>>[3,]?? 18?? 10????4
>>[,1] [,2] [,3]
>>[1,]????4?? 10?? 18
>>[2,]?? 63?? 64?? 63
>>[3,]?? 18?? 10????4
>>
>>
>>
>>
>>
>>On Mon, Sep 2, 2013 at 7:25 AM, arun <smartpink111 at yahoo.com> wrote:
>>
>>Hi,
>>>You could try:
>>>
>>>A<- matrix(unlist(read.table(text="
>>>1 2 3
>>>4 5 6
>>>7 8 9
>>>9 8 7
>>>6 5 4
>>>3 2 1
>>>",sep="",header=FALSE)),ncol=3,byrow=FALSE,dimnames=NULL)
>>>
>>>library(matrixStats)
>>>?res1<-t(sapply(split(as.data.frame(A),as.numeric(gl(nrow(A),2,6))),colProds))
>>>?res1
>>>#? [,1] [,2] [,3]
>>>#1??? 4?? 10?? 18
>>>#2?? 63?? 64?? 63
>>>#3?? 18?? 10??? 4
>>>
>>>
>>>?res2<-t(sapply(split(as.data.frame(A),((seq_len(nrow(A))-1)%/%2)+1),colProds))
>>>?identical(res1,res2)
>>>#[1] TRUE
>>>
>>>#or
>>>?t(sapply(split(as.data.frame(A),as.numeric(gl(nrow(A),2,6))),function(x) apply(x,2,prod)))
>>>
>>>#or
>>>library(plyr)
>>>?as.matrix(ddply(as.data.frame(A),.(as.numeric(gl(nrow(A),2,6))),colProds)[,-1])
>>>#???? V1 V2 V3
>>>#[1,]? 4 10 18
>>>#[2,] 63 64 63
>>>#[3,] 18 10? 4
>>>
>>>#or
>>>do.call(rbind,tapply(seq_len(nrow(A)),list(as.numeric(gl(nrow(A),2,6))),FUN=function(x) colProds(A[x,])))
>>>#or
>>>A1<- data.frame(A,ID=as.numeric(gl(nrow(At),2,6)))
>>>?aggregate(A1[,-4],list(A1[,4]),colProds)[,-1]
>>>#? X1 X2 X3
>>>#1? 4 10 18
>>>#2 63 64 63
>>>#3 18 10? 4
>>>
>>>#or
>>>library(data.table)
>>>At<- data.table(A1,key='ID')
>>>subset(At[,lapply(.SD,colProds),by=ID],select=-1)
>>>#?? X1 X2 X3
>>>#1:? 4 10 18
>>>#2: 63 64 63
>>>#3: 18 10? 4
>>>
>>>A.K.
>>>
>>>
>>>
>>>
>>>Hello,
>>>
>>>I have this matrix :
>>>A =
>>>1 2 3
>>>4 5 6
>>>7 8 9
>>>9 8 7
>>>6 5 4
>>>3 2 1
>>>
>>>I would like to have this matrix (product of rows 2 by 2) :
>>>A =
>>>4 10 18
>>>63 64 63
>>>18 10 4
>>>
>>>Is it possible to do that without a loop ?
>>>
>>>Thank you in advance !
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>>--
>>
>>
>>Bert Gunter
>>Genentech Nonclinical Biostatistics
>>
>>Internal Contact Info:
>>Phone: 467-7374
>>Website:
>>
>>http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>>
>


From szehnder at uni-bonn.de  Mon Sep  2 20:49:10 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Mon, 2 Sep 2013 20:49:10 +0200
Subject: [R] How to catch errors regarding the hessian in 'optim'
In-Reply-To: <5224A3B9.8030408@uottawa.ca>
References: <mailman.11.1378116005.20733.r-help@r-project.org>
	<5224A3B9.8030408@uottawa.ca>
Message-ID: <BE4DE675-0FDC-48F6-B520-75513B3FDCED@uni-bonn.de>

Dear John,

thank you very much for your answer. I take a look at these packages (Rvmmin and Rcgmin). That sounds very interesting. 

For the example: The method relies on data which I always try to avoid to send on the r-help list - not that my data is confidential - but it becomes even more cumbersome when sending datasets over the list. I made the experience, that in such case answers are rare. Maybe you have a suggestion if and how users should send data with their code. I am interested in your opinion and thankful for sharing it.

Best

Simon


On Sep 2, 2013, at 4:42 PM, Prof J C Nash (U30A) <nashjc at uottawa.ca> wrote:

> This may be one of the many mysteries of the internals of L-BFGS-B, which I have found fails from time to time. That is one of the reasons for Rvmmin and Rcgmin (and hopefully sooner rather than later Rtn - a truncated Newton method, currently working for unconstrained problems, but still glitchy for bounds constraints). These are all-R codes so that users and developers can get inside to control special situations.
> 
> If you have a test problem -- the infamous reproducible example -- there are several of us who can likely help to sort out your troubles.
> 
> JN
> 
> 
> On 13-09-02 06:00 AM, r-help-request at r-project.org wrote:
>> Message: 10
>> Date: Sun, 1 Sep 2013 17:09:35 +0200
>> From: Simon Zehnder<szehnder at uni-bonn.de>
>> To: R-help help<r-help at r-project.org>
>> Subject: [R] How to catch errors regarding the hessian in 'optim'
>> Message-ID:<EB37670E-8544-4C89-9172-245EB6CC596A at uni-bonn.de>
>> Content-Type: text/plain; charset=us-ascii
>> 
>> Dear R-Users and R-Developers,
>> 
>> in a comparison between two different estimation approaches I would like to catch errors from optim regarding the hessian matrix.
>> 
>> I use optim with method = "L-BFGS-B" thereby relying on numerical differentiation for the hessian matrix. I do know, that the estimation approach that uses numerical optimization has sometimes problems with singular hessian matrices and I consider it as one of its disadvantages of this method. To show the frequency of such problems in my simulation study I have to set 'hessian = TRUE' and to collect the errors from optim regarding the hessian.
>> 
>> Now I am a little stucked how I could catch specifically errors from the hessian matrix in 'optim'. I do know that such errors are thrown most certainly from function 'La_solve' in Lapack.c. Does anyone has an idea how I could solve this task (clearly with tryCatch but how to choose only errors for the hessian)?
>> 
>> 
>> Best
>> 
>> Simon


From gunter.berton at gene.com  Mon Sep  2 20:58:14 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 2 Sep 2013 11:58:14 -0700
Subject: [R] Product of certain rows in a matrix
In-Reply-To: <1378144640.20493.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1378131907.99820.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CACk-te16jF6r192tcANN6KPN2ig60WgGpR=q+o_1POe2ns2GrA@mail.gmail.com>
	<1378135609.35393.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1378136619.88673.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CAFsztN6R39vUhW9-NLS8eLvRmvXPjGXHmDFO8Jb7=8g1CnEaWA@mail.gmail.com>
	<1378137395.55129.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<CAFsztN4qYoGHvqJOZoz0uYnUm=QnRVt=hP7SDSE5L2ugjL1skA@mail.gmail.com>
	<1378138020.41945.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1378144640.20493.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <CACk-te3s3f45FYq-vULyQq4OobLZD9SZ61Qp89wKoOnWsuXHfA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130902/c2231d43/attachment.pl>

From David.Epstein at warwick.ac.uk  Mon Sep  2 21:18:21 2013
From: David.Epstein at warwick.ac.uk (David Epstein)
Date: Mon, 2 Sep 2013 20:18:21 +0100
Subject: [R] Sweave: printing an underscore in the output from an R
	command
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427CD351B5F@inbomail.inbo.be>
References: <8AAFC6A6-757E-4E74-A4BB-4D0A55037290@warwick.ac.uk>
	<AA818EAD2576BC488B4F623941DA7427CD351B5F@inbomail.inbo.be>
Message-ID: <A39E6A7C-11FF-4832-B251-146FF45450A6@warwick.ac.uk>

Dear Thierry,

Your suggestion doesn't work on my version of R. Here's what I get
> gsub("_", "\_", print(version$platform)
Error: '\_' is an unrecognized escape in character string starting ""\_"
> print(gsub("_", "\_", version$platform))
Error: '\_' is an unrecognized escape in character string starting ""\_"

> sub("_", "\\_", version$platform)
[1] "x86_64-apple-darwin10.8.0"
Sweave does not evaluate this expression when \Sexpr is applied and a tex error results

> sub("_", "\\\_", version$platform)
Error: '\_' is an unrecognized escape in character string starting ""\\\_"
Error message from R

> sub("_", "\\\\_", version$platform)
[1] "x86\\_64-apple-darwin10.8.0"
R evaluates this. However, the above examples indicate a deficiency/possible bug in the command sub, because sub does not seem to be able to output an expression with a single backslash.

I tried the previous version as follows in my .Rnw document
\Sexpr{print(sub("_", "\\\\_", version$platform))}
When Sweave is run, this expression is evaluated to illegal LaTeX

David.




On 2 Sep 2013, at 16:47, ONKELINX, Thierry wrote:

> You have to escape the underscore
> 
> \Sexpr{gsub("_", "\_", print(version$platform))}
> 
> Best regards,
> 
> Thierry
> 
> ________________________________________
> Van: r-help-bounces at r-project.org [r-help-bounces at r-project.org] namens David Epstein [David.Epstein at warwick.ac.uk]
> Verzonden: maandag 2 september 2013 17:38
> Aan: r-help at r-project.org
> Onderwerp: [R] Sweave: printing an underscore in the output from an R command
> 
> I am working with Sweave and would like to print out into my latex document the result of the R command
> version$platform
> So what I first tried in my .Rnw document was \Sexpr{print(version$platform)}.
> 
> However, the output from this command is the string "x86_64-apple-darwin10.8.0" (without the quotes). This contains an underscore, which is a special character in tex and so I get an error message from latex.
> 
> I can get round this by using sub to replace underscore with a space, but I would like to know how to print the underscore if I really wanted to do so.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
> The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.
> 


From smartpink111 at yahoo.com  Mon Sep  2 21:25:20 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 2 Sep 2013 12:25:20 -0700 (PDT)
Subject: [R] Product of certain rows in a matrix
In-Reply-To: <CAFsztN48yEEy_eik1twtHUo+D0U=qn7HNrFoJpFx5aDY_fWnOQ@mail.gmail.com>
References: <1378131907.99820.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CACk-te16jF6r192tcANN6KPN2ig60WgGpR=q+o_1POe2ns2GrA@mail.gmail.com>
	<1378135609.35393.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1378136619.88673.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CAFsztN6R39vUhW9-NLS8eLvRmvXPjGXHmDFO8Jb7=8g1CnEaWA@mail.gmail.com>
	<1378137395.55129.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<CAFsztN4qYoGHvqJOZoz0uYnUm=QnRVt=hP7SDSE5L2ugjL1skA@mail.gmail.com>
	<1378138020.41945.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1378144640.20493.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1378146465.5182.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<CAFsztN48yEEy_eik1twtHUo+D0U=qn7HNrFoJpFx5aDY_fWnOQ@mail.gmail.com>
Message-ID: <1378149920.4422.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
You can try this:
n<- 3
j3<-n*seq_len(nrow(A)/n)
vec1<- rep("j3",n)
eval(parse(text=paste0("A","[",paste0(vec1,"-",seq(n)-1),",]",collapse="*")))
#???? [,1] [,2] [,3]
#[1,]?? 28?? 80? 162
#[2,]? 162?? 80?? 28

Just saw Bert's new solution:
n<-3
?j <- seq_len(nrow(A))%%n
?b <- A[j==0,]
?for(i in seq_len(n-1))b <- b*A[j==i,]
?b
#???? [,1] [,2] [,3]
#[1,]?? 28?? 80? 162
#[2,]? 162?? 80?? 28







#For the bigger dataset with large "n, these methods may not work:


set.seed(28)
mat1<- matrix(sample(1:20,1e5*3,replace=TRUE),ncol=3)

n<- 40
nrow(mat1)%%40
#[1] 0


j <- seq_len(nrow(mat1))%%n
b <- mat1[j==0,]
for(i in seq_len(n-1))b <- b*mat1[j==i,]

Warning messages:
1: In b * mat1[j == i, ] : NAs produced by integer overflow
2: In b * mat1[j == i, ] : NAs produced by integer overflow
3: In b * mat1[j == i, ] : NAs produced by integer overflow
4: In b * mat1[j == i, ] : NAs produced by integer overflow
5: In b * mat1[j == i, ] : NAs produced by integer overflow
6: In b * mat1[j == i, ] : NAs produced by integer overflow
7: In b * mat1[j == i, ] : NAs produced by integer overflow
8: In b * mat1[j == i, ] : NAs produced by integer overflow
9: In b * mat1[j == i, ] : NAs produced by integer overflow
10: In b * mat1[j == i, ] : NAs produced by integer overflow

head(b,3)
#???? [,1] [,2] [,3]
#[1,]?? NA?? NA?? NA
#[2,]?? NA?? NA?? NA
#[3,]?? NA?? NA?? NA


j40<- n*seq_len(nrow(mat1)/n)
?vec1<- rep("j40",n)
?vec1<- rep("j22",n)
?res<- eval(parse(text= paste(paste0("mat1","[",paste0(vec1,"-",seq(n)-1),",]"),collapse="*")
?))
Warning messages:
1: In mat1[j22 - 0, ] * mat1[j22 - 1, ] * mat1[j22 - 2, ] * mat1[j22 -? :
? NAs produced by integer overflow
2: In mat1[j22 - 0, ] * mat1[j22 - 1, ] * mat1[j22 - 2, ] * mat1[j22 -? :
? NAs produced by integer overflow
3: In mat1[j22 - 0, ] * mat1[j22 - 1, ] * mat1[j22 - 2, ] * mat1[j22 -? :
? NAs produced by integer overflow
4: In mat1[j22 - 0, ] * mat1[j22 - 1, ] * mat1[j22 - 2, ] * mat1[j22 -? :
?head(res,3)
#???? [,1] [,2] [,3]
#[1,]?? NA?? NA?? NA
#[2,]?? NA?? NA?? NA
#[3,]?? NA?? NA?? NA


A.K.





________________________________
From: Edouard Hardy <hardy.edouard at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Monday, September 2, 2013 2:32 PM
Subject: Re: [R] Product of certain rows in a matrix



Yes, n is 250 or more...



Edouard Hardy



On Mon, Sep 2, 2013 at 8:31 PM, arun <smartpink111 at yahoo.com> wrote:

Also, BTW, are you looking for n>100?
>
>
>
>
>
>





On Mon, Sep 2, 2013 at 8:27 PM, arun <smartpink111 at yahoo.com> wrote:


>
>Hi,
>
>Not sure I understand your question.? If you don't know "n", then how are you applying other solutions also..
>A.K.
>
>
>
>Again, thank you for your help.
>
>I understand Bert's solution but this is possible only if I know n.
>
>How can I do A[j3,]*A[j3-1,]*A[j3-2,] (n=3) for n terms ?
>
>
>
>----- Original Message -----
>From: arun <smartpink111 at yahoo.com>
>To: Edouard Hardy <hardy.edouard at gmail.com>
>Cc: R help <r-help at r-project.org>; Bert Gunter <gunter.berton at gene.com>
>
>Sent: Monday, September 2, 2013 1:57 PM
>Subject: Re: [R] Product of certain rows in a matrix
>
>HI,
>You could modify Bert's solution:
>n<-3
>
>j3<-n*seq_len(nrow(A)/n)
>A[j3,]*A[j3-1,]*A[j3-2,]? ##assuming that nrow(dataset)%%n==0
>#???? [,1] [,2] [,3]
>#[1,]?? 28?? 80? 162
>#[2,]? 162?? 80?? 28
>
>
>#Speed comparison
>
>
>set.seed(28)
>mat1<- matrix(sample(1:20,1e5*3,replace=TRUE),ncol=3)
>
>n<-4
>system.time({res1<- t(sapply(split(as.data.frame(mat1),as.numeric(gl(nrow(mat1),n,nrow(mat1)))),function(x) apply(x,2,prod))) })
>#? user? system elapsed
>#? 8.508?? 0.620?? 9.146
>system.time({res2<- t(sapply(split(as.data.frame(mat1),as.numeric(gl(nrow(mat1),n,nrow(mat1)))),function(x) Reduce("*",as.data.frame(t(x))))) })
># user? system elapsed
>#? 8.556?? 0.000?? 8.566
>
>A1<- data.frame(mat1,ID=as.numeric(gl(nrow(mat1),n,nrow(mat1))))
>?system.time({res3<- aggregate(A1[,-4],list(A1[,4]),colProds)[,-1]})
># user? system elapsed
># 11.536?? 0.000? 11.553
>
>
>nrow(mat1)%%n
>#[1] 0
>system.time({j4<- n*seq_len(nrow(mat1)/n)
>??? ??? res5<- mat1[j4,]*mat1[j4-1,]*mat1[j4-2,]*mat1[j4-3,]
>??? ? })
>
># user? system elapsed
>#? 0.004?? 0.000?? 0.004
>
>?dimnames(res2)<- dimnames(res5)
>identical(res2,res5)
>#[1] TRUE
>
>
>#if
>n<-6
>?nrow(mat1)%%6
>#[1] 4
>
>
>system.time({
>?mat2<-mat1[seq(nrow(mat1)-4),]
>j6<- n*seq_len(nrow(mat2)/n)
>?res6<- mat2[j6,]*mat2[j6-1,]*mat2[j6-2,]*mat2[j6-3,]*mat2[j6-4,]*mat2[j6-5,]
>res6New<-rbind(res6,apply(tail(mat1,4),2,prod)
>)})
>
>#? user? system elapsed
>?# 0.004?? 0.000?? 0.006
>
>
>
>system.time({res6Alt<-
>t(sapply(split(as.data.frame(mat1),as.numeric(gl(nrow(mat1),n,nrow(mat1)))),function(x) Reduce("*",as.data.frame(t(x))))) })
>#user? system elapsed
>?# 5.576?? 0.000?? 5.583
>dimnames(res6Alt)<- dimnames(res6New)
>
>
>all.equal(res6New,res6Alt)
>#[1] TRUE
>
>
>A.K.
>
>
>
>As you said, this is very loooong.
>Do you have a better solution on big data ?
>
>
>
>----- Original Message -----
>From: arun <smartpink111 at yahoo.com>
>To: Edouard Hardy <hardy.edouard at gmail.com>
>Cc: R help <r-help at r-project.org>; Bert Gunter <gunter.berton at gene.com>
>Sent: Monday, September 2, 2013 12:07 PM
>Subject: Re: [R] Product of certain rows in a matrix
>
>
>
>Hi,
>No problem.
>n<- 4
>
>t(sapply(split(as.data.frame(Anew),as.numeric(gl(nrow(Anew),n,nrow(Anew)))),function(x) apply(x,2,prod)))?
>
>#? V1? V2?? V3
>#1 252 640 1134
>#2? 18? 30?? 20
>
>
>This could be a bit slow if you have big dataset.
>
>
>A.K.
>
>
>
>________________________________
>From: Edouard Hardy <hardy.edouard at gmail.com>
>To: arun <smartpink111 at yahoo.com>
>Cc: R help <r-help at r-project.org>
>Sent: Monday, September 2, 2013 11:58 AM
>Subject: Re: [R] Product of certain rows in a matrix
>
>
>
>Thank you A.K.
>And do you have a solution without installing any package ?
>Thank you in advance.
>E.H.
>
>
>
>Edouard Hardy
>
>
>
>On Mon, Sep 2, 2013 at 5:56 PM, arun <smartpink111 at yahoo.com> wrote:
>
>
>>
>>HI,
>>In my first solutions:
>>?n<-3
>>?t(sapply(split(as.data.frame(Anew),as.numeric(gl(nrow(Anew),n,nrow(Anew)))),colProds))
>>#? [,1] [,2] [,3]
>>#1?? 28?? 80? 162
>>#2? 162?? 80?? 28
>>#3??? 1??? 3??? 5
>>?n<-4
>>?t(sapply(split(as.data.frame(Anew),as.numeric(gl(nrow(Anew),n,nrow(Anew)))),colProds))
>>#? [,1] [,2] [,3]
>>#1? 252? 640 1134
>>#2?? 18?? 30?? 20
>>
>>A.K.
>>
>>________________________________
>>From: Edouard Hardy <hardy.edouard at gmail.com>
>>To: arun <smartpink111 at yahoo.com>
>>Cc: Bert Gunter <gunter.berton at gene.com>; R help <r-help at r-project.org>
>>Sent: Monday, September 2, 2013 11:46 AM
>>
>>Subject: Re: [R] Product of certain rows in a matrix
>>
>>
>>
>>Thank you all for your responses.
>>The real problem is that all your answer work for products 2 by 2.
>>I now have to do the product n by n row.
>>Do you have a solution ?
>>Thank you in advance,
>>E.H.?
>>
>>
>>
>>Edouard Hardy
>>
>>
>>
>>On Mon, Sep 2, 2013 at 5:43 PM, arun <smartpink111 at yahoo.com> wrote:
>>
>>I guess in such situations,
>>>
>>>
>>>fun1<- function(mat){
>>>?if(nrow(mat)%%2==0){
>>>?j<- 2*seq_len(nrow(mat)/2)
>>>?b<- mat[j,]* mat[j-1,]
>>>?}
>>>?else {mat1<- mat[-nrow(mat),]
>>>?j<- 2*seq_len(nrow(mat1)/2)
>>>?b<- rbind(mat1[j,]*mat1[j-1,],mat[nrow(mat),])
>>>? }
>>>b
>>>}
>>>fun1(A)
>>>#???? [,1] [,2] [,3]
>>>
>>>#[1,]??? 4?? 10?? 18
>>>#[2,]?? 63?? 64?? 63
>>>#[3,]?? 18?? 10??? 4
>>>?fun1(Anew)
>>>#???? [,1] [,2] [,3]
>>>
>>>#[1,]??? 4?? 10?? 18
>>>#[2,]?? 63?? 64?? 63
>>>#[3,]?? 18?? 10??? 4
>>>#[4,]??? 1??? 3??? 5
>>>
>>>
>>>A.K.
>>>
>>>
>>>
>>>
>>>----- Original Message -----
>>>From: arun <smartpink111 at yahoo.com>
>>>To: Bert Gunter <gunter.berton at gene.com>
>>>Cc: R help <r-help at r-project.org>
>>>
>>>Sent: Monday, September 2, 2013 11:26 AM
>>>Subject: Re: [R] Product of certain rows in a matrix
>>>
>>>Hi Bert,
>>>Thanks.? It is a better solution.
>>>
>>>If nrow() is not even.
>>>
>>>Anew<- rbind(A,c(1,3,5))
>>>j<-seq_len(nrow(Anew)/2)###
>>>?Anew[j,]*Anew[j-1,]
>>>#Error in Anew[j, ] * Anew[j - 1, ] : non-conformable arrays
>>>
>>>t(sapply(split(as.data.frame(Anew),as.numeric(gl(nrow(Anew),2,7))),colProds))
>>>? [,1] [,2] [,3]
>>>1??? 4?? 10?? 18
>>>2?? 63?? 64?? 63
>>>3?? 18?? 10??? 4
>>>4??? 1??? 3??? 5
>>>
>>>A.K.
>>>
>>>
>>>
>>>
>>>
>>>
>>>________________________________
>>>From: Bert Gunter <gunter.berton at gene.com>
>>>To: arun <smartpink111 at yahoo.com>
>>>Cc: R help <r-help at r-project.org>
>>>Sent: Monday, September 2, 2013 10:55 AM
>>>Subject: Re: [R] Product of certain rows in a matrix
>>>
>>>
>>>
>>>These elaborate manipulations are unnecessary and inefficient. Use indexing instead:
>>>
>>>j <- 2*seq_len(nrow(A)/2)
>>>b <- A[j,]*A[j-1,]
>>>b
>>>[,1] [,2] [,3]
>>>[1,]??? 4?? 10?? 18
>>>[2,]?? 63?? 64?? 63
>>>[3,]?? 18?? 10??? 4
>>>
>>>[,1] [,2] [,3]
>>>[1,]????4?? 10?? 18
>>>[2,]?? 63?? 64?? 63
>>>[3,]?? 18?? 10????4
>>>[,1] [,2] [,3]
>>>[1,]????4?? 10?? 18
>>>[2,]?? 63?? 64?? 63
>>>[3,]?? 18?? 10????4[,1] [,2] [,3]
>>>[1,]????4?? 10?? 18
>>>[2,]?? 63?? 64?? 63
>>>[3,]?? 18?? 10????4
>>>[,1] [,2] [,3]
>>>[1,]????4?? 10?? 18
>>>[2,]?? 63?? 64?? 63
>>>[3,]?? 18?? 10????4
>>>
>>>
>>>
>>>
>>>
>>>On Mon, Sep 2, 2013 at 7:25 AM, arun <smartpink111 at yahoo.com> wrote:
>>>
>>>Hi,
>>>>You could try:
>>>>
>>>>A<- matrix(unlist(read.table(text="
>>>>1 2 3
>>>>4 5 6
>>>>7 8 9
>>>>9 8 7
>>>>6 5 4
>>>>3 2 1
>>>>",sep="",header=FALSE)),ncol=3,byrow=FALSE,dimnames=NULL)
>>>>
>>>>library(matrixStats)
>>>>?res1<-t(sapply(split(as.data.frame(A),as.numeric(gl(nrow(A),2,6))),colProds))
>>>>?res1
>>>>#? [,1] [,2] [,3]
>>>>#1??? 4?? 10?? 18
>>>>#2?? 63?? 64?? 63
>>>>#3?? 18?? 10??? 4
>>>>
>>>>
>>>>?res2<-t(sapply(split(as.data.frame(A),((seq_len(nrow(A))-1)%/%2)+1),colProds))
>>>>?identical(res1,res2)
>>>>#[1] TRUE
>>>>
>>>>#or
>>>>?t(sapply(split(as.data.frame(A),as.numeric(gl(nrow(A),2,6))),function(x) apply(x,2,prod)))
>>>>
>>>>#or
>>>>library(plyr)
>>>>?as.matrix(ddply(as.data.frame(A),.(as.numeric(gl(nrow(A),2,6))),colProds)[,-1])
>>>>#???? V1 V2 V3
>>>>#[1,]? 4 10 18
>>>>#[2,] 63 64 63
>>>>#[3,] 18 10? 4
>>>>
>>>>#or
>>>>do.call(rbind,tapply(seq_len(nrow(A)),list(as.numeric(gl(nrow(A),2,6))),FUN=function(x) colProds(A[x,])))
>>>>#or
>>>>A1<- data.frame(A,ID=as.numeric(gl(nrow(At),2,6)))
>>>>?aggregate(A1[,-4],list(A1[,4]),colProds)[,-1]
>>>>#? X1 X2 X3
>>>>#1? 4 10 18
>>>>#2 63 64 63
>>>>#3 18 10? 4
>>>>
>>>>#or
>>>>library(data.table)
>>>>At<- data.table(A1,key='ID')
>>>>subset(At[,lapply(.SD,colProds),by=ID],select=-1)
>>>>#?? X1 X2 X3
>>>>#1:? 4 10 18
>>>>#2: 63 64 63
>>>>#3: 18 10? 4
>>>>
>>>>A.K.
>>>>
>>>>
>>>>
>>>>
>>>>Hello,
>>>>
>>>>I have this matrix :
>>>>A =
>>>>1 2 3
>>>>4 5 6
>>>>7 8 9
>>>>9 8 7
>>>>6 5 4
>>>>3 2 1
>>>>
>>>>I would like to have this matrix (product of rows 2 by 2) :
>>>>A =
>>>>4 10 18
>>>>63 64 63
>>>>18 10 4
>>>>
>>>>Is it possible to do that without a loop ?
>>>>
>>>>Thank you in advance !
>>>>
>>>>______________________________________________
>>>>R-help at r-project.org mailing list
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>>--
>>>
>>>
>>>Bert Gunter
>>>Genentech Nonclinical Biostatistics
>>>
>>>Internal Contact Info:
>>>Phone: 467-7374
>>>Website:
>>>
>>>http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>


From dwinsemius at comcast.net  Mon Sep  2 21:55:16 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 2 Sep 2013 12:55:16 -0700
Subject: [R] =?utf-8?q?Fisher_test_for_a_more_than_two_group_of_genes?=
 =?utf-8?b?4oCP?=
In-Reply-To: <BLU174-W13D5FDC3ED072273269508974B0@phx.gbl>
References: <mailman.0.1377714854.11664.r-help@r-project.org>,
	<BLU174-W3231850999CEEC956415B1974B0@phx.gbl>
	<BLU174-W13D5FDC3ED072273269508974B0@phx.gbl>
Message-ID: <2A738920-7845-4647-B86D-837388D9B55E@comcast.net>


On Aug 28, 2013, at 11:53 AM, Gabriel Wajnberg wrote:
> 
> Good Afternoon,
> My name is Gabriel, I'm doing an analysis if there is increase or decrease in dependence on the mutated genes, using 3 or more genes using the fisher exact test.I performed with success an analysis for two genes using fisher.test( ). example of the 2x2 contigency table:

Edited original table:

>               Gene A mutated | Gene A normal
> Gene B mutated| 26           |        12
> ------------------------------------------------
> Gene B normal |  10          |        50
> 
> Now I'm wondering how can I perform the analysis for 3 genes (and construct the contigency table), as follows: Gene A mutated, Gene A normal, Gene B mutated, Gene B normal, Gene C mutated and Gene C normal. How do I perform a fisher test using fisher.test( ) function using this data (3x3 contigency table)?Can someone help me ?
> 		 	   		   		 	   		  
> 	[[alternative HTML version deleted]]

I'm guessing you failed to read the Posting Guide where you are asked not to post in HTML format. I also don't understand what problems youa re having when you use fisr.test with a 3x3 table. Its help page says it acna handle a 2 dimnensional contingency table.

-- 

David Winsemius
Alameda, CA, USA


From smartpink111 at yahoo.com  Mon Sep  2 21:57:10 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 2 Sep 2013 12:57:10 -0700 (PDT)
Subject: [R] Product of certain rows in a matrix
In-Reply-To: <1378150281.21586.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <1378131907.99820.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CACk-te16jF6r192tcANN6KPN2ig60WgGpR=q+o_1POe2ns2GrA@mail.gmail.com>
	<1378135609.35393.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1378136619.88673.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CAFsztN6R39vUhW9-NLS8eLvRmvXPjGXHmDFO8Jb7=8g1CnEaWA@mail.gmail.com>
	<1378137395.55129.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<CAFsztN4qYoGHvqJOZoz0uYnUm=QnRVt=hP7SDSE5L2ugjL1skA@mail.gmail.com>
	<1378138020.41945.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1378144640.20493.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1378146465.5182.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<CAFsztN48yEEy_eik1twtHUo+D0U=qn7HNrFoJpFx5aDY_fWnOQ@mail.gmail.com>
	<1378149920.4422.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1378150281.21586.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <1378151830.72596.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,

Make sure you check the class of the columns.? I forgot about that.

str(mat1)
?int [1:100000, 1:3] 1 2 10 18 2 16 1 18 12 19 ...


Convert it to numeric.
mat1New<- sapply(split(mat1,col(mat1)),as.numeric)

n<- 40
nrow(mat1New)%%40
#[1] 0


system.time({
j40<- n*seq_len(nrow(mat1New)/n)
?vec1<- rep("j40",n)
? res<- eval(parse(text= paste(paste0("mat1New","[",paste0(vec1,"-",seq(n)-1),",]"),collapse="*")
?))
})
?#user? system elapsed 
?# 0.004?? 0.000?? 0.004 

system.time({
j <- seq_len(nrow(mat1New))%%n
b <- mat1New[j==0,]
for(i in seq_len(n-1))b <- b*mat1New[j==i,]
})
# user? system elapsed 
#? 0.112?? 0.000?? 0.116 

all.equal(b,res)
#[1] TRUE


#if

nrow(mat1New)%%n!=0

For example:
n<- 22
nrow(mat1New)%%n
#[1] 10
system.time({
?mat2<-mat1New[seq(nrow(mat1New)-10),]
j22<- n*seq_len(nrow(mat2)/n)
vec1<- rep("j22",n)
res<- eval(parse(text= paste(paste0("mat2","[",paste0(vec1,"-",seq(n)-1),",]"),collapse="*")
)) 
resNew<-rbind(res,apply(tail(mat1New,10),2,prod)
)})

#? user? system elapsed 
?# 0.008?? 0.000?? 0.007 




A.K. 









----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Edouard Hardy <hardy.edouard at gmail.com>
Cc: Bert Gunter <gunter.berton at gene.com>
Sent: Monday, September 2, 2013 3:31 PM
Subject: Re: [R] Product of certain rows in a matrix

There was a slight mistake in the end: 

I repeated vec1.? But, it doesn't matter as the warning messages are the same.


j40<- n*seq_len(nrow(mat1)/n)
?vec1<- rep("j40",n)
?res<- eval(parse(text= paste(paste0("mat1","[",paste0(vec1,"-",seq(n)-1),",]"),collapse="*")
?))

Warning messages:
1: In mat1[j40 - 0, ] * mat1[j40 - 1, ] * mat1[j40 - 2, ] * mat1[j40 -? :
? NAs produced by integer overflow
2: In mat1[j40 - 0, ] * mat1[j40 - 1, ] * mat1[j40 - 2, ] * mat1[j40 -? :
? NAs produced by integer overflow
3: In mat1[j40 - 0, ] * mat1[j40 - 1, ] * mat1[j40 - 2, ] * mat1[j40 -? :
? NAs produced by integer overflow
4: In mat1[j40 - 0, ] * mat1[j40 - 1, ] * mat1[j40 - 2, ] * mat1[j40 -? :
? NAs produced by integer overflow
5: In mat1[j40 - 0, ] * mat1[j40 - 1, ] * mat1[j40 - 2, ] * mat1[j40 -? :
? NAs produced by integer overflow
6: In mat1[j40 - 0, ] * mat1[j40 - 1, ] * mat1[j40 - 2, ] * mat1[j40 -? :




----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Edouard Hardy <hardy.edouard at gmail.com>
Cc: R help <r-help at r-project.org>; Bert Gunter <gunter.berton at gene.com>
Sent: Monday, September 2, 2013 3:25 PM
Subject: Re: [R] Product of certain rows in a matrix

Hi,
You can try this:
n<- 3
j3<-n*seq_len(nrow(A)/n)
vec1<- rep("j3",n)
eval(parse(text=paste0("A","[",paste0(vec1,"-",seq(n)-1),",]",collapse="*")))
#???? [,1] [,2] [,3]
#[1,]?? 28?? 80? 162
#[2,]? 162?? 80?? 28

Just saw Bert's new solution:
n<-3
?j <- seq_len(nrow(A))%%n
?b <- A[j==0,]
?for(i in seq_len(n-1))b <- b*A[j==i,]
?b
#???? [,1] [,2] [,3]
#[1,]?? 28?? 80? 162
#[2,]? 162?? 80?? 28







#For the bigger dataset with large "n, these methods may not work:


set.seed(28)
mat1<- matrix(sample(1:20,1e5*3,replace=TRUE),ncol=3)

n<- 40
nrow(mat1)%%40
#[1] 0


j <- seq_len(nrow(mat1))%%n
b <- mat1[j==0,]
for(i in seq_len(n-1))b <- b*mat1[j==i,]

Warning messages:
1: In b * mat1[j == i, ] : NAs produced by integer overflow
2: In b * mat1[j == i, ] : NAs produced by integer overflow
3: In b * mat1[j == i, ] : NAs produced by integer overflow
4: In b * mat1[j == i, ] : NAs produced by integer overflow
5: In b * mat1[j == i, ] : NAs produced by integer overflow
6: In b * mat1[j == i, ] : NAs produced by integer overflow
7: In b * mat1[j == i, ] : NAs produced by integer overflow
8: In b * mat1[j == i, ] : NAs produced by integer overflow
9: In b * mat1[j == i, ] : NAs produced by integer overflow
10: In b * mat1[j == i, ] : NAs produced by integer overflow

head(b,3)
#???? [,1] [,2] [,3]
#[1,]?? NA?? NA?? NA
#[2,]?? NA?? NA?? NA
#[3,]?? NA?? NA?? NA


j40<- n*seq_len(nrow(mat1)/n)
?vec1<- rep("j40",n)
?vec1<- rep("j22",n)
?res<- eval(parse(text= paste(paste0("mat1","[",paste0(vec1,"-",seq(n)-1),",]"),collapse="*")
?))
Warning messages:
1: In mat1[j22 - 0, ] * mat1[j22 - 1, ] * mat1[j22 - 2, ] * mat1[j22 -? :
? NAs produced by integer overflow
2: In mat1[j22 - 0, ] * mat1[j22 - 1, ] * mat1[j22 - 2, ] * mat1[j22 -? :
? NAs produced by integer overflow
3: In mat1[j22 - 0, ] * mat1[j22 - 1, ] * mat1[j22 - 2, ] * mat1[j22 -? :
? NAs produced by integer overflow
4: In mat1[j22 - 0, ] * mat1[j22 - 1, ] * mat1[j22 - 2, ] * mat1[j22 -? :
?head(res,3)
#???? [,1] [,2] [,3]
#[1,]?? NA?? NA?? NA
#[2,]?? NA?? NA?? NA
#[3,]?? NA?? NA?? NA


A.K.





________________________________
From: Edouard Hardy <hardy.edouard at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Monday, September 2, 2013 2:32 PM
Subject: Re: [R] Product of certain rows in a matrix



Yes, n is 250 or more...



Edouard Hardy



On Mon, Sep 2, 2013 at 8:31 PM, arun <smartpink111 at yahoo.com> wrote:

Also, BTW, are you looking for n>100?
>
>
>
>
>
>





On Mon, Sep 2, 2013 at 8:27 PM, arun <smartpink111 at yahoo.com> wrote:


>
>Hi,
>
>Not sure I understand your question.? If you don't know "n", then how are you applying other solutions also..
>A.K.
>
>
>
>Again, thank you for your help.
>
>I understand Bert's solution but this is possible only if I know n.
>
>How can I do A[j3,]*A[j3-1,]*A[j3-2,] (n=3) for n terms ?
>
>
>
>----- Original Message -----
>From: arun <smartpink111 at yahoo.com>
>To: Edouard Hardy <hardy.edouard at gmail.com>
>Cc: R help <r-help at r-project.org>; Bert Gunter <gunter.berton at gene.com>
>
>Sent: Monday, September 2, 2013 1:57 PM
>Subject: Re: [R] Product of certain rows in a matrix
>
>HI,
>You could modify Bert's solution:
>n<-3
>
>j3<-n*seq_len(nrow(A)/n)
>A[j3,]*A[j3-1,]*A[j3-2,]? ##assuming that nrow(dataset)%%n==0
>#???? [,1] [,2] [,3]
>#[1,]?? 28?? 80? 162
>#[2,]? 162?? 80?? 28
>
>
>#Speed comparison
>
>
>set.seed(28)
>mat1<- matrix(sample(1:20,1e5*3,replace=TRUE),ncol=3)
>
>n<-4
>system.time({res1<- t(sapply(split(as.data.frame(mat1),as.numeric(gl(nrow(mat1),n,nrow(mat1)))),function(x) apply(x,2,prod))) })
>#? user? system elapsed
>#? 8.508?? 0.620?? 9.146
>system.time({res2<- t(sapply(split(as.data.frame(mat1),as.numeric(gl(nrow(mat1),n,nrow(mat1)))),function(x) Reduce("*",as.data.frame(t(x))))) })
># user? system elapsed
>#? 8.556?? 0.000?? 8.566
>
>A1<- data.frame(mat1,ID=as.numeric(gl(nrow(mat1),n,nrow(mat1))))
>?system.time({res3<- aggregate(A1[,-4],list(A1[,4]),colProds)[,-1]})
># user? system elapsed
># 11.536?? 0.000? 11.553
>
>
>nrow(mat1)%%n
>#[1] 0
>system.time({j4<- n*seq_len(nrow(mat1)/n)
>??? ??? res5<- mat1[j4,]*mat1[j4-1,]*mat1[j4-2,]*mat1[j4-3,]
>??? ? })
>
># user? system elapsed
>#? 0.004?? 0.000?? 0.004
>
>?dimnames(res2)<- dimnames(res5)
>identical(res2,res5)
>#[1] TRUE
>
>
>#if
>n<-6
>?nrow(mat1)%%6
>#[1] 4
>
>
>system.time({
>?mat2<-mat1[seq(nrow(mat1)-4),]
>j6<- n*seq_len(nrow(mat2)/n)
>?res6<- mat2[j6,]*mat2[j6-1,]*mat2[j6-2,]*mat2[j6-3,]*mat2[j6-4,]*mat2[j6-5,]
>res6New<-rbind(res6,apply(tail(mat1,4),2,prod)
>)})
>
>#? user? system elapsed
>?# 0.004?? 0.000?? 0.006
>
>
>
>system.time({res6Alt<-
>t(sapply(split(as.data.frame(mat1),as.numeric(gl(nrow(mat1),n,nrow(mat1)))),function(x) Reduce("*",as.data.frame(t(x))))) })
>#user? system elapsed
>?# 5.576?? 0.000?? 5.583
>dimnames(res6Alt)<- dimnames(res6New)
>
>
>all.equal(res6New,res6Alt)
>#[1] TRUE
>
>
>A.K.
>
>
>
>As you said, this is very loooong.
>Do you have a better solution on big data ?
>
>
>
>----- Original Message -----
>From: arun <smartpink111 at yahoo.com>
>To: Edouard Hardy <hardy.edouard at gmail.com>
>Cc: R help <r-help at r-project.org>; Bert Gunter <gunter.berton at gene.com>
>Sent: Monday, September 2, 2013 12:07 PM
>Subject: Re: [R] Product of certain rows in a matrix
>
>
>
>Hi,
>No problem.
>n<- 4
>
>t(sapply(split(as.data.frame(Anew),as.numeric(gl(nrow(Anew),n,nrow(Anew)))),function(x) apply(x,2,prod)))?
>
>#? V1? V2?? V3
>#1 252 640 1134
>#2? 18? 30?? 20
>
>
>This could be a bit slow if you have big dataset.
>
>
>A.K.
>
>
>
>________________________________
>From: Edouard Hardy <hardy.edouard at gmail.com>
>To: arun <smartpink111 at yahoo.com>
>Cc: R help <r-help at r-project.org>
>Sent: Monday, September 2, 2013 11:58 AM
>Subject: Re: [R] Product of certain rows in a matrix
>
>
>
>Thank you A.K.
>And do you have a solution without installing any package ?
>Thank you in advance.
>E.H.
>
>
>
>Edouard Hardy
>
>
>
>On Mon, Sep 2, 2013 at 5:56 PM, arun <smartpink111 at yahoo.com> wrote:
>
>
>>
>>HI,
>>In my first solutions:
>>?n<-3
>>?t(sapply(split(as.data.frame(Anew),as.numeric(gl(nrow(Anew),n,nrow(Anew)))),colProds))
>>#? [,1] [,2] [,3]
>>#1?? 28?? 80? 162
>>#2? 162?? 80?? 28
>>#3??? 1??? 3??? 5
>>?n<-4
>>?t(sapply(split(as.data.frame(Anew),as.numeric(gl(nrow(Anew),n,nrow(Anew)))),colProds))
>>#? [,1] [,2] [,3]
>>#1? 252? 640 1134
>>#2?? 18?? 30?? 20
>>
>>A.K.
>>
>>________________________________
>>From: Edouard Hardy <hardy.edouard at gmail.com>
>>To: arun <smartpink111 at yahoo.com>
>>Cc: Bert Gunter <gunter.berton at gene.com>; R help <r-help at r-project.org>
>>Sent: Monday, September 2, 2013 11:46 AM
>>
>>Subject: Re: [R] Product of certain rows in a matrix
>>
>>
>>
>>Thank you all for your responses.
>>The real problem is that all your answer work for products 2 by 2.
>>I now have to do the product n by n row.
>>Do you have a solution ?
>>Thank you in advance,
>>E.H.?
>>
>>
>>
>>Edouard Hardy
>>
>>
>>
>>On Mon, Sep 2, 2013 at 5:43 PM, arun <smartpink111 at yahoo.com> wrote:
>>
>>I guess in such situations,
>>>
>>>
>>>fun1<- function(mat){
>>>?if(nrow(mat)%%2==0){
>>>?j<- 2*seq_len(nrow(mat)/2)
>>>?b<- mat[j,]* mat[j-1,]
>>>?}
>>>?else {mat1<- mat[-nrow(mat),]
>>>?j<- 2*seq_len(nrow(mat1)/2)
>>>?b<- rbind(mat1[j,]*mat1[j-1,],mat[nrow(mat),])
>>>? }
>>>b
>>>}
>>>fun1(A)
>>>#???? [,1] [,2] [,3]
>>>
>>>#[1,]??? 4?? 10?? 18
>>>#[2,]?? 63?? 64?? 63
>>>#[3,]?? 18?? 10??? 4
>>>?fun1(Anew)
>>>#???? [,1] [,2] [,3]
>>>
>>>#[1,]??? 4?? 10?? 18
>>>#[2,]?? 63?? 64?? 63
>>>#[3,]?? 18?? 10??? 4
>>>#[4,]??? 1??? 3??? 5
>>>
>>>
>>>A.K.
>>>
>>>
>>>
>>>
>>>----- Original Message -----
>>>From: arun <smartpink111 at yahoo.com>
>>>To: Bert Gunter <gunter.berton at gene.com>
>>>Cc: R help <r-help at r-project.org>
>>>
>>>Sent: Monday, September 2, 2013 11:26 AM
>>>Subject: Re: [R] Product of certain rows in a matrix
>>>
>>>Hi Bert,
>>>Thanks.? It is a better solution.
>>>
>>>If nrow() is not even.
>>>
>>>Anew<- rbind(A,c(1,3,5))
>>>j<-seq_len(nrow(Anew)/2)###
>>>?Anew[j,]*Anew[j-1,]
>>>#Error in Anew[j, ] * Anew[j - 1, ] : non-conformable arrays
>>>
>>>t(sapply(split(as.data.frame(Anew),as.numeric(gl(nrow(Anew),2,7))),colProds))
>>>? [,1] [,2] [,3]
>>>1??? 4?? 10?? 18
>>>2?? 63?? 64?? 63
>>>3?? 18?? 10??? 4
>>>4??? 1??? 3??? 5
>>>
>>>A.K.
>>>
>>>
>>>
>>>
>>>
>>>
>>>________________________________
>>>From: Bert Gunter <gunter.berton at gene.com>
>>>To: arun <smartpink111 at yahoo.com>
>>>Cc: R help <r-help at r-project.org>
>>>Sent: Monday, September 2, 2013 10:55 AM
>>>Subject: Re: [R] Product of certain rows in a matrix
>>>
>>>
>>>
>>>These elaborate manipulations are unnecessary and inefficient. Use indexing instead:
>>>
>>>j <- 2*seq_len(nrow(A)/2)
>>>b <- A[j,]*A[j-1,]
>>>b
>>>[,1] [,2] [,3]
>>>[1,]??? 4?? 10?? 18
>>>[2,]?? 63?? 64?? 63
>>>[3,]?? 18?? 10??? 4
>>>
>>>[,1] [,2] [,3]
>>>[1,]????4?? 10?? 18
>>>[2,]?? 63?? 64?? 63
>>>[3,]?? 18?? 10????4
>>>[,1] [,2] [,3]
>>>[1,]????4?? 10?? 18
>>>[2,]?? 63?? 64?? 63
>>>[3,]?? 18?? 10????4[,1] [,2] [,3]
>>>[1,]????4?? 10?? 18
>>>[2,]?? 63?? 64?? 63
>>>[3,]?? 18?? 10????4
>>>[,1] [,2] [,3]
>>>[1,]????4?? 10?? 18
>>>[2,]?? 63?? 64?? 63
>>>[3,]?? 18?? 10????4
>>>
>>>
>>>
>>>
>>>
>>>On Mon, Sep 2, 2013 at 7:25 AM, arun <smartpink111 at yahoo.com> wrote:
>>>
>>>Hi,
>>>>You could try:
>>>>
>>>>A<- matrix(unlist(read.table(text="
>>>>1 2 3
>>>>4 5 6
>>>>7 8 9
>>>>9 8 7
>>>>6 5 4
>>>>3 2 1
>>>>",sep="",header=FALSE)),ncol=3,byrow=FALSE,dimnames=NULL)
>>>>
>>>>library(matrixStats)
>>>>?res1<-t(sapply(split(as.data.frame(A),as.numeric(gl(nrow(A),2,6))),colProds))
>>>>?res1
>>>>#? [,1] [,2] [,3]
>>>>#1??? 4?? 10?? 18
>>>>#2?? 63?? 64?? 63
>>>>#3?? 18?? 10??? 4
>>>>
>>>>
>>>>?res2<-t(sapply(split(as.data.frame(A),((seq_len(nrow(A))-1)%/%2)+1),colProds))
>>>>?identical(res1,res2)
>>>>#[1] TRUE
>>>>
>>>>#or
>>>>?t(sapply(split(as.data.frame(A),as.numeric(gl(nrow(A),2,6))),function(x) apply(x,2,prod)))
>>>>
>>>>#or
>>>>library(plyr)
>>>>?as.matrix(ddply(as.data.frame(A),.(as.numeric(gl(nrow(A),2,6))),colProds)[,-1])
>>>>#???? V1 V2 V3
>>>>#[1,]? 4 10 18
>>>>#[2,] 63 64 63
>>>>#[3,] 18 10? 4
>>>>
>>>>#or
>>>>do.call(rbind,tapply(seq_len(nrow(A)),list(as.numeric(gl(nrow(A),2,6))),FUN=function(x) colProds(A[x,])))
>>>>#or
>>>>A1<- data.frame(A,ID=as.numeric(gl(nrow(At),2,6)))
>>>>?aggregate(A1[,-4],list(A1[,4]),colProds)[,-1]
>>>>#? X1 X2 X3
>>>>#1? 4 10 18
>>>>#2 63 64 63
>>>>#3 18 10? 4
>>>>
>>>>#or
>>>>library(data.table)
>>>>At<- data.table(A1,key='ID')
>>>>subset(At[,lapply(.SD,colProds),by=ID],select=-1)
>>>>#?? X1 X2 X3
>>>>#1:? 4 10 18
>>>>#2: 63 64 63
>>>>#3: 18 10? 4
>>>>
>>>>A.K.
>>>>
>>>>
>>>>
>>>>
>>>>Hello,
>>>>
>>>>I have this matrix :
>>>>A =
>>>>1 2 3
>>>>4 5 6
>>>>7 8 9
>>>>9 8 7
>>>>6 5 4
>>>>3 2 1
>>>>
>>>>I would like to have this matrix (product of rows 2 by 2) :
>>>>A =
>>>>4 10 18
>>>>63 64 63
>>>>18 10 4
>>>>
>>>>Is it possible to do that without a loop ?
>>>>
>>>>Thank you in advance !
>>>>
>>>>______________________________________________
>>>>R-help at r-project.org mailing list
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>>--
>>>
>>>
>>>Bert Gunter
>>>Genentech Nonclinical Biostatistics
>>>
>>>Internal Contact Info:
>>>Phone: 467-7374
>>>Website:
>>>
>>>http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>


From murdoch.duncan at gmail.com  Mon Sep  2 22:02:07 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 02 Sep 2013 16:02:07 -0400
Subject: [R] Sweave: printing an underscore in the output from an R
	command
In-Reply-To: <A39E6A7C-11FF-4832-B251-146FF45450A6@warwick.ac.uk>
References: <8AAFC6A6-757E-4E74-A4BB-4D0A55037290@warwick.ac.uk>
	<AA818EAD2576BC488B4F623941DA7427CD351B5F@inbomail.inbo.be>
	<A39E6A7C-11FF-4832-B251-146FF45450A6@warwick.ac.uk>
Message-ID: <5224EEBF.5080809@gmail.com>

On 13-09-02 3:18 PM, David Epstein wrote:
> Dear Thierry,
>
> Your suggestion doesn't work on my version of R. Here's what I get
>> gsub("_", "\_", print(version$platform)
> Error: '\_' is an unrecognized escape in character string starting ""\_"
>> print(gsub("_", "\_", version$platform))
> Error: '\_' is an unrecognized escape in character string starting ""\_"
>
>> sub("_", "\\_", version$platform)
> [1] "x86_64-apple-darwin10.8.0"
> Sweave does not evaluate this expression when \Sexpr is applied and a tex error results
>
>> sub("_", "\\\_", version$platform)
> Error: '\_' is an unrecognized escape in character string starting ""\\\_"
> Error message from R
>
>> sub("_", "\\\\_", version$platform)
> [1] "x86\\_64-apple-darwin10.8.0"
> R evaluates this. However, the above examples indicate a deficiency/possible bug in the command sub, because sub does not seem to be able to output an expression with a single backslash.

The final result has a single backslash.  The print() function doubles 
it so you can tell it from an escape of the next letter.  If you use 
cat() instead of the implicit print() you'll see the text that is there.
>
> I tried the previous version as follows in my .Rnw document
> \Sexpr{print(sub("_", "\\\\_", version$platform))}
> When Sweave is run, this expression is evaluated to illegal LaTeX


You need to give more details, e.g. what actually appeared in the .tex 
file and in what context, if you want help with this.

Duncan Murdoch


From xie at yihui.name  Mon Sep  2 22:11:48 2013
From: xie at yihui.name (Yihui Xie)
Date: Mon, 2 Sep 2013 15:11:48 -0500
Subject: [R] Sweave: printing an underscore in the output from an R
	command
In-Reply-To: <A39E6A7C-11FF-4832-B251-146FF45450A6@warwick.ac.uk>
References: <8AAFC6A6-757E-4E74-A4BB-4D0A55037290@warwick.ac.uk>
	<AA818EAD2576BC488B4F623941DA7427CD351B5F@inbomail.inbo.be>
	<A39E6A7C-11FF-4832-B251-146FF45450A6@warwick.ac.uk>
Message-ID: <CANROs4cmV6+v7je2aviz2NnAjS5xU0bTyy0MyGwc-hyLDq4DkQ@mail.gmail.com>

I think Thierry meant gsub("_", "\\\\_", version$platform); he just
typed too quickly. The point is to escape _ using \, but then people
are often trapped in the dreams of dreams of dreams of backslashes
like the movie Inception. And then due to a long-standing bug in
Sweave for \Sexpr{} (sorry I forgot to report to R core), you will be
so confused that you can never wake up and come back to the reality.

Dream level 1: when you need a backslash in a character string, you
need "\\", which really means \; you think "\\_" should be good, but
no --

Dream level 2: when you need one literal \ in a regular expression as
the replacement expression, you need \\

Combine the two levels of dreams, you end up with "\\\\_". \\\\ in R
really means \\, which really means \ in regular expressions.

Now you are good at the regular expression level, but Sweave comes and
bites you, and that is due to this bug in the regular expression in
Sweave Noweb syntax:

> SweaveSyntaxNoweb$docexpr
[1] "\\\\Sexpr\\{([^\\}]*)\\}"

It should have been "\\\\Sexpr\\{([^}]*)\\}", i.e. } does not need to
be escaped inside [], and \\ will be interpreted literally inside [].
In your case, Sweave sees \ in \Sexpr{}, and the regular expression
stops matching there, and is unable to see } after \, so it believes
there is no inline R expressions in your document.

BTW, knitr does not have this bug and works well in your case:

\documentclass{article}
\begin{document}
\Sexpr{sub("_", "\\\\_", version$platform)}
\end{document}

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


On Mon, Sep 2, 2013 at 2:18 PM, David Epstein
<David.Epstein at warwick.ac.uk> wrote:
> Dear Thierry,
>
> Your suggestion doesn't work on my version of R. Here's what I get
>> gsub("_", "\_", print(version$platform)
> Error: '\_' is an unrecognized escape in character string starting ""\_"
>> print(gsub("_", "\_", version$platform))
> Error: '\_' is an unrecognized escape in character string starting ""\_"
>
>> sub("_", "\\_", version$platform)
> [1] "x86_64-apple-darwin10.8.0"
> Sweave does not evaluate this expression when \Sexpr is applied and a tex error results
>
>> sub("_", "\\\_", version$platform)
> Error: '\_' is an unrecognized escape in character string starting ""\\\_"
> Error message from R
>
>> sub("_", "\\\\_", version$platform)
> [1] "x86\\_64-apple-darwin10.8.0"
> R evaluates this. However, the above examples indicate a deficiency/possible bug in the command sub, because sub does not seem to be able to output an expression with a single backslash.
>
> I tried the previous version as follows in my .Rnw document
> \Sexpr{print(sub("_", "\\\\_", version$platform))}
> When Sweave is run, this expression is evaluated to illegal LaTeX
>
> David.
>
>
>
>
> On 2 Sep 2013, at 16:47, ONKELINX, Thierry wrote:
>
>> You have to escape the underscore
>>
>> \Sexpr{gsub("_", "\_", print(version$platform))}
>>
>> Best regards,
>>
>> Thierry
>>
>> ________________________________________
>> Van: r-help-bounces at r-project.org [r-help-bounces at r-project.org] namens David Epstein [David.Epstein at warwick.ac.uk]
>> Verzonden: maandag 2 september 2013 17:38
>> Aan: r-help at r-project.org
>> Onderwerp: [R] Sweave: printing an underscore in the output from an R command
>>
>> I am working with Sweave and would like to print out into my latex document the result of the R command
>> version$platform
>> So what I first tried in my .Rnw document was \Sexpr{print(version$platform)}.
>>
>> However, the output from this command is the string "x86_64-apple-darwin10.8.0" (without the quotes). This contains an underscore, which is a special character in tex and so I get an error message from latex.
>>
>> I can get round this by using sub to replace underscore with a space, but I would like to know how to print the underscore if I really wanted to do so.


From wkreinen at gmail.com  Mon Sep  2 19:07:22 2013
From: wkreinen at gmail.com (Wim Kreinen)
Date: Mon, 2 Sep 2013 19:07:22 +0200
Subject: [R] restructure my data
Message-ID: <CAPFhJgbDzb2FD888xdeJwfrspuLtmfiWCqRpQUfAGBacpms+6g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130902/8c2bd189/attachment.pl>

From zf.yuan.y at gmail.com  Mon Sep  2 19:18:49 2013
From: zf.yuan.y at gmail.com (Zhenfei Yuan)
Date: Tue, 03 Sep 2013 01:18:49 +0800
Subject: [R] Questions about 'bigmemory'
Message-ID: <1378142329.18072.19.camel@Nimo>

Dear R users,

I'm now dealing with some big data set as big as 10GB, and my RAM got
16GB. Every time I run some models to this dataset using R, I have to
first load it into RAM via read.csv, which spends lots time.

I find the bigmemory package in the high performance task view of R, and
tried this package, found that it is really cool, especially for access
big matrix in shared memory through different R sessions.

My Question is that, when I call read.big.matrix on the .csv file (say
it aa.csv) the first time in R session 'R1', I would got one binary file
aa.bin and descriptor file aa.desc under specified backing path. I tried
to access the so called shared memory  via 'attach.big.matrix' in a
different R session 'R2', it works as I thought; however, when I quit
'R1', I could also access to the big matrix object via
attach.big.matrix('/path/to/aa.desc'), just like 'R1' still exists. I
copied the files 'aa.bin' and 'aa.desc' to another computer,
'attach.big.matrix' also worked on that one.


So, I don't know where the 'Shared Memory' is after turning 'R1' down;
is there differnece between existance and non-existance of 'R1'?

Best regards to you all,
Zhenfei


From 06dongsheng at 163.com  Mon Sep  2 19:33:19 2013
From: 06dongsheng at 163.com (=?GBK?B?tq3W0tDF?=)
Date: Tue, 3 Sep 2013 01:33:19 +0800 (CST)
Subject: [R] help
Message-ID: <38d2b21a.e1.140dfbc6177.Coremail.06dongsheng@163.com>









tt <- function(x) {
                obrien <- function(x) {
                  r <- rank(x)
                  (r - 0.5)/(0.5 + length(r) - r)
                }
                unlist(tapply(x, riskset, obrien))
            }
hi,  i am newer in R. when dealing  with a survival data, i have found the variable progression was not met the PH assumption.the picture show the residual agaist time.So i  use Cox model for time-depandent varibles.   i  use the default tt in function coxph,but when i use tt in "f<-cph(Surv(os$Stime,os$Status==1)~Metastasis+Surgery+Post.chem. +Age+tt(Progression)+ ALP, data=os, x=T, y=T, surv=TRUE, time.inc=60)",it didn't work. i don't kown what the arg"riskset" is .i beg your help . can you help me write down a appropriate tt expression to let me use in cph. thanks.            
                                                                                                                                                      Zhongxin Dong
  



From tobebryant at me.com  Mon Sep  2 21:29:37 2013
From: tobebryant at me.com (tobias schlager)
Date: Mon, 2 Sep 2013 21:29:37 +0200
Subject: [R] Convert chr pieces to numbers that have specific values defined
	by 2 vectors
Message-ID: <B72B6A4E-E524-4A85-BB8F-E11ACC833575@me.com>

Dear all, 

I think this is an easy task, but I don't know how to do it. Specifically, I have 69 columns with 300.000 rows. In each cell there is a code like 
"2E3", "4RR", etc.

I now have a list that replaces this with values, e.g., 
old	new
2E3 		5
4RR		3
etc. 

The list ist about 1600 rows long, so also to extensive for normal solutions

Do you how to do that? It would be great if you could help me, 
best, 
tobebryant

From hardy.edouard at gmail.com  Mon Sep  2 17:46:35 2013
From: hardy.edouard at gmail.com (Edouard Hardy)
Date: Mon, 2 Sep 2013 17:46:35 +0200
Subject: [R] Product of certain rows in a matrix
In-Reply-To: <1378136619.88673.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1378131907.99820.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CACk-te16jF6r192tcANN6KPN2ig60WgGpR=q+o_1POe2ns2GrA@mail.gmail.com>
	<1378135609.35393.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1378136619.88673.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <CAFsztN6R39vUhW9-NLS8eLvRmvXPjGXHmDFO8Jb7=8g1CnEaWA@mail.gmail.com>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
URL : <https://stat.ethz.ch/pipermail/r-help/attachments/20130902/30af385b/attachment.pl>

From hardy.edouard at gmail.com  Mon Sep  2 17:58:01 2013
From: hardy.edouard at gmail.com (Edouard Hardy)
Date: Mon, 2 Sep 2013 17:58:01 +0200
Subject: [R] Product of certain rows in a matrix
In-Reply-To: <1378137395.55129.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <1378131907.99820.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CACk-te16jF6r192tcANN6KPN2ig60WgGpR=q+o_1POe2ns2GrA@mail.gmail.com>
	<1378135609.35393.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1378136619.88673.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CAFsztN6R39vUhW9-NLS8eLvRmvXPjGXHmDFO8Jb7=8g1CnEaWA@mail.gmail.com>
	<1378137395.55129.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <CAFsztN4qYoGHvqJOZoz0uYnUm=QnRVt=hP7SDSE5L2ugjL1skA@mail.gmail.com>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
URL : <https://stat.ethz.ch/pipermail/r-help/attachments/20130902/54444410/attachment.pl>

From smartpink111 at yahoo.com  Mon Sep  2 23:01:36 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 2 Sep 2013 14:01:36 -0700 (PDT)
Subject: [R] R dataframe and looping help
Message-ID: <1378155696.79446.YahooMailNeo@web142605.mail.bf1.yahoo.com>

HI,
You may try this:

dat1<- read.table(text="
CustID TripDate Store Bread Butter Milk Eggs
1 2-Jan-12 a 2 0 2 1 
1 6-Jan-12 c 0 3 3 0 
1 9-Jan-12 a 3 3 0 0
1 31-Mar-13 a 3 0 0 0
2 31-Aug-12 a 0 3 3 0
2 24-Sep-12 a 3 3 0 0
2 25-Sep-12 b 3 0 0 0
",sep="",header=TRUE,stringsAsFactors=FALSE)
dat2<- dat1[,-c(1:3)]

res<- lapply(seq_len(ncol(dat2)),function(i) {x1<-cbind(dat1[,c(1:3)],dat2[,i]);colnames(x1)[4]<- colnames(dat2)[i];x2<-x1[x1[,4]!=0,];within(x2, {daysbetweentrips<-unlist(tapply(as.Date(x2$TripDate,"%d-%b-%y"),list(x2$CustID),function(x) c(NA,as.numeric(diff(x)))));previoustripstore<-ave(x2$Store,x2$CustID,FUN=function(x) c(NA,x[-length(x)]));Nexttripstore<- ave(x2$Store,x2$CustID,FUN=function(x) c(x[-1],NA))})})


?res
#[[1]]
?# CustID? TripDate Store Bread Nexttripstore previoustripstore daysbetweentrips
#1????? 1? 2-Jan-12???? a???? 2???????????? a????????????? <NA>?????????????? NA
#3????? 1? 9-Jan-12???? a???? 3???????????? a???????????????? a??????????????? 7
#4????? 1 31-Mar-13???? a???? 3????????? <NA>???????????????? a????????????? 447
#6????? 2 24-Sep-12???? a???? 3???????????? b????????????? <NA>?????????????? NA
#7????? 2 25-Sep-12???? b???? 3????????? <NA>???????????????? a??????????????? 1

#[[2]]
?# CustID? TripDate Store Butter Nexttripstore previoustripstore
#2????? 1? 6-Jan-12???? c????? 3???????????? a????????????? <NA>
#3????? 1? 9-Jan-12???? a????? 3????????? <NA>???????????????? c
#5????? 2 31-Aug-12???? a????? 3???????????? a????????????? <NA>
#6????? 2 24-Sep-12???? a????? 3????????? <NA>???????????????? a
?# daysbetweentrips
#2?????????????? NA
#3??????????????? 3
#5?????????????? NA
#6?????????????? 24

#[[3]]
?# CustID? TripDate Store Milk Nexttripstore previoustripstore daysbetweentrips
#1????? 1? 2-Jan-12???? a??? 2???????????? c????????????? <NA>?????????????? NA
#2????? 1? 6-Jan-12???? c??? 3????????? <NA>???????????????? a??????????????? 4
#5????? 2 31-Aug-12???? a??? 3????????? <NA>????????????? <NA>?????????????? NA

#[[4]]
?# CustID TripDate Store Eggs Nexttripstore previoustripstore daysbetweentrips
#1????? 1 2-Jan-12???? a??? 1????????? <NA>????????????? <NA>?????????????? NA



A.K.


Hi, I have a very quick question.. I have a data which has sales per 
category per trip of each customer at different store locations, like 
below..(dataset1 frome xcel attachment) CustID	TripDate	Store	Bread	Butter	Milk	Eggs
1	2-Jan-12	  a	2	0	2	1
1	6-Jan-12	  c	0	3	3	0
1	9-Jan-12	  a	3	3	0	0
1	31-Mar-13 a	3	0	0	0
2	31-Aug-12 a	0	3	3	0
2	24-Sep-12 a	3	3	0	0
2	25-Sep-12 b	3	0	0	0 Here i have shown 4 items and their sales per customer per trip at each 
store... However, my data contains around 100 columns with item names.. 
All i need to do is following: 1. Create a separate dataframe for each item. That is, create 100 
dataframs one for each item.. Within the dataframe for Butter, for 
example, will be contained columns 1-3 and Butter column, specifically 
filtered for rows where butter>0 in sales..(so rows 1,4,7 will be 
dropped from this dataframe)..Likewise for all items...(sample output 
for butter is: (dataset2) CustID	TripDate	Store	Butter
1	6-Jan-12	   c	3
1	9-Jan-12	   a	3
2	31-Aug-12  a	3
2	24-Sep-12  a	3 2. In same loop, create new derived variables within each dataframe for 
each item... like create a lag variable for TripDate, create lag 
variable for storename in next trip, storename in previous trip etc... 
and also # days between trips to each store for each customer...(an 
example for Butter dataframe with new derived variables would be...)
Dataset needs to be sorted by CustID, TripDate, Store before creating 
derived variables (dataset3)Book1.xlsx CustID	TripDate	Store	Butter	NextTripstore previoustripstore 
daysbetweentrips
1	6-Jan-12	   c	3	a	              -	       -
1	9-Jan-12	   a	3	-	              c	       -
2	31-Aug-12  a	3	a	              -	       -
2	24-Sep-12  a	3	-	              a	     24 Point of creating multiple item level dataframes is, i will use them 
iteratively as i will perform some regression on these datasets, using 
same set of variables each time


From gunter.berton at gene.com  Mon Sep  2 23:01:41 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 2 Sep 2013 14:01:41 -0700
Subject: [R] Product of certain rows in a matrix
In-Reply-To: <1378151830.72596.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1378131907.99820.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CACk-te16jF6r192tcANN6KPN2ig60WgGpR=q+o_1POe2ns2GrA@mail.gmail.com>
	<1378135609.35393.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1378136619.88673.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CAFsztN6R39vUhW9-NLS8eLvRmvXPjGXHmDFO8Jb7=8g1CnEaWA@mail.gmail.com>
	<1378137395.55129.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<CAFsztN4qYoGHvqJOZoz0uYnUm=QnRVt=hP7SDSE5L2ugjL1skA@mail.gmail.com>
	<1378138020.41945.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1378144640.20493.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1378146465.5182.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<CAFsztN48yEEy_eik1twtHUo+D0U=qn7HNrFoJpFx5aDY_fWnOQ@mail.gmail.com>
	<1378149920.4422.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1378150281.21586.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1378151830.72596.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <CACk-te1fv9_NCTGeNJnbR_8ZSBiUwzOBHrT1o+wgc0hsKPAuDQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130902/54e5258e/attachment.pl>

From smartpink111 at yahoo.com  Mon Sep  2 23:28:41 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 2 Sep 2013 14:28:41 -0700 (PDT)
Subject: [R] Convert chr pieces to numbers that have specific values
	defined	by 2 vectors
In-Reply-To: <B72B6A4E-E524-4A85-BB8F-E11ACC833575@me.com>
References: <B72B6A4E-E524-4A85-BB8F-E11ACC833575@me.com>
Message-ID: <1378157321.49510.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,

You may try this:

set.seed(285)
dat1<- as.data.frame(matrix(paste0(sample(1:10,100,replace=TRUE),sample(LETTERS[1:10],100,replace=TRUE)),10,10),stringsAsFactors=FALSE)

set.seed(3490)
dat2<- data.frame(old=unique(unlist(dat1)),new=sample(1:100,63,replace=FALSE),stringsAsFactors=FALSE)
?dat1New<-as.data.frame(array(dat2[,2][match(as.matrix(dat1),dat2[,1])],dim= dim(dat1),dimnames=dimnames(dat1)))
dat1New
#?? V1 V2 V3? V4 V5 V6 V7 V8 V9 V10
#1? 68 68 68? 14 48 28 30 27 17? 39
#2? 71? 7 64? 93 25 67 61 93 67? 31
#3? 58 27 17? 37 71 31 16 51 69? 19
#4? 30 71 75? 43 86 27 47 35 71? 22
#5? 22 38 59? 55? 6 11 10 32 54? 92
#6? 63 20 88? 65 17 12 48 73 54? 74
#7? 19 61 94? 99 54 83 10? 7 44? 49
#8?? 5? 2 58 100 43 63 12 10 97?? 2
#9? 63 94 91? 79 95 54 57 32 94? 84
#10? 5 60 65? 69 50 46 70 12 98? 54


A.K.




----- Original Message -----
From: tobias schlager <tobebryant at me.com>
To: r-help at r-project.org
Cc: 
Sent: Monday, September 2, 2013 3:29 PM
Subject: [R] Convert chr pieces to numbers that have specific values defined	by 2 vectors

Dear all, 

I think this is an easy task, but I don't know how to do it. Specifically, I have 69 columns with 300.000 rows. In each cell there is a code like 
"2E3", "4RR", etc.

I now have a list that replaces this with values, e.g., 
old??? new
2E3 ??? ??? 5
4RR??? ??? 3
etc. 

The list ist about 1600 rows long, so also to extensive for normal solutions

Do you how to do that? It would be great if you could help me, 
best, 
tobebryant
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Mon Sep  2 23:34:52 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 2 Sep 2013 14:34:52 -0700 (PDT)
Subject: [R] Convert chr pieces to numbers that have specific values
	defined	by 2 vectors
In-Reply-To: <1378157321.49510.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <B72B6A4E-E524-4A85-BB8F-E11ACC833575@me.com>
	<1378157321.49510.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1378157692.80849.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
On a bigger dataset:

#Speed:
set.seed(285)
dat1<- as.data.frame(matrix(paste0(sample(1:10,69*3e5,replace=TRUE),sample(LETTERS[1:10],69*3e5,replace=TRUE)),ncol=69,nrow=3e5),stringsAsFactors=FALSE)
length(unique(unlist(dat1)))
#[1] 100

set.seed(3490)
dat2<- data.frame(old=unique(unlist(dat1)),new=sample(1:100,100,replace=FALSE),stringsAsFactors=FALSE)
?system.time({dat1New<-as.data.frame(array(dat2[,2][match(as.matrix(dat1),dat2[,1])],dim= dim(dat1),dimnames=dimnames(dat1)))})
?#user? system elapsed 
?# 1.480?? 0.236?? 1.719 

A.K.


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: tobias schlager <tobebryant at me.com>
Cc: R help <r-help at r-project.org>
Sent: Monday, September 2, 2013 5:28 PM
Subject: Re: [R] Convert chr pieces to numbers that have specific values defined	by 2 vectors

Hi,

You may try this:

set.seed(285)
dat1<- as.data.frame(matrix(paste0(sample(1:10,100,replace=TRUE),sample(LETTERS[1:10],100,replace=TRUE)),10,10),stringsAsFactors=FALSE)

set.seed(3490)
dat2<- data.frame(old=unique(unlist(dat1)),new=sample(1:100,63,replace=FALSE),stringsAsFactors=FALSE)
?dat1New<-as.data.frame(array(dat2[,2][match(as.matrix(dat1),dat2[,1])],dim= dim(dat1),dimnames=dimnames(dat1)))
dat1New
#?? V1 V2 V3? V4 V5 V6 V7 V8 V9 V10
#1? 68 68 68? 14 48 28 30 27 17? 39
#2? 71? 7 64? 93 25 67 61 93 67? 31
#3? 58 27 17? 37 71 31 16 51 69? 19
#4? 30 71 75? 43 86 27 47 35 71? 22
#5? 22 38 59? 55? 6 11 10 32 54? 92
#6? 63 20 88? 65 17 12 48 73 54? 74
#7? 19 61 94? 99 54 83 10? 7 44? 49
#8?? 5? 2 58 100 43 63 12 10 97?? 2
#9? 63 94 91? 79 95 54 57 32 94? 84
#10? 5 60 65? 69 50 46 70 12 98? 54


A.K.




----- Original Message -----
From: tobias schlager <tobebryant at me.com>
To: r-help at r-project.org
Cc: 
Sent: Monday, September 2, 2013 3:29 PM
Subject: [R] Convert chr pieces to numbers that have specific values defined??? by 2 vectors

Dear all, 

I think this is an easy task, but I don't know how to do it. Specifically, I have 69 columns with 300.000 rows. In each cell there is a code like 
"2E3", "4RR", etc.

I now have a list that replaces this with values, e.g., 
old??? new
2E3 ??? ??? 5
4RR??? ??? 3
etc. 

The list ist about 1600 rows long, so also to extensive for normal solutions

Do you how to do that? It would be great if you could help me, 
best, 
tobebryant
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From dcarlson at tamu.edu  Mon Sep  2 23:38:13 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 2 Sep 2013 16:38:13 -0500
Subject: [R] restructure my data
In-Reply-To: <CAPFhJgbDzb2FD888xdeJwfrspuLtmfiWCqRpQUfAGBacpms+6g@mail.gmail.com>
References: <CAPFhJgbDzb2FD888xdeJwfrspuLtmfiWCqRpQUfAGBacpms+6g@mail.gmail.com>
Message-ID: <013e01cea824$b9fcbb00$2df63100$@tamu.edu>

Thanks for the reproducible data set. The unstack() function
produces a list of three vectors, one for each value of var, but
it cannot combine them into a matrix since the number of entries
in each is not the same. To get that you need to pad each vector
with NAs:

> df <- structure(list(var = c(1, 0, 0, 1, 0, 2, 2, 0, 2, 0),
cauc =
+ c(6462.32876712329,
+ 1585.27397260274, 2481.67808219178, 344.178082191781,
8871.57534246575,
+ 816.780821917808, 6031.33561643836, 1013.52739726027,
4913.52739726027,
+ 1517.25)), .Names = c("var", "cauc"), row.names = c(NA, 10L),
class =
+ "data.frame")
> datlst <- unstack(dat, cauc~var)
> datlst
$`0`
[1] 1585.274 2481.678 8871.575 1013.527 1517.250

$`1`
[1] 6462.3288  344.1781

$`2`
[1]  816.7808 6031.3356 4913.5274

> MaxL <- max(sapply(datlst, length))
> datmat <- sapply(datlst, function(x) c(x, rep(NA,
MaxL-length(x))))
> datmat
            0         1         2
[1,] 1585.274 6462.3288  816.7808
[2,] 2481.678  344.1781 6031.3356
[3,] 8871.575        NA 4913.5274
[4,] 1013.527        NA        NA
[5,] 1517.250        NA        NA

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352




-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Wim Kreinen
Sent: Monday, September 2, 2013 12:07 PM
To: r-help
Subject: [R] restructure my data

My data is in this form: var has 3 conditions (0,1,2)

> df
   var      cauc
1    1 6462.3288
2    0 1585.2740
3    0 2481.6781
4    1  344.1781
5    0 8871.5753
6    2  816.7808
7    2 6031.3356
8    0 1013.5274
9    2 4913.5274
10   0 1517.2500

For the three conditions (0,1,2) I want the cauc-values to be
listed like
this

0                         1               2
1585,2740       6462,3288     816.7808
 2481.6781      344.1781       6031.3356
...

Thanks Wim

> dput (df)
structure(list(var = c(1, 0, 0, 1, 0, 2, 2, 0, 2, 0), cauc =
c(6462.32876712329,
1585.27397260274, 2481.67808219178, 344.178082191781,
8871.57534246575,
816.780821917808, 6031.33561643836, 1013.52739726027,
4913.52739726027,
1517.25)), .Names = c("var", "cauc"), row.names = c(NA, 10L),
class =
"data.frame")
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From smartpink111 at yahoo.com  Mon Sep  2 23:51:15 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 2 Sep 2013 14:51:15 -0700 (PDT)
Subject: [R] restructure my data
In-Reply-To: <CAPFhJgbDzb2FD888xdeJwfrspuLtmfiWCqRpQUfAGBacpms+6g@mail.gmail.com>
References: <CAPFhJgbDzb2FD888xdeJwfrspuLtmfiWCqRpQUfAGBacpms+6g@mail.gmail.com>
Message-ID: <1378158675.47632.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
You could try:
df2<- do.call(cbind,split(df[,-1],df[,1]))

?res<-sapply(seq_len(ncol(df2)),function(i) {x<-df2[,i];x[duplicated(x)]<-NA;x})
dimnames(res)<- dimnames(df2)
res
#??????????? 0???????? 1???????? 2
#[1,] 1585.274 6462.3288? 816.7808
#[2,] 2481.678? 344.1781 6031.3356
#[3,] 8871.575??????? NA 4913.5274
#[4,] 1013.527??????? NA??????? NA
#[5,] 1517.250??????? NA??????? NA
A.K.




----- Original Message -----
From: Wim Kreinen <wkreinen at gmail.com>
To: r-help <r-help at r-project.org>
Cc: 
Sent: Monday, September 2, 2013 1:07 PM
Subject: [R] restructure my data

My data is in this form: var has 3 conditions (0,1,2)

> df
?  var? ? ? cauc
1? ? 1 6462.3288
2? ? 0 1585.2740
3? ? 0 2481.6781
4? ? 1? 344.1781
5? ? 0 8871.5753
6? ? 2? 816.7808
7? ? 2 6031.3356
8? ? 0 1013.5274
9? ? 2 4913.5274
10?  0 1517.2500

For the three conditions (0,1,2) I want the cauc-values to be listed like
this

0? ? ? ? ? ? ? ? ? ? ? ?  1? ? ? ? ? ? ?  2
1585,2740? ? ?  6462,3288? ?  816.7808
2481.6781? ? ? 344.1781? ? ?  6031.3356
...

Thanks Wim

> dput (df)
structure(list(var = c(1, 0, 0, 1, 0, 2, 2, 0, 2, 0), cauc =
c(6462.32876712329,
1585.27397260274, 2481.67808219178, 344.178082191781, 8871.57534246575,
816.780821917808, 6031.33561643836, 1013.52739726027, 4913.52739726027,
1517.25)), .Names = c("var", "cauc"), row.names = c(NA, 10L), class =
"data.frame")
>

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From dcarlson at tamu.edu  Mon Sep  2 23:51:32 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 2 Sep 2013 16:51:32 -0500
Subject: [R] restructure my data
In-Reply-To: <013e01cea824$b9fcbb00$2df63100$@tamu.edu>
References: <CAPFhJgbDzb2FD888xdeJwfrspuLtmfiWCqRpQUfAGBacpms+6g@mail.gmail.com>
	<013e01cea824$b9fcbb00$2df63100$@tamu.edu>
Message-ID: <014501cea826$963a9b90$c2afd2b0$@tamu.edu>

Sorry, there was a typo in my original message:

> df <- structure(list(var = c(1, 0, 0, 1, 0, 2, 2, 0, 2, 0), 
+   cauc = c(6462.32876712329, 1585.27397260274,
2481.67808219178, 
+   344.178082191781, 8871.57534246575, 816.780821917808, 
+   6031.33561643836, 1013.52739726027, 4913.52739726027,
+   1517.25)), .Names = c("var", "cauc"), row.names = c(NA,
10L),
+   class = "data.frame")
> datlst <- unstack(df, cauc~var)
> # or datlst <-  split(df$cauc, df$var)
> datlst
$`0`
[1] 1585.274 2481.678 8871.575 1013.527 1517.250

$`1`
[1] 6462.3288  344.1781

$`2`
[1]  816.7808 6031.3356 4913.5274

> MaxL <- max(sapply(datlst, length))
> datmat <- sapply(datlst, function(x) c(x, rep(NA,
MaxL-length(x))))
> datmat
            0         1         2
[1,] 1585.274 6462.3288  816.7808
[2,] 2481.678  344.1781 6031.3356
[3,] 8871.575        NA 4913.5274
[4,] 1013.527        NA        NA
[5,] 1517.250        NA        NA

David 

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of David Carlson
Sent: Monday, September 2, 2013 4:38 PM
To: 'Wim Kreinen'; 'r-help'
Subject: Re: [R] restructure my data

Thanks for the reproducible data set. The unstack() function
produces a list of three vectors, one for each value of var, but
it cannot combine them into a matrix since the number of entries
in each is not the same. To get that you need to pad each vector
with NAs:

> df <- structure(list(var = c(1, 0, 0, 1, 0, 2, 2, 0, 2, 0),
cauc =
+ c(6462.32876712329,
+ 1585.27397260274, 2481.67808219178, 344.178082191781,
8871.57534246575,
+ 816.780821917808, 6031.33561643836, 1013.52739726027,
4913.52739726027,
+ 1517.25)), .Names = c("var", "cauc"), row.names = c(NA, 10L),
class =
+ "data.frame")
> datlst <- unstack(dat, cauc~var)
> datlst
$`0`
[1] 1585.274 2481.678 8871.575 1013.527 1517.250

$`1`
[1] 6462.3288  344.1781

$`2`
[1]  816.7808 6031.3356 4913.5274

> MaxL <- max(sapply(datlst, length))
> datmat <- sapply(datlst, function(x) c(x, rep(NA,
MaxL-length(x))))
> datmat
            0         1         2
[1,] 1585.274 6462.3288  816.7808
[2,] 2481.678  344.1781 6031.3356
[3,] 8871.575        NA 4913.5274
[4,] 1013.527        NA        NA
[5,] 1517.250        NA        NA

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352




-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Wim Kreinen
Sent: Monday, September 2, 2013 12:07 PM
To: r-help
Subject: [R] restructure my data

My data is in this form: var has 3 conditions (0,1,2)

> df
   var      cauc
1    1 6462.3288
2    0 1585.2740
3    0 2481.6781
4    1  344.1781
5    0 8871.5753
6    2  816.7808
7    2 6031.3356
8    0 1013.5274
9    2 4913.5274
10   0 1517.2500

For the three conditions (0,1,2) I want the cauc-values to be
listed like
this

0                         1               2
1585,2740       6462,3288     816.7808
 2481.6781      344.1781       6031.3356
...

Thanks Wim

> dput (df)
structure(list(var = c(1, 0, 0, 1, 0, 2, 2, 0, 2, 0), cauc =
c(6462.32876712329,
1585.27397260274, 2481.67808219178, 344.178082191781,
8871.57534246575,
816.780821917808, 6031.33561643836, 1013.52739726027,
4913.52739726027,
1517.25)), .Names = c("var", "cauc"), row.names = c(NA, 10L),
class =
"data.frame")
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From David.Epstein at warwick.ac.uk  Tue Sep  3 00:01:25 2013
From: David.Epstein at warwick.ac.uk (David Epstein)
Date: Mon, 2 Sep 2013 23:01:25 +0100
Subject: [R] knitr: Was previously " Sweave: printing an underscore in the
	output from an R command"
In-Reply-To: <CANROs4cmV6+v7je2aviz2NnAjS5xU0bTyy0MyGwc-hyLDq4DkQ@mail.gmail.com>
References: <8AAFC6A6-757E-4E74-A4BB-4D0A55037290@warwick.ac.uk>
	<AA818EAD2576BC488B4F623941DA7427CD351B5F@inbomail.inbo.be>
	<A39E6A7C-11FF-4832-B251-146FF45450A6@warwick.ac.uk>
	<CANROs4cmV6+v7je2aviz2NnAjS5xU0bTyy0MyGwc-hyLDq4DkQ@mail.gmail.com>
Message-ID: <2E5A0841-B60C-40B2-BCBE-BD6E73A87E35@warwick.ac.uk>

Dear Yihui
Thanks very much for drawing my attention to knitr, which I had not heard of before. Also thanks for pointing out the bug in Sweave, which I don't fully understand, but I don't want to spend time and effort on understanding it. So I hope you will find time to report the bug. I was pretty sure there was a bug somewhere that was preventing me from doing what I wanted to do in Sweave, but I misdiagnosed the source of the problem.

I notice you didn't use print() or cat() in your short program for knitr. Is it the case that it's necessary to use print() or cat() with \Sexpr in Sweave, but unnecessary in knitr?

I'll stick to Sweave for my current project, and try out knitr on my next project. I would welcome a list of documents about knitr that I should download, so as to make it as easy as possible to get started. I don't want to understand the internals of knitr, but I am interested in any documents on knitr, written by you or by others, directed at the user, rather than at programmers of packages.

Is it convenient to use vi(m) to produce knitr source? Can vi(m) be integrated into the knitr package? My experience with editors designed specially to work with particular products (like the built-in editor for TeXWorks on the Mac) do not have the power of vi(m) and emacs, and I require this power.

@Duncan: thanks for indicating the use of cat() instead of print(). However, due to the bug in Sweave pointed out by Yihui, replacing print by cat didn't help me.

Thanks
David




On 2 Sep 2013, at 21:11, Yihui Xie wrote:

> I think Thierry meant gsub("_", "\\\\_", version$platform); he just
> typed too quickly. The point is to escape _ using \, but then people
> are often trapped in the dreams of dreams of dreams of backslashes
> like the movie Inception. And then due to a long-standing bug in
> Sweave for \Sexpr{} (sorry I forgot to report to R core), you will be
> so confused that you can never wake up and come back to the reality.
> 
> Dream level 1: when you need a backslash in a character string, you
> need "\\", which really means \; you think "\\_" should be good, but
> no --
> 
> Dream level 2: when you need one literal \ in a regular expression as
> the replacement expression, you need \\
> 
> Combine the two levels of dreams, you end up with "\\\\_". \\\\ in R
> really means \\, which really means \ in regular expressions.
> 
> Now you are good at the regular expression level, but Sweave comes and
> bites you, and that is due to this bug in the regular expression in
> Sweave Noweb syntax:
> 
>> SweaveSyntaxNoweb$docexpr
> [1] "\\\\Sexpr\\{([^\\}]*)\\}"
> 
> It should have been "\\\\Sexpr\\{([^}]*)\\}", i.e. } does not need to
> be escaped inside [], and \\ will be interpreted literally inside [].
> In your case, Sweave sees \ in \Sexpr{}, and the regular expression
> stops matching there, and is unable to see } after \, so it believes
> there is no inline R expressions in your document.
> 
> BTW, knitr does not have this bug and works well in your case:
> 
> \documentclass{article}
> \begin{document}
> \Sexpr{sub("_", "\\\\_", version$platform)}
> \end{document}
> 
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Web: http://yihui.name
> Department of Statistics, Iowa State University
> 2215 Snedecor Hall, Ames, IA
> 
> 
> On Mon, Sep 2, 2013 at 2:18 PM, David Epstein
> <David.Epstein at warwick.ac.uk> wrote:
>> Dear Thierry,
>> 
>> Your suggestion doesn't work on my version of R. Here's what I get
>>> gsub("_", "\_", print(version$platform)
>> Error: '\_' is an unrecognized escape in character string starting ""\_"
>>> print(gsub("_", "\_", version$platform))
>> Error: '\_' is an unrecognized escape in character string starting ""\_"
>> 
>>> sub("_", "\\_", version$platform)
>> [1] "x86_64-apple-darwin10.8.0"
>> Sweave does not evaluate this expression when \Sexpr is applied and a tex error results
>> 
>>> sub("_", "\\\_", version$platform)
>> Error: '\_' is an unrecognized escape in character string starting ""\\\_"
>> Error message from R
>> 
>>> sub("_", "\\\\_", version$platform)
>> [1] "x86\\_64-apple-darwin10.8.0"
>> R evaluates this. However, the above examples indicate a deficiency/possible bug in the command sub, because sub does not seem to be able to output an expression with a single backslash.
>> 
>> I tried the previous version as follows in my .Rnw document
>> \Sexpr{print(sub("_", "\\\\_", version$platform))}
>> When Sweave is run, this expression is evaluated to illegal LaTeX
>> 
>> David.
>> 
>> 
>> 
>> 
>> On 2 Sep 2013, at 16:47, ONKELINX, Thierry wrote:
>> 
>>> You have to escape the underscore
>>> 
>>> \Sexpr{gsub("_", "\_", print(version$platform))}
>>> 
>>> Best regards,
>>> 
>>> Thierry
>>> 
>>> ________________________________________
>>> Van: r-help-bounces at r-project.org [r-help-bounces at r-project.org] namens David Epstein [David.Epstein at warwick.ac.uk]
>>> Verzonden: maandag 2 september 2013 17:38
>>> Aan: r-help at r-project.org
>>> Onderwerp: [R] Sweave: printing an underscore in the output from an R command
>>> 
>>> I am working with Sweave and would like to print out into my latex document the result of the R command
>>> version$platform
>>> So what I first tried in my .Rnw document was \Sexpr{print(version$platform)}.
>>> 
>>> However, the output from this command is the string "x86_64-apple-darwin10.8.0" (without the quotes). This contains an underscore, which is a special character in tex and so I get an error message from latex.
>>> 
>>> I can get round this by using sub to replace underscore with a space, but I would like to know how to print the underscore if I really wanted to do so.
> 


From xie at yihui.name  Tue Sep  3 00:21:44 2013
From: xie at yihui.name (Yihui Xie)
Date: Mon, 2 Sep 2013 17:21:44 -0500
Subject: [R] knitr: Was previously " Sweave: printing an underscore in
 the output from an R command"
In-Reply-To: <2E5A0841-B60C-40B2-BCBE-BD6E73A87E35@warwick.ac.uk>
References: <8AAFC6A6-757E-4E74-A4BB-4D0A55037290@warwick.ac.uk>
	<AA818EAD2576BC488B4F623941DA7427CD351B5F@inbomail.inbo.be>
	<A39E6A7C-11FF-4832-B251-146FF45450A6@warwick.ac.uk>
	<CANROs4cmV6+v7je2aviz2NnAjS5xU0bTyy0MyGwc-hyLDq4DkQ@mail.gmail.com>
	<2E5A0841-B60C-40B2-BCBE-BD6E73A87E35@warwick.ac.uk>
Message-ID: <CANROs4fgUo7W86Lu-t=94BAdJfrkrHQkDGhj=4s8pfdSYnygoA@mail.gmail.com>

On Mon, Sep 2, 2013 at 5:01 PM, David Epstein
<David.Epstein at warwick.ac.uk> wrote:
> Dear Yihui
> Thanks very much for drawing my attention to knitr, which I had not heard of before. Also thanks for pointing out the bug in Sweave, which I don't fully understand, but I don't want to spend time and effort on understanding it. So I hope you will find time to report the bug. I was pretty sure there was a bug somewhere that was preventing me from doing what I wanted to do in Sweave, but I misdiagnosed the source of the problem.
>
> I notice you didn't use print() or cat() in your short program for knitr. Is it the case that it's necessary to use print() or cat() with \Sexpr in Sweave, but unnecessary in knitr?

No, print() is superfluous; it is not necessary for either Sweave or
knitr, and cat() is a wrong way to go here, since cat() returns
character(0).

>
> I'll stick to Sweave for my current project, and try out knitr on my next project. I would welcome a list of documents about knitr that I should download, so as to make it as easy as possible to get started. I don't want to understand the internals of knitr, but I am interested in any documents on knitr, written by you or by others, directed at the user, rather than at programmers of packages.

Electronic version of the documentation: http://yihui.name/knitr Paper
version: http://www.amazon.com/gp/product/1482203537

You do not need to understand the internals of knitr, otherwise I
would not mention it at all. Depending on the size and complexity of
your project, it may take you a few seconds or hours to switch from
Sweave to knitr: http://yihui.name/knitr/demo/sweave/

>
> Is it convenient to use vi(m) to produce knitr source? Can vi(m) be integrated into the knitr package? My experience with editors designed specially to work with particular products (like the built-in editor for TeXWorks on the Mac) do not have the power of vi(m) and emacs, and I require this power.

Whatever editor you use: http://yihui.name/knitr/demo/editors/

>
> @Duncan: thanks for indicating the use of cat() instead of print(). However, due to the bug in Sweave pointed out by Yihui, replacing print by cat didn't help me.
>
> Thanks
> David


Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


From rolf.turner at xtra.co.nz  Tue Sep  3 01:10:54 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Tue, 03 Sep 2013 11:10:54 +1200
Subject: [R] Issue with R libraries
In-Reply-To: <1377945337592-4675074.post@n4.nabble.com>
References: <1377945337592-4675074.post@n4.nabble.com>
Message-ID: <52251AFE.8090208@xtra.co.nz>

On 31/08/13 22:35, prakashdevkumar wrote:
> I have an Ubuntu Quantal 12.10 Server 64-bit instance. Trying to install R
> libraries. Facing issue in installing library(qdap)
> library(openNLP)
> Can you suggest me how to go ahead.

No one should reply to you until you learn that what you are trying to 
install is a
***package*** (not a library)!!!  (A library is a collection of packages.)

     cheers,

     Rolf Turner


From kristi.glover at hotmail.com  Tue Sep  3 04:51:59 2013
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Mon, 2 Sep 2013 23:51:59 -0300
Subject: [R] how to calculate bioclim for table dataset in dismo package
In-Reply-To: <COL129-W60213BF056CE9309CA2F51FA310@phx.gbl>
References: <COL129-W60213BF056CE9309CA2F51FA310@phx.gbl>
Message-ID: <COL129-W83BC632CC582EA71EB74C6FA310@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130902/c0c41d83/attachment.pl>

From smartpink111 at yahoo.com  Tue Sep  3 05:29:26 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 2 Sep 2013 20:29:26 -0700 (PDT)
Subject: [R] R dataframe and looping help
In-Reply-To: <1378155696.79446.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1378155696.79446.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1378178966.37014.YahooMailNeo@web142605.mail.bf1.yahoo.com>

HI Satish,

colnames(Output)[4]<- colnames(dat2)[i]; #guess this line should be:

colnames(x1)[4]<- colnames(dat2)[i]

Regarding the warning, I used 

read.table(..., stringsAsFactors=FALSE).? In your case, you might need to either use that option while reading the data or convert the factor variables to character class.

Check:
str(Output) 


I forgot about sorting the data.? You can use either ?sort() or ?order

?dat1New<-dat1[order(dat1$CustID,as.Date(dat1$TripDate,"%d-%b-%y"),dat1$Store),]? #in the example data, it didn't change anything

dat2<- dat1New[,-c(1:3)]
str(dat1New)
'data.frame':??? 7 obs. of? 7 variables:
?$ CustID? : int? 1 1 1 1 2 2 2
?$ TripDate: chr? "2-Jan-12" "6-Jan-12" "9-Jan-12" "31-Mar-13" ... ##should be factor in your original dataset
?$ Store?? : chr? "a" "c" "a" "a" ...? #####
?$ Bread?? : int? 2 0 3 3 0 3 3
?$ Butter? : int? 0 3 3 0 3 3 0
?$ Milk??? : int? 2 3 0 0 3 0 0
?$ Eggs??? : int? 1 0 0 0 0 0 0



Suppose, I read the data with stringsAsFactors=TRUE (default is this option)

dat1<- read.table(text="
CustID TripDate Store Bread Butter Milk Eggs
1 2-Jan-12 a 2 0 2 1 
1 6-Jan-12 c 0 3 3 0 
1 9-Jan-12 a 3 3 0 0
1 31-Mar-13 a 3 0 0 0
2 31-Aug-12 a 0 3 3 0
2 24-Sep-12 a 3 3 0 0
2 25-Sep-12 b 3 0 0 0
",sep="",header=TRUE)

?str(dat1)
'data.frame':??? 7 obs. of? 7 variables:
?$ CustID? : int? 1 1 1 1 2 2 2
?$ TripDate: Factor w/ 7 levels "24-Sep-12","25-Sep-12",..: 3 6 7 5 4 1 2
?$ Store?? : Factor w/ 3 levels "a","b","c": 1 3 1 1 1 1 2
?$ Bread?? : int? 2 0 3 3 0 3 3
?$ Butter? : int? 0 3 3 0 3 3 0
?$ Milk??? : int? 2 3 0 0 3 0 0
?$ Eggs??? : int? 1 0 0 0 0 0 0


dat2<- dat1[,-c(1:3)]
?
?res<- lapply(seq_len(ncol(dat2)),function(i) {x1<-cbind(dat1[,c(1:3)],dat2[,i]);colnames(x1)[4]<- colnames(dat2)[i];x2<-x1[x1[,4]!=0,];within(x2, {daysbetweentrips<-unlist(tapply(as.Date(x2$TripDate,"%d-%b-%y"),list(x2$CustID),function(x) c(NA,as.numeric(diff(x)))));previoustripstore<-ave(x2$Store,x2$CustID,FUN=function(x) c(NA,x[-length(x)]));Nexttripstore<- ave(x2$Store,x2$CustID,FUN=function(x) c(x[-1],NA))})})
Warning messages:
1: In `[<-.factor`(`*tmp*`, i, value = c(NA, 1L, 1L)) :
? invalid factor level, NA generated
2: In `[<-.factor`(`*tmp*`, i, value = c(NA, 1L)) :
? invalid factor level, NA generated
3: In `[<-.factor`(`*tmp*`, i, value = c(1L, 1L, NA)) :
? invalid factor level, NA generated
---------------------------------------------------
?

To convert to character class after reading the data:
dat1[]<-lapply(dat1,function(x) if(is.factor(x)) as.character(x) else x)
?str(dat1)
#'data.frame':??? 7 obs. of? 7 variables:
# $ CustID? : int? 1 1 1 1 2 2 2
# $ TripDate: chr? "2-Jan-12" "6-Jan-12" "9-Jan-12" "31-Mar-13" ...
# $ Store?? : chr? "a" "c" "a" "a" ...
# $ Bread?? : int? 2 0 3 3 0 3 3
# $ Butter? : int? 0 3 3 0 3 3 0
# $ Milk??? : int? 2 3 0 0 3 0 0
# $ Eggs??? : int? 1 0 0 0 0 0 0


?dat2<- dat1[,-c(1:3)]
?
? res<- lapply(seq_len(ncol(dat2)),function(i) {x1<-cbind(dat1[,c(1:3)],dat2[,i]);colnames(x1)[4]<- colnames(dat2)[i];x2<-x1[x1[,4]!=0,];within(x2, {daysbetweentrips<-unlist(tapply(as.Date(x2$TripDate,"%d-%b-%y"),list(x2$CustID),function(x) c(NA,as.numeric(diff(x)))));previoustripstore<-ave(x2$Store,x2$CustID,FUN=function(x) c(NA,x[-length(x)]));Nexttripstore<- ave(x2$Store,x2$CustID,FUN=function(x) c(x[-1],NA))})}) #works




A.K.


? 





Hi Arun-
?
Thanks for this...
?
I ran this code. without the days between trips... Can you please 
confirm the paranthesis and code looks?right.?. they do to me....
?

res<- lapply(seq_len(ncol(dat2)),function(i) 
{
x1<-cbind(Output[,c(1:3)],dat2[,i]);
colnames(Output)[4]<- colnames(dat2)[i];
x2<-x1[x1[,4]!=0,];
previoustripstore<-ave(x2$store,x2$CUSTID,FUN=function(x) c(NA,x[-length(x)]));
Nexttripstore<- ave(x2$store,x2$CUSTID,FUN=function(x) c(x[-1],NA))
}
) 
?
But i get an warning like this:In `[<-.factor`(`*tmp*`, i, value = c(NA, 3L, 3L, 3L,? ... :
? invalid factor level, NA generated
?
Wat might be wrong? Please help
?
Thanks,
Satish


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Monday, September 2, 2013 5:01 PM
Subject: Re: R dataframe and looping help

HI,
You may try this:

dat1<- read.table(text="
CustID TripDate Store Bread Butter Milk Eggs
1 2-Jan-12 a 2 0 2 1 
1 6-Jan-12 c 0 3 3 0 
1 9-Jan-12 a 3 3 0 0
1 31-Mar-13 a 3 0 0 0
2 31-Aug-12 a 0 3 3 0
2 24-Sep-12 a 3 3 0 0
2 25-Sep-12 b 3 0 0 0
",sep="",header=TRUE,stringsAsFactors=FALSE)
dat2<- dat1[,-c(1:3)]

res<- lapply(seq_len(ncol(dat2)),function(i) {x1<-cbind(dat1[,c(1:3)],dat2[,i]);colnames(x1)[4]<- colnames(dat2)[i];x2<-x1[x1[,4]!=0,];within(x2, {daysbetweentrips<-unlist(tapply(as.Date(x2$TripDate,"%d-%b-%y"),list(x2$CustID),function(x) c(NA,as.numeric(diff(x)))));previoustripstore<-ave(x2$Store,x2$CustID,FUN=function(x) c(NA,x[-length(x)]));Nexttripstore<- ave(x2$Store,x2$CustID,FUN=function(x) c(x[-1],NA))})})


?res
#[[1]]
?# CustID? TripDate Store Bread Nexttripstore previoustripstore daysbetweentrips
#1????? 1? 2-Jan-12???? a???? 2???????????? a????????????? <NA>?????????????? NA
#3????? 1? 9-Jan-12???? a???? 3???????????? a???????????????? a??????????????? 7
#4????? 1 31-Mar-13???? a???? 3????????? <NA>???????????????? a????????????? 447
#6????? 2 24-Sep-12???? a???? 3???????????? b????????????? <NA>?????????????? NA
#7????? 2 25-Sep-12???? b???? 3????????? <NA>???????????????? a??????????????? 1

#[[2]]
?# CustID? TripDate Store Butter Nexttripstore previoustripstore
#2????? 1? 6-Jan-12???? c????? 3???????????? a????????????? <NA>
#3????? 1? 9-Jan-12???? a????? 3????????? <NA>???????????????? c
#5????? 2 31-Aug-12???? a????? 3???????????? a????????????? <NA>
#6????? 2 24-Sep-12???? a????? 3????????? <NA>???????????????? a
?# daysbetweentrips
#2?????????????? NA
#3??????????????? 3
#5?????????????? NA
#6?????????????? 24

#[[3]]
?# CustID? TripDate Store Milk Nexttripstore previoustripstore daysbetweentrips
#1????? 1? 2-Jan-12???? a??? 2???????????? c????????????? <NA>?????????????? NA
#2????? 1? 6-Jan-12???? c??? 3????????? <NA>???????????????? a??????????????? 4
#5????? 2 31-Aug-12???? a??? 3????????? <NA>????????????? <NA>?????????????? NA

#[[4]]
?# CustID TripDate Store Eggs Nexttripstore previoustripstore daysbetweentrips
#1????? 1 2-Jan-12???? a??? 1????????? <NA>????????????? <NA>?????????????? NA



A.K.


Hi, I have a very quick question.. I have a data which has sales per 
category per trip of each customer at different store locations, like 
below..(dataset1 frome xcel attachment) CustID??? TripDate??? Store??? Bread??? Butter??? Milk??? Eggs
1??? 2-Jan-12??? ? a??? 2??? 0??? 2??? 1
1??? 6-Jan-12??? ? c??? 0??? 3??? 3??? 0
1??? 9-Jan-12??? ? a??? 3??? 3??? 0??? 0
1??? 31-Mar-13 a??? 3??? 0??? 0??? 0
2??? 31-Aug-12 a??? 0??? 3??? 3??? 0
2??? 24-Sep-12 a??? 3??? 3??? 0??? 0
2??? 25-Sep-12 b??? 3??? 0??? 0??? 0 Here i have shown 4 items and their sales per customer per trip at each 
store... However, my data contains around 100 columns with item names.. 
All i need to do is following: 1. Create a separate dataframe for each item. That is, create 100 
dataframs one for each item.. Within the dataframe for Butter, for 
example, will be contained columns 1-3 and Butter column, specifically 
filtered for rows where butter>0 in sales..(so rows 1,4,7 will be 
dropped from this dataframe)..Likewise for all items...(sample output 
for butter is: (dataset2) CustID??? TripDate??? Store??? Butter
1??? 6-Jan-12??? ?  c??? 3
1??? 9-Jan-12??? ?  a??? 3
2??? 31-Aug-12? a??? 3
2??? 24-Sep-12? a??? 3 2. In same loop, create new derived variables within each dataframe for 
each item... like create a lag variable for TripDate, create lag 
variable for storename in next trip, storename in previous trip etc... 
and also # days between trips to each store for each customer...(an 
example for Butter dataframe with new derived variables would be...)
Dataset needs to be sorted by CustID, TripDate, Store before creating 
derived variables (dataset3)Book1.xlsx CustID??? TripDate??? Store??? Butter??? NextTripstore previoustripstore 
daysbetweentrips
1??? 6-Jan-12??? ?  c??? 3??? a??? ? ? ? ? ? ? ? -??? ? ? ?  -
1??? 9-Jan-12??? ?  a??? 3??? -??? ? ? ? ? ? ? ? c??? ? ? ?  -
2??? 31-Aug-12? a??? 3??? a??? ? ? ? ? ? ? ? -??? ? ? ?  -
2??? 24-Sep-12? a??? 3??? -??? ? ? ? ? ? ? ? a??? ? ?  24 Point of creating multiple item level dataframes is, i will use them 
iteratively as i will perform some regression on these datasets, using 
same set of variables each time


From eajeong at gmail.com  Tue Sep  3 05:27:05 2013
From: eajeong at gmail.com (Euna Jeong)
Date: Tue, 3 Sep 2013 12:27:05 +0900
Subject: [R] Question about the prediction plot in pls package
Message-ID: <CAMLpsns732kzp=TiUOnNh5AyKVxw55NrYiEXjTCa8RF3B3sHkg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130903/98ff4904/attachment.pl>

From smartpink111 at yahoo.com  Tue Sep  3 07:02:59 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 2 Sep 2013 22:02:59 -0700 (PDT)
Subject: [R] R dataframe and looping help
In-Reply-To: <1378178966.37014.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1378155696.79446.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1378178966.37014.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1378184579.39924.YahooMailNeo@web142604.mail.bf1.yahoo.com>

HI,
Try:
res<- lapply(seq_len(ncol(dat2)),function(i)
{
x1<-cbind(dat1New[,c(1:4)],dat2[,i]);
colnames(x1)[5]<- colnames(dat2)[i];
x2<-x1[x1[,5]!=0,];
x2$previoustripstore<-ave(x2$Store,x2$CUSTID,FUN=function(x) c("",x[-length(x)]));
x2$Nexttripstore<- ave(x2$Store,x2$PANID,FUN=function(x) c(x[-1],""))
x2
}
) 


In my previous reply, I used ?within().? 


A.K.




Hi Arun.. I made the factor to character and eventually date conversion. 

I am able to see the res dataframe, but it only has the store 
names in it.. I cant see all columns like your output? Here is code i 
use.. 

Output is name of my dataframe and 1st 4 columns are CustID,TripID,TripDate,Store 

# CONVERT all factor to character type 
Output[]<-lapply(Output,function(x) if(is.factor(x)) as.character(x) else x) 
# SORT 
dat1New<-Output[order(Output$CUSTID,as.Date(Output$TRIPDATE,"%m-%d-%y"),Output$Store),] 

dat2<- dat1New[,-c(1:4)] 

res<- lapply(seq_len(ncol(dat2)),function(i) 
{ 
x1<-cbind(dat1New[,c(1:4)],dat2[,i]); 
colnames(x1)[5]<- colnames(dat2)[i]; 
x2<-x1[x1[,5]!=0,]; 
previoustripstore<-ave(x2$Store,x2$CUSTID,FUN=function(x) c("",x[-length(x)])); 
Nexttripstore<- ave(x2$Store,x2$PANID,FUN=function(x) c(x[-1],"")) 
} 
) 

What am i doing wrong? 


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Monday, September 2, 2013 11:29 PM
Subject: Re: R dataframe and looping help

HI Satish,

colnames(Output)[4]<- colnames(dat2)[i]; #guess this line should be:

colnames(x1)[4]<- colnames(dat2)[i]

Regarding the warning, I used 

read.table(..., stringsAsFactors=FALSE).? In your case, you might need to either use that option while reading the data or convert the factor variables to character class.

Check:
str(Output) 


I forgot about sorting the data.? You can use either ?sort() or ?order

?dat1New<-dat1[order(dat1$CustID,as.Date(dat1$TripDate,"%d-%b-%y"),dat1$Store),]? #in the example data, it didn't change anything

dat2<- dat1New[,-c(1:3)]
str(dat1New)
'data.frame':??? 7 obs. of? 7 variables:
?$ CustID? : int? 1 1 1 1 2 2 2
?$ TripDate: chr? "2-Jan-12" "6-Jan-12" "9-Jan-12" "31-Mar-13" ... ##should be factor in your original dataset
?$ Store?? : chr? "a" "c" "a" "a" ...? #####
?$ Bread?? : int? 2 0 3 3 0 3 3
?$ Butter? : int? 0 3 3 0 3 3 0
?$ Milk??? : int? 2 3 0 0 3 0 0
?$ Eggs??? : int? 1 0 0 0 0 0 0



Suppose, I read the data with stringsAsFactors=TRUE (default is this option)

dat1<- read.table(text="
CustID TripDate Store Bread Butter Milk Eggs
1 2-Jan-12 a 2 0 2 1 
1 6-Jan-12 c 0 3 3 0 
1 9-Jan-12 a 3 3 0 0
1 31-Mar-13 a 3 0 0 0
2 31-Aug-12 a 0 3 3 0
2 24-Sep-12 a 3 3 0 0
2 25-Sep-12 b 3 0 0 0
",sep="",header=TRUE)

?str(dat1)
'data.frame':??? 7 obs. of? 7 variables:
?$ CustID? : int? 1 1 1 1 2 2 2
?$ TripDate: Factor w/ 7 levels "24-Sep-12","25-Sep-12",..: 3 6 7 5 4 1 2
?$ Store?? : Factor w/ 3 levels "a","b","c": 1 3 1 1 1 1 2
?$ Bread?? : int? 2 0 3 3 0 3 3
?$ Butter? : int? 0 3 3 0 3 3 0
?$ Milk??? : int? 2 3 0 0 3 0 0
?$ Eggs??? : int? 1 0 0 0 0 0 0


dat2<- dat1[,-c(1:3)]
?
?res<- lapply(seq_len(ncol(dat2)),function(i) {x1<-cbind(dat1[,c(1:3)],dat2[,i]);colnames(x1)[4]<- colnames(dat2)[i];x2<-x1[x1[,4]!=0,];within(x2, {daysbetweentrips<-unlist(tapply(as.Date(x2$TripDate,"%d-%b-%y"),list(x2$CustID),function(x) c(NA,as.numeric(diff(x)))));previoustripstore<-ave(x2$Store,x2$CustID,FUN=function(x) c(NA,x[-length(x)]));Nexttripstore<- ave(x2$Store,x2$CustID,FUN=function(x) c(x[-1],NA))})})
Warning messages:
1: In `[<-.factor`(`*tmp*`, i, value = c(NA, 1L, 1L)) :
? invalid factor level, NA generated
2: In `[<-.factor`(`*tmp*`, i, value = c(NA, 1L)) :
? invalid factor level, NA generated
3: In `[<-.factor`(`*tmp*`, i, value = c(1L, 1L, NA)) :
? invalid factor level, NA generated
---------------------------------------------------
?

To convert to character class after reading the data:
dat1[]<-lapply(dat1,function(x) if(is.factor(x)) as.character(x) else x)
?str(dat1)
#'data.frame':??? 7 obs. of? 7 variables:
# $ CustID? : int? 1 1 1 1 2 2 2
# $ TripDate: chr? "2-Jan-12" "6-Jan-12" "9-Jan-12" "31-Mar-13" ...
# $ Store?? : chr? "a" "c" "a" "a" ...
# $ Bread?? : int? 2 0 3 3 0 3 3
# $ Butter? : int? 0 3 3 0 3 3 0
# $ Milk??? : int? 2 3 0 0 3 0 0
# $ Eggs??? : int? 1 0 0 0 0 0 0


?dat2<- dat1[,-c(1:3)]
?
? res<- lapply(seq_len(ncol(dat2)),function(i) {x1<-cbind(dat1[,c(1:3)],dat2[,i]);colnames(x1)[4]<- colnames(dat2)[i];x2<-x1[x1[,4]!=0,];within(x2, {daysbetweentrips<-unlist(tapply(as.Date(x2$TripDate,"%d-%b-%y"),list(x2$CustID),function(x) c(NA,as.numeric(diff(x)))));previoustripstore<-ave(x2$Store,x2$CustID,FUN=function(x) c(NA,x[-length(x)]));Nexttripstore<- ave(x2$Store,x2$CustID,FUN=function(x) c(x[-1],NA))})}) #works




A.K.


? 





Hi Arun-
?
Thanks for this...
?
I ran this code. without the days between trips... Can you please 
confirm the paranthesis and code looks?right.?. they do to me....
?

res<- lapply(seq_len(ncol(dat2)),function(i) 
{
x1<-cbind(Output[,c(1:3)],dat2[,i]);
colnames(Output)[4]<- colnames(dat2)[i];
x2<-x1[x1[,4]!=0,];
previoustripstore<-ave(x2$store,x2$CUSTID,FUN=function(x) c(NA,x[-length(x)]));
Nexttripstore<- ave(x2$store,x2$CUSTID,FUN=function(x) c(x[-1],NA))
}
) 
?
But i get an warning like this:In `[<-.factor`(`*tmp*`, i, value = c(NA, 3L, 3L, 3L,? ... :
? invalid factor level, NA generated
?
Wat might be wrong? Please help
?
Thanks,
Satish


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Monday, September 2, 2013 5:01 PM
Subject: Re: R dataframe and looping help

HI,
You may try this:

dat1<- read.table(text="
CustID TripDate Store Bread Butter Milk Eggs
1 2-Jan-12 a 2 0 2 1 
1 6-Jan-12 c 0 3 3 0 
1 9-Jan-12 a 3 3 0 0
1 31-Mar-13 a 3 0 0 0
2 31-Aug-12 a 0 3 3 0
2 24-Sep-12 a 3 3 0 0
2 25-Sep-12 b 3 0 0 0
",sep="",header=TRUE,stringsAsFactors=FALSE)
dat2<- dat1[,-c(1:3)]

res<- lapply(seq_len(ncol(dat2)),function(i) {x1<-cbind(dat1[,c(1:3)],dat2[,i]);colnames(x1)[4]<- colnames(dat2)[i];x2<-x1[x1[,4]!=0,];within(x2, {daysbetweentrips<-unlist(tapply(as.Date(x2$TripDate,"%d-%b-%y"),list(x2$CustID),function(x) c(NA,as.numeric(diff(x)))));previoustripstore<-ave(x2$Store,x2$CustID,FUN=function(x) c(NA,x[-length(x)]));Nexttripstore<- ave(x2$Store,x2$CustID,FUN=function(x) c(x[-1],NA))})})


?res
#[[1]]
?# CustID? TripDate Store Bread Nexttripstore previoustripstore daysbetweentrips
#1????? 1? 2-Jan-12???? a???? 2???????????? a????????????? <NA>?????????????? NA
#3????? 1? 9-Jan-12???? a???? 3???????????? a???????????????? a??????????????? 7
#4????? 1 31-Mar-13???? a???? 3????????? <NA>???????????????? a????????????? 447
#6????? 2 24-Sep-12???? a???? 3???????????? b????????????? <NA>?????????????? NA
#7????? 2 25-Sep-12???? b???? 3????????? <NA>???????????????? a??????????????? 1

#[[2]]
?# CustID? TripDate Store Butter Nexttripstore previoustripstore
#2????? 1? 6-Jan-12???? c????? 3???????????? a????????????? <NA>
#3????? 1? 9-Jan-12???? a????? 3????????? <NA>???????????????? c
#5????? 2 31-Aug-12???? a????? 3???????????? a????????????? <NA>
#6????? 2 24-Sep-12???? a????? 3????????? <NA>???????????????? a
?# daysbetweentrips
#2?????????????? NA
#3??????????????? 3
#5?????????????? NA
#6?????????????? 24

#[[3]]
?# CustID? TripDate Store Milk Nexttripstore previoustripstore daysbetweentrips
#1????? 1? 2-Jan-12???? a??? 2???????????? c????????????? <NA>?????????????? NA
#2????? 1? 6-Jan-12???? c??? 3????????? <NA>???????????????? a??????????????? 4
#5????? 2 31-Aug-12???? a??? 3????????? <NA>????????????? <NA>?????????????? NA

#[[4]]
?# CustID TripDate Store Eggs Nexttripstore previoustripstore daysbetweentrips
#1????? 1 2-Jan-12???? a??? 1????????? <NA>????????????? <NA>?????????????? NA



A.K.


Hi, I have a very quick question.. I have a data which has sales per 
category per trip of each customer at different store locations, like 
below..(dataset1 frome xcel attachment) CustID??? TripDate??? Store??? Bread??? Butter??? Milk??? Eggs
1??? 2-Jan-12??? ? a??? 2??? 0??? 2??? 1
1??? 6-Jan-12??? ? c??? 0??? 3??? 3??? 0
1??? 9-Jan-12??? ? a??? 3??? 3??? 0??? 0
1??? 31-Mar-13 a??? 3??? 0??? 0??? 0
2??? 31-Aug-12 a??? 0??? 3??? 3??? 0
2??? 24-Sep-12 a??? 3??? 3??? 0??? 0
2??? 25-Sep-12 b??? 3??? 0??? 0??? 0 Here i have shown 4 items and their sales per customer per trip at each 
store... However, my data contains around 100 columns with item names.. 
All i need to do is following: 1. Create a separate dataframe for each item. That is, create 100 
dataframs one for each item.. Within the dataframe for Butter, for 
example, will be contained columns 1-3 and Butter column, specifically 
filtered for rows where butter>0 in sales..(so rows 1,4,7 will be 
dropped from this dataframe)..Likewise for all items...(sample output 
for butter is: (dataset2) CustID??? TripDate??? Store??? Butter
1??? 6-Jan-12??? ?? c??? 3
1??? 9-Jan-12??? ?? a??? 3
2??? 31-Aug-12? a??? 3
2??? 24-Sep-12? a??? 3 2. In same loop, create new derived variables within each dataframe for 
each item... like create a lag variable for TripDate, create lag 
variable for storename in next trip, storename in previous trip etc... 
and also # days between trips to each store for each customer...(an 
example for Butter dataframe with new derived variables would be...)
Dataset needs to be sorted by CustID, TripDate, Store before creating 
derived variables (dataset3)Book1.xlsx CustID??? TripDate??? Store??? Butter??? NextTripstore previoustripstore 
daysbetweentrips
1??? 6-Jan-12??? ?? c??? 3??? a??? ? ? ? ? ? ? ? -??? ? ? ?? -
1??? 9-Jan-12??? ?? a??? 3??? -??? ? ? ? ? ? ? ? c??? ? ? ?? -
2??? 31-Aug-12? a??? 3??? a??? ? ? ? ? ? ? ? -??? ? ? ?? -
2??? 24-Sep-12? a??? 3??? -??? ? ? ? ? ? ? ? a??? ? ?? 24 Point of creating multiple item level dataframes is, i will use them 
iteratively as i will perform some regression on these datasets, using 
same set of variables each time


From b.h.mevik at usit.uio.no  Tue Sep  3 08:18:40 2013
From: b.h.mevik at usit.uio.no (=?utf-8?Q?Bj=C3=B8rn-Helge_Mevik?=)
Date: Tue, 03 Sep 2013 08:18:40 +0200
Subject: [R] Question about the prediction plot in pls package
In-Reply-To: <CAMLpsns732kzp=TiUOnNh5AyKVxw55NrYiEXjTCa8RF3B3sHkg@mail.gmail.com>
	(Euna Jeong's message of "Tue, 3 Sep 2013 12:27:05 +0900")
References: <CAMLpsns732kzp=TiUOnNh5AyKVxw55NrYiEXjTCa8RF3B3sHkg@mail.gmail.com>
Message-ID: <s3shae2h1hb.fsf@slagelg.uio.no>

Euna Jeong <eajeong at gmail.com> writes:

> R> plot(gas1, ncomp=2, asp = 1, line = TRUE)
>
> This shows only the cross-validated predictions.

If you add the argument which = c("train", "validation") (see
?predplot.mvr), you will get both.  However, you will get them in
separate panels in the plot.

If you wish to have them in the same panel, you will have to add the
points yourself.  This should work:

plot(gas1, ncomp=2, asp = 1, line = TRUE)
points(predict(gas1, ncomp = 2) ~ gasoline$octane, col = "red")

-- 
Regards,
Bj?rn-Helge Mevik


From smartpink111 at yahoo.com  Tue Sep  3 08:47:48 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 2 Sep 2013 23:47:48 -0700 (PDT)
Subject: [R] remove rows with infinite/nan values from a zoo dataset
Message-ID: <1378190868.36659.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Please dput() the example dataset.? When I read from the one shown below, it looks a bit altered.

library(zoo)
dat1<- read.zoo(text="2009-07-15,#N/A N/A,#N/A N/A,18.96858
2009-07-16,20.30685,20.40664,#N/A N/A
2009-07-17,20.78813,20.03991,20.40664
2009-07-20,21.41278,21.41278,20.03991
2009-07-21,22.9963,22.98397,21.41278
2009-07-22,23.06443,23.01112,22.98397
2009-07-23,23.45905,24.72232,23.01112
2009-07-24,24.89291,25.56603,24.72232
2009-07-27,25.38929,24.80535,25.56603
2009-07-28,25.26712,25.65566,24.80535
2009-07-29,25.83884,24.98163,25.65566
2009-07-30,#N/A N/A,#N/A N/A,24.98163
2009-08-03,25.25553,25.93297,#N/A N/A
2009-08-04,26.02464,25.49159,25.93297
",sep=",",header=FALSE,FUN=as.Date,format="%Y-%m-%d",fill=TRUE) 


dput(dat1)? ###
structure(c(NA, 20.30685, 20.78813, 21.41278, 22.9963, 23.06443, 
23.45905, 24.89291, 25.38929, 25.26712, 25.83884, NA, 25.25553, 
26.02464, NA, 20.40664, 20.03991, 21.41278, 22.98397, 23.01112, 
24.72232, 25.56603, 24.80535, 25.65566, 24.98163, NA, 25.93297, 
25.49159, NA, NA, 20.40664, 20.03991, 21.41278, 22.98397, 23.01112, 
24.72232, 25.56603, 24.80535, 25.65566, NA, NA, 25.93297), .Dim = c(14L, 
3L), .Dimnames = list(NULL, c("V2", "V3", "V4")), index = structure(c(14440, 
14441, 14442, 14445, 14446, 14447, 14448, 14449, 14452, 14453, 
14454, 14455, 14459, 14460), class = "Date"), class = "zoo")


dat2<- dat1[!rowSums(is.na(dat1)),]
dat2
#???????????????? V2?????? V3?????? V4
#2009-07-17 20.78813 20.03991 20.40664
#2009-07-20 21.41278 21.41278 20.03991
#2009-07-21 22.99630 22.98397 21.41278
#2009-07-22 23.06443 23.01112 22.98397
#2009-07-23 23.45905 24.72232 23.01112
#2009-07-24 24.89291 25.56603 24.72232
#2009-07-27 25.38929 24.80535 25.56603
#2009-07-28 25.26712 25.65566 24.80535
#2009-07-29 25.83884 24.98163 25.65566
#2009-08-04 26.02464 25.49159 25.93297


dat2[1,2]<- Inf
?dat2[5,3]<- -Inf


dat2[rowSums(is.finite(dat2))==ncol(dat2),]
#???????????????? V2?????? V3?????? V4
#2009-07-20 21.41278 21.41278 20.03991
#2009-07-21 22.99630 22.98397 21.41278
#2009-07-22 23.06443 23.01112 22.98397
#2009-07-24 24.89291 25.56603 24.72232
#2009-07-27 25.38929 24.80535 25.56603
#2009-07-28 25.26712 25.65566 24.80535
#2009-07-29 25.83884 24.98163 25.65566
#2009-08-04 26.02464 25.49159 25.93297


A.K.

Hi There, 

I have a dataset with many rows and few columns as following: 

2009-07-15	#N/A N/A	#N/A N/A	18.96858 
2009-07-16	20.30685	20.40664	#N/A N/A 
2009-07-17	20.78813	20.03991	20.40664 
2009-07-20	21.41278	21.41278	20.03991 
2009-07-21	22.9963	22.98397	21.41278 
2009-07-22	23.06443	23.01112	22.98397 
2009-07-23	23.45905	24.72232	23.01112 
2009-07-24	24.89291	25.56603	24.72232 
2009-07-27	25.38929	24.80535	25.56603 
2009-07-28	25.26712	25.65566	24.80535 
2009-07-29	25.83884	24.98163	25.65566 
2009-07-30	#N/A N/A	#N/A N/A	24.98163 
2009-08-03	25.25553	25.93297	#N/A N/A 
2009-08-04	26.02464	25.49159	25.93297 

The class of the dataset is "zoo". My question might be stupid 
but could anyone suggest a way to remove the rows with #N/A values? 
I tried "rapply" command but it didn't work due to the data class. 

btw, how about for the "Inf" values? 

Thank you in advance!


From eajeong at gmail.com  Tue Sep  3 09:19:21 2013
From: eajeong at gmail.com (Euna Jeong)
Date: Tue, 3 Sep 2013 16:19:21 +0900
Subject: [R] Question about the prediction plot in pls package
In-Reply-To: <s3shae2h1hb.fsf@slagelg.uio.no>
References: <CAMLpsns732kzp=TiUOnNh5AyKVxw55NrYiEXjTCa8RF3B3sHkg@mail.gmail.com>
	<s3shae2h1hb.fsf@slagelg.uio.no>
Message-ID: <CAMLpsnvdjgwLz-bWc=TYMQUan3sVxNcY3kEE60ObrK=tpm8cgw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130903/2015143a/attachment.pl>

From hardy.edouard at gmail.com  Tue Sep  3 09:34:12 2013
From: hardy.edouard at gmail.com (Edouard Hardy)
Date: Tue, 3 Sep 2013 09:34:12 +0200
Subject: [R] Product of certain rows in a matrix without loop
Message-ID: <CAFsztN6X0+zxkcU64yvY8KUxFdJ60ySR4ri7reywASizDipqZg@mail.gmail.com>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
URL : <https://stat.ethz.ch/pipermail/r-help/attachments/20130903/5ec72292/attachment.pl>

From teresamarso at hotmail.com  Tue Sep  3 10:59:00 2013
From: teresamarso at hotmail.com (=?iso-8859-1?B?TaogVGVyZXNhIE1hcnRpbmV6IFNvcmlhbm8=?=)
Date: Tue, 3 Sep 2013 08:59:00 +0000
Subject: [R] Legend Help
Message-ID: <DUB125-W15DF57EF93F0659BA635C7B9310@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130903/55be1069/attachment.pl>

From Gerrit.Eichner at math.uni-giessen.de  Tue Sep  3 11:49:31 2013
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Tue, 3 Sep 2013 11:49:31 +0200 (MEST)
Subject: [R] Product of certain rows in a matrix without loop
In-Reply-To: <CAFsztN6X0+zxkcU64yvY8KUxFdJ60ySR4ri7reywASizDipqZg@mail.gmail.com>
References: <CAFsztN6X0+zxkcU64yvY8KUxFdJ60ySR4ri7reywASizDipqZg@mail.gmail.com>
Message-ID: <Pine.SOC.4.64.1309031142240.16518@solcom.hrz.uni-giessen.de>

Hello, Edouard,

taking logs of A's elements (so that * turns into +, so to say), using a 
left-multiplication with a certain band matrix of the package Matrix, and 
exponentiating the result again could provide a solution (see below).

> I know have the following problem:
> I have a matrix :
> A =
> 1  2  3
> 4  5  6
> 7  8  9
> 9  8  7
> 4  5  6
> 3  2  1
>
> And I would like to have :
> B =
> 1*4*7  2*5*8  3*6*9
> 4*7*9  5*8*8  6*9*7
> 7*9*4  8*8*5  9*7*6
> 9*4*3  8*5*2  7*6*1
>
> Here I took the product of 3 rows each time. And 3 needs to be a parameter.
>
> Is it possible to do so without any loop ?


Caveat: Not very carefully tested!

library( Matrix)

k <- 3
ones <- lapply( 1:k, function( j) rep( 1, nrow( A) - j + 1)))
leftmatrix <- bandSparse( n = nrow(A) - k + 1, m = nrow(A),
                           k = 0:(k-1), diagonals = ones)

exp( leftmatrix %*% log(A))

  Hth  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
Fax: +49-(0)641-99-32109        http://www.uni-giessen.de/cms/eichner


From Christoph.Scherber at agr.uni-goettingen.de  Tue Sep  3 11:51:54 2013
From: Christoph.Scherber at agr.uni-goettingen.de (Christoph Scherber)
Date: Tue, 03 Sep 2013 11:51:54 +0200
Subject: [R] Multiple regression (with interactions) by hand
Message-ID: <5225B13A.7060903@agr.uni-goettingen.de>

Dear all,

I?ve played around with the "airquality" dataset, trying to solve the matrix equations of a simple
multiple regression by hand; however, my matrix multiplications don?t lead to the estimates returned
by coef(). What have I done wrong here?

##
m1=lm(Ozone~Solar.R*Wind,airquality)

# remove NA?s:
airquality2=airquality[complete.cases(airquality$Ozone)&
complete.cases(airquality$Solar.R)&
complete.cases(airquality$Wind),]

# create the model matrix by hand:
X=cbind("(Intercept)"=1,Solar.R=airquality2$Solar.R,Wind=airquality2$Wind,"Solar.R:Wind"=airquality2$Solar.R*airquality2$Wind)
# is the same as:
model.matrix(m1)

# create the response vector by hand:
Y=airquality2$Ozone
# is the same as:
m1$model$Ozone

# Now solve for the parameter estimates:
library(MASS)
ginv(t(X)%*%X)%*%t(X)%*%Y

# is not the same as:
coef(m1)

##
Now why is my result (line ginv(...)) not the same as the one returned by coef(m1)?

Thanks very much for your help!

Best regards,
Christoph

[using R 3.0.1 on Windows 7 32-Bit]





-- 
PD Dr Christoph Scherber
Georg-August University Goettingen
Department of Crop Science
Agroecology
Grisebachstrasse 6
D-37077 Goettingen
Germany
phone 0049 (0)551 39 8807
fax 0049 (0)551 39 8806
http://www.gwdg.de/~cscherb1


From hardy.edouard at gmail.com  Tue Sep  3 11:55:45 2013
From: hardy.edouard at gmail.com (Edouard Hardy)
Date: Tue, 3 Sep 2013 11:55:45 +0200
Subject: [R] Product of certain rows in a matrix without loop
In-Reply-To: <Pine.SOC.4.64.1309031142240.16518@solcom.hrz.uni-giessen.de>
References: <CAFsztN6X0+zxkcU64yvY8KUxFdJ60ySR4ri7reywASizDipqZg@mail.gmail.com>
	<Pine.SOC.4.64.1309031142240.16518@solcom.hrz.uni-giessen.de>
Message-ID: <CAFsztN78ofPHNw=35TZ3pBan59Dk+-zBGbNScF7z66vhjJW=ZQ@mail.gmail.com>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
URL : <https://stat.ethz.ch/pipermail/r-help/attachments/20130903/61b161de/attachment.pl>

From Gerrit.Eichner at math.uni-giessen.de  Tue Sep  3 12:03:32 2013
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Tue, 3 Sep 2013 12:03:32 +0200 (MEST)
Subject: [R] Product of certain rows in a matrix without loop
In-Reply-To: <CAFsztN78ofPHNw=35TZ3pBan59Dk+-zBGbNScF7z66vhjJW=ZQ@mail.gmail.com>
References: <CAFsztN6X0+zxkcU64yvY8KUxFdJ60ySR4ri7reywASizDipqZg@mail.gmail.com>
	<Pine.SOC.4.64.1309031142240.16518@solcom.hrz.uni-giessen.de>
	<CAFsztN78ofPHNw=35TZ3pBan59Dk+-zBGbNScF7z66vhjJW=ZQ@mail.gmail.com>
Message-ID: <Pine.SOC.4.64.1309031159060.16518@solcom.hrz.uni-giessen.de>

> Thank you very much for your answer. Unfortunately, I cannot use any 
> package...
Er, ... this is quite unusual! (Is this is homework?)

> Do you have a solution ?
Well, take a look at the resulting bandmatrix leftmatrix. Yould can 
certainly build it yourself "by hand" somehow. I used the Matrix package 
just for convenience.

  Regards -- Gerrit

> Thank you in advance
>
>
> Edouard Hardy
>
>
> On Tue, Sep 3, 2013 at 11:49 AM, Gerrit Eichner <
> Gerrit.Eichner at math.uni-giessen.de> wrote:
>
>> Hello, Edouard,
>>
>> taking logs of A's elements (so that * turns into +, so to say), using a
>> left-multiplication with a certain band matrix of the package Matrix, and
>> exponentiating the result again could provide a solution (see below).
>>
>>
>>  I know have the following problem:
>>> I have a matrix :
>>> A =
>>> 1  2  3
>>> 4  5  6
>>> 7  8  9
>>> 9  8  7
>>> 4  5  6
>>> 3  2  1
>>>
>>> And I would like to have :
>>> B =
>>> 1*4*7  2*5*8  3*6*9
>>> 4*7*9  5*8*8  6*9*7
>>> 7*9*4  8*8*5  9*7*6
>>> 9*4*3  8*5*2  7*6*1
>>>
>>> Here I took the product of 3 rows each time. And 3 needs to be a
>>> parameter.
>>>
>>> Is it possible to do so without any loop ?
>>>
>>
>>
>> Caveat: Not very carefully tested!
>>
>> library( Matrix)
>>
>> k <- 3
>> ones <- lapply( 1:k, function( j) rep( 1, nrow( A) - j + 1)))
>> leftmatrix <- bandSparse( n = nrow(A) - k + 1, m = nrow(A),
>>                           k = 0:(k-1), diagonals = ones)
>>
>> exp( leftmatrix %*% log(A))
>>
>>  Hth  --  Gerrit


From Gerrit.Eichner at math.uni-giessen.de  Tue Sep  3 12:09:14 2013
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Tue, 3 Sep 2013 12:09:14 +0200 (MEST)
Subject: [R] Product of certain rows in a matrix without loop
In-Reply-To: <Pine.SOC.4.64.1309031159060.16518@solcom.hrz.uni-giessen.de>
References: <CAFsztN6X0+zxkcU64yvY8KUxFdJ60ySR4ri7reywASizDipqZg@mail.gmail.com>
	<Pine.SOC.4.64.1309031142240.16518@solcom.hrz.uni-giessen.de>
	<CAFsztN78ofPHNw=35TZ3pBan59Dk+-zBGbNScF7z66vhjJW=ZQ@mail.gmail.com>
	<Pine.SOC.4.64.1309031159060.16518@solcom.hrz.uni-giessen.de>
Message-ID: <Pine.SOC.4.64.1309031206510.16518@solcom.hrz.uni-giessen.de>

Ok, here is a bandmatrix solution "by hand":

leftmatrix <- matrix( c( rep( 1, k), rep( 0, nrow(A) - k + 1)),
                       byrow = TRUE, ncol = nrow(A), nrow = nrow(A) - k + 1)


  Gerrit

>> Thank you very much for your answer. Unfortunately, I cannot use any 
>> package...
> Er, ... this is quite unusual! (Is this is homework?)
>
>> Do you have a solution ?
> Well, take a look at the resulting bandmatrix leftmatrix. Yould can certainly 
> build it yourself "by hand" somehow. I used the Matrix package just for 
> convenience.
>
> Regards -- Gerrit
>
>> Thank you in advance
>> 
>> 
>> Edouard Hardy
>> 
>> 
>> On Tue, Sep 3, 2013 at 11:49 AM, Gerrit Eichner <
>> Gerrit.Eichner at math.uni-giessen.de> wrote:
>> 
>>> Hello, Edouard,
>>> 
>>> taking logs of A's elements (so that * turns into +, so to say), using a
>>> left-multiplication with a certain band matrix of the package Matrix, and
>>> exponentiating the result again could provide a solution (see below).
>>> 
>>>
>>>  I know have the following problem:
>>>> I have a matrix :
>>>> A =
>>>> 1  2  3
>>>> 4  5  6
>>>> 7  8  9
>>>> 9  8  7
>>>> 4  5  6
>>>> 3  2  1
>>>> 
>>>> And I would like to have :
>>>> B =
>>>> 1*4*7  2*5*8  3*6*9
>>>> 4*7*9  5*8*8  6*9*7
>>>> 7*9*4  8*8*5  9*7*6
>>>> 9*4*3  8*5*2  7*6*1
>>>> 
>>>> Here I took the product of 3 rows each time. And 3 needs to be a
>>>> parameter.
>>>> 
>>>> Is it possible to do so without any loop ?
>>>> 
>>> 
>>> 
>>> Caveat: Not very carefully tested!
>>> 
>>> library( Matrix)
>>> 
>>> k <- 3
>>> ones <- lapply( 1:k, function( j) rep( 1, nrow( A) - j + 1)))
>>> leftmatrix <- bandSparse( n = nrow(A) - k + 1, m = nrow(A),
>>>                           k = 0:(k-1), diagonals = ones)
>>> 
>>> exp( leftmatrix %*% log(A))
>>>
>>>  Hth  --  Gerrit


From jwiley.psych at gmail.com  Tue Sep  3 12:29:43 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Tue, 3 Sep 2013 03:29:43 -0700
Subject: [R] Multiple regression (with interactions) by hand
In-Reply-To: <5225B13A.7060903@agr.uni-goettingen.de>
References: <5225B13A.7060903@agr.uni-goettingen.de>
Message-ID: <CANz9Z_+2ksBgEQhWxNZvuR5HPduJx3pYJS2mdumV4YQz+pqinQ@mail.gmail.com>

Hi Christoph,

Use this matrix expression instead:

solve(crossprod(X)) %*% t(X) %*% Y

Note that:

all.equal(crossprod(X), t(X) %*% X)

Cheers,

Joshua



On Tue, Sep 3, 2013 at 2:51 AM, Christoph Scherber
<Christoph.Scherber at agr.uni-goettingen.de> wrote:
> Dear all,
>
> I?ve played around with the "airquality" dataset, trying to solve the matrix equations of a simple
> multiple regression by hand; however, my matrix multiplications don?t lead to the estimates returned
> by coef(). What have I done wrong here?
>
> ##
> m1=lm(Ozone~Solar.R*Wind,airquality)
>
> # remove NA?s:
> airquality2=airquality[complete.cases(airquality$Ozone)&
> complete.cases(airquality$Solar.R)&
> complete.cases(airquality$Wind),]
>
> # create the model matrix by hand:
> X=cbind("(Intercept)"=1,Solar.R=airquality2$Solar.R,Wind=airquality2$Wind,"Solar.R:Wind"=airquality2$Solar.R*airquality2$Wind)
> # is the same as:
> model.matrix(m1)
>
> # create the response vector by hand:
> Y=airquality2$Ozone
> # is the same as:
> m1$model$Ozone
>
> # Now solve for the parameter estimates:
> library(MASS)
> ginv(t(X)%*%X)%*%t(X)%*%Y
>
> # is not the same as:
> coef(m1)
>
> ##
> Now why is my result (line ginv(...)) not the same as the one returned by coef(m1)?
>
> Thanks very much for your help!
>
> Best regards,
> Christoph
>
> [using R 3.0.1 on Windows 7 32-Bit]
>
>
>
>
>
> --
> PD Dr Christoph Scherber
> Georg-August University Goettingen
> Department of Crop Science
> Agroecology
> Grisebachstrasse 6
> D-37077 Goettingen
> Germany
> phone 0049 (0)551 39 8807
> fax 0049 (0)551 39 8806
> http://www.gwdg.de/~cscherb1
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://joshuawiley.com/
Senior Analyst - Elkhart Group Ltd.
http://elkhartgroup.com


From therneau at mayo.edu  Tue Sep  3 13:07:04 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Tue, 03 Sep 2013 06:07:04 -0500
Subject: [R] help
In-Reply-To: <mailman.17.1378202408.2323.r-help@r-project.org>
References: <mailman.17.1378202408.2323.r-help@r-project.org>
Message-ID: <5225C2D8.4010102@mayo.edu>

The tt function is documented for coxph, and you are using cph.   They are not the same.

On 09/03/2013 05:00 AM, r-help-request at r-project.org wrote:
> tt<- function(x) {
>                  obrien<- function(x) {
>                    r<- rank(x)
>                    (r - 0.5)/(0.5 + length(r) - r)
>                  }
>                  unlist(tapply(x, riskset, obrien))
>              }
> hi,  i am newer in R. when dealing  with a survival data, i have found the variable progression was not met the PH assumption.the picture show the residual agaist time.So i  use Cox model for time-depandent varibles.   i  use the default tt in function coxph,but when i use tt in "f<-cph(Surv(os$Stime,os$Status==1)~Metastasis+Surgery+Post.chem. +Age+tt(Progression)+ ALP, data=os, x=T, y=T, surv=TRUE, time.inc=60)",it didn't work. i don't kown what the arg"riskset" is .i beg your help . can you help me write down a appropriate tt expression to let me use in cph. thanks.
>                                                                                                                                                        Zhongxin Dong
>


From carlos.nasher at googlemail.com  Tue Sep  3 13:28:21 2013
From: carlos.nasher at googlemail.com (Carlos Nasher)
Date: Tue, 3 Sep 2013 13:28:21 +0200
Subject: [R] [dfoptim] 'Error in fn(ginv(par),
	...) : object 'alpha' not found'
Message-ID: <CAP=BVWOTjnLwBSAfa6XtN_CeT=pHymGbYeLF+qZB4v=6jZ+z1A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130903/31382019/attachment.pl>

From therneau at mayo.edu  Tue Sep  3 13:31:40 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Tue, 03 Sep 2013 06:31:40 -0500
Subject: [R] POSIXlt and months
Message-ID: <5225C89C.9030607@mayo.edu>

The help page for as.POSIXlt suggests using it as a way to extract month, day, and year.
However, I can't find any documentation on the results and am a bit surprised by the month 
portion.

An example, run about 6:21 AM on Sept 3.

 > unlist(unclass(as.POSIXlt(Sys.time())))

       sec       min      hour      mday       mon      year      wday      yday
  43.24545  21.00000   6.00000   3.00000   8.00000 113.00000   2.00000 245.00000
     isdst
   1.00000


So: it appears that I need to
       add 1900 to year
       add 1 to month
but other components are as I would expect.

 > unlist(unclass(as.POSIXlt(as.Date("1953/03/10"))))
   sec   min  hour  mday   mon  year  wday  yday isdst
     0     0     0    10     2    53     2    68     0

Supports a 0 origin for everything except year and mday.

  A pointer to formal documentation of this would make me feel easier about using the 
function.

Terry Therneau


From ggrothendieck at gmail.com  Tue Sep  3 13:57:31 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 3 Sep 2013 07:57:31 -0400
Subject: [R] POSIXlt and months
In-Reply-To: <5225C89C.9030607@mayo.edu>
References: <5225C89C.9030607@mayo.edu>
Message-ID: <CAP01uRktE6eHsYCqWFrbTHZoRswH7WyyB4jcUjxvTs48jhOxhg@mail.gmail.com>

On Tue, Sep 3, 2013 at 7:31 AM, Terry Therneau <therneau at mayo.edu> wrote:
> The help page for as.POSIXlt suggests using it as a way to extract month,
> day, and year.
> However, I can't find any documentation on the results and am a bit
> surprised by the month portion.
>
> An example, run about 6:21 AM on Sept 3.
>
>> unlist(unclass(as.POSIXlt(Sys.time())))
>
>       sec       min      hour      mday       mon      year      wday
> yday
>  43.24545  21.00000   6.00000   3.00000   8.00000 113.00000   2.00000
> 245.00000
>     isdst
>   1.00000
>
>
> So: it appears that I need to
>       add 1900 to year
>       add 1 to month
> but other components are as I would expect.
>
>> unlist(unclass(as.POSIXlt(as.Date("1953/03/10"))))
>   sec   min  hour  mday   mon  year  wday  yday isdst
>     0     0     0    10     2    53     2    68     0
>
> Supports a 0 origin for everything except year and mday.
>
>  A pointer to formal documentation of this would make me feel easier about
> using the function.

?DateTimeClasses


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From anupam.contact at gmail.com  Tue Sep  3 12:58:31 2013
From: anupam.contact at gmail.com (anupam sinha)
Date: Tue, 3 Sep 2013 16:28:31 +0530
Subject: [R] reading files
Message-ID: <CAPPk2Aj2pgfxnO0=1O1Dv_JX-yG2DrNzGp4K4Qx0ZB8PoBZg8w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130903/40744a27/attachment.pl>

From htl10 at users.sourceforge.net  Tue Sep  3 11:51:28 2013
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Tue, 03 Sep 2013 10:51:28 +0100
Subject: [R] new bugs and new bundles Re: [Rd] R/Sweave/cairo/freetype bug
	fix.
In-Reply-To: <1371134413.44971.YahooMailClassic@web172306.mail.ir2.yahoo.com>
References: <1371134413.44971.YahooMailClassic@web172306.mail.ir2.yahoo.com>
Message-ID: <5225B120.8050406@users.sourceforge.net>

The most up-to-date version of freetype (2.5.0.1) have problems with at least 
two of the system fonts shipped with Mac OS X. So the "p1" in "2.5.0.1p1":

cairo-1.12.16+freetype-2.5.0.1p1_macosx.tar.bz2
cairo-1.12.16+freetype-2.5.0.1p1_windows.tar.bz2

means "2.5.0.1" + 274207eb9a0e3bb20edf30e9a62e25120d5d15e5 (the fix for one of 
the problems). There might be p2 bundles if 2.5.1 doesn't come out soon enough
with fixes for the rest of the problems.

http://sourceforge.net/projects/outmodedbonsai/files/R/

Just so we are clear, if freetype have problem with a system font, fontconfig 
has problem with a system font, and cairo and R etc.

Unix users should just upgrade. I'll get round to build R 2.15.3 (or 2.15.x) for 
windows and Mac OS X at some stage, but if somebody want to beat me to it, 
please feel free to do so.

Hin-Tak Leung wrote:
> Freetype 2.4.12 was released in early May. Just so that we are clear that this is a freetype bug which affects R's use of Cairo (among other things). So there are updated bundles, and also bundles for Mac OS X as well, for both a patched 2.4.11 and 2.4.12 proper. The accompanying *.txt has a listing of versions.
>
> http://sourceforge.net/projects/outmodedbonsai/files/R/
>
> Unix users should just upgrade. I'll get round to build R 2.15.3 (or 2.15.x) for windows and Mac OS X at some stage, but if somebody want to beat me to it, please feel free to do so.
>
> --- On Tue, 2/4/13, Hin-Tak Leung <htl10 at users.sourceforge.net> wrote:
>
>> --- On Mon, 1/4/13, Hin-Tak Leung
>> <htl10 at users.sourceforge.net>
>> wrote:
>>> --- On Sat, 30/3/13, Hin-Tak Leung
>>> <htl10 at users.sourceforge.net>
>>> wrote:
>>>
>>>> "... was committed to freetype in January and will
>> form
>>> the
>>>> next release (2.4.12)".
>>>
>>> It is perhaps worth repeating the quote:  'The
>> official
>>> R binaries for windows ... are compiled against static
>>> libraries of cairo 1.10.2 ... are firmly in the "do not
>> work
>>> correctly" category'
>>>
>>> The minimum version of cairo to work being 1.11.2. On
>> closer
>>> examination, the official bundle (http://www.rforge.net/Cairo/files/cairo-current-win.tar.gz)
>>> is built with neither fontconfig nor freetype. So even
>> if it
>>> is bumped to current version (1.12.x), it does not
>> work
>>> correctly.
>>
>> Here is a drop-in replacement for the above:
>> http://sourceforge.net/projects/outmodedbonsai/files/R/cairo-1.12.14%2Bft%2Bfc-win.tar.gz
>>
>> Besides being over 2 years more up-to-date, cairo (1.12.14)
>> is also built with fontconfig and freetype enabled, and
>> freetype being 2.4.11 + back-ported patch (https://bugzilla.redhat.com/show_bug.cgi?id=891457#c35)
>> so at least there is a a better chance of R working
>> correctly.
>>
>> The full list of the tar ball is (a superset of the above,
>> due to addition of fontconfig and freetype and their
>> dependencies):
>> -------
>> cairo-1.12.14
>> pixman-0.26.2
>> libpng-1.5.13
>> zlib-1.2.7
>> fontconfig-2.10.1
>> freetype-2.4.11 (patched)
>> glib2-2.34.3
>> expat-2.1.0
>> bzip2-1.0.6
>> libffi-3.0.11
>> gettext-0.18.2
>> ---------
>> This allows the C-based cairo bug demo (#c10) to build so I
>> am sure it is sufficient for building windows R. At some
>> stage I'll rebuild a less-buggy R 2.15.3 for windows, but
>> not for a few weeks so if somebody wants to beat me to it,
>> please feel free to do so.
>>
>>> Perhaps also wasn't clear in the bugzilla thread -
>> everybody
>>> from fontconfig/cairo/freetype involved knew it being
>> the
>>> issue so it has never been explicitly spelled out -
>> the
>>> problem was (is) with cairo's pdf/ps generation, aided
>> by
>>> freetype.
>>>
>>>> ------------------------------
>>>> On Sat, Mar 30, 2013 18:54 GMT Simon Urbanek
>> wrote:
>>>>
>>>>> On Mar 30, 2013, at 9:24 AM, Hin-Tak Leung
>> wrote:
>>>>>
>>>>>> Perhaps that's too much details. There
>> is
>>> (will be)
>>>> a new freetype because of cairo's unanticipated
>> usage
>>> (which
>>>> R uses, among other cairo users). Most people
>> should
>>> upgrade
>>>> or request an upgrade eventually, when they are
>>>> comfortable.
>>>>>>
>>>>>
>>>>> Which versions are affected? R binary for OS
>> X
>>> uses
>>>> freetype 2.4.11 (and cairo 1.12.14) so I just need
>> to
>>> know
>>>> if there is an action item.
>>>>>
>>>>> Thanks,
>>>>> SImon
>>>>>
>>>>>
>>>>>
>>>>>> --- On Sat, 30/3/13, peter dalgaard
>> <pdalgd at gmail.com>
>>>> wrote:
>>>>>>
>>>>>> Huh?
>>>>>>
>>>>>> This is utterly incomprehensible without
>>> reading
>>>> the redhat
>>>>>> bugzilla, and even after reading, I'm not
>> sure
>>> what
>>>> the
>>>>>> issue is. Something with bold Chinese
>> fonts in
>>> X11,
>>>> but
>>>>>> maybe also affecting Latin fonts, ....?
>>>>>>
>>>>>> Please explain yourself.
>>>>>>
>>>>>> -pd
>>>>>>
>>>>>> On Mar 30, 2013, at 09:25 , Hin-Tak
>> Leung
>>> wrote:
>>>>>>
>>>>>>> The problem was first seen with
>> R/Sweave
>>> (#c0)
>>>> then
>>>>>> reproduced directly with cairo (#c10) and
>> was
>>>> eventually
>>>>>> traced to freetype. The 5-part bug fix:
>>>>>>>
>> 610ee58e07090ead529849b2a454bb6c503b4995
>>>>>>>
>> da11e5e7647b668dee46fd0418ea5ecbc33ae3b2
>>>>>>>
>> e1a2ac1900f2f16ec48fb4840a6b7965a8373c2b
>>>>>>>
>> 869fb8c49ddf292d6daf4826172a308973d3e11f
>>>>>>>
>> d56e544d653b09c657911629557ffc5277a503e3
>>>>>>> was committed to freetype in January
>> and
>>> will
>>>> form the
>>>>>> next release (2.4.12). They were back
>> ported
>>> to
>>>> 2.4.11
>>>>>>> https://bugzilla.redhat.com/show_bug.cgi?id=891457#c35
>>>>>>> and the redhat people had further
>>> back-ported
>>>> it to
>>>>>> 2.4.10 for fedora 18/19 (#c51).
>>>>>>>
>>>>>>> The freetype people had reproduced
>> the
>>> problem
>>>> with a
>>>>>> latin font, so this affects most people,
>>> unlike
>>>> what the
>>>>>> initial report (#c0) suggests.
>>>>>>>
>>>>>>> Since freetype is part of X11, most
>>> unix/linux
>>>> users
>>>>>> would be understandably nervous about
>> breaking
>>> X
>>>> (see #c45
>>>>>> for screenshot of broken gnome terminal!)
>> and
>>>> should wait up
>>>>>> to a year before the new and
>> not-yet-released
>>>> 2.4.12 becomes
>>>>>> an official upgrade; or contact their
>>> favourite
>>>> unix vendors
>>>>>> and/or Apple for upgrades. AFAIK,
>> current
>>>> up-to-date linux
>>>>>> distributions ships the rather older
>> 2.4.10,
>>> with
>>>> the
>>>>>> exception of fedora 18/19 (#c51). Mac OS
>> X
>>> 10.5
>>>> ships
>>>>>> freetype 2.3.5 as part of X11; I haven't
>>> bother
>>>> looking up
>>>>>> later Mac OS X's.
>>>>>>>
>>>>>>> The official R binaries for windows
>> and
>>> mac OS
>>>> X are
>>>>>> compiled against static libraries of
>> cairo
>>> 1.10.2
>>>> (over 2
>>>>>> years old), and cairo 1.11.2 and
>> freetype
>>> 2.4.4
>>>>>> respectively, and are firmly in the "do
>> not
>>> work
>>>> correctly"
>>>>>> category.
>>>>>>>
>>>>>>> The long and short of the story is
>> that
>>>> R/Sweave uses a
>>>>>> feature of cairo which wasn't
>> implemented
>>> before
>>>> cairo
>>>>>> 1.11.2 (#c13, Jan 2011), which in turn
>> depends
>>> on a
>>>> feature
>>>>>> of freetype that has been around since
>> 2005
>>> but did
>>>> not
>>>>>> anticipate cairo's usage. It is
>> commendable
>>> that
>>>> the
>>>>>> freetype people did not refer to cairo's
>> usage
>>> as
>>>> "misuse"
>>>>>> but took the patience to address the
>> problem,
>>>> unlike some
>>>>>> group's style.
>>>>>>>
>>>>>>> It has been an interesting few
>> months
>>> returning
>>>> to
>>>>>> freetype after about 17 years, I think.
>>>>>>>
>>>>>>> Here is how to look up what version
>> of
>>> freetype
>>>> -
>>>>>> libfreetype.so.x.y.z for most unix
>> platforms,
>>> and
>>>>>> /usr/X11/lib/libfreetype.x.y.z.dylib on
>> Mac OS
>>> X:
>>>>>>>
>>>>>>> (excerpt from docs/VERSION.DLL)
>>>>>>>
>>>>>>>        version
>>>>>> x.y.z   date of release
>>>>>>>        2.4.11
>>>>>>      6.10.0  Dec 2012
>>>>>>>        2.4.10
>>>>>>      6.9.0   June 2012
>>>>>>>        2.4.9
>>>>
>>>>>> 6.8.1   March 2012
>>>>>>> ...
>>>>>>>        2.4.4
>>>>
>>>>>> 6.6.2   Nov 2010  (official R
>>>> mac
>>>>>> binaries)
>>>>>>> ...
>>>>>>>        2.3.5
>>>>
>>>>>> 6.3.16  July 2007 (Mac OS X 10.5)
>>>>>>>
>>>>>>>
>>>>>>>
>>> ______________________________________________
>>>>>>> R-devel at r-project.org
>>>>>> mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>
>>>>>> --
>>>>>> Peter Dalgaard, Professor,
>>>>>> Center for Statistics, Copenhagen
>> Business
>>> School
>>>>>> Solbjerg Plads 3, 2000 Frederiksberg,
>> Denmark
>>>>>> Phone: (+45)38153501
>>>>>> Email: pd.mes at cbs.dk
>>>>>> Priv: PDalgd at gmail.com
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>> ______________________________________________
>>>>>> R-devel at r-project.org
>>>> mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>
>>>>>>
>>>>>
>>>>
>>>>
>>>
>>
>


From youngrang.kang at hotmail.com  Tue Sep  3 14:12:33 2013
From: youngrang.kang at hotmail.com (YoungrangKang)
Date: Tue, 3 Sep 2013 21:12:33 +0900
Subject: [R] Enquiry for applying Self-Organizing Map for Time Series
 Prediction in R
Message-ID: <BAY176-W44C0864EFD6219F8F1709492310@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130903/7b7c2930/attachment.pl>

From petr.pikal at precheza.cz  Tue Sep  3 11:45:22 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 3 Sep 2013 09:45:22 +0000
Subject: [R] Legend Help
In-Reply-To: <DUB125-W15DF57EF93F0659BA635C7B9310@phx.gbl>
References: <DUB125-W15DF57EF93F0659BA635C7B9310@phx.gbl>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B900EE@SRVEXCHMBX.precheza.cz>

Hi

put line

legend("topright", legend=names(a)[3:9], lty=1, col=3:9)

before dev.off()

see ?legend for fine tuning.

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Ma Teresa Martinez Soriano
> Sent: Tuesday, September 03, 2013 10:59 AM
> To: r-help at r-project.org
> Subject: [R] Legend Help
> 
> Hi to everyone and thanks for this service.
> 
> I have a doubt with legend, I have seen ?legend, but I don't get the
> way to write in my code the
> 
> legend that I want,
> 
> This is my code:
> 
> 
> 
> for( i in 1:4)}
> 
>         pdf(paste("plotImputed", i,".pdf",sep=""))
>  	plot(a[,6], type="l", main=paste( "Imputed Data GRUPO",i) )
>  	for(k in 3:9)(lines(a[, k], type="l", col=k))
>  	dev.off()
> 
> }
> 
> 
> Each line represent a column of my data set, they are called: IE.2004,
> IE.2006, IE.2007....IE.2010 and this is (IE.2005, IE.2006...)
> 
>  what I would like to see in the graph
> 
> Thanks a lot
> 
> Best regards, Teresa
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Tue Sep  3 11:57:55 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 3 Sep 2013 09:57:55 +0000
Subject: [R] Product of certain rows in a matrix without loop
In-Reply-To: <CAFsztN6X0+zxkcU64yvY8KUxFdJ60ySR4ri7reywASizDipqZg@mail.gmail.com>
References: <CAFsztN6X0+zxkcU64yvY8KUxFdJ60ySR4ri7reywASizDipqZg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9010C@SRVEXCHMBX.precheza.cz>

Hi

one option is use embed

fff<-function(vec, n=3) apply(embed(vec,n),1,prod)
apply(A,2, fff)

Regards
Petr



> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Edouard Hardy
> Sent: Tuesday, September 03, 2013 9:34 AM
> To: R help
> Subject: [R] Product of certain rows in a matrix without loop
> 
> Hello everybody.
> Thank you again to Bert and Arun for their help on my previous
> question.
> I know have the following problem:
> I have a matrix :
> A =
> 1  2  3
> 4  5  6
> 7  8  9
> 9  8  7
> 4  5  6
> 3  2  1
> 
> And I would like to have :
> B =
> 1*4*7  2*5*8  3*6*9
> 4*7*9  5*8*8  6*9*7
> 7*9*4  8*8*5  9*7*6
> 9*4*3  8*5*2  7*6*1
> 
> Here I took the product of 3 rows each time. And 3 needs to be a
> parameter.
> 
> Is it possible to do so without any loop ?
> 
> Thank you in advance !
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From spyqqqdia at yahoo.com  Tue Sep  3 15:08:30 2013
From: spyqqqdia at yahoo.com (Michael Meyer)
Date: Tue, 3 Sep 2013 21:08:30 +0800 (SGT)
Subject: [R] optim evils
Message-ID: <1378213710.11750.YahooMailNeo@web193404.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130903/0fda03cd/attachment.pl>

From fronczyk at vizja.pl  Tue Sep  3 14:32:55 2013
From: fronczyk at vizja.pl (fronczyk at vizja.pl)
Date: Tue, 3 Sep 2013 14:32:55 +0200
Subject: [R] ESEM in R
Message-ID: <730a23623491d441c8fbae055bf0e3c4.squirrel@poczta.vizja.pl>

Hello R experts,

Is there any possibility to perform exploratory structural equation modeling
(ESEM) in R? Which package should I use?

Thanks a lot for help,
Krzysztof


From Christoph.Scherber at agr.uni-goettingen.de  Tue Sep  3 15:22:02 2013
From: Christoph.Scherber at agr.uni-goettingen.de (Christoph Scherber)
Date: Tue, 03 Sep 2013 15:22:02 +0200
Subject: [R] Multiple regression (with interactions) by hand
In-Reply-To: <CANz9Z_+2ksBgEQhWxNZvuR5HPduJx3pYJS2mdumV4YQz+pqinQ@mail.gmail.com>
References: <5225B13A.7060903@agr.uni-goettingen.de>
	<CANz9Z_+2ksBgEQhWxNZvuR5HPduJx3pYJS2mdumV4YQz+pqinQ@mail.gmail.com>
Message-ID: <5225E27A.5050809@agr.uni-goettingen.de>

Dear all,

But why are there such huge differences betwen solve() and ginv()? (see code below)?

##
m1=lm(Ozone~Solar.R*Wind,airquality)

# remove NA?s:
airquality2=airquality[complete.cases(airquality$Ozone)&
complete.cases(airquality$Solar.R)&
complete.cases(airquality$Wind),]

# create the model matrix by hand:
X=cbind("(Intercept)"=1,Solar.R=airquality2$Solar.R,Wind=airquality2$Wind,"Solar.R:Wind"=airquality2$Solar.R*airquality2$Wind)
# is the same as:
model.matrix(m1)
# create the response vector by hand:
Y=airquality2$Ozone
# is the same as:
m1$model$Ozone
# Now solve for the parameter estimates:

solve(crossprod(X)) %*% crossprod(X,Y) #gives the correct answer

library(MASS)
ginv(t(X)%*%X)%*%t(X)%*%Y #gives a wrong answer





Am 03/09/2013 12:29, schrieb Joshua Wiley:
> Hi Christoph,
> 
> Use this matrix expression instead:
> 
> solve(crossprod(X)) %*% t(X) %*% Y
> 
> Note that:
> 
> all.equal(crossprod(X), t(X) %*% X)
> 
> Cheers,
> 
> Joshua
> 
> 
> 
> On Tue, Sep 3, 2013 at 2:51 AM, Christoph Scherber
> <Christoph.Scherber at agr.uni-goettingen.de> wrote:
>> Dear all,
>>
>> I?ve played around with the "airquality" dataset, trying to solve the matrix equations of a simple
>> multiple regression by hand; however, my matrix multiplications don?t lead to the estimates returned
>> by coef(). What have I done wrong here?
>>
>> ##
>> m1=lm(Ozone~Solar.R*Wind,airquality)
>>
>> # remove NA?s:
>> airquality2=airquality[complete.cases(airquality$Ozone)&
>> complete.cases(airquality$Solar.R)&
>> complete.cases(airquality$Wind),]
>>
>> # create the model matrix by hand:
>> X=cbind("(Intercept)"=1,Solar.R=airquality2$Solar.R,Wind=airquality2$Wind,"Solar.R:Wind"=airquality2$Solar.R*airquality2$Wind)
>> # is the same as:
>> model.matrix(m1)
>>
>> # create the response vector by hand:
>> Y=airquality2$Ozone
>> # is the same as:
>> m1$model$Ozone
>>
>> # Now solve for the parameter estimates:
>> library(MASS)
>> ginv(t(X)%*%X)%*%t(X)%*%Y
>>
>> # is not the same as:
>> coef(m1)
>>
>> ##
>> Now why is my result (line ginv(...)) not the same as the one returned by coef(m1)?
>>
>> Thanks very much for your help!
>>
>> Best regards,
>> Christoph
>>
>> [using R 3.0.1 on Windows 7 32-Bit]
>>
>>
>>
>>
>>
>> --
>> PD Dr Christoph Scherber
>> Georg-August University Goettingen
>> Department of Crop Science
>> Agroecology
>> Grisebachstrasse 6
>> D-37077 Goettingen
>> Germany
>> phone 0049 (0)551 39 8807
>> fax 0049 (0)551 39 8806
>> http://www.gwdg.de/~cscherb1
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 


From smartpink111 at yahoo.com  Tue Sep  3 15:42:44 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 3 Sep 2013 06:42:44 -0700 (PDT)
Subject: [R] reading files
In-Reply-To: <1378215161.18697.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <CAPPk2Aj2pgfxnO0=1O1Dv_JX-yG2DrNzGp4K4Qx0ZB8PoBZg8w@mail.gmail.com>
	<1378215161.18697.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <1378215764.91942.YahooMailNeo@web142604.mail.bf1.yahoo.com>



HI,

?list.files()
list.files()? #created 4 files in my working directory
#[1] "A_hubs.txt"??? "A_nonhubs.txt" "B_hubs.txt"??? "B_nonhubs.txt"

#If you want to do wilcox.test in a pairwise manner:


combn(list.files(),2)
#???? [,1]??????????? [,2]???????? [,3]??????????? [,4]?????????? 
#[1,] "A_hubs.txt"??? "A_hubs.txt" "A_hubs.txt"??? "A_nonhubs.txt"
#[2,] "A_nonhubs.txt" "B_hubs.txt" "B_nonhubs.txt" "B_hubs.txt"?? 
?# ?? [,5]??????????? [,6]?????????? 
#[1,] "A_nonhubs.txt" "B_hubs.txt"?? 
#[2,] "B_nonhubs.txt" "B_nonhubs.txt"


P_value<- sapply(as.data.frame(combn(list.files(),2),stringsAsFactors=FALSE),function(x){ x1<-read.table(x[1],sep="",header=TRUE); x2<- read.table(x[2],sep="",header=TRUE); wilcox.test(x1$TIS_SV,x2$TIS_SV)$p.value})

NAME<-gsub("[.txt]","",apply(as.data.frame(combn(list.files(),2),stringsAsFactors=FALSE),2, paste,collapse="_"))
res<- data.frame(NAME,P_value,stringsAsFactors=FALSE)
?row.names(res)<-1:nrow(res)
res
#???????????????? NAME?? P_value
#1??? A_hubs_A_nonhubs 0.3684845
#2?????? A_hubs_B_hubs 0.1388408
#3??? A_hubs_B_nonhubs 0.1531984
#4??? A_nonhubs_B_hubs 0.7910863
#5 A_nonhubs_B_nonhubs 0.4926012
#6??? B_hubs_B_nonhubs 0.6350055

A.K.



----- Original Message -----
From: anupam sinha <anupam.contact at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Tuesday, September 3, 2013 6:58 AM
Subject: [R] reading files

Dear all,

I need help with some coding. I have a directory with files like these:

A_hubs
A_nonhubs
B_hubs
B_nonhubs
:
:
Each of these files have the following header and content:

GENE? TIS_DEG?? TOT_SV? ? TIS_SV? ? TIS_DISO

ensg1?? 20? ? ? ? ? ? ? ?? 12? ? ? ?? 4? ? ? ? ? ? ? 40
.
.
and so on...

I want to calculate the p-value of the function
wilcox.test(A_hubs$TIS_SV,A_nonhubs$TIS_SV) and store it in a table of the
format

NAME?? p-value

A? ? ? ? ?? 0.05

Can some give me pointers in the direction? Thanks in advance


Anupam

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Tue Sep  3 16:09:52 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 3 Sep 2013 07:09:52 -0700 (PDT)
Subject: [R] Writing list into csv file
Message-ID: <1378217392.44905.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Please use dput() to show the example dataset:


Not sure this matches with your original example though..


lst1<- structure(list(Contrasts = structure(list(linear = c(-0.437, 
-0.378, -0.201, 0.271, 0.743), emax1 = c(-0.799, -0.17, 0.207, 
0.362, 0.399), emax2 = c(-0.643, -0.361, 0.061, 0.413, 0.53), 
??? linInt = c(-0.894, 0.224, 0.224, 0.224, 0.224)), .Names = c("linear", 
"emax1", "emax2", "linInt"), class = "data.frame", row.names = c("0", 
"0.05", "0.2", "0.6", "1")), `Contrast Correlation` = structure(list(
??? linear = c(1, 0.766, 0.912, 0.488), emax1 = c(0.766, 1, 0.949, 
??? 0.893), emax2 = c(0.912, 0.949, 1, 0.719), linInt = c(0.488, 
??? 0.893, 0.719, 1)), .Names = c("linear", "emax1", "emax2", 
"linInt"), class = "data.frame", row.names = c("linear", "emax1", 
"emax2", "linInt")), `Multiple Contrast Test` = structure(list(
??? t.Stat = c(3.464, 3.339, 2.972, 2.486), adj.p = structure(1:4, .Label = c("< 0.001", 
??? "0.00143", "0.00459", "0.01610"), class = "factor")), .Names = c("t.Stat", 
"adj.p"), class = "data.frame", row.names = c("emax2", "emax1", 
"linear", "linInt"))), .Names = c("Contrasts", "Contrast Correlation", 
"Multiple Contrast Test"))




You may try:
capture.output(sapply(lst1,print),file="test.csv",append=TRUE)? #not perfect as some headings might be misplaced.


A.K.




Hello Guys 
? 
Say I have ?a List MM with 

Multiple Contrast Test 

Contrasts: 
? ? ?linear ?emax1 ?emax2 linInt 
0 ? ?-0.437 -0.799 -0.643 -0.894 
0.05 -0.378 -0.170 -0.361 ?0.224 
0.2 ?-0.201 ?0.207 ?0.061 ?0.224 
0.6 ? 0.271 ?0.362 ?0.413 ?0.224 
1 ? ? 0.743 ?0.399 ?0.530 ?0.224 

Contrast Correlation: 
? ? ? ? ? ?linear emax1 emax2 linInt 
linear ?1.000 0.766 0.912 ?0.488 
emax1 0.766 1.000 0.949 ?0.893 
emax2 0.912 0.949 1.000 ?0.719 
linInt ? 0.488 0.893 0.719 ?1.000 

Multiple Contrast Test: 
? ? ? ?t-Stat ? adj-p 
emax2 ? 3.464 < 0.001 
emax1 ? 3.339 0.00143 
linear ?2.972 0.00459 
linInt ?2.486 0.01610 

each element of MM has different number elements of diffrent 
datatypes. I wanted write a single csv file containning all the 
elements. 

Is is possible to do in R. 


Krishna | Cytel


From sid.arun91 at gmail.com  Tue Sep  3 16:18:02 2013
From: sid.arun91 at gmail.com (Siddharth Arun)
Date: Tue, 3 Sep 2013 19:48:02 +0530
Subject: [R] Parts of Speach Tagging
In-Reply-To: <BLU170-W132F97D33FB7030F9EBD0EF480@phx.gbl>
References: <CADym=9WqaQRb==2BAf5sgNf5KkAQHoZ4Aas1oRU+hmJcOGZsig@mail.gmail.com>
	<BLU170-W132F97D33FB7030F9EBD0EF480@phx.gbl>
Message-ID: <CADym=9XFP540NvvHc0BjfvC=Jkjr8DtixvH3L80QUFDsnoW5+A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130903/76fe5e7f/attachment.pl>

From sid.arun91 at gmail.com  Tue Sep  3 16:18:02 2013
From: sid.arun91 at gmail.com (Siddharth Arun)
Date: Tue, 3 Sep 2013 19:48:02 +0530
Subject: [R] Parts of Speach Tagging
In-Reply-To: <BLU170-W132F97D33FB7030F9EBD0EF480@phx.gbl>
References: <CADym=9WqaQRb==2BAf5sgNf5KkAQHoZ4Aas1oRU+hmJcOGZsig@mail.gmail.com>
	<BLU170-W132F97D33FB7030F9EBD0EF480@phx.gbl>
Message-ID: <CADym=9XFP540NvvHc0BjfvC=Jkjr8DtixvH3L80QUFDsnoW5+A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130903/76fe5e7f/attachment-0001.pl>

From sid.arun91 at gmail.com  Tue Sep  3 16:18:40 2013
From: sid.arun91 at gmail.com (Siddharth Arun)
Date: Tue, 3 Sep 2013 19:48:40 +0530
Subject: [R] Error in Parts of Speach Tagging using openNLP
Message-ID: <CADym=9XmAeN1cP1H8Y5=FK2oF9RTFNo6P2MUW-FAZYH4QE4rgQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130903/281526e8/attachment.pl>

From smartpink111 at yahoo.com  Tue Sep  3 16:42:07 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 3 Sep 2013 07:42:07 -0700 (PDT)
Subject: [R] Rows with positive values
In-Reply-To: <CAFkF=gHDA7iNNDpJcaYVB3CNFeAmxg6gcqD-U=UKbBixWTOz7Q@mail.gmail.com>
References: <CAFkF=gHDA7iNNDpJcaYVB3CNFeAmxg6gcqD-U=UKbBixWTOz7Q@mail.gmail.com>
Message-ID: <1378219327.74021.YahooMailNeo@web142606.mail.bf1.yahoo.com>



Hi,
set.seed(285)
dat1<- as.data.frame(matrix(sample(c(-3:30),10*100,replace=TRUE),ncol=10))
dat2<- dat1[!rowSums(dat1<0),]
head(dat1,3)
#? V1 V2 V3 V4 V5 V6 V7 V8 V9 V10
#1 21 19 16 24 11 -1? 4 13 18? -3
#2? 3 13 13 29 16 29 16 18 12? 12
#3 13 22 14 25? 9 19 13 30? 6?? 6

head(dat2,3)
#?? V1 V2 V3 V4 V5 V6 V7 V8 V9 V10
#2?? 3 13 13 29 16 29 16 18 12? 12
#3? 13 22 14 25? 9 19 13 30? 6?? 6
#11 23 20? 5 27? 1 24 18 18 26? 14
A.K.


________________________________
From: Vivek Das <vd4mmind at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Tuesday, September 3, 2013 10:34 AM
Subject: 



Hi Arun,

I would like to know if you have any idea of any function in R by which you can only extract rows from a data frame having only positive values. Is there any way to do it?

----------------------------------------------------------

Vivek Das
PhD Student in Computational Biology
Giuseppe Testa's Lab
European School of Molecular Medicine
IFOM-IEO Campus
Via Adamello, 16
Milan, Italy

emails:?vivek.das at ieo.eu
??? ??? ??? vchris_05 at yahoo.co.in
??? ??? ??? vd4mmind at gmail.com


From kw.stat at gmail.com  Tue Sep  3 16:49:53 2013
From: kw.stat at gmail.com (Kevin Wright)
Date: Tue, 3 Sep 2013 09:49:53 -0500
Subject: [R] Should I wrap more package examples in \dontrun{} ?
Message-ID: <CAKFxdiTZOHG6oSQtTUfJ3Ys+Qnd3ahKBDU4bCGCsrOYMckbW=g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130903/6ad7d733/attachment.pl>

From soledad.esteban at transmittingscience.org  Tue Sep  3 16:54:17 2013
From: soledad.esteban at transmittingscience.org (Soledad De Esteban Trivigno)
Date: Tue, 3 Sep 2013 16:54:17 +0200 (CEST)
Subject: [R] ANN: Course Data Mining with R in Spain
Message-ID: <1997517346.123743.1378220057604.open-xchange@email.1and1.es>

Dear colleague:

Registration is open for the course CLASSIFICATION AND REGRESSION TREES AND
NEURAL NETWORKS WITH R - Second Edition.

INSTRUCTORS: Dr. Lloren? Badiella (UAB, Spain), Dr. Joan Valls? (Biomedical
Research Institute of Lleida, Spain) and Dr. Montserrat Mart?nez-Alonso
(Biomedical Research Institute of Lleida, Spain).

DATES: November 4-7, 2013; 24 teaching hours.

PLACE:? Premises of Sabadell of the Institut Catal? de Paleontologia Miquel
Crusafont,? Sabadell,? Barcelona (Spain).

Organized by: Transmitting Science and the Institut Catal? de Paleontologia
Miquel? Crusafont.

More information: http://www.transmittingscience.org/cart_with_r.htm or? writing
to courses at transmittingscience.org

The main goal of the methods such as CART (Classification and Regression Trees),
is to model and predict one response variable explained by a set of dependent
variables. This methods can be particularly effective to model interactions
between explanatory variables. On the other hand, as a statistical model, a
neural network is based on linear and non-linear combinations of explanatory
variables that interact with other combinations to predict or explain an outcome
variable. Both CART and neural networks methods can provide good results to
explain or predict an outcome variable, particularly when the number of
interactions is important. Nevertheless, these techniques also tend to over-fit
the data and a validation of the models is required. ROC methods, including a
sensitivity/specificity analyses and/or external validations can be performed to
assess the consistency of these techniques. Applications cover a wide range of
problems, including species classification in biology, prediction of the
prognosis of a patient in biomedicine, etc.

Please feel free to distribute this information between your colleagues if you?
consider it appropriate.

With best regards

Soledad De Esteban-Trivigno, PhD.
Academic Director
soledad.esteban at transmittingscience.org
Transmitting Science
www.transmittingscience.org


From murdoch.duncan at gmail.com  Tue Sep  3 17:14:13 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 03 Sep 2013 11:14:13 -0400
Subject: [R] Should I wrap more package examples in \dontrun{} ?
In-Reply-To: <CAKFxdiTZOHG6oSQtTUfJ3Ys+Qnd3ahKBDU4bCGCsrOYMckbW=g@mail.gmail.com>
References: <CAKFxdiTZOHG6oSQtTUfJ3Ys+Qnd3ahKBDU4bCGCsrOYMckbW=g@mail.gmail.com>
Message-ID: <5225FCC5.6070005@gmail.com>

On 03/09/2013 10:49 AM, Kevin Wright wrote:
> I have a package with more than 100 datasets, each of which has an
> \examples{} section.  On the plus side, these example test the "R
> ecosystem" to make sure that everything is working (both my package and
> others' packages).  On the down side, changes in this ecosystem have caused
> repeated NOTEs and WARNINGs from CRAN.
>
> As a commentary on one recent R-help discussion, none of the code breakages
> have been caused by use of ":::".  All of the problems have been caused by
> (1) Changes in "stable" packages and (2) changing CRAN requirements (3)
> changes in "beta" packages. In roughly that order.
>
> In the interest of long-term package stability I'm thinking about wrapping
> more of the examples in my package in \dontrun{}.  Especially the parts
> that depend on other packages.
>
> I'm interested to know how other package developers approach this problem.
>
As a user of your package, I would find it irritating if example(foo) 
didn't run anything.   It would be more irritating (and would indicate 
sloppiness on your part) if the examples failed when I cut and pasted 
them.  These both suggest leaving the examples running.

As the author of your package, it sounds as though you find it quite 
irritating when other authors break your code.

Isn't the right solution to this to work with the other package authors 
to come up with code that is unlikely to break?  If that's not possible, 
then maybe don't use those packages that cause you trouble.

Duncan Murdoch


From smartpink111 at yahoo.com  Tue Sep  3 17:49:23 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 3 Sep 2013 08:49:23 -0700 (PDT)
Subject: [R] remove rows with infinite/nan values from a zoo dataset
In-Reply-To: <1378190868.36659.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1378190868.36659.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1378223363.10293.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,

No problem.

In my previous post, I showed how to dput() your example dataset.? Please use dput() in the future.
vec1<- c(3.369247e-04,0.000000e+00,9.022183e-04,0.000000e+00,-1.105819e-04,-Inf,1.191271e-04,1.681718e-04,NaN,1.150126e-04,1.031037e-03,2.710993e-04)

indx<-seq(as.Date("2009-09-01"),as.Date("2009-09-17"),by=1)
indx1<-indx[-c(5:7,12:13)]
library(zoo)
z1<- zoo(vec1,order.by=indx1)
?sum(z1,na.rm=TRUE) #without removing the Inf. 
#[1] -Inf


sum(z1[is.finite(z1)],na.rm=TRUE)
#[1] 0.002833009


#or just
sum(z1[is.finite(z1)])
#[1] 0.002833009
A.K.





Thank you for your reply A.K. 

Sorry for my misleading -- the first question should be removing
 #N/A N/A values when reading a csv file. So the example provided in the
 original post was dragged from a csv spreadsheet directly. 
(which I used the code "prices=read.zoo("C:\\Users\\Desktop\\\\awc_au.csv",header=TRUE,sep=",",format="%Y-%m-%d" ") 

Then the following up question is removing from a zoo data set. 
After some calculation, the new zoo data set is as following: 
?2009-09-01 ? ? ? ? 2009-09-02 ? ? ? 2009-09-03 ? ? 2009-09-04 ? ? 2009-09-08 ? ?2009-09-09 
?3.369247e-04 ?0.000000e+00 ?9.022183e-04 ?0.000000e+00 -1.105819e-04 ? ? ? ? ?-Inf 
? ?2009-09-10 ? ? ? 2009-09-11 ? ? ?2009-09-14 ? ?2009-09-15 ? ? ?2009-09-16 ? ? 2009-09-17 
?1.191271e-04 ?1.681718e-04 ? ? ? ?NaN ? ? ? ? ? ? 1.150126e-04 ?1.031037e-03 ?2.710993e-04 

I need to sum them up so I used "sum(Z, na.rm=TRUE)" to remove the NaN values but not for the Inf/-Inf. 

Hope it is clear to you. 

Cheers, 
R.L 
----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Tuesday, September 3, 2013 2:47 AM
Subject: Re: remove rows with infinite/nan values from a zoo dataset

Hi,
Please dput() the example dataset.? When I read from the one shown below, it looks a bit altered.

library(zoo)
dat1<- read.zoo(text="2009-07-15,#N/A N/A,#N/A N/A,18.96858
2009-07-16,20.30685,20.40664,#N/A N/A
2009-07-17,20.78813,20.03991,20.40664
2009-07-20,21.41278,21.41278,20.03991
2009-07-21,22.9963,22.98397,21.41278
2009-07-22,23.06443,23.01112,22.98397
2009-07-23,23.45905,24.72232,23.01112
2009-07-24,24.89291,25.56603,24.72232
2009-07-27,25.38929,24.80535,25.56603
2009-07-28,25.26712,25.65566,24.80535
2009-07-29,25.83884,24.98163,25.65566
2009-07-30,#N/A N/A,#N/A N/A,24.98163
2009-08-03,25.25553,25.93297,#N/A N/A
2009-08-04,26.02464,25.49159,25.93297
",sep=",",header=FALSE,FUN=as.Date,format="%Y-%m-%d",fill=TRUE) 


dput(dat1)? ###
structure(c(NA, 20.30685, 20.78813, 21.41278, 22.9963, 23.06443, 
23.45905, 24.89291, 25.38929, 25.26712, 25.83884, NA, 25.25553, 
26.02464, NA, 20.40664, 20.03991, 21.41278, 22.98397, 23.01112, 
24.72232, 25.56603, 24.80535, 25.65566, 24.98163, NA, 25.93297, 
25.49159, NA, NA, 20.40664, 20.03991, 21.41278, 22.98397, 23.01112, 
24.72232, 25.56603, 24.80535, 25.65566, NA, NA, 25.93297), .Dim = c(14L, 
3L), .Dimnames = list(NULL, c("V2", "V3", "V4")), index = structure(c(14440, 
14441, 14442, 14445, 14446, 14447, 14448, 14449, 14452, 14453, 
14454, 14455, 14459, 14460), class = "Date"), class = "zoo")


dat2<- dat1[!rowSums(is.na(dat1)),]
dat2
#???????????????? V2?????? V3?????? V4
#2009-07-17 20.78813 20.03991 20.40664
#2009-07-20 21.41278 21.41278 20.03991
#2009-07-21 22.99630 22.98397 21.41278
#2009-07-22 23.06443 23.01112 22.98397
#2009-07-23 23.45905 24.72232 23.01112
#2009-07-24 24.89291 25.56603 24.72232
#2009-07-27 25.38929 24.80535 25.56603
#2009-07-28 25.26712 25.65566 24.80535
#2009-07-29 25.83884 24.98163 25.65566
#2009-08-04 26.02464 25.49159 25.93297


dat2[1,2]<- Inf
?dat2[5,3]<- -Inf


dat2[rowSums(is.finite(dat2))==ncol(dat2),]
#???????????????? V2?????? V3?????? V4
#2009-07-20 21.41278 21.41278 20.03991
#2009-07-21 22.99630 22.98397 21.41278
#2009-07-22 23.06443 23.01112 22.98397
#2009-07-24 24.89291 25.56603 24.72232
#2009-07-27 25.38929 24.80535 25.56603
#2009-07-28 25.26712 25.65566 24.80535
#2009-07-29 25.83884 24.98163 25.65566
#2009-08-04 26.02464 25.49159 25.93297


A.K.

Hi There, 

I have a dataset with many rows and few columns as following: 

2009-07-15??? #N/A N/A??? #N/A N/A??? 18.96858 
2009-07-16??? 20.30685??? 20.40664??? #N/A N/A 
2009-07-17??? 20.78813??? 20.03991??? 20.40664 
2009-07-20??? 21.41278??? 21.41278??? 20.03991 
2009-07-21??? 22.9963??? 22.98397??? 21.41278 
2009-07-22??? 23.06443??? 23.01112??? 22.98397 
2009-07-23??? 23.45905??? 24.72232??? 23.01112 
2009-07-24??? 24.89291??? 25.56603??? 24.72232 
2009-07-27??? 25.38929??? 24.80535??? 25.56603 
2009-07-28??? 25.26712??? 25.65566??? 24.80535 
2009-07-29??? 25.83884??? 24.98163??? 25.65566 
2009-07-30??? #N/A N/A??? #N/A N/A??? 24.98163 
2009-08-03??? 25.25553??? 25.93297??? #N/A N/A 
2009-08-04??? 26.02464??? 25.49159??? 25.93297 

The class of the dataset is "zoo". My question might be stupid 
but could anyone suggest a way to remove the rows with #N/A values? 
I tried "rapply" command but it didn't work due to the data class. 

btw, how about for the "Inf" values? 

Thank you in advance!


From rayd at liondatasystems.com  Tue Sep  3 18:02:42 2013
From: rayd at liondatasystems.com (Ray DiGiacomo, Jr.)
Date: Tue, 3 Sep 2013 09:02:42 -0700
Subject: [R] The new "rockchalk" R package (Free Webinar)
Message-ID: <CACT39Nb27baYxJpNPcRoPVe2H2ph=bdpB1MyojoE=oMo_eo1FA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130903/c8fe1edb/attachment.pl>

From syntereo at gmail.com  Tue Sep  3 16:19:32 2013
From: syntereo at gmail.com (Matt Strauser)
Date: Tue, 3 Sep 2013 07:19:32 -0700
Subject: [R] How to assign names to global data frames created in a function
Message-ID: <CAGA64gGwrNR2uPZ53KHn1H3Pqdtb_ah-spMK00c2UCZwZSa4cA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130903/9f4eec64/attachment.pl>

From ssubramanian at sssihl.edu.in  Tue Sep  3 17:01:23 2013
From: ssubramanian at sssihl.edu.in (S Subramanian)
Date: Tue, 3 Sep 2013 20:31:23 +0530
Subject: [R] R CMD check Note: Non-standard file found at top level
Message-ID: <CALS_8bEcLj_mFNLVxzBP1bbsCGsCb1uc6RnsvccZ1+uC=+fXDg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130903/59c9c936/attachment.pl>

From xie at yihui.name  Tue Sep  3 19:02:31 2013
From: xie at yihui.name (Yihui Xie)
Date: Tue, 3 Sep 2013 12:02:31 -0500
Subject: [R] Should I wrap more package examples in \dontrun{} ?
In-Reply-To: <5225FCC5.6070005@gmail.com>
References: <CAKFxdiTZOHG6oSQtTUfJ3Ys+Qnd3ahKBDU4bCGCsrOYMckbW=g@mail.gmail.com>
	<5225FCC5.6070005@gmail.com>
Message-ID: <CANROs4crtZyNeGaG8O43R3K4JrioQppwV0qkJRZNKdHgmR1ZFw@mail.gmail.com>

But "don't use those packages that cause you trouble" implies you will
have to reinvent and maintain all the wheels by yourself?

What I do for long/complicated/time-consuming examples is I move them
to package websites or separate repositories. For example, I started
to use Vistat to show examples of the animation package (e.g. I write
http://vis.supstat.com/2013/04/buffons-needle/ in the References in
?buffon.needle), and the knitr-examples repository
(https://github.com/yihui/knitr-examples) to serve as both a testing
repository and a learning repository. In these cases, it will reduce
the check time on CRAN, and I'll know potential problems before CRAN's
ticket comes. Of course, example(foo) won't show the long examples any
more, but I believe it is worth it, since you gain more: you can make
websites more visually pleasant than Rd (R documentation), you can
show output so users do not really have to open R and run
example(foo), and you have comments/interactivity/Google Analytics,
etc... Rd is an excellent format for documenting function arguments
and showing quick examples, though.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


On Tue, Sep 3, 2013 at 10:14 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 03/09/2013 10:49 AM, Kevin Wright wrote:
>>
>> I have a package with more than 100 datasets, each of which has an
>> \examples{} section.  On the plus side, these example test the "R
>> ecosystem" to make sure that everything is working (both my package and
>> others' packages).  On the down side, changes in this ecosystem have
>> caused
>> repeated NOTEs and WARNINGs from CRAN.
>>
>> As a commentary on one recent R-help discussion, none of the code
>> breakages
>> have been caused by use of ":::".  All of the problems have been caused by
>> (1) Changes in "stable" packages and (2) changing CRAN requirements (3)
>> changes in "beta" packages. In roughly that order.
>>
>> In the interest of long-term package stability I'm thinking about wrapping
>> more of the examples in my package in \dontrun{}.  Especially the parts
>> that depend on other packages.
>>
>> I'm interested to know how other package developers approach this problem.
>>
> As a user of your package, I would find it irritating if example(foo) didn't
> run anything.   It would be more irritating (and would indicate sloppiness
> on your part) if the examples failed when I cut and pasted them.  These both
> suggest leaving the examples running.
>
> As the author of your package, it sounds as though you find it quite
> irritating when other authors break your code.
>
> Isn't the right solution to this to work with the other package authors to
> come up with code that is unlikely to break?  If that's not possible, then
> maybe don't use those packages that cause you trouble.
>
> Duncan Murdoch


From murdoch.duncan at gmail.com  Tue Sep  3 19:11:49 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 03 Sep 2013 13:11:49 -0400
Subject: [R] Should I wrap more package examples in \dontrun{} ?
In-Reply-To: <CANROs4crtZyNeGaG8O43R3K4JrioQppwV0qkJRZNKdHgmR1ZFw@mail.gmail.com>
References: <CAKFxdiTZOHG6oSQtTUfJ3Ys+Qnd3ahKBDU4bCGCsrOYMckbW=g@mail.gmail.com>
	<5225FCC5.6070005@gmail.com>
	<CANROs4crtZyNeGaG8O43R3K4JrioQppwV0qkJRZNKdHgmR1ZFw@mail.gmail.com>
Message-ID: <52261855.2020007@gmail.com>

On 03/09/2013 1:02 PM, Yihui Xie wrote:
> But "don't use those packages that cause you trouble" implies you will
> have to reinvent and maintain all the wheels by yourself?

Isn't that a better alternative than having examples that don't work?
>
> What I do for long/complicated/time-consuming examples is I move them
> to package websites or separate repositories. For example, I started
> to use Vistat to show examples of the animation package (e.g. I write
> http://vis.supstat.com/2013/04/buffons-needle/ in the References in
> ?buffon.needle), and the knitr-examples repository
> (https://github.com/yihui/knitr-examples) to serve as both a testing
> repository and a learning repository. In these cases, it will reduce
> the check time on CRAN, and I'll know potential problems before CRAN's
> ticket comes. Of course, example(foo) won't show the long examples any
> more, but I believe it is worth it, since you gain more: you can make
> websites more visually pleasant than Rd (R documentation), you can
> show output so users do not really have to open R and run
> example(foo), and you have comments/interactivity/Google Analytics,
> etc... Rd is an excellent format for documenting function arguments
> and showing quick examples, though.

As a user, I'd rather have examples like the ones you are discussing 
above as vignettes in the package, so that I can use them while offline, 
and so that I can have some assurance that they are tested.  As a 
package author, I'm not so sure:  it is certainly more work to produce a 
vignette than to produce a web page, but the automatic testing is a good 
thing.  I don't like having my name on documents that give bad advice, 
and the CRAN checks detect some of that.

Duncan Murdoch
>
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Web: http://yihui.name
> Department of Statistics, Iowa State University
> 2215 Snedecor Hall, Ames, IA
>
>
> On Tue, Sep 3, 2013 at 10:14 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
> > On 03/09/2013 10:49 AM, Kevin Wright wrote:
> >>
> >> I have a package with more than 100 datasets, each of which has an
> >> \examples{} section.  On the plus side, these example test the "R
> >> ecosystem" to make sure that everything is working (both my package and
> >> others' packages).  On the down side, changes in this ecosystem have
> >> caused
> >> repeated NOTEs and WARNINGs from CRAN.
> >>
> >> As a commentary on one recent R-help discussion, none of the code
> >> breakages
> >> have been caused by use of ":::".  All of the problems have been caused by
> >> (1) Changes in "stable" packages and (2) changing CRAN requirements (3)
> >> changes in "beta" packages. In roughly that order.
> >>
> >> In the interest of long-term package stability I'm thinking about wrapping
> >> more of the examples in my package in \dontrun{}.  Especially the parts
> >> that depend on other packages.
> >>
> >> I'm interested to know how other package developers approach this problem.
> >>
> > As a user of your package, I would find it irritating if example(foo) didn't
> > run anything.   It would be more irritating (and would indicate sloppiness
> > on your part) if the examples failed when I cut and pasted them.  These both
> > suggest leaving the examples running.
> >
> > As the author of your package, it sounds as though you find it quite
> > irritating when other authors break your code.
> >
> > Isn't the right solution to this to work with the other package authors to
> > come up with code that is unlikely to break?  If that's not possible, then
> > maybe don't use those packages that cause you trouble.
> >
> > Duncan Murdoch


From sid.arun91 at gmail.com  Tue Sep  3 19:15:36 2013
From: sid.arun91 at gmail.com (Siddharth Arun)
Date: Tue, 3 Sep 2013 22:45:36 +0530
Subject: [R] Error in Parts of Speach Tagging using openNLP
Message-ID: <CADym=9WOU1j4byspZJoomaE79iuBb35Y-KSNVENjAQ4muPoyXg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130903/508f471a/attachment.pl>

From xie at yihui.name  Tue Sep  3 19:29:39 2013
From: xie at yihui.name (Yihui Xie)
Date: Tue, 3 Sep 2013 12:29:39 -0500
Subject: [R] Should I wrap more package examples in \dontrun{} ?
In-Reply-To: <52261855.2020007@gmail.com>
References: <CAKFxdiTZOHG6oSQtTUfJ3Ys+Qnd3ahKBDU4bCGCsrOYMckbW=g@mail.gmail.com>
	<5225FCC5.6070005@gmail.com>
	<CANROs4crtZyNeGaG8O43R3K4JrioQppwV0qkJRZNKdHgmR1ZFw@mail.gmail.com>
	<52261855.2020007@gmail.com>
Message-ID: <CANROs4emzt0+FpNCYDFUNYHiY=E41fXXPwRzB=wUgucaCkbKXw@mail.gmail.com>

Well, there is always trade-off. You can reinvent the whole universe
so that it is well under your control, or stand on other people's
shoulders and take the risk that they may fall one day. It is tricky
to decide how much one should depend on others.

I absolutely agree that automatic testing is a good thing. My point is
to let CRAN do everything, or the authors share some work and enjoy
some additional benefits. In either case, the testing is indeed done.

You also have a good point that package vignettes works offline, and
in my approach, it requires an additional step, which is `git clone`
(or whatever version control tools) and the whole website can be
rebuilt offline (normally via `make` or other simple commands).

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


On Tue, Sep 3, 2013 at 12:11 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 03/09/2013 1:02 PM, Yihui Xie wrote:
>>
>> But "don't use those packages that cause you trouble" implies you will
>> have to reinvent and maintain all the wheels by yourself?
>
>
> Isn't that a better alternative than having examples that don't work?
>
>>
>> What I do for long/complicated/time-consuming examples is I move them
>> to package websites or separate repositories. For example, I started
>> to use Vistat to show examples of the animation package (e.g. I write
>> http://vis.supstat.com/2013/04/buffons-needle/ in the References in
>> ?buffon.needle), and the knitr-examples repository
>> (https://github.com/yihui/knitr-examples) to serve as both a testing
>> repository and a learning repository. In these cases, it will reduce
>> the check time on CRAN, and I'll know potential problems before CRAN's
>> ticket comes. Of course, example(foo) won't show the long examples any
>> more, but I believe it is worth it, since you gain more: you can make
>> websites more visually pleasant than Rd (R documentation), you can
>> show output so users do not really have to open R and run
>> example(foo), and you have comments/interactivity/Google Analytics,
>> etc... Rd is an excellent format for documenting function arguments
>> and showing quick examples, though.
>
>
> As a user, I'd rather have examples like the ones you are discussing above
> as vignettes in the package, so that I can use them while offline, and so
> that I can have some assurance that they are tested.  As a package author,
> I'm not so sure:  it is certainly more work to produce a vignette than to
> produce a web page, but the automatic testing is a good thing.  I don't like
> having my name on documents that give bad advice, and the CRAN checks detect
> some of that.
>
> Duncan Murdoch


From h.wickham at gmail.com  Tue Sep  3 19:53:27 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 3 Sep 2013 12:53:27 -0500
Subject: [R] Should I wrap more package examples in \dontrun{} ?
In-Reply-To: <5225FCC5.6070005@gmail.com>
References: <CAKFxdiTZOHG6oSQtTUfJ3Ys+Qnd3ahKBDU4bCGCsrOYMckbW=g@mail.gmail.com>
	<5225FCC5.6070005@gmail.com>
Message-ID: <CABdHhvEQZAf=P9WESza6oY=G3EZQD4ZKM2YwKtFzjUAkcnSpRw@mail.gmail.com>

> As a user of your package, I would find it irritating if example(foo) didn't
> run anything.   It would be more irritating (and would indicate sloppiness
> on your part) if the examples failed when I cut and pasted them.  These both
> suggest leaving the examples running.
>
> As the author of your package, it sounds as though you find it quite
> irritating when other authors break your code.
>
> Isn't the right solution to this to work with the other package authors to
> come up with code that is unlikely to break?  If that's not possible, then
> maybe don't use those packages that cause you trouble.

It was my understanding that package authors are responsible for not
breaking other CRAN packages without warning.  For example, before I
release a new version of plyr or ggplot2, I run R CMD check on every
package that depends on my package. I then let the maintainers know if
something is broken - sometimes it's because I introduced a bug, and
other times it's because I'm enforcing a stricter check than I did
previously

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From hollymaya at gmail.com  Tue Sep  3 20:01:04 2013
From: hollymaya at gmail.com (hollymaya)
Date: Tue, 3 Sep 2013 11:01:04 -0700
Subject: [R] Permuting friendship nominations in a social network
Message-ID: <635E18A9-0895-462D-8ED6-C6FB5B82CBE3@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130903/be9dda64/attachment.pl>

From soumitrodey1 at gmail.com  Tue Sep  3 20:51:16 2013
From: soumitrodey1 at gmail.com (Soumitro Dey)
Date: Tue, 3 Sep 2013 13:51:16 -0500
Subject: [R] summary(object) not showing all values of a factor
Message-ID: <CAJ+M79=SLBbWnyHMe5MOM74zuuY-VNSTkPjAWEnB03SSB23Yfg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130903/fad2521b/attachment.pl>

From maxzakh at ucdavis.edu  Tue Sep  3 20:49:18 2013
From: maxzakh at ucdavis.edu (maxzakh)
Date: Tue, 3 Sep 2013 11:49:18 -0700 (PDT)
Subject: [R] Having problems with doing anything with my data sets
Message-ID: <1378234158130-4675292.post@n4.nabble.com>

I just installed R on my computer but I have greatly reduced functionality.
For instance, when I import a data set, I cannot do anything to it: number
summaries, any means tests, variance, etc. Literally all of the options that
should be there are not.
Can anyone help? I am so lost!



--
View this message in context: http://r.789695.n4.nabble.com/Having-problems-with-doing-anything-with-my-data-sets-tp4675292.html
Sent from the R help mailing list archive at Nabble.com.


From sarah.goslee at gmail.com  Tue Sep  3 21:02:40 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 3 Sep 2013 15:02:40 -0400
Subject: [R] Having problems with doing anything with my data sets
In-Reply-To: <1378234158130-4675292.post@n4.nabble.com>
References: <1378234158130-4675292.post@n4.nabble.com>
Message-ID: <CAM_vjumC=QOwqPz67uEodGti7n3ADo95F4Obj4djtedh=E5aow@mail.gmail.com>

Hi,

Unless you've installed some sort of add-on GUI, R is a
command-line-driven environment.

Once you've imported your dataset (with read.table most commonly, but
you don't give us enough information to know what you're doing), then
an entire universe of commands is open to you, like
summary(mydata)
colMeans(mydata)

and so on. It sounds like you need to read the intro to R that came
with your installation, put together a reproducible example, and get
back to us with a clearer description of your problem.

Sarah

On Tue, Sep 3, 2013 at 2:49 PM, maxzakh <maxzakh at ucdavis.edu> wrote:
> I just installed R on my computer but I have greatly reduced functionality.
> For instance, when I import a data set, I cannot do anything to it: number
> summaries, any means tests, variance, etc. Literally all of the options that
> should be there are not.
> Can anyone help? I am so lost!
>
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From roy.mendelssohn at noaa.gov  Tue Sep  3 21:15:09 2013
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Tue, 3 Sep 2013 12:15:09 -0700
Subject: [R] Having problems with doing anything with my data sets
In-Reply-To: <1378234158130-4675292.post@n4.nabble.com>
References: <1378234158130-4675292.post@n4.nabble.com>
Message-ID: <9F0AE0D8-419E-4A9E-B102-062ED882F117@noaa.gov>

Hi:

I know that it is frustrating when something like what you describe occurs, but realize that it  is also frustrating for anyone on the list to try and help you, because there is no information to go on.  What would help is information like:

1.  Your OS and version

2.  How you did the install.

3.  How you imported the data and how you know the data was successfully imported  (for example did you try a dataset that comes with R).

4.  The actual commands given and the error messages  

The usual "read the post guide" applies, but knowing how you did the install would likely help in this case,

-Roy M.



On Sep 3, 2013, at 11:49 AM, maxzakh <maxzakh at ucdavis.edu> wrote:

> I just installed R on my computer but I have greatly reduced functionality.
> For instance, when I import a data set, I cannot do anything to it: number
> summaries, any means tests, variance, etc. Literally all of the options that
> should be there are not.
> Can anyone help? I am so lost!
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Having-problems-with-doing-anything-with-my-data-sets-tp4675292.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
1352 Lighthouse Avenue
Pacific Grove, CA 93950-2097

e-mail: Roy.Mendelssohn at noaa.gov (Note new e-mail address)
voice: (831)-648-9029
fax: (831)-648-8440
www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From ucfagls at gmail.com  Tue Sep  3 21:16:36 2013
From: ucfagls at gmail.com (Gavin Simpson)
Date: Tue, 3 Sep 2013 13:16:36 -0600
Subject: [R] Assessing temporal correlation in GAM with irregular time
	steps
In-Reply-To: <C1A5238848713043B7C18ED38FFEF1F8122879FD@STWMB01.ad.okstate.edu>
References: <C1A5238848713043B7C18ED38FFEF1F8122879FD@STWMB01.ad.okstate.edu>
Message-ID: <CAAHES9ye8bEN4Lb68QtK_vtpwXCSWanS25AYqrMh03dbHTS72A@mail.gmail.com>

It is possible, but you can't use the discrete time or classical
stochastic trend models (or evaluate using the ACF). Also, why do you
care to do this with regard to DoY? The assumption of the model
relates to the residuals, so you should check those for residual
autocorrelation.

As you are using `mgcv::gam` you could also use `mgcv::gamm` which can
then leverage the correlation structures from the nlme package, which
has spatial correlation structures (and you can think of time as a 1-d
spatial direction). The package also has a `corCAR1()` correlation
structure which is the continuous-time analogue of the AR(1). Fitting
via `gamm()` will also allow you to use the `Variogram()` function
from the nlme package to assess the model residuals for residual
autocorrelation.

For example you could compare the two fits

m0 <- gamm(Length ~ s(DOY, by = SiteCode) + SiteCode, data = foo,
method = "REML")
m1 <- gamm(Length ~ s(DOY, by = SiteCode) + SiteCode, data = foo,
method = "REML",
                    correlation = corCAR1( ~ bar | SiteCode))

where `foo` is the object that contains the variables mentioned in the
call, and `bar` is the variable (in `foo)` that indicates the ordering
of the samples. Notice that I nest the CAR(1) within the two
respective Sites, but do note IIRC that this fits the same residual
correlation structure to both sites' residuals (i.e. there is 1 CAR(1)
process, not two separate ones).

require(nlme)
anova(m0$lme, m1$lme)

will perform a likelihood ratio test on the two models.

If you have residual autocorrelation, do note that the smooth for DoY
may be chosen to be more complex than is appropriate (it might be
fitting the autocorrleated noise), so you may want to fix the degrees
of freedom for the smoother at some a priori chosen value and use this
same value when fitting both m0 and m1, or at the very least set an
upper limit on the complexity of the DoY smooth, say via s(DoY, by =
SiteCode, k = 5).

Finally, as a length <= 0 insect makes no sense, the assumption of
Gaussian (Normal) errors may be in trouble with your data; apart from
their strictly positive nature, the mean-variance relationship of the
data may not follow that of the assumptions for the errors. You can
move to a GLM (GAM) to account for this but things get very tricky
with the correlation structures (you can use gamm() still but fitting
then goes via glmmPQL() in the MASS package a thence to lme()).

If you just want to fit a variogram to something, there are a large
number of spatial packages available for R, several of which can fit
variograms to data, though you will need to study their respective
help files for how to use them. As for the input data, often the
time/date of sampling encoded as a numeric will be sufficient input,
but you will need to check individual functions for what they require.
I would check out the Spatial Task View on CRAN.

HTH

G

On 28 August 2013 14:26, Worthington, Thomas A
<thomas.worthington at okstate.edu> wrote:
> I have constructed a GAM using the package mgcv to test whether the lengths of an emerging insect (Length) varies with day of the year (DOY) and between two sites (SiteCode). The data are collected at irregular time steps ranging from 2 days to 20 days between samples. The GAM takes the form
>
> M3 <- gam(Length ~s(DOY, by = SiteCode) + SiteCode)
>
> As the data are a time series I would like to test for temporal autocorrelation. I have read that it is not possible to use the autocorrelation function (ACF) due to the irregular spacing and that producing a variogram in relation to DOY would be an option.
>
> Is this a correct method to test for temporal autocorrelation?
>
> And could someone suggest the code to produce the variogram as I'm getting an error related to the 'distance' argument
>
> Best wishes
> Tom
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gavin Simpson, PhD


From ucfagls at gmail.com  Tue Sep  3 21:21:11 2013
From: ucfagls at gmail.com (Gavin Simpson)
Date: Tue, 3 Sep 2013 13:21:11 -0600
Subject: [R] Setting up 3D tensor product interactions in mgcv
In-Reply-To: <CAGBzUO9PKbRjnRfJjcbi4=VNqWcj2UbMSSU8FsavOoGYvep0yQ@mail.gmail.com>
References: <CAGBzUO9PKbRjnRfJjcbi4=VNqWcj2UbMSSU8FsavOoGYvep0yQ@mail.gmail.com>
Message-ID: <CAAHES9z1=VxtjG6CBt3VN5ArPgDYLEaWps=-WuHW9xENspnmTw@mail.gmail.com>

>From a reading of `?ti`

     It is sometimes useful to investigate smooth models with a
     main-effects + interactions structure, for example

                         f_1(x)  + f_2(z) + f_3(x,z)

     This functional ANOVA decomposition is supported by ?ti? terms,
     which produce tensor product interactions from which the main
     effects have been excluded, under the assumption that they will be
     included separately. For example the ?~ ti(x) + ti(z) + ti(x,z)?
     would produce the above main effects + interaction structure. This
     is much better than attempting the same thing with ?s?or ?te?
     terms representing the interactions (although mgcv does not forbid
     it).

I think the following will do what you want:

mdl <- gam(PA ~ ti(x) + ti(y) + ti(z) + ti(x,y) + ti(x,z) + ti(y,z) +
ti(x,y,z), ....)

HTH

G

On 23 August 2013 02:05, Mark Payne <markpayneatwork at gmail.com> wrote:
> Hi,
>
> I am trying to fit a smoothing model where there are three dimensions
> over which I can smooth (x,y,z). I expect interactions between some,
> or all, of these terms, and so I have set up my model as
>
> mdl <- gam(PA ~ s(x) + s(y) + s(z) + te(x,y) + te(x,z) + te(y,z) +
> te(x,y,z),...)
>
> I have recently read about the ti(), "tensor product interaction
> smoother", which takes care of these interaction terms elegantly and
> does the nesting properly. The help file says "This is much better
> than attempting the same thing with ?s?or ?te? terms representing the
> interactions (although mgcv does not forbid it)." There is a 2D
> example there also. But I don't understand how I should set this up
> for my 3D example. Do I simply replace the te's above with ti? Or is
> there more to it than that?
>
> Does anyone have experience with this, and can explain how I should do
> it properly?
>
> Mark
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gavin Simpson, PhD


From voronaam at gmail.com  Tue Sep  3 21:38:00 2013
From: voronaam at gmail.com (Aleksey Vorona)
Date: Tue, 3 Sep 2013 12:38:00 -0700
Subject: [R] Contributing to R
Message-ID: <CAL_Jc-EzqSEcUv=BvvpwNbKhC_Vk9Vv6r4q2GApxPDJUf6MJog@mail.gmail.com>

Hi all,

Could anyone describe what is the proper way to contribute to R? So
far I was going over r-bugs and trying to write patches for bugs I can
fix. My questions is should I also send an email to somebody?

It seems that for some old bugs Bugzilla does not send emails. For
example, I went over an old bug #412 and most of it is fixed. I left a
comment about its current status and Bugzilla notified me that no
email has been sent.

Also, I would really like to get a feedback on the proposed patch to
bug #15211. It would be interesting to see the patch logistic, since
the bug is in Lapack code, not in R itself.

The "developers" page is more for svn committers. And I am feeling a
bit lost here. If there are casual contributors on this list, could
you sent the best practice description, please? Better still would be
to document it somewhere.

-- Aleksey


From gunter.berton at gene.com  Tue Sep  3 21:43:46 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 3 Sep 2013 12:43:46 -0700
Subject: [R] summary(object) not showing all values of a factor
In-Reply-To: <CAJ+M79=SLBbWnyHMe5MOM74zuuY-VNSTkPjAWEnB03SSB23Yfg@mail.gmail.com>
References: <CAJ+M79=SLBbWnyHMe5MOM74zuuY-VNSTkPjAWEnB03SSB23Yfg@mail.gmail.com>
Message-ID: <CACk-te2UMnz8wy76fPK__ExfjCX7UyDP1U_8hGDnaumhqzDntg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130903/7a2c8fd3/attachment.pl>

From dwinsemius at comcast.net  Tue Sep  3 22:09:13 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 3 Sep 2013 13:09:13 -0700
Subject: [R] How to assign names to global data frames created in a
	function
In-Reply-To: <CAGA64gGwrNR2uPZ53KHn1H3Pqdtb_ah-spMK00c2UCZwZSa4cA@mail.gmail.com>
References: <CAGA64gGwrNR2uPZ53KHn1H3Pqdtb_ah-spMK00c2UCZwZSa4cA@mail.gmail.com>
Message-ID: <3D0B7B21-6941-4B2B-823A-92D394407E9F@comcast.net>


On Sep 3, 2013, at 7:19 AM, Matt Strauser wrote:

> I have several data frames containing similar data. I'd like to pass these
> data frames to a function for processing. The function would create newly
> named "global" data frames containing the processed data. I cannot figure
> out how to assign names to the data frames in Step 1 or Step 2 in the
> following example:
> 
> # sample function in pseudo code
> processdf <- function(df, prefix) {
> # df - data frame containing data for processing
> # prefix - string to become the first part of the names of the resulting
> data frames
> # Step 1 - processs df into several subsets
>  df1 <<- subset(df, df$cond1 & df$cond2 & ...)
>  df2 <<- subset(df, df$cond3 & df$cond4 & ...)
>  df3 <<- subset(df, df$cond5 & df$cond6 & ...)
> # and so on....for many more steps with resulting data frames

Generally subset does not need to have 'df$cond1' used. It uses nonstandard evaluation and will assume that unquoted tokens are column names, so this can be wrtten:

>  df1 <- subset(df, cond1 & cond2 )
>  df2 <- subset(df, cond3 & cond4)
>  df3 <- subset(df, cond5 & cond6 )

There is, however, this warning in the help file: "For programming it is better to use the standard subsetting functions like `[`, and in particular the non-standard evaluation of argument subset can have unanticipated consequences." A similar warning is seen on the help page for 'with'. So this would be advised

df1 <- df[ df[, 'cond1'] & df[,'cond2'], ]

> 
> # Step 2 - rename the resulting global data frames
>   rename "df1" to prefix + "cond1cond2"

?assign  # e.g.:
# untested in absence of reproducible example
# You should learn to use dput()

assign(paste0(prefix, "cond1", "cond2"), df1, envir=.GlobalEnv)

And please read the manual of your chosen mail-client and learn to post to Rhelp in plain text.

-- David

>   rename "df2" to prefix + "cond3cond4"
>   rename "df3" to prefix + "cond5cond6"
> # and so on for the remaining data frames
> }
> 
> Example using data frames: frame1 and frame2:
> 
> processdf(frame1, "frame1")
> # produces these data frames:
> frame1cond1cond2
> frame1cond3cond4
> frame1cond5cond6
> 
> processdf(frame2, "frame2")
> # produces these data frames:
> frame2cond1cond2
> frame2cond3cond4
> frame2cond5cond6
> 
> Thank you for your thoughts,
> Matt
> 
> 	[[alternative HTML version deleted]]

David Winsemius
Alameda, CA, USA


From murdoch.duncan at gmail.com  Tue Sep  3 22:13:06 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 03 Sep 2013 16:13:06 -0400
Subject: [R] Should I wrap more package examples in \dontrun{} ?
In-Reply-To: <CABdHhvEQZAf=P9WESza6oY=G3EZQD4ZKM2YwKtFzjUAkcnSpRw@mail.gmail.com>
References: <CAKFxdiTZOHG6oSQtTUfJ3Ys+Qnd3ahKBDU4bCGCsrOYMckbW=g@mail.gmail.com>
	<5225FCC5.6070005@gmail.com>
	<CABdHhvEQZAf=P9WESza6oY=G3EZQD4ZKM2YwKtFzjUAkcnSpRw@mail.gmail.com>
Message-ID: <522642D2.8090101@gmail.com>

On 03/09/2013 1:53 PM, Hadley Wickham wrote:
> > As a user of your package, I would find it irritating if example(foo) didn't
> > run anything.   It would be more irritating (and would indicate sloppiness
> > on your part) if the examples failed when I cut and pasted them.  These both
> > suggest leaving the examples running.
> >
> > As the author of your package, it sounds as though you find it quite
> > irritating when other authors break your code.
> >
> > Isn't the right solution to this to work with the other package authors to
> > come up with code that is unlikely to break?  If that's not possible, then
> > maybe don't use those packages that cause you trouble.
>
> It was my understanding that package authors are responsible for not
> breaking other CRAN packages without warning.  For example, before I
> release a new version of plyr or ggplot2, I run R CMD check on every
> package that depends on my package. I then let the maintainers know if
> something is broken - sometimes it's because I introduced a bug, and
> other times it's because I'm enforcing a stricter check than I did
> previously

It sounds as though you're doing the right thing.   Can you describe how 
you determine the set of packages to check, and how you do your checks?  
It would be great if we could convince everyone to follow those steps.

Duncan Murdoch


From h.wickham at gmail.com  Tue Sep  3 22:33:56 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 3 Sep 2013 15:33:56 -0500
Subject: [R] Should I wrap more package examples in \dontrun{} ?
In-Reply-To: <522642D2.8090101@gmail.com>
References: <CAKFxdiTZOHG6oSQtTUfJ3Ys+Qnd3ahKBDU4bCGCsrOYMckbW=g@mail.gmail.com>
	<5225FCC5.6070005@gmail.com>
	<CABdHhvEQZAf=P9WESza6oY=G3EZQD4ZKM2YwKtFzjUAkcnSpRw@mail.gmail.com>
	<522642D2.8090101@gmail.com>
Message-ID: <CABdHhvH37B+Zqx+SZd5D9KN-65O+=OH8Q0kYsePgf-fCF=iUeA@mail.gmail.com>

>> It was my understanding that package authors are responsible for not
>> breaking other CRAN packages without warning.  For example, before I
>> release a new version of plyr or ggplot2, I run R CMD check on every
>> package that depends on my package. I then let the maintainers know if
>> something is broken - sometimes it's because I introduced a bug, and
>> other times it's because I'm enforcing a stricter check than I did
>> previously
>
> It sounds as though you're doing the right thing.   Can you describe how you
> determine the set of packages to check, and how you do your checks?  It
> would be great if we could convince everyone to follow those steps.

I have some functions in devtools to do this:

library(ggplot2)
revdep("ggplot2")

# Takes a _long_ time
revdep_check("ggplot2")


Winston, cc'd, build some additional infrastructure on top of this, so
that tests are run in parallel on a fast EC2 instance, and checked
into a git repo (e.g. https://github.com/wch/ggplot2-checkresults).
That makes it very easy to do a diff
(https://github.com/wch/testthat-checkresults/commit/179219f2563330449ea2bf9aa44d70dbc96ea0e6),
and see what packages are failing now that didn't fail in the past.

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From h.wickham at gmail.com  Tue Sep  3 22:50:55 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 3 Sep 2013 15:50:55 -0500
Subject: [R] R CMD check Note: Non-standard file found at top level
In-Reply-To: <CALS_8bEcLj_mFNLVxzBP1bbsCGsCb1uc6RnsvccZ1+uC=+fXDg@mail.gmail.com>
References: <CALS_8bEcLj_mFNLVxzBP1bbsCGsCb1uc6RnsvccZ1+uC=+fXDg@mail.gmail.com>
Message-ID: <CABdHhvF_B8tZ7CirXWyoFQhRzx98hwcBoqYUNPP45D3O84g+zw@mail.gmail.com>

The note is telling you that you usually shouldn't have a file called
build in the top level of your package. What's in the file and why is
it there?

Hadley

On Tue, Sep 3, 2013 at 10:01 AM, S Subramanian
<ssubramanian at sssihl.edu.in> wrote:
> My R CMD check pkgname and R CMD build pkgname run without any notes or
> warnings or errors.
>
> However when i run R CMD check --as-cran-pkgname_version.tar.gz, i get the
> following note:
>
> * checking top-level files ... NOTE
> Non-standard file found at top level:
>   'build'
>
>
> Everything else is ok. What is going wrong?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Chief Scientist, RStudio
http://had.co.nz/


From szehnder at uni-bonn.de  Tue Sep  3 22:59:19 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Tue, 3 Sep 2013 22:59:19 +0200
Subject: [R] [dfoptim] 'Error in fn(ginv(par),
	...) : object 'alpha' not found'
In-Reply-To: <CAP=BVWOTjnLwBSAfa6XtN_CeT=pHymGbYeLF+qZB4v=6jZ+z1A@mail.gmail.com>
References: <CAP=BVWOTjnLwBSAfa6XtN_CeT=pHymGbYeLF+qZB4v=6jZ+z1A@mail.gmail.com>
Message-ID: <6E4A7F6A-C1E7-4582-9A42-A5A8BB8CD320@uni-bonn.de>

Hi Carlos,

your problem is a wrong definition of your Likelihood function. You call symbols in the code (alpha, beta) which have no value assigned to. When L the long calculation in the last lines is assigned to L alpha and beta do not exist. The code below corrects it. But you have a problem with a divergent integral when calling integrate. A problem you can surely fix <as you know what your function is doing.

Likelihood_cov <- function(params, x, tx, T, IS) {
 r <- params[1]
 alpha_zero <- params[2]
 s <- params[3]
 beta_zero <- params[4]
 gamma_1 <- params[5]
 gamma_2 <- params[6]
 data$alpha <- alpha_zero*exp(-gamma_1*IS)
 data$beta <- beta_zero*exp(-gamma_2*IS)
 f <- function(x, tx, T, alpha, beta)
 {
   g <- function(y)
     (y + alpha)^(-( r + x))*(y + beta)^(-(s + 1))
   integrate(g, tx, T)$value
 }
 integral <- mdply(data, f)
 L <-
exp(lgamma(r+x)-lgamma(r)+r*(log(alpha_zero)-log(alpha_zero+T))-x*log(alpha_zero+T)+s*(log(beta_zero)-log(beta_zero+T)))+exp(lgamma(r+x)-lgamma(r)+r*log(alpha_zero)+log(s)+s*log(beta_zero)+log(integral$V1))
 f <- -sum(log(L))
 return (f)
}


Best

Simon


On Sep 3, 2013, at 1:28 PM, Carlos Nasher <carlos.nasher at googlemail.com> wrote:

> Dear R helpers,
> 
> I have problems to properly define a Likelihood function. Thanks to your
> help my basic model is running quite well, but I have problems to get the
> enhanced version (now incorporating covariates) running.
> 
> Within my likelihood function I define a variable 'alpha'. When I want to
> optimize the function I get the error message:
> 
> 'Error in fn(ginv(par), ...) : object 'alpha' not found'
> 
> I think it's actually not a problem with the optimization function (nmkb),
> but with the Likelihood function itself. I do not understand why 'alpha' is
> a missing object. 'alpha' should be part of the dataframe 'data' (as 'beta'
> should be too), like 'x', 'tx', ''T. But it obviously isn't.
> 
> Here's a minimum example which reproduces my problem:
> 
> ##################################################################
> 
> library(plyr)
> library(dfoptim)
> 
> ### Sample data ###
> x <- c(3, 0, 2, 5, 1, 0, 0, 1, 0, 2)
> tx <- c(24.57, 0.00, 26.86, 34.57, 2.14, 0.00, 0.00, 8.57, 0.00, 14.29)
> T <- c(33.29, 30.71, 31.29, 34.57, 36.00, 35.43, 31.14, 33.86, 35.71, 35.86)
> IS <- c(54.97, 13.97, 122.33, 110.84, 30.72, 14.96, 30.72, 20.74, 29.16,
> 83.00)
> data <- data.frame(x=x, tx=tx, T=T)
> rm(x, tx, T)
> 
> ### Likelihood function ###
> Likelihood_cov <- function(params, x, tx, T, IS) {
>  r <- params[1]
>  alpha_zero <- params[2]
>  s <- params[3]
>  beta_zero <- params[4]
>  gamma_1 <- params[5]
>  gamma_2 <- params[6]
>  data$alpha <- alpha_zero*exp(-gamma_1*IS)
>  data$beta <- beta_zero*exp(-gamma_2*IS)
>  f <- function(x, tx, T, alpha, beta)
>  {
>    g <- function(y)
>      (y + alpha)^(-( r + x))*(y + beta)^(-(s + 1))
>    integrate(g, tx, T)$value
>  }
>  integral <- mdply(data, f)
>  L <-
> exp(lgamma(r+x)-lgamma(r)+r*(log(alpha)-log(alpha+T))-x*log(alpha+T)+s*(log(beta)-log(beta+T)))+exp(lgamma(r+x)-lgamma(r)+r*log(alpha)+log(s)+s*log(beta)+log(integral$V1))
>  f <- -sum(log(L))
>  return (f)
> }
> 
> ### ML optimization ###
> params <- c(0.2, 5, 0.2, 5, -0.02, -0.02)
> fit <- nmkb(par=params, fn=Likelihood_cov, lower=c(0.0001, 0.0001, 0.0001,
> 0.0001, -Inf, -Inf), upper=c(Inf, Inf, Inf, Inf, Inf, Inf), x=data$x,
> tx=data$tx, T=data$T, IS=IS)
> 
> ##################################################################
> 
> 
> Maybe you could give me a hint were the flaw in my code is. Many thanks in
> advance.
> Carlos
> 
> 
> -----------------------------------------------------------------
> Carlos Nasher
> Buchenstr. 12
> 22299 Hamburg
> 
> tel:            +49 (0)40 67952962
> mobil:        +49 (0)175 9386725
> mail:          carlos.nasher at gmail.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ggrothendieck at gmail.com  Tue Sep  3 22:59:34 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 3 Sep 2013 16:59:34 -0400
Subject: [R] Should I wrap more package examples in \dontrun{} ?
In-Reply-To: <CAKFxdiTZOHG6oSQtTUfJ3Ys+Qnd3ahKBDU4bCGCsrOYMckbW=g@mail.gmail.com>
References: <CAKFxdiTZOHG6oSQtTUfJ3Ys+Qnd3ahKBDU4bCGCsrOYMckbW=g@mail.gmail.com>
Message-ID: <CAP01uRnW-yh+0Nk7KKrVBFoj3yZ9dta4rh+=siQtUbz3mC3zXQ@mail.gmail.com>

On Tue, Sep 3, 2013 at 10:49 AM, Kevin Wright <kw.stat at gmail.com> wrote:
> I have a package with more than 100 datasets, each of which has an
> \examples{} section.  On the plus side, these example test the "R
> ecosystem" to make sure that everything is working (both my package and
> others' packages).  On the down side, changes in this ecosystem have caused
> repeated NOTEs and WARNINGs from CRAN.
>
> As a commentary on one recent R-help discussion, none of the code breakages
> have been caused by use of ":::".  All of the problems have been caused by
> (1) Changes in "stable" packages and (2) changing CRAN requirements (3)
> changes in "beta" packages. In roughly that order.
>
> In the interest of long-term package stability I'm thinking about wrapping
> more of the examples in my package in \dontrun{}.  Especially the parts
> that depend on other packages.
>

You can avoid checks with any of these:
1. wrap your example in:   if (interactive()) { ... }
2. turn your example into a demo
3. turn your example into a unit test using RUnit, svUnit or other
unit testing package

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From ripley at stats.ox.ac.uk  Tue Sep  3 23:17:38 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 03 Sep 2013 22:17:38 +0100
Subject: [R] R CMD check Note: Non-standard file found at top level
In-Reply-To: <CABdHhvF_B8tZ7CirXWyoFQhRzx98hwcBoqYUNPP45D3O84g+zw@mail.gmail.com>
References: <CALS_8bEcLj_mFNLVxzBP1bbsCGsCb1uc6RnsvccZ1+uC=+fXDg@mail.gmail.com>
	<CABdHhvF_B8tZ7CirXWyoFQhRzx98hwcBoqYUNPP45D3O84g+zw@mail.gmail.com>
Message-ID: <522651F2.9030807@stats.ox.ac.uk>

On 03/09/2013 21:50, Hadley Wickham wrote:
> The note is telling you that you usually shouldn't have a file called
> build in the top level of your package. What's in the file and why is
> it there?

Under some circumstances R CMD build puts files in a directory called 
'build', and in the last couple of days R-devel does so much more often. 
  But that NOTE is presumably from a not-current unreleased version of R 
(we were not told, and they should be discussed on the R-devel list).

If you use R-devel, remember it is 'Under development' and new features 
may be experimental, unfinished (including not-yet-documented).
>
> Hadley
>
> On Tue, Sep 3, 2013 at 10:01 AM, S Subramanian
> <ssubramanian at sssihl.edu.in> wrote:
>> My R CMD check pkgname and R CMD build pkgname run without any notes or
>> warnings or errors.
>>
>> However when i run R CMD check --as-cran-pkgname_version.tar.gz, i get the
>> following note:
>>
>> * checking top-level files ... NOTE
>> Non-standard file found at top level:
>>    'build'
>>
>>
>> Everything else is ok. What is going wrong?
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From 538280 at gmail.com  Tue Sep  3 23:57:20 2013
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 3 Sep 2013 15:57:20 -0600
Subject: [R] How to assign names to global data frames created in a
	function
In-Reply-To: <CAGA64gGwrNR2uPZ53KHn1H3Pqdtb_ah-spMK00c2UCZwZSa4cA@mail.gmail.com>
References: <CAGA64gGwrNR2uPZ53KHn1H3Pqdtb_ah-spMK00c2UCZwZSa4cA@mail.gmail.com>
Message-ID: <CAFEqCdycDaaN479BnE47g=ztOgM0h6FE0aV2C_WxB4RqgyVG2A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130903/d3f8ecce/attachment.pl>

From rolf.turner at xtra.co.nz  Wed Sep  4 00:03:08 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Wed, 04 Sep 2013 10:03:08 +1200
Subject: [R] optim evils
In-Reply-To: <1378213710.11750.YahooMailNeo@web193404.mail.sg3.yahoo.com>
References: <1378213710.11750.YahooMailNeo@web193404.mail.sg3.yahoo.com>
Message-ID: <52265C9C.6010908@xtra.co.nz>


I don't think anyone can do much to help you unless you show us (a) your
objective function "OF" and your starting value for "pars" --- which I 
do not
see in your posting.  Examples should be ***reproducible***!!!

My personal experience with optim() has always been very good.

     cheers,

     Rolf Turner

On 09/04/13 01:08, Michael Meyer wrote:
> Greetings,
>
> I am in great anguish as the routine stats::optim shows unexplicable behaviour
> of various sorts.
> For one it is immune to the choice of optimization method and seems to always do the same.
> The following trace log
>
>
> N = 21, M = 5 machine precision = 2.22045e-16
> At X0, 0 variables are exactly at the bounds
> At iterate     0  f=       1756.8  |proj g|=      0.73581
> At iterate     1  f =       911.52  |proj g|=       0.70136
> At iterate     2  f =       791.62  |proj g|=       0.68563
> At iterate     3  f =       749.81  |proj g|=             1
>      .....
>      .....
> At iterate    87  f =       666.91  |proj g|=       0.98217
> At iterate    88  f =        666.9  |proj g|=       0.96966
>
> Bad direction in the line search;
>     refresh the lbfgs memory and restart the iteration.
> At iterate    89  f =       9022.8  |proj g|=        1.0426
> iterations 89
> function evaluations 132
> segments explored during Cauchy searches 128
> BFGS updates skipped 0
> active bounds at final generalized Cauchy point 18
> norm of the final projected gradient 1.04257
> final function value 9022.84
> F = 9022.84
> final  value 9022.836050
> converged
>
>
> by each of the following calls to optim:
>
> optPars <- optim(   pars,OF,#gradientOF,
>                                  method  = "CG",
>                                  lower   = pars_lb,upper=pars_ub,
>                                  control = list(fnscale=1,trace=3,REPORT=1)
> )
> optPars <- optim(   pars,OF,#gradientOF,
>                                  method  = "Nelder-Mead",
>                                  lower   = pars_lb,upper=pars_ub,
>                                  control = list(fnscale=1,trace=3,REPORT=1)
> )
> optPars <- optim(   pars,OF,#gradientOF,
>                                  method  = "L-BFGS-B",
>                                  lower   = pars_lb,upper=pars_ub,
>                                  control = list(fnscale=1,trace=3,REPORT=1)
> )
>
> If method != "L-BFGS-B", then the routine complains about the uses of bounds for
> the parameters as expected, however the trace log above reminas the same.
>
> Note also that the routine makes fine progress toward a minimum (as desired)
> but in the last iteration reverses course and returns a function value much larger than the starting value.
>
> What is going on here?
> All help is much appreciated.


From thomas.worthington at okstate.edu  Wed Sep  4 00:10:05 2013
From: thomas.worthington at okstate.edu (Worthington, Thomas A)
Date: Tue, 3 Sep 2013 22:10:05 +0000
Subject: [R] Assessing temporal correlation in GAM with irregular time
 steps
In-Reply-To: <CAAHES9ye8bEN4Lb68QtK_vtpwXCSWanS25AYqrMh03dbHTS72A@mail.gmail.com>
References: <C1A5238848713043B7C18ED38FFEF1F8122879FD@STWMB01.ad.okstate.edu>
	<CAAHES9ye8bEN4Lb68QtK_vtpwXCSWanS25AYqrMh03dbHTS72A@mail.gmail.com>
Message-ID: <C1A5238848713043B7C18ED38FFEF1F81228A27D@STWMB01.ad.okstate.edu>

Dear Gavin 

Thank you for the very detailed response. I had started to go down the route of fitting a correlation structure via gamm. 

I tried applying your code to my data but returned the error 
"Error in corCAR1(~ID | SiteCode1971) : parameter in CAR(1) structure must be between 0 and 1" 

I set the 'bar' in your code to the sample ID (basically a number between 1 and 192) but I wasn't sure if this was what you meant in relation to 'ordering of the samples'

Best wishes
Tom   

-----Original Message-----
From: Gavin Simpson [mailto:ucfagls at gmail.com] 
Sent: Tuesday, September 03, 2013 3:17 PM
To: Worthington, Thomas A
Cc: r-help at r-project.org
Subject: Re: [R] Assessing temporal correlation in GAM with irregular time steps

It is possible, but you can't use the discrete time or classical stochastic trend models (or evaluate using the ACF). Also, why do you care to do this with regard to DoY? The assumption of the model relates to the residuals, so you should check those for residual autocorrelation.

As you are using `mgcv::gam` you could also use `mgcv::gamm` which can then leverage the correlation structures from the nlme package, which has spatial correlation structures (and you can think of time as a 1-d spatial direction). The package also has a `corCAR1()` correlation structure which is the continuous-time analogue of the AR(1). Fitting via `gamm()` will also allow you to use the `Variogram()` function from the nlme package to assess the model residuals for residual autocorrelation.

For example you could compare the two fits

m0 <- gamm(Length ~ s(DOY, by = SiteCode) + SiteCode, data = foo, method = "REML")
m1 <- gamm(Length ~ s(DOY, by = SiteCode) + SiteCode, data = foo, method = "REML",
                    correlation = corCAR1( ~ bar | SiteCode))

where `foo` is the object that contains the variables mentioned in the call, and `bar` is the variable (in `foo)` that indicates the ordering of the samples. Notice that I nest the CAR(1) within the two respective Sites, but do note IIRC that this fits the same residual correlation structure to both sites' residuals (i.e. there is 1 CAR(1) process, not two separate ones).

require(nlme)
anova(m0$lme, m1$lme)

will perform a likelihood ratio test on the two models.

If you have residual autocorrelation, do note that the smooth for DoY may be chosen to be more complex than is appropriate (it might be fitting the autocorrleated noise), so you may want to fix the degrees of freedom for the smoother at some a priori chosen value and use this same value when fitting both m0 and m1, or at the very least set an upper limit on the complexity of the DoY smooth, say via s(DoY, by = SiteCode, k = 5).

Finally, as a length <= 0 insect makes no sense, the assumption of Gaussian (Normal) errors may be in trouble with your data; apart from their strictly positive nature, the mean-variance relationship of the data may not follow that of the assumptions for the errors. You can move to a GLM (GAM) to account for this but things get very tricky with the correlation structures (you can use gamm() still but fitting then goes via glmmPQL() in the MASS package a thence to lme()).

If you just want to fit a variogram to something, there are a large number of spatial packages available for R, several of which can fit variograms to data, though you will need to study their respective help files for how to use them. As for the input data, often the time/date of sampling encoded as a numeric will be sufficient input, but you will need to check individual functions for what they require.
I would check out the Spatial Task View on CRAN.

HTH

G

On 28 August 2013 14:26, Worthington, Thomas A <thomas.worthington at okstate.edu> wrote:
> I have constructed a GAM using the package mgcv to test whether the 
> lengths of an emerging insect (Length) varies with day of the year 
> (DOY) and between two sites (SiteCode). The data are collected at 
> irregular time steps ranging from 2 days to 20 days between samples. 
> The GAM takes the form
>
> M3 <- gam(Length ~s(DOY, by = SiteCode) + SiteCode)
>
> As the data are a time series I would like to test for temporal autocorrelation. I have read that it is not possible to use the autocorrelation function (ACF) due to the irregular spacing and that producing a variogram in relation to DOY would be an option.
>
> Is this a correct method to test for temporal autocorrelation?
>
> And could someone suggest the code to produce the variogram as I'm 
> getting an error related to the 'distance' argument
>
> Best wishes
> Tom
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



--
Gavin Simpson, PhD

From smartpink111 at yahoo.com  Wed Sep  4 00:12:36 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 3 Sep 2013 15:12:36 -0700 (PDT)
Subject: [R] How to assign names to global data frames created in a
	function
In-Reply-To: <CAGA64gGwrNR2uPZ53KHn1H3Pqdtb_ah-spMK00c2UCZwZSa4cA@mail.gmail.com>
References: <CAGA64gGwrNR2uPZ53KHn1H3Pqdtb_ah-spMK00c2UCZwZSa4cA@mail.gmail.com>
Message-ID: <1378246356.96349.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
May be this helps you in getting started.


set.seed(29)
?df1<- as.data.frame(matrix(sample(1:20,5*10,replace=TRUE),5,10))
?cond<- c("V1eq2","V8eq2","V6eq4orV8eq7")


fun1<- function(df,prefix,cond){
lst1<- list(df[df$V1==2,],df[df$V8==2,],df[df$V6==4|df$V8==7,]) 
for(i in seq_along(cond)){
?assign(paste(prefix,cond[i],sep="_"),lst1[[i]],envir=.GlobalEnv)
?print(paste(prefix,cond[i],sep="_"))}
?}

fun1(df1,"frame1",cond)
#[1] "frame1_V1eq2"
#[1] "frame1_V8eq2"
#[1] "frame1_V6eq4orV8eq7"
?frame1_V1eq2
#? V1 V2 V3 V4 V5 V6 V7 V8 V9 V10
#1? 2? 2 20 17 14? 8? 8? 2 13? 18
?frame1_V8eq2
#? V1 V2 V3 V4 V5 V6 V7 V8 V9 V10
#1? 2? 2 20 17 14? 8? 8? 2 13? 18
#5 12? 5? 4? 8 13? 4 10? 2? 2? 13
?frame1_V6eq4orV8eq7
#? V1 V2 V3 V4 V5 V6 V7 V8 V9 V10
#3? 3 18? 7? 8 20 18? 2? 7 20? 15
#4? 7? 3 13 18 20 14 15? 7 14? 12
#5 12? 5? 4? 8 13? 4 10? 2? 2? 13

A.K.



----- Original Message -----
From: Matt Strauser <syntereo at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Tuesday, September 3, 2013 10:19 AM
Subject: [R] How to assign names to global data frames created in a function

I have several data frames containing similar data. I'd like to pass these
data frames to a function for processing. The function would create newly
named "global" data frames containing the processed data. I cannot figure
out how to assign names to the data frames in Step 1 or Step 2 in the
following example:

# sample function in pseudo code
processdf <- function(df, prefix) {
# df - data frame containing data for processing
# prefix - string to become the first part of the names of the resulting
data frames
# Step 1 - processs df into several subsets
? df1 <<- subset(df, df$cond1 & df$cond2 & ...)
? df2 <<- subset(df, df$cond3 & df$cond4 & ...)
? df3 <<- subset(df, df$cond5 & df$cond6 & ...)
# and so on....for many more steps with resulting data frames

# Step 2 - rename the resulting global data frames
?  rename "df1" to prefix + "cond1cond2"
?  rename "df2" to prefix + "cond3cond4"
?  rename "df3" to prefix + "cond5cond6"
# and so on for the remaining data frames
}

Example using data frames: frame1 and frame2:

processdf(frame1, "frame1")
# produces these data frames:
frame1cond1cond2
frame1cond3cond4
frame1cond5cond6

processdf(frame2, "frame2")
# produces these data frames:
frame2cond1cond2
frame2cond3cond4
frame2cond5cond6

Thank you for your thoughts,
Matt

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From rolf.turner at xtra.co.nz  Wed Sep  4 00:15:14 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Wed, 04 Sep 2013 10:15:14 +1200
Subject: [R] Multivariate discrete HMMs
In-Reply-To: <CAAsww2hU5RQaDcBZ1_CB1G8vjR1GmL9vzNxtBoGHdmC9kowopw@mail.gmail.com>
References: <CAAsww2hU5RQaDcBZ1_CB1G8vjR1GmL9vzNxtBoGHdmC9kowopw@mail.gmail.com>
Message-ID: <52265F72.30400@xtra.co.nz>


I am not familiar with the RHmm package, but in theory there should be
no problem with discrete multivariate observations.  However, in general
in order to fit an HMM you need to specify a family of ***distributions***
for your observations (one distribution for each of the hidden states).
Usually the family is of parametric form with the values of the parameters
depending on the states.

This could be tricky, depending on the nature of your data. Without more
information it is impossible to say.

If the number of possible values of observations is reasonably small
relative to the total number of observations --- which seems to me to be
unlikely --- then you could fit a discrete non-parametric family. (You could
try using the package hmm.discnp.)

     cheers,

     Rolf Turner

On 09/03/13 02:47, Claus O'Rourke wrote:
> Hi r-help,
>
> I have been using your RHmm package for some time and have recently
> had to try using the package for a new dataset.
>
> Basically I have a dataset with a number of discrete observation
> variables that change over time, and I would love to try modeling them
> using a HMM.
>
> Basically I was wondering if RHmm can be used to model a multivariate
> discrete HMM, i.e., the observations are a vector of discrete
> measurements? From what I see in the documentation and from playing
> around with examples, it seems like this may not be possible. My
> understand of the mathematics behind multivariate HMMs is limited, so
> I would appreciate any advance you might be able to give.
>
> Thanks for any help anyone can give.


From bbolker at gmail.com  Wed Sep  4 00:27:31 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 3 Sep 2013 22:27:31 +0000
Subject: [R] Contributing to R
References: <CAL_Jc-EzqSEcUv=BvvpwNbKhC_Vk9Vv6r4q2GApxPDJUf6MJog@mail.gmail.com>
Message-ID: <loom.20130904T002329-758@post.gmane.org>

Aleksey Vorona <voronaam <at> gmail.com> writes:

> 
> Hi all,
> 
> Could anyone describe what is the proper way to contribute to R? So
> far I was going over r-bugs and trying to write patches for bugs I can
> fix. My questions is should I also send an email to somebody?
> 
> It seems that for some old bugs Bugzilla does not send emails. For
> example, I went over an old bug #412 and most of it is fixed. I left a
> comment about its current status and Bugzilla notified me that no
> email has been sent.
> 
> Also, I would really like to get a feedback on the proposed patch to
> bug #15211. It would be interesting to see the patch logistic, since
> the bug is in Lapack code, not in R itself.
> 
> The "developers" page is more for svn committers. And I am feeling a
> bit lost here. If there are casual contributors on this list, could
> you sent the best practice description, please? Better still would be
> to document it somewhere.
> 

  (1) This might be a better question for the r-devel at -project.org
list ...
  (2) Some (slightly related) discussion on StackOverflow:

stackoverflow.com/questions/8065835/
  proposing-feature-requests-to-the-r-core-team



[url broken to respect gmane's line length limit]


From bbolker at gmail.com  Wed Sep  4 00:33:12 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 3 Sep 2013 22:33:12 +0000
Subject: [R]
	=?utf-8?q?Should_I_wrap_more_package_examples_in_=5Cdontrun?=
	=?utf-8?b?e30gPw==?=
References: <CAKFxdiTZOHG6oSQtTUfJ3Ys+Qnd3ahKBDU4bCGCsrOYMckbW=g@mail.gmail.com>
	<5225FCC5.6070005@gmail.com>
	<CABdHhvEQZAf=P9WESza6oY=G3EZQD4ZKM2YwKtFzjUAkcnSpRw@mail.gmail.com>
	<522642D2.8090101@gmail.com>
	<CABdHhvH37B+Zqx+SZd5D9KN-65O+=OH8Q0kYsePgf-fCF=iUeA@mail.gmail.com>
Message-ID: <loom.20130904T002936-976@post.gmane.org>

Hadley Wickham <h.wickham <at> gmail.com> writes:

> 
> >> It was my understanding that package authors are responsible for not
> >> breaking other CRAN packages without warning.  For example, before I
> >> release a new version of plyr or ggplot2, I run R CMD check on every
> >> package that depends on my package. I then let the maintainers know if
> >> something is broken - sometimes it's because I introduced a bug, and
> >> other times it's because I'm enforcing a stricter check than I did
> >> previously
> >
> > It sounds as though you're doing the right thing.  
> > Can you describe how you
> > determine the set of packages to check, and how you do your checks?  It
> > would be great if we could convince everyone to follow those steps.
> 
> I have some functions in devtools to do this:
> 
> library(ggplot2)
> revdep("ggplot2")
> 
> # Takes a _long_ time
> revdep_check("ggplot2")
> 


  There is also some infrastructure in the tools package for doing 
this task, especially tools::check_packages_in_dir .  I also reinvented
some of these wheels: see
https://github.com/lme4/lme4/tree/master/misc/pkgtests ... the main
differences between my home-grown version and the 'tools' version
is that I have some crude logic that only re-checks packages that
are more recent than the last test (re-testing from a clean
set-up is better, but as Hadley notes it's very time-consuming).

  My output looks like this:

http://htmlpreview.github.io/?https://github.com/lme4/lme4/blob
  /master/misc/pkgtests/lme4_compat_report.html

 [broken URL]


> Winston, cc'd, build some additional infrastructure on top of this, so
> that tests are run in parallel on a fast EC2 instance, and checked
> into a git repo (e.g. https://github.com/wch/ggplot2-checkresults).
> That makes it very easy to do a diff
> (https://github.com/wch/testthat-checkresults
> /commit/179219f2563330449ea2bf9aa44d70dbc96ea0e6),
> and see what packages are failing now that didn't fail in the past.
> 
> Hadley
>


From dwinsemius at comcast.net  Wed Sep  4 02:38:59 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 3 Sep 2013 17:38:59 -0700
Subject: [R] Error in Parts of Speach Tagging using openNLP
In-Reply-To: <CADym=9WOU1j4byspZJoomaE79iuBb35Y-KSNVENjAQ4muPoyXg@mail.gmail.com>
References: <CADym=9WOU1j4byspZJoomaE79iuBb35Y-KSNVENjAQ4muPoyXg@mail.gmail.com>
Message-ID: <3223147E-C3F0-4016-8AA0-3902E51CC78B@comcast.net>

This was also posted on StackOverflow. Crossposting to R-help is discouraged. You are encouraged to read the Posting Guide and to learn how to post from gmail using plain text.

-- 
David.


On Sep 3, 2013, at 10:15 AM, Siddharth Arun wrote:

> I have an Ubuntu Quantal 12.10 Server 64-bit instance. I am using openNLP
> for POS Tagging of sentences.
> 
> I am using POS tagging using openNLP with ?Parallel Lapply setup?. It is
> running fine in RStudio environment. But in Ubuntu environment it is
> showing the following error.
> 
> 
> 
> *Error in do.call(c, clusterApply(cl, x = splitList(X, length(cl)), fun =
> lapply,  :*
> 
> *  second argument must be a list*
> 
> 
> Any suggestion for the problem I?m facing?
> 
> 
> 
> This is the code that I am using:
> 
> 
> 
> tagPOS <-  function(x, ...) {
> 
>    s <- as.String(x)
> 
>    word_token_annotator <- Maxent_Word_Token_Annotator()
> 
>    a2 <- Annotation(1L, "sentence", 1L, nchar(s))
> 
>    a2 <- annotate(s, word_token_annotator, a2)
> 
>    a3 <- annotate(s, PTA, a2)
> 
>    a3w <- a3[a3$type == "word"]
> 
>    POStags <- unlist(lapply(a3w$features, `[[`, "POS"))
> 
>    POStagged <- paste(sprintf("%s/%s", s[a3w], POStags), collapse = " ")
> 
>    list(POStagged = POStagged, POStags = POStags)
> 
>  }
> 
> 
> 
>  cl <- makeCluster(mc <- getOption("cl.cores", detectCores()/2))
> 
>  clusterEvalQ(cl, {
> 
>    library(openNLP)
> 
>    library(NLP)
> 
>    PTA <- Maxent_POS_Tag_Annotator()
> 
>  })
> 
> 
> 
> This is the setup I am using:
> 
> ? Created an cloud instance with "Ubuntu Quantal 12.10 Server 64-bit
> instance"
> 
> 
> 
> ? Installed LAMP server in the instance
> 
> 
> 
> ? After which I installed R. By default R version was 2.15.0
> 
> 
> 
> ? Upgraded the R version to R 3.0.1
> 
> -- 
> Regards,
> 
> Siddharth Arun,
> Contact No. - +91 8880065278
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From maxzakh at ucdavis.edu  Tue Sep  3 23:55:12 2013
From: maxzakh at ucdavis.edu (maxzakh)
Date: Tue, 3 Sep 2013 14:55:12 -0700 (PDT)
Subject: [R] Having problems with doing anything with my data sets
In-Reply-To: <9F0AE0D8-419E-4A9E-B102-062ED882F117@noaa.gov>
References: <1378234158130-4675292.post@n4.nabble.com>
	<9F0AE0D8-419E-4A9E-B102-062ED882F117@noaa.gov>
Message-ID: <1378245312460-4675314.post@n4.nabble.com>

I really appreciate all the help and I am sorry that I did not post enough
clarifying details. Turns out all that was wrong was the type of separator,
I needed to use commas instead of white space haha.



--
View this message in context: http://r.789695.n4.nabble.com/Having-problems-with-doing-anything-with-my-data-sets-tp4675292p4675314.html
Sent from the R help mailing list archive at Nabble.com.


From pietr007 at gmail.com  Wed Sep  4 01:38:15 2013
From: pietr007 at gmail.com (Ricardo Pietrobon)
Date: Tue, 3 Sep 2013 19:38:15 -0400
Subject: [R] tm::stemDocument function not work
Message-ID: <CAF4X4oPkb5NTkCgZmir_gFf3OYjnDpfYm-EeyfT9ZXRH85ZimQ@mail.gmail.com>

https://gist.github.com/rpietro/6430771

stemDocument function doesn't seem to be working. Tried to look up and
a few people have reported the problem, but no solution that I could
find.

would appreciate any help


From ssubramanian at sssihl.edu.in  Wed Sep  4 03:14:59 2013
From: ssubramanian at sssihl.edu.in (S Subramanian)
Date: Wed, 4 Sep 2013 06:44:59 +0530
Subject: [R] R CMD check Note: Non-standard file found at top level
In-Reply-To: <CALS_8bEcLj_mFNLVxzBP1bbsCGsCb1uc6RnsvccZ1+uC=+fXDg@mail.gmail.com>
References: <CALS_8bEcLj_mFNLVxzBP1bbsCGsCb1uc6RnsvccZ1+uC=+fXDg@mail.gmail.com>
Message-ID: <CALS_8bEtjuHVvM8h=zhUQbnHV9Fz8p-+1TaC=MzZ1WWpkjw4rg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130904/fb417435/attachment.pl>

From kridox at ymail.com  Wed Sep  4 06:54:32 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Wed, 4 Sep 2013 13:54:32 +0900
Subject: [R] tm::stemDocument function not work
In-Reply-To: <CAF4X4oPkb5NTkCgZmir_gFf3OYjnDpfYm-EeyfT9ZXRH85ZimQ@mail.gmail.com>
References: <CAF4X4oPkb5NTkCgZmir_gFf3OYjnDpfYm-EeyfT9ZXRH85ZimQ@mail.gmail.com>
Message-ID: <CAAcyNCwMFORe1PYMzO2Ob6M6n5R9E6+pvK=T7e7T_W8XrTwXHQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130904/54621bc3/attachment.pl>

From irasharenow100 at yahoo.com  Wed Sep  4 07:16:15 2013
From: irasharenow100 at yahoo.com (Ira Sharenow)
Date: Tue, 03 Sep 2013 22:16:15 -0700
Subject: [R] Manipulate stock market data in R
Message-ID: <5226C21F.7010206@yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130903/8a4b7291/attachment.pl>

From anupam.contact at gmail.com  Wed Sep  4 08:57:04 2013
From: anupam.contact at gmail.com (anupam sinha)
Date: Wed, 4 Sep 2013 12:27:04 +0530
Subject: [R] reading files
In-Reply-To: <1378215764.91942.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <CAPPk2Aj2pgfxnO0=1O1Dv_JX-yG2DrNzGp4K4Qx0ZB8PoBZg8w@mail.gmail.com>
	<1378215161.18697.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1378215764.91942.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <CAPPk2Aj8nEAtDKv=h1LJneYX=gQOyXM=ckGB-njeRDmm7V7GMw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130904/c9a8967d/attachment.pl>

From sid.arun91 at gmail.com  Wed Sep  4 09:47:48 2013
From: sid.arun91 at gmail.com (Siddharth Arun)
Date: Wed, 4 Sep 2013 13:17:48 +0530
Subject: [R] Error in Parts of Speach Tagging using openNLP
In-Reply-To: <3223147E-C3F0-4016-8AA0-3902E51CC78B@comcast.net>
References: <CADym=9WOU1j4byspZJoomaE79iuBb35Y-KSNVENjAQ4muPoyXg@mail.gmail.com>
	<3223147E-C3F0-4016-8AA0-3902E51CC78B@comcast.net>
Message-ID: <CADym=9WCJbo-R7JaP+HK0UuEQZ0L3gSEK1fKwWXZR8TO8eCCbQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130904/a3d8a605/attachment.pl>

From petr.pikal at precheza.cz  Wed Sep  4 10:07:08 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 4 Sep 2013 08:07:08 +0000
Subject: [R] summary(object) not showing all values of a factor
In-Reply-To: <CAJ+M79=SLBbWnyHMe5MOM74zuuY-VNSTkPjAWEnB03SSB23Yfg@mail.gmail.com>
References: <CAJ+M79=SLBbWnyHMe5MOM74zuuY-VNSTkPjAWEnB03SSB23Yfg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B904A2@SRVEXCHMBX.precheza.cz>

Hi

see

?contrasts
?model.matrix

go through archives

and through chapter

11.1.1 Contrasts

from R-Intro document.

Anyway, when you go through this chapter you will probably benefit from reading previous chapters too.

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Soumitro Dey
> Sent: Tuesday, September 03, 2013 8:51 PM
> To: r-help at r-project.org
> Subject: [R] summary(object) not showing all values of a factor
> 
> Dear all,
> 
> I am encountering some odd results from the summary(object) command for
> coxph and hurdle models. In both cases the result of summary(object)
> function leaves out one of the categories of a categorical variable
> used in the model. It is typically the first category if sorted
> alphabetically. Is there any way around this problem?
> 
> For example, if I have categorical variable "type" with values
> {A,B,C,D,E}, it typically leaves out A in the result of the summary.
> 
> Thanks!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Wed Sep  4 10:14:30 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 4 Sep 2013 01:14:30 -0700
Subject: [R] Error in Parts of Speach Tagging using openNLP
In-Reply-To: <CADym=9WCJbo-R7JaP+HK0UuEQZ0L3gSEK1fKwWXZR8TO8eCCbQ@mail.gmail.com>
References: <CADym=9WOU1j4byspZJoomaE79iuBb35Y-KSNVENjAQ4muPoyXg@mail.gmail.com>
	<3223147E-C3F0-4016-8AA0-3902E51CC78B@comcast.net>
	<CADym=9WCJbo-R7JaP+HK0UuEQZ0L3gSEK1fKwWXZR8TO8eCCbQ@mail.gmail.com>
Message-ID: <a739a31a-2910-4f5d-9a08-ecb00a1ab6f1@email.android.com>

Well, abusing the system does not appear to be working, does it? The correct approach is to be more targeted in your audience. Is your problem with Ubuntu? Perhaps you need to post in the r-sig-debian mailing list. Is your issue specifically with the openNLS package? Try a simplified parallel processing example to see if that works (the error indicates some problem with the clusterApply function). If the package is the issue, contact the package maintainer. If the parallel processing example does not work, you will have narrowed the scope of concern considerably for discussion here. However, with RStudio and unfamiliar (to me) packages in the mix, and cross-posting that I interpret to mean some other conversation may answer it anyway, it is way easier to ignore your plea than to try to help you figure it out.

And you still have not followed the Posting Guide recommendation to post using plain text format, so your example code is messed up.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Siddharth Arun <sid.arun91 at gmail.com> wrote:
>I posted on both the forums because i needed urgent help on the issue.
>And
>I am still waiting for a relevant reply on how to solve the issue. If
>you
>have any suggestions please do share.
>
>
>On Wed, Sep 4, 2013 at 6:08 AM, David Winsemius
><dwinsemius at comcast.net>wrote:
>
>> This was also posted on StackOverflow. Crossposting to R-help is
>> discouraged. You are encouraged to read the Posting Guide and to
>learn how
>> to post from gmail using plain text.
>>
>> --
>> David.
>>
>>
>> On Sep 3, 2013, at 10:15 AM, Siddharth Arun wrote:
>>
>> > I have an Ubuntu Quantal 12.10 Server 64-bit instance. I am using
>openNLP
>> > for POS Tagging of sentences.
>> >
>> > I am using POS tagging using openNLP with ???Parallel Lapply
>setup???. It is
>> > running fine in RStudio environment. But in Ubuntu environment it
>is
>> > showing the following error.
>> >
>> >
>> >
>> > *Error in do.call(c, clusterApply(cl, x = splitList(X, length(cl)),
>fun =
>> > lapply,  :*
>> >
>> > *  second argument must be a list*
>> >
>> >
>> > Any suggestion for the problem I???m facing?
>> >
>> >
>> >
>> > This is the code that I am using:
>> >
>> >
>> >
>> > tagPOS <-  function(x, ...) {
>> >
>> >    s <- as.String(x)
>> >
>> >    word_token_annotator <- Maxent_Word_Token_Annotator()
>> >
>> >    a2 <- Annotation(1L, "sentence", 1L, nchar(s))
>> >
>> >    a2 <- annotate(s, word_token_annotator, a2)
>> >
>> >    a3 <- annotate(s, PTA, a2)
>> >
>> >    a3w <- a3[a3$type == "word"]
>> >
>> >    POStags <- unlist(lapply(a3w$features, `[[`, "POS"))
>> >
>> >    POStagged <- paste(sprintf("%s/%s", s[a3w], POStags), collapse =
>" ")
>> >
>> >    list(POStagged = POStagged, POStags = POStags)
>> >
>> >  }
>> >
>> >
>> >
>> >  cl <- makeCluster(mc <- getOption("cl.cores", detectCores()/2))
>> >
>> >  clusterEvalQ(cl, {
>> >
>> >    library(openNLP)
>> >
>> >    library(NLP)
>> >
>> >    PTA <- Maxent_POS_Tag_Annotator()
>> >
>> >  })
>> >
>> >
>> >
>> > This is the setup I am using:
>> >
>> > ?? Created an cloud instance with "Ubuntu Quantal 12.10 Server
>64-bit
>> > instance"
>> >
>> >
>> >
>> > ?? Installed LAMP server in the instance
>> >
>> >
>> >
>> > ?? After which I installed R. By default R version was 2.15.0
>> >
>> >
>> >
>> > ?? Upgraded the R version to R 3.0.1
>> >
>> > --
>> > Regards,
>> >
>> > Siddharth Arun,
>> > Contact No. - +91 8880065278
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>>


From spyqqqdia at yahoo.com  Wed Sep  4 10:34:54 2013
From: spyqqqdia at yahoo.com (Michael Meyer)
Date: Wed, 4 Sep 2013 16:34:54 +0800 (SGT)
Subject: [R] optim  evils
Message-ID: <1378283694.77272.YahooMailNeo@web193402.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130904/2c39ab1a/attachment.pl>

From jwiley.psych at gmail.com  Wed Sep  4 10:50:14 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Wed, 4 Sep 2013 01:50:14 -0700
Subject: [R] optim evils
In-Reply-To: <1378283694.77272.YahooMailNeo@web193402.mail.sg3.yahoo.com>
References: <1378283694.77272.YahooMailNeo@web193402.mail.sg3.yahoo.com>
Message-ID: <CANz9Z_JbneN_vu3a1EGc+LzD9bYp3dJozop-omWwvHaS2BjxkA@mail.gmail.com>

Hi Michael,

You do not need to create a self-contained example from the mass of
code where it is embedded, but given that optim() works in many cases,
to file a bug report, you do need to give _an_ example where it is
failing.

Here is an example where it works great:

> optim(1, fn = function(x) x - 5, method = "CG", lower = 3)
$par
[1] 3

$value
[1] -2

$counts
function gradient
       1        1

$convergence
[1] 0

$message
[1] "CONVERGENCE: NORM OF PROJECTED GRADIENT <= PGTOL"

Warning message:
In optim(1, fn = function(x) x - 5, method = "CG", lower = 3) :
  bounds can only be used with method L-BFGS-B (or Brent)

and it gives a warning at the end regarding L-BFGS-B.


On Wed, Sep 4, 2013 at 1:34 AM, Michael Meyer <spyqqqdia at yahoo.com> wrote:
> It would take some effort to extract selfcontained code from the mass of code wherein this optimization is embedded. Moreover I would have to obtain permission from my employer to do so.
>
> This is not efficient.
> However some things are evident from the trace log which I have submitted:
> (a) L-BFGS-B does not identify itself even though it was called overriding the method
> parameter in optim.
> (b) Optim  reports as final converged minimum value a function value that is much larger than
> others computed during the optimization.
>
> I think we can agree on calling this a bug.
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://joshuawiley.com/
Senior Analyst - Elkhart Group Ltd.
http://elkhartgroup.com


From zsurzsalaszlo at gmail.com  Wed Sep  4 10:57:13 2013
From: zsurzsalaszlo at gmail.com (Zsurzsa Laszlo)
Date: Wed, 4 Sep 2013 10:57:13 +0200
Subject: [R] XLSX package + Excel creation question
In-Reply-To: <CAAxdm-5jiDq2_dnEuxJwKLcKFJVbNXw6rhBPVHOVh7LC6SxUSw@mail.gmail.com>
References: <CAF4U=Vkk-Y0SL4150MYVAHkNxEoSE3kcmdiYqh8Ndnug8heFjQ@mail.gmail.com>
	<521F44D7.8040000@gwdg.de>
	<CAF4U=V=UJ=6vPsM0KieQKObnozcLSb5Ph1Q2H7-jiP7uQOATAQ@mail.gmail.com>
	<521F4E6D.5070105@gwdg.de>
	<CAF4U=VnvM0AVyLVHdjDAeuWFonshrdFQ7hqp7nW2RB=bc=sNVA@mail.gmail.com>
	<CAAxdm-5jiDq2_dnEuxJwKLcKFJVbNXw6rhBPVHOVh7LC6SxUSw@mail.gmail.com>
Message-ID: <CAF4U=V=ox+W=WGiz_xe5eCrm97G2NjQh4+to+Dt3RLrsYYPUKQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130904/199234fd/attachment.pl>

From Xochitl.Cormon at ifremer.fr  Wed Sep  4 11:11:59 2013
From: Xochitl.Cormon at ifremer.fr (Xochitl CORMON)
Date: Wed, 04 Sep 2013 11:11:59 +0200
Subject: [R] Stepwise selection with qAIC and qBIC
In-Reply-To: <521E189B.5000900@ifremer.fr>
References: <521E189B.5000900@ifremer.fr>
Message-ID: <5226F95F.7080903@ifremer.fr>

Here is a solution I applied using qAIC and package bbmle so I share it 
for next ones. It is not really automatized as I need to read every 
results of the drop() test an enter manually the less significant 
variable but I guess a function can be created in this goal.

nullQ <- update (null, family = quasibinomial)
fullQ <- update (full, family = quasibinomial)

# backward manual selection #Zuur, 2010 p.227 ; Faraway, 2006 p.149
drop1(fullQ, test= "F")
modelQ1 <- update(fullQ, .~. - #Highest p_value (not significant)#)
drop1(modelQ1, test = "F")
modelQ2 <- update(modelQ1, .~. -#2nd Highest p_value (not significant)#)
drop1(modelQ2, test = "F")
modelQ3 <- update(modelQ2, .~. - # 3rd #)
drop1(modelQ3, test = "F")
modelQ4 <- update(modelQ3, .~. - # 4th #)
drop1(modelQ4, test = "F")
modelQ5 <- update(modelQ4, .~. - # 5th #)
drop1(modelQ5, test = "F")
modelQ6 <- update(modelQ5, .~. - # 6th #)
drop1(modelQ6, test = "F")

library(bbmle)

# overdispersion parameter calculated from the most complex model as the 
sum of squares Pearson residuals divided by the number of degrees of 
freedom # Burnham & Anderson, 2002, p.67

Qi2 <- sum(residuals(fullQ, type= "pearson")^2)
dfr <-  summary(fullQ)$df.residual
disp <- Qi2/dfr

full <- update(fullQ, family = binomial) # we need to retrieve the 
loglikelihood so we use the "binomial model"
model1 <- update(modelQ1, family = binomial)
model2 <- update(modelQ2, family = binomial)
model3 <- update(modelQ3, family = binomial)
model4 <- update(modelQ4, family = binomial)
model5 <- update(modelQ5, family = binomial)
model6 <- update(modelQ6, family = binomial)

qAICtab <- ICtab (full, model1, model2, model3, model4, model5, model6, 
dispersion = disp, type = "qAIC", base = TRUE) # we use the global 
dispersion parameter as recommended in Burnham & Anderson, 2002


<>< <>< <>< <><

Xochitl CORMON
+33 (0)3 21 99 56 84

Doctorante en sciences halieutiques
PhD student in fishery sciences

<>< <>< <>< <><

IFREMER
Centre Manche Mer du Nord
150 quai Gambetta
62200 Boulogne-sur-Mer

<>< <>< <>< <><



Le 28/08/2013 17:34, Xochitl CORMON a ?crit :
> Dear list,
>
> I am currently working with presence/absence GLM. Therefore I am using
> binomial family and selection my models this way :
>
> null <- glm(respvarPAT ~ 1 , family = binomial, data = datafit)
> full <- glm(respvarPAT ~ CSpp + FSpp + Gpp + Mpp + Ppp + Lpp + TempPoly2
> + DepthPoly2 + DepthPoly3 , family = binomial, data = datafit)
> model1 <- stepAIC(full, scope = list(lower = null, upper = full),
> direction = "backward") #AIC backward
> model2 <- stepAIC(full, scope = list(lower = null, upper = full),
> direction = "backward", k=log(nobs(full))) #BIC backward
> model3 <- stepAIC(null, scope = list(lower = null, upper = full),
> direction = "forward") #AIC forward
> model4 <- stepAIC(null, scope = list(lower = null, upper = full),
> direction = "forward", k=log(nobs(full))) #BIC forward
> model5 <- stepAIC(null, scope = list(lower = null, upper = full),
> direction = "both") #AIC both
> model6 <- stepAIC(null, scope = list(lower = null, upper = full),
> direction = "both", k=log(nobs(full))) #BIC both
>
> Every model generated are actually identical being :
>
> glm(formula = respvarPAT ~ DepthPoly2 + DepthPoly3 + Gpp + Mpp +
> TempPoly2 + Lpp, family = binomial, data = datafit)
>
> This worked pretty good for the last set of explanatory variables I used
> however for these ones I have a bit of overdispersion problem.
> Dispersion parameter for more complex model(full) being : 7.415653.
>
> I looked into literature and found out that I should use qAIC and qBIC
> for selection. Thus my former stepwise selection is biased as using AIC
> and BIC (binomial family).
>
> My question is to know if there is way to change the k parameter in
> stepAIC in order to get quasi criterion. If not is there a way to
> automatize the selection using this criterion and having the dispersion
> parameter, customizing stepAIC function for example? Unfortunately I am
> reaching here my abilities in statistics and programming and cannot
> figure out if what I want to do is doable or not.
>
> Thank you for your help,
>
> Regards,
>
> Xochitl C.
>


From jwiley.psych at gmail.com  Wed Sep  4 12:07:05 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Wed, 4 Sep 2013 03:07:05 -0700
Subject: [R] Multiple regression (with interactions) by hand
In-Reply-To: <5225E27A.5050809@agr.uni-goettingen.de>
References: <5225B13A.7060903@agr.uni-goettingen.de>
	<CANz9Z_+2ksBgEQhWxNZvuR5HPduJx3pYJS2mdumV4YQz+pqinQ@mail.gmail.com>
	<5225E27A.5050809@agr.uni-goettingen.de>
Message-ID: <CANz9Z_KBA++cQqT+wM0zeSMmkjGVO4hy51T82fChBi2ApRBCDg@mail.gmail.com>

Hi Christoph,

ginv() computes the Moore-Penrose generalized inverse by way of a
singular value decomposition.  Part of the calculation involves taking
the reciprocal of the non zero values.  In practice, non zero is
really "within some precision tolerance of zero".  Numerical precision
can bite you in scientific computing.

There are many examples where the most conceptually straightforward
approach is not the best approach because whereas the equation may be
easy to write symbolically, it is more vulnerable to rounding or
truncation errors that occur in floating point representations.

Aside from working through some matrix algebra for understanding,
using established code (like lm) for models where the authors will
have taken issues like numerical precision and stability into
consideration is generally safest.

Cheers,

Josh



On Tue, Sep 3, 2013 at 6:22 AM, Christoph Scherber
<Christoph.Scherber at agr.uni-goettingen.de> wrote:
> Dear all,
>
> But why are there such huge differences betwen solve() and ginv()? (see code below)?
>
> ##
> m1=lm(Ozone~Solar.R*Wind,airquality)
>
> # remove NA?s:
> airquality2=airquality[complete.cases(airquality$Ozone)&
> complete.cases(airquality$Solar.R)&
> complete.cases(airquality$Wind),]
>
> # create the model matrix by hand:
> X=cbind("(Intercept)"=1,Solar.R=airquality2$Solar.R,Wind=airquality2$Wind,"Solar.R:Wind"=airquality2$Solar.R*airquality2$Wind)
> # is the same as:
> model.matrix(m1)
> # create the response vector by hand:
> Y=airquality2$Ozone
> # is the same as:
> m1$model$Ozone
> # Now solve for the parameter estimates:
>
> solve(crossprod(X)) %*% crossprod(X,Y) #gives the correct answer
>
> library(MASS)
> ginv(t(X)%*%X)%*%t(X)%*%Y #gives a wrong answer
>
>
>
>
>
> Am 03/09/2013 12:29, schrieb Joshua Wiley:
>> Hi Christoph,
>>
>> Use this matrix expression instead:
>>
>> solve(crossprod(X)) %*% t(X) %*% Y
>>
>> Note that:
>>
>> all.equal(crossprod(X), t(X) %*% X)
>>
>> Cheers,
>>
>> Joshua
>>
>>
>>
>> On Tue, Sep 3, 2013 at 2:51 AM, Christoph Scherber
>> <Christoph.Scherber at agr.uni-goettingen.de> wrote:
>>> Dear all,
>>>
>>> I?ve played around with the "airquality" dataset, trying to solve the matrix equations of a simple
>>> multiple regression by hand; however, my matrix multiplications don?t lead to the estimates returned
>>> by coef(). What have I done wrong here?
>>>
>>> ##
>>> m1=lm(Ozone~Solar.R*Wind,airquality)
>>>
>>> # remove NA?s:
>>> airquality2=airquality[complete.cases(airquality$Ozone)&
>>> complete.cases(airquality$Solar.R)&
>>> complete.cases(airquality$Wind),]
>>>
>>> # create the model matrix by hand:
>>> X=cbind("(Intercept)"=1,Solar.R=airquality2$Solar.R,Wind=airquality2$Wind,"Solar.R:Wind"=airquality2$Solar.R*airquality2$Wind)
>>> # is the same as:
>>> model.matrix(m1)
>>>
>>> # create the response vector by hand:
>>> Y=airquality2$Ozone
>>> # is the same as:
>>> m1$model$Ozone
>>>
>>> # Now solve for the parameter estimates:
>>> library(MASS)
>>> ginv(t(X)%*%X)%*%t(X)%*%Y
>>>
>>> # is not the same as:
>>> coef(m1)
>>>
>>> ##
>>> Now why is my result (line ginv(...)) not the same as the one returned by coef(m1)?
>>>
>>> Thanks very much for your help!
>>>
>>> Best regards,
>>> Christoph
>>>
>>> [using R 3.0.1 on Windows 7 32-Bit]
>>>
>>>
>>>
>>>
>>>
>>> --
>>> PD Dr Christoph Scherber
>>> Georg-August University Goettingen
>>> Department of Crop Science
>>> Agroecology
>>> Grisebachstrasse 6
>>> D-37077 Goettingen
>>> Germany
>>> phone 0049 (0)551 39 8807
>>> fax 0049 (0)551 39 8806
>>> http://www.gwdg.de/~cscherb1
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://joshuawiley.com/
Senior Analyst - Elkhart Group Ltd.
http://elkhartgroup.com


From mohan.radhakrishnan at polarisft.com  Wed Sep  4 12:43:42 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Wed, 4 Sep 2013 16:13:42 +0530
Subject: [R] Memory usage bar plot
In-Reply-To: <CAAxdm-739EF6d97vmcD_cam8J-usEufk5yJk3bbj2VBjsC3WMg@mail.gmail.com>
References: <OF29567033.DA4CECCE-ON65257BD7.003DC8DA-65257BD7.003EA3F1@polarisft.com>
	<CAAxdm-739EF6d97vmcD_cam8J-usEufk5yJk3bbj2VBjsC3WMg@mail.gmail.com>
Message-ID: <OF4ADE6E1A.CA966802-ON65257BDC.003A830D-65257BDC.003AE3CE@polarisft.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130904/6a9f3351/attachment.pl>

From Jose.Iparraguirre at ageuk.org.uk  Wed Sep  4 12:54:43 2013
From: Jose.Iparraguirre at ageuk.org.uk (Jose Iparraguirre)
Date: Wed, 4 Sep 2013 10:54:43 +0000
Subject: [R] ESEM in R
In-Reply-To: <730a23623491d441c8fbae055bf0e3c4.squirrel@poczta.vizja.pl>
References: <730a23623491d441c8fbae055bf0e3c4.squirrel@poczta.vizja.pl>
Message-ID: <5F8EC5C77B9AE547A8959F690F04C7B2063C9A@AGEPXMB006.uk.age.local>

Hi Krzysztof,

Have a look at the packages sem, lavaan and psych.
Regards,
Jos?

Prof. Jos? Iparraguirre
Chief Economist
Age UK


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of fronczyk at vizja.pl
Sent: 03 September 2013 13:33
To: r-help at r-project.org
Subject: [R] ESEM in R

Hello R experts,

Is there any possibility to perform exploratory structural equation modeling
(ESEM) in R? Which package should I use?

Thanks a lot for help,
Krzysztof

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

The Wireless from Age UK | Radio for grown-ups.

www.ageuk.org.uk/thewireless


If you?re looking for a radio station that offers real variety, tune in to The Wireless from Age UK. 
Whether you choose to listen through the website at www.ageuk.org.uk/thewireless, on digital radio (currently available in London and Yorkshire) or through our TuneIn Radio app, you can look forward to an inspiring mix of music, conversation and useful information 24 hours a day.



 
-------------------------------
Age UK is a registered charity and company limited by guarantee, (registered charity number 1128267, registered company number 6825798). 
Registered office: Tavis House, 1-6 Tavistock Square, London WC1H 9NA.

For the purposes of promoting Age UK Insurance, Age UK is an Appointed Representative of Age UK Enterprises Limited, Age UK is an Introducer 
Appointed Representative of JLT Benefit Solutions Limited and Simplyhealth Access for the purposes of introducing potential annuity and health 
cash plans customers respectively.  Age UK Enterprises Limited, JLT Benefit Solutions Limited and Simplyhealth Access are all authorised and 
regulated by the Financial Services Authority. 
------------------------------

This email and any files transmitted with it are confidential and intended solely for the use of the individual or entity to whom they are 
addressed. If you receive a message in error, please advise the sender and delete immediately.

Except where this email is sent in the usual course of our business, any opinions expressed in this email are those of the author and do not 
necessarily reflect the opinions of Age UK or its subsidiaries and associated companies. Age UK monitors all e-mail transmissions passing 
through its network and may block or modify mails which are deemed to be unsuitable.

Age Concern England (charity number 261794) and Help the Aged (charity number 272786) and their trading and other associated companies merged 
on 1st April 2009.  Together they have formed the Age UK Group, dedicated to improving the lives of people in later life.  The three national 
Age Concerns in Scotland, Northern Ireland and Wales have also merged with Help the Aged in these nations to form three registered charities: 
Age Scotland, Age NI, Age Cymru.





From keith.jewell at campdenbri.co.uk  Wed Sep  4 13:22:41 2013
From: keith.jewell at campdenbri.co.uk (Keith Jewell)
Date: Wed, 4 Sep 2013 12:22:41 +0100
Subject: [R] XLSX package + Excel creation question
In-Reply-To: <CAF4U=V=ox+W=WGiz_xe5eCrm97G2NjQh4+to+Dt3RLrsYYPUKQ@mail.gmail.com>
References: <CAF4U=Vkk-Y0SL4150MYVAHkNxEoSE3kcmdiYqh8Ndnug8heFjQ@mail.gmail.com>
	<521F44D7.8040000@gwdg.de>
	<CAF4U=V=UJ=6vPsM0KieQKObnozcLSb5Ph1Q2H7-jiP7uQOATAQ@mail.gmail.com>
	<521F4E6D.5070105@gwdg.de>
	<CAF4U=VnvM0AVyLVHdjDAeuWFonshrdFQ7hqp7nW2RB=bc=sNVA@mail.gmail.com>
	<CAAxdm-5jiDq2_dnEuxJwKLcKFJVbNXw6rhBPVHOVh7LC6SxUSw@mail.gmail.com>
	<CAF4U=V=ox+W=WGiz_xe5eCrm97G2NjQh4+to+Dt3RLrsYYPUKQ@mail.gmail.com>
Message-ID: <l0755o$kvr$1@ger.gmane.org>

I'll skip over the courtesy implications of double posting/pointing to 
stackoverflow.

The stackoverflow thread makes it look as if you need to learn more 
Excel. Do you really not know what an Excel template is?

It sounds as if you want what Excel calls "conditional formatting" which 
you can specify as custom number formats, see 
http://www.ozgrid.com/Excel/CustomFormats.htm.

Excel's help on custom number formats says:
----------------
To specify number formats that will be applied only if a number meets a 
condition that you specify, enclose the condition in square brackets. 
The condition consists of a comparison operator (comparison operator: A 
sign that is used in comparison criteria to compare two values. 
Operators include: = Equal to, > Greater than, < Less than, >= Greater 
than or equal to, <= Less than or equal to, and <> Not equal to.) and a 
value. For example, the following format displays numbers that are less 
than or equal to 100 in a red font and numbers that are greater than 100 
in a blue font.
[Red][<=100];[Blue][>100]
------------------

R package xlsx allows such formats (?DataFormat) as does R package 
XLConnect (?setDataFormat).

HTH

Keith J

On 04/09/2013 09:57, Zsurzsa Laszlo wrote:
> http://stackoverflow.com/questions/18511249/excel-cell-coloring-using-xlsx
>
> This is the initial post on stackoverflow. Please look at this maybe I'm
> clearer here.
>
> Thank you in advance,
>
> -------------------------------------------------------------------------------------
> - L?szl?-Andr?s Zsurzsa,                                                -
> - Msc. Infromatics, Technical University Munich, Germany -
> - Scientific Employee, TUM                                             -
> -------------------------------------------------------------------------------------
>
>
> On Fri, Aug 30, 2013 at 3:48 PM, jim holtman<jholtman at gmail.com>  wrote:
>
>> You can also look at the XLConnect package.
>> Jim Holtman
>> Data Munger Guru
>>
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>>
>>
>> On Thu, Aug 29, 2013 at 9:40 AM, Zsurzsa Laszlo<zsurzsalaszlo at gmail.com>
>> wrote:
>>> I understand you response but it does not solve the problem. I'am aware
>>> that one can simply color every cell in an excel file by using his own
>>> algorithm.
>>>
>>> The question was if I can write my data to a *single* cells and use
>>> different formatting for every piece of data.
>>>
>>>
>> -------------------------------------------------------------------------------------
>>> - L?szl?-Andr?s Zsurzsa,                                                -
>>> - Msc. Infromatics, Technical University Munich, Germany -
>>> - Scientific Employee, TUM                                             -
>>>
>> -------------------------------------------------------------------------------------
>>>
>>>
>>> On Thu, Aug 29, 2013 at 3:36 PM, Rainer Hurling<rhurlin at gwdg.de>  wrote:
>>>
>>>> Am 29.08.2013 15:03 (UTC+1) schrieb Zsurzsa Laszlo:
>>>>> First of all thank you for the quick resposen.
>>>>>
>>>>> I know I can color and set up every cell. I will take a look again *
>>>>> CellStyle* but is it possbile for example to write an array to a
>> single
>>>>> cell that has different colors for some data. Basically the color
>> depends
>>>>> on the data.
>>>>
>>>> As far as I know there is no ready to use functionality to mask groups
>>>> of selected cells. You have to write your own function, which selects
>>>> the right cells and changes their style with setCellStyle(cell,
>> cellStyle).
>>>>
>>>> Some hints are given in the examples section of ?CellStyle.
>>>>
>>>>>
>>>>>
>>>>
>> -------------------------------------------------------------------------------------
>>>>> - L?szl?-Andr?s Zsurzsa,
>>     -
>>>>> - Msc. Infromatics, Technical University Munich, Germany -
>>>>> - Scientific Employee, TUM
>>    -
>>>>>
>>>>
>> -------------------------------------------------------------------------------------
>>>>>
>>>>>
>>>>> On Thu, Aug 29, 2013 at 2:55 PM, Rainer Hurling<rhurlin at gwdg.de>
>> wrote:
>>>>>
>>>>>> Am 29.08.2013 12:08 (UTC+1) schrieb Zsurzsa Laszlo:
>>>>>>> Dear R users,
>>>>>>>
>>>>>>> I have a question about the xlsx package. It's possible to create
>> excel
>>>>>>> files and color cells and etc.
>>>>>>
>>>>>> yes, with package xlsx you can colourize you data sheets, even the
>>>>>> fonts. See for example ?CellStyle .
>>>>>>
>>>>>> A good demonstration of the capabilities is on
>>>>>>
>>>>>>
>>>>
>> http://tradeblotter.wordpress.com/2013/05/02/writing-from-r-to-excel-with-xlsx/
>>>>>>
>>>>>>>
>>>>>>> My question would be that is it possible to color only some part of
>> the
>>>>>>> data hold in a cell. Let's assume I've got the following data :
>>>>>>> 167,153,120,100 and I want to color to red everything that is bigger
>>>> then
>>>>>>> 120. How can I achive this using R.
>>>>>>>
>>>>>>> Example file setup with a few lines in attachment. (SEL_MASS column
>> can
>>>>>> be
>>>>>>> used for example)
>>>>>>
>>>>>> Attachment missing ...
>>>>>>
>>>>>> HTH,
>>>>>> Rainer
>>>>>>
>>>>>>>
>>>>>>> Thank you in advance,
>>>>>>>
>>>>>>
>>>>
>> -------------------------------------------------------------------------------------
>>>>>>> - L?szl?-Andr?s Zsurzsa,
>>>>   -
>>>>>>> - Msc. Infromatics, Technical University Munich, Germany -
>>>>>>> - Scientific Employee, TUM
>>>> -
>>>>>>>
>>>>>>
>>>>
>> -------------------------------------------------------------------------------------
>>>>>>
>>>>>
>>>>>        [[alternative HTML version deleted]]
>>>>>
>>>>>
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.


From zsurzsalaszlo at gmail.com  Wed Sep  4 14:09:36 2013
From: zsurzsalaszlo at gmail.com (Zsurzsa Laszlo)
Date: Wed, 4 Sep 2013 14:09:36 +0200
Subject: [R] XLSX package + Excel creation question
In-Reply-To: <l0755o$kvr$1@ger.gmane.org>
References: <CAF4U=Vkk-Y0SL4150MYVAHkNxEoSE3kcmdiYqh8Ndnug8heFjQ@mail.gmail.com>
	<521F44D7.8040000@gwdg.de>
	<CAF4U=V=UJ=6vPsM0KieQKObnozcLSb5Ph1Q2H7-jiP7uQOATAQ@mail.gmail.com>
	<521F4E6D.5070105@gwdg.de>
	<CAF4U=VnvM0AVyLVHdjDAeuWFonshrdFQ7hqp7nW2RB=bc=sNVA@mail.gmail.com>
	<CAAxdm-5jiDq2_dnEuxJwKLcKFJVbNXw6rhBPVHOVh7LC6SxUSw@mail.gmail.com>
	<CAF4U=V=ox+W=WGiz_xe5eCrm97G2NjQh4+to+Dt3RLrsYYPUKQ@mail.gmail.com>
	<l0755o$kvr$1@ger.gmane.org>
Message-ID: <CAF4U=V==cvJHyeRhx-ded87ajr_iE=c+zS4dWtc4tbnn1ubcYw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130904/7a0384b8/attachment.pl>

From bhh at xs4all.nl  Wed Sep  4 14:35:49 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 4 Sep 2013 14:35:49 +0200
Subject: [R] Multiple regression (with interactions) by hand
In-Reply-To: <CANz9Z_KBA++cQqT+wM0zeSMmkjGVO4hy51T82fChBi2ApRBCDg@mail.gmail.com>
References: <5225B13A.7060903@agr.uni-goettingen.de>
	<CANz9Z_+2ksBgEQhWxNZvuR5HPduJx3pYJS2mdumV4YQz+pqinQ@mail.gmail.com>
	<5225E27A.5050809@agr.uni-goettingen.de>
	<CANz9Z_KBA++cQqT+wM0zeSMmkjGVO4hy51T82fChBi2ApRBCDg@mail.gmail.com>
Message-ID: <5EEFFDD2-CAC9-4AE3-B355-8697364F0D3F@xs4all.nl>




On Tue, Sep 3, 2013 at 2:51 AM, Christoph Scherber
<Christoph.Scherber at agr.uni-goettingen.de> wrote:
> Dear all,
> 
> I?ve played around with the "airquality" dataset, trying to solve the matrix equations of a simple
> multiple regression by hand; however, my matrix multiplications don?t lead to the estimates returned
> by coef(). What have I done wrong here?
> 
> ##
> m1=lm(Ozone~Solar.R*Wind,airquality)
> 
> # remove NA?s:
> airquality2=airquality[complete.cases(airquality$Ozone)&
> complete.cases(airquality$Solar.R)&
> complete.cases(airquality$Wind),]
> 
> # create the model matrix by hand:
> X=cbind("(Intercept)"=1,Solar.R=airquality2$Solar.R,Wind=airquality2$Wind,"Solar.R:Wind"=airquality2$Solar.R*airquality2$Wind)
> # is the same as:
> model.matrix(m1)
> 
> # create the response vector by hand:
> Y=airquality2$Ozone
> # is the same as:
> m1$model$Ozone
> 
> # Now solve for the parameter estimates:
> library(MASS)
> ginv(t(X)%*%X)%*%t(X)%*%Y
> 
> # is not the same as:
> coef(m1)
> 
> ##
> Now why is my result (line ginv(...)) not the same as the one returned by coef(m1)?

Have a look at the help of ginv. It mentions the tol argument.
If you do

ginv(crossprod(X),tol=1e-12) %*% crossprod(X,Y)

you'll see that all is well. It's up to you to play with tol.

Berend


From kristi.glover at hotmail.com  Wed Sep  4 14:48:35 2013
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Wed, 4 Sep 2013 09:48:35 -0300
Subject: [R] would you give me hints in r?
Message-ID: <COL129-W481B59502C8BB82B1BB3F1FA320@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130904/3c24b8f2/attachment.pl>

From therneau at mayo.edu  Wed Sep  4 15:02:58 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Wed, 04 Sep 2013 08:02:58 -0500
Subject: [R] Should I wrap more package examples in \dontrun{} ?
In-Reply-To: <mailman.21.1378288807.16075.r-help@r-project.org>
References: <mailman.21.1378288807.16075.r-help@r-project.org>
Message-ID: <52272F82.6060908@mayo.edu>

To give a specific example, the simple code for my test suite is given at the bottom of 
this message.  A simpler (simple-minded maybe) approach than creating a new packge for 
testing.  I now run this on the survival package every time that I submit a new version to 
CRAN.  It takes a while, since there are over 200 dependencies.  It creates a file 
"progress" containing each package name as it is run folllowed by either "Ok" or "Failed" 
along with a directory "tests" containing the results.  Almost every run generates 1-3 hits.
   I have not automated this further because many runs also lead to exceptions, often 
packages that won't load because I don't have some ancillary piece of software installed 
that they depend on.  (I can't seem to get JAVA set up sufficient to satisfy everyone, for 
example, and have very low motivation to work harder at the task.)  And a small number 
have made it to the bad actors "I give up don't even bother to test" list.

Note that any package I want to fully test was installed on this local machine using
     install.packages("xxx", dependencies=TRUE, INSTALL_opts="--install-tests")
where "xxx" is the name of the package.

Terry T.


On 09/04/2013 05:00 AM, r-help-request at r-project.org wrote:
> n 03/09/2013 1:53 PM, Hadley Wickham wrote:
>>> >  >  As a user of your package, I would find it irritating if example(foo) didn't
>>> >  >  run anything.   It would be more irritating (and would indicate sloppiness
>>> >  >  on your part) if the examples failed when I cut and pasted them.  These both
>>> >  >  suggest leaving the examples running.
>>> >  >
>>> >  >  As the author of your package, it sounds as though you find it quite
>>> >  >  irritating when other authors break your code.
>>> >  >
>>> >  >  Isn't the right solution to this to work with the other package authors to
>>> >  >  come up with code that is unlikely to break?  If that's not possible, then
>>> >  >  maybe don't use those packages that cause you trouble.
>> >
>> >  It was my understanding that package authors are responsible for not
>> >  breaking other CRAN packages without warning.  For example, before I
>> >  release a new version of plyr or ggplot2, I run R CMD check on every
>> >  package that depends on my package. I then let the maintainers know if
>> >  something is broken - sometimes it's because I introduced a bug, and
>> >  other times it's because I'm enforcing a stricter check than I did
>> >  previously
> It sounds as though you're doing the right thing.   Can you describe how
> you determine the set of packages to check, and how you do your checks?
> It would be great if we could convince everyone to follow those steps.
>
> Duncan Murdoch
tmt% cat checkdeps.R
require("tools")

# First set a repository to look at
#chooseCRANmirror()     # do it graphically
#chooseBioCmirror()
options(repos=c(CRAN="http://streaming.stat.iastate.edu/CRAN/",
                 BioC="http://bioconductor.org/packages/2.11/bioc/"))

# This function is provided by Uwe Wigges
reverse <-
function(packages, which = c("Depends", "Imports", "LinkingTo"),
          recursive = FALSE)
{
     description <- sprintf("%s/web/packages/packages.rds",
                            getOption("repos")["CRAN"])
     con <- if(substring(description, 1L, 7L) == "file://")
         file(description, "rb")
     else
         url(description, "rb")
     on.exit(close(con))
     db <- readRDS(gzcon(con))
     rownames(db) <- NULL

     rdepends <- package_dependencies(packages, db, which,
                                      recursive = recursive,
                                      reverse = TRUE)
     rdepends <- sort(unique(unlist(rdepends)))
     pos <- match(rdepends, db[, "Package"], nomatch = 0L)

     db[pos, c("Package", "Version", "Maintainer")]
}

survdep <- reverse("survival")[,1]

# I don't want to check coxme (since I maintain a more up to date
# local copy), and there are a few known bad actors
avoid <- c("coxme", "STAR", "compareGroups")
survdep <- survdep[is.na(match(survdep, avoid))]

# Some packages may have failed to install, don't test those
inplace <- installed.packages()[,"Package"]  #ones we already have
missed <-  is.na(match(survdep, inplace))
if (any(missed)) {
     message("Unable to load packages ",
             paste(survdep[missed], collapse=", "), "\n")
     survdep <- survdep[!missed]
}

# Do the long list of tests
unlink("progress")
unlink("tests", recursive=TRUE)
system("mkdir tests")
pfile <- file("progress", open="write")
for (testpkg in survdep) {
     z <- testInstalledPackage(testpkg, outDir="tests")
     cat(testpkg, c("Ok", "Failed")[z+1], "\n", file=pfile)
}


From kridox at ymail.com  Wed Sep  4 15:00:59 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Wed, 4 Sep 2013 22:00:59 +0900
Subject: [R] tm::stemDocument function not work
In-Reply-To: <CAF4X4oN4Z2esf-fvGUMhnfWaTYHGsazys4tv7x2VPALW5-4wUg@mail.gmail.com>
References: <CAF4X4oPkb5NTkCgZmir_gFf3OYjnDpfYm-EeyfT9ZXRH85ZimQ@mail.gmail.com>
	<CAAcyNCwMFORe1PYMzO2Ob6M6n5R9E6+pvK=T7e7T_W8XrTwXHQ@mail.gmail.com>
	<CAF4X4oN4Z2esf-fvGUMhnfWaTYHGsazys4tv7x2VPALW5-4wUg@mail.gmail.com>
Message-ID: <CAAcyNCyAz9+Ve334so-N5+ptPKho-qnP2kZ7108-G9qssOBrfw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130904/044ba380/attachment.pl>

From hardy.edouard at gmail.com  Wed Sep  4 09:58:47 2013
From: hardy.edouard at gmail.com (Edouard Hardy)
Date: Wed, 4 Sep 2013 09:58:47 +0200
Subject: [R] Random products of rows in a matrix
Message-ID: <CAFsztN6ApLCJHoE0v1=p2ECoyMLTDotmF=PusCnsRmePvO8LFg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130904/c09453b7/attachment.pl>

From pietr007 at gmail.com  Wed Sep  4 13:37:02 2013
From: pietr007 at gmail.com (Ricardo Pietrobon)
Date: Wed, 4 Sep 2013 07:37:02 -0400
Subject: [R] tm::stemDocument function not work
In-Reply-To: <CAAcyNCwMFORe1PYMzO2Ob6M6n5R9E6+pvK=T7e7T_W8XrTwXHQ@mail.gmail.com>
References: <CAF4X4oPkb5NTkCgZmir_gFf3OYjnDpfYm-EeyfT9ZXRH85ZimQ@mail.gmail.com>
	<CAAcyNCwMFORe1PYMzO2Ob6M6n5R9E6+pvK=T7e7T_W8XrTwXHQ@mail.gmail.com>
Message-ID: <CAF4X4oN4Z2esf-fvGUMhnfWaTYHGsazys4tv7x2VPALW5-4wUg@mail.gmail.com>

thanks Pascal. actually, right after I sent the post I realized that I
didn't send my sessionInfo (at the bottom of this message now). Just
to make sure, everything in my script works except for the line with
stemDocument, which was commented in my gist. Below is the specific
warning I am getting:

> corpus  <- tm_map(corpus, stemDocument, language = "english")
Warning message:
In parallel::mclapply(x, FUN, ...) :
  all scheduled cores encountered errors in user code



> sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

On Wed, Sep 4, 2013 at 12:54 AM, Pascal Oettli <kridox at ymail.com> wrote:
> Hello,
>
> Your example worked for me.
>
> R> sessionInfo()
> R version 3.0.1 Patched (2013-09-02 r63805)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_GB.UTF-8        LC_COLLATE=en_GB.UTF-8
>  [5] LC_MONETARY=en_GB.UTF-8    LC_MESSAGES=en_GB.UTF-8
>  [7] LC_PAPER=C                 LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] scatterplot3d_0.3-33 lsa_0.63-3           RWeka_0.4-19
> [4] Snowball_0.0-10      ggplot2_0.9.3.1      tm_0.5-9.1
>
> loaded via a namespace (and not attached):
>  [1] colorspace_1.2-2   dichromat_2.0-0    digest_0.6.3       grid_3.0.1
>  [5] gtable_0.1.2       labeling_0.2       MASS_7.3-29        munsell_0.4.2
>  [9] parallel_3.0.1     plyr_1.8           proto_0.3-10
> RColorBrewer_1.0-5
> [13] reshape2_1.2.2     rJava_0.9-4        RWekajars_3.7.10-1 scales_0.2.3
> [17] slam_0.1-28        stringr_0.6.2
>
>
> Regards,
> Pascal
>
>
>
> 2013/9/4 Ricardo Pietrobon <pietr007 at gmail.com>
>>
>> https://gist.github.com/rpietro/6430771
>>
>> stemDocument function doesn't seem to be working. Tried to look up and
>> a few people have reported the problem, but no solution that I could
>> find.
>>
>> would appreciate any help
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From hh132 at le.ac.uk  Wed Sep  4 13:55:27 2013
From: hh132 at le.ac.uk (Rose)
Date: Wed, 4 Sep 2013 04:55:27 -0700 (PDT)
Subject: [R] panel multinomial logit
Message-ID: <1378295727096-4675348.post@n4.nabble.com>

Hi there,
I am trying to apply multinomial Logit for a panel data set. I have 5016
observations for 22 countries (id). Each country has 228 observations over
time domain.
Following table shows the part of my dataset including 10 variables.
      id  t     X1    X2    X3        X4    X5      X6         X7       X8  
X9      X10
500  3 44   NA     NA   NA       NA    NA 150.9211       NA      NA   NA
0.005684
501  3 45   NA     NA   NA       NA    NA 153.6307 0.409641   NA   NA
0.006196
502  3 46   NA     NA   NA       NA    NA 156.1034 0.422223   NA   NA
0.006666
503  3 47   NA     NA   NA       NA    NA 157.7336 0.541157   NA   NA
0.007110
504  3 48   NA     NA   NA       NA    NA 163.7610 0.717920   NA   NA
0.007533
505  3 49   NA     NA   NA       NA    NA 151.5358 0.727861   NA   NA
0.007580
506  3 50   NA     NA   NA       NA    NA 151.9387 0.842376   NA   NA
0.008198
I have generated a dependent variable with 3 states which are 0, 1, 2.
      id  t    y
500  3 44   1
501  3 45   2
502  3 46   0
503  3 47   0
504  3 48   0  
505  3 49   0
506  3 50   1
In order to reshape data from wide to long format I used the command below;
mdat <- mlogit.data (dat, id="id", choice="y", shape = "long",  alt.levels =
c("0", "1","2"))
> mdat[500:510,]
         id  t    X1     X2    X3       X4    X5      X6         X7       
X8  X9      
167.1  3 44   NA     NA   NA       NA    NA 150.9211       NA      NA   NA
167.2  3 45   NA     NA   NA       NA    NA 153.6307 0.409641   NA   NA
168.0  3 46   NA     NA   NA       NA    NA 156.1034 0.422223   NA   NA
168.1  3 47   NA     NA   NA       NA    NA 157.7336 0.541157   NA   NA
168.2  3 48   NA     NA   NA       NA    NA 163.7610 0.717920   NA   NA
169.0  3 49   NA     NA   NA       NA    NA 151.5358 0.727861   NA   NA
169.1  3 50   NA     NA   NA       NA    NA 151.9387 0.842376   NA   NA
             X10         y
167.1 0.005684   TRUE
167.2 0.006196   TRUE
168.0 0.006666   FALSE
168.1 0.007110   FALSE
168.2 0.007533   FALSE
169.0 0.007580   FALSE
169.1 0.008198   TRUE
This code has not given /chid/ or /alt/ columns in the result. These two
columns usually appear when you run the command for reshape the data format.
The problem in here is when I check y it shows True and False. I think it
ignores the other state that I defined for y it just shows 2 states! I am
confused. I don?t know whether the code which I have used for reshaping is
correct?
The main struggle is when I run the mlogit command. I have tried two
commands:
First;
> mlogit.model <- mlogit(y~ X1 + X2 +X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10,
> data = mdat, reflevel = "0")
I got following error;
Error in if (abs(x - oldx) < ftol) { : 
  missing value where TRUE/FALSE needed
Second;
mlogit.model <- mlogit(y~ X1 + X2 +X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10,
data = mdat, reflevel = "0",  R=50, halton=NA, print.level=0, panel=TRUE)
 Error in mlogit(y ~ X1 + X2 +X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10 +  : 
  panel is only relevant for mixed logit models.
Now, I would like to know if the mlogit.dat is correct or not? Secondly, how
could I make correct the mlogit command.

Any help would be appreciated in advance.

Best,
Rose 




--
View this message in context: http://r.789695.n4.nabble.com/panel-multinomial-logit-tp4675348.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Wed Sep  4 15:52:56 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 4 Sep 2013 06:52:56 -0700 (PDT)
Subject: [R] Memory usage bar plot
In-Reply-To: <OF4ADE6E1A.CA966802-ON65257BDC.003A830D-65257BDC.003AE3CE@polarisft.com>
References: <OF29567033.DA4CECCE-ON65257BD7.003DC8DA-65257BD7.003EA3F1@polarisft.com>	<CAAxdm-739EF6d97vmcD_cam8J-usEufk5yJk3bbj2VBjsC3WMg@mail.gmail.com>
	<OF4ADE6E1A.CA966802-ON65257BDC.003A830D-65257BDC.003AE3CE@polarisft.com>
Message-ID: <1378302776.9524.YahooMailNeo@web142602.mail.bf1.yahoo.com>

HI,
May be this helps.


input<- readLines(textConnection("
Private? +? Shared? =? RAM used????? Program

84.0 KiB +? 14.5 KiB =? 98.5 KiB????? sleep
108.0 KiB +? 11.5 KiB = 119.5 KiB????? klogd
124.0 KiB +? 15.0 KiB = 139.0 KiB????? hidd
128.0 KiB +? 12.5 KiB = 140.5 KiB????? gpm
116.0 KiB +? 28.5 KiB = 144.5 KiB????? hald-addon-storage
120.0 KiB +? 28.0 KiB = 148.0 KiB????? acpid
128.0 KiB +? 25.0 KiB = 153.0 KiB????? dbus-launch
128.0 KiB +? 31.5 KiB = 159.5 KiB????? hald-addon-acpi
144.0 KiB +? 19.0 KiB = 163.0 KiB????? sdpd
152.0 KiB +? 16.5 KiB = 168.5 KiB????? irqbalance
140.0 KiB +? 28.5 KiB = 168.5 KiB????? pam_timestamp_check
152.0 KiB +? 20.0 KiB = 172.0 KiB????? init
148.0 KiB +? 26.0 KiB = 174.0 KiB????? mapping-daemon
152.0 KiB +? 25.5 KiB = 177.5 KiB????? gnome-keyring-daemon
152.0 KiB +? 26.5 KiB = 178.5 KiB????? portmap
164.0 KiB +? 16.0 KiB = 180.0 KiB????? syslogd
168.0 KiB +? 24.5 KiB = 192.5 KiB????? atd
180.0 KiB +? 18.5 KiB = 198.5 KiB????? brcm_iscsiuio
188.0 KiB +? 37.0 KiB = 225.0 KiB????? rpc.statd
208.0 KiB +? 26.0 KiB = 234.0 KiB????? audispd
208.0 KiB +? 39.5 KiB = 247.5 KiB????? hald-runner
244.0 KiB +? 23.5 KiB = 267.5 KiB????? smartd
240.0 KiB +? 35.5 KiB = 275.5 KiB????? hpiod
244.0 KiB +? 35.0 KiB = 279.0 KiB????? hcid
228.0 KiB +? 73.0 KiB = 301.0 KiB????? hald-addon-keyboard (2)
328.0 KiB +? 32.5 KiB = 360.5 KiB????? gam_server
336.0 KiB +? 31.5 KiB = 367.5 KiB????? xinetd
364.0 KiB +? 28.5 KiB = 392.5 KiB????? auditd
420.0 KiB +? 78.0 KiB = 498.0 KiB????? mingetty (6)
552.0 KiB +? 19.5 KiB = 571.5 KiB????? udevd
532.0 KiB +? 56.0 KiB = 588.0 KiB????? rpc.idmapd
544.0 KiB +? 51.5 KiB = 595.5 KiB????? ssh-agent
372.0 KiB + 225.0 KiB = 597.0 KiB????? sh (2)
612.0 KiB +? 28.0 KiB = 640.0 KiB????? crond
484.0 KiB + 175.0 KiB = 659.0 KiB????? avahi-daemon (2)
744.0 KiB +? 74.5 KiB = 818.5 KiB????? automount
756.0 KiB + 186.5 KiB = 942.5 KiB????? gnome-vfs-daemon
736.0 KiB + 295.0 KiB =? 1.0 MiB????? dbus-daemon (2)
988.0 KiB +? 61.5 KiB =? 1.0 MiB????? pcscd
824.0 KiB + 231.5 KiB =? 1.0 MiB????? pam-panel-icon
? 1.0 MiB +? 26.0 KiB =? 1.1 MiB????? nmon
864.0 KiB + 229.5 KiB =? 1.1 MiB????? bt-applet
712.0 KiB + 402.0 KiB =? 1.1 MiB????? nm-system-settings
? 1.0 MiB +? 63.0 KiB =? 1.1 MiB????? nmbd
996.0 KiB + 131.0 KiB =? 1.1 MiB????? bonobo-activation-server
740.0 KiB + 398.5 KiB =? 1.1 MiB????? escd
868.0 KiB + 375.0 KiB =? 1.2 MiB????? bash (2)
? 1.1 MiB + 212.5 KiB =? 1.3 MiB????? gnome-screensaver
796.0 KiB + 621.5 KiB =? 1.4 MiB????? gdm-rh-security-token-helper
? 1.2 MiB + 387.5 KiB =? 1.6 MiB????? gnome-session
916.0 KiB + 749.5 KiB =? 1.6 MiB????? gdm-binary (2)
? 1.4 MiB + 225.0 KiB =? 1.6 MiB????? cupsd
? 1.3 MiB + 443.5 KiB =? 1.8 MiB????? notification-area-applet
? 2.1 MiB +? 68.0 KiB =? 2.2 MiB????? xfs
? 1.8 MiB + 545.5 KiB =? 2.3 MiB????? eggcups
? 2.2 MiB +? 86.5 KiB =? 2.3 MiB????? gconfd-2
? 1.9 MiB + 492.5 KiB =? 2.4 MiB????? gnome-settings-daemon
? 2.0 MiB + 421.5 KiB =? 2.4 MiB????? gnome-power-manager
? 1.9 MiB + 570.0 KiB =? 2.5 MiB????? trashapplet
? 1.7 MiB +? 1.0 MiB =? 2.7 MiB????? smbd (2)
? 2.6 MiB + 422.0 KiB =? 3.0 MiB????? iscsid (2)
? 2.7 MiB + 350.0 KiB =? 3.0 MiB????? sendmail.sendmail (2)
? 3.2 MiB +? 72.0 KiB =? 3.2 MiB????? hald
? 2.0 MiB +? 1.3 MiB =? 3.3 MiB????? sshd (3)
? 2.7 MiB + 651.0 KiB =? 3.4 MiB????? clock-applet
? 2.5 MiB +? 1.4 MiB =? 3.9 MiB????? nm-applet
? 3.4 MiB + 728.5 KiB =? 4.1 MiB????? metacity
? 3.4 MiB + 853.0 KiB =? 4.3 MiB????? wnck-applet
? 4.4 MiB + 376.5 KiB =? 4.8 MiB????? Xorg
? 4.3 MiB + 718.5 KiB =? 5.0 MiB????? mixer_applet2
? 4.5 MiB + 809.5 KiB =? 5.3 MiB????? gnome-panel
? 5.3 MiB + 251.5 KiB =? 5.6 MiB????? hpssd.py
? 6.2 MiB +? 4.1 MiB =? 10.3 MiB????? httpd (18)
10.5 MiB + 869.0 KiB =? 11.3 MiB????? gdmgreeter
12.8 MiB +? 1.1 MiB =? 13.8 MiB????? Xvnc
13.7 MiB + 515.5 KiB =? 14.2 MiB????? yum-updatesd
16.3 MiB +? 1.6 MiB =? 17.9 MiB????? nautilus
20.8 MiB +? 1.4 MiB =? 22.2 MiB????? puplet
? 1.5 GiB + 441.0 KiB =? 1.5 GiB????? java
---------------------------------
????????????????????????? 1.7 GiB
=================================
Private? +? Shared? =? RAM used????? Program

108.0 KiB +? 11.5 KiB = 119.5 KiB????? klogd
124.0 KiB +? 15.0 KiB = 139.0 KiB????? hidd
128.0 KiB +? 12.5 KiB = 140.5 KiB????? gpm
116.0 KiB +? 29.5 KiB = 145.5 KiB????? hald-addon-storage
120.0 KiB +? 28.0 KiB = 148.0 KiB????? acpid
128.0 KiB +? 25.0 KiB = 153.0 KiB????? dbus-launch
128.0 KiB +? 31.5 KiB = 159.5 KiB????? hald-addon-acpi
144.0 KiB +? 20.0 KiB = 164.0 KiB????? sdpd
140.0 KiB +? 26.5 KiB = 166.5 KiB????? pam_timestamp_check
152.0 KiB +? 16.5 KiB = 168.5 KiB????? irqbalance
152.0 KiB +? 20.0 KiB = 172.0 KiB????? init
148.0 KiB +? 26.0 KiB = 174.0 KiB????? mapping-daemon
152.0 KiB +? 25.5 KiB = 177.5 KiB????? gnome-keyring-daemon
152.0 KiB +? 27.5 KiB = 179.5 KiB????? portmap
164.0 KiB +? 18.0 KiB = 182.0 KiB????? syslogd
168.0 KiB +? 24.5 KiB = 192.5 KiB????? atd
180.0 KiB +? 18.5 KiB = 198.5 KiB????? brcm_iscsiuio
188.0 KiB +? 37.0 KiB = 225.0 KiB????? rpc.statd
208.0 KiB +? 24.0 KiB = 232.0 KiB????? audispd
208.0 KiB +? 40.5 KiB = 248.5 KiB????? hald-runner
244.0 KiB +? 23.5 KiB = 267.5 KiB????? smartd
240.0 KiB +? 35.5 KiB = 275.5 KiB????? hpiod
244.0 KiB +? 35.0 KiB = 279.0 KiB????? hcid
228.0 KiB +? 75.0 KiB = 303.0 KiB????? hald-addon-keyboard (2)
196.0 KiB + 144.0 KiB = 340.0 KiB????? sh
328.0 KiB +? 32.5 KiB = 360.5 KiB????? gam_server
336.0 KiB +? 32.5 KiB = 368.5 KiB????? xinetd
364.0 KiB +? 28.5 KiB = 392.5 KiB????? auditd
420.0 KiB +? 84.0 KiB = 504.0 KiB????? mingetty (6)
552.0 KiB +? 19.5 KiB = 571.5 KiB????? udevd
532.0 KiB +? 56.0 KiB = 588.0 KiB????? rpc.idmapd
544.0 KiB +? 50.5 KiB = 594.5 KiB????? ssh-agent
612.0 KiB +? 29.0 KiB = 641.0 KiB????? crond
484.0 KiB + 176.0 KiB = 660.0 KiB????? avahi-daemon (2)
576.0 KiB + 164.0 KiB = 740.0 KiB????? sftp-server
744.0 KiB +? 74.5 KiB = 818.5 KiB????? automount
756.0 KiB + 186.5 KiB = 942.5 KiB????? gnome-vfs-daemon
736.0 KiB + 296.0 KiB =? 1.0 MiB????? dbus-daemon (2)
988.0 KiB +? 61.5 KiB =? 1.0 MiB????? pcscd
824.0 KiB + 231.5 KiB =? 1.0 MiB????? pam-panel-icon
? 1.0 MiB +? 26.0 KiB =? 1.1 MiB????? nmon
864.0 KiB + 229.5 KiB =? 1.1 MiB????? bt-applet
712.0 KiB + 398.0 KiB =? 1.1 MiB????? nm-system-settings
? 1.0 MiB +? 63.0 KiB =? 1.1 MiB????? nmbd
996.0 KiB + 131.0 KiB =? 1.1 MiB????? bonobo-activation-server
740.0 KiB + 395.5 KiB =? 1.1 MiB????? escd
880.0 KiB + 432.0 KiB =? 1.3 MiB????? bash (2)
? 1.1 MiB + 212.5 KiB =? 1.3 MiB????? gnome-screensaver
796.0 KiB + 617.5 KiB =? 1.4 MiB????? gdm-rh-security-token-helper
916.0 KiB + 739.5 KiB =? 1.6 MiB????? gdm-binary (2)
? 1.2 MiB + 387.5 KiB =? 1.6 MiB????? gnome-session
? 1.4 MiB + 221.0 KiB =? 1.6 MiB????? cupsd
? 1.3 MiB + 443.5 KiB =? 1.8 MiB????? notification-area-applet
? 2.1 MiB +? 69.0 KiB =? 2.2 MiB????? xfs
? 1.8 MiB + 545.5 KiB =? 2.3 MiB????? eggcups
? 2.2 MiB +? 86.5 KiB =? 2.3 MiB????? gconfd-2
? 1.9 MiB + 492.5 KiB =? 2.4 MiB????? gnome-settings-daemon
? 2.0 MiB + 421.5 KiB =? 2.4 MiB????? gnome-power-manager
? 1.9 MiB + 569.0 KiB =? 2.5 MiB????? trashapplet
? 1.7 MiB +? 1.0 MiB =? 2.7 MiB????? smbd (2)
? 2.6 MiB + 365.0 KiB =? 2.9 MiB????? iscsid (2)
? 2.7 MiB + 349.0 KiB =? 3.0 MiB????? sendmail.sendmail (2)
? 3.2 MiB +? 73.0 KiB =? 3.2 MiB????? hald
? 2.7 MiB + 649.0 KiB =? 3.4 MiB????? clock-applet
? 2.5 MiB +? 1.4 MiB =? 3.9 MiB????? nm-applet
? 3.4 MiB + 729.5 KiB =? 4.1 MiB????? metacity
? 2.8 MiB +? 1.4 MiB =? 4.2 MiB????? sshd (4)
? 3.4 MiB + 853.0 KiB =? 4.3 MiB????? wnck-applet
? 4.4 MiB + 377.5 KiB =? 4.8 MiB????? Xorg
? 4.3 MiB + 717.5 KiB =? 5.0 MiB????? mixer_applet2
? 4.5 MiB + 809.5 KiB =? 5.3 MiB????? gnome-panel
? 5.3 MiB + 251.5 KiB =? 5.6 MiB????? hpssd.py
? 4.0 MiB +? 3.3 MiB =? 7.2 MiB????? httpd (11)
10.5 MiB + 870.0 KiB =? 11.3 MiB????? gdmgreeter
12.8 MiB +? 1.1 MiB =? 13.8 MiB????? Xvnc
13.7 MiB + 515.5 KiB =? 14.2 MiB????? yum-updatesd
16.3 MiB +? 1.6 MiB =? 17.9 MiB????? nautilus
20.8 MiB +? 1.4 MiB =? 22.2 MiB????? puplet
? 1.5 GiB + 438.0 KiB =? 1.5 GiB????? java
---------------------------------
????????????????????????? 1.7 GiB
================================="))


input1<- input

?input2<- str_trim(gsub("[=+]","",input1))
?input3<- input2[input2!=""]
?dat1<-read.table(text=gsub("\\,+",",",gsub("\\s{2}",",",input3)),sep=",",header=FALSE,stringsAsFactors=FALSE,fill=TRUE)
dat2<- dat1[,3:4]
?dat3<- dat2[dat2[,1]!="",][-1,]
lst1<-lapply(split(dat3,cumsum(1*grepl("RAM",dat3[,1]))),function(x) {x1<-if(length(grep("RAM",x[,1]))>0) x[-grep("RAM",x[,1]),] else x; x2<- data.frame(read.table(text=x1[,1],sep="",header=FALSE,stringsAsFactors=FALSE),x1[,2],stringsAsFactors=FALSE); colnames(x2)<- c("RAM", "used", "Program");x2})
?str(lst1)
#List of 2
# $ 0:'data.frame':??? 79 obs. of? 3 variables:
#? ..$ RAM??? : num [1:79] 98.5 119.5 139 140.5 144.5 ...
#? ..$ used?? : chr [1:79] "KiB" "KiB" "KiB" "KiB" ...
#? ..$ Program: chr [1:79] "sleep" "klogd" "hidd" "gpm" ...
# $ 1:'data.frame':??? 79 obs. of? 3 variables:
#? ..$ RAM??? : num [1:79] 120 139 140 146 148 ...
#? ..$ used?? : chr [1:79] "KiB" "KiB" "KiB" "KiB" ...
#? ..$ Program: chr [1:79] "klogd" "hidd" "gpm" "hald-addon-storage" ...

lapply(lst1,head)
#$`0`
#??? RAM used??????????? Program
#1? 98.5? KiB????????????? sleep
#2 119.5? KiB????????????? klogd
#3 139.0? KiB?????????????? hidd
#4 140.5? KiB??????????????? gpm
#5 144.5? KiB hald-addon-storage
#6 148.0? KiB????????????? acpid
#
#$`1`
#??? RAM used??????????? Program
#1 119.5? KiB????????????? klogd
#2 139.0? KiB?????????????? hidd
#3 140.5? KiB??????????????? gpm
#4 145.5? KiB hald-addon-storage
#5 148.0? KiB????????????? acpid
#6 153.0? KiB??????? dbus-launch

A.K.



----- Original Message -----
From: "mohan.radhakrishnan at polarisft.com" <mohan.radhakrishnan at polarisft.com>
To: jim holtman <jholtman at gmail.com>
Cc: R mailing list <r-help at r-project.org>
Sent: Wednesday, September 4, 2013 6:43 AM
Subject: Re: [R] Memory usage bar plot

Hi,
? ? ? ? ? ? ?  I have tried the ideas with an actual data set but couldn't 
pass the parsing phase. The name of the 'Program' varies.? MiB and KiB are 
both included.

I should have shown the real-time data set.

Private? +?  Shared? =? RAM used? ? ?  Program 

84.0 KiB +? 14.5 KiB =? 98.5 KiB? ? ?  sleep
108.0 KiB +? 11.5 KiB = 119.5 KiB? ? ?  klogd
124.0 KiB +? 15.0 KiB = 139.0 KiB? ? ?  hidd
128.0 KiB +? 12.5 KiB = 140.5 KiB? ? ?  gpm
116.0 KiB +? 28.5 KiB = 144.5 KiB? ? ?  hald-addon-storage
120.0 KiB +? 28.0 KiB = 148.0 KiB? ? ?  acpid
128.0 KiB +? 25.0 KiB = 153.0 KiB? ? ?  dbus-launch
128.0 KiB +? 31.5 KiB = 159.5 KiB? ? ?  hald-addon-acpi
144.0 KiB +? 19.0 KiB = 163.0 KiB? ? ?  sdpd
152.0 KiB +? 16.5 KiB = 168.5 KiB? ? ?  irqbalance
140.0 KiB +? 28.5 KiB = 168.5 KiB? ? ?  pam_timestamp_check
152.0 KiB +? 20.0 KiB = 172.0 KiB? ? ?  init
148.0 KiB +? 26.0 KiB = 174.0 KiB? ? ?  mapping-daemon
152.0 KiB +? 25.5 KiB = 177.5 KiB? ? ?  gnome-keyring-daemon
152.0 KiB +? 26.5 KiB = 178.5 KiB? ? ?  portmap
164.0 KiB +? 16.0 KiB = 180.0 KiB? ? ?  syslogd
168.0 KiB +? 24.5 KiB = 192.5 KiB? ? ?  atd
180.0 KiB +? 18.5 KiB = 198.5 KiB? ? ?  brcm_iscsiuio
188.0 KiB +? 37.0 KiB = 225.0 KiB? ? ?  rpc.statd
208.0 KiB +? 26.0 KiB = 234.0 KiB? ? ?  audispd
208.0 KiB +? 39.5 KiB = 247.5 KiB? ? ?  hald-runner
244.0 KiB +? 23.5 KiB = 267.5 KiB? ? ?  smartd
240.0 KiB +? 35.5 KiB = 275.5 KiB? ? ?  hpiod
244.0 KiB +? 35.0 KiB = 279.0 KiB? ? ?  hcid
228.0 KiB +? 73.0 KiB = 301.0 KiB? ? ?  hald-addon-keyboard (2)
328.0 KiB +? 32.5 KiB = 360.5 KiB? ? ?  gam_server
336.0 KiB +? 31.5 KiB = 367.5 KiB? ? ?  xinetd
364.0 KiB +? 28.5 KiB = 392.5 KiB? ? ?  auditd
420.0 KiB +? 78.0 KiB = 498.0 KiB? ? ?  mingetty (6)
552.0 KiB +? 19.5 KiB = 571.5 KiB? ? ?  udevd
532.0 KiB +? 56.0 KiB = 588.0 KiB? ? ?  rpc.idmapd
544.0 KiB +? 51.5 KiB = 595.5 KiB? ? ?  ssh-agent
372.0 KiB + 225.0 KiB = 597.0 KiB? ? ?  sh (2)
612.0 KiB +? 28.0 KiB = 640.0 KiB? ? ?  crond
484.0 KiB + 175.0 KiB = 659.0 KiB? ? ?  avahi-daemon (2)
744.0 KiB +? 74.5 KiB = 818.5 KiB? ? ?  automount
756.0 KiB + 186.5 KiB = 942.5 KiB? ? ?  gnome-vfs-daemon
736.0 KiB + 295.0 KiB =?  1.0 MiB? ? ?  dbus-daemon (2)
988.0 KiB +? 61.5 KiB =?  1.0 MiB? ? ?  pcscd
824.0 KiB + 231.5 KiB =?  1.0 MiB? ? ?  pam-panel-icon
? 1.0 MiB +? 26.0 KiB =?  1.1 MiB? ? ?  nmon
864.0 KiB + 229.5 KiB =?  1.1 MiB? ? ?  bt-applet
712.0 KiB + 402.0 KiB =?  1.1 MiB? ? ?  nm-system-settings
? 1.0 MiB +? 63.0 KiB =?  1.1 MiB? ? ?  nmbd
996.0 KiB + 131.0 KiB =?  1.1 MiB? ? ?  bonobo-activation-server
740.0 KiB + 398.5 KiB =?  1.1 MiB? ? ?  escd
868.0 KiB + 375.0 KiB =?  1.2 MiB? ? ?  bash (2)
? 1.1 MiB + 212.5 KiB =?  1.3 MiB? ? ?  gnome-screensaver
796.0 KiB + 621.5 KiB =?  1.4 MiB? ? ?  gdm-rh-security-token-helper
? 1.2 MiB + 387.5 KiB =?  1.6 MiB? ? ?  gnome-session
916.0 KiB + 749.5 KiB =?  1.6 MiB? ? ?  gdm-binary (2)
? 1.4 MiB + 225.0 KiB =?  1.6 MiB? ? ?  cupsd
? 1.3 MiB + 443.5 KiB =?  1.8 MiB? ? ?  notification-area-applet
? 2.1 MiB +? 68.0 KiB =?  2.2 MiB? ? ?  xfs
? 1.8 MiB + 545.5 KiB =?  2.3 MiB? ? ?  eggcups
? 2.2 MiB +? 86.5 KiB =?  2.3 MiB? ? ?  gconfd-2
? 1.9 MiB + 492.5 KiB =?  2.4 MiB? ? ?  gnome-settings-daemon
? 2.0 MiB + 421.5 KiB =?  2.4 MiB? ? ?  gnome-power-manager
? 1.9 MiB + 570.0 KiB =?  2.5 MiB? ? ?  trashapplet
? 1.7 MiB +?  1.0 MiB =?  2.7 MiB? ? ?  smbd (2)
? 2.6 MiB + 422.0 KiB =?  3.0 MiB? ? ?  iscsid (2)
? 2.7 MiB + 350.0 KiB =?  3.0 MiB? ? ?  sendmail.sendmail (2)
? 3.2 MiB +? 72.0 KiB =?  3.2 MiB? ? ?  hald
? 2.0 MiB +?  1.3 MiB =?  3.3 MiB? ? ?  sshd (3)
? 2.7 MiB + 651.0 KiB =?  3.4 MiB? ? ?  clock-applet
? 2.5 MiB +?  1.4 MiB =?  3.9 MiB? ? ?  nm-applet
? 3.4 MiB + 728.5 KiB =?  4.1 MiB? ? ?  metacity
? 3.4 MiB + 853.0 KiB =?  4.3 MiB? ? ?  wnck-applet
? 4.4 MiB + 376.5 KiB =?  4.8 MiB? ? ?  Xorg
? 4.3 MiB + 718.5 KiB =?  5.0 MiB? ? ?  mixer_applet2
? 4.5 MiB + 809.5 KiB =?  5.3 MiB? ? ?  gnome-panel
? 5.3 MiB + 251.5 KiB =?  5.6 MiB? ? ?  hpssd.py
? 6.2 MiB +?  4.1 MiB =? 10.3 MiB? ? ?  httpd (18)
10.5 MiB + 869.0 KiB =? 11.3 MiB? ? ?  gdmgreeter
12.8 MiB +?  1.1 MiB =? 13.8 MiB? ? ?  Xvnc
13.7 MiB + 515.5 KiB =? 14.2 MiB? ? ?  yum-updatesd
16.3 MiB +?  1.6 MiB =? 17.9 MiB? ? ?  nautilus
20.8 MiB +?  1.4 MiB =? 22.2 MiB? ? ?  puplet
? 1.5 GiB + 441.0 KiB =?  1.5 GiB? ? ?  java
---------------------------------
? ? ? ? ? ? ? ? ? ? ? ? ? 1.7 GiB
=================================
Private? +?  Shared? =? RAM used? ? ?  Program 

108.0 KiB +? 11.5 KiB = 119.5 KiB? ? ?  klogd
124.0 KiB +? 15.0 KiB = 139.0 KiB? ? ?  hidd
128.0 KiB +? 12.5 KiB = 140.5 KiB? ? ?  gpm
116.0 KiB +? 29.5 KiB = 145.5 KiB? ? ?  hald-addon-storage
120.0 KiB +? 28.0 KiB = 148.0 KiB? ? ?  acpid
128.0 KiB +? 25.0 KiB = 153.0 KiB? ? ?  dbus-launch
128.0 KiB +? 31.5 KiB = 159.5 KiB? ? ?  hald-addon-acpi
144.0 KiB +? 20.0 KiB = 164.0 KiB? ? ?  sdpd
140.0 KiB +? 26.5 KiB = 166.5 KiB? ? ?  pam_timestamp_check
152.0 KiB +? 16.5 KiB = 168.5 KiB? ? ?  irqbalance
152.0 KiB +? 20.0 KiB = 172.0 KiB? ? ?  init
148.0 KiB +? 26.0 KiB = 174.0 KiB? ? ?  mapping-daemon
152.0 KiB +? 25.5 KiB = 177.5 KiB? ? ?  gnome-keyring-daemon
152.0 KiB +? 27.5 KiB = 179.5 KiB? ? ?  portmap
164.0 KiB +? 18.0 KiB = 182.0 KiB? ? ?  syslogd
168.0 KiB +? 24.5 KiB = 192.5 KiB? ? ?  atd
180.0 KiB +? 18.5 KiB = 198.5 KiB? ? ?  brcm_iscsiuio
188.0 KiB +? 37.0 KiB = 225.0 KiB? ? ?  rpc.statd
208.0 KiB +? 24.0 KiB = 232.0 KiB? ? ?  audispd
208.0 KiB +? 40.5 KiB = 248.5 KiB? ? ?  hald-runner
244.0 KiB +? 23.5 KiB = 267.5 KiB? ? ?  smartd
240.0 KiB +? 35.5 KiB = 275.5 KiB? ? ?  hpiod
244.0 KiB +? 35.0 KiB = 279.0 KiB? ? ?  hcid
228.0 KiB +? 75.0 KiB = 303.0 KiB? ? ?  hald-addon-keyboard (2)
196.0 KiB + 144.0 KiB = 340.0 KiB? ? ?  sh
328.0 KiB +? 32.5 KiB = 360.5 KiB? ? ?  gam_server
336.0 KiB +? 32.5 KiB = 368.5 KiB? ? ?  xinetd
364.0 KiB +? 28.5 KiB = 392.5 KiB? ? ?  auditd
420.0 KiB +? 84.0 KiB = 504.0 KiB? ? ?  mingetty (6)
552.0 KiB +? 19.5 KiB = 571.5 KiB? ? ?  udevd
532.0 KiB +? 56.0 KiB = 588.0 KiB? ? ?  rpc.idmapd
544.0 KiB +? 50.5 KiB = 594.5 KiB? ? ?  ssh-agent
612.0 KiB +? 29.0 KiB = 641.0 KiB? ? ?  crond
484.0 KiB + 176.0 KiB = 660.0 KiB? ? ?  avahi-daemon (2)
576.0 KiB + 164.0 KiB = 740.0 KiB? ? ?  sftp-server
744.0 KiB +? 74.5 KiB = 818.5 KiB? ? ?  automount
756.0 KiB + 186.5 KiB = 942.5 KiB? ? ?  gnome-vfs-daemon
736.0 KiB + 296.0 KiB =?  1.0 MiB? ? ?  dbus-daemon (2)
988.0 KiB +? 61.5 KiB =?  1.0 MiB? ? ?  pcscd
824.0 KiB + 231.5 KiB =?  1.0 MiB? ? ?  pam-panel-icon
? 1.0 MiB +? 26.0 KiB =?  1.1 MiB? ? ?  nmon
864.0 KiB + 229.5 KiB =?  1.1 MiB? ? ?  bt-applet
712.0 KiB + 398.0 KiB =?  1.1 MiB? ? ?  nm-system-settings
? 1.0 MiB +? 63.0 KiB =?  1.1 MiB? ? ?  nmbd
996.0 KiB + 131.0 KiB =?  1.1 MiB? ? ?  bonobo-activation-server
740.0 KiB + 395.5 KiB =?  1.1 MiB? ? ?  escd
880.0 KiB + 432.0 KiB =?  1.3 MiB? ? ?  bash (2)
? 1.1 MiB + 212.5 KiB =?  1.3 MiB? ? ?  gnome-screensaver
796.0 KiB + 617.5 KiB =?  1.4 MiB? ? ?  gdm-rh-security-token-helper
916.0 KiB + 739.5 KiB =?  1.6 MiB? ? ?  gdm-binary (2)
? 1.2 MiB + 387.5 KiB =?  1.6 MiB? ? ?  gnome-session
? 1.4 MiB + 221.0 KiB =?  1.6 MiB? ? ?  cupsd
? 1.3 MiB + 443.5 KiB =?  1.8 MiB? ? ?  notification-area-applet
? 2.1 MiB +? 69.0 KiB =?  2.2 MiB? ? ?  xfs
? 1.8 MiB + 545.5 KiB =?  2.3 MiB? ? ?  eggcups
? 2.2 MiB +? 86.5 KiB =?  2.3 MiB? ? ?  gconfd-2
? 1.9 MiB + 492.5 KiB =?  2.4 MiB? ? ?  gnome-settings-daemon
? 2.0 MiB + 421.5 KiB =?  2.4 MiB? ? ?  gnome-power-manager
? 1.9 MiB + 569.0 KiB =?  2.5 MiB? ? ?  trashapplet
? 1.7 MiB +?  1.0 MiB =?  2.7 MiB? ? ?  smbd (2)
? 2.6 MiB + 365.0 KiB =?  2.9 MiB? ? ?  iscsid (2)
? 2.7 MiB + 349.0 KiB =?  3.0 MiB? ? ?  sendmail.sendmail (2)
? 3.2 MiB +? 73.0 KiB =?  3.2 MiB? ? ?  hald
? 2.7 MiB + 649.0 KiB =?  3.4 MiB? ? ?  clock-applet
? 2.5 MiB +?  1.4 MiB =?  3.9 MiB? ? ?  nm-applet
? 3.4 MiB + 729.5 KiB =?  4.1 MiB? ? ?  metacity
? 2.8 MiB +?  1.4 MiB =?  4.2 MiB? ? ?  sshd (4)
? 3.4 MiB + 853.0 KiB =?  4.3 MiB? ? ?  wnck-applet
? 4.4 MiB + 377.5 KiB =?  4.8 MiB? ? ?  Xorg
? 4.3 MiB + 717.5 KiB =?  5.0 MiB? ? ?  mixer_applet2
? 4.5 MiB + 809.5 KiB =?  5.3 MiB? ? ?  gnome-panel
? 5.3 MiB + 251.5 KiB =?  5.6 MiB? ? ?  hpssd.py
? 4.0 MiB +?  3.3 MiB =?  7.2 MiB? ? ?  httpd (11)
10.5 MiB + 870.0 KiB =? 11.3 MiB? ? ?  gdmgreeter
12.8 MiB +?  1.1 MiB =? 13.8 MiB? ? ?  Xvnc
13.7 MiB + 515.5 KiB =? 14.2 MiB? ? ?  yum-updatesd
16.3 MiB +?  1.6 MiB =? 17.9 MiB? ? ?  nautilus
20.8 MiB +?  1.4 MiB =? 22.2 MiB? ? ?  puplet
? 1.5 GiB + 438.0 KiB =?  1.5 GiB? ? ?  java
---------------------------------
? ? ? ? ? ? ? ? ? ? ? ? ? 1.7 GiB
=================================


Thanks,
Mohan



From:?  jim holtman <jholtman at gmail.com>
To:? ? mohan.radhakrishnan at polarisft.com
Cc:? ?  R mailing list <r-help at r-project.org>
Date:?  08/30/2013 07:14 PM
Subject:? ? ? ? Re: [R] Memory usage bar plot



Here is how to parse the data and put it into groups.? Not sure what
the 'timing' of each group is since not time information was given.
Also not sure is there is an 'MiB' qualifier on the data, but you have
the matrix of data which is easy to do with as you want.


> input <- readLines(textConnection("
+? Private? +?  Shared? =? RAM used? ? ?  Program
+
+? 96.0 KiB +? 11.5 KiB = 107.5 KiB? ? ?  uuidd
+ 108.0 KiB +? 12.5 KiB = 120.5 KiB? ? ?  klogd
+ 124.0 KiB +? 17.0 KiB = 141.0 KiB? ? ?  hidd
+ 116.0 KiB +? 30.0 KiB = 146.0 KiB? ? ?  acpid
+ 124.0 KiB +? 29.5 KiB = 153.5 KiB? ? ?  hald-addon-storage
+ 144.0 KiB +? 15.0 KiB = 159.0 KiB? ? ?  gpm
+ 136.0 KiB +? 26.5 KiB = 162.5 KiB? ? ?  pam_timestamp_check
+ ---------------------------------------------------------
+? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?  453.9 MiB
+
+ =================================
+? Private? +?  Shared? =? RAM used? ? ?  Program
+
+? 96.0 KiB +? 11.5 KiB = 107.5 KiB? ? ?  uuidd
+ 108.0 KiB +? 12.5 KiB = 120.5 KiB? ? ?  klogd
+ 124.0 KiB +? 17.0 KiB = 141.0 KiB? ? ?  hidd
+ 116.0 KiB +? 30.0 KiB = 146.0 KiB? ? ?  acpid
+ 124.0 KiB +? 29.5 KiB = 153.5 KiB? ? ?  hald-addon-storage
+ 144.0 KiB +? 15.0 KiB = 159.0 KiB? ? ?  gpm
+ 136.0 KiB +? 26.5 KiB = 162.5 KiB? ? ?  pam_timestamp_check
+ ----------------------------------------------------------
+? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?  453.9 MiB
+ ================================="))
>
> # keep only the data
> input <- input[grepl('=', input)]
>
> # separate into groups
> grps <- split(input, cumsum(grepl("=? RAM", input)))
>
> # parse the data (not sure if there is also 'MiB')
> parsed <- lapply(grps, function(.grp){
+? ?  # parse ignoring first and last lines
+? ?  .data <- sub(".*= ([^ ]+) ([^ ]+)\\s+(.*)", "\\1 \\2 \\3"
+? ? ? ? ? ? ? ?  , .grp[2:(length(.grp) - 1L)]
+? ? ? ? ? ? ? ?  )
+? ?  # return matrix
+? ?  do.call(rbind, strsplit(.data, ' '))
+ })
>
>
>
> parsed
$`1`
? ?  [,1]? ? [,2]? [,3]
[1,] "107.5" "KiB" "uuidd"
[2,] "120.5" "KiB" "klogd"
[3,] "141.0" "KiB" "hidd"
[4,] "146.0" "KiB" "acpid"
[5,] "153.5" "KiB" "hald-addon-storage"
[6,] "159.0" "KiB" "gpm"
[7,] "162.5" "KiB" "pam_timestamp_check"

$`2`
? ?  [,1]? ? [,2]? [,3]
[1,] "107.5" "KiB" "uuidd"
[2,] "120.5" "KiB" "klogd"
[3,] "141.0" "KiB" "hidd"
[4,] "146.0" "KiB" "acpid"
[5,] "153.5" "KiB" "hald-addon-storage"
[6,] "159.0" "KiB" "gpm"
[7,] "162.5" "KiB" "pam_timestamp_check"

>
Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Fri, Aug 30, 2013 at 7:24 AM,? <mohan.radhakrishnan at polarisft.com> 
wrote:
> Hi,
>? ? ? ? ?  I haven't tried the code yet. Is there a way to parse this 
data
> using R and create bar plots so that each program's 'RAM used' figures 
are
> grouped together.
> So 'uuidd' bars will be together. The data will have about 50 sets. So 
if
> there are 100 processes each will have about 50 bars.
>
> What is the recommended way to graph these big barplots ? I am looking 
for
> only 'RAM used' figures.
>
>
> Thanks,
> Mohan
>
>
>? Private? +?  Shared? =? RAM used? ? ?  Program
>
>? 96.0 KiB +? 11.5 KiB = 107.5 KiB? ? ?  uuidd
> 108.0 KiB +? 12.5 KiB = 120.5 KiB? ? ?  klogd
> 124.0 KiB +? 17.0 KiB = 141.0 KiB? ? ?  hidd
> 116.0 KiB +? 30.0 KiB = 146.0 KiB? ? ?  acpid
> 124.0 KiB +? 29.5 KiB = 153.5 KiB? ? ?  hald-addon-storage
> 144.0 KiB +? 15.0 KiB = 159.0 KiB? ? ?  gpm
> 136.0 KiB +? 26.5 KiB = 162.5 KiB? ? ?  pam_timestamp_check
> ---------------------------------------------------------
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?  453.9 MiB
>
> =================================
>? Private? +?  Shared? =? RAM used? ? ?  Program
>
>? 96.0 KiB +? 11.5 KiB = 107.5 KiB? ? ?  uuidd
> 108.0 KiB +? 12.5 KiB = 120.5 KiB? ? ?  klogd
> 124.0 KiB +? 17.0 KiB = 141.0 KiB? ? ?  hidd
> 116.0 KiB +? 30.0 KiB = 146.0 KiB? ? ?  acpid
> 124.0 KiB +? 29.5 KiB = 153.5 KiB? ? ?  hald-addon-storage
> 144.0 KiB +? 15.0 KiB = 159.0 KiB? ? ?  gpm
> 136.0 KiB +? 26.5 KiB = 162.5 KiB? ? ?  pam_timestamp_check
> ----------------------------------------------------------
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?  453.9 MiB
> =================================
>
>
> This e-Mail may contain proprietary and confidential information and is 
sent for the intended recipient(s) only.? If by an addressing or 
transmission error this mail has been misdirected to you, you are 
requested to delete this mail immediately. You are also hereby notified 
that any use, any form of reproduction, dissemination, copying, 
disclosure, modification, distribution and/or publication of this e-mail 
message, contents or its attachment other than by its intended recipient/s 
is strictly prohibited.
>
> Visit us at http://www.polarisFT.com
>
>? ? ? ?  [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




This e-Mail may contain proprietary and confidential information and is sent for the intended recipient(s) only.? If by an addressing or transmission error this mail has been misdirected to you, you are requested to delete this mail immediately. You are also hereby notified that any use, any form of reproduction, dissemination, copying, disclosure, modification, distribution and/or publication of this e-mail message, contents or its attachment other than by its intended recipient/s is strictly prohibited.

Visit us at http://www.polarisFT.com

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ruipbarradas at sapo.pt  Wed Sep  4 15:57:45 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 04 Sep 2013 14:57:45 +0100
Subject: [R] would you give me hints in r?
In-Reply-To: <COL129-W481B59502C8BB82B1BB3F1FA320@phx.gbl>
References: <COL129-W481B59502C8BB82B1BB3F1FA320@phx.gbl>
Message-ID: <52273C59.9030601@sapo.pt>

Hello,

Where does the function bioclim come from? What package? If it's from 
package dismo, then you should try predict() with the arguments reversed:

pred <- predict(mod, ex)


Hope this helps,

Rui Barradas

Em 04-09-2013 13:48, Kristi Glover escreveu:
> Dear R User,
> Would you give me some hints on why I could not predict using data. format' data.
> Here is the example:
>
> ex<-structure(list(env1 = c(182, 163.33, 443.02, 1240.16), env2 = c(1134,
> 550, 2111, 2523), env3 = c(24.53, 24.93, 24.71, 21.05), env4 = c(0.05,
> 0, 0, 0)), .Names = c("env1", "env2", "env3", "env4"), row.names = c(NA,
> -4L), class = "data.frame")
>
> mod<-bioclim(ex)
> pred<-predict(ex,mod)
>
> Error in UseMethod("predict") :
>    no applicable method for 'predict' applied to an object of class "data.frame"
>
> Thanks for your help
> KG
>
>   		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From kristi.glover at hotmail.com  Wed Sep  4 16:02:51 2013
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Wed, 4 Sep 2013 11:02:51 -0300
Subject: [R] would you give me hints in r?
In-Reply-To: <52273C59.9030601@sapo.pt>
References: <COL129-W481B59502C8BB82B1BB3F1FA320@phx.gbl>,
	<52273C59.9030601@sapo.pt>
Message-ID: <COL129-W77A875219094E51E9E4DEFFA320@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130904/bbe39289/attachment.pl>

From sarah.goslee at gmail.com  Wed Sep  4 16:20:39 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 4 Sep 2013 10:20:39 -0400
Subject: [R] would you give me hints in r?
In-Reply-To: <COL129-W77A875219094E51E9E4DEFFA320@phx.gbl>
References: <COL129-W481B59502C8BB82B1BB3F1FA320@phx.gbl>
	<52273C59.9030601@sapo.pt>
	<COL129-W77A875219094E51E9E4DEFFA320@phx.gbl>
Message-ID: <CAM_vjunZENqzKrJzhE76BQwm4n_1Aaw8RmrmKW1QkdN5TimtvQ@mail.gmail.com>

Rui's suggestion and your reproducible example work for me. Can you
give us more information about what you did, including the output of
sessionInfo() ?

library(dismo)
ex<-structure(list(env1 = c(182, 163.33, 443.02, 1240.16), env2 = c(1134,
550, 2111, 2523), env3 = c(24.53, 24.93, 24.71, 21.05), env4 = c(0.05,
0, 0, 0)), .Names = c("env1", "env2", "env3", "env4"), row.names = c(NA,
-4L), class = "data.frame")

mod<-bioclim(ex)
pred<-predict(mod, ex)


On Wed, Sep 4, 2013 at 10:02 AM, Kristi Glover
<kristi.glover at hotmail.com> wrote:
> Hi Rui,
> Thanks for the message. i used dismo package.
> I changed the argument as you suggested, still did not work.
>
> Error in UseMethod("predict") :
>   no applicable method for 'predict' applied to an object of class "data.frame"
>
> Thanks
> KG
>
>> Date: Wed, 4 Sep 2013 14:57:45 +0100
>> From: ruipbarradas at sapo.pt
>> To: kristi.glover at hotmail.com
>> CC: r-help at r-project.org
>> Subject: Re: [R] would you give me hints in r?
>>
>> Hello,
>>
>> Where does the function bioclim come from? What package? If it's from
>> package dismo, then you should try predict() with the arguments reversed:
>>
>> pred <- predict(mod, ex)
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> Em 04-09-2013 13:48, Kristi Glover escreveu:
>> > Dear R User,
>> > Would you give me some hints on why I could not predict using data. format' data.
>> > Here is the example:
>> >
>> > ex<-structure(list(env1 = c(182, 163.33, 443.02, 1240.16), env2 = c(1134,
>> > 550, 2111, 2523), env3 = c(24.53, 24.93, 24.71, 21.05), env4 = c(0.05,
>> > 0, 0, 0)), .Names = c("env1", "env2", "env3", "env4"), row.names = c(NA,
>> > -4L), class = "data.frame")
>> >
>> > mod<-bioclim(ex)
>> > pred<-predict(ex,mod)
>> >
>> > Error in UseMethod("predict") :
>> >    no applicable method for 'predict' applied to an object of class "data.frame"
>> >
>> > Thanks for your help
>> > KG
>> >
>> >

Sarah Goslee
http://www.functionaldiversity.org


From dcarlson at tamu.edu  Wed Sep  4 16:34:50 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Wed, 4 Sep 2013 09:34:50 -0500
Subject: [R] Random products of rows in a matrix
In-Reply-To: <CAFsztN6ApLCJHoE0v1=p2ECoyMLTDotmF=PusCnsRmePvO8LFg@mail.gmail.com>
References: <CAFsztN6ApLCJHoE0v1=p2ECoyMLTDotmF=PusCnsRmePvO8LFg@mail.gmail.com>
Message-ID: <03ae01cea97b$e9716f40$bc544dc0$@tamu.edu>

Actually you have two loops, the for() loop you created and the
loop that is hidden inside apply(). You can hide the first loop
with lapply() or sapply():

B <- do.call(rbind, lapply(1:N, function(x)
colSums(A[sample.int(nrow(A), M, replace=TRUE),])))

Or

B <- t(sapply(1:N, function(x) colSums(A[sample.int(nrow(A), M,
replace=TRUE),])))

You could eliminate the apply() loop by taking log(A), using
colSums(), and then converting back with exp().

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Edouard Hardy
Sent: Wednesday, September 4, 2013 2:59 AM
To: R help
Subject: [R] Random products of rows in a matrix

Hello everybody,

Without any loop and any package,

I would like to return N products of M rows in a matrix A :

Today, I managed to do it with a loop :

B <- matrix(NA, ncol = ncol(A), nrow = 0)
for (i in 1 : N) B <- rbind(B, apply(A[sample(1 : nrow(A), M,
replace = T),
], 2, prod))

Do you have a solution ?

Thank you in advance !

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From smartpink111 at yahoo.com  Wed Sep  4 16:38:53 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 4 Sep 2013 07:38:53 -0700 (PDT)
Subject: [R] remove rows with infinite/nan values from a zoo dataset
In-Reply-To: <1378223363.10293.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1378190868.36659.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1378223363.10293.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1378305533.3503.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,

This is confusing because the error message suggests that you were not able to read the csv file.? Then how did you removed the Inf values?.? I guess this should be a different dataset.


From your previous email: 

"

prices=read.zoo("C:\\Users\\Desktop\\\\awc_au.csv",header=TRUE,sep=",",format="%Y-%m-%d" ")"


Try:
read.zoo(...., fill=TRUE)

From my first reply:

dat1<- read.zoo(text="2009-07-15,#N/A N/A,#N/A N/A,18.96858
?2009-07-16,20.30685,20.40664,#N/A N/A
?2009-07-17,20.78813,20.03991,20.40664
?2009-07-20,21.41278,21.41278,20.03991
?2009-07-21,22.9963,22.98397,21.41278
?2009-07-22,23.06443,23.01112,22.98397
?2009-07-23,23.45905,24.72232,23.01112
?2009-07-24,24.89291,25.56603,24.72232
?2009-07-27,25.38929,24.80535,25.56603
?2009-07-28,25.26712,25.65566,24.80535
?2009-07-29,25.83884,24.98163,25.65566
?2009-07-30,#N/A N/A,#N/A N/A,24.98163
?2009-08-03,25.25553,25.93297,#N/A N/A
?2009-08-04,26.02464,25.49159,25.93297
?",sep=",",header=FALSE,FUN=as.Date,format="%Y-%m-%d")
#Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,? : 
?# line 1 did not have 4 elements


dat1<- read.zoo(text="2009-07-15,#N/A N/A,#N/A N/A,18.96858
2009-07-16,20.30685,20.40664,#N/A N/A
2009-07-17,20.78813,20.03991,20.40664
2009-07-20,21.41278,21.41278,20.03991
2009-07-21,22.9963,22.98397,21.41278
2009-07-22,23.06443,23.01112,22.98397
2009-07-23,23.45905,24.72232,23.01112
2009-07-24,24.89291,25.56603,24.72232
2009-07-27,25.38929,24.80535,25.56603
2009-07-28,25.26712,25.65566,24.80535
2009-07-29,25.83884,24.98163,25.65566
2009-07-30,#N/A N/A,#N/A N/A,24.98163
2009-08-03,25.25553,25.93297,#N/A N/A
2009-08-04,26.02464,25.49159,25.93297
",sep=",",header=FALSE,FUN=as.Date,format="%Y-%m-%d",fill=TRUE)##works.

A.K.





Thank you A.K. 

The infinite values are removed but how about the NA values in a
 csv file? I got error message like "Error in scan(file, what, nmax, 
sep, dec, quote, skip, nlines, na.strings, ?: 
? line 1356 did not have 4 elements" 

How could I ignore the rows with NA value when read a csv file? 

Thank you. 

R.L 


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Tuesday, September 3, 2013 11:49 AM
Subject: Re: remove rows with infinite/nan values from a zoo dataset

Hi,

No problem.

In my previous post, I showed how to dput() your example dataset.? Please use dput() in the future.
vec1<- c(3.369247e-04,0.000000e+00,9.022183e-04,0.000000e+00,-1.105819e-04,-Inf,1.191271e-04,1.681718e-04,NaN,1.150126e-04,1.031037e-03,2.710993e-04)

indx<-seq(as.Date("2009-09-01"),as.Date("2009-09-17"),by=1)
indx1<-indx[-c(5:7,12:13)]
library(zoo)
z1<- zoo(vec1,order.by=indx1)
?sum(z1,na.rm=TRUE) #without removing the Inf. 
#[1] -Inf


sum(z1[is.finite(z1)],na.rm=TRUE)
#[1] 0.002833009


#or just
sum(z1[is.finite(z1)])
#[1] 0.002833009
A.K.





Thank you for your reply A.K. 

Sorry for my misleading -- the first question should be removing
#N/A N/A values when reading a csv file. So the example provided in the
original post was dragged from a csv spreadsheet directly. 
(which I used the code "prices=read.zoo("C:\\Users\\Desktop\\\\awc_au.csv",header=TRUE,sep=",",format="%Y-%m-%d" ") 

Then the following up question is removing from a zoo data set. 
After some calculation, the new zoo data set is as following: 
?2009-09-01 ? ? ? ? 2009-09-02 ? ? ? 2009-09-03 ? ? 2009-09-04 ? ? 2009-09-08 ? ?2009-09-09 
?3.369247e-04 ?0.000000e+00 ?9.022183e-04 ?0.000000e+00 -1.105819e-04 ? ? ? ? ?-Inf 
? ?2009-09-10 ? ? ? 2009-09-11 ? ? ?2009-09-14 ? ?2009-09-15 ? ? ?2009-09-16 ? ? 2009-09-17 
?1.191271e-04 ?1.681718e-04 ? ? ? ?NaN ? ? ? ? ? ? 1.150126e-04 ?1.031037e-03 ?2.710993e-04 

I need to sum them up so I used "sum(Z, na.rm=TRUE)" to remove the NaN values but not for the Inf/-Inf. 

Hope it is clear to you. 

Cheers, 
R.L 
----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Tuesday, September 3, 2013 2:47 AM
Subject: Re: remove rows with infinite/nan values from a zoo dataset

Hi,
Please dput() the example dataset.? When I read from the one shown below, it looks a bit altered.

library(zoo)
dat1<- read.zoo(text="2009-07-15,#N/A N/A,#N/A N/A,18.96858
2009-07-16,20.30685,20.40664,#N/A N/A
2009-07-17,20.78813,20.03991,20.40664
2009-07-20,21.41278,21.41278,20.03991
2009-07-21,22.9963,22.98397,21.41278
2009-07-22,23.06443,23.01112,22.98397
2009-07-23,23.45905,24.72232,23.01112
2009-07-24,24.89291,25.56603,24.72232
2009-07-27,25.38929,24.80535,25.56603
2009-07-28,25.26712,25.65566,24.80535
2009-07-29,25.83884,24.98163,25.65566
2009-07-30,#N/A N/A,#N/A N/A,24.98163
2009-08-03,25.25553,25.93297,#N/A N/A
2009-08-04,26.02464,25.49159,25.93297
",sep=",",header=FALSE,FUN=as.Date,format="%Y-%m-%d",fill=TRUE) 


dput(dat1)? ###
structure(c(NA, 20.30685, 20.78813, 21.41278, 22.9963, 23.06443, 
23.45905, 24.89291, 25.38929, 25.26712, 25.83884, NA, 25.25553, 
26.02464, NA, 20.40664, 20.03991, 21.41278, 22.98397, 23.01112, 
24.72232, 25.56603, 24.80535, 25.65566, 24.98163, NA, 25.93297, 
25.49159, NA, NA, 20.40664, 20.03991, 21.41278, 22.98397, 23.01112, 
24.72232, 25.56603, 24.80535, 25.65566, NA, NA, 25.93297), .Dim = c(14L, 
3L), .Dimnames = list(NULL, c("V2", "V3", "V4")), index = structure(c(14440, 
14441, 14442, 14445, 14446, 14447, 14448, 14449, 14452, 14453, 
14454, 14455, 14459, 14460), class = "Date"), class = "zoo")


dat2<- dat1[!rowSums(is.na(dat1)),]
dat2
#???????????????? V2?????? V3?????? V4
#2009-07-17 20.78813 20.03991 20.40664
#2009-07-20 21.41278 21.41278 20.03991
#2009-07-21 22.99630 22.98397 21.41278
#2009-07-22 23.06443 23.01112 22.98397
#2009-07-23 23.45905 24.72232 23.01112
#2009-07-24 24.89291 25.56603 24.72232
#2009-07-27 25.38929 24.80535 25.56603
#2009-07-28 25.26712 25.65566 24.80535
#2009-07-29 25.83884 24.98163 25.65566
#2009-08-04 26.02464 25.49159 25.93297


dat2[1,2]<- Inf
?dat2[5,3]<- -Inf


dat2[rowSums(is.finite(dat2))==ncol(dat2),]
#???????????????? V2?????? V3?????? V4
#2009-07-20 21.41278 21.41278 20.03991
#2009-07-21 22.99630 22.98397 21.41278
#2009-07-22 23.06443 23.01112 22.98397
#2009-07-24 24.89291 25.56603 24.72232
#2009-07-27 25.38929 24.80535 25.56603
#2009-07-28 25.26712 25.65566 24.80535
#2009-07-29 25.83884 24.98163 25.65566
#2009-08-04 26.02464 25.49159 25.93297


A.K.

Hi There, 

I have a dataset with many rows and few columns as following: 

2009-07-15??? #N/A N/A??? #N/A N/A??? 18.96858 
2009-07-16??? 20.30685??? 20.40664??? #N/A N/A 
2009-07-17??? 20.78813??? 20.03991??? 20.40664 
2009-07-20??? 21.41278??? 21.41278??? 20.03991 
2009-07-21??? 22.9963??? 22.98397??? 21.41278 
2009-07-22??? 23.06443??? 23.01112??? 22.98397 
2009-07-23??? 23.45905??? 24.72232??? 23.01112 
2009-07-24??? 24.89291??? 25.56603??? 24.72232 
2009-07-27??? 25.38929??? 24.80535??? 25.56603 
2009-07-28??? 25.26712??? 25.65566??? 24.80535 
2009-07-29??? 25.83884??? 24.98163??? 25.65566 
2009-07-30??? #N/A N/A??? #N/A N/A??? 24.98163 
2009-08-03??? 25.25553??? 25.93297??? #N/A N/A 
2009-08-04??? 26.02464??? 25.49159??? 25.93297 

The class of the dataset is "zoo". My question might be stupid 
but could anyone suggest a way to remove the rows with #N/A values? 
I tried "rapply" command but it didn't work due to the data class. 

btw, how about for the "Inf" values? 

Thank you in advance!


From S.Ellison at lgcgroup.com  Wed Sep  4 16:43:33 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Wed, 4 Sep 2013 15:43:33 +0100
Subject: [R] mean
In-Reply-To: <1377865093652-4674999.post@n4.nabble.com>
References: <1377865093652-4674999.post@n4.nabble.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED50B466E108@GOLD.corp.lgc-group.com>

 

> -----Original Message-----
> When I try to apply mean to a list, I get the answer :
> 
> argument is not numeric or logical: returning NA
> 
Example: 
l4 <- list(1:4)
class(l4) #not numeric or logical ...
mean(l4) #same error

#a list is not a number, a logical (TRUE/FALSE) or a vector or array of either of those. So mean() can't handle it unaided and tells you what it needs.

#But if your list is a list of numeric objects, unlist will often work.

unlist(l4) #a numeric vector
mean( unlist(l4) ) #no problem

l.some <- list(matrix(1:4, ncol=2), 3:7)
l.some
unlist(l.some) #a numeric vector
mean( unlist(l.some) ) #works

#But a) magic has limits and b) if you want averages, maybe you should not be using a list? A vector would save hassle if it fits ...

S Ellison

*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From kristi.glover at hotmail.com  Wed Sep  4 16:48:20 2013
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Wed, 4 Sep 2013 11:48:20 -0300
Subject: [R] would you give me hints in r?
In-Reply-To: <CAM_vjunZENqzKrJzhE76BQwm4n_1Aaw8RmrmKW1QkdN5TimtvQ@mail.gmail.com>
References: <COL129-W481B59502C8BB82B1BB3F1FA320@phx.gbl>,
	<52273C59.9030601@sapo.pt>,
	<COL129-W77A875219094E51E9E4DEFFA320@phx.gbl>,
	<CAM_vjunZENqzKrJzhE76BQwm4n_1Aaw8RmrmKW1QkdN5TimtvQ@mail.gmail.com>
Message-ID: <COL129-W11F5A33B44601A5215B64EFA320@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130904/8e0b9998/attachment.pl>

From simon.pickert at t-online.de  Wed Sep  4 17:17:13 2013
From: simon.pickert at t-online.de (Simon Pickert)
Date: Wed, 4 Sep 2013 17:17:13 +0200
Subject: [R] Placeholders for String Operations
Message-ID: <973E49AF-65CA-402A-A3F7-7DBB76AF7F61@t-online.de>

Hi all,

what are the placeholders for string operations/modifications? Is there a placeholder for numbers, which would allow me to easily replace all numbers in a string? Something like

text1 <- c("this is a number 23%")
text2 <- c("this is not a number bla%")

newtext1 <- gsub(#%, [percentagevalue], text) 
newtext2 <- gsub(#%, [percentagevalue], text) 


newtext1  should be "this is a number [percentagevalue]"
newtext2  should be "this is not a number 23%"


I figured there is * ? . but I can't find a source that explains their use and lists other placeholders..


Appreciate your help!
Thanks
Simon

From lucien.blandenier at unine.ch  Wed Sep  4 17:05:03 2013
From: lucien.blandenier at unine.ch (BLANDENIER Lucien)
Date: Wed, 4 Sep 2013 15:05:03 +0000
Subject: [R] Problem with installing the TRR package
Message-ID: <84F1DDBD03D55944AA4E63A2FE5EADE5530860B8@MAIL-MBX-05.UNINE.CH>

Dear all,

I met some problems trying to install the TRR package.

I runed the command : install.packages("TRR")


I've received the following message :

In getDependencies(pkgs, dependencies, available, lib) :
  package ?TRR? is not available (for R version 2.14.1)

I'm in Linux Mint and it seems it that the R 2.14.1 is the latest version.

Does someones could give some guidance how to install the TRR package?

Regards


Lucien


From lucien.blandenier at unine.ch  Wed Sep  4 17:09:36 2013
From: lucien.blandenier at unine.ch (BLANDENIER Lucien)
Date: Wed, 4 Sep 2013 15:09:36 +0000
Subject: [R] Problem with installing the TRR package
In-Reply-To: <84F1DDBD03D55944AA4E63A2FE5EADE5530860B8@MAIL-MBX-05.UNINE.CH>
References: <84F1DDBD03D55944AA4E63A2FE5EADE5530860B8@MAIL-MBX-05.UNINE.CH>
Message-ID: <84F1DDBD03D55944AA4E63A2FE5EADE5530860E4@MAIL-MBX-05.UNINE.CH>


Dear all,

I met some problems trying to install the TRR package.

I runed the command : install.packages("TRR")


I've received the following message :

In getDependencies(pkgs, dependencies, available, lib) :
  package ?TRR? is not available (for R version 2.14.1)

I'm in Linux Mint and it seems it that the R 2.14.1 is the latest version.

Does someones could give some guidance how to install the TRR package?

Regards


Lucien


From jrkrideau at inbox.com  Wed Sep  4 17:31:22 2013
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 4 Sep 2013 07:31:22 -0800
Subject: [R] Problem with installing the TRR package
In-Reply-To: <84F1DDBD03D55944AA4E63A2FE5EADE5530860B8@MAIL-MBX-05.UNINE.CH>
Message-ID: <757E37E70E2.000007DEjrkrideau@inbox.com>

The latest release (2013-05-16, Good Sport) R-3.0.1 so perhaps you need to upgrade to 3.0.1?

John Kane
Kingston ON Canada


> -----Original Message-----
> From: lucien.blandenier at unine.ch
> Sent: Wed, 4 Sep 2013 15:05:03 +0000
> To: r-help at r-project.org
> Subject: [R] Problem with installing the TRR package
> 
> Dear all,
> 
> I met some problems trying to install the TRR package.
> 
> I runed the command : install.packages("TRR")
> 
> 
> I've received the following message :
> 
> In getDependencies(pkgs, dependencies, available, lib) :
>   package ?TRR? is not available (for R version 2.14.1)
> 
> I'm in Linux Mint and it seems it that the R 2.14.1 is the latest
> version.
> 
> Does someones could give some guidance how to install the TRR package?
> 
> Regards
> 
> 
> Lucien
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From deter088 at umn.edu  Wed Sep  4 17:32:05 2013
From: deter088 at umn.edu (Charles Determan Jr)
Date: Wed, 4 Sep 2013 10:32:05 -0500
Subject: [R] glmnet lambda and number of variables
Message-ID: <CAOLJphnD_zd2dWMCz2z142yKU=YLdD5oJeChJ=fGDZGECG+XVA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130904/a2948ab8/attachment.pl>

From smartpink111 at yahoo.com  Wed Sep  4 17:35:35 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 4 Sep 2013 08:35:35 -0700 (PDT)
Subject: [R] Placeholders for String Operations
In-Reply-To: <973E49AF-65CA-402A-A3F7-7DBB76AF7F61@t-online.de>
References: <973E49AF-65CA-402A-A3F7-7DBB76AF7F61@t-online.de>
Message-ID: <1378308935.27602.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
?gsub("#%", "[percentagevalue]", text1) 
#[1] "this is a number 23%"


?gsub("\\d+%$", "[percentagevalue]", text1) 
#[1] "this is a number [percentagevalue]"


?gsub("bla", "23", text2) 
#[1] "this is not a number 23%"
A.K.



----- Original Message -----
From: Simon Pickert <simon.pickert at t-online.de>
To: r-help at r-project.org
Cc: 
Sent: Wednesday, September 4, 2013 11:17 AM
Subject: [R] Placeholders for String Operations

Hi all,

what are the placeholders for string operations/modifications? Is there a placeholder for numbers, which would allow me to easily replace all numbers in a string? Something like

text1 <- c("this is a number 23%")
text2 <- c("this is not a number bla%")

newtext1 <- gsub(#%, [percentagevalue], text) 
newtext2 <- gsub(#%, [percentagevalue], text) 


newtext1? should be "this is a number [percentagevalue]"
newtext2? should be "this is not a number 23%"


I figured there is * ? . but I can't find a source that explains their use and lists other placeholders..


Appreciate your help!
Thanks
Simon
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From sarah.goslee at gmail.com  Wed Sep  4 17:52:09 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 4 Sep 2013 11:52:09 -0400
Subject: [R] Placeholders for String Operations
In-Reply-To: <973E49AF-65CA-402A-A3F7-7DBB76AF7F61@t-online.de>
References: <973E49AF-65CA-402A-A3F7-7DBB76AF7F61@t-online.de>
Message-ID: <CAM_vjunRxRzCHx9G8PJZa9amZH8a-_rZ=52paa5hwKxDV5FYjQ@mail.gmail.com>

Hi Simon,

What you need are regular expressions.

The help for gsub says this, but in such a way that if you didn't know
that's what you were looking for, you wouldn't learn it there:

     See the help pages on regular expression for details of the
     different types of regular expressions.

The See Also section has a better clue:

     regular expression (aka ?regexp?) for the details of the pattern
     specification.

?regexp has a fairly terse explanation. I'd look at some of the many
guides to regular expressions online, and use ?regexp mainly for how
the R implementation differs from standard (mostly in the use of \).
The help page does list all the groups, which is what you wanted.

Sarah

On Wed, Sep 4, 2013 at 11:17 AM, Simon Pickert
<simon.pickert at t-online.de> wrote:
> Hi all,
>
> what are the placeholders for string operations/modifications? Is there a placeholder for numbers, which would allow me to easily replace all numbers in a string? Something like
>
> text1 <- c("this is a number 23%")
> text2 <- c("this is not a number bla%")
>
> newtext1 <- gsub(#%, [percentagevalue], text)
> newtext2 <- gsub(#%, [percentagevalue], text)
>
>
> newtext1  should be "this is a number [percentagevalue]"
> newtext2  should be "this is not a number 23%"
>
>
> I figured there is * ? . but I can't find a source that explains their use and lists other placeholders..
>
>
> Appreciate your help!
> Thanks
> Simon
-- 
Sarah Goslee
http://www.functionaldiversity.org


From wdunlap at tibco.com  Wed Sep  4 18:24:09 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 4 Sep 2013 16:24:09 +0000
Subject: [R] optim  evils
In-Reply-To: <1378283694.77272.YahooMailNeo@web193402.mail.sg3.yahoo.com>
References: <1378283694.77272.YahooMailNeo@web193402.mail.sg3.yahoo.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C3405BA@PA-MBX01.na.tibco.com>

> This is not efficient.

For whom?

> (a) L-BFGS-B does not identify itself even though it was called overriding the method
> parameter in optim.

Would you prefer that the warning 
  > o <- optim(par=c(1,2), fn=function(x)-sum(abs(sin(x))), method="CG", lower=c(-1,-1), upper= c(2,3))
  Warning message:
  In optim(par = c(1, 2), fn = function(x) -sum(abs(sin(x))), method = "CG",  :
    bounds can only be used with method L-BFGS-B (or Brent)
explicitly say that method L-BFGS-B was used because bounds were given?

> (b) Optim  reports as final converged minimum value a function value that is much larger
> than others computed during the optimization.

That is where a self-contained example would make it much quicker to identify and perhaps fix the problem.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Michael Meyer
> Sent: Wednesday, September 04, 2013 1:35 AM
> To: r-help at r-project.org
> Subject: [R] optim evils
> 
> It would take some effort to extract selfcontained code from the mass of code wherein
> this optimization is embedded. Moreover I would have to obtain permission from my
> employer to do so.
> 
> This is not efficient.
> However some things are evident from the trace log which I have submitted:
> (a) L-BFGS-B does not identify itself even though it was called overriding the method
> parameter in optim.
> (b) Optim? reports as final converged minimum value a function value that is much larger
> than
> others computed during the optimization.
> 
> I think we can agree on calling this a bug.
> 	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Wed Sep  4 18:36:59 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 04 Sep 2013 17:36:59 +0100
Subject: [R] Placeholders for String Operations
In-Reply-To: <973E49AF-65CA-402A-A3F7-7DBB76AF7F61@t-online.de>
References: <973E49AF-65CA-402A-A3F7-7DBB76AF7F61@t-online.de>
Message-ID: <522761AB.3020107@sapo.pt>

Hello,

I'm not sure I understand, but if you want a ?regexp to only match 
numbers before a %, try the following.


gsub("[0-9]+%", "[percentagevalue]", text1)
gsub("[0-9]+%", "[percentagevalue]", text2)


[0-9] matches any character in the range from 0 to 9, and the + means to 
repeat that character any number of times. See the help page for ?regexp.

Hope this helps,

Rui Barradas

Em 04-09-2013 16:17, Simon Pickert escreveu:
> Hi all,
>
> what are the placeholders for string operations/modifications? Is there a placeholder for numbers, which would allow me to easily replace all numbers in a string? Something like
>
> text1 <- c("this is a number 23%")
> text2 <- c("this is not a number bla%")
>
> newtext1 <- gsub(#%, [percentagevalue], text)
> newtext2 <- gsub(#%, [percentagevalue], text)
>
>
> newtext1  should be "this is a number [percentagevalue]"
> newtext2  should be "this is not a number 23%"
>
>
> I figured there is * ? . but I can't find a source that explains their use and lists other placeholders..
>
>
> Appreciate your help!
> Thanks
> Simon
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From helios.derosario at ibv.upv.es  Wed Sep  4 19:05:32 2013
From: helios.derosario at ibv.upv.es (Helios de Rosario)
Date: Wed, 04 Sep 2013 19:05:32 +0200
Subject: [R] outliers for Likert scale data
Message-ID: <5227847C0200000C00017A57@mailhost.biomec.upv.es>

>>> El d?a 01/09/2013 a las 15:13, Helen Sawaya
<helensawaya at hotmail.com>
escribi?:
> Dear R experts,
> I have data from a questionnaire that I would like to factor analyse.
It is 
> in a likert scale form (0-3). I would like to check first for
univariate and 
> multivariate outliers but the most common ways of doing so assume the
data is 
> continuous and normal- neither of which is the case here. I found an
article 
> discussing this (Outlier Detection in Test and Questionnaire Data by
Wobbe P. 
> Zijlstra, L. Andries van der Ark, and Klaas Sijtsma), but I was
wondering if 
> I could get the exact R code on how to implement the outlier
detection 
> analyses.

I have not found an exact implementation of that article, but one of
its authors (van den Ark) has published the "mokken" package with some
methods referred to in it:
https://sites.google.com/a/tilburguniversity.edu/avdrark/mokken

The ESD method for identifying outliers, also used in the paper to
handle outlier scores, is implemented (together with others) in the
package "parody":
http://www.bioconductor.org/packages/release/bioc/html/parody.html

Hope it helps
Helios De Rosario


INSTITUTO DE BIOMEC?NICA DE VALENCIA
Universidad Polit?cnica de Valencia ? Edificio 9C
Camino de Vera s/n ? 46022 VALENCIA (ESPA?A)
Tel. +34 96 387 91 60 ? Fax +34 96 387 91 69
www.ibv.org

  Antes de imprimir este e-mail piense bien si es necesario hacerlo.
En cumplimiento de la Ley Org?nica 15/1999 reguladora de la Protecci?n
de Datos de Car?cter Personal, le informamos de que el presente mensaje
contiene informaci?n confidencial, siendo para uso exclusivo del
destinatario arriba indicado. En caso de no ser usted el destinatario
del mismo le informamos que su recepci?n no le autoriza a su divulgaci?n
o reproducci?n por cualquier medio, debiendo destruirlo de inmediato,
rog?ndole lo notifique al remitente.


From jvadams at usgs.gov  Wed Sep  4 19:14:12 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 4 Sep 2013 12:14:12 -0500
Subject: [R] Permuting friendship nominations in a social network
In-Reply-To: <635E18A9-0895-462D-8ED6-C6FB5B82CBE3@gmail.com>
References: <635E18A9-0895-462D-8ED6-C6FB5B82CBE3@gmail.com>
Message-ID: <CAN5YmCG2S0WZfQsyus6Qh_UXou_-uVJejv7E-ntWdknkxwG5FQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130904/31ee9074/attachment.pl>

From Hui.Du at dataventures.com  Wed Sep  4 19:57:19 2013
From: Hui.Du at dataventures.com (Hui Du)
Date: Wed, 4 Sep 2013 17:57:19 +0000
Subject: [R] 'snow' package -- parallel process
Message-ID: <13A371591163EE48BD95F2D2B244AAF41C1AE857@SNICKERS.dataventures.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130904/815a60db/attachment.pl>

From hollymaya at gmail.com  Wed Sep  4 20:01:33 2013
From: hollymaya at gmail.com (hollymaya)
Date: Wed, 4 Sep 2013 11:01:33 -0700
Subject: [R] Permuting friendship nominations in a social network
In-Reply-To: <CAN5YmCG2S0WZfQsyus6Qh_UXou_-uVJejv7E-ntWdknkxwG5FQ@mail.gmail.com>
References: <635E18A9-0895-462D-8ED6-C6FB5B82CBE3@gmail.com>
	<CAN5YmCG2S0WZfQsyus6Qh_UXou_-uVJejv7E-ntWdknkxwG5FQ@mail.gmail.com>
Message-ID: <10C2CACF-2CDD-4DAF-8B29-E36F4A11BE09@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130904/0f2efe56/attachment.pl>

From ripley at stats.ox.ac.uk  Wed Sep  4 20:30:25 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 04 Sep 2013 19:30:25 +0100
Subject: [R] 'snow' package -- parallel process
In-Reply-To: <13A371591163EE48BD95F2D2B244AAF41C1AE857@SNICKERS.dataventures.local>
References: <13A371591163EE48BD95F2D2B244AAF41C1AE857@SNICKERS.dataventures.local>
Message-ID: <52277C41.9000308@stats.ox.ac.uk>

On 04/09/2013 18:57, Hui Du wrote:
>
>
> Hi R-community:
> I heard 'snow' package is a good tool to parallelize processes and speed them up. I tried to use it but was not successful. Could someboy point where I was wrong? Thanks.
> I want to read a HUGE file to R and hope 'snow' helps me to speed it up. Here are codes:

Why are you not using package 'parallel'?

But read the help for clusterApply: you have the arguments wrong.

And please do read the 'R Data Import/Export' manual and get read.delim 
working optimally first.

> library(snow)
>
> iFile = 'BIG.FILE.txt'
>
> numCluster = 4;
> readFile = function(file)
> {
>      orig_d = read.delim(file);
>      orig_d;
> }
> cl = makeCluster(numCluster, type = "SOCK");
> x = clusterApply(cl, readFile, iFile);
>
> I got the error
>
> Error in x[[i]] : object of type 'closure' is not subsettable
>
> I also tried to read multiple files once
>
> filenames = rep(iFile, numCluster);
> x = clusterApply(cl, readFile, filenames);
> stopCluster(cl);
>
> and got the same error
>
> Thanks you for your help.
> HXD
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pmassicotte at hotmail.com  Wed Sep  4 20:34:18 2013
From: pmassicotte at hotmail.com (philippe massicotte)
Date: Wed, 4 Sep 2013 18:34:18 +0000
Subject: [R] Histogram
Message-ID: <COL127-W49B3E97D4ABD80B64BCFEBB3320@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130904/2fd31772/attachment.pl>

From dcarlson at tamu.edu  Wed Sep  4 21:18:35 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Wed, 4 Sep 2013 14:18:35 -0500
Subject: [R] Histogram
In-Reply-To: <COL127-W49B3E97D4ABD80B64BCFEBB3320@phx.gbl>
References: <COL127-W49B3E97D4ABD80B64BCFEBB3320@phx.gbl>
Message-ID: <041d01cea9a3$8d4e10b0$a7ea3210$@tamu.edu>

We can just ask hist():

? hist

. . . 

breaks 	

one of:

    a vector giving the breakpoints between histogram cells,

    a function to compute the vector of breakpoints,

    a single number giving the number of cells for the
histogram,
================================================================
=
    a character string naming an algorithm to compute the number
of cells (see 'Details'),

    a function to compute the number of cells.

In the last three cases the number is a suggestion only.
========================================================

In this case hist has decided to ignore you. You can overrule by
specifying the breaks:

hist(1:10, 0:10+.5)

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352





-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of philippe
massicotte
Sent: Wednesday, September 4, 2013 1:34 PM
To: r-help at R-project.org
Subject: [R] Histogram

Hi everyone.
I'm currently translating some Matlab code into R. However, I
realized that the hsit function produce different results in
both languages.
in Matlab, hist(1:10, 10) will produce 10 bins with a count of 1
in each, but in R it will produce 9 classes with count of
2,1,1,1,1,1,1,1,1.
I'm a bit embarrassed to ask such question, but why R is not
producing 10 classes as requested?
Thanks in advance,Phil 		 	   		  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From ruipbarradas at sapo.pt  Wed Sep  4 21:27:36 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 04 Sep 2013 20:27:36 +0100
Subject: [R] Histogram
In-Reply-To: <COL127-W49B3E97D4ABD80B64BCFEBB3320@phx.gbl>
References: <COL127-W49B3E97D4ABD80B64BCFEBB3320@phx.gbl>
Message-ID: <522789A8.8070800@sapo.pt>

Hello,

See the arguments 'right' and 'include.lowest' of ?hist.
To give what you want, try instead

h1 <- hist(1:10, 10)  # counts are 2, 1, 1, ...
h2 <- hist(1:10, breaks = 0:10)  # all counts are 1


and see the difference between h1 and h2, components 'breaks' and 'counts'.

Hope this helps,

Rui Barradas

Em 04-09-2013 19:34, philippe massicotte escreveu:
> Hi everyone.
> I'm currently translating some Matlab code into R. However, I realized that the hsit function produce different results in both languages.
> in Matlab, hist(1:10, 10) will produce 10 bins with a count of 1 in each, but in R it will produce 9 classes with count of 2,1,1,1,1,1,1,1,1.
> I'm a bit embarrassed to ask such question, but why R is not producing 10 classes as requested?
> Thanks in advance,Phil 		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jfrei006 at fiu.edu  Wed Sep  4 19:35:38 2013
From: jfrei006 at fiu.edu (jfrei006)
Date: Wed, 4 Sep 2013 10:35:38 -0700 (PDT)
Subject: [R] Linear Regression line equation
Message-ID: <1378316138003-4675375.post@n4.nabble.com>

First of I am new to using R.

I have a dataset that I plotted using R, I created a scatter plot and used
abline to create the line, what I need is to find the equation of the line.
Below is the script I have used up until this point.

>young400_1<-read.csv("Z:\\SOFTEL\\North Key Largo
project\\Canopy_Height\\random_age_strat\\young400_1.csv")

>attach(young400_1)
>names(young400_1)

>plot(Ground_Elevation,Canopy_Height,pch=16)

>abline(lm(Canopy_Height~Ground_Elevation), col='red', main='Check the axis
labels')

This is where I'm stuck I don't know how to go about getting the equation to
the line.

My dataset is called young400_1 and it consist of 400 rows with 5 columns, I
am only using 2 of the columns for the scatter plot; Ground_Elevation on the
x axis and Canopy_Height on the y axis. 

Thanks in advance.










--
View this message in context: http://r.789695.n4.nabble.com/Linear-Regression-line-equation-tp4675375.html
Sent from the R help mailing list archive at Nabble.com.


From lross8 at kent.edu  Wed Sep  4 21:22:48 2013
From: lross8 at kent.edu (lross8)
Date: Wed, 4 Sep 2013 12:22:48 -0700 (PDT)
Subject: [R] Attribute Length Error when Trying plm Regression
Message-ID: <1378322567885-4675384.post@n4.nabble.com>

Hello,

I am trying to run a fixed effects panel regression on data containing 5
columns and 1,494 rows. 

I read the data in as follows:

>drugsXX<-read.csv(file="C:\\Folder\\vX.X\\Drugs\\drugsXX_panel.csv",
head=TRUE, sep=",")

Verified it read in correctly and had a good data.frame:
>dim(drugsXX)
[1] 1494    5
>drugs XX
produce expected data with correct column names

The issue is, when I go to run the plm using:
>fixed <- plm (h ~ o + m + a, data=drugsXX, index=c("h","year"),
model="within") 

I get this error:
Error in names(y) <- namesy : 
  'names' attribute [996] must be the same length as the vector [0]

I know the data recognizes that I have 5 columns. I also know that there's
nothing wrong with row 996 (I even want back and checked for hidden
characters in the original .csv file).

traceback() was useless:
4: pmodel.response.pFormula(formula, data, model = model, effect = effect, 
       theta = theta)
3: pmodel.response(formula, data, model = model, effect = effect, 
       theta = theta)
2: plm.fit(formula, data, model, effect, random.method, inst.method)
1: plm(h ~ o + m + a, data = drugsXX, index = c("h", 
       "year"), model = "within")

What explicit steps can I follow to get my panel regression to run? 

Thank you, 
Laura



--
View this message in context: http://r.789695.n4.nabble.com/Attribute-Length-Error-when-Trying-plm-Regression-tp4675384.html
Sent from the R help mailing list archive at Nabble.com.


From sarah.goslee at gmail.com  Wed Sep  4 21:46:17 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 4 Sep 2013 15:46:17 -0400
Subject: [R] Linear Regression line equation
In-Reply-To: <1378316138003-4675375.post@n4.nabble.com>
References: <1378316138003-4675375.post@n4.nabble.com>
Message-ID: <CAM_vjunujHMjgNJf5+Lm8WvjAttLJMLi7DvyPF09xgHyZbjCow@mail.gmail.com>

summary(lm(Canopy_Height~Ground_Elevation, data=young400_1)) #use
data= instead of attach!

Or even

mylm <- lm(Canopy_Height~Ground_Elevation, data=young400_1)
mylm
summary(mylm)
coefficients(mylm)

Most intro to R guides cover the basics of modeling; you might benefit
from reading one of them.

Sarah


On Wed, Sep 4, 2013 at 1:35 PM, jfrei006 <jfrei006 at fiu.edu> wrote:
> First of I am new to using R.
>
> I have a dataset that I plotted using R, I created a scatter plot and used
> abline to create the line, what I need is to find the equation of the line.
> Below is the script I have used up until this point.
>
>>young400_1<-read.csv("Z:\\SOFTEL\\North Key Largo
> project\\Canopy_Height\\random_age_strat\\young400_1.csv")
>
>>attach(young400_1)
>>names(young400_1)
>
>>plot(Ground_Elevation,Canopy_Height,pch=16)
>
>>abline(lm(Canopy_Height~Ground_Elevation), col='red', main='Check the axis
> labels')
>
> This is where I'm stuck I don't know how to go about getting the equation to
> the line.
>
> My dataset is called young400_1 and it consist of 400 rows with 5 columns, I
> am only using 2 of the columns for the scatter plot; Ground_Elevation on the
> x axis and Canopy_Height on the y axis.
>
> Thanks in advance.
>
>
>
>
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From macqueen1 at llnl.gov  Wed Sep  4 21:51:28 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 4 Sep 2013 19:51:28 +0000
Subject: [R] for loop of a geometric sequence
In-Reply-To: <1377881851086-4675035.post@n4.nabble.com>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521910D429CEB@PRDEXMBX-08.the-lab.llnl.gov>

So look at the examples found in
  ?Control
and give it a try.

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 8/30/13 9:57 AM, "BJN1417" <BJN1417 at uncw.edu> wrote:

>so I have to create a for loop of the geometric sequence
>h(x,n)=1+x+x^2+x^3^4...x^n.  I know that it would be easier to simply
>vectorize the sequence to x^(0:n), but I am required to make the loop,
>and I
>can't wrap my brain around how to loop it because the equation  is so
>simple.
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/for-loop-of-a-geometric-sequence-tp4675035.h
>tml
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pmassicotte at hotmail.com  Wed Sep  4 22:02:20 2013
From: pmassicotte at hotmail.com (philippe massicotte)
Date: Wed, 4 Sep 2013 20:02:20 +0000
Subject: [R] Histogram
In-Reply-To: <522789A8.8070800@sapo.pt>
References: <COL127-W49B3E97D4ABD80B64BCFEBB3320@phx.gbl>,
	<522789A8.8070800@sapo.pt>
Message-ID: <COL127-W22EB827D05EAFB3CAC73B1B3320@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130904/3426cf09/attachment.pl>

From smartpink111 at yahoo.com  Wed Sep  4 22:05:18 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 4 Sep 2013 13:05:18 -0700 (PDT)
Subject: [R] Random products of rows in a matrix
In-Reply-To: <1378318525.51115.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <CAFsztN6ApLCJHoE0v1=p2ECoyMLTDotmF=PusCnsRmePvO8LFg@mail.gmail.com>
	<03ae01cea97b$e9716f40$bc544dc0$@tamu.edu>
	<1378306371.63210.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CAFsztN5eq9G2_P0K4avkfyxgecOw-jiEojSJ9B--svGuJGJavw@mail.gmail.com>
	<1378309098.3756.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CAFsztN7jUc=aAYid=9_Qn3ZJqQ5BKAS3E=-5rkQxZb3tCz4J7Q@mail.gmail.com>
	<1378318525.51115.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1378325118.66397.YahooMailNeo@web142601.mail.bf1.yahoo.com>



Hi Edouard,

In terms of speed, your new solution may not be that much different from the old one:

#####large matrix
M<- 10
N<- 1e3
set.seed(249)
A<- matrix(sample(1:10,1e5*4,replace=TRUE),1e5,4)
B<- matrix(NA,ncol=ncol(A),nrow=0)
system.time({
set.seed(54)
for (i in 1 : N) B <- rbind(B, apply(A[sample(1 : nrow(A), M, replace = T),], 2, prod))
})
?# user? system elapsed 
?# 0.240?? 0.048?? 0.290 


system.time({
set.seed(54)
res<- do.call(rbind,lapply(1:N,function(x) {A1<-A[sample.int(nrow(A),M,replace=TRUE),]; tapply(as.vector(A1),list(rep(seq_len(ncol(A1)),each=nrow(A1))),prod)}))
})
#? user? system elapsed 
#? 0.300?? 0.000?? 0.302 


?dimnames(res)<- dimnames(B)
?identical(res,B)
#[1] TRUE

B1<- matrix(NA,ncol=ncol(A),nrow=0)
system.time({
set.seed(54)
for(i in 1:N) {
A1<-A[sample.int(nrow(A),M,replace=TRUE),]
B1<- rbind(B1,tapply(as.vector(A1),list(rep(seq_len(ncol(A1)),each=nrow(A1))),prod))
}
})
# user? system elapsed 
#? 0.312?? 0.008?? 0.318 


system.time({
set.seed(54)
l<-tapply(rep(M,N),1:N,function(x){A[sample(1:nrow(A), M, replace = T), ]})
B2<-t(sapply(l,apply,2,prod))
})
#? user? system elapsed 
#? 0.156?? 0.136?? 0.290 

dimnames(B1)<- dimnames(B2)
?identical(B1,B2)
#[1] TRUE
library(matrixStats)
system.time({
set.seed(54)
B3<-do.call(rbind, lapply(1:N, function(x)
colProds(A[sample.int(nrow(A), M, replace=TRUE),])))
})
#? user? system elapsed 
#? 0.152?? 0.000?? 0.155 
dimnames(B3)<- dimnames(B2)
?all.equal(B2,B3)
#[1] TRUE
A.K.



________________________________
From: Edouard Hardy <hardy.edouard at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Wednesday, September 4, 2013 1:31 PM
Subject: Re: [R] Random products of rows in a matrix



I am not allowed to.
I found a solution :
l<-tapply(rep(M,N),1:N,function(x){A[sample(1 : nrow(A), M, replace = T), ]})
t(sapply(l,apply,2,prod))



Edouard Hardy



On Wed, Sep 4, 2013 at 5:38 PM, arun <smartpink111 at yahoo.com> wrote:

No problem.
>Can I know the reason?
>Tx.
>
>
>
>
>
>
>
>________________________________
>From: Edouard Hardy <hardy.edouard at gmail.com>
>To: arun <smartpink111 at yahoo.com>
>Cc: "dcarlson at tamu.edu" <dcarlson at tamu.edu>
>Sent: Wednesday, September 4, 2013 11:32 AM
>
>Subject: Re: [R] Random products of rows in a matrix
>
>
>
>Hello and thank you for your help.
>Unfortunately, I cannot use any package...
>
>
>
>Edouard Hardy
>
>
>
>On Wed, Sep 4, 2013 at 4:52 PM, arun <smartpink111 at yahoo.com> wrote:
>
>
>>
>>HI Edouard,
>>
>>Is there any limitations in installing a package?
>>
>>Using David's solution, if you could install,
>>library(matrixStats)
>>set.seed(28)
>>?A<- matrix(sample(1:10,5*4,replace=TRUE),5,4)
>>
>>B <- matrix(NA, ncol = ncol(A), nrow = 0)
>>N<- 3
>>M<- nrow(A)
>>set.seed(54)
>>
>>for (i in 1 : N) B <- rbind(B, apply(A[sample(1 : nrow(A), M, replace = T),
>>], 2, prod))
>>
>>?set.seed(54)
>>?B1<- do.call(rbind, lapply(1:N, function(x)
>>?colProds(A[sample.int(nrow(A), M, replace=TRUE),])))
>>?all.equal(B,B1)
>>#[1] TRUE
>>A.K.
>>
>>
>>
>>
>>----- Original Message -----
>>From: David Carlson <dcarlson at tamu.edu>
>>To: 'Edouard Hardy' <hardy.edouard at gmail.com>; 'R help' <r-help at r-project.org>
>>Cc:
>>Sent: Wednesday, September 4, 2013 10:34 AM
>>Subject: Re: [R] Random products of rows in a matrix
>>
>>Actually you have two loops, the for() loop you created and the
>>loop that is hidden inside apply(). You can hide the first loop
>>with lapply() or sapply():
>>
>>B <- do.call(rbind, lapply(1:N, function(x)
>>colSums(A[sample.int(nrow(A), M, replace=TRUE),])))
>>
>>Or
>>
>>B <- t(sapply(1:N, function(x) colSums(A[sample.int(nrow(A), M,
>>replace=TRUE),])))
>>
>>You could eliminate the apply() loop by taking log(A), using
>>colSums(), and then converting back with exp().
>>
>>-------------------------------------
>>David L Carlson
>>Associate Professor of Anthropology
>>Texas A&M University
>>College Station, TX 77840-4352
>>
>>-----Original Message-----
>>From: r-help-bounces at r-project.org
>>[mailto:r-help-bounces at r-project.org] On Behalf Of Edouard Hardy
>>Sent: Wednesday, September 4, 2013 2:59 AM
>>To: R help
>>Subject: [R] Random products of rows in a matrix
>>
>>Hello everybody,
>>
>>Without any loop and any package,
>>
>>I would like to return N products of M rows in a matrix A :
>>
>>Today, I managed to do it with a loop :
>>
>>B <- matrix(NA, ncol = ncol(A), nrow = 0)
>>for (i in 1 : N) B <- rbind(B, apply(A[sample(1 : nrow(A), M,
>>replace = T),
>>], 2, prod))
>>
>>Do you have a solution ?
>>
>>Thank you in advance !
>>
>>??? [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible
>>code.
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>>
>>
>


From murdoch.duncan at gmail.com  Wed Sep  4 22:25:16 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 04 Sep 2013 16:25:16 -0400
Subject: [R] Histogram
In-Reply-To: <COL127-W22EB827D05EAFB3CAC73B1B3320@phx.gbl>
References: <COL127-W49B3E97D4ABD80B64BCFEBB3320@phx.gbl>,
	<522789A8.8070800@sapo.pt>
	<COL127-W22EB827D05EAFB3CAC73B1B3320@phx.gbl>
Message-ID: <5227972C.1070907@gmail.com>

On 04/09/2013 4:02 PM, philippe massicotte wrote:
> Thank you everyone.
> Try executing this:
> replicate(100, length(hist(rnorm(100), nclass = 10)$counts))
> I'm still not sure why the number of bins (classes) is not consistent.

R is behaving as documented.  You suggested 10 bins, but it finds for 
some datasets that a smaller or larger number gives better results.  If 
you really want exactly 10 bins, then specify where you want them.

Duncan Murdoch
> Thank in advance.
>
> > Date: Wed, 4 Sep 2013 20:27:36 +0100
> > From: ruipbarradas at sapo.pt
> > To: pmassicotte at hotmail.com
> > CC: r-help at r-project.org
> > Subject: Re: [R] Histogram
> >
> > Hello,
> >
> > See the arguments 'right' and 'include.lowest' of ?hist.
> > To give what you want, try instead
> >
> > h1 <- hist(1:10, 10)  # counts are 2, 1, 1, ...
> > h2 <- hist(1:10, breaks = 0:10)  # all counts are 1
> >
> >
> > and see the difference between h1 and h2, components 'breaks' and 'counts'.
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > Em 04-09-2013 19:34, philippe massicotte escreveu:
> > > Hi everyone.
> > > I'm currently translating some Matlab code into R. However, I realized that the hsit function produce different results in both languages.
> > > in Matlab, hist(1:10, 10) will produce 10 bins with a count of 1 in each, but in R it will produce 9 classes with count of 2,1,1,1,1,1,1,1,1.
> > > I'm a bit embarrassed to ask such question, but why R is not producing 10 classes as requested?
> > > Thanks in advance,Phil 		 	   		
> > > 	[[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
>   		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Wed Sep  4 22:27:43 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 4 Sep 2013 16:27:43 -0400
Subject: [R] Histogram
In-Reply-To: <COL127-W22EB827D05EAFB3CAC73B1B3320@phx.gbl>
References: <COL127-W49B3E97D4ABD80B64BCFEBB3320@phx.gbl>
	<522789A8.8070800@sapo.pt>
	<COL127-W22EB827D05EAFB3CAC73B1B3320@phx.gbl>
Message-ID: <CA+vqiLHnPR7N=ZtkhCo8SCBv0ecXk8G=-t=MWp=z-DjJEsJR7A@mail.gmail.com>

On Wed, Sep 4, 2013 at 4:02 PM, philippe massicotte
<pmassicotte at hotmail.com> wrote:
> Thank you everyone.
> Try executing this:
> replicate(100, length(hist(rnorm(100), nclass = 10)$counts))
> I'm still not sure why the number of bins (classes) is not consistent.

It depends on the range of x. If you look at the definition of the
hist function (just type "hist.default" at the prompt) you will find
that when breaks are specified as a single number they are calculated
using

pretty(range(x), n = breaks)

see ?pretty for details.

Best,
Ista

> Thank in advance.
>
>> Date: Wed, 4 Sep 2013 20:27:36 +0100
>> From: ruipbarradas at sapo.pt
>> To: pmassicotte at hotmail.com
>> CC: r-help at r-project.org
>> Subject: Re: [R] Histogram
>>
>> Hello,
>>
>> See the arguments 'right' and 'include.lowest' of ?hist.
>> To give what you want, try instead
>>
>> h1 <- hist(1:10, 10)  # counts are 2, 1, 1, ...
>> h2 <- hist(1:10, breaks = 0:10)  # all counts are 1
>>
>>
>> and see the difference between h1 and h2, components 'breaks' and 'counts'.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> Em 04-09-2013 19:34, philippe massicotte escreveu:
>> > Hi everyone.
>> > I'm currently translating some Matlab code into R. However, I realized that the hsit function produce different results in both languages.
>> > in Matlab, hist(1:10, 10) will produce 10 bins with a count of 1 in each, but in R it will produce 9 classes with count of 2,1,1,1,1,1,1,1,1.
>> > I'm a bit embarrassed to ask such question, but why R is not producing 10 classes as requested?
>> > Thanks in advance,Phil
>> >     [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Wed Sep  4 22:28:11 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 4 Sep 2013 13:28:11 -0700 (PDT)
Subject: [R] Histogram
In-Reply-To: <COL127-W22EB827D05EAFB3CAC73B1B3320@phx.gbl>
References: <COL127-W49B3E97D4ABD80B64BCFEBB3320@phx.gbl>,
	<522789A8.8070800@sapo.pt>
	<COL127-W22EB827D05EAFB3CAC73B1B3320@phx.gbl>
Message-ID: <1378326491.82219.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
replicate(100,length(hist(10,0:10)$counts))
#? [1] 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10
?#[26] 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10
?#[51] 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10
?#[76] 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10


?set.seed(56)
?a1<- rnorm(100)
?bins<- seq(min(a1),max(a1)+1,by=0.2)
?replicate(100,length(hist(a1,breaks=bins)$counts))
?# [1] 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29
?#[26] 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29
?#[51] 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29
?#[76] 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29


#May be this is what you are looking for:

library(Rlab)
set.seed(56)
?replicate(100,length(hplot(rnorm(100),nclass=10)$counts))
#? [1] 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10
?#[26] 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10
?#[51] 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10
?#[76] 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10


A.K.




----- Original Message -----
From: philippe massicotte <pmassicotte at hotmail.com>
To: Rui Barradas <ruipbarradas at sapo.pt>
Cc: "r-help at R-project.org" <r-help at r-project.org>
Sent: Wednesday, September 4, 2013 4:02 PM
Subject: Re: [R] Histogram

Thank you everyone.
Try executing this:
replicate(100, length(hist(rnorm(100), nclass = 10)$counts))
I'm still not sure why the number of bins (classes) is not consistent. 
Thank in advance.

> Date: Wed, 4 Sep 2013 20:27:36 +0100
> From: ruipbarradas at sapo.pt
> To: pmassicotte at hotmail.com
> CC: r-help at r-project.org
> Subject: Re: [R] Histogram
> 
> Hello,
> 
> See the arguments 'right' and 'include.lowest' of ?hist.
> To give what you want, try instead
> 
> h1 <- hist(1:10, 10)? # counts are 2, 1, 1, ...
> h2 <- hist(1:10, breaks = 0:10)? # all counts are 1
> 
> 
> and see the difference between h1 and h2, components 'breaks' and 'counts'.
> 
> Hope this helps,
> 
> Rui Barradas
> 
> Em 04-09-2013 19:34, philippe massicotte escreveu:
> > Hi everyone.
> > I'm currently translating some Matlab code into R. However, I realized that the hsit function produce different results in both languages.
> > in Matlab, hist(1:10, 10) will produce 10 bins with a count of 1 in each, but in R it will produce 9 classes with count of 2,1,1,1,1,1,1,1,1.
> > I'm a bit embarrassed to ask such question, but why R is not producing 10 classes as requested?
> > Thanks in advance,Phil ??? ???  ??? ?  ??? ??? 
> > ??? [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
??? ???  ??? ?  ??? ??? ? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From dcarlson at tamu.edu  Wed Sep  4 22:44:42 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Wed, 4 Sep 2013 15:44:42 -0500
Subject: [R] Histogram
In-Reply-To: <COL127-W22EB827D05EAFB3CAC73B1B3320@phx.gbl>
References: <COL127-W49B3E97D4ABD80B64BCFEBB3320@phx.gbl>,
	<522789A8.8070800@sapo.pt>
	<COL127-W22EB827D05EAFB3CAC73B1B3320@phx.gbl>
Message-ID: <042201cea9af$94e2de30$bea89a90$@tamu.edu>

Good question. It turns out that the manual page does not tell
the whole story. Looking at the source code for hist.default,
the function starts with the number of breaks suggested by
nclass.Sturges(), but then this number (or any other number of
breaks that you specify) is passed to pretty() along with the
maximum and the minimum values of the data (ie range(data)) to
create "pretty" break intervals. In your example,
nclass.Sturges() always recommends 8 breaks, but the number of
the breaks changes based on the minimum and maximum values. So
the only way to get exactly the number of breaks you want is to
specify the break intervals yourself.

David Carlson


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of philippe
massicotte
Sent: Wednesday, September 4, 2013 3:02 PM
To: Rui Barradas
Cc: r-help at R-project.org
Subject: Re: [R] Histogram

Thank you everyone.
Try executing this:
replicate(100, length(hist(rnorm(100), nclass = 10)$counts))
I'm still not sure why the number of bins (classes) is not
consistent. 
Thank in advance.

> Date: Wed, 4 Sep 2013 20:27:36 +0100
> From: ruipbarradas at sapo.pt
> To: pmassicotte at hotmail.com
> CC: r-help at r-project.org
> Subject: Re: [R] Histogram
> 
> Hello,
> 
> See the arguments 'right' and 'include.lowest' of ?hist.
> To give what you want, try instead
> 
> h1 <- hist(1:10, 10)  # counts are 2, 1, 1, ...
> h2 <- hist(1:10, breaks = 0:10)  # all counts are 1
> 
> 
> and see the difference between h1 and h2, components 'breaks'
and 'counts'.
> 
> Hope this helps,
> 
> Rui Barradas
> 
> Em 04-09-2013 19:34, philippe massicotte escreveu:
> > Hi everyone.
> > I'm currently translating some Matlab code into R. However,
I realized that the hsit function produce different results in
both languages.
> > in Matlab, hist(1:10, 10) will produce 10 bins with a count
of 1 in each, but in R it will produce 9 classes with count of
2,1,1,1,1,1,1,1,1.
> > I'm a bit embarrassed to ask such question, but why R is not
producing 10 classes as requested?
> > Thanks in advance,Phil 		 	   		
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible
code.
> >
 		 	   		  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From smartpink111 at yahoo.com  Wed Sep  4 23:14:23 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 4 Sep 2013 14:14:23 -0700 (PDT)
Subject: [R] Attribute Length Error when Trying plm Regression
In-Reply-To: <1378322567885-4675384.post@n4.nabble.com>
References: <1378322567885-4675384.post@n4.nabble.com>
Message-ID: <1378329263.73618.YahooMailNeo@web142604.mail.bf1.yahoo.com>

HI,
It is better to provide a reproducible example using ?dput().
you can also check in this link.

http://r.789695.n4.nabble.com/names-attribute-must-be-the-same-length-as-the-vector-td4503946.html

library(plm)
#Using the example from ?plm()
?data("Produc", package = "plm")
?zz <- plm(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp, data = Produc, index = c("state","year"))

#Suppose, if I use a model like this:
zz1<- plm(gsp~pcap+pc+emp+unemp+water+util,data=Produc,index=c("gsp","year"))
#Error in names(y) <- namesy : 
?# 'names' attribute [816] must be the same length as the vector [0]

In your model statement, 

fixed <- plm (h ~ o + m + a, data=drugsXX, index=c("h","year"),
model="within") 


A.K.


----- Original Message -----
From: lross8 <lross8 at kent.edu>
To: r-help at r-project.org
Cc: 
Sent: Wednesday, September 4, 2013 3:22 PM
Subject: [R] Attribute Length Error when Trying plm Regression

Hello,

I am trying to run a fixed effects panel regression on data containing 5
columns and 1,494 rows. 

I read the data in as follows:

>drugsXX<-read.csv(file="C:\\Folder\\vX.X\\Drugs\\drugsXX_panel.csv",
head=TRUE, sep=",")

Verified it read in correctly and had a good data.frame:
>dim(drugsXX)
[1] 1494? ? 5
>drugs XX
produce expected data with correct column names

The issue is, when I go to run the plm using:
>fixed <- plm (h ~ o + m + a, data=drugsXX, index=c("h","year"),
model="within") 

I get this error:
Error in names(y) <- namesy : 
? 'names' attribute [996] must be the same length as the vector [0]

I know the data recognizes that I have 5 columns. I also know that there's
nothing wrong with row 996 (I even want back and checked for hidden
characters in the original .csv file).

traceback() was useless:
4: pmodel.response.pFormula(formula, data, model = model, effect = effect, 
? ? ?  theta = theta)
3: pmodel.response(formula, data, model = model, effect = effect, 
? ? ?  theta = theta)
2: plm.fit(formula, data, model, effect, random.method, inst.method)
1: plm(h ~ o + m + a, data = drugsXX, index = c("h", 
? ? ?  "year"), model = "within")

What explicit steps can I follow to get my panel regression to run? 

Thank you, 
Laura



--
View this message in context: http://r.789695.n4.nabble.com/Attribute-Length-Error-when-Trying-plm-Regression-tp4675384.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From noahsilverman at ucla.edu  Wed Sep  4 23:56:48 2013
From: noahsilverman at ucla.edu (Noah Silverman)
Date: Wed, 4 Sep 2013 14:56:48 -0700
Subject: [R] Console Output Formatting
Message-ID: <C55AF251-862A-4967-BF6B-2D460C7D3449@ucla.edu>

Hi,

Working with R, I often want to copy and paste some values somewhere else.  (Its not worth saving a CSV file for a dozen or so entries.)  Or, I may want to copy all the names of an object into some code.

R, rather nicely, wraps output with an index number on the left side.

For example:

[1] -1.07781972 -1.12157840  1.79303276  1.53313388 -1.30854455  0.45641730  0.23866722 -1.96265084
  [9] -1.90779578 -0.68418936 -2.04910282  0.12008358 -1.71072687 -0.36707605 -0.36939204 -2.02799948
 [17]  0.36466562 -1.34204214 -0.45100125 -0.60483154  0.42208268 -0.89535576 -1.09398009 -2.07257728
 [25] -0.04615273 -0.23659570  0.27232736  1.28432538 -2.17042948 -0.45364579  1.52957528  0.39838320
 [33]  0.64923323 -1.01651051 -0.36287974 -0.73787761  0.48088199 -1.19539814 -0.80079095 -1.02507331



While this is great to read on screen, it is a pain to have to edit out all the index numbers.  

Is there a simple way to just back the values, or even a comma separated list of the values?



Thanks!



--
Noah Silverman, M.S., C.Phil
UCLA Department of Statistics
8117 Math Sciences Building
Los Angeles, CA 90095


From skfglades at gmail.com  Thu Sep  5 00:08:30 2013
From: skfglades at gmail.com (Steve Friedman)
Date: Wed, 4 Sep 2013 18:08:30 -0400
Subject: [R] Console Output Formatting
In-Reply-To: <C55AF251-862A-4967-BF6B-2D460C7D3449@ucla.edu>
References: <C55AF251-862A-4967-BF6B-2D460C7D3449@ucla.edu>
Message-ID: <CAHB_=UdRJoZ7nhRMo9VYvDbU4oHXtmx4BvfcJkrEe9YibjxAzQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130904/1c6e2522/attachment.pl>

From ripley at stats.ox.ac.uk  Thu Sep  5 00:09:58 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 04 Sep 2013 23:09:58 +0100
Subject: [R] Console Output Formatting
In-Reply-To: <C55AF251-862A-4967-BF6B-2D460C7D3449@ucla.edu>
References: <C55AF251-862A-4967-BF6B-2D460C7D3449@ucla.edu>
Message-ID: <5227AFB6.5050808@stats.ox.ac.uk>

On 04/09/2013 22:56, Noah Silverman wrote:
> Hi,
>
> Working with R, I often want to copy and paste some values somewhere else.  (Its not worth saving a CSV file for a dozen or so entries.)  Or, I may want to copy all the names of an object into some code.
>
> R, rather nicely, wraps output with an index number on the left side.
>
> For example:
>
> [1] -1.07781972 -1.12157840  1.79303276  1.53313388 -1.30854455  0.45641730  0.23866722 -1.96265084
>    [9] -1.90779578 -0.68418936 -2.04910282  0.12008358 -1.71072687 -0.36707605 -0.36939204 -2.02799948
>   [17]  0.36466562 -1.34204214 -0.45100125 -0.60483154  0.42208268 -0.89535576 -1.09398009 -2.07257728
>   [25] -0.04615273 -0.23659570  0.27232736  1.28432538 -2.17042948 -0.45364579  1.52957528  0.39838320
>   [33]  0.64923323 -1.01651051 -0.36287974 -0.73787761  0.48088199 -1.19539814 -0.80079095 -1.02507331
>
>
>
> While this is great to read on screen, it is a pain to have to edit out all the index numbers.
>
> Is there a simple way to just back the values, or even a comma separated list of the values?

There are many.  Here I usually use write(x, "").  The file = "" trick 
works in many other functions.

Using dput() and removing c( and ) is also often useful when comma 
separation is needed.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From spencer.graves at structuremonitoring.com  Thu Sep  5 00:12:32 2013
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Wed, 04 Sep 2013 15:12:32 -0700
Subject: [R] Read a Google Spreadsheet?
Message-ID: <5227B050.1080502@structuremonitoring.com>

Hello, All:


What do you recommend for reading a Google Spreadsheet into R? I didn't 
find anything useful using library(sos); findFn('google spreadsheet').


I can solve the problem by downloading the file either as *.ods or 
*.xlsx format, then opening it and saving it as *.xls, then using 
read.xls{gdata}.


Alternatives I haven't tried use read.xlsx{xlsx} and 
readWorksheetFromFile{XLConnect} with 32-bit R. Neither of these work 
for me with 64-bit R, because they can't find an appropriate rJava on my 
computer; see below. (I've been using 64-bit R with Emacs, so switching 
to 32-bit R is not completely trivial.) Similarly, 
read.gnumeric.sheet{gnumeric} requires the "external program, 
ssconvert", which seems not to be available on my computer or installed 
for 64-bit R.


What do you suggest? Avoid 64-bit R unless I really need it? That seems 
to be the message I'm getting from this. (The writeFindFn2xls{sos} also 
works in 32-bit R but fails in 64-bit apparently for the same reason.)


Thanks,
Spencer


 > library(xlsx)
Loading required package: xlsxjars
Loading required package: rJava
Error : .onLoad failed in loadNamespace() for 'rJava', details:
call: fun(libname, pkgname)
error: No CurrentVersion entry in Software/JavaSoft registry! Try 
re-installing Java and make sure R and Java have matching architectures.
Error: package ?rJava? could not be loaded
 > library(XLConnect)
Loading required package: rJava
Error : .onLoad failed in loadNamespace() for 'rJava', details:
call: fun(libname, pkgname)
error: No CurrentVersion entry in Software/JavaSoft registry! Try 
re-installing Java and make sure R and Java have matching architectures.
Error: package ?rJava? could not be loaded
 > sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats graphics grDevices utils datasets methods base


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com


From nfultz at gmail.com  Thu Sep  5 00:12:53 2013
From: nfultz at gmail.com (Neal Fultz)
Date: Wed, 4 Sep 2013 15:12:53 -0700
Subject: [R] Console Output Formatting
In-Reply-To: <5227AFB6.5050808@stats.ox.ac.uk>
References: <C55AF251-862A-4967-BF6B-2D460C7D3449@ucla.edu>
	<5227AFB6.5050808@stats.ox.ac.uk>
Message-ID: <CAL9B2vetA=5X9=-gWYcqr3QvSAv=Hw0AAPUg4rWXOhwHWBahwQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130904/1c9b8c51/attachment.pl>

From daniel.hornung at ds.mpg.de  Wed Sep  4 22:45:49 2013
From: daniel.hornung at ds.mpg.de (Daniel Hornung)
Date: Wed, 4 Sep 2013 22:45:49 +0200
Subject: [R] xyplot and lwd
Message-ID: <201309042245.52185.daniel.hornung@ds.mpg.de>

Hello,

can it be that xyplot does not support the lwd argument?

At least here, the following still shows thin lines, as opposed to the regular 
plot command:

xyplot(Sepal.Length ~ Sepal.Width, data = iris, pch=4, lwd=4)

Cheers,
Daniel

-- 
Max-Planck-Institute for Dynamics and Self-Organization
Laboratory for Fluid Dynamics, Pattern Formation and Biocomplexity
Biomedical Physics Group

Am Fassberg 17
D-37077 Goettingen

(+49) 551 5176 373
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 836 bytes
Desc: This is a digitally signed message part.
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130904/ad433506/attachment.bin>

From smartpink111 at yahoo.com  Thu Sep  5 00:24:02 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 4 Sep 2013 15:24:02 -0700 (PDT)
Subject: [R] Console Output Formatting
In-Reply-To: <C55AF251-862A-4967-BF6B-2D460C7D3449@ucla.edu>
References: <C55AF251-862A-4967-BF6B-2D460C7D3449@ucla.edu>
Message-ID: <1378333442.14975.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
You could use ?cat()
For ex:
vec1<-1:100
cat(vec1)
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100> 
?cat(vec1,sep=",")
1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100> 

#or
?write(vec1,"",sep=",")
1,2,3,4,5
6,7,8,9,10
11,12,13,14,15
16,17,18,19,20
21,22,23,24,25
26,27,28,29,30
31,32,33,34,35
36,37,38,39,40
41,42,43,44,45
46,47,48,49,50
51,52,53,54,55
56,57,58,59,60
61,62,63,64,65
66,67,68,69,70
71,72,73,74,75
76,77,78,79,80
81,82,83,84,85
86,87,88,89,90
91,92,93,94,95
96,97,98,99,100


A.K.





----- Original Message -----
From: Noah Silverman <noahsilverman at ucla.edu>
To: R help <r-help at r-project.org>
Cc: 
Sent: Wednesday, September 4, 2013 5:56 PM
Subject: [R] Console Output Formatting

Hi,

Working with R, I often want to copy and paste some values somewhere else.? (Its not worth saving a CSV file for a dozen or so entries.)? Or, I may want to copy all the names of an object into some code.

R, rather nicely, wraps output with an index number on the left side.

For example:

[1] -1.07781972 -1.12157840? 1.79303276? 1.53313388 -1.30854455? 0.45641730? 0.23866722 -1.96265084
? [9] -1.90779578 -0.68418936 -2.04910282? 0.12008358 -1.71072687 -0.36707605 -0.36939204 -2.02799948
[17]? 0.36466562 -1.34204214 -0.45100125 -0.60483154? 0.42208268 -0.89535576 -1.09398009 -2.07257728
[25] -0.04615273 -0.23659570? 0.27232736? 1.28432538 -2.17042948 -0.45364579? 1.52957528? 0.39838320
[33]? 0.64923323 -1.01651051 -0.36287974 -0.73787761? 0.48088199 -1.19539814 -0.80079095 -1.02507331



While this is great to read on screen, it is a pain to have to edit out all the index numbers.? 

Is there a simple way to just back the values, or even a comma separated list of the values?



Thanks!



--
Noah Silverman, M.S., C.Phil
UCLA Department of Statistics
8117 Math Sciences Building
Los Angeles, CA 90095

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From gunter.berton at gene.com  Thu Sep  5 00:33:32 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 4 Sep 2013 15:33:32 -0700
Subject: [R] xyplot and lwd
In-Reply-To: <201309042245.52185.daniel.hornung@ds.mpg.de>
References: <201309042245.52185.daniel.hornung@ds.mpg.de>
Message-ID: <CACk-te1xuVYGS=yt93HSs_NcWb0GMZ53iqQWywVH8_EuvmhUiw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130904/5790bbc1/attachment.pl>

From murdoch.duncan at gmail.com  Thu Sep  5 02:00:02 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 04 Sep 2013 20:00:02 -0400
Subject: [R] Histogram
In-Reply-To: <042201cea9af$94e2de30$bea89a90$@tamu.edu>
References: <COL127-W49B3E97D4ABD80B64BCFEBB3320@phx.gbl>,
	<522789A8.8070800@sapo.pt>
	<COL127-W22EB827D05EAFB3CAC73B1B3320@phx.gbl>
	<042201cea9af$94e2de30$bea89a90$@tamu.edu>
Message-ID: <5227C982.8020605@gmail.com>

On 13-09-04 4:44 PM, David Carlson wrote:> Good question. It turns out 
that the manual page does not tell
 > the whole story.

Do you really think the manual page would be improved if it went into as 
much detail as you give below?  It does say clearly that breaks is a 
"suggestion only".  I don't think it would be clearer if it explained 
exactly how the suggestion is used. It would just be more complicated, 
and less likely to be read.

Duncan Murdoch


  Looking at the source code for hist.default,
 > the function starts with the number of breaks suggested by
 > nclass.Sturges(), but then this number (or any other number of
 > breaks that you specify) is passed to pretty() along with the
 > maximum and the minimum values of the data (ie range(data)) to
 > create "pretty" break intervals. In your example,
 > nclass.Sturges() always recommends 8 breaks, but the number of
 > the breaks changes based on the minimum and maximum values. So
 > the only way to get exactly the number of breaks you want is to
 > specify the break intervals yourself.
 >
 > David Carlson
 >
 >
 > -----Original Message-----
 > From: r-help-bounces at r-project.org
 > [mailto:r-help-bounces at r-project.org] On Behalf Of philippe
 > massicotte
 > Sent: Wednesday, September 4, 2013 3:02 PM
 > To: Rui Barradas
 > Cc: r-help at R-project.org
 > Subject: Re: [R] Histogram
 >
 > Thank you everyone.
 > Try executing this:
 > replicate(100, length(hist(rnorm(100), nclass = 10)$counts))
 > I'm still not sure why the number of bins (classes) is not
 > consistent.
 > Thank in advance.
 >
 >> Date: Wed, 4 Sep 2013 20:27:36 +0100
 >> From: ruipbarradas at sapo.pt
 >> To: pmassicotte at hotmail.com
 >> CC: r-help at r-project.org
 >> Subject: Re: [R] Histogram
 >>
 >> Hello,
 >>
 >> See the arguments 'right' and 'include.lowest' of ?hist.
 >> To give what you want, try instead
 >>
 >> h1 <- hist(1:10, 10)  # counts are 2, 1, 1, ...
 >> h2 <- hist(1:10, breaks = 0:10)  # all counts are 1
 >>
 >>
 >> and see the difference between h1 and h2, components 'breaks'
 > and 'counts'.
 >>
 >> Hope this helps,
 >>
 >> Rui Barradas
 >>
 >> Em 04-09-2013 19:34, philippe massicotte escreveu:
 >>> Hi everyone.
 >>> I'm currently translating some Matlab code into R. However,
 > I realized that the hsit function produce different results in
 > both languages.
 >>> in Matlab, hist(1:10, 10) will produce 10 bins with a count
 > of 1 in each, but in R it will produce 9 classes with count of
 > 2,1,1,1,1,1,1,1,1.
 >>> I'm a bit embarrassed to ask such question, but why R is not
 > producing 10 classes as requested?
 >>> Thanks in advance,Phil 		 	   		
 >>> 	[[alternative HTML version deleted]]
 >>>
 >>> ______________________________________________
 >>> R-help at r-project.org mailing list
 >>> https://stat.ethz.ch/mailman/listinfo/r-help
 >>> PLEASE do read the posting guide
 > http://www.R-project.org/posting-guide.html
 >>> and provide commented, minimal, self-contained, reproducible
 > code.
 >>>
 >   		 	   		
 > 	[[alternative HTML version deleted]]
 >
 > ______________________________________________
 > R-help at r-project.org mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide
 > http://www.R-project.org/posting-guide.html
 > and provide commented, minimal, self-contained, reproducible
 > code.
 >
 > ______________________________________________
 > R-help at r-project.org mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
 > and provide commented, minimal, self-contained, reproducible code.
 >


From murdoch.duncan at gmail.com  Thu Sep  5 02:11:15 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 04 Sep 2013 20:11:15 -0400
Subject: [R] Console Output Formatting
In-Reply-To: <C55AF251-862A-4967-BF6B-2D460C7D3449@ucla.edu>
References: <C55AF251-862A-4967-BF6B-2D460C7D3449@ucla.edu>
Message-ID: <5227CC23.9040903@gmail.com>

On 13-09-04 5:56 PM, Noah Silverman wrote:
> Hi,
>
> Working with R, I often want to copy and paste some values somewhere else.  (Its not worth saving a CSV file for a dozen or so entries.)  Or, I may want to copy all the names of an object into some code.

Besides the other suggestions, the data editor in R can be a source for 
cut and paste to a spreadsheet, at least in Windows and Mac OSX.  This 
is useful for matrices and dataframes.

Duncan Murdoch


> R, rather nicely, wraps output with an index number on the left side.
>
> For example:
>
> [1] -1.07781972 -1.12157840  1.79303276  1.53313388 -1.30854455  0.45641730  0.23866722 -1.96265084
>    [9] -1.90779578 -0.68418936 -2.04910282  0.12008358 -1.71072687 -0.36707605 -0.36939204 -2.02799948
>   [17]  0.36466562 -1.34204214 -0.45100125 -0.60483154  0.42208268 -0.89535576 -1.09398009 -2.07257728
>   [25] -0.04615273 -0.23659570  0.27232736  1.28432538 -2.17042948 -0.45364579  1.52957528  0.39838320
>   [33]  0.64923323 -1.01651051 -0.36287974 -0.73787761  0.48088199 -1.19539814 -0.80079095 -1.02507331
>
>
>
> While this is great to read on screen, it is a pain to have to edit out all the index numbers.
>
> Is there a simple way to just back the values, or even a comma separated list of the values?
>
>
>
> Thanks!
>
>
>
> --
> Noah Silverman, M.S., C.Phil
> UCLA Department of Statistics
> 8117 Math Sciences Building
> Los Angeles, CA 90095
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From pmassicotte at hotmail.com  Thu Sep  5 02:57:10 2013
From: pmassicotte at hotmail.com (philippe massicotte)
Date: Thu, 5 Sep 2013 00:57:10 +0000
Subject: [R] Histogram
In-Reply-To: <5227C982.8020605@gmail.com>
References: <COL127-W49B3E97D4ABD80B64BCFEBB3320@phx.gbl>,
	<522789A8.8070800@sapo.pt>
	<COL127-W22EB827D05EAFB3CAC73B1B3320@phx.gbl>
	<042201cea9af$94e2de30$bea89a90$@tamu.edu>, <5227C982.8020605@gmail.com>
Message-ID: <COL127-W41B39F8B24407A8EE42CC1B3330@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130905/9c4ae555/attachment.pl>

From istazahn at gmail.com  Thu Sep  5 03:09:34 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 4 Sep 2013 21:09:34 -0400
Subject: [R] Read a Google Spreadsheet?
In-Reply-To: <5227B050.1080502@structuremonitoring.com>
References: <5227B050.1080502@structuremonitoring.com>
Message-ID: <CA+vqiLEbZK_3-oGD3DjjVz3n9NsShMFUvTMP+-MqBHkzu8eNww@mail.gmail.com>

Hi Spencer,

Why don't you want to install 64bit Java?

On Wed, Sep 4, 2013 at 6:12 PM, Spencer Graves
<spencer.graves at structuremonitoring.com> wrote:
> Hello, All:
>
>
> What do you recommend for reading a Google Spreadsheet into R? I didn't find
> anything useful using library(sos); findFn('google spreadsheet').
>
>
> I can solve the problem by downloading the file either as *.ods or *.xlsx
> format, then opening it and saving it as *.xls, then using read.xls{gdata}.
>
>
> Alternatives I haven't tried use read.xlsx{xlsx} and
> readWorksheetFromFile{XLConnect} with 32-bit R. Neither of these work for me
> with 64-bit R, because they can't find an appropriate rJava on my computer;
> see below. (I've been using 64-bit R with Emacs, so switching to 32-bit R is
> not completely trivial.) Similarly, read.gnumeric.sheet{gnumeric} requires
> the "external program, ssconvert", which seems not to be available on my
> computer or installed for 64-bit R.
>
>
> What do you suggest? Avoid 64-bit R unless I really need it? That seems to
> be the message I'm getting from this. (The writeFindFn2xls{sos} also works
> in 32-bit R but fails in 64-bit apparently for the same reason.)
>
>
> Thanks,
> Spencer
>
>
>> library(xlsx)
> Loading required package: xlsxjars
> Loading required package: rJava
> Error : .onLoad failed in loadNamespace() for 'rJava', details:
> call: fun(libname, pkgname)
> error: No CurrentVersion entry in Software/JavaSoft registry! Try
> re-installing Java and make sure R and Java have matching architectures.
> Error: package ?rJava? could not be loaded
>> library(XLConnect)
> Loading required package: rJava
> Error : .onLoad failed in loadNamespace() for 'rJava', details:
> call: fun(libname, pkgname)
> error: No CurrentVersion entry in Software/JavaSoft registry! Try
> re-installing Java and make sure R and Java have matching architectures.
> Error: package ?rJava? could not be loaded
>> sessionInfo()
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats graphics grDevices utils datasets methods base
>
>
> --
> Spencer Graves, PE, PhD
> President and Chief Technology Officer
> Structure Inspection and Monitoring, Inc.
> 751 Emerson Ct.
> San Jos?, CA 95126
> ph:  408-655-4567
> web:  www.structuremonitoring.com
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From spencer.graves at structuremonitoring.com  Thu Sep  5 03:36:32 2013
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Wed, 04 Sep 2013 18:36:32 -0700
Subject: [R] Read a Google Spreadsheet?
In-Reply-To: <CA+vqiLEbZK_3-oGD3DjjVz3n9NsShMFUvTMP+-MqBHkzu8eNww@mail.gmail.com>
References: <5227B050.1080502@structuremonitoring.com>
	<CA+vqiLEbZK_3-oGD3DjjVz3n9NsShMFUvTMP+-MqBHkzu8eNww@mail.gmail.com>
Message-ID: <5227E020.4000401@structuremonitoring.com>

On 9/4/2013 6:09 PM, Ista Zahn wrote:
> Hi Spencer,
>
> Why don't you want to install 64bit Java?


       That may be a reasonable approach.


       I may have Java confused with something else, but I remember 
hearing that it was difficult or unwise to try to install both 32- and 
64-bit versions of something like Java or Java Script on the same 
Windows operating system.  If I need to uninstall 32-bit Java to install 
64-bit, who knows what else I could break.  I'm a statistician, not an 
information technologist:  If I spend more time playing with Java, I'll 
have less time for other things I want to do.


       Thanks for the reply.
       Spencer
>
> On Wed, Sep 4, 2013 at 6:12 PM, Spencer Graves
> <spencer.graves at structuremonitoring.com> wrote:
>> Hello, All:
>>
>>
>> What do you recommend for reading a Google Spreadsheet into R? I didn't find
>> anything useful using library(sos); findFn('google spreadsheet').
>>
>>
>> I can solve the problem by downloading the file either as *.ods or *.xlsx
>> format, then opening it and saving it as *.xls, then using read.xls{gdata}.
>>
>>
>> Alternatives I haven't tried use read.xlsx{xlsx} and
>> readWorksheetFromFile{XLConnect} with 32-bit R. Neither of these work for me
>> with 64-bit R, because they can't find an appropriate rJava on my computer;
>> see below. (I've been using 64-bit R with Emacs, so switching to 32-bit R is
>> not completely trivial.) Similarly, read.gnumeric.sheet{gnumeric} requires
>> the "external program, ssconvert", which seems not to be available on my
>> computer or installed for 64-bit R.
>>
>>
>> What do you suggest? Avoid 64-bit R unless I really need it? That seems to
>> be the message I'm getting from this. (The writeFindFn2xls{sos} also works
>> in 32-bit R but fails in 64-bit apparently for the same reason.)
>>
>>
>> Thanks,
>> Spencer
>>
>>
>>> library(xlsx)
>> Loading required package: xlsxjars
>> Loading required package: rJava
>> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>> call: fun(libname, pkgname)
>> error: No CurrentVersion entry in Software/JavaSoft registry! Try
>> re-installing Java and make sure R and Java have matching architectures.
>> Error: package ?rJava? could not be loaded
>>> library(XLConnect)
>> Loading required package: rJava
>> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>> call: fun(libname, pkgname)
>> error: No CurrentVersion entry in Software/JavaSoft registry! Try
>> re-installing Java and make sure R and Java have matching architectures.
>> Error: package ?rJava? could not be loaded
>>> sessionInfo()
>> R version 3.0.1 (2013-05-16)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats graphics grDevices utils datasets methods base
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From nashjc at uottawa.ca  Thu Sep  5 03:47:28 2013
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Wed, 04 Sep 2013 21:47:28 -0400
Subject: [R]  optim  evils
Message-ID: <5227E2B0.8050002@uottawa.ca>


Sometimes one has to really read the manual carefully.

"If non-trivial bounds are supplied, this
      method will be selected, with a warning." (re L-BFGS-B)

Several of us have noted problems occasionally with this code.

You might want to look at the box constrained codes offered in optimx 
package through other packages (bobyqa, nmkb, Rvmmin, Rcgmin)

JN

On 13-09-04 06:00 AM, r-help-request at r-project.org wrote:
 > Message: 67
 > Date: Wed, 4 Sep 2013 16:34:54 +0800 (SGT)
 > From: Michael Meyer<spyqqqdia at yahoo.com>
 > To:"r-help at r-project.org"  <r-help at r-project.org>
 > Subject: [R] optim  evils
 > Message-ID:
 >     <1378283694.77272.YahooMailNeo at web193402.mail.sg3.yahoo.com>
 > Content-Type: text/plain
 >
 > It would take some effort to extract selfcontained code from the mass 
of code wherein this optimization is embedded. Moreover I would have to 
obtain permission from my employer to do so.
 >
 > This is not efficient.
 > However some things are evident from the trace log which I have 
submitted:
 > (a) L-BFGS-B does not identify itself even though it was called 
overriding the method
 > parameter in optim.
 > (b) Optim  reports as final converged minimum value a function value 
that is much larger than
 > others computed during the optimization.
 >
 > I think we can agree on calling this a bug.
 >     [[alternative HTML version deleted]]
 >


From jwiley.psych at gmail.com  Thu Sep  5 03:50:30 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Wed, 4 Sep 2013 18:50:30 -0700
Subject: [R] Read a Google Spreadsheet?
In-Reply-To: <5227E020.4000401@structuremonitoring.com>
References: <5227B050.1080502@structuremonitoring.com>
	<CA+vqiLEbZK_3-oGD3DjjVz3n9NsShMFUvTMP+-MqBHkzu8eNww@mail.gmail.com>
	<5227E020.4000401@structuremonitoring.com>
Message-ID: <CANz9Z_LL7UJeDAtubow+JFDpiPcRj8p-AxwwM1HTmFhxn_nnCA@mail.gmail.com>

Hi Spencer,

It really is not very hard, and I have never had issue with it:

http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html

Just download the x86 and x64 versions for your OS and install.  Worst
case, you need to add the directory to the PATH variable in Windows.

I do this regularly so I can use/test either version of R.

Cheers,

Josh

P.S. Emacs + ESS allows for different versions of R and it is not too
difficult to use the 64 or 32 bit version... M-x
R-version-architecture


On Wed, Sep 4, 2013 at 6:36 PM, Spencer Graves
<spencer.graves at structuremonitoring.com> wrote:
> On 9/4/2013 6:09 PM, Ista Zahn wrote:
>>
>> Hi Spencer,
>>
>> Why don't you want to install 64bit Java?
>
>
>
>       That may be a reasonable approach.
>
>
>       I may have Java confused with something else, but I remember hearing
> that it was difficult or unwise to try to install both 32- and 64-bit
> versions of something like Java or Java Script on the same Windows operating
> system.  If I need to uninstall 32-bit Java to install 64-bit, who knows
> what else I could break.  I'm a statistician, not an information
> technologist:  If I spend more time playing with Java, I'll have less time
> for other things I want to do.
>
>
>       Thanks for the reply.
>       Spencer
>>
>>
>> On Wed, Sep 4, 2013 at 6:12 PM, Spencer Graves
>> <spencer.graves at structuremonitoring.com> wrote:
>>>
>>> Hello, All:
>>>
>>>
>>> What do you recommend for reading a Google Spreadsheet into R? I didn't
>>> find
>>> anything useful using library(sos); findFn('google spreadsheet').
>>>
>>>
>>> I can solve the problem by downloading the file either as *.ods or *.xlsx
>>> format, then opening it and saving it as *.xls, then using
>>> read.xls{gdata}.
>>>
>>>
>>> Alternatives I haven't tried use read.xlsx{xlsx} and
>>> readWorksheetFromFile{XLConnect} with 32-bit R. Neither of these work for
>>> me
>>> with 64-bit R, because they can't find an appropriate rJava on my
>>> computer;
>>> see below. (I've been using 64-bit R with Emacs, so switching to 32-bit R
>>> is
>>> not completely trivial.) Similarly, read.gnumeric.sheet{gnumeric}
>>> requires
>>> the "external program, ssconvert", which seems not to be available on my
>>> computer or installed for 64-bit R.
>>>
>>>
>>> What do you suggest? Avoid 64-bit R unless I really need it? That seems
>>> to
>>> be the message I'm getting from this. (The writeFindFn2xls{sos} also
>>> works
>>> in 32-bit R but fails in 64-bit apparently for the same reason.)
>>>
>>>
>>> Thanks,
>>> Spencer
>>>
>>>
>>>> library(xlsx)
>>>
>>> Loading required package: xlsxjars
>>> Loading required package: rJava
>>> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>>> call: fun(libname, pkgname)
>>> error: No CurrentVersion entry in Software/JavaSoft registry! Try
>>> re-installing Java and make sure R and Java have matching architectures.
>>> Error: package ?rJava? could not be loaded
>>>>
>>>> library(XLConnect)
>>>
>>> Loading required package: rJava
>>> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>>> call: fun(libname, pkgname)
>>> error: No CurrentVersion entry in Software/JavaSoft registry! Try
>>> re-installing Java and make sure R and Java have matching architectures.
>>> Error: package ?rJava? could not be loaded
>>>>
>>>> sessionInfo()
>>>
>>> R version 3.0.1 (2013-05-16)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>
>>> locale:
>>> [1] LC_COLLATE=English_United States.1252
>>> [2] LC_CTYPE=English_United States.1252
>>> [3] LC_MONETARY=English_United States.1252
>>> [4] LC_NUMERIC=C
>>> [5] LC_TIME=English_United States.1252
>>>
>>> attached base packages:
>>> [1] stats graphics grDevices utils datasets methods base
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://joshuawiley.com/
Senior Analyst - Elkhart Group Ltd.
http://elkhartgroup.com


From eajeong at gmail.com  Thu Sep  5 04:39:35 2013
From: eajeong at gmail.com (Euna Jeong)
Date: Thu, 5 Sep 2013 11:39:35 +0900
Subject: [R] Question about R2 in pls package
Message-ID: <CAMLpsnu-mHwznPfXtqN78hYGFT407C=qokj5z5gV0iHmnFiHWw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130905/0e6f2197/attachment.pl>

From mhacker at nycap.rr.com  Thu Sep  5 04:18:57 2013
From: mhacker at nycap.rr.com (Michael Hacker)
Date: Wed, 4 Sep 2013 22:18:57 -0400
Subject: [R] Poly Correlations
Message-ID: <057601cea9de$46d3e9d0$d47bbd70$@nycap.rr.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130904/ab884cb7/attachment.pl>

From alan.mainwaring at deakin.edu.au  Thu Sep  5 04:19:52 2013
From: alan.mainwaring at deakin.edu.au (alanidris)
Date: Wed, 4 Sep 2013 19:19:52 -0700 (PDT)
Subject: [R] New Version of R 3.0.1 problems with installing Rcmdr
Message-ID: <1378347592735-4675414.post@n4.nabble.com>

I have been using R version 2.15.1 happly along side R Commander. I then
tried to go through a fresh install using the latest version of R, R 3.0.1.
The trouble started when I wanted to install Rcmdr, I kept getting an error
message about previous installs of R Commander. I went through and
deinstalled all versions of R and tried fresh installs. Still could not get
R Commander installed using the Latest version of R.

It is possible that restrictions placed on me through my work computer may
be a factor. But I tried numerous times to deinstall all versions of R and
reinstall R 3.0.1, but I could not install the R Commander package. I then
deinstalled all versions of R and then decided to install an earlier
verision of R. This time I was more succesfull and after a few repeated
starts of R 2.15.1 i managed to get R Commander working.

Talk about a frustrating effort, can any one put any light on this issue? I
work at a University where firewalls may be a factor, but this is only a
guess.

Please dont get too technical I know very little of how R installs itself
and finds out where various packages and modules are. PS I am using Windows
7 as the operating system.



--
View this message in context: http://r.789695.n4.nabble.com/New-Version-of-R-3-0-1-problems-with-installing-Rcmdr-tp4675414.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Thu Sep  5 06:34:00 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 5 Sep 2013 00:34:00 -0400
Subject: [R] Question about R2 in pls package
In-Reply-To: <CAMLpsnu-mHwznPfXtqN78hYGFT407C=qokj5z5gV0iHmnFiHWw@mail.gmail.com>
References: <CAMLpsnu-mHwznPfXtqN78hYGFT407C=qokj5z5gV0iHmnFiHWw@mail.gmail.com>
Message-ID: <7817E4D6-8D6A-4EF6-B90F-7CE8AA761E1B@comcast.net>


On Sep 4, 2013, at 10:39 PM, Euna Jeong wrote:

> Hi,
>
> I have questions about R2 used in pls (or multivariate analysis).
>
> Is R2 same with the square of the PCC (Pearson Correlation  
> Coefficient)?
>
> I found the following description from wiki (Coefficient of  
> determination)
>
> ------------------------
> Similarly, in linear least squares regression with an estimated  
> intercept
> term, R2 equals the square of the Pearson correlation coefficient  
> between
> the observed and modeled (predicted) data values of the dependent  
> variable.
> -------------------------
>
> If so, Q2 (R2 of cross validation) should range between 0 and 1.
> But it doesn't. I got negative values of Q2 when running my dataset.
> Of course, from the definition of Q2, Q2 can be negative when my  
> model is
> not at all predictive.
>
> My question is what the relationship between R2 and pcc^2 is.
>

"Adjusted R-squareds" can become negative when the adjustment for the  
added number of predictors overwhelms the increased model fit on the  
scale of adjustment.

Do a search of the archives for negative r-squared. Here's just one of  
many:

http://r-project.markmail.org/search/?q=list%3Aorg.r-project.r-help%20%20negative%20r-squared#query 
:list%3Aorg.r-project.r-help%20%20negative%20r-squared+page:1+mid:rhiqm5bcm4maxnef+state:results

-- 

David Winsemius, MD
Alameda, CA, USA


From jdnewmil at dcn.davis.CA.us  Thu Sep  5 07:09:04 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 04 Sep 2013 22:09:04 -0700
Subject: [R] Permuting friendship nominations in a social network
In-Reply-To: <10C2CACF-2CDD-4DAF-8B29-E36F4A11BE09@gmail.com>
References: <635E18A9-0895-462D-8ED6-C6FB5B82CBE3@gmail.com>
	<CAN5YmCG2S0WZfQsyus6Qh_UXou_-uVJejv7E-ntWdknkxwG5FQ@mail.gmail.com>
	<10C2CACF-2CDD-4DAF-8B29-E36F4A11BE09@gmail.com>
Message-ID: <8f66de00-df76-4105-9156-282c677b483e@email.android.com>

It might be, but with appropriate indexes a SQL engine (via sqldf or RODBC for example) might be able to do it that way anyway.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

hollymaya <hollymaya at gmail.com> wrote:
>Jean, 
>Thank you for the suggestion. Actually the dataset is quite large so
>that method might be unmanageable. 
>Holly
>
>
>hollymaya at gmail.com
>
>
>
>On Sep 4, 2013, at 10:14 AM, "Adams, Jean" <jvadams at usgs.gov> wrote:
>
>> Holly,
>> 
>> I don't know of a clever way to do this, but I can think of a brute
>force way, which might only be feasible if you have a small data set
>(as in your example).  You could permute every possible set of
>connections, then choose from that collection only the ones that meet
>your criteria.  
>> 
>> Using your example, there are c=21 possible connections among the n=7
>unique individuals, c = n*(n-1)/2.  Your example shows a total of 8
>connections (16 rows / 2).  So you could generate all permutations of
>choose(21, 8) = 203,490 ways to have 8 connections.  Then subset the
>ones that have individual totals the same as your example (1 connection
>for Alicia and Beth, 2 for Kerry and Kim, 3 for James and John, and 4
>for Rachel).
>> 
>> Jean
>> 
>> 
>> On Tue, Sep 3, 2013 at 1:01 PM, hollymaya <hollymaya at gmail.com>
>wrote:
>> 
>> I have a dataset of dyads (an edgelist) representing friendship
>nominations between egos and their nominated alters. The network is
>undirected so if ego is connected to alter, then there is a separate
>observation in the dataset for the reverse. I would like to randomly
>permute the friendships so that 1.) the total degree for each
>individual remains the same, i.e. each individual ends up with the same
>number of friendships they had in the original undirected dataset and
>2.) there are no self loops, so individuals are not connected to
>themselves. Any suggestions on this would be greatly appreciated.
>> 
>> 
>> 
>> Example
>> 
>> Observed data:
>> 
>> Ego          Alter
>> 
>> Alicia       James
>> 
>> Beth        Kim
>> 
>> James      John
>> 
>> James      Rachel
>> 
>> James      Alicia
>> 
>> John        Kerry
>> 
>> John        Rachel
>> 
>> John        James
>> 
>> Kerry     Rachel
>> 
>> Kerry      John
>> 
>> Kim         Rachel
>> 
>> Kim          Beth
>> 
>> Rachel    Kim
>> 
>> Rachel    James
>> 
>> Rachel    Kerry
>> 
>> Rachel    John
>> 
>> 
>> 
>> Permuted data:
>> 
>> Ego          Alter
>> 
>> Alicia
>> 
>> Rachel
>> 
>> Beth
>> 
>> James
>> 
>> James
>> 
>> Beth
>> 
>> James
>> 
>> John
>> 
>> James
>> 
>> Kim
>> 
>> John
>> 
>> Rachel
>> 
>> John
>> 
>> Kerry
>> 
>> John
>> 
>> James
>> 
>> Kerry
>> 
>> Rachel
>> 
>> Kerry
>> 
>> John
>> 
>> Kim
>> 
>>  Rachel
>> 
>> Kim
>> 
>> James
>> 
>> Rachel
>> 
>> Kim
>> 
>> Rachel
>> 
>> John
>> 
>> Rachel
>> 
>> Alicia
>> 
>> Rachel
>> 
>> Kerry
>> 
>> 
>> 
>> Thank you in advance,
>> Holly
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> hollymaya at gmail.com
>> 
>> 
>> 
>> 
>>         [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From daniel.hornung at ds.mpg.de  Thu Sep  5 08:54:59 2013
From: daniel.hornung at ds.mpg.de (Daniel Hornung)
Date: Thu, 5 Sep 2013 08:54:59 +0200
Subject: [R] xyplot and lwd
In-Reply-To: <CACk-te1xuVYGS=yt93HSs_NcWb0GMZ53iqQWywVH8_EuvmhUiw@mail.gmail.com>
References: <201309042245.52185.daniel.hornung@ds.mpg.de>
	<CACk-te1xuVYGS=yt93HSs_NcWb0GMZ53iqQWywVH8_EuvmhUiw@mail.gmail.com>
Message-ID: <201309050855.03057.daniel.hornung@ds.mpg.de>

> On Wed, Sep 4, 2013 at 1:45 PM, Daniel Hornung 
<daniel.hornung at ds.mpg.de>wrote:
> > Hello,
> > 
> > can it be that xyplot does not support the lwd argument?
> > 
> > At least here, the following still shows thin lines, as opposed to the
> > regular
> > plot command:
> > 
> > xyplot(Sepal.Length ~ Sepal.Width, data = iris, pch=4, lwd=4)

On Thursday, September 05, 2013 00:33:32 Bert Gunter wrote:
> You should get no lines at all, as you have not specified that lines be
> drawn. Use the "type" argument to do so.
> 
> xyplot(rnorm(5) ~1:5,pch=4)  ## points only
> xyplot(rnorm(5) ~1:5,pch=4,type="b",lwd=4) ## points with thick lines
> 
> read ?panel.xyplot carefully (the default panel function for xyplot) for
> details
> 
> Cheers,
> Bert

Hello Bert,

no, maybe I expressed myself ambiguously: I was referring to the line 
thickness of the symbols, not a line between symbols:

xyplot(rnorm(5) ~ 1:5, pch=4, lwd=4)
versus
plot(rnorm(5), 1:5, pch=4, lwd=4)

I would like the points (4("x") in this case) to have thicker lines.

Cheers,
Daniel

-- 
Max-Planck-Institute for Dynamics and Self-Organization
Laboratory for Fluid Dynamics, Pattern Formation and Biocomplexity
Biomedical Physics Group

Am Fassberg 17
D-37077 Goettingen

(+49) 551 5176 373
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 836 bytes
Desc: This is a digitally signed message part.
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130905/4f6aa889/attachment.bin>

From b.h.mevik at usit.uio.no  Thu Sep  5 09:09:12 2013
From: b.h.mevik at usit.uio.no (=?utf-8?Q?Bj=C3=B8rn-Helge_Mevik?=)
Date: Thu, 05 Sep 2013 09:09:12 +0200
Subject: [R] Question about R2 in pls package
In-Reply-To: <CAMLpsnu-mHwznPfXtqN78hYGFT407C=qokj5z5gV0iHmnFiHWw@mail.gmail.com>
	(Euna Jeong's message of "Thu, 5 Sep 2013 11:39:35 +0900")
References: <CAMLpsnu-mHwznPfXtqN78hYGFT407C=qokj5z5gV0iHmnFiHWw@mail.gmail.com>
Message-ID: <s3swqmvbv8n.fsf@slagelg.uio.no>

Euna Jeong <eajeong at gmail.com> writes:

> I have questions about R2 used in pls (or multivariate analysis).
>
> Is R2 same with the square of the PCC (Pearson Correlation Coefficient)?

If you read the manual for R2 in the pls package, it will tell you how
R2 is calculated there, and that for _training_ data it is indeed
PCC^2, but _not_ for cross-validation or test data.

IMHO, R^2 only has a meaningful interpretation for training data.  For
test data or cross-validation, I prefer MSEP or RMSEP.

-- 
Regards,
Bj?rn-Helge Mevik


From lucien.blandenier at unine.ch  Thu Sep  5 09:01:48 2013
From: lucien.blandenier at unine.ch (BLANDENIER Lucien)
Date: Thu, 5 Sep 2013 07:01:48 +0000
Subject: [R] Problem with installing the TRR package
In-Reply-To: <757E37E70E2.000007DEjrkrideau@inbox.com>
References: <84F1DDBD03D55944AA4E63A2FE5EADE5530860B8@MAIL-MBX-05.UNINE.CH>,
	<757E37E70E2.000007DEjrkrideau@inbox.com>
Message-ID: <84F1DDBD03D55944AA4E63A2FE5EADE553086233@MAIL-MBX-05.UNINE.CH>

Do you know if R-3.0.1 is available for Linux Mint? Do you know how I can check it?


________________________________________
De : John Kane [jrkrideau at inbox.com]
Envoy? : mercredi 4 septembre 2013 17:31
? : BLANDENIER Lucien; r-help at R-project.org
Objet : RE: [R] Problem with installing the TRR package

The latest release (2013-05-16, Good Sport) R-3.0.1 so perhaps you need to upgrade to 3.0.1?

John Kane
Kingston ON Canada


> -----Original Message-----
> From: lucien.blandenier at unine.ch
> Sent: Wed, 4 Sep 2013 15:05:03 +0000
> To: r-help at r-project.org
> Subject: [R] Problem with installing the TRR package
>
> Dear all,
>
> I met some problems trying to install the TRR package.
>
> I runed the command : install.packages("TRR")
>
>
> I've received the following message :
>
> In getDependencies(pkgs, dependencies, available, lib) :
>   package ?TRR? is not available (for R version 2.14.1)
>
> I'm in Linux Mint and it seems it that the R 2.14.1 is the latest
> version.
>
> Does someones could give some guidance how to install the TRR package?
>
> Regards
>
>
> Lucien
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!
Check it out at http://www.inbox.com/marineaquarium




From szehnder at uni-bonn.de  Thu Sep  5 10:08:21 2013
From: szehnder at uni-bonn.de (szehnder at uni-bonn.de)
Date: Thu, 5 Sep 2013 08:08:21 +0000
Subject: [R] Problem with installing the TRR package
In-Reply-To: <84F1DDBD03D55944AA4E63A2FE5EADE553086233@MAIL-MBX-05.UNINE.CH>
References: <84F1DDBD03D55944AA4E63A2FE5EADE5530860B8@MAIL-MBX-05.UNINE.CH>
	,	<757E37E70E2.000007DEjrkrideau@inbox.com>
	<84F1DDBD03D55944AA4E63A2FE5EADE553086233@MAIL-MBX-05.UNINE.CH>
Message-ID: <1746107944-1378368494-cardhu_decombobulator_blackberry.rim.net-188360395-@b13.c6.bise7.blackberry>

I do not know Linux Mint, but what is always possible is to build R from sources on a UNIX system. 
Gesendet ?ber den BlackBerry? Service von E-Plus.

-----Original Message-----
From: BLANDENIER Lucien <lucien.blandenier at unine.ch>
Sender: r-help-bounces at r-project.orgDate: Thu, 5 Sep 2013 07:01:48 
To: John Kane<jrkrideau at inbox.com>; r-help at R-project.org<r-help at r-project.org>
Subject: Re: [R] Problem with installing the TRR package

Do you know if R-3.0.1 is available for Linux Mint? Do you know how I can check it?


________________________________________
De : John Kane [jrkrideau at inbox.com]
Envoy? : mercredi 4 septembre 2013 17:31
? : BLANDENIER Lucien; r-help at R-project.org
Objet : RE: [R] Problem with installing the TRR package

The latest release (2013-05-16, Good Sport) R-3.0.1 so perhaps you need to upgrade to 3.0.1?

John Kane
Kingston ON Canada


> -----Original Message-----
> From: lucien.blandenier at unine.ch
> Sent: Wed, 4 Sep 2013 15:05:03 +0000
> To: r-help at r-project.org
> Subject: [R] Problem with installing the TRR package
>
> Dear all,
>
> I met some problems trying to install the TRR package.
>
> I runed the command : install.packages("TRR")
>
>
> I've received the following message :
>
> In getDependencies(pkgs, dependencies, available, lib) :
>   package ?TRR? is not available (for R version 2.14.1)
>
> I'm in Linux Mint and it seems it that the R 2.14.1 is the latest
> version.
>
> Does someones could give some guidance how to install the TRR package?
>
> Regards
>
>
> Lucien
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!
Check it out at http://www.inbox.com/marineaquarium



______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From bhh at xs4all.nl  Thu Sep  5 10:23:54 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 5 Sep 2013 10:23:54 +0200
Subject: [R] Problem with installing the TRR package
In-Reply-To: <84F1DDBD03D55944AA4E63A2FE5EADE553086233@MAIL-MBX-05.UNINE.CH>
References: <84F1DDBD03D55944AA4E63A2FE5EADE5530860B8@MAIL-MBX-05.UNINE.CH>,
	<757E37E70E2.000007DEjrkrideau@inbox.com>
	<84F1DDBD03D55944AA4E63A2FE5EADE553086233@MAIL-MBX-05.UNINE.CH>
Message-ID: <84EF2580-6B09-427C-81DF-2C408131F653@xs4all.nl>


On 05-09-2013, at 09:01, BLANDENIER Lucien <lucien.blandenier at unine.ch> wrote:

> Do you know if R-3.0.1 is available for Linux Mint? Do you know how I can check it?
> 

Look on CRAN:  http://cran.r-project.org/bin/linux/ubuntu/
Since Mint is derived from Ubuntu this should work.

Berend

> ________________________________________
> De : John Kane [jrkrideau at inbox.com]
> Envoy? : mercredi 4 septembre 2013 17:31
> ? : BLANDENIER Lucien; r-help at R-project.org
> Objet : RE: [R] Problem with installing the TRR package
> 
> The latest release (2013-05-16, Good Sport) R-3.0.1 so perhaps you need to upgrade to 3.0.1?
> 
> John Kane
> Kingston ON Canada
> 
> 
>> -----Original Message-----
>> From: lucien.blandenier at unine.ch
>> Sent: Wed, 4 Sep 2013 15:05:03 +0000
>> To: r-help at r-project.org
>> Subject: [R] Problem with installing the TRR package
>> 
>> Dear all,
>> 
>> I met some problems trying to install the TRR package.
>> 
>> I runed the command : install.packages("TRR")
>> 
>> 
>> I've received the following message :
>> 
>> In getDependencies(pkgs, dependencies, available, lib) :
>>  package ?TRR? is not available (for R version 2.14.1)
>> 
>> I'm in Linux Mint and it seems it that the R 2.14.1 is the latest
>> version.
>> 
>> Does someones could give some guidance how to install the TRR package?
>> 
>> Regards
>> 
>> 
>> Lucien
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ____________________________________________________________
> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!
> Check it out at http://www.inbox.com/marineaquarium
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From arrayprofile at yahoo.com  Thu Sep  5 10:37:54 2013
From: arrayprofile at yahoo.com (array chip)
Date: Thu, 5 Sep 2013 01:37:54 -0700 (PDT)
Subject: [R] sparse PCA using nsprcomp package
Message-ID: <1378370274.8239.YahooMailNeo@web122906.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130905/6263cd9a/attachment.pl>

From teresamarso at hotmail.com  Thu Sep  5 11:07:12 2013
From: teresamarso at hotmail.com (=?iso-8859-1?B?TaogVGVyZXNhIE1hcnRpbmV6IFNvcmlhbm8=?=)
Date: Thu, 5 Sep 2013 09:07:12 +0000
Subject: [R] R Help
Message-ID: <DUB125-W805072ED30788ADCC9E95B9330@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130905/4d29462b/attachment.pl>

From kridox at ymail.com  Thu Sep  5 11:22:58 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 5 Sep 2013 18:22:58 +0900
Subject: [R] R Help
In-Reply-To: <DUB125-W805072ED30788ADCC9E95B9330@phx.gbl>
References: <DUB125-W805072ED30788ADCC9E95B9330@phx.gbl>
Message-ID: <CAAcyNCw=sRHXKKZPJTcAAwGgWUYpG_ZfCSOMprsy+bXNPnqpkA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130905/92458836/attachment.pl>

From ligges at statistik.tu-dortmund.de  Thu Sep  5 12:10:52 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 05 Sep 2013 12:10:52 +0200
Subject: [R] New Version of R 3.0.1 problems with installing Rcmdr
In-Reply-To: <1378347592735-4675414.post@n4.nabble.com>
References: <1378347592735-4675414.post@n4.nabble.com>
Message-ID: <522858AC.8030806@statistik.tu-dortmund.de>


On 05.09.2013 04:19, alanidris wrote:
> I have been using R version 2.15.1 happly along side R Commander. I then
> tried to go through a fresh install using the latest version of R, R 3.0.1.
> The trouble started when I wanted to install Rcmdr, I kept getting an error
> message about previous installs of R Commander. I went through and
> deinstalled all versions of R and tried fresh installs. Still could not get
> R Commander installed using the Latest version of R.
>
> It is possible that restrictions placed on me through my work computer may
> be a factor. But I tried numerous times to deinstall all versions of R and
> reinstall R 3.0.1, but I could not install the R Commander package. I then
> deinstalled all versions of R and then decided to install an earlier
> verision of R. This time I was more succesfull and after a few repeated
> starts of R 2.15.1 i managed to get R Commander working.
>
> Talk about a frustrating effort, can any one put any light on this issue? I
> work at a University where firewalls may be a factor, but this is only a
> guess.
>
> Please dont get too technical I know very little of how R installs itself
> and finds out where various packages and modules are. PS I am using Windows
> 7 as the operating system.


1. You must not load a package such as Rcmdr prior to reinstalltion / 
update.

2. If this is installed on a network shared directory, all other members 
of your group have to unload the package.

Uwe Ligges



>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/New-Version-of-R-3-0-1-problems-with-installing-Rcmdr-tp4675414.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From spyqqqdia at yahoo.com  Thu Sep  5 12:23:15 2013
From: spyqqqdia at yahoo.com (Michael Meyer)
Date: Thu, 5 Sep 2013 18:23:15 +0800 (SGT)
Subject: [R] optim evils
Message-ID: <1378376595.24747.YahooMailNeo@web193405.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130905/655543c1/attachment.pl>

From Sebastien.Bihorel at cognigencorp.com  Thu Sep  5 13:12:05 2013
From: Sebastien.Bihorel at cognigencorp.com (Sebastien Bihorel)
Date: Thu, 5 Sep 2013 07:12:05 -0400
Subject: [R] Capturing warnings with capture.output
Message-ID: <52286705.6010704@cognigencorp.com>

Dear R-users,

I would like to follow-up on a old thread by Hadley Wickham about 
capturing warnings with capture.output. My goal is to evaluate a 
function call and capture the results of the function call plus warning 
calls and messages if a warning is returned. For instance, in the 
following case, I would like to capture the 3 lines of text returned by R

 > log(-1)
[1] NaN
Warning message:
In log(-1) : NaNs produced

In Hadley's thread, a combination of capture.output and a custom 
"withWarnings" function was proposed to capture warnings but this seems 
to only capture the warning message and the results of the function call.

withWarnings <- function(expr) {
      wHandler <- function(w) {
       cat(w$message, "\n")
       invokeRestart("muffleWarning")
      }
      withCallingHandlers(expr, warning = wHandler)
}

 > out <- capture.output(withWarnings(log(-1)))
 > out
[1] "NaNs produced " "[1] NaN"

In withWarnings, the wHandler function manipulate an object w, which I 
understand to be a list with a call and message levels. All my attempts 
to manipulate w$call failed because w$call is of class language. I don't 
know how to work with this class and I would appreciate any advise on 
how to process this type of object. Again, the goal is to store both 
call and message in the output of the withWarnings function.

Thank you

Sebastien


From istazahn at gmail.com  Thu Sep  5 13:20:31 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 5 Sep 2013 07:20:31 -0400
Subject: [R] Read a Google Spreadsheet?
In-Reply-To: <CANz9Z_LL7UJeDAtubow+JFDpiPcRj8p-AxwwM1HTmFhxn_nnCA@mail.gmail.com>
References: <5227B050.1080502@structuremonitoring.com>
	<CA+vqiLEbZK_3-oGD3DjjVz3n9NsShMFUvTMP+-MqBHkzu8eNww@mail.gmail.com>
	<5227E020.4000401@structuremonitoring.com>
	<CANz9Z_LL7UJeDAtubow+JFDpiPcRj8p-AxwwM1HTmFhxn_nnCA@mail.gmail.com>
Message-ID: <CA+vqiLEP1dOa2O5uLOXO=tjGQWAE-YvfsAJR3pvj8gNAJVCuPg@mail.gmail.com>

I've also never had a problem with both 32 and 64 bit java installed.

Best,
Ista

On Wed, Sep 4, 2013 at 9:50 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
> Hi Spencer,
>
> It really is not very hard, and I have never had issue with it:
>
> http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html
>
> Just download the x86 and x64 versions for your OS and install.  Worst
> case, you need to add the directory to the PATH variable in Windows.
>
> I do this regularly so I can use/test either version of R.
>
> Cheers,
>
> Josh
>
> P.S. Emacs + ESS allows for different versions of R and it is not too
> difficult to use the 64 or 32 bit version... M-x
> R-version-architecture
>
>
> On Wed, Sep 4, 2013 at 6:36 PM, Spencer Graves
> <spencer.graves at structuremonitoring.com> wrote:
>> On 9/4/2013 6:09 PM, Ista Zahn wrote:
>>>
>>> Hi Spencer,
>>>
>>> Why don't you want to install 64bit Java?
>>
>>
>>
>>       That may be a reasonable approach.
>>
>>
>>       I may have Java confused with something else, but I remember hearing
>> that it was difficult or unwise to try to install both 32- and 64-bit
>> versions of something like Java or Java Script on the same Windows operating
>> system.  If I need to uninstall 32-bit Java to install 64-bit, who knows
>> what else I could break.  I'm a statistician, not an information
>> technologist:  If I spend more time playing with Java, I'll have less time
>> for other things I want to do.
>>
>>
>>       Thanks for the reply.
>>       Spencer
>>>
>>>
>>> On Wed, Sep 4, 2013 at 6:12 PM, Spencer Graves
>>> <spencer.graves at structuremonitoring.com> wrote:
>>>>
>>>> Hello, All:
>>>>
>>>>
>>>> What do you recommend for reading a Google Spreadsheet into R? I didn't
>>>> find
>>>> anything useful using library(sos); findFn('google spreadsheet').
>>>>
>>>>
>>>> I can solve the problem by downloading the file either as *.ods or *.xlsx
>>>> format, then opening it and saving it as *.xls, then using
>>>> read.xls{gdata}.
>>>>
>>>>
>>>> Alternatives I haven't tried use read.xlsx{xlsx} and
>>>> readWorksheetFromFile{XLConnect} with 32-bit R. Neither of these work for
>>>> me
>>>> with 64-bit R, because they can't find an appropriate rJava on my
>>>> computer;
>>>> see below. (I've been using 64-bit R with Emacs, so switching to 32-bit R
>>>> is
>>>> not completely trivial.) Similarly, read.gnumeric.sheet{gnumeric}
>>>> requires
>>>> the "external program, ssconvert", which seems not to be available on my
>>>> computer or installed for 64-bit R.
>>>>
>>>>
>>>> What do you suggest? Avoid 64-bit R unless I really need it? That seems
>>>> to
>>>> be the message I'm getting from this. (The writeFindFn2xls{sos} also
>>>> works
>>>> in 32-bit R but fails in 64-bit apparently for the same reason.)
>>>>
>>>>
>>>> Thanks,
>>>> Spencer
>>>>
>>>>
>>>>> library(xlsx)
>>>>
>>>> Loading required package: xlsxjars
>>>> Loading required package: rJava
>>>> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>>>> call: fun(libname, pkgname)
>>>> error: No CurrentVersion entry in Software/JavaSoft registry! Try
>>>> re-installing Java and make sure R and Java have matching architectures.
>>>> Error: package ?rJava? could not be loaded
>>>>>
>>>>> library(XLConnect)
>>>>
>>>> Loading required package: rJava
>>>> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>>>> call: fun(libname, pkgname)
>>>> error: No CurrentVersion entry in Software/JavaSoft registry! Try
>>>> re-installing Java and make sure R and Java have matching architectures.
>>>> Error: package ?rJava? could not be loaded
>>>>>
>>>>> sessionInfo()
>>>>
>>>> R version 3.0.1 (2013-05-16)
>>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>>
>>>> locale:
>>>> [1] LC_COLLATE=English_United States.1252
>>>> [2] LC_CTYPE=English_United States.1252
>>>> [3] LC_MONETARY=English_United States.1252
>>>> [4] LC_NUMERIC=C
>>>> [5] LC_TIME=English_United States.1252
>>>>
>>>> attached base packages:
>>>> [1] stats graphics grDevices utils datasets methods base
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Joshua Wiley
> Ph.D. Student, Health Psychology
> University of California, Los Angeles
> http://joshuawiley.com/
> Senior Analyst - Elkhart Group Ltd.
> http://elkhartgroup.com


From dwinsemius at comcast.net  Thu Sep  5 13:40:00 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 5 Sep 2013 07:40:00 -0400
Subject: [R] xyplot and lwd
In-Reply-To: <201309050855.03057.daniel.hornung@ds.mpg.de>
References: <201309042245.52185.daniel.hornung@ds.mpg.de>
	<CACk-te1xuVYGS=yt93HSs_NcWb0GMZ53iqQWywVH8_EuvmhUiw@mail.gmail.com>
	<201309050855.03057.daniel.hornung@ds.mpg.de>
Message-ID: <E9221340-D03E-4D56-B590-62C02491D500@comcast.net>


On Sep 5, 2013, at 2:54 AM, Daniel Hornung wrote:

>> On Wed, Sep 4, 2013 at 1:45 PM, Daniel Hornung
> <daniel.hornung at ds.mpg.de>wrote:
>>> Hello,
>>>
>>> can it be that xyplot does not support the lwd argument?

The lattice plotting system uses the grid plotting engine and does  
accepts some base  par-type arguments but not all. You may need to  
read more about lattice and grid:

?lattice
?trellis.par.set
require(grid)
?gpar

-- 
David.
>>>
>>> At least here, the following still shows thin lines, as opposed to  
>>> the
>>> regular
>>> plot command:
>>>
>>> xyplot(Sepal.Length ~ Sepal.Width, data = iris, pch=4, lwd=4)
>
> On Thursday, September 05, 2013 00:33:32 Bert Gunter wrote:
>> You should get no lines at all, as you have not specified that  
>> lines be
>> drawn. Use the "type" argument to do so.
>>
>> xyplot(rnorm(5) ~1:5,pch=4)  ## points only
>> xyplot(rnorm(5) ~1:5,pch=4,type="b",lwd=4) ## points with thick lines
>>
>> read ?panel.xyplot carefully (the default panel function for  
>> xyplot) for
>> details
>>
>> Cheers,
>> Bert
>
> Hello Bert,
>
> no, maybe I expressed myself ambiguously: I was referring to the line
> thickness of the symbols, not a line between symbols:
>
> xyplot(rnorm(5) ~ 1:5, pch=4, lwd=4)
> versus
> plot(rnorm(5), 1:5, pch=4, lwd=4)
>
> I would like the points (4("x") in this case) to have thicker lines.
>
> Cheers,
> Daniel
>

David Winsemius, MD
Alameda, CA, USA


From daniel.hornung at ds.mpg.de  Thu Sep  5 13:52:55 2013
From: daniel.hornung at ds.mpg.de (Daniel Hornung)
Date: Thu, 5 Sep 2013 13:52:55 +0200
Subject: [R] xyplot and lwd
In-Reply-To: <E9221340-D03E-4D56-B590-62C02491D500@comcast.net>
References: <201309042245.52185.daniel.hornung@ds.mpg.de>
	<201309050855.03057.daniel.hornung@ds.mpg.de>
	<E9221340-D03E-4D56-B590-62C02491D500@comcast.net>
Message-ID: <201309051352.58758.daniel.hornung@ds.mpg.de>

On Thursday, September 05, 2013 13:40:00 David Winsemius wrote:
> >>> can it be that xyplot does not support the lwd argument?
> 
> The lattice plotting system uses the grid plotting engine and does
> accepts some base  par-type arguments but not all. You may need to
> read more about lattice and grid:
> 
> ?lattice
> ?trellis.par.set
> require(grid)
> ?gpar

Thanks for the hint, I will look further into this direction.

Daniel

-- 
Max-Planck-Institute for Dynamics and Self-Organization
Laboratory for Fluid Dynamics, Pattern Formation and Biocomplexity
Biomedical Physics Group

Am Fassberg 17
D-37077 Goettingen

(+49) 551 5176 373
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 836 bytes
Desc: This is a digitally signed message part.
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130905/5c57d7c5/attachment.bin>

From Giovanni_Millo at Generali.com  Thu Sep  5 14:06:01 2013
From: Giovanni_Millo at Generali.com (Millo Giovanni)
Date: Thu, 5 Sep 2013 14:06:01 +0200
Subject: [R] Attribute Length Error when Trying plm Regression
Message-ID: <D41D66AB93B9E04BBA5378B621FFDACB034CF2EB@BEMAILEXPD01.corp.generali.net>

Dear Laura,

as Arun said it is difficult to help w/o a reproducible example. However
this is most likely to be an indexing problem, as he suggests; the
output of traceback() is far from useless here, because it shows that
the problem occurs in the data transformation step. The latter, which is
by default the within transf., wants (correct indexing and-) time
variation in the data. Hence I suggest you 
- better check the data, especially indices, possibly with str() to see
if they have the right type etc.
then do simpler things, complicating step by step until you spot the
critical one:
- try lm(yourformula, yourdata) to see whether there are data problems
w.r.t. OLS (unlikely, but would spot string variables or other common
pitfalls)
- try pdata.frame() using the individual and time index, to spot if the
indices are somehow inappropriate
- try plm(... , model="pooling"), which does not transform the data, or
model="random", which allows for time-invariants; both are more tolerant
than "within"

This is most likely either bad indices or bad data formats/NAs/empty
groups...

Best wishes,
Giovanni

Giovanni Millo, PhD
Research Dept.,
Assicurazioni Generali SpA
Via Machiavelli 3,
34132 Trieste (Italy)
tel. +39 040 671184
fax  +39 040 671160


------------ Original thread ------------------

Message: 48
Date: Wed, 4 Sep 2013 14:14:23 -0700 (PDT)
From: arun <smartpink111 at yahoo.com>
To: lross8 <lross8 at kent.edu>
Cc: R help <r-help at r-project.org>
Subject: Re: [R] Attribute Length Error when Trying plm Regression
Message-ID:
	<1378329263.73618.YahooMailNeo at web142604.mail.bf1.yahoo.com>
Content-Type: text/plain; charset=iso-8859-1

HI,
It is better to provide a reproducible example using ?dput().
you can also check in this link.

http://r.789695.n4.nabble.com/names-attribute-must-be-the-same-length-as
-the-vector-td4503946.html

library(plm)
#Using the example from ?plm()
?data("Produc", package = "plm")
?zz <- plm(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp, data =
Produc, index = c("state","year"))

#Suppose, if I use a model like this:
zz1<-
plm(gsp~pcap+pc+emp+unemp+water+util,data=Produc,index=c("gsp","year"))
#Error in names(y) <- namesy : 
?# 'names' attribute [816] must be the same length as the vector [0]

In your model statement, 

fixed <- plm (h ~ o + m + a, data=drugsXX, index=c("h","year"),
model="within") 


A.K.


----- Original Message -----
From: lross8 <lross8 at kent.edu>
To: r-help at r-project.org
Cc: 
Sent: Wednesday, September 4, 2013 3:22 PM
Subject: [R] Attribute Length Error when Trying plm Regression

Hello,

I am trying to run a fixed effects panel regression on data containing 5
columns and 1,494 rows. 

I read the data in as follows:

>drugsXX<-read.csv(file="C:\\Folder\\vX.X\\Drugs\\drugsXX_panel.csv",
head=TRUE, sep=",")

Verified it read in correctly and had a good data.frame:
>dim(drugsXX)
[1] 1494? ? 5
>drugs XX
produce expected data with correct column names

The issue is, when I go to run the plm using:
>fixed <- plm (h ~ o + m + a, data=drugsXX, index=c("h","year"),
model="within") 

I get this error:
Error in names(y) <- namesy : 
? 'names' attribute [996] must be the same length as the vector [0]

I know the data recognizes that I have 5 columns. I also know that
there's
nothing wrong with row 996 (I even want back and checked for hidden
characters in the original .csv file).

traceback() was useless:
4: pmodel.response.pFormula(formula, data, model = model, effect =
effect, 
? ? ?  theta = theta)
3: pmodel.response(formula, data, model = model, effect = effect, 
? ? ?  theta = theta)
2: plm.fit(formula, data, model, effect, random.method, inst.method)
1: plm(h ~ o + m + a, data = drugsXX, index = c("h", 
? ? ?  "year"), model = "within")

What explicit steps can I follow to get my panel regression to run? 

Thank you, 
Laura



--
View this message in context:
http://r.789695.n4.nabble.com/Attribute-Length-Error-when-Trying-plm-Reg
ression-tp4675384.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

------------- end original thread --------------

?
Ai sensi del D.Lgs. 196/2003 si precisa che le informazi...{{dropped:12}}


From kiran4u2all at gmail.com  Thu Sep  5 14:44:49 2013
From: kiran4u2all at gmail.com (Venkata Kirankumar)
Date: Thu, 5 Sep 2013 18:14:49 +0530
Subject: [R] Problem with converting F to FALSE
Message-ID: <CABXCXR3WSQfN00CJvx-2mLdi3iL2sJTJ7QtvjPddAnamKj50FQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130905/210f151c/attachment.pl>

From pmassicotte at hotmail.com  Thu Sep  5 14:54:47 2013
From: pmassicotte at hotmail.com (philippe massicotte)
Date: Thu, 5 Sep 2013 12:54:47 +0000
Subject: [R] Problem with converting F to FALSE
In-Reply-To: <CABXCXR3WSQfN00CJvx-2mLdi3iL2sJTJ7QtvjPddAnamKj50FQ@mail.gmail.com>
References: <CABXCXR3WSQfN00CJvx-2mLdi3iL2sJTJ7QtvjPddAnamKj50FQ@mail.gmail.com>
Message-ID: <COL127-W509915C6F1547F69211D2DB3330@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130905/84baf3d9/attachment.pl>

From smartpink111 at yahoo.com  Thu Sep  5 14:56:10 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 5 Sep 2013 05:56:10 -0700 (PDT)
Subject: [R] Problem with converting F to FALSE
Message-ID: <1378385770.15999.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
Try:
dat1<-read.table(text="
sex? group
F?????? 1
F?????? 2
F?????? 3
",sep="",header=TRUE,colClasses=c("character","numeric"))
?dat1
#? sex group
#1?? F???? 1
#2?? F???? 2
#3?? F???? 3


#if you are using read.csv()
?dat2<-read.csv("new1.csv",sep="",header=TRUE,colClasses=c("character","numeric"))
?dat2
#? sex group
#1?? F???? 1
#2?? F???? 2
#3?? F???? 3


#Suppose you want to convert after reading it:
?dat2New<-read.csv("new1.csv",sep="",header=TRUE)
?dat2New[,1]<-substr(dat2New[,1],1,1)
?dat2New
#? sex group
#1?? F???? 1
#2?? F???? 2
#3?? F???? 3
A.K.


Hi, 
I have a peculier problem in R-Project that is when my CSV file have one 
column with all values as 'F' the R-Project converting this 'F' to FALSE. 
Can some one please suggest how to stop this convertion. Because I want to 
use 'F' in my calculations and show it in screen. for example my data is 
like 

sex ?group 
F ? ? ? 1 
F ? ? ? 2 
F ? ? ? 3 

but when I use read.csv and load the csv file data is converting it to 

sex ? ? ? ? ?group 
FALSE ? ? ? 1 
FALSE ? ? ? 2 
FALSE ? ? ? 3 
but i want it as source data like 

sex group 
F ? ? ?1 
F ? ? ?2 
F ? ? ?3 


Thanks in advance, 
D V Kiran Kumar


From jwiley.psych at gmail.com  Thu Sep  5 14:58:48 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 5 Sep 2013 05:58:48 -0700
Subject: [R] Problem with converting F to FALSE
In-Reply-To: <CABXCXR3WSQfN00CJvx-2mLdi3iL2sJTJ7QtvjPddAnamKj50FQ@mail.gmail.com>
References: <CABXCXR3WSQfN00CJvx-2mLdi3iL2sJTJ7QtvjPddAnamKj50FQ@mail.gmail.com>
Message-ID: <CANz9Z_Kfw7jUtHDTQ8O3O3cYXhQAFq+AxCsWDSbFd6tKi_ipkg@mail.gmail.com>

Hi,

You can either manually specify colClasses or the asis argument.  See
?read.csv for more details.

If you just had those two columns, something like:

     read.table(header = TRUE, text = "
     sex group
     F 1
     T 2
     ", colClasses = c("character", "integer"))

Cheers,

Josh


read.csv("file.csv", colClasses = c("character", "integer"))




On Thu, Sep 5, 2013 at 5:44 AM, Venkata Kirankumar
<kiran4u2all at gmail.com> wrote:
> Hi,
> I have a peculier problem in R-Project that is when my CSV file have one
> column with all values as 'F' the R-Project converting this 'F' to FALSE.
> Can some one please suggest how to stop this convertion. Because I want to
> use 'F' in my calculations and show it in screen. for example my data is
> like
>
> sex  group
> F       1
> F       2
> F       3
>
> but when I use read.csv and load the csv file data is converting it to
>
> sex          group
> FALSE       1
> FALSE       2
> FALSE       3
> but i want it as source data like
>
> sex group
> F      1
> F      2
> F      3
>
>
> Thanks in advance,
> D V Kiran Kumar
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://joshuawiley.com/
Senior Analyst - Elkhart Group Ltd.
http://elkhartgroup.com


From mohan.radhakrishnan at polarisft.com  Thu Sep  5 15:22:43 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Thu, 5 Sep 2013 18:52:43 +0530
Subject: [R] Y-axis labels as decimal numbers
Message-ID: <OF36A91BE0.A8B1F70D-ON65257BDD.00492114-65257BDD.00496C61@polarisft.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130905/d40b5127/attachment.pl>

From anna.zakrisson at su.se  Thu Sep  5 12:13:17 2013
From: anna.zakrisson at su.se (Anna Zakrisson Braeunlich)
Date: Thu, 5 Sep 2013 10:13:17 +0000
Subject: [R] ggplot2: connecting medians of boxes using facet_wrap. Changing
 median marker.
Message-ID: <11019DCE9B47004F90B2D9C62FF15792025D4E67@ebox-prod-srv02.win.su.se>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130905/fcb559b8/attachment.pl>

From letterjaya at gmail.com  Thu Sep  5 13:24:18 2013
From: letterjaya at gmail.com (Jaya Pudashine)
Date: Thu, 5 Sep 2013 18:24:18 +0700
Subject: [R] Using qmap module
Message-ID: <CAGja6kSj=u0DQy8G6rZ9+By9niKpToM1xsG3D0Z+ioNBhyO=yQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130905/78c27f93/attachment.pl>

From istazahn at gmail.com  Thu Sep  5 15:44:34 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 5 Sep 2013 09:44:34 -0400
Subject: [R] Poly Correlations
In-Reply-To: <057601cea9de$46d3e9d0$d47bbd70$@nycap.rr.com>
References: <057601cea9de$46d3e9d0$d47bbd70$@nycap.rr.com>
Message-ID: <CA+vqiLH8t_283d27L67vW0sPMztQhWiwxHvWDLFGVY6fG8uaNA@mail.gmail.com>

Hi Michael,

See comments in line.

On Wed, Sep 4, 2013 at 10:18 PM, Michael Hacker <mhacker at nycap.rr.com> wrote:
> Dear Colleagues,
>
>
>
> I'm working on a Delphi study comparing perceptions of high school
> technology teachers and university engineering educators about the
> importance of concepts about engineering for HS students to learn as part of
> their fundamental education. I'm actually doing this as part of my Ph.D.
>
> The survey items (n=37) are categorized into five scales: design, human
> values, modeling, resources, and systems thinking. I'm seeking to determine
> the reliability of these scales and of the overall survey instrument. Since
> I'm working with ordinal data, Chronbach's Alpha probably isn't the best
> statistical tool to use.
>
>
>
> I've literally spent several days learning my way around R-project but am
> struggling with procedures and interpretations.
>
>
>
> I'm aware that there is now a plug-in for R for SPSS that can be downloaded
> ( <http://www-01.ibm.com/support/docview.wss?uid=swg21477550>
> http://www-01.ibm.com/support/docview.wss?uid=swg21477550 and
> <http://gruener.userpage.fu-berlin.de/Essentials%20for%20R%20Installation%20
> Instructions_21.pdf>
> http://gruener.userpage.fu-berlin.de/Essentials%20for%20R%20Installation%20I
> nstructions_21.pdf). Just learned that today and I downloaded
> PolyCorrelations.zip from
> https://www.ibm.com/developerworks/community/files/app?lang=en#/file/9f47f9a
> 0-7793-4ad5-8bb7-d3fd1a028e44
>
>

I would ditch the SPSS/R integration and just run R from RCommander.
You don't need PollyCorrelations.zip or SPSS for this, and trying to
get the R and SPSS talking to each other is just another level of
complication that you don't need.

>
> I've gotten as far as loading Rcmdr and running some analyses - (Statistics,
> dimensional analysis, scale reliability) and I've generated this output:
>
>
>
> Reliability deleting each item in turn:
>
>                         Alpha   Std.Alpha   r(item, total)
>
> design              0.8445    0.8490         0.7629
>
> humanvalues   0.8526    0.8541         0.7170
>
> modeling          0.8511    0.8546         0.7271
>
> resources        0.8712    0.8757         0.6328
>
> systems           0.8461    0.8498         0.7488
>
>
>
> I now would sincerely appreciate some help. At the age of 70, never having
> studied programming, the meaning of these statistics is not apparent.

Understanding these statistics has nothing to do with studying
programming. You need to study statistics!

>
> For example, I'm not clear if either of these three statistics are Ordinal
> Alpha. Since I'm working with Likert scale items, my advisor suggested that
> I seek an alternative to Chronbach's Alpha to determine reliability.

Since we have no idea how you calculated these statistics there is no
way for us to answer this question.

>
>
>
> So far, here are the steps I have taken:
>
> I've searched the FAQs
>
> Searched specifically for answers on the Web
>
> Played with the software for hours
>
> Read the accompanying documentation.
>
> Downloaded and installed Rcmdr
>
> Downloaded and installed PolyCorrelations.
>
>
>
> I tried running PolyCorrelations  but I get a message that states that this
> requires the Polychor and Gclus libraries. I tried to install them into the
> R console, but no luck.

What does "no luck" mean?

>
>
>
> I'd also be pleased to work with someone-on-one on a consulting basis if
> someone has the time and inclination.  Hoping to find an individual who
> knows SPSS and R.

Appendix B of http://pareonline.net/pdf/v17n3.pdf shows how to
calculate reliability from ordinal data using R.

Best,
Ista


>
>
>
> Thanks very sincerely for considering this request.
>
>
>
> Michael
>
>
>
>
>
> --------------------------------
>
> END OF MESSAGE
>
> --------------------------------
>
> Michael Hacker, Co-Director
>
> Hofstra University Center for STEM Education Research
>
> Ph: 518-724-6437
>
> Cell: 518-229-7300
>
> Fax: 518-434-6783
>
> URL: www.Hofstra.edu/CSR
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From keith.jewell at campdenbri.co.uk  Thu Sep  5 16:01:48 2013
From: keith.jewell at campdenbri.co.uk (Keith Jewell)
Date: Thu, 5 Sep 2013 15:01:48 +0100
Subject: [R] Problem with converting F to FALSE
In-Reply-To: <CANz9Z_Kfw7jUtHDTQ8O3O3cYXhQAFq+AxCsWDSbFd6tKi_ipkg@mail.gmail.com>
References: <CABXCXR3WSQfN00CJvx-2mLdi3iL2sJTJ7QtvjPddAnamKj50FQ@mail.gmail.com>
	<CANz9Z_Kfw7jUtHDTQ8O3O3cYXhQAFq+AxCsWDSbFd6tKi_ipkg@mail.gmail.com>
Message-ID: <l0a2s4$s6v$1@ger.gmane.org>

Depending what you're doing with the data, you might want
     colClasses=c("factor","numeric")

On 05/09/2013 13:58, Joshua Wiley wrote:
> Hi,
>
> You can either manually specify colClasses or the asis argument.  See
> ?read.csv for more details.
>
> If you just had those two columns, something like:
>
>       read.table(header = TRUE, text = "
>       sex group
>       F 1
>       T 2
>       ", colClasses = c("character", "integer"))
>
> Cheers,
>
> Josh
>
>
> read.csv("file.csv", colClasses = c("character", "integer"))
>
>
>
>
> On Thu, Sep 5, 2013 at 5:44 AM, Venkata Kirankumar
> <kiran4u2all at gmail.com>  wrote:
>> Hi,
>> I have a peculier problem in R-Project that is when my CSV file have one
>> column with all values as 'F' the R-Project converting this 'F' to FALSE.
>> Can some one please suggest how to stop this convertion. Because I want to
>> use 'F' in my calculations and show it in screen. for example my data is
>> like
>>
>> sex  group
>> F       1
>> F       2
>> F       3
>>
>> but when I use read.csv and load the csv file data is converting it to
>>
>> sex          group
>> FALSE       1
>> FALSE       2
>> FALSE       3
>> but i want it as source data like
>>
>> sex group
>> F      1
>> F      2
>> F      3
>>
>>
>> Thanks in advance,
>> D V Kiran Kumar


From dfife at ou.edu  Thu Sep  5 16:02:25 2013
From: dfife at ou.edu (Dustin Fife)
Date: Thu, 5 Sep 2013 09:02:25 -0500
Subject: [R] plot densities outside axis
Message-ID: <CAB0Y+LT4ni9_2WwE_piErTi9_R0WrfoKp4nqLSNO3XX0JieqFw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130905/aca820a5/attachment.pl>

From istazahn at gmail.com  Thu Sep  5 16:02:59 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 5 Sep 2013 10:02:59 -0400
Subject: [R] ggplot2: connecting medians of boxes using facet_wrap.
 Changing median marker.
In-Reply-To: <11019DCE9B47004F90B2D9C62FF15792025D4E67@ebox-prod-srv02.win.su.se>
References: <11019DCE9B47004F90B2D9C62FF15792025D4E67@ebox-prod-srv02.win.su.se>
Message-ID: <CA+vqiLGq=UCkvGpJrbxK=R_Nh5TWPnaMNUCZuHxF-YAZV34KCA@mail.gmail.com>

Hi Anna,

On Thu, Sep 5, 2013 at 6:13 AM, Anna Zakrisson Braeunlich
<anna.zakrisson at su.se> wrote:
> # Dear all,
>
> # Thank you for taking your time.
>
> # What I would like to do:
>
> # (Run the code below to see what I am referring to)
>
> # I want lines connecting the medians of of the boxes. I do not want a function, just a simple,
> # straight connection between points. I also would like the lines to be different: lty=c(1:3)

geom_line(stat="summary", fun.y = "median",
mapping=aes(linetype=organism, group=organism))

>
> # Furthermore, I wish to change the line/dot marking the medians to be pch=c(1:3). It seems not to be so simple when using facet_wrap? I have obviously missed something obvious.

geom_point(stat="summary", fun.y = "median", mapping=aes(shape=organism)) +

>
> # Finally, I would like the boxes to be filled white and to have the legend reflecting this.

Then don't tell ggplot to color them. Change

ggplot(mydata, aes(x = week, y = var1, fill = organism))

to

ggplot(mydata, aes(x = week, y = var1))
>
> # I know that this was many questions, I apologize if some may seem basic. It is just that I am
> # "jumping packages" the whole time and sometimes par() adjustments work and sometimes not.
> # I have searched alot for answers, but as a ggplot2 beginner, I have failed to find a solution
> # to my problems above.


Hope this helps!

Best,
Ista

>
> # I would like to thank the programmers for a great package. The layer principle is much easier to work with.
>
> ####
>
> # Some dummy data:
> mydata<- data.frame(week = factor(rep(c("19", "21", "23", "25", "27", "29", "31", "33",
>                                            "35", "37", "39"), each = 45*3)), #week
>                     station = factor(rep(c("BY31", "B1", "H2", "H3", "H4",
>                                            "H5", "H6", "H7", "H8"), each = 15)), #station
>                     organism = factor(rep(c("zpl", "ses", "cy"), each = 5)), #organism
>                     var1 = rnorm(1485, mean = rep(c(0, 3, 15), each = 40),
>                                  sd = rep(c(1, 3, 6), each = 20)))
>
> p <- ggplot(mydata, aes(x = week, y = var1, fill = organism)) +
>   geom_boxplot() +
>   facet_wrap(~ station, ncol = 3) +
>   theme_bw() +
>   theme(strip.background = element_blank())+
>   ylab("var1")+
>   xlab("week") +
>   geom_smooth(aes(group = 1), method="lm", se = F) +  #Here is my problem.
>   theme(strip.text.x = element_text(size = 12, colour="black", family="serif", angle=00)) +
>   theme(axis.text.x = element_text(size = 12, colour="black", family="serif", angle=90)) +
>   theme(axis.text.y = element_text(size = 12, colour="black", family="serif", angle=00)) +
>   geom_hline(yintercept=0, linetype=3) #draws dotted line at 0
>
> p
>
>   # method="lm" is definately wrong,
>   # I just added it to be a ble to draw some lines at all.
>   # I also suspect geom_smooth to be wrong.
> ### TO CLARIFY: I want the medians connected within each level. cy medians connected and
>   # and ses medians connected and zpl connected. Not cy-ses-zpl, but that is perhaps obvious.
> ### Thank you for your time!
>   # with kind regards
>   # A. Zakrisson
>
>
>
> Anna Zakrisson Braeunlich
> PhD student
>
> Department of Ecology, Environment and Plant Sciences
> Stockholm University
> Svante Arrheniusv. 21A
> SE-106 91 Stockholm
> Sweden/Sverige
>
> Lives in Berlin.
> For paper mail:
> Katzbachstr. 21
> D-10965, Berlin - Kreuzberg
> Germany/Deutschland
>
> E-mail: anna.zakrisson at su.se
> Tel work: +49-(0)3091541281
> Mobile: +49-(0)15777374888
> LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b
>
>><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?. .? `?. .><((((?>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From kiran4u2all at gmail.com  Thu Sep  5 16:09:46 2013
From: kiran4u2all at gmail.com (Venkata Kirankumar)
Date: Thu, 5 Sep 2013 19:39:46 +0530
Subject: [R] Problem with converting F to FALSE
In-Reply-To: <l0a2s4$s6v$1@ger.gmane.org>
References: <CABXCXR3WSQfN00CJvx-2mLdi3iL2sJTJ7QtvjPddAnamKj50FQ@mail.gmail.com>
	<CANz9Z_Kfw7jUtHDTQ8O3O3cYXhQAFq+AxCsWDSbFd6tKi_ipkg@mail.gmail.com>
	<l0a2s4$s6v$1@ger.gmane.org>
Message-ID: <CABXCXR1RRYp=3AJSyiQ6WOOzZbb02xdOhBzMn8TTEzJRPgengg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130905/48c6ec54/attachment.pl>

From dcarlson at tamu.edu  Thu Sep  5 16:17:12 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Thu, 5 Sep 2013 09:17:12 -0500
Subject: [R] Histogram
In-Reply-To: <5227C982.8020605@gmail.com>
References: <COL127-W49B3E97D4ABD80B64BCFEBB3320@phx.gbl>,
	<522789A8.8070800@sapo.pt>
	<COL127-W22EB827D05EAFB3CAC73B1B3320@phx.gbl>
	<042201cea9af$94e2de30$bea89a90$@tamu.edu>
	<5227C982.8020605@gmail.com>
Message-ID: <04ed01ceaa42$9db06670$d9113350$@tamu.edu>

I wasn't suggesting that much detail, but I think the addition
of one sentence in the last paragraph of the Details section
would make it the meaning of "the number is a suggestion only"
clearer. 

"These functions provide a suggested number of bins that may be
modified to produce 'round' breakpoints covering the range of
the values in x."

Added just before the last sentence, "Alternatively, . . ."

Also pretty() could be added to the See Also section.


David Carlson

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: Wednesday, September 4, 2013 7:00 PM
To: dcarlson at tamu.edu
Cc: 'philippe massicotte'; 'Rui Barradas';
'r-help at R-project.org'
Subject: Re: [R] Histogram

On 13-09-04 4:44 PM, David Carlson wrote:> Good question. It
turns out 
that the manual page does not tell
 > the whole story.

Do you really think the manual page would be improved if it went
into as 
much detail as you give below?  It does say clearly that breaks
is a 
"suggestion only".  I don't think it would be clearer if it
explained 
exactly how the suggestion is used. It would just be more
complicated, 
and less likely to be read.

Duncan Murdoch


  Looking at the source code for hist.default,
 > the function starts with the number of breaks suggested by
 > nclass.Sturges(), but then this number (or any other number
of
 > breaks that you specify) is passed to pretty() along with the
 > maximum and the minimum values of the data (ie range(data))
to
 > create "pretty" break intervals. In your example,
 > nclass.Sturges() always recommends 8 breaks, but the number
of
 > the breaks changes based on the minimum and maximum values.
So
 > the only way to get exactly the number of breaks you want is
to
 > specify the break intervals yourself.
 >
 > David Carlson
 >
 >
 > -----Original Message-----
 > From: r-help-bounces at r-project.org
 > [mailto:r-help-bounces at r-project.org] On Behalf Of philippe
 > massicotte
 > Sent: Wednesday, September 4, 2013 3:02 PM
 > To: Rui Barradas
 > Cc: r-help at R-project.org
 > Subject: Re: [R] Histogram
 >
 > Thank you everyone.
 > Try executing this:
 > replicate(100, length(hist(rnorm(100), nclass = 10)$counts))
 > I'm still not sure why the number of bins (classes) is not
 > consistent.
 > Thank in advance.
 >
 >> Date: Wed, 4 Sep 2013 20:27:36 +0100
 >> From: ruipbarradas at sapo.pt
 >> To: pmassicotte at hotmail.com
 >> CC: r-help at r-project.org
 >> Subject: Re: [R] Histogram
 >>
 >> Hello,
 >>
 >> See the arguments 'right' and 'include.lowest' of ?hist.
 >> To give what you want, try instead
 >>
 >> h1 <- hist(1:10, 10)  # counts are 2, 1, 1, ...
 >> h2 <- hist(1:10, breaks = 0:10)  # all counts are 1
 >>
 >>
 >> and see the difference between h1 and h2, components
'breaks'
 > and 'counts'.
 >>
 >> Hope this helps,
 >>
 >> Rui Barradas
 >>
 >> Em 04-09-2013 19:34, philippe massicotte escreveu:
 >>> Hi everyone.
 >>> I'm currently translating some Matlab code into R. However,
 > I realized that the hsit function produce different results
in
 > both languages.
 >>> in Matlab, hist(1:10, 10) will produce 10 bins with a count
 > of 1 in each, but in R it will produce 9 classes with count
of
 > 2,1,1,1,1,1,1,1,1.
 >>> I'm a bit embarrassed to ask such question, but why R is
not
 > producing 10 classes as requested?
 >>> Thanks in advance,Phil 		 	   		
 >>> 	[[alternative HTML version deleted]]
 >>>
 >>> ______________________________________________
 >>> R-help at r-project.org mailing list
 >>> https://stat.ethz.ch/mailman/listinfo/r-help
 >>> PLEASE do read the posting guide
 > http://www.R-project.org/posting-guide.html
 >>> and provide commented, minimal, self-contained,
reproducible
 > code.
 >>>
 >   		 	   		
 > 	[[alternative HTML version deleted]]
 >
 > ______________________________________________
 > R-help at r-project.org mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide
 > http://www.R-project.org/posting-guide.html
 > and provide commented, minimal, self-contained, reproducible
 > code.
 >
 > ______________________________________________
 > R-help at r-project.org mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
 > and provide commented, minimal, self-contained, reproducible
code.
 >


From gunter.berton at gene.com  Thu Sep  5 16:39:14 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 5 Sep 2013 07:39:14 -0700
Subject: [R] xyplot and lwd
In-Reply-To: <201309051352.58758.daniel.hornung@ds.mpg.de>
References: <201309042245.52185.daniel.hornung@ds.mpg.de>
	<201309050855.03057.daniel.hornung@ds.mpg.de>
	<E9221340-D03E-4D56-B590-62C02491D500@comcast.net>
	<201309051352.58758.daniel.hornung@ds.mpg.de>
Message-ID: <CACk-te3uKQrSKRmi6vbZDDS3bK2UEamKEPN2J9GA6fPFdVFmHg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130905/96a86316/attachment.pl>

From maechler at stat.math.ethz.ch  Thu Sep  5 16:41:07 2013
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 5 Sep 2013 16:41:07 +0200
Subject: [R] optim evils
In-Reply-To: <1378376595.24747.YahooMailNeo@web193405.mail.sg3.yahoo.com>
References: <1378376595.24747.YahooMailNeo@web193405.mail.sg3.yahoo.com>
Message-ID: <21032.38915.967197.335694@stat.math.ethz.ch>


> Thanks for all replies.
> The problem occurred in the following context:

> A Gaussian one dimensional mixture (number of constituents, locations, variances all unknown)
> is to be fitted to data (as starting value to or in lieu of mixtools). A likelihood maximization is performed.

Cool.  That is all provided with my  nor1mix  CRAN package  (of which
most parts I have written even before R came to life, i.e., for S):

The relatively new addition to  nor1mix  is the 
norMixMLE() function which uses my smart (almost) unconstrained
parametrization and hence typically works much better, i.e., faster than the EM.

Then, the code uses optim(), currently always with "BFGS".

Martin Maechler, ETH Zurich

> I'll try to destill the code so that reproducible failure of L-BFGS-B occurs
> and post it here.


> Michael Meyer


> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Thu Sep  5 16:41:46 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 05 Sep 2013 10:41:46 -0400
Subject: [R] Histogram
In-Reply-To: <04ed01ceaa42$9db06670$d9113350$@tamu.edu>
References: <COL127-W49B3E97D4ABD80B64BCFEBB3320@phx.gbl>,
	<522789A8.8070800@sapo.pt>
	<COL127-W22EB827D05EAFB3CAC73B1B3320@phx.gbl>
	<042201cea9af$94e2de30$bea89a90$@tamu.edu>
	<5227C982.8020605@gmail.com>
	<04ed01ceaa42$9db06670$d9113350$@tamu.edu>
Message-ID: <5228982A.9090003@gmail.com>

On 05/09/2013 10:17 AM, David Carlson wrote:
> I wasn't suggesting that much detail, but I think the addition
> of one sentence in the last paragraph of the Details section
> would make it the meaning of "the number is a suggestion only"
> clearer.
>
> "These functions provide a suggested number of bins that may be
> modified to produce 'round' breakpoints covering the range of
> the values in x."

I think that's the wrong place for it (since breaks=10 is perfectly 
fine, but is not a function).  I'll change the initial sentence to say:

In the last three cases the number is a suggestion only; the
      breakpoints will be set to \code{\link{pretty}} values.

If people want to know what pretty values are, they can follow the link.

Duncan Murdoch

>
> Added just before the last sentence, "Alternatively, . . ."
>
> Also pretty() could be added to the See Also section.
>
>
> David Carlson
>
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Wednesday, September 4, 2013 7:00 PM
> To: dcarlson at tamu.edu
> Cc: 'philippe massicotte'; 'Rui Barradas';
> 'r-help at R-project.org'
> Subject: Re: [R] Histogram
>
> On 13-09-04 4:44 PM, David Carlson wrote:> Good question. It
> turns out
> that the manual page does not tell
>   > the whole story.
>
> Do you really think the manual page would be improved if it went
> into as
> much detail as you give below?  It does say clearly that breaks
> is a
> "suggestion only".  I don't think it would be clearer if it
> explained
> exactly how the suggestion is used. It would just be more
> complicated,
> and less likely to be read.
>
> Duncan Murdoch
>
>
>    Looking at the source code for hist.default,
>   > the function starts with the number of breaks suggested by
>   > nclass.Sturges(), but then this number (or any other number
> of
>   > breaks that you specify) is passed to pretty() along with the
>   > maximum and the minimum values of the data (ie range(data))
> to
>   > create "pretty" break intervals. In your example,
>   > nclass.Sturges() always recommends 8 breaks, but the number
> of
>   > the breaks changes based on the minimum and maximum values.
> So
>   > the only way to get exactly the number of breaks you want is
> to
>   > specify the break intervals yourself.
>   >
>   > David Carlson
>   >
>   >
>   > -----Original Message-----
>   > From: r-help-bounces at r-project.org
>   > [mailto:r-help-bounces at r-project.org] On Behalf Of philippe
>   > massicotte
>   > Sent: Wednesday, September 4, 2013 3:02 PM
>   > To: Rui Barradas
>   > Cc: r-help at R-project.org
>   > Subject: Re: [R] Histogram
>   >
>   > Thank you everyone.
>   > Try executing this:
>   > replicate(100, length(hist(rnorm(100), nclass = 10)$counts))
>   > I'm still not sure why the number of bins (classes) is not
>   > consistent.
>   > Thank in advance.
>   >
>   >> Date: Wed, 4 Sep 2013 20:27:36 +0100
>   >> From: ruipbarradas at sapo.pt
>   >> To: pmassicotte at hotmail.com
>   >> CC: r-help at r-project.org
>   >> Subject: Re: [R] Histogram
>   >>
>   >> Hello,
>   >>
>   >> See the arguments 'right' and 'include.lowest' of ?hist.
>   >> To give what you want, try instead
>   >>
>   >> h1 <- hist(1:10, 10)  # counts are 2, 1, 1, ...
>   >> h2 <- hist(1:10, breaks = 0:10)  # all counts are 1
>   >>
>   >>
>   >> and see the difference between h1 and h2, components
> 'breaks'
>   > and 'counts'.
>   >>
>   >> Hope this helps,
>   >>
>   >> Rui Barradas
>   >>
>   >> Em 04-09-2013 19:34, philippe massicotte escreveu:
>   >>> Hi everyone.
>   >>> I'm currently translating some Matlab code into R. However,
>   > I realized that the hsit function produce different results
> in
>   > both languages.
>   >>> in Matlab, hist(1:10, 10) will produce 10 bins with a count
>   > of 1 in each, but in R it will produce 9 classes with count
> of
>   > 2,1,1,1,1,1,1,1,1.
>   >>> I'm a bit embarrassed to ask such question, but why R is
> not
>   > producing 10 classes as requested?
>   >>> Thanks in advance,Phil 		 	   		
>   >>> 	[[alternative HTML version deleted]]
>   >>>
>   >>> ______________________________________________
>   >>> R-help at r-project.org mailing list
>   >>> https://stat.ethz.ch/mailman/listinfo/r-help
>   >>> PLEASE do read the posting guide
>   > http://www.R-project.org/posting-guide.html
>   >>> and provide commented, minimal, self-contained,
> reproducible
>   > code.
>   >>>
>   >   		 	   		
>   > 	[[alternative HTML version deleted]]
>   >
>   > ______________________________________________
>   > R-help at r-project.org mailing list
>   > https://stat.ethz.ch/mailman/listinfo/r-help
>   > PLEASE do read the posting guide
>   > http://www.R-project.org/posting-guide.html
>   > and provide commented, minimal, self-contained, reproducible
>   > code.
>   >
>   > ______________________________________________
>   > R-help at r-project.org mailing list
>   > https://stat.ethz.ch/mailman/listinfo/r-help
>   > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>   > and provide commented, minimal, self-contained, reproducible
> code.
>   >
>
>


From gunter.berton at gene.com  Thu Sep  5 16:48:41 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 5 Sep 2013 07:48:41 -0700
Subject: [R] optim evils
In-Reply-To: <1378376595.24747.YahooMailNeo@web193405.mail.sg3.yahoo.com>
References: <1378376595.24747.YahooMailNeo@web193405.mail.sg3.yahoo.com>
Message-ID: <CACk-te278dmhHO33_y24YPe_6DRPbNUwJY9yj9YKNGR3JrMGxA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130905/154ff629/attachment.pl>

From gunter.berton at gene.com  Thu Sep  5 16:52:50 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 5 Sep 2013 07:52:50 -0700
Subject: [R] optim evils
In-Reply-To: <CACk-te278dmhHO33_y24YPe_6DRPbNUwJY9yj9YKNGR3JrMGxA@mail.gmail.com>
References: <1378376595.24747.YahooMailNeo@web193405.mail.sg3.yahoo.com>
	<CACk-te278dmhHO33_y24YPe_6DRPbNUwJY9yj9YKNGR3JrMGxA@mail.gmail.com>
Message-ID: <CACk-te3HZ+Cp2p4gZXmPBUVp8ZBybRwjGZmm3D=+HM3+qaxN9w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130905/b8c6ff8a/attachment.pl>

From istazahn at gmail.com  Thu Sep  5 17:17:09 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 5 Sep 2013 11:17:09 -0400
Subject: [R] ggplot2: connecting medians of boxes using facet_wrap.
 Changing median marker.
In-Reply-To: <11019DCE9B47004F90B2D9C62FF15792025D506C@ebox-prod-srv02.win.su.se>
References: <11019DCE9B47004F90B2D9C62FF15792025D4E67@ebox-prod-srv02.win.su.se>
	<CA+vqiLGq=UCkvGpJrbxK=R_Nh5TWPnaMNUCZuHxF-YAZV34KCA@mail.gmail.com>
	<11019DCE9B47004F90B2D9C62FF15792025D506C@ebox-prod-srv02.win.su.se>
Message-ID: <CA+vqiLGLuhon0_y5hxWvJnwJNuFe_U9Rnj74SNHeyzQGe28HkQ@mail.gmail.com>

On Thu, Sep 5, 2013 at 11:08 AM, Anna Zakrisson Braeunlich
<anna.zakrisson at su.se> wrote:
> Hi and thank you for the help and for the fast reply!
>
> A. One thing still is a problem. I have prior my first mail tried to not fill the boxes. The result is a different plot.
> If chosing to do:
>
> ggplot(mydata, aes(x = week, y = var1))
>
> instead of
>
> ggplot(mydata, aes(x = week, y = var1, fill=organism))
>
> I get the median of all the levels of organisms plotted per week and not the median per organism level per week.
> I would like to have white boxes, but to define each level of organism with a different non-filled symbol that mark the median of each box.

Ooops, sorry I missed that before. You can use

geom_boxplot(mapping=aes(group=interaction(week, organism)))

to achieve this, though it now becomes hard to tell which boxplots
correspond to which organisms.

>
> B. Can I define the shapes of the geom_point other than the default filled points that I will automatically generate when I define:
> geom_point(stat="summary", fun.y = "median", mapping=aes(shape=organism)) + # I need non-filled symbols

add

scale_shape(solid=FALSE)

or

scale_shape_manual(values = 1:3)

Best,
Ista
>
> The two versions mentioned in A are:
>
> ###################DATA########################################
> mydata<- data.frame(week = factor(rep(c("19", "21", "23", "25", "27", "29", "31", "33",
>                                            "35", "37", "39"), each = 45*3)), #week
>                     station = factor(rep(c("BY31", "B1", "H2", "H3", "H4",
>                                            "H5", "H6", "H7", "H8"), each = 15)), #station
>                     organism = factor(rep(c("zpl", "ses", "cy"), each = 5)), #organism
>                     var1 = rnorm(1485, mean = rep(c(0, 3, 15), each = 40),
>                                  sd = rep(c(1, 3, 6), each = 20)))
>
> ###################VERSION 1####################################
> p <- ggplot(mydata, aes(x = week, y = var1)) + #here all organisms are bunted together
>   geom_boxplot() +
>   facet_wrap(~ station, ncol = 3) +
>   theme_bw() +
>   theme(strip.background = element_blank())+
>   ylab("var1")+
>   xlab("week") +
>   geom_line(stat="summary", fun.y = "median",
>             mapping=aes(linetype=organism, group=organism))+ #must add jitter if using this
>   geom_point(stat="summary", fun.y = "median", mapping=aes(shape=organism)) + #must be unfilled
>   theme(strip.text.x = element_text(size = 12, colour="black", family="serif", angle=00)) +
>   theme(axis.text.x = element_text(size = 12, colour="black", family="serif", angle=90)) +
>   theme(axis.text.y = element_text(size = 12, colour="black", family="serif", angle=00)) +
>   geom_hline(yintercept=0, linetype=3) #draws dotted line at 0
>
> p
>
> ###################VERSION 2####################################
>
> p <- ggplot(mydata, aes(x = week, y = var1, fill=organism)) + #here the levels in organism are considered
>   geom_boxplot() +
>   facet_wrap(~ station, ncol = 3) +
>   theme_bw() +
>   theme(strip.background = element_blank())+
>   ylab("var1")+
>   xlab("week") +
>   geom_line(stat="summary", fun.y = "median",
>             mapping=aes(linetype=organism, group=organism))+ #must add jitter if using this
>   geom_point(stat="summary", fun.y = "median", mapping=aes(shape=organism)) + #must be unfilled
>   theme(strip.text.x = element_text(size = 12, colour="black", family="serif", angle=00)) +
>   theme(axis.text.x = element_text(size = 12, colour="black", family="serif", angle=90)) +
>   theme(axis.text.y = element_text(size = 12, colour="black", family="serif", angle=00)) +
>   geom_hline(yintercept=0, linetype=3) #draws dotted line at 0
>
> p
> #############################################################################
>
>
>
>
> Anna Zakrisson Braeunlich
> PhD student
>
> Department of Ecology, Environment and Plant Sciences
> Stockholm University
> Svante Arrheniusv. 21A
> SE-106 91 Stockholm
> Sweden/Sverige
>
> Lives in Berlin.
> For paper mail:
> Katzbachstr. 21
> D-10965, Berlin - Kreuzberg
> Germany/Deutschland
>
> E-mail: anna.zakrisson at su.se
> Tel work: +49-(0)3091541281
> Mobile: +49-(0)15777374888
> LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b
>
>><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?. .? `?. .><((((?>
>
> ________________________________________
> From: Ista Zahn [istazahn at gmail.com]
> Sent: 05 September 2013 16:02
> To: Anna Zakrisson Braeunlich
> Cc: r-help at r-project.org
> Subject: Re: [R] ggplot2: connecting medians of boxes using facet_wrap. Changing median marker.
>
> Hi Anna,
>
> On Thu, Sep 5, 2013 at 6:13 AM, Anna Zakrisson Braeunlich
> <anna.zakrisson at su.se> wrote:
>> # Dear all,
>>
>> # Thank you for taking your time.
>>
>> # What I would like to do:
>>
>> # (Run the code below to see what I am referring to)
>>
>> # I want lines connecting the medians of of the boxes. I do not want a function, just a simple,
>> # straight connection between points. I also would like the lines to be different: lty=c(1:3)
>
> geom_line(stat="summary", fun.y = "median",
> mapping=aes(linetype=organism, group=organism))
>
>>
>> # Furthermore, I wish to change the line/dot marking the medians to be pch=c(1:3). It seems not to be so simple when using facet_wrap? I have obviously missed something obvious.
>
> geom_point(stat="summary", fun.y = "median", mapping=aes(shape=organism)) +
>
>>
>> # Finally, I would like the boxes to be filled white and to have the legend reflecting this.
>
> Then don't tell ggplot to color them. Change
>
> ggplot(mydata, aes(x = week, y = var1, fill = organism))
>
> to
>
> ggplot(mydata, aes(x = week, y = var1))
>>
>> # I know that this was many questions, I apologize if some may seem basic. It is just that I am
>> # "jumping packages" the whole time and sometimes par() adjustments work and sometimes not.
>> # I have searched alot for answers, but as a ggplot2 beginner, I have failed to find a solution
>> # to my problems above.
>
>
> Hope this helps!
>
> Best,
> Ista
>
>>
>> # I would like to thank the programmers for a great package. The layer principle is much easier to work with.
>>
>> ####
>>
>> # Some dummy data:
>> mydata<- data.frame(week = factor(rep(c("19", "21", "23", "25", "27", "29", "31", "33",
>>                                            "35", "37", "39"), each = 45*3)), #week
>>                     station = factor(rep(c("BY31", "B1", "H2", "H3", "H4",
>>                                            "H5", "H6", "H7", "H8"), each = 15)), #station
>>                     organism = factor(rep(c("zpl", "ses", "cy"), each = 5)), #organism
>>                     var1 = rnorm(1485, mean = rep(c(0, 3, 15), each = 40),
>>                                  sd = rep(c(1, 3, 6), each = 20)))
>>
>> p <- ggplot(mydata, aes(x = week, y = var1, fill = organism)) +
>>   geom_boxplot() +
>>   facet_wrap(~ station, ncol = 3) +
>>   theme_bw() +
>>   theme(strip.background = element_blank())+
>>   ylab("var1")+
>>   xlab("week") +
>>   geom_smooth(aes(group = 1), method="lm", se = F) +  #Here is my problem.
>>   theme(strip.text.x = element_text(size = 12, colour="black", family="serif", angle=00)) +
>>   theme(axis.text.x = element_text(size = 12, colour="black", family="serif", angle=90)) +
>>   theme(axis.text.y = element_text(size = 12, colour="black", family="serif", angle=00)) +
>>   geom_hline(yintercept=0, linetype=3) #draws dotted line at 0
>>
>> p
>>
>>   # method="lm" is definately wrong,
>>   # I just added it to be a ble to draw some lines at all.
>>   # I also suspect geom_smooth to be wrong.
>> ### TO CLARIFY: I want the medians connected within each level. cy medians connected and
>>   # and ses medians connected and zpl connected. Not cy-ses-zpl, but that is perhaps obvious.
>> ### Thank you for your time!
>>   # with kind regards
>>   # A. Zakrisson
>>
>>
>>
>> Anna Zakrisson Braeunlich
>> PhD student
>>
>> Department of Ecology, Environment and Plant Sciences
>> Stockholm University
>> Svante Arrheniusv. 21A
>> SE-106 91 Stockholm
>> Sweden/Sverige
>>
>> Lives in Berlin.
>> For paper mail:
>> Katzbachstr. 21
>> D-10965, Berlin - Kreuzberg
>> Germany/Deutschland
>>
>> E-mail: anna.zakrisson at su.se
>> Tel work: +49-(0)3091541281
>> Mobile: +49-(0)15777374888
>> LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b
>>
>>><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?. .? `?. .><((((?>
>>
>>         [[alternative HTML version deleted]]
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From smartpink111 at yahoo.com  Thu Sep  5 17:36:38 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 5 Sep 2013 08:36:38 -0700 (PDT)
Subject: [R] Writing list into csv file
In-Reply-To: <1378217392.44905.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1378217392.44905.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1378395398.63443.YahooMailNeo@web142602.mail.bf1.yahoo.com>

HI,

No problem.

I am using linux, may be there is a difference.

You could try this:
?for(i in seq_along(lst1)) write.table(lst1[[i]],file="Crish1.txt",append=TRUE,quote=FALSE,sep=",")


#Will get some warning message.

You can save .txt to .csv and open it in excel. The column headings would be slightly misplaced. 

A.K.




Thanks for replying Arun! 

I tried the way you suggested. But all the elements are being 
clumped together in a single coulumn and i could see no commas 
separating them in csv file. 

Is it a good idea to recursively collect the each element down the list and print them separated by comma. 


Krishna | Cytel 
----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Tuesday, September 3, 2013 10:09 AM
Subject: Re: Writing list into csv file

Hi,
Please use dput() to show the example dataset:


Not sure this matches with your original example though..


lst1<- structure(list(Contrasts = structure(list(linear = c(-0.437, 
-0.378, -0.201, 0.271, 0.743), emax1 = c(-0.799, -0.17, 0.207, 
0.362, 0.399), emax2 = c(-0.643, -0.361, 0.061, 0.413, 0.53), 
??? linInt = c(-0.894, 0.224, 0.224, 0.224, 0.224)), .Names = c("linear", 
"emax1", "emax2", "linInt"), class = "data.frame", row.names = c("0", 
"0.05", "0.2", "0.6", "1")), `Contrast Correlation` = structure(list(
??? linear = c(1, 0.766, 0.912, 0.488), emax1 = c(0.766, 1, 0.949, 
??? 0.893), emax2 = c(0.912, 0.949, 1, 0.719), linInt = c(0.488, 
??? 0.893, 0.719, 1)), .Names = c("linear", "emax1", "emax2", 
"linInt"), class = "data.frame", row.names = c("linear", "emax1", 
"emax2", "linInt")), `Multiple Contrast Test` = structure(list(
??? t.Stat = c(3.464, 3.339, 2.972, 2.486), adj.p = structure(1:4, .Label = c("< 0.001", 
??? "0.00143", "0.00459", "0.01610"), class = "factor")), .Names = c("t.Stat", 
"adj.p"), class = "data.frame", row.names = c("emax2", "emax1", 
"linear", "linInt"))), .Names = c("Contrasts", "Contrast Correlation", 
"Multiple Contrast Test"))




You may try:
capture.output(sapply(lst1,print),file="test.csv",append=TRUE)? #not perfect as some headings might be misplaced.


A.K.




Hello Guys 
? 
Say I have ?a List MM with 

Multiple Contrast Test 

Contrasts: 
? ? ?linear ?emax1 ?emax2 linInt 
0 ? ?-0.437 -0.799 -0.643 -0.894 
0.05 -0.378 -0.170 -0.361 ?0.224 
0.2 ?-0.201 ?0.207 ?0.061 ?0.224 
0.6 ? 0.271 ?0.362 ?0.413 ?0.224 
1 ? ? 0.743 ?0.399 ?0.530 ?0.224 

Contrast Correlation: 
? ? ? ? ? ?linear emax1 emax2 linInt 
linear ?1.000 0.766 0.912 ?0.488 
emax1 0.766 1.000 0.949 ?0.893 
emax2 0.912 0.949 1.000 ?0.719 
linInt ? 0.488 0.893 0.719 ?1.000 

Multiple Contrast Test: 
? ? ? ?t-Stat ? adj-p 
emax2 ? 3.464 < 0.001 
emax1 ? 3.339 0.00143 
linear ?2.972 0.00459 
linInt ?2.486 0.01610 

each element of MM has different number elements of diffrent 
datatypes. I wanted write a single csv file containning all the 
elements. 

Is is possible to do in R. 


Krishna | Cytel


From anna.zakrisson at su.se  Thu Sep  5 17:08:50 2013
From: anna.zakrisson at su.se (Anna Zakrisson Braeunlich)
Date: Thu, 5 Sep 2013 15:08:50 +0000
Subject: [R] ggplot2: connecting medians of boxes using facet_wrap.
 Changing median marker.
In-Reply-To: <CA+vqiLGq=UCkvGpJrbxK=R_Nh5TWPnaMNUCZuHxF-YAZV34KCA@mail.gmail.com>
References: <11019DCE9B47004F90B2D9C62FF15792025D4E67@ebox-prod-srv02.win.su.se>,
	<CA+vqiLGq=UCkvGpJrbxK=R_Nh5TWPnaMNUCZuHxF-YAZV34KCA@mail.gmail.com>
Message-ID: <11019DCE9B47004F90B2D9C62FF15792025D506C@ebox-prod-srv02.win.su.se>

Hi and thank you for the help and for the fast reply!

A. One thing still is a problem. I have prior my first mail tried to not fill the boxes. The result is a different plot.
If chosing to do:

ggplot(mydata, aes(x = week, y = var1))

instead of 

ggplot(mydata, aes(x = week, y = var1, fill=organism))

I get the median of all the levels of organisms plotted per week and not the median per organism level per week.
I would like to have white boxes, but to define each level of organism with a different non-filled symbol that mark the median of each box.

B. Can I define the shapes of the geom_point other than the default filled points that I will automatically generate when I define:
geom_point(stat="summary", fun.y = "median", mapping=aes(shape=organism)) + # I need non-filled symbols

The two versions mentioned in A are:

###################DATA########################################
mydata<- data.frame(week = factor(rep(c("19", "21", "23", "25", "27", "29", "31", "33",
                                           "35", "37", "39"), each = 45*3)), #week
                    station = factor(rep(c("BY31", "B1", "H2", "H3", "H4",
                                           "H5", "H6", "H7", "H8"), each = 15)), #station
                    organism = factor(rep(c("zpl", "ses", "cy"), each = 5)), #organism
                    var1 = rnorm(1485, mean = rep(c(0, 3, 15), each = 40),
                                 sd = rep(c(1, 3, 6), each = 20)))

###################VERSION 1####################################
p <- ggplot(mydata, aes(x = week, y = var1)) + #here all organisms are bunted together
  geom_boxplot() +
  facet_wrap(~ station, ncol = 3) +
  theme_bw() +
  theme(strip.background = element_blank())+
  ylab("var1")+
  xlab("week") +
  geom_line(stat="summary", fun.y = "median",
            mapping=aes(linetype=organism, group=organism))+ #must add jitter if using this
  geom_point(stat="summary", fun.y = "median", mapping=aes(shape=organism)) + #must be unfilled
  theme(strip.text.x = element_text(size = 12, colour="black", family="serif", angle=00)) +
  theme(axis.text.x = element_text(size = 12, colour="black", family="serif", angle=90)) +
  theme(axis.text.y = element_text(size = 12, colour="black", family="serif", angle=00)) +
  geom_hline(yintercept=0, linetype=3) #draws dotted line at 0
  
p

###################VERSION 2#################################### 

p <- ggplot(mydata, aes(x = week, y = var1, fill=organism)) + #here the levels in organism are considered
  geom_boxplot() +
  facet_wrap(~ station, ncol = 3) +
  theme_bw() +
  theme(strip.background = element_blank())+
  ylab("var1")+
  xlab("week") +
  geom_line(stat="summary", fun.y = "median",
            mapping=aes(linetype=organism, group=organism))+ #must add jitter if using this
  geom_point(stat="summary", fun.y = "median", mapping=aes(shape=organism)) + #must be unfilled
  theme(strip.text.x = element_text(size = 12, colour="black", family="serif", angle=00)) +
  theme(axis.text.x = element_text(size = 12, colour="black", family="serif", angle=90)) +
  theme(axis.text.y = element_text(size = 12, colour="black", family="serif", angle=00)) +
  geom_hline(yintercept=0, linetype=3) #draws dotted line at 0
  
p
#############################################################################




Anna Zakrisson Braeunlich
PhD student

Department of Ecology, Environment and Plant Sciences
Stockholm University
Svante Arrheniusv. 21A
SE-106 91 Stockholm
Sweden/Sverige

Lives in Berlin.
For paper mail:
Katzbachstr. 21
D-10965, Berlin - Kreuzberg
Germany/Deutschland

E-mail: anna.zakrisson at su.se
Tel work: +49-(0)3091541281
Mobile: +49-(0)15777374888
LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b

><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?. .? `?. .><((((?>

________________________________________
From: Ista Zahn [istazahn at gmail.com]
Sent: 05 September 2013 16:02
To: Anna Zakrisson Braeunlich
Cc: r-help at r-project.org
Subject: Re: [R] ggplot2: connecting medians of boxes using facet_wrap. Changing median marker.

Hi Anna,

On Thu, Sep 5, 2013 at 6:13 AM, Anna Zakrisson Braeunlich
<anna.zakrisson at su.se> wrote:
> # Dear all,
>
> # Thank you for taking your time.
>
> # What I would like to do:
>
> # (Run the code below to see what I am referring to)
>
> # I want lines connecting the medians of of the boxes. I do not want a function, just a simple,
> # straight connection between points. I also would like the lines to be different: lty=c(1:3)

geom_line(stat="summary", fun.y = "median",
mapping=aes(linetype=organism, group=organism))

>
> # Furthermore, I wish to change the line/dot marking the medians to be pch=c(1:3). It seems not to be so simple when using facet_wrap? I have obviously missed something obvious.

geom_point(stat="summary", fun.y = "median", mapping=aes(shape=organism)) +

>
> # Finally, I would like the boxes to be filled white and to have the legend reflecting this.

Then don't tell ggplot to color them. Change

ggplot(mydata, aes(x = week, y = var1, fill = organism))

to

ggplot(mydata, aes(x = week, y = var1))
>
> # I know that this was many questions, I apologize if some may seem basic. It is just that I am
> # "jumping packages" the whole time and sometimes par() adjustments work and sometimes not.
> # I have searched alot for answers, but as a ggplot2 beginner, I have failed to find a solution
> # to my problems above.


Hope this helps!

Best,
Ista

>
> # I would like to thank the programmers for a great package. The layer principle is much easier to work with.
>
> ####
>
> # Some dummy data:
> mydata<- data.frame(week = factor(rep(c("19", "21", "23", "25", "27", "29", "31", "33",
>                                            "35", "37", "39"), each = 45*3)), #week
>                     station = factor(rep(c("BY31", "B1", "H2", "H3", "H4",
>                                            "H5", "H6", "H7", "H8"), each = 15)), #station
>                     organism = factor(rep(c("zpl", "ses", "cy"), each = 5)), #organism
>                     var1 = rnorm(1485, mean = rep(c(0, 3, 15), each = 40),
>                                  sd = rep(c(1, 3, 6), each = 20)))
>
> p <- ggplot(mydata, aes(x = week, y = var1, fill = organism)) +
>   geom_boxplot() +
>   facet_wrap(~ station, ncol = 3) +
>   theme_bw() +
>   theme(strip.background = element_blank())+
>   ylab("var1")+
>   xlab("week") +
>   geom_smooth(aes(group = 1), method="lm", se = F) +  #Here is my problem.
>   theme(strip.text.x = element_text(size = 12, colour="black", family="serif", angle=00)) +
>   theme(axis.text.x = element_text(size = 12, colour="black", family="serif", angle=90)) +
>   theme(axis.text.y = element_text(size = 12, colour="black", family="serif", angle=00)) +
>   geom_hline(yintercept=0, linetype=3) #draws dotted line at 0
>
> p
>
>   # method="lm" is definately wrong,
>   # I just added it to be a ble to draw some lines at all.
>   # I also suspect geom_smooth to be wrong.
> ### TO CLARIFY: I want the medians connected within each level. cy medians connected and
>   # and ses medians connected and zpl connected. Not cy-ses-zpl, but that is perhaps obvious.
> ### Thank you for your time!
>   # with kind regards
>   # A. Zakrisson
>
>
>
> Anna Zakrisson Braeunlich
> PhD student
>
> Department of Ecology, Environment and Plant Sciences
> Stockholm University
> Svante Arrheniusv. 21A
> SE-106 91 Stockholm
> Sweden/Sverige
>
> Lives in Berlin.
> For paper mail:
> Katzbachstr. 21
> D-10965, Berlin - Kreuzberg
> Germany/Deutschland
>
> E-mail: anna.zakrisson at su.se
> Tel work: +49-(0)3091541281
> Mobile: +49-(0)15777374888
> LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b
>
>><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?. .? `?. .><((((?>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From gdb02 at health.state.ny.us  Thu Sep  5 16:20:53 2013
From: gdb02 at health.state.ny.us (Gwen D. LaSelva)
Date: Thu, 5 Sep 2013 10:20:53 -0400
Subject: [R] setStatusBar function gives error message in R 3.01 under
	Windows 7
Message-ID: <OF86C592C8.A9C7FA98-ON85257BDD.004EB674-85257BDD.004ED16C@notes.health.state.ny.us>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130905/04f202f0/attachment.pl>

From jholtman at gmail.com  Thu Sep  5 18:31:23 2013
From: jholtman at gmail.com (jim holtman)
Date: Thu, 5 Sep 2013 12:31:23 -0400
Subject: [R] Y-axis labels as decimal numbers
In-Reply-To: <OF36A91BE0.A8B1F70D-ON65257BDD.00492114-65257BDD.00496C61@polarisft.com>
References: <OF36A91BE0.A8B1F70D-ON65257BDD.00492114-65257BDD.00496C61@polarisft.com>
Message-ID: <CAAxdm-7by-vZkrug0JaLcpkSCWJEpRGUun=YgjQFu+W_M_LeJQ@mail.gmail.com>

So what is wrong with the y-axis?  When I run your script, things seem
right.  Can you explain what it is that you want.
Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Thu, Sep 5, 2013 at 9:22 AM,  <mohan.radhakrishnan at polarisft.com> wrote:
> Hi,
>              I am able to create a graph with this code but the decimal
> numbers are not plotted accurately because the ylim values are not set
> properly. x-axis is proper.
>
> How do I accurately set the ylim for duration.1 column ?
>
> Thanks,
> Mohan
>
> set1$duration<- as.POSIXct(paste('2013-08-24', set1$duration))
> plot(set1$duration,set1$duration.1,type="b",col = "blue",  ylab="", xaxt =
> 'n', xlab="",las=2,lwd=2.5, lty=1,cex.axis=2.5)
> # now plot you times
> axis(1, at = set1$duration, labels = set1$duration, las = 2,cex.axis=2.5)
>
>    duration duration.1
> 2  16:03:41       0.05
> 3  17:03:41       0.27
> 4  18:03:43       1.22
> 5  19:03:45       1.51
> 6  20:03:47       1.27
> 7  21:03:48       1.15
> 8  22:03:50       1.22
> 9  23:03:52       1.27
> 10 00:03:54       1.27
> 11 01:03:55       1.22
> 12 02:03:57       1.26
> 13 03:03:59       1.57
> 14 04:04:01       1.31
> 15 05:04:03       1.24
>
>
> This e-Mail may contain proprietary and confidential information and is sent for the intended recipient(s) only.  If by an addressing or transmission error this mail has been misdirected to you, you are requested to delete this mail immediately. You are also hereby notified that any use, any form of reproduction, dissemination, copying, disclosure, modification, distribution and/or publication of this e-mail message, contents or its attachment other than by its intended recipient/s is strictly prohibited.
>
> Visit us at http://www.polarisFT.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Thu Sep  5 18:49:16 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 5 Sep 2013 09:49:16 -0700 (PDT)
Subject: [R] Looping an lapply linear regression function
Message-ID: <1378399756.77090.YahooMailNeo@web142606.mail.bf1.yahoo.com>

HI,
May be this helps:
?set.seed(28)
?dat1<- setNames(as.data.frame(matrix(sample(1:40,10*5,replace=TRUE),ncol=5)),letters[1:5])
indx<-as.data.frame(combn(names(dat1),2),stringsAsFactors=FALSE)
res<-t(sapply(indx,function(x) {x1<-cbind(dat1[x[1]],dat1[x[2]]);summary(lm(x1[,1]~x1[,2]))$coef[,4]}))
?rownames(res)<-apply(indx,2,paste,collapse="_")
?colnames(res)[2]<- "Coef1"
?head(res,3)
#??? (Intercept)???? Coef1
#a_b? 0.39862676 0.8365606
#a_c? 0.02427885 0.6094141
#a_d? 0.37521423 0.7578723


#permutation
indx2<-expand.grid(names(dat1),names(dat1),stringsAsFactors=FALSE)
#or
indx2<- expand.grid(rep(list(names(dat1)),2),stringsAsFactors=FALSE)
indx2New<- indx2[indx2[,1]!=indx2[,2],]
res2<-t(sapply(seq_len(nrow(indx2New)),function(i) {x1<- indx2New[i,]; x2<-cbind(dat1[x1[,1]],dat1[x1[,2]]);summary(lm(x2[,1]~x2[,2]))$coef[,4]}))
row.names(res2)<-apply(indx2New,1,paste,collapse="_")
?colnames(res2)<- colnames(res)


A.K.


Hi everyone, 

First off just like to say thanks to everyone?s contributions. 
Up until now, I?ve never had to post as I?ve always found the answers 
from trawling through the database. I?ve finally managed to stump 
myself, and although for someone out there, I?m sure the answer to my 
problem is fairly simple, I, however have spent the whole day infront of
 my computer struggling. I know I?ll probably get an absolute ribbing 
for making a basic mistake, or not understanding something fully, but 
I?m blind to the mistake now after looking so long at it. 

What I?m looking to do, is formulate a matrix ([28,28]) of 
p-values produced from running linear regressions of 28 variables 
against themselves (eg a~b, a~c, a~d.....b~a, b~c etc...), if that makes
 sense. I?ve managed to get this to work if I just input each variable 
by hand, but this isn?t going to help when I have to make 20 matrices. 

My script is as follows; 


for (j in [1:28]) 
{ 
?##This section works perfectly, if I don?t try to loop it, I know 
this wont work at the moment, because I haven?t designated what j is, 
but I?m showing to highlight what I?m attempting to do. ? 
? 

? ?models <- lapply(varlist, function(x) { 
? ? lm(substitute(ANS ~ i, list(i = as.name(x))), data = con.i) 
? }) 
? 
? ? ? ? ? abc<- lapply(models, function(f) summary(f)$coefficients[,4]) 
? 
? ? ? ? ? abc<- do.call(rbind, abc) 
? 
? ? ? ? ? 
? 
} 

I get the following error when I try to loop it... 

Error in model.frame.default(formula = substitute(j ~ i, list(i = as.name(x))), ?: 
? variable lengths differ (found for 'ANS') ##?NS being my first variable 

All variables are of the same length, with 21 recordings for each 


If anyone can suggest a method of looping, or another means 
or producing ?models? for each of my 28 variables, without having to do 
it by hand that would be fantastic. 

Thanks in advance!!


From friendly at yorku.ca  Thu Sep  5 19:07:38 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 05 Sep 2013 13:07:38 -0400
Subject: [R] applying a univariate function for each response in a
 multivariate linear model (mlm)
Message-ID: <5228BA5A.2060208@yorku.ca>

After fitting a multivariate linear model (mlm), I'd like to be able to 
run or apply
a standard univariate stats:::*.lm function to each of the response 
variables,
within a function -- i.e., by operating on the mlm object, rather than 
re-running
the univariate models separately manually.

An example: extracting cooks.distance components (via 
stats:::cooks.distance.lm)

grain <- c(40, 17, 9, 15, 6, 12, 5, 9)        # y1
straw <- c(53, 19, 10, 29, 13, 27, 19, 30)    # y2
fertilizer <- c(24, 11, 5, 12, 7, 14, 11, 18) # x

Fertilizer <- data.frame(grain, straw, fertilizer)
# fit the mlm
mod <- lm(cbind(grain, straw) ~ fertilizer, data=Fertilizer)

# run univariate regressionsand get cooks.distance
 > (cookd.grain <- cooks.distance(lm(grain ~ fertilizer, data=Fertilizer)))
          1          2          3          4 5          6          7
3.4436e+00 4.0957e-02 2.2733e-01 4.8605e-03 1.4073e-05 2.0479e-02 
6.4192e-02
          8
4.8383e-01
 > (cookd.straw <- cooks.distance(lm(straw ~ fertilizer, data=Fertilizer)))
         1         2         3         4         5 6         7         8
2.0003953 0.0283225 0.0675803 0.1591198 0.0013352 0.0024076 0.0283225 
0.4672299

This is the result I want:

 > data.frame(cookd.grain, cookd.straw)
   cookd.grain cookd.straw
1  3.4436e+00   2.0003953
2  4.0957e-02   0.0283225
3  2.2733e-01   0.0675803
4  4.8605e-03   0.1591198
5  1.4073e-05   0.0013352
6  2.0479e-02   0.0024076
7  6.4192e-02   0.0283225
8  4.8383e-01   0.4672299

Note that if I call cooks.distance.lm directly on the mlm object, there 
is no complaint
or warning, but the result is silently WRONG:

 > # try calling cooks.distance.lm directly:  silently WRONG
 >  stats:::cooks.distance.lm(mod)
        grain      straw
1 3.4436e+00 0.51729792
2 1.5838e-01 0.02832250
3 2.2733e-01 0.01747613
4 1.8796e-02 0.15911979
5 1.4073e-05 0.00034527
6 7.9192e-02 0.00240762
7 6.4192e-02 0.00732414
8 1.8710e+00 0.46722985
 >

I realize that I can also use update() on the mlm object to re-fit the 
univariate models,
but I don't know how to extract the response names from it to do this in 
a function

 > coef(mod)  # multivariate
               grain   straw
(Intercept) -3.7524 -2.2965
fertilizer   1.4022  2.1409

 > coef(update(mod, grain ~ .))
(Intercept)  fertilizer
     -3.7524      1.4022
 > coef(update(mod, straw ~ .))
(Intercept)  fertilizer
     -2.2965      2.1409
 >


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From murdoch.duncan at gmail.com  Thu Sep  5 19:20:21 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 05 Sep 2013 13:20:21 -0400
Subject: [R] setStatusBar function gives error message in R 3.01 under
 Windows 7
In-Reply-To: <OF86C592C8.A9C7FA98-ON85257BDD.004EB674-85257BDD.004ED16C@notes.health.state.ny.us>
References: <OF86C592C8.A9C7FA98-ON85257BDD.004EB674-85257BDD.004ED16C@notes.health.state.ny.us>
Message-ID: <5228BD55.7060608@gmail.com>

On 05/09/2013 10:20 AM, Gwen D. LaSelva wrote:
> I am running R 3.01 under 64-bit Windows 7.  When I try to set the status
> bar, I get an error message.  For example:
>
> >text<-"hello"
> > setStatusBar(text)
> > Error in .Call(setStatusBar, text) :
> >   first argument must be a string (of length 1) or native symbol
> reference
>
> The related function, setWindowTitle(), appears to work just fine.
>
> Is this a bug?  Or am I doing something wrong?  It does seem to work OK in
> R 2.13.0.

Thanks, looks like a bug, and looks easy to fix.  Should make it into 
3.0.2 later this month.

Duncan Murdoch


From murdoch.duncan at gmail.com  Thu Sep  5 19:50:18 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 05 Sep 2013 13:50:18 -0400
Subject: [R] setStatusBar function gives error message in R 3.01 under
 Windows 7
In-Reply-To: <OF86C592C8.A9C7FA98-ON85257BDD.004EB674-85257BDD.004ED16C@notes.health.state.ny.us>
References: <OF86C592C8.A9C7FA98-ON85257BDD.004EB674-85257BDD.004ED16C@notes.health.state.ny.us>
Message-ID: <5228C45A.6010205@gmail.com>

On 05/09/2013 10:20 AM, Gwen D. LaSelva wrote:
> I am running R 3.01 under 64-bit Windows 7.  When I try to set the status
> bar, I get an error message.  For example:
>
> >text<-"hello"
> > setStatusBar(text)
> > Error in .Call(setStatusBar, text) :
> >   first argument must be a string (of length 1) or native symbol
> reference
>
> The related function, setWindowTitle(), appears to work just fine.
>
> Is this a bug?  Or am I doing something wrong?  It does seem to work OK in
> R 2.13.0.

Could you please try the R-patched nightly build (from 
http://cran.r-project.org/bin/windows/base/rpatched.html)?  I think this 
has already been fixed.

Duncan Murdoch


From flaviomargarito at gmail.com  Thu Sep  5 21:41:22 2013
From: flaviomargarito at gmail.com (Flavio Barros)
Date: Thu, 5 Sep 2013 16:41:22 -0300
Subject: [R] Looping an lapply linear regression function
In-Reply-To: <1378399756.77090.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <1378399756.77090.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <CAOKagtNJoYA8m1fn2FwtxE6QyRV6Q8pOmUD7aHBVMYPzxbJzvA@mail.gmail.com>

Um texto embutido e sem conjunto de caracteres especificado foi limpo...
Nome: n?o dispon?vel
Url: <https://stat.ethz.ch/pipermail/r-help/attachments/20130905/f361c503/attachment.pl>

From smartpink111 at yahoo.com  Thu Sep  5 22:09:30 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 5 Sep 2013 13:09:30 -0700 (PDT)
Subject: [R] binary symmetric matrix combination
Message-ID: <1378411770.83414.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
May be this helps:

m1<- as.matrix(read.table(text="
y1 g24
y1 0 1
g24 1 0
",sep="",header=TRUE))

m2<-as.matrix(read.table(text="y1 c1 c2 l17
?y1 0 1 1 1
?c1 1 0 1 1
?c2 1 1 0 1
?l17 1 1 1 0",sep="",header=TRUE))
m3<- as.matrix(read.table(text="y1 h4??? s2???? s30
?y1 0 1 1 1
?h4 1 0 1 1
?s2 1 1 0 1
?s30 1 1 1 0",sep="",header=TRUE))
m4<- as.matrix(read.table(text="y1 e5 l15
?y1 0 1 1
e5 1 0 1
l15 1 1 0",sep="",header=TRUE))

###desired output: at some place the label is "s2" and at other "s29".? I used "s2" for consistency
Out1<- as.matrix(read.table(text="y1 g24 c1 c2 l17 h4 s2 s30 e5 l15
y1 0 1 1 1 1 1 1 1 1 1
g24 1 0 0 0 0 0 0 0 0 0
c1 1 0 0 1 1 0 0 0 0 0
c2 1 0 1 0 1 0 0 0 0 0
l17 1 0 1 1 0 0 0 0 0 0
h4 1 0 0 0 0 0 1 1 0 0
s2 1 0 0 0 0 1 0 1 0 0
s30 1 0 0 0 0 1 1 0 0 0
e5 1 0 0 0 0 0 0 0 0 1
l15 1 0 0 0 0 0 0 0 1 0",sep="",header=TRUE))


names1<-unique(c(colnames(m1),colnames(m2),colnames(m3),colnames(m4)))
Out2<-matrix(0,length(names1),length(names1),dimnames=list(names1,names1))
vec1<- paste0(colnames(m1)[col(m1)],rownames(m1)[row(m1)])
vecOut<- paste0(colnames(Out2)[col(Out2)],rownames(Out2)[row(Out2)])
Out2[match(vec1,vecOut)]<- m1
vec2<- paste0(colnames(m2)[col(m2)],rownames(m2)[row(m2)])
Out2[match(vec2,vecOut)]<- m2
vec3<- paste0(colnames(m3)[col(m3)],rownames(m3)[row(m3)])
Out2[match(vec3,vecOut)]<- m3
vec4<- paste0(colnames(m4)[col(m4)],rownames(m4)[row(m4)])
Out2[match(vec4,vecOut)]<- m4
?all.equal(Out1,Out2)
#[1] TRUE
?Out2
??? y1 g24 c1 c2 l17 h4 s2 s30 e5 l15
y1?? 0?? 1? 1? 1?? 1? 1? 1?? 1? 1?? 1
g24? 1?? 0? 0? 0?? 0? 0? 0?? 0? 0?? 0
c1?? 1?? 0? 0? 1?? 1? 0? 0?? 0? 0?? 0
c2?? 1?? 0? 1? 0?? 1? 0? 0?? 0? 0?? 0
l17? 1?? 0? 1? 1?? 0? 0? 0?? 0? 0?? 0
h4?? 1?? 0? 0? 0?? 0? 0? 1?? 1? 0?? 0
s2?? 1?? 0? 0? 0?? 0? 1? 0?? 1? 0?? 0
s30? 1?? 0? 0? 0?? 0? 1? 1?? 0? 0?? 0
e5?? 1?? 0? 0? 0?? 0? 0? 0?? 0? 0?? 1
l15? 1?? 0? 0? 0?? 0? 0? 0?? 0? 1?? 0


A.K.



I have the following binary labeled matrices with different dimensions 
(2x2, 3x3, 4x4) which I need to create in R as seen below: 

? ? ? ? y1	 g24 
y1 	0	1 
g2 4	1	0 
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 
? ? ? ? ?y1	c1	c2	l17 
?y1	0	1	1	1 
?c1	1	0	1	1 
?c2	1	1	0	1 
?l17	1	1	1	0 
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 
? ? ? ?y1	h4 ? ?s2 ? ? s30 
?y1	0	1	1	1 
?h4	1	0	1	1 
?s29	1	1	0	1 
?s30	1	1	1	0 
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 
? ? ? ? y1 	e5	l15 
?y1	0	1	1 
e5	1	0	1 
l15	1	1	0 

Then, I need to combine them to achieve the following result: 

? ? ? ? y1	g24	c1	c2	l17	h4	s29	s30	e5	l15 
y1	0	1	1	1	1	1	1	1	1	1 
g24	1	0	0	0	0	0	0	0	0	0 
c1	1	0	0	1	1	0	0	0	0	0 
c2	1	0	1	0	1	0	0	0	0	0 
l17	1	0	1	1	0	0	0	0	0	0 
h4	1	0	0	0	0	0	1	1	0	0 
s29	1	0	0	0	0	1	0	1	0	0 
s30	1	0	0	0	0	1	1	0	0	0 
e5	1	0	0	0	0	0	0	0	0	1 
l15	1	0	0	0	0	0	0	0	1	0 

Your help would be very much appreciated. 

ps. if the matrices don't appear correctly, please notice that all values different from 0 and 1 are row and column names 

Thank You!


From rshepard at appl-ecosys.com  Thu Sep  5 22:24:27 2013
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Thu, 5 Sep 2013 13:24:27 -0700 (PDT)
Subject: [R] xyplot() with discontinuous x-axis variable
Message-ID: <alpine.LNX.2.00.1309051253480.25728@salmo.appl-ecosys.com>

   My xyplot() with superposed multiple condiions looks better with lines
than with points (it's easier to see changes over time with the lines). But,
there are gaps in the years (the x axis) for which there are data to be
plotted. For example, there are data for years 2004-2006 and 2010-2012, but
not for 2007-2009. I would like to have the lines for only the two groups
with data.

   Reading ?xyplot suggests that the group attribute might do the job but I
do not see how to write the equation.

   Is it possible to plot with lines on discontinuous data or should I use
large, solid circles for each year's data points?

Rich


From smartpink111 at yahoo.com  Thu Sep  5 22:30:00 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 5 Sep 2013 13:30:00 -0700 (PDT)
Subject: [R] binary symmetric matrix combination
In-Reply-To: <1378411770.83414.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1378411770.83414.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1378413000.30677.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Also, some of the steps could be reduced by:

names1<-unique(c(colnames(m1),colnames(m2),colnames(m3),colnames(m4)))
Out3<-matrix(0,length(names1),length(names1),dimnames=list(names1,names1))
lst1<-sapply(paste0("m",1:4),function(x) {x1<- get(x); x2<-paste0(colnames(x1)[col(x1)],rownames(x1)[row(x1)]); match(x2,vecOut)})
lst2<- list(m1,m2,m3,m4)
N<- length(lst1)

?fn1<- function(N,Out){
?i=1
?while(i<=N){
?Out[lst1[[i]]]<-lst2[[i]]
?i<-i+1
?}
Out
?}
fn1(N,Out3)
#??? y1 g24 c1 c2 l17 h4 s2 s30 e5 l15
#y1?? 0?? 1? 1? 1?? 1? 1? 1?? 1? 1?? 1
#g24? 1?? 0? 0? 0?? 0? 0? 0?? 0? 0?? 0
#c1?? 1?? 0? 0? 1?? 1? 0? 0?? 0? 0?? 0
#c2?? 1?? 0? 1? 0?? 1? 0? 0?? 0? 0?? 0
#l17? 1?? 0? 1? 1?? 0? 0? 0?? 0? 0?? 0
#h4?? 1?? 0? 0? 0?? 0? 0? 1?? 1? 0?? 0
#s2?? 1?? 0? 0? 0?? 0? 1? 0?? 1? 0?? 0
#s30? 1?? 0? 0? 0?? 0? 1? 1?? 0? 0?? 0
#e5?? 1?? 0? 0? 0?? 0? 0? 0?? 0? 0?? 1
#l15? 1?? 0? 0? 0?? 0? 0? 0?? 0? 1?? 0


?identical(Out2,fn1(N,Out3))
#[1] TRUE

A.K.


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Thursday, September 5, 2013 4:09 PM
Subject: Re: binary symmetric matrix combination

Hi,
May be this helps:

m1<- as.matrix(read.table(text="
y1 g24
y1 0 1
g24 1 0
",sep="",header=TRUE))

m2<-as.matrix(read.table(text="y1 c1 c2 l17
?y1 0 1 1 1
?c1 1 0 1 1
?c2 1 1 0 1
?l17 1 1 1 0",sep="",header=TRUE))
m3<- as.matrix(read.table(text="y1 h4??? s2???? s30
?y1 0 1 1 1
?h4 1 0 1 1
?s2 1 1 0 1
?s30 1 1 1 0",sep="",header=TRUE))
m4<- as.matrix(read.table(text="y1 e5 l15
?y1 0 1 1
e5 1 0 1
l15 1 1 0",sep="",header=TRUE))

###desired output: at some place the label is "s2" and at other "s29".? I used "s2" for consistency
Out1<- as.matrix(read.table(text="y1 g24 c1 c2 l17 h4 s2 s30 e5 l15
y1 0 1 1 1 1 1 1 1 1 1
g24 1 0 0 0 0 0 0 0 0 0
c1 1 0 0 1 1 0 0 0 0 0
c2 1 0 1 0 1 0 0 0 0 0
l17 1 0 1 1 0 0 0 0 0 0
h4 1 0 0 0 0 0 1 1 0 0
s2 1 0 0 0 0 1 0 1 0 0
s30 1 0 0 0 0 1 1 0 0 0
e5 1 0 0 0 0 0 0 0 0 1
l15 1 0 0 0 0 0 0 0 1 0",sep="",header=TRUE))


names1<-unique(c(colnames(m1),colnames(m2),colnames(m3),colnames(m4)))
Out2<-matrix(0,length(names1),length(names1),dimnames=list(names1,names1))
vec1<- paste0(colnames(m1)[col(m1)],rownames(m1)[row(m1)])
vecOut<- paste0(colnames(Out2)[col(Out2)],rownames(Out2)[row(Out2)])
Out2[match(vec1,vecOut)]<- m1
vec2<- paste0(colnames(m2)[col(m2)],rownames(m2)[row(m2)])
Out2[match(vec2,vecOut)]<- m2
vec3<- paste0(colnames(m3)[col(m3)],rownames(m3)[row(m3)])
Out2[match(vec3,vecOut)]<- m3
vec4<- paste0(colnames(m4)[col(m4)],rownames(m4)[row(m4)])
Out2[match(vec4,vecOut)]<- m4
?all.equal(Out1,Out2)
#[1] TRUE
?Out2
??? y1 g24 c1 c2 l17 h4 s2 s30 e5 l15
y1?? 0?? 1? 1? 1?? 1? 1? 1?? 1? 1?? 1
g24? 1?? 0? 0? 0?? 0? 0? 0?? 0? 0?? 0
c1?? 1?? 0? 0? 1?? 1? 0? 0?? 0? 0?? 0
c2?? 1?? 0? 1? 0?? 1? 0? 0?? 0? 0?? 0
l17? 1?? 0? 1? 1?? 0? 0? 0?? 0? 0?? 0
h4?? 1?? 0? 0? 0?? 0? 0? 1?? 1? 0?? 0
s2?? 1?? 0? 0? 0?? 0? 1? 0?? 1? 0?? 0
s30? 1?? 0? 0? 0?? 0? 1? 1?? 0? 0?? 0
e5?? 1?? 0? 0? 0?? 0? 0? 0?? 0? 0?? 1
l15? 1?? 0? 0? 0?? 0? 0? 0?? 0? 1?? 0


A.K.



I have the following binary labeled matrices with different dimensions 
(2x2, 3x3, 4x4) which I need to create in R as seen below: 

? ? ? ? y1???  g24 
y1 ??? 0??? 1 
g2 4??? 1??? 0 
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 
? ? ? ? ?y1??? c1??? c2??? l17 
?y1??? 0??? 1??? 1??? 1 
?c1??? 1??? 0??? 1??? 1 
?c2??? 1??? 1??? 0??? 1 
?l17??? 1??? 1??? 1??? 0 
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 
? ? ? ?y1??? h4 ? ?s2 ? ? s30 
?y1??? 0??? 1??? 1??? 1 
?h4??? 1??? 0??? 1??? 1 
?s29??? 1??? 1??? 0??? 1 
?s30??? 1??? 1??? 1??? 0 
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 
? ? ? ? y1 ??? e5??? l15 
?y1??? 0??? 1??? 1 
e5??? 1??? 0??? 1 
l15??? 1??? 1??? 0 

Then, I need to combine them to achieve the following result: 

? ? ? ? y1??? g24??? c1??? c2??? l17??? h4??? s29??? s30??? e5??? l15 
y1??? 0??? 1??? 1??? 1??? 1??? 1??? 1??? 1??? 1??? 1 
g24??? 1??? 0??? 0??? 0??? 0??? 0??? 0??? 0??? 0??? 0 
c1??? 1??? 0??? 0??? 1??? 1??? 0??? 0??? 0??? 0??? 0 
c2??? 1??? 0??? 1??? 0??? 1??? 0??? 0??? 0??? 0??? 0 
l17??? 1??? 0??? 1??? 1??? 0??? 0??? 0??? 0??? 0??? 0 
h4??? 1??? 0??? 0??? 0??? 0??? 0??? 1??? 1??? 0??? 0 
s29??? 1??? 0??? 0??? 0??? 0??? 1??? 0??? 1??? 0??? 0 
s30??? 1??? 0??? 0??? 0??? 0??? 1??? 1??? 0??? 0??? 0 
e5??? 1??? 0??? 0??? 0??? 0??? 0??? 0??? 0??? 0??? 1 
l15??? 1??? 0??? 0??? 0??? 0??? 0??? 0??? 0??? 1??? 0 

Your help would be very much appreciated. 

ps. if the matrices don't appear correctly, please notice that all values different from 0 and 1 are row and column names 

Thank You!


From jim at bitwrit.com.au  Thu Sep  5 23:05:02 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 06 Sep 2013 07:05:02 +1000
Subject: [R] Y-axis labels as decimal numbers
In-Reply-To: <OF36A91BE0.A8B1F70D-ON65257BDD.00492114-65257BDD.00496C61@polarisft.com>
References: <OF36A91BE0.A8B1F70D-ON65257BDD.00492114-65257BDD.00496C61@polarisft.com>
Message-ID: <5228F1FE.3020604@bitwrit.com.au>

On 09/05/2013 11:22 PM, mohan.radhakrishnan at polarisft.com wrote:
> Hi,
>               I am able to create a graph with this code but the decimal
> numbers are not plotted accurately because the ylim values are not set
> properly. x-axis is proper.
>
> How do I accurately set the ylim for duration.1 column ?

Hi Mohan,
I think you may have your axes mixed up. Try this and see:

set1<-read.table(text="duration duration.1
16:03:41       0.05
17:03:41       0.27
18:03:43       1.22
19:03:45       1.51
20:03:47       1.27
21:03:48       1.15
22:03:50       1.22
23:03:52       1.27
00:03:54       1.27
01:03:55       1.22
02:03:57       1.26
03:03:59       1.57
04:04:01       1.31
05:04:03       1.24",header=TRUE)
set1$duration<- as.POSIXct(paste(c(rep('2013-08-24',8),rep('2013-08-25',6)),
  set1$duration))
par(mar=c(10,4,4,2))
plot(set1$duration,set1$duration.1,type="b",col="blue",ylab="",xaxt='n',
  xlab="",las=2,lwd=2.5,lty=1,cex.axis=2.5)
axis(1, at = set1$duration, labels = set1$duration, las = 2,cex.axis=1)
par(mar=c(5,4,4,2))

Jim


From jfox at mcmaster.ca  Thu Sep  5 23:14:47 2013
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 05 Sep 2013 17:14:47 -0400
Subject: [R] Poly Correlations
In-Reply-To: <057601cea9de$46d3e9d0$d47bbd70$@nycap.rr.com>
References: <057601cea9de$46d3e9d0$d47bbd70$@nycap.rr.com>
Message-ID: <web-472631581@cgpsrv2.cis.mcmaster.ca>

Dear Michael,

Please see comments below, interspersed with your questions:

On Wed, 4 Sep 2013 22:18:57 -0400
 "Michael Hacker" <mhacker at nycap.rr.com> wrote:
> Dear Colleagues,
> 
>  
> 
> I'm working on a Delphi study comparing perceptions of high school
> technology teachers and university engineering educators about the
> importance of concepts about engineering for HS students to learn as part of
> their fundamental education. I'm actually doing this as part of my Ph.D.
> 
> The survey items (n=37) are categorized into five scales: design, human
> values, modeling, resources, and systems thinking. I'm seeking to determine
> the reliability of these scales and of the overall survey instrument. Since
> I'm working with ordinal data, Chronbach's Alpha probably isn't the best
> statistical tool to use.
> 
>  
> 
> I've literally spent several days learning my way around R-project but am
> struggling with procedures and interpretations. 
> 
>  
> 
> I'm aware that there is now a plug-in for R for SPSS that can be downloaded
> ( <http://www-01.ibm.com/support/docview.wss?uid=swg21477550>
> http://www-01.ibm.com/support/docview.wss?uid=swg21477550 and
> <http://gruener.userpage.fu-berlin.de/Essentials%20for%20R%20Installation%20
> Instructions_21.pdf>
> http://gruener.userpage.fu-berlin.de/Essentials%20for%20R%20Installation%20I
> nstructions_21.pdf). Just learned that today and I downloaded
> PolyCorrelations.zip from
> https://www.ibm.com/developerworks/community/files/app?lang=en#/file/9f47f9a
> 0-7793-4ad5-8bb7-d3fd1a028e44 
> 
>  
> 
> I've gotten as far as loading Rcmdr and running some analyses - (Statistics,
> dimensional analysis, scale reliability) and I've generated this output:
> 
>  
> 
> Reliability deleting each item in turn:
> 
>                         Alpha   Std.Alpha   r(item, total)
> 
> design              0.8445    0.8490         0.7629
> 
> humanvalues   0.8526    0.8541         0.7170
> 
> modeling          0.8511    0.8546         0.7271
> 
> resources        0.8712    0.8757         0.6328
> 
> systems           0.8461    0.8498         0.7488
> 
>  
> 
> I now would sincerely appreciate some help. At the age of 70, never having
> studied programming, the meaning of these statistics is not apparent.
> 
> For example, I'm not clear if either of these three statistics are Ordinal
> Alpha. Since I'm working with Likert scale items, my advisor suggested that
> I seek an alternative to Chronbach's Alpha to determine reliability.

The table seems self-explanatory to me: it includes Chronbach's alpha and alpha for standardized items with each item deleted in turn, along with the correlation of each item with the total of the other items. All of this is described if you press the Help button in the Reliability dialog for the Rcmdr.

The computation isn't really appropriate for ordinal items (unless you plan to treat the ordinal items as numeric).

> 
>  
> 
> So far, here are the steps I have taken:
> 
> I've searched the FAQs
> 
> Searched specifically for answers on the Web
> 
> Played with the software for hours
> 
> Read the accompanying documentation.
> 
> Downloaded and installed Rcmdr
> 
> Downloaded and installed PolyCorrelations. 
> 
>  
> 
> I tried running PolyCorrelations  but I get a message that states that this
> requires the Polychor and Gclus libraries. I tried to install them into the
> R console, but no luck. 

As far as I know, this is no Polychor package on CRAN, though there is a polycor package, which will compute polychoric and polyserial correlations. These could be used to calculate reliability for ordinal items, I suppose, though not, to my knowledge, with the Rcmdr.

> 
>  
> 
> I'd also be pleased to work with someone-on-one on a consulting basis if
> someone has the time and inclination.  Hoping to find an individual who
> knows SPSS and R.

It's unclear to me what SPSS has to do with all this.

Best,
 John

------------------------------------------------
John Fox
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/
	

> 
>  
> 
> Thanks very sincerely for considering this request.
> 
>  
> 
> Michael
> 
>  
> 
>  
> 
> -------------------------------- 
> 
> END OF MESSAGE  
> 
> -------------------------------- 
> 
> Michael Hacker, Co-Director
> 
> Hofstra University Center for STEM Education Research
> 
> Ph: 518-724-6437
> 
> Cell: 518-229-7300
> 
> Fax: 518-434-6783
> 
> URL: www.Hofstra.edu/CSR
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lmumladze at gmail.com  Thu Sep  5 22:27:09 2013
From: lmumladze at gmail.com (levan mumladze)
Date: Fri, 6 Sep 2013 00:27:09 +0400
Subject: [R] Matrix randomization
Message-ID: <CAOyjOq0YF2vPVTWbnLUC25XP1LwWBe-WP6W+H_uZncp9RVM-kQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130906/a7c0e4eb/attachment.pl>

From villarino.ernesto at gmail.com  Thu Sep  5 22:27:51 2013
From: villarino.ernesto at gmail.com (ernesto villarino)
Date: Thu, 5 Sep 2013 13:27:51 -0700 (PDT)
Subject: [R] ANN: Course Data Mining with R in Spain
In-Reply-To: <1997517346.123743.1378220057604.open-xchange@email.1and1.es>
References: <1997517346.123743.1378220057604.open-xchange@email.1and1.es>
Message-ID: <CAAmrVFpok8n9UR8kaR-z1jE-dJKwFRpztQpMOYrmnf+2SkrC4Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130905/173e9cda/attachment.pl>

From r-help at sigg-iten.ch  Thu Sep  5 23:43:27 2013
From: r-help at sigg-iten.ch (Christian Sigg)
Date: Thu, 5 Sep 2013 23:43:27 +0200
Subject: [R] sparse PCA using nsprcomp package
In-Reply-To: <1378400566.3566.YahooMailNeo@web122904.mail.ne1.yahoo.com>
References: <1378370274.8239.YahooMailNeo@web122906.mail.ne1.yahoo.com>
	<1378400566.3566.YahooMailNeo@web122904.mail.ne1.yahoo.com>
Message-ID: <F45A74BC-D9F5-47AC-85B4-0391F0C6D3CF@sigg-iten.ch>

Hi John

I am currently traveling and have sporadic net access, I therefore can only answer briefly. It's also quite late, I hope what follows still makes sense...

> For regular PCA by prcomp(), we can easily calculate the percent of total variance explained by the first k PCs by using cumsum(obj$sdev^2) because these PCs are independent of each other so you can simply add up the variance of these PCs. For sparse PCA, as far as I understand, the generated PCs are not independent of each other anymore, so you can not simply add up variances to calculate percentage of variance explained by the first k PCs. For example, in the package of elasticnet where spca() also performs sparse PCA, one of the output from spca() is "pev" for percent explained variation which is based on so-called "adjusted" variance that adjusted for the fact that these variances of PCs are not independent anymore.

You are correct that measuring explained variance is more involved with sparse (or non-negative) PCA, because the principal axes no longer correspond to eigenvectors of the covariance matrix, and are usually not even orthogonal.

The next update for the 'nsprcomp' package is almost done, and one of the changes will concern the reported standard deviations. In the current version (0.3), the standard deviations are computed from the scores matrix X*W, where X is the data matrix and W is the (pseudo-)rotation matrix consisting of the sparse loadings. Computing variance this way has the advantage that 'sdev' is consistent with the scores matrix, but it has the disadvantage that some of the explained variance is counted more than once because of the non-orthogonality of the principal axes. One of the symptoms of this counting is that the variance of a later component can actually exceed the variance of an earlier component, which is not possible in regular PCA.

In the new version of the package, 'sdev' will report the _additional_ standard deviation of each component, i.e. the variance not explained by the previous components. Given a basis of the space spanned by the previous PAs, the variance of the PC is computed after projecting the current PA to the ortho-complement space of the basis. This procedure reverts back to standard PCA if no sparsity or non-negativity constraints are enforced on the PAs.

> My question is for nsprcomp, how can I calculate percent explained variation by using "sdev" when I know these PCs are not independent of each other?

The new version of the package will do it for you. Until then, you can use something like the following function

asdev <- function(X, W) {
    nc <- ncol(W)
    sdev <- numeric(nc)
    Q <- qr.Q(qr(W))
    Xp <- X
    for (cc in seq_len(nc)) {
        sdev[cc] <- sd(Xp%*%W[ , cc])
        Xp <- Xp - Xp%*%Q[ , cc]%*%t(Q[ , cc])   
    }
    return(sdev)
}

to compute the additional variances for given X and W.

The package documentation will explain the above in some more detail, and I will also have a small blog post which compares the 'nsprcomp' and 'spca' routine from the 'elasticnet' package on the 'marty' data from the EMA package.

Best regards
Christian


From ucfagls at gmail.com  Fri Sep  6 00:35:01 2013
From: ucfagls at gmail.com (Gavin Simpson)
Date: Thu, 5 Sep 2013 16:35:01 -0600
Subject: [R] Assessing temporal correlation in GAM with irregular time
	steps
In-Reply-To: <C1A5238848713043B7C18ED38FFEF1F81228A27D@STWMB01.ad.okstate.edu>
References: <C1A5238848713043B7C18ED38FFEF1F8122879FD@STWMB01.ad.okstate.edu>
	<CAAHES9ye8bEN4Lb68QtK_vtpwXCSWanS25AYqrMh03dbHTS72A@mail.gmail.com>
	<C1A5238848713043B7C18ED38FFEF1F81228A27D@STWMB01.ad.okstate.edu>
Message-ID: <CAAHES9w96apsAwD+8JBvGgFJNe6=LwnYD+hszWFQVTS09CCGzw@mail.gmail.com>

On 3 September 2013 16:10, Worthington, Thomas A
<thomas.worthington at okstate.edu> wrote:
> Dear Gavin
>
> Thank you for the very detailed response. I had started to go down the route of fitting a correlation structure via gamm.
>
> I tried applying your code to my data but returned the error
> "Error in corCAR1(~ID | SiteCode1971) : parameter in CAR(1) structure must be between 0 and 1"

Sorry, that is my fault, I keep forgetting that you need to specify
the formula argument, the first argument of corCAR1() is the value of
the correlation parameter if you want to specify it. So try:

corCAR1(form = ~ID | SiteCode1971)

I do this (get that error) all the time myself.
> I set the 'bar' in your code to the sample ID (basically a number between 1 and 192) but I wasn't sure if this was what you meant in relation to 'ordering of the samples'

That is not that useful as you need to give the software something
about when the samples occur in time, otherwise it doesn't have the
information needed to properly model the decay in correlation with
time.

You need to give it the observation time, however you measured it.

HTH

G

> Best wishes
> Tom
>
> -----Original Message-----
> From: Gavin Simpson [mailto:ucfagls at gmail.com]
> Sent: Tuesday, September 03, 2013 3:17 PM
> To: Worthington, Thomas A
> Cc: r-help at r-project.org
> Subject: Re: [R] Assessing temporal correlation in GAM with irregular time steps
>
> It is possible, but you can't use the discrete time or classical stochastic trend models (or evaluate using the ACF). Also, why do you care to do this with regard to DoY? The assumption of the model relates to the residuals, so you should check those for residual autocorrelation.
>
> As you are using `mgcv::gam` you could also use `mgcv::gamm` which can then leverage the correlation structures from the nlme package, which has spatial correlation structures (and you can think of time as a 1-d spatial direction). The package also has a `corCAR1()` correlation structure which is the continuous-time analogue of the AR(1). Fitting via `gamm()` will also allow you to use the `Variogram()` function from the nlme package to assess the model residuals for residual autocorrelation.
>
> For example you could compare the two fits
>
> m0 <- gamm(Length ~ s(DOY, by = SiteCode) + SiteCode, data = foo, method = "REML")
> m1 <- gamm(Length ~ s(DOY, by = SiteCode) + SiteCode, data = foo, method = "REML",
>                     correlation = corCAR1( ~ bar | SiteCode))
>
> where `foo` is the object that contains the variables mentioned in the call, and `bar` is the variable (in `foo)` that indicates the ordering of the samples. Notice that I nest the CAR(1) within the two respective Sites, but do note IIRC that this fits the same residual correlation structure to both sites' residuals (i.e. there is 1 CAR(1) process, not two separate ones).
>
> require(nlme)
> anova(m0$lme, m1$lme)
>
> will perform a likelihood ratio test on the two models.
>
> If you have residual autocorrelation, do note that the smooth for DoY may be chosen to be more complex than is appropriate (it might be fitting the autocorrleated noise), so you may want to fix the degrees of freedom for the smoother at some a priori chosen value and use this same value when fitting both m0 and m1, or at the very least set an upper limit on the complexity of the DoY smooth, say via s(DoY, by = SiteCode, k = 5).
>
> Finally, as a length <= 0 insect makes no sense, the assumption of Gaussian (Normal) errors may be in trouble with your data; apart from their strictly positive nature, the mean-variance relationship of the data may not follow that of the assumptions for the errors. You can move to a GLM (GAM) to account for this but things get very tricky with the correlation structures (you can use gamm() still but fitting then goes via glmmPQL() in the MASS package a thence to lme()).
>
> If you just want to fit a variogram to something, there are a large number of spatial packages available for R, several of which can fit variograms to data, though you will need to study their respective help files for how to use them. As for the input data, often the time/date of sampling encoded as a numeric will be sufficient input, but you will need to check individual functions for what they require.
> I would check out the Spatial Task View on CRAN.
>
> HTH
>
> G
>
> On 28 August 2013 14:26, Worthington, Thomas A <thomas.worthington at okstate.edu> wrote:
>> I have constructed a GAM using the package mgcv to test whether the
>> lengths of an emerging insect (Length) varies with day of the year
>> (DOY) and between two sites (SiteCode). The data are collected at
>> irregular time steps ranging from 2 days to 20 days between samples.
>> The GAM takes the form
>>
>> M3 <- gam(Length ~s(DOY, by = SiteCode) + SiteCode)
>>
>> As the data are a time series I would like to test for temporal autocorrelation. I have read that it is not possible to use the autocorrelation function (ACF) due to the irregular spacing and that producing a variogram in relation to DOY would be an option.
>>
>> Is this a correct method to test for temporal autocorrelation?
>>
>> And could someone suggest the code to produce the variogram as I'm
>> getting an error related to the 'distance' argument
>>
>> Best wishes
>> Tom
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Gavin Simpson, PhD



-- 
Gavin Simpson, PhD


From smartpink111 at yahoo.com  Fri Sep  6 00:54:19 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 5 Sep 2013 15:54:19 -0700 (PDT)
Subject: [R] binary symmetric matrix combination
In-Reply-To: <1378413000.30677.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1378411770.83414.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1378413000.30677.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1378421659.27771.YahooMailNeo@web142605.mail.bf1.yahoo.com>

HI,
No problem.
I think you didn't run the `vecOut` after adding the new matrix.? `lst1` is based on `vecOut`
For example:
m5<- as.matrix(read.table(text="y1 e6 l16
?y1 0 1 1
e6 1 0 1
l16 1 1 0",sep="",header=TRUE))
names1<-unique(c(colnames(m1),colnames(m2),colnames(m3),colnames(m4), colnames(m5)))
Out3<-matrix(0,length(names1),length(names1),dimnames=list(names1,names1))
lst1<-sapply(paste0("m",1:5),function(x) {x1<- get(x); x2<-paste0(colnames(x1)[col(x1)],rownames(x1)[row(x1)]); match(x2,vecOut)})
?lst1
#$m1
#[1]? 1? 2 11 12
#
#$m2
?#[1]? 1? 3? 4? 5 21 23 24 25 31 33 34 35 41 43 44 45
#
#$m3
?#[1]? 1? 6? 7? 8 51 56 57 58 61 66 67 68 71 76 77 78
#
#$m4
#[1]?? 1?? 9? 10? 81? 89? 90? 91? 99 100
#
#$m5
#[1]? 1 NA NA NA NA NA NA NA NA? ########
###Here vecOut was based on Out2


lst2<- list(m1,m2,m3,m4,m5)
N<- length(lst1)

?fn1<- function(N,Out){
?i=1
?while(i<=N){
?Out[lst1[[i]]]<-lst2[[i]]
?i<-i+1
?}
Out
?}
fn1(N,Out3) 
#Error in Out[lst1[[i]]] <- lst2[[i]] : 
#? NAs are not allowed in subscripted assignments

###Running vecOut using Out3

vecOut<-paste0(colnames(Out3)[col(Out3)],rownames(Out3)[row(Out3)])? 
lst1<-sapply(paste0("m",1:5),function(x) {x1<- get(x); x2<-paste0(colnames(x1)[col(x1)],rownames(x1)[row(x1)]); match(x2,vecOut)})
fn1(N,Out3) 
#??? y1 g24 c1 c2 l17 h4 s2 s30 e5 l15 e6 l16
#y1?? 0?? 1? 1? 1?? 1? 1? 1?? 1? 1?? 1? 1?? 1
#g24? 1?? 0? 0? 0?? 0? 0? 0?? 0? 0?? 0? 0?? 0
#c1?? 1?? 0? 0? 1?? 1? 0? 0?? 0? 0?? 0? 0?? 0
#c2?? 1?? 0? 1? 0?? 1? 0? 0?? 0? 0?? 0? 0?? 0
#l17? 1?? 0? 1? 1?? 0? 0? 0?? 0? 0?? 0? 0?? 0
#h4?? 1?? 0? 0? 0?? 0? 0? 1?? 1? 0?? 0? 0?? 0
#s2?? 1?? 0? 0? 0?? 0? 1? 0?? 1? 0?? 0? 0?? 0
#s30? 1?? 0? 0? 0?? 0? 1? 1?? 0? 0?? 0? 0?? 0
#e5?? 1?? 0? 0? 0?? 0? 0? 0?? 0? 0?? 1? 0?? 0
#l15? 1?? 0? 0? 0?? 0? 0? 0?? 0? 1?? 0? 0?? 0
#e6?? 1?? 0? 0? 0?? 0? 0? 0?? 0? 0?? 0? 0?? 1
#l16? 1?? 0? 0? 0?? 0? 0? 0?? 0? 0?? 0? 1?? 0

A.K.

?


Thanks a lot, all the codes worked perfectly. I have an additional question on the last steps you mentioned. 

I wanted to add another matrix to the ones I gave as an example,
 inputing m5 worked well, however when I type the code (added colnames 
(m5), changed 1:4 with 1:5 and added m5 to list2 I get the following 
error: 

Error in Out[lst1[[i]]] <- lst2[[i]] : 
? NAs are not allowed in subscripted assignments 

Below is the code: (am I doing something wrong? very many thanks again for helping!! 

names1<-unique(c(colnames(m1),colnames(m2),colnames(m3),colnames(m4), colnames(m5))) 
Out3<-matrix(0,length(names1),length(names1),dimnames=list(names1,names1)) 
lst1<-sapply(paste0("m",1:5),function(x) {x1<- get(x); 
x2<-paste0(colnames(x1)[col(x1)],rownames(x1)[row(x1)]); 
match(x2,vecOut)}) 
lst2<- list(m1,m2,m3,m4,m5) 
N<- length(lst1) 

?fn1<- function(N,Out){ 
?i=1 
?while(i<=N){ 
?Out[lst1[[i]]]<-lst2[[i]] 
?i<-i+1 
?} 
Out 
?} 
fn1(N,Out3) 



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Thursday, September 5, 2013 4:30 PM
Subject: Re: binary symmetric matrix combination

Also, some of the steps could be reduced by:

names1<-unique(c(colnames(m1),colnames(m2),colnames(m3),colnames(m4)))
Out3<-matrix(0,length(names1),length(names1),dimnames=list(names1,names1))
lst1<-sapply(paste0("m",1:4),function(x) {x1<- get(x); x2<-paste0(colnames(x1)[col(x1)],rownames(x1)[row(x1)]); match(x2,vecOut)})
lst2<- list(m1,m2,m3,m4)
N<- length(lst1)

?fn1<- function(N,Out){
?i=1
?while(i<=N){
?Out[lst1[[i]]]<-lst2[[i]]
?i<-i+1
?}
Out
?}
fn1(N,Out3)
#??? y1 g24 c1 c2 l17 h4 s2 s30 e5 l15
#y1?? 0?? 1? 1? 1?? 1? 1? 1?? 1? 1?? 1
#g24? 1?? 0? 0? 0?? 0? 0? 0?? 0? 0?? 0
#c1?? 1?? 0? 0? 1?? 1? 0? 0?? 0? 0?? 0
#c2?? 1?? 0? 1? 0?? 1? 0? 0?? 0? 0?? 0
#l17? 1?? 0? 1? 1?? 0? 0? 0?? 0? 0?? 0
#h4?? 1?? 0? 0? 0?? 0? 0? 1?? 1? 0?? 0
#s2?? 1?? 0? 0? 0?? 0? 1? 0?? 1? 0?? 0
#s30? 1?? 0? 0? 0?? 0? 1? 1?? 0? 0?? 0
#e5?? 1?? 0? 0? 0?? 0? 0? 0?? 0? 0?? 1
#l15? 1?? 0? 0? 0?? 0? 0? 0?? 0? 1?? 0


?identical(Out2,fn1(N,Out3))
#[1] TRUE

A.K.


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Thursday, September 5, 2013 4:09 PM
Subject: Re: binary symmetric matrix combination

Hi,
May be this helps:

m1<- as.matrix(read.table(text="
y1 g24
y1 0 1
g24 1 0
",sep="",header=TRUE))

m2<-as.matrix(read.table(text="y1 c1 c2 l17
?y1 0 1 1 1
?c1 1 0 1 1
?c2 1 1 0 1
?l17 1 1 1 0",sep="",header=TRUE))
m3<- as.matrix(read.table(text="y1 h4??? s2???? s30
?y1 0 1 1 1
?h4 1 0 1 1
?s2 1 1 0 1
?s30 1 1 1 0",sep="",header=TRUE))
m4<- as.matrix(read.table(text="y1 e5 l15
?y1 0 1 1
e5 1 0 1
l15 1 1 0",sep="",header=TRUE))

###desired output: at some place the label is "s2" and at other "s29".? I used "s2" for consistency
Out1<- as.matrix(read.table(text="y1 g24 c1 c2 l17 h4 s2 s30 e5 l15
y1 0 1 1 1 1 1 1 1 1 1
g24 1 0 0 0 0 0 0 0 0 0
c1 1 0 0 1 1 0 0 0 0 0
c2 1 0 1 0 1 0 0 0 0 0
l17 1 0 1 1 0 0 0 0 0 0
h4 1 0 0 0 0 0 1 1 0 0
s2 1 0 0 0 0 1 0 1 0 0
s30 1 0 0 0 0 1 1 0 0 0
e5 1 0 0 0 0 0 0 0 0 1
l15 1 0 0 0 0 0 0 0 1 0",sep="",header=TRUE))


names1<-unique(c(colnames(m1),colnames(m2),colnames(m3),colnames(m4)))
Out2<-matrix(0,length(names1),length(names1),dimnames=list(names1,names1))
vec1<- paste0(colnames(m1)[col(m1)],rownames(m1)[row(m1)])
vecOut<- paste0(colnames(Out2)[col(Out2)],rownames(Out2)[row(Out2)])
Out2[match(vec1,vecOut)]<- m1
vec2<- paste0(colnames(m2)[col(m2)],rownames(m2)[row(m2)])
Out2[match(vec2,vecOut)]<- m2
vec3<- paste0(colnames(m3)[col(m3)],rownames(m3)[row(m3)])
Out2[match(vec3,vecOut)]<- m3
vec4<- paste0(colnames(m4)[col(m4)],rownames(m4)[row(m4)])
Out2[match(vec4,vecOut)]<- m4
?all.equal(Out1,Out2)
#[1] TRUE
?Out2
??? y1 g24 c1 c2 l17 h4 s2 s30 e5 l15
y1?? 0?? 1? 1? 1?? 1? 1? 1?? 1? 1?? 1
g24? 1?? 0? 0? 0?? 0? 0? 0?? 0? 0?? 0
c1?? 1?? 0? 0? 1?? 1? 0? 0?? 0? 0?? 0
c2?? 1?? 0? 1? 0?? 1? 0? 0?? 0? 0?? 0
l17? 1?? 0? 1? 1?? 0? 0? 0?? 0? 0?? 0
h4?? 1?? 0? 0? 0?? 0? 0? 1?? 1? 0?? 0
s2?? 1?? 0? 0? 0?? 0? 1? 0?? 1? 0?? 0
s30? 1?? 0? 0? 0?? 0? 1? 1?? 0? 0?? 0
e5?? 1?? 0? 0? 0?? 0? 0? 0?? 0? 0?? 1
l15? 1?? 0? 0? 0?? 0? 0? 0?? 0? 1?? 0


A.K.



I have the following binary labeled matrices with different dimensions 
(2x2, 3x3, 4x4) which I need to create in R as seen below: 

? ? ? ? y1???? g24 
y1 ??? 0??? 1 
g2 4??? 1??? 0 
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 
? ? ? ? ?y1??? c1??? c2??? l17 
?y1??? 0??? 1??? 1??? 1 
?c1??? 1??? 0??? 1??? 1 
?c2??? 1??? 1??? 0??? 1 
?l17??? 1??? 1??? 1??? 0 
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 
? ? ? ?y1??? h4 ? ?s2 ? ? s30 
?y1??? 0??? 1??? 1??? 1 
?h4??? 1??? 0??? 1??? 1 
?s29??? 1??? 1??? 0??? 1 
?s30??? 1??? 1??? 1??? 0 
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 
? ? ? ? y1 ??? e5??? l15 
?y1??? 0??? 1??? 1 
e5??? 1??? 0??? 1 
l15??? 1??? 1??? 0 

Then, I need to combine them to achieve the following result: 

? ? ? ? y1??? g24??? c1??? c2??? l17??? h4??? s29??? s30??? e5??? l15 
y1??? 0??? 1??? 1??? 1??? 1??? 1??? 1??? 1??? 1??? 1 
g24??? 1??? 0??? 0??? 0??? 0??? 0??? 0??? 0??? 0??? 0 
c1??? 1??? 0??? 0??? 1??? 1??? 0??? 0??? 0??? 0??? 0 
c2??? 1??? 0??? 1??? 0??? 1??? 0??? 0??? 0??? 0??? 0 
l17??? 1??? 0??? 1??? 1??? 0??? 0??? 0??? 0??? 0??? 0 
h4??? 1??? 0??? 0??? 0??? 0??? 0??? 1??? 1??? 0??? 0 
s29??? 1??? 0??? 0??? 0??? 0??? 1??? 0??? 1??? 0??? 0 
s30??? 1??? 0??? 0??? 0??? 0??? 1??? 1??? 0??? 0??? 0 
e5??? 1??? 0??? 0??? 0??? 0??? 0??? 0??? 0??? 0??? 1 
l15??? 1??? 0??? 0??? 0??? 0??? 0??? 0??? 0??? 1??? 0 

Your help would be very much appreciated. 

ps. if the matrices don't appear correctly, please notice that all values different from 0 and 1 are row and column names 

Thank You!


From ivo.welch at anderson.ucla.edu  Fri Sep  6 01:37:03 2013
From: ivo.welch at anderson.ucla.edu (ivo welch)
Date: Thu, 5 Sep 2013 16:37:03 -0700
Subject: [R] get syntax for inherited environments
Message-ID: <CAPr7RtWJsOvi=12dwg5LOJbQdfUAtjJttn8Up8B8xCj66YfPBA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130905/ef9a5c1d/attachment.pl>

From arrayprofile at yahoo.com  Fri Sep  6 01:41:42 2013
From: arrayprofile at yahoo.com (array chip)
Date: Thu, 5 Sep 2013 16:41:42 -0700 (PDT)
Subject: [R] sparse PCA using nsprcomp package
In-Reply-To: <F45A74BC-D9F5-47AC-85B4-0391F0C6D3CF@sigg-iten.ch>
References: <1378370274.8239.YahooMailNeo@web122906.mail.ne1.yahoo.com>
	<1378400566.3566.YahooMailNeo@web122904.mail.ne1.yahoo.com>
	<F45A74BC-D9F5-47AC-85B4-0391F0C6D3CF@sigg-iten.ch>
Message-ID: <1378424502.93780.YahooMailNeo@web122906.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130905/ea67d048/attachment.pl>

From gunter.berton at gene.com  Fri Sep  6 01:48:21 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 5 Sep 2013 16:48:21 -0700
Subject: [R] get syntax for inherited environments
In-Reply-To: <CAPr7RtWJsOvi=12dwg5LOJbQdfUAtjJttn8Up8B8xCj66YfPBA@mail.gmail.com>
References: <CAPr7RtWJsOvi=12dwg5LOJbQdfUAtjJttn8Up8B8xCj66YfPBA@mail.gmail.com>
Message-ID: <CACk-te3GTRuif9kktf=hGrqbzFUPRSGnYHDO+fwQEk8D_eDLKg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130905/c5d85552/attachment.pl>

From eajeong at gmail.com  Fri Sep  6 03:20:05 2013
From: eajeong at gmail.com (Euna Jeong)
Date: Fri, 6 Sep 2013 10:20:05 +0900
Subject: [R] Question about R2 in pls package
In-Reply-To: <s3swqmvbv8n.fsf@slagelg.uio.no>
References: <CAMLpsnu-mHwznPfXtqN78hYGFT407C=qokj5z5gV0iHmnFiHWw@mail.gmail.com>
	<s3swqmvbv8n.fsf@slagelg.uio.no>
Message-ID: <CAMLpsnv6+x1+ZFBiEYQGN1rDMnh_r-V1zDtgXTjXDf-wth2qFg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130906/8a27c8e9/attachment.pl>

From debauck at yahoo.com  Fri Sep  6 04:53:09 2013
From: debauck at yahoo.com (Debasish Roy)
Date: Thu, 5 Sep 2013 19:53:09 -0700 (PDT)
Subject: [R] read.dta()
Message-ID: <1378435989.41375.YahooMailNeo@web161802.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130905/79c3e3cb/attachment.pl>

From dulcalma at bigpond.com  Fri Sep  6 04:56:42 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Fri, 6 Sep 2013 12:56:42 +1000
Subject: [R] xyplot() with discontinuous x-axis variable
In-Reply-To: <alpine.LNX.2.00.1309051253480.25728@salmo.appl-ecosys.com>
References: <alpine.LNX.2.00.1309051253480.25728@salmo.appl-ecosys.com>
Message-ID: <000d01ceaaac$b7dc2d80$27948880$@bigpond.com>

Hi Rich

This is a case of where data needs to be supplied to go further.

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Rich Shepard
Sent: Friday, 6 September 2013 06:24
To: r-help at r-project.org
Subject: [R] xyplot() with discontinuous x-axis variable

   My xyplot() with superposed multiple condiions looks better with lines
than with points (it's easier to see changes over time with the lines). But,
there are gaps in the years (the x axis) for which there are data to be
plotted. For example, there are data for years 2004-2006 and 2010-2012, but
not for 2007-2009. I would like to have the lines for only the two groups
with data.

   Reading ?xyplot suggests that the group attribute might do the job but I
do not see how to write the equation.

   Is it possible to plot with lines on discontinuous data or should I use
large, solid circles for each year's data points?

Rich

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From cryan at binghamton.edu  Fri Sep  6 05:37:37 2013
From: cryan at binghamton.edu (Christopher W. Ryan)
Date: Thu, 05 Sep 2013 23:37:37 -0400
Subject: [R] read.dta()
In-Reply-To: <1378435989.41375.YahooMailNeo@web161802.mail.bf1.yahoo.com>
References: <1378435989.41375.YahooMailNeo@web161802.mail.bf1.yahoo.com>
Message-ID: <52294E01.5050002@binghamton.edu>

I don't know about 3.0.1, but the 2.15.x that I'm still using requires
the foreign package--that's where the read.dta command resides.

library(foreign)

--Chris Ryan
SUNY Upstate Medical University
Binghamton, NY USA



Debasish Roy wrote:
> I've been using R 3.0.1 version. I tried to read a file named  abc.dta() 
> 
> I used the command  X <- read.dta("abc.dta") and it gave me             Error: could not find function "read.dta"
> 
> Can anyone help me what could be the problem and how to fix it ? 
> 
> 
> 
> Thanks, Deb.
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mohan.radhakrishnan at polarisft.com  Fri Sep  6 07:42:02 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Fri, 6 Sep 2013 11:12:02 +0530
Subject: [R] Y-axis labels as decimal numbers
In-Reply-To: <CAAxdm-7by-vZkrug0JaLcpkSCWJEpRGUun=YgjQFu+W_M_LeJQ@mail.gmail.com>
References: <OF36A91BE0.A8B1F70D-ON65257BDD.00492114-65257BDD.00496C61@polarisft.com>
	<CAAxdm-7by-vZkrug0JaLcpkSCWJEpRGUun=YgjQFu+W_M_LeJQ@mail.gmail.com>
Message-ID: <OFF117EDB1.25E0BDB7-ON65257BDE.001F2574-65257BDE.001F4FD8@polarisft.com>

Hi,

set1$duration.2<- as.POSIXct(paste('2013-08-24', set1$duration))
plot(set1$duration.2,set1$duration.1,type="b",col = "blue",  ylab="", xaxt 
= 'n', xlab="",las=2,lwd=2.5, lty=1,cex.axis=2.5)
# now plot you times
axis(1, at = set1$duration.2, labels = set1$duration, las = 
2,cex.axis=2.5)
text(set1$duration,set1$duration.1, set1$duration.1, 2, cex=1.45)

I think this is the correct code. The graphs is attached. y-axis is not 
accurately shown.




Thanks.



From:   jim holtman <jholtman at gmail.com>
To:     mohan.radhakrishnan at polarisft.com
Cc:     R mailing list <r-help at r-project.org>
Date:   09/05/2013 10:01 PM
Subject:        Re: [R] Y-axis labels as decimal numbers



So what is wrong with the y-axis?  When I run your script, things seem
right.  Can you explain what it is that you want.
Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Thu, Sep 5, 2013 at 9:22 AM,  <mohan.radhakrishnan at polarisft.com> 
wrote:
> Hi,
>              I am able to create a graph with this code but the decimal
> numbers are not plotted accurately because the ylim values are not set
> properly. x-axis is proper.
>
> How do I accurately set the ylim for duration.1 column ?
>
> Thanks,
> Mohan
>
> set1$duration<- as.POSIXct(paste('2013-08-24', set1$duration))
> plot(set1$duration,set1$duration.1,type="b",col = "blue",  ylab="", xaxt 
=
> 'n', xlab="",las=2,lwd=2.5, lty=1,cex.axis=2.5)
> # now plot you times
> axis(1, at = set1$duration, labels = set1$duration, las = 
2,cex.axis=2.5)
>
>    duration duration.1
> 2  16:03:41       0.05
> 3  17:03:41       0.27
> 4  18:03:43       1.22
> 5  19:03:45       1.51
> 6  20:03:47       1.27
> 7  21:03:48       1.15
> 8  22:03:50       1.22
> 9  23:03:52       1.27
> 10 00:03:54       1.27
> 11 01:03:55       1.22
> 12 02:03:57       1.26
> 13 03:03:59       1.57
> 14 04:04:01       1.31
> 15 05:04:03       1.24
>
>
> This e-Mail may contain proprietary and confidential information and is 
sent for the intended recipient(s) only.  If by an addressing or 
transmission error this mail has been misdirected to you, you are 
requested to delete this mail immediately. You are also hereby notified 
that any use, any form of reproduction, dissemination, copying, 
disclosure, modification, distribution and/or publication of this e-mail 
message, contents or its attachment other than by its intended recipient/s 
is strictly prohibited.
>
> Visit us at http://www.polarisFT.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




This e-Mail may contain proprietary and confidential information and is sent for the intended recipient(s) only.  If by an addressing or transmission error this mail has been misdirected to you, you are requested to delete this mail immediately. You are also hereby notified that any use, any form of reproduction, dissemination, copying, disclosure, modification, distribution and/or publication of this e-mail message, contents or its attachment other than by its intended recipient/s is strictly prohibited.

Visit us at http://www.polarisFT.com

From kridox at ymail.com  Fri Sep  6 07:45:53 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Fri, 6 Sep 2013 14:45:53 +0900
Subject: [R] plot densities outside axis
In-Reply-To: <CAB0Y+LT4ni9_2WwE_piErTi9_R0WrfoKp4nqLSNO3XX0JieqFw@mail.gmail.com>
References: <CAB0Y+LT4ni9_2WwE_piErTi9_R0WrfoKp4nqLSNO3XX0JieqFw@mail.gmail.com>
Message-ID: <CAAcyNCxVp39w8FFx0EEcTX-dbrqN1LFgd+2Z3EkwgdHE9D+VUQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130906/62919f18/attachment.pl>

From mohan.radhakrishnan at polarisft.com  Fri Sep  6 11:10:14 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Fri, 6 Sep 2013 14:40:14 +0530
Subject: [R] Y-axis labels as decimal numbers
In-Reply-To: <CAAxdm-5kZEjEFwDGji5w-9AwozsBYuyPmGaPF4GTB-J8wpgfjQ@mail.gmail.com>
References: <OF36A91BE0.A8B1F70D-ON65257BDD.00492114-65257BDD.00496C61@polarisft.com>
	<CAAxdm-5kZEjEFwDGji5w-9AwozsBYuyPmGaPF4GTB-J8wpgfjQ@mail.gmail.com>
Message-ID: <OFAD815848.CF08A424-ON65257BDE.003222B7-65257BDE.00325E3F@polarisft.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130906/229ce73c/attachment.pl>

From kicco1991 at hotmail.it  Fri Sep  6 12:10:59 2013
From: kicco1991 at hotmail.it (Francesco Miranda)
Date: Fri, 6 Sep 2013 12:10:59 +0200
Subject: [R] probability of occurrence of an event and the probability of an
 event upon the occurrence of another event
Message-ID: <DUB109-W321C117496BF4F90CE0733DE3C0@phx.gbl>

? stato filtrato un testo allegato il cui set di caratteri non era
indicato...
Nome: non disponibile
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130906/80bdb8b1/attachment.pl>

From Gerrit.Eichner at math.uni-giessen.de  Fri Sep  6 12:34:43 2013
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Fri, 6 Sep 2013 12:34:43 +0200 (MEST)
Subject: [R] probability of occurrence of an event and the probabilityof
	anevent upon the occurrence of another event
In-Reply-To: <DUB109-W321C117496BF4F90CE0733DE3C0@phx.gbl>
References: <DUB109-W321C117496BF4F90CE0733DE3C0@phx.gbl>
Message-ID: <Pine.SOC.4.64.1309061232030.1655@solcom.hrz.uni-giessen.de>

Hello, Francesco,

these could be considered as two of the central questions in statistics in 
general ... but they do not necessarily have anything to do with R.

  Regards -- Gerrit

On Fri, 6 Sep 2013, Francesco Miranda wrote:

> how can i calculate the probability of occurrence of an event and the 
> probability of an event upon the occurrence of another event.
>  P (A) and P (A | B) ..
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jour4life at gmail.com  Fri Sep  6 13:58:58 2013
From: jour4life at gmail.com (Carlos Valenzuela)
Date: Fri, 6 Sep 2013 06:58:58 -0500
Subject: [R] read.dta()
In-Reply-To: <1378435989.41375.YahooMailNeo@web161802.mail.bf1.yahoo.com>
References: <1378435989.41375.YahooMailNeo@web161802.mail.bf1.yahoo.com>
Message-ID: <CAOFdM0i4W4NA4inVOi3oW87=9GPn5CLfkdtBo4Ringss_03C8w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130906/3ad4942e/attachment.pl>

From pdalgd at gmail.com  Fri Sep  6 14:04:58 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 6 Sep 2013 14:04:58 +0200
Subject: [R] probability of occurrence of an event and the probabilityof
	anevent upon the occurrence of another event
In-Reply-To: <Pine.SOC.4.64.1309061232030.1655@solcom.hrz.uni-giessen.de>
References: <DUB109-W321C117496BF4F90CE0733DE3C0@phx.gbl>
	<Pine.SOC.4.64.1309061232030.1655@solcom.hrz.uni-giessen.de>
Message-ID: <284387A3-D6A0-40CC-B139-1499A0318953@gmail.com>


On Sep 6, 2013, at 12:34 , Gerrit Eichner wrote:

> Hello, Francesco,
> 
> these could be considered as two of the central questions in statistics in general ... but they do not necessarily have anything to do with R.
> 
> Regards -- Gerrit

Yes.

However, since it is Friday and my brain is fried from the morning lecture anyway:

If you can represent the (finite) sample space in R, you can also do probability calculations in R. Conditioning corresponds to subsetting the sample space. E.g., for a double dice throw (D1,D2) you can find 

> twodice <- expand.grid(d1=1:6,d2=1:6) 
> with(twodice, mean(d1==5))
[1] 0.1666667
> with(subset(twodice,d1+d2==8), mean(d1==5))
[1] 0.2
> with(subset(twodice,d1+d2==11), mean(d1==5))
[1] 0.5

I.e. 

P(D1=5) = 1/6
P(D1=5 | D1+D2=8) = 1/5
P(D1=5 | D1+D2=11) = 1/2

The above works for symmetric probability spaces. For general finite spaces, include a vector of probabilities and do something like this:

> twodice$p <- 1/nrow(twodice)
> with(subset(twodice,d1+d2==11), sum(p[d1==5])/sum(p))
[1] 0.5

- Peter D.


> 
> On Fri, 6 Sep 2013, Francesco Miranda wrote:
> 
>> how can i calculate the probability of occurrence of an event and the probability of an event upon the occurrence of another event.
>> P (A) and P (A | B) ..
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From S.Ellison at LGCGroup.com  Fri Sep  6 14:25:28 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 6 Sep 2013 13:25:28 +0100
Subject: [R] xyplot() with discontinuous x-axis variable
In-Reply-To: <alpine.LNX.2.00.1309051253480.25728@salmo.appl-ecosys.com>
References: <alpine.LNX.2.00.1309051253480.25728@salmo.appl-ecosys.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED50B49009CE@GOLD.corp.lgc-group.com>

>    My xyplot() with superposed multiple condiions looks 
> better with lines than with points (it's easier to see 
> changes over time with the lines). But, there are gaps in the 
> years (the x axis) for which there are data to be plotted. 
> For example, there are data for years 2004-2006 and 
> 2010-2012, but not for 2007-2009. I would like to have the 
> lines for only the two groups with data.
> 
>    Reading ?xyplot suggests that the group attribute might do 
> the job but I do not see how to write the equation. 

#Test data
ym <-as.data.frame(expand.grid(Y=c(2004:2006, 2010:2012), A=1:4)) #A is an arbitrary variable to give us some panels.
ym$x <- runif(nrow(ym))

library(lattice)

#Plots without, andf with, a groups argument

xyplot(x~Y|A, data=ym, type="l")
xyplot(x~Y|A, data=ym, type="l", groups=ym$Y<2007)

Is that what you had in mind?

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From rshepard at appl-ecosys.com  Fri Sep  6 15:37:21 2013
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Fri, 6 Sep 2013 06:37:21 -0700 (PDT)
Subject: [R] xyplot() with discontinuous x-axis variable
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED50B49009CE@GOLD.corp.lgc-group.com>
References: <alpine.LNX.2.00.1309051253480.25728@salmo.appl-ecosys.com>
	<A4E5A0B016B8CB41A485FC629B633CED50B49009CE@GOLD.corp.lgc-group.com>
Message-ID: <alpine.LNX.2.00.1309060636170.24397@salmo.appl-ecosys.com>

On Fri, 6 Sep 2013, S Ellison wrote:

> #Test data
> ym <-as.data.frame(expand.grid(Y=c(2004:2006, 2010:2012), A=1:4)) #A is an arbitrary variable to give us some panels.
> ym$x <- runif(nrow(ym))
>
> library(lattice)
>
> #Plots without, andf with, a groups argument
>
> xyplot(x~Y|A, data=ym, type="l")
> xyplot(x~Y|A, data=ym, type="l", groups=ym$Y<2007)
>
> Is that what you had in mind?

   Yes, it is. Thanks very much for the lesson is using groups.

Rich


From dfife at ou.edu  Fri Sep  6 15:58:34 2013
From: dfife at ou.edu (Dustin Fife)
Date: Fri, 6 Sep 2013 08:58:34 -0500
Subject: [R] plot densities outside axis
In-Reply-To: <CAAcyNCxVp39w8FFx0EEcTX-dbrqN1LFgd+2Z3EkwgdHE9D+VUQ@mail.gmail.com>
References: <CAB0Y+LT4ni9_2WwE_piErTi9_R0WrfoKp4nqLSNO3XX0JieqFw@mail.gmail.com>
	<CAAcyNCxVp39w8FFx0EEcTX-dbrqN1LFgd+2Z3EkwgdHE9D+VUQ@mail.gmail.com>
Message-ID: <CAB0Y+LTK_7aGPrSNt07eN_mz1j2hMtKaaiWkvqDqUDpaf70oAg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130906/6c2c618b/attachment.pl>

From kicco1991 at hotmail.it  Fri Sep  6 16:36:02 2013
From: kicco1991 at hotmail.it (Francesco Miranda)
Date: Fri, 6 Sep 2013 16:36:02 +0200
Subject: [R] calculate the probability
Message-ID: <DUB109-W79A2B1319D517A299BABA6DE3C0@phx.gbl>

? stato filtrato un testo allegato il cui set di caratteri non era
indicato...
Nome: non disponibile
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130906/311ecc52/attachment.pl>

From marc_schwartz at me.com  Fri Sep  6 16:49:56 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 06 Sep 2013 09:49:56 -0500
Subject: [R] calculate the probability
In-Reply-To: <DUB109-W79A2B1319D517A299BABA6DE3C0@phx.gbl>
References: <DUB109-W79A2B1319D517A299BABA6DE3C0@phx.gbl>
Message-ID: <1F345D5D-6547-472A-A198-B737D272B52A@me.com>


On Sep 6, 2013, at 9:36 AM, Francesco Miranda <kicco1991 at hotmail.it> wrote:

> How to calculate the probability P (xt <q | yt <q) where xt and yt are two time series and q is a conditional quantile.
> thankFrancesco Miranda 		 	   		  


You were told previously, directly and indirectly, that this is not the proper place to post general statistics and probability questions and especially not homework questions, if that is the case here.

Peter kindly took the time to reply to your first post, but that should not be an indication that you have tacit approval to continue to post such questions here.

If these are indeed homework questions, seek assistance from your professor or other academic support resources. If they are not, seek out other more general online resources such as StackExchange/CrossValidated (http://stats.stackexchange.com/questions).

Regards,

Marc Schwartz


From jholtman at gmail.com  Fri Sep  6 16:50:08 2013
From: jholtman at gmail.com (jim holtman)
Date: Fri, 6 Sep 2013 10:50:08 -0400
Subject: [R] Y-axis labels as decimal numbers
In-Reply-To: <OFF117EDB1.25E0BDB7-ON65257BDE.001F2574-65257BDE.001F4FD8@polarisft.com>
References: <OF36A91BE0.A8B1F70D-ON65257BDD.00492114-65257BDD.00496C61@polarisft.com>
	<CAAxdm-7by-vZkrug0JaLcpkSCWJEpRGUun=YgjQFu+W_M_LeJQ@mail.gmail.com>
	<OFF117EDB1.25E0BDB7-ON65257BDE.001F2574-65257BDE.001F4FD8@polarisft.com>
Message-ID: <CAAxdm-5rimSbfvVXryJD4BbphgMLytKuDgiVYM2d9ARAnOxW-A@mail.gmail.com>

Does this modification work for you:

par(mar=c(10,4,4,2))
plot(set1$duration,set1$duration.1,type="b",col = "blue",  ylab="", xaxt =
'n', xlab="",las=2,lwd=2.5, lty=1,cex.axis=2.5)
# now plot you times
axis(1
    , at = set1$duration
    , labels = format(set1$duration, format = "%H:%M")
    , las = 2
    ,cex.axis=2.5
    )


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Fri, Sep 6, 2013 at 1:42 AM,  <mohan.radhakrishnan at polarisft.com> wrote:
> Hi,
>
> set1$duration.2<- as.POSIXct(paste('2013-08-24', set1$duration))
> plot(set1$duration.2,set1$duration.1,type="b",col = "blue",  ylab="", xaxt =
> 'n', xlab="",las=2,lwd=2.5, lty=1,cex.axis=2.5)
> # now plot you times
> axis(1, at = set1$duration.2, labels = set1$duration, las = 2,cex.axis=2.5)
> text(set1$duration,set1$duration.1, set1$duration.1, 2, cex=1.45)
>
> I think this is the correct code. The graphs is attached. y-axis is not
> accurately shown.
>
>
>
>
> Thanks.
>
>
>
> From:        jim holtman <jholtman at gmail.com>
> To:        mohan.radhakrishnan at polarisft.com
> Cc:        R mailing list <r-help at r-project.org>
> Date:        09/05/2013 10:01 PM
> Subject:        Re: [R] Y-axis labels as decimal numbers
> ________________________________
>
>
>
> So what is wrong with the y-axis?  When I run your script, things seem
> right.  Can you explain what it is that you want.
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
>
>
> On Thu, Sep 5, 2013 at 9:22 AM,  <mohan.radhakrishnan at polarisft.com> wrote:
>> Hi,
>>              I am able to create a graph with this code but the decimal
>> numbers are not plotted accurately because the ylim values are not set
>> properly. x-axis is proper.
>>
>> How do I accurately set the ylim for duration.1 column ?
>>
>> Thanks,
>> Mohan
>>
>> set1$duration<- as.POSIXct(paste('2013-08-24', set1$duration))
>> plot(set1$duration,set1$duration.1,type="b",col = "blue",  ylab="", xaxt =
>> 'n', xlab="",las=2,lwd=2.5, lty=1,cex.axis=2.5)
>> # now plot you times
>> axis(1, at = set1$duration, labels = set1$duration, las = 2,cex.axis=2.5)
>>
>>    duration duration.1
>> 2  16:03:41       0.05
>> 3  17:03:41       0.27
>> 4  18:03:43       1.22
>> 5  19:03:45       1.51
>> 6  20:03:47       1.27
>> 7  21:03:48       1.15
>> 8  22:03:50       1.22
>> 9  23:03:52       1.27
>> 10 00:03:54       1.27
>> 11 01:03:55       1.22
>> 12 02:03:57       1.26
>> 13 03:03:59       1.57
>> 14 04:04:01       1.31
>> 15 05:04:03       1.24
>>
>>
>> This e-Mail may contain proprietary and confidential information and is
>> sent for the intended recipient(s) only.  If by an addressing or
>> transmission error this mail has been misdirected to you, you are requested
>> to delete this mail immediately. You are also hereby notified that any use,
>> any form of reproduction, dissemination, copying, disclosure, modification,
>> distribution and/or publication of this e-mail message, contents or its
>> attachment other than by its intended recipient/s is strictly prohibited.
>>
>> Visit us at http://www.polarisFT.com
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
> ________________________________
> This e-Mail may contain proprietary and confidential information and is sent
> for the intended recipient(s) only. If by an addressing or transmission
> error this mail has been misdirected to you, you are requested to delete
> this mail immediately. You are also hereby notified that any use, any form
> of reproduction, dissemination, copying, disclosure, modification,
> distribution and/or publication of this e-mail message, contents or its
> attachment other than by its intended recipient/s is strictly prohibited.
> Visit us at http://www.polarisFT.com
> ________________________________
-------------- next part --------------
A non-text attachment was scrubbed...
Name: r-help.png
Type: image/png
Size: 7084 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130906/cdcf587d/attachment.png>

From azzalini at stat.unipd.it  Fri Sep  6 16:53:45 2013
From: azzalini at stat.unipd.it (Adelchi Azzalini)
Date: Fri, 6 Sep 2013 16:53:45 +0200
Subject: [R] calculate the probability
In-Reply-To: <DUB109-W79A2B1319D517A299BABA6DE3C0@phx.gbl>
References: <DUB109-W79A2B1319D517A299BABA6DE3C0@phx.gbl>
Message-ID: <20130906165345.c063d977a52e158af69c7d56@stat.unipd.it>

On Fri, 6 Sep 2013 16:36:02 +0200, Francesco Miranda wrote:

FM> How to calculate the probability P (xt <q | yt <q) where xt and yt
FM> are two time series and q is a conditional quantile. thankFrancesco
FM> Miranda [[alternative HTML version deleted]]
FM> 

This is a non-R question.

What do you know about these time series, specifically about their
joint distribution? 

Also, is "t" a single time point or a sequence of time points?
In the first case, we are just dealing with a bivariate distribution.

Finally, what do you mean by "conditional quantile", conditional on
what? 


Adelchi Azzalini  <azzalini at stat.unipd.it>
Dipart.Scienze Statistiche, Universit? di Padova, Italia
tel. +39 049 8274147,  http://azzalini.stat.unipd.it/


From pmassicotte at hotmail.com  Fri Sep  6 16:57:48 2013
From: pmassicotte at hotmail.com (philippe massicotte)
Date: Fri, 6 Sep 2013 14:57:48 +0000
Subject: [R] Combining rasters
Message-ID: <COL127-W243D2BEC44B3DFA6326BFAB33C0@phx.gbl>

Hi everyone.

I would like to know if it is possible to combine rasters in R to form a "collage".

For example, I would like to place 2 copies of the R logo side by side.


r = raster(system.file("external/rlogo.grd", package = "raster"))



After reading the help file (maybe I missed it) I did not find a way to do it.

Any help would be appreciated.

Sincerely,
Phil 		 	   		  

From b.rowlingson at lancaster.ac.uk  Fri Sep  6 17:10:28 2013
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 6 Sep 2013 16:10:28 +0100
Subject: [R] Combining rasters
In-Reply-To: <a5057b9c70c3421a8c6184e7dc3bdfa6@EX-0-HT0.lancs.local>
References: <a5057b9c70c3421a8c6184e7dc3bdfa6@EX-0-HT0.lancs.local>
Message-ID: <CANVKczMhD2PKh8Tfb=rnDTsYELoJxzjuWi0Z2frKmUPfDGeDjQ@mail.gmail.com>

[Probably an R-Sig-geo question...]



On Fri, Sep 6, 2013 at 3:57 PM, philippe massicotte
<pmassicotte at hotmail.com> wrote:
> Hi everyone.
>
> I would like to know if it is possible to combine rasters in R to form a "collage".
>
> For example, I would like to place 2 copies of the R logo side by side.
>
>
> r = raster(system.file("external/rlogo.grd", package = "raster"))

 Convert to matrix, cbind, convert to raster:

  r2 = raster(cbind(as.matrix(r),as.matrix(r)))
  plot(r2)

If you want to preserve the x and y scale somehow then you need to
think about exactly where you are putting the second r and set xmx,
ymx xmn, ymn when you construct the new raster.

Barry


From jixiangwu05 at gmail.com  Fri Sep  6 17:53:53 2013
From: jixiangwu05 at gmail.com (Jixiang Wu)
Date: Fri, 6 Sep 2013 10:53:53 -0500
Subject: [R] While using R CMD check: LaTex error: File
 `inconsolata.sty' not found
In-Reply-To: <12F955D2-CF20-4C32-9AB4-AA1A32093EE9@xs4all.nl>
References: <2F9EA67EF9AE1C48A147CB41BE2E15C3480E41@DOM-EB-MAIL1.win.ad.jhu.edu>
	<12F955D2-CF20-4C32-9AB4-AA1A32093EE9@xs4all.nl>
Message-ID: <CAE6ecRoPoCLcX3c6dxkDUJU25Do+Bm=RSDJQgDEfP0Q1390Kpw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130906/7f563dc0/attachment.pl>

From smartpink111 at yahoo.com  Fri Sep  6 18:03:50 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 6 Sep 2013 09:03:50 -0700 (PDT)
Subject: [R] Looping an lapply linear regression function
In-Reply-To: <1378399756.77090.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <1378399756.77090.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <1378483430.98925.YahooMailNeo@web142604.mail.bf1.yahoo.com>

HI,
Using the example dataset (Test_data.csv):
dat1<- read.csv("Test_data.csv",header=TRUE,sep="\t",row.names=1)
indx2<-expand.grid(names(dat1),names(dat1),stringsAsFactors=FALSE) 
indx2New<- indx2[indx2[,1]!=indx2[,2],] 
res2<-t(sapply(seq_len(nrow(indx2New)),function(i) {x1<- indx2New[i,]; x2<-cbind(dat1[x1[,1]],dat1[x1[,2]]);summary(lm(x2[,1]~x2[,2]))$coef[,4]}))
?dat2<- cbind(indx2New,value=res2[,2])
library(reshape2)
res2New<- dcast(dat2,Var1~Var2,value.var="value")
row.names(res2New)<- res2New[,1]
?res2New<- as.matrix(res2New[,-1])
?dim(res2New)
#[1] 28 28
head(res2New,3)
#??????????? AgriEmi?? AgriMach? AgriValAd???? AgrVaGDP?????? AIL???? ALAre
#AgriEmi????????? NA 0.23401895 0.45697412 4.644877e-01 0.6398030 0.4039855
#AgriMach? 0.2340189???????? NA 0.01449519 4.922558e-06 0.3890046 0.9279044
#AgriValAd 0.4569741 0.01449519???????? NA 5.135269e-02 0.5325943 0.4872555
#????????????? ALPer????????? ANS???? AraLa? AraLaPer??? CombusRen????? ForArea
#AgriEmi?? 0.4039855 2.507257e-01 0.2303275 0.2303275 0.9438409125 0.0004473563
#AgriMach? 0.9279044 6.072123e-05 0.3154370 0.3154370 0.0040254771 0.2590309747
#AgriValAd 0.4872555 2.060412e-01 0.8449600 0.8449600 0.0008077264 0.5152352072
#???????????? ForArePer? ForProTon ForProTonSKm????? ForRen????????? GDP
#AgriEmi?? 0.0004473563 0.01714768 0.0007089448 0.900222038 0.6022470671
#AgriMach? 0.2590309748 0.20170800 0.2305335762 0.005584703 0.4199684378
#AgriValAd 0.5152352071 0.80983446 0.4368256400 0.208975126 0.0003534226
#?????????????????? GEF GroAgriProVal PermaCrop? RoadDens?? RoadTot? RurPopGro
#AgriEmi?? 0.0008580856??? 0.01078593 0.6863110 0.6398030 0.6398030 0.40734903
#AgriMach? 0.1315182244??? 0.14074612 0.2530378 0.3064186 0.3064186 0.33705434
#AgriValAd 0.7520803684??? 0.31556633 0.1151395 0.4374599 0.4374599 0.04837586
#????????? RurPopPerc??? TerrPA???????? Trac????? Vehi WaterWith
#AgriEmi??? 0.4835676 0.4504239 2.279566e-01 0.6398030 0.3056195
#AgriMach?? 0.6401556 0.1707857 4.730759e-33 0.3064186 0.9502553
#AgriValAd? 0.2383507 0.0223124 1.513169e-02 0.1251843 0.3307148


#or
res3<-xtabs(value~Var1+Var2,data=dat2) #here the diagonals are "0"s
?attr(res3,"class")<- NULL
?attr(res3,"call")<-NULL
names(dimnames(res3))<-NULL

#You can change it in the first solution also.
?res2New<- dcast(dat2,Var1~Var2,value.var="value",fill=0)
row.names(res2New)<- res2New[,1]
?res2New<- as.matrix(res2New[,-1])
?identical(res2New,res3)
#[1] TRUE

A.K.




Arun, 

That does exactly what I wanted to do, but how would I 
manipulate into a matrix where the indepedent variable was on the x and 
dependent on y, or vice versa, rather than a 736, 2 matrix 



? ? V1 ? V2 ? V3 ? V4 ? V5...Vn 
V1 - 

V2 ? ? ? - 

V3 ? ? ? ? ? ? ?- 

V4 ? ? ? ? ? ? ? ? ? ?- ? 

V5 ? ? ? ? ? ? ? ? ? ? ? ? ?- 

Vn ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? - 


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Thursday, September 5, 2013 12:49 PM
Subject: Re: Looping an lapply linear regression function

HI,
May be this helps:
?set.seed(28)
?dat1<- setNames(as.data.frame(matrix(sample(1:40,10*5,replace=TRUE),ncol=5)),letters[1:5])
indx<-as.data.frame(combn(names(dat1),2),stringsAsFactors=FALSE)
res<-t(sapply(indx,function(x) {x1<-cbind(dat1[x[1]],dat1[x[2]]);summary(lm(x1[,1]~x1[,2]))$coef[,4]}))
?rownames(res)<-apply(indx,2,paste,collapse="_")
?colnames(res)[2]<- "Coef1"
?head(res,3)
#??? (Intercept)???? Coef1
#a_b? 0.39862676 0.8365606
#a_c? 0.02427885 0.6094141
#a_d? 0.37521423 0.7578723


#permutation
indx2<-expand.grid(names(dat1),names(dat1),stringsAsFactors=FALSE)
#or
indx2<- expand.grid(rep(list(names(dat1)),2),stringsAsFactors=FALSE)
indx2New<- indx2[indx2[,1]!=indx2[,2],]
res2<-t(sapply(seq_len(nrow(indx2New)),function(i) {x1<- indx2New[i,]; x2<-cbind(dat1[x1[,1]],dat1[x1[,2]]);summary(lm(x2[,1]~x2[,2]))$coef[,4]}))
row.names(res2)<-apply(indx2New,1,paste,collapse="_")
?colnames(res2)<- colnames(res)


A.K.


Hi everyone, 

First off just like to say thanks to everyone?s contributions. 
Up until now, I?ve never had to post as I?ve always found the answers 
from trawling through the database. I?ve finally managed to stump 
myself, and although for someone out there, I?m sure the answer to my 
problem is fairly simple, I, however have spent the whole day infront of
my computer struggling. I know I?ll probably get an absolute ribbing 
for making a basic mistake, or not understanding something fully, but 
I?m blind to the mistake now after looking so long at it. 

What I?m looking to do, is formulate a matrix ([28,28]) of 
p-values produced from running linear regressions of 28 variables 
against themselves (eg a~b, a~c, a~d.....b~a, b~c etc...), if that makes
sense. I?ve managed to get this to work if I just input each variable 
by hand, but this isn?t going to help when I have to make 20 matrices. 

My script is as follows; 


for (j in [1:28]) 
{ 
?##This section works perfectly, if I don?t try to loop it, I know 
this wont work at the moment, because I haven?t designated what j is, 
but I?m showing to highlight what I?m attempting to do. ? 
? 

? ?models <- lapply(varlist, function(x) { 
? ? lm(substitute(ANS ~ i, list(i = as.name(x))), data = con.i) 
? }) 
? 
? ? ? ? ? abc<- lapply(models, function(f) summary(f)$coefficients[,4]) 
? 
? ? ? ? ? abc<- do.call(rbind, abc) 
? 
? ? ? ? ? 
? 
} 

I get the following error when I try to loop it... 

Error in model.frame.default(formula = substitute(j ~ i, list(i = as.name(x))), ?: 
? variable lengths differ (found for 'ANS') ##?NS being my first variable 

All variables are of the same length, with 21 recordings for each 


If anyone can suggest a method of looping, or another means 
or producing ?models? for each of my 28 variables, without having to do 
it by hand that would be fantastic. 

Thanks in advance!!


From csmeredith at fs.fed.us  Fri Sep  6 18:57:28 2013
From: csmeredith at fs.fed.us (Meredith, Christy S -FS)
Date: Fri, 6 Sep 2013 16:57:28 +0000
Subject: [R] using correlation compound correlation structure with nlme;
 how to incorporate multple random effects?
Message-ID: <0720E9865B786C4E86338F700C57DCCD01025DE6@001FSN2MPN1-046.001f.mgd2.msft.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130906/bb9b3b0b/attachment.pl>

From gunter.berton at gene.com  Fri Sep  6 19:19:38 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 6 Sep 2013 10:19:38 -0700
Subject: [R] using correlation compound correlation structure with nlme;
 how to incorporate multple random effects?
In-Reply-To: <0720E9865B786C4E86338F700C57DCCD01025DE6@001FSN2MPN1-046.001f.mgd2.msft.net>
References: <0720E9865B786C4E86338F700C57DCCD01025DE6@001FSN2MPN1-046.001f.mgd2.msft.net>
Message-ID: <CACk-te1OLSzeE4SNLFihK1RMMWLnDpAociDgoOg0HnJpJ-aN1A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130906/bb9ae207/attachment.pl>

From 11050330 at life.hkbu.edu.hk  Fri Sep  6 10:00:06 2013
From: 11050330 at life.hkbu.edu.hk (gaofield)
Date: Fri, 6 Sep 2013 01:00:06 -0700 (PDT)
Subject: [R] Impute missing data by regression in R
In-Reply-To: <AANLkTinGJsyhs2cSaBgccdT60u18oaQ1fYe5hXYKD7qh@mail.gmail.com>
References: <4CB7E34F.5000704@gmail.com>
	<AANLkTinGJsyhs2cSaBgccdT60u18oaQ1fYe5hXYKD7qh@mail.gmail.com>
Message-ID: <1378454405928-4675516.post@n4.nabble.com>

i dont think it works. is there any function in any package?



--
View this message in context: http://r.789695.n4.nabble.com/Impute-missing-data-by-regression-in-R-tp2996520p4675516.html
Sent from the R help mailing list archive at Nabble.com.


From markus.gschwind at gmail.com  Fri Sep  6 11:29:19 2013
From: markus.gschwind at gmail.com (Markus Gschwind)
Date: Fri, 6 Sep 2013 11:29:19 +0200
Subject: [R] how to define ordinal, nominal and scale type variables?
Message-ID: <CABaUQnxNf8TZhFk2dwhvBvZZNFddEcvoK5Vo0LJQtDmGspo5pA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130906/2fb23586/attachment.pl>

From pietr007 at gmail.com  Fri Sep  6 13:12:01 2013
From: pietr007 at gmail.com (Ricardo Pietrobon)
Date: Fri, 6 Sep 2013 07:12:01 -0400
Subject: [R] error with RNetLogo on a mac
Message-ID: <CAF4X4oMGqt0YFvvF6vSwYjPzQ-7qznMCKraXb4xuehXVvSRWQw@mail.gmail.com>

gist with code and respective errors: http://goo.gl/r6VrHl

would appreciate any input on how to get around the java vm problem.
btw, the very idea of connecting R and netlogo is superb

copying Jan in case he might have some input

many thanks


From NutterB at ccf.org  Fri Sep  6 17:59:28 2013
From: NutterB at ccf.org (Nutter, Benjamin)
Date: Fri, 6 Sep 2013 11:59:28 -0400
Subject: [R] melt error that I don't understand.
Message-ID: <B6C1631FCD1980499A5F02B4895037E801A24F9B@CCHSCLEXMB77.cc.ad.cchs.net>

I'm stumped.  I have a dataset I want to melt to create a temporal sequence of events for each subject, but in each row, I would like to retain the baseline characteristics.

D <- structure(list(ID = c("A", "B", "C", "D", "E", "F", "G", "H", "I", "J"), 
                    AGE = structure(c(68L, 63L, 55L, 64L, 60L, 78L, 60L, 62L, 60L, 75L), 
                                    label = "Age", class = "labelled"), 
                    BMI = structure(c(25L, 27L, 27L, 28L, 32L, NA, 36L, 27L, 31L, 25L), 
                                    label = "BMI (kg/m2)", class = "labelled"), 
                    EventDays = structure(c(722L, 738L, 707L, 751L, 735L, 728L, 731L, 717L, 728L, 735L), 
                                          label = "Time to first ACM/censor (days)", class = "labelled"), 
                    ImplantDays = c(NA, NA, 575, NA, NA, NA, 490, 643, NA, NA)), 
               .Names = c("ID", "AGE", "BMI", "EventDays", "InterventionDays"), 
               row.names = c(NA, 10L), 
               class = "data.frame")

melt(D, c("ID", "AGE", "BMI")) # produces the following error

Error in data.frame(ids, variable, value, stringsAsFactors = FALSE) : 
  arguments imply differing number of rows: 10, 20


Now, I know AGE and BMI aren't exactly identifying variables, but my hope would be that, since ID uniquely identifies the subjects, I could use this as a short cut to getting the data set I want.  I can get the data I want if I go about it a little differently.

#* What I would like it to look like.
Timeline <- melt(D[, c("ID", "EventDays", "InterventionDays")], "ID", na.rm=TRUE)
Timeline <- arrange(Timeline, ID, value)
Timeline <- merge(D[, c("ID", "AGE", "BMI")],
                  Timeline,                  
                  by="ID", all.x=TRUE)


At first I thought it might be the mixture of character and numeric variables as IDs, but the following example works

A <- data.frame(id = LETTERS[1:10],
                age = c(50, NA, 51, 52, 53, 54, 55, 56, 57, 58),
                meas1 = rnorm(10),
                meas2 = rnorm(10, 5),
                stringsAsFactors=FALSE)
melt(A, c("id", "age"))


I'm sure I'm missing something really obvious (kind of like how I can stare at the dry goods aisle for 10 minutes and still not find the chocolate chips).  If anyone could help me understand why this error is occurring, I'd greatly appreciate it.  

> sessionInfo()
R version 2.15.2 (2012-10-26)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
[1] C

attached base packages:
[1] splines   stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] lazyWeave_2.2.3  Hmisc_3.10-1     survival_2.36-14 plyr_1.7.1       reshape2_1.2.2  

loaded via a namespace (and not attached):
[1] cluster_1.14.3  grid_2.15.2     lattice_0.20-10 stringr_0.6.1   tools_2.15.2


? Benjamin Nutter |??Biostatistician?    |??Quantitative Health Sciences
? Cleveland Clinic  ? | ?9500 Euclid Ave.? | ?Cleveland, OH 44195? |?(216) 445-1365



===================================


 Please consider the environment before printing this e-mail

Cleveland Clinic is ranked as one of the top hospitals in America by U.S.News & World Report (2013).  
Visit us online at http://www.clevelandclinic.org for a complete listing of our services, staff and locations.


Confidentiality Note:  This message is intended for use ...{{dropped:18}}


From smartpink111 at yahoo.com  Fri Sep  6 19:29:41 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 6 Sep 2013 10:29:41 -0700 (PDT)
Subject: [R] binary symmetric matrix combination
In-Reply-To: <1378421659.27771.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1378411770.83414.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1378413000.30677.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1378421659.27771.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1378488581.72798.YahooMailNeo@web142604.mail.bf1.yahoo.com>

HI,
No problem.? Suppose you have many matrices and you want to sum up the repeated variables, may be this helps:
#Creating one more matrix which has some repeated variables.


m6<- as.matrix(read.table(text="y1 e5 s2
?y1 0 1 1
?e5 1 0 1
?s2 1 1 0",sep="",header=TRUE))
#m1:m5 same as previous

dat<-do.call(rbind,lapply(paste0("m",1:6),function(x) {x1<- get(x);cbind(expand.grid(rep(list(colnames(x1)),2),stringsAsFactors=FALSE),value=as.vector(x1))}))

library(reshape2)
res<- dcast(dat,Var1~Var2,value.var="value",sum)
row.names(res)<- res[,1]
?res<- as.matrix(res[,-1])
?res
#??? c1 c2 e5 e6 g24 h4 l15 l16 l17 s2 s30 y1
#c1?? 0? 1? 0? 0?? 0? 0?? 0?? 0?? 1? 0?? 0? 1
#c2?? 1? 0? 0? 0?? 0? 0?? 0?? 0?? 1? 0?? 0? 1
#e5?? 0? 0? 0? 0?? 0? 0?? 1?? 0?? 0? 1?? 0? 2
#e6?? 0? 0? 0? 0?? 0? 0?? 0?? 1?? 0? 0?? 0? 1
#g24? 0? 0? 0? 0?? 0? 0?? 0?? 0?? 0? 0?? 0? 1
#h4?? 0? 0? 0? 0?? 0? 0?? 0?? 0?? 0? 1?? 1? 1
#l15? 0? 0? 1? 0?? 0? 0?? 0?? 0?? 0? 0?? 0? 1
#l16? 0? 0? 0? 1?? 0? 0?? 0?? 0?? 0? 0?? 0? 1
#l17? 1? 1? 0? 0?? 0? 0?? 0?? 0?? 0? 0?? 0? 1
#s2?? 0? 0? 1? 0?? 0? 1?? 0?? 0?? 0? 0?? 1? 2
#s30? 0? 0? 0? 0?? 0? 1?? 0?? 0?? 0? 1?? 0? 1
#y1?? 1? 1? 2? 1?? 1? 1?? 1?? 1?? 1? 2?? 1? 0


#If you want it in a particular order, say:
names1<-unique(unlist(lapply(paste0("m",1:6),function(x) colnames(get(x)))))

?names1
?#[1] "y1"? "g24" "c1"? "c2"? "l17" "h4"? "s2"? "s30" "e5"? "l15" "e6"? "l16"

dat1<- datdat1$Var1<- factor(dat1$Var1,levels=names1)
dat1$Var2<- factor(dat1$Var2,levels=names1)



?dat2<-dat1[order(dat1$Var1,dat1$Var2),]

res1<- dcast(dat2,Var1~Var2,value.var="value",sum)row.names(res1)<- res1[,1]
?res1<- as.matrix(res1[,-1])
res1
#??? y1 g24 c1 c2 l17 h4 s2 s30 e5 l15 e6 l16
#y1?? 0?? 1? 1? 1?? 1? 1? 2?? 1? 2?? 1? 1?? 1
#g24? 1?? 0? 0? 0?? 0? 0? 0?? 0? 0?? 0? 0?? 0
#c1?? 1?? 0? 0? 1?? 1? 0? 0?? 0? 0?? 0? 0?? 0
#c2?? 1?? 0? 1? 0?? 1? 0? 0?? 0? 0?? 0? 0?? 0
#l17? 1?? 0? 1? 1?? 0? 0? 0?? 0? 0?? 0? 0?? 0
#h4?? 1?? 0? 0? 0?? 0? 0? 1?? 1? 0?? 0? 0?? 0
#s2?? 2?? 0? 0? 0?? 0? 1? 0?? 1? 1?? 0? 0?? 0
#s30? 1?? 0? 0? 0?? 0? 1? 1?? 0? 0?? 0? 0?? 0
#e5?? 2?? 0? 0? 0?? 0? 0? 1?? 0? 0?? 1? 0?? 0
#l15? 1?? 0? 0? 0?? 0? 0? 0?? 0? 1?? 0? 0?? 0
#e6?? 1?? 0? 0? 0?? 0? 0? 0?? 0? 0?? 0? 0?? 1
#l16? 1?? 0? 0? 0?? 0? 0? 0?? 0? 0?? 0? 1?? 0


#or
res2<- xtabs(value~Var1+Var2,data=dat2)
? attr(res2,"class")<- NULL
? attr(res2,"call")<-NULL
?names(dimnames(res2))<-NULL
?all.equal(res1,res2)
#[1] TRUE


A.K.


Very many thanks once again...does the code work for many matrices? I have around 200 small matrices. 

Another question, is there a similar code to merge the matrices 
by summing up the "1" values for repeated variables (row/colnames)? 


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Thursday, September 5, 2013 6:54 PM
Subject: Re: binary symmetric matrix combination

HI,
No problem.
I think you didn't run the `vecOut` after adding the new matrix.? `lst1` is based on `vecOut`
For example:
m5<- as.matrix(read.table(text="y1 e6 l16
?y1 0 1 1
e6 1 0 1
l16 1 1 0",sep="",header=TRUE))
names1<-unique(c(colnames(m1),colnames(m2),colnames(m3),colnames(m4), colnames(m5)))
Out3<-matrix(0,length(names1),length(names1),dimnames=list(names1,names1))
lst1<-sapply(paste0("m",1:5),function(x) {x1<- get(x); x2<-paste0(colnames(x1)[col(x1)],rownames(x1)[row(x1)]); match(x2,vecOut)})
?lst1
#$m1
#[1]? 1? 2 11 12
#
#$m2
?#[1]? 1? 3? 4? 5 21 23 24 25 31 33 34 35 41 43 44 45
#
#$m3
?#[1]? 1? 6? 7? 8 51 56 57 58 61 66 67 68 71 76 77 78
#
#$m4
#[1]?? 1?? 9? 10? 81? 89? 90? 91? 99 100
#
#$m5
#[1]? 1 NA NA NA NA NA NA NA NA? ########
###Here vecOut was based on Out2


lst2<- list(m1,m2,m3,m4,m5)
N<- length(lst1)

?fn1<- function(N,Out){
?i=1
?while(i<=N){
?Out[lst1[[i]]]<-lst2[[i]]
?i<-i+1
?}
Out
?}
fn1(N,Out3) 
#Error in Out[lst1[[i]]] <- lst2[[i]] : 
#? NAs are not allowed in subscripted assignments

###Running vecOut using Out3

vecOut<-paste0(colnames(Out3)[col(Out3)],rownames(Out3)[row(Out3)])? 
lst1<-sapply(paste0("m",1:5),function(x) {x1<- get(x); x2<-paste0(colnames(x1)[col(x1)],rownames(x1)[row(x1)]); match(x2,vecOut)})
fn1(N,Out3) 
#??? y1 g24 c1 c2 l17 h4 s2 s30 e5 l15 e6 l16
#y1?? 0?? 1? 1? 1?? 1? 1? 1?? 1? 1?? 1? 1?? 1
#g24? 1?? 0? 0? 0?? 0? 0? 0?? 0? 0?? 0? 0?? 0
#c1?? 1?? 0? 0? 1?? 1? 0? 0?? 0? 0?? 0? 0?? 0
#c2?? 1?? 0? 1? 0?? 1? 0? 0?? 0? 0?? 0? 0?? 0
#l17? 1?? 0? 1? 1?? 0? 0? 0?? 0? 0?? 0? 0?? 0
#h4?? 1?? 0? 0? 0?? 0? 0? 1?? 1? 0?? 0? 0?? 0
#s2?? 1?? 0? 0? 0?? 0? 1? 0?? 1? 0?? 0? 0?? 0
#s30? 1?? 0? 0? 0?? 0? 1? 1?? 0? 0?? 0? 0?? 0
#e5?? 1?? 0? 0? 0?? 0? 0? 0?? 0? 0?? 1? 0?? 0
#l15? 1?? 0? 0? 0?? 0? 0? 0?? 0? 1?? 0? 0?? 0
#e6?? 1?? 0? 0? 0?? 0? 0? 0?? 0? 0?? 0? 0?? 1
#l16? 1?? 0? 0? 0?? 0? 0? 0?? 0? 0?? 0? 1?? 0

A.K.

?


Thanks a lot, all the codes worked perfectly. I have an additional question on the last steps you mentioned. 

I wanted to add another matrix to the ones I gave as an example,
inputing m5 worked well, however when I type the code (added colnames 
(m5), changed 1:4 with 1:5 and added m5 to list2 I get the following 
error: 

Error in Out[lst1[[i]]] <- lst2[[i]] : 
? NAs are not allowed in subscripted assignments 

Below is the code: (am I doing something wrong? very many thanks again for helping!! 

names1<-unique(c(colnames(m1),colnames(m2),colnames(m3),colnames(m4), colnames(m5))) 
Out3<-matrix(0,length(names1),length(names1),dimnames=list(names1,names1)) 
lst1<-sapply(paste0("m",1:5),function(x) {x1<- get(x); 
x2<-paste0(colnames(x1)[col(x1)],rownames(x1)[row(x1)]); 
match(x2,vecOut)}) 
lst2<- list(m1,m2,m3,m4,m5) 
N<- length(lst1) 

?fn1<- function(N,Out){ 
?i=1 
?while(i<=N){ 
?Out[lst1[[i]]]<-lst2[[i]] 
?i<-i+1 
?} 
Out 
?} 
fn1(N,Out3) 



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Thursday, September 5, 2013 4:30 PM
Subject: Re: binary symmetric matrix combination

Also, some of the steps could be reduced by:

names1<-unique(c(colnames(m1),colnames(m2),colnames(m3),colnames(m4)))
Out3<-matrix(0,length(names1),length(names1),dimnames=list(names1,names1))
lst1<-sapply(paste0("m",1:4),function(x) {x1<- get(x); x2<-paste0(colnames(x1)[col(x1)],rownames(x1)[row(x1)]); match(x2,vecOut)})
lst2<- list(m1,m2,m3,m4)
N<- length(lst1)

?fn1<- function(N,Out){
?i=1
?while(i<=N){
?Out[lst1[[i]]]<-lst2[[i]]
?i<-i+1
?}
Out
?}
fn1(N,Out3)
#??? y1 g24 c1 c2 l17 h4 s2 s30 e5 l15
#y1?? 0?? 1? 1? 1?? 1? 1? 1?? 1? 1?? 1
#g24? 1?? 0? 0? 0?? 0? 0? 0?? 0? 0?? 0
#c1?? 1?? 0? 0? 1?? 1? 0? 0?? 0? 0?? 0
#c2?? 1?? 0? 1? 0?? 1? 0? 0?? 0? 0?? 0
#l17? 1?? 0? 1? 1?? 0? 0? 0?? 0? 0?? 0
#h4?? 1?? 0? 0? 0?? 0? 0? 1?? 1? 0?? 0
#s2?? 1?? 0? 0? 0?? 0? 1? 0?? 1? 0?? 0
#s30? 1?? 0? 0? 0?? 0? 1? 1?? 0? 0?? 0
#e5?? 1?? 0? 0? 0?? 0? 0? 0?? 0? 0?? 1
#l15? 1?? 0? 0? 0?? 0? 0? 0?? 0? 1?? 0


?identical(Out2,fn1(N,Out3))
#[1] TRUE

A.K.


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Thursday, September 5, 2013 4:09 PM
Subject: Re: binary symmetric matrix combination

Hi,
May be this helps:

m1<- as.matrix(read.table(text="
y1 g24
y1 0 1
g24 1 0
",sep="",header=TRUE))

m2<-as.matrix(read.table(text="y1 c1 c2 l17
?y1 0 1 1 1
?c1 1 0 1 1
?c2 1 1 0 1
?l17 1 1 1 0",sep="",header=TRUE))
m3<- as.matrix(read.table(text="y1 h4??? s2???? s30
?y1 0 1 1 1
?h4 1 0 1 1
?s2 1 1 0 1
?s30 1 1 1 0",sep="",header=TRUE))
m4<- as.matrix(read.table(text="y1 e5 l15
?y1 0 1 1
e5 1 0 1
l15 1 1 0",sep="",header=TRUE))

###desired output: at some place the label is "s2" and at other "s29".? I used "s2" for consistency
Out1<- as.matrix(read.table(text="y1 g24 c1 c2 l17 h4 s2 s30 e5 l15
y1 0 1 1 1 1 1 1 1 1 1
g24 1 0 0 0 0 0 0 0 0 0
c1 1 0 0 1 1 0 0 0 0 0
c2 1 0 1 0 1 0 0 0 0 0
l17 1 0 1 1 0 0 0 0 0 0
h4 1 0 0 0 0 0 1 1 0 0
s2 1 0 0 0 0 1 0 1 0 0
s30 1 0 0 0 0 1 1 0 0 0
e5 1 0 0 0 0 0 0 0 0 1
l15 1 0 0 0 0 0 0 0 1 0",sep="",header=TRUE))


names1<-unique(c(colnames(m1),colnames(m2),colnames(m3),colnames(m4)))
Out2<-matrix(0,length(names1),length(names1),dimnames=list(names1,names1))
vec1<- paste0(colnames(m1)[col(m1)],rownames(m1)[row(m1)])
vecOut<- paste0(colnames(Out2)[col(Out2)],rownames(Out2)[row(Out2)])
Out2[match(vec1,vecOut)]<- m1
vec2<- paste0(colnames(m2)[col(m2)],rownames(m2)[row(m2)])
Out2[match(vec2,vecOut)]<- m2
vec3<- paste0(colnames(m3)[col(m3)],rownames(m3)[row(m3)])
Out2[match(vec3,vecOut)]<- m3
vec4<- paste0(colnames(m4)[col(m4)],rownames(m4)[row(m4)])
Out2[match(vec4,vecOut)]<- m4
?all.equal(Out1,Out2)
#[1] TRUE
?Out2
??? y1 g24 c1 c2 l17 h4 s2 s30 e5 l15
y1?? 0?? 1? 1? 1?? 1? 1? 1?? 1? 1?? 1
g24? 1?? 0? 0? 0?? 0? 0? 0?? 0? 0?? 0
c1?? 1?? 0? 0? 1?? 1? 0? 0?? 0? 0?? 0
c2?? 1?? 0? 1? 0?? 1? 0? 0?? 0? 0?? 0
l17? 1?? 0? 1? 1?? 0? 0? 0?? 0? 0?? 0
h4?? 1?? 0? 0? 0?? 0? 0? 1?? 1? 0?? 0
s2?? 1?? 0? 0? 0?? 0? 1? 0?? 1? 0?? 0
s30? 1?? 0? 0? 0?? 0? 1? 1?? 0? 0?? 0
e5?? 1?? 0? 0? 0?? 0? 0? 0?? 0? 0?? 1
l15? 1?? 0? 0? 0?? 0? 0? 0?? 0? 1?? 0


A.K.



I have the following binary labeled matrices with different dimensions 
(2x2, 3x3, 4x4) which I need to create in R as seen below: 

? ? ? ? y1???? g24 
y1 ??? 0??? 1 
g2 4??? 1??? 0 
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 
? ? ? ? ?y1??? c1??? c2??? l17 
?y1??? 0??? 1??? 1??? 1 
?c1??? 1??? 0??? 1??? 1 
?c2??? 1??? 1??? 0??? 1 
?l17??? 1??? 1??? 1??? 0 
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 
? ? ? ?y1??? h4 ? ?s2 ? ? s30 
?y1??? 0??? 1??? 1??? 1 
?h4??? 1??? 0??? 1??? 1 
?s29??? 1??? 1??? 0??? 1 
?s30??? 1??? 1??? 1??? 0 
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 
? ? ? ? y1 ??? e5??? l15 
?y1??? 0??? 1??? 1 
e5??? 1??? 0??? 1 
l15??? 1??? 1??? 0 

Then, I need to combine them to achieve the following result: 

? ? ? ? y1??? g24??? c1??? c2??? l17??? h4??? s29??? s30??? e5??? l15 
y1??? 0??? 1??? 1??? 1??? 1??? 1??? 1??? 1??? 1??? 1 
g24??? 1??? 0??? 0??? 0??? 0??? 0??? 0??? 0??? 0??? 0 
c1??? 1??? 0??? 0??? 1??? 1??? 0??? 0??? 0??? 0??? 0 
c2??? 1??? 0??? 1??? 0??? 1??? 0??? 0??? 0??? 0??? 0 
l17??? 1??? 0??? 1??? 1??? 0??? 0??? 0??? 0??? 0??? 0 
h4??? 1??? 0??? 0??? 0??? 0??? 0??? 1??? 1??? 0??? 0 
s29??? 1??? 0??? 0??? 0??? 0??? 1??? 0??? 1??? 0??? 0 
s30??? 1??? 0??? 0??? 0??? 0??? 1??? 1??? 0??? 0??? 0 
e5??? 1??? 0??? 0??? 0??? 0??? 0??? 0??? 0??? 0??? 1 
l15??? 1??? 0??? 0??? 0??? 0??? 0??? 0??? 0??? 1??? 0 

Your help would be very much appreciated. 

ps. if the matrices don't appear correctly, please notice that all values different from 0 and 1 are row and column names 

Thank You!


From waqas1518 at gmail.com  Fri Sep  6 19:32:29 2013
From: waqas1518 at gmail.com (Waqas Shafqat)
Date: Fri, 6 Sep 2013 22:32:29 +0500
Subject: [R] Fwd:
In-Reply-To: <CADHyn5hZ-wvP67DdmRvezsP8FW_9_GRHQ686Wnfcs2DY5wGJCg@mail.gmail.com>
References: <CADHyn5hZ-wvP67DdmRvezsP8FW_9_GRHQ686Wnfcs2DY5wGJCg@mail.gmail.com>
Message-ID: <CADHyn5gowj3NzwE02Rff9MLoq8XbEyVGJeDrYEzUFov1BfFaJA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130906/189ed0ca/attachment.pl>

From murdoch.duncan at gmail.com  Fri Sep  6 19:36:51 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 06 Sep 2013 13:36:51 -0400
Subject: [R] how to define ordinal, nominal and scale type variables?
In-Reply-To: <CABaUQnxNf8TZhFk2dwhvBvZZNFddEcvoK5Vo0LJQtDmGspo5pA@mail.gmail.com>
References: <CABaUQnxNf8TZhFk2dwhvBvZZNFddEcvoK5Vo0LJQtDmGspo5pA@mail.gmail.com>
Message-ID: <522A12B3.1010405@gmail.com>

On 06/09/2013 5:29 AM, Markus Gschwind wrote:
> Hello,
>
> I am a beginner of R but knowing SPSS and matlab.
>
> I need to analyse my data with a mixed type cluster analysis, that's why I
> am looking into R.
>
> I have a datasheet with 45 subjects (rows) and 30 variables of each subjet
> (columns) in Excel (datasheet.csv) or SPSS (datasheet.sav).
>
> In SPSS I can define if the variable is ordinal (e.g.  low - intermediate -
> high), nominal (e.g. type of hobby) or scale (e.g. age).
> The variables are all numerical (as SPSS needs them in numbers coding the
> ordinal or nominal qualities).
>
> However, when using data importing like
>
> mydata<-read.spss("datasheet.sav")
> or
> mydata<-read.table("datasheet.csv", sep=",",na="",stringsAsFactors=F)
>
> this produces a 'list' and not a 'data frame' with factors.
>
> My question: How can I import the "measure" (i.e. nominal, ordinal, scale)
> form SPSS?
> Or how can I define variables in mydata as nominal or ordinal, even if they
> consist of numbers?

Actually, the read.table() function will produce a dataframe, but you 
asked for no factors, so you'll get no factors.

To convert a variable x to a nominal factor, use

f <- factor(x, levels = c( ..... ))

where the levels are chosen to list all possible values that x could 
take.  If x is a column of a dataframe d, use

d$f <- factor(d$x, levels = c( .... ))

to create a new column named f in the dataframe.

For an ordinal factor, do the same, but use ordered() instead of factor().

(You can do some of this automatically using read.table, e.g. by 
specifying colClasses, but you have more flexibility if you do it as 
shown above.)

Duncan Murdoch


From bhh at xs4all.nl  Fri Sep  6 19:39:40 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 6 Sep 2013 19:39:40 +0200
Subject: [R] Fwd:
In-Reply-To: <CADHyn5gowj3NzwE02Rff9MLoq8XbEyVGJeDrYEzUFov1BfFaJA@mail.gmail.com>
References: <CADHyn5hZ-wvP67DdmRvezsP8FW_9_GRHQ686Wnfcs2DY5wGJCg@mail.gmail.com>
	<CADHyn5gowj3NzwE02Rff9MLoq8XbEyVGJeDrYEzUFov1BfFaJA@mail.gmail.com>
Message-ID: <2C01710C-85B2-4260-B586-ADDFB5519FAF@xs4all.nl>


On 06-09-2013, at 19:32, Waqas Shafqat <waqas1518 at gmail.com> wrote:

> ---------- Forwarded message ----------
> From: Waqas Shafqat <waqas1518 at gmail.com>
> Date: Fri, Sep 6, 2013 at 10:31 PM
> Subject:
> To: rosyara at msu.edu
> 
> 
> sorry sir
> 
> 
> i have istalled plantbreeding libraray..but when i give command
> "require(plantbreeding)" then following message appear
>> require(plantbreeding)
> Loading required package: plantbreeding
> Loading required package: qtl
> Failed with error:  ?package ?qtl? could not be loaded?
> In addition: Warning message:
> In library(pkg, character.only = TRUE, logical.return = TRUE, lib.loc =
> lib.loc) :
>  there is no package called ?qtl?
> 

Well, just install package qtl.

Berend


> further any anlysis i.e dialle or stability not  to be done
> 
> please guide me
> sorry to disturb for so many times......
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Fri Sep  6 20:40:22 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Fri, 6 Sep 2013 14:40:22 -0400
Subject: [R] melt error that I don't understand.
In-Reply-To: <B6C1631FCD1980499A5F02B4895037E801A24F9B@CCHSCLEXMB77.cc.ad.cchs.net>
References: <B6C1631FCD1980499A5F02B4895037E801A24F9B@CCHSCLEXMB77.cc.ad.cchs.net>
Message-ID: <CA+vqiLEW+OQZCpcgjReykvHgq-NomW=ee1ZP0Cv+Oqq-Tv-yjw@mail.gmail.com>

Hi Benjamin,

This looks like a bug, whereby melt fails when numeric id.vars have
attributes. Consider:

D <- structure(list(ID = c("A", "B", "C", "D", "E", "F", "G", "H", "I", "J"),
                    AGE = structure(c(68L, 63L, 55L, 64L, 60L, 78L,
60L, 62L, 60L, 75L),
                                    label = "Age", class = "labelled"),
                    BMI = structure(c(25L, 27L, 27L, 28L, 32L, NA,
36L, 27L, 31L, 25L),
                                    label = "BMI (kg/m2)", class = "labelled"),
                    EventDays = structure(c(722L, 738L, 707L, 751L,
735L, 728L, 731L, 717L, 728L, 735L),
                                          label = "Time to first
ACM/censor (days)", class = "labelled"),
                    ImplantDays = c(NA, NA, 575, NA, NA, NA, 490, 643, NA, NA)),
               .Names = c("ID", "AGE", "BMI", "EventDays", "InterventionDays"),
               row.names = c(NA, 10L),
               class = "data.frame")

melt(D, c("ID", "AGE", "BMI")) ## does not work

D <- as.data.frame(lapply(D, as.vector)) ## strip attributes
melt(D, c("ID", "AGE", "BMI")) ## works

attr(D$ID, "label") <- "ID number"  ## add attribute to factor
melt(D, c("ID", "AGE", "BMI")) ## works

attr(D$AGE, "label") <- "Age" ## add attribute to numeric variable
melt(D, c("ID", "AGE", "BMI")) ## does not work


I've reported the bug at https://github.com/hadley/reshape/issues/36

Best,
Ista

On Fri, Sep 6, 2013 at 11:59 AM, Nutter, Benjamin <NutterB at ccf.org> wrote:
> I'm stumped.  I have a dataset I want to melt to create a temporal sequence of events for each subject, but in each row, I would like to retain the baseline characteristics.
>
> D <- structure(list(ID = c("A", "B", "C", "D", "E", "F", "G", "H", "I", "J"),
>                     AGE = structure(c(68L, 63L, 55L, 64L, 60L, 78L, 60L, 62L, 60L, 75L),
>                                     label = "Age", class = "labelled"),
>                     BMI = structure(c(25L, 27L, 27L, 28L, 32L, NA, 36L, 27L, 31L, 25L),
>                                     label = "BMI (kg/m2)", class = "labelled"),
>                     EventDays = structure(c(722L, 738L, 707L, 751L, 735L, 728L, 731L, 717L, 728L, 735L),
>                                           label = "Time to first ACM/censor (days)", class = "labelled"),
>                     ImplantDays = c(NA, NA, 575, NA, NA, NA, 490, 643, NA, NA)),
>                .Names = c("ID", "AGE", "BMI", "EventDays", "InterventionDays"),
>                row.names = c(NA, 10L),
>                class = "data.frame")
>
> melt(D, c("ID", "AGE", "BMI")) # produces the following error
>
> Error in data.frame(ids, variable, value, stringsAsFactors = FALSE) :
>   arguments imply differing number of rows: 10, 20
>
>
> Now, I know AGE and BMI aren't exactly identifying variables, but my hope would be that, since ID uniquely identifies the subjects, I could use this as a short cut to getting the data set I want.  I can get the data I want if I go about it a little differently.
>
> #* What I would like it to look like.
> Timeline <- melt(D[, c("ID", "EventDays", "InterventionDays")], "ID", na.rm=TRUE)
> Timeline <- arrange(Timeline, ID, value)
> Timeline <- merge(D[, c("ID", "AGE", "BMI")],
>                   Timeline,
>                   by="ID", all.x=TRUE)
>
>
> At first I thought it might be the mixture of character and numeric variables as IDs, but the following example works
>
> A <- data.frame(id = LETTERS[1:10],
>                 age = c(50, NA, 51, 52, 53, 54, 55, 56, 57, 58),
>                 meas1 = rnorm(10),
>                 meas2 = rnorm(10, 5),
>                 stringsAsFactors=FALSE)
> melt(A, c("id", "age"))
>
>
> I'm sure I'm missing something really obvious (kind of like how I can stare at the dry goods aisle for 10 minutes and still not find the chocolate chips).  If anyone could help me understand why this error is occurring, I'd greatly appreciate it.
>
>> sessionInfo()
> R version 2.15.2 (2012-10-26)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
> [1] C
>
> attached base packages:
> [1] splines   stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] lazyWeave_2.2.3  Hmisc_3.10-1     survival_2.36-14 plyr_1.7.1       reshape2_1.2.2
>
> loaded via a namespace (and not attached):
> [1] cluster_1.14.3  grid_2.15.2     lattice_0.20-10 stringr_0.6.1   tools_2.15.2
>
>
>   Benjamin Nutter |  Biostatistician     |  Quantitative Health Sciences
>   Cleveland Clinic    |  9500 Euclid Ave.  |  Cleveland, OH 44195  | (216) 445-1365
>
>
>
> ===================================
>
>
>  Please consider the environment before printing this e-mail
>
> Cleveland Clinic is ranked as one of the top hospitals in America by U.S.News & World Report (2013).
> Visit us online at http://www.clevelandclinic.org for a complete listing of our services, staff and locations.
>
>
> Confidentiality Note:  This message is intended for use ...{{dropped:18}}
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rosbreed.pba at gmail.com  Fri Sep  6 21:36:02 2013
From: rosbreed.pba at gmail.com (John Clark)
Date: Fri, 6 Sep 2013 15:36:02 -0400
Subject: [R] Fwd:
In-Reply-To: <CADHyn5gowj3NzwE02Rff9MLoq8XbEyVGJeDrYEzUFov1BfFaJA@mail.gmail.com>
References: <CADHyn5hZ-wvP67DdmRvezsP8FW_9_GRHQ686Wnfcs2DY5wGJCg@mail.gmail.com>
	<CADHyn5gowj3NzwE02Rff9MLoq8XbEyVGJeDrYEzUFov1BfFaJA@mail.gmail.com>
Message-ID: <CA+FynjuZU+hdEDshde8S_-794udSPTq0=5obpH=FwG6BtQME9w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130906/2150ae6e/attachment.pl>

From thomas.worthington at okstate.edu  Fri Sep  6 22:17:43 2013
From: thomas.worthington at okstate.edu (Worthington, Thomas A)
Date: Fri, 6 Sep 2013 20:17:43 +0000
Subject: [R] Assessing temporal correlation in GAM with irregular time
 steps
In-Reply-To: <CAAHES9w96apsAwD+8JBvGgFJNe6=LwnYD+hszWFQVTS09CCGzw@mail.gmail.com>
References: <C1A5238848713043B7C18ED38FFEF1F8122879FD@STWMB01.ad.okstate.edu>
	<CAAHES9ye8bEN4Lb68QtK_vtpwXCSWanS25AYqrMh03dbHTS72A@mail.gmail.com>
	<C1A5238848713043B7C18ED38FFEF1F81228A27D@STWMB01.ad.okstate.edu>
	<CAAHES9w96apsAwD+8JBvGgFJNe6=LwnYD+hszWFQVTS09CCGzw@mail.gmail.com>
Message-ID: <C1A5238848713043B7C18ED38FFEF1F81228C12B@STWMB01.ad.okstate.edu>

Dear Gavin 

I got the code to work by setting the 'bar' to DOY as this was the measured time step. I stumbled across another problem, on some days I have multiple measurements which isn't allowed in corCAR1, therefore I've had to take the average of the replicates as suggested in another R help post.

Taking the average has meant adding the autocorrelation structure now doesn't improve the model, although I now appear to have heterogeneity in the residuals (as you suggested in your initial post). I will look at variance structures or moving to the GLM GAM 

Thanks again,     

Tom

-----Original Message-----
From: Gavin Simpson [mailto:ucfagls at gmail.com] 
Sent: Thursday, September 05, 2013 6:35 PM
To: Worthington, Thomas A
Cc: r-help at r-project.org
Subject: Re: [R] Assessing temporal correlation in GAM with irregular time steps

On 3 September 2013 16:10, Worthington, Thomas A <thomas.worthington at okstate.edu> wrote:
> Dear Gavin
>
> Thank you for the very detailed response. I had started to go down the route of fitting a correlation structure via gamm.
>
> I tried applying your code to my data but returned the error "Error in 
> corCAR1(~ID | SiteCode1971) : parameter in CAR(1) structure must be between 0 and 1"

Sorry, that is my fault, I keep forgetting that you need to specify the formula argument, the first argument of corCAR1() is the value of the correlation parameter if you want to specify it. So try:

corCAR1(form = ~ID | SiteCode1971)

I do this (get that error) all the time myself.
> I set the 'bar' in your code to the sample ID (basically a number between 1 and 192) but I wasn't sure if this was what you meant in relation to 'ordering of the samples'

That is not that useful as you need to give the software something about when the samples occur in time, otherwise it doesn't have the information needed to properly model the decay in correlation with time.

You need to give it the observation time, however you measured it.

HTH

G

> Best wishes
> Tom
>
> -----Original Message-----
> From: Gavin Simpson [mailto:ucfagls at gmail.com]
> Sent: Tuesday, September 03, 2013 3:17 PM
> To: Worthington, Thomas A
> Cc: r-help at r-project.org
> Subject: Re: [R] Assessing temporal correlation in GAM with irregular 
> time steps
>
> It is possible, but you can't use the discrete time or classical stochastic trend models (or evaluate using the ACF). Also, why do you care to do this with regard to DoY? The assumption of the model relates to the residuals, so you should check those for residual autocorrelation.
>
> As you are using `mgcv::gam` you could also use `mgcv::gamm` which can then leverage the correlation structures from the nlme package, which has spatial correlation structures (and you can think of time as a 1-d spatial direction). The package also has a `corCAR1()` correlation structure which is the continuous-time analogue of the AR(1). Fitting via `gamm()` will also allow you to use the `Variogram()` function from the nlme package to assess the model residuals for residual autocorrelation.
>
> For example you could compare the two fits
>
> m0 <- gamm(Length ~ s(DOY, by = SiteCode) + SiteCode, data = foo, 
> method = "REML")
> m1 <- gamm(Length ~ s(DOY, by = SiteCode) + SiteCode, data = foo, method = "REML",
>                     correlation = corCAR1( ~ bar | SiteCode))
>
> where `foo` is the object that contains the variables mentioned in the call, and `bar` is the variable (in `foo)` that indicates the ordering of the samples. Notice that I nest the CAR(1) within the two respective Sites, but do note IIRC that this fits the same residual correlation structure to both sites' residuals (i.e. there is 1 CAR(1) process, not two separate ones).
>
> require(nlme)
> anova(m0$lme, m1$lme)
>
> will perform a likelihood ratio test on the two models.
>
> If you have residual autocorrelation, do note that the smooth for DoY may be chosen to be more complex than is appropriate (it might be fitting the autocorrleated noise), so you may want to fix the degrees of freedom for the smoother at some a priori chosen value and use this same value when fitting both m0 and m1, or at the very least set an upper limit on the complexity of the DoY smooth, say via s(DoY, by = SiteCode, k = 5).
>
> Finally, as a length <= 0 insect makes no sense, the assumption of Gaussian (Normal) errors may be in trouble with your data; apart from their strictly positive nature, the mean-variance relationship of the data may not follow that of the assumptions for the errors. You can move to a GLM (GAM) to account for this but things get very tricky with the correlation structures (you can use gamm() still but fitting then goes via glmmPQL() in the MASS package a thence to lme()).
>
> If you just want to fit a variogram to something, there are a large number of spatial packages available for R, several of which can fit variograms to data, though you will need to study their respective help files for how to use them. As for the input data, often the time/date of sampling encoded as a numeric will be sufficient input, but you will need to check individual functions for what they require.
> I would check out the Spatial Task View on CRAN.
>
> HTH
>
> G
>
> On 28 August 2013 14:26, Worthington, Thomas A <thomas.worthington at okstate.edu> wrote:
>> I have constructed a GAM using the package mgcv to test whether the 
>> lengths of an emerging insect (Length) varies with day of the year
>> (DOY) and between two sites (SiteCode). The data are collected at 
>> irregular time steps ranging from 2 days to 20 days between samples.
>> The GAM takes the form
>>
>> M3 <- gam(Length ~s(DOY, by = SiteCode) + SiteCode)
>>
>> As the data are a time series I would like to test for temporal autocorrelation. I have read that it is not possible to use the autocorrelation function (ACF) due to the irregular spacing and that producing a variogram in relation to DOY would be an option.
>>
>> Is this a correct method to test for temporal autocorrelation?
>>
>> And could someone suggest the code to produce the variogram as I'm 
>> getting an error related to the 'distance' argument
>>
>> Best wishes
>> Tom
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Gavin Simpson, PhD



--
Gavin Simpson, PhD

From elaine.kuo.tw at gmail.com  Sat Sep  7 00:25:12 2013
From: elaine.kuo.tw at gmail.com (Elaine Kuo)
Date: Sat, 7 Sep 2013 06:25:12 +0800
Subject: [R] Fwd: calculating dissimilarity index of islands (vegan and
	betapart)
In-Reply-To: <CAGJhoDzJJzRY7P2-2YwGPo-54evH-pdaBnFm0kHLH1MJ5tYjnw@mail.gmail.com>
References: <CAGJhoDzJJzRY7P2-2YwGPo-54evH-pdaBnFm0kHLH1MJ5tYjnw@mail.gmail.com>
Message-ID: <CAGJhoDyS9qH0RpijWNC0dd9LzozFjcLCKAtbSk+SVEM8Fgov7g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130907/7ae2b3c7/attachment.pl>

From gunter.berton at gene.com  Sat Sep  7 00:51:00 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 6 Sep 2013 15:51:00 -0700
Subject: [R] Fwd: calculating dissimilarity index of islands (vegan and
	betapart)
In-Reply-To: <CAGJhoDyS9qH0RpijWNC0dd9LzozFjcLCKAtbSk+SVEM8Fgov7g@mail.gmail.com>
References: <CAGJhoDzJJzRY7P2-2YwGPo-54evH-pdaBnFm0kHLH1MJ5tYjnw@mail.gmail.com>
	<CAGJhoDyS9qH0RpijWNC0dd9LzozFjcLCKAtbSk+SVEM8Fgov7g@mail.gmail.com>
Message-ID: <CACk-te2SRhfnJWmwmLKaNOpufEUY_SHwvnVhSDfXsZ7JXTBqiA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130906/868d3280/attachment.pl>

From HTRobertson at seton.org  Fri Sep  6 23:14:42 2013
From: HTRobertson at seton.org (Robertson, Henry T.)
Date: Fri, 6 Sep 2013 21:14:42 +0000
Subject: [R] How do I parse text?
Message-ID: <6BDD257BAF1CDB4998CE0CE577B3C34C01146C@TX1P03DAG0107.apptixhealth.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130906/500dccbc/attachment.pl>

From Nasrin.Mostafavipak at stantec.com  Fri Sep  6 21:42:02 2013
From: Nasrin.Mostafavipak at stantec.com (Mostafavipak, Nasrin)
Date: Fri, 6 Sep 2013 13:42:02 -0600
Subject: [R] Alignment of data sets
Message-ID: <7FA4CD320A8C134A85CD4F78AAE082720373FD381D@CD1001-M360.corp.ads>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130906/b32e4c4b/attachment.pl>

From HTRobertson at seton.org  Fri Sep  6 23:18:02 2013
From: HTRobertson at seton.org (Robertson, Henry T.)
Date: Fri, 6 Sep 2013 21:18:02 +0000
Subject: [R] How do I parse text?
Message-ID: <6BDD257BAF1CDB4998CE0CE577B3C34C01148C@TX1P03DAG0107.apptixhealth.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130906/09714971/attachment.pl>

From panagiotis.isigonis at gmail.com  Fri Sep  6 23:59:48 2013
From: panagiotis.isigonis at gmail.com (Panagiotis Isigonis)
Date: Fri, 06 Sep 2013 23:59:48 +0200
Subject: [R] Java exception error (Jcheck) while running an R script
Message-ID: <522A5054.2080105@gmail.com>

Dear all,

I am facing a problem with running a script that i have written in R and i hope
you can help me spot which exactly is the problem and how i can solve it.

The error I get is the following:
----
Error in .jcheck(silent = FALSE) :
   Java Exception <no description because toString() failed>.jcall(row[[ir]],

"Lorg/apache/poi/ss/usermodel/Cell;", "createCell", as.integer(colIndex[ic] -
1))<S4 object of

class "jobjRef">
----

As I am not a programmer, i don't really understand the error message. I did a
search to try to understand what is wrong and if i am correct the problem is
related with the 'rjava' package. I am not using directly this package but i am
using the 'xlsx' package that is calling the 'rjava' one.

I have made a search on the available resources online for tips/solutions.
I found some similar errors on these reports:
http://r.789695.n4.nabble.com/Java-Exception-error-while-reading-large-data-in-R-from-DB-using-RJDBC-td4647844.html
but it is not really similar with my problem, as i don't read any data online.
On
http://stackoverflow.com/questions/12476044/r-how-to-clear-memory-used-by-rjava
the problem seems similar but there is no reply.

Since it mentions a memory problem, based on this post
http://www.bramschoenmakers.nl/en/node/726 i tried to change the available java
memory by using
> options(java.parameters = "-Xmx4g" )
It didn't work out. (Possibly is not related, but i had to try something).

I would like to point out that i am loading to the script an excel file (through
xlsx), making some calculations with the use of 'data.table' and 'sqldf'
packages and then writing the results to a new excel file. We have tested the
script with a file of 3120 lines and it works without any problem but when i try
to run the script and load the excel file of interest that has 47000 lines, i
get the error that i reported above.

I would be more than grateful if anyone can help me on this.
I am running R on Windows 7, with R version 3.0.1 and Java 7 update 10, all 64-bit.

Thank you very much in advance,
Panos

-- 
Panagiotis Isigonis

PhD student
Department of Environmental Sciences, Informatics and Statistics
Ca Foscari University Venice
email: isigonis at unive.it
tel: (+39) 041 509 3190


From tyler_rinker at hotmail.com  Sat Sep  7 02:27:29 2013
From: tyler_rinker at hotmail.com (Tyler Rinker)
Date: Fri, 6 Sep 2013 20:27:29 -0400
Subject: [R] How do I parse text?
In-Reply-To: <6BDD257BAF1CDB4998CE0CE577B3C34C01146C@TX1P03DAG0107.apptixhealth.net>
References: <6BDD257BAF1CDB4998CE0CE577B3C34C01146C@TX1P03DAG0107.apptixhealth.net>
Message-ID: <BLU170-W35BF5F5312C0A72DEB5168EF3D0@phx.gbl>

Henry,

Have look at the qdap package's termco, wfm, adjacency_matrix, and (possibly) word_associate functions. ?I'm not sure if they'll work as you really don't give much in the way of what the data is and the desired output (an example of the output).

Cheers,
Tyler Rinker

?----------------------------------------
> From: HTRobertson at seton.org
> To: r-help at r-project.org
> Date: Fri, 6 Sep 2013 21:14:42 +0000
> Subject: [R] How do I parse text?
>
> I have a data frame with a character field of the form "ACUTE URI NOS", "OPEN WOUND OF FOREHEAD", "CROUP", "STREP SORE THROAT", ....
>
> How can I get counts of all the words and their co-occurences? I've spent a long time searching on google, but it just takes me on a wild goose chase of dozens of modules involving advanced natural language processing theory. All I want is word counts and co-occurences.
>
> Thanks
>
>
>
>
> CONFIDENTIALITY NOTICE:\ This email message and any acco...{{dropped:13}}
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code. 		 	   		  

From smartpink111 at yahoo.com  Sat Sep  7 04:08:19 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 6 Sep 2013 19:08:19 -0700 (PDT)
Subject: [R] Alignment of data sets
In-Reply-To: <7FA4CD320A8C134A85CD4F78AAE082720373FD381D@CD1001-M360.corp.ads>
References: <7FA4CD320A8C134A85CD4F78AAE082720373FD381D@CD1001-M360.corp.ads>
Message-ID: <1378519699.10183.YahooMailNeo@web142604.mail.bf1.yahoo.com>

HI,

The question is not clear.

Lines1<- readLines(textConnection("Year, Day, Hour, Value
2010,? 001,??? 0,??? 15.9
2010,? 001,??? 1,??? 7.3
2010,? 001,??? 2,??? 5.2
2010,? 001,??? 3,??? 8.0
2010,? 001,??? 4,??? 0.0
2010,? 001,??? 5,??? 12.1
2010,? 001,??? 6,??? 11.6
2010,? 001,??? 7,??? 13.9
2010,? 001,??? 8,??? 11.9
2010,? 001,??? 9,??? 13.6
2010,? 001,??? 10,??? 16.1
2010,? 001,??? 11,??? 18.5"))

library(stringr)
#Looking at the spaces between each comma.

str_count(gsub("(\\d+,\\s+\\d+).*","\\1",Lines1[-1])," ")
# [1] 2 2 2 2 2 2 2 2 2 2 2 2
str_count(gsub("^\\d+,\\s+(\\d+,\\s+\\d+).*","\\1",Lines1[-1])," ")
# [1] 4 4 4 4 4 4 4 4 4 4 4 4
str_count(gsub("\\d+,\\s+\\d+,\\s+(\\d+,\\s+\\d+)","\\1",Lines1[-1])," ")
# [1] 4 4 4 4 4 4 4 4 4 4 4 4


Lines2<- gsub(",",",?? ",gsub(" ","",Lines1))[-1]
?str_count(Lines2," ")
# [1] 9 9 9 9 9 9 9 9 9 9 9 9
?str_count(gsub("(\\d+,\\s+\\d+).*","\\1",Lines2)," ")
# [1] 3 3 3 3 3 3 3 3 3 3 3 3
str_count(gsub("^\\d+,\\s+(\\d+,\\s+\\d+).*","\\1",Lines2)," ")
# [1] 3 3 3 3 3 3 3 3 3 3 3 3
str_count(gsub("\\d+,\\s+\\d+,\\s+(\\d+,\\s+\\d+)","\\1",Lines2)," ")
# [1] 3 3 3 3 3 3 3 3 3 3 3 3



write(Lines2,"capture2.txt")

A.K.





----- Original Message -----
From: "Mostafavipak, Nasrin" <Nasrin.Mostafavipak at stantec.com>
To: "r-help at R-project.org" <r-help at r-project.org>
Cc: 
Sent: Friday, September 6, 2013 3:42 PM
Subject: [R] Alignment of data sets

Hi all;

I have a data set with the format below:


Year, Day, Hour, Value

2010,? 001,? ? 0,? ? 15.9
2010,? 001,? ? 1,? ? 7.3
2010,? 001,? ? 2,? ? 5.2
2010,? 001,? ? 3,? ? 8.0
2010,? 001,? ? 4,? ? 0.0
2010,? 001,? ? 5,? ? 12.1
2010,? 001,? ? 6,? ? 11.6
2010,? 001,? ? 7,? ? 13.9
2010,? 001,? ? 8,? ? 11.9
2010,? 001,? ? 9,? ? 13.6
2010,? 001,? ? 10,? ? 16.1
2010,? 001,? ? 11,? ? 18.5

That should be converted to this format:

2010,? 001,? ? 0,? ? 15.9
2010,? 001,? ? 1,? ? ? 7.3
2010,? 001,? ? 2,? ? ? 5.2
2010,? 001,? ? 3,? ? ? 8.0
2010,? 001,? ? 4,? ? ? 0.0
2010,? 001,? ? 5,? ? 12.1
2010,? 001,? ? 6,? ? 11.6
2010,? 001,? ? 7,? ? 13.9
2010,? 001,? ? 8,? ? 11.9
2010,? 001,? ? 9,? ? 13.6
2010,? 001,? 10,? ? 16.1
2010,? 001,? 11,? ? 18.5
The number of spaces is important. I have tried justify, but it produces spaces at the end or at the beginning of the rows depending on the choice of right, left alignment. Also I need 3 significant digits for the second column, when I use read.csv it gives me 1 instead of 001. So I use read.table, and one of the problems with read.table is that it produces row names that I don't want. Also I need commas in my output file.


So far this is the best I could do:

mydata = read.table("C:/ozone3.txt", sep = "")


capture.output( print(mydata, sep = ",", print.gap=3), file="capture2.txt" )

and the output has all the unwanted row names and also there are no commas.


Any suggestions?

Thank you
Nasrin

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From robert.b.lynch at gmail.com  Sat Sep  7 09:02:47 2013
From: robert.b.lynch at gmail.com (Robert Lynch)
Date: Sat, 7 Sep 2013 00:02:47 -0700
Subject: [R] finding both rows that are duplicated in a data frame
Message-ID: <CACYeG1j-T1PQwrwtctNK5FNTkh2Z1Hzdbn1tvzQOswcOFRpJ4Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130907/eec5f015/attachment.pl>

From ankurseth82 at gmail.com  Sat Sep  7 07:06:45 2013
From: ankurseth82 at gmail.com (Ankur Seth)
Date: Sat, 7 Sep 2013 10:36:45 +0530
Subject: [R] Simple Model in R
Message-ID: <CAK6WB8v1kDH4aP47ENWwVBY7toC1477472ZzHvjTmZRtKvp2mQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130907/2b158b09/attachment.pl>

From ruipbarradas at sapo.pt  Sat Sep  7 10:41:08 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 7 Sep 2013 09:41:08 +0100
Subject: [R] Simple Model in R
In-Reply-To: <CAK6WB8v1kDH4aP47ENWwVBY7toC1477472ZzHvjTmZRtKvp2mQ@mail.gmail.com>
References: <CAK6WB8v1kDH4aP47ENWwVBY7toC1477472ZzHvjTmZRtKvp2mQ@mail.gmail.com>
Message-ID: <522AE6A4.9090500@sapo.pt>

Hello,

Try the following.

dat <- read.table(text = "
Date                                Value
08/01/2013                        100
08/02/2013                         100.5
08/03/2013                         102
", header = TRUE)


dat$New <- c(NA, diff(dat$Value))
dat


Hope this helps,

Rui Barradas

Em 07-09-2013 06:06, Ankur Seth escreveu:
> Hello All,
>
> I am trying to build a model in R. I am facing the following problem...
>
> My Data Frame contains the following data...
>
> Date                                Value
> 08/01/2013                        100
> 08/02/2013                         100.5
> 08/03/2013                         102
> ....
>
> Now I want to add a column to this data frame where New Column Value =
> Difference of two subsequent observations. For Eg. on 08/02/2013 the new
> value = 100.5 - 100=0.5
>
> I want to do this dynamically such that if I change the value in Value
> column the new column should recalculate automatically.
>
> Is there a way to do this in R?
>
> Regards,
> Ankur Seth
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ankurseth82 at gmail.com  Sat Sep  7 12:52:41 2013
From: ankurseth82 at gmail.com (Ankur Seth)
Date: Sat, 7 Sep 2013 16:22:41 +0530
Subject: [R] Simple Model in R
In-Reply-To: <522AE6A4.9090500@sapo.pt>
References: <CAK6WB8v1kDH4aP47ENWwVBY7toC1477472ZzHvjTmZRtKvp2mQ@mail.gmail.com>
	<522AE6A4.9090500@sapo.pt>
Message-ID: <CAK6WB8s4HNPGBpaU+fXBrD0D3g3B7xhuBMW7VSAsNRHJjxZHUA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130907/0e1769b4/attachment.pl>

From ruipbarradas at sapo.pt  Sat Sep  7 13:19:09 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 7 Sep 2013 12:19:09 +0100
Subject: [R] Simple Model in R
In-Reply-To: <CAK6WB8s4HNPGBpaU+fXBrD0D3g3B7xhuBMW7VSAsNRHJjxZHUA@mail.gmail.com>
References: <CAK6WB8v1kDH4aP47ENWwVBY7toC1477472ZzHvjTmZRtKvp2mQ@mail.gmail.com>
	<522AE6A4.9090500@sapo.pt>
	<CAK6WB8s4HNPGBpaU+fXBrD0D3g3B7xhuBMW7VSAsNRHJjxZHUA@mail.gmail.com>
Message-ID: <522B0BAD.3080404@sapo.pt>

Hello,

It will not change the value automatically, you will have to rerun the code.

Rui Barradas

Em 07-09-2013 11:52, Ankur Seth escreveu:
> Thanks Rui, but this does not change the value in the new column
> automatically if I change the value in the data column. Any ideas?
>
> Regards,
> Ankur Seth
>
>
> On Sat, Sep 7, 2013 at 2:11 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
>> Hello,
>>
>> Try the following.
>>
>> dat <- read.table(text = "
>>
>> Date                                Value
>> 08/01/2013                        100
>> 08/02/2013                         100.5
>> 08/03/2013                         102
>> ", header = TRUE)
>>
>>
>> dat$New <- c(NA, diff(dat$Value))
>> dat
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> Em 07-09-2013 06:06, Ankur Seth escreveu:
>>
>>> Hello All,
>>>
>>> I am trying to build a model in R. I am facing the following problem...
>>>
>>> My Data Frame contains the following data...
>>>
>>> Date                                Value
>>> 08/01/2013                        100
>>> 08/02/2013                         100.5
>>> 08/03/2013                         102
>>> ....
>>>
>>> Now I want to add a column to this data frame where New Column Value =
>>> Difference of two subsequent observations. For Eg. on 08/02/2013 the new
>>> value = 100.5 - 100=0.5
>>>
>>> I want to do this dynamically such that if I change the value in Value
>>> column the new column should recalculate automatically.
>>>
>>> Is there a way to do this in R?
>>>
>>> Regards,
>>> Ankur Seth
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________**________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>>> PLEASE do read the posting guide http://www.R-project.org/**
>>> posting-guide.html <http://www.R-project.org/posting-guide.html>
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>
>


From ankurseth82 at gmail.com  Sat Sep  7 13:19:58 2013
From: ankurseth82 at gmail.com (Ankur Seth)
Date: Sat, 7 Sep 2013 16:49:58 +0530
Subject: [R] Simple Model in R
In-Reply-To: <522B0BAD.3080404@sapo.pt>
References: <CAK6WB8v1kDH4aP47ENWwVBY7toC1477472ZzHvjTmZRtKvp2mQ@mail.gmail.com>
	<522AE6A4.9090500@sapo.pt>
	<CAK6WB8s4HNPGBpaU+fXBrD0D3g3B7xhuBMW7VSAsNRHJjxZHUA@mail.gmail.com>
	<522B0BAD.3080404@sapo.pt>
Message-ID: <CAK6WB8t5Vc7rDrRU5UAhwZ7CBQoJDMKxynxP__aoFop-FHkVHQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130907/ae6ba407/attachment.pl>

From ruipbarradas at sapo.pt  Sat Sep  7 13:21:41 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 7 Sep 2013 12:21:41 +0100
Subject: [R] Simple Model in R
In-Reply-To: <CAK6WB8t5Vc7rDrRU5UAhwZ7CBQoJDMKxynxP__aoFop-FHkVHQ@mail.gmail.com>
References: <CAK6WB8v1kDH4aP47ENWwVBY7toC1477472ZzHvjTmZRtKvp2mQ@mail.gmail.com>
	<522AE6A4.9090500@sapo.pt>
	<CAK6WB8s4HNPGBpaU+fXBrD0D3g3B7xhuBMW7VSAsNRHJjxZHUA@mail.gmail.com>
	<522B0BAD.3080404@sapo.pt>
	<CAK6WB8t5Vc7rDrRU5UAhwZ7CBQoJDMKxynxP__aoFop-FHkVHQ@mail.gmail.com>
Message-ID: <522B0C45.7050003@sapo.pt>

Hello,

No, I don't believe so. If you change one column and want another column 
to change you have to tell R to do it.

Rui Barradas

Em 07-09-2013 12:19, Ankur Seth escreveu:
> Is there a way in which I can setup a model like that?
>
> Regards,
> Ankur Seth
>
>
> On Sat, Sep 7, 2013 at 4:49 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
>> Hello,
>>
>> It will not change the value automatically, you will have to rerun the
>> code.
>>
>> Rui Barradas
>>
>> Em 07-09-2013 11:52, Ankur Seth escreveu:
>>
>>> Thanks Rui, but this does not change the value in the new column
>>> automatically if I change the value in the data column. Any ideas?
>>>
>>> Regards,
>>> Ankur Seth
>>>
>>>
>>> On Sat, Sep 7, 2013 at 2:11 PM, Rui Barradas <ruipbarradas at sapo.pt>
>>> wrote:
>>>
>>>   Hello,
>>>>
>>>> Try the following.
>>>>
>>>> dat <- read.table(text = "
>>>>
>>>> Date                                Value
>>>> 08/01/2013                        100
>>>> 08/02/2013                         100.5
>>>> 08/03/2013                         102
>>>> ", header = TRUE)
>>>>
>>>>
>>>> dat$New <- c(NA, diff(dat$Value))
>>>> dat
>>>>
>>>>
>>>> Hope this helps,
>>>>
>>>> Rui Barradas
>>>>
>>>> Em 07-09-2013 06:06, Ankur Seth escreveu:
>>>>
>>>>   Hello All,
>>>>>
>>>>> I am trying to build a model in R. I am facing the following problem...
>>>>>
>>>>> My Data Frame contains the following data...
>>>>>
>>>>> Date                                Value
>>>>> 08/01/2013                        100
>>>>> 08/02/2013                         100.5
>>>>> 08/03/2013                         102
>>>>> ....
>>>>>
>>>>> Now I want to add a column to this data frame where New Column Value =
>>>>> Difference of two subsequent observations. For Eg. on 08/02/2013 the new
>>>>> value = 100.5 - 100=0.5
>>>>>
>>>>> I want to do this dynamically such that if I change the value in Value
>>>>> column the new column should recalculate automatically.
>>>>>
>>>>> Is there a way to do this in R?
>>>>>
>>>>> Regards,
>>>>> Ankur Seth
>>>>>
>>>>>           [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________****________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/****listinfo/r-help<https://stat.ethz.ch/mailman/**listinfo/r-help>
>>>>> <https://stat.**ethz.ch/mailman/listinfo/r-**help<https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>>
>>>>> PLEASE do read the posting guide http://www.R-project.org/**
>>>>> posting-guide.html <http://www.R-project.org/**posting-guide.html<http://www.R-project.org/posting-guide.html>
>>>>>>
>>>>>
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>
>>>>>
>>>
>>>
>
>


From ruipbarradas at sapo.pt  Sat Sep  7 13:27:16 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 7 Sep 2013 12:27:16 +0100
Subject: [R] Simple Model in R
In-Reply-To: <CAK6WB8t5Vc7rDrRU5UAhwZ7CBQoJDMKxynxP__aoFop-FHkVHQ@mail.gmail.com>
References: <CAK6WB8v1kDH4aP47ENWwVBY7toC1477472ZzHvjTmZRtKvp2mQ@mail.gmail.com>
	<522AE6A4.9090500@sapo.pt>
	<CAK6WB8s4HNPGBpaU+fXBrD0D3g3B7xhuBMW7VSAsNRHJjxZHUA@mail.gmail.com>
	<522B0BAD.3080404@sapo.pt>
	<CAK6WB8t5Vc7rDrRU5UAhwZ7CBQoJDMKxynxP__aoFop-FHkVHQ@mail.gmail.com>
Message-ID: <522B0D94.9030002@sapo.pt>

Hello,

What you can do is to write a function to do the change. When you want 
to change a value in column Value, it will update the value in column 
New. Something like this:


fun <- function(data, row, newval){
	data$Value[row] <- newval
	data$New <- c(NA, diff(data$Value))
	data
}

fun(dat, 2, 101.5)


Hope this helps,

Rui Barradas

Em 07-09-2013 12:19, Ankur Seth escreveu:
> Is there a way in which I can setup a model like that?
>
> Regards,
> Ankur Seth
>
>
> On Sat, Sep 7, 2013 at 4:49 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
>> Hello,
>>
>> It will not change the value automatically, you will have to rerun the
>> code.
>>
>> Rui Barradas
>>
>> Em 07-09-2013 11:52, Ankur Seth escreveu:
>>
>>> Thanks Rui, but this does not change the value in the new column
>>> automatically if I change the value in the data column. Any ideas?
>>>
>>> Regards,
>>> Ankur Seth
>>>
>>>
>>> On Sat, Sep 7, 2013 at 2:11 PM, Rui Barradas <ruipbarradas at sapo.pt>
>>> wrote:
>>>
>>>   Hello,
>>>>
>>>> Try the following.
>>>>
>>>> dat <- read.table(text = "
>>>>
>>>> Date                                Value
>>>> 08/01/2013                        100
>>>> 08/02/2013                         100.5
>>>> 08/03/2013                         102
>>>> ", header = TRUE)
>>>>
>>>>
>>>> dat$New <- c(NA, diff(dat$Value))
>>>> dat
>>>>
>>>>
>>>> Hope this helps,
>>>>
>>>> Rui Barradas
>>>>
>>>> Em 07-09-2013 06:06, Ankur Seth escreveu:
>>>>
>>>>   Hello All,
>>>>>
>>>>> I am trying to build a model in R. I am facing the following problem...
>>>>>
>>>>> My Data Frame contains the following data...
>>>>>
>>>>> Date                                Value
>>>>> 08/01/2013                        100
>>>>> 08/02/2013                         100.5
>>>>> 08/03/2013                         102
>>>>> ....
>>>>>
>>>>> Now I want to add a column to this data frame where New Column Value =
>>>>> Difference of two subsequent observations. For Eg. on 08/02/2013 the new
>>>>> value = 100.5 - 100=0.5
>>>>>
>>>>> I want to do this dynamically such that if I change the value in Value
>>>>> column the new column should recalculate automatically.
>>>>>
>>>>> Is there a way to do this in R?
>>>>>
>>>>> Regards,
>>>>> Ankur Seth
>>>>>
>>>>>           [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________****________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/****listinfo/r-help<https://stat.ethz.ch/mailman/**listinfo/r-help>
>>>>> <https://stat.**ethz.ch/mailman/listinfo/r-**help<https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>>
>>>>> PLEASE do read the posting guide http://www.R-project.org/**
>>>>> posting-guide.html <http://www.R-project.org/**posting-guide.html<http://www.R-project.org/posting-guide.html>
>>>>>>
>>>>>
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>
>>>>>
>>>
>>>
>
>


From istazahn at gmail.com  Sat Sep  7 15:58:38 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Sat, 7 Sep 2013 09:58:38 -0400
Subject: [R] error with RNetLogo on a mac
In-Reply-To: <CAF4X4oMGqt0YFvvF6vSwYjPzQ-7qznMCKraXb4xuehXVvSRWQw@mail.gmail.com>
References: <CAF4X4oMGqt0YFvvF6vSwYjPzQ-7qznMCKraXb4xuehXVvSRWQw@mail.gmail.com>
Message-ID: <CA+vqiLHqvtXDWckhdoU12yct0QYcX7FxEPWUvm8-8i5GzoJ0dw@mail.gmail.com>

There are a number of discussions on the interwebs about this problem,
try googleing the error. Starting points might be

http://stackoverflow.com/questions/11374211/jpype-cant-start-the-awt-because-java-was-started-on-the-first-thread

http://lists.apple.com/archives/java-dev/2005/Mar/msg00506.html

http://r.789695.n4.nabble.com/Troubles-with-stemming-tm-Snowball-packages-under-MacOS-td4292605.html

http://forums.instantiations.com/topic-11-1822.html

HTH,
Ista

On Fri, Sep 6, 2013 at 7:12 AM, Ricardo Pietrobon <pietr007 at gmail.com> wrote:
> gist with code and respective errors: http://goo.gl/r6VrHl
>
> would appreciate any input on how to get around the java vm problem.
> btw, the very idea of connecting R and netlogo is superb
>
> copying Jan in case he might have some input
>
> many thanks
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Sat Sep  7 16:20:15 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 7 Sep 2013 07:20:15 -0700
Subject: [R] Simple Model in R
In-Reply-To: <522B0D94.9030002@sapo.pt>
References: <CAK6WB8v1kDH4aP47ENWwVBY7toC1477472ZzHvjTmZRtKvp2mQ@mail.gmail.com>
	<522AE6A4.9090500@sapo.pt>
	<CAK6WB8s4HNPGBpaU+fXBrD0D3g3B7xhuBMW7VSAsNRHJjxZHUA@mail.gmail.com>
	<522B0BAD.3080404@sapo.pt>
	<CAK6WB8t5Vc7rDrRU5UAhwZ7CBQoJDMKxynxP__aoFop-FHkVHQ@mail.gmail.com>
	<522B0D94.9030002@sapo.pt>
Message-ID: <CACk-te1jyUMwt7NaZ10ZBCYbeb-u-Ke1xRh8hfVcShhzu9cOvA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130907/640407c3/attachment.pl>

From smartpink111 at yahoo.com  Sat Sep  7 16:52:00 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 7 Sep 2013 07:52:00 -0700 (PDT)
Subject: [R] finding both rows that are duplicated in a data frame
In-Reply-To: <CACYeG1j-T1PQwrwtctNK5FNTkh2Z1Hzdbn1tvzQOswcOFRpJ4Q@mail.gmail.com>
References: <CACYeG1j-T1PQwrwtctNK5FNTkh2Z1Hzdbn1tvzQOswcOFRpJ4Q@mail.gmail.com>
Message-ID: <1378565520.73807.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
example<- data.frame(id1,id2,GENDER,ETH,stringsAsFactors=FALSE)

res<-unique(example[!(grepl("UNK",example$GENDER)|grepl("UNK",example$ETH)),]) 
?res
#?? id1 id2 GENDER? ETH
#1??? 1? 22??? G-M E-VT
#3??? 2? 34??? G-M E-AF
#5??? 3? 15??? G-M E-AF
#7??? 4? 76??? G-F E-VT
#8??? 5? 45??? G-F E-VT
#12?? 7? 37??? G-F E-AF
#13?? 8? 52??? G-F E-AF
#14?? 9? 66??? G-F E-AF
#16? 10? 91??? G-F E-VT


It is a bit unclear about the condition for id1 #6.? If I include both of them, the nrows will be 11, now it is 9.

10?? 6? 84? G-UNK? E-AF
11?? 6? 84??? G-F E-UNK


A.K.



----- Original Message -----
From: Robert Lynch <robert.b.lynch at gmail.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Saturday, September 7, 2013 3:02 AM
Subject: [R] finding both rows that are duplicated in a data frame

I have a data frame that looks like

id1<-c(1,1,2,2,3,3,4,5,5,6,6,7,8,9,9,10)
id2<-c(22,22,34,34,15,15,76,45,45,84,84,37,52,66,66,91)
GENDER<-sample(c("G-UNK","G-M","G-F"),16, replace = TRUE)
ETH <-sample(c("E-AF","E-UNK","E-VT"),16, replace = TRUE)
example<-cbind(id1,id2,GENDER,ETH)

where there are two id's and some duplicate entries for ID's that have
different GENDER or ETH(nicity)
I would like to get a data frame that doesn't have the duplicates, but the
ones that are kept are which ever GENDER is not G-UNK (unknown) and the
kept ETH is what ever is not E-UNK

the resultant data frame should have 10 rows with no *-UNK in either of the
last two columns ( unless both entries were UNK)

yes the example data may have some impossible results but it does capture
important aspects.
1) G-UNK is alphabetically last of G-F, G-M & G-UNK
2) E-UNK is in the middle alphabetically
3) some times the first entry is the unknown gender, some times it is the
second *likely to happen with random sample
4) some times both entries for one variable, GENDER or ETH are unknown.
5) only appears to be two of each row, * not 100% sure

Thanks!
Robert

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From hannah.hlx at gmail.com  Sat Sep  7 17:44:54 2013
From: hannah.hlx at gmail.com (li li)
Date: Sat, 7 Sep 2013 11:44:54 -0400
Subject: [R] Change color of the boxplot outliers
Message-ID: <CAHLnndYpVpr9dc4HLaFu8bsTA5X56ba4Zjfg+4A=rdBMwOoOKg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130907/856f5625/attachment.pl>

From smartpink111 at yahoo.com  Sat Sep  7 17:54:54 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 7 Sep 2013 08:54:54 -0700 (PDT)
Subject: [R] Extract components of gam object
Message-ID: <1378569294.36228.YahooMailNeo@web142606.mail.bf1.yahoo.com>



Hi,

summary(pres.gam)

Family: gaussian 
Link function: identity 

Formula:
prestige ~ s(income) + s(education)

Parametric coefficients:
??????????? Estimate Std. Error t value Pr(>|t|)??? 
(Intercept)? 47.3276???? 0.6914?? 68.45?? <2e-16 ***
---
Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Approximate significance of smooth terms:
?????????????? edf Ref.df???? F? p-value??? 
s(income)??? 3.079? 3.813 12.18 8.03e-08 ***
s(education) 3.005? 3.746 42.68? < 2e-16 ***
---
Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

R-sq.(adj) =?? 0.84?? Deviance explained =?? 85%
GCV score = 50.493? Scale est. = 46.843??? n = 98




Assuming that you want to extract `3.079`.
summary(pres.gam)$edf[1]
#[1] 3.07938
A.K.





I want to extract the components of a gam object. Sample code and data follows: 

library(MASS) 
library(mgcv)#package for GAM 
library(car)#to get the data 

data(Prestige) 
Prestige2<-na.omit(Prestige) 
pres.gam<-gam(prestige~s(income)+s(education),data =Prestige2) 

As an example I wish to extract the edf for income. In addition I
 want to learn how to systematically understand the components of 
structure pres.gam. I have tried str(pres.gam) which produce large 
output which is difficult to understand. Please explain using the edf 
component. 
Thank you


From marc_schwartz at me.com  Sat Sep  7 17:57:03 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Sat, 07 Sep 2013 10:57:03 -0500
Subject: [R] Change color of the boxplot outliers
In-Reply-To: <CAHLnndYpVpr9dc4HLaFu8bsTA5X56ba4Zjfg+4A=rdBMwOoOKg@mail.gmail.com>
References: <CAHLnndYpVpr9dc4HLaFu8bsTA5X56ba4Zjfg+4A=rdBMwOoOKg@mail.gmail.com>
Message-ID: <750D8736-12BC-4C59-9AAE-8E9AF3DA08F3@me.com>

On Sep 7, 2013, at 10:44 AM, li li <hannah.hlx at gmail.com> wrote:

> Hi all,
>  Is there a way to change the color of the boxplot plots outliers?
>  Thanks.
>    Hanna



If you review ?boxplot, you will see that ?bxp is listed in the See Also section and is used for the actual plotting. In ?bxp is a description of the various parameters for the plot.

Thus:

  set.seed(1)
  boxplot(rexp(50), outcol = "red")


Regards,

Marc Schwartz


From smartpink111 at yahoo.com  Sat Sep  7 18:19:15 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 7 Sep 2013 09:19:15 -0700 (PDT)
Subject: [R] finding both rows that are duplicated in a data frame
In-Reply-To: <1378568753.68050.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <CACYeG1j-T1PQwrwtctNK5FNTkh2Z1Hzdbn1tvzQOswcOFRpJ4Q@mail.gmail.com>
	<1378565520.73807.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1378567835.1118.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1378568753.68050.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <1378570755.67327.YahooMailNeo@web142606.mail.bf1.yahoo.com>






Hi,

Suppose you have situations like this: (duplicates are both UNKNOWN and want to remove those)


example1<-rbind(example,data.frame(id1=c(11,12,12),id2=c(93,95,95),GENDER=rep("G-UNK",3),ETH=rep("E-UNK",3)))
spl<- as.character(interaction(example1$id1,example1$id2))
?res1<-do.call(rbind,lapply(split(example1,spl),function(x) {indx<-!(grepl("UNK",x[,3])|grepl("UNK",x[,4]));if(sum(indx)==0) {x[,3]<-x[,3][-grep("UNK",x[,3])];x[,4]<- x[,4][-grep("UNK",x[,4])];unique(x) } else unique(x[indx,])}))
res1<-res1[!(is.na(res1[,3])|is.na(res1[,4])),]? ##remove the rows with NA

?res2<-res1[order(res1$id1),]
?row.names(res2)<- 1:nrow(res2)
?res2
#? id1 id2 GENDER? ETH
#1??? 1? 22??? G-M E-VT
#2??? 2? 34??? G-M E-AF
#3??? 3? 15??? G-M E-AF
#4??? 4? 76??? G-F E-VT
#5??? 5? 45??? G-F E-VT
#6??? 6? 84??? G-F E-AF
#7??? 7? 37??? G-F E-AF
#8??? 8? 52??? G-F E-AF
#9??? 9? 66??? G-F E-AF
#10? 10? 91??? G-F E-VT

A.K.


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Robert Lynch <robert.b.lynch at gmail.com>
Cc: R help <r-help at r-project.org>
Sent: Saturday, September 7, 2013 11:30 AM
Subject: Re: [R] finding both rows that are duplicated in a data frame

HI,
May be this is what you are looking for.


spl<- as.character(interaction(example$id1,example$id2))
res<-do.call(rbind,lapply(split(example,spl),function(x) {indx<-!(grepl("UNK",x[,3])|grepl("UNK",x[,4]));if(sum(indx)==0) {x[,3]<-x[,3][-grep("UNK",x[,3])];x[,4]<- x[,4][-grep("UNK",x[,4])];unique(x) } else unique(x[indx,])}))
?
?res1<-res[order(res$id1),]
?row.names(res1)<-1:nrow(res1)
?res1
#?? id1 id2 GENDER? ETH
#1??? 1? 22??? G-M E-VT
#2??? 2? 34??? G-M E-AF
#3??? 3? 15??? G-M E-AF
#4??? 4? 76??? G-F E-VT
#5??? 5? 45??? G-F E-VT
#6??? 6? 84??? G-F E-AF
#7??? 7? 37??? G-F E-AF
#8??? 8? 52??? G-F E-AF
#9??? 9? 66??? G-F E-AF
#10? 10? 91??? G-F E-VT
A.K.



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Robert Lynch <robert.b.lynch at gmail.com>
Cc: R help <r-help at r-project.org>
Sent: Saturday, September 7, 2013 10:52 AM
Subject: Re: [R] finding both rows that are duplicated in a data frame

Hi,
example<- data.frame(id1,id2,GENDER,ETH,stringsAsFactors=FALSE)

res<-unique(example[!(grepl("UNK",example$GENDER)|grepl("UNK",example$ETH)),]) 
?res
#?? id1 id2 GENDER? ETH
#1??? 1? 22??? G-M E-VT
#3??? 2? 34??? G-M E-AF
#5??? 3? 15??? G-M E-AF
#7??? 4? 76??? G-F E-VT
#8??? 5? 45??? G-F E-VT
#12?? 7? 37??? G-F E-AF
#13?? 8? 52??? G-F E-AF
#14?? 9? 66??? G-F E-AF
#16? 10? 91??? G-F E-VT


It is a bit unclear about the condition for id1 #6.? If I include both of them, the nrows will be 11, now it is 9.

10?? 6? 84? G-UNK? E-AF
11?? 6? 84??? G-F E-UNK


A.K.



----- Original Message -----
From: Robert Lynch <robert.b.lynch at gmail.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Saturday, September 7, 2013 3:02 AM
Subject: [R] finding both rows that are duplicated in a data frame

I have a data frame that looks like

id1<-c(1,1,2,2,3,3,4,5,5,6,6,7,8,9,9,10)
id2<-c(22,22,34,34,15,15,76,45,45,84,84,37,52,66,66,91)
GENDER<-sample(c("G-UNK","G-M","G-F"),16, replace = TRUE)
ETH <-sample(c("E-AF","E-UNK","E-VT"),16, replace = TRUE)
example<-cbind(id1,id2,GENDER,ETH)

where there are two id's and some duplicate entries for ID's that have
different GENDER or ETH(nicity)
I would like to get a data frame that doesn't have the duplicates, but the
ones that are kept are which ever GENDER is not G-UNK (unknown) and the
kept ETH is what ever is not E-UNK

the resultant data frame should have 10 rows with no *-UNK in either of the
last two columns ( unless both entries were UNK)

yes the example data may have some impossible results but it does capture
important aspects.
1) G-UNK is alphabetically last of G-F, G-M & G-UNK
2) E-UNK is in the middle alphabetically
3) some times the first entry is the unknown gender, some times it is the
second *likely to happen with random sample
4) some times both entries for one variable, GENDER or ETH are unknown.
5) only appears to be two of each row, * not 100% sure

Thanks!
Robert

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jholtman at gmail.com  Sat Sep  7 18:22:21 2013
From: jholtman at gmail.com (jim holtman)
Date: Sat, 7 Sep 2013 12:22:21 -0400
Subject: [R] finding both rows that are duplicated in a data frame
In-Reply-To: <CACYeG1j-T1PQwrwtctNK5FNTkh2Z1Hzdbn1tvzQOswcOFRpJ4Q@mail.gmail.com>
References: <CACYeG1j-T1PQwrwtctNK5FNTkh2Z1Hzdbn1tvzQOswcOFRpJ4Q@mail.gmail.com>
Message-ID: <CAAxdm-6U3L_4pP87=ik=GeDninf3Qs16=sZvn364uXRGhXXkQA@mail.gmail.com>

try this.  Splits the dataframe based on the two IDs and then chooses
the first one in cases where condition not met.


> id1<-c(1,1,2,2,3,3,4,5,5,6,6,7,8,9,9,10)
>  id2<-c(22,22,34,34,15,15,76,45,45,84,84,37,52,66,66,91)
>  GENDER<-sample(c("G-UNK","G-M","G-F"),16, replace = TRUE)
>  ETH <-sample(c("E-AF","E-UNK","E-VT"),16, replace = TRUE)
>  example<-data.frame(id1,id2,GENDER,ETH, stringsAsFactors = FALSE)
> # find dups by spliting on id1,id2
> result <- do.call(rbind
+ , lapply(split(example, list(example$id1, example$id2), drop =
TRUE), function(x){
+ indx <- which(!grepl("UNK", x$GENDER) & !grepl("UNK", x$ETH))[1L] #
choose first one
+ if (is.na(indx)) indx <- 1L  # none match so choose one
+ x[indx,]
+ })
+ )
> result
      id1 id2 GENDER   ETH
3.15    3  15    G-F  E-AF
1.22    1  22    G-F  E-VT
2.34    2  34    G-F  E-AF
7.37    7  37  G-UNK  E-VT
5.45    5  45    G-M  E-AF
8.52    8  52    G-F  E-AF
9.66    9  66  G-UNK  E-AF
4.76    4  76    G-M  E-AF
6.84    6  84    G-M  E-VT
10.91  10  91    G-F E-UNK
Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Sat, Sep 7, 2013 at 3:02 AM, Robert Lynch <robert.b.lynch at gmail.com> wrote:
> I have a data frame that looks like
>
> id1<-c(1,1,2,2,3,3,4,5,5,6,6,7,8,9,9,10)
> id2<-c(22,22,34,34,15,15,76,45,45,84,84,37,52,66,66,91)
> GENDER<-sample(c("G-UNK","G-M","G-F"),16, replace = TRUE)
> ETH <-sample(c("E-AF","E-UNK","E-VT"),16, replace = TRUE)
> example<-cbind(id1,id2,GENDER,ETH)
>
> where there are two id's and some duplicate entries for ID's that have
> different GENDER or ETH(nicity)
> I would like to get a data frame that doesn't have the duplicates, but the
> ones that are kept are which ever GENDER is not G-UNK (unknown) and the
> kept ETH is what ever is not E-UNK
>
> the resultant data frame should have 10 rows with no *-UNK in either of the
> last two columns ( unless both entries were UNK)
>
> yes the example data may have some impossible results but it does capture
> important aspects.
> 1) G-UNK is alphabetically last of G-F, G-M & G-UNK
> 2) E-UNK is in the middle alphabetically
> 3) some times the first entry is the unknown gender, some times it is the
> second *likely to happen with random sample
> 4) some times both entries for one variable, GENDER or ETH are unknown.
> 5) only appears to be two of each row, * not 100% sure
>
> Thanks!
>  Robert
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Sat Sep  7 19:24:46 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 7 Sep 2013 10:24:46 -0700 (PDT)
Subject: [R] Questions of non-conformable arrays
Message-ID: <1378574686.44071.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
?sini<- sin(i)
?is.vector(sini)
#[1] TRUE
lni<- log(i)
?is.vector(lni)
#[1] TRUE

x<-cbind(int=1,sini,lni)
?is.matrix(x)
#[1] TRUE
t(x)*x
#Error in t(x) * x : non-conformable arrays
?
t(x)%*%x
#??????????? int?????? sini???????? lni
#int? 20.0000000? 0.9982219? 42.3356165
#sini? 0.9982219 10.2971266? -0.1138875
#lni? 42.3356165 -0.1138875 102.1647590


xxi<-solve(t(x)%*%x)
?xxi
#???????????? int??????? sini???????? lni
#int?? 0.42542540 -0.04319182 -0.17633836
#sini -0.04319182? 0.10150077? 0.01801122
#lni? -0.17633836? 0.01801122? 0.08288028

A.K.


Dear R-help, 

I have new learner of R, I try to get an inverse matrix ?of (X'X), however it returen that my t(x)*x is non-conformable. 
I try to figure out my mistake in code, However I failed. 

This is my code, thank you for your help. 
? 
> i<-c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20) 
> sini<-as.vector(sin(i)) 
> lni<-as.vector(log(i)) 
> x<-as.matrix(cbind(int=1,sini,lni)) 
> xxi<-solve(t(x)*x) 
Error in t(x) * x : non-conformable arrays


From jholtman at gmail.com  Sat Sep  7 19:50:56 2013
From: jholtman at gmail.com (jim holtman)
Date: Sat, 7 Sep 2013 13:50:56 -0400
Subject: [R] Alignment of data sets
In-Reply-To: <7FA4CD320A8C134A85CD4F78AAE082720373FD381D@CD1001-M360.corp.ads>
References: <7FA4CD320A8C134A85CD4F78AAE082720373FD381D@CD1001-M360.corp.ads>
Message-ID: <CAAxdm-6P=fNR2WpCq3uBiuni-BrKO5dvnbANGGm0rLY7uamF4Q@mail.gmail.com>

If spacing is critical, use 'sprintf' for creating the output.


> Lines1<- read.csv(textConnection("Year, Day, Hour, Value
+ 2010,  001,    0,    15.9
+  2010,  001,    1,    7.3
+  2010,  001,    2,    5.2
+  2010,  001,    3,    8.0
+  2010,  001,    4,    0.0
+  2010,  001,    5,    12.1
+  2010,  001,    6,    11.6
+  2010,  001,    7,    13.9
+  2010,  001,    8,    11.9
+  2010,  001,    9,    13.6
+  2010,  001,    10,    16.1
+
+ 2010,  001,    11,    18.5"))
> # use sprintf for the spacing
> cat(with(Lines1, sprintf("%4d, %03d,%3d,%5.1f\n"
+ , Year, Day, Hour, Value
+ )), sep = ''
+ )
2010, 001,  0, 15.9
2010, 001,  1,  7.3
2010, 001,  2,  5.2
2010, 001,  3,  8.0
2010, 001,  4,  0.0
2010, 001,  5, 12.1
2010, 001,  6, 11.6
2010, 001,  7, 13.9
2010, 001,  8, 11.9
2010, 001,  9, 13.6
2010, 001, 10, 16.1
2010, 001, 11, 18.5
>
Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Fri, Sep 6, 2013 at 3:42 PM, Mostafavipak, Nasrin
<Nasrin.Mostafavipak at stantec.com> wrote:
> Hi all;
>
> I have a data set with the format below:
>
>
> Year, Day, Hour, Value
>
> 2010,  001,    0,    15.9
> 2010,  001,    1,    7.3
> 2010,  001,    2,    5.2
> 2010,  001,    3,    8.0
> 2010,  001,    4,    0.0
> 2010,  001,    5,    12.1
> 2010,  001,    6,    11.6
> 2010,  001,    7,    13.9
> 2010,  001,    8,    11.9
> 2010,  001,    9,    13.6
> 2010,  001,    10,    16.1
> 2010,  001,    11,    18.5
>
> That should be converted to this format:
>
> 2010,  001,    0,    15.9
> 2010,  001,    1,      7.3
> 2010,  001,    2,      5.2
> 2010,  001,    3,      8.0
> 2010,  001,    4,      0.0
> 2010,  001,    5,    12.1
> 2010,  001,    6,    11.6
> 2010,  001,    7,    13.9
> 2010,  001,    8,    11.9
> 2010,  001,    9,    13.6
> 2010,  001,  10,    16.1
> 2010,  001,  11,    18.5
> The number of spaces is important. I have tried justify, but it produces spaces at the end or at the beginning of the rows depending on the choice of right, left alignment. Also I need 3 significant digits for the second column, when I use read.csv it gives me 1 instead of 001. So I use read.table, and one of the problems with read.table is that it produces row names that I don't want. Also I need commas in my output file.
>
>
> So far this is the best I could do:
>
> mydata = read.table("C:/ozone3.txt", sep = "")
>
>
> capture.output( print(mydata, sep = ",", print.gap=3), file="capture2.txt" )
>
> and the output has all the unwanted row names and also there are no commas.
>
>
> Any suggestions?
>
> Thank you
> Nasrin
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From irasharenow100 at yahoo.com  Sat Sep  7 22:11:18 2013
From: irasharenow100 at yahoo.com (Ira Sharenow)
Date: Sat, 07 Sep 2013 13:11:18 -0700
Subject: [R] Create a new column based on values in two other columns
Message-ID: <522B8866.70800@yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130907/6d015ae8/attachment.pl>

From smartpink111 at yahoo.com  Sat Sep  7 22:12:33 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 7 Sep 2013 13:12:33 -0700 (PDT)
Subject: [R] Subsetting isolating a group of values in a group of
	variables
Message-ID: <1378584753.66498.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,

The expected output is not clear.
dat1<- read.table(text="ID diag1 diag2 diag3 proc1 proc2 proc3
1 k23 i269 j123?? u123? u456? u123
2 k69 i80 u456?? z456? z123? z456
3 l91 i801 g678?? u456? u123? u123
4 i80 i90 h983?? z123? z456?? z456",sep="",header=TRUE,stringsAsFactors=FALSE)

vec1<- c("i80","i90","l91")


subset(dat1,diag1%in%vec1|diag2%in%vec1|diag3%in% vec1)
#? ID diag1 diag2 diag3 proc1 proc2 proc3
#2? 2?? k69?? i80? u456? z456? z123? z456
#3? 3?? l91? i801? g678? u456? u123? u123
#4? 4?? i80?? i90? h983? z123? z456? z456


##Creating another data frame with codes and diagnosis

dat2<-data.frame(code=unique(unlist(dat1[,2:4])),diag=c(rep("Broken finger",2),rep("Broken toe",2),rep("Broken legs",2),"Broken toe",rep("Broken foot",2),rep("Broken rib",2)),stringsAsFactors=FALSE)



?lst1<- lapply(split(dat2,dat2$diag), function(x) {x1<- x$code;x2<- subset(dat1,diag1%in%x1|diag2%in%x1|diag3%in%x1);cbind(x2,Diag=x$diag)})
?lst1
#$`Broken finger`
?# ID diag1 diag2 diag3 proc1 proc2 proc3????????? Diag
#1? 1?? k23? i269? j123? u123? u456? u123 Broken finger
#2? 2?? k69?? i80? u456? z456? z123? z456 Broken finger
#
#$`Broken foot`
?# ID diag1 diag2 diag3 proc1 proc2 proc3??????? Diag
#1? 1?? k23? i269? j123? u123? u456? u123 Broken foot
#2? 2?? k69?? i80? u456? z456? z123? z456 Broken foot
#
#$`Broken legs`
?# ID diag1 diag2 diag3 proc1 proc2 proc3??????? Diag
#1? 1?? k23? i269? j123? u123? u456? u123 Broken legs
#3? 3?? l91? i801? g678? u456? u123? u123 Broken legs

#$`Broken rib`
?# ID diag1 diag2 diag3 proc1 proc2 proc3?????? Diag
#3? 3?? l91? i801? g678? u456? u123? u123 Broken rib
#4? 4?? i80?? i90? h983? z123? z456? z456 Broken rib

#$`Broken toe`
#? ID diag1 diag2 diag3 proc1 proc2 proc3?????? Diag
#2? 2?? k69?? i80? u456? z456? z123? z456 Broken toe
#3? 3?? l91? i801? g678? u456? u123? u123 Broken toe
#4? 4?? i80?? i90? h983? z123? z456? z456 Broken toe


A.K.


Hello. 

I have date frame structured like this: 

ID	diag1 diag2 diag3 proc1 proc2 proc3 
1	k23	i269	 j123	 ? u123 ?u456 ?u123 
2	k69	i80	 u456 ? z456 ?z123 ?z456 
3	l91	i801	 g678 ? u456 ?u123 ?u123 
4	i80	i90	 h983 ? z123 ?z456 ? z456 

Each observation has a group of diagnostics codes(diag) and procedure codes(proc). 

A single diagnosis maybe be described by more than one code eg broken toe maybe coded for by i80,i90,l91 or more. 

My aim to subset all rows with any of the codes representing a 
single diagnosis. So i would like to use multiple values (i80,i90,l91= 
broken toe) applied to specific columns, ie diag1,2 and 3 to isolate 
those rows which contain any of the specified codes. 

Your help would be greatly appreciated.


From smartpink111 at yahoo.com  Sun Sep  8 04:25:43 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 7 Sep 2013 19:25:43 -0700 (PDT)
Subject: [R] Subsetting isolating a group of values in a group of
	variables
In-Reply-To: <1378584753.66498.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1378584753.66498.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <1378607143.98976.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Using the same example:
str1<-paste(colnames(dat1)[grepl("diag",colnames(dat1))],"%in%","vec1",collapse="|")
?subset(dat1,eval(parse(text=str1)))
#? ID diag1 diag2 diag3 proc1 proc2 proc3
#2? 2?? k69?? i80? u456? z456? z123? z456
#3? 3?? l91? i801? g678? u456? u123? u123
#4? 4?? i80?? i90? h983? z123? z456? z456
lapply(split(dat2,dat2$diag),function(x) {x1<- x$code; str1<- paste(colnames(dat1)[grepl("diag",colnames(dat1))],"%in%","x1",collapse="|"); x2<- subset(dat1,eval(parse(text=str1))); cbind(x2,Diag=x$diag)})
#$`Broken finger`
#? ID diag1 diag2 diag3 proc1 proc2 proc3????????? Diag
#1? 1?? k23? i269? j123? u123? u456? u123 Broken finger
#2? 2?? k69?? i80? u456? z456? z123? z456 Broken finger
#
#$`Broken foot`
#? ID diag1 diag2 diag3 proc1 proc2 proc3??????? Diag
#1? 1?? k23? i269? j123? u123? u456? u123 Broken foot
#2? 2?? k69?? i80? u456? z456? z123? z456 Broken foot
#
#$`Broken legs`
#? ID diag1 diag2 diag3 proc1 proc2 proc3??????? Diag
#1? 1?? k23? i269? j123? u123? u456? u123 Broken legs
#3? 3?? l91? i801? g678? u456? u123? u123 Broken legs
#
#$`Broken rib`
#? ID diag1 diag2 diag3 proc1 proc2 proc3?????? Diag
#3? 3?? l91? i801? g678? u456? u123? u123 Broken rib
#4? 4?? i80?? i90? h983? z123? z456? z456 Broken rib
#
#$`Broken toe`
#? ID diag1 diag2 diag3 proc1 proc2 proc3?????? Diag
#2? 2?? k69?? i80? u456? z456? z123? z456 Broken toe
#3? 3?? l91? i801? g678? u456? u123? u123 Broken toe
#4? 4?? i80?? i90? h983? z123? z456? z456 Broken toe

##############You can also use a larger dataset:
set.seed(48)
dat1New<- as.data.frame(matrix(sample(paste0(letters,sample(1:800,700,replace=TRUE)),90*1e5,replace=TRUE),ncol=90),stringsAsFactors=FALSE)
set.seed(185)
?dat2New<- as.data.frame(matrix(sample(paste0(letters,sample(400:1200,700,replace=TRUE)),90*1e5,replace=TRUE),ncol=90),stringsAsFactors=FALSE)
?dat3<- cbind(ID=1:1e5,dat1New,dat2New)
colnames(dat3)[-1]<-c(paste0("diag",1:90),paste0("proc",1:90))

set.seed(1459)
Refdat<- data.frame(code=unique(unlist(dat1New)), diag=sample(c("Broken finger","Broken toe", "Broken legs", "Broken foot", "Broken rib", "Broken nose", "Broken elbow", "Broken hip"),length(unique(unlist(dat1New))),replace=TRUE),stringsAsFactors=FALSE)

res<- lapply(split(Refdat,Refdat$diag),function(x) {x1<- x$code; str1<- paste(colnames(dat3)[grepl("diag",colnames(dat3))],"%in%","x1",collapse="|"); x2<- subset(dat3,eval(parse(text=str1))) })

sapply(split(Refdat,Refdat$diag),function(x) {x1<- x$code; str1<- paste(colnames(dat3)[grepl("diag",colnames(dat3))],"%in%","x1",collapse="|"); x2<- subset(dat3,eval(parse(text=str1)));nrow(x2) })
# Broken elbow Broken finger?? Broken foot??? Broken hip?? Broken legs 
?# ????? 99997??????? 100000???????? 99994??????? 100000???????? 99997 
?# Broken nose??? Broken rib??? Broken toe 
? # ???? 99996???????? 99999??????? 100000 


A.K.






Thanks for the prompt reply arun, this really has helped. 

My actual data frame has diagnostic codes diag1, diag2 etc which are range from 1 to 93. Is there any way to apply "subset(dat1,diag1%in%vec1|diag2%in%vec1|diag3%in% vec1)"??such that i can search many multiple columns in dat1 without specifying each column separately? 


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Saturday, September 7, 2013 4:12 PM
Subject: Re: Subsetting isolating a group of values in a group of variables

Hi,

The expected output is not clear.
dat1<- read.table(text="ID diag1 diag2 diag3 proc1 proc2 proc3
1 k23 i269 j123?? u123? u456? u123
2 k69 i80 u456?? z456? z123? z456
3 l91 i801 g678?? u456? u123? u123
4 i80 i90 h983?? z123? z456?? z456",sep="",header=TRUE,stringsAsFactors=FALSE)

vec1<- c("i80","i90","l91")


subset(dat1,diag1%in%vec1|diag2%in%vec1|diag3%in% vec1)
#? ID diag1 diag2 diag3 proc1 proc2 proc3
#2? 2?? k69?? i80? u456? z456? z123? z456
#3? 3?? l91? i801? g678? u456? u123? u123
#4? 4?? i80?? i90? h983? z123? z456? z456


##Creating another data frame with codes and diagnosis

dat2<-data.frame(code=unique(unlist(dat1[,2:4])),diag=c(rep("Broken finger",2),rep("Broken toe",2),rep("Broken legs",2),"Broken toe",rep("Broken foot",2),rep("Broken rib",2)),stringsAsFactors=FALSE)



?lst1<- lapply(split(dat2,dat2$diag), function(x) {x1<- x$code;x2<- subset(dat1,diag1%in%x1|diag2%in%x1|diag3%in%x1);cbind(x2,Diag=x$diag)})
?lst1
#$`Broken finger`
?# ID diag1 diag2 diag3 proc1 proc2 proc3????????? Diag
#1? 1?? k23? i269? j123? u123? u456? u123 Broken finger
#2? 2?? k69?? i80? u456? z456? z123? z456 Broken finger
#
#$`Broken foot`
?# ID diag1 diag2 diag3 proc1 proc2 proc3??????? Diag
#1? 1?? k23? i269? j123? u123? u456? u123 Broken foot
#2? 2?? k69?? i80? u456? z456? z123? z456 Broken foot
#
#$`Broken legs`
?# ID diag1 diag2 diag3 proc1 proc2 proc3??????? Diag
#1? 1?? k23? i269? j123? u123? u456? u123 Broken legs
#3? 3?? l91? i801? g678? u456? u123? u123 Broken legs

#$`Broken rib`
?# ID diag1 diag2 diag3 proc1 proc2 proc3?????? Diag
#3? 3?? l91? i801? g678? u456? u123? u123 Broken rib
#4? 4?? i80?? i90? h983? z123? z456? z456 Broken rib

#$`Broken toe`
#? ID diag1 diag2 diag3 proc1 proc2 proc3?????? Diag
#2? 2?? k69?? i80? u456? z456? z123? z456 Broken toe
#3? 3?? l91? i801? g678? u456? u123? u123 Broken toe
#4? 4?? i80?? i90? h983? z123? z456? z456 Broken toe


A.K.


Hello. 

I have date frame structured like this: 

ID??? diag1 diag2 diag3 proc1 proc2 proc3 
1??? k23??? i269???  j123???  ? u123 ?u456 ?u123 
2??? k69??? i80???  u456 ? z456 ?z123 ?z456 
3??? l91??? i801???  g678 ? u456 ?u123 ?u123 
4??? i80??? i90???  h983 ? z123 ?z456 ? z456 

Each observation has a group of diagnostics codes(diag) and procedure codes(proc). 

A single diagnosis maybe be described by more than one code eg broken toe maybe coded for by i80,i90,l91 or more. 

My aim to subset all rows with any of the codes representing a 
single diagnosis. So i would like to use multiple values (i80,i90,l91= 
broken toe) applied to specific columns, ie diag1,2 and 3 to isolate 
those rows which contain any of the specified codes. 

Your help would be greatly appreciated.


From smartpink111 at yahoo.com  Sun Sep  8 07:37:17 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 7 Sep 2013 22:37:17 -0700 (PDT)
Subject: [R] Sub setting multiple ids based on a 2nd data frame
Message-ID: <1378618637.44071.YahooMailNeo@web142606.mail.bf1.yahoo.com>

HI Matt,

I changed the dates a little bit to show dates that are outside the range in dataset B.

A<- read.table(text="
ID????? Date???????????? Depth? Temp
1?????? 2002-05-12?????????? 10 12
1?????? 2003-05-13?????????? 10 12
1?????? 2003-05-14?????????? 10 12
1?????? 2004-04-15?????????? 10 12
2?????? 2002-05-16?????????? 10 12
2?????? 2002-12-17?????????? 10 12
2?????? 2003-04-18?????????? 10 12
2?????? 2002-05-19?????????? 10 12
3?????? 2003-05-10?????????? 10 12
3?????? 2004-05-21?????????? 10 12
3?????? 2004-05-22?????????? 10 12
3?????? 2005-05-10?????????? 10 12
3?????? 2006-05-24?????????? 10 12
",sep="",header=TRUE,stringsAsFactors=FALSE)
?
B<- read.table(text="
Year?? Start??? End
2002 2002-05-10 2002-11-01
2003 2003-05-11 2003-11-02
2004 2004-05-12 2004-11-03
2005 2005-05-13 2005-11-04
2006 2006-05-14 2006-11-05
",sep="",header=TRUE,stringsAsFactors=FALSE) 

?A$Year<-gsub("-.*","",A$Date)
?library(plyr)
AB<-join(A,B,by="Year")
?indx<-(as.numeric(as.Date(AB$Start))<= as.numeric(as.Date(AB$Date))) & (as.numeric(as.Date(AB$Date)) <= as.numeric(as.Date(AB$End)))

?res<- AB[indx,-c(6,7)]
?res
#?? ID?????? Date Depth Temp Year
#1?? 1 2002-05-12??? 10?? 12 2002
#2?? 1 2003-05-13??? 10?? 12 2003
#3?? 1 2003-05-14??? 10?? 12 2003
#5?? 2 2002-05-16??? 10?? 12 2002
#8?? 2 2002-05-19??? 10?? 12 2002
#10? 3 2004-05-21??? 10?? 12 2004
#11? 3 2004-05-22??? 10?? 12 2004
#13? 3 2006-05-24??? 10?? 12 2006


A.K.


Hi All, 

I accidentally posted this in the data.table forum and deleted it to post here. 

I have some telemetry data that spans multiple years (2002 - 2013) with 
multiple individuals per year. I want to subset the telemetry data to 
include only those data points that fall between specific dates which are 
provided in a 2nd data frame. The telemetry df is in the form of: 

DF "A" 

ID ? ? ?Date ? ? ? ? ? ? Depth ?Temp 
1 ? ? ? 2002-05-12 ? ? ? ? ? 10 12 
1 ? ? ? 2002-05-13 ? ? ? ? ? 10 12 
1 ? ? ? 2002-05-14 ? ? ? ? ? 10 12 
1 ? ? ? 2002-05-15 ? ? ? ? ? 10 12 
2 ? ? ? 2002-05-16 ? ? ? ? ? 10 12 
2 ? ? ? 2002-05-17 ? ? ? ? ? 10 12 
2 ? ? ? 2002-05-18 ? ? ? ? ? 10 12 
2 ? ? ? 2002-05-19 ? ? ? ? ? 10 12 
3 ? ? ? 2002-05-20 ? ? ? ? ? 10 12 
3 ? ? ? 2002-05-21 ? ? ? ? ? 10 12 
3 ? ? ? 2002-05-22 ? ? ? ? ? 10 12 
3 ? ? ? 2002-05-23 ? ? ? ? ? 10 12 
3 ? ? ? 2002-05-24 ? ? ? ? ? 10 12 

And the df with the dates I want to use to subset is formatted as follows: 

?DF "B" 

Year ? ? ? Start ? ? ? ? ? ?End 
2002 ? ?2002-05-10 ? ? ?2002-11-01 
2003 ? ?2003-05-11 ? ? ?2003-11-02 
2004 ? ?2004-05-12 ? ? ?2004-11-03 
2005 ? ?2005-05-13 ? ? ?2005-11-04 
2006 ? ?2006-05-14 ? ? ?2006-11-05 

So, I want to say, for each ID in DF A, subset and keep only those data 
points collected on a date that fall between the start and end date for the 
corresponding year from DF B. 

I am unsure if a loop is my best bet, or using plyr (which I am unfamiliar 
with). I am relatively new to R, so this seems a bit above my head. Any help 
is much appreciated. 

Thanks in advance!


From harb at student.unimelb.edu.au  Sun Sep  8 12:46:37 2013
From: harb at student.unimelb.edu.au (Ben Harrison)
Date: Sun, 8 Sep 2013 20:46:37 +1000
Subject: [R] Use of parantheses to force order of execution
Message-ID: <CAGYnQNSPt7NgqJnDBUi9GO2fxiKAuK_8FtXP9+-oVW-7QW0PSA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130908/e8572062/attachment.pl>

From walt at dataanalyticscorp.com  Sun Sep  8 05:33:09 2013
From: walt at dataanalyticscorp.com (Data Analytics Corp.)
Date: Sat, 07 Sep 2013 23:33:09 -0400
Subject: [R] melting a data frame
Message-ID: <522BEFF5.40903@dataanalyticscorp.com>

Hi,

Suppose I have a data frame with 189 columns.  The columns are actually 
9 blocks of 21 columns each, each block representing measures on each of 
9 products.  There are 130 rows.  Suppose I extract the first block of 
21 columns and make them into a separate data frame.  I then want to 
take the second block of 21 columns and rbind it to the first; then the 
third set of 21 and rbind it to the first two; etc.  The final data 
frame should have 1170 (= 9 * 130)  rows and 21 columns.  Is there an 
easy way to melt the blocks comparable to using the melt function in the 
plyr package (which is why I'm referring to what I want to do as 
"melting")?  It seems that there should be a simple way to do this.  I 
used a for loop which worked, but I want to see if there's a more 
efficient way.

Thanks,

Walt

________________________

Walter R. Paczkowski, Ph.D.
Data Analytics Corp.
44 Hamilton Lane
Plainsboro, NJ 08536
________________________
(V) 609-936-8999
(F) 609-936-3733
walt at dataanalyticscorp.com
www.dataanalyticscorp.com


From smartpink111 at yahoo.com  Sun Sep  8 15:29:42 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 8 Sep 2013 06:29:42 -0700 (PDT)
Subject: [R] melting a data frame
In-Reply-To: <522BEFF5.40903@dataanalyticscorp.com>
References: <522BEFF5.40903@dataanalyticscorp.com>
Message-ID: <1378646982.64577.YahooMailNeo@web142605.mail.bf1.yahoo.com>



Hi,

You could try:
set.seed(48)
dat1<- as.data.frame(matrix(sample(1:40,189*130,replace=TRUE),ncol=189))
res<-do.call(rbind,lapply(split(colnames(dat1),((seq_len(ncol(dat1))-1)%/%21)+1),function(x) {x1<- dat1[,x]; colnames(x1)<- paste("V",1:21);x1}))
?row.names(res)<- 1:nrow(res)
?dim(res)
#[1] 1170?? 21
A.K.



----- Original Message -----
From: Data Analytics Corp. <walt at dataanalyticscorp.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Saturday, September 7, 2013 11:33 PM
Subject: [R] melting a data frame

Hi,

Suppose I have a data frame with 189 columns.? The columns are actually 9 blocks of 21 columns each, each block representing measures on each of 9 products.? There are 130 rows.? Suppose I extract the first block of 21 columns and make them into a separate data frame.? I then want to take the second block of 21 columns and rbind it to the first; then the third set of 21 and rbind it to the first two; etc.? The final data frame should have 1170 (= 9 * 130)? rows and 21 columns.? Is there an easy way to melt the blocks comparable to using the melt function in the plyr package (which is why I'm referring to what I want to do as "melting")?? It seems that there should be a simple way to do this.? I used a for loop which worked, but I want to see if there's a more efficient way.

Thanks,

Walt

________________________

Walter R. Paczkowski, Ph.D.
Data Analytics Corp.
44 Hamilton Lane
Plainsboro, NJ 08536
________________________
(V) 609-936-8999
(F) 609-936-3733
walt at dataanalyticscorp.com
www.dataanalyticscorp.com

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Sun Sep  8 15:49:36 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 8 Sep 2013 06:49:36 -0700 (PDT)
Subject: [R] melting a data frame
In-Reply-To: <1378646982.64577.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <522BEFF5.40903@dataanalyticscorp.com>
	<1378646982.64577.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1378648176.20992.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,

You may also try ?reshape()
dat2<- dat1
names(dat2)[-c(1:21)]<- paste(rep(names(dat2)[1:21],8),rep(2:9,each=21),sep="_")
names(dat2)[1:21]<- paste(names(dat2)[1:21],rep(1,21),sep="_")
res1<- reshape(dat2,direction="long",varying=1:ncol(dat2),sep="_")
row.names(res1)<- 1:nrow(res1)
attr(res1,"reshapeLong")<-NULL

###
res<-do.call(rbind,lapply(split(colnames(dat1),((seq_len(ncol(dat1))-1)%/%21)+1),function(x) {x1<- dat1[,x]; colnames(x1)<- paste0("V",1:21);x1}))##previous solution changed "paste" to "paste0"
?row.names(res)<- 1:nrow(res)


all.equal(res,res2)
#[1] TRUE


A.K.





----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: "walt at dataanalyticscorp.com" <walt at dataanalyticscorp.com>
Cc: R help <r-help at r-project.org>
Sent: Sunday, September 8, 2013 9:29 AM
Subject: Re: [R] melting a data frame



Hi,

You could try:
set.seed(48)
dat1<- as.data.frame(matrix(sample(1:40,189*130,replace=TRUE),ncol=189))
res<-do.call(rbind,lapply(split(colnames(dat1),((seq_len(ncol(dat1))-1)%/%21)+1),function(x) {x1<- dat1[,x]; colnames(x1)<- paste("V",1:21);x1}))
?row.names(res)<- 1:nrow(res)
?dim(res)
#[1] 1170?? 21
A.K.



----- Original Message -----
From: Data Analytics Corp. <walt at dataanalyticscorp.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Saturday, September 7, 2013 11:33 PM
Subject: [R] melting a data frame

Hi,

Suppose I have a data frame with 189 columns.? The columns are actually 9 blocks of 21 columns each, each block representing measures on each of 9 products.? There are 130 rows.? Suppose I extract the first block of 21 columns and make them into a separate data frame.? I then want to take the second block of 21 columns and rbind it to the first; then the third set of 21 and rbind it to the first two; etc.? The final data frame should have 1170 (= 9 * 130)? rows and 21 columns.? Is there an easy way to melt the blocks comparable to using the melt function in the plyr package (which is why I'm referring to what I want to do as "melting")?? It seems that there should be a simple way to do this.? I used a for loop which worked, but I want to see if there's a more efficient way.

Thanks,

Walt

________________________

Walter R. Paczkowski, Ph.D.
Data Analytics Corp.
44 Hamilton Lane
Plainsboro, NJ 08536
________________________
(V) 609-936-8999
(F) 609-936-3733
walt at dataanalyticscorp.com
www.dataanalyticscorp.com

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Sun Sep  8 15:51:38 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 8 Sep 2013 06:51:38 -0700 (PDT)
Subject: [R] melting a data frame
In-Reply-To: <1378648176.20992.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <522BEFF5.40903@dataanalyticscorp.com>
	<1378646982.64577.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1378648176.20992.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <1378648298.63995.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Forgot:
?res2<-subset(res1,select= -c(time,id))
A.K.




----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: "walt at dataanalyticscorp.com" <walt at dataanalyticscorp.com>
Cc: R help <r-help at r-project.org>
Sent: Sunday, September 8, 2013 9:49 AM
Subject: Re: [R] melting a data frame

Hi,

You may also try ?reshape()
dat2<- dat1
names(dat2)[-c(1:21)]<- paste(rep(names(dat2)[1:21],8),rep(2:9,each=21),sep="_")
names(dat2)[1:21]<- paste(names(dat2)[1:21],rep(1,21),sep="_")
res1<- reshape(dat2,direction="long",varying=1:ncol(dat2),sep="_")
row.names(res1)<- 1:nrow(res1)
attr(res1,"reshapeLong")<-NULL

###
res<-do.call(rbind,lapply(split(colnames(dat1),((seq_len(ncol(dat1))-1)%/%21)+1),function(x) {x1<- dat1[,x]; colnames(x1)<- paste0("V",1:21);x1}))##previous solution changed "paste" to "paste0"
?row.names(res)<- 1:nrow(res)


all.equal(res,res2)
#[1] TRUE


A.K.





----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: "walt at dataanalyticscorp.com" <walt at dataanalyticscorp.com>
Cc: R help <r-help at r-project.org>
Sent: Sunday, September 8, 2013 9:29 AM
Subject: Re: [R] melting a data frame



Hi,

You could try:
set.seed(48)
dat1<- as.data.frame(matrix(sample(1:40,189*130,replace=TRUE),ncol=189))
res<-do.call(rbind,lapply(split(colnames(dat1),((seq_len(ncol(dat1))-1)%/%21)+1),function(x) {x1<- dat1[,x]; colnames(x1)<- paste("V",1:21);x1}))
?row.names(res)<- 1:nrow(res)
?dim(res)
#[1] 1170?? 21
A.K.



----- Original Message -----
From: Data Analytics Corp. <walt at dataanalyticscorp.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Saturday, September 7, 2013 11:33 PM
Subject: [R] melting a data frame

Hi,

Suppose I have a data frame with 189 columns.? The columns are actually 9 blocks of 21 columns each, each block representing measures on each of 9 products.? There are 130 rows.? Suppose I extract the first block of 21 columns and make them into a separate data frame.? I then want to take the second block of 21 columns and rbind it to the first; then the third set of 21 and rbind it to the first two; etc.? The final data frame should have 1170 (= 9 * 130)? rows and 21 columns.? Is there an easy way to melt the blocks comparable to using the melt function in the plyr package (which is why I'm referring to what I want to do as "melting")?? It seems that there should be a simple way to do this.? I used a for loop which worked, but I want to see if there's a more efficient way.

Thanks,

Walt

________________________

Walter R. Paczkowski, Ph.D.
Data Analytics Corp.
44 Hamilton Lane
Plainsboro, NJ 08536
________________________
(V) 609-936-8999
(F) 609-936-3733
walt at dataanalyticscorp.com
www.dataanalyticscorp.com

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From murdoch.duncan at gmail.com  Sun Sep  8 16:09:06 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 08 Sep 2013 10:09:06 -0400
Subject: [R] Use of parantheses to force order of execution
In-Reply-To: <CAGYnQNSPt7NgqJnDBUi9GO2fxiKAuK_8FtXP9+-oVW-7QW0PSA@mail.gmail.com>
References: <CAGYnQNSPt7NgqJnDBUi9GO2fxiKAuK_8FtXP9+-oVW-7QW0PSA@mail.gmail.com>
Message-ID: <522C8502.5040107@gmail.com>

On 13-09-08 6:46 AM, Ben Harrison wrote:
> Hello,
> I wish to create a copy of a data frame, but with missing values replaced
> with NAs.
>
> I thought I should be able to do it in one step using parentheses to group
> the statements and force those inside the parens to execute first:
>
> df <- (BWS6[BWS6 < -998] <- NA)
>
> But all this does is assign NA to df, as described in ?"[" for the case
> with no parens.
>
> Can I do this in some way? It's no great problem of course to have two
> separate statements, just curious.

This isn't an order of execution issue.  Your parenthesized assignment 
modifies BWS6, and that's not what you want to do.

If you convert BWS6 to a matrix instead of a dataframe, you could use

res <- ifelse(BWS6 < -998, NA, BWS6)

but ifelse doesn't work on dataframes in general.  You can do it in one 
long line with a dataframe using lapply, but it is ugly:

df <- as.data.frame( lapply(BWS6, function(col) ifelse(col < -998, NA, 
col)))

Duncan Murdoch


From jfox at mcmaster.ca  Sun Sep  8 16:06:47 2013
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 08 Sep 2013 10:06:47 -0400
Subject: [R] melting a data frame
In-Reply-To: <1378646982.64577.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <522BEFF5.40903@dataanalyticscorp.com>
	<1378646982.64577.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <web-472904387@cgpsrv2.cis.mcmaster.ca>

Dear Walt and A.K.,

One shouldn't reflexively avoid loops in R. In this case, it seems to me clearer to use a loop, and it's no less "efficient" (especially, I would guess, when one takes into account the time to figure out how to do the computation). I get

> system.time({
+ res<-do.call(rbind,lapply(split(colnames(dat1),((seq_len(ncol(dat1))-1)%/%21)+1),function(x) {x1<- dat1[,x]; colnames(x1)<- paste("V",1:21);x1}))
+ row.names(res)<- 1:nrow(res)
+ })
   user  system elapsed 
   0.02    0.00    0.02 
> dim(res)
[1] 1170   21


> system.time({
+ res2 <- as.data.frame(matrix(0, 1170, 21))
+ for (i in 1:9){
+     res2[((i - 1)*130 + 1):(i*130), ] <- dat1[, ((i - 1)*21 + 1):(i*21)]
+ }
+ })
   user  system elapsed 
   0.02    0.00    0.01 
> dim(res2)
[1] 1170   21

> all(res == res2)
[1] TRUE

Best,
 John

On Sun, 8 Sep 2013 06:29:42 -0700 (PDT)
 arun <smartpink111 at yahoo.com> wrote:
> 
> 
> Hi,
> 
> You could try:
> set.seed(48)
> dat1<- as.data.frame(matrix(sample(1:40,189*130,replace=TRUE),ncol=189))
> res<-do.call(rbind,lapply(split(colnames(dat1),((seq_len(ncol(dat1))-1)%/%21)+1),function(x) {x1<- dat1[,x]; colnames(x1)<- paste("V",1:21);x1}))
> ?row.names(res)<- 1:nrow(res)
> ?dim(res)
> #[1] 1170?? 21
> A.K.
> 
> 
> 
> ----- Original Message -----
> From: Data Analytics Corp. <walt at dataanalyticscorp.com>
> To: R help <r-help at r-project.org>
> Cc: 
> Sent: Saturday, September 7, 2013 11:33 PM
> Subject: [R] melting a data frame
> 
> Hi,
> 
> Suppose I have a data frame with 189 columns.? The columns are actually 9 blocks of 21 columns each, each block representing measures on each of 9 products.? There are 130 rows.? Suppose I extract the first block of 21 columns and make them into a separate data frame.? I then want to take the second block of 21 columns and rbind it to the first; then the third set of 21 and rbind it to the first two; etc.? The final data frame should have 1170 (= 9 * 130)? rows and 21 columns.? Is there an easy way to melt the blocks comparable to using the melt function in the plyr package (which is why I'm referring to what I want to do as "melting")?? It seems that there should be a simple way to do this.? I used a for loop which worked, but I want to see if there's a more efficient way.
> 
> Thanks,
> 
> Walt
> 
> ________________________
> 
> Walter R. Paczkowski, Ph.D.
> Data Analytics Corp.
> 44 Hamilton Lane
> Plainsboro, NJ 08536
> ________________________
> (V) 609-936-8999
> (F) 609-936-3733
> walt at dataanalyticscorp.com
> www.dataanalyticscorp.com
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

------------------------------------------------
John Fox
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/


From smartpink111 at yahoo.com  Sun Sep  8 16:31:28 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 8 Sep 2013 07:31:28 -0700 (PDT)
Subject: [R] Sub setting multiple ids based on a 2nd data frame
In-Reply-To: <1378618637.44071.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <1378618637.44071.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <1378650688.62642.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,

The ?as.numeric() in 'indx' is not needed.

?indx1<-(as.Date(AB$Start)<= as.Date(AB$Date)) & (as.Date(AB$Date) <= as.Date(AB$End))
?identical(indx,indx1)
#[1] TRUE
?AB[indx1,-c(5:7)]


A.K.

----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: Matthew Guzzo <mattguzzo12 at gmail.com>
Sent: Sunday, September 8, 2013 1:37 AM
Subject: Re: Sub setting multiple ids based on a 2nd data frame

HI Matt,

I changed the dates a little bit to show dates that are outside the range in dataset B.

A<- read.table(text="
ID????? Date???????????? Depth? Temp
1?????? 2002-05-12?????????? 10 12
1?????? 2003-05-13?????????? 10 12
1?????? 2003-05-14?????????? 10 12
1?????? 2004-04-15?????????? 10 12
2?????? 2002-05-16?????????? 10 12
2?????? 2002-12-17?????????? 10 12
2?????? 2003-04-18?????????? 10 12
2?????? 2002-05-19?????????? 10 12
3?????? 2003-05-10?????????? 10 12
3?????? 2004-05-21?????????? 10 12
3?????? 2004-05-22?????????? 10 12
3?????? 2005-05-10?????????? 10 12
3?????? 2006-05-24?????????? 10 12
",sep="",header=TRUE,stringsAsFactors=FALSE)
?
B<- read.table(text="
Year?? Start??? End
2002 2002-05-10 2002-11-01
2003 2003-05-11 2003-11-02
2004 2004-05-12 2004-11-03
2005 2005-05-13 2005-11-04
2006 2006-05-14 2006-11-05
",sep="",header=TRUE,stringsAsFactors=FALSE) 

?A$Year<-gsub("-.*","",A$Date)
?library(plyr)
AB<-join(A,B,by="Year")
?indx<-(as.numeric(as.Date(AB$Start))<= as.numeric(as.Date(AB$Date))) & (as.numeric(as.Date(AB$Date)) <= as.numeric(as.Date(AB$End)))

?res<- AB[indx,-c(6,7)]
?res
#?? ID?????? Date Depth Temp Year
#1?? 1 2002-05-12??? 10?? 12 2002
#2?? 1 2003-05-13??? 10?? 12 2003
#3?? 1 2003-05-14??? 10?? 12 2003
#5?? 2 2002-05-16??? 10?? 12 2002
#8?? 2 2002-05-19??? 10?? 12 2002
#10? 3 2004-05-21??? 10?? 12 2004
#11? 3 2004-05-22??? 10?? 12 2004
#13? 3 2006-05-24??? 10?? 12 2006


A.K.


Hi All, 

I accidentally posted this in the data.table forum and deleted it to post here. 

I have some telemetry data that spans multiple years (2002 - 2013) with 
multiple individuals per year. I want to subset the telemetry data to 
include only those data points that fall between specific dates which are 
provided in a 2nd data frame. The telemetry df is in the form of: 

DF "A" 

ID ? ? ?Date ? ? ? ? ? ? Depth ?Temp 
1 ? ? ? 2002-05-12 ? ? ? ? ? 10 12 
1 ? ? ? 2002-05-13 ? ? ? ? ? 10 12 
1 ? ? ? 2002-05-14 ? ? ? ? ? 10 12 
1 ? ? ? 2002-05-15 ? ? ? ? ? 10 12 
2 ? ? ? 2002-05-16 ? ? ? ? ? 10 12 
2 ? ? ? 2002-05-17 ? ? ? ? ? 10 12 
2 ? ? ? 2002-05-18 ? ? ? ? ? 10 12 
2 ? ? ? 2002-05-19 ? ? ? ? ? 10 12 
3 ? ? ? 2002-05-20 ? ? ? ? ? 10 12 
3 ? ? ? 2002-05-21 ? ? ? ? ? 10 12 
3 ? ? ? 2002-05-22 ? ? ? ? ? 10 12 
3 ? ? ? 2002-05-23 ? ? ? ? ? 10 12 
3 ? ? ? 2002-05-24 ? ? ? ? ? 10 12 

And the df with the dates I want to use to subset is formatted as follows: 

?DF "B" 

Year ? ? ? Start ? ? ? ? ? ?End 
2002 ? ?2002-05-10 ? ? ?2002-11-01 
2003 ? ?2003-05-11 ? ? ?2003-11-02 
2004 ? ?2004-05-12 ? ? ?2004-11-03 
2005 ? ?2005-05-13 ? ? ?2005-11-04 
2006 ? ?2006-05-14 ? ? ?2006-11-05 

So, I want to say, for each ID in DF A, subset and keep only those data 
points collected on a date that fall between the start and end date for the 
corresponding year from DF B. 

I am unsure if a loop is my best bet, or using plyr (which I am unfamiliar 
with). I am relatively new to R, so this seems a bit above my head. Any help 
is much appreciated. 

Thanks in advance!


From pdalgd at gmail.com  Sun Sep  8 16:39:25 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 8 Sep 2013 16:39:25 +0200
Subject: [R] Use of parantheses to force order of execution
In-Reply-To: <522C8502.5040107@gmail.com>
References: <CAGYnQNSPt7NgqJnDBUi9GO2fxiKAuK_8FtXP9+-oVW-7QW0PSA@mail.gmail.com>
	<522C8502.5040107@gmail.com>
Message-ID: <71376B1D-75A3-4D56-8943-BE40F1C72490@gmail.com>


On Sep 8, 2013, at 16:09 , Duncan Murdoch wrote:

> On 13-09-08 6:46 AM, Ben Harrison wrote:
>> Hello,
>> I wish to create a copy of a data frame, but with missing values replaced
>> with NAs.
>> 
>> I thought I should be able to do it in one step using parentheses to group
>> the statements and force those inside the parens to execute first:
>> 
>> df <- (BWS6[BWS6 < -998] <- NA)
>> 
>> But all this does is assign NA to df, as described in ?"[" for the case
>> with no parens.
>> 
>> Can I do this in some way? It's no great problem of course to have two
>> separate statements, just curious.
> 
> This isn't an order of execution issue.  Your parenthesized assignment modifies BWS6, and that's not what you want to do.

Also, the value of an assignment is always the right hand side, in this case NA.

The canonical way would be --- but There be Tygers There! --- this: 

df <- `[<-`(BWS6, BWS6 < -998, NA)

The "Tygers" are that R sometimes cheats in order to avoid duplication and assumes that `[<-` can destructively modify its argument. So you shouldn't actually do the above.

- Peter D. 

> 
> If you convert BWS6 to a matrix instead of a dataframe, you could use
> 
> res <- ifelse(BWS6 < -998, NA, BWS6)
> 
> but ifelse doesn't work on dataframes in general.  You can do it in one long line with a dataframe using lapply, but it is ugly:
> 
> df <- as.data.frame( lapply(BWS6, function(col) ifelse(col < -998, NA, col)))
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From szehnder at uni-bonn.de  Sun Sep  8 17:00:10 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Sun, 8 Sep 2013 17:00:10 +0200
Subject: [R] Package installation and path.package
Message-ID: <A166BE3A-A67C-4924-BAA0-E353D36F8D37@uni-bonn.de>

Dear R-Users and R-Devels,

I am writing right now my own package that makes use of 'tempfile' and there within with 'path.package'. When I install it, I get the error: Error in path.package("mypackage") : none of the packages are loaded. 

I understand the error, but I would like to have a workaround. How can I give the path to the package I am actually installing without getting this error? 


Best

Simon


From michel.arnaud at cirad.fr  Sun Sep  8 18:22:31 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Sun, 08 Sep 2013 18:22:31 +0200
Subject: [R] to avoid a do loop
Message-ID: <522CA447.60506@cirad.fr>

Hello
I have a large dataframe  (nrow=55000).
This below df1 an extract of the original dataframe

dput(df1)
structure(list(Cat = c(6, 6, 6, 6, 6, 6, 6, 6, 4, 4, 4, 4, 4,
4, 8, 8, 9, 9, 9, 9, 9, 9, 9, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7,
7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
8, 8, 8, 8, 8, 8, 8, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
6, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 2, 2, 2, 2, 2, 6, 7, 7,
7, 7, 7), Ech = c(8, 9, 10, 11, 12, 12, 13, 13, 11, 12, 13, 14,
14, 14, 9, 10, 5, 6, 7, 7, 7, 7, 7, 7, 8, 9, 10, 11, 11, 11,
4, 5, 6, 7, 8, 8, 8, 9, 9, 8, 9, 2, 3, 4, 5, 5, 5, 5, 5, 5, 5,
5, 1, 2, 3, 4, 5, 6, 6, 6, 7, 7, 7, 5, 6, 7, 8, 9, 9, 10, 10,
11, 11, 11, 11, 11, 11, 15, 5, 6, 7, 7, 8, 8, 8, 8, 9, 9, 13,
13, 14, 15, 15, 15, 10, 1, 2, 3, 4, 5)), .Names = c("Cat", "Ech"
), row.names = c("1", "2", "3", "4", "5", "6", "7", "8", "10",
"11", "12", "13", "14", "15", "17", "18", "19", "20", "21", "22",
"23", "24", "25", "27", "28", "29", "30", "31", "32", "33", "35",
"36", "37", "38", "39", "40", "41", "42", "43", "45", "46", "47",
"48", "49", "50", "51", "52", "53", "54", "55", "56", "57", "59",
"60", "61", "62", "63", "64", "65", "66", "67", "68", "69", "71",
"72", "73", "74", "75", "76", "77", "78", "79", "80", "81", "82",
"83", "84", "86", "87", "88", "89", "90", "91", "92", "93", "94",
"95", "96", "98", "99", "100", "101", "102", "103", "105", "106",
"107", "108", "109", "110"), class = "data.frame")

I do not manage to avoid a do loop because very slow
I want to obtain a new dataframe df2 with a new variable CatEch.
CatEch is the paste of the 2 variables Cat and Ech
dput(df2)
structure(list(Cat = c(6, 6, 6, 6, 6, 6, 6, 6, 4, 4, 4, 4, 4,
4, 8, 8, 9, 9, 9, 9, 9, 9, 9, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7,
7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
8, 8, 8, 8, 8, 8, 8, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
6, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 2, 2, 2, 2, 2, 6, 7, 7,
7, 7, 7), Ech = c(8, 9, 10, 11, 12, 12, 13, 13, 11, 12, 13, 14,
14, 14, 9, 10, 5, 6, 7, 7, 7, 7, 7, 7, 8, 9, 10, 11, 11, 11,
4, 5, 6, 7, 8, 8, 8, 9, 9, 8, 9, 2, 3, 4, 5, 5, 5, 5, 5, 5, 5,
5, 1, 2, 3, 4, 5, 6, 6, 6, 7, 7, 7, 5, 6, 7, 8, 9, 9, 10, 10,
11, 11, 11, 11, 11, 11, 15, 5, 6, 7, 7, 8, 8, 8, 8, 9, 9, 13,
13, 14, 15, 15, 15, 10, 1, 2, 3, 4, 5), CatEch = c("6.08", "6.09",
"6.10", "6.11", "6.12", "6.12", "6.13", "6.13", "4.11", "4.12",
"4.13", "4.14", "4.14", "4.14", "8.09", "8.10", "9.05", "9.06",
"9.07", "9.07", "9.07", "9.07", "9.07", "6.07", "6.08", "6.09",
"6.10", "6.11", "6.11", "6.11", "7.04", "7.05", "7.06", "7.07",
"7.08", "7.08", "7.08", "7.09", "7.09", "7.08", "7.09", "8.02",
"8.03", "8.04", "8.05", "8.05", "8.05", "8.05", "8.05", "8.05",
"8.05", "8.05", "8.01", "8.02", "8.03", "8.04", "8.05", "8.06",
"8.06", "8.06", "8.07", "8.07", "8.07", "6.05", "6.06", "6.07",
"6.08", "6.09", "6.09", "6.10", "6.10", "6.11", "6.11", "6.11",
"6.11", "6.11", "6.11", "7.15", "8.05", "8.06", "8.07", "8.07",
"8.08", "8.08", "8.08", "8.08", "8.09", "8.09", "2.13", "2.13",
"2.14", "2.15", "2.15", "2.15", "6.10", "7.01", "7.02", "7.03",
"7.04", "7.05")), .Names = c("Cat", "Ech", "CatEch"), row.names = c("1",
"2", "3", "4", "5", "6", "7", "8", "10", "11", "12", "13", "14",
"15", "17", "18", "19", "20", "21", "22", "23", "24", "25", "27",
"28", "29", "30", "31", "32", "33", "35", "36", "37", "38", "39",
"40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "51",
"52", "53", "54", "55", "56", "57", "59", "60", "61", "62", "63",
"64", "65", "66", "67", "68", "69", "71", "72", "73", "74", "75",
"76", "77", "78", "79", "80", "81", "82", "83", "84", "86", "87",
"88", "89", "90", "91", "92", "93", "94", "95", "96", "98", "99",
"100", "101", "102", "103", "105", "106", "107", "108", "109",
"110"), class = "data.frame")
Any idea ?

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From smartpink111 at yahoo.com  Sun Sep  8 18:33:06 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 8 Sep 2013 09:33:06 -0700 (PDT)
Subject: [R] to avoid a do loop
In-Reply-To: <522CA447.60506@cirad.fr>
References: <522CA447.60506@cirad.fr>
Message-ID: <1378657986.73141.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
Try:
df1$CatEch<-paste0(df1[,1],".",sprintf("%02d",df1[,2]))
?identical(df1,df2)
#[1] TRUE
A.K.



----- Original Message -----
From: Arnaud Michel <michel.arnaud at cirad.fr>
To: R help <r-help at r-project.org>
Cc: 
Sent: Sunday, September 8, 2013 12:22 PM
Subject: [R] to avoid a do loop

Hello
I have a large dataframe? (nrow=55000).
This below df1 an extract of the original dataframe

dput(df1)
structure(list(Cat = c(6, 6, 6, 6, 6, 6, 6, 6, 4, 4, 4, 4, 4,
4, 8, 8, 9, 9, 9, 9, 9, 9, 9, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7,
7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
8, 8, 8, 8, 8, 8, 8, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
6, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 2, 2, 2, 2, 2, 6, 7, 7,
7, 7, 7), Ech = c(8, 9, 10, 11, 12, 12, 13, 13, 11, 12, 13, 14,
14, 14, 9, 10, 5, 6, 7, 7, 7, 7, 7, 7, 8, 9, 10, 11, 11, 11,
4, 5, 6, 7, 8, 8, 8, 9, 9, 8, 9, 2, 3, 4, 5, 5, 5, 5, 5, 5, 5,
5, 1, 2, 3, 4, 5, 6, 6, 6, 7, 7, 7, 5, 6, 7, 8, 9, 9, 10, 10,
11, 11, 11, 11, 11, 11, 15, 5, 6, 7, 7, 8, 8, 8, 8, 9, 9, 13,
13, 14, 15, 15, 15, 10, 1, 2, 3, 4, 5)), .Names = c("Cat", "Ech"
), row.names = c("1", "2", "3", "4", "5", "6", "7", "8", "10",
"11", "12", "13", "14", "15", "17", "18", "19", "20", "21", "22",
"23", "24", "25", "27", "28", "29", "30", "31", "32", "33", "35",
"36", "37", "38", "39", "40", "41", "42", "43", "45", "46", "47",
"48", "49", "50", "51", "52", "53", "54", "55", "56", "57", "59",
"60", "61", "62", "63", "64", "65", "66", "67", "68", "69", "71",
"72", "73", "74", "75", "76", "77", "78", "79", "80", "81", "82",
"83", "84", "86", "87", "88", "89", "90", "91", "92", "93", "94",
"95", "96", "98", "99", "100", "101", "102", "103", "105", "106",
"107", "108", "109", "110"), class = "data.frame")

I do not manage to avoid a do loop because very slow
I want to obtain a new dataframe df2 with a new variable CatEch.
CatEch is the paste of the 2 variables Cat and Ech
dput(df2)
structure(list(Cat = c(6, 6, 6, 6, 6, 6, 6, 6, 4, 4, 4, 4, 4,
4, 8, 8, 9, 9, 9, 9, 9, 9, 9, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7,
7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
8, 8, 8, 8, 8, 8, 8, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
6, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 2, 2, 2, 2, 2, 6, 7, 7,
7, 7, 7), Ech = c(8, 9, 10, 11, 12, 12, 13, 13, 11, 12, 13, 14,
14, 14, 9, 10, 5, 6, 7, 7, 7, 7, 7, 7, 8, 9, 10, 11, 11, 11,
4, 5, 6, 7, 8, 8, 8, 9, 9, 8, 9, 2, 3, 4, 5, 5, 5, 5, 5, 5, 5,
5, 1, 2, 3, 4, 5, 6, 6, 6, 7, 7, 7, 5, 6, 7, 8, 9, 9, 10, 10,
11, 11, 11, 11, 11, 11, 15, 5, 6, 7, 7, 8, 8, 8, 8, 9, 9, 13,
13, 14, 15, 15, 15, 10, 1, 2, 3, 4, 5), CatEch = c("6.08", "6.09",
"6.10", "6.11", "6.12", "6.12", "6.13", "6.13", "4.11", "4.12",
"4.13", "4.14", "4.14", "4.14", "8.09", "8.10", "9.05", "9.06",
"9.07", "9.07", "9.07", "9.07", "9.07", "6.07", "6.08", "6.09",
"6.10", "6.11", "6.11", "6.11", "7.04", "7.05", "7.06", "7.07",
"7.08", "7.08", "7.08", "7.09", "7.09", "7.08", "7.09", "8.02",
"8.03", "8.04", "8.05", "8.05", "8.05", "8.05", "8.05", "8.05",
"8.05", "8.05", "8.01", "8.02", "8.03", "8.04", "8.05", "8.06",
"8.06", "8.06", "8.07", "8.07", "8.07", "6.05", "6.06", "6.07",
"6.08", "6.09", "6.09", "6.10", "6.10", "6.11", "6.11", "6.11",
"6.11", "6.11", "6.11", "7.15", "8.05", "8.06", "8.07", "8.07",
"8.08", "8.08", "8.08", "8.08", "8.09", "8.09", "2.13", "2.13",
"2.14", "2.15", "2.15", "2.15", "6.10", "7.01", "7.02", "7.03",
"7.04", "7.05")), .Names = c("Cat", "Ech", "CatEch"), row.names = c("1",
"2", "3", "4", "5", "6", "7", "8", "10", "11", "12", "13", "14",
"15", "17", "18", "19", "20", "21", "22", "23", "24", "25", "27",
"28", "29", "30", "31", "32", "33", "35", "36", "37", "38", "39",
"40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "51",
"52", "53", "54", "55", "56", "57", "59", "60", "61", "62", "63",
"64", "65", "66", "67", "68", "69", "71", "72", "73", "74", "75",
"76", "77", "78", "79", "80", "81", "82", "83", "84", "86", "87",
"88", "89", "90", "91", "92", "93", "94", "95", "96", "98", "99",
"100", "101", "102", "103", "105", "106", "107", "108", "109",
"110"), class = "data.frame")
Any idea ?

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Sun Sep  8 18:39:13 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 08 Sep 2013 17:39:13 +0100
Subject: [R] to avoid a do loop
In-Reply-To: <522CA447.60506@cirad.fr>
References: <522CA447.60506@cirad.fr>
Message-ID: <522CA831.4000506@sapo.pt>

Hello,

Try the following.


df3 <- df1
df3$CatEch <- paste(df1$Cat, sprintf("%02d", df1$Ech), sep = ".")

identical(df2, df3)  # TRUE


Hope this helps,

Rui Barradas

Em 08-09-2013 17:22, Arnaud Michel escreveu:
> Hello
> I have a large dataframe  (nrow=55000).
> This below df1 an extract of the original dataframe
>
> dput(df1)
> structure(list(Cat = c(6, 6, 6, 6, 6, 6, 6, 6, 4, 4, 4, 4, 4,
> 4, 8, 8, 9, 9, 9, 9, 9, 9, 9, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7,
> 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
> 8, 8, 8, 8, 8, 8, 8, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
> 6, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 2, 2, 2, 2, 2, 6, 7, 7,
> 7, 7, 7), Ech = c(8, 9, 10, 11, 12, 12, 13, 13, 11, 12, 13, 14,
> 14, 14, 9, 10, 5, 6, 7, 7, 7, 7, 7, 7, 8, 9, 10, 11, 11, 11,
> 4, 5, 6, 7, 8, 8, 8, 9, 9, 8, 9, 2, 3, 4, 5, 5, 5, 5, 5, 5, 5,
> 5, 1, 2, 3, 4, 5, 6, 6, 6, 7, 7, 7, 5, 6, 7, 8, 9, 9, 10, 10,
> 11, 11, 11, 11, 11, 11, 15, 5, 6, 7, 7, 8, 8, 8, 8, 9, 9, 13,
> 13, 14, 15, 15, 15, 10, 1, 2, 3, 4, 5)), .Names = c("Cat", "Ech"
> ), row.names = c("1", "2", "3", "4", "5", "6", "7", "8", "10",
> "11", "12", "13", "14", "15", "17", "18", "19", "20", "21", "22",
> "23", "24", "25", "27", "28", "29", "30", "31", "32", "33", "35",
> "36", "37", "38", "39", "40", "41", "42", "43", "45", "46", "47",
> "48", "49", "50", "51", "52", "53", "54", "55", "56", "57", "59",
> "60", "61", "62", "63", "64", "65", "66", "67", "68", "69", "71",
> "72", "73", "74", "75", "76", "77", "78", "79", "80", "81", "82",
> "83", "84", "86", "87", "88", "89", "90", "91", "92", "93", "94",
> "95", "96", "98", "99", "100", "101", "102", "103", "105", "106",
> "107", "108", "109", "110"), class = "data.frame")
>
> I do not manage to avoid a do loop because very slow
> I want to obtain a new dataframe df2 with a new variable CatEch.
> CatEch is the paste of the 2 variables Cat and Ech
> dput(df2)
> structure(list(Cat = c(6, 6, 6, 6, 6, 6, 6, 6, 4, 4, 4, 4, 4,
> 4, 8, 8, 9, 9, 9, 9, 9, 9, 9, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7,
> 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
> 8, 8, 8, 8, 8, 8, 8, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
> 6, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 2, 2, 2, 2, 2, 6, 7, 7,
> 7, 7, 7), Ech = c(8, 9, 10, 11, 12, 12, 13, 13, 11, 12, 13, 14,
> 14, 14, 9, 10, 5, 6, 7, 7, 7, 7, 7, 7, 8, 9, 10, 11, 11, 11,
> 4, 5, 6, 7, 8, 8, 8, 9, 9, 8, 9, 2, 3, 4, 5, 5, 5, 5, 5, 5, 5,
> 5, 1, 2, 3, 4, 5, 6, 6, 6, 7, 7, 7, 5, 6, 7, 8, 9, 9, 10, 10,
> 11, 11, 11, 11, 11, 11, 15, 5, 6, 7, 7, 8, 8, 8, 8, 9, 9, 13,
> 13, 14, 15, 15, 15, 10, 1, 2, 3, 4, 5), CatEch = c("6.08", "6.09",
> "6.10", "6.11", "6.12", "6.12", "6.13", "6.13", "4.11", "4.12",
> "4.13", "4.14", "4.14", "4.14", "8.09", "8.10", "9.05", "9.06",
> "9.07", "9.07", "9.07", "9.07", "9.07", "6.07", "6.08", "6.09",
> "6.10", "6.11", "6.11", "6.11", "7.04", "7.05", "7.06", "7.07",
> "7.08", "7.08", "7.08", "7.09", "7.09", "7.08", "7.09", "8.02",
> "8.03", "8.04", "8.05", "8.05", "8.05", "8.05", "8.05", "8.05",
> "8.05", "8.05", "8.01", "8.02", "8.03", "8.04", "8.05", "8.06",
> "8.06", "8.06", "8.07", "8.07", "8.07", "6.05", "6.06", "6.07",
> "6.08", "6.09", "6.09", "6.10", "6.10", "6.11", "6.11", "6.11",
> "6.11", "6.11", "6.11", "7.15", "8.05", "8.06", "8.07", "8.07",
> "8.08", "8.08", "8.08", "8.08", "8.09", "8.09", "2.13", "2.13",
> "2.14", "2.15", "2.15", "2.15", "6.10", "7.01", "7.02", "7.03",
> "7.04", "7.05")), .Names = c("Cat", "Ech", "CatEch"), row.names = c("1",
> "2", "3", "4", "5", "6", "7", "8", "10", "11", "12", "13", "14",
> "15", "17", "18", "19", "20", "21", "22", "23", "24", "25", "27",
> "28", "29", "30", "31", "32", "33", "35", "36", "37", "38", "39",
> "40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "51",
> "52", "53", "54", "55", "56", "57", "59", "60", "61", "62", "63",
> "64", "65", "66", "67", "68", "69", "71", "72", "73", "74", "75",
> "76", "77", "78", "79", "80", "81", "82", "83", "84", "86", "87",
> "88", "89", "90", "91", "92", "93", "94", "95", "96", "98", "99",
> "100", "101", "102", "103", "105", "106", "107", "108", "109",
> "110"), class = "data.frame")
> Any idea ?
>


From renaud.lancelot at gmail.com  Sun Sep  8 18:41:10 2013
From: renaud.lancelot at gmail.com (Renaud Lancelot)
Date: Sun, 8 Sep 2013 18:41:10 +0200
Subject: [R] to avoid a do loop
In-Reply-To: <522CA447.60506@cirad.fr>
References: <522CA447.60506@cirad.fr>
Message-ID: <CADobZH+U6TgsJVQRRAqypJPrFhE_PxR9A_+BBVmF4vrZZckHJA@mail.gmail.com>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
URL : <https://stat.ethz.ch/pipermail/r-help/attachments/20130908/cefdb338/attachment.pl>

From michel.arnaud at cirad.fr  Sun Sep  8 19:15:30 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Sun, 08 Sep 2013 19:15:30 +0200
Subject: [R] to avoid a do loop
In-Reply-To: <CADobZH+U6TgsJVQRRAqypJPrFhE_PxR9A_+BBVmF4vrZZckHJA@mail.gmail.com>
References: <522CA447.60506@cirad.fr>
	<CADobZH+U6TgsJVQRRAqypJPrFhE_PxR9A_+BBVmF4vrZZckHJA@mail.gmail.com>
Message-ID: <522CB0B2.1020409@cirad.fr>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
URL : <https://stat.ethz.ch/pipermail/r-help/attachments/20130908/8f9d14d4/attachment.pl>

From ektaj.1jain at gmail.com  Sun Sep  8 19:27:55 2013
From: ektaj.1jain at gmail.com (Ekta Jain)
Date: Sun, 8 Sep 2013 22:57:55 +0530
Subject: [R] CHAID Analysis in R
Message-ID: <CAAgBEozCOXBnFZXdGqrQvQa--8CRSn86K2njdK0qkR_kM4J31A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130908/b08960d5/attachment.pl>

From rhodeearly at yahoo.fr  Sun Sep  8 19:08:09 2013
From: rhodeearly at yahoo.fr (Rhode Early CHARLES)
Date: Sun, 8 Sep 2013 18:08:09 +0100 (BST)
Subject: [R] Need Help
Message-ID: <1378660089.96844.YahooMailNeo@web171206.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130908/18666fcf/attachment.pl>

From walt at dataanalyticscorp.com  Sun Sep  8 18:54:31 2013
From: walt at dataanalyticscorp.com (Data Analytics Corp.)
Date: Sun, 08 Sep 2013 12:54:31 -0400
Subject: [R] melting a data frame
In-Reply-To: <web-472904387@cgpsrv2.cis.mcmaster.ca>
References: <522BEFF5.40903@dataanalyticscorp.com>
	<1378646982.64577.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<web-472904387@cgpsrv2.cis.mcmaster.ca>
Message-ID: <522CABC7.9010504@dataanalyticscorp.com>

Hi,

I received several really good suggestions, but the feeling seems to be 
to use a for loop.  I did this at first, but my curiosity took over -- 
hence, my question.  The loop, coupled with a list of relevant columns, 
seems best.

Thanks all,

Walt

________________________

Walter R. Paczkowski, Ph.D.
Data Analytics Corp.
44 Hamilton Lane
Plainsboro, NJ 08536
________________________
(V) 609-936-8999
(F) 609-936-3733
walt at dataanalyticscorp.com
www.dataanalyticscorp.com
_____________________________________________________


On 9/8/2013 10:06 AM, John Fox wrote:
> Dear Walt and A.K.,
>
> One shouldn't reflexively avoid loops in R. In this case, it seems to me clearer to use a loop, and it's no less "efficient" (especially, I would guess, when one takes into account the time to figure out how to do the computation). I get
>
>> system.time({
> + res<-do.call(rbind,lapply(split(colnames(dat1),((seq_len(ncol(dat1))-1)%/%21)+1),function(x) {x1<- dat1[,x]; colnames(x1)<- paste("V",1:21);x1}))
> + row.names(res)<- 1:nrow(res)
> + })
>     user  system elapsed
>     0.02    0.00    0.02
>> dim(res)
> [1] 1170   21
>
>
>> system.time({
> + res2 <- as.data.frame(matrix(0, 1170, 21))
> + for (i in 1:9){
> +     res2[((i - 1)*130 + 1):(i*130), ] <- dat1[, ((i - 1)*21 + 1):(i*21)]
> + }
> + })
>     user  system elapsed
>     0.02    0.00    0.01
>> dim(res2)
> [1] 1170   21
>
>> all(res == res2)
> [1] TRUE
>
> Best,
>   John
>
> On Sun, 8 Sep 2013 06:29:42 -0700 (PDT)
>   arun <smartpink111 at yahoo.com> wrote:
>>
>> Hi,
>>
>> You could try:
>> set.seed(48)
>> dat1<- as.data.frame(matrix(sample(1:40,189*130,replace=TRUE),ncol=189))
>> res<-do.call(rbind,lapply(split(colnames(dat1),((seq_len(ncol(dat1))-1)%/%21)+1),function(x) {x1<- dat1[,x]; colnames(x1)<- paste("V",1:21);x1}))
>>   row.names(res)<- 1:nrow(res)
>>   dim(res)
>> #[1] 1170   21
>> A.K.
>>
>>
>>
>> ----- Original Message -----
>> From: Data Analytics Corp. <walt at dataanalyticscorp.com>
>> To: R help <r-help at r-project.org>
>> Cc:
>> Sent: Saturday, September 7, 2013 11:33 PM
>> Subject: [R] melting a data frame
>>
>> Hi,
>>
>> Suppose I have a data frame with 189 columns.  The columns are actually 9 blocks of 21 columns each, each block representing measures on each of 9 products.  There are 130 rows.  Suppose I extract the first block of 21 columns and make them into a separate data frame.  I then want to take the second block of 21 columns and rbind it to the first; then the third set of 21 and rbind it to the first two; etc.  The final data frame should have 1170 (= 9 * 130)  rows and 21 columns.  Is there an easy way to melt the blocks comparable to using the melt function in the plyr package (which is why I'm referring to what I want to do as "melting")?  It seems that there should be a simple way to do this.  I used a for loop which worked, but I want to see if there's a more efficient way.
>>
>> Thanks,
>>
>> Walt
>>
>> ________________________
>>
>> Walter R. Paczkowski, Ph.D.
>> Data Analytics Corp.
>> 44 Hamilton Lane
>> Plainsboro, NJ 08536
>> ________________________
>> (V) 609-936-8999
>> (F) 609-936-3733
>> walt at dataanalyticscorp.com
>> www.dataanalyticscorp.com
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ------------------------------------------------
> John Fox
> McMaster University
> Hamilton, Ontario, Canada
> http://socserv.mcmaster.ca/jfox/
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From michel.arnaud at cirad.fr  Sun Sep  8 20:50:16 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Sun, 08 Sep 2013 20:50:16 +0200
Subject: [R] to avoid a do loop
In-Reply-To: <522CB0B2.1020409@cirad.fr>
References: <522CA447.60506@cirad.fr>
	<CADobZH+U6TgsJVQRRAqypJPrFhE_PxR9A_+BBVmF4vrZZckHJA@mail.gmail.com>
	<522CB0B2.1020409@cirad.fr>
Message-ID: <522CC6E8.7000004@cirad.fr>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
URL : <https://stat.ethz.ch/pipermail/r-help/attachments/20130908/f9b0a31a/attachment.pl>

From narillosdesantos at gmail.com  Sun Sep  8 21:42:40 2013
From: narillosdesantos at gmail.com (Jose Narillos de Santos)
Date: Sun, 8 Sep 2013 21:42:40 +0200
Subject: [R] ADF test
Message-ID: <CAAk9BOTbbP1_Rd6nogi0hSwc7gmJXvTut8V_qG9B4+UUTJuEMg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: no disponible
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130908/b24e66ef/attachment.pl>

From Achim.Zeileis at uibk.ac.at  Sun Sep  8 21:50:29 2013
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Sun, 8 Sep 2013 21:50:29 +0200 (CEST)
Subject: [R] CHAID Analysis in R
In-Reply-To: <CAAgBEozCOXBnFZXdGqrQvQa--8CRSn86K2njdK0qkR_kM4J31A@mail.gmail.com>
References: <CAAgBEozCOXBnFZXdGqrQvQa--8CRSn86K2njdK0qkR_kM4J31A@mail.gmail.com>
Message-ID: <alpine.DEB.2.10.1309082147580.4402@paninaro.uibk.ac.at>

On Sun, 8 Sep 2013, Ekta Jain wrote:

> Dear all,
> I have been researching on whether there is a package in R that can do
> CHAID analysis. The CHAID package in R-Forge is not available for windows
> and thus wondering if at all there is something equivalent in R?

I have just triggered a rebuild on R-Forge. So hopefully the Windows 
binary should also be available again in a couple of days.

If not, the simplest thing is to install the Rtools for Windows and then 
install the package from source: install.packages("CHAID", repos = 
"http://R-Forge.R-project.org", type = "source")


> Many Thanks,
> Ekta
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From pdalgd at gmail.com  Sun Sep  8 22:04:18 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 8 Sep 2013 22:04:18 +0200
Subject: [R] Need Help
In-Reply-To: <1378660089.96844.YahooMailNeo@web171206.mail.ir2.yahoo.com>
References: <1378660089.96844.YahooMailNeo@web171206.mail.ir2.yahoo.com>
Message-ID: <5D76D6EB-B550-450B-BD53-B449F43E99F4@gmail.com>


On Sep 8, 2013, at 19:08 , Rhode Early CHARLES wrote:

> Good morning
> I am trying to read this file in R.
>  
> Nome AK 2.5 15 Miami FL 6.75
> 18 Raleigh NC . 12
> 
> 
> This what the code is for SAS, I ma trying to di the same in R.
> 
> Input more than one observation from each record;
> DATA rainfall;
> INFILE ?c:\MyRawData\Precipitation.dat?;
> INPUT City $ State $ NormalRain MeanDaysRain @@;
> RUN;
> PROC PRINT DATA = rainfall;
> TITLE ?Normal Total Precipitation and?;
> TITLE2 ?Mean Days with Precipitation for July?;
> RUN;
> 
> Thanks.
> ------A Dieu soit la Gloire--------

scan() is your friend here:

> l <- 
+ scan(text="Nome AK 2.5 15 Miami FL 6.75
+ 18 Raleigh NC . 12
+ ", what=list("","",0,0), multi.line=TRUE, na.strings=".")
Read 3 records
> l
[[1]]
[1] "Nome"    "Miami"   "Raleigh"

[[2]]
[1] "AK" "FL" "NC"

[[3]]
[1] 2.50 6.75   NA

[[4]]
[1] 15 18 12
> names(l) <- c("city","state","normalRain","meanDaysRain")
> as.data.frame(l)
     city state normalRain meanDaysRain
1    Nome    AK       2.50           15
2   Miami    FL       6.75           18
3 Raleigh    NC         NA           12
> 

(or use a named list for the what= argument)

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From smartpink111 at yahoo.com  Mon Sep  9 00:43:09 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 8 Sep 2013 15:43:09 -0700 (PDT)
Subject: [R] Create a new column based on values in two other columns
In-Reply-To: <522B8866.70800@yahoo.com>
References: <522B8866.70800@yahoo.com>
Message-ID: <1378680189.96145.YahooMailNeo@web142605.mail.bf1.yahoo.com>

HI,
df$NewPrices<- unsplit(lapply(split(df,df$Stocks),function(x) {do.call(rbind,lapply(seq_len(nrow(x)),function(i) {if(x[i,]$Offsets==2)
??? ??? ??? ??? ??? ??? ??? ??? ??? ???? x[i+2,]$Prices
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? else if(x[i,]$Offsets==1)
??? ??? ??? ??? ??? ??? ??? ??? ??? ???? x[i+1,]$Prices
??? ??? ??? ??? ??? ??? ??? ??? ??? ???? else x[i,]$Prices
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? })) }),df$Stocks)


?df$NewPrices
#[1] 13 17 12 16 17 18 16 17 18

sqldf(Q2)[,1]
#[1] 13 17 12 16 17 18 16 17 18


I think sqldf() would be faster.


A.K.



----- Original Message -----
From: Ira Sharenow <irasharenow100 at yahoo.com>
To: r-help at r-project.org
Cc: 
Sent: Saturday, September 7, 2013 4:11 PM
Subject: [R] Create a new column based on values in two other columns

I am trying to add a column to a data frame. Each day for each stock I 
make a prediction for a future date. Then I need to compare my 
predictions to the actual values. So looking at the first row of data:

For Stock A on 2011-01-01 I predicted that on 2011-01-02 the price would 
be 10.25.

Now I need an ActualPrices column. The first value should be 13.

I solved the problem using sqldf, but I would appreciate some advice on 
how to solve the problem using standard R techniques. The real data 
frame has over 100,000 rows.

I know that the conditions for the correct row can be found in the WHERE 
clause of the SQL query and then I need to look in the Prices column to 
get the value, but I do not know how to do that in standard R.

If another library would be easier, I am open to other ideas.

Dates = as.Date(c(rep("2011-01-01",3), rep("2011-01-02",3), 
rep("2011-01-03",3) ), "%Y-%m-%d")

Stocks = rep(c("A", "B", "C"), 3)

Offsets = c(1,2,0,1,1,1,0,0,0)

Prices = 10:18

PredPrices = 10:18 + 0.25

df = data.frame(Stocks, Dates, Offsets, Prices, PredPrices )

df$NewDates = df$Dates + df$Offsets

df

StocksDates Offsets Prices PredPricesNewDates

1A 2011-01-0111010.25 2011-01-02

2B 2011-01-0121111.25 2011-01-03

3C 2011-01-0101212.25 2011-01-01

4A 2011-01-0211313.25 2011-01-03

5B 2011-01-0211414.25 2011-01-03

6C 2011-01-0211515.25 2011-01-03

7A 2011-01-0301616.25 2011-01-03

8B 2011-01-0301717.25 2011-01-03

9C 2011-01-0301818.25 2011-01-03

library(sqldf)

# To see everything in this small example

Q1 = "SELECT df1.Stocks, df1.Dates, df1.Offsets, df1.Prices, 
df1.PredPrices, df2.Prices AS NewPrices

FROM df AS df1, df AS df2

WHERE df1.NewDates = df2.Dates AND df1.Stocks = df2.Stocks";

sqldf(Q1)

# To get the column. This what I really want

Q2 = "SELECT df2.Prices AS NewPrices

FROM df AS df1, df AS df2

WHERE df1.NewDates = df2.Dates AND df1.Stocks = df2.Stocks";

sqldf(Q2)

As I will need to reshape my data so that each row is for a specific 
date, a second starting point is this data frame.

dfWide= reshape(df, direction = "wide", idvar = "Dates", timevar = "Stocks")

> dfWide

Dates Offsets.A Prices.A PredPrices.A NewDates.A Offsets.B Prices.B 
PredPrices.B NewDates.B Offsets.C Prices.C PredPrices.C NewDates.C

1 2011-01-0111010.25 2011-01-0221111.25 2011-01-0301212.25 2011-01-01

4 2011-01-0211313.25 2011-01-0311414.25 2011-01-0311515.25 2011-01-03

7 2011-01-0301616.25 2011-01-0301717.25 2011-01-0301818.25 2011-01-03


??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Mon Sep  9 02:59:31 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 8 Sep 2013 17:59:31 -0700 (PDT)
Subject: [R] Subsetting isolating a group of values in a group of
	variables
In-Reply-To: <1378607143.98976.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1378584753.66498.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1378607143.98976.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1378688371.86261.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi Razi,

Using dat1:
dat1[apply(dat1[,2:4],1,function(x) any(x%in% vec1)),]
#? ID diag1 diag2 diag3 proc1 proc2 proc3
#2? 2?? k69?? i80? u456? z456? z123? z456
#3? 3?? l91? i801? g678? u456? u123? u123
#4? 4?? i80?? i90? h983? z123? z456? z456


#similarly, if the columns are from 18:93, change accordingly.

A.K.






Hi, thanks again. 

Just wondering, if you have a data frame dat.1 and you know the 
"diag" codes are in columns from 18:93, is there any way to search for 
the "vec1" codes while specifying the range of columns. 


Best Wishes 

Razi Zaidi 



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Saturday, September 7, 2013 10:25 PM
Subject: Re: Subsetting isolating a group of values in a group of variables

Hi,
Using the same example:
str1<-paste(colnames(dat1)[grepl("diag",colnames(dat1))],"%in%","vec1",collapse="|")
?subset(dat1,eval(parse(text=str1)))
#? ID diag1 diag2 diag3 proc1 proc2 proc3
#2? 2?? k69?? i80? u456? z456? z123? z456
#3? 3?? l91? i801? g678? u456? u123? u123
#4? 4?? i80?? i90? h983? z123? z456? z456
lapply(split(dat2,dat2$diag),function(x) {x1<- x$code; str1<- paste(colnames(dat1)[grepl("diag",colnames(dat1))],"%in%","x1",collapse="|"); x2<- subset(dat1,eval(parse(text=str1))); cbind(x2,Diag=x$diag)})
#$`Broken finger`
#? ID diag1 diag2 diag3 proc1 proc2 proc3????????? Diag
#1? 1?? k23? i269? j123? u123? u456? u123 Broken finger
#2? 2?? k69?? i80? u456? z456? z123? z456 Broken finger
#
#$`Broken foot`
#? ID diag1 diag2 diag3 proc1 proc2 proc3??????? Diag
#1? 1?? k23? i269? j123? u123? u456? u123 Broken foot
#2? 2?? k69?? i80? u456? z456? z123? z456 Broken foot
#
#$`Broken legs`
#? ID diag1 diag2 diag3 proc1 proc2 proc3??????? Diag
#1? 1?? k23? i269? j123? u123? u456? u123 Broken legs
#3? 3?? l91? i801? g678? u456? u123? u123 Broken legs
#
#$`Broken rib`
#? ID diag1 diag2 diag3 proc1 proc2 proc3?????? Diag
#3? 3?? l91? i801? g678? u456? u123? u123 Broken rib
#4? 4?? i80?? i90? h983? z123? z456? z456 Broken rib
#
#$`Broken toe`
#? ID diag1 diag2 diag3 proc1 proc2 proc3?????? Diag
#2? 2?? k69?? i80? u456? z456? z123? z456 Broken toe
#3? 3?? l91? i801? g678? u456? u123? u123 Broken toe
#4? 4?? i80?? i90? h983? z123? z456? z456 Broken toe

##############You can also use a larger dataset:
set.seed(48)
dat1New<- as.data.frame(matrix(sample(paste0(letters,sample(1:800,700,replace=TRUE)),90*1e5,replace=TRUE),ncol=90),stringsAsFactors=FALSE)
set.seed(185)
?dat2New<- as.data.frame(matrix(sample(paste0(letters,sample(400:1200,700,replace=TRUE)),90*1e5,replace=TRUE),ncol=90),stringsAsFactors=FALSE)
?dat3<- cbind(ID=1:1e5,dat1New,dat2New)
colnames(dat3)[-1]<-c(paste0("diag",1:90),paste0("proc",1:90))

set.seed(1459)
Refdat<- data.frame(code=unique(unlist(dat1New)), diag=sample(c("Broken finger","Broken toe", "Broken legs", "Broken foot", "Broken rib", "Broken nose", "Broken elbow", "Broken hip"),length(unique(unlist(dat1New))),replace=TRUE),stringsAsFactors=FALSE)

res<- lapply(split(Refdat,Refdat$diag),function(x) {x1<- x$code; str1<- paste(colnames(dat3)[grepl("diag",colnames(dat3))],"%in%","x1",collapse="|"); x2<- subset(dat3,eval(parse(text=str1))) })

sapply(split(Refdat,Refdat$diag),function(x) {x1<- x$code; str1<- paste(colnames(dat3)[grepl("diag",colnames(dat3))],"%in%","x1",collapse="|"); x2<- subset(dat3,eval(parse(text=str1)));nrow(x2) })
# Broken elbow Broken finger?? Broken foot??? Broken hip?? Broken legs 
?# ????? 99997??????? 100000???????? 99994??????? 100000???????? 99997 
?# Broken nose??? Broken rib??? Broken toe 
? # ???? 99996???????? 99999??????? 100000 


A.K.






Thanks for the prompt reply arun, this really has helped. 

My actual data frame has diagnostic codes diag1, diag2 etc which are range from 1 to 93. Is there any way to apply "subset(dat1,diag1%in%vec1|diag2%in%vec1|diag3%in% vec1)"??such that i can search many multiple columns in dat1 without specifying each column separately? 


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Saturday, September 7, 2013 4:12 PM
Subject: Re: Subsetting isolating a group of values in a group of variables

Hi,

The expected output is not clear.
dat1<- read.table(text="ID diag1 diag2 diag3 proc1 proc2 proc3
1 k23 i269 j123?? u123? u456? u123
2 k69 i80 u456?? z456? z123? z456
3 l91 i801 g678?? u456? u123? u123
4 i80 i90 h983?? z123? z456?? z456",sep="",header=TRUE,stringsAsFactors=FALSE)

vec1<- c("i80","i90","l91")


subset(dat1,diag1%in%vec1|diag2%in%vec1|diag3%in% vec1)
#? ID diag1 diag2 diag3 proc1 proc2 proc3
#2? 2?? k69?? i80? u456? z456? z123? z456
#3? 3?? l91? i801? g678? u456? u123? u123
#4? 4?? i80?? i90? h983? z123? z456? z456


##Creating another data frame with codes and diagnosis

dat2<-data.frame(code=unique(unlist(dat1[,2:4])),diag=c(rep("Broken finger",2),rep("Broken toe",2),rep("Broken legs",2),"Broken toe",rep("Broken foot",2),rep("Broken rib",2)),stringsAsFactors=FALSE)



?lst1<- lapply(split(dat2,dat2$diag), function(x) {x1<- x$code;x2<- subset(dat1,diag1%in%x1|diag2%in%x1|diag3%in%x1);cbind(x2,Diag=x$diag)})
?lst1
#$`Broken finger`
?# ID diag1 diag2 diag3 proc1 proc2 proc3????????? Diag
#1? 1?? k23? i269? j123? u123? u456? u123 Broken finger
#2? 2?? k69?? i80? u456? z456? z123? z456 Broken finger
#
#$`Broken foot`
?# ID diag1 diag2 diag3 proc1 proc2 proc3??????? Diag
#1? 1?? k23? i269? j123? u123? u456? u123 Broken foot
#2? 2?? k69?? i80? u456? z456? z123? z456 Broken foot
#
#$`Broken legs`
?# ID diag1 diag2 diag3 proc1 proc2 proc3??????? Diag
#1? 1?? k23? i269? j123? u123? u456? u123 Broken legs
#3? 3?? l91? i801? g678? u456? u123? u123 Broken legs

#$`Broken rib`
?# ID diag1 diag2 diag3 proc1 proc2 proc3?????? Diag
#3? 3?? l91? i801? g678? u456? u123? u123 Broken rib
#4? 4?? i80?? i90? h983? z123? z456? z456 Broken rib

#$`Broken toe`
#? ID diag1 diag2 diag3 proc1 proc2 proc3?????? Diag
#2? 2?? k69?? i80? u456? z456? z123? z456 Broken toe
#3? 3?? l91? i801? g678? u456? u123? u123 Broken toe
#4? 4?? i80?? i90? h983? z123? z456? z456 Broken toe


A.K.


Hello. 

I have date frame structured like this: 

ID??? diag1 diag2 diag3 proc1 proc2 proc3 
1??? k23??? i269???? j123???? ? u123 ?u456 ?u123 
2??? k69??? i80???? u456 ? z456 ?z123 ?z456 
3??? l91??? i801???? g678 ? u456 ?u123 ?u123 
4??? i80??? i90???? h983 ? z123 ?z456 ? z456 

Each observation has a group of diagnostics codes(diag) and procedure codes(proc). 

A single diagnosis maybe be described by more than one code eg broken toe maybe coded for by i80,i90,l91 or more. 

My aim to subset all rows with any of the codes representing a 
single diagnosis. So i would like to use multiple values (i80,i90,l91= 
broken toe) applied to specific columns, ie diag1,2 and 3 to isolate 
those rows which contain any of the specified codes. 

Your help would be greatly appreciated.


From dwinsemius at comcast.net  Mon Sep  9 03:09:41 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 8 Sep 2013 18:09:41 -0700
Subject: [R] Package installation and path.package
In-Reply-To: <A166BE3A-A67C-4924-BAA0-E353D36F8D37@uni-bonn.de>
References: <A166BE3A-A67C-4924-BAA0-E353D36F8D37@uni-bonn.de>
Message-ID: <5230D0FC-A1BF-4290-87B2-BC5551442820@comcast.net>


On Sep 8, 2013, at 8:00 AM, Simon Zehnder wrote:

> Dear R-Users and R-Devels,
> 
> I am writing right now my own package that makes use of 'tempfile' and there within with 'path.package'. When I install it, I get the error: Error in path.package("mypackage") : none of the packages are loaded. 
> 
> I understand the error, but I would like to have a workaround. How can I give the path to the package I am actually installing without getting this error? 

(We do not have the code so this is speculation.) Your packages should be assumed to be available in one of the directories in .libPaths()

-- 

David Winsemius
Alameda, CA, USA


From harb at student.unimelb.edu.au  Mon Sep  9 04:09:16 2013
From: harb at student.unimelb.edu.au (Ben Harrison)
Date: Mon, 9 Sep 2013 12:09:16 +1000
Subject: [R] Use of parantheses to force order of execution
In-Reply-To: <71376B1D-75A3-4D56-8943-BE40F1C72490@gmail.com>
References: <CAGYnQNSPt7NgqJnDBUi9GO2fxiKAuK_8FtXP9+-oVW-7QW0PSA@mail.gmail.com>
	<522C8502.5040107@gmail.com>
	<71376B1D-75A3-4D56-8943-BE40F1C72490@gmail.com>
Message-ID: <CAGYnQNQ+QY4TBo2cnwyuqFPfzptFvCzuSLVYY-V6gnt-UQ_y_Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130909/76de16c5/attachment.pl>

From ripley at stats.ox.ac.uk  Mon Sep  9 07:58:57 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 09 Sep 2013 06:58:57 +0100
Subject: [R] Package installation and path.package
In-Reply-To: <5230D0FC-A1BF-4290-87B2-BC5551442820@comcast.net>
References: <A166BE3A-A67C-4924-BAA0-E353D36F8D37@uni-bonn.de>
	<5230D0FC-A1BF-4290-87B2-BC5551442820@comcast.net>
Message-ID: <522D63A1.9020806@stats.ox.ac.uk>

On 09/09/2013 02:09, David Winsemius wrote:
>
> On Sep 8, 2013, at 8:00 AM, Simon Zehnder wrote:
>
>> Dear R-Users and R-Devels,
>>
>> I am writing right now my own package that makes use of 'tempfile' and there within with 'path.package'. When I install it, I get the error: Error in path.package("mypackage") : none of the packages are loaded.
>>
>> I understand the error, but I would like to have a workaround. How can I give the path to the package I am actually installing without getting this error?
>
> (We do not have the code so this is speculation.) Your packages should be assumed to be available in one of the directories in .libPaths()
>
Not until the package is fully installed.  We do have no idea what is 
going on here ... and R-devel seems the appropriate list.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From daniel.hornung at ds.mpg.de  Mon Sep  9 08:42:16 2013
From: daniel.hornung at ds.mpg.de (Daniel Hornung)
Date: Mon, 9 Sep 2013 08:42:16 +0200
Subject: [R] xyplot and lwd
In-Reply-To: <CACk-te3uKQrSKRmi6vbZDDS3bK2UEamKEPN2J9GA6fPFdVFmHg@mail.gmail.com>
References: <201309042245.52185.daniel.hornung@ds.mpg.de>
	<201309051352.58758.daniel.hornung@ds.mpg.de>
	<CACk-te3uKQrSKRmi6vbZDDS3bK2UEamKEPN2J9GA6fPFdVFmHg@mail.gmail.com>
Message-ID: <201309090842.20060.daniel.hornung@ds.mpg.de>

On Thursday, September 05, 2013 16:39:14 Bert Gunter wrote:
> Daniel:
> 
> I wondered if that might be what you meant ...
> 
> To amplify a bit on David's response, the answer is that you do **not**
> have separate control over the line width of characters -- lwd controls the
> width of lines in a graph (exactly as it does in base graphics! ), so you
> misunderstood the lwd parameter in the first place. The "cex" parameter
> controls the overall size of plotting characters (and text), so that
> incidentally affects the thickness of lines in character rendering. To get
> different line thicknesses without changing the overall size, you need to
> use different characters, fonts (e.g. bold), or font families, for which
> details can be found on the gpar man page, as David said. Note that some of
> this may also be device and system dependent,

Hello Bert,

I doubt it is this simple: xyplot(rnorm(5) ~ 1:5, pch=4, cex=10) gives huge 
symbols, but their thickness is not affected, most probably because they are 
not implemented as characters.

It is not that important to me personally anymore, I worked around the 
problem.  But still, I would be interested if there is a simple solution.

Cheers,
Daniel

-- 
Max-Planck-Institute for Dynamics and Self-Organization
Laboratory for Fluid Dynamics, Pattern Formation and Biocomplexity
Biomedical Physics Group

Am Fassberg 17
D-37077 Goettingen

(+49) 551 5176 373
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 836 bytes
Desc: This is a digitally signed message part.
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130909/4f6a554f/attachment.bin>

From rhodeearly at yahoo.fr  Mon Sep  9 04:22:58 2013
From: rhodeearly at yahoo.fr (Rhode Early CHARLES)
Date: Mon, 9 Sep 2013 03:22:58 +0100 (BST)
Subject: [R] Need help
Message-ID: <1378693378.90905.YahooMailNeo@web171203.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130909/e59661f7/attachment.asc>

From david.chertudi at gmail.com  Mon Sep  9 05:13:15 2013
From: david.chertudi at gmail.com (David Chertudi)
Date: Sun, 8 Sep 2013 20:13:15 -0700
Subject: [R] Mann-Whitney by group
In-Reply-To: <8B4AAC08-5E1C-40A2-AE9D-A554B2545625@gmail.com>
References: <37A3F822-30EF-42FE-B2BD-01882245E37B@gmail.com>
	<004301cd5b93$70c71db0$52555910$@edu>
	<1341606869728-4635667.post@n4.nabble.com>
	<006401cd5c87$6fc8bfa0$4f5a3ee0$@edu>
	<1341953156748-4636055.post@n4.nabble.com>
	<8B4AAC08-5E1C-40A2-AE9D-A554B2545625@gmail.com>
Message-ID: <CAA2cm79TT_7HHsD6N3RRmUda3qPrp5Pm_QZYyOGCTCcLf6Nzfg@mail.gmail.com>

The time has come to shake the cobwebs off of this analysis.  I have
more data now and need to run the same tests, the same way as above.
My question is this--some of the pairs include NAs, and so are gumming
up the works.  I'm not sure how to exclude them using the lhs ~ rhs
syntax.  Any ideas here?

Many thanks, as usual.  Data and syntax below.

David


sara.data=structure(list(Groups = c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
2L), Pairs = c(1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L), Actb =
c(2.2734065552504,
1.69621901296377, 1.07836251830772, 1.46314001007756, 1.76537848566894,
0.689064098855446, 0.462820758081676, NA, NA, 2.22119254577143
), Bcl2 = c(0.12954440593121, 0.0902306425601895, 0.219044589401239,
0.103793432483774, 0.119463699676088, 0.112179645963861, 0.136910739776212,
0.433953247043377, 0.401539702575691, 0.352218179109105), Bcl6 =
c(1.78964109252879,
1.56011379020288, 0.750029838175481, 1.80189108290585, 1.09372632818505,
0.275815381178548, 0.785680035605173, NA, NA, 0.311865838414934
), Ccl5 = c(0.140676314771846, 0.103227179167928, 0.210718001043218,
0.101548390950462, 0.140625579216236, 0.218846310909471, 0.132902076760262,
0.35763207205821, 0.320733407260836, 0.0983004520984843), Ccr7 =
c(0.116274608274044,
0.0623582657156311, 0.111654418769019, 0.110221412062233, 0.0646423645035265,
0.0924168984762384, 0.0322085814124609, NA, NA, 0.0315246913534493
), Cd27 = c(0.599332581326994, 0.536313800392409, 0.776647646561188,
0.511624999868611, 0.481254858629634, 0.365428233004039, 0.30446734845483,
0.880574935388197, 1.19362122336861, 0.121581553928565), Cd28 =
c(0.8476006082089,
0.976603410250505, 0.976783190446247, 0.8288118647421, 0.854672311976977,
0.576719839424659, 0.4221908111396, 1.22864113852622, 5.19562728663742,
0.401610355554234), Cd40 = c(0.209298226865743, 0.0680133680665235,
0.0233440779283003, 0.191986570448918, 0.128784506152115, NA,
NA, NA, NA, NA)), .Names = c("Groups", "Pairs", "Actb", "Bcl2",
"Bcl6", "Ccl5", "Ccr7", "Cd27", "Cd28", "Cd40"), class = "data.frame",
row.names = c(NA,
-10L))

results=apply(saradata[,4:length(saradata)], 2,
              function(x)

wilcox.test(x~saradata$Groups,paired=TRUE,alternative="two.sided"))

# Extract p-values from saved results
lapply(results, function(x) x[['p.value']])


--
I drink your milkshake.


On Tue, Jul 10, 2012 at 3:13 PM, R. Michael Weylandt
<michael.weylandt at gmail.com> <michael.weylandt at gmail.com> wrote:
> Untested, I think you need to lapply() over thing with some sort of extractor:
>
> lapply(thing, function(x) x[['p.value']])
>
> Michael
>
> On Jul 10, 2012, at 3:45 PM, Oxenstierna <david.chertudi at gmail.com> wrote:
>
>> This works very well--thanks so much.
>>
>> By way of extension:  how would one extract elements from the result object?
>>
>> For example:
>>
>> thing<=apply(Dtb[,3:10], 2, function(x) wilcox.test(x~Dtb$Group))
>>
>> summary(thing)$p.value
>>
>> Does not provide a list of p-values as it would in a regression object.
>> Ideally, I would like to be able to extract the W score and p-value by
>> A,B,C,...
>>
>> Any ideas greatly appreciated!
>>
>>
>> --
>> View this message in context: http://r.789695.n4.nabble.com/Mann-Whitney-by-group-tp4635618p4636055.html
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From kridox at ymail.com  Mon Sep  9 09:38:48 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Mon, 9 Sep 2013 16:38:48 +0900
Subject: [R] Need help
In-Reply-To: <1378693378.90905.YahooMailNeo@web171203.mail.ir2.yahoo.com>
References: <1378693378.90905.YahooMailNeo@web171203.mail.ir2.yahoo.com>
Message-ID: <CAAcyNCyM-9_AupDBdQUfw4=6ZyQaPruckMNRcqwNAgv6ENkB4w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130909/839e2a6f/attachment.pl>

From narillosdesantos at gmail.com  Mon Sep  9 09:41:21 2013
From: narillosdesantos at gmail.com (Jose Narillos de Santos)
Date: Mon, 9 Sep 2013 09:41:21 +0200
Subject: [R] Fwd: ADF test
In-Reply-To: <CAAk9BOTbbP1_Rd6nogi0hSwc7gmJXvTut8V_qG9B4+UUTJuEMg@mail.gmail.com>
References: <CAAk9BOTbbP1_Rd6nogi0hSwc7gmJXvTut8V_qG9B4+UUTJuEMg@mail.gmail.com>
Message-ID: <CAAk9BOTeiZe0T8OHrDG66SXreU9RKAKhdQ2SB3Awej0tmPBnVQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: no disponible
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130909/f880ebf3/attachment.pl>

From cantonfe at mtu.edu  Mon Sep  9 09:48:55 2013
From: cantonfe at mtu.edu (Clara)
Date: Mon, 09 Sep 2013 09:48:55 +0200
Subject: [R] Cannot create summary of old glm object. How to ensure that R
 objects will be usable in the future.
Message-ID: <522D7D67.9010506@mtu.edu>

Hi all,

I have an older, probably about 2 years old glm object, I am not sure 
with which version of glm it was produced. I have tried to 
summary(my.model) but I get an error.

 > summary(my.model)
Error in .Call("binomial_dev_resids", y, mu, wt, PACKAGE = "stats") :
   "binomial_dev_resids" not available for .Call() for package "stats"

Some info about the model:
Call:  glm(formula = my.formula, family = binomial, data = my.data, 
weights = my.weights,
     x = T, y = T)

My current r version and platform:
R version 3.0.1 (2013-05-16) -- "Good Sport"
Platform: x86_64-pc-linux-gnu (64-bit)

I have used my.model before, about a year ago, without any problems. So 
my questions are,
(1) Is there a way to "update" the model so it works with the new 
version of summary.glm? or is there a way to make the new summary.glm 
function agreeable to my.model?
(2) Should I expect this behavior with other older models? I mean, If I 
create a model today should I expect to have problems when I try to do 
simple stuff with it, like "summary", in a couple of years?
(3) Is there a way to prevent this? What would be the best way to make 
sure, as much as possible, that the models I produce today will be 
usable in the future by me and others?

Any help is greatly appreciated. I will run into this problem again, so 
I would very much appreciate any help on how to handle this.
Clara


From szehnder at uni-bonn.de  Mon Sep  9 10:14:26 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Mon, 9 Sep 2013 10:14:26 +0200
Subject: [R] Package installation and path.package
In-Reply-To: <522D63A1.9020806@stats.ox.ac.uk>
References: <A166BE3A-A67C-4924-BAA0-E353D36F8D37@uni-bonn.de>
	<5230D0FC-A1BF-4290-87B2-BC5551442820@comcast.net>
	<522D63A1.9020806@stats.ox.ac.uk>
Message-ID: <974412E3-AC78-4036-B78F-53E86FF25CE3@uni-bonn.de>

I am following your suggestion and move this discussion to the R-devel list. 

Best 

Simon
On Sep 9, 2013, at 7:58 AM, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> On 09/09/2013 02:09, David Winsemius wrote:
>> 
>> On Sep 8, 2013, at 8:00 AM, Simon Zehnder wrote:
>> 
>>> Dear R-Users and R-Devels,
>>> 
>>> I am writing right now my own package that makes use of 'tempfile' and there within with 'path.package'. When I install it, I get the error: Error in path.package("mypackage") : none of the packages are loaded.
>>> 
>>> I understand the error, but I would like to have a workaround. How can I give the path to the package I am actually installing without getting this error?
>> 
>> (We do not have the code so this is speculation.) Your packages should be assumed to be available in one of the directories in .libPaths()
>> 
> Not until the package is fully installed.  We do have no idea what is going on here ... and R-devel seems the appropriate list.
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Mon Sep  9 10:22:13 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 09 Sep 2013 09:22:13 +0100
Subject: [R] Cannot create summary of old glm object. How to ensure that
 R objects will be usable in the future.
In-Reply-To: <522D7D67.9010506@mtu.edu>
References: <522D7D67.9010506@mtu.edu>
Message-ID: <522D8535.3090103@stats.ox.ac.uk>

On 09/09/2013 08:48, Clara wrote:
> Hi all,
>
> I have an older, probably about 2 years old glm object, I am not sure
> with which version of glm it was produced. I have tried to

Before R 3.0.0, which was a change in major version number.

> summary(my.model) but I get an error.
>
>  > summary(my.model)
> Error in .Call("binomial_dev_resids", y, mu, wt, PACKAGE = "stats") :
>    "binomial_dev_resids" not available for .Call() for package "stats"
>
> Some info about the model:
> Call:  glm(formula = my.formula, family = binomial, data = my.data,
> weights = my.weights,
>      x = T, y = T)
>
> My current r version and platform:
> R version 3.0.1 (2013-05-16) -- "Good Sport"
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> I have used my.model before, about a year ago, without any problems. So
> my questions are,
> (1) Is there a way to "update" the model so it works with the new
> version of summary.glm? or is there a way to make the new summary.glm
> function agreeable to my.model?

It is not to do with summary.glm: it is AFAIK due to what is stored in 
'my.model'.  You should re-fit my.model.

In this particular case (which is not reproducible to us) it is possible 
that

my.model$family <- binomial()

would work.

> (2) Should I expect this behavior with other older models? I mean, If I
> create a model today should I expect to have problems when I try to do
> simple stuff with it, like "summary", in a couple of years?

Yes.

> (3) Is there a way to prevent this? What would be the best way to make
> sure, as much as possible, that the models I produce today will be
> usable in the future by me and others?

Not save .RData files and expect them to work with an R with an 
increased major version number.

You should regard .RData files as a permanent form of storage only for 
data (things like data frames).

> Any help is greatly appreciated. I will run into this problem again, so
> I would very much appreciate any help on how to handle this.

Use the version of R you used to create the object my.model to explore it.

And BTW R 3.0.x has been out for several months and I have not seen 
anyone one else reporting such a problem so I think it is much rarer 
than you believe.

> Clara


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From 11050330 at life.hkbu.edu.hk  Mon Sep  9 10:44:43 2013
From: 11050330 at life.hkbu.edu.hk (gaofield)
Date: Mon, 9 Sep 2013 01:44:43 -0700 (PDT)
Subject: [R] regression imputation in R
Message-ID: <1378716283153-4675667.post@n4.nabble.com>

i have a data matrix with some x variables complete and some y variables
incomplete. i want to use the simplest regression imputation to fill in the
missing data. (form a regression line with all complete cases and predict
the missing values). is there any package that can do so? if not how should
i write the code?



--
View this message in context: http://r.789695.n4.nabble.com/regression-imputation-in-R-tp4675667.html
Sent from the R help mailing list archive at Nabble.com.


From ripley at stats.ox.ac.uk  Mon Sep  9 11:07:32 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 09 Sep 2013 10:07:32 +0100
Subject: [R] Cannot create summary of old glm object. How to ensure that
 R objects will be usable in the future.
In-Reply-To: <522D8EA0.1040801@mtu.edu>
References: <522D7D67.9010506@mtu.edu> <522D8535.3090103@stats.ox.ac.uk>
	<522D8EA0.1040801@mtu.edu>
Message-ID: <522D8FD4.2070208@stats.ox.ac.uk>

On 09/09/2013 10:02, Clara wrote:
> Thanks Prof. Ripley,
>
> my.model$family <- binomial() worked
>
> Do you have any suggestions on how to store the models? I used the
> models mostly for projections, so being able to use "predict" would be
> handy. Refitting the model would be an option but it would not ensure
> AFAIK that the resulting model would be the same in all cases.

It should, if you store scripts.  But ultimately to reproduce results 
you need to use the same version of R and of all your packages (and of 
your OS ...).

>
> Clara
>
>
>
>
>
> On 2013-09-09 10:22, Prof Brian Ripley wrote:
>> On 09/09/2013 08:48, Clara wrote:
>>> my.model$family <- binomial()
>>> Hi all,
>>>
>>> I have an older, probably about 2 years old glm object, I am not sure
>>> with which version of glm it was produced. I have tried to
>>
>> Before R 3.0.0, which was a change in major version number.
>>
>>> summary(my.model) but I get an error.
>>>
>>>  > summary(my.model)
>>> Error in .Call("binomial_dev_resids", y, mu, wt, PACKAGE = "stats") :
>>>    "binomial_dev_resids" not available for .Call() for package "stats"
>>>
>>> Some info about the model:
>>> Call:  glm(formula = my.formula, family = binomial, data = my.data,
>>> weights = my.weights,
>>>      x = T, y = T)
>>>
>>> My current r version and platform:
>>> R version 3.0.1 (2013-05-16) -- "Good Sport"
>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>>
>>> I have used my.model before, about a year ago, without any problems. So
>>> my questions are,
>>> (1) Is there a way to "update" the model so it works with the new
>>> version of summary.glm? or is there a way to make the new summary.glm
>>> function agreeable to my.model?
>>
>> It is not to do with summary.glm: it is AFAIK due to what is stored in
>> 'my.model'.  You should re-fit my.model.
>>
>> In this particular case (which is not reproducible to us) it is
>> possible that
>>
>> my.model$family <- binomial()
>>
>> would work.
>>
>>> (2) Should I expect this behavior with other older models? I mean, If I
>>> create a model today should I expect to have problems when I try to do
>>> simple stuff with it, like "summary", in a couple of years?
>>
>> Yes.
>>
>>> (3) Is there a way to prevent this? What would be the best way to make
>>> sure, as much as possible, that the models I produce today will be
>>> usable in the future by me and others?
>>
>> Not save .RData files and expect them to work with an R with an
>> increased major version number.
>>
>> You should regard .RData files as a permanent form of storage only for
>> data (things like data frames).
>>
>>> Any help is greatly appreciated. I will run into this problem again, so
>>> I would very much appreciate any help on how to handle this.
>>
>> Use the version of R you used to create the object my.model to explore
>> it.
>>
>> And BTW R 3.0.x has been out for several months and I have not seen
>> anyone one else reporting such a problem so I think it is much rarer
>> than you believe.
>>
>>> Clara
>>
>>
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From carlos.nasher at googlemail.com  Mon Sep  9 11:50:21 2013
From: carlos.nasher at googlemail.com (Carlos Nasher)
Date: Mon, 9 Sep 2013 11:50:21 +0200
Subject: [R] [dfoptim] 'Error in fn(ginv(par),
	...) : object 'alpha' not found'
In-Reply-To: <6E4A7F6A-C1E7-4582-9A42-A5A8BB8CD320@uni-bonn.de>
References: <CAP=BVWOTjnLwBSAfa6XtN_CeT=pHymGbYeLF+qZB4v=6jZ+z1A@mail.gmail.com>
	<6E4A7F6A-C1E7-4582-9A42-A5A8BB8CD320@uni-bonn.de>
Message-ID: <CAP=BVWPYRTNr492rfEpMeFKUEsFA=S77-EYMvdR9xkVzUy_9dg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130909/f2eac9c2/attachment.pl>

From markleeds2 at gmail.com  Mon Sep  9 13:00:17 2013
From: markleeds2 at gmail.com (Mark Leeds)
Date: Mon, 9 Sep 2013 07:00:17 -0400
Subject: [R] Fwd: ADF test
In-Reply-To: <CAAk9BOTeiZe0T8OHrDG66SXreU9RKAKhdQ2SB3Awej0tmPBnVQ@mail.gmail.com>
References: <CAAk9BOTbbP1_Rd6nogi0hSwc7gmJXvTut8V_qG9B4+UUTJuEMg@mail.gmail.com>
	<CAAk9BOTeiZe0T8OHrDG66SXreU9RKAKhdQ2SB3Awej0tmPBnVQ@mail.gmail.com>
Message-ID: <CAHz+bWY4kgqHBB66=+b2+Ep954Lp4YwFOe8hTZbJ_f=aY009bg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130909/ea77608c/attachment.pl>

From cantonfe at mtu.edu  Mon Sep  9 11:02:24 2013
From: cantonfe at mtu.edu (Clara)
Date: Mon, 09 Sep 2013 11:02:24 +0200
Subject: [R] Cannot create summary of old glm object. How to ensure that
 R objects will be usable in the future.
In-Reply-To: <522D8535.3090103@stats.ox.ac.uk>
References: <522D7D67.9010506@mtu.edu> <522D8535.3090103@stats.ox.ac.uk>
Message-ID: <522D8EA0.1040801@mtu.edu>

Thanks Prof. Ripley,

my.model$family <- binomial() worked

Do you have any suggestions on how to store the models? I used the 
models mostly for projections, so being able to use "predict" would be 
handy. Refitting the model would be an option but it would not ensure 
AFAIK that the resulting model would be the same in all cases.

Clara





On 2013-09-09 10:22, Prof Brian Ripley wrote:
> On 09/09/2013 08:48, Clara wrote:
>> my.model$family <- binomial()
>> Hi all,
>>
>> I have an older, probably about 2 years old glm object, I am not sure
>> with which version of glm it was produced. I have tried to
>
> Before R 3.0.0, which was a change in major version number.
>
>> summary(my.model) but I get an error.
>>
>>  > summary(my.model)
>> Error in .Call("binomial_dev_resids", y, mu, wt, PACKAGE = "stats") :
>>    "binomial_dev_resids" not available for .Call() for package "stats"
>>
>> Some info about the model:
>> Call:  glm(formula = my.formula, family = binomial, data = my.data,
>> weights = my.weights,
>>      x = T, y = T)
>>
>> My current r version and platform:
>> R version 3.0.1 (2013-05-16) -- "Good Sport"
>> Platform: x86_64-pc-linux-gnu (64-bit)
>>
>> I have used my.model before, about a year ago, without any problems. So
>> my questions are,
>> (1) Is there a way to "update" the model so it works with the new
>> version of summary.glm? or is there a way to make the new summary.glm
>> function agreeable to my.model?
>
> It is not to do with summary.glm: it is AFAIK due to what is stored in 
> 'my.model'.  You should re-fit my.model.
>
> In this particular case (which is not reproducible to us) it is 
> possible that
>
> my.model$family <- binomial()
>
> would work.
>
>> (2) Should I expect this behavior with other older models? I mean, If I
>> create a model today should I expect to have problems when I try to do
>> simple stuff with it, like "summary", in a couple of years?
>
> Yes.
>
>> (3) Is there a way to prevent this? What would be the best way to make
>> sure, as much as possible, that the models I produce today will be
>> usable in the future by me and others?
>
> Not save .RData files and expect them to work with an R with an 
> increased major version number.
>
> You should regard .RData files as a permanent form of storage only for 
> data (things like data frames).
>
>> Any help is greatly appreciated. I will run into this problem again, so
>> I would very much appreciate any help on how to handle this.
>
> Use the version of R you used to create the object my.model to explore 
> it.
>
> And BTW R 3.0.x has been out for several months and I have not seen 
> anyone one else reporting such a problem so I think it is much rarer 
> than you believe.
>
>> Clara
>
>


From alfonso.carfora at uniparthenope.it  Mon Sep  9 15:07:03 2013
From: alfonso.carfora at uniparthenope.it (alfonso.carfora at uniparthenope.it)
Date: Mon, 09 Sep 2013 15:07:03 +0200
Subject: [R] theta parameter - plm package
Message-ID: <20130909150703.49586m05rwqjf65z@webmail.uniparthenope.it>

Hi all,

what indicates the parameter theta in the summary of a random effect  
panel model estimated with the plm function?

example:

data("Produc", package = "plm")
zz <- plm(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp,  
model="random", data = Produc, index = c("state","year"))

summary(zz)

Effects:
                    var  std.dev share
idiosyncratic 0.001454 0.038137 0.175
individual    0.006838 0.082691 0.825

theta:  0.8888

Thanks
Alfonso


From Giovanni_Millo at Generali.com  Mon Sep  9 15:16:40 2013
From: Giovanni_Millo at Generali.com (Millo Giovanni)
Date: Mon, 9 Sep 2013 15:16:40 +0200
Subject: [R] R: theta parameter - plm package
In-Reply-To: <20130909150703.49586m05rwqjf65z@webmail.uniparthenope.it>
References: <20130909150703.49586m05rwqjf65z@webmail.uniparthenope.it>
Message-ID: <D41D66AB93B9E04BBA5378B621FFDACB035C3D55@BEMAILEXPD01.corp.generali.net>

Hello.
Relative importance of individual effects' variance: i.e., the standard quas-demeaning parameter, as in any panel data textbook (e.g. Baltagi, Wooldridge).

Cheers,
Giovanni 

-----Messaggio originale-----
Da: alfonso.carfora at uniparthenope.it [mailto:alfonso.carfora at uniparthenope.it] 
Inviato: luned? 9 settembre 2013 15.07
A: r-help at r-project.org
Cc: Millo Giovanni
Oggetto: theta parameter - plm package

Hi all,

what indicates the parameter theta in the summary of a random effect panel model estimated with the plm function?

example:

data("Produc", package = "plm")
zz <- plm(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp, model="random", data = Produc, index = c("state","year"))

summary(zz)

Effects:
                    var  std.dev share
idiosyncratic 0.001454 0.038137 0.175
individual    0.006838 0.082691 0.825

theta:  0.8888

Thanks
Alfonso






?
Ai sensi del D.Lgs. 196/2003 si precisa che le informazi...{{dropped:12}}


From HDoran at air.org  Mon Sep  9 15:56:47 2013
From: HDoran at air.org (Doran, Harold)
Date: Mon, 9 Sep 2013 13:56:47 +0000
Subject: [R] S3 Methods for Linear Regression
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6862457646D@DC1VEX10MB001.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130909/4a8be324/attachment.pl>

From Thierry.ONKELINX at inbo.be  Mon Sep  9 16:18:04 2013
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 9 Sep 2013 14:18:04 +0000
Subject: [R] S3 Methods for Linear Regression
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD6862457646D@DC1VEX10MB001.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD6862457646D@DC1VEX10MB001.air.org>
Message-ID: <AA818EAD2576BC488B4F623941DA7427CD35347B@inbomail.inbo.be>

Dear Harold,

An easy work-around would be to pass the names of the variables as a character vector.

fm <- lm.eiv(y ~ x1 + x2, dat, ind = c(2,3), semDep = 0, semMat = c("sem1", "sem2"))

And the change your lm.eiv.fit accordingly.

Or you could have a look at the .() function of the plyr package.

ddply(dat, c("sem1", "sem2"), some.function)

is equivalent to

ddply(dat, .(sem1, sem2), some.function)


Best regards,

Thierry
________________________________________
Van: r-help-bounces at r-project.org [r-help-bounces at r-project.org] namens Doran, Harold [HDoran at air.org]
Verzonden: maandag 9 september 2013 15:56
Aan: r-help at r-project.org
Onderwerp: [R] S3 Methods for Linear Regression

I have a function for fitting a type of linear regression and have written methods for it as shown below. I exclude the main lm.eiv.fit function as it is large and I don't think necessary for the reproducible example. But, I can certainly provide if that would be needed.

These methods allow for the normal formula interface with the function and some of the other common methods (e.g., subset). One thing I cannot figure out is how to allow the argument semMat in the function to recognize the variable can also be in the dataframe "dat".

When I call the function as follows everything is just fine.

fm <- lm.eiv(y ~ x1 + x2, dat, ind = c(2,3), semDep = 0, semMat = cbind(dat$sem1, dat$sem2))

However, if I were to use the following instead such that I do not specify that both sem1 and sem2 are in the dataframe 'dat',

fm <- lm.eiv(y ~ x1 + x2, dat, ind = c(2,3), semDep = 0, semMat = cbind(sem1, sem2))
Error in as.matrix(semMat) :
  error in evaluating the argument 'x' in selecting a method for function 'as.matrix': Error in cbind(sem1, sem2) : object 'sem1' not found

How can I resolve this such that the argument semMat will also work with variables in the dataframe 'dat' just as the variables in the formula depend on dat?


lm.eiv <- function(...) UseMethod("lm.eiv")

lm.eiv.default <- function(x, y, ind, semDep, semMat, ...){
                result <- lm.eiv.fit(x, y, ind, semDep, semMat, ...)
                result$call <- match.call()
                class(result) <- "eiv"
                result
}

lm.eiv.formula <- function(formula, data, na.action, subset, ind, semDep, semMat, ...){
                mf <- match.call(expand.dots = FALSE)
    m <- match(c("formula", "data", "na.action", "subset"), names(mf), 0L)
    mf <- mf[c(1L, m)]
    mf$drop.unused.levels <- TRUE
    mf[[1L]] <- as.name("model.frame")
    mf <- eval(mf, parent.frame())
                y <- model.response(mf)
                mt <- attr(mf, "terms")
                x <- model.matrix(mt, mf, contrasts)
                result <- lm.eiv.default(x, y, ind, semDep, semMat, ...)
                result$call <- match.call()
                result$formula <- formula
                result
                }

aa <- lm.eiv.formula(InstructScore_Spring ~ InstructScore_Fall, dat, ind = 2, semDep = 0, semMat = dat$InstructScoreSE_Fall)

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From gunter.berton at gene.com  Mon Sep  9 16:52:32 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 9 Sep 2013 07:52:32 -0700
Subject: [R] S3 Methods for Linear Regression
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427CD35347B@inbomail.inbo.be>
References: <B08B6AF0CF8CA44F81B9983EEBDCD6862457646D@DC1VEX10MB001.air.org>
	<AA818EAD2576BC488B4F623941DA7427CD35347B@inbomail.inbo.be>
Message-ID: <CACk-te0Wx0pWWBjg21R-C3-qf4VJeyR-qC7TKzL9cyhvUUe2Pg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130909/20b77096/attachment.pl>

From r-help at sigg-iten.ch  Mon Sep  9 17:06:48 2013
From: r-help at sigg-iten.ch (Christian Sigg)
Date: Mon, 9 Sep 2013 17:06:48 +0200
Subject: [R] sparse PCA using nsprcomp package
In-Reply-To: <1378424502.93780.YahooMailNeo@web122906.mail.ne1.yahoo.com>
References: <1378370274.8239.YahooMailNeo@web122906.mail.ne1.yahoo.com>
	<1378400566.3566.YahooMailNeo@web122904.mail.ne1.yahoo.com>
	<F45A74BC-D9F5-47AC-85B4-0391F0C6D3CF@sigg-iten.ch>
	<1378424502.93780.YahooMailNeo@web122906.mail.ne1.yahoo.com>
Message-ID: <B3CEEAEB-8F09-4D1F-A54B-A0C40280B680@sigg-iten.ch>

Hi John

> 1). Assume now I can calculate these "adjusted" standard deviation from sparse PCA, should the percent variation explained by each sparse PC be calculated using the sum of all these "adjusted" variance (i.e. square of the "adjusted" standard deviation) as the denominator (then these percent variation explained will always add up to 1 if all sparse PCs are counted, or using the sum of the PC variances estimated by REGULAR PCA as the denominator (then, adding up all PCs may not be equal to 1)?

It depends on what you want to do with this percentage, but to me the second would be more meaningful. A sparse PCA will usually be truncated (fewer than all possible components are computed), and due to the additional constraints on the principal axes you will usually explain less variance than with standard PCA. I would want to know what I lose in a sparse PCA w.r.t. a standard PCA.

Note that you don't actually have to compute the standard PCA if you are only interested in the total variance of the data, i.e. the sum of all variances. The total variance 

1/(n-1)*sum(diag(t(X)%*%X)) 

for the zero-mean data matrix X is invariant to a rotation of the coordinate system and therefore identical to

Z <- X%*%W
1/(n-1)*sum(diag(t(Z)%*%Z)) 

so you can skip computing the PCA rotation matrix W. The fastest way to compute the total variance is probably

1/(n-1)*sum(X^2) 

because all expressions compute the squared Frobenius norm of X. 

If you want to compare variances of individual components, then compute a regular PCA.

I also had a look how the spca function computes the "percentage explained variation". I don't yet entirely understand what is going on, but the results differ from using the "asdev" function I mentioned in my previous reply. Keep that in mind if you want to compare nsprcomp to spca.

> 2). How do you choose the 2 important parameters in nsprcomp(), ncomp and k? If for example, my regular PCA showed that I need 20 PCs to account for 80% of the variation in my dataset, does it mean I should set ncomp=20? And then what about any rules setting the value of "k"?

I don't have any hard answers for this question. 

There are a number of heuristics for choosing the number of components in regular PCA (e.g. the PCA book by Jolliffe presents several), and some of them should translate to sparse PCA. If you think that 20 PCs or 80% explained variance works well for regular PCA, I suggest also using 20 components in sparse PCA, then measure the explained variance and then increase the number of components (if necessary) to again achieve 80% explained variance.

Same for setting the cardinality parameter k. You could use a criterion such as BIC to optimize the trade-off between model fidelity and complexity, but I don't have any experience how well this works in practice. What I did so far was to check for loadings with small magnitudes. I set k such that all loadings have "substantial" magnitudes.

In the end what matters is what follows after running the algorithm. Are you directly interpreting the sparse PCA result, or is this an intermediate step in a complete data processing pipeline with a measurable goal? If the latter, choose the algortihm parameters that give you the best results at the end of the pipeline.

> 3). Would you recommend nscumcomp() or nsprcomp() in general?

It depends whether you want to perform a sequential or cumulative analysis of your data. If you want maximum variance in the first (second, third, ...) PC, and specify the precise cardinality of each principal axis, then use nsprcomp. If instead you want to only specify the total cardinality of all loadings and leave the distribution of non-zero loadings to the algorithm, use nscumcomp.

There will be substantial improvements to nscumcomp in the next release, if you want to use it I suggest you wait until then.

Regards
Christian

From joao.fadista at med.lu.se  Mon Sep  9 17:25:07 2013
From: joao.fadista at med.lu.se (Joao Fadista)
Date: Mon, 9 Sep 2013 15:25:07 +0000
Subject: [R] longitudinal GWAS analysis
Message-ID: <F904320E6997EB47A7A04A9661D6CF6D4CE178EA@UWMBX03.uw.lu.se>

Dear all,

I would like to know if there is any R package that can deal with longitudinal GWAS analysis. Briefly, I have phenotypic data for some individuals (measured at different time points; not necessarily the same number of measures, so one individual can have 2 measures over time, while another might have 5). Then I want to analyze if that phenotype changes differently with time depending on the SNP genotype that I am testing. Thanks in advance.

Cheers,
Jo?o


From panagiotis.isigonis at gmail.com  Mon Sep  9 13:05:27 2013
From: panagiotis.isigonis at gmail.com (Panagiotis Isigonis)
Date: Mon, 09 Sep 2013 13:05:27 +0200
Subject: [R] Jcheck error - Any ideas?
In-Reply-To: <522A5054.2080105@gmail.com>
References: <522A5054.2080105@gmail.com>
Message-ID: <522DAB77.80005@gmail.com>

Dear all,

I am facing a problem with running a script that i have written in R and i hope
you can help me spot which exactly is the problem and how i can solve it.

The error I get is the following:
----
Error in .jcheck(silent = FALSE) :
   Java Exception <no description because toString() failed>.jcall(row[[ir]],

"Lorg/apache/poi/ss/usermodel/Cell;", "createCell", as.integer(colIndex[ic] -
1))<S4 object of

class "jobjRef">
----

As I am not a programmer, i don't really understand the error message. I did a
search to try to understand what is wrong and if i am correct the problem is
related with the 'rjava' package. I am not using directly this package but i am
using the 'xlsx' package that is calling the 'rjava' one.

I have made a search on the available resources online for tips/solutions.
I found some similar errors on these reports:
http://r.789695.n4.nabble.com/Java-Exception-error-while-reading-large-data-in-R-from-DB-using-RJDBC-td4647844.html
but it is not really similar with my problem, as i don't read any data online.
On
http://stackoverflow.com/questions/12476044/r-how-to-clear-memory-used-by-rjava
the problem seems similar but there is no reply.

Since it mentions a memory problem, based on this post
http://www.bramschoenmakers.nl/en/node/726 i tried to change the available java
memory by using
> options(java.parameters = "-Xmx4g" )
It didn't work out. (Possibly is not related, but i had to try something).

I would like to point out that i am loading to the script an excel file (through
xlsx), making some calculations with the use of 'data.table' and 'sqldf'
packages and then writing the results to a new excel file. We have tested the
script with a file of 3120 lines and it works without any problem but when i try
to run the script and load the excel file of interest that has 47000 lines, i
get the error that i reported above.

I would be more than grateful if anyone can help me on this.
I am running R on Windows 7, with R version 3.0.1 and Java 7 update 10, all 64-bit.

Thank you very much in advance,
Panos

-- 
Panagiotis Isigonis

PhD student
Department of Environmental Sciences, Informatics and Statistics
Ca Foscari University Venice
email: isigonis at unive.it
tel: (+39) 041 509 3190


From chrisege at stud.ntnu.no  Mon Sep  9 13:52:40 2013
From: chrisege at stud.ntnu.no (Chris89)
Date: Mon, 9 Sep 2013 04:52:40 -0700 (PDT)
Subject: [R] Regression using ggplot2
Message-ID: <1378727560269-4675676.post@n4.nabble.com>

Hi!
I am currently working with a project where I want to plot the regression
line in a plot using ggplot.
The problem occurs when I want to add the second variable, i.e. the z in the
source code:

p = ggplot(data = dat, aes_string(x = "sd", y = "mean", z = "corr"))  
p = p + stat_smooth(method = lm, formula = y~x+z, se = FALSE, size = 0.75,
linetype = "solid")
p = p + geom_point()
plot(p)

I?m not sure if it is even possible to do multiple regression using
stat_smooth, in which case do you have any alternative method?

Best regards
Chris



--
View this message in context: http://r.789695.n4.nabble.com/Regression-using-ggplot2-tp4675676.html
Sent from the R help mailing list archive at Nabble.com.


From chrisege at stud.ntnu.no  Mon Sep  9 14:06:20 2013
From: chrisege at stud.ntnu.no (Chris89)
Date: Mon, 9 Sep 2013 05:06:20 -0700 (PDT)
Subject: [R] regression imputation in R
In-Reply-To: <1378716283153-4675667.post@n4.nabble.com>
References: <1378716283153-4675667.post@n4.nabble.com>
Message-ID: <1378728380689-4675677.post@n4.nabble.com>

Hi!

For example if "data" is the complete dataset with both x and y values:

tempdata = data[complete.cases(data[,1:2]),] # Regression data
model = lm(y~x, data = tempdata)               # Linear model

>From this you can calculate the regression value of the missing values.

Hope this helped!
Regards,
Chris




--
View this message in context: http://r.789695.n4.nabble.com/regression-imputation-in-R-tp4675667p4675677.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Mon Sep  9 14:42:02 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 9 Sep 2013 05:42:02 -0700 (PDT)
Subject: [R] Mann-Whitney by group
In-Reply-To: <CAA2cm79TT_7HHsD6N3RRmUda3qPrp5Pm_QZYyOGCTCcLf6Nzfg@mail.gmail.com>
References: <37A3F822-30EF-42FE-B2BD-01882245E37B@gmail.com>	<004301cd5b93$70c71db0$52555910$@edu>	<1341606869728-4635667.post@n4.nabble.com>	<006401cd5c87$6fc8bfa0$4f5a3ee0$@edu>	<1341953156748-4636055.post@n4.nabble.com>	<8B4AAC08-5E1C-40A2-AE9D-A554B2545625@gmail.com>
	<CAA2cm79TT_7HHsD6N3RRmUda3qPrp5Pm_QZYyOGCTCcLf6Nzfg@mail.gmail.com>
Message-ID: <1378730522.1409.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,

You may try:
unlist(lapply(sara.data[,4:length(sara.data)],function(x) {x1<-tapply(is.na(x),list(sara.data$Groups),FUN=sum); if(x1[1]!=x1[2]) NULL else wilcox.test(x~sara.data$Groups,paired=TRUE,alternative="two.sided")$p.value}))
#? Bcl2?? Ccl5?? Cd27?? Cd28 
#0.1250 0.1875 0.8125 0.8125 

A.K.



----- Original Message -----
From: David Chertudi <david.chertudi at gmail.com>
To: R. Michael Weylandt <michael.weylandt at gmail.com>
Cc: "r-help at r-project.org" <r-help at r-project.org>
Sent: Sunday, September 8, 2013 11:13 PM
Subject: Re: [R] Mann-Whitney by group

The time has come to shake the cobwebs off of this analysis.? I have
more data now and need to run the same tests, the same way as above.
My question is this--some of the pairs include NAs, and so are gumming
up the works.? I'm not sure how to exclude them using the lhs ~ rhs
syntax.? Any ideas here?

Many thanks, as usual.? Data and syntax below.

David


sara.data=structure(list(Groups = c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
2L), Pairs = c(1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L), Actb =
c(2.2734065552504,
1.69621901296377, 1.07836251830772, 1.46314001007756, 1.76537848566894,
0.689064098855446, 0.462820758081676, NA, NA, 2.22119254577143
), Bcl2 = c(0.12954440593121, 0.0902306425601895, 0.219044589401239,
0.103793432483774, 0.119463699676088, 0.112179645963861, 0.136910739776212,
0.433953247043377, 0.401539702575691, 0.352218179109105), Bcl6 =
c(1.78964109252879,
1.56011379020288, 0.750029838175481, 1.80189108290585, 1.09372632818505,
0.275815381178548, 0.785680035605173, NA, NA, 0.311865838414934
), Ccl5 = c(0.140676314771846, 0.103227179167928, 0.210718001043218,
0.101548390950462, 0.140625579216236, 0.218846310909471, 0.132902076760262,
0.35763207205821, 0.320733407260836, 0.0983004520984843), Ccr7 =
c(0.116274608274044,
0.0623582657156311, 0.111654418769019, 0.110221412062233, 0.0646423645035265,
0.0924168984762384, 0.0322085814124609, NA, NA, 0.0315246913534493
), Cd27 = c(0.599332581326994, 0.536313800392409, 0.776647646561188,
0.511624999868611, 0.481254858629634, 0.365428233004039, 0.30446734845483,
0.880574935388197, 1.19362122336861, 0.121581553928565), Cd28 =
c(0.8476006082089,
0.976603410250505, 0.976783190446247, 0.8288118647421, 0.854672311976977,
0.576719839424659, 0.4221908111396, 1.22864113852622, 5.19562728663742,
0.401610355554234), Cd40 = c(0.209298226865743, 0.0680133680665235,
0.0233440779283003, 0.191986570448918, 0.128784506152115, NA,
NA, NA, NA, NA)), .Names = c("Groups", "Pairs", "Actb", "Bcl2",
"Bcl6", "Ccl5", "Ccr7", "Cd27", "Cd28", "Cd40"), class = "data.frame",
row.names = c(NA,
-10L))

results=apply(saradata[,4:length(saradata)], 2,
? ? ? ? ? ? ? function(x)

wilcox.test(x~saradata$Groups,paired=TRUE,alternative="two.sided"))

# Extract p-values from saved results
lapply(results, function(x) x[['p.value']])


--
I drink your milkshake.


On Tue, Jul 10, 2012 at 3:13 PM, R. Michael Weylandt
<michael.weylandt at gmail.com> <michael.weylandt at gmail.com> wrote:
> Untested, I think you need to lapply() over thing with some sort of extractor:
>
> lapply(thing, function(x) x[['p.value']])
>
> Michael
>
> On Jul 10, 2012, at 3:45 PM, Oxenstierna <david.chertudi at gmail.com> wrote:
>
>> This works very well--thanks so much.
>>
>> By way of extension:? how would one extract elements from the result object?
>>
>> For example:
>>
>> thing<=apply(Dtb[,3:10], 2, function(x) wilcox.test(x~Dtb$Group))
>>
>> summary(thing)$p.value
>>
>> Does not provide a list of p-values as it would in a regression object.
>> Ideally, I would like to be able to extract the W score and p-value by
>> A,B,C,...
>>
>> Any ideas greatly appreciated!
>>
>>
>> --
>> View this message in context: http://r.789695.n4.nabble.com/Mann-Whitney-by-group-tp4635618p4636055.html
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From renger at vannieuwkoop.ch  Mon Sep  9 14:44:38 2013
From: renger at vannieuwkoop.ch (Renger van Nieuwkoop)
Date: Mon, 9 Sep 2013 12:44:38 +0000
Subject: [R] Merging big data sets
Message-ID: <5E17CCD4AACE3A4C8CFF411186AE8190319A442E@EXDAG30-N2.hostallapps.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130909/a8b8384a/attachment.pl>

From bgnumis at gmail.com  Mon Sep  9 16:41:20 2013
From: bgnumis at gmail.com (bgnumis)
Date: Mon, 9 Sep 2013 16:41:20 +0200
Subject: [R] ADF
Message-ID: <CAN25tHS1Gxr29bE7FNMQb5tuQHwSFbF7XWqOt5G6ov2f=AE-sw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130909/868e82f3/attachment.pl>

From tryingtolearnagain at gmail.com  Mon Sep  9 17:30:03 2013
From: tryingtolearnagain at gmail.com (Trying To learn again)
Date: Mon, 9 Sep 2013 17:30:03 +0200
Subject: [R] F test
Message-ID: <CAN5rfDMGMzmfStHuG7Ayi6cuV4MN5g71biMPPZvJyddTr2fRxQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130909/25bb7d25/attachment.pl>

From Ahmed.El-Tahtawy at pfizer.com  Mon Sep  9 17:46:04 2013
From: Ahmed.El-Tahtawy at pfizer.com (El-Tahtawy, Ahmed)
Date: Mon, 9 Sep 2013 15:46:04 +0000
Subject: [R] replacing Na's with values on different records
Message-ID: <595D6D39142B7847B7638CF46AF84F0AED13C5@NDHAMREXDE05.amer.pfizer.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130909/964ca9ab/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Mon Sep  9 17:48:59 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 09 Sep 2013 08:48:59 -0700
Subject: [R] Merging big data sets
In-Reply-To: <5E17CCD4AACE3A4C8CFF411186AE8190319A442E@EXDAG30-N2.hostallapps.net>
References: <5E17CCD4AACE3A4C8CFF411186AE8190319A442E@EXDAG30-N2.hostallapps.net>
Message-ID: <aad716ab-0b14-4cd8-8b08-b833bd9d5535@email.android.com>

Please don't post in HTML. (Read the Posting Guide.)

Consider using the sqldf package.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Renger van Nieuwkoop <renger at vannieuwkoop.ch> wrote:
>Hi
>I have 6 rather big data sets (between 400000 and 800000 lines) on
>transport data (times, distances and travelers between nodes). They all
>have a common index (start-end nodes).
>I want to aggregate this data, but for that I have to merge them.
>I tried to use "merge" with the result that R (3.0.1) crashes (Windows
>8 machine, 16 Gb Ram).
>Then I tried the join from the data.table package. Here I got the
>message that 2^34 is too big (no idea why it is 2^34 as it is a left
>join).
>Then I decided to do a loop using the tables and assigning them, which
>takes a very, very long time (still running at the moment).
>
>Here is the code:
>for (i in 1:length(dataP$Start)){
>    c<-dataP$Start[i]
>    d<-dataP$End[i]
>    dataP[J(c,d)]$OEV.T<-ttoevP[J(c,d)]$OEV.T
>}
>
>dataP has 800'000 lines and ttoevP has about 500'000 lines.
>
>Any hints to speed up this process are welcome.
>
>Renger
>_________________________________________
>Centre of Economic Research (CER-ETH)
>Z?richbergstrasse 18 (ZUE)
>CH - 8032 Z?rich
>+41 44 632 02 63
>mailto: rengerv at etzh.ch<mailto:rengerv at etzh.ch>
>blog.modelworks.ch
>
>
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From Achim.Zeileis at uibk.ac.at  Mon Sep  9 18:16:17 2013
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Mon, 9 Sep 2013 18:16:17 +0200 (CEST)
Subject: [R] ADF
In-Reply-To: <CAN25tHS1Gxr29bE7FNMQb5tuQHwSFbF7XWqOt5G6ov2f=AE-sw@mail.gmail.com>
References: <CAN25tHS1Gxr29bE7FNMQb5tuQHwSFbF7XWqOt5G6ov2f=AE-sw@mail.gmail.com>
Message-ID: <alpine.DEB.2.10.1309091805490.8209@paninaro.uibk.ac.at>

On Mon, 9 Sep 2013, bgnumis wrote:

> Hi all,
>
> Imagine I hava e a simulated variable
> original<-matrix(rnorm(10000),100,100)
>
> If I install tseries and I run adf.test(original[,2],k=0)
>
> the result is:
>
> Augmented Dickey-Fuller Test
>
> data:  original[, 2]
> Dickey-Fuller = -11.5645, Lag order = 0, p-value = 0.01
> alternative hypothesis: stationary
>
> Mensajes de aviso perdidos
> In adf.test(original[, 2], k = 0) : p-value smaller than printed p-value
>
> I want to obtain de Dickey-Fuller -11.5645 but I cannot achive, I have
> tried all similar to that
>
> coef(summary(lm(originaldiff[[]~(1+originaltminus1)  ) ))[2,"t value"]
>
> More or less to obtain the t value is this formala no?
>
> Has anyone prove me applying code that the ADF is similar like in a lm
> stimation?

## simulate white noise time series
set.seed(1)
x <- ts(rnorm(1000))

## conduct ADF test with only one lag
adf.test(x, k = 1)

## set up series differences and lags
d <- ts.intersect(dx = diff(x), x1 = lag(x, -1), dx1 = lag(diff(x), -1))

## auxiliary regression (lagged levels, lagged differences, time trend)
m <- lm(dx ~ x1 + dx1 + time(d), data = d)

## t statistic of lagged levels
summary(m)$coefficients[2,3]

Note that the default number of lags included in the auxiliary regression 
is higher by default, see ?adf.test. There are also other implmentations 
available in R that offer more/other options to ADF testing, e.g., "urca" 
and "CADFtest" (see http://www.jstatsoft.org/v32/i02/).

> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Mon Sep  9 18:49:33 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 9 Sep 2013 09:49:33 -0700 (PDT)
Subject: [R] replacing Na's with values on different records
Message-ID: <1378745373.80914.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Please ?dput() your example dataset.? Not sure this helps or not.
u3s<- read.table(text="Current-ID visit AUC Wight ID1
101 3 . . 1
101 4 10 13 2
101 5? . . 3
102 3 .? . 4
102 4 4 10 5
102 5 . . 6
103 3 . . 7
103 4 6 9 8
103 5 . . 9",sep="",header=TRUE,na.strings=".",check.names=FALSE) 

u3d<- read.table(text="Desired-ID visit AUC Wight ID1
101 3 5 13 1
101 4 10 13 2
101 5 20 13 3
102 3 2 10 4
102 4 4 10 5
102 5 8 10 6
103 3 3 9 7
103 4 6 9 8
103 5 12 9 9",sep="",header=TRUE,check.names=FALSE)

?u3s1<-unsplit(lapply(split(u3s,u3s$`Current-ID`),function(x) {(x$AUC<-as.integer(x$AUC[!is.na(x$AUC)]/2)* (2^(0:floor(log(4,2))))); x$Wight<- x$Wight[!is.na(x$Wight)];x }),u3s$`Current-ID`)

attr(u3s1,"row.names")<- attr(u3d,"row.names")
colnames(u3s1)<- colnames(u3d)
all.equal(u3s1,u3d)
#[1] TRUE

A.K.


I'm sure I'm missing something really obvious in the "for loop"... 

Here is simplified data for 3 patients, we need filling in Na's 
with same WT for each patient, AUC halved for visit 3, doubled for visit
 5 for the same patient, based on visit 4 


for(i in unique(u3s$ID)){ ? ? ? ? ? ? ? ? ? ? ? ? ? ? #fill in same Wt for each patient 
? u3s$WT <- ifelse(is.na(u3s$WT),u3s$WT[u3s$visit == "4"],u3s$WT) 

? for(j in length(u3s$ID1)){ ? ? ? ? ? ? ? ? ? ? ? ?#fill in .5 AUC for visit 3, 2*AUC for visit 5 

? ? u3s$AUC24 <- ifelse(is.na(u3s$AUC24),u3s$AUC24[u3s$visit == "4"]*0.5,u3s$AUC24) 
? ? u3s$AUC24 <- ifelse(!is.na(u3s$AUC24),u3s$AUC24[u3s$visit == "4"]*1.0,u3s$AUC24) 
? ? u3s$AUC24 <- ifelse(is.na(u3s$AUC24),u3s$AUC24[u3s$visit == "4"]*2.0,u3s$AUC24) 
? } 
} 

Current- 
ID 

visit 

AUC 

Wight 

ID1 

101 

3 





1 

101 

4 

10 

13 

2 

101 

5 





3 

102 

3 





4 

102 

4 

4 

10 

5 

102 

5 





6 

103 

3 





7 

103 

4 

6 

9 

8 

103 

5 





9 


Desired- 

ID 

visit 

AUC 

Wight 

ID1 

101 

3 

5 

13 

1 

101 

4 

10 

13 

2 

101 

5 

20 

13 

3 

102 

3 

2 

10 

4 

102 

4 

4 

10 

5 

102 

5 

8 

10 

6 

103 

3 

3 

9 

7 

103 

4 

6 

9 

8 

103 

5 

12 

9 

9 



Your help is greatly appreciated... 


Best Regards


From kristi.glover at hotmail.com  Mon Sep  9 18:55:07 2013
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Mon, 9 Sep 2013 13:55:07 -0300
Subject: [R] plotting issue
Message-ID: <COL129-W19A5738D3A02C3A4411EAFA3F0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130909/8431be3b/attachment.pl>

From wdunlap at tibco.com  Mon Sep  9 19:10:39 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 9 Sep 2013 17:10:39 +0000
Subject: [R] Merging big data sets
In-Reply-To: <5E17CCD4AACE3A4C8CFF411186AE8190319A442E@EXDAG30-N2.hostallapps.net>
References: <5E17CCD4AACE3A4C8CFF411186AE8190319A442E@EXDAG30-N2.hostallapps.net>
Message-ID: <E66794E69CFDE04D9A70842786030B931C341E12@PA-MBX01.na.tibco.com>

Your sample code does not run and you didn't show the format of
your inputs.  If your 'ttoevP' is a table without duplicate Start/End
pairs that maps Start/End to OEV.T then using match and subscripting
can be quicker than merge.  E.g.,

   f0 <- function (dataP, ttoevP) 
   {
       encode <- function(df) paste(df$Start, df$End, sep = "\r")
       if (anyDuplicated(ttoevPEncoded <- encode(ttoevP))) {
           stop("duplicated Start/End pairs in ttoevP")
       }
       i <- match(encode(dataP), ttoevPEncoded)
       dataP$OEV.T <- ttoevP$OEV.T[i]
       dataP
   }

I made sample inputs with

makeData <- function (nrow, nTimes) 
{
    Start <- trunc(runif(nrow, 1, nTimes))
    End <- trunc(runif(nrow, Start, nTimes))
    dataP <- data.frame(Start = Start, End = End)
    ttoevP <- expand.grid(Start = seq_len(nTimes), End = seq_len(nTimes))
    ttoevP <- ttoevP[ttoevP$Start <= ttoevP$End, ]
    ttoevP$OEV.T <- paste(ttoevP$Start, ttoevP$End, sep = "-")
    list(dataP = dataP, ttoevP = ttoevP)
}

For nrows=4*10^4 and nTimes=10^3 f0 took 1.5 seconds and merge 10.5.
Aside from the order of the output, they produced the same output.

You can make your looping solution faster by removing repeated
operations from the loop, especially when those operations operate
on a data.frame (vectors operations are much faster, and no operation
is faster still).  E.g., replace
    for(i in seq_len(nrow(df))) {
         df$column[i] <- func(i)
    }
with
    column <- df$column
    for(i in seq_len(nrow(df))) {
        column[i] <- func(i)
    }
    df$column <- column

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Renger van Nieuwkoop
> Sent: Monday, September 09, 2013 5:45 AM
> To: r-help at r-project.org
> Subject: [R] Merging big data sets
> 
> Hi
> I have 6 rather big data sets (between 400000 and 800000 lines) on transport data (times,
> distances and travelers between nodes). They all have a common index (start-end nodes).
> I want to aggregate this data, but for that I have to merge them.
> I tried to use "merge" with the result that R (3.0.1) crashes (Windows 8 machine, 16 Gb
> Ram).
> Then I tried the join from the data.table package. Here I got the message that 2^34 is too
> big (no idea why it is 2^34 as it is a left join).
> Then I decided to do a loop using the tables and assigning them, which takes a very, very
> long time (still running at the moment).
> 
> Here is the code:
> for (i in 1:length(dataP$Start)){
>     c<-dataP$Start[i]
>     d<-dataP$End[i]
>     dataP[J(c,d)]$OEV.T<-ttoevP[J(c,d)]$OEV.T
> }
> 
> dataP has 800'000 lines and ttoevP has about 500'000 lines.
> 
> Any hints to speed up this process are welcome.
> 
> Renger
> _________________________________________
> Centre of Economic Research (CER-ETH)
> Z?richbergstrasse 18 (ZUE)
> CH - 8032 Z?rich
> +41 44 632 02 63
> mailto: rengerv at etzh.ch<mailto:rengerv at etzh.ch>
> blog.modelworks.ch
> 
> 
> 	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon Sep  9 19:17:02 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 09 Sep 2013 13:17:02 -0400
Subject: [R] plotting issue
In-Reply-To: <COL129-W19A5738D3A02C3A4411EAFA3F0@phx.gbl>
References: <COL129-W19A5738D3A02C3A4411EAFA3F0@phx.gbl>
Message-ID: <522E028E.6030502@gmail.com>

On 09/09/2013 12:55 PM, Kristi Glover wrote:
> Hi R user,
> I was trying to put four figures in a row, in which value of Y axis are similar but different in X axis. Therefore I wanted to put four figures in row.
>
> To remove y axis for second, thrid and forth figures, I used [yaxt="n"]. But, I saw that tick mark of Y was found to be missing. I dont want value in y axis but still I want tick mark. How is it possible?
> Example
> plot(data1$y, data2$x1, pch=".", cex=1)
> plot(data1$y, data2$x2, pch=".", cex=1, yaxt="n")# here I lost tick marks on y axis: I want tick mark but not text
> plot(data1$y, data2$x3, pch=".", cex=1, yaxt="n")
> plot(data1$y, data2$x4, pch=".", cex=1, yaxt="n")

After plotting with yaxt="n", add the ticks using axis(2, 
labels=FALSE).  (There are many more options to axis, so you have a lot 
of flexibility here.)

Duncan Murdoch


From Christian.Cech at fh-vie.ac.at  Mon Sep  9 18:00:51 2013
From: Christian.Cech at fh-vie.ac.at (Cech, Christian)
Date: Mon, 9 Sep 2013 16:00:51 +0000
Subject: [R] Problem adding lines to a plot, when y is defined
Message-ID: <d0558fa1f2dc4dffaf183b08ae663b49@AMXPR03MB023.eurprd03.prod.outlook.com>

Dear all,

I want to create a line-plot with two lines and some additional scatter-plots.
However, adding a line to the plot does not work when I specify the y-argument in the plot command, while it does work when y is not specified.

I first send you an example that works:
plot(var[, 3],
     type="l",
     ylim=c(-0.04, 0),
     ylab   = 'portfolio returns',
     xlab   = 'time')
lines(var[, 5], type="l", lty=3)
for (i in 1:nrow(var)) {
  if(var[i, 4] | var[i,6])
    points(i, var[i, 2], pch=4)
}

--> the result is displayed in attachment "Plot1.pdf"

What does not work is the following code, where as the first argument of plot (ie the y-argument) is defined:
plot(as.Date(var[, 1], origin="1899-12-30"),
     var[, 3],
     type="l",
     ylim=c(-0.04, 0),
     ylab='portfolio returns',
     xlab='time')
lines(var[, 5], type="l", lty=3)
for (i in 1:nrow(var)) {
  if(var[i, 4] | var[i,6])
    points(i, var[i, 2], pch=4)
}

--> the result is displayed in attachment "Plot2.pdf"

The same problem appears if instead of

as.Date(var[, 1], origin="1899-12-30")

I use

var[, 1]

to define the y-argument.

I do very much appreciate your help!
Kind regards,
Christian Cech

________________________________


Firmenwortlaut: Fachhochschule des bfi Wien Gesellschaft m.b.H
Firmenbuchnummer: 148597 a
Firmenbuchgericht: Handelsgericht Wien
Firmensitz: Wohlmutstra?e 22, 1020 Wien

This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secure or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Plot1.pdf
Type: application/pdf
Size: 170140 bytes
Desc: Plot1.pdf
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130909/424ca860/attachment.pdf>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Plot2.pdf
Type: application/pdf
Size: 87948 bytes
Desc: Plot2.pdf
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130909/424ca860/attachment-0001.pdf>

From dwinsemius at comcast.net  Mon Sep  9 19:57:40 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 9 Sep 2013 10:57:40 -0700
Subject: [R] Problem adding lines to a plot, when y is defined
In-Reply-To: <d0558fa1f2dc4dffaf183b08ae663b49@AMXPR03MB023.eurprd03.prod.outlook.com>
References: <d0558fa1f2dc4dffaf183b08ae663b49@AMXPR03MB023.eurprd03.prod.outlook.com>
Message-ID: <84FE6A09-76AE-4320-8F40-8A978F7E6CF3@comcast.net>


On Sep 9, 2013, at 9:00 AM, Cech, Christian wrote:

> Dear all,
> 
> I want to create a line-plot with two lines and some additional scatter-plots.
> However, adding a line to the plot does not work when I specify the y-argument in the plot command, while it does work when y is not specified.
> 
> I first send you an example that works:
> plot(var[, 3],
>     type="l",
>     ylim=c(-0.04, 0),
>     ylab   = 'portfolio returns',
>     xlab   = 'time')
> lines(var[, 5], type="l", lty=3)
> for (i in 1:nrow(var)) {
>  if(var[i, 4] | var[i,6])
>    points(i, var[i, 2], pch=4)
> }
> 
> --> the result is displayed in attachment "Plot1.pdf"
> 
> What does not work is the following code, where as the first argument of plot (ie the y-argument) is defined:
> plot(as.Date(var[, 1], origin="1899-12-30"),
>     var[, 3],
>     type="l",
>     ylim=c(-0.04, 0),
>     ylab='portfolio returns',
>     xlab='time')
> lines(var[, 5], type="l", lty=3)
> for (i in 1:nrow(var)) {
>  if(var[i, 4] | var[i,6])
>    points(i, var[i, 2], pch=4)
> }
> 
> --> the result is displayed in attachment "Plot2.pdf"
> 
> The same problem appears if instead of
> 
> as.Date(var[, 1], origin="1899-12-30")
> 
> I use
> 
> var[, 1]
> 
> to define the y-argument.

This puzzles me. At the moment yu are using postional matching and it is var[,3] that would be matched to the y argument.

You need to post output of str(var) so that we can see the class of var[,1].

> 
-- 

David Winsemius
Alameda, CA, USA


From david at revolutionanalytics.com  Mon Sep  9 20:25:05 2013
From: david at revolutionanalytics.com (David Smith)
Date: Mon, 9 Sep 2013 11:25:05 -0700
Subject: [R] Revolutions Blog: August 2013 roundup
Message-ID: <CABgvEC-0ABFkuNJ-cYQeO+nsRCOWa2f2QodWBfTiF4ZJd4WGww@mail.gmail.com>

Revolution Analytics staff write about R every weekday at the Revolutions blog:
 http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month
of particular interest to readers of r-help.

In case you missed them, here are some articles related to R from the
month of August:

A tutorial on parallel programming with the foreach, doMC and doSNOW
packages: http://bit.ly/16fmf8J

Joe Rickert reviews R's capabilities for linear algebra, sparse
matrices and big matrices: http://bit.ly/16fmgK3

How R is disrupting the insurance industry with big data: http://bit.ly/16fmgK1

Revolution Analytics has teamed with Cloudera to bring statistical
models into Hadoop clusters from R: http://bit.ly/16fmgK4

R graphics recognized in DataWeek's Top Innovator award for data
visualization: http://bit.ly/16fmgK2

Slides and replay for a new webinar on high-performance predictive
analytics in R and Hadoop: http://bit.ly/16fmf8I

A catalog of free, public big data sets you can use with R:
http://bit.ly/16fmgK5

Demand for employees with R skills continues to rise according to job
posting data: http://bit.ly/16fmgK7 . Demand for SAS skills, by
contrast, is declining: http://bit.ly/16fmf8K

A unique way of looking at (and listening to) the 2008 financial
crisis, using R to animate and sonify US Treasury data:
http://bit.ly/16fmgK6

The City of Chicago uses R-based semantic analysis of tweets to
identify outbreaks of food borne illness: http://bit.ly/16fmf8L

Discussions of R, drug development and the FDA from the JSM 2013
conference: http://bit.ly/16fmf8M

Statistics from Australian Rules Football games, visualized with R:
http://bit.ly/16fmf8N

Dr. Rob Hodges used R and NOAA climate sensor data to visualize the
strongest winds during the 2005 Katrina hurricane:
http://bit.ly/16fmh0k

Google has produced a series of introductory videos for beginners to
R: http://bit.ly/16fmh0l

Nate Silver's presentation at the JSM 2013 conference included 11
principles for journalists to make effective use of Statistics:
http://bit.ly/16fmf8O

Symphony Analytics uses Revolution R Enterprise to develop solutions
in healthcare, retails and telecommunications: http://bit.ly/16fmh0m

Rodolfo Vanzini used R and the ggmap package to select a new location
for his business: http://bit.ly/16fmh0n

Simon Urbanek showed at JSM "Nanocube" based visualization of billions
of tweets to explore smartphone market share across the USA:
http://bit.ly/16fmf8P

Joe Rickert responds to a recent AmstatNews editorial that portrays
mainstream academic statisticians as being left behind by the rise of
Big Data:
http://bit.ly/16fmf8Q

Some non-R stories in the past month included: a mathematician and an
engineer divide a restaurant bill (http://bit.ly/16fmf8S), an optical
illusion makes straight lines look like a rotating circles
(http://bit.ly/16fmf8R), misleading weight-loss photos
(http://bit.ly/16fmh0q), video of a beautiful eclipse in Australia
(http://bit.ly/16fmf8T) and an old-school visualization of 4000 years
of works history (http://bit.ly/16fmh0r).

Meeting times for local R user groups (http://bit.ly/eC5YQe) can be
found on the updated R Community Calendar at: http://bit.ly/bb3naW

If you're looking for more articles about R, you can find summaries
from previous months at http://blog.revolutionanalytics.com/roundups/.
Join the Revolution mailing list at
http://revolutionanalytics.com/newsletter to be alerted to new
articles on a monthly basis.

As always, thanks for the comments and please keep sending suggestions
to me at david at revolutionanalytics.com . Don't forget you can also
follow the blog using an RSS reader, or by following me on Twitter
(I'm @revodavid).

Cheers,
# David

-- 
David M Smith <david at revolutionanalytics.com>
VP of Marketing, Revolution Analytics  http://blog.revolutionanalytics.com
Tel: +1 (650) 646-9523 (Seattle WA, USA)
Twitter: @revodavid
We're hiring! www.revolutionanalytics.com/careers


From Stephen.Bond at cibc.com  Mon Sep  9 20:58:33 2013
From: Stephen.Bond at cibc.com (Bond, Stephen)
Date: Mon, 9 Sep 2013 18:58:33 +0000
Subject: [R] windowing
Message-ID: <624EC9773CAB044ABA65327271BED9B601C3FF@CBMCC-X10-MA01.ad.cibc.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130909/6b36b977/attachment.pl>

From Michael.Folkes at dfo-mpo.gc.ca  Mon Sep  9 21:35:14 2013
From: Michael.Folkes at dfo-mpo.gc.ca (Folkes, Michael)
Date: Mon, 9 Sep 2013 12:35:14 -0700
Subject: [R] Hmisc binconf function value interpretation during narrow
	confidence intervals
Message-ID: <63F107BCC37AEA49A75FD94AA3E07CB008CD9515@pacpbsex01.pac.dfo-mpo.ca>

Hello all,
I've been using binconf (package Hmisc) at a range of alpha values and
noticed that using the 'Wilson' method when alpha is larger (i.e. narrow
CI), results in the upper value being smaller than the lower value. The
'exact' and 'asymptotic' methods give results in the realm I'd expect.
But the help file suggests:
"Following Agresti and Coull, the Wilson interval is to be preferred and
so is the default."

Suggestions and clarifications gratefully received.

The following code shows the curious results:

#calc 5% CI's.
require(Hmisc)
alpha <-.95
bin.prob <- binconf(1, 100, alpha=alpha,method='all')
colnames(bin.prob)[-1] <- paste('p',c(alpha/2,1-alpha/2),sep='')
bin.prob

______________________________________
Michael Folkes
Salmon Stock Assessment
Canadian Dept. of Fisheries & Oceans     
Pacific Biological Station
3190 Hammond Bay Rd.
Nanaimo, B.C., Canada
V9T-6N7
Michael.Folkes at dfo-mpo.gc.ca


From paulbernal07 at gmail.com  Mon Sep  9 21:36:15 2013
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Mon, 9 Sep 2013 14:36:15 -0500
Subject: [R] Fitting Arima Models and Forecasting Using Daily Historical Data
Message-ID: <CAMOcQfNm7bNcOQqO73nHnHoSBk3s2stuAgFNaSrYPh=p04WdBg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130909/3681f392/attachment.pl>

From david.chertudi at gmail.com  Mon Sep  9 20:29:13 2013
From: david.chertudi at gmail.com (David Chertudi)
Date: Mon, 9 Sep 2013 11:29:13 -0700
Subject: [R] Mann-Whitney by group
In-Reply-To: <1378730522.1409.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <37A3F822-30EF-42FE-B2BD-01882245E37B@gmail.com>
	<004301cd5b93$70c71db0$52555910$@edu>
	<1341606869728-4635667.post@n4.nabble.com>
	<006401cd5c87$6fc8bfa0$4f5a3ee0$@edu>
	<1341953156748-4636055.post@n4.nabble.com>
	<8B4AAC08-5E1C-40A2-AE9D-A554B2545625@gmail.com>
	<CAA2cm79TT_7HHsD6N3RRmUda3qPrp5Pm_QZYyOGCTCcLf6Nzfg@mail.gmail.com>
	<1378730522.1409.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <CAA2cm7_a9Ek4reOz4LfpgZq_g=NBaeB0fUYo2XTCG1wRhzD6Qg@mail.gmail.com>

 Hello Arun,

Thanks so much--while I haven't tried it yet, this seems as though it
will be an excellent way to skip the categories (Actb, etc) that have
missing values (NAs).

The second part of my question, which I didn't ask before:  instead of
skipping, is there a way to continue with the wilcoxons even if there
are NA's?  In this dataset, Groups is the two-level factor that sets
up the pairwise comparison, and Pairs is a 5-level factor that pairs
together each instance within the groups.  For Actb, for example, the
3rd and 4th instance of Group 2 are missing.  How would I automate the
procedure of excluding the 3rd and 4th instance in Group 1, and then
running wilcox.test on the remaining three instances (1,2, and 5)?
The exclusions will vary by category (saradata[,4:10]) in the sample I
provided.

Many thanks.

David


--
I drink your milkshake.


On Mon, Sep 9, 2013 at 5:42 AM, arun <smartpink111 at yahoo.com> wrote:
> Hi,
>
> You may try:
> unlist(lapply(sara.data[,4:length(sara.data)],function(x) {x1<-tapply(is.na(x),list(sara.data$Groups),FUN=sum); if(x1[1]!=x1[2]) NULL else wilcox.test(x~sara.data$Groups,paired=TRUE,alternative="two.sided")$p.value}))
> #  Bcl2   Ccl5   Cd27   Cd28
> #0.1250 0.1875 0.8125 0.8125
>
> A.K.
>
>
>
> ----- Original Message -----
> From: David Chertudi <david.chertudi at gmail.com>
> To: R. Michael Weylandt <michael.weylandt at gmail.com>
> Cc: "r-help at r-project.org" <r-help at r-project.org>
> Sent: Sunday, September 8, 2013 11:13 PM
> Subject: Re: [R] Mann-Whitney by group
>
> The time has come to shake the cobwebs off of this analysis.  I have
> more data now and need to run the same tests, the same way as above.
> My question is this--some of the pairs include NAs, and so are gumming
> up the works.  I'm not sure how to exclude them using the lhs ~ rhs
> syntax.  Any ideas here?
>
> Many thanks, as usual.  Data and syntax below.
>
> David
>
>
> sara.data=structure(list(Groups = c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
> 2L), Pairs = c(1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L), Actb =
> c(2.2734065552504,
> 1.69621901296377, 1.07836251830772, 1.46314001007756, 1.76537848566894,
> 0.689064098855446, 0.462820758081676, NA, NA, 2.22119254577143
> ), Bcl2 = c(0.12954440593121, 0.0902306425601895, 0.219044589401239,
> 0.103793432483774, 0.119463699676088, 0.112179645963861, 0.136910739776212,
> 0.433953247043377, 0.401539702575691, 0.352218179109105), Bcl6 =
> c(1.78964109252879,
> 1.56011379020288, 0.750029838175481, 1.80189108290585, 1.09372632818505,
> 0.275815381178548, 0.785680035605173, NA, NA, 0.311865838414934
> ), Ccl5 = c(0.140676314771846, 0.103227179167928, 0.210718001043218,
> 0.101548390950462, 0.140625579216236, 0.218846310909471, 0.132902076760262,
> 0.35763207205821, 0.320733407260836, 0.0983004520984843), Ccr7 =
> c(0.116274608274044,
> 0.0623582657156311, 0.111654418769019, 0.110221412062233, 0.0646423645035265,
> 0.0924168984762384, 0.0322085814124609, NA, NA, 0.0315246913534493
> ), Cd27 = c(0.599332581326994, 0.536313800392409, 0.776647646561188,
> 0.511624999868611, 0.481254858629634, 0.365428233004039, 0.30446734845483,
> 0.880574935388197, 1.19362122336861, 0.121581553928565), Cd28 =
> c(0.8476006082089,
> 0.976603410250505, 0.976783190446247, 0.8288118647421, 0.854672311976977,
> 0.576719839424659, 0.4221908111396, 1.22864113852622, 5.19562728663742,
> 0.401610355554234), Cd40 = c(0.209298226865743, 0.0680133680665235,
> 0.0233440779283003, 0.191986570448918, 0.128784506152115, NA,
> NA, NA, NA, NA)), .Names = c("Groups", "Pairs", "Actb", "Bcl2",
> "Bcl6", "Ccl5", "Ccr7", "Cd27", "Cd28", "Cd40"), class = "data.frame",
> row.names = c(NA,
> -10L))
>
> results=apply(saradata[,4:length(saradata)], 2,
>               function(x)
>
> wilcox.test(x~saradata$Groups,paired=TRUE,alternative="two.sided"))
>
> # Extract p-values from saved results
> lapply(results, function(x) x[['p.value']])
>
>
> --
> I drink your milkshake.
>
>
> On Tue, Jul 10, 2012 at 3:13 PM, R. Michael Weylandt
> <michael.weylandt at gmail.com> <michael.weylandt at gmail.com> wrote:
>> Untested, I think you need to lapply() over thing with some sort of extractor:
>>
>> lapply(thing, function(x) x[['p.value']])
>>
>> Michael
>>
>> On Jul 10, 2012, at 3:45 PM, Oxenstierna <david.chertudi at gmail.com> wrote:
>>
>>> This works very well--thanks so much.
>>>
>>> By way of extension:  how would one extract elements from the result object?
>>>
>>> For example:
>>>
>>> thing<=apply(Dtb[,3:10], 2, function(x) wilcox.test(x~Dtb$Group))
>>>
>>> summary(thing)$p.value
>>>
>>> Does not provide a list of p-values as it would in a regression object.
>>> Ideally, I would like to be able to extract the W score and p-value by
>>> A,B,C,...
>>>
>>> Any ideas greatly appreciated!
>>>
>>>
>>> --
>>> View this message in context: http://r.789695.n4.nabble.com/Mann-Whitney-by-group-tp4635618p4636055.html
>>> Sent from the R help mailing list archive at Nabble.com.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Mon Sep  9 20:57:48 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 9 Sep 2013 11:57:48 -0700 (PDT)
Subject: [R] Mann-Whitney by group
In-Reply-To: <CAA2cm7_a9Ek4reOz4LfpgZq_g=NBaeB0fUYo2XTCG1wRhzD6Qg@mail.gmail.com>
References: <37A3F822-30EF-42FE-B2BD-01882245E37B@gmail.com>
	<004301cd5b93$70c71db0$52555910$@edu>
	<1341606869728-4635667.post@n4.nabble.com>
	<006401cd5c87$6fc8bfa0$4f5a3ee0$@edu>
	<1341953156748-4636055.post@n4.nabble.com>
	<8B4AAC08-5E1C-40A2-AE9D-A554B2545625@gmail.com>
	<CAA2cm79TT_7HHsD6N3RRmUda3qPrp5Pm_QZYyOGCTCcLf6Nzfg@mail.gmail.com>
	<1378730522.1409.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<CAA2cm7_a9Ek4reOz4LfpgZq_g=NBaeB0fUYo2XTCG1wRhzD6Qg@mail.gmail.com>
Message-ID: <1378753068.74805.YahooMailNeo@web142606.mail.bf1.yahoo.com>



Hi David:
Try:
unlist(lapply(sara.data[,4:length(sara.data)],function(x){indx1<- 1:(length(x)/2); indx2<- ((length(x)/2)+1):length(x); x1<-data.frame(FH=x[indx1],LH=x[indx2],Group1=sara.data$Group[indx1],Group2=sara.data$Group[indx2]); x2<- x1[!(is.na(x1$FH) | is.na(x1$LH)),]; if(nrow(x2)==0) NULL else with(x2,wilcox.test(FH,LH,paired=TRUE, alternative="two.sided")$p.value)??? }))
#? Bcl2?? Bcl6?? Ccl5?? Ccr7?? Cd27?? Cd28 
#0.1250 0.2500 0.1875 0.2500 0.8125 0.8125 


#Cd40 Group 2 values were all NAs, so it was not tested.


A.K.

----- Original Message -----
From: David Chertudi <david.chertudi at gmail.com>
To: arun <smartpink111 at yahoo.com>
Cc: R help <r-help at r-project.org>
Sent: Monday, September 9, 2013 2:29 PM
Subject: Re: [R] Mann-Whitney by group

Hello Arun,

Thanks so much--while I haven't tried it yet, this seems as though it
will be an excellent way to skip the categories (Actb, etc) that have
missing values (NAs).

The second part of my question, which I didn't ask before:? instead of
skipping, is there a way to continue with the wilcoxons even if there
are NA's?? In this dataset, Groups is the two-level factor that sets
up the pairwise comparison, and Pairs is a 5-level factor that pairs
together each instance within the groups.? For Actb, for example, the
3rd and 4th instance of Group 2 are missing.? How would I automate the
procedure of excluding the 3rd and 4th instance in Group 1, and then
running wilcox.test on the remaining three instances (1,2, and 5)?
The exclusions will vary by category (saradata[,4:10]) in the sample I
provided.

Many thanks.

David


--
I drink your milkshake.


On Mon, Sep 9, 2013 at 5:42 AM, arun <smartpink111 at yahoo.com> wrote:
> Hi,
>
> You may try:
> unlist(lapply(sara.data[,4:length(sara.data)],function(x) {x1<-tapply(is.na(x),list(sara.data$Groups),FUN=sum); if(x1[1]!=x1[2]) NULL else wilcox.test(x~sara.data$Groups,paired=TRUE,alternative="two.sided")$p.value}))
> #? Bcl2???Ccl5???Cd27???Cd28
> #0.1250 0.1875 0.8125 0.8125
>
> A.K.
>
>
>
> ----- Original Message -----
> From: David Chertudi <david.chertudi at gmail.com>
> To: R. Michael Weylandt <michael.weylandt at gmail.com>
> Cc: "r-help at r-project.org" <r-help at r-project.org>
> Sent: Sunday, September 8, 2013 11:13 PM
> Subject: Re: [R] Mann-Whitney by group
>
> The time has come to shake the cobwebs off of this analysis.? I have
> more data now and need to run the same tests, the same way as above.
> My question is this--some of the pairs include NAs, and so are gumming
> up the works.? I'm not sure how to exclude them using the lhs ~ rhs
> syntax.? Any ideas here?
>
> Many thanks, as usual.? Data and syntax below.
>
> David
>
>
> sara.data=structure(list(Groups = c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
> 2L), Pairs = c(1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L), Actb =
> c(2.2734065552504,
> 1.69621901296377, 1.07836251830772, 1.46314001007756, 1.76537848566894,
> 0.689064098855446, 0.462820758081676, NA, NA, 2.22119254577143
> ), Bcl2 = c(0.12954440593121, 0.0902306425601895, 0.219044589401239,
> 0.103793432483774, 0.119463699676088, 0.112179645963861, 0.136910739776212,
> 0.433953247043377, 0.401539702575691, 0.352218179109105), Bcl6 =
> c(1.78964109252879,
> 1.56011379020288, 0.750029838175481, 1.80189108290585, 1.09372632818505,
> 0.275815381178548, 0.785680035605173, NA, NA, 0.311865838414934
> ), Ccl5 = c(0.140676314771846, 0.103227179167928, 0.210718001043218,
> 0.101548390950462, 0.140625579216236, 0.218846310909471, 0.132902076760262,
> 0.35763207205821, 0.320733407260836, 0.0983004520984843), Ccr7 =
> c(0.116274608274044,
> 0.0623582657156311, 0.111654418769019, 0.110221412062233, 0.0646423645035265,
> 0.0924168984762384, 0.0322085814124609, NA, NA, 0.0315246913534493
> ), Cd27 = c(0.599332581326994, 0.536313800392409, 0.776647646561188,
> 0.511624999868611, 0.481254858629634, 0.365428233004039, 0.30446734845483,
> 0.880574935388197, 1.19362122336861, 0.121581553928565), Cd28 =
> c(0.8476006082089,
> 0.976603410250505, 0.976783190446247, 0.8288118647421, 0.854672311976977,
> 0.576719839424659, 0.4221908111396, 1.22864113852622, 5.19562728663742,
> 0.401610355554234), Cd40 = c(0.209298226865743, 0.0680133680665235,
> 0.0233440779283003, 0.191986570448918, 0.128784506152115, NA,
> NA, NA, NA, NA)), .Names = c("Groups", "Pairs", "Actb", "Bcl2",
> "Bcl6", "Ccl5", "Ccr7", "Cd27", "Cd28", "Cd40"), class = "data.frame",
> row.names = c(NA,
> -10L))
>
> results=apply(saradata[,4:length(saradata)], 2,
>? ? ? ? ? ? ???function(x)
>
> wilcox.test(x~saradata$Groups,paired=TRUE,alternative="two.sided"))
>
> # Extract p-values from saved results
> lapply(results, function(x) x[['p.value']])
>
>
> --
> I drink your milkshake.
>
>
> On Tue, Jul 10, 2012 at 3:13 PM, R. Michael Weylandt
> <michael.weylandt at gmail.com> <michael.weylandt at gmail.com> wrote:
>> Untested, I think you need to lapply() over thing with some sort of extractor:
>>
>> lapply(thing, function(x) x[['p.value']])
>>
>> Michael
>>
>> On Jul 10, 2012, at 3:45 PM, Oxenstierna <david.chertudi at gmail.com> wrote:
>>
>>> This works very well--thanks so much.
>>>
>>> By way of extension:? how would one extract elements from the result object?
>>>
>>> For example:
>>>
>>> thing<=apply(Dtb[,3:10], 2, function(x) wilcox.test(x~Dtb$Group))
>>>
>>> summary(thing)$p.value
>>>
>>> Does not provide a list of p-values as it would in a regression object.
>>> Ideally, I would like to be able to extract the W score and p-value by
>>> A,B,C,...
>>>
>>> Any ideas greatly appreciated!
>>>
>>>
>>> --
>>> View this message in context: http://r.789695.n4.nabble.com/Mann-Whitney-by-group-tp4635618p4636055.html
>>> Sent from the R help mailing list archive at Nabble.com.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From Christian.Cech at fh-vie.ac.at  Mon Sep  9 21:27:18 2013
From: Christian.Cech at fh-vie.ac.at (Cech, Christian)
Date: Mon, 9 Sep 2013 19:27:18 +0000
Subject: [R] Problem adding lines to a plot, when y is defined
In-Reply-To: <8AAD2E23-CD33-45CB-9CDE-F12DBDB98ABA@comcast.net>
References: <d0558fa1f2dc4dffaf183b08ae663b49@AMXPR03MB023.eurprd03.prod.outlook.com>,
	<84FE6A09-76AE-4320-8F40-8A978F7E6CF3@comcast.net>
	<7d811a7e653241aeb768529c3e0bac27@AMXPR03MB023.eurprd03.prod.outlook.com>,
	<8AAD2E23-CD33-45CB-9CDE-F12DBDB98ABA@comcast.net>
Message-ID: <86658a5f496d44718a021de910b432ce@AMXPR03MB023.eurprd03.prod.outlook.com>

>> On Sep 9, 2013, at 9:00 AM, Cech, Christian wrote:
>>
>>> Dear all,
>>>
>>> I want to create a line-plot with two lines and some additional scatter-plots.
>>> However, adding a line to the plot does not work when I specify the y-argument in the plot command, while it does work when y is not specified.
>>>
>>> I first send you an example that works:
>>> plot(var[, 3],
>>>    type="l",
>>>    ylim=c(-0.04, 0),
>>>    ylab   = 'portfolio returns',
>>>    xlab   = 'time')
>>> lines(var[, 5], type="l", lty=3)
>>> for (i in 1:nrow(var)) {
>>> if(var[i, 4] | var[i,6])
>>>   points(i, var[i, 2], pch=4)
>>> }
>>>
>>> --> the result is displayed in attachment "Plot1.pdf"
>>>
>>> What does not work is the following code, where as the first argument of plot (ie the y-argument) is defined:
>>> plot(as.Date(var[, 1], origin="1899-12-30"),
>>>    var[, 3],
>>>    type="l",
>>>    ylim=c(-0.04, 0),
>>>    ylab='portfolio returns',
>>>    xlab='time')
>>> lines(var[, 5], type="l", lty=3)
>>> for (i in 1:nrow(var)) {
>>> if(var[i, 4] | var[i,6])
>>>   points(i, var[i, 2], pch=4)
>>> }
>>>
>>> --> the result is displayed in attachment "Plot2.pdf"
>>>
>>> The same problem appears if instead of
>>>
>>> as.Date(var[, 1], origin="1899-12-30")
>>>
>>> I use
>>>
>>> var[, 1]
>>>
>>> to define the y-argument.
>>
>> This puzzles me. At the moment yu are using postional matching and it is var[,3] that would be matched to the y argument.
>>
>> You need to post output of str(var) so that we can see the class of var[,1].
>>
>>

> Dear David,
>
> thank you for the quick reply! Unfortunately I confused you because I mixed up y-value and x-value. What I actually wanted to say is that the plot does not work when x is specified (2nd example) while it does work if x is not specified (1st example). Sorry for this!
> y = var[, 3]
> x = var[, 1]
>
> When I type str(var) i get the following output:
> num [1:4747, 1:6] 33450 33451 33452 33455 33456 ...
>
> Is that the information you needed?

Maybe. 'var' is  a numeric matrix which may not be what you think it was if it started out life as having dates. (On this list it is requested that you post in context which means bottom posting in many cases. So I moved your reply.)

When you apply the as.Date function with an origin, you will get an different number as the internal representation of the Date value than what you put in:

 as.numeric(as.Date(c(33450, 33451, 33452, 33455, 33456), origin="1899-01-01"))
[1] 7518 7519 7520 7523 7524
 I suspect that you have a misregistration of the x values. Since it is a matrix we might have better view of it with:

 dput(head(var))

I also supect that you will end up using the `axis` function to do your labeling.

--

David Winsemius
Alameda, CA, USA

 > dput(head(var))
structure(c(33450, 33451, 33452, 33455, 33456, 33457, -0.00299369609998333,
-0.000882805884818571, -0.000570821462061429, 0.00735101809395667,
-0.000574642535598095, -0.000464474459045714, -0.010510137214196,
-0.0105173750100507, -0.0104987866171353, -0.0104808796029616,
-0.0104561013745608, -0.0104562836793838, 0, 0, 0, 0, 0, 0, -0.0115901618181903,
-0.0115901618181903, -0.0115901618181903, -0.0115901618181903,
-0.0115901618181903, -0.0115901618181903, 0, 0, 0, 0, 0, 0), .Dim = c(6L,
6L), .Dimnames = list(NULL, c("col1", "col2", "col3", "col4",
"col5", "col6")))

Christian
________________________________


Firmenwortlaut: Fachhochschule des bfi Wien Gesellschaft m.b.H
Firmenbuchnummer: 148597 a
Firmenbuchgericht: Handelsgericht Wien
Firmensitz: Wohlmutstra?e 22, 1020 Wien

This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secure or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version.

From smartpink111 at yahoo.com  Mon Sep  9 21:30:27 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 9 Sep 2013 12:30:27 -0700 (PDT)
Subject: [R] Duplicated genes
In-Reply-To: <CAFkF=gG1qTshKSAa1pdOCbc_-FZ-ZOrxOkZygMbi7i_E_KpwGg@mail.gmail.com>
References: <CAFkF=gH38pj8p+i4S+pquwwdAPoyo6JsyaJJyi+DmaCzcXk3GA@mail.gmail.com>
	<1378751256.26332.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<CAFkF=gG1qTshKSAa1pdOCbc_-FZ-ZOrxOkZygMbi7i_E_KpwGg@mail.gmail.com>
Message-ID: <1378755027.79101.YahooMailNeo@web142601.mail.bf1.yahoo.com>



Hi,

May be you can try this:
dat1New<-? dat1[!(duplicated(dat1$gene)|duplicated(dat1$gene,fromLast=TRUE)),]
dat2<-dat1[duplicated(dat1$gene)|duplicated(dat1$gene,fromLast=TRUE),]
?lst1<-split(dat2,dat2$gene)
dat3<-unsplit(lapply(lst1,function(x) {x1<- sum(apply(x[,6:32],2,function(y) y[1]>=y[2]));x2<- sum(apply(x[,6:32],2, function(y) y[1]<=y[2])); if(x1>x2) x[1,] else x[2,] } ),unique(dat2$gene)) #assuming that there are not more than 2 copies of a particular gene. (In the dataset, it was not present)
?dat4<-rbind(dat1New,dat3)
dat5<-dat4[order(as.numeric(row.names(dat4))),]
?dim(dat5)
#[1] 639? 32


A.K.

________________________________
From: Vivek Das <vd4mmind at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Monday, September 9, 2013 2:30 PM
Subject: Re: Duplicated genes



actually these are all differentially expressed genes. So the one with the most differentially expressed will be there in the list and its duplicate will be removed. Can you tell me again? I think then the script will change right?


----------------------------------------------------------

Vivek Das
PhD Student in Computational Biology
Giuseppe Testa's Lab
European School of Molecular Medicine
IFOM-IEO Campus
Via Adamello, 16
Milan, Italy

emails:?vivek.das at ieo.eu
??? ??? ??? vchris_05 at yahoo.co.in
??? ??? ??? vd4mmind at gmail.com



On Mon, Sep 9, 2013 at 8:27 PM, arun <smartpink111 at yahoo.com> wrote:

Hi,
>Try:
>dat1<- read.table("DEGs_all.txt",sep="",header=TRUE,stringsAsFactors=FALSE)
>dim(dat1)
>#[1] 725? 32
>length(unique(dat1$gene))
>#[1] 639
>?dat2<-dat1[!duplicated(dat1$gene),]
>?dim(dat2)
>#[1] 639? 32
>
>dim(unique(dat1))
>#[1] 725? 32
>
>The duplicated genes have different expression values.? You didn't provide information on how to select those unique genes.? Here, the first row of every duplicated gene will be selected and others are removed.
>
>But suppose, you want to get the mean values of those rows.
>library(plyr)
>?res<-ddply(dat1[,c(1,6:32)],.(gene), numcolwise(mean,na.rm=TRUE))
>dim(res)
>#[1] 639? 28
>
>A.K.
>
>
>
>
>
>
>
>________________________________
>From: Vivek Das <vd4mmind at gmail.com>
>To: arun <smartpink111 at yahoo.com>
>Sent: Monday, September 9, 2013 1:35 PM
>Subject: Urgent help
>
>
>
>I have a data list with genes , I want to reduce the list to its unique genes. The genes are having expression values but some of the genes are duplicates. Is there any way where I can remove the duplicate names from the list and only have the genes once with their corresponding values.Please see the attached matrix.
>
>It will be nice if you can let me know. Its a bit urgent
>
>----------------------------------------------------------
>
>Vivek Das
>PhD Student in Computational Biology
>Giuseppe Testa's Lab
>European School of Molecular Medicine
>IFOM-IEO Campus
>Via Adamello, 16
>Milan, Italy
>
>emails:?vivek.das at ieo.eu
>??? ??? ??? vchris_05 at yahoo.co.in
>??? ??? ??? vd4mmind at gmail.com
>


From dwinsemius at comcast.net  Mon Sep  9 21:42:22 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 9 Sep 2013 12:42:22 -0700
Subject: [R] Problem adding lines to a plot, when y is defined
In-Reply-To: <86658a5f496d44718a021de910b432ce@AMXPR03MB023.eurprd03.prod.outlook.com>
References: <d0558fa1f2dc4dffaf183b08ae663b49@AMXPR03MB023.eurprd03.prod.outlook.com>,
	<84FE6A09-76AE-4320-8F40-8A978F7E6CF3@comcast.net>
	<7d811a7e653241aeb768529c3e0bac27@AMXPR03MB023.eurprd03.prod.outlook.com>,
	<8AAD2E23-CD33-45CB-9CDE-F12DBDB98ABA@comcast.net>
	<86658a5f496d44718a021de910b432ce@AMXPR03MB023.eurprd03.prod.outlook.com>
Message-ID: <311F187D-AE6D-409D-859B-4B3C9CB30C65@comcast.net>


On Sep 9, 2013, at 12:27 PM, Cech, Christian wrote:

>>> On Sep 9, 2013, at 9:00 AM, Cech, Christian wrote:
>>> 
>>>> Dear all,
>>>> 
>>>> I want to create a line-plot with two lines and some additional scatter-plots.
>>>> However, adding a line to the plot does not work when I specify the y-argument in the plot command, while it does work when y is not specified.
>>>> 
>>>> I first send you an example that works:
>>>> plot(var[, 3],
>>>>   type="l",
>>>>   ylim=c(-0.04, 0),
>>>>   ylab   = 'portfolio returns',
>>>>   xlab   = 'time')
>>>> lines(var[, 5], type="l", lty=3)
>>>> for (i in 1:nrow(var)) {
>>>> if(var[i, 4] | var[i,6])
>>>>  points(i, var[i, 2], pch=4)
>>>> }
>>>> 
>>>> --> the result is displayed in attachment "Plot1.pdf"
>>>> 
>>>> What does not work is the following code, where as the first argument of plot (ie the y-argument) is defined:
>>>> plot(as.Date(var[, 1], origin="1899-12-30"),
>>>>   var[, 3],
>>>>   type="l",
>>>>   ylim=c(-0.04, 0),
>>>>   ylab='portfolio returns',
>>>>   xlab='time')
>>>> lines(var[, 5], type="l", lty=3)
>>>> for (i in 1:nrow(var)) {
>>>> if(var[i, 4] | var[i,6])
>>>>  points(i, var[i, 2], pch=4)
>>>> }
>>>> 
>>>> --> the result is displayed in attachment "Plot2.pdf"
>>>> 
>>>> The same problem appears if instead of
>>>> 
>>>> as.Date(var[, 1], origin="1899-12-30")
>>>> 
>>>> I use
>>>> 
>>>> var[, 1]
>>>> 
>>>> to define the y-argument.
>>> 
>>> This puzzles me. At the moment yu are using postional matching and it is var[,3] that would be matched to the y argument.
>>> 
>>> You need to post output of str(var) so that we can see the class of var[,1].
>>> 
>>> 
> 
>> Dear David,
>> 
>> thank you for the quick reply! Unfortunately I confused you because I mixed up y-value and x-value. What I actually wanted to say is that the plot does not work when x is specified (2nd example) while it does work if x is not specified (1st example). Sorry for this!
>> y = var[, 3]
>> x = var[, 1]
>> 
>> When I type str(var) i get the following output:
>> num [1:4747, 1:6] 33450 33451 33452 33455 33456 ...
>> 
>> Is that the information you needed?
> 
> Maybe. 'var' is  a numeric matrix which may not be what you think it was if it started out life as having dates. (On this list it is requested that you post in context which means bottom posting in many cases. So I moved your reply.)
> 
> When you apply the as.Date function with an origin, you will get an different number as the internal representation of the Date value than what you put in:
> 
> as.numeric(as.Date(c(33450, 33451, 33452, 33455, 33456), origin="1899-01-01"))
> [1] 7518 7519 7520 7523 7524
> I suspect that you have a misregistration of the x values. Since it is a matrix we might have better view of it with:
> 
> dput(head(var))
> 
> I also supect that you will end up using the `axis` function to do your labeling.
> 
> --
> 
> David Winsemius
> Alameda, CA, USA
> 
>> dput(head(var))
> structure(c(33450, 33451, 33452, 33455, 33456, 33457, -0.00299369609998333,
> -0.000882805884818571, -0.000570821462061429, 0.00735101809395667,
> -0.000574642535598095, -0.000464474459045714, -0.010510137214196,
> -0.0105173750100507, -0.0104987866171353, -0.0104808796029616,
> -0.0104561013745608, -0.0104562836793838, 0, 0, 0, 0, 0, 0, -0.0115901618181903,
> -0.0115901618181903, -0.0115901618181903, -0.0115901618181903,
> -0.0115901618181903, -0.0115901618181903, 0, 0, 0, 0, 0, 0), .Dim = c(6L,
> 6L), .Dimnames = list(NULL, c("col1", "col2", "col3", "col4",
> "col5", "col6")))
> 
> 

You need to get the x-axis values registered corectly for `lines` and `points` calls:

plot(as.Date(var[, 1], origin="1899-12-30"),
  var[, 3],
  type="l",
  ylim=c(-0.04, 0),
  ylab='portfolio returns',
  xlab='time')
dts <- as.numeric(as.Date(var[, 1], origin="1899-12-30"));lines(dts, var[, 5], type="l", lty=3)
for (i in 1:nrow(var)) {
if(var[i, 4] | var[i,6])
 points(dts[i], var[i, 2], pch=4)

-- 

David Winsemius
Alameda, CA, USA


From es at enricoschumann.net  Mon Sep  9 22:00:58 2013
From: es at enricoschumann.net (Enrico Schumann)
Date: Mon, 09 Sep 2013 22:00:58 +0200
Subject: [R] Problem adding lines to a plot, when y is defined
In-Reply-To: <d0558fa1f2dc4dffaf183b08ae663b49@AMXPR03MB023.eurprd03.prod.outlook.com>
	(Christian Cech's message of "Mon, 9 Sep 2013 16:00:51 +0000")
References: <d0558fa1f2dc4dffaf183b08ae663b49@AMXPR03MB023.eurprd03.prod.outlook.com>
Message-ID: <87y5759345.fsf@enricoschumann.net>

On Mon, 09 Sep 2013, "Cech, Christian" <Christian.Cech at fh-vie.ac.at> writes:

> Dear all,
>
> I want to create a line-plot with two lines and some additional scatter-plots.
> However, adding a line to the plot does not work when I specify the y-argument in the plot command, while it does work when y is not specified.
>
> I first send you an example that works:
> plot(var[, 3],
>      type="l",
>      ylim=c(-0.04, 0),
>      ylab   = 'portfolio returns',
>      xlab   = 'time')
> lines(var[, 5], type="l", lty=3)
> for (i in 1:nrow(var)) {
>   if(var[i, 4] | var[i,6])
>     points(i, var[i, 2], pch=4)
> }
>
> --> the result is displayed in attachment "Plot1.pdf"
>
> What does not work is the following code, where as the first argument of plot (ie the y-argument) is defined:
> plot(as.Date(var[, 1], origin="1899-12-30"),
>      var[, 3],
>      type="l",
>      ylim=c(-0.04, 0),
>      ylab='portfolio returns',
>      xlab='time')
> lines(var[, 5], type="l", lty=3)
> for (i in 1:nrow(var)) {
>   if(var[i, 4] | var[i,6])
>     points(i, var[i, 2], pch=4)
> }
>
> --> the result is displayed in attachment "Plot2.pdf"
>
> The same problem appears if instead of
>
> as.Date(var[, 1], origin="1899-12-30")
>
> I use
>
> var[, 1]
>
> to define the y-argument.

Hard to say without a reproducible example, but try 

  lines(as.Date(var[, 1], origin="1899-12-30"),  var[, 5])

instead.

>
> I do very much appreciate your help!
> Kind regards,
> Christian Cech
>

[...]


-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From macqueen1 at llnl.gov  Mon Sep  9 22:22:38 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 9 Sep 2013 20:22:38 +0000
Subject: [R] Problem adding lines to a plot, when y is defined
In-Reply-To: <d0558fa1f2dc4dffaf183b08ae663b49@AMXPR03MB023.eurprd03.prod.outlook.com>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521910D435422@PRDEXMBX-08.the-lab.llnl.gov>

In the second example, in the three functions that create the plot:

 plot()
 lines()
 points()

all must have two arguments, the first of which is the x-values (dates),
and the second of which is the y-values associated with the dates.

For example, in your second version, where you have
   points(i, var[i, 2], pch=4)
you want to replace i with the date associated with the i'th row in your
data.

You may also be slightly confused about which argument to plot() is the
"y-argument". In your second example, the y-argument is the second
argument, not the first.

Compare the results of these two commands:

   plot(  c(5,3,6) )
   plot(  c(2,9,10) , c(5,3,6) )



-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 9/9/13 9:00 AM, "Cech, Christian" <Christian.Cech at fh-vie.ac.at> wrote:

>Dear all,
>
>I want to create a line-plot with two lines and some additional
>scatter-plots.
>However, adding a line to the plot does not work when I specify the
>y-argument in the plot command, while it does work when y is not
>specified.
>
>I first send you an example that works:
>plot(var[, 3],
>     type="l",
>     ylim=c(-0.04, 0),
>     ylab   = 'portfolio returns',
>     xlab   = 'time')
>lines(var[, 5], type="l", lty=3)
>for (i in 1:nrow(var)) {
>  if(var[i, 4] | var[i,6])
>    points(i, var[i, 2], pch=4)
>}
>
>--> the result is displayed in attachment "Plot1.pdf"
>
>What does not work is the following code, where as the first argument of
>plot (ie the y-argument) is defined:
>plot(as.Date(var[, 1], origin="1899-12-30"),
>     var[, 3],
>     type="l",
>     ylim=c(-0.04, 0),
>     ylab='portfolio returns',
>     xlab='time')
>lines(var[, 5], type="l", lty=3)
>for (i in 1:nrow(var)) {
>  if(var[i, 4] | var[i,6])
>    points(i, var[i, 2], pch=4)
>}
>
>--> the result is displayed in attachment "Plot2.pdf"
>
>The same problem appears if instead of
>
>as.Date(var[, 1], origin="1899-12-30")
>
>I use
>
>var[, 1]
>
>to define the y-argument.
>
>I do very much appreciate your help!
>Kind regards,
>Christian Cech
>
>________________________________
>
>
>Firmenwortlaut: Fachhochschule des bfi Wien Gesellschaft m.b.H
>Firmenbuchnummer: 148597 a
>Firmenbuchgericht: Handelsgericht Wien
>Firmensitz: Wohlmutstra?e 22, 1020 Wien
>
>This message contains confidential information and is i...{{dropped:12}}


From ripley at stats.ox.ac.uk  Mon Sep  9 23:39:12 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 09 Sep 2013 22:39:12 +0100
Subject: [R] Fitting Arima Models and Forecasting Using Daily Historical
 Data
In-Reply-To: <CAMOcQfNm7bNcOQqO73nHnHoSBk3s2stuAgFNaSrYPh=p04WdBg@mail.gmail.com>
References: <CAMOcQfNm7bNcOQqO73nHnHoSBk3s2stuAgFNaSrYPh=p04WdBg@mail.gmail.com>
Message-ID: <522E4000.9080909@stats.ox.ac.uk>

On 09/09/2013 20:36, Paul Bernal wrote:
> Hello everyone,
>
> I was trying to fit an arima model to a daily historical data, but, for
> some reason, havent been able to.
>
> I basically have 212 observations (from 12/1/2012 to 06/30/2013) containing

Those dates are not in a standard format: ISO 8601 is preferred.

> the number of transits for a particular vessel.

Which seems to be less than a year and you are trying to fit a 
seasonally differenced model with period 365.  So I guess there are no 
pairs of observations a year apart.

This is not really an R issue: you need to get basic advice on 
time-series modelling.

> The following messages are produced by R:
>
> dailytrans.fit<-arima(dailytrans$transits, order=c(0,1,2),
> seasonal=list(order=c(0,1,2), period=365), include.mean=FALSE)
> Error in arima(dailytrans$transits, order = c(0, 1, 2), seasonal =
> list(order = c(0,  :
>    too few non-missing observations
>> dailytrans.fit<-arima(dailytrans$transits, order=c(0,1,2),
> seasonal=list(order=c(0,1,2), period=200), include.mean=FALSE)
> Error in makeARIMA(trarma[[1]], trarma[[2]], Delta, kappa) :
>    maximum supported lag is 350
>
> Then I tried the auto.arima function but the following happened:

Which is not part of R.

> fit<-auto.arima(dailytrans$transits)
>
> Warning in if (class(fit) != "try-error") offset <- -2 * fit$loglik -
> length(x) *  :
>
>    the condition has length > 1 and only the first element will be used
>
> If anyone could give me some guidance I will really truly appreciate it,
>
>
> Best regards,
>
>
> Paul



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From paulbernal07 at gmail.com  Tue Sep 10 00:14:30 2013
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Mon, 9 Sep 2013 17:14:30 -0500
Subject: [R] Fitting Arima Models and Forecasting Using Daily Historical
	Data
In-Reply-To: <522E4000.9080909@stats.ox.ac.uk>
References: <CAMOcQfNm7bNcOQqO73nHnHoSBk3s2stuAgFNaSrYPh=p04WdBg@mail.gmail.com>
	<522E4000.9080909@stats.ox.ac.uk>
Message-ID: <CAMOcQfNdRO4kohwozGvs1deSjfVLbj8VyxZym8UNFrYy+wxW5A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130909/14cee4aa/attachment.pl>

From murdoch.duncan at gmail.com  Tue Sep 10 00:30:55 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 09 Sep 2013 18:30:55 -0400
Subject: [R] Fitting Arima Models and Forecasting Using Daily Historical
 Data
In-Reply-To: <CAMOcQfNdRO4kohwozGvs1deSjfVLbj8VyxZym8UNFrYy+wxW5A@mail.gmail.com>
References: <CAMOcQfNm7bNcOQqO73nHnHoSBk3s2stuAgFNaSrYPh=p04WdBg@mail.gmail.com>
	<522E4000.9080909@stats.ox.ac.uk>
	<CAMOcQfNdRO4kohwozGvs1deSjfVLbj8VyxZym8UNFrYy+wxW5A@mail.gmail.com>
Message-ID: <522E4C1F.2030302@gmail.com>

On 13-09-09 6:14 PM, Paul Bernal wrote:
> Dear Mr. Brian,
>
> What is the ISO 8601 standard for dates?

http://lmgtfy.com/?q=ISO+8601

Duncan Murdoch

>
> Excuse my ignorance and best regards,
>
> Paul
>   El 09/09/2013 16:41, "Prof Brian Ripley" <ripley at stats.ox.ac.uk> escribi?:
>
>> On 09/09/2013 20:36, Paul Bernal wrote:
>>
>>> Hello everyone,
>>>
>>> I was trying to fit an arima model to a daily historical data, but, for
>>> some reason, havent been able to.
>>>
>>> I basically have 212 observations (from 12/1/2012 to 06/30/2013)
>>> containing
>>>
>>
>> Those dates are not in a standard format: ISO 8601 is preferred.
>>
>>   the number of transits for a particular vessel.
>>>
>>
>> Which seems to be less than a year and you are trying to fit a seasonally
>> differenced model with period 365.  So I guess there are no pairs of
>> observations a year apart.
>>
>> This is not really an R issue: you need to get basic advice on time-series
>> modelling.
>>
>>   The following messages are produced by R:
>>>
>>> dailytrans.fit<-arima(**dailytrans$transits, order=c(0,1,2),
>>> seasonal=list(order=c(0,1,2), period=365), include.mean=FALSE)
>>> Error in arima(dailytrans$transits, order = c(0, 1, 2), seasonal =
>>> list(order = c(0,  :
>>>     too few non-missing observations
>>>
>>>> dailytrans.fit<-arima(**dailytrans$transits, order=c(0,1,2),
>>>>
>>> seasonal=list(order=c(0,1,2), period=200), include.mean=FALSE)
>>> Error in makeARIMA(trarma[[1]], trarma[[2]], Delta, kappa) :
>>>     maximum supported lag is 350
>>>
>>> Then I tried the auto.arima function but the following happened:
>>>
>>
>> Which is not part of R.
>>
>>   fit<-auto.arima(dailytrans$**transits)
>>>
>>> Warning in if (class(fit) != "try-error") offset <- -2 * fit$loglik -
>>> length(x) *  :
>>>
>>>     the condition has length > 1 and only the first element will be used
>>>
>>> If anyone could give me some guidance I will really truly appreciate it,
>>>
>>>
>>> Best regards,
>>>
>>>
>>> Paul
>>>
>>
>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~**ripley/<http://www.stats.ox.ac.uk/~ripley/>
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>> ______________________________**________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide http://www.R-project.org/**
>> posting-guide.html <http://www.R-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Tue Sep 10 00:23:56 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 9 Sep 2013 15:23:56 -0700 (PDT)
Subject: [R] replacing Na's with values on different records
In-Reply-To: <595D6D39142B7847B7638CF46AF84F0AED1C4D@NDHAMREXDE05.amer.pfizer.com>
References: <27583015.285071.1378743277927.JavaMail.nabble@joe.nabble.com>
	<595D6D39142B7847B7638CF46AF84F0AED17C9@NDHAMREXDE05.amer.pfizer.com>
	<1378757829.12282.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<595D6D39142B7847B7638CF46AF84F0AED1A70@NDHAMREXDE05.amer.pfizer.com>
	<1378760388.90826.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<595D6D39142B7847B7638CF46AF84F0AED1C4D@NDHAMREXDE05.amer.pfizer.com>
Message-ID: <1378765436.46353.YahooMailNeo@web142602.mail.bf1.yahoo.com>

HI Ahmed,

No problem.

You got the error because one of the IDs had all NAs for AUC24.



Also, In your dataset, there are NAs in BLADDERWALL, BLADDERWALLC, AUC12d, 
Cmaxd,? in addition to WT, and AUC24.?? Do you want to follow any particular 
methodology for filling the NAs in these columns? or the filling of NAs 
are only applicable to AUC24.? 


res<-unsplit(lapply(split(u3s,u3s$ID),function(x) { x$AUC24<- if(all(is.na(x$AUC24))) NA else as.integer(x$AUC24[!is.na(x$AUC24)]/2)* (2^(0:floor(log(4,2))));x$WT<- if(all(is.na(x$WT))) NA else x$WT[!is.na(x$WT)];x}),u3s$ID)
res
#?? ID PERIOD DOSE VOL1stD MCC BLADDERWALL visit VOL1stDC MCCC BLADDERWALLC
#1 101???? p1 0.03????? 22? 72???????? 2.9???? 3?????? -8? -21????????? 1.2
#2 101???? p2 0.06????? 24? 80???????? 1.0???? 4?????? -6? -13???????? -0.7
#3 101???? p3 0.12????? 17? 59???????? 4.6???? 5????? -13? -34????????? 2.9
#4 102???? p1 0.03?????? 5? 25???????? 0.3???? 3????? -10? -20???????? -1.3
#5 102???? p2 0.06????? 67 125????????? NA???? 4?????? 52?? 80?????????? NA
#6 102???? p3 0.12????? 10? 24???????? 0.2???? 5?????? -5? -21???????? -1.4
#7 103???? p1 0.03?????? 6? 15???????? 0.0???? 3????? -23? -20???????? -0.1
#8 103???? p2 0.06????? 58? 72???????? 0.8???? 4?????? 29?? 37????????? 0.7
#9 103???? p3 0.12????? 15? 35???????? 0.5???? 5????? -14??? 0????????? 0.4
?#? AUC12d Cmaxd Cmind?? WT???????????????? PHENO RACE SEX???? AGE_y AUC24
#1????? NA??? NA??? NA 12.7????????????????????????? 1?? 2 1.8152448??? NA
#2????? NA??? NA??? NA 12.7????????????????????????? 1?? 2 1.8152448??? NA
#3????? NA??? NA??? NA 12.7????????????????????????? 1?? 2 1.8152448??? NA
#4????? NA??? NA??? NA 13.4 Extensive Metabolizer??? 1?? 1 2.1465338??? 10
#5 10.1150? 2.98???? 0 13.4 Extensive Metabolizer??? 1?? 1 2.1465338??? 20
#6????? NA??? NA??? NA 13.4 Extensive Metabolizer??? 1?? 1 2.1465338??? 40
#7????? NA??? NA??? NA 10.0????????????????????????? 1?? 1 0.5010404???? 4
#8? 4.5817? 1.41???? 0 10.0????????????????????????? 1?? 1 0.5010404???? 8
#9????? NA??? NA??? NA 10.0????????????????????????? 1?? 1 0.5010404??? 16




A.K.


----- Original Message -----
From: "El-Tahtawy, Ahmed" <Ahmed.El-Tahtawy at pfizer.com>
To: arun <smartpink111 at yahoo.com>
Cc: 
Sent: Monday, September 9, 2013 6:06 PM
Subject: RE: replacing Na's with values on different records

Dear Arun,

Thanks a million for the sophisticated code- it is little above my skill level. I never saw brilliant use of function x like this before!!( I am a clinical Pharmacologist who loves to explore patient data!!). it seems impossible to use for loop or a simpler function I guess?

The code worked with the simple data, tried to use it with actual data and got an error!!

################################################################################
dput(head(u3s,9))? ?  # only 3 patients

structure(list(ID = c(101L, 101L, 101L, 102L, 102L, 102L, 103L, 
103L, 103L), PERIOD = c("p1", "p2", "p3", "p1", "p2", "p3", "p1", 
"p2", "p3"), DOSE = c("0.03", "0.06", "0.12", "0.03", "0.06", 
"0.12", "0.03", "0.06", "0.12"), VOL1stD = c(22L, 24L, 17L, 5L, 
67L, 10L, 6L, 58L, 15L), MCC = c(72L, 80L, 59L, 25L, 125L, 24L, 
15L, 72L, 35L), BLADDERWALL = c(2.9, 1, 4.6, 0.3, NA, 0.2, 0, 
0.8, 0.5), visit = c(3L, 4L, 5L, 3L, 4L, 5L, 3L, 4L, 5L), VOL1stDC = c(-8L, 
-6L, -13L, -10L, 52L, -5L, -23L, 29L, -14L), MCCC = c(-21L, -13L, 
-34L, -20L, 80L, -21L, -20L, 37L, 0L), BLADDERWALLC = c(1.2, 
-0.7, 2.9, -1.3, NA, -1.4, -0.1, 0.7, 0.4), AUC12d = c(NA, NA, 
NA, NA, 10.115, NA, NA, 4.5817, NA), Cmaxd = c(NA, NA, NA, NA, 
2.98, NA, NA, 1.41, NA), Cmind = c(NA, NA, NA, NA, 0, NA, NA, 
0, NA), WT = c(NA, 12.7, NA, NA, 13.4, NA, NA, 10, NA), PHENO = c("", 
"", "", "Extensive Metabolizer", "Extensive Metabolizer", "Extensive Metabolizer", 
"", "", ""), RACE = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), SEX = c(2L, 
2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L), AGE_y = c(1.815244771, 1.815244771, 
1.815244771, 2.146533786, 2.146533786, 2.146533786, 0.501040412, 
0.501040412, 0.501040412), AUC24 = c(NA, NA, NA, NA, 20.23, NA, 
NA, 9.1634, NA)), .Names = c("ID", "PERIOD", "DOSE", "VOL1stD", 
"MCC", "BLADDERWALL", "visit", "VOL1stDC", "MCCC", "BLADDERWALLC", 
"AUC12d", "Cmaxd", "Cmind", "WT", "PHENO", "RACE", "SEX", "AGE_y", 
"AUC24"), row.names = c(NA, 9L), class = "data.frame")
######################################################################
Here is your code- changed current ID to ID & AUC to AUC24 to match actual data

u3s1<-unsplit(lapply(split(u3s,u3s$"ID"),function(x) {
? (x$AUC24<-as.integer(x$AUC24[!is.na(x$AUC24)]/2)* (2^(0:floor(log(4,2))))); 
? x$WT<- x$WT[!is.na(x$WT)];
? x }),u3s$"ID")

################################################################################
Error in `$<-.data.frame`(`*tmp*`, "AUC24", value = numeric(0)) : 
? replacement has 0 rows, data has 3




Thank you again for your time and help..
Ahmed 
.


-----Original Message-----
Fr
3 5:00 PM
To: El-Tahtawy, Ahmed
Subject: Re: replacing Na's with values on different records

HI Ahmed,
No problem.? Don't know if you didn't get the reply or not.? This is what I sent..
u3s<- read.table(text="Current-ID visit AUC Wight ID1
101 3 . . 1
101 4 10 13 2
101 5? . . 3
102 3 .? . 4
102 4 4 10 5
102 5 . . 6
103 3 . . 7
103 4 6 9 8
103 5 . . 9",sep="",header=TRUE,na.strings=".",check.names=FALSE)

u3d<- read.table(text="Desired-ID visit AUC Wight ID1
101 3 5 13 1
101 4 10 13 2
101 5 20 13 3
102 3 2 10 4
102 4 4 10 5
102 5 8 10 6
103 3 3 9 7
103 4 6 9 8
103 5 12 9 9",sep="",header=TRUE,check.names=FALSE)

?u3s1<-unsplit(lapply(split(u3s,u3s$`Current-ID`),function(x) {(x$AUC<-as.integer(x$AUC[!is.na(x$AUC)]/2)* (2^(0:floor(log(4,2))))); x$Wight<- x$Wight[!is.na(x$Wight)];x }),u3s$`Current-ID`)

attr(u3s1,"row.names")<- attr(u3d,"row.names")
colnames(u3s1)<- colnames(u3d)
all.equal(u3s1,u3d)






----- Original Message -----
From: "El-Tahtawy, Ahmed" <Ahmed.El-Tahtawy at pfizer.com>
To: arun <s
ubject: RE: replacing Na's with values on different records

Hi Arun,

Thanks a million...
I am looking forward to seeing your replay tomorrow.

Best Regards
Ahmed 
.


-----Original Message-----
F
13 4:17 PM
To: El-Tahtawy, Ahmed
Subject: Re: replacing Na's with values on different records

HI Ahmed,

I already sent the reply.? Let me know if that works.
A.K.




----- Original Message -----
From: "El-Tahtawy, Ahmed" <Ahmed.El-Tahtawy at pfizer.com>
To: "smartpink
 2013 2:50 PM
Subject: RE: replacing Na's with values on different records

Greeting,

Thank you for your quick response.

There are 5 columns and only 3 patients. the actual data has 50 variables and so many patients; but a simplified version is made to help focus on the main problem. I used dput as suggested and there an "L" added to all numbers!!

Please let me know if you have any more questions...

head(u3s,10)
?? ID visit AUC Wight ID1
1 101? ?? 3? NA? ? NA?? 1
2 101? ?? 4? 10? ? 13?? 2
3 101? ?? 5? NA? ? NA?? 3
4 102? ?? 3? NA? ? NA?? 4
5 102? ?? 4?? 4? ? 10?? 5
6 102? ?? 5? NA? ? NA?? 6
7 103? ?? 3? NA? ? NA?? 7
8 103? ?? 4?? 6? ?? 9?? 8
9 103? ?? 5? NA? ? NA?? 9

> dput(u3s)
structure(list(ID = c(101L, 101L, 101L, 102L, 102L, 102L, 103L, 103L, 103L), visit = c(3L, 4L, 5L, 3L, 4L, 5L, 3L, 4L, 5L), AUC = c(NA, 10L, NA, NA, 4L, NA, NA, 6L, NA), Wight = c(NA, 13L, NA, NA, 10L, NA, NA, 9L, NA), ID1 = 1:9), .Names = c("ID", "visit", "AUC", "Wight", "ID1"), class = "data.frame", row.names = c(NA, -9L))

Best Regards
Ahmed
.



, Ahmed
Subject: replacing Na's with values on different records

HI,

The example dataset "Current" and "Desired" are mangled by HTML.? It is not clear how many columns you have.? I tried it like this, but still it is still not clear..

ID visit AUC Wight ID1
101 3 1 101 4
10 13 2 101 5
3 102 3 4 102
4 4 10 5 102
5 6 103 3 7
103 4 6 9 8
103 5 9?? ####two elements are missing.

Please use ?dput()
For e.g.
dput(head(dataset,20))

<quote author='El-Tahtawy, Ahmed'>
I'm sure I'm missing something really obvious in the "for loop"...

Here is simplified data for 3 patients, we need filling in Na's with same WT for each patient, AUC halved for visit 3, doubled for visit 5 for the same patient, based on visit 4


for(i in unique(u3s$ID)){? ? ? ? ? ? ? ? ? ? ? ? ? ?? #fill in same Wt for each patient
? u3s$WT <- ifelse(is.na(u3s$WT),u3s$WT[u3s$visit == "4"],u3s$WT)

? for(j in length(u3s$ID1)){? ? ? ? ? ? ? ? ? ? ? ? #fill in .5 AUC for visit 3, 2*AUC for visit 5

? ? u3s$AUC24 <- ifelse(is.na(u3s$AUC24),u3s$AUC24[u3s$visit ==
"4"]*0.5,u3s$AUC24)
? ? u3s$AUC24 <- ifelse(!is.na(u3s$AUC24),u3s$AUC24[u3s$visit ==
"4"]*1.0,u3s$AUC24)
? ? u3s$AUC24 <- ifelse(is.na(u3s$AUC24),u3s$AUC24[u3s$visit ==
"4"]*2.0,u3s$AUC24)
? }
}

Current-
ID

visit

AUC

Wight

ID1

101

3





1

101

4

10

13

2

101

5





3

102

3





4

102

4

4

10

5

102

5





6

103

3





7

103

4

6

9

8

103

5





9


Desired-

ID

visit

AUC

Wight

ID1

101

3

5

13

1

101

4

10

13

2

101

5

20

13

3

102

3

2

10

4

102

4

4

10

5

102

5

8

10

6

103

3

3

9

7

103

4

6

9

8

103

5

12

9

9



Your help is greatly appreciated...


Best Regards

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

</quote>
Quoted from: 
http://r.789695.n4.nabble.com/replacing-Na-s-with-values-on-different-records-tp4675696.html


_____________________________________
Sent from http://r.789695.n4.nabble.com



From smartpink111 at yahoo.com  Tue Sep 10 00:58:41 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 9 Sep 2013 15:58:41 -0700 (PDT)
Subject: [R] replacing Na's with values on different records
In-Reply-To: <1378765436.46353.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <27583015.285071.1378743277927.JavaMail.nabble@joe.nabble.com>
	<595D6D39142B7847B7638CF46AF84F0AED17C9@NDHAMREXDE05.amer.pfizer.com>
	<1378757829.12282.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<595D6D39142B7847B7638CF46AF84F0AED1A70@NDHAMREXDE05.amer.pfizer.com>
	<1378760388.90826.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<595D6D39142B7847B7638CF46AF84F0AED1C4D@NDHAMREXDE05.amer.pfizer.com>
	<1378765436.46353.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1378767521.58640.YahooMailNeo@web142604.mail.bf1.yahoo.com>



HI Ahmed,

No problem.

You got the error because one of the IDs had all NAs for AUC24.
Also, In your dataset, there are NAs in BLADDERWALL, BLADDERWALLC, AUC12d, 
Cmaxd,? in addition to WT, and AUC24.? How do you want to fill those NAs?


res<-unsplit(lapply(split(u3s,u3s$ID),function(x) { x$AUC24<- if(all(is.na(x$AUC24))) NA else as.integer(x$AUC24[!is.na(x$AUC24)]/2)* (2^(0:floor(log(4,2))));x$WT<- if(all(is.na(x$WT))) NA else x$WT[!is.na(x$WT)];x}),u3s$ID)
res
#?? ID PERIOD DOSE VOL1stD MCC BLADDERWALL visit VOL1stDC MCCC BLADDERWALLC
#1 101???? p1 0.03????? 22? 72???????? 2.9???? 3?????? -8? -21????????? 1.2
#2 101???? p2 0.06????? 24? 80???????? 1.0???? 4?????? -6? -13???????? -0.7
#3 101???? p3 0.12????? 17? 59???????? 4.6???? 5????? -13? -34????????? 2.9
#4 102???? p1 0.03?????? 5? 25???????? 0.3???? 3????? -10? -20???????? -1.3
#5 102???? p2 0.06????? 67 125????????? NA???? 4?????? 52?? 80?????????? NA
#6 102???? p3 0.12????? 10? 24???????? 0.2???? 5?????? -5? -21???????? -1.4
#7 103???? p1 0.03?????? 6? 15???????? 0.0???? 3????? -23? -20???????? -0.1
#8 103???? p2 0.06????? 58? 72???????? 0.8???? 4?????? 29?? 37????????? 0.7
#9 103???? p3 0.12????? 15? 35???????? 0.5???? 5????? -14??? 0????????? 0.4
?#? AUC12d Cmaxd Cmind?? WT???????????????? PHENO RACE SEX???? AGE_y AUC24
#1????? NA??? NA??? NA 12.7????????????????????????? 1?? 2 1.8152448??? NA
#2????? NA??? NA??? NA 12.7????????????????????????? 1?? 2 1.8152448??? NA
#3????? NA??? NA??? NA 12.7????????????????????????? 1?? 2 1.8152448??? NA
#4????? NA??? NA??? NA 13.4 Extensive Metabolizer??? 1?? 1 2.1465338??? 10
#5 10.1150? 2.98???? 0 13.4 Extensive Metabolizer??? 1?? 1 2.1465338??? 20
#6????? NA??? NA??? NA 13.4 Extensive Metabolizer??? 1?? 1 2.1465338??? 40
#7????? NA??? NA??? NA 10.0????????????????????????? 1?? 1 0.5010404???? 4
#8? 4.5817? 1.41???? 0 10.0????????????????????????? 1?? 1 0.5010404???? 8
#9????? NA??? NA??? NA 10.0????????????????????????? 1?? 1 0.5010404??? 16

A.K.


----- Original Message -----
From: "El-Tahtawy, Ahmed" <Ahmed.El-Tahtawy at pfizer.com>
To: arun <smartpink111 at yahoo.com>
Cc: 
Sent: Monday, September 9, 2013 6:06 PM
Subject: RE: replacing Na's with values on different records

Dear Arun,

Thanks a million for the sophisticated code- it is little above my skill level. I never saw brilliant use of function x like this before!!( I am a clinical Pharmacologist who loves to explore patient data!!). it seems impossible to use for loop or a simpler function I guess?

The code worked with the simple data, tried to use it with actual data and got an error!!

################################################################################
dput(head(u3s,9))? ?? # only 3 patients

structure(list(ID = c(101L, 101L, 101L, 102L, 102L, 102L, 103L, 
103L, 103L), PERIOD = c("p1", "p2", "p3", "p1", "p2", "p3", "p1", 
"p2", "p3"), DOSE = c("0.03", "0.06", "0.12", "0.03", "0.06", 
"0.12", "0.03", "0.06", "0.12"), VOL1stD = c(22L, 24L, 17L, 5L, 
67L, 10L, 6L, 58L, 15L), MCC = c(72L, 80L, 59L, 25L, 125L, 24L, 
15L, 72L, 35L), BLADDERWALL = c(2.9, 1, 4.6, 0.3, NA, 0.2, 0, 
0.8, 0.5), visit = c(3L, 4L, 5L, 3L, 4L, 5L, 3L, 4L, 5L), VOL1stDC = c(-8L, 
-6L, -13L, -10L, 52L, -5L, -23L, 29L, -14L), MCCC = c(-21L, -13L, 
-34L, -20L, 80L, -21L, -20L, 37L, 0L), BLADDERWALLC = c(1.2, 
-0.7, 2.9, -1.3, NA, -1.4, -0.1, 0.7, 0.4), AUC12d = c(NA, NA, 
NA, NA, 10.115, NA, NA, 4.5817, NA), Cmaxd = c(NA, NA, NA, NA, 
2.98, NA, NA, 1.41, NA), Cmind = c(NA, NA, NA, NA, 0, NA, NA, 
0, NA), WT = c(NA, 12.7, NA, NA, 13.4, NA, NA, 10, NA), PHENO = c("", 
"", "", "Extensive Metabolizer", "Extensive Metabolizer", "Extensive Metabolizer", 
"", "", ""), RACE = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), SEX = c(2L, 
2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L), AGE_y = c(1.815244771, 1.815244771, 
1.815244771, 2.146533786, 2.146533786, 2.146533786, 0.501040412, 
0.501040412, 0.501040412), AUC24 = c(NA, NA, NA, NA, 20.23, NA, 
NA, 9.1634, NA)), .Names = c("ID", "PERIOD", "DOSE", "VOL1stD", 
"MCC", "BLADDERWALL", "visit", "VOL1stDC", "MCCC", "BLADDERWALLC", 
"AUC12d", "Cmaxd", "Cmind", "WT", "PHENO", "RACE", "SEX", "AGE_y", 
"AUC24"), row.names = c(NA, 9L), class = "data.frame")
######################################################################
Here is your code- changed current ID to ID & AUC to AUC24 to match actual data

u3s1<-unsplit(lapply(split(u3s,u3s$"ID"),function(x) {
? (x$AUC24<-as.integer(x$AUC24[!is.na(x$AUC24)]/2)* (2^(0:floor(log(4,2))))); 
? x$WT<- x$WT[!is.na(x$WT)];
? x }),u3s$"ID")

################################################################################
Error in `$<-.data.frame`(`*tmp*`, "AUC24", value = numeric(0)) : 
? replacement has 0 rows, data has 3




Thank you again for your time and help..
Ahmed 
.


-----Origi
ay, September 09, 2013 5:00 PM
To: El-Tahtawy, Ahmed
Subject: Re: replacing Na's with values on different records

HI Ahmed,
No problem.? Don't know if you didn't get the reply or not.? This is what I sent..
u3s<- read.table(text="Current-ID visit AUC Wight ID1
101 3 . . 1
101 4 10 13 2
101 5? . . 3
102 3 .? . 4
102 4 4 10 5
102 5 . . 6
103 3 . . 7
103 4 6 9 8
103 5 . . 9",sep="",header=TRUE,na.strings=".",check.names=FALSE)

u3d<- read.table(text="Desired-ID visit AUC Wight ID1
101 3 5 13 1
101 4 10 13 2
101 5 20 13 3
102 3 2 10 4
102 4 4 10 5
102 5 8 10 6
103 3 3 9 7
103 4 6 9 8
103 5 12 9 9",sep="",header=TRUE,check.names=FALSE)

?u3s1<-unsplit(lapply(split(u3s,u3s$`Current-ID`),function(x) {(x$AUC<-as.integer(x$AUC[!is.na(x$AUC)]/2)* (2^(0:floor(log(4,2))))); x$Wight<- x$Wight[!is.na(x$Wight)];x }),u3s$`Current-ID`)

attr(u3s1,"row.names")<- attr(u3d,"row.names")
colnames(u3s1)<- colnames(u3d)
all.equal(u3s1,u3d)






----- Original Message -----
From: "El-Tahtawy, Ahmed" <Ahmed.El-Tahtawy at pfizer
9, 2013 4:48 PM
Subject: RE: replacing Na's with values on different records

Hi Arun,

Thanks a million...
I am looking forward to seeing your replay tomorrow.

Best Regards
Ahmed 
.


-----Original
 September 09, 2013 4:17 PM
To: El-Tahtawy, Ahmed
Subject: Re: replacing Na's with values on different records

HI Ahmed,

I already sent the reply.? Let me know if that works.
A.K.




----- Original Message -----
From: "El-Tahtawy, Ahmed" <Ahmed.El-Tahtawy at pfizer.com>
day, September 9, 2013 2:50 PM
Subject: RE: replacing Na's with values on different records

Greeting,

Thank you for your quick response.

There are 5 columns and only 3 patients. the actual data has 50 variables and so many patients; but a simplified version is made to help focus on the main problem. I used dput as suggested and there an "L" added to all numbers!!

Please let me know if you have any more questions...

head(u3s,10)
?? ID visit AUC Wight ID1
1 101? ?? 3? NA? ? NA?? 1
2 101? ?? 4? 10? ? 13?? 2
3 101? ?? 5? NA? ? NA?? 3
4 102? ?? 3? NA? ? NA?? 4
5 102? ?? 4?? 4? ? 10?? 5
6 102? ?? 5? NA? ? NA?? 6
7 103? ?? 3? NA? ? NA?? 7
8 103? ?? 4?? 6? ?? 9?? 8
9 103? ?? 5? NA? ? NA?? 9

> dput(u3s)
structure(list(ID = c(101L, 101L, 101L, 102L, 102L, 102L, 103L, 103L, 103L), visit = c(3L, 4L, 5L, 3L, 4L, 5L, 3L, 4L, 5L), AUC = c(NA, 10L, NA, NA, 4L, NA, NA, 6L, NA), Wight = c(NA, 13L, NA, NA, 10L, NA, NA, 9L, NA), ID1 = 1:9), .Names = c("ID", "visit", "AUC", "Wight", "ID1"), class = "data.frame", row.names = c(NA, -9L))

Best Regards

M
To: El-Tahtawy, Ahmed
Subject: replacing Na's with values on different records

HI,

The example dataset "Current" and "Desired" are mangled by HTML.? It is not clear how many columns you have.? I tried it like this, but still it is still not clear..

ID visit AUC Wight ID1
101 3 1 101 4
10 13 2 101 5
3 102 3 4 102
4 4 10 5 102
5 6 103 3 7
103 4 6 9 8
103 5 9?? ####two elements are missing.

Please use ?dput()
For e.g.
dput(head(dataset,20))

<quote author='El-Tahtawy, Ahmed'>
I'm sure I'm missing something really obvious in the "for loop"...

Here is simplified data for 3 patients, we need filling in Na's with same WT for each patient, AUC halved for visit 3, doubled for visit 5 for the same patient, based on visit 4


for(i in unique(u3s$ID)){? ? ? ? ? ? ? ? ? ? ? ? ? ?? #fill in same Wt for each patient
? u3s$WT <- ifelse(is.na(u3s$WT),u3s$WT[u3s$visit == "4"],u3s$WT)

? for(j in length(u3s$ID1)){? ? ? ? ? ? ? ? ? ? ? ? #fill in .5 AUC for visit 3, 2*AUC for visit 5

? ? u3s$AUC24 <- ifelse(is.na(u3s$AUC24),u3s$AUC24[u3s$visit ==
"4"]*0.5,u3s$AUC24)
? ? u3s$AUC24 <- ifelse(!is.na(u3s$AUC24),u3s$AUC24[u3s$visit ==
"4"]*1.0,u3s$AUC24)
? ? u3s$AUC24 <- ifelse(is.na(u3s$AUC24),u3s$AUC24[u3s$visit ==
"4"]*2.0,u3s$AUC24)
? }
}

Current-
ID

visit

AUC

Wight

ID1

101

3





1

101

4

10

13

2

101

5





3

102

3





4

102

4

4

10

5

102

5





6

103

3





7

103

4

6

9

8

103

5





9


Desired-

ID

visit

AUC

Wight

ID1

101

3

5

13

1

101

4

10

13

2

101

5

20

13

3

102

3

2

10

4

102

4

4

10

5

102

5

8

10

6

103

3

3

9

7

103

4

6

9

8

103

5

12

9

9



Your help is greatly appreciated...


Best Regards

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

</quote>
Quoted from: 
http://r.789695.n4.nabble.com/replacing-Na-s-with-values-on-different-records-tp4675696.html


_____________________________________
Sent from http://r.789695.n4.nabble.com



From erinm.hodgess at gmail.com  Tue Sep 10 03:33:19 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Mon, 9 Sep 2013 20:33:19 -0500
Subject: [R] question about rSymPy and integration
Message-ID: <CACxE24nLAezKpAZ8Ht3TeYS+JgF9qMWmdd9n+x2m6Vkx1XJu6w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130909/4dca4106/attachment.pl>

From murray at stokely.org  Tue Sep 10 06:15:28 2013
From: murray at stokely.org (Murray Stokely)
Date: Mon, 9 Sep 2013 21:15:28 -0700
Subject: [R] Cramer von Mises test for a discrete distribution
In-Reply-To: <1361367029.3688.YahooMailNeo@web160806.mail.bf1.yahoo.com>
References: <d0780416866c4bfc890b71074b19bc80@EX-1-HT0.lancs.local>
	<CANVKczOvfbSAS==mqjfpWAadXo4ia9TNqAFFucAYUH5dYvHa_A@mail.gmail.com>
	<6ebd9ccdf6424ed6bcf5e530046b2477@EX-1-HT0.lancs.local>
	<CANVKczMHAfJPz+cNshDaUcvcHYhYZnUwCRYN8jaN=iT2yPbbnQ@mail.gmail.com>
	<1361367029.3688.YahooMailNeo@web160806.mail.bf1.yahoo.com>
Message-ID: <CAECWziJfr4uSUU8cfUZo1nEm4rv=xX+XvKQMLeNkB9U-pDCcXA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130909/b198e673/attachment.pl>

From sewal026 at umn.edu  Mon Sep  9 22:45:34 2013
From: sewal026 at umn.edu (sewal026 at umn.edu)
Date: 09 Sep 2013 15:45:34 -0500
Subject: [R] Need to learn or get R tutor in Minneapolis
Message-ID: <Gophermail.2.0.1309091545340.10317@vs-w.tc.umn.edu>

Please advise

-- 
 Barrett


From lucagaegauf at gmx.ch  Tue Sep 10 02:11:33 2013
From: lucagaegauf at gmx.ch (lpupp)
Date: Mon, 9 Sep 2013 17:11:33 -0700 (PDT)
Subject: [R] How are tables accessed?
Message-ID: <1378771893490-4675736.post@n4.nabble.com>

Hey everyone,

I have a small problem understanding how matrices are accessed.

I created 2 matrices: 

data <- structure(c("A", "B", "C", "D", "D", "E", "H", "H", "H", "I", 
                    "F", "G", "F", "F", "G", "G", "F", "G", "I", "J"), 
                  .Dim = c(10L, 2L), .Dimnames = list(NULL, c("source",
"target")))

layout <- structure(c(-3.26366930571836, -5.50712710968822,
-0.551118328281495, -3.37122322327009, -5.66968864118556, -2.33181335195352,
-0.48117505795906, -7.44294029152183, -9.97273217503719, -8.78752994522558,
-8.32625987988611, -5.19337297863283, -1.01252729738437, -2.2253279705488,
-8.08918461763048, -5.09532606864114, -3.15827376499008, -1.940378485401,,
0.600378834777586, 3.57175093511171), 
                    .Dim = c(10L, 2L), .Dimnames = list(NULL,
c("coordinate.1", "coordinate.2")))

my problem occurs when I try to plot a network:

base.net <- graph.edgelist(data, directed=FALSE)
plot(base.net, layout=layout)

The network needs to be structured in a very specific way and I don't
understand in which order the coordinates I created are assigned to the
nodes. (All nodes are labeled A-J. The coordinates aren't assigned
alphabetically or in the order of occurrence in the data matrix).

I hope someone can help me out. Thanks in advance!

L





--
View this message in context: http://r.789695.n4.nabble.com/How-are-tables-accessed-tp4675736.html
Sent from the R help mailing list archive at Nabble.com.


From lucagaegauf at gmx.ch  Tue Sep 10 02:13:01 2013
From: lucagaegauf at gmx.ch (Luca Gaegauf)
Date: Mon, 9 Sep 2013 20:13:01 -0400
Subject: [R] How are Matrices accessed
Message-ID: <A8A2F650-76CD-46F9-B95B-54518057674A@gmx.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130909/9589f297/attachment.pl>

From kridox at ymail.com  Tue Sep 10 06:16:20 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Tue, 10 Sep 2013 13:16:20 +0900
Subject: [R] Hmisc binconf function value interpretation during narrow
 confidence intervals
In-Reply-To: <63F107BCC37AEA49A75FD94AA3E07CB008CD9515@pacpbsex01.pac.dfo-mpo.ca>
References: <63F107BCC37AEA49A75FD94AA3E07CB008CD9515@pacpbsex01.pac.dfo-mpo.ca>
Message-ID: <CAAcyNCxBC-RfEE-FHKF_OtVvcWA3+qzFwmviHLrDik0uCOu-+w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130910/0f287486/attachment.pl>

From algerant at gmail.com  Tue Sep 10 06:51:47 2013
From: algerant at gmail.com (Bembi Prima)
Date: Tue, 10 Sep 2013 11:51:47 +0700
Subject: [R] RStudio Server init script
Message-ID: <CAC5DFuAzNbB41T+28U34vHiOJ+Wn-eGNNHt5oW_0Af4ufs2D-A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130910/20424a35/attachment.pl>

From kridox at ymail.com  Tue Sep 10 06:59:18 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Tue, 10 Sep 2013 13:59:18 +0900
Subject: [R] How are Matrices accessed
In-Reply-To: <A8A2F650-76CD-46F9-B95B-54518057674A@gmx.ch>
References: <A8A2F650-76CD-46F9-B95B-54518057674A@gmx.ch>
Message-ID: <CAAcyNCxsY8GsfxKN-S3ACmzjLqw0JiFtjwMKgX47cuWz0jV-fQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130910/20b65137/attachment.pl>

From kridox at ymail.com  Tue Sep 10 07:10:32 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Tue, 10 Sep 2013 14:10:32 +0900
Subject: [R] RStudio Server init script
In-Reply-To: <CAC5DFuAzNbB41T+28U34vHiOJ+Wn-eGNNHt5oW_0Af4ufs2D-A@mail.gmail.com>
References: <CAC5DFuAzNbB41T+28U34vHiOJ+Wn-eGNNHt5oW_0Af4ufs2D-A@mail.gmail.com>
Message-ID: <CAAcyNCzOf+jQGjoiwSixTkX-0PGGKNdvSC+KADmbxFPy50oK5Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130910/8bff4056/attachment.pl>

From joshwong at stanfordalumni.org  Tue Sep 10 07:12:02 2013
From: joshwong at stanfordalumni.org (RJWR)
Date: Mon, 9 Sep 2013 22:12:02 -0700 (PDT)
Subject: [R] getSymbols error for DGS1MO in FRED
Message-ID: <1378789922510-4675749.post@n4.nabble.com>

hi, 

I am a novice in R, therefore apologies if my question is too basic, and
thanks for your time. 

I used the line below and got the following error: 

> getSymbols("DGS1MO", src= "FRED", from="2013-01-01", to=Sys.Date()) 
Error in read.table(file = file, header = header, sep = sep, quote = quote, 
: 
  duplicate 'row.names' are not allowed 

I don't understand why this is happening and don't know how to rectify it.
There are no issues with a number of other series (e.g. DGS3MO) either. I
have checked the forum but can't find anything specific to this issue. Any
help is appreciated, thanks! 



--
View this message in context: http://r.789695.n4.nabble.com/getSymbols-error-for-DGS1MO-in-FRED-tp4675749.html
Sent from the R help mailing list archive at Nabble.com.


From S.Ellison at LGCGroup.com  Tue Sep 10 11:18:44 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Tue, 10 Sep 2013 10:18:44 +0100
Subject: [R] How do I parse text?
In-Reply-To: <6BDD257BAF1CDB4998CE0CE577B3C34C01146C@TX1P03DAG0107.apptixhealth.net>
References: <6BDD257BAF1CDB4998CE0CE577B3C34C01146C@TX1P03DAG0107.apptixhealth.net>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED526870BF0D@GOLD.corp.lgc-group.com>

> I have a data frame with a character field of the form "ACUTE 
> URI NOS", "OPEN WOUND OF FOREHEAD", "CROUP", "STREP SORE THROAT", ....
> 
> How can I get counts of all the words and their 
> co-occurences?  I've spent a long time searching on google, 
> but it just takes me on a wild goose chase of dozens of 
> modules involving advanced natural language processing 
> theory.  All I want is word counts and co-occurences.

Perhaps a combination of strsplit(), unlist() and table() would do the job? 

Example:

sometext <- c("ACUTE URI NOS", "OPEN WOUND OF FOREHEAD", "CROUP", "STREP SORE THROAT", "ACUTE STREP SORE THROAT")

st <- strsplit(sometext, " ")

table(unlist(st))

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From careyshan at gmail.com  Tue Sep 10 12:40:20 2013
From: careyshan at gmail.com (Shane Carey)
Date: Tue, 10 Sep 2013 11:40:20 +0100
Subject: [R] plotting time series
Message-ID: <CA+jRDxDB4-zMCcRwGGZpNk8qj_Pvg7f-ygwXc0Pz+rOsWdSNEQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130910/08641f5c/attachment.pl>

From sachin.abeywardana at gmail.com  Tue Sep 10 14:27:21 2013
From: sachin.abeywardana at gmail.com (Sachinthaka Abeywardana)
Date: Tue, 10 Sep 2013 22:27:21 +1000
Subject: [R] xtable Highlight the lowest and plus minus
Message-ID: <CAGuusR-q4M6nPgaCm=VzoVvV2aLDk-Ab=yZ8474R-udbH2z0Mw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130910/d2e7d822/attachment.pl>

From mohan.radhakrishnan at polarisft.com  Tue Sep 10 15:11:32 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Tue, 10 Sep 2013 18:41:32 +0530
Subject: [R] Y-axis labels as decimal numbers
In-Reply-To: <CAAxdm-5rimSbfvVXryJD4BbphgMLytKuDgiVYM2d9ARAnOxW-A@mail.gmail.com>
References: <OF36A91BE0.A8B1F70D-ON65257BDD.00492114-65257BDD.00496C61@polarisft.com>	<CAAxdm-7by-vZkrug0JaLcpkSCWJEpRGUun=YgjQFu+W_M_LeJQ@mail.gmail.com>
	<OFF117EDB1.25E0BDB7-ON65257BDE.001F2574-65257BDE.001F4FD8@polarisft.com>
	<CAAxdm-5rimSbfvVXryJD4BbphgMLytKuDgiVYM2d9ARAnOxW-A@mail.gmail.com>
Message-ID: <OFB4E46812.F9569E98-ON65257BE2.00484F0B-65257BE2.00487681@polarisft.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130910/5fad86bf/attachment.pl>

From h.wickham at gmail.com  Tue Sep 10 16:04:53 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 10 Sep 2013 09:04:53 -0500
Subject: [R] RStudio Server init script
In-Reply-To: <CAC5DFuAzNbB41T+28U34vHiOJ+Wn-eGNNHt5oW_0Af4ufs2D-A@mail.gmail.com>
References: <CAC5DFuAzNbB41T+28U34vHiOJ+Wn-eGNNHt5oW_0Af4ufs2D-A@mail.gmail.com>
Message-ID: <CABdHhvEoouN70CkWExCXHL==35c9Rbhi5=7ousGeZFs8e2uy+A@mail.gmail.com>

You might find ?Startup helpful - it describes all the places the R
looks for config files when starting up.

Hadley

On Mon, Sep 9, 2013 at 11:51 PM, Bembi Prima <algerant at gmail.com> wrote:
> Hi All,
>
> Anyone here using RStudio Server?
> I want to ask how can I put .Rprofile that can be accessed by all user.
> So if someone want to add general function, he can just edit one .Rprofile
> without distribution difficulties.
> If I just update .Rprofile in my home directory, other user's .Rprofile
> will not be updated.
>
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Chief Scientist, RStudio
http://had.co.nz/


From pentti.pirinen at fmi.fi  Tue Sep 10 09:50:16 2013
From: pentti.pirinen at fmi.fi (Pentti)
Date: Tue, 10 Sep 2013 00:50:16 -0700 (PDT)
Subject: [R] Daily average temperature from monthly average temperature
Message-ID: <1378799416500-4675752.post@n4.nabble.com>

Dear all

I'm a new R user and don't know how to find help for my problem:
I have monthly mean temperature values for different 30-years periods in the
past and future. I want calculate average temperature values for every day
in year for  each period using the 12 values I have as input data.
I have about 4000 points and 5 periods and I think the monthly values
represent the daily value in the middle of the month (day numbers 15, 46, 76
...,350).

What library and which functions shall I use (and how) ?

Thank you in advance

Pentti 




--
View this message in context: http://r.789695.n4.nabble.com/Daily-average-temperature-from-monthly-average-temperature-tp4675752.html
Sent from the R help mailing list archive at Nabble.com.


From hollandlucas at gmail.com  Tue Sep 10 10:53:00 2013
From: hollandlucas at gmail.com (Lucas Holland)
Date: Tue, 10 Sep 2013 10:53:00 +0200
Subject: [R] Problem fitting GAM
Message-ID: <2173CD8D-F8F7-40CF-95E9-2A3C531138A0@gmail.com>

Hey all,

I've got some data of the form:

> head(df)
  claims accident_year development_year
1  45630             1                1
2  53025             2                1
3  67318             3                1
4  93489             4                1
5  80517             5                1
6  68690             6                1

where accident_year is a factor (development_year is not). 

with one entry in "claims" being negative. I'm trying to follow a paper on claims reserving, fitting a GAM (using the GAM package) to the data with a model of the form:

g <- gam(claims ~ s(development_year,5) + accident_year, data=df, family=quasi(link="log", variance="mu"))

The paper specifies an over dispersed Poisson model with logarithmic link function. It also states that the one negative value is not a problem. 

However, when I run the above code I get an error: 

Error in if (!(validmu(mu) && valideta(eta))) stop("Can't find valid starting values: please specify some") : 
  missing value where TRUE/FALSE needed
In addition: Warning message:
In log(mu) : NaNs produced

I don't understand what exactly that means and what the problem is since in the paper (granted, it doesn't show any implementation detail) it seems to work fine.

If you need the complete code or any other information I'll be happy to provide that.

Thanks!

From M.Rosario.Garcia at slu.se  Tue Sep 10 13:00:33 2013
From: M.Rosario.Garcia at slu.se (Rosario Garcia Gil)
Date: Tue, 10 Sep 2013 11:00:33 +0000
Subject: [R] merge two lists by column
In-Reply-To: <A1C4DF829DB4AE45BF8447F83C7EAFFE0850DD13@exchange2-3>
References: <A1C4DF829DB4AE45BF8447F83C7EAFFE0850DD13@exchange2-3>
Message-ID: <A1C4DF829DB4AE45BF8447F83C7EAFFE0850E2FE@exchange2-3>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130910/0f59d763/attachment.pl>

From smartpink111 at yahoo.com  Tue Sep 10 15:03:56 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 10 Sep 2013 06:03:56 -0700 (PDT)
Subject: [R] replacing Na's with values on different records
In-Reply-To: <1378767521.58640.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <27583015.285071.1378743277927.JavaMail.nabble@joe.nabble.com>
	<595D6D39142B7847B7638CF46AF84F0AED17C9@NDHAMREXDE05.amer.pfizer.com>
	<1378757829.12282.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<595D6D39142B7847B7638CF46AF84F0AED1A70@NDHAMREXDE05.amer.pfizer.com>
	<1378760388.90826.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<595D6D39142B7847B7638CF46AF84F0AED1C4D@NDHAMREXDE05.amer.pfizer.com>
	<1378765436.46353.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1378767521.58640.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <1378818236.47166.YahooMailNeo@web142602.mail.bf1.yahoo.com>

HI,

In the example you showed, there were only two cases: 1) For each ID, 2nd element of AUC24 is NA. 2) or all the entries for a particular ID is missing.? Suppose you have NAs in 1st or 3rd element or multiple NAs (1 and 2, 2 and 3, 1 and 3 etc) in addition to the cases you already described. For example:
u3s1<- u3s
?u3s1$AUC24[1]<- 2
u3sNew<- rbind(u3s1,u3s,u3s,u3s)
u3sNew$ID[10:36]<- rep(104:112,each=3)
u3sNew$AUC24[c(12,19:22,27,28,30)]<- c(20,2,4,8,10.115,18.3268,2,8)
res<- unsplit(lapply(split(u3sNew,u3sNew$ID),function(x) {
??? ??? ??? ??? indx<-!is.na(x$AUC24)
??? ??? ??? ??? x1<- x$AUC24[indx]
??? ??? ??? ??? x2<- 2^(0:floor(log(4,2)))
??? ??? ??? ??? ?x$AUC24<-if(sum(indx)==3) {
??? ??? ??? ??? ??? x$AUC24
??? ??? ??? ??? ??? }
??? ??? ??? ??? ?else if( sum(indx)==2)??? {
??? ??? ??? ??? ???? ?if(which(!indx)==2|which(!indx)==3) {
??? ??? ??? ??? ? ??? ?x1[1]* x2
??? ??? ??? ??? ??? ?? }??? 
??? ??? ??? ??? ???? ? else (x1[1]/2)*x2
??? ??? ??? ??? ??? ??? ??? ??? ???? 
??? ??? ??? ??? ??? } 
??? ??? ??? ??? else if( sum(indx)==1) {
??? ??? ??? ??? ?? if(which(indx)==1) {
??? ??? ??? ??? ??? x1*x2
??? ??? ??? ??? ??? } 
??? ??? ??? ??? ???? else if(which(indx)==2){
??? ??? ??? ??? ???? (x1/2)*x2
??? ??? ??? ??? ??? }??? ??? ??? ??? 
??? ??? ??? ??? ???? else (x1/4)*x2
??? ??? ??? ??? ? }
??? ??? ??? ??? ?else NA
??? ??? ??? ??? ?? x}),u3sNew$ID)

?u3sNew$AUC24
# [1]? 2.0000????? NA????? NA????? NA 20.2300????? NA????? NA? 9.1634????? NA
#[10]????? NA????? NA 20.0000????? NA 20.2300????? NA????? NA? 9.1634????? NA
#[19]? 2.0000? 4.0000? 8.0000 10.1150 20.2300????? NA????? NA? 9.1634 18.3268
#[28]? 2.0000????? NA? 8.0000????? NA 20.2300????? NA????? NA? 9.1634????? NA

res$AUC24
# [1]? 2.0000? 4.0000? 8.0000 10.1150 20.2300 40.4600? 4.5817? 9.1634 18.3268
#[10]? 5.0000 10.0000 20.0000 10.1150 20.2300 40.4600? 4.5817? 9.1634 18.3268
#[19]? 2.0000? 4.0000? 8.0000 10.1150 20.2300 40.4600? 4.5817? 9.1634 18.3268
#[28]? 2.0000? 4.0000? 8.0000 10.1150 20.2300 40.4600? 4.5817? 9.1634 18.3268


A.K.








----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Monday, September 9, 2013 6:58 PM
Subject: Re: replacing Na's with values on different records



HI Ahmed,

No problem.

You got the error because one of the IDs had all NAs for AUC24.
Also, In your dataset, there are NAs in BLADDERWALL, BLADDERWALLC, AUC12d, 
Cmaxd,? in addition to WT, and AUC24.? How do you want to fill those NAs?


res<-unsplit(lapply(split(u3s,u3s$ID),function(x) { x$AUC24<- if(all(is.na(x$AUC24))) NA else as.integer(x$AUC24[!is.na(x$AUC24)]/2)* (2^(0:floor(log(4,2))));x$WT<- if(all(is.na(x$WT))) NA else x$WT[!is.na(x$WT)];x}),u3s$ID)
res
#?? ID PERIOD DOSE VOL1stD MCC BLADDERWALL visit VOL1stDC MCCC BLADDERWALLC
#1 101???? p1 0.03????? 22? 72???????? 2.9???? 3?????? -8? -21????????? 1.2
#2 101???? p2 0.06????? 24? 80???????? 1.0???? 4?????? -6? -13???????? -0.7
#3 101???? p3 0.12????? 17? 59???????? 4.6???? 5????? -13? -34????????? 2.9
#4 102???? p1 0.03?????? 5? 25???????? 0.3???? 3????? -10? -20???????? -1.3
#5 102???? p2 0.06????? 67 125????????? NA???? 4?????? 52?? 80?????????? NA
#6 102???? p3 0.12????? 10? 24???????? 0.2???? 5?????? -5? -21???????? -1.4
#7 103???? p1 0.03?????? 6? 15???????? 0.0???? 3????? -23? -20???????? -0.1
#8 103???? p2 0.06????? 58? 72???????? 0.8???? 4?????? 29?? 37????????? 0.7
#9 103???? p3 0.12????? 15? 35???????? 0.5???? 5????? -14??? 0????????? 0.4
?#? AUC12d Cmaxd Cmind?? WT???????????????? PHENO RACE SEX???? AGE_y AUC24
#1????? NA??? NA??? NA 12.7????????????????????????? 1?? 2 1.8152448??? NA
#2????? NA??? NA??? NA 12.7????????????????????????? 1?? 2 1.8152448??? NA
#3????? NA??? NA??? NA 12.7????????????????????????? 1?? 2 1.8152448??? NA
#4????? NA??? NA??? NA 13.4 Extensive Metabolizer??? 1?? 1 2.1465338??? 10
#5 10.1150? 2.98???? 0 13.4 Extensive Metabolizer??? 1?? 1 2.1465338??? 20
#6????? NA??? NA??? NA 13.4 Extensive Metabolizer??? 1?? 1 2.1465338??? 40
#7????? NA??? NA??? NA 10.0????????????????????????? 1?? 1 0.5010404???? 4
#8? 4.5817? 1.41???? 0 10.0????????????????????????? 1?? 1 0.5010404???? 8
#9????? NA??? NA??? NA 10.0????????????????????????? 1?? 1 0.5010404??? 16

A.K.


----- Original Message -----
From: "El-Tahtawy, Ahmed" <Ahmed.El-Tahtawy at pfizer.com>
To: arun <smartpink111 at yahoo.com>
Cc: 
Sent: Monday, September 9, 2013 6:06 PM
Subject: RE: replacing Na's with values on different records

Dear Arun,

Thanks a million for the sophisticated code- it is little above my skill level. I never saw brilliant use of function x like this before!!( I am a clinical Pharmacologist who loves to explore patient data!!). it seems impossible to use for loop or a simpler function I guess?

The code worked with the simple data, tried to use it with actual data and got an error!!

################################################################################
dput(head(u3s,9))? ?? # only 3 patients

structure(list(ID = c(101L, 101L, 101L, 102L, 102L, 102L, 103L, 
103L, 103L), PERIOD = c("p1", "p2", "p3", "p1", "p2", "p3", "p1", 
"p2", "p3"), DOSE = c("0.03", "0.06", "0.12", "0.03", "0.06", 
"0.12", "0.03", "0.06", "0.12"), VOL1stD = c(22L, 24L, 17L, 5L, 
67L, 10L, 6L, 58L, 15L), MCC = c(72L, 80L, 59L, 25L, 125L, 24L, 
15L, 72L, 35L), BLADDERWALL = c(2.9, 1, 4.6, 0.3, NA, 0.2, 0, 
0.8, 0.5), visit = c(3L, 4L, 5L, 3L, 4L, 5L, 3L, 4L, 5L), VOL1stDC = c(-8L, 
-6L, -13L, -10L, 52L, -5L, -23L, 29L, -14L), MCCC = c(-21L, -13L, 
-34L, -20L, 80L, -21L, -20L, 37L, 0L), BLADDERWALLC = c(1.2, 
-0.7, 2.9, -1.3, NA, -1.4, -0.1, 0.7, 0.4), AUC12d = c(NA, NA, 
NA, NA, 10.115, NA, NA, 4.5817, NA), Cmaxd = c(NA, NA, NA, NA, 
2.98, NA, NA, 1.41, NA), Cmind = c(NA, NA, NA, NA, 0, NA, NA, 
0, NA), WT = c(NA, 12.7, NA, NA, 13.4, NA, NA, 10, NA), PHENO = c("", 
"", "", "Extensive Metabolizer", "Extensive Metabolizer", "Extensive Metabolizer", 
"", "", ""), RACE = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), SEX = c(2L, 
2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L), AGE_y = c(1.815244771, 1.815244771, 
1.815244771, 2.146533786, 2.146533786, 2.146533786, 0.501040412, 
0.501040412, 0.501040412), AUC24 = c(NA, NA, NA, NA, 20.23, NA, 
NA, 9.1634, NA)), .Names = c("ID", "PERIOD", "DOSE", "VOL1stD", 
"MCC", "BLADDERWALL", "visit", "VOL1stDC", "MCCC", "BLADDERWALLC", 
"AUC12d", "Cmaxd", "Cmind", "WT", "PHENO", "RACE", "SEX", "AGE_y", 
"AUC24"), row.names = c(NA, 9L), class = "data.frame")
######################################################################
Here is your code- changed current ID to ID & AUC to AUC24 to match actual data

u3s1<-unsplit(lapply(split(u3s,u3s$"ID"),function(x) {
? (x$AUC24<-as.integer(x$AUC24[!is.na(x$AUC24)]/2)* (2^(0:floor(log(4,2))))); 
? x$WT<- x$WT[!is.na(x$WT)];
? x }),u3s$"ID")

################################################################################
Error in `$<-.data.frame`(`*tmp*`, "AUC24", value = numeric(0)) : 
? replacement has 0 rows, data has 3




Thank you again for your time and help..
Ahmed 
.


-----Original Message-----
From: arun [mailto:smartpink111 at yahoo.com] 
Sent: Monday, September 09, 2013 5:00 PM
To: El-Tahtawy, Ahmed
Subject: Re: replacing Na's with values on different records

HI Ahmed,
No problem.? Don't know if you didn't get the reply or not.? This is what I sent..
u3s<- read.table(text="Current-ID visit AUC Wight ID1
101 3 . . 1
101 4 10 13 2
101 5? . . 3
102 3 .? . 4
102 4 4 10 5
102 5 . . 6
103 3 . . 7
103 4 6 9 8
103 5 . . 9",sep="",header=TRUE,na.strings=".",check.names=FALSE)

u3d<- read.table(text="Desired-ID visit AUC Wight ID1
101 3 5 13 1
101 4 10 13 2
101 5 20 13 3
102 3 2 10 4
102 4 4 10 5
102 5 8 10 6
103 3 3 9 7
103 4 6 9 8
103 5 12 9 9",sep="",header=TRUE,check.names=FALSE)

?u3s1<-unsplit(lapply(split(u3s,u3s$`Current-ID`),function(x) {(x$AUC<-as.integer(x$AUC[!is.na(x$AUC)]/2)* (2^(0:floor(log(4,2))))); x$Wight<- x$Wight[!is.na(x$Wight)];x }),u3s$`Current-ID`)

attr(u3s1,"row.names")<- attr(u3d,"row.names")
colnames(u3s1)<- colnames(u3d)
all.equal(u3s1,u3d)






----- Original Message -----
From: "El-Tahtawy, Ahmed" <Ahmed.El-Tahtawy at pfizer.com>
To: arun <smartpink111 at yahoo.com>
Cc: 
Sent: Monday, September 9, 2013 4:48 PM
Subject: RE: replacing Na's with values on different records

Hi Arun,

Thanks a million...
I am looking forward to seeing your replay tomorrow.

Best Regards
Ahmed 
.


-----Original Message-----
From: arun [mailto:smartpink111 at yahoo.com] 
Sent: Monday, September 09, 2013 4:17 PM
To: El-Tahtawy, Ahmed
Subject: Re: replacing Na's with values on different records

HI Ahmed,

I already sent the reply.? Let me know if that works.
A.K.




----- Original Message -----
From: "El-Tahtawy, Ahmed" <Ahmed.El-Tahtawy at pfizer.com>
To: "smartpink111 at yahoo.com" <smartpink111 at yahoo.com>
Cc: 
Sent: Monday, September 9, 2013 2:50 PM
Subject: RE: replacing Na's with values on different records

Greeting,

Thank you for your quick response.

There are 5 columns and only 3 patients. the actual data has 50 variables and so many patients; but a simplified version is made to help focus on the main problem. I used dput as suggested and there an "L" added to all numbers!!

Please let me know if you have any more questions...

head(u3s,10)
?? ID visit AUC Wight ID1
1 101? ?? 3? NA? ? NA?? 1
2 101? ?? 4? 10? ? 13?? 2
3 101? ?? 5? NA? ? NA?? 3
4 102? ?? 3? NA? ? NA?? 4
5 102? ?? 4?? 4? ? 10?? 5
6 102? ?? 5? NA? ? NA?? 6
7 103? ?? 3? NA? ? NA?? 7
8 103? ?? 4?? 6? ?? 9?? 8
9 103? ?? 5? NA? ? NA?? 9

> dput(u3s)
structure(list(ID = c(101L, 101L, 101L, 102L, 102L, 102L, 103L, 103L, 103L), visit = c(3L, 4L, 5L, 3L, 4L, 5L, 3L, 4L, 5L), AUC = c(NA, 10L, NA, NA, 4L, NA, NA, 6L, NA), Wight = c(NA, 13L, NA, NA, 10L, NA, NA, 9L, NA), ID1 = 1:9), .Names = c("ID", "visit", "AUC", "Wight", "ID1"), class = "data.frame", row.names = c(NA, -9L))

Best Regards
Ahmed
.

-----Original Message-----
From: smartpink111 at yahoo.com [mailto:smartpink111 at yahoo.com]
Sent: Monday, September 09, 2013 12:15 PM
To: El-Tahtawy, Ahmed
Subject: replacing Na's with values on different records

HI,

The example dataset "Current" and "Desired" are mangled by HTML.? It is not clear how many columns you have.? I tried it like this, but still it is still not clear..

ID visit AUC Wight ID1
101 3 1 101 4
10 13 2 101 5
3 102 3 4 102
4 4 10 5 102
5 6 103 3 7
103 4 6 9 8
103 5 9?? ####two elements are missing.

Please use ?dput()
For e.g.
dput(head(dataset,20))

<quote author='El-Tahtawy, Ahmed'>
I'm sure I'm missing something really obvious in the "for loop"...

Here is simplified data for 3 patients, we need filling in Na's with same WT for each patient, AUC halved for visit 3, doubled for visit 5 for the same patient, based on visit 4


for(i in unique(u3s$ID)){? ? ? ? ? ? ? ? ? ? ? ? ? ?? #fill in same Wt for each patient
? u3s$WT <- ifelse(is.na(u3s$WT),u3s$WT[u3s$visit == "4"],u3s$WT)

? for(j in length(u3s$ID1)){? ? ? ? ? ? ? ? ? ? ? ? #fill in .5 AUC for visit 3, 2*AUC for visit 5

? ? u3s$AUC24 <- ifelse(is.na(u3s$AUC24),u3s$AUC24[u3s$visit ==
"4"]*0.5,u3s$AUC24)
? ? u3s$AUC24 <- ifelse(!is.na(u3s$AUC24),u3s$AUC24[u3s$visit ==
"4"]*1.0,u3s$AUC24)
? ? u3s$AUC24 <- ifelse(is.na(u3s$AUC24),u3s$AUC24[u3s$visit ==
"4"]*2.0,u3s$AUC24)
? }
}

Current-
ID

visit

AUC

Wight

ID1

101

3





1

101

4

10

13

2

101

5





3

102

3





4

102

4

4

10

5

102

5





6

103

3





7

103

4

6

9

8

103

5





9


Desired-

ID

visit

AUC

Wight

ID1

101

3

5

13

1

101

4

10

13

2

101

5

20

13

3

102

3

2

10

4

102

4

4

10

5

102

5

8

10

6

103

3

3

9

7

103

4

6

9

8

103

5

12

9

9



Your help is greatly appreciated...


Best Regards

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

</quote>
Quoted from: 
http://r.789695.n4.nabble.com/replacing-Na-s-with-values-on-different-records-tp4675696.html


_____________________________________
Sent from http://r.789695.n4.nabble.com



From jdnewmil at dcn.davis.CA.us  Tue Sep 10 16:29:10 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 10 Sep 2013 07:29:10 -0700
Subject: [R] Daily average temperature from monthly average temperature
In-Reply-To: <1378799416500-4675752.post@n4.nabble.com>
References: <1378799416500-4675752.post@n4.nabble.com>
Message-ID: <21eabf67-bd1a-4e60-a09d-a1f14c7110ee@email.android.com>

Temperature data from the future? This sounds like homework, and the Posting Guide points out that this list is not for homework.

I will point out that a linear interpolation approach would be appropriate for an introductory class but would not be very realistic, and there exist papers describing stochastic interpolation methods more appropriate to this type of data, but this is not a statistics or weather modeling mailing list either.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Pentti <pentti.pirinen at fmi.fi> wrote:
>Dear all
>
>I'm a new R user and don't know how to find help for my problem:
>I have monthly mean temperature values for different 30-years periods
>in the
>past and future. I want calculate average temperature values for every
>day
>in year for  each period using the 12 values I have as input data.
>I have about 4000 points and 5 periods and I think the monthly values
>represent the daily value in the middle of the month (day numbers 15,
>46, 76
>...,350).
>
>What library and which functions shall I use (and how) ?
>
>Thank you in advance
>
>Pentti 
>
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/Daily-average-temperature-from-monthly-average-temperature-tp4675752.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Tue Sep 10 16:34:07 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 10 Sep 2013 07:34:07 -0700
Subject: [R] merge two lists by column
In-Reply-To: <A1C4DF829DB4AE45BF8447F83C7EAFFE0850E2FE@exchange2-3>
References: <A1C4DF829DB4AE45BF8447F83C7EAFFE0850DD13@exchange2-3>
	<A1C4DF829DB4AE45BF8447F83C7EAFFE0850E2FE@exchange2-3>
Message-ID: <CACk-te0OqpEg+ouYXeG0xBybd-rZya-TjU7pPXdUsOjnoAGSeg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130910/434c3f57/attachment.pl>

From michel.arnaud at cirad.fr  Tue Sep 10 17:03:56 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Tue, 10 Sep 2013 17:03:56 +0200
Subject: [R] to delete lines by means of a vector
Message-ID: <522F34DC.5070406@cirad.fr>

Hi
I would like to eliminate a large number of  lines of the dataframe df1
The lines to delete are given here by the values of Mat (ex : 2,4,7,10).
but I have a large number (300) values of Mat

dput(df1)
structure(list(Mat = c(1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3,
3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7,
7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 10, 10,
10, 11, 11, 11, 11, 11, 11, 11), Prenom = c("Ginette", "Ginette",
"Ginette", "Ginette", "Ginette", "Ginette", "Nicole", "Nicole",
"Nicole", "Nicole", "Jean", "Jean", "Jean", "Jean", "Jean", "Ginette",
"Ginette", "Ginette", "Ginette", "Ginette", "H?l?ne", "H?l?ne",
"H?l?ne", "H?l?ne", "H?l?ne", "H?l?ne", "Guy", "Guy", "Guy",
"Guy", "Guy", "Guy", "Claude", "Claude", "Claude", "Claude",
"Claude", "Claude", "Claude", "R?gine", "R?gine", "R?gine", "R?gine",
"R?gine", "R?gine", "R?gine", "Germain", "Germain", "Germain",
"Germain", "Germain", "Germain", "B?atrice", "B?atrice", "B?atrice",
"Josette", "Josette", "Josette", "Josette", "Josette", "Josette",
"Josette"), Sexe = c("F?minin", "F?minin", "F?minin", "F?minin",
"F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "F?minin",
"F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
"F?minin", "F?minin", "F?minin", "F?minin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "F?minin",
"F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
"F?minin", "F?minin", "F?minin", "F?minin")), .Names = c("Mat",
"Prenom", "Sexe"), row.names = c(NA, 62L), class = "data.frame")

I would like to obtain the data frame df2
dput(df2)
structure(list(Mat = c(1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3,
3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7,
7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 10, 10,
10, 11, 11, 11, 11, 11, 11, 11), Prenom = c("Ginette", "Ginette",
"Ginette", "Ginette", "Ginette", "Ginette", "Nicole", "Nicole",
"Nicole", "Nicole", "Jean", "Jean", "Jean", "Jean", "Jean", "Ginette",
"Ginette", "Ginette", "Ginette", "Ginette", "H?l?ne", "H?l?ne",
"H?l?ne", "H?l?ne", "H?l?ne", "H?l?ne", "Guy", "Guy", "Guy",
"Guy", "Guy", "Guy", "Claude", "Claude", "Claude", "Claude",
"Claude", "Claude", "Claude", "R?gine", "R?gine", "R?gine", "R?gine",
"R?gine", "R?gine", "R?gine", "Germain", "Germain", "Germain",
"Germain", "Germain", "Germain", "B?atrice", "B?atrice", "B?atrice",
"Josette", "Josette", "Josette", "Josette", "Josette", "Josette",
"Josette"), Sexe = c("F?minin", "F?minin", "F?minin", "F?minin",
"F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "F?minin",
"F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
"F?minin", "F?minin", "F?minin", "F?minin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "F?minin",
"F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
"F?minin", "F?minin", "F?minin", "F?minin")), .Names = c("Mat",
"Prenom", "Sexe"), row.names = c(NA, 62L), class = "data.frame")

It is possible to obtain by
df2 <- df1[df1$Mat != 2 | df1$Mat !=4 | [df1$Mat !=7 | [df1$Mat !=10,]
But how to delete these lines when the 300 values of Mat are in the 
vector MatDelete

Any ideas ?

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From Markus.Gesmann at lloyds.com  Tue Sep 10 17:09:19 2013
From: Markus.Gesmann at lloyds.com (Gesmann, Markus)
Date: Tue, 10 Sep 2013 15:09:19 +0000
Subject: [R] Problem fitting GAM
In-Reply-To: <2173CD8D-F8F7-40CF-95E9-2A3C531138A0@gmail.com>
References: <2173CD8D-F8F7-40CF-95E9-2A3C531138A0@gmail.com>
Message-ID: <2D1AC19CDA3D5643B9D7AE596C377B280C0A01BA@GBS0039303.lloyds.net>

Hi Lucas,

A similar question was raised on R-help about 10 years ago.
Take a look at David Firth's amended "quasipoisson" function here:
https://stat.ethz.ch/pipermail/r-help/2003-January/028743.html

I hope this helps

Markus

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Lucas Holland
Sent: 10 September 2013 09:53
To: r-help at R-project.org
Subject: [R] Problem fitting GAM

Hey all,

I've got some data of the form:

> head(df)
  claims accident_year development_year
1  45630             1                1
2  53025             2                1
3  67318             3                1
4  93489             4                1
5  80517             5                1
6  68690             6                1

where accident_year is a factor (development_year is not). 

with one entry in "claims" being negative. I'm trying to follow a paper on claims reserving, fitting a GAM (using the GAM package) to the data with a model of the form:

g <- gam(claims ~ s(development_year,5) + accident_year, data=df, family=quasi(link="log", variance="mu"))

The paper specifies an over dispersed Poisson model with logarithmic link function. It also states that the one negative value is not a problem. 

However, when I run the above code I get an error: 

Error in if (!(validmu(mu) && valideta(eta))) stop("Can't find valid starting values: please specify some") : 
  missing value where TRUE/FALSE needed
In addition: Warning message:
In log(mu) : NaNs produced

I don't understand what exactly that means and what the problem is since in the paper (granted, it doesn't show any implementation detail) it seems to work fine.

If you need the complete code or any other information I'll be happy to provide that.

Thanks!
______________________________________________
R-help at r-project.org mailing list
https://urldefense.proofpoint.com/v1/url?u=https://stat.ethz.ch/mailman/listinfo/r-help&k=VTIXiGvdT7U4yPSpeHcrHQ%3D%3D%0A&r=dUkLGPeM%2BYkyyiRRq50yGs%2BmEf8kG%2FyCNQPwZn%2FaQD0%3D%0A&m=7a8qJHimzZrXoL0T1j4mF%2BgSPqGLT%2Bzk%2BTIU5bqqdm0%3D%0A&s=892bd469ab64880d20fa885aae982d33442d29650695dd773300f07762573ff2
PLEASE do read the posting guide https://urldefense.proofpoint.com/v1/url?u=http://www.r-project.org/posting-guide.html&k=VTIXiGvdT7U4yPSpeHcrHQ%3D%3D%0A&r=dUkLGPeM%2BYkyyiRRq50yGs%2BmEf8kG%2FyCNQPwZn%2FaQD0%3D%0A&m=7a8qJHimzZrXoL0T1j4mF%2BgSPqGLT%2Bzk%2BTIU5bqqdm0%3D%0A&s=8b87892a4a68507989ac498e2906e4604f18adad73b84e420874b21ad211a26a
and provide commented, minimal, self-contained, reproducible code.

----------------------------------------------------------------------
The information in this E-Mail and in any attachments is...{{dropped:19}}


From smartpink111 at yahoo.com  Tue Sep 10 17:11:27 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 10 Sep 2013 08:11:27 -0700 (PDT)
Subject: [R] to delete lines by means of a vector
In-Reply-To: <522F34DC.5070406@cirad.fr>
References: <522F34DC.5070406@cirad.fr>
Message-ID: <1378825887.13255.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
Try:
vec1<- c(2,4,7,10)
df1New<-df1[!df1$Mat %in% vec1,]
?dim(df1New)
#[1] 43? 3
A.K.



----- Original Message -----
From: Arnaud Michel <michel.arnaud at cirad.fr>
To: R help <r-help at r-project.org>
Cc: 
Sent: Tuesday, September 10, 2013 11:03 AM
Subject: [R] to delete lines by means of a vector

Hi
I would like to eliminate a large number of? lines of the dataframe df1
The lines to delete are given here by the values of Mat (ex : 2,4,7,10).
but I have a large number (300) values of Mat

dput(df1)
structure(list(Mat = c(1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3,
3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7,
7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 10, 10,
10, 11, 11, 11, 11, 11, 11, 11), Prenom = c("Ginette", "Ginette",
"Ginette", "Ginette", "Ginette", "Ginette", "Nicole", "Nicole",
"Nicole", "Nicole", "Jean", "Jean", "Jean", "Jean", "Jean", "Ginette",
"Ginette", "Ginette", "Ginette", "Ginette", "H?l?ne", "H?l?ne",
"H?l?ne", "H?l?ne", "H?l?ne", "H?l?ne", "Guy", "Guy", "Guy",
"Guy", "Guy", "Guy", "Claude", "Claude", "Claude", "Claude",
"Claude", "Claude", "Claude", "R?gine", "R?gine", "R?gine", "R?gine",
"R?gine", "R?gine", "R?gine", "Germain", "Germain", "Germain",
"Germain", "Germain", "Germain", "B?atrice", "B?atrice", "B?atrice",
"Josette", "Josette", "Josette", "Josette", "Josette", "Josette",
"Josette"), Sexe = c("F?minin", "F?minin", "F?minin", "F?minin",
"F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "F?minin",
"F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
"F?minin", "F?minin", "F?minin", "F?minin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "F?minin",
"F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
"F?minin", "F?minin", "F?minin", "F?minin")), .Names = c("Mat",
"Prenom", "Sexe"), row.names = c(NA, 62L), class = "data.frame")

I would like to obtain the data frame df2
dput(df2)
structure(list(Mat = c(1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3,
3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7,
7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 10, 10,
10, 11, 11, 11, 11, 11, 11, 11), Prenom = c("Ginette", "Ginette",
"Ginette", "Ginette", "Ginette", "Ginette", "Nicole", "Nicole",
"Nicole", "Nicole", "Jean", "Jean", "Jean", "Jean", "Jean", "Ginette",
"Ginette", "Ginette", "Ginette", "Ginette", "H?l?ne", "H?l?ne",
"H?l?ne", "H?l?ne", "H?l?ne", "H?l?ne", "Guy", "Guy", "Guy",
"Guy", "Guy", "Guy", "Claude", "Claude", "Claude", "Claude",
"Claude", "Claude", "Claude", "R?gine", "R?gine", "R?gine", "R?gine",
"R?gine", "R?gine", "R?gine", "Germain", "Germain", "Germain",
"Germain", "Germain", "Germain", "B?atrice", "B?atrice", "B?atrice",
"Josette", "Josette", "Josette", "Josette", "Josette", "Josette",
"Josette"), Sexe = c("F?minin", "F?minin", "F?minin", "F?minin",
"F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "F?minin",
"F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
"F?minin", "F?minin", "F?minin", "F?minin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "F?minin",
"F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
"F?minin", "F?minin", "F?minin", "F?minin")), .Names = c("Mat",
"Prenom", "Sexe"), row.names = c(NA, 62L), class = "data.frame")

It is possible to obtain by
df2 <- df1[df1$Mat != 2 | df1$Mat !=4 | [df1$Mat !=7 | [df1$Mat !=10,]
But how to delete these lines when the 300 values of Mat are in the 
vector MatDelete

Any ideas ?

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Tue Sep 10 17:18:06 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 10 Sep 2013 08:18:06 -0700
Subject: [R] to delete lines by means of a vector
In-Reply-To: <522F34DC.5070406@cirad.fr>
References: <522F34DC.5070406@cirad.fr>
Message-ID: <CACk-te0f-ztW--wZG9JjgNLkAJqMJ33crh=pXHf05soyvUUFiw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130910/828dffa5/attachment.pl>

From ruipbarradas at sapo.pt  Tue Sep 10 17:18:05 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 10 Sep 2013 16:18:05 +0100
Subject: [R] to delete lines by means of a vector
In-Reply-To: <522F34DC.5070406@cirad.fr>
References: <522F34DC.5070406@cirad.fr>
Message-ID: <522F382D.1090304@sapo.pt>

Hello,

It seems you've made a mistake and posted df1 twice,

identical(df1, df2)  # TRUE


As for your question, try negating ?%in%


MatDelete <- c(2, 4, 7, 10)

df3 <- df1[!df1$Mat %in% MatDelete, ]


Hope this helps,

Rui Barradas

Em 10-09-2013 16:03, Arnaud Michel escreveu:
> Hi
> I would like to eliminate a large number of  lines of the dataframe df1
> The lines to delete are given here by the values of Mat (ex : 2,4,7,10).
> but I have a large number (300) values of Mat
>
> dput(df1)
> structure(list(Mat = c(1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3,
> 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7,
> 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 10, 10,
> 10, 11, 11, 11, 11, 11, 11, 11), Prenom = c("Ginette", "Ginette",
> "Ginette", "Ginette", "Ginette", "Ginette", "Nicole", "Nicole",
> "Nicole", "Nicole", "Jean", "Jean", "Jean", "Jean", "Jean", "Ginette",
> "Ginette", "Ginette", "Ginette", "Ginette", "H?l?ne", "H?l?ne",
> "H?l?ne", "H?l?ne", "H?l?ne", "H?l?ne", "Guy", "Guy", "Guy",
> "Guy", "Guy", "Guy", "Claude", "Claude", "Claude", "Claude",
> "Claude", "Claude", "Claude", "R?gine", "R?gine", "R?gine", "R?gine",
> "R?gine", "R?gine", "R?gine", "Germain", "Germain", "Germain",
> "Germain", "Germain", "Germain", "B?atrice", "B?atrice", "B?atrice",
> "Josette", "Josette", "Josette", "Josette", "Josette", "Josette",
> "Josette"), Sexe = c("F?minin", "F?minin", "F?minin", "F?minin",
> "F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "F?minin",
> "F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
> "F?minin", "F?minin", "F?minin", "F?minin", "Masculin", "Masculin",
> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "F?minin",
> "F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
> "F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
> "F?minin", "F?minin", "F?minin", "F?minin")), .Names = c("Mat",
> "Prenom", "Sexe"), row.names = c(NA, 62L), class = "data.frame")
>
> I would like to obtain the data frame df2
> dput(df2)
> structure(list(Mat = c(1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3,
> 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7,
> 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 10, 10,
> 10, 11, 11, 11, 11, 11, 11, 11), Prenom = c("Ginette", "Ginette",
> "Ginette", "Ginette", "Ginette", "Ginette", "Nicole", "Nicole",
> "Nicole", "Nicole", "Jean", "Jean", "Jean", "Jean", "Jean", "Ginette",
> "Ginette", "Ginette", "Ginette", "Ginette", "H?l?ne", "H?l?ne",
> "H?l?ne", "H?l?ne", "H?l?ne", "H?l?ne", "Guy", "Guy", "Guy",
> "Guy", "Guy", "Guy", "Claude", "Claude", "Claude", "Claude",
> "Claude", "Claude", "Claude", "R?gine", "R?gine", "R?gine", "R?gine",
> "R?gine", "R?gine", "R?gine", "Germain", "Germain", "Germain",
> "Germain", "Germain", "Germain", "B?atrice", "B?atrice", "B?atrice",
> "Josette", "Josette", "Josette", "Josette", "Josette", "Josette",
> "Josette"), Sexe = c("F?minin", "F?minin", "F?minin", "F?minin",
> "F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "F?minin",
> "F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
> "F?minin", "F?minin", "F?minin", "F?minin", "Masculin", "Masculin",
> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "F?minin",
> "F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
> "F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
> "F?minin", "F?minin", "F?minin", "F?minin")), .Names = c("Mat",
> "Prenom", "Sexe"), row.names = c(NA, 62L), class = "data.frame")
>
> It is possible to obtain by
> df2 <- df1[df1$Mat != 2 | df1$Mat !=4 | [df1$Mat !=7 | [df1$Mat !=10,]
> But how to delete these lines when the 300 values of Mat are in the
> vector MatDelete
>
> Any ideas ?
>


From kw.stat at gmail.com  Tue Sep 10 17:20:31 2013
From: kw.stat at gmail.com (Kevin Wright)
Date: Tue, 10 Sep 2013 10:20:31 -0500
Subject: [R] Daily average temperature from monthly average temperature
In-Reply-To: <1378799416500-4675752.post@n4.nabble.com>
References: <1378799416500-4675752.post@n4.nabble.com>
Message-ID: <CAKFxdiQuQnJ93xBF1LtOsaZ-3=O7JjHsAeZWUa-8r3SiyOa+6w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130910/31f4d094/attachment.pl>

From bhh at xs4all.nl  Tue Sep 10 17:33:36 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Tue, 10 Sep 2013 17:33:36 +0200
Subject: [R] Daily average temperature from monthly average temperature
In-Reply-To: <1378799416500-4675752.post@n4.nabble.com>
References: <1378799416500-4675752.post@n4.nabble.com>
Message-ID: <8DC0256F-6E92-4068-A089-95BDC0BE7DC7@xs4all.nl>


On 10-09-2013, at 09:50, Pentti <pentti.pirinen at fmi.fi> wrote:

> Dear all
> 
> I'm a new R user and don't know how to find help for my problem:
> I have monthly mean temperature values for different 30-years periods in the
> past and future. I want calculate average temperature values for every day
> in year for  each period using the 12 values I have as input data.
> I have about 4000 points and 5 periods and I think the monthly values
> represent the daily value in the middle of the month (day numbers 15, 46, 76
> ...,350).
> 
> What library and which functions shall I use (and how) ?

A package that can do temporal disaggregation is: tempdisagg 
See CRAN Task Views TimeSeries (http://cran.r-project.org/web/views/TimeSeries.html).

But to generate daily temperatures from monthly temperatures? H'm.

Berend


From andreas at maunz.de  Tue Sep 10 16:58:53 2013
From: andreas at maunz.de (Andreas Maunz)
Date: Tue, 10 Sep 2013 16:58:53 +0200
Subject: [R] rgl snapshot on headless server
Message-ID: <CAJHOUEMjjYO98UYrkJ_SfSByC9xNqd2ydGVgkFoazbW21ccMvQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130910/7e92db06/attachment.pl>

From ppalmes at yahoo.com  Tue Sep 10 18:15:42 2013
From: ppalmes at yahoo.com (Paulito Palmes)
Date: Tue, 10 Sep 2013 09:15:42 -0700 (PDT)
Subject: [R] Formula in R
Message-ID: <1378829742.60247.YahooMailNeo@web125402.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130910/7c0bae03/attachment.pl>

From smartpink111 at yahoo.com  Tue Sep 10 16:53:01 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 10 Sep 2013 07:53:01 -0700 (PDT)
Subject: [R] replacing Na's with values on different records
In-Reply-To: <595D6D39142B7847B7638CF46AF84F0AED2637@NDHAMREXDE05.amer.pfizer.com>
References: <27583015.285071.1378743277927.JavaMail.nabble@joe.nabble.com>
	<595D6D39142B7847B7638CF46AF84F0AED17C9@NDHAMREXDE05.amer.pfizer.com>
	<1378757829.12282.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<595D6D39142B7847B7638CF46AF84F0AED1A70@NDHAMREXDE05.amer.pfizer.com>
	<1378760388.90826.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<595D6D39142B7847B7638CF46AF84F0AED1C4D@NDHAMREXDE05.amer.pfizer.com>
	<1378765436.46353.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<595D6D39142B7847B7638CF46AF84F0AED2637@NDHAMREXDE05.amer.pfizer.com>
Message-ID: <1378824781.91055.YahooMailNeo@web142605.mail.bf1.yahoo.com>

HI,

You should take out the as.integer()
res<- unsplit(lapply(split(u3s,u3s$ID),function(x) { x$AUC24<- if(all(is.na(x$AUC24))) NA else round(x$AUC24[!is.na(x$AUC24)]/2* (2^(0:floor(log(4,2)))),3);x$WT<- if(all(is.na(x$WT))) NA else x$WT[!is.na(x$WT)];x}),u3s$ID)
?res$AUC24
#[1]???? NA???? NA???? NA 10.115 20.230 40.460? 4.582? 9.163 18.327

Regarding the other question about AUC24 with NA in the first entry, you should try this:
u3s1<- u3s
?u3s1$AUC24[1]<- 2
u3sNew<- rbind(u3s1,u3s,u3s,u3s)
u3sNew$ID[10:36]<- rep(104:112,each=3)
u3sNew$AUC24[c(12,19:22,27,28,30)]<- c(20,2,4,8,10.115,18.3268,2,8)

#Modified added ?round()

res<- unsplit(lapply(split(u3sNew,u3sNew$ID),function(x) {
??? ??? ??? ??? indx<-!is.na(x$AUC24)
??? ??? ??? ??? x1<- x$AUC24[indx]
??? ??? ??? ??? x2<- 2^(0:floor(log(4,2)))
??? ??? ??? ??? ?x$AUC24<-round(if(sum(indx)==3) {
??? ??? ??? ??? ??? x$AUC24
??? ??? ??? ??? ??? }
??? ??? ??? ??? ?else if( sum(indx)==2)??? {
??? ??? ??? ??? ???? ?if(which(!indx)==2|which(!indx)==3) {
??? ??? ??? ??? ? ??? ?x1[1]* x2
??? ??? ??? ??? ??? ?? }??? 
??? ??? ??? ??? ???? ? else (x1[1]/2)*x2
??? ??? ??? ??? ??? ??? ??? ??? ???? 
??? ??? ??? ??? ??? } 
??? ??? ??? ??? else if( sum(indx)==1) {
??? ??? ??? ??? ?? if(which(indx)==1) {
??? ??? ??? ??? ??? x1*x2
??? ??? ??? ??? ??? } 
??? ??? ??? ??? ???? else if(which(indx)==2){
??? ??? ??? ??? ???? (x1/2)*x2
??? ??? ??? ??? ??? }??? ??? ??? ??? 
??? ??? ??? ??? ???? else (x1/4)*x2
??? ??? ??? ??? ? }
??? ??? ??? ??? ?else NA,3)
??? ??? ??? ??? x$WT<- if(all(is.na(x$WT))){
??? ??? ??? ??? ??? ??? ??? ?NA
??? ??? ??? ??? ??? }
??? ??? ??? ??? ?else x$WT[!is.na(x$WT)]
??? ??? ??? ??? ?? x}),u3sNew$ID)

?res$AUC24
# [1]? 2.000? 4.000? 8.000 10.115 20.230 40.460? 4.582? 9.163 18.327? 5.000
#[11] 10.000 20.000 10.115 20.230 40.460? 4.582? 9.163 18.327? 2.000? 4.000
#[21]? 8.000 10.115 20.230 40.460? 4.582? 9.163 18.327? 2.000? 4.000? 8.000
#[31] 10.115 20.230 40.460? 4.582? 9.163 18.327

?u3sNew$AUC24
?#[1]? 2.0000????? NA????? NA????? NA 20.2300????? NA????? NA? 9.1634????? NA
#[10]????? NA????? NA 20.0000????? NA 20.2300????? NA????? NA? 9.1634????? NA
#[19]? 2.0000? 4.0000? 8.0000 10.1150 20.2300????? NA????? NA? 9.1634 18.3268
#[28]? 2.0000????? NA? 8.0000????? NA 20.2300????? NA????? NA? 9.1634????? NA
A.K.




----- Original Message -----
From: "El-Tahtawy, Ahmed" <Ahmed.El-Tahtawy at pfizer.com>
To: arun <smartpink111 at yahoo.com>
Cc: 
Sent: Tuesday, September 10, 2013 10:39 AM
Subject: RE: replacing Na's with values on different records

Hi Arun,

Thanks for the code. I just applied it and it ran like a charm!!
I ran the code with the first child (AUC24=NA) before seeking your help, but gave me the same error!!

One last question- I tried to use round(3), but AUC24 didn't change.

res<-unsplit(lapply(split(u3s,u3s$ID),function(x) { 
? x$AUC24<- if(all(is.na(x$AUC24))) NA else round(as.integer(x$AUC24[!is.na(x$AUC24)]/2)* (2^(0:floor(log(4,2)))),3);
x$WT<- if(all(is.na(x$WT))) NA else x$WT[!is.na(x$WT)];x}),u3s$ID)


Thanks again...
Ahmed 
.


-----Original Message-----
From: arun [mailto:smartpink111 at yahoo.com] 
Sent: Monday, September 09, 2013 6:24 PM
To: R help
Cc: El-Tahtawy, Ahmed
Subject: Re: replacing Na's with values on different records

HI Ahmed,

No problem.

You got the error because one of the IDs had all NAs for AUC24.



Also, In your dataset, there are NAs in BLADDERWALL, BLADDERWALLC, AUC12d, Cmaxd,? in addition to WT, and AUC24.?? Do you want to follow any particular methodology for filling the NAs in these columns? or the filling of NAs are only applicable to AUC24.? 


res<-unsplit(lapply(split(u3s,u3s$ID),function(x) { x$AUC24<- if(all(is.na(x$AUC24))) NA else as.integer(x$AUC24[!is.na(x$AUC24)]/2)* (2^(0:floor(log(4,2))));x$WT<- if(all(is.na(x$WT))) NA else x$WT[!is.na(x$WT)];x}),u3s$ID) res #?? ID PERIOD DOSE VOL1stD MCC BLADDERWALL visit VOL1stDC MCCC BLADDERWALLC
#1 101???? p1 0.03????? 22? 72???????? 2.9???? 3?????? -8? -21????????? 1.2
#2 101???? p2 0.06????? 24? 80???????? 1.0???? 4?????? -6? -13???????? -0.7
#3 101???? p3 0.12????? 17? 59???????? 4.6???? 5????? -13? -34????????? 2.9
#4 102???? p1 0.03?????? 5? 25???????? 0.3???? 3????? -10? -20???????? -1.3
#5 102???? p2 0.06????? 67 125????????? NA???? 4?????? 52?? 80?????????? NA
#6 102???? p3 0.12????? 10? 24???????? 0.2???? 5?????? -5? -21???????? -1.4
#7 103???? p1 0.03?????? 6? 15???????? 0.0???? 3????? -23? -20???????? -0.1
#8 103???? p2 0.06????? 58? 72???????? 0.8???? 4?????? 29?? 37????????? 0.7
#9 103???? p3 0.12????? 15? 35???????? 0.5???? 5????? -14??? 0????????? 0.4
?#? AUC12d Cmaxd Cmind?? WT???????????????? PHENO RACE SEX???? AGE_y AUC24
#1????? NA??? NA??? NA 12.7????????????????????????? 1?? 2 1.8152448??? NA
#2????? NA??? NA??? NA 12.7????????????????????????? 1?? 2 1.8152448??? NA
#3????? NA??? NA??? NA 12.7????????????????????????? 1?? 2 1.8152448??? NA
#4????? NA??? NA??? NA 13.4 Extensive Metabolizer??? 1?? 1 2.1465338??? 10
#5 10.1150? 2.98???? 0 13.4 Extensive Metabolizer??? 1?? 1 2.1465338??? 20
#6????? NA??? NA??? NA 13.4 Extensive Metabolizer??? 1?? 1 2.1465338??? 40
#7????? NA??? NA??? NA 10.0????????????????????????? 1?? 1 0.5010404???? 4
#8? 4.5817? 1.41???? 0 10.0????????????????????????? 1?? 1 0.5010404???? 8
#9????? NA??? NA??? NA 10.0????????????????????????? 1?? 1 0.5010404??? 16




A.K.


----- Original Message -----
From: "El-Tahtawy, Ahmed" <Ahmed.El-Tahtawy at pfizer.com>
To: arun <smartpink111 at yahoo.com>
Cc: 
Sent: Monday, September 9, 2013 6:06 PM
Subject: RE: replacing Na's with values on different records

Dear Arun,

Thanks a million for the sophisticated code- it is little above my skill level. I never saw brilliant use of function x like this before!!( I am a clinical Pharmacologist who loves to explore patient data!!). it seems impossible to use for loop or a simpler function I guess?

The code worked with the simple data, tried to use it with actual data and got an error!!

################################################################################
dput(head(u3s,9))? ?? # only 3 patients

structure(list(ID = c(101L, 101L, 101L, 102L, 102L, 102L, 103L, 103L, 103L), PERIOD = c("p1", "p2", "p3", "p1", "p2", "p3", "p1", "p2", "p3"), DOSE = c("0.03", "0.06", "0.12", "0.03", "0.06", "0.12", "0.03", "0.06", "0.12"), VOL1stD = c(22L, 24L, 17L, 5L, 67L, 10L, 6L, 58L, 15L), MCC = c(72L, 80L, 59L, 25L, 125L, 24L, 15L, 72L, 35L), BLADDERWALL = c(2.9, 1, 4.6, 0.3, NA, 0.2, 0, 0.8, 0.5), visit = c(3L, 4L, 5L, 3L, 4L, 5L, 3L, 4L, 5L), VOL1stDC = c(-8L, -6L, -13L, -10L, 52L, -5L, -23L, 29L, -14L), MCCC = c(-21L, -13L, -34L, -20L, 80L, -21L, -20L, 37L, 0L), BLADDERWALLC = c(1.2, -0.7, 2.9, -1.3, NA, -1.4, -0.1, 0.7, 0.4), AUC12d = c(NA, NA, NA, NA, 10.115, NA, NA, 4.5817, NA), Cmaxd = c(NA, NA, NA, NA, 2.98, NA, NA, 1.41, NA), Cmind = c(NA, NA, NA, NA, 0, NA, NA, 0, NA), WT = c(NA, 12.7, NA, NA, 13.4, NA, NA, 10, NA), PHENO = c("", "", "", "Extensive Metabolizer", "Extensive Metabolizer", "Extensive Metabolizer", "", "", ""), RACE = c(1L, 1L, 1L, 1L, 1L,
 1L, 1L, 1L, 1L), SEX = c(2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L), AGE_y = c(1.815244771, 1.815244771, 1.815244771, 2.146533786, 2.146533786, 2.146533786, 0.501040412, 0.501040412, 0.501040412), AUC24 = c(NA, NA, NA, NA, 20.23, NA, NA, 9.1634, NA)), .Names = c("ID", "PERIOD", "DOSE", "VOL1stD", "MCC", "BLADDERWALL", "visit", "VOL1stDC", "MCCC", "BLADDERWALLC", "AUC12d", "Cmaxd", "Cmind", "WT", "PHENO", "RACE", "SEX", "AGE_y", "AUC24"), row.names = c(NA, 9L), class = "data.frame") ######################################################################
Here is your code- changed current ID to ID & AUC to AUC24 to match actual data

u3s1<-unsplit(lapply(split(u3s,u3s$"ID"),function(x) {
? (x$AUC24<-as.integer(x$AUC24[!is.na(x$AUC24)]/2)* (2^(0:floor(log(4,2)))));
? x$WT<- x$WT[!is.na(x$WT)];
? x }),u3s$"ID")

################################################################################
Error in `$<-.data.frame`(`*tmp*`, "AUC24", value = numeric(0)) : 
? replacement has 0 rows, data has 3




Thank you again for your time and help..
Ahmed
.


-----Original Message-----
From: arun [mailto:smartpink111 at yahoo.com] 
Sent: Monday, September 09, 2013 5:00 PM
To: El-Tahtawy, Ahmed
Subject: Re: replacing Na's with values on different records

HI Ahmed,
No problem.? Don't know if you didn't get the reply or not.? This is what I sent..
u3s<- read.table(text="Current-ID visit AUC Wight ID1
101 3 . . 1
101 4 10 13 2
101 5? . . 3
102 3 .? . 4
102 4 4 10 5
102 5 . . 6
103 3 . . 7
103 4 6 9 8
103 5 . . 9",sep="",header=TRUE,na.strings=".",check.names=FALSE)

u3d<- read.table(text="Desired-ID visit AUC Wight ID1
101 3 5 13 1
101 4 10 13 2
101 5 20 13 3
102 3 2 10 4
102 4 4 10 5
102 5 8 10 6
103 3 3 9 7
103 4 6 9 8
103 5 12 9 9",sep="",header=TRUE,check.names=FALSE)

?u3s1<-unsplit(lapply(split(u3s,u3s$`Current-ID`),function(x) {(x$AUC<-as.integer(x$AUC[!is.na(x$AUC)]/2)* (2^(0:floor(log(4,2))))); x$Wight<- x$Wight[!is.na(x$Wight)];x }),u3s$`Current-ID`)

attr(u3s1,"row.names")<- attr(u3d,"row.names")
colnames(u3s1)<- colnames(u3d)
all.equal(u3s1,u3d)






----- Original Message -----
From: "El-Tahtawy, Ahmed" <Ahmed.El-Tahtawy at pfizer.com>
To: arun <smartpink111 at yahoo.com>
Cc: 
Sent: Monday, September 9, 2013 4:48 PM
Subject: RE: replacing Na's with values on different records

Hi Arun,

Thanks a million...
I am looking forward to seeing your replay tomorrow.

Best Regards
Ahmed 
.


-----Original Message-----
From: arun [mailto:smartpink111 at yahoo.com] 
Sent: Monday, September 09, 2013 4:17 PM
To: El-Tahtawy, Ahmed
Subject: Re: replacing Na's with values on different records

HI Ahmed,

I already sent the reply.? Let me know if that works.
A.K.




----- Original Message -----
From: "El-Tahtawy, Ahmed" <Ahmed.El-Tahtawy at pfizer.com>
To: "smartpink111 at yahoo.com" <smartpink111 at yahoo.com>
Cc: 
Sent: Monday, September 9, 2013 2:50 PM
Subject: RE: replacing Na's with values on different records

Greeting,

Thank you for your quick response.

There are 5 columns and only 3 patients. the actual data has 50 variables and so many patients; but a simplified version is made to help focus on the main problem. I used dput as suggested and there an "L" added to all numbers!!

Please let me know if you have any more questions...

head(u3s,10)
?? ID visit AUC Wight ID1
1 101? ?? 3? NA? ? NA?? 1
2 101? ?? 4? 10? ? 13?? 2
3 101? ?? 5? NA? ? NA?? 3
4 102? ?? 3? NA? ? NA?? 4
5 102? ?? 4?? 4? ? 10?? 5
6 102? ?? 5? NA? ? NA?? 6
7 103? ?? 3? NA? ? NA?? 7
8 103? ?? 4?? 6? ?? 9?? 8
9 103? ?? 5? NA? ? NA?? 9

> dput(u3s)
structure(list(ID = c(101L, 101L, 101L, 102L, 102L, 102L, 103L, 103L, 103L), visit = c(3L, 4L, 5L, 3L, 4L, 5L, 3L, 4L, 5L), AUC = c(NA, 10L, NA, NA, 4L, NA, NA, 6L, NA), Wight = c(NA, 13L, NA, NA, 10L, NA, NA, 9L, NA), ID1 = 1:9), .Names = c("ID", "visit", "AUC", "Wight", "ID1"), class = "data.frame", row.names = c(NA, -9L))

Best Regards
Ahmed
.

-----Original Message-----
From: smartpink111 at yahoo.com [mailto:smartpink111 at yahoo.com]
Sent: Monday, September 09, 2013 12:15 PM
To: El-Tahtawy, Ahmed
Subject: replacing Na's with values on different records

HI,

The example dataset "Current" and "Desired" are mangled by HTML.? It is not clear how many columns you have.? I tried it like this, but still it is still not clear..

ID visit AUC Wight ID1
101 3 1 101 4
10 13 2 101 5
3 102 3 4 102
4 4 10 5 102
5 6 103 3 7
103 4 6 9 8
103 5 9?? ####two elements are missing.

Please use ?dput()
For e.g.
dput(head(dataset,20))

<quote author='El-Tahtawy, Ahmed'>
I'm sure I'm missing something really obvious in the "for loop"...

Here is simplified data for 3 patients, we need filling in Na's with same WT for each patient, AUC halved for visit 3, doubled for visit 5 for the same patient, based on visit 4


for(i in unique(u3s$ID)){? ? ? ? ? ? ? ? ? ? ? ? ? ?? #fill in same Wt for each patient
? u3s$WT <- ifelse(is.na(u3s$WT),u3s$WT[u3s$visit == "4"],u3s$WT)

? for(j in length(u3s$ID1)){? ? ? ? ? ? ? ? ? ? ? ? #fill in .5 AUC for visit 3, 2*AUC for visit 5

? ? u3s$AUC24 <- ifelse(is.na(u3s$AUC24),u3s$AUC24[u3s$visit ==
"4"]*0.5,u3s$AUC24)
? ? u3s$AUC24 <- ifelse(!is.na(u3s$AUC24),u3s$AUC24[u3s$visit ==
"4"]*1.0,u3s$AUC24)
? ? u3s$AUC24 <- ifelse(is.na(u3s$AUC24),u3s$AUC24[u3s$visit ==
"4"]*2.0,u3s$AUC24)
? }
}

Current-
ID

visit

AUC

Wight

ID1

101

3





1

101

4

10

13

2

101

5





3

102

3





4

102

4

4

10

5

102

5





6

103

3





7

103

4

6

9

8

103

5





9


Desired-

ID

visit

AUC

Wight

ID1

101

3

5

13

1

101

4

10

13

2

101

5

20

13

3

102

3

2

10

4

102

4

4

10

5

102

5

8

10

6

103

3

3

9

7

103

4

6

9

8

103

5

12

9

9



Your help is greatly appreciated...


Best Regards

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

</quote>
Quoted from: 
http://r.789695.n4.nabble.com/replacing-Na-s-with-values-on-different-records-tp4675696.html


_____________________________________
Sent from http://r.789695.n4.nabble.com



From smartpink111 at yahoo.com  Tue Sep 10 17:31:47 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 10 Sep 2013 08:31:47 -0700 (PDT)
Subject: [R] Looping an lapply linear regression function
In-Reply-To: <DUB119-W32AF029C0BBBAD3764B437C4380@phx.gbl>
References: <756385.314708.1378825455310.JavaMail.nabble@joe.nabble.com>
	<DUB119-W32AF029C0BBBAD3764B437C4380@phx.gbl>
Message-ID: <1378827107.5403.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
Try:

dat2<- read.csv("BOlValues.csv",header=TRUE,sep="\t",row.names=1)
dim(dat2)
#[1] 20 28

indx2<-expand.grid(names(dat2),names(dat2),stringsAsFactors=FALSE)
nrow(indx2)
#[1] 784

indx2New<- indx2[indx2[,1]!=indx2[,2],]
nrow(indx2New)
#[1] 756

res2<-sapply(seq_len(nrow(indx2New)),function(i) {x1<- indx2New[i,]; x2<-cbind(dat2[x1[,1]],dat2[x1[,2]]);summary(lm(x2[,1]~x2[,2]))$coef[,4][2]}) #changed here
dat3<- cbind(indx2New,value=res2)
dim(dat3)
#[1] 756?? 3
library(reshape2)
res2New<- dcast(dat3,Var1~Var2,value.var="value")
row.names(res2New)<- res2New[,1]
?res2New<- as.matrix(res2New[,-1])
?dim(res2New)
#[1] 28 28
A.K.


________________________________
From: Rhys Manners <rhys.manners at hotmail.co.uk>
To: "smartpink111 at yahoo.com" <smartpink111 at yahoo.com> 
Sent: Tuesday, September 10, 2013 11:10 AM
Subject: RE: Looping an lapply linear regression function




Hi,

Thanks for responding to my post, data set attached...

R


> Date: Tue, 10 Sep 2013 08:04:30 -0700
> From: smartpink111 at yahoo.com
> To: rhys.manners at hotmail.co.uk
> Subject: Re: Looping an lapply linear regression function
> 
> Hi,
> Any chance you could email me the dataset you tested for? I will take a look at it.
> Tx.
> 
> 
> 
> <quote author='Rhys_Man'>
> Arun,
> 
> Any reason why I?d keep getting this error whenever I try and run this code
> on fferent country data, which is identical in terms of structure as the
> example I sent you, except for the data being obviously different.
> 
> Error in structure(ordered, dim = ns) : 
>?? dims [product 784] do not match the length of object [0]
> 
> 
> 
> </quote>
> Quoted from: 
> http://r.789695.n4.nabble.com/Looping-an-lapply-linear-regression-function-tp4675475p4675761.html
> 
> 
> _____________________________________
> Sent from http://r.789695.n4.nabble.com
>


From sjkiss at gmail.com  Tue Sep 10 18:23:26 2013
From: sjkiss at gmail.com (Simon Kiss)
Date: Tue, 10 Sep 2013 12:23:26 -0400
Subject: [R] ggplot2 percentages of subpopulations
Message-ID: <9218630F-7F43-4483-85DA-74B0A0FF5B6E@gmail.com>

Hi there: 
I have a sample data set that looks like below.  The variable 'value' represents the counts of cases in each response category.  And I would like to get the barchart to graph the number of responses as a percentage of each total *subpopulation* (Males compared to Females), rather than as a percentage of *all* the responses.
Can someone provide a suggestion?
Thank you

Yours, Simon Kiss
#Sample Code
sample.dat<-data.frame(response.category=rep(c('A', 'B','C'), 2), value=c(50,25,25, 25,25,25), pop=c(rep('Males', 3), rep('Females', 3)))
#Draw GGPLot
test<-ggplot(sample.dat, aes(x=response.category,y=value, group=pop))
test+geom_bar(stat='identity', position='dodge',aes(fill=pop))


From murdoch.duncan at gmail.com  Tue Sep 10 18:38:31 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 10 Sep 2013 12:38:31 -0400
Subject: [R] rgl snapshot on headless server
In-Reply-To: <CAJHOUEMjjYO98UYrkJ_SfSByC9xNqd2ydGVgkFoazbW21ccMvQ@mail.gmail.com>
References: <CAJHOUEMjjYO98UYrkJ_SfSByC9xNqd2ydGVgkFoazbW21ccMvQ@mail.gmail.com>
Message-ID: <522F4B07.4030004@gmail.com>

On 10/09/2013 10:58 AM, Andreas Maunz wrote:
> Hi all,
>
> I have a shiny app, in which I want to use rgl's snapshot function. I am
> running Xvfb on my server so that rgl works. I start my shiny app as
> follows:
>
> echo "Checking for Xvfb..."
> pgrep -U username Xvfb > /dev/null 2>&1
>
> if [ "$?" -gt 0 ]; then
>    echo "Starting Xvfb..."
>    Xvfb :7 -screen 0 1280x1024x24 &
>    sleep 2
> fi
>
> echo "...starting shiny"
> export DISPLAY=":7"; R --no-save --no-restore -e "library('shiny');
> runApp('/path/to/app', port=8101)"
>
> In the app, I do plot3d(), generate webGL and send the results to the
> browser. But the rgl.snapshot or rgl.postscript functionality do not work,
> i.e. they produce black or empty images. I assume this is due to Xvfb. Any
> chance I can create snapshots?

rgl.snapshot requires the X server to maintain a frame buffer that it 
can read.   It looks as though something is going wrong with yours.  I 
don't use a system with Xvfb, so I can't really help, but you could try 
Googling to see if that turns anything up.

rgl.postscript shouldn't need the X server, but it is limited in what it 
can display.

Duncan Murdoch


From Michael.Folkes at dfo-mpo.gc.ca  Tue Sep 10 18:54:53 2013
From: Michael.Folkes at dfo-mpo.gc.ca (Folkes, Michael)
Date: Tue, 10 Sep 2013 09:54:53 -0700
Subject: [R] Hmisc binconf function value interpretation during narrow
	confidence intervals
In-Reply-To: <CAAcyNCxBC-RfEE-FHKF_OtVvcWA3+qzFwmviHLrDik0uCOu-+w@mail.gmail.com>
References: <63F107BCC37AEA49A75FD94AA3E07CB008CD9515@pacpbsex01.pac.dfo-mpo.ca>
	<CAAcyNCxBC-RfEE-FHKF_OtVvcWA3+qzFwmviHLrDik0uCOu-+w@mail.gmail.com>
Message-ID: <63F107BCC37AEA49A75FD94AA3E07CB008CD951B@pacpbsex01.pac.dfo-mpo.ca>

Thanks for your reply Pascal.
The alpha argument in binconf() is "probability of a type I error, so
confidence coefficient = 1-alpha".
Alternately, binom::binom.confint() is given the argument as confidence
level.
The 'exact' method in both functions gives results as expected. It's
just odd for me to go that way when binconf() help says:
"Following Agresti and Coull, the Wilson interval is to be preferred and
so is the default."

Cheers
Michael

________________________________

From: skalp.oettli at gmail.com [mailto:skalp.oettli at gmail.com] On Behalf
Of Pascal Oettli
Sent: September 9, 2013 9:16 PM
To: Folkes, Michael
Cc: R help
Subject: Re: [R] Hmisc binconf function value interpretation during
narrow confidence intervals


Hello,

Are you sure of the alpha value?

Regards,
Pascal

2013/9/10 Folkes, Michael <Michael.Folkes at dfo-mpo.gc.ca>


	Hello all,
	I've been using binconf (package Hmisc) at a range of alpha
values and
	noticed that using the 'Wilson' method when alpha is larger
(i.e. narrow
	CI), results in the upper value being smaller than the lower
value. The
	'exact' and 'asymptotic' methods give results in the realm I'd
expect.
	But the help file suggests:
	"Following Agresti and Coull, the Wilson interval is to be
preferred and
	so is the default."
	
	Suggestions and clarifications gratefully received.
	
	The following code shows the curious results:
	
	#calc 5% CI's.
	require(Hmisc)
	alpha <-.95
	bin.prob <- binconf(1, 100, alpha=alpha,method='all')
	colnames(bin.prob)[-1] <- paste('p',c(alpha/2,1-alpha/2),sep='')
	bin.prob
	
	______________________________________
	Michael Folkes
	Salmon Stock Assessment
	Canadian Dept. of Fisheries & Oceans
	Pacific Biological Station
	3190 Hammond Bay Rd.
	Nanaimo, B.C., Canada
	V9T-6N7
	Michael.Folkes at dfo-mpo.gc.ca
	
	______________________________________________
	R-help at r-project.org mailing list
	https://stat.ethz.ch/mailman/listinfo/r-help
	PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
	and provide commented, minimal, self-contained, reproducible
code.
	




-- 

Pascal Oettli
Project Scientist
JAMSTEC

Yokohama, Japan


From ruipbarradas at sapo.pt  Tue Sep 10 20:33:09 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 10 Sep 2013 19:33:09 +0100
Subject: [R] ggplot2 percentages of subpopulations
In-Reply-To: <9218630F-7F43-4483-85DA-74B0A0FF5B6E@gmail.com>
References: <9218630F-7F43-4483-85DA-74B0A0FF5B6E@gmail.com>
Message-ID: <522F65E5.1040902@sapo.pt>

Hello,

I believe you'll have to do some data aggregation first. The following 
will do it.



dat2 <- merge(sample.dat, aggregate(value ~ pop, data = sample.dat, FUN 
= sum), by = "pop")
dat2$value.x <- dat2$value.x/dat2$value.y

test<-ggplot(dat2, aes(x=response.category,y=value.x, group=pop))
test+geom_bar(stat='identity', position='dodge',aes(fill=pop))


Hope this helps,

Rui Barradas

Em 10-09-2013 17:23, Simon Kiss escreveu:
> Hi there:
> I have a sample data set that looks like below.  The variable 'value' represents the counts of cases in each response category.  And I would like to get the barchart to graph the number of responses as a percentage of each total *subpopulation* (Males compared to Females), rather than as a percentage of *all* the responses.
> Can someone provide a suggestion?
> Thank you
>
> Yours, Simon Kiss
> #Sample Code
> sample.dat<-data.frame(response.category=rep(c('A', 'B','C'), 2), value=c(50,25,25, 25,25,25), pop=c(rep('Males', 3), rep('Females', 3)))
> #Draw GGPLot
> test<-ggplot(sample.dat, aes(x=response.category,y=value, group=pop))
> test+geom_bar(stat='identity', position='dodge',aes(fill=pop))
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From kolassa at stat.rutgers.edu  Tue Sep 10 20:46:50 2013
From: kolassa at stat.rutgers.edu (John Kolassa)
Date: Tue, 10 Sep 2013 14:46:50 -0400 (EDT)
Subject: [R] Function aovp in library lmPerm
In-Reply-To: <b1dad89f-020e-403f-a2e9-ed20d3f239a9@email1>
Message-ID: <1e66a3c5-02a7-45dc-9974-40236b8a7777@email1>

Dear Colleagues,
     I'm attempting to use the function aovp in library lmPerm, and am getting strange results.  The package maintainer appears to be deceased, and I'm wondering if anyone else has experience with this package.
     I'm attempting a permutation test for a two-way analysis of variance model.  An
example in the aovp documentation for the lmPerm library uses the following code:

library("lmPerm")
data(Hald17.4)
summary(aovp(Y~T+Error(block),Hald17.4))

to give a MC p-value for T of approximately .02.  I compare this with the normal theory results of 

summary(aov(Y~T+Error(block),Hald17.4))

to give a p-value of 0.0221.  So far so good.  I then try a new example, using data
from Higgins, Introduction to Nonparametric Statistics, p. 142:

hay<-as.data.frame(list(y=c(
 1.5,2.1,1.9,2.8,1.4,1.8, 1.8,2.0,2.0,2.7,1.6,2.3,
 1.9,2.5,2.5,2.6,2.1,2.4),
 day=as.factor(c(rep("1",6),rep("15",6),rep("30",6))),
 block=as.factor(rep(1:6,3))))
summary(aov(y~Error(block)+day,data=hay))

gives a MC p-value of about .2.  Increasing the MC sample size as

summary(aovp(y~Error(block)+day,data=hay,Ca=.00001,maxIter=100000))

confirms that the p-value is .20, to two decimal paces.  But the normal-theory p-value, determined by 

summary(aov(y~Error(block)+day,data=hay))

is 0.0129.  Furthermore, I can calculate the permutation p-value exactly, by
examining all (3!)^6 permutations, and I obtain the p-value 0.0218.  To complicate
matters further, reordering the data by block, and rerunning the permutation anova,

hay<-hay[order(hay$block),]
summary(aovp(y~Error(block)+day,data=hay,Ca=.00001,maxIter=100000))

gives a p-value .046.

Does anyone with experience with lmPerm have any suggestions for resolving what looks like contradictory results?  Thanks, John


From smartpink111 at yahoo.com  Tue Sep 10 21:08:57 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 10 Sep 2013 12:08:57 -0700 (PDT)
Subject: [R] ggplot2 percentages of subpopulations
In-Reply-To: <9218630F-7F43-4483-85DA-74B0A0FF5B6E@gmail.com>
References: <9218630F-7F43-4483-85DA-74B0A0FF5B6E@gmail.com>
Message-ID: <1378840137.2067.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Try:
library(reshape2)

?sample.dat1<-ddply(sample.dat,.(pop),mutate, valueper=(value/sum(value))*100)
?test<-ggplot(sample.dat1, aes(x=response.category,y=valueper, group=pop))
?test+geom_bar(stat='identity', position='dodge',aes(fill=pop))
A.K.



----- Original Message -----
From: Simon Kiss <sjkiss at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Tuesday, September 10, 2013 12:23 PM
Subject: [R] ggplot2 percentages of subpopulations

Hi there: 
I have a sample data set that looks like below.? The variable 'value' represents the counts of cases in each response category.? And I would like to get the barchart to graph the number of responses as a percentage of each total *subpopulation* (Males compared to Females), rather than as a percentage of *all* the responses.
Can someone provide a suggestion?
Thank you

Yours, Simon Kiss
#Sample Code
sample.dat<-data.frame(response.category=rep(c('A', 'B','C'), 2), value=c(50,25,25, 25,25,25), pop=c(rep('Males', 3), rep('Females', 3)))
#Draw GGPLot
test<-ggplot(sample.dat, aes(x=response.category,y=value, group=pop))
test+geom_bar(stat='identity', position='dodge',aes(fill=pop))

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Tue Sep 10 21:10:10 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 10 Sep 2013 12:10:10 -0700 (PDT)
Subject: [R] ggplot2 percentages of subpopulations
In-Reply-To: <1378840137.2067.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <9218630F-7F43-4483-85DA-74B0A0FF5B6E@gmail.com>
	<1378840137.2067.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1378840210.68638.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Sorry, a mistake:
library(plyr) #instead of library(reshape2)




----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Simon Kiss <sjkiss at gmail.com>
Cc: R help <r-help at r-project.org>
Sent: Tuesday, September 10, 2013 3:08 PM
Subject: Re: [R] ggplot2 percentages of subpopulations

Hi,
Try:
library(reshape2)

?sample.dat1<-ddply(sample.dat,.(pop),mutate, valueper=(value/sum(value))*100)
?test<-ggplot(sample.dat1, aes(x=response.category,y=valueper, group=pop))
?test+geom_bar(stat='identity', position='dodge',aes(fill=pop))
A.K.



----- Original Message -----
From: Simon Kiss <sjkiss at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Tuesday, September 10, 2013 12:23 PM
Subject: [R] ggplot2 percentages of subpopulations

Hi there: 
I have a sample data set that looks like below.? The variable 'value' represents the counts of cases in each response category.? And I would like to get the barchart to graph the number of responses as a percentage of each total *subpopulation* (Males compared to Females), rather than as a percentage of *all* the responses.
Can someone provide a suggestion?
Thank you

Yours, Simon Kiss
#Sample Code
sample.dat<-data.frame(response.category=rep(c('A', 'B','C'), 2), value=c(50,25,25, 25,25,25), pop=c(rep('Males', 3), rep('Females', 3)))
#Draw GGPLot
test<-ggplot(sample.dat, aes(x=response.category,y=value, group=pop))
test+geom_bar(stat='identity', position='dodge',aes(fill=pop))

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jgrn at illinois.edu  Tue Sep 10 21:40:27 2013
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Tue, 10 Sep 2013 14:40:27 -0500
Subject: [R] ifelse question (I'm not sure why this is working)...
Message-ID: <CABG0rfsU08JDp269MVVnCzPT8iYVMmGAZd_KOSPxkZxRg_jTEw@mail.gmail.com>

R-helpers:

One of my intrepid students came up with a solution to a problem where
they need to write a function that takes a vector x and a "scalar" d,
and return the indices of the vector x where x %% d is equal to 0 (x
is evenly divisible by d).  I thought I had a good handle on the
potential solutions, but one of my students sent me a function that
WORKS, but for the life of me I can't figure out WHY.  Here is the
solution:

remainderFunction<-function(x,d)
{
   ifelse(x%%d==0,yes=return(which(x%%d==0)),no=return(NULL))
}
remainderFunction(x=c(23:47),d=3)

I've never seen an ifelse statement used that way, and I was fully
expecting that to NOT work, or to place the output of which(x%%d==0)
in each location where the statement x%%d==0 was true.

Any ideas on deconstructing this?

--j

-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
607 South Mathews Avenue, MC 150
Urbana, IL 61801
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From Brian.Davis at uth.tmc.edu  Tue Sep 10 21:54:47 2013
From: Brian.Davis at uth.tmc.edu (Davis, Brian)
Date: Tue, 10 Sep 2013 14:54:47 -0500
Subject: [R] assigning the class of an object
Message-ID: <8AB18F255888194F82934830982C82C16FAADC92B4@UTHCMS1.uthouston.edu>

I'm sure this has been answered before but alas my googlefoo is not that strong.

I have several .Rdata files with a single object in them.  I need to set the class of the object to "myClass".  Unfortunately, I don't know the name of the object beforehand.  Obviously I could ls() and get the name but as I have quite a few of these I'd like to do it programmatically.


I thought something like this would work, but I get an error.

>obj_name <- load("Robject.RData")   # get the name of the loaded object
>class(get(obj_name)) <- "myClass"

Error in class(get(obj_name)) <- " myClass " : 
  could not find function "get<-"


So I guess the question is how do I set the class of an R object when I only have the object name as a character string?

Thanks in advance,

Brian


From wdunlap at tibco.com  Tue Sep 10 21:58:33 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 10 Sep 2013 19:58:33 +0000
Subject: [R] ifelse question (I'm not sure why this is working)...
In-Reply-To: <CABG0rfsU08JDp269MVVnCzPT8iYVMmGAZd_KOSPxkZxRg_jTEw@mail.gmail.com>
References: <CABG0rfsU08JDp269MVVnCzPT8iYVMmGAZd_KOSPxkZxRg_jTEw@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C3421D7@PA-MBX01.na.tibco.com>

> remainderFunction<-function(x,d)
> {
>    ifelse(x%%d==0,yes=return(which(x%%d==0)),no=return(NULL))
> }
> remainderFunction(x=c(23:47),d=3)

The above call returns c(2, 5, 8, 11, 14, 17, 20, 23), the value of (23:47)%%3.
Note that remainderFunction(integer(0), 3) returns logical(0).

The return() calls in the call to ifelse cause the problem.  The one used
for the second argument to ifelse causes remainderFunction to return,
abandoning the evaluation of ifself, as soon as ifelse evaluates its second
argument.

I think that using return this way is bad practice, but have seen it in code like
   tryCatch(return(something),
                    error=function(e)"Error in something")
which is common in support code for RStudio.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Jonathan Greenberg
> Sent: Tuesday, September 10, 2013 12:40 PM
> To: r-help
> Subject: [R] ifelse question (I'm not sure why this is working)...
> 
> R-helpers:
> 
> One of my intrepid students came up with a solution to a problem where
> they need to write a function that takes a vector x and a "scalar" d,
> and return the indices of the vector x where x %% d is equal to 0 (x
> is evenly divisible by d).  I thought I had a good handle on the
> potential solutions, but one of my students sent me a function that
> WORKS, but for the life of me I can't figure out WHY.  Here is the
> solution:
> 
> remainderFunction<-function(x,d)
> {
>    ifelse(x%%d==0,yes=return(which(x%%d==0)),no=return(NULL))
> }
> remainderFunction(x=c(23:47),d=3)
> 
> I've never seen an ifelse statement used that way, and I was fully
> expecting that to NOT work, or to place the output of which(x%%d==0)
> in each location where the statement x%%d==0 was true.
> 
> Any ideas on deconstructing this?
> 
> --j
> 
> --
> Jonathan A. Greenberg, PhD
> Assistant Professor
> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
> Department of Geography and Geographic Information Science
> University of Illinois at Urbana-Champaign
> 607 South Mathews Avenue, MC 150
> Urbana, IL 61801
> Phone: 217-300-1924
> http://www.geog.illinois.edu/~jgrn/
> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Tue Sep 10 22:10:12 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 10 Sep 2013 20:10:12 +0000
Subject: [R] ifelse question (I'm not sure why this is working)...
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C3421D7@PA-MBX01.na.tibco.com>
References: <CABG0rfsU08JDp269MVVnCzPT8iYVMmGAZd_KOSPxkZxRg_jTEw@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C3421D7@PA-MBX01.na.tibco.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C342200@PA-MBX01.na.tibco.com>

Here is the same issue in a simpler form:
   > f <- function(x) log(return(x))
   > f(10)
   [1] 10
f's 'x' is returned before log does anything with it.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of William Dunlap
> Sent: Tuesday, September 10, 2013 12:59 PM
> To: Jonathan Greenberg; r-help
> Subject: Re: [R] ifelse question (I'm not sure why this is working)...
> 
> > remainderFunction<-function(x,d)
> > {
> >    ifelse(x%%d==0,yes=return(which(x%%d==0)),no=return(NULL))
> > }
> > remainderFunction(x=c(23:47),d=3)
> 
> The above call returns c(2, 5, 8, 11, 14, 17, 20, 23), the value of (23:47)%%3.
> Note that remainderFunction(integer(0), 3) returns logical(0).
> 
> The return() calls in the call to ifelse cause the problem.  The one used
> for the second argument to ifelse causes remainderFunction to return,
> abandoning the evaluation of ifself, as soon as ifelse evaluates its second
> argument.
> 
> I think that using return this way is bad practice, but have seen it in code like
>    tryCatch(return(something),
>                     error=function(e)"Error in something")
> which is common in support code for RStudio.
> 
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
> 
> 
> > -----Original Message-----
> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> > Of Jonathan Greenberg
> > Sent: Tuesday, September 10, 2013 12:40 PM
> > To: r-help
> > Subject: [R] ifelse question (I'm not sure why this is working)...
> >
> > R-helpers:
> >
> > One of my intrepid students came up with a solution to a problem where
> > they need to write a function that takes a vector x and a "scalar" d,
> > and return the indices of the vector x where x %% d is equal to 0 (x
> > is evenly divisible by d).  I thought I had a good handle on the
> > potential solutions, but one of my students sent me a function that
> > WORKS, but for the life of me I can't figure out WHY.  Here is the
> > solution:
> >
> > remainderFunction<-function(x,d)
> > {
> >    ifelse(x%%d==0,yes=return(which(x%%d==0)),no=return(NULL))
> > }
> > remainderFunction(x=c(23:47),d=3)
> >
> > I've never seen an ifelse statement used that way, and I was fully
> > expecting that to NOT work, or to place the output of which(x%%d==0)
> > in each location where the statement x%%d==0 was true.
> >
> > Any ideas on deconstructing this?
> >
> > --j
> >
> > --
> > Jonathan A. Greenberg, PhD
> > Assistant Professor
> > Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
> > Department of Geography and Geographic Information Science
> > University of Illinois at Urbana-Champaign
> > 607 South Mathews Avenue, MC 150
> > Urbana, IL 61801
> > Phone: 217-300-1924
> > http://www.geog.illinois.edu/~jgrn/
> > AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mbudnick08 at snet.net  Tue Sep 10 22:06:48 2013
From: mbudnick08 at snet.net (Michael Budnick)
Date: Tue, 10 Sep 2013 16:06:48 -0400
Subject: [R] Subtracting elements of a vector from each other stepwise
Message-ID: <CANTLroGb_R4HOgG5gNk9HCPaPX2=EZ_J_KLhYmRtLfLB+W-OAw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130910/e1135b40/attachment.pl>

From rolf.turner at xtra.co.nz  Tue Sep 10 22:56:07 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Wed, 11 Sep 2013 08:56:07 +1200
Subject: [R] assigning the class of an object
In-Reply-To: <8AB18F255888194F82934830982C82C16FAADC92B4@UTHCMS1.uthouston.edu>
References: <8AB18F255888194F82934830982C82C16FAADC92B4@UTHCMS1.uthouston.edu>
Message-ID: <522F8767.7040504@xtra.co.nz>

On 09/11/13 07:54, Davis, Brian wrote:
> I'm sure this has been answered before but alas my googlefoo is not that strong.
>
> I have several .Rdata files with a single object in them.  I need to set the class of the object to "myClass".  Unfortunately, I don't know the name of the object beforehand.  Obviously I could ls() and get the name but as I have quite a few of these I'd like to do it programmatically.
>
>
> I thought something like this would work, but I get an error.
>
>> obj_name <- load("Robject.RData")   # get the name of the loaded object
>> class(get(obj_name)) <- "myClass"
> Error in class(get(obj_name)) <- " myClass " :
>    could not find function "get<-"
>
>
> So I guess the question is how do I set the class of an R object when I only have the object name as a character string?

(a) Actually, a wee experiment that I did indicates that your strategy 
actually *works* despite the error message!!!
That is, you wind up with an object, named by obj_name, with class 
"myClass". I don't understand this.  Perhaps
someone more knowledgeable than I will enlighten us both.

(b) To accomplish your task without getting an off-putting error 
message, you proceed in two (three?) steps:

	obj_name <- load("Robject.RData")
	tempObj <- get(obj_name)
	class(tempObj) <- "myClass"
	assign(obj_name,tempObj)

HTH

	cheers,

	Rolf Turner


From smartpink111 at yahoo.com  Tue Sep 10 23:06:39 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 10 Sep 2013 14:06:39 -0700 (PDT)
Subject: [R] Subtracting elements of a vector from each other stepwise
In-Reply-To: <CANTLroGb_R4HOgG5gNk9HCPaPX2=EZ_J_KLhYmRtLfLB+W-OAw@mail.gmail.com>
References: <CANTLroGb_R4HOgG5gNk9HCPaPX2=EZ_J_KLhYmRtLfLB+W-OAw@mail.gmail.com>
Message-ID: <1378847199.17716.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
Not sure this is what you wanted:


?sapply(seq_along(x), function(i) {x1<- x[i]; x2<- x[-i]; x3<-x2[which.min(abs(x1-x2))];c(x1,x3)})
#???? [,1] [,2] [,3] [,4]
#[1,]?? 17?? 19?? 23?? 29
#[2,]?? 19?? 17?? 19?? 23
A.K.



----- Original Message -----
From: Michael Budnick <mbudnick08 at snet.net>
To: r-help at r-project.org
Cc: 
Sent: Tuesday, September 10, 2013 4:06 PM
Subject: [R] Subtracting elements of a vector from each other stepwise

I am trying to figure out how to create a loop that will take the
difference of each member of a vector from each other and also spit out
which one has the least difference.

I do not want the vector member to subtract from itself or it must be able
to disregard the 0 obtained from subtracting from itself.

For example:

x = c(17,19,23,29)

1. abs(x-x[1]) = (0, 2, 6, 12)

2. abs(x-x[2]) = (2, 0, 4, 10)

3. abs(x-x[3]) = (6, 4, 0, 6)

4. abs(x-x[4]) = (12, 10, 6, 0)

The code would then spit out that x[1] and x[2] are the least different,
but if there were 2 separate values that were equal the program would
recognize them as least different.

A little extra help would be to also make this go down row by row through
horizontal vectors.

I am new to R and all my for loops I'm trying come back null.

Thanks for any help.

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From pdalgd at gmail.com  Tue Sep 10 23:16:23 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 10 Sep 2013 23:16:23 +0200
Subject: [R] assigning the class of an object
In-Reply-To: <522F8767.7040504@xtra.co.nz>
References: <8AB18F255888194F82934830982C82C16FAADC92B4@UTHCMS1.uthouston.edu>
	<522F8767.7040504@xtra.co.nz>
Message-ID: <0DDCDE22-601F-412C-BCB9-3CB5F9EA741E@gmail.com>


On Sep 10, 2013, at 22:56 , Rolf Turner wrote:

> On 09/11/13 07:54, Davis, Brian wrote:
>> I'm sure this has been answered before but alas my googlefoo is not that strong.
>> 
>> I have several .Rdata files with a single object in them.  I need to set the class of the object to "myClass".  Unfortunately, I don't know the name of the object beforehand.  Obviously I could ls() and get the name but as I have quite a few of these I'd like to do it programmatically.
>> 
>> 
>> I thought something like this would work, but I get an error.
>> 
>>> obj_name <- load("Robject.RData")   # get the name of the loaded object
>>> class(get(obj_name)) <- "myClass"
>> Error in class(get(obj_name)) <- " myClass " :
>>   could not find function "get<-"
>> 
>> 
>> So I guess the question is how do I set the class of an R object when I only have the object name as a character string?
> 
> (a) Actually, a wee experiment that I did indicates that your strategy actually *works* despite the error message!!!
> That is, you wind up with an object, named by obj_name, with class "myClass". I don't understand this.  Perhaps
> someone more knowledgeable than I will enlighten us both.

It certainly won't work universally:

> x <- 5
> obj_name <- "x"
> class(get(obj_name))<-"foo"
Error in class(get(obj_name)) <- "foo" : could not find function "get<-"
> x
[1] 5

so further details of your wee experiments need to be revealed.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bbolker at gmail.com  Tue Sep 10 23:39:10 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 10 Sep 2013 21:39:10 +0000
Subject: [R] Subtracting elements of a vector from each other stepwise
References: <CANTLroGb_R4HOgG5gNk9HCPaPX2=EZ_J_KLhYmRtLfLB+W-OAw@mail.gmail.com>
	<1378847199.17716.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <loom.20130910T233603-460@post.gmane.org>

arun <smartpink111 <at> yahoo.com> writes:

> 
> Hi,
> Not sure this is what you wanted:
> 
> ?sapply(seq_along(x), function(i) {x1<- x[i]; x2<- x[-i];
x3<-x2[which.min(abs(x1-x2))];c(x1,x3)})
> #???? [,1] [,2] [,3] [,4]
> #[1,]?? 17?? 19?? 23?? 29
> #[2,]?? 19?? 17?? 19?? 23
> A.K.


  It's a little inefficient (because it constructs
the distances in both directions), but how about:

x = c(17,19,23,29)
d <- abs(outer(x,x,"-"))
diag(d) <- NA
d[lower.tri(d)] <- NA
which(d==min(d,na.rm=TRUE),arr.ind=TRUE)


?
 
> ----- Original Message -----
> From: Michael Budnick <mbudnick08 <at> snet.net>
> To: r-help <at> r-project.org
> Cc: 
> Sent: Tuesday, September 10, 2013 4:06 PM
> Subject: [R] Subtracting elements of a vector from each other stepwise
> 
> I am trying to figure out how to create a loop that will take the
> difference of each member of a vector from each other and also spit out
> which one has the least difference.
> 
> I do not want the vector member to subtract from itself or it must be able
> to disregard the 0 obtained from subtracting from itself.
> 
> For example:
> 
> x = c(17,19,23,29)


 [snip]


From jim at bitwrit.com.au  Tue Sep 10 23:39:01 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 11 Sep 2013 07:39:01 +1000
Subject: [R] ifelse question (I'm not sure why this is working)...
In-Reply-To: <CABG0rfsU08JDp269MVVnCzPT8iYVMmGAZd_KOSPxkZxRg_jTEw@mail.gmail.com>
References: <CABG0rfsU08JDp269MVVnCzPT8iYVMmGAZd_KOSPxkZxRg_jTEw@mail.gmail.com>
Message-ID: <522F9175.9050704@bitwrit.com.au>

On 09/11/2013 05:40 AM, Jonathan Greenberg wrote:
> R-helpers:
>
> One of my intrepid students came up with a solution to a problem where
> they need to write a function that takes a vector x and a "scalar" d,
> and return the indices of the vector x where x %% d is equal to 0 (x
> is evenly divisible by d).  I thought I had a good handle on the
> potential solutions, but one of my students sent me a function that
> WORKS, but for the life of me I can't figure out WHY.  Here is the
> solution:
>
> remainderFunction<-function(x,d)
> {
>     ifelse(x%%d==0,yes=return(which(x%%d==0)),no=return(NULL))
> }
> remainderFunction(x=c(23:47),d=3)
>
> I've never seen an ifelse statement used that way, and I was fully
> expecting that to NOT work, or to place the output of which(x%%d==0)
> in each location where the statement x%%d==0 was true.
>
> Any ideas on deconstructing this?
>
> --j
>
Hi Jonathan,
While this has already been answered, the question was "why does it 
work?". As Bill Dunlap pointed out, it is because the "return" does not 
allow the ifelse to complete. That was not a problem for the student, 
for it did do what was requested. It is just an unnecessary elaboration 
of the code, for:

remainderFunction<-function(x,d) {
  which(x%%d==0)
}

works just as well. I think Bill was pointing out the the order of 
evaluation was important, for:

remainderFunction<-function(x,d) {
  which(return(x%%d==0))
}

doesn't work. The student probably deserves a Rube Goldberg award.

Jim


From wdunlap at tibco.com  Tue Sep 10 23:41:17 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 10 Sep 2013 21:41:17 +0000
Subject: [R] assigning the class of an object
In-Reply-To: <8AB18F255888194F82934830982C82C16FAADC92B4@UTHCMS1.uthouston.edu>
References: <8AB18F255888194F82934830982C82C16FAADC92B4@UTHCMS1.uthouston.edu>
Message-ID: <E66794E69CFDE04D9A70842786030B931C34227C@PA-MBX01.na.tibco.com>

You could use assign(name, newValue, envir=env) but I prefer env[[name]]<-newValue
since the env[[name]] works on either side of the assignment operator.  E.g.,

> env <- new.env() # or environment() if you prefer to put things in the current environment
> objNames <- load("Robject.RData", envir=env) # contains zzz<-17 and xxx<-23:24
> sapply(objNames, function(objName)class(env[[objName]]) <- "someClass")
        zzz         xxx
"someClass" "someClass"
> env$xxx
[1] 23 24
attr(,"class")
[1] "someClass"
> env$zzz
[1] 17
attr(,"class")
[1] "someClass"

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Davis, Brian
> Sent: Tuesday, September 10, 2013 12:55 PM
> To: r-help at r-project.org
> Subject: [R] assigning the class of an object
> 
> I'm sure this has been answered before but alas my googlefoo is not that strong.
> 
> I have several .Rdata files with a single object in them.  I need to set the class of the
> object to "myClass".  Unfortunately, I don't know the name of the object beforehand.
> Obviously I could ls() and get the name but as I have quite a few of these I'd like to do it
> programmatically.
> 
> 
> I thought something like this would work, but I get an error.
> 
> >obj_name <- load("Robject.RData")   # get the name of the loaded object
> >class(get(obj_name)) <- "myClass"
> 
> Error in class(get(obj_name)) <- " myClass " :
>   could not find function "get<-"
> 
> 
> So I guess the question is how do I set the class of an R object when I only have the
> object name as a character string?
> 
> Thanks in advance,
> 
> Brian
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rolf.turner at xtra.co.nz  Tue Sep 10 23:49:36 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Wed, 11 Sep 2013 09:49:36 +1200
Subject: [R] assigning the class of an object
In-Reply-To: <0DDCDE22-601F-412C-BCB9-3CB5F9EA741E@gmail.com>
References: <8AB18F255888194F82934830982C82C16FAADC92B4@UTHCMS1.uthouston.edu>
	<522F8767.7040504@xtra.co.nz>
	<0DDCDE22-601F-412C-BCB9-3CB5F9EA741E@gmail.com>
Message-ID: <522F93F0.8080802@xtra.co.nz>

On 09/11/13 09:16, peter dalgaard wrote:
> On Sep 10, 2013, at 22:56 , Rolf Turner wrote:
>
>> On 09/11/13 07:54, Davis, Brian wrote:
>>> I'm sure this has been answered before but alas my googlefoo is not that strong.
>>>
>>> I have several .Rdata files with a single object in them.  I need to set the class of the object to "myClass".  Unfortunately, I don't know the name of the object beforehand.  Obviously I could ls() and get the name but as I have quite a few of these I'd like to do it programmatically.
>>>
>>>
>>> I thought something like this would work, but I get an error.
>>>
>>>> obj_name <- load("Robject.RData")   # get the name of the loaded object
>>>> class(get(obj_name)) <- "myClass"
>>> Error in class(get(obj_name)) <- " myClass " :
>>>    could not find function "get<-"
>>>
>>>
>>> So I guess the question is how do I set the class of an R object when I only have the object name as a character string?
>> (a) Actually, a wee experiment that I did indicates that your strategy actually *works* despite the error message!!!
>> That is, you wind up with an object, named by obj_name, with class "myClass". I don't understand this.  Perhaps
>> someone more knowledgeable than I will enlighten us both.
> It certainly won't work universally:
>
>> x <- 5
>> obj_name <- "x"
>> class(get(obj_name))<-"foo"
> Error in class(get(obj_name)) <- "foo" : could not find function "get<-"
>> x
> [1] 5
>
> so further details of your wee experiments need to be revealed.
>
Hmmm.  I did:

x <- 42
save(x,file="Robject.RData")
rm(list=ls())
obj_name <- load("Robject.RData")
class(get(obj_name)) <- "myClass"
x

and got:

[1] 42
attr(,"class")
[1] "myClass"

(also got the familiar error message).

When I did it your way --- without the saving and loading bit --- I got
the same result that you did.  I.e. assigning the class that way did *not*
work (as one would expect it wouldn't!).

This is weird, n'est-ce pas?

Here is my

 > sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods base

other attached packages:
[1] misc_0.0-15

     cheers,

     Rolf


From marius.hofert at math.ethz.ch  Tue Sep 10 23:50:08 2013
From: marius.hofert at math.ethz.ch (Marius Hofert)
Date: Tue, 10 Sep 2013 23:50:08 +0200
Subject: [R] double.xmin really the smallest non-zero normalized
	floating-point number?
Message-ID: <CAM3-KjZa_ezO-hpm9nh66SV9LuX+JLAwJ580UTmGMaihfe7PoA@mail.gmail.com>

Hi,

?.Machine says that 'double.xmin' is 'the smallest non-zero normalized
floating-point number'. On my machine, this is 2.225074e-308. However,
2.225074e-308 / 2 is > 0 and smaller than 2.225074e-308, so
double.xmin is not the smallest such number (?) Am I missing anything?

Cheers,

Marius


From paulbernal07 at gmail.com  Tue Sep 10 23:53:48 2013
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Tue, 10 Sep 2013 16:53:48 -0500
Subject: [R] Fitting Arima Model to Daily Time Series
Message-ID: <CAMOcQfPKLfpa9b79nbWi_C2ryAb4QrZJvsSuuO-aSuiumvBeyA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130910/cbb5aa14/attachment.pl>

From wdunlap at tibco.com  Wed Sep 11 00:07:23 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 10 Sep 2013 22:07:23 +0000
Subject: [R] double.xmin really the smallest non-zero
	normalized	floating-point number?
In-Reply-To: <CAM3-KjZa_ezO-hpm9nh66SV9LuX+JLAwJ580UTmGMaihfe7PoA@mail.gmail.com>
References: <CAM3-KjZa_ezO-hpm9nh66SV9LuX+JLAwJ580UTmGMaihfe7PoA@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C3422C8@PA-MBX01.na.tibco.com>

'normalized' is key.  A normalized double precision floating point
number has 52 binary digits of precision and .Machine$double.eps/2
does not.  E.g.,

  > bitsOfPrecision <- function(x)max(which( x != x*(1+2^-(1:60))))
  > bitsOfPrecision(4)
  [1] 52
  > bitsOfPrecision(.Machine$double.xmin)
  [1] 52
  > bitsOfPrecision(.Machine$double.xmin/2)
  [1] 51
  > bitsOfPrecision(.Machine$double.xmin/4)
  [1] 50

Google for 'normalized floating point'.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Marius Hofert
> Sent: Tuesday, September 10, 2013 2:50 PM
> To: R-help
> Subject: [R] double.xmin really the smallest non-zero normalized floating-point number?
> 
> Hi,
> 
> ?.Machine says that 'double.xmin' is 'the smallest non-zero normalized
> floating-point number'. On my machine, this is 2.225074e-308. However,
> 2.225074e-308 / 2 is > 0 and smaller than 2.225074e-308, so
> double.xmin is not the smallest such number (?) Am I missing anything?
> 
> Cheers,
> 
> Marius
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Wed Sep 11 00:11:33 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 11 Sep 2013 00:11:33 +0200
Subject: [R] ifelse question (I'm not sure why this is working)...
In-Reply-To: <522F9175.9050704@bitwrit.com.au>
References: <CABG0rfsU08JDp269MVVnCzPT8iYVMmGAZd_KOSPxkZxRg_jTEw@mail.gmail.com>
	<522F9175.9050704@bitwrit.com.au>
Message-ID: <48F8D1AE-8253-4AFB-B98A-AD8E20D8B859@gmail.com>


On Sep 10, 2013, at 23:39 , Jim Lemon wrote:

> On 09/11/2013 05:40 AM, Jonathan Greenberg wrote:
>> R-helpers:
>> 
>> One of my intrepid students came up with a solution to a problem where
>> they need to write a function that takes a vector x and a "scalar" d,
>> and return the indices of the vector x where x %% d is equal to 0 (x
>> is evenly divisible by d).  I thought I had a good handle on the
>> potential solutions, but one of my students sent me a function that
>> WORKS, but for the life of me I can't figure out WHY.  Here is the
>> solution:
>> 
>> remainderFunction<-function(x,d)
>> {
>>    ifelse(x%%d==0,yes=return(which(x%%d==0)),no=return(NULL))
>> }
>> remainderFunction(x=c(23:47),d=3)
>> 
>> I've never seen an ifelse statement used that way, and I was fully
>> expecting that to NOT work, or to place the output of which(x%%d==0)
>> in each location where the statement x%%d==0 was true.
>> 
>> Any ideas on deconstructing this?
>> 
>> --j
>> 
> Hi Jonathan,
> While this has already been answered, the question was "why does it work?". As Bill Dunlap pointed out, it is because the "return" does not allow the ifelse to complete. That was not a problem for the student, for it did do what was requested. It is just an unnecessary elaboration of the code, for:
> 
> remainderFunction<-function(x,d) {
> which(x%%d==0)
> }
> 
> works just as well. I think Bill was pointing out the the order of evaluation was important, for:
> 
> remainderFunction<-function(x,d) {
> which(return(x%%d==0))
> }
> 
> doesn't work. The student probably deserves a Rube Goldberg award.


It's slightly trickier: the yes= part of an ifelse is not evaluated unless at least one element of the test is TRUE, so I think the equivalence is closer to

remainderFunction<-function(x,d)
  if (any(x %% d == 0) ) which(x %% d==0) 

except that ifelse() has the curious feature of returning logical(0) if the test vector is logical(0) (evaluating neither of its arguments).

(If you want to be really picky, the above returns NULL _invisibly_ if the any() condition fails. Whether or not the student deserves a little credit for thinking about that case is up in the air, I think. He/she may have failed to grasp the meaning of integer(0).)

> 
> Jim
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From marius.hofert at math.ethz.ch  Wed Sep 11 00:17:22 2013
From: marius.hofert at math.ethz.ch (Marius Hofert)
Date: Wed, 11 Sep 2013 00:17:22 +0200
Subject: [R] double.xmin really the smallest non-zero normalized
 floating-point number?
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C3422C8@PA-MBX01.na.tibco.com>
References: <CAM3-KjZa_ezO-hpm9nh66SV9LuX+JLAwJ580UTmGMaihfe7PoA@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C3422C8@PA-MBX01.na.tibco.com>
Message-ID: <CAM3-KjZitZ4z72pcvuFXpCid7jhH_e9cXjmdtnUvAV5Q+ZuNyw@mail.gmail.com>

On Wed, Sep 11, 2013 at 12:07 AM, William Dunlap <wdunlap at tibco.com> wrote:
> 'normalized' is key.  A normalized double precision floating point
> number has 52 binary digits of precision and .Machine$double.eps/2
> does not.  E.g.,
>
>   > bitsOfPrecision <- function(x)max(which( x != x*(1+2^-(1:60))))

what a nice function :-)

>   > bitsOfPrecision(4)
>   [1] 52
>   > bitsOfPrecision(.Machine$double.xmin)
>   [1] 52
>   > bitsOfPrecision(.Machine$double.xmin/2)
>   [1] 51
>   > bitsOfPrecision(.Machine$double.xmin/4)
>   [1] 50
>
> Google for 'normalized floating point'.

Okay, thanks a lot.

Do you know whether one can find out the smallest positive number on
the current machine?
Or, actually, I was wondering what the smallest number x is, such that
exp(-x) = 0 in machine arithmetic.
On my machine, x=745 leads to exp(-x) being not quite 0, but x=746
leads to exp(-x)==0 being TRUE. But these are integer x's...

Many thanks and cheers,

Marius


>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
>> Of Marius Hofert
>> Sent: Tuesday, September 10, 2013 2:50 PM
>> To: R-help
>> Subject: [R] double.xmin really the smallest non-zero normalized floating-point number?
>>
>> Hi,
>>
>> ?.Machine says that 'double.xmin' is 'the smallest non-zero normalized
>> floating-point number'. On my machine, this is 2.225074e-308. However,
>> 2.225074e-308 / 2 is > 0 and smaller than 2.225074e-308, so
>> double.xmin is not the smallest such number (?) Am I missing anything?
>>
>> Cheers,
>>
>> Marius
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Wed Sep 11 00:24:04 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 10 Sep 2013 15:24:04 -0700 (PDT)
Subject: [R] Subtracting elements of a vector from each other stepwise
In-Reply-To: <loom.20130910T233603-460@post.gmane.org>
References: <CANTLroGb_R4HOgG5gNk9HCPaPX2=EZ_J_KLhYmRtLfLB+W-OAw@mail.gmail.com>	<1378847199.17716.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<loom.20130910T233603-460@post.gmane.org>
Message-ID: <1378851844.80715.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
May be this also works:

?dist(x)
#?? 1? 2? 3
#2? 2????? 
#3? 6? 4?? 
#4 12 10? 6

as.matrix(dist(x))
#?? 1? 2 3? 4
#1? 0? 2 6 12
#2? 2? 0 4 10
#3? 6? 4 0? 6
#4 12 10 6? 0
which(dist(x)==min(dist(x)))
#[1] 1
A.K.



----- Original Message -----
From: Ben Bolker <bbolker at gmail.com>
To: r-help at stat.math.ethz.ch
Cc: 
Sent: Tuesday, September 10, 2013 5:39 PM
Subject: Re: [R] Subtracting elements of a vector from each other stepwise

arun <smartpink111 <at> yahoo.com> writes:

> 
> Hi,
> Not sure this is what you wanted:
> 
> ?sapply(seq_along(x), function(i) {x1<- x[i]; x2<- x[-i];
x3<-x2[which.min(abs(x1-x2))];c(x1,x3)})
> #???? [,1] [,2] [,3] [,4]
> #[1,]?? 17?? 19?? 23?? 29
> #[2,]?? 19?? 17?? 19?? 23
> A.K.


? It's a little inefficient (because it constructs
the distances in both directions), but how about:

x = c(17,19,23,29)
d <- abs(outer(x,x,"-"))
diag(d) <- NA
d[lower.tri(d)] <- NA
which(d==min(d,na.rm=TRUE),arr.ind=TRUE)


?

> ----- Original Message -----
> From: Michael Budnick <mbudnick08 <at> snet.net>
> To: r-help <at> r-project.org
> Cc: 
> Sent: Tuesday, September 10, 2013 4:06 PM
> Subject: [R] Subtracting elements of a vector from each other stepwise
> 
> I am trying to figure out how to create a loop that will take the
> difference of each member of a vector from each other and also spit out
> which one has the least difference.
> 
> I do not want the vector member to subtract from itself or it must be able
> to disregard the 0 obtained from subtracting from itself.
> 
> For example:
> 
> x = c(17,19,23,29)


[snip]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From charles.santana at gmail.com  Wed Sep 11 01:06:44 2013
From: charles.santana at gmail.com (Charles Novaes de Santana)
Date: Wed, 11 Sep 2013 01:06:44 +0200
Subject: [R] Problems to show X-labels when plotting small values
Message-ID: <CAH-FEngEUzrXbjw_LOm78aH03goS61+bTESnKj=h0fMT=49CQw@mail.gmail.com>

Um texto embutido e sem conjunto de caracteres especificado foi limpo...
Nome: n?o dispon?vel
Url: <https://stat.ethz.ch/pipermail/r-help/attachments/20130911/3c6d8b7b/attachment.pl>

From bbolker at gmail.com  Wed Sep 11 01:48:04 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 10 Sep 2013 19:48:04 -0400
Subject: [R] Subtracting elements of a vector from each other stepwise
In-Reply-To: <1378851844.80715.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <CANTLroGb_R4HOgG5gNk9HCPaPX2=EZ_J_KLhYmRtLfLB+W-OAw@mail.gmail.com>	<1378847199.17716.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<loom.20130910T233603-460@post.gmane.org>
	<1378851844.80715.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <522FAFB4.907@gmail.com>

On 13-09-10 06:24 PM, arun wrote:
> Hi,
> May be this also works:
> 
>  dist(x)
> #   1  2  3
> #2  2      
> #3  6  4   
> #4 12 10  6
> 
> as.matrix(dist(x))
> #   1  2 3  4
> #1  0  2 6 12
> #2  2  0 4 10
> #3  6  4 0  6
> #4 12 10 6  0
> which(dist(x)==min(dist(x)))
> #[1] 1
> A.K.

  Yes, but you need to set the diagonal to NA, or something -- the OP
doesn't want to include self-comparison. It also helps to use
arr.ind=TRUE in which().  You're right that dist() would be a hair more
efficient that outer(...), though

> 
> 
> 
> ----- Original Message -----
> From: Ben Bolker <bbolker at gmail.com>
> To: r-help at stat.math.ethz.ch
> Cc: 
> Sent: Tuesday, September 10, 2013 5:39 PM
> Subject: Re: [R] Subtracting elements of a vector from each other stepwise
> 
> arun <smartpink111 <at> yahoo.com> writes:
> 
>>
>> Hi,
>> Not sure this is what you wanted:
>>
>>  sapply(seq_along(x), function(i) {x1<- x[i]; x2<- x[-i];
> x3<-x2[which.min(abs(x1-x2))];c(x1,x3)})
>> #     [,1] [,2] [,3] [,4]
>> #[1,]   17   19   23   29
>> #[2,]   19   17   19   23
>> A.K.
> 
> 
>   It's a little inefficient (because it constructs
> the distances in both directions), but how about:
> 
> x = c(17,19,23,29)
> d <- abs(outer(x,x,"-"))
> diag(d) <- NA
> d[lower.tri(d)] <- NA
> which(d==min(d,na.rm=TRUE),arr.ind=TRUE)
> 
> 
> ?
> 
>> ----- Original Message -----
>> From: Michael Budnick <mbudnick08 <at> snet.net>
>> To: r-help <at> r-project.org
>> Cc: 
>> Sent: Tuesday, September 10, 2013 4:06 PM
>> Subject: [R] Subtracting elements of a vector from each other stepwise
>>
>> I am trying to figure out how to create a loop that will take the
>> difference of each member of a vector from each other and also spit out
>> which one has the least difference.
>>
>> I do not want the vector member to subtract from itself or it must be able
>> to disregard the 0 obtained from subtracting from itself.
>>
>> For example:
>>
>> x = c(17,19,23,29)
> 
> 
> [snip]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Wed Sep 11 02:21:29 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 10 Sep 2013 17:21:29 -0700
Subject: [R] ifelse question (I'm not sure why this is working)...
In-Reply-To: <CABG0rfsU08JDp269MVVnCzPT8iYVMmGAZd_KOSPxkZxRg_jTEw@mail.gmail.com>
References: <CABG0rfsU08JDp269MVVnCzPT8iYVMmGAZd_KOSPxkZxRg_jTEw@mail.gmail.com>
Message-ID: <121B30EF-F1E7-45F3-978D-98688036125D@comcast.net>


On Sep 10, 2013, at 12:40 PM, Jonathan Greenberg wrote:

> R-helpers:
> 
> One of my intrepid students came up with a solution to a problem where
> they need to write a function that takes a vector x and a "scalar" d,
> and return the indices of the vector x where x %% d is equal to 0 (x
> is evenly divisible by d).  I thought I had a good handle on the
> potential solutions, but one of my students sent me a function that
> WORKS, but for the life of me I can't figure out WHY.  Here is the
> solution:
> 
> remainderFunction<-function(x,d)
> {
>   ifelse(x%%d==0,yes=return(which(x%%d==0)),no=return(NULL))
> }
> remainderFunction(x=c(23:47),d=3)
> 
> I've never seen an ifelse statement used that way, and I was fully
> expecting that to NOT work, or to place the output of which(x%%d==0)
> in each location where the statement x%%d==0 was true.

I think it did what you expected (at east your second expectation). Look at:

c(NULL, 1,2,3, NULL, 4,5,6, NULL)

# [1] 1 2 3 4 5 6

Obviously teh ifelse is not needed since this is cleaner code:

remainderFunction<-function(x,d)
{
   which(x%%d==0)
 }
 remainderFunction(x=c(23:47),d=3)
# [1]  2  5  8 11 14 17 20 23


-- 
David.
> 
> Any ideas on deconstructing this?
> 
> --j
> 
> -- 
> Jonathan A. Greenberg, PhD
> Assistant Professor
> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
> Department of Geography and Geographic Information Science
> University of Illinois at Urbana-Champaign
> 607 South Mathews Avenue, MC 150
> Urbana, IL 61801
> Phone: 217-300-1924
> http://www.geog.illinois.edu/~jgrn/
> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From hh132 at le.ac.uk  Tue Sep 10 23:01:09 2013
From: hh132 at le.ac.uk (Rose)
Date: Tue, 10 Sep 2013 14:01:09 -0700 (PDT)
Subject: [R] computationaly singular error!
Message-ID: <1378846869214-4675810.post@n4.nabble.com>

Hi there,

I am trying to estimate the mlogit model. but I get the following error.

Error in solve.default(H, g[!fixed]) : 
  system is computationally singular: reciprocal condition number =
4.65795e-19

I have googled it and found out the collinearity between independent
variables cause this error. when I use VIF to test the collinearity,
everything is fine i.e. result shows NO collinearity!

Does anyone have any idea about this error?

Thanks in advance.  



--
View this message in context: http://r.789695.n4.nabble.com/computationaly-singular-error-tp4675810.html
Sent from the R help mailing list archive at Nabble.com.


From lucagaegauf at gmx.ch  Wed Sep 11 03:01:01 2013
From: lucagaegauf at gmx.ch (lpupp)
Date: Tue, 10 Sep 2013 18:01:01 -0700 (PDT)
Subject: [R] Changing shapes of some Nodes
Message-ID: <1378861261307-4675831.post@n4.nabble.com>

Hi,

I am using the "igraph" package to plot a network. I need most of the
vertices to be green and circular. A few selected vertices I need to change
to make them blue squares.

I created this loop to color the necessary nodes blue but I dont know how to
change their shapes:

for(i in projectionV.node) {
	base.net.node <- set.vertex.attribute(base.net.node, name="color",
index=which(V(base.net)$name==i), value=blue.color)
}

help is much appreciated!



--
View this message in context: http://r.789695.n4.nabble.com/Changing-shapes-of-some-Nodes-tp4675831.html
Sent from the R help mailing list archive at Nabble.com.


From jim at bitwrit.com.au  Wed Sep 11 03:49:14 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 11 Sep 2013 11:49:14 +1000
Subject: [R] Problems to show X-labels when plotting small values
In-Reply-To: <CAH-FEngEUzrXbjw_LOm78aH03goS61+bTESnKj=h0fMT=49CQw@mail.gmail.com>
References: <CAH-FEngEUzrXbjw_LOm78aH03goS61+bTESnKj=h0fMT=49CQw@mail.gmail.com>
Message-ID: <522FCC1A.9070308@bitwrit.com.au>

On 09/11/2013 09:06 AM, Charles Novaes de Santana wrote:
> Dear all,
>
> I am following instructions of FAQ 7.2 (
> http://cran.r-project.org/doc/FAQ/R-FAQ.html#How-can-I-create-rotated-axis-labels_003f)
> to create rotated labels in my plots, but I am facing some problems when
> plotting variables with small values (in my case, values between 0.001 and
> 0.007).
>
> When I try to plot these small values, the X-label of my plot doesn't
> appear. Please find below the example I am trying to run:
>
> #Definition of my variable and of the labels
> a<-c(0.007,0.0004,0.0001)
> laba<-c("number1","number2","number3")
>
> #This plot doesn't work fine (label doesn't appear)
> par(mar = c(7, 4, 4, 2) + 0.1)
> plot(a,xaxt="n",xlab="",ylab="Y-Label")
> axis(1,labels=FALSE,tick=FALSE)
> mtext(1,text="X-Label",line=6)
> text(1:length(a), par("usr")[3] - 0.25, srt = 45, adj = 1,labels = a, xpd =
> TRUE,cex=0.75)
>
> #If I just multiply my variable, the plot works fine (label appears)
> par(mar = c(7, 4, 4, 2) + 0.1)
> plot(1000*a,xaxt="n",xlab="",ylab="Y-Label")
> axis(1,labels=FALSE,tick=FALSE)
> mtext(1,text="X-Label",line=6)
> text(1:length(a), par("usr")[3] - 0.25, srt = 45, adj = 1,labels = laba,
> xpd = TRUE,cex=0.75)
>
> Do you have any idea about why is it happening? I much appreciate any help!
>
Hi Charles,
The problem lies in your specification of the y values for the labels in 
the "text" call. Because you are subtracting a large value relative to 
the range of y values, the labels are displayed way off the bottom of 
the plot. Try this instead:

text(1:length(a),par("usr")[3]-0.0002,srt=45,adj=1,
  labels=a,xpd=TRUE,cex=0.75)

If you want to pass explicit values for the positions on the plot, check 
them against the x and y ranges.

Jim


From pentti.pirinen at fmi.fi  Wed Sep 11 06:54:10 2013
From: pentti.pirinen at fmi.fi (Pentti)
Date: Tue, 10 Sep 2013 21:54:10 -0700 (PDT)
Subject: [R] Daily average temperature from monthly average temperature
In-Reply-To: <1378799416500-4675752.post@n4.nabble.com>
References: <1378799416500-4675752.post@n4.nabble.com>
Message-ID: <1378875250686-4675836.post@n4.nabble.com>

Thank you very much for your help.

Here in Scandinavia the annual average temperature profile looks very much
like sin-function. So it's possible estimate the average daily values using
monthly average values. The future data is climate change scenario data. 

Regards Pentti  



--
View this message in context: http://r.789695.n4.nabble.com/Daily-average-temperature-from-monthly-average-temperature-tp4675752p4675836.html
Sent from the R help mailing list archive at Nabble.com.


From algerant at gmail.com  Wed Sep 11 07:53:22 2013
From: algerant at gmail.com (Bembi Prima)
Date: Wed, 11 Sep 2013 12:53:22 +0700
Subject: [R] RStudio Server init script
In-Reply-To: <CABdHhvEoouN70CkWExCXHL==35c9Rbhi5=7ousGeZFs8e2uy+A@mail.gmail.com>
References: <CAC5DFuAzNbB41T+28U34vHiOJ+Wn-eGNNHt5oW_0Af4ufs2D-A@mail.gmail.com>
	<CABdHhvEoouN70CkWExCXHL==35c9Rbhi5=7ousGeZFs8e2uy+A@mail.gmail.com>
Message-ID: <CAC5DFuBY9HmY1p3QMU-2=1h+hKcygxeJ0Dqpts2ggyRUV=m3sA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130911/e37475af/attachment.pl>

From ppalmes at yahoo.com  Wed Sep 11 09:04:11 2013
From: ppalmes at yahoo.com (Paulito Palmes)
Date: Wed, 11 Sep 2013 00:04:11 -0700 (PDT)
Subject: [R] Formula in a model
Message-ID: <1378883051.43820.YahooMailNeo@web125405.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130911/3ca22ee3/attachment.pl>

From elaine.kuo.tw at gmail.com  Wed Sep 11 09:38:38 2013
From: elaine.kuo.tw at gmail.com (Elaine Kuo)
Date: Wed, 11 Sep 2013 15:38:38 +0800
Subject: [R] to retrieve specific data from a matrix
Message-ID: <CAGJhoDz4F5w8ODWWzphjUK2HWfb6+96fyyP_ZR8WgBMMzd1=2Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130911/e8d7346e/attachment.pl>

From bhh at xs4all.nl  Wed Sep 11 09:50:58 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 11 Sep 2013 09:50:58 +0200
Subject: [R] to retrieve specific data from a matrix
In-Reply-To: <CAGJhoDz4F5w8ODWWzphjUK2HWfb6+96fyyP_ZR8WgBMMzd1=2Q@mail.gmail.com>
References: <CAGJhoDz4F5w8ODWWzphjUK2HWfb6+96fyyP_ZR8WgBMMzd1=2Q@mail.gmail.com>
Message-ID: <5AFE5CDA-6E9B-4D3E-9934-5CDBAC18DF5C@xs4all.nl>


On 11-09-2013, at 09:38, Elaine Kuo <elaine.kuo.tw at gmail.com> wrote:

> Dear list,
> 
> I want to retrieve a specific data from a matrix with 3000 columns.
> The matrix has island ID as its rows and species ID as its columns.
> There are 20 rows and 3000 columns in the matrix.
> (Island ID: Species 1- Species 20/ species ID: Species 1- Species 3000)
> The contents of the matrix grids is 1 or 0, for presence and absence.
> 
> Now I would like to check in Island 1 which species is 1. (Island 1 as row
> 2)
> Please kindly advise how to code the command and thank you in advance.

What have you tried?
Something like this perhaps

which(datamatrix[2,] == 1) or which(datamatrix[2,] == 1L)

Berend


From charles.santana at gmail.com  Wed Sep 11 09:59:15 2013
From: charles.santana at gmail.com (Charles Novaes de Santana)
Date: Wed, 11 Sep 2013 09:59:15 +0200
Subject: [R] Problems to show X-labels when plotting small values
In-Reply-To: <522FCC1A.9070308@bitwrit.com.au>
References: <CAH-FEngEUzrXbjw_LOm78aH03goS61+bTESnKj=h0fMT=49CQw@mail.gmail.com>
	<522FCC1A.9070308@bitwrit.com.au>
Message-ID: <CAH-FEngrkkznV_h=yiTkbuQgT=+uXpt08-omSeTzCxxMfkb0Hw@mail.gmail.com>

Um texto embutido e sem conjunto de caracteres especificado foi limpo...
Nome: n?o dispon?vel
Url: <https://stat.ethz.ch/pipermail/r-help/attachments/20130911/417980a9/attachment.pl>

From Gerrit.Eichner at math.uni-giessen.de  Wed Sep 11 11:48:18 2013
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Wed, 11 Sep 2013 11:48:18 +0200 (MEST)
Subject: [R] Formula in a model
In-Reply-To: <1378883051.43820.YahooMailNeo@web125405.mail.ne1.yahoo.com>
References: <1378883051.43820.YahooMailNeo@web125405.mail.ne1.yahoo.com>
Message-ID: <Pine.SOC.4.64.1309111142530.6509@solcom.hrz.uni-giessen.de>

Hello, Paulito,

first, I think you haven't received an answer yet because you did not 
"provide commented, minimal, self-contained, reproducible code" as the 
posting guide does request it from you.

Second, see inline below.

On Wed, 11 Sep 2013, Paulito Palmes wrote:

> Hi,
>
> I have a data.frame with dimension 336x336 called *training*, and 
> another one called *observation* which is 336x1. I combined them as one 
> table using table=data.frame(training, observation). table now has 
> 336x337 dimension with the last column as the observation to learn using 
> the training data of the rest of the column in the table. For 
> prediction, i combined the testing data and observation and pass it like 
> predict(model,testingWTesingObservation)
>
>
> I've used the formula: rpart(table[,337] ~ ., data=table) or 
> svm(table[,337] ~ ., data=table).

I am not familiar with rpart() nor with svm() but "table[,337] ~ ., data = 
table" has the consequence that table[,337] is also in the right hand side 
of the formula, so that your "observations" are also in the "training" 
data. That doesn't seem to make sense to me, and is different from the 
call to svm() below.

  Hth  --  Gerrit

> I recently discovered that this formulation produces different model 
> from the: svm(training, observation) formulation. Which is correct and 
> why one of them is not correct? I thought that syntactically, both are 
> the same. I hope that R should be able to detect the error in one of the 
> formulation to avoid the possibility of using it.
>
> Regards,
> Paul
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Wed Sep 11 12:02:31 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 11 Sep 2013 12:02:31 +0200
Subject: [R] assigning the class of an object
In-Reply-To: <522F93F0.8080802@xtra.co.nz>
References: <8AB18F255888194F82934830982C82C16FAADC92B4@UTHCMS1.uthouston.edu>
	<522F8767.7040504@xtra.co.nz>
	<0DDCDE22-601F-412C-BCB9-3CB5F9EA741E@gmail.com>
	<522F93F0.8080802@xtra.co.nz>
Message-ID: <7B7AAA9D-63EB-4023-BBCE-BDBB993A0313@gmail.com>


On Sep 10, 2013, at 23:49 , Rolf Turner wrote:
>> 
> Hmmm.  I did:
> 
> x <- 42
> save(x,file="Robject.RData")
> rm(list=ls())
> obj_name <- load("Robject.RData")
> class(get(obj_name)) <- "myClass"
> x
> 
> and got:
> 
> [1] 42
> attr(,"class")
> [1] "myClass"
> 
> (also got the familiar error message).
> 
> When I did it your way --- without the saving and loading bit --- I got
> the same result that you did.  I.e. assigning the class that way did *not*
> work (as one would expect it wouldn't!).
> 
> This is weird, n'est-ce pas?
> 

A bug, I'm pretty sure.

-p

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From Jose.Iparraguirre at ageuk.org.uk  Wed Sep 11 12:53:47 2013
From: Jose.Iparraguirre at ageuk.org.uk (Jose Iparraguirre)
Date: Wed, 11 Sep 2013 10:53:47 +0000
Subject: [R] Fitting Arima Model to Daily Time Series
In-Reply-To: <CAMOcQfPKLfpa9b79nbWi_C2ryAb4QrZJvsSuuO-aSuiumvBeyA@mail.gmail.com>
References: <CAMOcQfPKLfpa9b79nbWi_C2ryAb4QrZJvsSuuO-aSuiumvBeyA@mail.gmail.com>
Message-ID: <5F8EC5C77B9AE547A8959F690F04C7B2065545@AGEPXMB006.uk.age.local>

Hi Paul,

There are different packages in R to fit an ARIMA model. I would use the forecast package.
In your case, perhaps you would want to explore SARIMA models to include seasonal components? 
Anyhow, the first port of call could be the auto.arima() function to select the best fitting representation according to AIC, AICc or BIC -but explore other representations as well.
To fit the models use the function Arima (note the capital "A"). The documentation in the package is very clear and comprehensive; the authors (Rob J Hyndman and George Athanasopoulos) published a free on-line book which will also help you: http://otexts.com/fpp/.
Hope this helps,

Jos?


Prof. Jos? Iparraguirre
Chief Economist
Age UK



-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Paul Bernal
Sent: 10 September 2013 22:54
To: r-help at r-project.org
Subject: [R] Fitting Arima Model to Daily Time Series

Hello everyone,

Hope everyone is doing great. I would like to know how to use the arima function in R to fit arima or arma models to daily data, that is, with period = 365, this taking into account the fact that I have 5 years worth of daily data (so 365 * 5 = my number of observations).

All I want is a very general line of code of I I would do to fit the arima model.

Any help will be greatly appreciated,

Have a wonderful day,

Paul

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

The Wireless from Age UK | Radio for grown-ups.

www.ageuk.org.uk/thewireless


If you?re looking for a radio station that offers real variety, tune in to The Wireless from Age UK. 
Whether you choose to listen through the website at www.ageuk.org.uk/thewireless, on digital radio (currently available in London and Yorkshire) or through our TuneIn Radio app, you can look forward to an inspiring mix of music, conversation and useful information 24 hours a day.



 
-------------------------------
Age UK is a registered charity and company limited by guarantee, (registered charity number 1128267, registered company number 6825798). 
Registered office: Tavis House, 1-6 Tavistock Square, London WC1H 9NA.

For the purposes of promoting Age UK Insurance, Age UK is an Appointed Representative of Age UK Enterprises Limited, Age UK is an Introducer 
Appointed Representative of JLT Benefit Solutions Limited and Simplyhealth Access for the purposes of introducing potential annuity and health 
cash plans customers respectively.  Age UK Enterprises Limited, JLT Benefit Solutions Limited and Simplyhealth Access are all authorised and 
regulated by the Financial Services Authority. 
------------------------------

This email and any files transmitted with it are confidential and intended solely for the use of the individual or entity to whom they are 
addressed. If you receive a message in error, please advise the sender and delete immediately.

Except where this email is sent in the usual course of our business, any opinions expressed in this email are those of the author and do not 
necessarily reflect the opinions of Age UK or its subsidiaries and associated companies. Age UK monitors all e-mail transmissions passing 
through its network and may block or modify mails which are deemed to be unsuitable.

Age Concern England (charity number 261794) and Help the Aged (charity number 272786) and their trading and other associated companies merged 
on 1st April 2009.  Together they have formed the Age UK Group, dedicated to improving the lives of people in later life.  The three national 
Age Concerns in Scotland, Northern Ireland and Wales have also merged with Help the Aged in these nations to form three registered charities: 
Age Scotland, Age NI, Age Cymru.





From pdalgd at gmail.com  Wed Sep 11 13:04:00 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 11 Sep 2013 13:04:00 +0200
Subject: [R] RStudio Server init script
In-Reply-To: <CAC5DFuBY9HmY1p3QMU-2=1h+hKcygxeJ0Dqpts2ggyRUV=m3sA@mail.gmail.com>
References: <CAC5DFuAzNbB41T+28U34vHiOJ+Wn-eGNNHt5oW_0Af4ufs2D-A@mail.gmail.com>
	<CABdHhvEoouN70CkWExCXHL==35c9Rbhi5=7ousGeZFs8e2uy+A@mail.gmail.com>
	<CAC5DFuBY9HmY1p3QMU-2=1h+hKcygxeJ0Dqpts2ggyRUV=m3sA@mail.gmail.com>
Message-ID: <6CC701C5-55B9-4BBF-A771-233BE45442FC@gmail.com>


On Sep 11, 2013, at 07:53 , Bembi Prima wrote:

> I have seen ?Startup and already update .RProfile in home folder, but as I
> already said it just affected user's Rprofile, not the global one.

So you didn't read the parts about Rprofile.site?

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From villarino.ernesto at gmail.com  Wed Sep 11 10:23:14 2013
From: villarino.ernesto at gmail.com (ernesto villarino)
Date: Wed, 11 Sep 2013 01:23:14 -0700 (PDT)
Subject: [R] include variable of a dataframe in other dataframe
In-Reply-To: <1378874103815-4675835.post@n4.nabble.com>
References: <1378764737354-4675730.post@n4.nabble.com>
	<1378874103815-4675835.post@n4.nabble.com>
Message-ID: <CAAmrVFqkq4n63vqp0ZK3FRJXB3hSinRN7atA8wngNpcGSZm=eQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130911/9da5d405/attachment.pl>

From robert.b.lynch at gmail.com  Wed Sep 11 10:06:30 2013
From: robert.b.lynch at gmail.com (Robert Lynch)
Date: Wed, 11 Sep 2013 01:06:30 -0700
Subject: [R] ggplot interactions
In-Reply-To: <CACYeG1gfjwh5TsiLNViVchQK7OY7-2c7AHNQdzcDraD2i8NuqQ@mail.gmail.com>
References: <CACYeG1gfjwh5TsiLNViVchQK7OY7-2c7AHNQdzcDraD2i8NuqQ@mail.gmail.com>
Message-ID: <CACYeG1ga3QH4w30RWRbn=wu07Q4gKHosiU3AoFNPfFAY6Wmecw@mail.gmail.com>

On Tue, Sep 10, 2013 at 11:33 PM, Robert Lynch <robert.b.lynch at gmail.com>wrote:

> I am sorry to ask what I am sure is a simple question but I am stuck
> trying to figure out how different parts of ggplot2 calls interact
>
> I am plotting using the following code
>
> ggplot(Chem.comp, aes(Course, GRADE)) + geom_boxplot(notch = TRUE,aes(fill
> = COHORT))+
>   labs(y ="Grade Points in class",
>        x = "Chemistry 2 quarter") +
>   ggtitle(expression(atop("Comparison between ISE cohorts and Peers",
> atop(italic("in Chem 2 classes"), ""))))
>   ylim(0,4.3333)+
>   scale_fill_manual(name = "ISE Cohorts &\nComparison groups",
>                     values =
> c("blue","red","blue3","red3","blue4","red4")) +
>   theme(plot.title = element_text(size = 25, face = "bold", colour =
> "black", vjust = -1))+
>   guides(fill = guide_legend(nrow = 3),byrow = TRUE)
>
> which give Rplot.jpeg  which is has the appropriate title, but the colors
> and the wrong are wrong.
>
> if I comment out the ggtitle() and theme(), or just ggtitle() I get
> Rplot01.jpeg which has the right colors but no title and subtitle.  Also
> the legend is out of order.  the first row should read ISE07 CMP07 with 08
> on the second row and 09 the third with a red column and a blue column.
>  Changing byrow = TRUE to bycol = TRUE does not change the plotting of the
> legend nor does byrow=FALSE
>
> I am asking for help with getting the title and sub-title to both show up
> at the same time as the appropriate colors for the different factor levels.
> And to get the legend to render so that the legend looks sort of like
> ISE07  [redbox  ] [bluebox  ] CMP07
> ISE08  [red3box][blue3box]  CMP08
> ISE09  [red4box] [blue4box] CMP09
>
> the exact colors are not important the the vertical
> and horizontal alignment is.
>
> Thanks!
> Robert
>

From M.Rosario.Garcia at slu.se  Wed Sep 11 12:20:45 2013
From: M.Rosario.Garcia at slu.se (Rosario Garcia Gil)
Date: Wed, 11 Sep 2013 10:20:45 +0000
Subject: [R] resample from data frame: unlinked columns
Message-ID: <A1C4DF829DB4AE45BF8447F83C7EAFFE0850FACF@exchange2-3>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130911/01ac8ccb/attachment.pl>

From eddieatr at gmail.com  Wed Sep 11 14:02:15 2013
From: eddieatr at gmail.com (Eddie Smith)
Date: Wed, 11 Sep 2013 13:02:15 +0100
Subject: [R] Imputation for space-time satellite data
Message-ID: <CABaJH79rAZ9dw=XSSFhVEa6_7nZ+fV8db0HPVHm-HSjuXA3dfg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130911/2b46cc3b/attachment.pl>

From petr.pikal at precheza.cz  Wed Sep 11 14:33:35 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 11 Sep 2013 12:33:35 +0000
Subject: [R] resample from data frame: unlinked columns
In-Reply-To: <A1C4DF829DB4AE45BF8447F83C7EAFFE0850FACF@exchange2-3>
References: <A1C4DF829DB4AE45BF8447F83C7EAFFE0850FACF@exchange2-3>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B915CD@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Rosario Garcia Gil
> Sent: Wednesday, September 11, 2013 12:21 PM
> To: r-help at r-project.org
> Subject: [R] resample from data frame: unlinked columns
> 
> Hello
> 
> I am trying to resample from this data set (see below). The function I
> am using so far is doing it by considering A and B columns as linked. I
> used this function.
> 
> >NUCh_rep<-
> replicate(500,data[sample(1:nrow(data),replace=T),],simplify=F)

Sample rows 1000 times and use two parts of this index

ind<-sample(1:nrow(data), 1000, replace=TRUE)

data[ind[1:500], "A"]
data[ind[501:1000], "B"]

You can organize it to data frame or matrix e.g.

result <- cbind(data[ind[1:500], "A"], data[ind[501:1000], "B"])

Regards
Petr

> 
> What I need is to resample (500 times) with replacement but considering
> A and B columns UNLINKED. Any advice it is most appreciated. Thanks.
> 
>              A           B
> 5          257       259
> 10         257       259
> 10.1       257       259
> 4          257       259
> 9          257       259
> 2          257       259
> 8          257       259
> 1          257       259
> 8.1        257       259
> 8.2        257       259
> 7          255       257
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Wed Sep 11 14:35:10 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 11 Sep 2013 05:35:10 -0700 (PDT)
Subject: [R] to retrieve specific data from a matrix
In-Reply-To: <CAGJhoDz4F5w8ODWWzphjUK2HWfb6+96fyyP_ZR8WgBMMzd1=2Q@mail.gmail.com>
References: <CAGJhoDz4F5w8ODWWzphjUK2HWfb6+96fyyP_ZR8WgBMMzd1=2Q@mail.gmail.com>
Message-ID: <1378902910.44046.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
set.seed(24)
mat1<- matrix(sample(0:1,20*100,replace=TRUE),ncol=100,dimnames=list(paste0("Species",1:20),paste0("Species",1:100)))
?which(mat1[1,]==1)
#or
which(!is.na(match(mat1[1,],1)))
A.K.




----- Original Message -----
From: Elaine Kuo <elaine.kuo.tw at gmail.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Wednesday, September 11, 2013 3:38 AM
Subject: [R] to retrieve specific data from a matrix

Dear list,

I want to retrieve a specific data from a matrix with 3000 columns.
The matrix has island ID as its rows and species ID as its columns.
There are 20 rows and 3000 columns in the matrix.
(Island ID: Species 1- Species 20/ species ID: Species 1- Species 3000)
The contents of the matrix grids is 1 or 0, for presence and absence.

Now I would like to check in Island 1 which species is 1. (Island 1 as row
2)
Please kindly advise how to code the command and thank you in advance.

Elaine

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From petr.pikal at precheza.cz  Wed Sep 11 14:50:30 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 11 Sep 2013 12:50:30 +0000
Subject: [R] superpose violin and boxplot in ggplot
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B915FE@SRVEXCHMBX.precheza.cz>

Dear all

I am struggling a bit with tricky violinplot. I found how to superpose boxplots correctly to violinplots.

p<-ggplot(Cars93, aes(x=Origin, y=Price, fill=Type, colour=Type))
p+geom_violin()+ geom_boxplot(aes(fill=NULL), position=position_dodge(width=.9), width=.3)

but if I wanted to change the boxplot to black colour I am lost

p+geom_violin()+ geom_boxplot(aes(fill=NULL), position=position_dodge(width=.9), width=.5, colour="black")

How I could change colour of boxplots to single colour but get the boxes at the correct locations e.g. over violins.

Thanks
Petr


From tcmuigai at gmail.com  Wed Sep 11 15:01:32 2013
From: tcmuigai at gmail.com (Charles Thuo)
Date: Wed, 11 Sep 2013 16:01:32 +0300
Subject: [R] how to read data from MSExcel into R
Message-ID: <CAAJc=rMEbWGiNGKrGt1B2m8kGdN=794ZNH+YG-N9LR7F8_ZE9Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130911/1b80ffb3/attachment.pl>

From smartpink111 at yahoo.com  Wed Sep 11 15:04:31 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 11 Sep 2013 06:04:31 -0700 (PDT)
Subject: [R] resample from data frame: unlinked columns
In-Reply-To: <A1C4DF829DB4AE45BF8447F83C7EAFFE0850FACF@exchange2-3>
References: <A1C4DF829DB4AE45BF8447F83C7EAFFE0850FACF@exchange2-3>
Message-ID: <1378904671.79911.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
Using ur code:

dat1<- read.table(text="A????????? B
5????????? 257????? 259
10??????? 257????? 259
10.1????? 257????? 259
4????????? 257????? 259
9????????? 257????? 259
2????????? 257????? 259
8????????? 257????? 259
1????????? 257????? 259
8.1??????? 257????? 259
8.2??????? 257????? 259
7????????? 255????? 257",sep="",header=TRUE)


set.seed(49)
?res<-sapply(dat1,function(x) as.vector(replicate(500,x[sample(seq_along(x),length(x),replace=TRUE)])))
?dim(res)
#[1] 5500??? 2

A.K.

----- Original Message -----
From: Rosario Garcia Gil <M.Rosario.Garcia at slu.se>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Wednesday, September 11, 2013 6:20 AM
Subject: [R] resample from data frame: unlinked columns

Hello

I am trying to resample from this data set (see below). The function I am using so far is doing it by considering A and B columns as linked. I used this function.

>NUCh_rep<-replicate(500,data[sample(1:nrow(data),replace=T),],simplify=F)

What I need is to resample (500 times) with replacement but considering A and B columns UNLINKED. Any advice it is most appreciated. Thanks.

? ? ? ? ? ?  A? ? ? ? ?  B
5? ? ? ? ? 257? ? ?  259
10? ? ? ?  257? ? ?  259
10.1? ? ?  257? ? ?  259
4? ? ? ? ? 257? ? ?  259
9? ? ? ? ? 257? ? ?  259
2? ? ? ? ? 257? ? ?  259
8? ? ? ? ? 257? ? ?  259
1? ? ? ? ? 257? ? ?  259
8.1? ? ? ? 257? ? ?  259
8.2? ? ? ? 257? ? ?  259
7? ? ? ? ? 255? ? ?  257


??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From deter088 at umn.edu  Wed Sep 11 15:06:43 2013
From: deter088 at umn.edu (Charles Determan Jr)
Date: Wed, 11 Sep 2013 08:06:43 -0500
Subject: [R] how to read data from MSExcel into R
In-Reply-To: <CAAJc=rMEbWGiNGKrGt1B2m8kGdN=794ZNH+YG-N9LR7F8_ZE9Q@mail.gmail.com>
References: <CAAJc=rMEbWGiNGKrGt1B2m8kGdN=794ZNH+YG-N9LR7F8_ZE9Q@mail.gmail.com>
Message-ID: <CAOLJph=akEZFOswyb+u-jX0+n0Y2Q-Y9wanr915Y6DXEwZk6Tg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130911/57926fc4/attachment.pl>

From muenchen at utk.edu  Wed Sep 11 15:16:20 2013
From: muenchen at utk.edu (Muenchen, Robert A (Bob))
Date: Wed, 11 Sep 2013 13:16:20 +0000
Subject: [R] R Online Workshops October 7-11
Message-ID: <81D92650D162664791CB7C482A8784124D13E6AD@kmbx1.utk.tennessee.edu>

Learn R and/or data mangement at home October 7 through 11 

http://r4stats.com/2013/09/11/learn-r-andor-data-management-from-home-october-7-11/

==================================================
  Bob Muenchen (pronounced Min'-chen)
  Accredited Professional Statistician(tm)   
  Manager, Research Computing Support
  Voice: (865) 974-5230  
  Email: muenchen at utk.edu
  UT Web Site:       http://oit.utk.edu/research
  Personal Web Site: http://r4stats.com 
  News:  http://itc2.utk.edu/newsletter_monthly/
==================================================


From tcmuigai at gmail.com  Wed Sep 11 15:21:46 2013
From: tcmuigai at gmail.com (Charles Thuo)
Date: Wed, 11 Sep 2013 16:21:46 +0300
Subject: [R] how to convert a list into a data frame.
Message-ID: <CAAJc=rM4vGSXEzBpbpD9VvYkKKWQk9quRutiM7pYTLJ_HG+kRw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130911/000dc27c/attachment.pl>

From petr.pikal at precheza.cz  Wed Sep 11 15:27:06 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 11 Sep 2013 13:27:06 +0000
Subject: [R] how to convert a list into a data frame.
In-Reply-To: <CAAJc=rM4vGSXEzBpbpD9VvYkKKWQk9quRutiM7pYTLJ_HG+kRw@mail.gmail.com>
References: <CAAJc=rM4vGSXEzBpbpD9VvYkKKWQk9quRutiM7pYTLJ_HG+kRw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B91649@SRVEXCHMBX.precheza.cz>

How did you read it? Normally data from Excel are in data.frame

Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Charles Thuo
> Sent: Wednesday, September 11, 2013 3:22 PM
> To: r-help at r-project.org
> Subject: [R] how to convert a list into a data frame.
> 
> After reading a data set from excel into R it is of the type list. How
> can such a list be converted into a data frame so as to attach the
> columns.
> 
> Charles.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bbolker at gmail.com  Wed Sep 11 15:45:55 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 11 Sep 2013 13:45:55 +0000
Subject: [R] superpose violin and boxplot in ggplot
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B915FE@SRVEXCHMBX.precheza.cz>
Message-ID: <loom.20130911T154501-883@post.gmane.org>

PIKAL Petr <petr.pikal <at> precheza.cz> writes:

> 
> Dear all
> 
> I am struggling a bit with tricky violinplot. I found how to superpose
boxplots correctly to violinplots.
> 
> p<-ggplot(Cars93, aes(x=Origin, y=Price, fill=Type, colour=Type))

 [snip]
> 
> How I could change colour of boxplots to single colour 
> but get the boxes at the correct locations e.g. over violins.
> 
> Thanks
> Petr
> 
> 

Use the group() aesthetic:

p+geom_violin()+ geom_boxplot(aes(fill=NULL,group=interaction(Type,Origin)),
   position=position_dodge(width=.9), width=.5, colour="black")

By the way, it would be useful to remind us that Cars93 is available in
the MASS package -- I had to hunt around a little bit.


From dimitri.liakhovitski at gmail.com  Wed Sep 11 15:59:03 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Wed, 11 Sep 2013 09:59:03 -0400
Subject: [R] Shiny error: connection reset by peer
Message-ID: <CAN2xGJZCBjxSQqo5ft-+hKzRjF=tzHz3M66QYDDUq6pMFycERw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130911/0bce356c/attachment.pl>

From petr.pikal at precheza.cz  Wed Sep 11 16:02:36 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 11 Sep 2013 14:02:36 +0000
Subject: [R] superpose violin and boxplot in ggplot
In-Reply-To: <loom.20130911T154501-883@post.gmane.org>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B915FE@SRVEXCHMBX.precheza.cz>
	<loom.20130911T154501-883@post.gmane.org>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B916AF@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Ben Bolker
> Sent: Wednesday, September 11, 2013 3:46 PM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] superpose violin and boxplot in ggplot
> 
> PIKAL Petr <petr.pikal <at> precheza.cz> writes:
> 
> >
> > Dear all
> >
> > I am struggling a bit with tricky violinplot. I found how to
> superpose
> boxplots correctly to violinplots.
> >
> > p<-ggplot(Cars93, aes(x=Origin, y=Price, fill=Type, colour=Type))
> 
>  [snip]
> >
> > How I could change colour of boxplots to single colour but get the
> > boxes at the correct locations e.g. over violins.
> >
> > Thanks
> > Petr
> >
> >
> 
> Use the group() aesthetic:
> 
> p+geom_violin()+
> p+geom_boxplot(aes(fill=NULL,group=interaction(Type,Origin)),
>    position=position_dodge(width=.9), width=.5, colour="black")

Thanks. In the meantime I found another solution using scale_colour_manual.

p+geom_violin()+geom_boxplot(aes(fill=NULL),
position=position_dodge(width=.9), width=.5)+scale_colour_manual(values=rep("black", 6))

Your solution seems to be better as the legend looks slightly better.

> 
> By the way, it would be useful to remind us that Cars93 is available in
> the MASS package -- I had to hunt around a little bit.

Sorry for that. I forgot to add it to my question together with ggplot2 package.

Regards
Petr



> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Wed Sep 11 16:03:11 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 11 Sep 2013 07:03:11 -0700
Subject: [R] how to convert a list into a data frame.
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B91649@SRVEXCHMBX.precheza.cz>
References: <CAAJc=rM4vGSXEzBpbpD9VvYkKKWQk9quRutiM7pYTLJ_HG+kRw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B91649@SRVEXCHMBX.precheza.cz>
Message-ID: <2b9a068a-3ed2-45fc-953c-9dd90a1c6643@email.android.com>

But a data.frame is a special type of list, so you could both be right. The best way to communicate clearly about these questions is to provide reproducible example R code.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

PIKAL Petr <petr.pikal at precheza.cz> wrote:
>How did you read it? Normally data from Excel are in data.frame
>
>Petr
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Charles Thuo
>> Sent: Wednesday, September 11, 2013 3:22 PM
>> To: r-help at r-project.org
>> Subject: [R] how to convert a list into a data frame.
>> 
>> After reading a data set from excel into R it is of the type list.
>How
>> can such a list be converted into a data frame so as to attach the
>> columns.
>> 
>> Charles.
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From sue at xlsolutions-corp.com  Wed Sep 11 16:11:16 2013
From: sue at xlsolutions-corp.com (Sue Turner)
Date: Wed, 11 Sep 2013 07:11:16 -0700
Subject: [R] R/S-PLUS Course schedule in US - XLSolutions Corp
Message-ID: <20130911071116.aa8924c5d28ca71e2a043bb294e795eb.e713063a85.wbe@email04.secureserver.net>

XLSolutions is working our October-November-December course schedule and
now seeking your input for your prefered location and courses.

September 2013 R/S-PLUS courses are available online
http://www.xlsolutions-corp.com/courselistlisting.aspx
 
(1) R-PLUS: A Point-and-Click Approach to R
(2) S-PLUS / R : Programming Essentials.
(3) R/S+ Fundamentals and Programming Techniques
(4) R/S-PLUS Functions by Example.
(5) S/R-PLUS Programming 3: Advanced Techniques and Efficiencies.
(6) R/S+ System: Advanced Programming.
(7) R/S-PLUS Graphics: Essentials.
(8) R/S-PLUS Graphics for SAS Users
(9) R/S-PLUS Graphical Techniques for Marketing Research.
(10) Multivariate Statistical Methods in R/S-PLUS: Practical Research
Applications
(11) Introduction to Applied Econometrics with R/S-PLUS
(12) Exploratory Analysis for Large and Complex Problems in R/S-PLUS
(13) Determining Power and Sample Size Using R/S-PLUS.
(14) R/S-PLUS: Data Preparation for Data Mining
(15) Data Cleaning Techniques in R/S-PLUS
(16) R/S-PLUS: Applied Clustering Techniques


More on website

http://www.xlsolutions-corp.com/courselistlisting.aspx

Ask for group discount and reserve your seat Now - Earlybird Rates.
Payment due after the class! Email Sue Turner: sue at
xlsolutions-corp.com

Phone: 206-686-1578


Please let us know if you and your colleagues are interested in this
class to take advantage of group discount. Register now to secure your
seat.

Cheers,
Elvis Miller, PhD
Manager Training.
XLSolutions Corporation
206 686 1578
www.xlsolutions-corp.com
elvis at xlsolutions-corp.com


From istazahn at gmail.com  Wed Sep 11 16:14:40 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 11 Sep 2013 10:14:40 -0400
Subject: [R] how to read data from MSExcel into R
In-Reply-To: <CAAJc=rMEbWGiNGKrGt1B2m8kGdN=794ZNH+YG-N9LR7F8_ZE9Q@mail.gmail.com>
References: <CAAJc=rMEbWGiNGKrGt1B2m8kGdN=794ZNH+YG-N9LR7F8_ZE9Q@mail.gmail.com>
Message-ID: <CA+vqiLH=j8crd07Ro8EY_1qJ5XrdJnuPp0fYPQztK1Y2naejDA@mail.gmail.com>

I don't think you need admin rights to install R packages. Did you try it?

Best,
Ista

On Wed, Sep 11, 2013 at 9:01 AM, Charles Thuo <tcmuigai at gmail.com> wrote:
> how can one read data from MSEXcel into R especially in a case where one
> does not have administrator rights to install additional packages. In short
> how to read data from MSExcel into R with base packages only.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Wed Sep 11 16:15:37 2013
From: rmh at temple.edu (Rmh)
Date: Wed, 11 Sep 2013 10:15:37 -0400
Subject: [R] Shiny error: connection reset by peer
In-Reply-To: <CAN2xGJZCBjxSQqo5ft-+hKzRjF=tzHz3M66QYDDUq6pMFycERw@mail.gmail.com>
References: <CAN2xGJZCBjxSQqo5ft-+hKzRjF=tzHz3M66QYDDUq6pMFycERw@mail.gmail.com>
Message-ID: <FE3568B8-0C25-45DA-AD4F-631880933E40@temple.edu>

shiny uses browser features that internet explorer doesn't have.

use either firefox or chrome.
enter
http://localhost:8100

to quit shiny, enter the escspe key in the R gui

Sent from my iPhone

On Sep 11, 2013, at 9:59, Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com> wrote:

> Hello!
> 
> I am learning Shiny via tutorial (
> http://rstudio.github.io/shiny/tutorial/#hello-shiny)
> 
> I am trying to recreate the first 2 lines:
> 
> library(shiny)
> runExample("01_hello")
> 
> 
> An IE window opens - it has the slider but does not have the histogram.
> And my R is stuck. I am seeing the following at the prompt:
> 
> Listening on port 8100
> ERROR: [uv_write] connection reset by peer
> ERROR: [on_request_read] connection reset by peer
> ERROR: [on_request_read] connection reset by peer
> ERROR: [on_request_read] connection reset by peer
> ERROR: [on_request_read] connection reset by peer
> 
> 
> In order to stop it I have to hit Escape. The same thing happens in R gui
> and in R studio.
> Any advice on what settings I should ask our IT to change in order for it
> to work?
> 
> Thank you very much!
> 
> -- 
> Dimitri Liakhovitski
> 
>   [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Wed Sep 11 16:17:37 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 11 Sep 2013 07:17:37 -0700
Subject: [R] how to read data from MSExcel into R
In-Reply-To: <CAOLJph=akEZFOswyb+u-jX0+n0Y2Q-Y9wanr915Y6DXEwZk6Tg@mail.gmail.com>
References: <CAAJc=rMEbWGiNGKrGt1B2m8kGdN=794ZNH+YG-N9LR7F8_ZE9Q@mail.gmail.com>
	<CAOLJph=akEZFOswyb+u-jX0+n0Y2Q-Y9wanr915Y6DXEwZk6Tg@mail.gmail.com>
Message-ID: <06c9820c-6aa5-4ad8-b295-a4d1a413a6b7@email.android.com>

The assertion that you need administrator privileges to install packages is false. You can install them into a directory under your Documents directory for your own use. You only need a administrator privileges to modify the packages located in the software installation directory.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Charles Determan Jr <deter088 at umn.edu> wrote:
>If there isn't multiple sheets you can use the 'gdata' package and
>read.xls().
>
>Otherwise you could re-save the file as a csv file and load that file
>with
>read.csv() assuming not multiple sheets again which a csv cannot
>contain.
>
>Regards,
>Charles
>
>
>On Wed, Sep 11, 2013 at 8:01 AM, Charles Thuo <tcmuigai at gmail.com>
>wrote:
>
>> how can one read data from MSEXcel into R especially in a case where
>one
>> does not have administrator rights to install additional packages. In
>short
>> how to read data from MSExcel into R with base packages only.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From petr.pikal at precheza.cz  Wed Sep 11 16:17:59 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 11 Sep 2013 14:17:59 +0000
Subject: [R] how to convert a list into a data frame.
In-Reply-To: <2b9a068a-3ed2-45fc-953c-9dd90a1c6643@email.android.com>
References: <CAAJc=rM4vGSXEzBpbpD9VvYkKKWQk9quRutiM7pYTLJ_HG+kRw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B91649@SRVEXCHMBX.precheza.cz>
	<2b9a068a-3ed2-45fc-953c-9dd90a1c6643@email.android.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B916DF@SRVEXCHMBX.precheza.cz>

Well as the original poster asks specifically how to convert imported list to data frame I assumed, maybe wrongly, that he/she knows R objects and by some tricky conversion managed to stuff Excel data to real list (class list) and not data.frame (class data frame).

But you are correct. Code, at least str(object) and detailed description of intention is vital here.

Petr


> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.CA.us]
> Sent: Wednesday, September 11, 2013 4:03 PM
> To: PIKAL Petr; Charles Thuo; r-help at r-project.org
> Subject: Re: [R] how to convert a list into a data frame.
> 
> But a data.frame is a special type of list, so you could both be right.
> The best way to communicate clearly about these questions is to provide
> reproducible example R code.
> -----------------------------------------------------------------------
> ----
> Jeff Newmiller                        The     .....       .....  Go
> Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..
> Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> -----------------------------------------------------------------------
> ----
> Sent from my phone. Please excuse my brevity.
> 
> PIKAL Petr <petr.pikal at precheza.cz> wrote:
> >How did you read it? Normally data from Excel are in data.frame
> >
> >Petr
> >
> >
> >> -----Original Message-----
> >> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> >> project.org] On Behalf Of Charles Thuo
> >> Sent: Wednesday, September 11, 2013 3:22 PM
> >> To: r-help at r-project.org
> >> Subject: [R] how to convert a list into a data frame.
> >>
> >> After reading a data set from excel into R it is of the type list.
> >How
> >> can such a list be converted into a data frame so as to attach the
> >> columns.
> >>
> >> Charles.
> >>
> >> 	[[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html and provide commented, minimal, self-contained,
> >> reproducible code.
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.


From dimitri.liakhovitski at gmail.com  Wed Sep 11 16:18:31 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Wed, 11 Sep 2013 10:18:31 -0400
Subject: [R] Shiny error: connection reset by peer
In-Reply-To: <FE3568B8-0C25-45DA-AD4F-631880933E40@temple.edu>
References: <CAN2xGJZCBjxSQqo5ft-+hKzRjF=tzHz3M66QYDDUq6pMFycERw@mail.gmail.com>
	<FE3568B8-0C25-45DA-AD4F-631880933E40@temple.edu>
Message-ID: <CAN2xGJb4f2aW17_2Qz-C551wEzK8jCm5pbHFVimpe0A2F=1aFg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130911/32e3d3e6/attachment.pl>

From eliza_botto at hotmail.com  Wed Sep 11 16:22:37 2013
From: eliza_botto at hotmail.com (eliza botto)
Date: Wed, 11 Sep 2013 14:22:37 +0000
Subject: [R] list to matrix
Message-ID: <BLU170-W121FB55A13AFCB7E7F111AE89390@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130911/2e122ec7/attachment.pl>

From ggrothendieck at gmail.com  Wed Sep 11 16:24:58 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 11 Sep 2013 10:24:58 -0400
Subject: [R] how to read data from MSExcel into R
In-Reply-To: <CAOLJph=akEZFOswyb+u-jX0+n0Y2Q-Y9wanr915Y6DXEwZk6Tg@mail.gmail.com>
References: <CAAJc=rMEbWGiNGKrGt1B2m8kGdN=794ZNH+YG-N9LR7F8_ZE9Q@mail.gmail.com>
	<CAOLJph=akEZFOswyb+u-jX0+n0Y2Q-Y9wanr915Y6DXEwZk6Tg@mail.gmail.com>
Message-ID: <CAP01uR=CSe147QRAQBE4WQSa3xkQvTZGPEg8ErV33OVyy81NhA@mail.gmail.com>

On Wed, Sep 11, 2013 at 9:06 AM, Charles Determan Jr <deter088 at umn.edu> wrote:
> If there isn't multiple sheets you can use the 'gdata' package and
> read.xls().
>
> Otherwise you could re-save the file as a csv file and load that file with
> read.csv() assuming not multiple sheets again which a csv cannot contain.
>

read.xls in gdata does support multiple sheets via the sheet= argument
as well as the sheetCount and sheetNames helper functions.

   fn <- "abc.xlsx"
   nms <- sheetNames(fn)
   lapply(nms, read.xls, xls = fn)



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From ppalmes at yahoo.com  Wed Sep 11 16:26:54 2013
From: ppalmes at yahoo.com (Paulito Palmes)
Date: Wed, 11 Sep 2013 07:26:54 -0700 (PDT)
Subject: [R] Formula in a model
In-Reply-To: <Pine.SOC.4.64.1309111142530.6509@solcom.hrz.uni-giessen.de>
References: <1378883051.43820.YahooMailNeo@web125405.mail.ne1.yahoo.com>
	<Pine.SOC.4.64.1309111142530.6509@solcom.hrz.uni-giessen.de> 
Message-ID: <1378909614.12435.YahooMailNeo@web125404.mail.ne1.yahoo.com>



Hello Gerrit, 

Thanks for the explanation. Let me give a specific example.

Assume Temp (column 4) is the output and the rest of the columns are input is the training features. Note that I only use the air quality data for illustration purpose. T input->output mapping may not make sense in the real interpretation of this data.

library(e1071)

data(airquality)
mytable=airquality

colnames(mytable)=c('a','b','c','d','e','f')


modelSVM1=svm(mytable[,6] ~ .,data=mytable)
modelSVM2=svm(mytable[,-6],mytable[,6])
modelSVM3=svm(f ~ ., data=mytable)

predSVM1=predict(modelSVM1,newdata=mytable)
predSVM2=predict(modelSVM2,newdata=mytable[,-6])
predSVM3=predict(modelSVM3,newdata=mytable)

Results of predSVM2 is similar with predSVM3 ?but different from?predSVM1.

Question: Which is the correct formulation? Why R doesn't detect error/discrepancy in formulation?


If I use the same formulation with rpart using the same data:

library(rpart)

data(airquality)
mytable=airquality

colnames(mytable)=c('a','b','c','d','e','f')

modelRP1=rpart(mytable[,6]~.,data=mytable,method='anova') # this works
modelRP3=rpart(f ~ ., data=mytable,method='anova') # this works

predRP1=predict(modelRP1,newdata=mytable)
predRP3=predict(modelRP3,newdata=mytable)



The results between predRP1 and predRP3 are different while the statements:

predRP2=predict(modelRP2,newdata=mytable[,-6])
modelRP2=rpart(mytable[,-6],mytable[,6],method='anova')?


have errors.



_____________________
From: Gerrit Eichner <Gerrit.Eichner at math.uni-giessen.de>
To: Paulito Palmes <ppalmes at yahoo.com> 
Cc: "r-help at r-project.org" <r-help at r-project.org> 
Sent: Wednesday, 11 September 2013, 10:48
Subject: Re: [R] Formula in a model


Hello, Paulito,

first, I think you haven't received an answer yet because you did not 
"provide commented, minimal, self-contained, reproducible code" as the 
posting guide does request it from you.

Second, see inline below.

On Wed, 11 Sep 2013, Paulito Palmes wrote:

> Hi,
>
> I have a data.frame with dimension 336x336 called *training*, and 
> another one called *observation* which is 336x1. I combined them as one 
> table using table=data.frame(training, observation). table now has 
> 336x337 dimension with the last column as the observation to learn using 
> the training data of the rest of the column in the table. For 
> prediction, i combined the testing data and observation and pass it like 
> predict(model,testingWTesingObservation)
>
>
> I've used the formula: rpart(table[,337] ~ ., data=table) or 
> svm(table[,337] ~ ., data=table).

I am not familiar with rpart() nor with svm() but "table[,337] ~ ., data = 
table" has the consequence that table[,337] is also in the right hand side 
of the formula, so that your "observations" are also in the "training" 
data. That doesn't seem to make sense to me, and is different from the 
call to svm() below.

? Hth? --? Gerrit

> I recently discovered that this formulation produces different model 
> from the: svm(training, observation) formulation. Which is correct and 
> why one of them is not correct? I thought that syntactically, both are 
> the same. I hope that R should be able to detect the error in one of the 
> formulation to avoid the possibility of using it.
>
> Regards,
> Paul
> ??? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From paulbernal07 at gmail.com  Wed Sep 11 16:41:04 2013
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Wed, 11 Sep 2013 09:41:04 -0500
Subject: [R] Fitting Arima Model to Daily Time Series
In-Reply-To: <5F8EC5C77B9AE547A8959F690F04C7B2065545@AGEPXMB006.uk.age.local>
References: <CAMOcQfPKLfpa9b79nbWi_C2ryAb4QrZJvsSuuO-aSuiumvBeyA@mail.gmail.com>
	<5F8EC5C77B9AE547A8959F690F04C7B2065545@AGEPXMB006.uk.age.local>
Message-ID: <CAMOcQfMU70FzSH6SoP2z+a8r9gZKMY79pQno6u6-nbtOKkXuCw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130911/f523a14d/attachment.pl>

From macqueen1 at llnl.gov  Wed Sep 11 16:42:13 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 11 Sep 2013 14:42:13 +0000
Subject: [R] windowing
In-Reply-To: <624EC9773CAB044ABA65327271BED9B601C3FF@CBMCC-X10-MA01.ad.cibc.com>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521910D437047@PRDEXMBX-08.the-lab.llnl.gov>

>From the help page for the aggregate function:


Compute Summary Statistics of Data Subsets

Description:

     Splits the data into subsets, computes summary statistics for
     each, and returns the result in a convenient form.




You might have to use cumsum() after the aggregation, if
"unbounded preceding" causes a cumulative sum to be calculated.

-Don
-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 9/9/13 11:58 AM, "Bond, Stephen" <Stephen.Bond at cibc.com> wrote:

>Is there a package or a command that does window aggregation like
>
>select
>sum(col1) over
>(partition by col2, col3 order by col4
>rows between unbounded preceding and current row) as sum1
>from table1 ;
>
>the above is Netezza syntax, but Postgre has same capability.
>
>Stephen B
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From eliza_botto at hotmail.com  Wed Sep 11 16:43:56 2013
From: eliza_botto at hotmail.com (eliza botto)
Date: Wed, 11 Sep 2013 14:43:56 +0000
Subject: [R] (no subject)
Message-ID: <BLU170-W56D248B0C016D79B34481E89390@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130911/061e1e3e/attachment.pl>

From Jose.Iparraguirre at ageuk.org.uk  Wed Sep 11 16:57:23 2013
From: Jose.Iparraguirre at ageuk.org.uk (Jose Iparraguirre)
Date: Wed, 11 Sep 2013 14:57:23 +0000
Subject: [R] Fitting Arima Model to Daily Time Series
In-Reply-To: <CAMOcQfMU70FzSH6SoP2z+a8r9gZKMY79pQno6u6-nbtOKkXuCw@mail.gmail.com>
References: <CAMOcQfPKLfpa9b79nbWi_C2ryAb4QrZJvsSuuO-aSuiumvBeyA@mail.gmail.com>
	<5F8EC5C77B9AE547A8959F690F04C7B2065545@AGEPXMB006.uk.age.local>
	<CAMOcQfMU70FzSH6SoP2z+a8r9gZKMY79pQno6u6-nbtOKkXuCw@mail.gmail.com>
Message-ID: <5F8EC5C77B9AE547A8959F690F04C7B2065EFD@AGEPXMB006.uk.age.local>

Paul
Good you ask because as far as I can remember (some people in the forum are experts on both time series and how R handles time series), it's not advisable to use the ts() function in the base package when dealing with daily observations (because of leap years, mostly).

Therefore, you need to use the packages zoo or xts, as explained here:  http://stackoverflow.com/questions/8437620/analyzing-daily-weekly-data-using-ts-in-r 
You can also use the package timeSeries. If you need to take into account weekdays or weekends (that depends on your research question and modelling, of course), R can do it for you as well.

Best,

Jos?




From: Paul Bernal [mailto:paulbernal07 at gmail.com] 
Sent: 11 September 2013 15:41
To: Jose Iparraguirre
Cc: r-help at r-project.org
Subject: Re: [R] Fitting Arima Model to Daily Time Series

Dear Jose, good morning,

First of all, let me thank you for your extremely valuable help. Now I have a question for you:

I have a table containing two fields, the first one is date and the second one is number of transits of vessels. This table contains daily observations for the past 5 years.

The date field has the following format: YYYY-MM-DD

The number of transits field is a regular numeric field.

How can I do to convert this table into a time series object?

Best regards,

Paul



2013/9/11 Jose Iparraguirre <Jose.Iparraguirre at ageuk.org.uk>
Hi Paul,

There are different packages in R to fit an ARIMA model. I would use the forecast package.
In your case, perhaps you would want to explore SARIMA models to include seasonal components?
Anyhow, the first port of call could be the auto.arima() function to select the best fitting representation according to AIC, AICc or BIC -but explore other representations as well.
To fit the models use the function Arima (note the capital "A"). The documentation in the package is very clear and comprehensive; the authors (Rob J Hyndman and George Athanasopoulos) published a free on-line book which will also help you: http://otexts.com/fpp/.
Hope this helps,

Jos?


Prof. Jos? Iparraguirre
Chief Economist
Age UK



-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Paul Bernal
Sent: 10 September 2013 22:54
To: r-help at r-project.org
Subject: [R] Fitting Arima Model to Daily Time Series

Hello everyone,

Hope everyone is doing great. I would like to know how to use the arima function in R to fit arima or arma models to daily data, that is, with period = 365, this taking into account the fact that I have 5 years worth of daily data (so 365 * 5 = my number of observations).

All I want is a very general line of code of I I would do to fit the arima model.

Any help will be greatly appreciated,

Have a wonderful day,

Paul
? ? ? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

The Wireless from Age UK | Radio for grown-ups.

www.ageuk.org.uk/thewireless


If you're looking for a radio station that offers real variety, tune in to The Wireless from Age UK.
Whether you choose to listen through the website at www.ageuk.org.uk/thewireless, on digital radio (currently available in London and Yorkshire) or through our TuneIn Radio app, you can look forward to an inspiring mix of music, conversation and useful information 24 hours a day.




-------------------------------
Age UK is a registered charity and company limited by guarantee, (registered charity number 1128267, registered company number 6825798).
Registered office: Tavis House, 1-6 Tavistock Square, London WC1H 9NA.

For the purposes of promoting Age UK Insurance, Age UK is an Appointed Representative of Age UK Enterprises Limited, Age UK is an Introducer
Appointed Representative of JLT Benefit Solutions Limited and Simplyhealth Access for the purposes of introducing potential annuity and health
cash plans customers respectively. ?Age UK Enterprises Limited, JLT Benefit Solutions Limited and Simplyhealth Access are all authorised and
regulated by the Financial Services Authority.
------------------------------

This email and any files transmitted with it are confide...{{dropped:24}}


From petr.pikal at precheza.cz  Wed Sep 11 17:12:12 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 11 Sep 2013 15:12:12 +0000
Subject: [R] (no subject)
In-Reply-To: <BLU170-W56D248B0C016D79B34481E89390@phx.gbl>
References: <BLU170-W56D248B0C016D79B34481E89390@phx.gbl>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B91787@SRVEXCHMBX.precheza.cz>

Hi

By HTML posting dput is scrambled and impossible to use.

Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of eliza botto
> Sent: Wednesday, September 11, 2013 4:44 PM
> To: r-help at r-project.org
> Subject: [R] (no subject)
> 
> Now?>dput(gg)
> list(structure(list(coefficients = structure(c(1, 0.0747202722085956,
> 0.359646782818708, 0.298384925903065, -0.443967849195675), .Names =
> c("x0", "x", "xx", "y", "yy")), residuals = structure(c(-
> 0.302776084510551, 0.183247980798144, -0.337231904223223,
> 0.199348794823859, 0.290269994519382, -0.328261122410049, -
> 0.191844336069409, 0.309937888934371, 0.249963958976373, -
> 0.51656422321523, 0.0255108830245443, 0.418398169351789), .Names =
> c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12")),
> effects = structure(c(-3.46410161513775, -0.183026540352922, -
> 0.880951105539393, 0.730890815400676, -1.08749469273032, -
> 0.055778138673626, 0.105917713121713, 0.425275592080333,
> 0.0893727217831096, -0.833878847761609, -0.213870821267818,
> 0.405405268871492), .Names = c("x0", "x", "xx", "y", "yy", "", "", "",
> "", "", "", "")), rank = 5L,     fitted.values =
> structure(c(1.00923807240423, 0.815143487596117,     1.06126185691564,
> 1.50939808712151, 1.64879363631755, 1.22366465369447,    !
>   0.520171981764853, 0.117496714766831, 0.341968291278227,
> 0.961191858709413, 1.4185661613195, 1.37310519811166), .Names = c("1",
> "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12")),     assign
> = 1:5, qr = structure(list(qr = structure(c(-3.46410161513775,
> 0.288675134594813, 0.288675134594813, 0.288675134594813,
> 0.288675134594813, 0.288675134594813, 0.288675134594813,
> 0.288675134594813, 0.288675134594813, 0.288675134594813,
> 0.288675134594813, 0.288675134594813, 1.0359551758099e-16,     -
> 2.44948974278318, -0.0791992255271195, -0.283323370759051,     -
> 0.432752616120393, -0.487447515990983, -0.432752616120393,     -
> 0.283323370759051, -0.0791992255271196, 0.124924919704812,
> 0.274354165066154, 0.329049064936743, 1.60326396256294e-16,     -
> 4.06575814682064e-17, -2.44948974278318, 0.385357119965326,
> 0.276818123873927, 0.0876608486418726, -0.131430166589936,     -
> 0.321749661221222, -0.432301680361632, -0.433463899760863,     -
> 0.324924903669464,!
>   -0.13576762843741, 4.07117915768307e-17,     2.16515173845355e-16, 3.
> 30898503042576e-16, 2.44948974278318,     -0.1565883283638, -
> 0.28412286470868, -0.0175072160832821,     0.422389924412376,
> 0.61883998250704, 0.369775078419853, -0.108638802574745,     -
> 0.389352556693728, -7.42678488152571e-18, 6.07912158112622e-16,
> 4.95615918097436e-17, -1.02240264865383e-16, 2.44948974278318,
> 0.0399663322170986, -0.36906922926158, -0.453581151684979,     -
> 0.103155496641535, 0.3733769380139, 0.545626107621939,
> 0.279668949241763    ), .Dim = c(12L, 5L), .Dimnames = list(c("1", "2",
> "3", "4",     "5", "6", "7", "8", "9", "10", "11", "12"), c("x0", "x",
> "xx", "y", "yy")), assign = 1:5), qraux = c(1.28867513459481,
> 1.12492491970481, 1.38419490056609, 1.18149437156933, 1.36122122075101
> ), pivot = 1:5, tol = 1e-07, rank = 5L), .Names = c("qr",     "qraux",
> "pivot", "tol", "rank"), class = "qr"), df.residual = 7L,     xlevels =
> structure(list(), .Names = character(0)), call = lm(formula = mm[,
> i] ~ 0 + (x0 + x + xx + y + yy)), terms = mm[!
>  , i] ~ 0 +         (x0 + x + xx + y + yy), model =
> structure(list(`mm[, i]` = c(0.706461987893674,     0.998391468394261,
> 0.72402995269242, 1.70874688194537, 1.93906363083693,
> 0.89540353128442, 0.328327645695443, 0.427434603701202,
> 0.591932250254601,     0.444627635494183, 1.44407704434405,
> 1.79150336746345), x0 = structure(c(1,     1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1), .Dim = c(12L, 1L)), x = structure(c(0.866025403784439,     0.5,
> 6.12303176911189e-17, -0.5, -0.866025403784439, -1,     -
> 0.866025403784439, -0.5, -1.83690953073357e-16, 0.5, 0.866025403784438,
> 1), .Dim = c(12L, 1L)), xx = structure(c(0.5, 0.866025403784439,     1,
> 0.866025403784439, 0.5, 1.22460635382238e-16, -0.5, -0.866025403784438,
> -1, -0.866025403784439, -0.5, -2.44921270764475e-16), .Dim = c(12L,
> 1L)), y = structure(c(0.5, -0.5, -1, -0.5, 0.5, 1, 0.5, -
> 0.499999999999999,     -1, -0.5, 0.499999999999999, 1), .Dim = c(12L,
> 1L)), yy = structure(c(0.866025403784439,     0.866025403784439,
> 1.2246!
>  0635382238e-16, -0.866025403784438,     -0.866025403784439, -2.4492127
> 0764475e-16, 0.866025403784439,     0.866025403784439,
> 3.67381906146713e-16, -0.866025403784439,     -0.866025403784439, -
> 4.89842541528951e-16), .Dim = c(12L,     1L))), .Names = c("mm[, i]",
> "x0", "x", "xx", "y", "yy"), terms = mm[,         i] ~ 0 + (x0 + x + xx
> + y + yy), row.names = c(NA, 12L    ), class = "data.frame")), .Names =
> c("coefficients", "residuals", "effects", "rank", "fitted.values",
> "assign", "qr", "df.residual", "xlevels", "call", "terms", "model"),
> class = "lm"), structure(list(    coefficients = structure(c(1,
> 0.308786314174914, 0.120489287397766,     0.116129002459147, -
> 0.283906024106553), .Names = c("x0",     "x", "xx", "y", "yy")),
> residuals = structure(c(-0.194600470874542,     0.147793243511181, -
> 0.0596338831684155, -0.19669043918067,     0.411977909847386, -
> 0.217327208227307, -0.172627741951063,     0.159445944832986,
> 0.251643280528442, -0.434578519402112,     0.159302024253958,
> 0.145295859830158), .Names = c("1", "2",     "3", "4", "5", "6", "7",
> "!
>  8", "9", "10", "11", "12")), effects = structure(c(-3.46410161513775,
> -0.756368909283277, -0.295137273596081, 0.284456800363322,     -
> 0.695424893963357, -0.130842377327931, 0.0826788149787507,
> 0.459795732697155, 0.4015715947845, -0.521947444480734, -
> 0.0607557637087129,     -0.00767162881851222), .Names = c("x0", "x",
> "xx", "y", "yy",     "", "", "", "", "", "", "")), rank = 5L,
> fitted.values = structure(c(1.13985610818118,     0.954805610464521,
> 1.00436028493862, 1.13775895461703, 1.09676218167573,
> 0.807342688284232, 0.484533235950539, 0.437325728748907,
> 0.763381710143087, 1.23785170125125, 1.51110647911084, 1.42491531663406
> ), .Names = c("1", "2", "3", "4", "5", "6", "7", "8", "9",     "10",
> "11", "12")), assign = 1:5, qr = structure(list(qr = structure(c(-
> 3.46410161513775,     0.288675134594813, 0.288675134594813,
> 0.288675134594813,     0.288675134594813, 0.288675134594813,
> 0.288675134594813,     0.288675134594813, 0.288675134594813,
> 0.288675134594813, !
>      0.288675134594813, 0.288675134594813, 1.0359551758099e-16,     -2.
> 44948974278318, -0.0791992255271195, -0.283323370759051,     -
> 0.432752616120393, -0.487447515990983, -0.432752616120393,     -
> 0.283323370759051, -0.0791992255271196, 0.124924919704812,
> 0.274354165066154, 0.329049064936743, 1.60326396256294e-16,     -
> 4.06575814682064e-17, -2.44948974278318, 0.385357119965326,
> 0.276818123873927, 0.0876608486418726, -0.131430166589936,     -
> 0.321749661221222, -0.432301680361632, -0.433463899760863,     -
> 0.324924903669464, -0.13576762843741, 4.07117915768307e-17,
> 2.16515173845355e-16, 3.30898503042576e-16, 2.44948974278318,     -
> 0.1565883283638, -0.28412286470868, -0.0175072160832821,
> 0.422389924412376, 0.61883998250704, 0.369775078419853, -
> 0.108638802574745,     -0.389352556693728, -7.42678488152571e-18,
> 6.07912158112622e-16,     4.95615918097436e-17, -1.02240264865383e-16,
> 2.44948974278318,     0.0399663322170986, -0.36906922926158, -
> 0.453581151684979,     -0.103155496641535, 0.3733769380139,
> 0.545626107621939, 0.27966894924176!
>  3    ), .Dim = c(12L, 5L), .Dimnames = list(c("1", "2", "3", "4",
> "5", "6", "7", "8", "9", "10", "11", "12"), c("x0", "x",     "xx", "y",
> "yy")), assign = 1:5), qraux = c(1.28867513459481,
> 1.12492491970481, 1.38419490056609, 1.18149437156933, 1.36122122075101
> ), pivot = 1:5, tol = 1e-07, rank = 5L), .Names = c("qr",     "qraux",
> "pivot", "tol", "rank"), class = "qr"), df.residual = 7L,     xlevels =
> structure(list(), .Names = character(0)), call = lm(formula = mm[,
> i] ~ 0 + (x0 + x + xx + y + yy)), terms = mm[, i] ~ 0 +         (x0 + x
> + xx + y + yy), model = structure(list(`mm[, i]` = c(0.94525563730664,
> 1.1025988539757, 0.944726401770203, 0.941068515436361,
> 1.50874009152312,     0.590015480056925, 0.311905493999476,
> 0.596771673581893,     1.01502499067153, 0.803273181849135,
> 1.6704085033648, 1.57021117646422    ), x0 = structure(c(1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1), .Dim = c(12L,     1L)), x =
> structure(c(0.866025403784439, 0.5, 6.12303176911189e-1!
>  7,     -0.5, -0.866025403784439, -1, -0.866025403784439, -0.5, -1.8369
> 0953073357e-16,     0.5, 0.866025403784438, 1), .Dim = c(12L, 1L)), xx
> = structure(c(0.5,     0.866025403784439, 1, 0.866025403784439, 0.5,
> 1.22460635382238e-16,     -0.5, -0.866025403784438, -1, -
> 0.866025403784439, -0.5, -2.44921270764475e-16    ), .Dim = c(12L,
> 1L)), y = structure(c(0.5, -0.5, -1, -0.5,     0.5, 1, 0.5, -
> 0.499999999999999, -1, -0.5, 0.499999999999999,     1), .Dim = c(12L,
> 1L)), yy = structure(c(0.866025403784439,     0.866025403784439,
> 1.22460635382238e-16, -0.866025403784438,     -0.866025403784439, -
> 2.44921270764475e-16, 0.866025403784439,     0.866025403784439,
> 3.67381906146713e-16, -0.866025403784439,     -0.866025403784439, -
> 4.89842541528951e-16), .Dim = c(12L,     1L))), .Names = c("mm[, i]",
> "x0", "x", "xx", "y", "yy"), terms = mm[,         i] ~ 0 + (x0 + x + xx
> + y + yy), row.names = c(NA, 12L    ), class = "data.frame")), .Names =
> c("coefficients", "residuals", "effects", "rank", "fitted.values",
> "assign", "qr", "df.residual", "xlevels", "call", !
>  "terms", "model"), class = "lm"), structure(list(    coefficients =
> structure(c(1, -0.996313162974889, -0.685856462834009,
> 0.325823696582116, 0.327699171167941), .Names = c("x0", "x",     "xx",
> "y", "yy")), residuals = structure(c(-0.0777045386979109,
> 0.089533319906306, 0.128276753641805, -0.184243237765273,     -
> 0.0952797955011903, 0.319208904474422, -0.190396651582146,     -
> 0.0358873535213481, 0.0787996209644746, -0.0691002539371463,
> 0.13416806330851, -0.0973748312905045), .Names = c("1", "2",     "3",
> "4", "5", "6", "7", "8", "9", "10", "11", "12")), effects =
> structure(c(-3.46410161513775,     2.44045887330686, 1.67999837073346,
> 0.798101802733592, 0.80269575849442,     0.332038944965529, -
> 0.144835679781188, 0.0788191020004607,     0.240265175450381,
> 0.066661487462206, 0.181376391686432,     -0.137568239718286), .Names =
> c("x0", "x", "xx", "y", "yy",     "", "", "", "", "", "", "")), rank =
> 5L, fitted.values = structure(c(0.240946914643516,     0.028758257088!
>  0492, -0.0116801594161259, 0.457479806001854,     1.39902031910459, 2.
> 32213685955701, 2.65246839599968, 2.21300966039092,
> 1.36003276625189, 0.649104883354945, 0.359211763416442,
> 0.329510533607227    ), .Names = c("1", "2", "3", "4", "5", "6", "7",
> "8", "9",     "10", "11", "12")), assign = 1:5, qr = structure(list(qr
> = structure(c(-3.46410161513775,     0.288675134594813,
> 0.288675134594813, 0.288675134594813,     0.288675134594813,
> 0.288675134594813, 0.288675134594813,     0.288675134594813,
> 0.288675134594813, 0.288675134594813,     0.288675134594813,
> 0.288675134594813, 1.0359551758099e-16,     -2.44948974278318, -
> 0.0791992255271195, -0.283323370759051,     -0.432752616120393, -
> 0.487447515990983, -0.432752616120393,     -0.283323370759051, -
> 0.0791992255271196, 0.124924919704812,     0.274354165066154,
> 0.329049064936743, 1.60326396256294e-16,     -4.06575814682064e-17, -
> 2.44948974278318, 0.385357119965326,     0.276818123873927,
> 0.0876608486418726, -0.131430166589936,     -0.321749661221222, -
> 0.432301680361632, -0.433463899760863,     -0.32!
>  4924903669464, -0.13576762843741, 4.07117915768307e-17,
> 2.16515173845355e-16, 3.30898503042576e-16, 2.44948974278318,     -
> 0.1565883283638, -0.28412286470868, -0.0175072160832821,
> 0.422389924412376, 0.61883998250704, 0.369775078419853, -
> 0.108638802574745,     -0.389352556693728, -7.42678488152571e-18,
> 6.07912158112622e-16,     4.95615918097436e-17, -1.02240264865383e-16,
> 2.44948974278318,     0.0399663322170986, -0.36906922926158, -
> 0.453581151684979,     -0.103155496641535, 0.3733769380139,
> 0.545626107621939, 0.279668949241763    ), .Dim = c(12L, 5L), .Dimnames
> = list(c("1", "2", "3", "4",     "5", "6", "7", "8", "9", "10", "11",
> "12"), c("x0", "x",     "xx", "y", "yy")), assign = 1:5), qraux =
> c(1.28867513459481,     1.12492491970481, 1.38419490056609,
> 1.18149437156933, 1.36122122075101    ), pivot = 1:5, tol = 1e-07, rank
> = 5L), .Names = c("qr",     "qraux", "pivot", "tol", "rank"), class =
> "qr"), df.residual = 7L,     xlevels = structure(list(), .Names =
> characte!
>  r(0)), call = lm(formula = mm[,         i] ~ 0 + (x0 + x + xx + y + yy
> )), terms = mm[, i] ~ 0 +         (x0 + x + xx + y + yy), model =
> structure(list(`mm[, i]` = c(0.163242375945605,     0.118291576994355,
> 0.116596594225679, 0.273236568236582,     1.3037405236034,
> 2.64134576403143, 2.46207174441754, 2.17712230686957,
> 1.43883238721637, 0.580004629417799, 0.493379826724952,
> 0.232135702316723    ), x0 = structure(c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1), .Dim = c(12L,     1L)), x = structure(c(0.866025403784439, 0.5,
> 6.12303176911189e-17,     -0.5, -0.866025403784439, -1, -
> 0.866025403784439, -0.5, -1.83690953073357e-16,     0.5,
> 0.866025403784438, 1), .Dim = c(12L, 1L)), xx = structure(c(0.5,
> 0.866025403784439, 1, 0.866025403784439, 0.5, 1.22460635382238e-16,
> -0.5, -0.866025403784438, -1, -0.866025403784439, -0.5, -
> 2.44921270764475e-16    ), .Dim = c(12L, 1L)), y = structure(c(0.5, -
> 0.5, -1, -0.5,     0.5, 1, 0.5, -0.499999999999999, -1, -0.5,
> 0.499999999999999,     1), .Dim = c(12L, 1L)), yy =
> structure(c(0.866025403784439,     0.86602!
>  5403784439, 1.22460635382238e-16, -0.866025403784438,     -
> 0.866025403784439, -2.44921270764475e-16, 0.866025403784439,
> 0.866025403784439, 3.67381906146713e-16, -0.866025403784439,     -
> 0.866025403784439, -4.89842541528951e-16), .Dim = c(12L,     1L))),
> .Names = c("mm[, i]", "x0", "x", "xx", "y", "yy"), terms = mm[,
> i] ~ 0 + (x0 + x + xx + y + yy), row.names = c(NA, 12L    ), class =
> "data.frame")), .Names = c("coefficients", "residuals", "effects",
> "rank", "fitted.values", "assign", "qr", "df.residual", "xlevels",
> "call", "terms", "model"), class = "lm"))
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Wed Sep 11 17:15:08 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 11 Sep 2013 08:15:08 -0700 (PDT)
Subject: [R] list to matrix
In-Reply-To: <BLU170-W121FB55A13AFCB7E7F111AE89390@phx.gbl>
References: <BLU170-W121FB55A13AFCB7E7F111AE89390@phx.gbl>
Message-ID: <1378912508.96170.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
Try:
set.seed(48)
lst1<-replicate(3,data.frame(y=rnorm(50),z=runif(50),x=sample(10:15,50,replace=TRUE)),simplify=FALSE)
?t(sapply(lst1,function(u) coef(lm(y~0+x+z,data=u))))? #change accordingly
#?????????????? x????????? z
#[1,] -0.01020553? 0.3852990
#[2,] -0.01157726? 0.3986898
#[3,]? 0.01788307 -0.5624307

A.K.




----- Original Message -----
From: eliza botto <eliza_botto at hotmail.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Wednesday, September 11, 2013 10:22 AM
Subject: [R] list to matrix

Dear useRs,
If i have a list of the following form and i want to convert the coefficient section of each element, combined into one matrix of dimension 3*5. How can i do that?I hope i am clear
thank in advance

[[1]]
Call:
lm(formula = mm[, i] ~ 0 + (x0 + x + xx + y + yy))
Coefficients:
? ?  x0? ? ? ? x? ? ?  xx? ? ? ? y? ? ?  yy? 
1.0000? -0.4250?  0.2494?  0.1683? -0.7449? 

[[2]]
Call:
lm(formula = mm[, i] ~ 0 + (x0 + x + xx + y + yy))
Coefficients:
? ?  x0? ? ? ? x? ? ?  xx? ? ? ? y? ? ?  yy? 
1.0000? -0.6355?  0.5876?  0.2518? -0.7293? 

[[3]]
Call:
lm(formula = mm[, i] ~ 0 + (x0 + x + xx + y + yy))
Coefficients:
? ?  x0? ? ? ? x? ? ?  xx? ? ? ? y? ? ?  yy? 
1.0000?  0.5778?  0.3838?  0.4207? -0.1354? 
??? ???  ??? ?  ??? ??? ? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From petr.pikal at precheza.cz  Wed Sep 11 17:17:49 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 11 Sep 2013 15:17:49 +0000
Subject: [R] list to matrix
In-Reply-To: <BLU170-W121FB55A13AFCB7E7F111AE89390@phx.gbl>
References: <BLU170-W121FB55A13AFCB7E7F111AE89390@phx.gbl>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B917A3@SRVEXCHMBX.precheza.cz>

Hi

Do not post HTML. Why you did not populate your list directly with coefficients by let say coef(lm.result)?

Anyway, you can reveal structure of individulal list component by str(your.object[[1]]). After that you can extract coefficient component and use sapply/lapply probably with rbind.

maybe

sapply(lapply(your.list, coef), rbind)

can do it.

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of eliza botto
> Sent: Wednesday, September 11, 2013 4:23 PM
> To: r-help at r-project.org
> Subject: [R] list to matrix
> 
> Dear useRs,
> If i have a list of the following form and i want to convert the
> coefficient section of each element, combined into one matrix of
> dimension 3*5. How can i do that?I hope i am clear thank in advance
> 
> [[1]]
> Call:
> lm(formula = mm[, i] ~ 0 + (x0 + x + xx + y + yy))
> Coefficients:
>      x0        x       xx        y       yy
>  1.0000  -0.4250   0.2494   0.1683  -0.7449
> 
> [[2]]
> Call:
> lm(formula = mm[, i] ~ 0 + (x0 + x + xx + y + yy))
> Coefficients:
>      x0        x       xx        y       yy
>  1.0000  -0.6355   0.5876   0.2518  -0.7293
> 
> [[3]]
> Call:
> lm(formula = mm[, i] ~ 0 + (x0 + x + xx + y + yy))
> Coefficients:
>      x0        x       xx        y       yy
>  1.0000   0.5778   0.3838   0.4207  -0.1354
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gilescrane at verizon.net  Wed Sep 11 17:21:04 2013
From: gilescrane at verizon.net (Giles Crane)
Date: Wed, 11 Sep 2013 11:21:04 -0400
Subject: [R] int vector
Message-ID: <52308A60.2050203@verizon.net>


class int seems to interact oddly with fix() and dotchart().

Reading a .csv file when there are no decimal points
in an item, results in a data.frame having a column
of class int.  The mode, however, is numeric.

fix() does not recognize int "vectors",
and thus does not spread its sheet.

dotchart() displays a 1 above the labels on the plot.

Converting the int column to numeric using as.numeric()
cures the problems.  However, the behavior of the int class
seems inconsistent.

R Version 3.01 (2013-05-16)

Thank you for your consideration.

Cordially,
Giles


-- 
Giles L Crane, MPH, ASA, NJPHA
Statistical Consultant and R Instructor
621 Lake Drive
Princeton, NJ  08540
Phone: 609 924-0971
Email: gilescrane at verizon.net


From smartpink111 at yahoo.com  Wed Sep 11 17:32:47 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 11 Sep 2013 08:32:47 -0700 (PDT)
Subject: [R] Running Loops
Message-ID: <1378913567.12933.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Try:
set.seed(24)
yall<- as.data.frame(matrix(sample(1:1e5,5000*10,replace=FALSE),ncol=10))
?set.seed(49)
? lst1<-replicate(100,yall[sample(1:nrow(yall),100,replace=FALSE),],simplify=FALSE)
?names(lst1)<- paste0("yall",1:100)

lapply(seq_along(lst1),function(i) write.csv(lst1[[i]],file=paste0("yall",i,".csv"),row.names=FALSE))



A.K.

I have a data set called yall with 5000 rows, I want to randomly sub sample 100 rows 100 times. 
This is what I have so far: 

yall<-read.csv("Z:\\SOFTEL\\North Key Largo project\\Canopy_Height\\random_age_strat\\Young\\Abv2ft_young.csv") 

yall1 <- yall[sample(1:nrow(yall), 100, replace=FALSE),] 

write.csv(yall1, file = "yall1.csv")

I want to run a 
loop of the bold script above 100 times, but I want to be able to change
 the name of the sub sample and name of the csv file each time. They 
should be named yall1, yall2,yall3...etc until 100.


From murdoch.duncan at gmail.com  Wed Sep 11 17:33:38 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 11 Sep 2013 11:33:38 -0400
Subject: [R] int vector
In-Reply-To: <52308A60.2050203@verizon.net>
References: <52308A60.2050203@verizon.net>
Message-ID: <52308D52.4040607@gmail.com>

On 11/09/2013 11:21 AM, Giles Crane wrote:
> class int seems to interact oddly with fix() and dotchart().
>
> Reading a .csv file when there are no decimal points
> in an item, results in a data.frame having a column
> of class int.  The mode, however, is numeric.
>
> fix() does not recognize int "vectors",
> and thus does not spread its sheet.
>
> dotchart() displays a 1 above the labels on the plot.
>
> Converting the int column to numeric using as.numeric()
> cures the problems.  However, the behavior of the int class
> seems inconsistent.
>
> R Version 3.01 (2013-05-16)
>
> Thank you for your consideration.
>
> Cordially,
> Giles
>
>
Could you please put together an example of this in R-patched?  I don't 
see it at all.  (I don't know if it has already been fixed, or if I am 
just misunderstanding your description.)

What I see is that fix() on a numeric or integer vector gives a text 
editor.  fix() on a dataframe containing either gives me the spreadsheet.

Duncan Murdoch


From Stephen.Bond at cibc.com  Wed Sep 11 17:36:09 2013
From: Stephen.Bond at cibc.com (Bond, Stephen)
Date: Wed, 11 Sep 2013 15:36:09 +0000
Subject: [R] windowing
In-Reply-To: <5E1B812FAC2C4A49B3D99593B5A521910D437047@PRDEXMBX-08.the-lab.llnl.gov>
References: <624EC9773CAB044ABA65327271BED9B601C3FF@CBMCC-X10-MA01.ad.cibc.com>
	<5E1B812FAC2C4A49B3D99593B5A521910D437047@PRDEXMBX-08.the-lab.llnl.gov>
Message-ID: <624EC9773CAB044ABA65327271BED9B601CE12@CBMCC-X10-MA01.ad.cibc.com>

Very interesting. Does not produce a solution outright, but may be still usable

> df <- data.frame(x1=c(rep(1,10),rep(2,7)),x2=rep(1:17))
> aggregate(df$x2,by=list(x1=df$x1),cumsum)-> a1
> a1
  x1                                   x
1  1 1, 3, 6, 10, 15, 21, 28, 36, 45, 55
2  2          11, 23, 36, 50, 65, 81, 98
> dim(a1)
[1] 2 2
> a1[1,2]
$`0`
 [1]  1  3  6 10 15 21 28 36 45 55

> a1[2,2]
$`1`
[1] 11 23 36 50 65 81 98

> class(a1[2,2])
[1] "list"

If anybody can suggest how to create a reshape-able dataframe out of this, please speak. 
Ideally I should be able to use 

reshape(a1,dir="long",varying=2:11,idvar="x1",v.names="x")

to get it back in long form.
Thank everybody.

Stephen B
-----Original Message-----
From: MacQueen, Don [mailto:macqueen1 at llnl.gov] 
Sent: Wednesday, September 11, 2013 10:42 AM
To: Bond, Stephen; r-help at r-project.org
Subject: Re: [R] windowing

>From the help page for the aggregate function:


Compute Summary Statistics of Data Subsets

Description:

     Splits the data into subsets, computes summary statistics for
     each, and returns the result in a convenient form.




You might have to use cumsum() after the aggregation, if
"unbounded preceding" causes a cumulative sum to be calculated.

-Don
-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 9/9/13 11:58 AM, "Bond, Stephen" <Stephen.Bond at cibc.com> wrote:

>Is there a package or a command that does window aggregation like
>
>select
>sum(col1) over
>(partition by col2, col3 order by col4
>rows between unbounded preceding and current row) as sum1
>from table1 ;
>
>the above is Netezza syntax, but Postgre has same capability.
>
>Stephen B
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Wed Sep 11 17:40:57 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 11 Sep 2013 15:40:57 +0000
Subject: [R] int vector
In-Reply-To: <52308A60.2050203@verizon.net>
References: <52308A60.2050203@verizon.net>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B91814@SRVEXCHMBX.precheza.cz>

Hi

data, data, data. Use dput(head(data,10)) if the data frame is too big.

zdrz <- structure(list(sklon = c(10, 10, 10, 10, 20, 20, 20, 20, 20, 
40, 40, 40, 40, 95, 95), ot = c(0.8, 1.5, 4, 10, 15, 1.5, 4, 
10, 15, 1.5, 4, 10, 15, 4, 15), doba = c(140, 111, 42.8, 20.3, 
15, 88, 38.25, 17.33333333, 12.5, 65.16666667, 27, 12.5, 9.166666667, 
15.75, 5.883333333)), .Names = c("sklon", "ot", "doba"), row.names = c(NA, 
15L), class = "data.frame")


> sapply(zdrz, class)
    sklon        ot      doba 
"integer" "numeric" "numeric" 
> dotchart(zdrz$sklon)
> fix(zdrz)
> sapply(zdrz, class)
    sklon        ot      doba 
"numeric" "numeric" "numeric" 
> dotchart(zdrz$sklon)

fix changes column class to numeric but dotchart looks same to me

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Giles Crane
> Sent: Wednesday, September 11, 2013 5:21 PM
> To: r-help at r-project.org
> Subject: [R] int vector
> 
> 
> class int seems to interact oddly with fix() and dotchart().
> 
> Reading a .csv file when there are no decimal points in an item,
> results in a data.frame having a column of class int.  The mode,
> however, is numeric.
> 
> fix() does not recognize int "vectors",
> and thus does not spread its sheet.
> 
> dotchart() displays a 1 above the labels on the plot.
> 
> Converting the int column to numeric using as.numeric() cures the
> problems.  However, the behavior of the int class seems inconsistent.
> 
> R Version 3.01 (2013-05-16)
> 
> Thank you for your consideration.
> 
> Cordially,
> Giles
> 
> 
> --
> Giles L Crane, MPH, ASA, NJPHA
> Statistical Consultant and R Instructor
> 621 Lake Drive
> Princeton, NJ  08540
> Phone: 609 924-0971
> Email: gilescrane at verizon.net
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From andreas at maunz.de  Wed Sep 11 17:44:57 2013
From: andreas at maunz.de (Andreas Maunz)
Date: Wed, 11 Sep 2013 17:44:57 +0200
Subject: [R] rgl snapshot on headless server
In-Reply-To: <522F4B07.4030004@gmail.com>
References: <CAJHOUEMjjYO98UYrkJ_SfSByC9xNqd2ydGVgkFoazbW21ccMvQ@mail.gmail.com>
	<522F4B07.4030004@gmail.com>
Message-ID: <CAJHOUEM6VM=znCy=g1RaLZ2gMSJ8Wei3-aFKN4tw-BVvEHy8fQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130911/eaf63ac6/attachment.pl>

From torvon at gmail.com  Wed Sep 11 17:47:39 2013
From: torvon at gmail.com (Torvon)
Date: Wed, 11 Sep 2013 17:47:39 +0200
Subject: [R] Chi-square values in GLM model comparison
Message-ID: <CACm_P7rmmzvidDoO43YJ_0Q9=hm6G851WorN_5g2WbJDZTA6zQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130911/382f1685/attachment.pl>

From smartpink111 at yahoo.com  Wed Sep 11 17:50:17 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 11 Sep 2013 08:50:17 -0700 (PDT)
Subject: [R] windowing
In-Reply-To: <624EC9773CAB044ABA65327271BED9B601CE12@CBMCC-X10-MA01.ad.cibc.com>
References: <624EC9773CAB044ABA65327271BED9B601C3FF@CBMCC-X10-MA01.ad.cibc.com>	<5E1B812FAC2C4A49B3D99593B5A521910D437047@PRDEXMBX-08.the-lab.llnl.gov>
	<624EC9773CAB044ABA65327271BED9B601CE12@CBMCC-X10-MA01.ad.cibc.com>
Message-ID: <1378914617.48025.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
Try:
library(plyr)
?ddply(df,.(x1),summarize,x=cumsum(x2))
#?? x1? x
#1?? 1? 1
#2?? 1? 3
#3?? 1? 6
#4?? 1 10
#5?? 1 15
#6?? 1 21
#7?? 1 28
#8?? 1 36
#9?? 1 45
#10? 1 55
#11? 2 11
#12? 2 23
#13? 2 36
#14? 2 50
#15? 2 65
#16? 2 81
#17? 2 98


#or using a1

?df2<- data.frame(x1=rep(a1$x1,sapply(a1$x,length)),x=unlist(a1$x))
row.names(df2)<-1:nrow(df2)


A.K.



----- Original Message -----
From: "Bond, Stephen" <Stephen.Bond at cibc.com>
To: "'MacQueen, Don'" <macqueen1 at llnl.gov>; "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Wednesday, September 11, 2013 11:36 AM
Subject: Re: [R] windowing

Very interesting. Does not produce a solution outright, but may be still usable

> df <- data.frame(x1=c(rep(1,10),rep(2,7)),x2=rep(1:17))
> aggregate(df$x2,by=list(x1=df$x1),cumsum)-> a1
> a1
? x1? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?  x
1? 1 1, 3, 6, 10, 15, 21, 28, 36, 45, 55
2? 2? ? ? ? ? 11, 23, 36, 50, 65, 81, 98
> dim(a1)
[1] 2 2
> a1[1,2]
$`0`
[1]? 1? 3? 6 10 15 21 28 36 45 55

> a1[2,2]
$`1`
[1] 11 23 36 50 65 81 98

> class(a1[2,2])
[1] "list"

If anybody can suggest how to create a reshape-able dataframe out of this, please speak. 
Ideally I should be able to use 

reshape(a1,dir="long",varying=2:11,idvar="x1",v.names="x")

to get it back in long form.
Thank everybody.

Stephen B
-----Original Message-----
From: MacQueen, Don [mailto:macqueen1 at llnl.gov] 
Sent: Wednesday, September 11, 2013 10:42 AM
To: Bond, Stephen; r-help at r-project.org
Subject: Re: [R] windowing

>From the help page for the aggregate function:


Compute Summary Statistics of Data Subsets

Description:

? ?  Splits the data into subsets, computes summary statistics for
? ?  each, and returns the result in a convenient form.




You might have to use cumsum() after the aggregation, if
"unbounded preceding" causes a cumulative sum to be calculated.

-Don
-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 9/9/13 11:58 AM, "Bond, Stephen" <Stephen.Bond at cibc.com> wrote:

>Is there a package or a command that does window aggregation like
>
>select
>sum(col1) over
>(partition by col2, col3 order by col4
>rows between unbounded preceding and current row) as sum1
>from table1 ;
>
>the above is Netezza syntax, but Postgre has same capability.
>
>Stephen B
>
>??? [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From Jose.Iparraguirre at ageuk.org.uk  Wed Sep 11 18:03:45 2013
From: Jose.Iparraguirre at ageuk.org.uk (Jose Iparraguirre)
Date: Wed, 11 Sep 2013 16:03:45 +0000
Subject: [R] Chi-square values in GLM model comparison
In-Reply-To: <CACm_P7rmmzvidDoO43YJ_0Q9=hm6G851WorN_5g2WbJDZTA6zQ@mail.gmail.com>
References: <CACm_P7rmmzvidDoO43YJ_0Q9=hm6G851WorN_5g2WbJDZTA6zQ@mail.gmail.com>
Message-ID: <5F8EC5C77B9AE547A8959F690F04C7B2065F96@AGEPXMB006.uk.age.local>

Hi Eiko,

How about this?

> anova (m1, m2, test="Chisq")

See: ?anova.glm

Regards,
Jos?


Prof. Jos? Iparraguirre
Chief Economist
Age UK



-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Torvon
Sent: 11 September 2013 16:48
To: r-help at r-project.org
Subject: [R] Chi-square values in GLM model comparison

Hello --
I am comparing two
GLMs (binomial dependent variable)
, the results are the following:
> m1<-glm(symptoms ~ phq_index, data=data2) m2<-glm(symptoms ~ 1, 
> data=data2)

Trying to compare these models using
> anova (m1, m2)
I do not obtain chi-square values or a chi-square difference test; instead, I get loglikelihood ratios:

> Likelihood ratio tests of cumulative link models:
> formula: link: threshold:
> m2 sym_bin ~ 1         logit flexible
> m1 sym_bin ~ phq_index logit flexible
>       no.par   AIC   logLik  LR.stat df Pr(>Chisq)
> m2      1    10947   -5472.5
> m1      9     9711   -4846.5    1252  8  < 2.2e-16 ***

Since reviewers would like me to report chi-square values: how to I obtain them when comparing GLMs? I'm looking for an output similar to the output of the GLMER function in LME4, e.g.:

> anova(m3,m4)
...
>       Df   AIC   BIC  logLik Chisq Chi Df Pr(>Chisq)
> m3 13 11288 11393 -5630.9
> m4 21 11212 11382 -5584.9 92.02      8  < 2.2e-16 ***

Thank you!
 Eiko

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

The Wireless from Age UK | Radio for grown-ups.

www.ageuk.org.uk/thewireless


If you?re looking for a radio station that offers real variety, tune in to The Wireless from Age UK. 
Whether you choose to listen through the website at www.ageuk.org.uk/thewireless, on digital radio (currently available in London and Yorkshire) or through our TuneIn Radio app, you can look forward to an inspiring mix of music, conversation and useful information 24 hours a day.



 
-------------------------------
Age UK is a registered charity and company limited by guarantee, (registered charity number 1128267, registered company number 6825798). 
Registered office: Tavis House, 1-6 Tavistock Square, London WC1H 9NA.

For the purposes of promoting Age UK Insurance, Age UK is an Appointed Representative of Age UK Enterprises Limited, Age UK is an Introducer 
Appointed Representative of JLT Benefit Solutions Limited and Simplyhealth Access for the purposes of introducing potential annuity and health 
cash plans customers respectively.  Age UK Enterprises Limited, JLT Benefit Solutions Limited and Simplyhealth Access are all authorised and 
regulated by the Financial Services Authority. 
------------------------------

This email and any files transmitted with it are confidential and intended solely for the use of the individual or entity to whom they are 
addressed. If you receive a message in error, please advise the sender and delete immediately.

Except where this email is sent in the usual course of our business, any opinions expressed in this email are those of the author and do not 
necessarily reflect the opinions of Age UK or its subsidiaries and associated companies. Age UK monitors all e-mail transmissions passing 
through its network and may block or modify mails which are deemed to be unsuitable.

Age Concern England (charity number 261794) and Help the Aged (charity number 272786) and their trading and other associated companies merged 
on 1st April 2009.  Together they have formed the Age UK Group, dedicated to improving the lives of people in later life.  The three national 
Age Concerns in Scotland, Northern Ireland and Wales have also merged with Help the Aged in these nations to form three registered charities: 
Age Scotland, Age NI, Age Cymru.





From torvon at gmail.com  Wed Sep 11 18:17:12 2013
From: torvon at gmail.com (Torvon)
Date: Wed, 11 Sep 2013 18:17:12 +0200
Subject: [R] Chi-square values in GLM model comparison
In-Reply-To: <5F8EC5C77B9AE547A8959F690F04C7B2065F96@AGEPXMB006.uk.age.local>
References: <CACm_P7rmmzvidDoO43YJ_0Q9=hm6G851WorN_5g2WbJDZTA6zQ@mail.gmail.com>
	<5F8EC5C77B9AE547A8959F690F04C7B2065F96@AGEPXMB006.uk.age.local>
Message-ID: <CACm_P7qVGFSA_UAy=msC-Yu+qd=ts_zjv58cG2drwxaL1cXJUA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130911/b04bbbd1/attachment.pl>

From murdoch.duncan at gmail.com  Wed Sep 11 18:19:46 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 11 Sep 2013 12:19:46 -0400
Subject: [R] rgl snapshot on headless server
In-Reply-To: <CAJHOUEM6VM=znCy=g1RaLZ2gMSJ8Wei3-aFKN4tw-BVvEHy8fQ@mail.gmail.com>
References: <CAJHOUEMjjYO98UYrkJ_SfSByC9xNqd2ydGVgkFoazbW21ccMvQ@mail.gmail.com>
	<522F4B07.4030004@gmail.com>
	<CAJHOUEM6VM=znCy=g1RaLZ2gMSJ8Wei3-aFKN4tw-BVvEHy8fQ@mail.gmail.com>
Message-ID: <52309822.5060403@gmail.com>

On 11/09/2013 11:44 AM, Andreas Maunz wrote:
> I am running Xvfb now with
>
> -fbdir /some/path and
> -extension RANDR
>
> but rgl.snapshot is still not working.
>
> Any other idea? Since I can display the webGL successfully in firefox 
> (so comes out correct), I assume there should be some way of 
> converting it on the server side to some (vector) graphic file format?

The .html file that writeWebGL produces could be considered to be that, 
but it's really mostly Javascript code, and I don't know anything other 
than a browser that can display it.  If you look at ?writeWebGL, you'll 
see links to various other ?write* files; they are all vector formats, 
but are all more limited than writeWebGL in what they can record.

Duncan Murdoch

>
> Thanks
> Andreas
>
>
>
> On Tue, Sep 10, 2013 at 6:38 PM, Duncan Murdoch 
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>
>     On 10/09/2013 10:58 AM, Andreas Maunz wrote:
>
>         Hi all,
>
>         I have a shiny app, in which I want to use rgl's snapshot
>         function. I am
>         running Xvfb on my server so that rgl works. I start my shiny
>         app as
>         follows:
>
>         echo "Checking for Xvfb..."
>         pgrep -U username Xvfb > /dev/null 2>&1
>
>         if [ "$?" -gt 0 ]; then
>            echo "Starting Xvfb..."
>            Xvfb :7 -screen 0 1280x1024x24 &
>            sleep 2
>         fi
>
>         echo "...starting shiny"
>         export DISPLAY=":7"; R --no-save --no-restore -e
>         "library('shiny');
>         runApp('/path/to/app', port=8101)"
>
>         In the app, I do plot3d(), generate webGL and send the results
>         to the
>         browser. But the rgl.snapshot or rgl.postscript functionality
>         do not work,
>         i.e. they produce black or empty images. I assume this is due
>         to Xvfb. Any
>         chance I can create snapshots?
>
>
>     rgl.snapshot requires the X server to maintain a frame buffer that
>     it can read.   It looks as though something is going wrong with
>     yours.  I don't use a system with Xvfb, so I can't really help,
>     but you could try Googling to see if that turns anything up.
>
>     rgl.postscript shouldn't need the X server, but it is limited in
>     what it can display.
>
>     Duncan Murdoch
>
>


From smartpink111 at yahoo.com  Wed Sep 11 19:29:22 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 11 Sep 2013 10:29:22 -0700 (PDT)
Subject: [R] Matrix mulitplication
In-Reply-To: <BLU170-W11403C0980D827C2107D98589390@phx.gbl>
References: <BLU170-W11403C0980D827C2107D98589390@phx.gbl>
Message-ID: <1378920562.39887.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
Try:


set.seed(445)
A<- matrix(sample(1:20,124*5,replace=TRUE),ncol=5)

set.seed(42)
B<- matrix(sample(1:25,12*5,replace=TRUE),ncol=5)
?res<- sapply(seq_len(nrow(A)),function(i) colSums(A[i,]*t(B)))

?dim(res)
#[1]? 12 124

A.K.



________________________________
From: eliza botto <eliza_botto at hotmail.com>
To: "smartpink111 at yahoo.com" <smartpink111 at yahoo.com> 
Sent: Wednesday, September 11, 2013 11:37 AM
Subject: 




Dear Arun,
Thanks for your previous reply. i have another question. if i have to matrix A and matrix B. matrix A is of dimension 124 row * 5 columns and B has a dimension of 12*5.?

What i want is to multiply each column of matrix B with each element of corresponding column A and then add.
more precisely

For Row 1 of A
A[1,1]*B[,1]+A[1,2]*B[,2]+A[1,3]*B[,3]+A[1,4]*B[,4]+A[1,5]*B[,5]


For Row 2 of A
A[2,1]*B[,1]+A[2,2]*B[,2]+A[2,3]*B[,3]+A[2,4]*B[,4]+A[2,5]*B[,5]

So in the end we should have a matrix of 12 rows and 124 columns.

I hope i m clear. if you feel any problem please tell me.

Eliza


From rune.haubo at gmail.com  Wed Sep 11 19:50:10 2013
From: rune.haubo at gmail.com (Rune Haubo)
Date: Wed, 11 Sep 2013 19:50:10 +0200
Subject: [R] Chi-square values in GLM model comparison
In-Reply-To: <CACm_P7qVGFSA_UAy=msC-Yu+qd=ts_zjv58cG2drwxaL1cXJUA@mail.gmail.com>
References: <CACm_P7rmmzvidDoO43YJ_0Q9=hm6G851WorN_5g2WbJDZTA6zQ@mail.gmail.com>
	<5F8EC5C77B9AE547A8959F690F04C7B2065F96@AGEPXMB006.uk.age.local>
	<CACm_P7qVGFSA_UAy=msC-Yu+qd=ts_zjv58cG2drwxaL1cXJUA@mail.gmail.com>
Message-ID: <CAG_uk90ZvYL3-5sWX0=iqaGY+H4xOO2MK160M5Lp8EOYOVvMYw@mail.gmail.com>

There is no argument 'test' to anova.clm hence the error message.

The likelihood ratio statistic (or, alternatively, G^2 statistic or
Deviance statistic) has an asymptotic chi-square distribution, so it
is the size of that statistic your reviewers are asking for. It is
printed in the anova output under the name 'LR.stat' (1252 on 8 df in
your case it seems).

Cheers,
Rune

On 11 September 2013 18:17, Torvon <torvon at gmail.com> wrote:
> Jos?,
>
> I get the following error message:
>
>> m1<-clm(sym_bin ~ phq_index, data=data2)
>> m2<-clm(sym_bin ~ 1, data=data2)
>> anova(m1,m2,test="Chisq")
>
>> Error in anova.clm(m1, m2, test = "Chisq") :
>>  only 'clm' and 'clmm' objects are allowed
>
> My dependent variable is binary, so I don't know what the problem could be.
> See below the model summaries. Thank you! Eiko
>
>> summary(m1)
> formula: sym_bin ~ phq_index
> data:    data2
>
>  link  threshold nobs  logLik   AIC     niter max.grad cond.H
>  logit flexible  12348 -4846.49 9710.97 7(0)  2.53e-08 1.4e+02
>
> Coefficients:
>            Estimate Std. Error z value Pr(>|z|)
> phq_index2 -0.29705    0.11954  -2.485    0.013 *
> phq_index3  0.63382    0.10262   6.176 6.56e-10 ***
> phq_index4  1.53022    0.09664  15.834  < 2e-16 ***
> phq_index5  0.90720    0.09996   9.075  < 2e-16 ***
> phq_index6 -0.03855    0.11337  -0.340    0.734
> phq_index7 -0.06488    0.11394  -0.569    0.569
> phq_index8 -1.15618    0.15156  -7.628 2.38e-14 ***
> phq_index9 -2.50064    0.25670  -9.741  < 2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Threshold coefficients:
>     Estimate Std. Error z value
> 0|1  1.87770    0.07959   23.59
>
>
>> summary(m2)
> formula: sym_bin ~ 1
> data:    data2
>
>  link  threshold nobs  logLik   AIC      niter max.grad
>  logit flexible  12348 -5472.48 10946.96 5(0)  1.01e-11
>
> Threshold coefficients:
>   0|1
> 1.642
>
>
>
>
>
>
>
> On 11 September 2013 18:03, Jose Iparraguirre <
> Jose.Iparraguirre at ageuk.org.uk> wrote:
>
>> Hi Eiko,
>>
>> How about this?
>>
>> > anova (m1, m2, test="Chisq")
>>
>> See: ?anova.glm
>>
>> Regards,
>> Jos?
>>
>>
>> Prof. Jos? Iparraguirre
>> Chief Economist
>> Age UK
>>
>>
>>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>> On Behalf Of Torvon
>> Sent: 11 September 2013 16:48
>> To: r-help at r-project.org
>> Subject: [R] Chi-square values in GLM model comparison
>>
>> Hello --
>> I am comparing two
>> GLMs (binomial dependent variable)
>> , the results are the following:
>> > m1<-glm(symptoms ~ phq_index, data=data2) m2<-glm(symptoms ~ 1,
>> > data=data2)
>>
>> Trying to compare these models using
>> > anova (m1, m2)
>> I do not obtain chi-square values or a chi-square difference test;
>> instead, I get loglikelihood ratios:
>>
>> > Likelihood ratio tests of cumulative link models:
>> > formula: link: threshold:
>> > m2 sym_bin ~ 1         logit flexible
>> > m1 sym_bin ~ phq_index logit flexible
>> >       no.par   AIC   logLik  LR.stat df Pr(>Chisq)
>> > m2      1    10947   -5472.5
>> > m1      9     9711   -4846.5    1252  8  < 2.2e-16 ***
>>
>> Since reviewers would like me to report chi-square values: how to I obtain
>> them when comparing GLMs? I'm looking for an output similar to the output
>> of the GLMER function in LME4, e.g.:
>>
>> > anova(m3,m4)
>> ...
>> >       Df   AIC   BIC  logLik Chisq Chi Df Pr(>Chisq)
>> > m3 13 11288 11393 -5630.9
>> > m4 21 11212 11382 -5584.9 92.02      8  < 2.2e-16 ***
>>
>> Thank you!
>>  Eiko
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> The Wireless from Age UK | Radio for grown-ups.
>>
>> www.ageuk.org.uk/thewireless
>>
>>
>> If you?re looking for a radio station that offers real variety, tune in to
>> The Wireless from Age UK.
>> Whether you choose to listen through the website at
>> www.ageuk.org.uk/thewireless, on digital radio (currently available in
>> London and Yorkshire) or through our TuneIn Radio app, you can look forward
>> to an inspiring mix of music, conversation and useful information 24 hours
>> a day.
>>
>>
>>
>>
>> -------------------------------
>> Age UK is a registered charity and company limited by guarantee,
>> (registered charity number 1128267, registered company number 6825798).
>> Registered office: Tavis House, 1-6 Tavistock Square, London WC1H 9NA.
>>
>> For the purposes of promoting Age UK Insurance, Age UK is an Appointed
>> Representative of Age UK Enterprises Limited, Age UK is an Introducer
>> Appointed Representative of JLT Benefit Solutions Limited and Simplyhealth
>> Access for the purposes of introducing potential annuity and health
>> cash plans customers respectively.  Age UK Enterprises Limited, JLT
>> Benefit Solutions Limited and Simplyhealth Access are all authorised and
>> regulated by the Financial Services Authority.
>> ------------------------------
>>
>> This email and any files transmitted with it are confidential and intended
>> solely for the use of the individual or entity to whom they are
>> addressed. If you receive a message in error, please advise the sender and
>> delete immediately.
>>
>> Except where this email is sent in the usual course of our business, any
>> opinions expressed in this email are those of the author and do not
>> necessarily reflect the opinions of Age UK or its subsidiaries and
>> associated companies. Age UK monitors all e-mail transmissions passing
>> through its network and may block or modify mails which are deemed to be
>> unsuitable.
>>
>> Age Concern England (charity number 261794) and Help the Aged (charity
>> number 272786) and their trading and other associated companies merged
>> on 1st April 2009.  Together they have formed the Age UK Group, dedicated
>> to improving the lives of people in later life.  The three national
>> Age Concerns in Scotland, Northern Ireland and Wales have also merged with
>> Help the Aged in these nations to form three registered charities:
>> Age Scotland, Age NI, Age Cymru.
>>
>>
>>
>>
>>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From marc_schwartz at me.com  Wed Sep 11 19:50:10 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 11 Sep 2013 12:50:10 -0500
Subject: [R] Chi-square values in GLM model comparison
In-Reply-To: <CACm_P7qVGFSA_UAy=msC-Yu+qd=ts_zjv58cG2drwxaL1cXJUA@mail.gmail.com>
References: <CACm_P7rmmzvidDoO43YJ_0Q9=hm6G851WorN_5g2WbJDZTA6zQ@mail.gmail.com>
	<5F8EC5C77B9AE547A8959F690F04C7B2065F96@AGEPXMB006.uk.age.local>
	<CACm_P7qVGFSA_UAy=msC-Yu+qd=ts_zjv58cG2drwxaL1cXJUA@mail.gmail.com>
Message-ID: <BC209985-1B45-4A08-A80F-02C86DEA85DC@me.com>

Torvon,

There is some confusion in your postings, as in your first posting the models were GLM's but with the default gaussian family (not binomial) since the 'family' argument was not present in the glm() call and in the second post you have references to clm() which is for ordinal response cumulative link models in the 'ordinal' CRAN package.

If you want binomial logistic regression models, you need to use:

  m1 <- glm(sym_bin ~ phq_index, data = data2, family = binomial)


As an example, using the ?infert dataset with a single IV:

MOD <- glm(case ~ education, data = infert, family = binomial)

> summary(MOD)

Call:
glm(formula = case ~ education, family = binomial, data = infert)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-0.9053  -0.9053  -0.9005   1.4765   1.4823  

Coefficients:
                   Estimate Std. Error z value Pr(>|z|)
(Intercept)      -6.931e-01  6.124e-01  -1.132    0.258
education6-11yrs  4.477e-15  6.423e-01   0.000    1.000
education12+ yrs  1.290e-02  6.431e-01   0.020    0.984

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 316.17  on 247  degrees of freedom
Residual deviance: 316.17  on 245  degrees of freedom
AIC: 322.17

Number of Fisher Scoring iterations: 4


> anova(MOD, test = "Chisq")
Analysis of Deviance Table

Model: binomial, link: logit

Response: case

Terms added sequentially (first to last)


          Df  Deviance Resid. Df Resid. Dev Pr(>Chi)
NULL                         247     316.17         
education  2 0.0022894       245     316.17   0.9989


Regards,

Marc Schwartz


On Sep 11, 2013, at 11:17 AM, Torvon <torvon at gmail.com> wrote:

> Jos?,
> 
> I get the following error message:
> 
>> m1<-clm(sym_bin ~ phq_index, data=data2)
>> m2<-clm(sym_bin ~ 1, data=data2)
>> anova(m1,m2,test="Chisq")
> 
>> Error in anova.clm(m1, m2, test = "Chisq") :
>> only 'clm' and 'clmm' objects are allowed
> 
> My dependent variable is binary, so I don't know what the problem could be.
> See below the model summaries. Thank you! Eiko
> 
>> summary(m1)
> formula: sym_bin ~ phq_index
> data:    data2
> 
> link  threshold nobs  logLik   AIC     niter max.grad cond.H
> logit flexible  12348 -4846.49 9710.97 7(0)  2.53e-08 1.4e+02
> 
> Coefficients:
>           Estimate Std. Error z value Pr(>|z|)
> phq_index2 -0.29705    0.11954  -2.485    0.013 *
> phq_index3  0.63382    0.10262   6.176 6.56e-10 ***
> phq_index4  1.53022    0.09664  15.834  < 2e-16 ***
> phq_index5  0.90720    0.09996   9.075  < 2e-16 ***
> phq_index6 -0.03855    0.11337  -0.340    0.734
> phq_index7 -0.06488    0.11394  -0.569    0.569
> phq_index8 -1.15618    0.15156  -7.628 2.38e-14 ***
> phq_index9 -2.50064    0.25670  -9.741  < 2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Threshold coefficients:
>    Estimate Std. Error z value
> 0|1  1.87770    0.07959   23.59
> 
> 
>> summary(m2)
> formula: sym_bin ~ 1
> data:    data2
> 
> link  threshold nobs  logLik   AIC      niter max.grad
> logit flexible  12348 -5472.48 10946.96 5(0)  1.01e-11
> 
> Threshold coefficients:
>  0|1
> 1.642
> 
> 
> 
> 
> 
> 
> 
> On 11 September 2013 18:03, Jose Iparraguirre <
> Jose.Iparraguirre at ageuk.org.uk> wrote:
> 
>> Hi Eiko,
>> 
>> How about this?
>> 
>>> anova (m1, m2, test="Chisq")
>> 
>> See: ?anova.glm
>> 
>> Regards,
>> Jos?
>> 
>> 
>> Prof. Jos? Iparraguirre
>> Chief Economist
>> Age UK
>> 
>> 
>> 
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>> On Behalf Of Torvon
>> Sent: 11 September 2013 16:48
>> To: r-help at r-project.org
>> Subject: [R] Chi-square values in GLM model comparison
>> 
>> Hello --
>> I am comparing two
>> GLMs (binomial dependent variable)
>> , the results are the following:
>>> m1<-glm(symptoms ~ phq_index, data=data2) m2<-glm(symptoms ~ 1,
>>> data=data2)
>> 
>> Trying to compare these models using
>>> anova (m1, m2)
>> I do not obtain chi-square values or a chi-square difference test;
>> instead, I get loglikelihood ratios:
>> 
>>> Likelihood ratio tests of cumulative link models:
>>> formula: link: threshold:
>>> m2 sym_bin ~ 1         logit flexible
>>> m1 sym_bin ~ phq_index logit flexible
>>>      no.par   AIC   logLik  LR.stat df Pr(>Chisq)
>>> m2      1    10947   -5472.5
>>> m1      9     9711   -4846.5    1252  8  < 2.2e-16 ***
>> 
>> Since reviewers would like me to report chi-square values: how to I obtain
>> them when comparing GLMs? I'm looking for an output similar to the output
>> of the GLMER function in LME4, e.g.:
>> 
>>> anova(m3,m4)
>> ...
>>>      Df   AIC   BIC  logLik Chisq Chi Df Pr(>Chisq)
>>> m3 13 11288 11393 -5630.9
>>> m4 21 11212 11382 -5584.9 92.02      8  < 2.2e-16 ***
>> 
>> Thank you!
>> Eiko


From petretta at unina.it  Wed Sep 11 19:51:16 2013
From: petretta at unina.it (petretta at unina.it)
Date: Wed, 11 Sep 2013 19:51:16 +0200
Subject: [R] meta-analysis of annualized event rate
Message-ID: <20130911195116.622620yqfe65v990@inbox.unina.it>

  r-help at r-project.org

Dear all,

I use R 2.15.2 for Windows 8

I ask if it is possible perform a meta-analysis of annualized event  
rate from several studies reporting

1) number of patients enrolled (N)
2) mean lenght of follow-up time (mo)
3) annualized event rate (AER) (expressed as % person-year)

I would like suggestions on package(s) and code.

Many thanks in advance.





-- 
Mario Petretta
Department of Translational Medical Sciences
Naples University Federico II
Italy


From isabella at ghement.ca  Wed Sep 11 19:51:18 2013
From: isabella at ghement.ca (isabella at ghement.ca)
Date: Wed, 11 Sep 2013 12:51:18 -0500
Subject: [R] How to split a plot into vertical subregions with width
	proportional to length of a character string?
Message-ID: <54184.1378921878@ghement.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130911/9dea7e3c/attachment.pl>

From robert.b.lynch at gmail.com  Wed Sep 11 19:53:08 2013
From: robert.b.lynch at gmail.com (Robert Lynch)
Date: Wed, 11 Sep 2013 10:53:08 -0700
Subject: [R] ggplot interactions
In-Reply-To: <CACYeG1gfjwh5TsiLNViVchQK7OY7-2c7AHNQdzcDraD2i8NuqQ@mail.gmail.com>
References: <CACYeG1gfjwh5TsiLNViVchQK7OY7-2c7AHNQdzcDraD2i8NuqQ@mail.gmail.com>
Message-ID: <CACYeG1go=9Giq2ChXn-m1h81qPmkSSjXspUJHM=XLg1LtHaXMw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130911/4c2f3c6a/attachment.pl>

From istazahn at gmail.com  Wed Sep 11 20:30:03 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 11 Sep 2013 14:30:03 -0400
Subject: [R] ggplot interactions
In-Reply-To: <CACYeG1go=9Giq2ChXn-m1h81qPmkSSjXspUJHM=XLg1LtHaXMw@mail.gmail.com>
References: <CACYeG1gfjwh5TsiLNViVchQK7OY7-2c7AHNQdzcDraD2i8NuqQ@mail.gmail.com>
	<CACYeG1go=9Giq2ChXn-m1h81qPmkSSjXspUJHM=XLg1LtHaXMw@mail.gmail.com>
Message-ID: <CA+vqiLFht4Q3k4U1ebGor80JkP=e1a7zkF+eh-BfkbPC_z3mYQ@mail.gmail.com>

Hi Robert,

It is really hard to follow this without the data or a reproducible
example. Also your attachments did not come through. Please read the
posting guide and re-formulate your question to make it easier to help
you. Finally, note that there is a separate ggplot2 mailing list at
https://groups.google.com/forum/?fromgroups#!forum/ggplot2

Best,
Ista

On Wed, Sep 11, 2013 at 1:53 PM, Robert Lynch <robert.b.lynch at gmail.com> wrote:
>> I am sorry to ask what I am sure is a simple question but I am stuck
>> trying to figure out how different parts of ggplot2 calls interact
>>
>> I am plotting using the following code
>>
>> ggplot(Chem.comp, aes(Course, GRADE)) + geom_boxplot(notch = TRUE,aes(fill
>> = COHORT))+
>>   labs(y ="Grade Points in class",
>>        x = "Chemistry 2 quarter") +
>>   ggtitle(expression(atop("Comparison between ISE cohorts and Peers",
>> atop(italic("in Chem 2 classes"), ""))))
>>   ylim(0,4.3333)+
>>   scale_fill_manual(name = "ISE Cohorts &\nComparison groups",
>>                     values =
>> c("blue","red","blue3","red3","blue4","red4")) +
>>   theme(plot.title = element_text(size = 25, face = "bold", colour =
>> "black", vjust = -1))+
>>   guides(fill = guide_legend(nrow = 3),byrow = TRUE)
>>
>> which gives me a plot [available as a jpeg, not attached due to size
>> limits]  which is has the appropriate title, but the colors and the legend
>> are wrong. The colors cycle through R's standard colors, and the legend is
>> 1 column.
>>
>> if I comment out the ggtitle() and theme(), or just ggtitle() I get a plot
>> [available, but not attached ue to size limits] which has the right colors
>> and mostly right legend, but no title and subtitle.  The legend is out of
>> order.  the first row should read ISE07 CMP07 with 08 on the second row and
>> 09 the third with a red column and a blue column.  Changing byrow = TRUE to
>> bycol = TRUE does not change the plotting of the legend nor does byrow=FALSE
>>
>> I am asking for help with getting the title and sub-title to both show up
>> at the same time as the appropriate colors for the different factor levels.
>> And to get the legend to render so that the legend looks sort of like
>> ISE07[red box]    [blue box   ]CMP07
>> ISE08 [red3 box] [blue3 box]CMP08
>> ISE09 [red4 box] [blue4 box]CMP09
>> the exact colors are not important but the the vertical
>> and horizontal alignment is.
>>
>> Thanks!
>> Robert
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From villarino.ernesto at gmail.com  Wed Sep 11 16:50:00 2013
From: villarino.ernesto at gmail.com (ernesto villarino)
Date: Wed, 11 Sep 2013 07:50:00 -0700 (PDT)
Subject: [R] include variable of a dataframe in other dataframe
In-Reply-To: <1378874103815-4675835.post@n4.nabble.com>
References: <1378764737354-4675730.post@n4.nabble.com>
	<1378874103815-4675835.post@n4.nabble.com>
Message-ID: <CAAmrVFr2fGJrMfOU++2KGz5sdL6Q0fF5_pneUADU22V+_NBDEQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130911/94a3b1b3/attachment.pl>

From fernanda_bonetti at hotmail.com  Wed Sep 11 21:32:55 2013
From: fernanda_bonetti at hotmail.com (Maria Fernanda Bonetti)
Date: Wed, 11 Sep 2013 19:32:55 +0000
Subject: [R] merge multi part polygons
Message-ID: <BLU180-W75108B8486C16299ACD980EA390@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130911/a18527aa/attachment.pl>

From jfrei006 at fiu.edu  Wed Sep 11 16:49:29 2013
From: jfrei006 at fiu.edu (jfrei006)
Date: Wed, 11 Sep 2013 07:49:29 -0700 (PDT)
Subject: [R] Running Loops
Message-ID: <1378910969676-4675886.post@n4.nabble.com>

I have a data set called yall with 5000 rows, I want to randomly sub sample
100 rows 100 times.
This is what I have so far:

yall<-read.csv("Z:\\SOFTEL\\North Key Largo
project\\Canopy_Height\\random_age_strat\\Young\\Abv2ft_young.csv")

*yall1 <- yall[sample(1:nrow(yall), 100, replace=FALSE),]

write.csv(yall1, file = "yall1.csv")*

I want to run a loop of the bold script above 100 times, but I want to be
able to change the name of the sub sample and name of the csv file each
time. They should be named yall1, yall2,yall3...etc until 100.



--
View this message in context: http://r.789695.n4.nabble.com/Running-Loops-tp4675886.html
Sent from the R help mailing list archive at Nabble.com.


From letterjaya at gmail.com  Wed Sep 11 20:08:53 2013
From: letterjaya at gmail.com (Jaya Pudashine)
Date: Thu, 12 Sep 2013 01:08:53 +0700
Subject: [R] About qmap package
Message-ID: <CAGja6kT8QWz8i2R_H1K1ecRNm=A-_Nx7t+K3Up-+-HkTCMjHSQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/bc9baad4/attachment.pl>

From gunter.berton at gene.com  Thu Sep 12 00:54:36 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 11 Sep 2013 15:54:36 -0700
Subject: [R] merge multi part polygons
In-Reply-To: <BLU180-W75108B8486C16299ACD980EA390@phx.gbl>
References: <BLU180-W75108B8486C16299ACD980EA390@phx.gbl>
Message-ID: <CACk-te0fYEQtYQZMJ5b+=gxK+b1Uw9o8hFpCps-psV=_HHtYNg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130911/3a33f35c/attachment.pl>

From harb at student.unimelb.edu.au  Thu Sep 12 01:06:50 2013
From: harb at student.unimelb.edu.au (Ben Harrison)
Date: Thu, 12 Sep 2013 09:06:50 +1000
Subject: [R] Subtracting elements of a vector from each other stepwise
In-Reply-To: <522FAFB4.907@gmail.com>
References: <CANTLroGb_R4HOgG5gNk9HCPaPX2=EZ_J_KLhYmRtLfLB+W-OAw@mail.gmail.com>	<1378847199.17716.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<loom.20130910T233603-460@post.gmane.org>
	<1378851844.80715.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<522FAFB4.907@gmail.com>
Message-ID: <5230F78A.2030600@student.unimelb.edu.au>

If I were Michael (OP) right now, I think my head would be spinning.

As a newbie myself, I know how hard it is to read R code for the first 
time, so could it also be part of the newsgroup etiquette to at least 
partially explain provided code to newbies?

I agree that the interactive help '?' is available and should be 
consulted, but it would also be helpful if those of you with great 
experience could add a little guidance for your code.

Excuse me if this is out-of-place.

Ben


On 11/09/13 09:48, Ben Bolker wrote:
> On 13-09-10 06:24 PM, arun wrote:
>> Hi,
>> May be this also works:
>>
>>   dist(x)
>> #   1  2  3
>> #2  2
>> #3  6  4
>> #4 12 10  6
>>
>> as.matrix(dist(x))
>> #   1  2 3  4
>> #1  0  2 6 12
>> #2  2  0 4 10
>> #3  6  4 0  6
>> #4 12 10 6  0
>> which(dist(x)==min(dist(x)))
>> #[1] 1
>> A.K.
>
>    Yes, but you need to set the diagonal to NA, or something -- the OP
> doesn't want to include self-comparison. It also helps to use
> arr.ind=TRUE in which().  You're right that dist() would be a hair more
> efficient that outer(...), though
>
>>
>>
>>
>> ----- Original Message -----
>> From: Ben Bolker <bbolker at gmail.com>
>> To: r-help at stat.math.ethz.ch
>> Cc:
>> Sent: Tuesday, September 10, 2013 5:39 PM
>> Subject: Re: [R] Subtracting elements of a vector from each other stepwise
>>
>> arun <smartpink111 <at> yahoo.com> writes:
>>
>>>
>>> Hi,
>>> Not sure this is what you wanted:
>>>
>>>   sapply(seq_along(x), function(i) {x1<- x[i]; x2<- x[-i];
>> x3<-x2[which.min(abs(x1-x2))];c(x1,x3)})
>>> #     [,1] [,2] [,3] [,4]
>>> #[1,]   17   19   23   29
>>> #[2,]   19   17   19   23
>>> A.K.
>>
>>
>>    It's a little inefficient (because it constructs
>> the distances in both directions), but how about:
>>
>> x = c(17,19,23,29)
>> d <- abs(outer(x,x,"-"))
>> diag(d) <- NA
>> d[lower.tri(d)] <- NA
>> which(d==min(d,na.rm=TRUE),arr.ind=TRUE)
>>
>>
>> ?
>>
>>> ----- Original Message -----
>>> From: Michael Budnick <mbudnick08 <at> snet.net>
>>> To: r-help <at> r-project.org
>>> Cc:
>>> Sent: Tuesday, September 10, 2013 4:06 PM
>>> Subject: [R] Subtracting elements of a vector from each other stepwise
>>>
>>> I am trying to figure out how to create a loop that will take the
>>> difference of each member of a vector from each other and also spit out
>>> which one has the least difference.
>>>
>>> I do not want the vector member to subtract from itself or it must be able
>>> to disregard the 0 obtained from subtracting from itself.
>>>
>>> For example:
>>>
>>> x = c(17,19,23,29)
>>
>>
>> [snip]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From harb at student.unimelb.edu.au  Thu Sep 12 01:06:50 2013
From: harb at student.unimelb.edu.au (Ben Harrison)
Date: Thu, 12 Sep 2013 09:06:50 +1000
Subject: [R] Subtracting elements of a vector from each other stepwise
In-Reply-To: <522FAFB4.907@gmail.com>
References: <CANTLroGb_R4HOgG5gNk9HCPaPX2=EZ_J_KLhYmRtLfLB+W-OAw@mail.gmail.com>	<1378847199.17716.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<loom.20130910T233603-460@post.gmane.org>
	<1378851844.80715.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<522FAFB4.907@gmail.com>
Message-ID: <5230F78A.2030600@student.unimelb.edu.au>

If I were Michael (OP) right now, I think my head would be spinning.

As a newbie myself, I know how hard it is to read R code for the first 
time, so could it also be part of the newsgroup etiquette to at least 
partially explain provided code to newbies?

I agree that the interactive help '?' is available and should be 
consulted, but it would also be helpful if those of you with great 
experience could add a little guidance for your code.

Excuse me if this is out-of-place.

Ben


On 11/09/13 09:48, Ben Bolker wrote:
> On 13-09-10 06:24 PM, arun wrote:
>> Hi,
>> May be this also works:
>>
>>   dist(x)
>> #   1  2  3
>> #2  2
>> #3  6  4
>> #4 12 10  6
>>
>> as.matrix(dist(x))
>> #   1  2 3  4
>> #1  0  2 6 12
>> #2  2  0 4 10
>> #3  6  4 0  6
>> #4 12 10 6  0
>> which(dist(x)==min(dist(x)))
>> #[1] 1
>> A.K.
>
>    Yes, but you need to set the diagonal to NA, or something -- the OP
> doesn't want to include self-comparison. It also helps to use
> arr.ind=TRUE in which().  You're right that dist() would be a hair more
> efficient that outer(...), though
>
>>
>>
>>
>> ----- Original Message -----
>> From: Ben Bolker <bbolker at gmail.com>
>> To: r-help at stat.math.ethz.ch
>> Cc:
>> Sent: Tuesday, September 10, 2013 5:39 PM
>> Subject: Re: [R] Subtracting elements of a vector from each other stepwise
>>
>> arun <smartpink111 <at> yahoo.com> writes:
>>
>>>
>>> Hi,
>>> Not sure this is what you wanted:
>>>
>>>   sapply(seq_along(x), function(i) {x1<- x[i]; x2<- x[-i];
>> x3<-x2[which.min(abs(x1-x2))];c(x1,x3)})
>>> #     [,1] [,2] [,3] [,4]
>>> #[1,]   17   19   23   29
>>> #[2,]   19   17   19   23
>>> A.K.
>>
>>
>>    It's a little inefficient (because it constructs
>> the distances in both directions), but how about:
>>
>> x = c(17,19,23,29)
>> d <- abs(outer(x,x,"-"))
>> diag(d) <- NA
>> d[lower.tri(d)] <- NA
>> which(d==min(d,na.rm=TRUE),arr.ind=TRUE)
>>
>>
>> ?
>>
>>> ----- Original Message -----
>>> From: Michael Budnick <mbudnick08 <at> snet.net>
>>> To: r-help <at> r-project.org
>>> Cc:
>>> Sent: Tuesday, September 10, 2013 4:06 PM
>>> Subject: [R] Subtracting elements of a vector from each other stepwise
>>>
>>> I am trying to figure out how to create a loop that will take the
>>> difference of each member of a vector from each other and also spit out
>>> which one has the least difference.
>>>
>>> I do not want the vector member to subtract from itself or it must be able
>>> to disregard the 0 obtained from subtracting from itself.
>>>
>>> For example:
>>>
>>> x = c(17,19,23,29)
>>
>>
>> [snip]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From harb at student.unimelb.edu.au  Thu Sep 12 01:10:27 2013
From: harb at student.unimelb.edu.au (Ben Harrison)
Date: Thu, 12 Sep 2013 09:10:27 +1000
Subject: [R] Need to learn or get R tutor in Minneapolis
In-Reply-To: <Gophermail.2.0.1309091545340.10317@vs-w.tc.umn.edu>
References: <Gophermail.2.0.1309091545340.10317@vs-w.tc.umn.edu>
Message-ID: <5230F863.9020309@student.unimelb.edu.au>

On 10/09/13 06:45, sewal026 at umn.edu wrote:
> Please advise
>

Can't help you in Minneapolis, though surely your university has a 
statistics department?

To learn R there are many online tutorials and video guides. The latest 
is a large collection from the Google developers:
http://www.youtube.com/playlist?list=PLOU2XLYxmsIK9qQfztXeybpHvru-TrqAP

It's called Intro to R, and it currently has 21 videos.

Good luck,
Ben.


From harb at student.unimelb.edu.au  Thu Sep 12 01:10:27 2013
From: harb at student.unimelb.edu.au (Ben Harrison)
Date: Thu, 12 Sep 2013 09:10:27 +1000
Subject: [R] Need to learn or get R tutor in Minneapolis
In-Reply-To: <Gophermail.2.0.1309091545340.10317@vs-w.tc.umn.edu>
References: <Gophermail.2.0.1309091545340.10317@vs-w.tc.umn.edu>
Message-ID: <5230F863.9020309@student.unimelb.edu.au>

On 10/09/13 06:45, sewal026 at umn.edu wrote:
> Please advise
>

Can't help you in Minneapolis, though surely your university has a 
statistics department?

To learn R there are many online tutorials and video guides. The latest 
is a large collection from the Google developers:
http://www.youtube.com/playlist?list=PLOU2XLYxmsIK9qQfztXeybpHvru-TrqAP

It's called Intro to R, and it currently has 21 videos.

Good luck,
Ben.


From jim at bitwrit.com.au  Thu Sep 12 01:26:18 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 12 Sep 2013 09:26:18 +1000
Subject: [R] How to split a plot into vertical subregions with
 width	proportional to length of a character string?
In-Reply-To: <54184.1378921878@ghement.ca>
References: <54184.1378921878@ghement.ca>
Message-ID: <5230FC1A.5040200@bitwrit.com.au>

On 09/12/2013 03:51 AM, isabella at ghement.ca wrote:
>
>
> 	BODY { font-family:Arial, Helvetica, sans-serif;font-size:12px;
> }Hello,
>
> 	I am trying to create a plot whose x-axis is wide enough to
> accommodate the following:
>
> 	a) a character string on the left side (i.e., Text 1);
>   b) a known range of values in the middle (i.e., Range);
>   c) a character string on the right side (i.e., Label 2)
>
> 	The plot would start with the range of values in the middle and would
> be expanded to the left and right by a width proportional to the
> length of Text 1 and Label 2, respectively.  (The width would need to
> be expressed in the same units as those of the middle range of
> values.)
>
> 	In R, how can I determine the width of Text 1 and Label 2 and express
> it in the same units as those pertaining to Range?  (I know how to
> determine the width of these character strings in inches for a given
> plot via strwidth(), but for some reason I am not able to connect that
> width to the units of Range.)
>
> 	Here is some R code illustrating what the plot would look like:
>   plot(NA, xlim=c(1,10), ylim=c(1,5),type="N")
>   abline(v=1,lty=2,col="red")
>   abline(v=2,lty=2,col="red")
>   abline(v=8,lty=3,col="blue")
>   abline(v=10,lty=3,col="blue")
>   text(1,3,"Text 1",pos=4)
>   text(8,3,"Label 2",pos=4)
>   arrows(2,3,8,3,code=3, length=0.1,lwd=2)
>   text(5,3,"Range",pos=3)

Hi Isabella,
Your illustration is helpful, but there are a couple of things that I 
will have to guess. The first is that you want the usual margins around 
the plot, and the second is that the outer vertical lines on your 
illustration are the "x" limits {par(usr[1:2])} of the plot. What you 
have is a fairly simple algebra problem.

xrange = stringwidth1 + xlim + stringwidth2

Using the default plotting device on my setup:

xrange = 5.76 in.
stringwidth1 = 0.457 in.
stringwidth2 = 0.551 in.

Therefore xlim must fit into:

5.76 - 1.008 = 4.75 in.

Say your xlim (in user units) is 1 to 10. This means that the xlim 
passed to the plot command must be:

10 * 5.76/4.75 = 12.13

or if you want the default .04 padding on either side:

10.08 * 5.76/4.75 = 12.23

Having discovered this, you can now plot with:

xlim<-c(1 - 2.13 * 0.457/1.008,10 + 2.13 * 0.551/1.008)
plot(1:10,1:10,xlim=xlim,xaxt="n")
axis(1,at=1:10)
text(xlim[1],5,"Text 1")
text(xlim[2],5,"Label 2",adj=1)

So in general, plot without the strings with the full x range, then 
adjust for the strings, then plot again.

You will probably want to fiddle with the padding and text adjustments.

Jim


From mrahmankufmrt at gmail.com  Thu Sep 12 02:30:51 2013
From: mrahmankufmrt at gmail.com (Moshiur Rahman)
Date: Thu, 12 Sep 2013 08:30:51 +0800
Subject: [R] Bar plot help
Message-ID: <CAGNSkSkoCtkPeAntFmbY4YqZjyW-hObUgV7Z5fKHNBpQ0+nmOw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/d2bca6c2/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Thu Sep 12 02:48:17 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 11 Sep 2013 17:48:17 -0700
Subject: [R] Subtracting elements of a vector from each other stepwise
In-Reply-To: <5230F78A.2030600@student.unimelb.edu.au>
References: <CANTLroGb_R4HOgG5gNk9HCPaPX2=EZ_J_KLhYmRtLfLB+W-OAw@mail.gmail.com>
	<1378847199.17716.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<loom.20130910T233603-460@post.gmane.org>
	<1378851844.80715.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<522FAFB4.907@gmail.com> <5230F78A.2030600@student.unimelb.edu.au>
Message-ID: <1c4a6d5b-7012-45f4-ac43-cc3914c06ac7@email.android.com>

It is worth asking for clarification sometimes, but I have to admit that I don't have much sympathy in this case because there isn't much code involved and typing in the code (or copy/pasting it line-by-line) and experimenting with it is crucial to the process of learning R. Picking out one expression at a time from each line and looking at the result with the str function is really how you have to do it. That is why responders on this list so often ask for reproducible examples from the questioner... the answer can be much more compact and quick to generate.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Ben Harrison <harb at student.unimelb.edu.au> wrote:
>If I were Michael (OP) right now, I think my head would be spinning.
>
>As a newbie myself, I know how hard it is to read R code for the first 
>time, so could it also be part of the newsgroup etiquette to at least 
>partially explain provided code to newbies?
>
>I agree that the interactive help '?' is available and should be 
>consulted, but it would also be helpful if those of you with great 
>experience could add a little guidance for your code.
>
>Excuse me if this is out-of-place.
>
>Ben
>
>
>On 11/09/13 09:48, Ben Bolker wrote:
>> On 13-09-10 06:24 PM, arun wrote:
>>> Hi,
>>> May be this also works:
>>>
>>>   dist(x)
>>> #   1  2  3
>>> #2  2
>>> #3  6  4
>>> #4 12 10  6
>>>
>>> as.matrix(dist(x))
>>> #   1  2 3  4
>>> #1  0  2 6 12
>>> #2  2  0 4 10
>>> #3  6  4 0  6
>>> #4 12 10 6  0
>>> which(dist(x)==min(dist(x)))
>>> #[1] 1
>>> A.K.
>>
>>    Yes, but you need to set the diagonal to NA, or something -- the
>OP
>> doesn't want to include self-comparison. It also helps to use
>> arr.ind=TRUE in which().  You're right that dist() would be a hair
>more
>> efficient that outer(...), though
>>
>>>
>>>
>>>
>>> ----- Original Message -----
>>> From: Ben Bolker <bbolker at gmail.com>
>>> To: r-help at stat.math.ethz.ch
>>> Cc:
>>> Sent: Tuesday, September 10, 2013 5:39 PM
>>> Subject: Re: [R] Subtracting elements of a vector from each other
>stepwise
>>>
>>> arun <smartpink111 <at> yahoo.com> writes:
>>>
>>>>
>>>> Hi,
>>>> Not sure this is what you wanted:
>>>>
>>>>   sapply(seq_along(x), function(i) {x1<- x[i]; x2<- x[-i];
>>> x3<-x2[which.min(abs(x1-x2))];c(x1,x3)})
>>>> #     [,1] [,2] [,3] [,4]
>>>> #[1,]   17   19   23   29
>>>> #[2,]   19   17   19   23
>>>> A.K.
>>>
>>>
>>>    It's a little inefficient (because it constructs
>>> the distances in both directions), but how about:
>>>
>>> x = c(17,19,23,29)
>>> d <- abs(outer(x,x,"-"))
>>> diag(d) <- NA
>>> d[lower.tri(d)] <- NA
>>> which(d==min(d,na.rm=TRUE),arr.ind=TRUE)
>>>
>>>
>>> ?
>>>
>>>> ----- Original Message -----
>>>> From: Michael Budnick <mbudnick08 <at> snet.net>
>>>> To: r-help <at> r-project.org
>>>> Cc:
>>>> Sent: Tuesday, September 10, 2013 4:06 PM
>>>> Subject: [R] Subtracting elements of a vector from each other
>stepwise
>>>>
>>>> I am trying to figure out how to create a loop that will take the
>>>> difference of each member of a vector from each other and also spit
>out
>>>> which one has the least difference.
>>>>
>>>> I do not want the vector member to subtract from itself or it must
>be able
>>>> to disregard the 0 obtained from subtracting from itself.
>>>>
>>>> For example:
>>>>
>>>> x = c(17,19,23,29)
>>>
>>>
>>> [snip]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From rlall at health.nyc.gov  Wed Sep 11 23:05:26 2013
From: rlall at health.nyc.gov (Ramona Lall)
Date: Wed, 11 Sep 2013 21:05:26 +0000
Subject: [R] how to allocate more memory?
Message-ID: <291F96371FCD954CBE1D512714A706B72A7DAA7B@XCHGMBX1.health.dohmh.nycnet>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130911/bd68a373/attachment.pl>

From smartpink111 at yahoo.com  Thu Sep 12 04:10:47 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 11 Sep 2013 19:10:47 -0700 (PDT)
Subject: [R] Combining information from two matrices
Message-ID: <1378951847.32442.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,

May be this helps:
mat1<- matrix(c(1,1,0,0,0,1,0,1,0),ncol=3,dimnames=list(paste("Plant",1:3), paste("Pollinator",1:3)),byrow=TRUE)
?mat2<- matrix(c(1,1,0,1,0,1,0,1,0),ncol=3,dimnames=list(paste("Plant",c(1,4,5)), paste("Pollinator",c(1,2,4))),byrow=TRUE)
dat1<- as.data.frame(mat1)
?dat2<- as.data.frame(mat2)
toadddat1<-setdiff(colnames(dat2),colnames(dat1))
toadddat2<-setdiff(colnames(dat1),colnames(dat2))
dat2[,evalq(toadddat2)]<-0
res<- as.matrix(dat2[!row.names(dat1)%in% row.names(dat2),!colnames(dat2)%in%evalq(toadddat1)] )
res
#??????? Pollinator 1 Pollinator 2 Pollinator 3
#Plant 4??????????? 1??????????? 0??????????? 0
#Plant 5??????????? 0??????????? 1??????????? 0
A.K.





Hello all 
I have been trying to find a solution for this for a while, and I hope you can help me. 
I have two matrices. Both are interaction matrices between plants 
and pollinators, and have plants as rows and pollinators as columns. The
 matrix is a presence/absence matrix with 1?s for interaction and 0?s 
for no interaction. Here are simplified examples: 

Matrix 1: 
? ? ? ? ? ? ?Pollinator 1 ? ? Pollinator 2 ? ? Pollinator 3 
Plant 1 ? ? ? ? ?1 ? ? ? ? ? ? ? ? ? 1 ? ? ? ? ? ? ? ? ?0 
Plant 2 ? ? ? ? ?0 ? ? ? ? ? ? ? ? ? 0 ? ? ? ? ? ? ? ? ?1 
Plant 3 ? ? ? ? ?0 ? ? ? ? ? ? ? ? ? 1 ? ? ? ? ? ? ? ? ?0 

Matrix 2: 
? ? ? ? ? ? ?Pollinator 1 ? ? Pollinator 2 ? ? Pollinator 4 
Plant 1 ? ? ? ? ?1 ? ? ? ? ? ? ? ? ? 1 ? ? ? ? ? ? ? ? ?0 
Plant 4 ? ? ? ? ?1 ? ? ? ? ? ? ? ? ? 0 ? ? ? ? ? ? ? ? ?1 
Plant 5 ? ? ? ? ?0 ? ? ? ? ? ? ? ? ? 1 ? ? ? ? ? ? ? ? ?0 

What I need is to make a new matrix with the columns 
(pollinators) from matrix 1 and the rows (plants) and entries from 
matrix 2, but only with those rows that are not in matrix 1. Like this: 

? ? ? ? ? ? Pollinator 1 ? ? Pollinator 2 ? ? Pollinator 3 
Plant 4 ? ? ? ? ?1 ? ? ? ? ? ? ? ? ? 0 ? ? ? ? ? ? ? ? ?0 
Plant 5 ? ? ? ? ?0 ? ? ? ? ? ? ? ? ? 1 ? ? ? ? ? ? ? ? ?0 

Hope you can help. Thanks a lot in advance. 
Daniel


From arrayprofile at yahoo.com  Thu Sep 12 07:33:00 2013
From: arrayprofile at yahoo.com (array chip)
Date: Wed, 11 Sep 2013 22:33:00 -0700 (PDT)
Subject: [R] sparse PCA using nsprcomp package
In-Reply-To: <B3CEEAEB-8F09-4D1F-A54B-A0C40280B680@sigg-iten.ch>
References: <1378370274.8239.YahooMailNeo@web122906.mail.ne1.yahoo.com>
	<1378400566.3566.YahooMailNeo@web122904.mail.ne1.yahoo.com>
	<F45A74BC-D9F5-47AC-85B4-0391F0C6D3CF@sigg-iten.ch>
	<1378424502.93780.YahooMailNeo@web122906.mail.ne1.yahoo.com>
	<B3CEEAEB-8F09-4D1F-A54B-A0C40280B680@sigg-iten.ch>
Message-ID: <1378963980.47246.YahooMailNeo@web122903.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130911/125a9342/attachment.pl>

From dwinsemius at comcast.net  Thu Sep 12 08:00:08 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 12 Sep 2013 02:00:08 -0400
Subject: [R] how to allocate more memory?
In-Reply-To: <291F96371FCD954CBE1D512714A706B72A7DAA7B@XCHGMBX1.health.dohmh.nycnet>
References: <291F96371FCD954CBE1D512714A706B72A7DAA7B@XCHGMBX1.health.dohmh.nycnet>
Message-ID: <04BF83AA-C320-4BFC-91A2-B91CB6970528@comcast.net>


On Sep 11, 2013, at 5:05 PM, Ramona Lall wrote:

> Hello all,
>
> I am running mixed model on a large dataset and I get the following  
> warning messages:
> "Reached total allocation of 1535Mb: see help(memory.size)"
> and
> "Calloc could not allocate memory (705648 of 8 bytes)"
>
> How do I get around this?

You should describe your situation in greater detail. Consult the  
Posting Guide for specifics.

-- 

David Winsemius, MD
Alameda, CA, USA


From gunter.berton at gene.com  Thu Sep 12 08:23:04 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 11 Sep 2013 23:23:04 -0700
Subject: [R] Combining information from two matrices
In-Reply-To: <1378951847.32442.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1378951847.32442.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <CACk-te0UQZC4fxXHVbHzngqO6kOiK_2jUZ541F3DPx-6ZAKHAQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130911/3c9cfbcf/attachment.pl>

From ripley at stats.ox.ac.uk  Thu Sep 12 08:58:38 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 12 Sep 2013 07:58:38 +0100
Subject: [R] how to allocate more memory?
In-Reply-To: <04BF83AA-C320-4BFC-91A2-B91CB6970528@comcast.net>
References: <291F96371FCD954CBE1D512714A706B72A7DAA7B@XCHGMBX1.health.dohmh.nycnet>
	<04BF83AA-C320-4BFC-91A2-B91CB6970528@comcast.net>
Message-ID: <5231661E.6050504@stats.ox.ac.uk>

On 12/09/2013 07:00, David Winsemius wrote:
>
> On Sep 11, 2013, at 5:05 PM, Ramona Lall wrote:
>
>> Hello all,
>>
>> I am running mixed model on a large dataset and I get the following
>> warning messages:
>> "Reached total allocation of 1535Mb: see help(memory.size)"
>> and
>> "Calloc could not allocate memory (705648 of 8 bytes)"
>>
>> How do I get around this?
>
> You should describe your situation in greater detail. Consult the
> Posting Guide for specifics.
>
Indeed, but (s)he is on Windows and this is covered in the rw-FAQ at 
http://cran.r-project.org/bin/windows/base/rw-FAQ.html (also mentioned 
in the posting guide).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tcmuigai at gmail.com  Thu Sep 12 09:15:52 2013
From: tcmuigai at gmail.com (Charles Thuo)
Date: Thu, 12 Sep 2013 10:15:52 +0300
Subject: [R] how to retain dimnames while exporting from excel into r
Message-ID: <CAAJc=rPEhLEP20dqyiwBamCi3Q3qxwoHf_vH56MHbupAAr5i6w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/4fb994dc/attachment.pl>

From petr.pikal at precheza.cz  Thu Sep 12 09:34:23 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 12 Sep 2013 07:34:23 +0000
Subject: [R] Running Loops
In-Reply-To: <1378910969676-4675886.post@n4.nabble.com>
References: <1378910969676-4675886.post@n4.nabble.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B91950@SRVEXCHMBX.precheza.cz>

Hi

Why not use loops

something like 

lll<-vector("list", 100)
for (i in 1:100) lll[[i]] <- yall[sample(1:nrow(yall), 100, replace=FALSE),]
for(i in 1:100) write.csv(lll[[i]], file = paste("yall",i, sep=""))

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of jfrei006
> Sent: Wednesday, September 11, 2013 4:49 PM
> To: r-help at r-project.org
> Subject: [R] Running Loops
> 
> I have a data set called yall with 5000 rows, I want to randomly sub
> sample 100 rows 100 times.
> This is what I have so far:
> 
> yall<-read.csv("Z:\\SOFTEL\\North Key Largo
> project\\Canopy_Height\\random_age_strat\\Young\\Abv2ft_young.csv")
> 
> *yall1 <- yall[sample(1:nrow(yall), 100, replace=FALSE),]
> 
> write.csv(yall1, file = "yall1.csv")*
> 
> I want to run a loop of the bold script above 100 times, but I want to
> be able to change the name of the sub sample and name of the csv file
> each time. They should be named yall1, yall2,yall3...etc until 100.
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Running-
> Loops-tp4675886.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Gerrit.Eichner at math.uni-giessen.de  Thu Sep 12 09:53:30 2013
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Thu, 12 Sep 2013 09:53:30 +0200 (MEST)
Subject: [R] Formula in a model
In-Reply-To: <1378909614.12435.YahooMailNeo@web125404.mail.ne1.yahoo.com>
References: <1378883051.43820.YahooMailNeo@web125405.mail.ne1.yahoo.com>
	<Pine.SOC.4.64.1309111142530.6509@solcom.hrz.uni-giessen.de> 
	<1378909614.12435.YahooMailNeo@web125404.mail.ne1.yahoo.com>
Message-ID: <Pine.SOC.4.64.1309120904570.21205@solcom.hrz.uni-giessen.de>

Hello, Paulito,

my comments are inline below:

> Thanks for the explanation. Let me give a specific example. Assume Temp 
> (column 4) is the output and the rest of the columns are input is the 
> training features. Note that I only use the air quality data for 
> illustration purpose. T input->output mapping may not make sense in the 
> real interpretation of this data.
>
> library(e1071)
>
> data(airquality)
> mytable=airquality
>
> colnames(mytable)=c('a','b','c','d','e','f')
>
> modelSVM1=svm(mytable[,6] ~ .,data=mytable)
> modelSVM2=svm(mytable[,-6],mytable[,6])
> modelSVM3=svm(f ~ ., data=mytable)
>
> predSVM1=predict(modelSVM1,newdata=mytable)
> predSVM2=predict(modelSVM2,newdata=mytable[,-6])
> predSVM3=predict(modelSVM3,newdata=mytable)
>
> Results of predSVM2 is similar with predSVM3 ?but different from?predSVM1.

Well, because already modelSVM1 is different from the other two. This is 
due to how the "." on the rhs of a formula is interpreted. From the help 
page of formula:

 	"There are two special interpretations of . in a formula. The
 	usual one is in the context of a data argument of model fitting
 	functions and means 'all columns not otherwise in the formula':
 	see terms.formula. In the context of update.formula, only, it
 	means 'what was previously in this part of the formula'."

The first interpretation applies to your situation. With the formula for 
your modelSVM1 the function model.matrix() (which is called inside the 
formula version of svm()) creates a model matrix after looking for a 
column "mytable[,6]" in the data argument. And since there is no column 
with that name, it takes all columns of mytable (including the 6th, i.e., 
the one named "f"). See what model.matrix() does in that case:

> head( model.matrix(mytable[,6] ~ .,data=mytable), 3)
   (Intercept)  a   b    c  d e f
1           1 41 190  7.4 67 5 1
2           1 36 118  8.0 72 5 2
3           1 12 149 12.6 74 5 3



In the case of modelSVM3 model.matrix() does find column "f" in the data 
argument, and hence omits this column in forming the terms of the rhs of 
the formula:

> head( model.matrix( f ~ .,data=mytable), 3)
   (Intercept)  a   b    c  d e
1           1 41 190  7.4 67 5
2           1 36 118  8.0 72 5
3           1 12 149 12.6 74 5



The call to svm() for modelSVM2 is the (non-formula) default version and 
does not need to call model.matrix() because (so to say) it expects that 
the user has done that already by supplying the response to its argument y 
and the adequately formed data matrix to its argument x.


> Question: Which is the correct formulation?

The second and the third (for a sensible purpose), unless you want to 
experiment with svm() to see what happens if one does something rather 
nonsensical.


> Why R doesn't detect error/discrepancy in formulation?

Because R, or in this case rather the concept of a formula and the 
function model.matrix() are not designed to replace the user who knows 
what s/he is doing after having read the documentation. ;)



> If I use the same formulation with rpart using the same data:
>
> library(rpart)
>
> data(airquality)
> mytable=airquality
>
> colnames(mytable)=c('a','b','c','d','e','f')
>
> modelRP1=rpart(mytable[,6]~.,data=mytable,method='anova') # this works
> modelRP3=rpart(f ~ ., data=mytable,method='anova') # this works
>
> predRP1=predict(modelRP1,newdata=mytable)
> predRP3=predict(modelRP3,newdata=mytable)
>
>
> The results between predRP1 and predRP3 are different while the statements:
>
> predRP2=predict(modelRP2,newdata=mytable[,-6])
> modelRP2=rpart(mytable[,-6],mytable[,6],method='anova')?
>
> have errors.

This is presumably due to the same reasons as described above.


Remark: It is generally - for various reasons - recommended to use "<-" as 
the assignment operator, not "=". (And I like to recommend to use use 
blanks to increase readability of code.)

[... snip ...]


  I hope the fog has lifted  --  Gerrit

From babuawara at gmail.com  Thu Sep 12 09:34:15 2013
From: babuawara at gmail.com (vikram ranga)
Date: Thu, 12 Sep 2013 13:04:15 +0530
Subject: [R] Fwd: how to retain dimnames while exporting from excel into r
In-Reply-To: <CAL-ALVHBNgonXYTgHPsNWaoYA9fJfaBigrX15HFK=81Mv4gUtA@mail.gmail.com>
References: <CAAJc=rPEhLEP20dqyiwBamCi3Q3qxwoHf_vH56MHbupAAr5i6w@mail.gmail.com>
	<CAL-ALVHBNgonXYTgHPsNWaoYA9fJfaBigrX15HFK=81Mv4gUtA@mail.gmail.com>
Message-ID: <CAL-ALVEJgvYe1Ok7FKS6o2rDmrpT91-o92s6SjDkLaUuj1VsLQ@mail.gmail.com>

---------- Forwarded message ----------
From: vikram ranga <babuawara at gmail.com>
Date: Thu, Sep 12, 2013 at 1:02 PM
Subject: Re: [R] how to retain dimnames while exporting from excel into r
To: Charles Thuo <tcmuigai at gmail.com>


On Thu, Sep 12, 2013 at 12:45 PM, Charles Thuo <tcmuigai at gmail.com> wrote:
>  v<- read.csv(file="sales.csv",header=TRUE)
>  v
>
Is it possible to share the file? because the code looks fine
>
> i get an output whose column names are V1,V2, and so on but i would like to
> retain the original column names such as january through to december.
>
> Charles.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bt_jannis at yahoo.de  Thu Sep 12 13:46:58 2013
From: bt_jannis at yahoo.de (Jannis)
Date: Thu, 12 Sep 2013 13:46:58 +0200
Subject: [R] substituting string variable in expression with its value
Message-ID: <5231A9B2.2020209@yahoo.de>

Hi,


the following code works:

plot(1,1, main=expression(paste("speed [", m * s^{-1}, "]")))


I would, however, like to be able to supply the value "speed" and 
m*s^{-a} by variables, e.g. do something like:


a = 'speed'
b = 'm*s^{-2}'

plot(1,1, main=expression(paste(a, " [", b, "]")))

This, however, does not work as a and b are not treated as variable 
names in this case. Does anyone have a solution for this?


Cheers
jannis


From pmilin at gmail.com  Thu Sep 12 14:11:11 2013
From: pmilin at gmail.com (Petar Milin)
Date: Thu, 12 Sep 2013 14:11:11 +0200
Subject: [R] Getting "Approximate Estimates after Deleting Factors" out from
	fastbw()
Message-ID: <7E0DC8F8-28A1-45F5-A3A3-238B420C821F@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/edf49ba4/attachment.pl>

From smartpink111 at yahoo.com  Thu Sep 12 14:23:46 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 12 Sep 2013 05:23:46 -0700 (PDT)
Subject: [R] how to retain dimnames while exporting from excel into r
In-Reply-To: <CAAJc=rPEhLEP20dqyiwBamCi3Q3qxwoHf_vH56MHbupAAr5i6w@mail.gmail.com>
References: <CAAJc=rPEhLEP20dqyiwBamCi3Q3qxwoHf_vH56MHbupAAr5i6w@mail.gmail.com>
Message-ID: <1378988626.40462.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Try with:

read.csv(file="sales.csv",header=TRUE,check.names=FALSE)
A.K.




----- Original Message -----
From: Charles Thuo <tcmuigai at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Thursday, September 12, 2013 3:15 AM
Subject: [R] how to retain dimnames while exporting from excel into r

v<- read.csv(file="sales.csv",header=TRUE)
v


i get an output whose column names are V1,V2, and so on but i would like to
retain the original column names such as january through to december.

Charles.

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From Gerrit.Eichner at math.uni-giessen.de  Thu Sep 12 14:28:10 2013
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Thu, 12 Sep 2013 14:28:10 +0200 (MEST)
Subject: [R] substituting string variable in expression with its value
In-Reply-To: <5231A9B2.2020209@yahoo.de>
References: <5231A9B2.2020209@yahoo.de>
Message-ID: <Pine.SOC.4.64.1309121422540.24925@solcom.hrz.uni-giessen.de>

Hi, Jannis,

maybe

plot( 1, 1, main = bquote( paste( .(a), " [", .(b), "]")))


comes close to what you want, but I think you may even have to use the 
following to get a varying exponent really printed elevated:

a <- "speed"
b <- "m * s"
cc <- -2

plot( 1, 1, main = bquote( paste( .(a), " [", .(b)^{.(cc)}, "]")))



  Hth  --  Gerrit


> plot(1,1, main=expression(paste("speed [", m * s^{-1}, "]")))
>
>
> I would, however, like to be able to supply the value "speed" and m*s^{-a} by 
> variables, e.g. do something like:
>
>
> a = 'speed'
> b = 'm*s^{-2}'
>
> plot(1,1, main=expression(paste(a, " [", b, "]")))
>
> This, however, does not work as a and b are not treated as variable names in 
> this case. Does anyone have a solution for this?
>
>
> Cheers
> jannis
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ppalmes at yahoo.com  Thu Sep 12 15:44:04 2013
From: ppalmes at yahoo.com (Paulito Palmes)
Date: Thu, 12 Sep 2013 06:44:04 -0700 (PDT)
Subject: [R] Formula in a model
In-Reply-To: <Pine.SOC.4.64.1309120904570.21205@solcom.hrz.uni-giessen.de>
References: <1378883051.43820.YahooMailNeo@web125405.mail.ne1.yahoo.com>
	<Pine.SOC.4.64.1309111142530.6509@solcom.hrz.uni-giessen.de>
	<1378909614.12435.YahooMailNeo@web125404.mail.ne1.yahoo.com>
	<Pine.SOC.4.64.1309120904570.21205@solcom.hrz.uni-giessen.de>
Message-ID: <1378993444.33575.YahooMailNeo@web125402.mail.ne1.yahoo.com>

Hi Gerrit,

Thank you very much for the precise explanation.?

Syntactically, I thought R is smart enough to detect that I'm using one of the columns because I use data=mytable syntax which means that input/output information are in the mytable.?

For a generic support, I think it's wise to support this syntax: genericModel(table[,columnLists] ~ ., data=table) because in many cases where you have hundred's of columns, you don't know the header but you know the column position of your inputs and outputs. You may say that why not use genericModel(table[,inputColumns],table[,outputColumns])? The formula expression shows more flexibility and elegance. Can this become a feature in the future? or at least R can be smart enough to detect that the output column is part of the input column.

I'm not sure how many will have a mistake of using this expression in the future specially in dealing with many columns and the easiest way to access it is by column number instead of headers. It can be sensible when you understand how R interprets it but syntactically, it makes sense to have the expression: mutable[,outputColumns] ~ .

Regards,
Paulito




----- Original Message -----
From: Gerrit Eichner <Gerrit.Eichner at math.uni-giessen.de>
To: Paulito Palmes <ppalmes at yahoo.com>
Cc: "r-help at r-project.org" <r-help at r-project.org>
Sent: Thursday, 12 September 2013, 8:53
Subject: Re: [R] Formula in a model

Hello, Paulito,

my comments are inline below:

> Thanks for the explanation. Let me give a specific example. Assume Temp 
> (column 4) is the output and the rest of the columns are input is the 
> training features. Note that I only use the air quality data for 
> illustration purpose. T input->output mapping may not make sense in the 
> real interpretation of this data.
>
> library(e1071)
>
> data(airquality)
> mytable=airquality
>
> colnames(mytable)=c('a','b','c','d','e','f')
>
> modelSVM1=svm(mytable[,6] ~ .,data=mytable)
> modelSVM2=svm(mytable[,-6],mytable[,6])
> modelSVM3=svm(f ~ ., data=mytable)
>
> predSVM1=predict(modelSVM1,newdata=mytable)
> predSVM2=predict(modelSVM2,newdata=mytable[,-6])
> predSVM3=predict(modelSVM3,newdata=mytable)
>
> Results of predSVM2 is similar with predSVM3 ?but different from?predSVM1.

Well, because already modelSVM1 is different from the other two. This is 
due to how the "." on the rhs of a formula is interpreted. From the help 
page of formula:

??? "There are two special interpretations of . in a formula. The
??? usual one is in the context of a data argument of model fitting
??? functions and means 'all columns not otherwise in the formula':
??? see terms.formula. In the context of update.formula, only, it
??? means 'what was previously in this part of the formula'."

The first interpretation applies to your situation. With the formula for 
your modelSVM1 the function model.matrix() (which is called inside the 
formula version of svm()) creates a model matrix after looking for a 
column "mytable[,6]" in the data argument. And since there is no column 
with that name, it takes all columns of mytable (including the 6th, i.e., 
the one named "f"). See what model.matrix() does in that case:

> head( model.matrix(mytable[,6] ~ .,data=mytable), 3)
?  (Intercept)? a?  b? ? c? d e f
1? ? ? ? ?  1 41 190? 7.4 67 5 1
2? ? ? ? ?  1 36 118? 8.0 72 5 2
3? ? ? ? ?  1 12 149 12.6 74 5 3



In the case of modelSVM3 model.matrix() does find column "f" in the data 
argument, and hence omits this column in forming the terms of the rhs of 
the formula:

> head( model.matrix( f ~ .,data=mytable), 3)
?  (Intercept)? a?  b? ? c? d e
1? ? ? ? ?  1 41 190? 7.4 67 5
2? ? ? ? ?  1 36 118? 8.0 72 5
3? ? ? ? ?  1 12 149 12.6 74 5



The call to svm() for modelSVM2 is the (non-formula) default version and 
does not need to call model.matrix() because (so to say) it expects that 
the user has done that already by supplying the response to its argument y 
and the adequately formed data matrix to its argument x.


> Question: Which is the correct formulation?

The second and the third (for a sensible purpose), unless you want to 
experiment with svm() to see what happens if one does something rather 
nonsensical.


> Why R doesn't detect error/discrepancy in formulation?

Because R, or in this case rather the concept of a formula and the 
function model.matrix() are not designed to replace the user who knows 
what s/he is doing after having read the documentation. ;)



> If I use the same formulation with rpart using the same data:
>
> library(rpart)
>
> data(airquality)
> mytable=airquality
>
> colnames(mytable)=c('a','b','c','d','e','f')
>
> modelRP1=rpart(mytable[,6]~.,data=mytable,method='anova') # this works
> modelRP3=rpart(f ~ ., data=mytable,method='anova') # this works
>
> predRP1=predict(modelRP1,newdata=mytable)
> predRP3=predict(modelRP3,newdata=mytable)
>
>
> The results between predRP1 and predRP3 are different while the statements:
>
> predRP2=predict(modelRP2,newdata=mytable[,-6])
> modelRP2=rpart(mytable[,-6],mytable[,6],method='anova')?
>
> have errors.

This is presumably due to the same reasons as described above.


Remark: It is generally - for various reasons - recommended to use "<-" as 
the assignment operator, not "=". (And I like to recommend to use use 
blanks to increase readability of code.)

[... snip ...]


? I hope the fog has lifted? --? Gerrit


From pmilin at gmail.com  Thu Sep 12 12:32:00 2013
From: pmilin at gmail.com (Petar Milin)
Date: Thu, 12 Sep 2013 12:32:00 +0200
Subject: [R] Getting "Approximate Estimates after Deleting Factors" out from
	fastbw()
Message-ID: <894EA901-C5BA-4B2B-861F-C60800663CFD@gmail.com>


Hello!
I am using relatively simple linear model. By applying fastbw() on ols() results from rms package I would like to get subtable "Approximate Estimates after Deleting Factors". However, it seems this is not possible. Am I right? I can only get coefficients for variables kept in the model (for example: x$coefficients), but not S.E., Wald's Z and P?

Is there any easy way to extract this part of results?

Many thanks!
PM


From schotz at gmail.com  Thu Sep 12 15:49:58 2013
From: schotz at gmail.com (Chris Schatschneider)
Date: Thu, 12 Sep 2013 09:49:58 -0400
Subject: [R] Creating a map in R using ACS PUMS data
Message-ID: <CACybgdGqrGwqzCNd7=o7zhs27WugYqQ7z1qMJK17_3azzH7fMg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/59455519/attachment.pl>

From John.Gonzalez at gmx.fr  Thu Sep 12 15:40:22 2013
From: John.Gonzalez at gmx.fr (John Gonzalez)
Date: Thu, 12 Sep 2013 15:40:22 +0200
Subject: [R] Privacy rights of an old user of this list
Message-ID: <20130912134022.202280@gmx.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/e705d1b2/attachment.pl>

From John.Gonzalez at gmx.fr  Thu Sep 12 15:40:22 2013
From: John.Gonzalez at gmx.fr (John Gonzalez)
Date: Thu, 12 Sep 2013 15:40:22 +0200
Subject: [R] Privacy rights of an old user of this list
Message-ID: <20130912134022.202280@gmx.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/e705d1b2/attachment-0001.pl>

From murdoch.duncan at gmail.com  Thu Sep 12 16:22:55 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 12 Sep 2013 10:22:55 -0400
Subject: [R] Privacy rights of an old user of this list
In-Reply-To: <20130912134022.202280@gmx.com>
References: <20130912134022.202280@gmx.com>
Message-ID: <5231CE3F.7070002@gmail.com>

On 13-09-12 9:40 AM, John Gonzalez wrote:
> Dear subscribers of r-help,
> I would like to know your opinion about a privacy problem that I recently had after publishing to this list. Not a long time ago, I requested to the administrators of this list that they removed 2 or 3 old posts from mine. These posts were associating my name with an old company for which I worked a few years ago when you would look up my real name at google. I'm 100% aware that there are many mirrors of this list archive and that this is a hard work, however my point was to move their google references to later pages so that new people that look up my name would focus first on more recent work that I see as more relevant for what I would like to do in the future.
> This is the answer that I received from Mr. Winsemius:

I think you misunderstood his response.  Your request is not possible. 
The administrators of this list have no control over most of the sites 
that archive it.

It's possible that you could approach those sites individually and ask 
each one to remove its copy of your postings, but it is unreasonable to 
expect the administrators of the list to do that for you, and honestly, 
I suspect you'll be unsuccessful in having your old messages purged 
completely.  Your messages were public as soon as you sent them, and 
it's very difficult to erase public records.

Duncan Murdoch

> <<
> Such a service is not available. Almost immediately rhelp postings are replicated in multiple websites around the world. The information that you could have (and should have) read at the time of signing up is here:
>
> https://stat.ethz.ch/mailman/listinfo/r-help
>
> ... and the relevant sentence is:
>
> "Posters should be aware that the R lists are  /public/ discussion lists and anything you post will be  *archived and accessible* via several websites for many years."
>>>
> I followed up explaining that at that time I was too young to understand the consequences of what I was doing and that, honestly, I didn't pay attention to such a note. Mr. Winsemius didn't understand the reason of my request and therefore decided to ignore it, even after asking a representative from the company mentioned in my old posts to contact him to request the removal of such posts.
> At this point I feel completely powerless and disturbed that the administrators of the r-help list refuse to remove a text that I decided a long time ago to publish here. I don't think that they own the rights of what I wrote and I wonder what I have done wrong to be disrespected in such a way.
> Best regards,
> John Gonzalez (pseudonym)
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From albin.blaschka at standortsanalyse.net  Thu Sep 12 16:26:01 2013
From: albin.blaschka at standortsanalyse.net (Albin Blaschka)
Date: Thu, 12 Sep 2013 16:26:01 +0200
Subject: [R] Privacy rights of an old user of this list
In-Reply-To: <20130912134022.202280@gmx.com>
References: <20130912134022.202280@gmx.com>
Message-ID: <5231CEF9.1000401@standortsanalyse.net>

Hello!

Just a short question:

If you publish something, say a paper or book or report (in dead tree 
format = on paper), do you ask libraries and owners of this publication 
also to throw it away, because it is old or you have changed positions?

If in the academic world every scientist would remove his/her 
publications because they are out of date or after changing position, 
the scientific literature would probably be more less non-existant.

So, unless your postings are somehow offensive or abusive, I must say, I 
do not see your point, sorry!

I hope my mail is not offensive for you, if yes, I apologize, but it 
expresses my own opinion...

Albin (no pseudonym)

Am 12.09.2013 15:40, schrieb John Gonzalez:
> Dear subscribers of r-help,
> I would like to know your opinion about a privacy problem that I recently had after publishing to this list. Not a long time ago, I requested to the administrators of this list that they removed 2 or 3 old posts from mine. These posts were associating my name with an old company for which I worked a few years ago when you would look up my real name at google. I'm 100% aware that there are many mirrors of this list archive and that this is a hard work, however my point was to move their google references to later pages so that new people that look up my name would focus first on more recent work that I see as more relevant for what I would like to do in the future.
> This is the answer that I received from Mr. Winsemius:
> <<
> Such a service is not available. Almost immediately rhelp postings are replicated in multiple websites around the world. The information that you could have (and should have) read at the time of signing up is here:
>
> https://stat.ethz.ch/mailman/listinfo/r-help
>
> ... and the relevant sentence is:
>
> "Posters should be aware that the R lists are  /public/ discussion lists and anything you post will be  *archived and accessible* via several websites for many years."
>>>
> I followed up explaining that at that time I was too young to understand the consequences of what I was doing and that, honestly, I didn't pay attention to such a note. Mr. Winsemius didn't understand the reason of my request and therefore decided to ignore it, even after asking a representative from the company mentioned in my old posts to contact him to request the removal of such posts.
> At this point I feel completely powerless and disturbed that the administrators of the r-help list refuse to remove a text that I decided a long time ago to publish here. I don't think that they own the rights of what I wrote and I wonder what I have done wrong to be disrespected in such a way.
> Best regards,
> John Gonzalez (pseudonym)
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
| Albin Blaschka, Mag.rer.nat.
| Etrichstrasse 26, A-5020 Salzburg
| * www.albinblaschka.info *
| * www.researchgate.net/profile/Albin_Blaschka *
| - It's hard to live in the mountains, hard but not hopeless!


From gunter.berton at gene.com  Thu Sep 12 16:47:37 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 12 Sep 2013 07:47:37 -0700
Subject: [R] Formula in a model
In-Reply-To: <1378993444.33575.YahooMailNeo@web125402.mail.ne1.yahoo.com>
References: <1378883051.43820.YahooMailNeo@web125405.mail.ne1.yahoo.com>
	<Pine.SOC.4.64.1309111142530.6509@solcom.hrz.uni-giessen.de>
	<1378909614.12435.YahooMailNeo@web125404.mail.ne1.yahoo.com>
	<Pine.SOC.4.64.1309120904570.21205@solcom.hrz.uni-giessen.de>
	<1378993444.33575.YahooMailNeo@web125402.mail.ne1.yahoo.com>
Message-ID: <CACk-te3fVdmq1vO0JVk1vStQ19vX01mZcZf764c59uYLRgSstQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/6801ab3a/attachment.pl>

From mrahmankufmrt at gmail.com  Thu Sep 12 16:48:40 2013
From: mrahmankufmrt at gmail.com (Moshiur Rahman)
Date: Thu, 12 Sep 2013 22:48:40 +0800
Subject: [R] Plot help
Message-ID: <CAGNSkSk_OZe5rOSrPQ6VDPCuq_teCN-vTUmg2zGY+vtsjO9zOg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/d78169cb/attachment.pl>

From bt_jannis at yahoo.de  Thu Sep 12 16:52:39 2013
From: bt_jannis at yahoo.de (Jannis)
Date: Thu, 12 Sep 2013 16:52:39 +0200
Subject: [R] substituting string variable in expression with its value
In-Reply-To: <Pine.SOC.4.64.1309121422540.24925@solcom.hrz.uni-giessen.de>
References: <5231A9B2.2020209@yahoo.de>
	<Pine.SOC.4.64.1309121422540.24925@solcom.hrz.uni-giessen.de>
Message-ID: <5231D537.3080102@yahoo.de>

Hi Gerrit,

thanks for your suggestion. I want to create some code were I can supply 
the 'm*s^{-2}' part as an argument to a function and which evaluates 
this as an expression to use Rs mathematical annotation features in the 
labels.


Any further ideas?

Jannis



On 12.09.2013 14:28, Gerrit Eichner wrote:
> Hi, Jannis,
>
> maybe
>
> plot( 1, 1, main = bquote( paste( .(a), " [", .(b), "]")))
>
>
> comes close to what you want, but I think you may even have to use the 
> following to get a varying exponent really printed elevated:
>
> a <- "speed"
> b <- "m * s"
> cc <- -2
>
> plot( 1, 1, main = bquote( paste( .(a), " [", .(b)^{.(cc)}, "]")))
>
>
>
>  Hth  --  Gerrit
>
>
>> plot(1,1, main=expression(paste("speed [", m * s^{-1}, "]")))
>>
>>
>> I would, however, like to be able to supply the value "speed" and 
>> m*s^{-a} by variables, e.g. do something like:
>>
>>
>> a = 'speed'
>> b = 'm*s^{-2}'
>>
>> plot(1,1, main=expression(paste(a, " [", b, "]")))
>>
>> This, however, does not work as a and b are not treated as variable 
>> names in this case. Does anyone have a solution for this?
>>
>>
>> Cheers
>> jannis
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From jdnewmil at dcn.davis.CA.us  Thu Sep 12 16:56:37 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 12 Sep 2013 07:56:37 -0700
Subject: [R] Privacy rights of an old user of this list
In-Reply-To: <20130912134022.202280@gmx.com>
References: <20130912134022.202280@gmx.com>
Message-ID: <71bd3343-1153-469f-9588-aea77669f147@email.android.com>

Not only are you asking the administrators of an email list to alter data stored on systems other than the ones they control, you are suggesting that they can somehow alter search records stored in Google's servers. At best you are naive. That does not mean you are the only person with such regrets... just that the toothpaste is out of the tube and you still haven't learned from your mistakes. I imagine you may still need to learn that there are scammers out there willing to take large amounts of money from you to "fix" things like this. Keep learning!
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

John Gonzalez <John.Gonzalez at gmx.fr> wrote:
>Dear subscribers of r-help,
>I would like to know your opinion about a privacy problem that I
>recently had after publishing to this list. Not a long time ago, I
>requested to the administrators of this list that they removed 2 or 3
>old posts from mine. These posts were associating my name with an old
>company for which I worked a few years ago when you would look up my
>real name at google. I'm 100% aware that there are many mirrors of this
>list archive and that this is a hard work, however my point was to move
>their google references to later pages so that new people that look up
>my name would focus first on more recent work that I see as more
>relevant for what I would like to do in the future.
>This is the answer that I received from Mr. Winsemius:
><<
>Such a service is not available. Almost immediately rhelp postings are
>replicated in multiple websites around the world. The information that
>you could have (and should have) read at the time of signing up is
>here: 
>
>https://stat.ethz.ch/mailman/listinfo/r-help 
>
>... and the relevant sentence is:
>
>"Posters should be aware that the R lists are  /public/ discussion
>lists and anything you post will be  *archived and accessible* via
>several websites for many years."
>>>
>I followed up explaining that at that time I was too young to
>understand the consequences of what I was doing and that, honestly, I
>didn't pay attention to such a note. Mr. Winsemius didn't understand
>the reason of my request and therefore decided to ignore it, even after
>asking a representative from the company mentioned in my old posts to
>contact him to request the removal of such posts.
>At this point I feel completely powerless and disturbed that the
>administrators of the r-help list refuse to remove a text that I
>decided a long time ago to publish here. I don't think that they own
>the rights of what I wrote and I wonder what I have done wrong to be
>disrespected in such a way.
>Best regards,
>John Gonzalez (pseudonym)
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ajdamico at gmail.com  Thu Sep 12 17:22:34 2013
From: ajdamico at gmail.com (Anthony Damico)
Date: Thu, 12 Sep 2013 11:22:34 -0400
Subject: [R] Creating a map in R using ACS PUMS data
In-Reply-To: <CACybgdGqrGwqzCNd7=o7zhs27WugYqQ7z1qMJK17_3azzH7fMg@mail.gmail.com>
References: <CACybgdGqrGwqzCNd7=o7zhs27WugYqQ7z1qMJK17_3azzH7fMg@mail.gmail.com>
Message-ID: <CAOwvMDziTv_mQ3_Feg-Wyq74isfcqBii+-7LJX9wSuthkfMzRA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/eefc7fe4/attachment.pl>

From S.Ellison at lgcgroup.com  Thu Sep 12 17:45:23 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Thu, 12 Sep 2013 16:45:23 +0100
Subject: [R] computationaly singular error!
In-Reply-To: <1378846869214-4675810.post@n4.nabble.com>
References: <1378846869214-4675810.post@n4.nabble.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED526870CCC5@GOLD.corp.lgc-group.com>

> Error in solve.default(H, g[!fixed]) : 
>   system is computationally singular: reciprocal condition number =
> 4.65795e-19
>
Maybe you have more predictors than data?

S Ellison 

 


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From hh132 at le.ac.uk  Thu Sep 12 17:55:58 2013
From: hh132 at le.ac.uk (Rose)
Date: Thu, 12 Sep 2013 08:55:58 -0700 (PDT)
Subject: [R] computationaly singular error!
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED526870CCC5@GOLD.corp.lgc-group.com>
References: <1378846869214-4675810.post@n4.nabble.com>
	<A4E5A0B016B8CB41A485FC629B633CED526870CCC5@GOLD.corp.lgc-group.com>
Message-ID: <1379001358468-4675962.post@n4.nabble.com>

I have 8 predictors and 1144 observations over 13 years. I think it is not
the case.



--
View this message in context: http://r.789695.n4.nabble.com/computationaly-singular-error-tp4675810p4675962.html
Sent from the R help mailing list archive at Nabble.com.


From wdunlap at tibco.com  Thu Sep 12 18:27:30 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 12 Sep 2013 16:27:30 +0000
Subject: [R] substituting string variable in expression with its value
In-Reply-To: <5231D537.3080102@yahoo.de>
References: <5231A9B2.2020209@yahoo.de>
	<Pine.SOC.4.64.1309121422540.24925@solcom.hrz.uni-giessen.de>
	<5231D537.3080102@yahoo.de>
Message-ID: <E66794E69CFDE04D9A70842786030B931C342BD5@PA-MBX01.na.tibco.com>

Is this what you want?

myTitle <- function (name, unitsExpr = parse(text = unitsString)[[1]], unitsString) 
{
    name <- as.name(name)
    bquote(.(name) ~ "[" * .(unitsExpr) * "]")
}
plot(1,1,xlab=myTitle("velocity", quote(km/hr)), ylab=myTitle("distance", quote(light~years)))

Note that unitsExpr should be an expression (typically as quote(...)) but
if you hate expressions you can give a string to unitsString, which will
be parsed to form the expression.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Jannis
> Sent: Thursday, September 12, 2013 7:53 AM
> To: Gerrit Eichner
> Cc: r-help at r-project.org
> Subject: Re: [R] substituting string variable in expression with its value
> 
> Hi Gerrit,
> 
> thanks for your suggestion. I want to create some code were I can supply
> the 'm*s^{-2}' part as an argument to a function and which evaluates
> this as an expression to use Rs mathematical annotation features in the
> labels.
> 
> 
> Any further ideas?
> 
> Jannis
> 
> 
> 
> On 12.09.2013 14:28, Gerrit Eichner wrote:
> > Hi, Jannis,
> >
> > maybe
> >
> > plot( 1, 1, main = bquote( paste( .(a), " [", .(b), "]")))
> >
> >
> > comes close to what you want, but I think you may even have to use the
> > following to get a varying exponent really printed elevated:
> >
> > a <- "speed"
> > b <- "m * s"
> > cc <- -2
> >
> > plot( 1, 1, main = bquote( paste( .(a), " [", .(b)^{.(cc)}, "]")))
> >
> >
> >
> >  Hth  --  Gerrit
> >
> >
> >> plot(1,1, main=expression(paste("speed [", m * s^{-1}, "]")))
> >>
> >>
> >> I would, however, like to be able to supply the value "speed" and
> >> m*s^{-a} by variables, e.g. do something like:
> >>
> >>
> >> a = 'speed'
> >> b = 'm*s^{-2}'
> >>
> >> plot(1,1, main=expression(paste(a, " [", b, "]")))
> >>
> >> This, however, does not work as a and b are not treated as variable
> >> names in this case. Does anyone have a solution for this?
> >>
> >>
> >> Cheers
> >> jannis
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bbolker at gmail.com  Thu Sep 12 18:33:53 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 12 Sep 2013 12:33:53 -0400
Subject: [R] Subtracting elements of a vector from each other stepwise
In-Reply-To: <5230F78A.2030600@student.unimelb.edu.au>
References: <CANTLroGb_R4HOgG5gNk9HCPaPX2=EZ_J_KLhYmRtLfLB+W-OAw@mail.gmail.com>	<1378847199.17716.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<loom.20130910T233603-460@post.gmane.org>
	<1378851844.80715.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<522FAFB4.907@gmail.com> <5230F78A.2030600@student.unimelb.edu.au>
Message-ID: <5231ECF1.6080708@gmail.com>

On 13-09-11 07:06 PM, Ben Harrison wrote:
> If I were Michael (OP) right now, I think my head would be spinning.
> 
> As a newbie myself, I know how hard it is to read R code for the first
> time, so could it also be part of the newsgroup etiquette to at least
> partially explain provided code to newbies?
> 
> I agree that the interactive help '?' is available and should be
> consulted, but it would also be helpful if those of you with great
> experience could add a little guidance for your code.
> 
> Excuse me if this is out-of-place.
> 
> Ben
> 
> 

  Perfectly reasonable request, and should be done where possible, but
also note that sometimes I feel like I have time to toss in a quick
answer but not to give much in the way of explanation, and I think
something is better than nothing ... (and hope that perhaps someone else
will come along to give an explanation)

  Ben Bolker


From gunter.berton at gene.com  Thu Sep 12 18:51:18 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 12 Sep 2013 09:51:18 -0700
Subject: [R] computationaly singular error!
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED526870CCC5@GOLD.corp.lgc-group.com>
References: <1378846869214-4675810.post@n4.nabble.com>
	<A4E5A0B016B8CB41A485FC629B633CED526870CCC5@GOLD.corp.lgc-group.com>
Message-ID: <CACk-te2ODz3MMP418M7mRbhu6OJ7C1TTnk7tchdk=11iMC98xQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/c74ec997/attachment.pl>

From info at aghmed.fsnet.co.uk  Thu Sep 12 19:01:12 2013
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Thu, 12 Sep 2013 18:01:12 +0100
Subject: [R] meta-analysis of annualized event rate
In-Reply-To: <20130911195116.622620yqfe65v990@inbox.unina.it>
References: <20130911195116.622620yqfe65v990@inbox.unina.it>
Message-ID: <Zen-1VKAGa-000Bwc-Rz@smarthost01d.mail.zen.net.uk>

At 18:51 11/09/2013, petretta at unina.it wrote:
>  r-help at r-project.org
>
>Dear all,
>
>I use R 2.15.2 for Windows 8
>
>I ask if it is possible perform a meta-analysis of annualized event
>rate from several studies reporting

Try metafor (from CRAN)

Look in the help for escalc for incidence rate ratio and see if that 
section fits the studies you have.


>1) number of patients enrolled (N)
>2) mean lenght of follow-up time (mo)
>3) annualized event rate (AER) (expressed as % person-year)
>
>I would like suggestions on package(s) and code.
>
>Many thanks in advance.
>
>
>
>
>
>--
>Mario Petretta
>Department of Translational Medical Sciences
>Naples University Federico II
>Italy
>
>

Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html


From S.Ellison at LGCGroup.com  Thu Sep 12 19:23:14 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 12 Sep 2013 18:23:14 +0100
Subject: [R] Privacy rights of an old user of this list
In-Reply-To: <20130912134022.202280@gmx.com>
References: <20130912134022.202280@gmx.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED52689DE3EA@GOLD.corp.lgc-group.com>

> I would like to know your opinion about a privacy problem that I recently had after publishing to this list. 
Well, in short, you appear to have wilfully ignored the terms of membership of the list, posted intentionally on a public mailing list without checking where the posts would end up, complained unreasonably that their distribution surprises you, compounded that by claiming to be an irresponsible juvenile at the time of signing up ('too young to understand the consequences ...', you said?), and now publicly distributed an admission of wilful omission.

On that basis, my opinion is that you neither have cause to complain, or to assert that the mailing list owners are to blame for your dismay at the consequences your actions. The responsibility is entirely your own.

I am also of the opinion that the list owner was not showing disrespect by describing the state of affairs you agreed to on signing up, or by declining to act beyond the requirements of the conditions applicable to the list. 

Steve E

PS: For the record, I am not associated with the management of this list and the above is a personal opinion and not given in any professional capacity. 

*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From erinm.hodgess at gmail.com  Thu Sep 12 19:42:20 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Thu, 12 Sep 2013 12:42:20 -0500
Subject: [R] problem with rJython and modules
Message-ID: <CACxE24kAJ5=FAPDjFTZ=8FCGn=bPFsJN_X5BbFr=6CThGB+JaA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/31a60229/attachment.pl>

From pdxgary163 at gmail.com  Thu Sep 12 20:08:49 2013
From: pdxgary163 at gmail.com (Gary Dong)
Date: Thu, 12 Sep 2013 11:08:49 -0700
Subject: [R] Logged ratio as Dependent variable
Message-ID: <CAEVDvzXTiuhQky6oU2eRYCDKA3Hh_M2LB-fJoeK0ZiAmQXkp2A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/0ed81992/attachment.pl>

From gunter.berton at gene.com  Thu Sep 12 20:37:35 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 12 Sep 2013 11:37:35 -0700
Subject: [R] Logged ratio as Dependent variable
In-Reply-To: <CAEVDvzXTiuhQky6oU2eRYCDKA3Hh_M2LB-fJoeK0ZiAmQXkp2A@mail.gmail.com>
References: <CAEVDvzXTiuhQky6oU2eRYCDKA3Hh_M2LB-fJoeK0ZiAmQXkp2A@mail.gmail.com>
Message-ID: <CACk-te1mzg9+tQS2ASZ038B4J5d8KuS++nB4pAapKAF=bhnx9Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/db04b2ac/attachment.pl>

From Allen.Joel at epa.gov  Thu Sep 12 20:49:45 2013
From: Allen.Joel at epa.gov (Allen, Joel)
Date: Thu, 12 Sep 2013 18:49:45 +0000
Subject: [R] grep(pattern = each element of a vector) ?
In-Reply-To: <f5c4a88642b94191873e6d6ed732a145@BL2PR09MB033.namprd09.prod.outlook.com>
References: <f5c4a88642b94191873e6d6ed732a145@BL2PR09MB033.namprd09.prod.outlook.com>
Message-ID: <3113ed39316f4d92ba2d9ce4be204956@BN1PR09MB058.namprd09.prod.outlook.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/1a8c8513/attachment.pl>

From hh132 at le.ac.uk  Thu Sep 12 21:13:25 2013
From: hh132 at le.ac.uk (Rose)
Date: Thu, 12 Sep 2013 12:13:25 -0700 (PDT)
Subject: [R] computationaly singular error!
In-Reply-To: <CACk-te2ODz3MMP418M7mRbhu6OJ7C1TTnk7tchdk=11iMC98xQ@mail.gmail.com>
References: <1378846869214-4675810.post@n4.nabble.com>
	<A4E5A0B016B8CB41A485FC629B633CED526870CCC5@GOLD.corp.lgc-group.com>
	<CACk-te2ODz3MMP418M7mRbhu6OJ7C1TTnk7tchdk=11iMC98xQ@mail.gmail.com>
Message-ID: <1379013205158-4675981.post@n4.nabble.com>

Thanks Bert, 
all predictors are numerical. By the way, I have checked the collinearity of
predictors by vif(). All vif of predictors were less than 2 that means none
of the predictors are linear combinations of the others.

Best,
Rose



--
View this message in context: http://r.789695.n4.nabble.com/computationaly-singular-error-tp4675810p4675981.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Thu Sep 12 21:22:01 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 12 Sep 2013 14:22:01 -0500
Subject: [R] Privacy rights of an old user of this list
In-Reply-To: <20130912134022.202280@gmx.com>
References: <20130912134022.202280@gmx.com>
Message-ID: <FDB33086-D194-4552-A5CC-557D17020137@comcast.net>


On Sep 12, 2013, at 8:40 AM, John Gonzalez wrote:

> Dear subscribers of r-help,
> I would like to know your opinion about a privacy problem that I  
> recently had after publishing to this list. Not a long time ago,


> I requested to the administrators of this list that they removed 2  
> or 3 old posts from mine. These posts were associating my name with  
> an old company for which I worked a few years ago when you would  
> look up my real name at google. I'm 100% aware that there are many  
> mirrors of this list archive and that this is a hard work, however  
> my point was to move their google references to later pages so that  
> new people that look up my name would focus first on more recent  
> work that I see as more relevant for what I would like to do in the  
> future.
> This is the answer that I received from Mr. Winsemius:

If you would use an honorific, it would be "Dr." I generally use  
'David', however.

> <<
> Such a service is not available. Almost immediately rhelp postings  
> are replicated in multiple websites around the world. The  
> information that you could have (and should have) read at the time  
> of signing up is here:
>
> https://stat.ethz.ch/mailman/listinfo/r-help
>
> ... and the relevant sentence is:
>
> "Posters should be aware that the R lists are  /public/ discussion  
> lists and anything you post will be  *archived and accessible* via  
> several websites for many years."
>>>
> I followed up explaining that at that time I was too young to  
> understand the consequences of what I was doing

I have no memory of incompetence by virtue of young age being offered  
as the basis for the request. My memory regarding the basis for the  
request was a desire not to be associated with the the domain name of  
the company in question because of a claim that they had used  
unethical practices.  I determined with a Google search that there  
were multiple other sources of that information on various websites.


> and that, honestly, I didn't pay attention to such a note. Mr.  
> Winsemius didn't understand the reason of my request and therefore  
> decided to ignore it, even after asking a representative from the  
> company mentioned in my old posts to contact him to request the  
> removal of such posts.

If motive for not pursuing the issue, rather than policy and  
feasibility, is being questioned, it's more that I didn't see the  
reason (the originally alleged reason, not the recently revised  
argument) as compelling. There are a quite a few of my postings to  
newsgroups that I wouldn't mind seeing disappear and even a few on the  
Rhelp archives. I just don't think that my errors in judgment or  
knowledge deserve to be ignored. My hope is that I am judged on the  
balance of useful versus boneheaded.

> At this point I feel completely powerless and disturbed that the  
> administrators of the r-help list refuse to remove a text that I  
> decided a long time ago to publish here. I don't think that they own  
> the rights of what I wrote and I wonder what I have done wrong to be  
> disrespected in such a way.
> Best regards,
> John Gonzalez (pseudonym)
>
> 	[[alternative HTML version deleted]]

-- 
David Winsemius, MD
Alameda, CA, USA


From smartpink111 at yahoo.com  Thu Sep 12 21:30:18 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 12 Sep 2013 12:30:18 -0700 (PDT)
Subject: [R] grep(pattern = each element of a vector) ?
In-Reply-To: <3113ed39316f4d92ba2d9ce4be204956@BN1PR09MB058.namprd09.prod.outlook.com>
References: <f5c4a88642b94191873e6d6ed732a145@BL2PR09MB033.namprd09.prod.outlook.com>
	<3113ed39316f4d92ba2d9ce4be204956@BN1PR09MB058.namprd09.prod.outlook.com>
Message-ID: <1379014218.34559.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
res<- ddply(.data=df1,
????? .variables='Taxa',
?????? .fun=transform,
?????? Class=find.class(Taxa))
#Warning messages:
#1: In grep(x, df2$Taxa) :
?# argument 'pattern' has length > 1 and only the first element will be used
#2: In grep(x, df2$Taxa) :
?# argument 'pattern' has length > 1 and only the first element will be used
#3: In grep(x, df2$Taxa) :
?# argument 'pattern' has length > 1 and only the first element will be used

May be it is better to modify the function:
find.class<- function(x) df2[grep(unique(x),df2$Taxa),'Class']
res1<- ddply(.data=df1,
?????? .variables='Taxa',
??????? .fun=transform,
??????? Class=find.class(Taxa)) #no warnings

#though it doesn't have any effect in the end result.
?identical(res,res1) 
#[1] TRUE


A.K.





----- Original Message -----
From: "Allen, Joel" <Allen.Joel at epa.gov>
To: "Beaulieu, Jake" <Beaulieu.Jake at epa.gov>; "r-help at r-project.org" <r-help at r-project.org>
Cc: "Farrar, David" <Farrar.David at epa.gov>; "Green, Hyatt" <Green.Hyatt at epa.gov>; "McManus, Michael" <McManus.Michael at epa.gov>; "Wahman, David" <Wahman.David at epa.gov>
Sent: Thursday, September 12, 2013 2:49 PM
Subject: Re: [R] grep(pattern = each element of a vector) ?

Jake,
You can use the plyr library or some form of apply.? If you are on a 64bit system you can multithread and it goes much faster.

something like this(for 32bit):
require(plyr)
df1 <- data.frame(Taxa = c('blue', 'red', NA,'blue', 'red', NA,'blue', 'red', NA))
df2 <- data.frame(Taxa = c( 'blue', 'red', NA), Class = c('Z', 'HI', 'A'))

#function to do the lookup
find.class<-function(x)df2[grep(x, df2$Taxa),'Class']

ddply(.data=df1,
? ? ? .variables='Taxa',
? ? ? .fun=transform,
? ? ? Class=find.class(Taxa))

Joel

From: Beaulieu, Jake
Sent: Thursday, September 12, 2013 12:06 PM
To: r-help at r-project.org
Cc: Wahman, David; Farrar, David; Allen, Joel; Green, Hyatt; McManus, Michael
Subject: grep(pattern = each element of a vector) ?

Hi,

I have a large dataframe that contains species names.? I have a second dataframe that contains species names and some additional info, called 'Class', about each species.? I would like match the species name is the first data frame with the 'Class' information contained in the second.? Since the species names are often formatted differently between the data sets, merge doesn't work well.? grep does the trick, but the function needs to be called separately for each observation in the first data frame.? I put grep into a loop, but this is too slow.? Is there a way to run grep repeatedly without resorting to a loop?? Possibly something in the apply family?

? df1 <- data.frame(Taxa = c('blue', 'red', NA))
? df2 <- data.frame(Taxa = c( 'blue', 'red', NA), Class = c('Z', 'HI', 'A'))

? index <- NULL
? for (i in 1:length(df1$Taxa)) {
? ? index[i] <- grep(df1$Taxa[1], df2$Taxa)
? ? }
? index

> sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: i386-w64-mingw32/i386 (32-bit)

==================================
Jake J. Beaulieu, PhD
US Environmental Protection Agency
National Risk Management Research Lab
26 W. Martin Luther King Drive
Cincinnati, OH 45268
USA
513-569-7842? (desk)
513-487-2511 (fax)
beaulieu.jake at epa.gov<mailto:beaulieu.jake at epa.gov>


??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From zhangweiwu at realss.com  Thu Sep 12 19:17:53 2013
From: zhangweiwu at realss.com (Zhang Weiwu)
Date: Fri, 13 Sep 2013 01:17:53 +0800 (CST)
Subject: [R] on how to make a skip-table
Message-ID: <alpine.DEB.2.00.1309130054380.20861@lyonesse>


I've got two data frames, as shown below:
(NR means Number of Record)

> record.lenths
         NR     length
         1       100
         2       130
         3       150
         4       148
         5       100
         6        83
 	7	 60

> valida.records
 	NR     factor
 	1       3
 	2       4
 	4       8
 	7       9

And I intend to obtain the following skip-table:

> skip.table
 	NR     skip   factor
 	1       0       3
 	2       0       4
 	4       150     8
 	7       183     9


The column 'skip' is the space needed to skip invalid records.

For example, the 3rd element of skip.table has skip of '150', intended to 
skip the invalid record No.3 in record.lengths

For example, the 4th element of skip.table has skip of '183', intended to 
skip the invalid record No.5 and No.6, together is 100+83.

It's rather apparently intended for reading huge data files, and looks 
simple math, and I admit I couldn't find an R-ish way doing it.

Thanks in advance and also thanks for pointing out if I had been on the 
right track to start with.


From hnorpois at gmail.com  Thu Sep 12 16:31:29 2013
From: hnorpois at gmail.com (Hermann Norpois)
Date: Thu, 12 Sep 2013 16:31:29 +0200
Subject: [R] princomp needs more obsverations than variables?
Message-ID: <CAKyZeBvX46XTkX5mdif0zkcHvQUtU-c_=O3Hh1HrXjtxhjuwEQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/b9a40aae/attachment.pl>

From Beaulieu.Jake at epa.gov  Thu Sep 12 18:06:14 2013
From: Beaulieu.Jake at epa.gov (Beaulieu, Jake)
Date: Thu, 12 Sep 2013 16:06:14 +0000
Subject: [R] grep(pattern = each element of a vector) ?
Message-ID: <f5c4a88642b94191873e6d6ed732a145@BL2PR09MB033.namprd09.prod.outlook.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/1dd2da83/attachment.pl>

From dieter.mayr at boku.ac.at  Thu Sep 12 17:38:14 2013
From: dieter.mayr at boku.ac.at (didimayr)
Date: Thu, 12 Sep 2013 08:38:14 -0700 (PDT)
Subject: [R] predict from tobit regression
Message-ID: <1379000294073-4675960.post@n4.nabble.com>

Dear R experts,

I am currently working on a rather simple tobit regression, where the
dependet variable is left-censored (>0). I would like to apply a Tobit
regression and then use the parameters of this regression to make a
prediction with new data. The intention behind this is to do an
extrapolation.

by using the VGAM or AER package, I already succeeded in getting fitted
values. However these values are not "censored", which means that negative
values appear. Perhaps my approach is totally wrong, but in case anybody has
experience with this kind of problem or has any idea, I am very thankful!

kind regards,
Dieter Mayr



--
View this message in context: http://r.789695.n4.nabble.com/predict-from-tobit-regression-tp4675960.html
Sent from the R help mailing list archive at Nabble.com.


From amoser1 at binghamton.edu  Thu Sep 12 19:26:25 2013
From: amoser1 at binghamton.edu (Alecia M Moser)
Date: Thu, 12 Sep 2013 13:26:25 -0400
Subject: [R] Package to manipulate timestamp data in format HH:MM:SS:sss
Message-ID: <CAHHZM+3AQN9n-8V34EV-ogLt7TdrBTh5CHYDe8ZLeZr12mHuwg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/161e402b/attachment.pl>

From jholtman at gmail.com  Thu Sep 12 22:03:23 2013
From: jholtman at gmail.com (jim holtman)
Date: Thu, 12 Sep 2013 16:03:23 -0400
Subject: [R] Package to manipulate timestamp data in format HH:MM:SS:sss
In-Reply-To: <CAHHZM+3AQN9n-8V34EV-ogLt7TdrBTh5CHYDe8ZLeZr12mHuwg@mail.gmail.com>
References: <CAHHZM+3AQN9n-8V34EV-ogLt7TdrBTh5CHYDe8ZLeZr12mHuwg@mail.gmail.com>
Message-ID: <CAAxdm-4hGgiKF75e7+DgvLic6-N-3ds-gRqbJMG4wtc54_BPWA@mail.gmail.com>

Use POSIXct for the date/time stamp.  For your data you will have to
substitute a period ('.') for the last colon (":"), but that is easy
to do with 'sub'.

You will get millisecond precision, but just barely; don't try for
microseconds since for that is the limit of precision with floating
point number representing the number of seconds from 1/1/1970 till now
(10 digits before the decimal and 4-5 after).  Here is an example:


> x <- "12:52:48:123"
> x1 <- sub("(.*):", "\\1.", x)  # replace last colon
> x1
[1] "12:52:48.123"
> xp <- as.POSIXct(x1, format="%H:%M:%OS")
> xp  # normal output
[1] "2013-09-12 12:52:48 EDT"
> format(xp, format = "%H:%M:%OS3")  # with milliseconds
[1] "12:52:48.122"

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Thu, Sep 12, 2013 at 1:26 PM, Alecia M Moser <amoser1 at binghamton.edu> wrote:
> Hello -
>
> I have imported timestamp data (collected in OpenSHAPA) into R as .csv
> file. Some columns in the data frame have timestamps in the format
> HH:MM:SS:sss. I have not found a package that will allow simple addition
> and subtraction of columns with this format, although 'strptime' in
> 'library(timeDate)' looked promising. The problem with the timeDate package
> is that it does not seem to support timestamps down to milliseconds. Are
> there any solutions available or packages that the community recommends?
> Thanks you.
>
> Alecia
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Thu Sep 12 22:14:07 2013
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 12 Sep 2013 14:14:07 -0600
Subject: [R] princomp needs more obsverations than variables?
In-Reply-To: <CAKyZeBvX46XTkX5mdif0zkcHvQUtU-c_=O3Hh1HrXjtxhjuwEQ@mail.gmail.com>
References: <CAKyZeBvX46XTkX5mdif0zkcHvQUtU-c_=O3Hh1HrXjtxhjuwEQ@mail.gmail.com>
Message-ID: <CAFEqCdwLD6YWPFnRFM+hf1e0pGnzGc6i2HZkyPh98bPBA+r32A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/a9270780/attachment.pl>

From gunter.berton at gene.com  Thu Sep 12 22:16:39 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 12 Sep 2013 13:16:39 -0700
Subject: [R] princomp needs more obsverations than variables?
In-Reply-To: <CAKyZeBvX46XTkX5mdif0zkcHvQUtU-c_=O3Hh1HrXjtxhjuwEQ@mail.gmail.com>
References: <CAKyZeBvX46XTkX5mdif0zkcHvQUtU-c_=O3Hh1HrXjtxhjuwEQ@mail.gmail.com>
Message-ID: <CACk-te0XENF-MRVxQM305mbn7FQk9KQRd77M9ypxeze32_BfVQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/94a38099/attachment.pl>

From jholtman at gmail.com  Thu Sep 12 22:21:10 2013
From: jholtman at gmail.com (jim holtman)
Date: Thu, 12 Sep 2013 16:21:10 -0400
Subject: [R] on how to make a skip-table
In-Reply-To: <alpine.DEB.2.00.1309130054380.20861@lyonesse>
References: <alpine.DEB.2.00.1309130054380.20861@lyonesse>
Message-ID: <CAAxdm-4mr1EApcAq5gmpjp4m9=2OqOxQi7MXUtZXS-S-VThWFQ@mail.gmail.com>

try this:

> record.length <- read.table(text = "    NR     length
+         1       100
+         2       130
+         3       150
+         4       148
+         5       100
+         6        83
+         7        60", header = TRUE)
> valida.records <- read.table(text = "  NR     factor
+         1       3
+         2       4
+         4       8
+         7       9", header = TRUE)
> x <- merge(record.length, valida.records, by = "NR", all.x = TRUE)
> x$seq <- cumsum(!is.na(x$factor))
>
> # need to add 1 to lines with NA to associate with next group
> x$seq[is.na(x$factor)] <- x$seq[is.na(x$factor)] + 1
>
> # split by 'seq', output last record and sum of preceeding records
> do.call(rbind
+     , lapply(split(x, x$seq), function(.sk){
+         if (nrow(.sk) > 1) .sk$skip <- sum(.sk$length[1:(nrow(.sk) - 1L)])
+         else .sk$skip <- 0
+         .sk[nrow(.sk), ] # return first value
+         })
+     )
  NR length factor seq skip
1  1    100      3   1    0
2  2    130      4   2    0
3  4    148      8   3  150
4  7     60      9   4  183
>

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Thu, Sep 12, 2013 at 1:17 PM, Zhang Weiwu <zhangweiwu at realss.com> wrote:
>
> I've got two data frames, as shown below:
> (NR means Number of Record)
>
>> record.lenths
>
>         NR     length
>         1       100
>         2       130
>         3       150
>         4       148
>         5       100
>         6        83
>         7        60
>
>> valida.records
>
>         NR     factor
>         1       3
>         2       4
>         4       8
>         7       9
>
> And I intend to obtain the following skip-table:
>
>> skip.table
>
>         NR     skip   factor
>         1       0       3
>         2       0       4
>         4       150     8
>         7       183     9
>
>
> The column 'skip' is the space needed to skip invalid records.
>
> For example, the 3rd element of skip.table has skip of '150', intended to
> skip the invalid record No.3 in record.lengths
>
> For example, the 4th element of skip.table has skip of '183', intended to
> skip the invalid record No.5 and No.6, together is 100+83.
>
> It's rather apparently intended for reading huge data files, and looks
> simple math, and I admit I couldn't find an R-ish way doing it.
>
> Thanks in advance and also thanks for pointing out if I had been on the
> right track to start with.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From michael.weylandt at gmail.com  Thu Sep 12 22:27:04 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt <michael.weylandt@gmail.com>)
Date: Thu, 12 Sep 2013 16:27:04 -0400
Subject: [R] problem with rJython and modules
In-Reply-To: <CACxE24kAJ5=FAPDjFTZ=8FCGn=bPFsJN_X5BbFr=6CThGB+JaA@mail.gmail.com>
References: <CACxE24kAJ5=FAPDjFTZ=8FCGn=bPFsJN_X5BbFr=6CThGB+JaA@mail.gmail.com>
Message-ID: <CC22A2AC-8B1E-409C-A975-B3C3A479251D@gmail.com>



On Sep 12, 2013, at 13:42, Erin Hodgess <erinm.hodgess at gmail.com> wrote:

> Dear R People:
> 
> I have been experimenting with rPython, rSymPy, and rJython.  Here is my
> latest snag:
> 
>> library(rJython)
> Loading required package: rJava
> Loading required package: rjson
>> library(rSymPy)
>> rJython <- rJython()
>> x <- "x"
>> y <- "y"
>> rJython$exec("from sympy import *")
> Error in .jcall("RJavaTools", "Ljava/lang/Object;", "invokeMethod", cl,  :
>  Traceback (most recent call last):
> 
>  File "<string>", line 1, in <module>
> 
> ImportError: No module named sympy
> 
> 
> This is on Windows 32 bit, with Version 3.0.1 of R and python 2.7.5.  Also,
> sypmy is available with regular python.

But is it installed under jython? Different platform. 

Michael

> 
> Any help would be much appreciated.
> 
> Sincerely,
> Erin
> 
> 
> -- 
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From michael.gang.peng at gmail.com  Thu Sep 12 21:56:26 2013
From: michael.gang.peng at gmail.com (Gang Peng)
Date: Thu, 12 Sep 2013 14:56:26 -0500
Subject: [R] How to avoid searching variables in global environment
Message-ID: <CAMjJGR3UkC8X9VuVuXbaad5ZkmTx4-FP4Urky78bjFz9zTwz2Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/db657a55/attachment.pl>

From michael.gang.peng at gmail.com  Thu Sep 12 22:31:03 2013
From: michael.gang.peng at gmail.com (Gang Peng)
Date: Thu, 12 Sep 2013 15:31:03 -0500
Subject: [R] on how to make a skip-table
In-Reply-To: <alpine.DEB.2.00.1309130054380.20861@lyonesse>
References: <alpine.DEB.2.00.1309130054380.20861@lyonesse>
Message-ID: <CAMjJGR14xBJn7Y5Hsg5gdj+PUPFTjpZpD4fYSL=DV7uRXPo-BQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/961f240e/attachment.pl>

From marine.regis at hotmail.fr  Thu Sep 12 22:31:37 2013
From: marine.regis at hotmail.fr (Marine Regis)
Date: Thu, 12 Sep 2013 22:31:37 +0200
Subject: [R] predict() from conditional logit model?
Message-ID: <DUB115-W96379AA4CFFC0D97751B0BE23A0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/d192f0d5/attachment.pl>

From sarah.goslee at gmail.com  Thu Sep 12 23:08:59 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 12 Sep 2013 17:08:59 -0400
Subject: [R] How to avoid searching variables in global environment
In-Reply-To: <CAMjJGR3UkC8X9VuVuXbaad5ZkmTx4-FP4Urky78bjFz9zTwz2Q@mail.gmail.com>
References: <CAMjJGR3UkC8X9VuVuXbaad5ZkmTx4-FP4Urky78bjFz9zTwz2Q@mail.gmail.com>
Message-ID: <CAM_vjukMOsAPa1KjtftX9tEixViK7XwGXLffczNDesh3PA_DLw@mail.gmail.com>

Hi,

You need to specify that a is an argument to the function:

On Thu, Sep 12, 2013 at 3:56 PM, Gang Peng <michael.gang.peng at gmail.com> wrote:
> For example:
>
> a <- 1
>
> f <- function(b){
>     return(a+b)
> }
>

f <- function(b, a) {
    return(a+b)
}

> when we call function f(2), r will search the local environment first, if
> it cannot find a, it will search global environment, and return 3. How to
> avoid r searching the global environment and return an error when we call
> this function?

The function will now give an error if a is not specified.

Sarah

-- 
Sarah Goslee
http://www.functionaldiversity.org


From gunter.berton at gene.com  Thu Sep 12 23:21:58 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 12 Sep 2013 14:21:58 -0700
Subject: [R] How to avoid searching variables in global environment
In-Reply-To: <CAM_vjukMOsAPa1KjtftX9tEixViK7XwGXLffczNDesh3PA_DLw@mail.gmail.com>
References: <CAMjJGR3UkC8X9VuVuXbaad5ZkmTx4-FP4Urky78bjFz9zTwz2Q@mail.gmail.com>
	<CAM_vjukMOsAPa1KjtftX9tEixViK7XwGXLffczNDesh3PA_DLw@mail.gmail.com>
Message-ID: <CACk-te0FhZChpq3yr8j+qLnjrBWOMJRj+xuGWv0LaiV_tS1q-Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/b1b96586/attachment.pl>

From wdunlap at tibco.com  Thu Sep 12 23:29:57 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 12 Sep 2013 21:29:57 +0000
Subject: [R] How to avoid searching variables in global environment
In-Reply-To: <CAM_vjukMOsAPa1KjtftX9tEixViK7XwGXLffczNDesh3PA_DLw@mail.gmail.com>
References: <CAMjJGR3UkC8X9VuVuXbaad5ZkmTx4-FP4Urky78bjFz9zTwz2Q@mail.gmail.com>
	<CAM_vjukMOsAPa1KjtftX9tEixViK7XwGXLffczNDesh3PA_DLw@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C342D65@PA-MBX01.na.tibco.com>

If you want to find out if you've forgotten to make 'a' an argument
you can use codetools::findGlobals(func) to list the names that don't
refer to something already defined in the 'func':
  > fun <- function(b) a + b
  > library(codetools)
  > findGlobals(fun)
  [1] "+" "a"
You need to filter out things defined in some attached package (like the "+"
from the base package).  I think that when you run 'R CMD check' on a
package this sort of check is made on the functions in the package.
findGlobals does not run the function to make its checks, it just looks at
the function.

A kludgy way to get an error message instead of having the function silently
use something from .GlobalEnv is to make the environment of the function
the parent of .GlobalEnv
   >  a <- 1000
   > environment(fun) <- parent.env(globalenv())
   > fun(7)
   Error in fun(7) : object 'a' not found
Since this is a run-time check it will not find problems in branches of the
code that are not run.  The parent environment of .GlobalEnv changes
every time you attach or detach a package.  For production code you will
want to use a package - the namespace mechanism and the check command
will take care of most of this sort of problem.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Sarah Goslee
> Sent: Thursday, September 12, 2013 2:09 PM
> To: Gang Peng
> Cc: r-help at r-project.org
> Subject: Re: [R] How to avoid searching variables in global environment
> 
> Hi,
> 
> You need to specify that a is an argument to the function:
> 
> On Thu, Sep 12, 2013 at 3:56 PM, Gang Peng <michael.gang.peng at gmail.com> wrote:
> > For example:
> >
> > a <- 1
> >
> > f <- function(b){
> >     return(a+b)
> > }
> >
> 
> f <- function(b, a) {
>     return(a+b)
> }
> 
> > when we call function f(2), r will search the local environment first, if
> > it cannot find a, it will search global environment, and return 3. How to
> > avoid r searching the global environment and return an error when we call
> > this function?
> 
> The function will now give an error if a is not specified.
> 
> Sarah
> 
> --
> Sarah Goslee
> http://www.functionaldiversity.org
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Thu Sep 12 23:47:26 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 12 Sep 2013 14:47:26 -0700 (PDT)
Subject: [R] gsub question
Message-ID: <1379022446.58829.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Try:
?string1<- "Red, Romeo, Calf"
?string2<- "Red, Rome, Ralf"
?string3<- "China, Japan, USA"
?gsub("R[[:alpha:]]{1,}","MM",string3)
#[1] "China, Japan, USA"
gsub("R[[:alpha:]]{1,}","MM",string2)
#[1] "MM, MM, MM"
?gsub("R[[:alpha:]]{1,}","MM",string1)
#[1] "MM, MM, Calf"


Other way would be:

?paste(gsub("^R.*\\w+","MM",strsplit(string1, ", ")[[1]]),collapse=", ")
#[1] "MM, MM, Calf"
A.K.




Hi all, 

I want to replace all words that begin with a given character 
with a different word. Tried gsub and str_replace_all but with little 
success. In this example I want to replace all words starting with R 
with MM. gsub replaces properly only once: 

> gsub("^R*\\w+", "MM", "Red, Rome, Ralf") 
[1] "MM, Rome, Ralf" 

Thanks in advance

From michael.gang.peng at gmail.com  Thu Sep 12 23:36:03 2013
From: michael.gang.peng at gmail.com (Gang Peng)
Date: Thu, 12 Sep 2013 16:36:03 -0500
Subject: [R] How to avoid searching variables in global environment
In-Reply-To: <CACk-te0FhZChpq3yr8j+qLnjrBWOMJRj+xuGWv0LaiV_tS1q-Q@mail.gmail.com>
References: <CAMjJGR3UkC8X9VuVuXbaad5ZkmTx4-FP4Urky78bjFz9zTwz2Q@mail.gmail.com>
	<CAM_vjukMOsAPa1KjtftX9tEixViK7XwGXLffczNDesh3PA_DLw@mail.gmail.com>
	<CACk-te0FhZChpq3yr8j+qLnjrBWOMJRj+xuGWv0LaiV_tS1q-Q@mail.gmail.com>
Message-ID: <CAMjJGR35rEPDw5QnSXwOZFM4D7uniC2oKi-aOiGNOTOpsiH06g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/95ede51b/attachment.pl>

From michael.gang.peng at gmail.com  Thu Sep 12 23:54:08 2013
From: michael.gang.peng at gmail.com (Gang Peng)
Date: Thu, 12 Sep 2013 16:54:08 -0500
Subject: [R] How to avoid searching variables in global environment
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C342D65@PA-MBX01.na.tibco.com>
References: <CAMjJGR3UkC8X9VuVuXbaad5ZkmTx4-FP4Urky78bjFz9zTwz2Q@mail.gmail.com>
	<CAM_vjukMOsAPa1KjtftX9tEixViK7XwGXLffczNDesh3PA_DLw@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C342D65@PA-MBX01.na.tibco.com>
Message-ID: <CAMjJGR08SFY16JrF5qkH=GLriaEEAHS2iOpWY08N=5heRSZ28w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/c44c31a2/attachment.pl>

From gunter.berton at gene.com  Fri Sep 13 00:17:07 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 12 Sep 2013 15:17:07 -0700
Subject: [R] How to avoid searching variables in global environment
In-Reply-To: <CAMjJGR35rEPDw5QnSXwOZFM4D7uniC2oKi-aOiGNOTOpsiH06g@mail.gmail.com>
References: <CAMjJGR3UkC8X9VuVuXbaad5ZkmTx4-FP4Urky78bjFz9zTwz2Q@mail.gmail.com>
	<CAM_vjukMOsAPa1KjtftX9tEixViK7XwGXLffczNDesh3PA_DLw@mail.gmail.com>
	<CACk-te0FhZChpq3yr8j+qLnjrBWOMJRj+xuGWv0LaiV_tS1q-Q@mail.gmail.com>
	<CAMjJGR35rEPDw5QnSXwOZFM4D7uniC2oKi-aOiGNOTOpsiH06g@mail.gmail.com>
Message-ID: <CACk-te173GqwB=zUp4L1eK6SGZ7bsrFA+mtv7BWpfX6Fdv+eSg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/82074185/attachment.pl>

From murdoch.duncan at gmail.com  Fri Sep 13 00:18:24 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 12 Sep 2013 18:18:24 -0400
Subject: [R] How to avoid searching variables in global environment
In-Reply-To: <CAMjJGR35rEPDw5QnSXwOZFM4D7uniC2oKi-aOiGNOTOpsiH06g@mail.gmail.com>
References: <CAMjJGR3UkC8X9VuVuXbaad5ZkmTx4-FP4Urky78bjFz9zTwz2Q@mail.gmail.com>
	<CAM_vjukMOsAPa1KjtftX9tEixViK7XwGXLffczNDesh3PA_DLw@mail.gmail.com>
	<CACk-te0FhZChpq3yr8j+qLnjrBWOMJRj+xuGWv0LaiV_tS1q-Q@mail.gmail.com>
	<CAMjJGR35rEPDw5QnSXwOZFM4D7uniC2oKi-aOiGNOTOpsiH06g@mail.gmail.com>
Message-ID: <52323DB0.1000407@gmail.com>

On 12/09/2013 5:36 PM, Gang Peng wrote:
> Hi Bert,
>
> Thanks for the explanation.
>
> In R, it first search the local environment and then the parent environment
> until the root environment (empty environment). I have a concern, when I
> write a function, I may write a variable name wrong by typo. But by
> coincidence,
> this variable name is defined in the parent's or the grandparent's
> environment, it is very hard to find this bug (It took me almost a day to
> find out it).  Just don't know why R do it like this.

I think the reasons are mostly historical.

A fix is to use codetools to identify the variables in your function.  
This is almost automatic if you put your code in a package and use  "R 
CMD check" on it.

Duncan Murdoch
>
> Thanks,
> Michael
>
>
>
> 2013/9/12 Bert Gunter <gunter.berton at gene.com>
>
> > Michael and Sarah:
> >
> > 1. Actually the original claim -- that R will search the global
> > environment if it does not find a free variable in the function environment
> > -- is not strictly true. It will search the function's enclosure and then
> > on up the tree of enclosures. In this case, the enclosure was the global
> > environment, but that is not always the case.
> >
> > 2. Sarah has answered one interpretation of your question. Another might
> > be -- how can you do things to throw an error when free variables are
> > encountered in a function. A qualified answer -- qualified, because there
> > are probably some clever ways to set this up that I can't and won't try to
> > think of -- is that you can't: you are defeating R's functional programming
> > paradigm by requesting such behavior. Or to put it another way: don't
> > do/expect this. Follow Sarah's recommendation instead.
> >
> > Cheers,
> > Bert
> >
> >
> > On Thu, Sep 12, 2013 at 2:08 PM, Sarah Goslee <sarah.goslee at gmail.com>wrote:
> >
> >> Hi,
> >>
> >> You need to specify that a is an argument to the function:
> >>
> >> On Thu, Sep 12, 2013 at 3:56 PM, Gang Peng <michael.gang.peng at gmail.com>
> >> wrote:
> >> > For example:
> >> >
> >> > a <- 1
> >> >
> >> > f <- function(b){
> >> >     return(a+b)
> >> > }
> >> >
> >>
> >> f <- function(b, a) {
> >>     return(a+b)
> >> }
> >>
> >> > when we call function f(2), r will search the local environment first,
> >> if
> >> > it cannot find a, it will search global environment, and return 3. How
> >> to
> >> > avoid r searching the global environment and return an error when we
> >> call
> >> > this function?
> >>
> >> The function will now give an error if a is not specified.
> >>
> >> Sarah
> >>
> >> --
> >> Sarah Goslee
> >> http://www.functionaldiversity.org
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
> >
> > --
> >
> > Bert Gunter
> > Genentech Nonclinical Biostatistics
> >
> > Internal Contact Info:
> > Phone: 467-7374
> > Website:
> >
> > http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm
> >
> >
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Fri Sep 13 00:18:50 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 12 Sep 2013 22:18:50 +0000
Subject: [R] How to avoid searching variables in global environment
In-Reply-To: <CAMjJGR08SFY16JrF5qkH=GLriaEEAHS2iOpWY08N=5heRSZ28w@mail.gmail.com>
References: <CAMjJGR3UkC8X9VuVuXbaad5ZkmTx4-FP4Urky78bjFz9zTwz2Q@mail.gmail.com>
	<CAM_vjukMOsAPa1KjtftX9tEixViK7XwGXLffczNDesh3PA_DLw@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C342D65@PA-MBX01.na.tibco.com>
	<CAMjJGR08SFY16JrF5qkH=GLriaEEAHS2iOpWY08N=5heRSZ28w@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C342D9C@PA-MBX01.na.tibco.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/f20f4d91/attachment.pl>

From murdoch.duncan at gmail.com  Fri Sep 13 00:19:33 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 12 Sep 2013 18:19:33 -0400
Subject: [R] How to avoid searching variables in global environment
In-Reply-To: <CAMjJGR08SFY16JrF5qkH=GLriaEEAHS2iOpWY08N=5heRSZ28w@mail.gmail.com>
References: <CAMjJGR3UkC8X9VuVuXbaad5ZkmTx4-FP4Urky78bjFz9zTwz2Q@mail.gmail.com>
	<CAM_vjukMOsAPa1KjtftX9tEixViK7XwGXLffczNDesh3PA_DLw@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C342D65@PA-MBX01.na.tibco.com>
	<CAMjJGR08SFY16JrF5qkH=GLriaEEAHS2iOpWY08N=5heRSZ28w@mail.gmail.com>
Message-ID: <52323DF5.3050400@gmail.com>

On 12/09/2013 5:54 PM, Gang Peng wrote:
> Hi Bill,
>
> Thanks. I think we can define the function in the environment whose parent
> environment is empty environment. But don't know how.

You can say environment(f) <- emptyenv()

but then almost nothing will work.  You wanted a+b.  It won't know what 
+ is.

Duncan Murdoch
>
> Best,
> Mike
>
>
>
>
> 2013/9/12 William Dunlap <wdunlap at tibco.com>
>
> > If you want to find out if you've forgotten to make 'a' an argument
> > you can use codetools::findGlobals(func) to list the names that don't
> > refer to something already defined in the 'func':
> >   > fun <- function(b) a + b
> >   > library(codetools)
> >   > findGlobals(fun)
> >   [1] "+" "a"
> > You need to filter out things defined in some attached package (like the
> > "+"
> > from the base package).  I think that when you run 'R CMD check' on a
> > package this sort of check is made on the functions in the package.
> > findGlobals does not run the function to make its checks, it just looks at
> > the function.
> >
> > A kludgy way to get an error message instead of having the function
> > silently
> > use something from .GlobalEnv is to make the environment of the function
> > the parent of .GlobalEnv
> >    >  a <- 1000
> >    > environment(fun) <- parent.env(globalenv())
> >    > fun(7)
> >    Error in fun(7) : object 'a' not found
> > Since this is a run-time check it will not find problems in branches of the
> > code that are not run.  The parent environment of .GlobalEnv changes
> > every time you attach or detach a package.  For production code you will
> > want to use a package - the namespace mechanism and the check command
> > will take care of most of this sort of problem.
> >
> > Bill Dunlap
> > Spotfire, TIBCO Software
> > wdunlap tibco.com
> >
> >
> > > -----Original Message-----
> > > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> > On Behalf
> > > Of Sarah Goslee
> > > Sent: Thursday, September 12, 2013 2:09 PM
> > > To: Gang Peng
> > > Cc: r-help at r-project.org
> > > Subject: Re: [R] How to avoid searching variables in global environment
> > >
> > > Hi,
> > >
> > > You need to specify that a is an argument to the function:
> > >
> > > On Thu, Sep 12, 2013 at 3:56 PM, Gang Peng <michael.gang.peng at gmail.com>
> > wrote:
> > > > For example:
> > > >
> > > > a <- 1
> > > >
> > > > f <- function(b){
> > > >     return(a+b)
> > > > }
> > > >
> > >
> > > f <- function(b, a) {
> > >     return(a+b)
> > > }
> > >
> > > > when we call function f(2), r will search the local environment first,
> > if
> > > > it cannot find a, it will search global environment, and return 3. How
> > to
> > > > avoid r searching the global environment and return an error when we
> > call
> > > > this function?
> > >
> > > The function will now give an error if a is not specified.
> > >
> > > Sarah
> > >
> > > --
> > > Sarah Goslee
> > > http://www.functionaldiversity.org
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dimitri.liakhovitski at gmail.com  Fri Sep 13 00:21:31 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 12 Sep 2013 18:21:31 -0400
Subject: [R] Shiny - can one create one RUN button?
Message-ID: <CAN2xGJY5HeNE_up6YR_qH=uwVufGxCuvEK1pXtjR5c+xLYuspA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/5ab03efa/attachment.pl>

From wdunlap at tibco.com  Fri Sep 13 00:24:05 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 12 Sep 2013 22:24:05 +0000
Subject: [R] How to avoid searching variables in global environment
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C342D9C@PA-MBX01.na.tibco.com>
References: <CAMjJGR3UkC8X9VuVuXbaad5ZkmTx4-FP4Urky78bjFz9zTwz2Q@mail.gmail.com>
	<CAM_vjukMOsAPa1KjtftX9tEixViK7XwGXLffczNDesh3PA_DLw@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C342D65@PA-MBX01.na.tibco.com>
	<CAMjJGR08SFY16JrF5qkH=GLriaEEAHS2iOpWY08N=5heRSZ28w@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C342D9C@PA-MBX01.na.tibco.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C342DCA@PA-MBX01.na.tibco.com>

Typo: in 
    environment(fun) <- new.env(parent=parent.env())
the parent.env() should have been emptyenv().  But, as
I said, you do not want to do that.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of William Dunlap
> Sent: Thursday, September 12, 2013 3:19 PM
> To: Gang Peng
> Cc: r-help at r-project.org
> Subject: Re: [R] How to avoid searching variables in global environment
> 
> You can do that with
>    environment(fun) <- new.env(parent=parent.env())
> but then your function, function(b)a+b, will not be able
> to find the "+" function.
> 
> Putting this code into a package simplifies things a lot.
> 
> E.g., I added a file containing the two lines
>    phi <- sum(1/(1:1e6)) - log(1e6) # 0.5772...
>    fun <- function(b) a + b + phi
> to a package (and added phi and fun to the NAMESPACE file's export
> command).  Then R CMD check myPackage reported
>    * checking R code for possible problems ... Note
>    fun: no visible binding for global variable 'a'
> It did not complain about the "+" or "phi", since they are
> either in the package or in some package required by my
> package but it did complain about the "a".
> 
> Furthermore, at runtime, fun will always get phi from the package,
> even if I happen to have a phi in  my global environment.
>   > fun(10)
>   Error in fun(10) : object 'a' not found
>   > a <- 1000
>   > fun(10) # uses .GlobalEnv's a
>   [1] 1010.577
>   > phi <- 100
>   > fun(10) # still uses myPackage's phi
>   [1] 1010.577
> 
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
> 
> From: Gang Peng [mailto:michael.gang.peng at gmail.com]
> Sent: Thursday, September 12, 2013 2:54 PM
> To: William Dunlap
> Cc: Sarah Goslee; r-help at r-project.org
> Subject: Re: [R] How to avoid searching variables in global environment
> 
> Hi Bill,
> 
> Thanks. I think we can define the function in the environment whose parent environment
> is empty environment. But don't know how.
> Best,
> Mike
> 
> 
> 2013/9/12 William Dunlap <wdunlap at tibco.com<mailto:wdunlap at tibco.com>>
> If you want to find out if you've forgotten to make 'a' an argument
> you can use codetools::findGlobals(func) to list the names that don't
> refer to something already defined in the 'func':
>   > fun <- function(b) a + b
>   > library(codetools)
>   > findGlobals(fun)
>   [1] "+" "a"
> You need to filter out things defined in some attached package (like the "+"
> from the base package).  I think that when you run 'R CMD check' on a
> package this sort of check is made on the functions in the package.
> findGlobals does not run the function to make its checks, it just looks at
> the function.
> 
> A kludgy way to get an error message instead of having the function silently
> use something from .GlobalEnv is to make the environment of the function
> the parent of .GlobalEnv
>    >  a <- 1000
>    > environment(fun) <- parent.env(globalenv())
>    > fun(7)
>    Error in fun(7) : object 'a' not found
> Since this is a run-time check it will not find problems in branches of the
> code that are not run.  The parent environment of .GlobalEnv changes
> every time you attach or detach a package.  For production code you will
> want to use a package - the namespace mechanism and the check command
> will take care of most of this sort of problem.
> 
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com<http://tibco.com>
> 
> 
> > -----Original Message-----
> > From: r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org> [mailto:r-
> help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf
> > Of Sarah Goslee
> > Sent: Thursday, September 12, 2013 2:09 PM
> > To: Gang Peng
> > Cc: r-help at r-project.org<mailto:r-help at r-project.org>
> > Subject: Re: [R] How to avoid searching variables in global environment
> >
> > Hi,
> >
> > You need to specify that a is an argument to the function:
> >
> > On Thu, Sep 12, 2013 at 3:56 PM, Gang Peng
> <michael.gang.peng at gmail.com<mailto:michael.gang.peng at gmail.com>> wrote:
> > > For example:
> > >
> > > a <- 1
> > >
> > > f <- function(b){
> > >     return(a+b)
> > > }
> > >
> >
> > f <- function(b, a) {
> >     return(a+b)
> > }
> >
> > > when we call function f(2), r will search the local environment first, if
> > > it cannot find a, it will search global environment, and return 3. How to
> > > avoid r searching the global environment and return an error when we call
> > > this function?
> >
> > The function will now give an error if a is not specified.
> >
> > Sarah
> >
> > --
> > Sarah Goslee
> > http://www.functionaldiversity.org
> >
> > ______________________________________________
> > R-help at r-project.org<mailto:R-help at r-project.org> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jim at bitwrit.com.au  Fri Sep 13 00:45:09 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 13 Sep 2013 08:45:09 +1000
Subject: [R] Plot help
In-Reply-To: <CAGNSkSk_OZe5rOSrPQ6VDPCuq_teCN-vTUmg2zGY+vtsjO9zOg@mail.gmail.com>
References: <CAGNSkSk_OZe5rOSrPQ6VDPCuq_teCN-vTUmg2zGY+vtsjO9zOg@mail.gmail.com>
Message-ID: <523243F5.7040500@bitwrit.com.au>

On 09/13/2013 12:48 AM, Moshiur Rahman wrote:
> Hi R-helpers,
>
> Can anyone help me to give hints/packages to make a simple bar plot with
> mean and standard error of variables (A, C&  F) that I'd like to plot in X
> and the values in Y? The factor (sex) should be as legend (Male&  Female).
> Actually, I'd prefer to have a plot like the attached Fig.
>
>> data:     Sex    A   C   F
> 1   Male  3.4 1.1 8.6
> 2   Male  6.1 2.4 0.1
> 3   Male   NA 0.7 0.8
> 4 Female 12.2  NA 0.6
> 5 Female  3.4 2.2 0.1
> 6 Female  3.5 2.4 2.7
>
>
Hi Moshi,
Your example didn't come through, but I will take a guess:

mrdat<-read.table(text="Sex    A   C   F
Male  3.4 1.1 8.6
Male  6.1 2.4 0.1
Male   NA 0.7 0.8
Female 12.2  NA 0.6
Female  3.4 2.2 0.1
Female  3.5 2.4 2.7",header=TRUE)
mmeans<-sapply(mrdat[1:3,2:4],mean,na.rm=TRUE)
fmeans<-sapply(mrdat[4:6,2:4],mean,na.rm=TRUE)
mfmeans<-matrix(c(mmeans,fmeans),nrow=2,byrow=TRUE)
barpos<-barplot(mfmeans,names.arg=c("A","C","F"),
  col=c("lightblue","pink"),beside=TRUE,
  main="Barplot",ylim=c(0,10))
library(plotrix)
mserrs<-sapply(mrdat[1:3,2:4],std.error,na.rm=TRUE)
fserrs<-sapply(mrdat[4:6,2:4],std.error,na.rm=TRUE)
mfserrs<-matrix(c(mserrs,fserrs),nrow=2,byrow=TRUE)
dispersion(barpos,mfmeans,mfserrs)
legend("top",c("Male","Female"),fill=c("lightblue","pink"))

Note that this plot and the one requested in your previous post are 
likely to attract negative comment.

Jim


From dwinsemius at comcast.net  Fri Sep 13 00:52:33 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 12 Sep 2013 17:52:33 -0500
Subject: [R] predict() from conditional logit model?
In-Reply-To: <DUB115-W96379AA4CFFC0D97751B0BE23A0@phx.gbl>
References: <DUB115-W96379AA4CFFC0D97751B0BE23A0@phx.gbl>
Message-ID: <FBB4FBB5-677A-4230-A8AE-6BB859A2EE87@comcast.net>


On Sep 12, 2013, at 3:31 PM, Marine Regis wrote:
>
> Hello everybody,
>
> I used the function clogit() (package survival) to build a  
> conditional logit
> model. This is the R output of my model :
> coef exp(coef) se(coef) robust se z
> Pr(>|z|)
> anthro 2.14776 8.56565 0.09352 0.53989 3.978 6.94e-05 ***
> cor 0.92365 2.51846 0.07757 0.41944 2.202 0.027659 *
> for 1.55191 4.72047 0.07513 0.41488 3.741 0.000184
> ***
> ---
> Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> The covariates anthro, cor and for are dichotomic covariates (0/1).
> Then, I used the function predict() to calculate predicted values as  
> follows
> :
>
> modpred <- predict(ML,type="lp")

You do understand that is on a log-relative-probability scale, right?  
And that it is relative to the mean values for the entire dataset?

>
> and I obtained the following values for the first line of my  
> original data :
>
> anthro cor for predited
> 1 0 1 0 0.0839679
>
> With modpred <- predict(ML,type="expected"), I obtained :
> anthro cor for predited
> 1 0 1 0 0.09618096

>
> My question is : from coefficients of clogit model, how can I find the
> predicted values 0.0839679 and 0.09618096 ?

You need to understand that those are really very different  
"predictions".

> In addition, how can I obtain predicted values ranged from 0 to 1 ?
>
> Thank you very much for your help.

(Reading the help pages.) There does not appear to be a  
`predict.clogit` function but clogit objects inherit from coxph  
objects so reading the Details section from `predict.coxph`:

"The Cox model is a relative risk model; predictions of type "linear  
predictor", "risk", and "terms" are all relative to the sample from  
which they came. By default, the reference value for each of these is  
the mean covariate within strata. The primary underlying reason is  
statistical: a Cox model only predicts relative risks between pairs of  
subjects within the same strata, and hence the addition of a constant  
to any covariate, either overall or only within a particular stratum,  
has no effect on the fitted results. Using the reference="strata"  
option causes this to be true for predictions as well."

The predict.coxph function is fairly long:

getAnywhere(predict.coxph)

-- 
David Winsemius, MD
Alameda, CA, USA


From macqueen1 at llnl.gov  Fri Sep 13 00:54:30 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 12 Sep 2013 22:54:30 +0000
Subject: [R] failure to replayPlot() a recordedplot object saved in a
 previous session?
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521910D43AB81@PRDEXMBX-08.the-lab.llnl.gov>

I have the following experience.

If I use, for example,
   tmp <-  recordPlot()
in a session, then immediately the saved plot replays successfully using
   replayPlot()
in the same session. But not in the next R session. See examples below,
copy/pasted from my shell window.

The first R session is brand new; no saved objects left over from a
previous session.

I also have the same experience with R 3.0.1 patched on a linux machine
(RHEL).


Is this a known or expected behavior?

Thanks
-Don


#### R session #1

mydir[42]% R

R version 3.0.1 Patched (2013-08-13 r63562) -- "Good Sport"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin10.8.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> 
> x11()
> plot(1:2)
> tmp <- recordPlot()
> replayPlot(tmp)
> q()
Save workspace image? [y/n/c]: y




#### R session #2


mydir[43]% R

R version 3.0.1 Patched (2013-08-13 r63562) -- "Good Sport"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin10.8.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> ls()
[1] "tmp"
> class(tmp)
[1] "recordedplot"
> x11()
> replayPlot(tmp)
Error: NULL value passed as symbol address
> 
> sessionInfo()
R version 3.0.1 Patched (2013-08-13 r63562)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
> 



-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062


From smartpink111 at yahoo.com  Fri Sep 13 02:10:21 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 12 Sep 2013 17:10:21 -0700 (PDT)
Subject: [R] on how to make a skip-table
In-Reply-To: <alpine.DEB.2.00.1309130054380.20861@lyonesse>
References: <alpine.DEB.2.00.1309130054380.20861@lyonesse>
Message-ID: <1379031021.95206.YahooMailNeo@web142606.mail.bf1.yahoo.com>

HI,
May be this helps:

record.length <- read.table(text = "NR??? length
??????? 1????? 100
??????? 2????? 130
??????? 3????? 150
??????? 4????? 148
??????? 5????? 100
??????? 6??????? 83
??????? 7??????? 60", sep="",header = TRUE)
?valida.records <- read.table(text = "NR??? factor
??????? 1????? 3
??????? 2????? 4
??????? 4????? 8
??????? 7????? 9", sep="", header = TRUE)
?indx<-diff(valida.records$NR)-1
skip.table<- within(valida.records, {skip<- with(record.length,tapply(length,c(-1,rep(indx,indx+1)),function(x) sum(x[-length(x)])))})[,c(1,3,2)]
skip.table
? NR skip factor
#1? 1??? 0????? 3
#2? 2??? 0????? 4
#3? 4? 150????? 8
#4? 7? 183????? 9
A.K.





----- Original Message -----
From: Zhang Weiwu <zhangweiwu at realss.com>
To: r-help at r-project.org
Cc: 
Sent: Thursday, September 12, 2013 1:17 PM
Subject: [R] on how to make a skip-table


I've got two data frames, as shown below:
(NR means Number of Record)

> record.lenths
? ? ? ?  NR? ?  length
? ? ? ?  1? ? ?  100
? ? ? ?  2? ? ?  130
? ? ? ?  3? ? ?  150
? ? ? ?  4? ? ?  148
? ? ? ?  5? ? ?  100
? ? ? ?  6? ? ? ? 83
??? 7???  60

> valida.records
??? NR? ?  factor
??? 1? ? ?  3
??? 2? ? ?  4
??? 4? ? ?  8
??? 7? ? ?  9

And I intend to obtain the following skip-table:

> skip.table
??? NR? ?  skip?  factor
??? 1? ? ?  0? ? ?  3
??? 2? ? ?  0? ? ?  4
??? 4? ? ?  150? ?  8
??? 7? ? ?  183? ?  9


The column 'skip' is the space needed to skip invalid records.

For example, the 3rd element of skip.table has skip of '150', intended to 
skip the invalid record No.3 in record.lengths

For example, the 4th element of skip.table has skip of '183', intended to 
skip the invalid record No.5 and No.6, together is 100+83.

It's rather apparently intended for reading huge data files, and looks 
simple math, and I admit I couldn't find an R-ish way doing it.

Thanks in advance and also thanks for pointing out if I had been on the 
right track to start with.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From safisce at gmail.com  Fri Sep 13 02:37:16 2013
From: safisce at gmail.com (Safiye Celik)
Date: Thu, 12 Sep 2013 17:37:16 -0700
Subject: [R] Deterministic initialization for k-means
Message-ID: <CAJRSaT_iLo3WJt9Z1SrF65ooVKvk3zj=eOCd35fpmALrZDg+yQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/48ec60c5/attachment.pl>

From michael.gang.peng at gmail.com  Fri Sep 13 02:45:45 2013
From: michael.gang.peng at gmail.com (Michael Peng)
Date: Thu, 12 Sep 2013 19:45:45 -0500
Subject: [R] How to avoid searching variables in global environment
In-Reply-To: <CACk-te173GqwB=zUp4L1eK6SGZ7bsrFA+mtv7BWpfX6Fdv+eSg@mail.gmail.com>
References: <CAMjJGR3UkC8X9VuVuXbaad5ZkmTx4-FP4Urky78bjFz9zTwz2Q@mail.gmail.com>
	<CAM_vjukMOsAPa1KjtftX9tEixViK7XwGXLffczNDesh3PA_DLw@mail.gmail.com>
	<CACk-te0FhZChpq3yr8j+qLnjrBWOMJRj+xuGWv0LaiV_tS1q-Q@mail.gmail.com>
	<CAMjJGR35rEPDw5QnSXwOZFM4D7uniC2oKi-aOiGNOTOpsiH06g@mail.gmail.com>
	<CACk-te173GqwB=zUp4L1eK6SGZ7bsrFA+mtv7BWpfX6Fdv+eSg@mail.gmail.com>
Message-ID: <CAMjJGR2ezTWyVHKO8SofC2Bo7CdaVTrtN8+OPNeeGANFHCBA4A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/8dcb2908/attachment.pl>

From sachin.abeywardana at gmail.com  Fri Sep 13 02:46:06 2013
From: sachin.abeywardana at gmail.com (Sachinthaka Abeywardana)
Date: Fri, 13 Sep 2013 10:46:06 +1000
Subject: [R] xtable use plus minus
Message-ID: <CAGuusR_oUt9NduBYCJug5Nh_Kwr8X7ek4Os-FZPGtVHeQ=n0zg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130913/d80457d7/attachment.pl>

From michael.gang.peng at gmail.com  Fri Sep 13 02:49:33 2013
From: michael.gang.peng at gmail.com (Michael Peng)
Date: Thu, 12 Sep 2013 19:49:33 -0500
Subject: [R] How to avoid searching variables in global environment
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C342DCA@PA-MBX01.na.tibco.com>
References: <CAMjJGR3UkC8X9VuVuXbaad5ZkmTx4-FP4Urky78bjFz9zTwz2Q@mail.gmail.com>
	<CAM_vjukMOsAPa1KjtftX9tEixViK7XwGXLffczNDesh3PA_DLw@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C342D65@PA-MBX01.na.tibco.com>
	<CAMjJGR08SFY16JrF5qkH=GLriaEEAHS2iOpWY08N=5heRSZ28w@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C342D9C@PA-MBX01.na.tibco.com>
	<E66794E69CFDE04D9A70842786030B931C342DCA@PA-MBX01.na.tibco.com>
Message-ID: <CAMjJGR21HA_hce0vVBCjs3EBJph40w_3iXkOqzak+rPDRNfk8g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/89048809/attachment.pl>

From smartpink111 at yahoo.com  Fri Sep 13 03:29:41 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 12 Sep 2013 18:29:41 -0700 (PDT)
Subject: [R] xtable use plus minus
In-Reply-To: <CAGuusR_oUt9NduBYCJug5Nh_Kwr8X7ek4Os-FZPGtVHeQ=n0zg@mail.gmail.com>
References: <CAGuusR_oUt9NduBYCJug5Nh_Kwr8X7ek4Os-FZPGtVHeQ=n0zg@mail.gmail.com>
Message-ID: <1379035781.82275.YahooMailNeo@web142603.mail.bf1.yahoo.com>



Hi,
Try:
a_table[grep("\\d+",a_table)]<- paste0(a_table[grep("\\d+",a_table)],"$\\pm$")
library(xtable)
?print(xtable(a_table),sanitize.text.function=identity)
% latex table generated in R 3.0.1 by xtable 1.7-1 package
% Thu Sep 12 21:26:45 2013
\begin{table}[ht]
\centering
\begin{tabular}{rlllll}
? \hline
?& 1 & 2 & 3 & 4 & 5 \\ 
? \hline
1 & Fruits & Adam & errorA & steve & errorS \\ 
? 2 & apples & 17.1$\pm$ & 2.22$\pm$ & 3.2$\pm$ & 1.1$\pm$ \\ 
? 3 & oranges & 3.1$\pm$ & 2.55$\pm$ & 18.1$\pm$ & 3.2$\pm$ \\ 
?? \hline
\end{tabular}
\end{table}

A.K.



----- Original Message -----
From: Sachinthaka Abeywardana <sachin.abeywardana at gmail.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Thursday, September 12, 2013 8:46 PM
Subject: [R] xtable use plus minus

I am using a similar dataset to the following:

a= c("Fruits", "Adam","errorA", "steve", "errorS",
? ?  "apples", 17.1,2.22, 3.2,1.1,
? ?  "oranges", 3.1,2.55, 18.1,3.2 )
a_table=data.matrix(t(matrix(a,nrow=5)))

I would like to plus minus every second column starting from errorA (using
xtable/ hmisc)

example output (ignoring decimals):

Fruits && Adam && Steve \\
Apples && 17\pm 2 && 3 \pm 1 \\
Oranges && 3\pm 2 && 18 \pm 3\\

Additionally is there any way I can have just to 2 d.p.?

Thanks,
Sachin

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From dulcalma at bigpond.com  Fri Sep 13 04:11:45 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Fri, 13 Sep 2013 12:11:45 +1000
Subject: [R] xtable use plus minus
In-Reply-To: <CAGuusR_oUt9NduBYCJug5Nh_Kwr8X7ek4Os-FZPGtVHeQ=n0zg@mail.gmail.com>
References: <CAGuusR_oUt9NduBYCJug5Nh_Kwr8X7ek4Os-FZPGtVHeQ=n0zg@mail.gmail.com>
Message-ID: <000601ceb026$99110b80$cb332280$@bigpond.com>

Here is a start

a= c("Fruits", "Adam","errorA", "steve", "errorS",
     "apples", 17.1,2.22, 3.2,1.1,
     "oranges", 3.1,2.55, 18.1,3.2 )
a_table=data.matrix(t(matrix(a,nrow=5)))

# restructure data
ahead = a_table[1,]
atab <- data.frame(a_table[-1,])
for (j in 2:5) atab[,j]=trunc(as.numeric(atab[,j]))

names(atab) <- ahead
atab
       X1 X2 X3 X4 X5
1  apples 17  2  3  1
2 oranges  3  2 18  3


  print(
  xtable(atab,
         digits = rep(0,6),
         ),
         type    = "latex",
         tabular.environment = "tabular",
         include.rownames = FALSE,
         include.colnames = TRUE,
         only.contents = TRUE, #NA.string = " ",
         hline.after = NULL
  ) ## xtable

% latex table generated in R 3.0.1 by xtable 1.7-1 package
% Fri Sep 13 12:04:31 2013
Fruits & Adam & errorA & steve & errorS \\ 
 apples & 17 & 2 & 3 & 1 \\ 
  oranges & 3 & 2 & 18 & 3 \\

You did not say how you wanted your output latex html ...

For latex you can use latex commands using new columntype to format \pm

Regards

Duncan


Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Sachinthaka Abeywardana
Sent: Friday, 13 September 2013 10:46
To: r-help at r-project.org
Subject: [R] xtable use plus minus

I am using a similar dataset to the following:

a= c("Fruits", "Adam","errorA", "steve", "errorS",
     "apples", 17.1,2.22, 3.2,1.1,
     "oranges", 3.1,2.55, 18.1,3.2 )
a_table=data.matrix(t(matrix(a,nrow=5)))

I would like to plus minus every second column starting from errorA (using
xtable/ hmisc)

example output (ignoring decimals):

 Fruits && Adam && Steve \\
 Apples && 17\pm 2 && 3 \pm 1 \\
 Oranges && 3\pm 2 && 18 \pm 3\\

Additionally is there any way I can have just to 2 d.p.?

Thanks,
Sachin

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Fri Sep 13 04:21:43 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 12 Sep 2013 19:21:43 -0700 (PDT)
Subject: [R] xtable use plus minus
In-Reply-To: <1379035781.82275.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <CAGuusR_oUt9NduBYCJug5Nh_Kwr8X7ek4Os-FZPGtVHeQ=n0zg@mail.gmail.com>
	<1379035781.82275.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <1379038903.81403.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
Also:


a_table[grep("\\d+",a_table)]<-paste0(sprintf("%.2f",as.numeric(a_table[grep("\\d+",a_table)])),"$\\pm$") # 2 d.p.
print(xtable(a_table),sanitize.text.function=identity)


A.K.

----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Sachinthaka Abeywardana <sachin.abeywardana at gmail.com>
Cc: R help <r-help at r-project.org>
Sent: Thursday, September 12, 2013 9:29 PM
Subject: Re: [R] xtable use plus minus



Hi,
Try:
a_table[grep("\\d+",a_table)]<- paste0(a_table[grep("\\d+",a_table)],"$\\pm$")
library(xtable)
?print(xtable(a_table),sanitize.text.function=identity)
% latex table generated in R 3.0.1 by xtable 1.7-1 package
% Thu Sep 12 21:26:45 2013
\begin{table}[ht]
\centering
\begin{tabular}{rlllll}
? \hline
?& 1 & 2 & 3 & 4 & 5 \\ 
? \hline
1 & Fruits & Adam & errorA & steve & errorS \\ 
? 2 & apples & 17.1$\pm$ & 2.22$\pm$ & 3.2$\pm$ & 1.1$\pm$ \\ 
? 3 & oranges & 3.1$\pm$ & 2.55$\pm$ & 18.1$\pm$ & 3.2$\pm$ \\ 
?? \hline
\end{tabular}
\end{table}

A.K.



----- Original Message -----
From: Sachinthaka Abeywardana <sachin.abeywardana at gmail.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Thursday, September 12, 2013 8:46 PM
Subject: [R] xtable use plus minus

I am using a similar dataset to the following:

a= c("Fruits", "Adam","errorA", "steve", "errorS",
? ?? "apples", 17.1,2.22, 3.2,1.1,
? ?? "oranges", 3.1,2.55, 18.1,3.2 )
a_table=data.matrix(t(matrix(a,nrow=5)))

I would like to plus minus every second column starting from errorA (using
xtable/ hmisc)

example output (ignoring decimals):

Fruits && Adam && Steve \\
Apples && 17\pm 2 && 3 \pm 1 \\
Oranges && 3\pm 2 && 18 \pm 3\\

Additionally is there any way I can have just to 2 d.p.?

Thanks,
Sachin

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Fri Sep 13 04:54:02 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 12 Sep 2013 19:54:02 -0700 (PDT)
Subject: [R] xtable use plus minus
In-Reply-To: <1379038903.81403.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <CAGuusR_oUt9NduBYCJug5Nh_Kwr8X7ek4Os-FZPGtVHeQ=n0zg@mail.gmail.com>
	<1379035781.82275.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1379038903.81403.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1379040842.9314.YahooMailNeo@web142601.mail.bf1.yahoo.com>

HI,
Sorry, there was a mistake as I didn't properly looked at the output you wanted.

a_tableNew<- data.matrix(matrix(0,3,3))

a_tableNew[2:3,2:3]<-paste0(sprintf("%.2f",as.numeric( a_table[,seq(2,5,2)][grep("\\d+",a_table[,seq(2,5,2)])])),"$\\pm$",sprintf("%.2f",as.numeric( a_table[,seq(3,5,2)][grep("\\d+",a_table[,seq(2,5,2)])])))
a_tableNew[grep("\\b0\\b",a_tableNew)]<- a_table[!grepl("\\d+",a_table)][!grepl("error",a_table[!grepl("\\d+",a_table)])]
?a_tableNew
#???? [,1]????? [,2]????????????? [,3]???????????? 
#[1,] "Fruits"? "Adam"??????????? "steve"????????? 
#[2,] "apples"? "17.10$\\pm$2.22" "3.20$\\pm$1.10" 
#[3,] "oranges" "3.10$\\pm$2.55"? "18.10$\\pm$3.20"


print(xtable(a_tableNew),sanitize.text.function=identity)

#If you wanted the column names as "Fruits", "Adam" etc,

colnames(a_tableNew)<- a_tableNew[1,]
?a_tableNew<- a_tableNew[-1,]


print(xtable(a_tableNew),sanitize.text.function=identity)
% latex table generated in R 3.0.1 by xtable 1.7-1 package
% Thu Sep 12 22:42:58 2013
\begin{table}[ht]
\centering
\begin{tabular}{rlll}
? \hline
?& Fruits & Adam & steve \\ 
? \hline
1 & apples & 17.10$\pm$2.22 & 3.20$\pm$1.10 \\ 
? 2 & oranges & 3.10$\pm$2.55 & 18.10$\pm$3.20 \\ 
?? \hline
\end{tabular}
\end{table}


A.K.



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Sachinthaka Abeywardana <sachin.abeywardana at gmail.com>
Cc: R help <r-help at r-project.org>
Sent: Thursday, September 12, 2013 10:21 PM
Subject: Re: [R] xtable use plus minus

Hi,
Also:


a_table[grep("\\d+",a_table)]<-paste0(sprintf("%.2f",as.numeric(a_table[grep("\\d+",a_table)])),"$\\pm$") # 2 d.p.
print(xtable(a_table),sanitize.text.function=identity)


A.K.

----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Sachinthaka Abeywardana <sachin.abeywardana at gmail.com>
Cc: R help <r-help at r-project.org>
Sent: Thursday, September 12, 2013 9:29 PM
Subject: Re: [R] xtable use plus minus



Hi,
Try:
a_table[grep("\\d+",a_table)]<- paste0(a_table[grep("\\d+",a_table)],"$\\pm$")
library(xtable)
?print(xtable(a_table),sanitize.text.function=identity)
% latex table generated in R 3.0.1 by xtable 1.7-1 package
% Thu Sep 12 21:26:45 2013
\begin{table}[ht]
\centering
\begin{tabular}{rlllll}
? \hline
?& 1 & 2 & 3 & 4 & 5 \\ 
? \hline
1 & Fruits & Adam & errorA & steve & errorS \\ 
? 2 & apples & 17.1$\pm$ & 2.22$\pm$ & 3.2$\pm$ & 1.1$\pm$ \\ 
? 3 & oranges & 3.1$\pm$ & 2.55$\pm$ & 18.1$\pm$ & 3.2$\pm$ \\ 
?? \hline
\end{tabular}
\end{table}

A.K.



----- Original Message -----
From: Sachinthaka Abeywardana <sachin.abeywardana at gmail.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Thursday, September 12, 2013 8:46 PM
Subject: [R] xtable use plus minus

I am using a similar dataset to the following:

a= c("Fruits", "Adam","errorA", "steve", "errorS",
? ?? "apples", 17.1,2.22, 3.2,1.1,
? ?? "oranges", 3.1,2.55, 18.1,3.2 )
a_table=data.matrix(t(matrix(a,nrow=5)))

I would like to plus minus every second column starting from errorA (using
xtable/ hmisc)

example output (ignoring decimals):

Fruits && Adam && Steve \\
Apples && 17\pm 2 && 3 \pm 1 \\
Oranges && 3\pm 2 && 18 \pm 3\\

Additionally is there any way I can have just to 2 d.p.?

Thanks,
Sachin

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From marine.regis at hotmail.fr  Fri Sep 13 05:38:58 2013
From: marine.regis at hotmail.fr (Marine Regis)
Date: Fri, 13 Sep 2013 05:38:58 +0200
Subject: [R] FW:  predict() from conditional logit model?
In-Reply-To: <FBB4FBB5-677A-4230-A8AE-6BB859A2EE87@comcast.net>
References: <DUB115-W96379AA4CFFC0D97751B0BE23A0@phx.gbl>,
	<FBB4FBB5-677A-4230-A8AE-6BB859A2EE87@comcast.net>
Message-ID: <DUB115-W17B5F3274D33F3AAFF7A76E23B0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130913/f3932052/attachment.pl>

From zhangweiwu at realss.com  Fri Sep 13 06:18:28 2013
From: zhangweiwu at realss.com (Zhang Weiwu)
Date: Fri, 13 Sep 2013 12:18:28 +0800 (CST)
Subject: [R] on how to make a skip-table
In-Reply-To: <alpine.DEB.2.00.1309130054380.20861@lyonesse>
References: <alpine.DEB.2.00.1309130054380.20861@lyonesse>
Message-ID: <alpine.DEB.2.00.1309131159250.5637@lyonesse>


It is a nice surprise to wake up receiving three answers, all producing 
correct results. Many thanks to all of you.

Jim Holtman solved it with amazing clarity. Gang Peng using a traditioanl 
C-like pointer style and Arun with awesome tight code thanks to diff().

I am embrassed to see my mis-spellings inherited in the answers ('lenths' 
should be 'lengths' and 'valida' should be 'valid'). This experience is to 
behove me to not to code in midnight again.

For anyone wishing to test these methods, I have compiled them all into one 
R script file, pasted at the end of this email.

Jim Holtman asked me to elaborate the problem:

     It is a common problem in reading sparse variable-lenght record data
     file.  Records are stored in file one next to another. The length of
     each record is known in advance, but a lot of them records are invalid,
     and should be skipped to make efficient use of memory.

     Ideally the datafile-reading routine should receive a skip-table. Before
     reading each wanted/valid record, it seeks forward for the distance
     given in the skip-table. The problem is how to obtain such a skip table.

     What we have at hand to produce the skip table, is a set of two data
     frames: a record.lengths data frame about each record's length, and a
     valid.records data frame about which records are significant and should
     be read.

--

###### input data:

record.lengths <- read.table(text = "    NR     length
          1       100
          2       130
          3       150
          4       148
          5       100
          6        83
          7        60", header = TRUE)

valid.records <- read.table(text = "  NR     factor
          1       3
          2       4
          4       8
          7       9", header = TRUE)

####### Jim Holtman's method:

x <- merge(record.length, valid.records, by = "NR", all.x = TRUE)
x$seq <- cumsum(!is.na(x$factor))

# need to add 1 to lines with NA to associate with next group
x$seq[is.na(x$factor)] <- x$seq[is.na(x$factor)] + 1

# split by 'seq', output last record and sum of preceeding records
skip.table <- do.call(rbind
      , lapply(split(x, x$seq), function(.sk){
          if (nrow(.sk) > 1) .sk$skip <- sum(.sk$length[1:(nrow(.sk) - 1L)])
          else .sk$skip <- 0
          .sk[nrow(.sk), ] # return first value
          })
      )

print(skip.table)


####### Gang Peng's method:

n.record <- length(record.lengths$NR)
index    <- record.lengths$NR %in% valid.records$NR
tmp <- 1:n.record
ind <- tmp[index]
st  <- 1
skip <- rep(0,length(ind))
for (i in 1:length(ind)) {
 	if(st<ind[i]){
 		skip[i]<-sum(record.lengths$length[st:(ind[i]-1)])
 	}
 	st <- ind[i]+1
}
print(cbind(valid.records,skip))

####### Arun's method:
indx<-diff(valid.records$NR)-1
skip.table<- within(valid.records, {skip<-
with(record.lengths,tapply(length,c(-1,rep(indx,indx+1)),function(x)
sum(x[-length(x)])))})[,c(1,3,2)]
print(skip.table)


From smartpink111 at yahoo.com  Fri Sep 13 07:12:43 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 12 Sep 2013 22:12:43 -0700 (PDT)
Subject: [R] help with a simple function
Message-ID: <1379049163.7091.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,

rownames(y_raw_mt)=y_raw[,1] ## y_raw not defined.


set.seed(25)
mat1<- matrix(sample(c(NA,1:20),100,replace=TRUE),20,5)

#changed the function to process 'mat1'.? Also, it is better to read the file separately and check ?str(dt.table) before proceeding.
write.table1=function(durty_data){? 
?# dt.table=read.table(durty_data, sep = "\t", header=T)#
?# y_raw_mt=as.matrix(dt.table[2:174])####
y_raw_mt<- durty_data? 
rownames(y_raw_mt)= paste0("Col",1:nrow(y_raw_mt)) #assigning the raw names to the matrix
? y_raw_mt_t=t(y_raw_mt)####
? y_raw_mt_t_mean=apply(y_raw_mt_t, 2, mean, na.rm=T)###
? means=c(y_raw_mt_t_mean)##
?
? y_raw_mt_t_meanbind=rbind(y_raw_mt_t,means)##
?
?
? t=function(x) {
??? x[is.na(x)]? = mean(x, na.rm = T)
??? return(x)
? }
?
? write.a.nice.table=apply(y_raw_mt_t_meanbind,2,t)
? return(write.a.nice.table)
}

#Function seemed to work as intended.
?write.table1(mat1)
????? Col1 Col2 Col3 Col4 Col5 Col6 Col7 Col8 Col9 Col10 Col11 Col12 Col13
???????? 8 14.0? 3.0 18.0? 2.0?? 20 13.0? 7.0? 1.0???? 5?? 6.0???? 7? 20.0
???????? 9? 9.0? 1.0? 3.0? 6.0??? 6? 1.0 12.0 11.0???? 4? 17.0???? 7?? 4.0
??????? 14? 5.0 11.0 15.0 11.0??? 6 20.0 14.0? 1.0??? 15?? 2.0??? 15? 17.0
???????? 2? 4.0? 6.0 14.0 13.0?? 17? 9.0 18.0 13.0???? 5? 18.0???? 2?? 1.0
??????? 12? 7.0 10.0? 1.0 16.0?? 16? 6.0? 8.0 16.0??? 11? 10.0???? 4? 12.0
means??? 9? 7.8? 6.2 10.2? 9.6?? 13? 9.8 11.8? 8.4???? 8? 10.6???? 7? 10.8
????? Col14 Col15 Col16 Col17 Col18 Col19 Col20
?????? 12.0? 14.0???? 3? 11.0? 15.0? 10.0??? 15
??????? 2.0? 17.0???? 8? 19.0?? 7.0?? 3.0???? 2
?????? 10.0? 11.0???? 2?? 2.0? 11.0?? 3.0???? 2
?????? 16.0?? 4.0???? 9?? 2.0? 17.0?? 3.0???? 3
?????? 13.0? 11.5???? 8? 13.0? 18.0?? 4.0???? 3
means? 10.6? 11.5???? 6?? 9.4? 13.6?? 4.6???? 5
?rowMeans(mat1,na.rm=TRUE)
# [1]? 9.0? 7.8? 6.2 10.2? 9.6 13.0? 9.8 11.8? 8.4? 8.0 10.6? 7.0 10.8 10.6 11.5
#[16]? 6.0? 9.4 13.6? 4.6? 5.0


A.K.





hi, I am new to are, very new and want to ask what's wrong with this 
function: It is suppose to read a table and return its matrix transposed
 with NA replaced by the average of each column and a row of means at 
the bottom row. The separated parts are returned correctly. Thanks a lot
 for any help. 

Guy 

write.table=function(durty_data){ 
? 
? 
? dt.table=read.table(durty_data, sep = "\t", header=T)# 
? y_raw_mt=as.matrix(dt.table[2:174])#### 
? rownames(y_raw_mt)=y_raw[,1] #assigning the raw names to the matrix 
? y_raw_mt_t=t(y_raw_mt)#### 
? y_raw_mt_t_mean=apply(y_raw_mt_t, 2, mean, na.rm=T)### 
? means=c(y_raw_mt_t_mean)## 
? 
? y_raw_mt_t_meanbind=rbind(y_raw_mt_t,means)## 
? 
? 
? t=function(x) { 
? ? x[is.na(x)] ?= mean(x, na.rm = T) 
? ? return(x) 
? } 
? 
? write.a.nice.table=apply(y_raw_mt_t_meanbind,2,t) 
? return(write.a.nice.table) 
}


From smartpink111 at yahoo.com  Fri Sep 13 08:54:28 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 12 Sep 2013 23:54:28 -0700 (PDT)
Subject: [R] How to export time series output in excel
Message-ID: <1379055268.53267.YahooMailNeo@web142605.mail.bf1.yahoo.com>

HI,



Hi, 

(fit <- arima(USAccDeaths, order = c(0,1,1),
????????????? seasonal = list(order = c(0,1,1))))
forecasted_value<-predict(fit, n.ahead = 24)

lst1<-lapply(forecasted_value,function(x) data.frame(Year=as.vector(floor(time(x))), Month=factor(as.vector(cycle(x)),label=month.abb),value=as.vector(x)))
?res<-join_all(lst1,by=c("Year","Month"))
res$Month<- as.character(res$Month)
colnames(res)[3:4]<- names(forecasted_value)
?head(res)
#? Year Month???? pred?????? se
#1 1979?? Jan 8336.061 315.4481
#2 1979?? Feb 7531.829 363.0056
#3 1979?? Mar 8314.644 405.0168
#4 1979?? Apr 8616.869 443.0623
#5 1979?? May 9488.913 478.0897
#6 1979?? Jun 9859.757 510.7204

You can use ?write.csv()? or try library(WriteXLS) or library(xlsx) etc..


A.K.




I am totally new to R, so please help me out with this problem. I am doing time series analysis using R. 
I have used following code and get the following result. 

forecasted_value <- predict(modal, n.ahead=24)

getting the output in the following form. 

$pred
? ? ? ? ? Jan ? ? ?Feb ? ? ?Mar ? ? ?Apr ? ? ?May ? ? ?Jun ? ? ?Jul ? ? ?Aug 
2014 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 
2015 12627404 14525630 16171502 12547396 12352726 16358894 15422821 15709633 
2016 12721883 14461853 16078897 12638576 12420660 16255545 15379709 15662661 
? ? ? ? ? Sep ? ? ?Oct ? ? ?Nov ? ? ?Dec 
2014 16486191 13558895 14611782 15184706 
2015 16556705 13512867 14495441 15198090 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 

$se
? ? ? ? ? ?Jan ? ? ? Feb ? ? ? Mar ? ? ? Apr ? ? ? May ? ? ? Jun ? ? ? Jul 
2014 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 
2015 1042911.1 1048954.3 1048981.1 1059934.9 1069479.4 1069730.6 1070260.2 
2016 1200349.5 1201876.3 1202060.9 1205038.6 1207152.0 1207254.1 1207498.9 
? ? ? ? ? ?Aug ? ? ? Sep ? ? ? Oct ? ? ? Nov ? ? ? Dec 
2014 ? ? ? ? ? ?822180.7 ?951041.6 ?952830.3 ?971687.7 
2015 1073420.9 1155495.6 1178595.1 1178596.2 1185176.4 



I want export in excel in the following way:

Year ? ? ? ? Month ? ? ? Pred ? ? ? ? ? se 
2014 ? ? ? ? Sep ? ? ? ? 16486191 ? ? 822180.7 

...............................


From mbudnick08 at snet.net  Fri Sep 13 05:42:27 2013
From: mbudnick08 at snet.net (Michael Budnick)
Date: Thu, 12 Sep 2013 23:42:27 -0400
Subject: [R] Subtracting elements of a vector from each other stepwise
In-Reply-To: <1c4a6d5b-7012-45f4-ac43-cc3914c06ac7@email.android.com>
References: <CANTLroGb_R4HOgG5gNk9HCPaPX2=EZ_J_KLhYmRtLfLB+W-OAw@mail.gmail.com>
	<1378847199.17716.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<loom.20130910T233603-460@post.gmane.org>
	<1378851844.80715.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<522FAFB4.907@gmail.com> <5230F78A.2030600@student.unimelb.edu.au>
	<1c4a6d5b-7012-45f4-ac43-cc3914c06ac7@email.android.com>
Message-ID: <CANTLroF002kS+M_xFdmyz1QjBN-=JzwEcqON6O5KeQuja=B80g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130912/c0531bc3/attachment.pl>

From gw57 at duke.edu  Fri Sep 13 06:14:41 2013
From: gw57 at duke.edu (wacguy)
Date: Thu, 12 Sep 2013 21:14:41 -0700 (PDT)
Subject: [R] help with a simple function
Message-ID: <1379045681809-4676026.post@n4.nabble.com>

hi, I am new to are, very new and want to ask what's wrong with this
function: It is suppose to read a table and return its matrix transposed
with NA replaced by the average of each column and a row of means at the
bottom row. The separated parts are returned correctly. Thanks a lot for any
help.

Guy

write.table=function(durty_data){
  
  
  dt.table=read.table(durty_data, sep = "\t", header=T)#
  y_raw_mt=as.matrix(dt.table[2:174])####
  rownames(y_raw_mt)=y_raw[,1] #assigning the raw names to the matrix
  y_raw_mt_t=t(y_raw_mt)####
  y_raw_mt_t_mean=apply(y_raw_mt_t, 2, mean, na.rm=T)###
  means=c(y_raw_mt_t_mean)##
  
  y_raw_mt_t_meanbind=rbind(y_raw_mt_t,means)##
  
 
  t=function(x) { 
    x[is.na(x)]  = mean(x, na.rm = T) 
    return(x) 
  }
  
  write.a.nice.table=apply(y_raw_mt_t_meanbind,2,t)
  return(write.a.nice.table)
}



--
View this message in context: http://r.789695.n4.nabble.com/help-with-a-simple-function-tp4676026.html
Sent from the R help mailing list archive at Nabble.com.


From ejoffe at hotmail.com  Fri Sep 13 11:15:49 2013
From: ejoffe at hotmail.com (E Joffe)
Date: Fri, 13 Sep 2013 11:15:49 +0200
Subject: [R] Creating dummy vars with contrasts - why does the returned
	identity matrix contain all levels (and not n-1 levels) ?
Message-ID: <DUB114-DS1481B35E35DF4AC29807F6CA3B0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130913/d64b2f91/attachment.pl>

From adam.ryczkowski at statystyka.net  Fri Sep 13 11:10:17 2013
From: adam.ryczkowski at statystyka.net (Adam Ryczkowski)
Date: Fri, 13 Sep 2013 11:10:17 +0200
Subject: [R] How to write a wrapper function which can honor default values,
 when the target function has ones?
Message-ID: <5232D679.3000804@statystyka.net>


   (This is crosspost from
   [1]http://stackoverflow.com/questions/18670895/how-to-write-a-wrapper-functi
   on-which-can-honour-default-values-when-the-target, posted week ago, where
   although the question did receive some attention, nobody was able to help
   me.)
   I'd like to write a more-or-less generic caller to `targetf` that retains
   its default parameters.
   Suppose we have a provided by some 3rd party library `targetf`:
       targetf<-function(x=1,...){
           print(paste("x =",x))
       }
   How to write `wrapperf`, that will respect `targetf`s default arguments, so
   calling `wrapperf()` would not yield the error massage `Error in paste("x
   =", x) : argument "x" is missing, with no default`?
   The obvious candidate
       wrapperf1<-function(x,y) {
           targetf(x=x)
       }
    doesn't seem to respect targetf's default value for parameter `x`.
   OTH the
       wrapperf2<-function(...) {
           targetf(...)
       }
    behaves correctly, but it doesn't work for me, because I only care to pass
   the `x` argument, (and possibly reserve the `...` to other functions in
   `wrapperf` body).
   Maybe to solve the issue I'd have to play with ellipsis filtering, which is
   a *terra incognita* for me at the moment...
       *    *    *
   One idea on how to solve the problem: maybe I'd need to create a specially
   crafted `...` object from scratch in `wrapperf` to do pseudo code like this:
       wrapperfX<-function(x,y,...)
       {
           ...<-if(missing(x){
                   list()
               }else{
                   list(x=x)
               }
           targetf(...)
       }
   But I have no idea how to even start doing assignments into ellipsis... is
   it possible at all?
   kind regards,
   Adam Ryczkowski

   [2]www.statystyka.net
   [3]+48505919892
   [4]Skype:sisteczko

References

   1. http://stackoverflow.com/questions/18670895/how-to-write-a-wrapper-function-which-can-honour-default-values-when-the-target
   2. http://www.google.com/
   3. callto:+48505919892
   4. skype:sisteczko

From pertsou at gmail.com  Fri Sep 13 12:10:14 2013
From: pertsou at gmail.com (Endy BlackEndy)
Date: Fri, 13 Sep 2013 13:10:14 +0300
Subject: [R] log-log link function
Message-ID: <CAGpBJKRiyL3vRi9xDC-o8Mf56fpZefqQMCfrsk4r7FdKRQnvuA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130913/acb6f394/attachment.pl>

From zhangweiwu at realss.com  Fri Sep 13 12:13:45 2013
From: zhangweiwu at realss.com (Zhang Weiwu)
Date: Fri, 13 Sep 2013 18:13:45 +0800 (CST)
Subject: [R] how to get values within a threshold
Message-ID: <alpine.DEB.2.00.1309131749520.11354@lyonesse>


input:

 	> values
 	[1] 0.854400 1.648465 1.829830 1.874704 7.670915 7.673585 7.722619

 	> thresholds
 	[1] 1 3 5 7 9

expected output:

 	[1] 1 4 4 4 7

That is, need a vector of indexes of the maximum value below the threshold.

e.g.
First  element is "1", because value[1] is the largest below threshold "1".
Second element is "4", because value[4] is the largest below threshold "3".

The way I do it is:

> sapply(1:length(threshold), function(x) { length(values[values < threshold[x]])})
[1] 1 4 4 4 7

It just seem to me too long and stupid to be like R. Is it already the best way?

Somehow I feel which() was designed for a purpose like this, but I couldn't 
figure out a way to apply which here.


From Achim.Zeileis at uibk.ac.at  Fri Sep 13 12:24:05 2013
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Fri, 13 Sep 2013 12:24:05 +0200 (CEST)
Subject: [R] log-log link function
In-Reply-To: <CAGpBJKRiyL3vRi9xDC-o8Mf56fpZefqQMCfrsk4r7FdKRQnvuA@mail.gmail.com>
References: <CAGpBJKRiyL3vRi9xDC-o8Mf56fpZefqQMCfrsk4r7FdKRQnvuA@mail.gmail.com>
Message-ID: <alpine.DEB.2.10.1309131219320.4347@paninaro.uibk.ac.at>

On Fri, 13 Sep 2013, Endy BlackEndy wrote:

> Hi to every body. I would like assistance on how to implement the 
> log-log link function for binary response. Is there any package that 
> implements it?

One way is to use the cloglog link and just flip the response categories.

To use the log-log link directly you can also use the "link-glm" object 
provided below. It's what we use internally in the "betareg" package to 
provide the log-log link.

loglog <- structure(list(
   linkfun = function(mu) -log(-log(mu)),
   linkinv = function(eta)
     pmax(pmin(exp(-exp(-eta)), 1 - .Machine$double.eps), .Machine$double.eps),
   mu.eta = function(eta) {
     eta <- pmin(eta, 700)
     pmax(exp(-eta - exp(-eta)), .Machine$double.eps)
   },
   dmu.deta = function(eta)
     pmax(exp(-exp(-eta) - eta) * expm1(-eta), .Machine$double.eps),
   valideta = function(eta) TRUE,
   name = "loglog"
), class = "link-glm")


> Many thanks
> Endy
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From zsurzsalaszlo at gmail.com  Fri Sep 13 12:56:58 2013
From: zsurzsalaszlo at gmail.com (Zsurzsa Laszlo)
Date: Fri, 13 Sep 2013 12:56:58 +0200
Subject: [R] Shiny - can one create one RUN button?
In-Reply-To: <CAN2xGJY5HeNE_up6YR_qH=uwVufGxCuvEK1pXtjR5c+xLYuspA@mail.gmail.com>
References: <CAN2xGJY5HeNE_up6YR_qH=uwVufGxCuvEK1pXtjR5c+xLYuspA@mail.gmail.com>
Message-ID: <CAF4U=VkXDVW6pN89DxJP+Z9ybRXZ_4h7GTJhWFyPhdRxd+UPJA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130913/cb5504de/attachment.pl>

From dimitri.liakhovitski at gmail.com  Fri Sep 13 13:05:21 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Fri, 13 Sep 2013 07:05:21 -0400
Subject: [R] Shiny - can one create one RUN button?
In-Reply-To: <CAF4U=VkXDVW6pN89DxJP+Z9ybRXZ_4h7GTJhWFyPhdRxd+UPJA@mail.gmail.com>
References: <CAN2xGJY5HeNE_up6YR_qH=uwVufGxCuvEK1pXtjR5c+xLYuspA@mail.gmail.com>
	<CAF4U=VkXDVW6pN89DxJP+Z9ybRXZ_4h7GTJhWFyPhdRxd+UPJA@mail.gmail.com>
Message-ID: <CAN2xGJboiJS6wgNdWU4qJeXMrDPeoN8wGPtd-Zyv-T-=2_fCHw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130913/c53f9898/attachment.pl>

From Gerrit.Eichner at math.uni-giessen.de  Fri Sep 13 13:21:40 2013
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Fri, 13 Sep 2013 13:21:40 +0200 (MEST)
Subject: [R] How to write a wrapper function which can honor
	defaultvalues, when the target function has ones?
In-Reply-To: <5232D679.3000804@statystyka.net>
References: <5232D679.3000804@statystyka.net>
Message-ID: <Pine.SOC.4.64.1309131312500.6455@solcom.hrz.uni-giessen.de>

Hello, Adam,

I'm rather uncertain about your goal (and consequently even more so about 
how to reach it), but anyway, maybe the function match.call() with its 
argument expand.dots is of some help for you. From its help page:

"match.call is most commonly used in two circumstances:

     To record the call for later re-use: for example most model-fitting 
functions record the call as element call of the list they return. Here 
the default expand.dots = TRUE is appropriate.

     To pass most of the call to another function, often model.frame. Here 
the common idiom is that expand.dots = FALSE is used, and the ... element 
of the matched call is removed. An alternative is to explicitly select the 
arguments to be passed on, as is done in lm."


  Hth  --  Gerrit

On Fri, 13 Sep 2013, Adam Ryczkowski wrote:

>
>   (This is crosspost from
>   [1]http://stackoverflow.com/questions/18670895/how-to-write-a-wrapper-functi
>   on-which-can-honour-default-values-when-the-target, posted week ago, where
>   although the question did receive some attention, nobody was able to help
>   me.)
>   I'd like to write a more-or-less generic caller to `targetf` that retains
>   its default parameters.
>   Suppose we have a provided by some 3rd party library `targetf`:
>       targetf<-function(x=1,...){
>           print(paste("x =",x))
>       }
>   How to write `wrapperf`, that will respect `targetf`s default arguments, so
>   calling `wrapperf()` would not yield the error massage `Error in paste("x
>   =", x) : argument "x" is missing, with no default`?
>   The obvious candidate
>       wrapperf1<-function(x,y) {
>           targetf(x=x)
>       }
>    doesn't seem to respect targetf's default value for parameter `x`.
>   OTH the
>       wrapperf2<-function(...) {
>           targetf(...)
>       }
>    behaves correctly, but it doesn't work for me, because I only care to pass
>   the `x` argument, (and possibly reserve the `...` to other functions in
>   `wrapperf` body).
>   Maybe to solve the issue I'd have to play with ellipsis filtering, which is
>   a *terra incognita* for me at the moment...
>       *    *    *
>   One idea on how to solve the problem: maybe I'd need to create a specially
>   crafted `...` object from scratch in `wrapperf` to do pseudo code like this:
>       wrapperfX<-function(x,y,...)
>       {
>           ...<-if(missing(x){
>                   list()
>               }else{
>                   list(x=x)
>               }
>           targetf(...)
>       }
>   But I have no idea how to even start doing assignments into ellipsis... is
>   it possible at all?
>   kind regards,
>   Adam Ryczkowski
>
>   [2]www.statystyka.net
>   [3]+48505919892
>   [4]Skype:sisteczko
>
> References
>
>   1. http://stackoverflow.com/questions/18670895/how-to-write-a-wrapper-function-which-can-honour-default-values-when-the-target
>   2. http://www.google.com/
>   3. callto:+48505919892
>   4. skype:sisteczko
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Sep 13 15:04:52 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 13 Sep 2013 08:04:52 -0500
Subject: [R] Creating dummy vars with contrasts - why does the returned
	identity matrix contain all levels (and not n-1 levels) ?
In-Reply-To: <DUB114-DS1481B35E35DF4AC29807F6CA3B0@phx.gbl>
References: <DUB114-DS1481B35E35DF4AC29807F6CA3B0@phx.gbl>
Message-ID: <FA5360B9-73E7-41A4-B577-77212FD4F25B@comcast.net>


On Sep 13, 2013, at 4:15 AM, E Joffe wrote:

> Hello,
>
>
>
> I have a problem with creating an identity matrix for glmnet by  
> using the
> contrasts function.

Why do you want to do this?

> I have a factor with 4 levels.
>
> When I create dummy variables I think there should be n-1 variables  
> (in this
> case 3) - so that the contrasts would be against the baseline level.
>
> This is also what is written in the help file for 'contrasts'.
>
> The problem is that the function creates a matrix with n variables  
> (i.e. the
> same as the number of levels) and not n-1 (where I would have a  
> baseline
> level for comparison).

Only if you specify contrasts=FALSE does it do so and this is  
documented in that help file.
>
>
>
> My questions are:
>
> 1.       How can I create a matrix with n-1 dummy vars ?

See below.

> was I supposed to
> define explicitly that I want contr.treatment (contrasts) ?

No need to do so.

>
> 2.       If it is not possible, how should I interpret the hazard  
> ratios in
> the Cox regression I am generating (I use glmnet for variable  
> selection and
> then generate a Cox regression)  - That is, if I get an HR of 3 for  
> the
> variable 300mg what does it mean ? the hazard is 3 times higher of  
> what ?
>

Relative hazards are generally referenced to the "baseline hazard",  
i.e. the hazard for a group with the omitted level for treatment  
constrasts and the mean value for any numeric predictors.

> Here is some code to reproduce the issue:
>
> # Create a 4 level example factor
>
> trt <- factor( sample( c("PLACEBO", "300 MG", "600 MG", "1200 MG"),
>
>                       100, replace=TRUE ) )

# If your intent is to use constrasts different than the defaults used  
by
#  regression functions, these factor contrasts need to be assigned,  
either
# within the construction of the factor or after the fact.

 >  contrasts(trt)
         300 MG 600 MG PLACEBO
1200 MG      0      0       0
300 MG       1      0       0
600 MG       0      1       0
PLACEBO      0      0       1

# the default value for the contrasts parameter is TRUE and the  
default type is treatement

# That did not cause any change to the 'trt'-object:
trt

#To make a change you need to use the `contrasts<-` function:

contrasts (trt) <- contrasts(trt)
trt

>
> # Use contrasts to get the identity matrix of dummy variables to be  
> used in
> glmnet
>
> trt2 <- contrasts (trt,contrasts=FALSE)
>
> Results (as you can see all levels are represented in the identity  
> matrix):
>
>> levels (trt)
> [1] "1200 MG" "300 MG"  "600 MG"  "PLACEBO"
>
>
>> print (trt2)
>
>        1200 MG 300 MG 600 MG PLACEBO
>
> 1200 MG       1      0      0       0
>
> 300 MG        0      1      0       0
>
> 600 MG        0      0      1       0
>
> PLACEBO       0      0      0       1
>
>
>
> 	[[alternative HTML version deleted]]

Rhelp is a plain text mailing list.

-- 
David Winsemius, MD
Alameda, CA, USA


From smartpink111 at yahoo.com  Fri Sep 13 15:27:18 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 13 Sep 2013 06:27:18 -0700 (PDT)
Subject: [R] how to get values within a threshold
In-Reply-To: <alpine.DEB.2.00.1309131749520.11354@lyonesse>
References: <alpine.DEB.2.00.1309131749520.11354@lyonesse>
Message-ID: <1379078838.2302.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
You could try:
val1<- c(0.854400, 1.648465, 1.829830, 1.874704, 7.670915, 7.673585, 7.722619)
thresh1<- c(1,3,5,7,9)
rowSums(t(replicate(length(thresh1),val1))<= thresh1)
#[1] 1 4 4 4 7

#using ?sapply() could be shortened
sapply(thresh1,function(x) {sum(val1<x)})
#[1] 1 4 4 4 7


A.K.




----- Original Message -----
From: Zhang Weiwu <zhangweiwu at realss.com>
To: r-help at r-project.org
Cc: 
Sent: Friday, September 13, 2013 6:13 AM
Subject: [R] how to get values within a threshold


input:

??? > values
??? [1] 0.854400 1.648465 1.829830 1.874704 7.670915 7.673585 7.722619

??? > thresholds
??? [1] 1 3 5 7 9

expected output:

??? [1] 1 4 4 4 7

That is, need a vector of indexes of the maximum value below the threshold.

e.g.
First? element is "1", because value[1] is the largest below threshold "1".
Second element is "4", because value[4] is the largest below threshold "3".

The way I do it is:

> sapply(1:length(threshold), function(x) { length(values[values < threshold[x]])})
[1] 1 4 4 4 7

It just seem to me too long and stupid to be like R. Is it already the best way?

Somehow I feel which() was designed for a purpose like this, but I couldn't 
figure out a way to apply which here.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ejoffe at hotmail.com  Fri Sep 13 16:33:16 2013
From: ejoffe at hotmail.com (E Joffe)
Date: Fri, 13 Sep 2013 16:33:16 +0200
Subject: [R] Creating dummy vars with contrasts - why does the returned
	identity matrix contain all levels (and not n-1 levels) ?
In-Reply-To: <FA5360B9-73E7-41A4-B577-77212FD4F25B@comcast.net>
References: <DUB114-DS1481B35E35DF4AC29807F6CA3B0@phx.gbl>
	<FA5360B9-73E7-41A4-B577-77212FD4F25B@comcast.net>
Message-ID: <DUB114-DS28C57F8A86245D07B7D278CA3B0@phx.gbl>

Thank you so much for your answer  !
As far as I understand, glmnet doesn't accept categorical variables only
binary factors - so I had to create dummy variables for all categorical
variables.
It worked perfectly.
Erel 


Erel Joffe MD MSc
School of Biomedical Informatics
University of Texas - Health Science Center in Houston
832.287.0829 (c)

-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: Friday, September 13, 2013 3:05 PM
To: E Joffe
Cc: r-help at r-project.org
Subject: Re: [R] Creating dummy vars with contrasts - why does the returned
identity matrix contain all levels (and not n-1 levels) ?


On Sep 13, 2013, at 4:15 AM, E Joffe wrote:

> Hello,
>
>
>
> I have a problem with creating an identity matrix for glmnet by using 
> the contrasts function.

Why do you want to do this?

> I have a factor with 4 levels.
>
> When I create dummy variables I think there should be n-1 variables 
> (in this case 3) - so that the contrasts would be against the baseline 
> level.
>
> This is also what is written in the help file for 'contrasts'.
>
> The problem is that the function creates a matrix with n variables 
> (i.e. the same as the number of levels) and not n-1 (where I would 
> have a baseline level for comparison).

Only if you specify contrasts=FALSE does it do so and this is documented in
that help file.
>
>
>
> My questions are:
>
> 1.       How can I create a matrix with n-1 dummy vars ?

See below.

> was I supposed to
> define explicitly that I want contr.treatment (contrasts) ?

No need to do so.

>
> 2.       If it is not possible, how should I interpret the hazard  
> ratios in
> the Cox regression I am generating (I use glmnet for variable  
> selection and
> then generate a Cox regression)  - That is, if I get an HR of 3 for  
> the
> variable 300mg what does it mean ? the hazard is 3 times higher of  
> what ?
>

Relative hazards are generally referenced to the "baseline hazard",  
i.e. the hazard for a group with the omitted level for treatment  
constrasts and the mean value for any numeric predictors.

> Here is some code to reproduce the issue:
>
> # Create a 4 level example factor
>
> trt <- factor( sample( c("PLACEBO", "300 MG", "600 MG", "1200 MG"),
>
>                       100, replace=TRUE ) )

# If your intent is to use constrasts different than the defaults used  
by
#  regression functions, these factor contrasts need to be assigned,  
either
# within the construction of the factor or after the fact.

 >  contrasts(trt)
         300 MG 600 MG PLACEBO
1200 MG      0      0       0
300 MG       1      0       0
600 MG       0      1       0
PLACEBO      0      0       1

# the default value for the contrasts parameter is TRUE and the  
default type is treatement

# That did not cause any change to the 'trt'-object:
trt

#To make a change you need to use the `contrasts<-` function:

contrasts (trt) <- contrasts(trt)
trt

>
> # Use contrasts to get the identity matrix of dummy variables to be  
> used in
> glmnet
>
> trt2 <- contrasts (trt,contrasts=FALSE)
>
> Results (as you can see all levels are represented in the identity  
> matrix):
>
>> levels (trt)
> [1] "1200 MG" "300 MG"  "600 MG"  "PLACEBO"
>
>
>> print (trt2)
>
>        1200 MG 300 MG 600 MG PLACEBO
>
> 1200 MG       1      0      0       0
>
> 300 MG        0      1      0       0
>
> 600 MG        0      0      1       0
>
> PLACEBO       0      0      0       1
>
>
>
> 	[[alternative HTML version deleted]]

Rhelp is a plain text mailing list.

-- 
David Winsemius, MD
Alameda, CA, USA


From smartpink111 at yahoo.com  Fri Sep 13 15:50:30 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 13 Sep 2013 06:50:30 -0700 (PDT)
Subject: [R] how to get values within a threshold
In-Reply-To: <1379078838.2302.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <alpine.DEB.2.00.1309131749520.11354@lyonesse>
	<1379078838.2302.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1379080230.89335.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,

Some speed comparison


set.seed(434)
?val1<- rnorm(1e5)
?set.seed(28)
?thresh1<- sample(1:20,1e2,replace=TRUE)
?system.time(res<- rowSums(t(replicate(length(thresh1),val1))<= thresh1))
#? user? system elapsed 
#? 0.320?? 0.064?? 0.382 
system.time(res2<- sapply(thresh1,function(x) {sum(val1<x)}))
#? user? system elapsed 
#? 0.088?? 0.004?? 0.093 
system.time(res3<- rowSums(matrix(rep(val1,length(thresh1)),nrow=length(thresh1),byrow=TRUE)<=thresh1))
# user? system elapsed 
#? 0.228?? 0.048?? 0.275 

system.time(res4<- sapply(1:length(thresh1),function(x){length(val1[val1<thresh1[x]])})) 
# user? system elapsed 
#? 0.300?? 0.044?? 0.345 

mat1<- matrix(rep(val1,length(thresh1)),nrow=length(thresh1),byrow=TRUE)
system.time(res5<- rowSums(mat1<=thresh1))
# user? system elapsed 
# 0.104?? 0.000?? 0.103?
system.time(res6<- unlist(lapply(thresh1,function(x) {sum(val1<x)})))
?#? user? system elapsed 
?# 0.088?? 0.000?? 0.088 



identical(res,as.numeric(res2))
#[1] TRUE
?identical(res,res3)
#[1] TRUE

identical(res,as.numeric(res4))
#[1] TRUE


identical(res,as.numeric(res6))
#[1] TRUE

A.K.

----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Zhang Weiwu <zhangweiwu at realss.com>
Cc: R help <r-help at r-project.org>
Sent: Friday, September 13, 2013 9:27 AM
Subject: Re: [R] how to get values within a threshold

Hi,
You could try:
val1<- c(0.854400, 1.648465, 1.829830, 1.874704, 7.670915, 7.673585, 7.722619)
thresh1<- c(1,3,5,7,9)
rowSums(t(replicate(length(thresh1),val1))<= thresh1)
#[1] 1 4 4 4 7

#using ?sapply() could be shortened
sapply(thresh1,function(x) {sum(val1<x)})
#[1] 1 4 4 4 7


A.K.




----- Original Message -----
From: Zhang Weiwu <zhangweiwu at realss.com>
To: r-help at r-project.org
Cc: 
Sent: Friday, September 13, 2013 6:13 AM
Subject: [R] how to get values within a threshold


input:

??? > values
??? [1] 0.854400 1.648465 1.829830 1.874704 7.670915 7.673585 7.722619

??? > thresholds
??? [1] 1 3 5 7 9

expected output:

??? [1] 1 4 4 4 7

That is, need a vector of indexes of the maximum value below the threshold.

e.g.
First? element is "1", because value[1] is the largest below threshold "1".
Second element is "4", because value[4] is the largest below threshold "3".

The way I do it is:

> sapply(1:length(threshold), function(x) { length(values[values < threshold[x]])})
[1] 1 4 4 4 7

It just seem to me too long and stupid to be like R. Is it already the best way?

Somehow I feel which() was designed for a purpose like this, but I couldn't 
figure out a way to apply which here.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From dwinsemius at comcast.net  Fri Sep 13 16:13:04 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 13 Sep 2013 09:13:04 -0500
Subject: [R] Creating dummy vars with contrasts - why does the returned
	identity matrix contain all levels (and not n-1 levels) ?
In-Reply-To: <DUB114-DS28C57F8A86245D07B7D278CA3B0@phx.gbl>
References: <DUB114-DS1481B35E35DF4AC29807F6CA3B0@phx.gbl>
	<FA5360B9-73E7-41A4-B577-77212FD4F25B@comcast.net>
	<DUB114-DS28C57F8A86245D07B7D278CA3B0@phx.gbl>
Message-ID: <6777E2A5-B864-481C-9875-6CF74092A16D@comcast.net>


On Sep 13, 2013, at 9:33 AM, E Joffe wrote:

> Thank you so much for your answer  !
> As far as I understand, glmnet doesn't accept categorical variables  
> only
> binary factors - so I had to create dummy variables for all  
> categorical
> variables.
> It worked perfectly.

It's not exactly clear what worked perfectly. Since glmnet will only  
accept a matrix as its `x` data input, did you use model.matrix to  
construct the "dummies" and cbind your numeric predictors to that  
result? If you just assigned a factor attribute, it's more likely that  
you didn't actually use "dummies" but rather regressed on the integer  
values of the factor.

-- 
David.

-- 
> Erel
>
>
> Erel Joffe MD MSc
> School of Biomedical Informatics
> University of Texas - Health Science Center in Houston
> 832.287.0829 (c)
>
> -----Original Message-----
> From: David Winsemius [mailto:dwinsemius at comcast.net]
> Sent: Friday, September 13, 2013 3:05 PM
> To: E Joffe
> Cc: r-help at r-project.org
> Subject: Re: [R] Creating dummy vars with contrasts - why does the  
> returned
> identity matrix contain all levels (and not n-1 levels) ?
>
>
> On Sep 13, 2013, at 4:15 AM, E Joffe wrote:
>
>> Hello,
>>
>>
>>
>> I have a problem with creating an identity matrix for glmnet by using
>> the contrasts function.
>
> Why do you want to do this?
>
>> I have a factor with 4 levels.
>>
>> When I create dummy variables I think there should be n-1 variables
>> (in this case 3) - so that the contrasts would be against the  
>> baseline
>> level.
>>
>> This is also what is written in the help file for 'contrasts'.
>>
>> The problem is that the function creates a matrix with n variables
>> (i.e. the same as the number of levels) and not n-1 (where I would
>> have a baseline level for comparison).
>
> Only if you specify contrasts=FALSE does it do so and this is  
> documented in
> that help file.
>>
>>
>>
>> My questions are:
>>
>> 1.       How can I create a matrix with n-1 dummy vars ?
>
> See below.
>
>> was I supposed to
>> define explicitly that I want contr.treatment (contrasts) ?
>
> No need to do so.
>
>>
>> 2.       If it is not possible, how should I interpret the hazard
>> ratios in
>> the Cox regression I am generating (I use glmnet for variable
>> selection and
>> then generate a Cox regression)  - That is, if I get an HR of 3 for
>> the
>> variable 300mg what does it mean ? the hazard is 3 times higher of
>> what ?
>>
>
> Relative hazards are generally referenced to the "baseline hazard",
> i.e. the hazard for a group with the omitted level for treatment
> constrasts and the mean value for any numeric predictors.
>
>> Here is some code to reproduce the issue:
>>
>> # Create a 4 level example factor
>>
>> trt <- factor( sample( c("PLACEBO", "300 MG", "600 MG", "1200 MG"),
>>
>>                      100, replace=TRUE ) )
>
> # If your intent is to use constrasts different than the defaults used
> by
> #  regression functions, these factor contrasts need to be assigned,
> either
> # within the construction of the factor or after the fact.
>
>> contrasts(trt)
>         300 MG 600 MG PLACEBO
> 1200 MG      0      0       0
> 300 MG       1      0       0
> 600 MG       0      1       0
> PLACEBO      0      0       1
>
> # the default value for the contrasts parameter is TRUE and the
> default type is treatement
>
> # That did not cause any change to the 'trt'-object:
> trt
>
> #To make a change you need to use the `contrasts<-` function:
>
> contrasts (trt) <- contrasts(trt)
> trt
>
>>
>> # Use contrasts to get the identity matrix of dummy variables to be
>> used in
>> glmnet
>>
>> trt2 <- contrasts (trt,contrasts=FALSE)
>>
>> Results (as you can see all levels are represented in the identity
>> matrix):
>>
>>> levels (trt)
>> [1] "1200 MG" "300 MG"  "600 MG"  "PLACEBO"
>>
>>
>>> print (trt2)
>>
>>       1200 MG 300 MG 600 MG PLACEBO
>>
>> 1200 MG       1      0      0       0
>>
>> 300 MG        0      1      0       0
>>
>> 600 MG        0      0      1       0
>>
>> PLACEBO       0      0      0       1
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>
> Rhelp is a plain text mailing list.
>
> -- 
> David Winsemius, MD
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From wdunlap at tibco.com  Fri Sep 13 16:44:18 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 13 Sep 2013 14:44:18 +0000
Subject: [R] how to get values within a threshold
In-Reply-To: <alpine.DEB.2.00.1309131749520.11354@lyonesse>
References: <alpine.DEB.2.00.1309131749520.11354@lyonesse>
Message-ID: <E66794E69CFDE04D9A70842786030B931C342FAA@PA-MBX01.na.tibco.com>

> findInterval(thresholds, values)
[1] 1 4 4 4 7

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Zhang Weiwu
> Sent: Friday, September 13, 2013 3:14 AM
> To: r-help at r-project.org
> Subject: [R] how to get values within a threshold
> 
> 
> input:
> 
>  	> values
>  	[1] 0.854400 1.648465 1.829830 1.874704 7.670915 7.673585 7.722619
> 
>  	> thresholds
>  	[1] 1 3 5 7 9
> 
> expected output:
> 
>  	[1] 1 4 4 4 7
> 
> That is, need a vector of indexes of the maximum value below the threshold.
> 
> e.g.
> First  element is "1", because value[1] is the largest below threshold "1".
> Second element is "4", because value[4] is the largest below threshold "3".
> 
> The way I do it is:
> 
> > sapply(1:length(threshold), function(x) { length(values[values < threshold[x]])})
> [1] 1 4 4 4 7
> 
> It just seem to me too long and stupid to be like R. Is it already the best way?
> 
> Somehow I feel which() was designed for a purpose like this, but I couldn't
> figure out a way to apply which here.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Fri Sep 13 16:56:59 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 13 Sep 2013 07:56:59 -0700 (PDT)
Subject: [R] how to get values within a threshold
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C342FAA@PA-MBX01.na.tibco.com>
References: <alpine.DEB.2.00.1309131749520.11354@lyonesse>
	<E66794E69CFDE04D9A70842786030B931C342FAA@PA-MBX01.na.tibco.com>
Message-ID: <1379084219.6994.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi Bill,

Great soluiton!
Just to add:
if values are not sorted (in this case, okay)

?set.seed(434)
? val1<- rnorm(1e5)
? set.seed(28)
? thresh1<- sample(1:20,1e2,replace=TRUE)
? system.time(res11<- findInterval(thresh1,val1))
#Error in findInterval(thresh1, val1) : 
?# 'vec' must be sorted non-decreasingly



system.time(res<- findInterval(thresh1,sort(val1)))
#?? user? system elapsed 
?# 0.012?? 0.000?? 0.014 

system.time(res2<- sapply(thresh1,function(x) {sum(val1<x)}))
#?? user? system elapsed 
?# 0.088?? 0.000?? 0.087 
?identical(res2,res)
#[1] TRUE



A.K.






----- Original Message -----
From: William Dunlap <wdunlap at tibco.com>
To: Zhang Weiwu <zhangweiwu at realss.com>; "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Friday, September 13, 2013 10:44 AM
Subject: Re: [R] how to get values within a threshold

> findInterval(thresholds, values)
[1] 1 4 4 4 7

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Zhang Weiwu
> Sent: Friday, September 13, 2013 3:14 AM
> To: r-help at r-project.org
> Subject: [R] how to get values within a threshold
> 
> 
> input:
> 
>? ??? > values
>? ??? [1] 0.854400 1.648465 1.829830 1.874704 7.670915 7.673585 7.722619
> 
>? ??? > thresholds
>? ??? [1] 1 3 5 7 9
> 
> expected output:
> 
>? ??? [1] 1 4 4 4 7
> 
> That is, need a vector of indexes of the maximum value below the threshold.
> 
> e.g.
> First? element is "1", because value[1] is the largest below threshold "1".
> Second element is "4", because value[4] is the largest below threshold "3".
> 
> The way I do it is:
> 
> > sapply(1:length(threshold), function(x) { length(values[values < threshold[x]])})
> [1] 1 4 4 4 7
> 
> It just seem to me too long and stupid to be like R. Is it already the best way?
> 
> Somehow I feel which() was designed for a purpose like this, but I couldn't
> figure out a way to apply which here.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jgrn at illinois.edu  Fri Sep 13 17:09:32 2013
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Fri, 13 Sep 2013 10:09:32 -0500
Subject: [R] library() and install.packages() no longer working ("Access is
 denied" error)
Message-ID: <CABG0rftd9vynuxrppWxTCoYedaL7UBqik=hTpYSwHXgozFhQLQ@mail.gmail.com>

In the last week, SOMETHING on my system must have changed because
when trying to library() or install.packages() on R 3.0.1 x64 on a
Windows 2008 R2 server:

> library("raster")
Error in normalizePath(path.expand(path), winslash, mustWork) :
  path[1]="D:/Users/[UID]/Documents/R/win-library/3.0": Access is denied

> install.packages("raster")
Installing package into ?D:/Users/[UID]/Documents/R/win-library/3.0?
(as ?lib? is unspecified)
trying URL 'http://ftp.osuosl.org/pub/cran/bin/windows/contrib/3.0/raster_2.1-49.zip'
Content type 'application/zip' length 2363295 bytes (2.3 Mb)
opened URL
downloaded 2.3 Mb

Error in normalizePath(path.expand(path), winslash, mustWork) :
  path[1]="D:\Users\[UID]\Documents\R\win-library\3.0": Access is denied
In addition: Warning message:
In normalizePath(path.expand(path), winslash, mustWork) :
  path[1]="D:/Users/[UID]/Documents/R/win-library/3.0": Access is denied

The permissions on that directory APPEAR to be correct (I can add
files/folders, rename them, delete them), but alas R continues to give
me these errors.  Both the users and the sysadmin claim nothing was
changed, but clearly something did.

As a heads up, I did try removing PATHTO/win-library/3.0, and re-ran
the install.packages("raster"), at which point R asked me "Would you
like to use a personal directory instead?".  I clicked yes.  It then
asks me "Would you like to create a personal library
'D:/Users/[UID]/Documents/R/win-library/3.0' to install packages into?
 I clicked yes.  The Mirror browser shows up, I select a mirror.  A
3.0 directory is created, but I got the same error, and when examining
the (new) 3.0 directory, nothing is created inside of it.

Any ideas what this could be caused by?

--j

-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
607 South Mathews Avenue, MC 150
Urbana, IL 61801
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From zhangweiwu at realss.com  Fri Sep 13 17:52:20 2013
From: zhangweiwu at realss.com (Zhang Weiwu)
Date: Fri, 13 Sep 2013 23:52:20 +0800 (CST)
Subject: [R] how to get values within a threshold
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C342FAA@PA-MBX01.na.tibco.com>
References: <alpine.DEB.2.00.1309131749520.11354@lyonesse>
	<E66794E69CFDE04D9A70842786030B931C342FAA@PA-MBX01.na.tibco.com>
Message-ID: <alpine.DEB.2.00.1309132314270.15045@lyonesse>



On Fri, 13 Sep 2013, William Dunlap wrote:

>> findInterval(thresholds, values)
> [1] 1 4 4 4 7

Thanks a lot! But now I have a new problem, a typical R issue perhaps.

First, let's look at  a successful case:

 	> thresholds <- c(1,3,5,7,9)
 	> values <- c(0.854, 1.648, 1.829, 1.874, 7.670, 7.673, 7.722)
 	> values[findInterval(thresholds, values)]
 	[1] 0.854 1.874 1.874 1.874 7.722

Then a new batch of values came, notice only the first element of new values 
differ:

 	> thresholds <- c(1,3,5,7,9)
 	> values <- c(1.254, 1.648, 1.829, 1.874, 7.670, 7.673, 7.722)
 	> findInterval(thresholds, values)
 	[1] 0 4 4 4 7
 	> values[findInterval(thresholds, values)]
 	[1] 1.874 1.874 1.874 7.722

This is a surprise. The desirable output is:

 	[1] 0     1.874 1.874 1.874 7.722

This is desirable, because so maintains the same number of elements during 
calculation. (You may suggest leaving out the indices and try to calculate 
maximum-values-below-threshold directly, but the indices are useful to 
address other fields in the data frame whence values came.)

This problem can be simplified as following:

in R, we have:
 	> a <- 1:10
 	> a[c(1,3)]
 	[1] 1 3
 	> a[c(0,3)]
 	[1] 3

While I was hoping to get:
 	> a <- 1:10
 	> a[c(1,3)]
 	[1] 1 3
 	> a[c(0,3)]
 	[1] 0 3

The straightforward solution, is to shift the whole test values one 
position, so that the first value is always zero:

 	> values <- c(0, 1.254, 1.648, 1.829, 1.874, 7.670, 7.673, 7.722)

This solution, despite begetting a train of changes elsewhere in the code, 
is semantically wrong, since the first element of values should be the first 
value, now it is actually the 0-th value.

What would you do in the case?


From wdunlap at tibco.com  Fri Sep 13 18:04:51 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 13 Sep 2013 16:04:51 +0000
Subject: [R] how to get values within a threshold
In-Reply-To: <alpine.DEB.2.00.1309132314270.15045@lyonesse>
References: <alpine.DEB.2.00.1309131749520.11354@lyonesse>
	<E66794E69CFDE04D9A70842786030B931C342FAA@PA-MBX01.na.tibco.com>
	<alpine.DEB.2.00.1309132314270.15045@lyonesse>
Message-ID: <E66794E69CFDE04D9A70842786030B931C343041@PA-MBX01.na.tibco.com>

You may want to append -Inf (or 0 if you know the data cannot be
negative) to the start of your 'values' vector so you don't
have to write code to catch the cases when a threshold is below
the range of the values.
   > findInterval(thresholds, c(0,values,Inf))
   [1] 1 5 5 5 8
   > c(0, values, Inf)[.Last.value]
   [1] 0.000 1.874 1.874 1.874 7.722

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: Zhang Weiwu [mailto:zhangweiwu at realss.com]
> Sent: Friday, September 13, 2013 8:52 AM
> To: William Dunlap; smartpink111 at yahoo.com
> Cc: r-help at r-project.org
> Subject: RE: [R] how to get values within a threshold
> 
> 
> 
> On Fri, 13 Sep 2013, William Dunlap wrote:
> 
> >> findInterval(thresholds, values)
> > [1] 1 4 4 4 7
> 
> Thanks a lot! But now I have a new problem, a typical R issue perhaps.
> 
> First, let's look at  a successful case:
> 
>  	> thresholds <- c(1,3,5,7,9)
>  	> values <- c(0.854, 1.648, 1.829, 1.874, 7.670, 7.673, 7.722)
>  	> values[findInterval(thresholds, values)]
>  	[1] 0.854 1.874 1.874 1.874 7.722
> 
> Then a new batch of values came, notice only the first element of new values
> differ:
> 
>  	> thresholds <- c(1,3,5,7,9)
>  	> values <- c(1.254, 1.648, 1.829, 1.874, 7.670, 7.673, 7.722)
>  	> findInterval(thresholds, values)
>  	[1] 0 4 4 4 7
>  	> values[findInterval(thresholds, values)]
>  	[1] 1.874 1.874 1.874 7.722
> 
> This is a surprise. The desirable output is:
> 
>  	[1] 0     1.874 1.874 1.874 7.722
> 
> This is desirable, because so maintains the same number of elements during
> calculation. (You may suggest leaving out the indices and try to calculate
> maximum-values-below-threshold directly, but the indices are useful to
> address other fields in the data frame whence values came.)
> 
> This problem can be simplified as following:
> 
> in R, we have:
>  	> a <- 1:10
>  	> a[c(1,3)]
>  	[1] 1 3
>  	> a[c(0,3)]
>  	[1] 3
> 
> While I was hoping to get:
>  	> a <- 1:10
>  	> a[c(1,3)]
>  	[1] 1 3
>  	> a[c(0,3)]
>  	[1] 0 3
> 
> The straightforward solution, is to shift the whole test values one
> position, so that the first value is always zero:
> 
>  	> values <- c(0, 1.254, 1.648, 1.829, 1.874, 7.670, 7.673, 7.722)
> 
> This solution, despite begetting a train of changes elsewhere in the code,
> is semantically wrong, since the first element of values should be the first
> value, now it is actually the 0-th value.
> 
> What would you do in the case?


From jcortazar at cicbiogune.es  Fri Sep 13 15:16:01 2013
From: jcortazar at cicbiogune.es (=?iso-8859-1?Q?Julen_Tom=E1s_Cortazar?=)
Date: Fri, 13 Sep 2013 15:16:01 +0200
Subject: [R] regression
Message-ID: <566F1F208BE5814DB3950DA9DB899949A3B0A9@MAILBOXES.cicbiogune.int>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130913/315db5cb/attachment.pl>

From gw57 at duke.edu  Fri Sep 13 15:16:53 2013
From: gw57 at duke.edu (wacguy)
Date: Fri, 13 Sep 2013 06:16:53 -0700 (PDT)
Subject: [R] help with a simple function
In-Reply-To: <1379045681809-4676026.post@n4.nabble.com>
References: <1379045681809-4676026.post@n4.nabble.com>
Message-ID: <1379078213683-4676051.post@n4.nabble.com>

Thanks a lot!!, So nice to get such a fast reply and not having to break my
head with it for a few more hours.

much appreciated.

Guy



--
View this message in context: http://r.789695.n4.nabble.com/help-with-a-simple-function-tp4676026p4676051.html
Sent from the R help mailing list archive at Nabble.com.


From adam.ryczkowski at statystyka.net  Fri Sep 13 15:18:16 2013
From: adam.ryczkowski at statystyka.net (Adam Ryczkowski)
Date: Fri, 13 Sep 2013 15:18:16 +0200
Subject: [R] How to write a wrapper function which can honor
 defaultvalues, when the target function has ones?
In-Reply-To: <Pine.SOC.4.64.1309131312500.6455@solcom.hrz.uni-giessen.de>
References: <5232D679.3000804@statystyka.net>
	<Pine.SOC.4.64.1309131312500.6455@solcom.hrz.uni-giessen.de>
Message-ID: <52331098.1010602@statystyka.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130913/68c25097/attachment.pl>

From rahmannorthampton at gmail.com  Fri Sep 13 16:38:25 2013
From: rahmannorthampton at gmail.com (Lutfor Rahman)
Date: Fri, 13 Sep 2013 15:38:25 +0100
Subject: [R] GLM result output..
Message-ID: <CAP43mJ97ZFJFaZRLeaK6zVB01v8RMXQ8SHFBdrB55vBDDXRwEg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130913/17bb6086/attachment.pl>

From wdunlap at tibco.com  Fri Sep 13 18:27:54 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 13 Sep 2013 16:27:54 +0000
Subject: [R] regression
In-Reply-To: <566F1F208BE5814DB3950DA9DB899949A3B0A9@MAILBOXES.cicbiogune.int>
References: <566F1F208BE5814DB3950DA9DB899949A3B0A9@MAILBOXES.cicbiogune.int>
Message-ID: <E66794E69CFDE04D9A70842786030B931C343078@PA-MBX01.na.tibco.com>

The newdata argument to predict should be a data.frame (or environment or list)
containing the variables that are on the right side of the formula (the predictors).
In your case that means it should have a variable called 'Concentration'.
Since it didn't have such a variable (it contained only 'Replica.1'), predict found a
variable called 'Concentration' in the global environment and used it for the prediction.

To help avoid this problem, do not use the idiom
            Conc <- c(.1, .4, .9)
            Std <- c(2, 5, 7)
            myData <- data.frame(Conc, Std)
to make your data.frame: it leaves unwanted global variables around.
Instead use
            myData <- data.frame(
                 Conc = c(.1, .4, .9),
                 Std = c(2, 5, 7))
Then, if your newdata argument to predict is inappropriate you will get a
complaint that predict cannot find 'Conc'.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Julen Tom?s Cortazar
> Sent: Friday, September 13, 2013 6:16 AM
> To: r-help at r-project.org
> Subject: [R] regression
> 
> I am sorry,
> 
> 
> 
> I have a problem. When I use the "predict" function I am always obtaining the same
> result and I don't  know why. In adittion, the intercept and the residual values I get are
> wrong too.
> 
> 
> 
> std:
> 
> 
> 
> [1] 0.068 0.117 0.167 0.269 0.470 0.722
> 
> 
> 
> 
> 
> Concentration:
> 
> 
> 
> [1]   3.90625   7.81250  15.62500  31.25000  62.50000 125.00000
> 
> 
> 
> replica1:
> 
> 
> 
>   Replica.1
> 1     0.080
> 2     1.325
> 3     1.309
> 4     1.072
> 5     1.595
> 6     1.384
> 
> replica2:
> 
> Replica.2
> 1     0.098
> 2     1.335
> 3     1.271
> 4     1.187
> 5     1.569
> 6     1.268
> 
> 
> 
> 
> regresion <- lm(std ~ Concentration, mydata):
> 
> 
> 
> Call:
> lm(formula = std ~ Concentration, data = mydata)
> 
> Residuals:
>         1         2         3         4         5         6
> -0.035531 -0.007440  0.000742  0.019106  0.052834 -0.029711
> 
> Coefficients:
>                Estimate Std. Error t value Pr(>|t|)
> (Intercept)   0.0826219  0.0208118    3.97 0.016539 *
> Concentration 0.0053527  0.0003532   15.15 0.000111 ***
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> Residual standard error: 0.0366 on 4 degrees of freedom
> Multiple R-squared:  0.9829,   Adjusted R-squared:  0.9786
> F-statistic: 229.6 on 1 and 4 DF,  p-value: 0.0001106
> 
> 
> 
> 
> 
> > predict(regresion, replica1, int = "p")
>         fit          lwr       upr
> 1 0.1035309 -0.012098349 0.2191602
> 2 0.1244399  0.009958707 0.2389212
> 3 0.1662580  0.053716164 0.2787998
> 4 0.2498941  0.139724612 0.3600636
> 5 0.4171663  0.305409665 0.5289230
> 6 0.7517107  0.614489312 0.8889322
> 
> > predict(regresion, replica2, int = "p")
>         fit          lwr       upr
> 1 0.1035309 -0.012098349 0.2191602
> 2 0.1244399  0.009958707 0.2389212
> 3 0.1662580  0.053716164 0.2787998
> 4 0.2498941  0.139724612 0.3600636
> 5 0.4171663  0.305409665 0.5289230
> 6 0.7517107  0.614489312 0.8889322
> 
> 
> So, anyone knows what is happening to me?
> 
> Thank you very much!
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> This e-mail comes from CIC bioGUNE. The e-mail and any files transmitted with it are
> confidential and intended solely for the use of the individual or entity to whom they are
> addressed. Any unauthorised dissemination or copying of this e-mail or its attachments,
> and any use or disclosure of any information contained in them, is strictly prohibited and
> may be illegal. If you have received this e-mail in error, please notify or telephone + 34
> 944 06 13 00 and delete it from your system.
> 
> Please consider the environment before printing this email
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From zhangweiwu at realss.com  Fri Sep 13 18:50:58 2013
From: zhangweiwu at realss.com (Zhang Weiwu)
Date: Sat, 14 Sep 2013 00:50:58 +0800 (CST)
Subject: [R] how to get values within a threshold
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C343041@PA-MBX01.na.tibco.com>
References: <alpine.DEB.2.00.1309131749520.11354@lyonesse>
	<E66794E69CFDE04D9A70842786030B931C342FAA@PA-MBX01.na.tibco.com>
	<alpine.DEB.2.00.1309132314270.15045@lyonesse>
	<E66794E69CFDE04D9A70842786030B931C343041@PA-MBX01.na.tibco.com>
Message-ID: <alpine.DEB.2.00.1309140050230.15719@lyonesse>



On Fri, 13 Sep 2013, William Dunlap wrote:

> You may want to append -Inf (or 0 if you know the data cannot be
> negative) to the start of your 'values' vector so you don't
> have to write code to catch the cases when a threshold is below
> the range of the values.
>   > findInterval(thresholds, c(0,values,Inf))
>   [1] 1 5 5 5 8
>   > c(0, values, Inf)[.Last.value]
>   [1] 0.000 1.874 1.874 1.874 7.722

Thanks a lot! I'll stick with this method for this project.

Thanks a lot to arun as well, for profiling different methods.


From bt_jannis at yahoo.de  Fri Sep 13 18:51:58 2013
From: bt_jannis at yahoo.de (Jannis)
Date: Fri, 13 Sep 2013 18:51:58 +0200
Subject: [R] prevent mfrow from changing cex
Message-ID: <523342AE.2070404@yahoo.de>

Dear R users,


if I use par(mfrow=c(3,3)), R automatically changes the value of cex and 
even setting cex=1 in the same par() call does not seem to prevent this. 
Even though such behavior may be helpful an many cases, I am wondering 
whether there is a easy way to switch this off (short of setting cex to 
a value that would be 1 if modified by mfrow).

In the end my desire to have the software do what I tell it to do and 
not what its programmers think I would want to do was one of the reasons 
to move away to R from (in)famous Excel ;-).

Cheers
Jannis


From gunter.berton at gene.com  Fri Sep 13 19:01:11 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 13 Sep 2013 10:01:11 -0700
Subject: [R] prevent mfrow from changing cex
In-Reply-To: <523342AE.2070404@yahoo.de>
References: <523342AE.2070404@yahoo.de>
Message-ID: <CACk-te0odXA2+V-WKKx8s0NXu=xBZddWdpswV9gGYqC1twgTxQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130913/989ebfbf/attachment.pl>

From shidaxia at yahoo.com  Fri Sep 13 20:34:41 2013
From: shidaxia at yahoo.com (Shi, Tao)
Date: Fri, 13 Sep 2013 11:34:41 -0700 (PDT)
Subject: [R] code folding for both TeX sections and R code chunks in .rnw
	file
Message-ID: <1379097281.83378.YahooMailNeo@web124705.mail.ne1.yahoo.com>


Hi list,

Sorry, this is not a question directly for R, rather for R code editor.? I'm posting it here to capture wider audience.

The problem I'm facing is that as sometimes my .rnw file gets bigger and bigger, navigating through it becomes an issue.? Scrolling back-n-forth or remembering the line number of the section you want to go to are just not efficient.? It would be nice for the text editor to show a "table of content" tree NOT ONLY for .tex section/subsection headers BUT ALSO for R code chunks.? It's kind of like what WinEdt is doing for .tex file but also adding R code chunks into the tree.? (please see the first figure on?? http://www.winedt.com/snap.html ).? Rstudio does pretty good job on folding R code, but not the .tex section headers.? 


What are your best solutions?

Thanks!

Tao



From mary.kindall at gmail.com  Fri Sep 13 20:41:52 2013
From: mary.kindall at gmail.com (Mary Kindall)
Date: Fri, 13 Sep 2013 14:41:52 -0400
Subject: [R] Which regression tree algorithm to use for large data?
Message-ID: <CANStr57VKZknsK6d41GS7B6pXSp0OL+dwM1tWx6bjQvBGYvLWw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130913/579ed8c1/attachment.pl>

From dwinsemius at comcast.net  Fri Sep 13 20:42:39 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 13 Sep 2013 13:42:39 -0500
Subject: [R] GLM result output..
In-Reply-To: <CAP43mJ97ZFJFaZRLeaK6zVB01v8RMXQ8SHFBdrB55vBDDXRwEg@mail.gmail.com>
References: <CAP43mJ97ZFJFaZRLeaK6zVB01v8RMXQ8SHFBdrB55vBDDXRwEg@mail.gmail.com>
Message-ID: <8974D68E-04B6-4EE8-93A0-47FA0690F6A4@comcast.net>


On Sep 13, 2013, at 9:38 AM, Lutfor Rahman wrote:

> Dear forum members,
>
> Please help me understanding significance value when GLM done in r.
>
> After doing minimal adequate model, I have found a number of  
> independent
> values  which are significant. But doing their anova significant  
> values are
> different. Please find my result following. Which significant values  
> should
> I use.
>
>
> glm(formula = richness ~ moistcont + orgmatter + baresoil + grass10 +
>    wood10 + rdnet10 + moistcont:orgmatter + moistcont:baresoil +
>    grass10:wood10 + grass10:rdnet10 + wood10:rdnet10, family =  
> poisson,
>    data = data)
>
> Deviance Residuals:
>     Min        1Q    Median        3Q       Max
> -1.19112  -0.33682   0.09813   0.32808   0.70509
>
> Coefficients:
>                     Estimate Std. Error z value Pr(>|z|)
> (Intercept)         11.384447   4.014170   2.836  0.00457 **
> moistcont           -0.095813   0.084995  -1.127  0.25962
> orgmatter           -1.810116   0.613688  -2.950  0.00318 **
> baresoil            -1.636707   0.559129  -2.927  0.00342 **
> grass10             -0.018979   0.065647  -0.289  0.77250
> wood10               0.150683   0.128386   1.174  0.24053
> rdnet10             -0.011448   0.068090  -0.168  0.86648
> moistcont:orgmatter  0.025698   0.011521   2.231  0.02571 *
> moistcont:baresoil   0.044110   0.015799   2.792  0.00524 **
> grass10:wood10       0.010740   0.006498   1.653  0.09838 .
> grass10:rdnet10      0.011013   0.004412   2.496  0.01255 *
> wood10:rdnet10      -0.088297   0.027120  -3.256  0.00113 **

The only p-value I would have expected to be the same would have been  
the last one in the avova output:

>                    Df Deviance Resid. Df Resid. Dev Pr(>Chi)
> .....
> wood10:rdnet10       1  10.7812         6      3.928 0.001025 **

And that particular p-value is not far off from the 0.00113 value  
reported in the model summary. The other p-values are not of the same  
sort. The p-values above are basically reporting the "significance" of  
removing single predictors or interactions from the full model. The  
anova reported below is perfoming sequential addition of terms to a  
NULL model as well as doing a different test:  LR tests instead of  
Wald statistics.

-- 
David.


> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> (Dispersion parameter for poisson family taken to be 1)
>
>    Null deviance: 36.1673  on 17  degrees of freedom
> Residual deviance:  3.9276  on  6  degrees of freedom
> AIC: 97.893
>
> Number of Fisher Scoring iterations: 4
>
>> anova(data1, test="Chisq")
> Analysis of Deviance Table
>
> Model: poisson, link: log
>
> Response: richness
>
> Terms added sequentially (first to last)
>
>
>                    Df Deviance Resid. Df Resid. Dev Pr(>Chi)
> NULL                                   17     36.167
> moistcont            1   8.6322        16     27.535 0.003303 **
> orgmatter            1   2.1244        15     25.411 0.144966
> baresoil             1   0.0029        14     25.408 0.956986
> grass10              1   1.5251        13     23.883 0.216842
> wood10               1   3.6952        12     20.187 0.054570 .
> rdnet10              1   0.0001        11     20.187 0.990564
> moistcont:orgmatter  1   2.0482        10     18.139 0.152381
> moistcont:baresoil   1   2.8730         9     15.266 0.090076 .
> grass10:wood10       1   0.1431         8     15.123 0.705247
> grass10:rdnet10      1   0.4141         7     14.709 0.519883
> wood10:rdnet10       1  10.7812         6      3.928 0.001025 **
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From dwinsemius at comcast.net  Fri Sep 13 20:51:07 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 13 Sep 2013 13:51:07 -0500
Subject: [R] Creating dummy vars with contrasts - why does the returned
	identity matrix contain all levels (and not n-1 levels) ?
In-Reply-To: <DUB114-DS28C57F8A86245D07B7D278CA3B0@phx.gbl>
References: <DUB114-DS1481B35E35DF4AC29807F6CA3B0@phx.gbl>
	<FA5360B9-73E7-41A4-B577-77212FD4F25B@comcast.net>
	<DUB114-DS28C57F8A86245D07B7D278CA3B0@phx.gbl>
Message-ID: <544106D3-0042-4ACF-A5A1-0F572A4F7D5B@comcast.net>


On Sep 13, 2013, at 9:33 AM, E Joffe wrote:

> Thank you so much for your answer  !
> As far as I understand, glmnet doesn't accept categorical variables  
> only
> binary factors - so I had to create dummy variables for all  
> categorical
> variables.

I was rather puzzled by your question. The conventions used by glmnet  
should prevent constrasts from being pre-specified. Only matrices are  
accepted as data objects and one cannot assign contrast attributes to  
matrix columns.

> It worked perfectly.
> Erel
>
>
> Erel Joffe MD MSc
> School of Biomedical Informatics
> University of Texas - Health Science Center in Houston
> 832.287.0829 (c)
>
> -----Original Message-----
> From: David Winsemius [mailto:dwinsemius at comcast.net]
> Sent: Friday, September 13, 2013 3:05 PM
> To: E Joffe
> Cc: r-help at r-project.org
> Subject: Re: [R] Creating dummy vars with contrasts - why does the  
> returned
> identity matrix contain all levels (and not n-1 levels) ?
>
>
> On Sep 13, 2013, at 4:15 AM, E Joffe wrote:
>
>> Hello,
>>
>>
>>
>> I have a problem with creating an identity matrix for glmnet by using
>> the contrasts function.
>
> Why do you want to do this?
>
>> I have a factor with 4 levels.
>>
>> When I create dummy variables I think there should be n-1 variables
>> (in this case 3) - so that the contrasts would be against the  
>> baseline
>> level.
>>
>> This is also what is written in the help file for 'contrasts'.
>>
>> The problem is that the function creates a matrix with n variables
>> (i.e. the same as the number of levels) and not n-1 (where I would
>> have a baseline level for comparison).
>
> Only if you specify contrasts=FALSE does it do so and this is  
> documented in
> that help file.
>>
>>
>>
>> My questions are:
>>
>> 1.       How can I create a matrix with n-1 dummy vars ?
>
> See below.
>
>> was I supposed to
>> define explicitly that I want contr.treatment (contrasts) ?
>
> No need to do so.
>
>>
>> 2.       If it is not possible, how should I interpret the hazard
>> ratios in
>> the Cox regression I am generating (I use glmnet for variable
>> selection and
>> then generate a Cox regression)  - That is, if I get an HR of 3 for
>> the
>> variable 300mg what does it mean ? the hazard is 3 times higher of
>> what ?
>>
>
> Relative hazards are generally referenced to the "baseline hazard",
> i.e. the hazard for a group with the omitted level for treatment
> constrasts and the mean value for any numeric predictors.
>
>> Here is some code to reproduce the issue:
>>
>> # Create a 4 level example factor
>>
>> trt <- factor( sample( c("PLACEBO", "300 MG", "600 MG", "1200 MG"),
>>
>>                      100, replace=TRUE ) )
>
> # If your intent is to use constrasts different than the defaults used
> by
> #  regression functions, these factor contrasts need to be assigned,
> either
> # within the construction of the factor or after the fact.
>
>> contrasts(trt)
>         300 MG 600 MG PLACEBO
> 1200 MG      0      0       0
> 300 MG       1      0       0
> 600 MG       0      1       0
> PLACEBO      0      0       1
>
> # the default value for the contrasts parameter is TRUE and the
> default type is treatement
>
> # That did not cause any change to the 'trt'-object:
> trt
>
> #To make a change you need to use the `contrasts<-` function:
>
> contrasts (trt) <- contrasts(trt)
> trt
>
>>
>> # Use contrasts to get the identity matrix of dummy variables to be
>> used in
>> glmnet
>>
>> trt2 <- contrasts (trt,contrasts=FALSE)
>>
>> Results (as you can see all levels are represented in the identity
>> matrix):
>>
>>> levels (trt)
>> [1] "1200 MG" "300 MG"  "600 MG"  "PLACEBO"
>>
>>
>>> print (trt2)
>>
>>       1200 MG 300 MG 600 MG PLACEBO
>>
>> 1200 MG       1      0      0       0
>>
>> 300 MG        0      1      0       0
>>
>> 600 MG        0      0      1       0
>>
>> PLACEBO       0      0      0       1
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>
> Rhelp is a plain text mailing list.
>
> -- 
> David Winsemius, MD
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From capricyg at yahoo.com  Sat Sep 14 03:29:51 2013
From: capricyg at yahoo.com (capricy gao)
Date: Fri, 13 Sep 2013 18:29:51 -0700 (PDT)
Subject: [R] problem with grep under loop
In-Reply-To: <1378295727096-4675348.post@n4.nabble.com>
References: <1378295727096-4675348.post@n4.nabble.com>
Message-ID: <1379122191.23805.YahooMailNeo@web125004.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130913/f2f3a175/attachment.pl>

From patrick.schorderet at gmail.com  Fri Sep 13 19:02:14 2013
From: patrick.schorderet at gmail.com (Patrick Schorderet)
Date: Fri, 13 Sep 2013 13:02:14 -0400
Subject: [R] Running an R scrit from Automator
Message-ID: <8974C676-2918-4F8A-964B-366F1C7F624A@gmail.com>


I'm trying to write an Automator script for people who don't want to run scripts from the R console.
The workflow would ideally look like this:
- Ask user to enter different parameters (I was able to do this part)
- Run an R script using the paramters

I guess I need to run R via a shell script, but I just can't get my head around the problem.
Whatever I am doing, my R just pops open and closes directly.

This is what I tried (in Automator):
open "/usr/bin/Rscript" "./test_file/test.R"


From evan.sticca at stonybrook.edu  Fri Sep 13 18:47:42 2013
From: evan.sticca at stonybrook.edu (Evan Sticca)
Date: Fri, 13 Sep 2013 12:47:42 -0400
Subject: [R] Splitting data into two camps
Message-ID: <CAAomMNynA9UdQGJN7Va2XDLPtW1FZYav4KOc+OSUtwoTWOnorw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130913/d02478b7/attachment.pl>

From ryung.kim at einstein.yu.edu  Fri Sep 13 20:59:12 2013
From: ryung.kim at einstein.yu.edu (Ryung Kim)
Date: Fri, 13 Sep 2013 18:59:12 +0000
Subject: [R] Looking for data sets with unordered failure events of
 different types
Message-ID: <48C81F98C3BE8D4090474B110F2EC94666E3EC42@YUWEXCPM24.yuad.uds.yu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130913/796532f1/attachment.pl>

From mlinchits at gmail.com  Fri Sep 13 21:38:47 2013
From: mlinchits at gmail.com (Maxim Linchits)
Date: Fri, 13 Sep 2013 23:38:47 +0400
Subject: [R] Non-ACSII characters in R on Windows
Message-ID: <CAGKs4siL8rasbtsCgEfX=haESyAD5=7BHZv1R9CqeABS560aSQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130913/01b01fc6/attachment.pl>

From dwinsemius at comcast.net  Sat Sep 14 03:57:02 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 13 Sep 2013 18:57:02 -0700
Subject: [R] problem with grep under loop
In-Reply-To: <1379122191.23805.YahooMailNeo@web125004.mail.ne1.yahoo.com>
References: <1378295727096-4675348.post@n4.nabble.com>
	<1379122191.23805.YahooMailNeo@web125004.mail.ne1.yahoo.com>
Message-ID: <40494DF4-154D-4DA9-A34A-2DC015223CAA@comcast.net>

Wrap a print or cat function around it.



Sent from my iPhone

On Sep 13, 2013, at 6:29 PM, capricy gao <capricyg at yahoo.com> wrote:

> 
> 
> I am just testing the possibility of using grep under for loop:
> 
>> for(i in 1:10){grep("a",letters)}
> 
> 
> nothing came out;
> 
> when I ran: 
> 
> 
>> grep("a",letters),
> 
> 
> I got "1"
> 
> so in my for loop, I expected to see ten "1"s, but I did not.
> 
> Could anybody help me to figure out why? Thanks a lot for your help.
> 
> Capricy
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Sat Sep 14 04:05:32 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 13 Sep 2013 19:05:32 -0700 (PDT)
Subject: [R] problem with grep under loop
In-Reply-To: <1379122191.23805.YahooMailNeo@web125004.mail.ne1.yahoo.com>
References: <1378295727096-4675348.post@n4.nabble.com>
	<1379122191.23805.YahooMailNeo@web125004.mail.ne1.yahoo.com>
Message-ID: <1379124332.18645.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
Try:
for(i in 1:10) {print(grep("a",letters))}
[1] 1
[1] 1
[1] 1
[1] 1
[1] 1
[1] 1
[1] 1
[1] 1
[1] 1
[1] 1

x<- vector()
?for(i in 1:10) {x[i]<-grep("a",letters) }
?x
# [1] 1 1 1 1 1 1 1 1 1 1
A.K.





----- Original Message -----
From: capricy gao <capricyg at yahoo.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Friday, September 13, 2013 9:29 PM
Subject: [R] problem with grep under loop



I am just testing the possibility of using grep under for loop:

>for(i in 1:10){grep("a",letters)}


nothing came out;

when I ran: 


>grep("a",letters), 


I got "1"

so in my for loop, I expected to see ten "1"s, but I did not.

Could anybody help me to figure out why? Thanks a lot for your help.

Capricy
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jdnewmil at dcn.davis.CA.us  Sat Sep 14 04:21:00 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 13 Sep 2013 19:21:00 -0700
Subject: [R] problem with grep under loop
In-Reply-To: <1379122191.23805.YahooMailNeo@web125004.mail.ne1.yahoo.com>
References: <1378295727096-4675348.post@n4.nabble.com>
	<1379122191.23805.YahooMailNeo@web125004.mail.ne1.yahoo.com>
Message-ID: <a7c3f863-4913-4122-9bf0-344aea4fdd0c@email.android.com>

This is because you are not printing it (with the print or cat functions). Keep in mind that the visible result you get from calling a function or evaluating a variable interactively comes from the interactive R command line, not from R itself. Once you put such an expression inside a function (such as the "for" function) it is no longer directly being invoked by the command interpreter.

You might want to read [1] and [2] (which says don't post using HTML).

[1] http://stackoverflow.com/questions/4716152/why-do-r-objects-not-print-in-a-function-or-a-for-loop
[2] http://www.R-project.org/posting-guide.html
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

capricy gao <capricyg at yahoo.com> wrote:
>
>
>I am just testing the possibility of using grep under for loop:
>
>>for(i in 1:10){grep("a",letters)}
>
>
>nothing came out;
>
>when I ran: 
>
>
>>grep("a",letters), 
>
>
>I got "1"
>
>so in my for loop, I expected to see ten "1"s, but I did not.
>
>Could anybody help me to figure out why? Thanks a lot for your help.
>
>Capricy
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From capricyg at yahoo.com  Sat Sep 14 05:17:16 2013
From: capricyg at yahoo.com (capricy gao)
Date: Fri, 13 Sep 2013 20:17:16 -0700 (PDT)
Subject: [R] problem with grep under loop
In-Reply-To: <a7c3f863-4913-4122-9bf0-344aea4fdd0c@email.android.com>
References: <1378295727096-4675348.post@n4.nabble.com>
	<1379122191.23805.YahooMailNeo@web125004.mail.ne1.yahoo.com>
	<a7c3f863-4913-4122-9bf0-344aea4fdd0c@email.android.com>
Message-ID: <1379128636.42243.YahooMailNeo@web125003.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130913/b512f727/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Sat Sep 14 05:36:00 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 13 Sep 2013 20:36:00 -0700
Subject: [R] problem with grep under loop
In-Reply-To: <1379128636.42243.YahooMailNeo@web125003.mail.ne1.yahoo.com>
References: <1378295727096-4675348.post@n4.nabble.com>
	<1379122191.23805.YahooMailNeo@web125004.mail.ne1.yahoo.com>
	<a7c3f863-4913-4122-9bf0-344aea4fdd0c@email.android.com>
	<1379128636.42243.YahooMailNeo@web125003.mail.ne1.yahoo.com>
Message-ID: <e106089a-c3cd-4e28-b87c-d5cf546b3c82@email.android.com>

Please read the Posting Guide before you post again, and study how to make a reproducible example of your problem [1], and change the settings on your mail program to send plain text. I, for one, am not psychic, so need things spelled out clearly.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

capricy gao <capricyg at yahoo.com> wrote:
>Thanks a lot for all the responses!!
>
>I then first test my data:
>
>> dim(data)
>[1] 52086??? 13
>>? if(grep(data[3,4],data[3,12])==1) print("Y")
>[1] "Y"
>> for(i in 1:52086){if(grep(data[i,4],data[i,12])==1) print ("Y")}
>Error in if (grep(data[i, 4], data[i, 12]) == 1) print("Y") :
>? argument is of length zero
>
>
>What is this new error message? "argument is of length zero"
>
>Here is my data format:
>>head(data)
>
>?????????? V1???? V2???????? V3?????????? V4?????? V5? V6??????
>V7?????????? V8
>1 ref_gene_id ref_id class_code cuff_gene_id? cuff_id FMI???? FPKM
>FPKM_conf_lo
>2?????????? -????? -????????? u?????? C.3 C.3.1 100 1.000000????
>0.000000
>3?????????? -????? -????????? u?????? C.2 C.2.1 100 1.000000????
>0.000000
>4?????????? -????? -????????? u?????? C.4 C.4.1 100 1.000000????
>0.000000
>5?????????? -????? -????????? u?????? C.1 C.1.1 100 1.000000????
>0.000000
>6?????????? -????? -????????? u?????? C.5 C.5.1 100 1.000000????
>0.000000
>??????????? V9????? V10 V11????????? V12?????????? V13
>1 FPKM_conf_hi????? cov len major_iso_id ref_match_len
>2???? 0.000000 0.056682? 96???? C.3.1???????????? -
>3???? 0.000000 0.058453? 99???? C.2.1???????????? -
>4???? 0.000000 0.059634 101???? C.4.1???????????? -
>5???? 0.000000 0.059634 101???? C.2.1???????????? -
>6???? 0.000000 0.059634 101???? C.5.1???????????? -
>
>
>________________________________
> From: Jeff Newmiller <jdnewmil at dcn.davis.CA.us>
>To: capricy gao <capricyg at yahoo.com>; capricy gao <capricyg at yahoo.com>;
>"r-help at r-project.org" <r-help at r-project.org> 
>Sent: Friday, September 13, 2013 9:21 PM
>Subject: Re: [R] problem with grep under loop
> 
>
>This is because you are not printing it (with the print or cat
>functions). Keep in mind that the visible result you get from calling a
>function or evaluating a variable interactively comes from the
>interactive R command line, not from R itself. Once you put such an
>expression inside a function (such as the "for" function) it is no
>longer directly being invoked by the command interpreter.
>
>You might want to read [1] and [2] (which says don't post using HTML).
>
>[1]
>http://stackoverflow.com/questions/4716152/why-do-r-objects-not-print-in-a-function-or-a-for-loop
>[2] http://www.R-project.org/posting-guide.html
>---------------------------------------------------------------------------
>Jeff Newmiller? ? ? ? ? ? ? ? ? ? ? ? The? ?  .....? ? ?  .....? Go
>Live...
>DCN:<jdnewmil at dcn.davis.ca.us>? ? ? ? Basics: ##.#.? ? ?  ##.#.? Live
>Go...
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Live:?  OO#.. Dead: OO#..?
>Playing
>Research Engineer (Solar/Batteries? ? ? ? ? ? O.O#.? ? ?  #.O#.? with
>/Software/Embedded Controllers)? ? ? ? ? ? ?  .OO#.? ? ?  .OO#.?
>rocks...1k
>---------------------------------------------------------------------------
>
>Sent from my phone. Please excuse my brevity.
>
>capricy gao <capricyg at yahoo.com> wrote:
>>
>>
>>I am just testing the possibility of using grep under for loop:
>>
>>>for(i in 1:10){grep("a",letters)}
>>
>>
>>nothing came out;
>>
>>when I ran: 
>>
>>
>>>grep("a",letters), 
>>
>>
>>I got "1"
>>
>>so in my for loop, I expected to see ten "1"s, but I did not.
>>
>>Could anybody help me to figure out why? Thanks a lot for your help.
>>
>>Capricy
>>??? [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.


From capricyg at yahoo.com  Sat Sep 14 05:54:54 2013
From: capricyg at yahoo.com (capricy gao)
Date: Fri, 13 Sep 2013 20:54:54 -0700 (PDT)
Subject: [R] problem with grep under loop
In-Reply-To: <e106089a-c3cd-4e28-b87c-d5cf546b3c82@email.android.com>
References: <1378295727096-4675348.post@n4.nabble.com>
	<1379122191.23805.YahooMailNeo@web125004.mail.ne1.yahoo.com>
	<a7c3f863-4913-4122-9bf0-344aea4fdd0c@email.android.com>
	<1379128636.42243.YahooMailNeo@web125003.mail.ne1.yahoo.com>
	<e106089a-c3cd-4e28-b87c-d5cf546b3c82@email.android.com>
Message-ID: <1379130894.63762.YahooMailNeo@web125003.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130913/c50ff850/attachment.pl>

From zhangweiwu at realss.com  Sat Sep 14 06:01:59 2013
From: zhangweiwu at realss.com (Zhang Weiwu)
Date: Sat, 14 Sep 2013 12:01:59 +0800 (CST)
Subject: [R] the problem of buying and selling
Message-ID: <alpine.DEB.2.00.1309141014010.3530@lyonesse>


I own a lot to the folks on r-help list, especially arun who answered every 
of my question and was never wrong. I am disinclined to once again ask this 
question, since it is more arithmatic than technical. But, having worked 2 
days on it, I realized my brain is just not juicy enough....

Here is the problem.

 	Trust not for freedom to the Franks---
 	They have a king who buys and sells.
 			- Lord Byron: The Isles of Greece

Suppose the French King commands you to buy and sell, and tells you only to
deal if the profit is higher than 2%. Question: how much quantity will be 
dealt, and what is the actual profit? In fact, the King wants to see the 
relationship between his minimum-profit requirement and your result, in 
order to better his decision.

Let's look at the input data - a dump of which is attached to this mail.

Column 1 is the price of the market where you buy goods from, column 2 is 
the quantity of goods that is being sold at that price.

Column 3 is the price of the market where you sell goods to, column 4 is the 
quantity the buyers willing to buy at that price.

> cbind(t(to_buy_from), t(to_sell_to))

 	 [,1]  [,2]   [,3]   [,4]
  [1,] 61.7050   190 63.170   2500
  [2,] 61.7500    29 63.150    799
  [3,] 61.8050   166 63.110    500
  [4,] 61.8950   166 63.060  10000
  [5,] 61.9450   166 63.020   7840
  [6,] 61.9805  6150 62.995   2000
  [7,] 62.0000  3069 62.930   2000
  [8,] 62.0600   166 62.860  10811
  [9,] 62.1100   166 62.780  18054
[10,] 62.1450   166 62.755   9000
[11,] 62.1750   166 62.690  10960
[12,] 62.2250   166 62.635    100
[13,] 62.2450   166 62.585   2380
[14,] 62.2720   100 62.550   2119
[15,] 62.2830  4000 62.525 108091
[16,] 62.2875   100 62.505   2000
[17,] 62.2955   100 62.485    816
[18,] 62.3250   307 62.435    600
[19,] 62.3800  2906 62.400    300
[20,] 62.3940  1969 62.375   4611
[21,] 62.4250   166 62.355   5111
[22,] 62.4505  2000 62.335   1969
[23,] 62.4700   259 62.315    500
[24,] 62.4755    50 62.250   5142
[25,] 62.4800   166 62.165    660
[26,] 62.4935   305 62.115   2428
[27,] 62.4975  7786 62.085    779
[28,] 62.4995 50049 62.050  12811
[29,] 62.5045   914 62.015    192
[30,] 62.5150  1110 61.975   1200
[31,] 62.5285   400 61.895  40000
[32,] 62.5500  6352 61.835    100
[33,] 62.5750     9 61.775    133
[34,] 62.6000   394 61.750   7723

For the simpliest case, if the King had commanded that the minimum profit 
should be 2.3742%, which is equal to 63.170/61.7050 (look at the first row), 
then you can easily project that 190 quantity of goods will be dealt (the 
minmum of [1,2] and [1,4]), and that the actual profit is 2.3742%.

If the king, however, has commanded that a deal should only be carried out 
if the profit is higher than 2%, the calculation will be more complicated. I 
don't know the right method, but I can demonstrate the wrong method and 
explain why it is wrong.

The wrong approach is the following:

The idea is to write a function that asks how much volume (total quantity) 
you want to deal, and returns the profit. This generates a relationship 
between volume and profit, and with interpolation you can get the volumen 
for any given minimum-profit requirement.


revenues <- function(open_orders, volumes) {
# calculate revenue using a list of open orders and desirable "volumes" of goods

# expecting volumnes as a vector, to test the revenue (total amont of money)
# for each volume (total amount of goods to deal) in the 'volumes'

 	volume  <- sapply(1:length(open_orders[2,]),
 		function(x) { sum(open_orders[2,1:x])})
 	revenue <- sapply(1:length(open_orders[2,]),
 		function(x) { sum(open_orders[1, 1:x] * open_orders[2,1:x])})
 	i <- findInterval(volumes, c(0, volume))
 	c(0, revenue)[i] + c(open_orders[1,], 0)[i]*(
 		volumes - c(0, volume)[i])
}

data.frame(volume = volumes, profit = revenues(to_sell_to, volumes) /
 	                              revenues(to_buy_from, volumes) - 1)

With the above routine, let us test the profit with the following volumes:

> volumes = c(10, 100, 500, 1000, 5000, 10000, 30000, 50000, 70000, 90000)

And the result:

> data.frame(volume = volumes, profit = revenues(to_sell_to, volumes) /
+                                       revenues(to_buy_from, volumes) - 1)
    volume      profit
    1      10 0.023741938
    2     100 0.023741938
    3     500 0.022424508
    4    1000 0.020974612
    5    5000 0.018972785
    6   10000 0.018087976
    7   30000 0.012223652
    8   50000 0.009288480
    9   70000 0.007729286
    10  90000 0.006204251

So, by looking up the table, if the king requires minimum profit of 2%, the 
volume (total quantity) of goods being dealt should be a bit more than 1000. 
This answer is inexact, but our French King should get by with it. After 
all, he remembers nothing more than the number of digits.

Now let's look at why it is wrong. This answer is, actually, correct, but 
the method won't hold.

Suppose our greedy King asks what volume should be deal if he requires 
ANY deal should be done as long as there is a tiny bit of profit to be made, 
then, according to our lookup-table, we need to deal 90000 volume of goods, 
which is about all the goods you can buy from the market (look at the 
to_buy_from vector, the sum of all goods is some 90000). Now look at the 
bottom rows:

> cbind(t(to_buy_from), t(to_sell_to))
          [,1]  [,2]   [,3]   [,4]
  [1,] 61.7050   190 63.170   2500
  [2,] 61.7500    29 63.150    799
  [3,] 61.8050   166 63.110    500
...
[31,] 62.5285   400 61.895  40000
[32,] 62.5500  6352 61.835    100
[33,] 62.5750     9 61.775    133
[34,] 62.6000   394 61.750   7723

It suggests that if you buys up the whole market, the last a few hands of 
deals are perhaps not profiting at all - they are losing money - since the 
price you buy may be higher than the price you sell - consider for example 
buying at 62.6000 and selling at 61.750. This can be verified.?

So what is the right approach? I don't know. I exhused my brain. Perhaps you 
can shed some lights.

And in case you wonder why I do the calculation in R: that's because I am 
studying hundreds of markets, having calculation in one place and statistics 
in another is not convenient, besides noone said R isn't good for 
calculation.

--

? To verify:

   When you buy up the whole market, and sell all goods, the worse price you
   sell at will be 62.525, at [15,3], the point where the market-to-sell-in
   volume reaches that of the market-to-buy-from, this is lower than the
   price you buy at 62.6000 ([34,1]), indicating that you are, indeed, in
   this last hand of deal, buying at a higher price than you sell it. The
   lose is small, but can be much wore with a different set of data.
-------------- next part --------------
to_sell_to <-
structure(c(63.1699981689453, 2500, 63.1500015258789, 799, 63.1100006103516, 
500, 63.060001373291, 10000, 63.0200004577637, 7840, 62.9949989318848, 
2000, 62.9300003051758, 2000, 62.8600006103516, 10811, 62.7799987792969, 
18054, 62.7550010681152, 9000, 62.689998626709, 10960, 62.6349983215332, 
100, 62.5849990844727, 2380, 62.5499992370605, 2119, 62.5250015258789, 
108091, 62.5050010681152, 2000, 62.4850006103516, 816, 62.435001373291, 
600, 62.4000015258789, 300, 62.375, 4611, 62.3549995422363, 5111, 
62.3349990844727, 1969, 62.314998626709, 500, 62.25, 5142, 62.1650009155273, 
660, 62.1150016784668, 2428, 62.0849990844727, 779, 62.0499992370605, 
12811, 62.0149993896484, 192, 61.9749984741211, 1200, 61.8950004577637, 
40000, 61.8349990844727, 100, 61.7750015258789, 133, 61.75, 7723
), .Dim = c(2L, 34L))

From bhh at xs4all.nl  Sat Sep 14 06:47:31 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sat, 14 Sep 2013 06:47:31 +0200
Subject: [R] Running an R scrit from Automator
In-Reply-To: <8974C676-2918-4F8A-964B-366F1C7F624A@gmail.com>
References: <8974C676-2918-4F8A-964B-366F1C7F624A@gmail.com>
Message-ID: <0230F6B4-E725-4ACF-82CC-3365A678A906@xs4all.nl>


On 13-09-2013, at 19:02, Patrick Schorderet <patrick.schorderet at gmail.com> wrote:

> 
> I'm trying to write an Automator script for people who don't want to run scripts from the R console.
> The workflow would ideally look like this:
> - Ask user to enter different parameters (I was able to do this part)
> - Run an R script using the paramters
> 
> I guess I need to run R via a shell script, but I just can't get my head around the problem.
> Whatever I am doing, my R just pops open and closes directly.
> 
> This is what I tried (in Automator):
> open "/usr/bin/Rscript" "./test_file/test.R"
> 

This is a Mac question.
It belongs in the R-SIG-Mac mailing list (  R-SIG-Mac at r-project.org  )(https://stat.ethz.ch/mailman/listinfo/r-sig-mac)
And it's more an Automator than an R subject.

But to answer your question: just

/usr/bin/Rscript "./test_file/test.R"

will do.
Since there are no spaces in the filepath you can leave out those double quotes.

Berend

> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Sat Sep 14 06:46:52 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 13 Sep 2013 21:46:52 -0700 (PDT)
Subject: [R] problem with grep under loop
In-Reply-To: <1379122191.23805.YahooMailNeo@web125004.mail.ne1.yahoo.com>
References: <1378295727096-4675348.post@n4.nabble.com>
	<1379122191.23805.YahooMailNeo@web125004.mail.ne1.yahoo.com>
Message-ID: <1379134012.31325.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
dat1<- read.table("gao.txt",sep="",header=FALSE,stringsAsFactors=FALSE)
?dat1
#?????????? V1???? V2???????? V3?????????? V4????? V5? V6?????? V7?????????? V8
#1 ref_gene_id ref_id class_code cuff_gene_id cuff_id FMI???? FPKM FPKM_conf_lo
#2?????????? -????? -????????? u????????? C.3?? C.3.1 100 1.000000???? 0.000000
#3?????????? -????? -????????? u????????? C.2?? C.2.1 100 1.000000???? 0.000000
#4?????????? -????? -????????? u????????? C.4?? C.4.1 100 1.000000???? 0.000000
#5?????????? -????? -????????? u????????? C.1?? C.1.1 100 1.000000???? 0.000000
#6?????????? -????? -????????? u????????? C.5?? C.5.1 100 1.000000???? 0.000000
#??????????? V9????? V10 V11????????? V12?????????? V13
#1 FPKM_conf_hi????? cov len major_iso_id ref_match_len
#2???? 0.000000 0.056682? 96??????? C.3.1???????????? -
#3???? 0.000000 0.058453? 99??????? C.2.1???????????? -
#4???? 0.000000 0.059634 101??????? C.4.1???????????? -
#5???? 0.000000 0.059634 101??????? C.2.1???????????? -
#6???? 0.000000 0.059634 101??????? C.5.1???????????? -

You should read the dataset with? read.table(...., header=TRUE) as your dataset already had colnames.

for(i in 1:nrow(dat1)){if(length(grep(dat1[i,4],dat1[i,12])==1)!=0) print("Y")}
[1] "Y"
[1] "Y"
[1] "Y"
[1] "Y"

A.K.



Sorry about that. I will try to reformat my question. 

I have a dataset with format like: 
---------------------------------- 
> head(data) 
?????????? V1???? V2???????? V3?????????? V4?????? V5? V6?????? V7?????????? V8 
1 ref_gene_id ref_id class_code cuff_gene_id? cuff_id FMI???? FPKM FPKM_conf_lo 
2?????????? -????? -????????? u?????? C.3 C.3.1 100 1.000000???? 0.000000 
3?????????? -????? -????????? u?????? C.2 C.2.1 100 1.000000???? 0.000000 
4?????????? -????? -????????? u?????? C.4 C.4.1 100 1.000000???? 0.000000 
5?????????? -????? -????????? u?????? C.1 C.1.1 100 1.000000???? 0.000000 
6?????????? -????? -????????? u?????? C.5 C.5.1 100 1.000000???? 0.000000 
??????????? V9????? V10 V11????????? V12?????????? V13 
1 FPKM_conf_hi????? cov len major_iso_id ref_match_len 
2???? 0.000000 0.056682? 96???? C.3.1???????????? - 
3???? 0.000000 0.058453? 99???? C.2.1???????????? - 
4???? 0.000000 0.059634 101???? C.4.1???????????? - 
5???? 0.000000 0.059634 101???? C.7.1???????????? - 
6???? 0.000000 0.059634 101???? C.5.1???????????? - 
--------------------- 
here column5 has extra ".1" compared with column4, and column12 
might be different from column5 with similar format, for example row 5; 
but most of them (column5 and column12) are the same (like the rest of 
the rows) . I am trying to find the different ones by using "grep" 

this data has a dimension of ?52086? by 13 

so my ran the following code: 
------------ 
> dim(data) 
[1] 52086??? 13 
>? if(grep(data[3,4],data[3,12])==1) print("Y") 
[1] "Y" 
> for(i in 1:52086){if(grep(data[i,4],data[i,12])==1) print ("Y")} 
Error in if (grep(data[i, 4], data[i, 12]) == 1) print("Y") : 
? argument is of length zero 

----------- 

here I tested the grep command first and it looks ok. However, when I put it in for loop, error message came: 
argument is of length zero 

Could you please help me figure out what happened here? 

Thanks a lot for your help. 




----- Original Message -----
From: capricy gao <capricyg at yahoo.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Friday, September 13, 2013 9:29 PM
Subject: [R] problem with grep under loop



I am just testing the possibility of using grep under for loop:

>for(i in 1:10){grep("a",letters)}


nothing came out;

when I ran: 


>grep("a",letters), 


I got "1"

so in my for loop, I expected to see ten "1"s, but I did not.

Could anybody help me to figure out why? Thanks a lot for your help.

Capricy
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ejoffe at hotmail.com  Sat Sep 14 08:21:10 2013
From: ejoffe at hotmail.com (E Joffe)
Date: Sat, 14 Sep 2013 08:21:10 +0200
Subject: [R] Creating dummy vars with contrasts - why does the returned
	identity matrix contain all levels (and not n-1 levels) ?
In-Reply-To: <544106D3-0042-4ACF-A5A1-0F572A4F7D5B@comcast.net>
References: <DUB114-DS1481B35E35DF4AC29807F6CA3B0@phx.gbl>
	<FA5360B9-73E7-41A4-B577-77212FD4F25B@comcast.net>
	<DUB114-DS28C57F8A86245D07B7D278CA3B0@phx.gbl>
	<544106D3-0042-4ACF-A5A1-0F572A4F7D5B@comcast.net>
Message-ID: <DUB114-DS392E0830FFA2D67F34763CCA240@phx.gbl>

Hi David,

First I ordered the levels of each factor in a descending order based on
frequency.
Then, I used the following code to generate a matrix from the dataframe with
dummy variables and  subsequently run the glmnet (coxnet)

  ## tranform categorical variables into binary variables with dummy for
trainSet
  predict_matrix <- model.matrix(~ ., data=trainSet, 
                                 contrasts.arg = lapply
(trainSet[,sapply(trainSet, is.factor)], contrasts))
  
  ## remove the status/time variables from the predictor matrix (x) for
glmnet
  predict_matrix <- subset (predict_matrix, select=c(-time,-status))
  
  ## create a glmnet cox object using lasso regularization and cross
validation
  glmnet.cv <- cv.glmnet (predict_matrix, surv_obj, family="cox")


I hope I did not do anything wrong .....

Can't thank you enough for your advice and interest.

Erel 



-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: Friday, September 13, 2013 8:51 PM
To: E Joffe
Cc: r-help at r-project.org
Subject: Re: [R] Creating dummy vars with contrasts - why does the returned
identity matrix contain all levels (and not n-1 levels) ?


On Sep 13, 2013, at 9:33 AM, E Joffe wrote:

> Thank you so much for your answer  !
> As far as I understand, glmnet doesn't accept categorical variables 
> only binary factors - so I had to create dummy variables for all 
> categorical variables.

I was rather puzzled by your question. The conventions used by glmnet should
prevent constrasts from being pre-specified. Only matrices are accepted as
data objects and one cannot assign contrast attributes to matrix columns.

> It worked perfectly.
> Erel
>
>
> Erel Joffe MD MSc
> School of Biomedical Informatics
> University of Texas - Health Science Center in Houston
> 832.287.0829 (c)
>
> -----Original Message-----
> From: David Winsemius [mailto:dwinsemius at comcast.net]
> Sent: Friday, September 13, 2013 3:05 PM
> To: E Joffe
> Cc: r-help at r-project.org
> Subject: Re: [R] Creating dummy vars with contrasts - why does the 
> returned identity matrix contain all levels (and not n-1 levels) ?
>
>
> On Sep 13, 2013, at 4:15 AM, E Joffe wrote:
>
>> Hello,
>>
>>
>>
>> I have a problem with creating an identity matrix for glmnet by using 
>> the contrasts function.
>
> Why do you want to do this?
>
>> I have a factor with 4 levels.
>>
>> When I create dummy variables I think there should be n-1 variables 
>> (in this case 3) - so that the contrasts would be against the 
>> baseline level.
>>
>> This is also what is written in the help file for 'contrasts'.
>>
>> The problem is that the function creates a matrix with n variables 
>> (i.e. the same as the number of levels) and not n-1 (where I would 
>> have a baseline level for comparison).
>
> Only if you specify contrasts=FALSE does it do so and this is 
> documented in that help file.
>>
>>
>>
>> My questions are:
>>
>> 1.       How can I create a matrix with n-1 dummy vars ?
>
> See below.
>
>> was I supposed to
>> define explicitly that I want contr.treatment (contrasts) ?
>
> No need to do so.
>
>>
>> 2.       If it is not possible, how should I interpret the hazard
>> ratios in
>> the Cox regression I am generating (I use glmnet for variable
>> selection and
>> then generate a Cox regression)  - That is, if I get an HR of 3 for
>> the
>> variable 300mg what does it mean ? the hazard is 3 times higher of
>> what ?
>>
>
> Relative hazards are generally referenced to the "baseline hazard",
> i.e. the hazard for a group with the omitted level for treatment
> constrasts and the mean value for any numeric predictors.
>
>> Here is some code to reproduce the issue:
>>
>> # Create a 4 level example factor
>>
>> trt <- factor( sample( c("PLACEBO", "300 MG", "600 MG", "1200 MG"),
>>
>>                      100, replace=TRUE ) )
>
> # If your intent is to use constrasts different than the defaults used
> by
> #  regression functions, these factor contrasts need to be assigned,
> either
> # within the construction of the factor or after the fact.
>
>> contrasts(trt)
>         300 MG 600 MG PLACEBO
> 1200 MG      0      0       0
> 300 MG       1      0       0
> 600 MG       0      1       0
> PLACEBO      0      0       1
>
> # the default value for the contrasts parameter is TRUE and the
> default type is treatement
>
> # That did not cause any change to the 'trt'-object:
> trt
>
> #To make a change you need to use the `contrasts<-` function:
>
> contrasts (trt) <- contrasts(trt)
> trt
>
>>
>> # Use contrasts to get the identity matrix of dummy variables to be
>> used in
>> glmnet
>>
>> trt2 <- contrasts (trt,contrasts=FALSE)
>>
>> Results (as you can see all levels are represented in the identity
>> matrix):
>>
>>> levels (trt)
>> [1] "1200 MG" "300 MG"  "600 MG"  "PLACEBO"
>>
>>
>>> print (trt2)
>>
>>       1200 MG 300 MG 600 MG PLACEBO
>>
>> 1200 MG       1      0      0       0
>>
>> 300 MG        0      1      0       0
>>
>> 600 MG        0      0      1       0
>>
>> PLACEBO       0      0      0       1
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>
> Rhelp is a plain text mailing list.
>
> -- 
> David Winsemius, MD
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From zhangweiwu at realss.com  Sat Sep 14 10:49:19 2013
From: zhangweiwu at realss.com (Zhang Weiwu)
Date: Sat, 14 Sep 2013 16:49:19 +0800 (CST)
Subject: [R] the problem of buying and selling
In-Reply-To: <alpine.DEB.2.00.1309141014010.3530@lyonesse>
References: <alpine.DEB.2.00.1309141014010.3530@lyonesse>
Message-ID: <alpine.DEB.2.00.1309141643450.17934@lyonesse>



On Sat, 14 Sep 2013, Zhang Weiwu wrote:

> I own a lot to the folks on r-help list, especially arun who answered 
> every of my question and was never wrong. I am disinclined to once again 
> ask this question, since it is more arithmatic than technical. But, having 
> worked 2 days on it, I realized my brain is just not juicy enough....
>
> Here is the problem.
>
> 	Trust not for freedom to the Franks---
> 	They have a king who buys and sells.
> 			- Lord Byron: The Isles of Greece
>
> Suppose the French King commands you to buy and sell, and tells you only to
> deal if the profit is higher than 2%. Question: how much quantity will be 
> dealt, and what is the actual profit? In fact, the King wants to see the 
> relationship between his minimum-profit requirement and your result, in order 
> to better his decision.
>
> Let's look at the input data - a dump of which is attached to this mail.
>
> Column 1 is the price of the market where you buy goods from, column 2 is the 
> quantity of goods that is being sold at that price.
>
> Column 3 is the price of the market where you sell goods to, column 4 is the 
> quantity the buyers willing to buy at that price.

Forgive my carelessness. I should emphasize that there is only one type 
goods to be dealt. The below table should be read in this way: there is 190 
quantity of goods being sold at 61.7050 that you can buy from, and 29 
quantity of goods beign sold at 61.7500 that you can buy from (row 1 and 2, 
column 1 and 2).  They are exactly the same type of goods, that you can sell 
the total volume of 219 at the price of 63.170.

>> cbind(t(to_buy_from), t(to_sell_to))
>
> 	 [,1]  [,2]   [,3]   [,4]
> [1,] 61.7050   190 63.170   2500
> [2,] 61.7500    29 63.150    799
> [3,] 61.8050   166 63.110    500
> [4,] 61.8950   166 63.060  10000
> [5,] 61.9450   166 63.020   7840
> [6,] 61.9805  6150 62.995   2000
> [7,] 62.0000  3069 62.930   2000
> [8,] 62.0600   166 62.860  10811
> [9,] 62.1100   166 62.780  18054
> [10,] 62.1450   166 62.755   9000
> [11,] 62.1750   166 62.690  10960
> [12,] 62.2250   166 62.635    100
> [13,] 62.2450   166 62.585   2380
> [14,] 62.2720   100 62.550   2119
> [15,] 62.2830  4000 62.525 108091
> [16,] 62.2875   100 62.505   2000
> [17,] 62.2955   100 62.485    816
> [18,] 62.3250   307 62.435    600
> [19,] 62.3800  2906 62.400    300
> [20,] 62.3940  1969 62.375   4611
> [21,] 62.4250   166 62.355   5111
> [22,] 62.4505  2000 62.335   1969
> [23,] 62.4700   259 62.315    500
> [24,] 62.4755    50 62.250   5142
> [25,] 62.4800   166 62.165    660
> [26,] 62.4935   305 62.115   2428
> [27,] 62.4975  7786 62.085    779
> [28,] 62.4995 50049 62.050  12811
> [29,] 62.5045   914 62.015    192
> [30,] 62.5150  1110 61.975   1200
> [31,] 62.5285   400 61.895  40000
> [32,] 62.5500  6352 61.835    100
> [33,] 62.5750     9 61.775    133
> [34,] 62.6000   394 61.750   7723
>
> For the simpliest case, if the King had commanded that the minimum profit 
> should be 2.3742%, which is equal to 63.170/61.7050 (look at the first row), 
> then you can easily project that 190 quantity of goods will be dealt (the 
> minmum of [1,2] and [1,4]), and that the actual profit is 2.3742%.
>
> If the king, however, has commanded that a deal should only be carried out if 
> the profit is higher than 2%, the calculation will be more complicated. I 
> don't know the right method, but I can demonstrate the wrong method and 
> explain why it is wrong.
>
> The wrong approach is the following:
>
> The idea is to write a function that asks how much volume (total quantity) 
> you want to deal, and returns the profit. This generates a relationship 
> between volume and profit, and with interpolation you can get the volumen for 
> any given minimum-profit requirement.
>
>
> revenues <- function(open_orders, volumes) {
> # calculate revenue using a list of open orders and desirable "volumes" of 
> goods
>
> # expecting volumnes as a vector, to test the revenue (total amont of money)
> # for each volume (total amount of goods to deal) in the 'volumes'
>
> 	volume  <- sapply(1:length(open_orders[2,]),
> 		function(x) { sum(open_orders[2,1:x])})
> 	revenue <- sapply(1:length(open_orders[2,]),
> 		function(x) { sum(open_orders[1, 1:x] * open_orders[2,1:x])})
> 	i <- findInterval(volumes, c(0, volume))
> 	c(0, revenue)[i] + c(open_orders[1,], 0)[i]*(
> 		volumes - c(0, volume)[i])
> }
>
> data.frame(volume = volumes, profit = revenues(to_sell_to, volumes) /
> 	                              revenues(to_buy_from, volumes) - 1)
>
> With the above routine, let us test the profit with the following volumes:
>
>> volumes = c(10, 100, 500, 1000, 5000, 10000, 30000, 50000, 70000, 90000)
>
> And the result:
>
>> data.frame(volume = volumes, profit = revenues(to_sell_to, volumes) /
> +                                       revenues(to_buy_from, volumes) - 1)
>   volume      profit
>   1      10 0.023741938
>   2     100 0.023741938
>   3     500 0.022424508
>   4    1000 0.020974612
>   5    5000 0.018972785
>   6   10000 0.018087976
>   7   30000 0.012223652
>   8   50000 0.009288480
>   9   70000 0.007729286
>   10  90000 0.006204251


From petretta at unina.it  Sat Sep 14 12:44:44 2013
From: petretta at unina.it (petretta at unina.it)
Date: Sat, 14 Sep 2013 12:44:44 +0200
Subject: [R] meta-analysis of annualized event rate (Michael Dewey)
Message-ID: <20130914124444.49760wk2qo3uo5y4@inbox.unina.it>

Many thanks to Michael Dewey for the kindly replay.

escalc (and metafor) works well !!

-- 
Mario Petretta
Department of Translational Medical Sciences
Naples University Federico II
Italy


Michael Dewey <info at aghmed.fsnet.co.uk> ha scritto:

> At 18:51 11/09/2013, petretta at unina.it wrote:
>> r-help at r-project.org
>>
>> Dear all,
>>
>> I use R 2.15.2 for Windows 8
>>
>> I ask if it is possible perform a meta-analysis of annualized event
>> rate from several studies reporting
>
> Try metafor (from CRAN)
>
> Look in the help for escalc for incidence rate ratio and see if that  
> section fits the studies you have.
>
>
>> 1) number of patients enrolled (N)
>> 2) mean lenght of follow-up time (mo)
>> 3) annualized event rate (AER) (expressed as % person-year)
>>
>> I would like suggestions on package(s) and code.
>>
>> Many thanks in advance.
>>

-- 
Mario Petretta
Department of Translational Medical Sciences
Naples University Federico II
Italy




-- 
Mario Petretta
Department of Translational Medical Sciences
Naples University Federico II
Italy


From lorenzo.isella at gmail.com  Sat Sep 14 12:56:35 2013
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Sat, 14 Sep 2013 12:56:35 +0200
Subject: [R] Markov Decision Process
Message-ID: <op.w3ed0lskzqkd1e@nirvana>

Dear All,
I am struggling with the conceptual aspects of a problem.
I am sure that someone on this list must be familiar with this.
Let's say that you have some cancer data for your patients.
In particular, every patient may undergo up to [i.e. the cycles may stop  
earlier for various reasons] 6 cycles of therapy (hormonal or  
chemotherapy) whose durations and starting times are known. There are  
plenty of other data available, but let us keep it simple for now.
At the end of the therapy cycles, you know if the patient is dead or alive  
(in reality, the final states are more as the patient may be dead  
with/without cancer or alive with/without cancer, but again, let's keep it  
simple for now).
Of course, you want to develop a policy which maximizes the probability of  
the patient to be alive at the end of the cycles of therapies.
Does anybody know how to tackle this in a Markov decision approach?
There are so many R packages dealing with Markov chains that it is almost  
confusing for a beginner.
Any suggestion is welcome.
Many thanks

Lorenzo


From bt_jannis at yahoo.de  Sat Sep 14 15:01:02 2013
From: bt_jannis at yahoo.de (Jannis)
Date: Sat, 14 Sep 2013 15:01:02 +0200
Subject: [R] prevent mfrow from changing cex
In-Reply-To: <CACk-te0odXA2+V-WKKx8s0NXu=xBZddWdpswV9gGYqC1twgTxQ@mail.gmail.com>
References: <523342AE.2070404@yahoo.de>
	<CACk-te0odXA2+V-WKKx8s0NXu=xBZddWdpswV9gGYqC1twgTxQ@mail.gmail.com>
Message-ID: <52345E0E.20101@yahoo.de>

Thanks for your reply, Gert. I was aware of the documentation. Thanks 
for your hint. In addition I have found that running

par(mfrow = c(2,2))
par(cex=1)

sequentially also has the desired result.


Cheers
Jannis

On 13.09.2013 19:01, Bert Gunter wrote:
> ?par documents this behavior. I think if you just initially large cex by
> the appropriate amount, that might compensate for it, but I haven't tested
> this (I use lattice and grid graphics). Otherwise, as suggested in ?par,
> consider ?layout.
>
> Cheers,
> Bert
>
>
> On Fri, Sep 13, 2013 at 9:51 AM, Jannis <bt_jannis at yahoo.de> wrote:
>
>> Dear R users,
>>
>>
>> if I use par(mfrow=c(3,3)), R automatically changes the value of cex and
>> even setting cex=1 in the same par() call does not seem to prevent this.
>> Even though such behavior may be helpful an many cases, I am wondering
>> whether there is a easy way to switch this off (short of setting cex to a
>> value that would be 1 if modified by mfrow).
>>
>> In the end my desire to have the software do what I tell it to do and not
>> what its programmers think I would want to do was one of the reasons to
>> move away to R from (in)famous Excel ;-).
>>
>> Cheers
>> Jannis
>>
>> ______________________________**________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide http://www.R-project.org/**
>> posting-guide.html <http://www.R-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


From khufu at 139.com  Sat Sep 14 14:47:32 2013
From: khufu at 139.com (=?utf-8?B?6IOh5aSr?=)
Date: Sat, 14 Sep 2013 20:47:32 +0800 (CST)
Subject: [R] the problem of buying and selling
References: <alpine.DEB.2.00.1309141014010.3530@lyonesse>
Message-ID: <2afa523451b8c59-0000d.Richmail.00020880316198468359@139.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130914/be49be25/attachment.pl>

From gildororonar at mail-on.us  Sat Sep 14 18:35:43 2013
From: gildororonar at mail-on.us (gildororonar at mail-on.us)
Date: Sat, 14 Sep 2013 11:35:43 -0500
Subject: [R] how to do this trimming/selecting in canonical R?
Message-ID: <20130914113543.14365omqcwrp9mo0@www.vfemail.net>

This is better explained by example:

> A <- data.frame(force = sort(runif(10, 0, 1)), condition =  
> sort(sample(0:100, 10)))
> B <- data.frame(counterforce = sort(runif(15, 0, 1), decreasing=T),  
> condition = sort(sample(0:100, 15)))

So we have:

> A
         force condition
1  0.03515542         1
2  0.13267882        13
3  0.26155689        24
4  0.37453142        38
5  0.39360520        45 <--- trim everything after this
6  0.43924737        48
7  0.47669800        50
8  0.57044795        51
9  0.81177499        61
10 0.98860450        94

> B
    counterforce condition
1   0.965769548         2
2   0.965266255         5
3   0.846941244         7
4   0.818013029        11
5   0.813139978        22
6   0.730599939        34
7   0.715985436        39
8   0.658073895        40
9   0.421264948        42 <--- trim everything after this
10  0.373774505        52
11  0.242191461        62
12  0.090584590        63
13  0.070020635        68
14  0.067366062        83
15  0.001585313        84

I need to trim away rows after No. 5, from A, trim away rows after No.  
9, from B.

Because

A[5, condition] > max(B[1:9, condition] && A[5, force] > B[9+1, counterforce]

In a general way, I am looking for x and y, where:

A[x, condition] > max(B[1:y, condition] && A[x, force] > B[y+1, counterforce]

and I will select A[1:x,] and B[1:y,], or trim away the rest, because  
they are irrelevent for the calculation onwards.

This is easy to do it in C, and I actually have done it in C-like R  
script, by looping through all rows of A, and breaking from the loop  
when finding the matching trim-point in B. But I am learning R, so  
what is the native way to do it in R?


-------------------------------------------------

VFEmail.net - http://www.vfemail.net
$14.95 ONETIME Lifetime accounts with Privacy Features!  
15GB disk! No bandwidth quotas!
Commercial and Bulk Mail Options!


From ggrothendieck at gmail.com  Sat Sep 14 20:04:39 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 14 Sep 2013 14:04:39 -0400
Subject: [R] how to do this trimming/selecting in canonical R?
In-Reply-To: <20130914113543.14365omqcwrp9mo0@www.vfemail.net>
References: <20130914113543.14365omqcwrp9mo0@www.vfemail.net>
Message-ID: <CAP01uR=XxeRuo+jNrNjdjY0j=9cWsgimDwu5fdGbApzmd4p8KQ@mail.gmail.com>

On Sat, Sep 14, 2013 at 12:35 PM,  <gildororonar at mail-on.us> wrote:
> This is better explained by example:
>
>> A <- data.frame(force = sort(runif(10, 0, 1)), condition =
>> sort(sample(0:100, 10)))
>> B <- data.frame(counterforce = sort(runif(15, 0, 1), decreasing=T),
>> condition = sort(sample(0:100, 15)))
>
>
> So we have:
>
>> A
>
>         force condition
> 1  0.03515542         1
> 2 0.13267882        13
> 3 0.26155689        24
> 4 0.37453142        38
> 5 0.39360520        45 <--- trim everything after this
> 6 0.43924737        48
> 7 0.47669800        50
> 8 0.57044795        51
> 9  0.81177499        61
> 10 0.98860450        94
>
>> B
>
>    counterforce condition
> 1   0.965769548         2
> 2   0.965266255         5
> 3   0.846941244         7
> 4   0.818013029        11
> 5   0.813139978        22
> 6   0.730599939        34
> 7   0.715985436        39
> 8   0.658073895        40
> 9   0.421264948        42 <--- trim everything after this
> 10  0.373774505        52
> 11  0.242191461        62
> 12  0.090584590        63
> 13  0.070020635        68
> 14  0.067366062        83
> 15  0.001585313        84
>
> I need to trim away rows after No. 5, from A, trim away rows after No. 9,
> from B.
>
> Because
>
> A[5, condition] > max(B[1:9, condition] && A[5, force] > B[9+1,
> counterforce]
>
> In a general way, I am looking for x and y, where:
>
> A[x, condition] > max(B[1:y, condition] && A[x, force] > B[y+1,
> counterforce]
>
> and I will select A[1:x,] and B[1:y,], or trim away the rest, because they
> are irrelevent for the calculation onwards.

Try this:

library(sqldf)

r <- sqldf("select a.condition,  b1.condition
   from A a, B b1, B b2
   where a.condition > b1.condition
   and a.force > b2.counterforce
   and b2.rowid = b1.rowid + 1
   order by a.condition, b1.condition
   limit 1")

Atrim <- fn$sqldf("select * from A where condition <= `r[1]` ")
Btrim <- fn$sqldf("select * from B where condition <= `r[2]` ")

giving:

> Atrim
       force condition
1 0.03515542         1
2 0.13267882        13
3 0.26155689        24
4 0.37453142        38
5 0.39360520        45
> Btrim
  counterforce condition
1    0.9657695         2
2    0.9652663         5
3    0.8469412         7
4    0.8180130        11
5    0.8131400        22
6    0.7305999        34
7    0.7159854        39
8    0.6580739        40
9    0.4212649        42


From bhh at xs4all.nl  Sat Sep 14 22:06:03 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sat, 14 Sep 2013 22:06:03 +0200
Subject: [R] how to do this trimming/selecting in canonical R?
In-Reply-To: <20130914113543.14365omqcwrp9mo0@www.vfemail.net>
References: <20130914113543.14365omqcwrp9mo0@www.vfemail.net>
Message-ID: <97E5E243-4EC3-434E-9F20-06456D170AC3@xs4all.nl>


On 14-09-2013, at 18:35, gildororonar at mail-on.us wrote:

> This is better explained by example:
> 
>> A <- data.frame(force = sort(runif(10, 0, 1)), condition = sort(sample(0:100, 10)))
>> B <- data.frame(counterforce = sort(runif(15, 0, 1), decreasing=T), condition = sort(sample(0:100, 15)))
> 
> So we have:
> 
>> A
>        force condition
> 1  0.03515542         1
> 2  0.13267882        13
> 3  0.26155689        24
> 4  0.37453142        38
> 5  0.39360520        45 <--- trim everything after this
> 6  0.43924737        48
> 7  0.47669800        50
> 8  0.57044795        51
> 9  0.81177499        61
> 10 0.98860450        94
> 
>> B
>   counterforce condition
> 1   0.965769548         2
> 2   0.965266255         5
> 3   0.846941244         7
> 4   0.818013029        11
> 5   0.813139978        22
> 6   0.730599939        34
> 7   0.715985436        39
> 8   0.658073895        40
> 9   0.421264948        42 <--- trim everything after this
> 10  0.373774505        52
> 11  0.242191461        62
> 12  0.090584590        63
> 13  0.070020635        68
> 14  0.067366062        83
> 15  0.001585313        84
> 
> I need to trim away rows after No. 5, from A, trim away rows after No. 9, from B.
> 
> Because
> 
> A[5, condition] > max(B[1:9, condition] && A[5, force] > B[9+1, counterforce]
> 
> In a general way, I am looking for x and y, where:
> 
> A[x, condition] > max(B[1:y, condition] && A[x, force] > B[y+1, counterforce]
> 
> and I will select A[1:x,] and B[1:y,], or trim away the rest, because they are irrelevent for the calculation onwards.
> 
> This is easy to do it in C, and I actually have done it in C-like R script, by looping through all rows of A, and breaking from the loop when finding the matching trim-point in B. But I am learning R, so what is the native way to do it in R?

Your trim-point in B is not unique (at least for the data you provided).
Use a loop in R like this

for( x in seq_len(nrow(A)) ) {
    for( y in seq_len(nrow(B)-1) ) {
        res1 <- A[x,"condition"] > max(B[1:y,"condition"])
        res2 <- A[x,"force"] > B[y+1,"counterforce"]
        res <- res1 && res2 
        if(res) cat("x=",x,"y=",y,"res=",res,"\n")
    }
}

Result is:

# x= 5 y= 9 res= TRUE 
# x= 6 y= 8 res= TRUE 
# x= 6 y= 9 res= TRUE 
# x= 7 y= 8 res= TRUE 
# x= 7 y= 9 res= TRUE 
# x= 8 y= 8 res= TRUE 
# x= 8 y= 9 res= TRUE 
# x= 9 y= 5 res= TRUE 
# x= 9 y= 6 res= TRUE 
# x= 9 y= 7 res= TRUE 
# x= 9 y= 8 res= TRUE 
# x= 9 y= 9 res= TRUE 
# x= 9 y= 10 res= TRUE 
# x= 10 y= 1 res= TRUE 
# x= 10 y= 2 res= TRUE 
# x= 10 y= 3 res= TRUE 
# x= 10 y= 4 res= TRUE 
# x= 10 y= 5 res= TRUE 
# x= 10 y= 6 res= TRUE 
# x= 10 y= 7 res= TRUE 
# x= 10 y= 8 res= TRUE 
# x= 10 y= 9 res= TRUE 
# x= 10 y= 10 res= TRUE 
# x= 10 y= 11 res= TRUE 
# x= 10 y= 12 res= TRUE 
# x= 10 y= 13 res= TRUE 
# x= 10 y= 14 res= TRUE 

If you want a unique answer you'll need additional restrictions.

Berend


From chschulz at email.de  Sat Sep 14 22:22:31 2013
From: chschulz at email.de (Christian Schulz)
Date: Sat, 14 Sep 2013 22:22:31 +0200
Subject: [R] Markov Decision Process
In-Reply-To: <op.w3ed0lskzqkd1e@nirvana>
References: <op.w3ed0lskzqkd1e@nirvana>
Message-ID: <5234C587.5080100@email.de>

Maybe  msm (Multi-state modelling)  is a starting point. You'll find the 
manual in the package/doc folder after installation.

HTH
Christian


> Dear All,
> I am struggling with the conceptual aspects of a problem.
> I am sure that someone on this list must be familiar with this.
> Let's say that you have some cancer data for your patients.
> In particular, every patient may undergo up to [i.e. the cycles may 
> stop earlier for various reasons] 6 cycles of therapy (hormonal or 
> chemotherapy) whose durations and starting times are known. There are 
> plenty of other data available, but let us keep it simple for now.
> At the end of the therapy cycles, you know if the patient is dead or 
> alive (in reality, the final states are more as the patient may be 
> dead with/without cancer or alive with/without cancer, but again, 
> let's keep it simple for now).
> Of course, you want to develop a policy which maximizes the 
> probability of the patient to be alive at the end of the cycles of 
> therapies.
> Does anybody know how to tackle this in a Markov decision approach?
> There are so many R packages dealing with Markov chains that it is 
> almost confusing for a beginner.
> Any suggestion is welcome.
> Many thanks
>
> Lorenzo
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From lmramba at ufl.edu  Sat Sep 14 22:44:10 2013
From: lmramba at ufl.edu (Laz)
Date: Sat, 14 Sep 2013 16:44:10 -0400
Subject: [R] Error in Loop
Message-ID: <5234CA9A.7060401@ufl.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130914/c7a1b5f1/attachment.pl>

From smartpink111 at yahoo.com  Sat Sep 14 22:57:20 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 14 Sep 2013 13:57:20 -0700 (PDT)
Subject: [R] Error in Loop
In-Reply-To: <5234CA9A.7060401@ufl.edu>
References: <5234CA9A.7060401@ufl.edu>
Message-ID: <1379192240.22620.YahooMailNeo@web142606.mail.bf1.yahoo.com>

HI,
By running your code: on the example dataset:


mat<- structure(c(0.8959863, 0.8951168, 0.8971445, 0.8962497, 0.8963061, 
0.8973174, 0.8986438, 0.8964609, 0.8975849, 0.8965599, 1, 2, 
3, 4, 5, 6, 7, 8, 9, 10), .Dim = c(10L, 2L), .Dimnames = list(
??? NULL, c("trace", "iterations")))


while(nrow(mat) > 1){
???? high <- diff(mat[, 'trace']) > 0
???? if (!any(high)) break? # done
???? # find which one to delete
???? delete <- which.max(high) + 1L
???? mat <- mat[-delete,, drop=FALSE]
?? }

Couldn't reproduce the error.? 

?mat
#???????? trace iterations
#[1,] 0.8959863????????? 1
#[2,] 0.8951168????????? 2



----- Original Message -----
From: Laz <lmramba at ufl.edu>
To: r-help at r-project.org
Cc: 
Sent: Saturday, September 14, 2013 4:44 PM
Subject: [R] Error in Loop

Hi,
I have a matrix given by:

>mat
? ? ?  trace? ?  iterations
? [1,] 0.8959863 1
? [2,] 0.8951168 2
? [3,] 0.8971445 3
? [4,] 0.8962497 4
? [5,] 0.8963061 5
? [6,] 0.8973174 6
? [7,] 0.8986438 7
? [8,] 0.8964609 8
? [9,] 0.8975849 9
[10,] 0.8965599 10


I want to use the code below:
It?  keeps the first observation but compares all the rest with the 
earlier one and drops the one that is larger and it continues until all 
the rows are done.

while(nrow(mat) > 1){
? ?  high <- diff(mat[, 'trace']) > 0
? ?  if (!any(high)) break? # done
? ?  # find which one to delete
? ?  delete <- which.max(high) + 1L
? ?  mat <- mat[-delete,, drop=FALSE]
?  }
? The error I get is
" Error in r[i1] - r[-length(r):-(length(r) - lag + 1L)] : non-numeric 
argument to binary operator"

How do I fix it?

Laz

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From dwarnold45 at suddenlink.net  Sat Sep 14 23:49:26 2013
From: dwarnold45 at suddenlink.net (David Arnold)
Date: Sat, 14 Sep 2013 14:49:26 -0700 (PDT)
Subject: [R] Masking
Message-ID: <1379195366356-4676137.post@n4.nabble.com>

Hi,

I'm a bit confused by masking. Thought I understood, but today makes me
wonder.

x=0:9
y=0:9
sm=data.frame(x=4:8,y=9:13)
attach(sm)
x
detach(sm)

The code produces this message:

> attach(sm)
The following object is masked _by_ .GlobalEnv:

    x, y

> x
 [1] 0 1 2 3 4 5 6 7 8 9

I guess I thought that when you attach a dataframe, then the values in the
dataframe now override any existing variables in your workspace with the
same name. But this example seems to say that if I have something in my data
frame with the same name as an existing variable in my workspace, if I
attach the data frame, then it won't be the variable in the data frame that
is in play, but the existing variable in my workspace.

Have I learned my lesson?

And what are those commands that help you see what will be searched first,
second, third ... for a variable in your code?

D.



--
View this message in context: http://r.789695.n4.nabble.com/Masking-tp4676137.html
Sent from the R help mailing list archive at Nabble.com.


From istazahn at gmail.com  Sun Sep 15 00:40:21 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Sat, 14 Sep 2013 18:40:21 -0400
Subject: [R] Masking
In-Reply-To: <1379195366356-4676137.post@n4.nabble.com>
References: <1379195366356-4676137.post@n4.nabble.com>
Message-ID: <CA+vqiLGXv-DaQvR_vyPKsSOC8=5cg32g9V5dtPa5k9wtCk0XSg@mail.gmail.com>

Hi David,

On Sat, Sep 14, 2013 at 5:49 PM, David Arnold <dwarnold45 at suddenlink.net> wrote:
> Hi,
>
> I'm a bit confused by masking. Thought I understood, but today makes me
> wonder.
>
> x=0:9
> y=0:9
> sm=data.frame(x=4:8,y=9:13)
> attach(sm)
> x
> detach(sm)
>
> The code produces this message:
>
>> attach(sm)
> The following object is masked _by_ .GlobalEnv:
>
>     x, y
>
>> x
>  [1] 0 1 2 3 4 5 6 7 8 9
>
> I guess I thought that when you attach a dataframe, then the values in the
> dataframe now override any existing variables in your workspace with the
> same name. But this example seems to say that if I have something in my data
> frame with the same name as an existing variable in my workspace, if I
> attach the data frame, then it won't be the variable in the data frame that
> is in play, but the existing variable in my workspace.

Apparently. I never use attach, so never paid much attention.

>
> Have I learned my lesson?

Maybe, but see below.

>
> And what are those commands that help you see what will be searched first,
> second, third ... for a variable in your code?

The lesson you still need to learn is to read the documentation when
you are confused or uncertain about something. The answers to all your
questions are in ?attach which clearly tells you that the second
argument is

"     pos: integer specifying position in ?search()? where to attach."

(i.e., seach() is the function that tells you what will be searched
and in what order) and that

"By default the database is attached in position 2 in the search
     path, immediately after the user's workspace and before all
     previously attached packages and previously attached databases.
     This can be altered to attach later in the search path with the
     ?pos? option, but you cannot attach at ?pos = 1?"

Best,
Ista

>
> D.
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Masking-tp4676137.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun Sep 15 01:53:14 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 14 Sep 2013 16:53:14 -0700
Subject: [R] predict() from conditional logit model?
In-Reply-To: <DUB115-W17B5F3274D33F3AAFF7A76E23B0@phx.gbl>
References: <DUB115-W96379AA4CFFC0D97751B0BE23A0@phx.gbl>,
	<FBB4FBB5-677A-4230-A8AE-6BB859A2EE87@comcast.net>
	<DUB115-W17B5F3274D33F3AAFF7A76E23B0@phx.gbl>
Message-ID: <87E00016-AAE4-468A-9D84-2E54FFA9B14D@comcast.net>


On Sep 12, 2013, at 8:38 PM, Marine Regis wrote:

> Hello everybody,
> 
> Thank you David for your answer. Sorry I am beginner with cox model and R software. Is it possible to do predictions from newdata which has a size equal to the vector hour <- seq(0,23.99,0.1) ? In fact, I don't know how to define parameters "cluster" and "strata" in the newdata knowing that I would like to have one prediction value for each vector value "hour <- seq(0,23.99,0.1)" and to have a prediction curve for each category "anthro", "cor", "for" (these covariates are dichotomic) ?

I'm sorry. Did you think that we would understand this question without a data example and reference to specific features of results developed with code applied to that example?

-- 
David.
> 
> Thank you very much for your help. 
> Have a good day
> Marine 
> 
>> CC: r-help at r-project.org
>> From: dwinsemius at comcast.net
>> To: marine.regis at hotmail.fr
>> Subject: Re: [R] predict() from conditional logit model?
>> Date: Thu, 12 Sep 2013 17:52:33 -0500
>> 
>> 
>> On Sep 12, 2013, at 3:31 PM, Marine Regis wrote:
>>> 
>>> Hello everybody,
>>> 
>>> I used the function clogit() (package survival) to build a  
>>> conditional logit
>>> model. This is the R output of my model :
>>> coef exp(coef) se(coef) robust se z
>>> Pr(>|z|)
>>> anthro 2.14776 8.56565 0.09352 0.53989 3.978 6.94e-05 ***
>>> cor 0.92365 2.51846 0.07757 0.41944 2.202 0.027659 *
>>> for 1.55191 4.72047 0.07513 0.41488 3.741 0.000184
>>> ***
>>> ---
>>> Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>> 
>>> The covariates anthro, cor and for are dichotomic covariates (0/1).
>>> Then, I used the function predict() to calculate predicted values as  
>>> follows
>>> :
>>> 
>>> modpred <- predict(ML,type="lp")
>> 
>> You do understand that is on a log-relative-probability scale, right?  
>> And that it is relative to the mean values for the entire dataset?
>> 
>>> 
>>> and I obtained the following values for the first line of my  
>>> original data :
>>> 
>>> anthro cor for predited
>>> 1 0 1 0 0.0839679
>>> 
>>> With modpred <- predict(ML,type="expected"), I obtained :
>>> anthro cor for predited
>>> 1 0 1 0 0.09618096
>> 
>>> 
>>> My question is : from coefficients of clogit model, how can I find the
>>> predicted values 0.0839679 and 0.09618096 ?
>> 
>> You need to understand that those are really very different  
>> "predictions".
>> 
>>> In addition, how can I obtain predicted values ranged from 0 to 1 ?
>>> 
>>> Thank you very much for your help.
>> 
>> (Reading the help pages.) There does not appear to be a  
>> `predict.clogit` function but clogit objects inherit from coxph  
>> objects so reading the Details section from `predict.coxph`:
>> 
>> "The Cox model is a relative risk model; predictions of type "linear  
>> predictor", "risk", and "terms" are all relative to the sample from  
>> which they came. By default, the reference value for each of these is  
>> the mean covariate within strata. The primary underlying reason is  
>> statistical: a Cox model only predicts relative risks between pairs of  
>> subjects within the same strata, and hence the addition of a constant  
>> to any covariate, either overall or only within a particular stratum,  
>> has no effect on the fitted results. Using the reference="strata"  
>> option causes this to be true for predictions as well."
>> 
>> The predict.coxph function is fairly long:
>> 
>> getAnywhere(predict.coxph)
>> 
>> -- 
>> David Winsemius, MD
>> Alameda, CA, USA
>> 
> 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sun Sep 15 02:01:48 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 14 Sep 2013 17:01:48 -0700
Subject: [R] the problem of buying and selling
In-Reply-To: <2afa523451b8c59-0000d.Richmail.00020880316198468359@139.com>
References: <alpine.DEB.2.00.1309141014010.3530@lyonesse>
	<2afa523451b8c59-0000d.Richmail.00020880316198468359@139.com>
Message-ID: <01AAF705-BC4A-4645-8EC7-CAEEADFD31BA@comcast.net>


On Sep 14, 2013, at 5:47 AM, ?? wrote:

> 
> Your problem is very easy to solve, it fits well a first-lesson programming introduction course.

Exactly.  And... It is for this reason that such quesions which are obviously homework are deprecated on this mailing list.m

Snipped ramineder of posting which had no context and was posted in HTML, also both deprecated practices.

> 
> 	[[alternative HTML version deleted]]

Please read the Posting Guide.

-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sun Sep 15 02:17:52 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 14 Sep 2013 17:17:52 -0700
Subject: [R] Splitting data into two camps
In-Reply-To: <CAAomMNynA9UdQGJN7Va2XDLPtW1FZYav4KOc+OSUtwoTWOnorw@mail.gmail.com>
References: <CAAomMNynA9UdQGJN7Va2XDLPtW1FZYav4KOc+OSUtwoTWOnorw@mail.gmail.com>
Message-ID: <0E64603C-E3AE-4E16-800B-C94B5703BA97@comcast.net>


On Sep 13, 2013, at 9:47 AM, Evan Sticca wrote:

> Hello R-help,
> 
> I have recently generated some meta-data on SNP variation across whole
> exomes and I need to begin sorting it into two camps: one in which the
> alternate allele matches the derived form and one where the alternate
> allele matches the ancestral form. I have the data saved as a .txt file
> from its original VCF format. I am a novice at writing my own functions in
> R, so any help would greatly be appreciated.
> 
> Thank you,
> Evan Sticca
> 
> 	[[alternative HTML version deleted]]

Please post a minimal reproducible example and post it in plain text. (I suspect most of us have no idea what "VCF format" might  mean.)

-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sun Sep 15 02:20:05 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 14 Sep 2013 17:20:05 -0700
Subject: [R] Looking for data sets with unordered failure events of
	different types
In-Reply-To: <48C81F98C3BE8D4090474B110F2EC94666E3EC42@YUWEXCPM24.yuad.uds.yu.edu>
References: <48C81F98C3BE8D4090474B110F2EC94666E3EC42@YUWEXCPM24.yuad.uds.yu.edu>
Message-ID: <CD4B3E5D-7C46-41A7-B1A2-F289837AEE1D@comcast.net>


On Sep 13, 2013, at 11:59 AM, Ryung Kim wrote:

> Dear R community,
> 
> Please let me know if there is an R data set with time to multiple outcomes (unordered failure events of different types).
> 
> I am specifically looking for non-competing risks so that I can have observed times for both outcomes. Twin data or recurrent data will not work for me because I need two types of events for each subject.
> 
> For example, a time-to-multiple injuries or time-to-multiple non-fatal disease outcomes would be useful.  (Censoring is fine.)
> 

What difficulties are you having in simulating this data? It would seem to be a simple matter to take the examples of single outcome data and modify to create multiple outcome data.

-- 

David Winsemius
Alameda, CA, USA


From saumya.gupta at outlook.com  Sat Sep 14 22:12:24 2013
From: saumya.gupta at outlook.com (Saumya Gupta)
Date: Sun, 15 Sep 2013 01:42:24 +0530
Subject: [R] Regression model for predicting ranks of the dependent variable
Message-ID: <BAY168-W133889764D7F2EA374101A497240@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130915/a9e67608/attachment.pl>

From a783929 at drdrb.com  Sun Sep 15 00:32:54 2013
From: a783929 at drdrb.com (ajuto1989)
Date: Sat, 14 Sep 2013 15:32:54 -0700 (PDT)
Subject: [R] need help for var analysis using R
Message-ID: <1379197974101-4676138.post@n4.nabble.com>

 study the risk based ranking of the daily financial assets (Companies stock)
which changes with the selection of different measures of risk such as
standard deviation, semi deviation, Beta & Value at risk.




--
View this message in context: http://r.789695.n4.nabble.com/need-help-for-var-analysis-using-R-tp4676138.html
Sent from the R help mailing list archive at Nabble.com.


From canamika at gmail.com  Sun Sep 15 03:04:42 2013
From: canamika at gmail.com (Anamika Chaudhuri)
Date: Sat, 14 Sep 2013 21:04:42 -0400
Subject: [R] DataEllipse versus Ellipse Function in R
Message-ID: <CALv--daCWy_mmGQkpeWFaDpzbukyXHnD4_aTo4xxje-+HPY+Sg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130914/0bbcc4ed/attachment.pl>

From bhh at xs4all.nl  Sun Sep 15 07:49:38 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 15 Sep 2013 07:49:38 +0200
Subject: [R] how to do this trimming/selecting in canonical R?
In-Reply-To: <20130914204645.2135179c3rrhi0sg@www.vfemail.net>
References: <20130914113543.14365omqcwrp9mo0@www.vfemail.net>
	<97E5E243-4EC3-434E-9F20-06456D170AC3@xs4all.nl>
	<20130914204645.2135179c3rrhi0sg@www.vfemail.net>
Message-ID: <1BCB89E9-BCC5-41F5-896C-DFEAD7D09DCB@xs4all.nl>


On 15-09-2013, at 03:46, gildororonar at mail-on.us wrote:

> Quoting "Berend Hasselman" <bhh at xs4all.nl>:
> 
>> Your trim-point in B is not unique (at least for the data you provided).
> 
> Indeed. It's quit a surprise to me. I couldn't figure out why my evaluation expression results in multiple trimp-points
> 
>> In a general way, I am looking for x and y, where:
>> A[x, condition] > max(B[1:y, condition] && A[x, force] > B[y+1, counterforce]
> 
> but I'll show you the code I wrote, which is a better explanation of my indention:
> 
> for( x in seq_len(nrow(A)) ) {
>    y = sum(B[,"condition"] < A[x, "condition"])
>    if (A[x, "force"] > B[y+1, "counterforce"]) break
> }
> cat("x=",x,"y=",y,"res=",res,"\n")
> 
> Result is:
> 
> # x= 5 y= 9 res= TRUE
> 

This I really don't understand.
And it can go wrong. With the same data doing this

for( x in seq_len(nrow(A)) ) {
        y <- sum(A[x,"condition"] > B[,"condition"])
        res <- A[x,"force"] > B[y+1,"counterforce"]
        cat("x=",x,"y=",y,"res=",res,"\n")
}

will give you

# x= 1 y= 0 res= FALSE 
# x= 2 y= 4 res= FALSE 
# x= 3 y= 5 res= FALSE 
# x= 4 y= 6 res= FALSE 
# x= 5 y= 9 res= TRUE 
# x= 6 y= 9 res= TRUE 
# x= 7 y= 9 res= TRUE 
# x= 8 y= 9 res= TRUE 
# x= 9 y= 10 res= TRUE 
# x= 10 y= 15 res= NA 

When y==15 then y+1 references a non-existing row in B and when res==NA the if will throw an error message.

Berend


> --
> To use the same test data as I have:
> 
>> A <- read.table(text = "force condition
> 0.03515542         1
> 0.13267882        13
> 0.26155689        24
> 0.37453142        38
> 0.39360520        45
> 0.43924737        48
> 0.47669800        50
> 0.57044795        51
> 0.81177499        61
> 0.98860450        94", header=T)
> 
>> B <- read.table(text = "counterforce condition
> 0.965769548         2
> 0.965266255         5
> 0.846941244         7
> 0.818013029        11
> 0.813139978        22
> 0.730599939        34
> 0.715985436        39
> 0.658073895        40
> 0.421264948        42
> 0.373774505        52
> 0.242191461        62
> 0.090584590        63
> 0.070020635        68
> 0.067366062        83
> 0.001585313        84", header=T)
> 
> 
> -------------------------------------------------
> 
> VFEmail.net - http://www.vfemail.net
> $14.95 ONETIME Lifetime accounts with Privacy Features!
> 15GB disk! No bandwidth quotas!
> Commercial and Bulk Mail Options!


From gildororonar at mail-on.us  Sun Sep 15 03:46:45 2013
From: gildororonar at mail-on.us (gildororonar at mail-on.us)
Date: Sat, 14 Sep 2013 20:46:45 -0500
Subject: [R] how to do this trimming/selecting in canonical R?
In-Reply-To: <97E5E243-4EC3-434E-9F20-06456D170AC3@xs4all.nl>
References: <20130914113543.14365omqcwrp9mo0@www.vfemail.net>
	<97E5E243-4EC3-434E-9F20-06456D170AC3@xs4all.nl>
Message-ID: <20130914204645.2135179c3rrhi0sg@www.vfemail.net>

Quoting "Berend Hasselman" <bhh at xs4all.nl>:

> Your trim-point in B is not unique (at least for the data you provided).

Indeed. It's quit a surprise to me. I couldn't figure out why my  
evaluation expression results in multiple trimp-points

> In a general way, I am looking for x and y, where:
> A[x, condition] > max(B[1:y, condition] && A[x, force] > B[y+1, counterforce]

but I'll show you the code I wrote, which is a better explanation of  
my indention:

for( x in seq_len(nrow(A)) ) {
     y = sum(B[,"condition"] < A[x, "condition"])
     if (A[x, "force"] > B[y+1, "counterforce"]) break
}
cat("x=",x,"y=",y,"res=",res,"\n")

Result is:

# x= 5 y= 9 res= TRUE

--
To use the same test data as I have:

> A <- read.table(text = "force condition
0.03515542         1
0.13267882        13
0.26155689        24
0.37453142        38
0.39360520        45
0.43924737        48
0.47669800        50
0.57044795        51
0.81177499        61
0.98860450        94", header=T)

> B <- read.table(text = "counterforce condition
0.965769548         2
0.965266255         5
0.846941244         7
0.818013029        11
0.813139978        22
0.730599939        34
0.715985436        39
0.658073895        40
0.421264948        42
0.373774505        52
0.242191461        62
0.090584590        63
0.070020635        68
0.067366062        83
0.001585313        84", header=T)


-------------------------------------------------

VFEmail.net - http://www.vfemail.net
$14.95 ONETIME Lifetime accounts with Privacy Features!  
15GB disk! No bandwidth quotas!
Commercial and Bulk Mail Options!


From gildororonar at mail-on.us  Sun Sep 15 04:21:03 2013
From: gildororonar at mail-on.us (gildororonar at mail-on.us)
Date: Sat, 14 Sep 2013 21:21:03 -0500
Subject: [R] how to do this trimming/selecting in canonical R?
In-Reply-To: <CAP01uR=XxeRuo+jNrNjdjY0j=9cWsgimDwu5fdGbApzmd4p8KQ@mail.gmail.com>
References: <20130914113543.14365omqcwrp9mo0@www.vfemail.net>
	<CAP01uR=XxeRuo+jNrNjdjY0j=9cWsgimDwu5fdGbApzmd4p8KQ@mail.gmail.com>
Message-ID: <20130914212103.22622nmqt46mrpus@www.vfemail.net>


Quoting "Gabor Grothendieck" <ggrothendieck at gmail.com>:
> Try this:
>
> library(sqldf)

Thank you for introducing me to SQLDF package! I wasn't aware I could  
use SQL in R!

Right now Arun sent me (forgetting to cc the list) a solution using  
apply/sapply, which inspired me of my own version:

> x <- which(sapply(seq_len(nrow(A)), function (x)
{ A[x, "force"] > B[sum(B[,"condition"] < A[x, "condition"])+1,  
"counterforce"] }
))[1]

> y  <- sum(B[,"condition"]<A[x,"condition"])

> c(x, y)
[1] 5 9

I am guessing this is already as good as can be.

--
To use the same test data as I have:
A <- read.table(text = "force condition
0.03515542         1 0.13267882        13
0.26155689        24
0.37453142        38
0.39360520        45
0.43924737        48
0.47669800        50
0.57044795        51
0.81177499        61
0.98860450        94", header=T)
B <- read.table(text = "counterforce condition
0.965769548         2 0.965266255         5
0.846941244         7
0.818013029        11
0.813139978        22
0.730599939        34
0.715985436        39
0.658073895        40
0.421264948        42
0.373774505        52
0.242191461        62
0.090584590        63
0.070020635        68
0.067366062        83
0.001585313        84", header=T)


-------------------------------------------------

VFEmail.net - http://www.vfemail.net
$14.95 ONETIME Lifetime accounts with Privacy Features!  
15GB disk! No bandwidth quotas!
Commercial and Bulk Mail Options!


From gildororonar at mail-on.us  Sun Sep 15 04:36:23 2013
From: gildororonar at mail-on.us (gildororonar at mail-on.us)
Date: Sat, 14 Sep 2013 21:36:23 -0500
Subject: [R] accumulate() function in R?
Message-ID: <20130914213623.9844702dgc370ug4@www.vfemail.net>

I came from Python, newly learning R. is there something like  
accumulate() in R?

Example:
accumulate([1,2,3,4,5]) --> 1 3 6 10 15

Or perhaps I should show the problem. The problem I am trying to  
solve, is to select elements from X until it accumulate to 30. My  
solution is:

> X = c(1,3,4,5,8,15,35,62,78,99)
> X[sapply(seq_len(length(X)), function(x) { sum(X[1:x])}) < 30]
[1] 1 3 4 5 8

Is this already the shortest/canonical way to do it in R?


-------------------------------------------------

VFEmail.net - http://www.vfemail.net
$14.95 ONETIME Lifetime accounts with Privacy Features!  
15GB disk! No bandwidth quotas!
Commercial and Bulk Mail Options!


From bhh at xs4all.nl  Sun Sep 15 08:38:11 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 15 Sep 2013 08:38:11 +0200
Subject: [R] accumulate() function in R?
In-Reply-To: <20130914213623.9844702dgc370ug4@www.vfemail.net>
References: <20130914213623.9844702dgc370ug4@www.vfemail.net>
Message-ID: <3835E513-2569-4302-8BEC-55A16280A149@xs4all.nl>


On 15-09-2013, at 04:36, gildororonar at mail-on.us wrote:

> I came from Python, newly learning R. is there something like accumulate() in R?
> 

Yes: cumsum

Berend

> Example:
> accumulate([1,2,3,4,5]) --> 1 3 6 10 15
> 
> Or perhaps I should show the problem. The problem I am trying to solve, is to select elements from X until it accumulate to 30. My solution is:
> 
>> X = c(1,3,4,5,8,15,35,62,78,99)
>> X[sapply(seq_len(length(X)), function(x) { sum(X[1:x])}) < 30]
> [1] 1 3 4 5 8
> 
> Is this already the shortest/canonical way to do it in R?
> 
> 
> -------------------------------------------------
> 
> VFEmail.net - http://www.vfemail.net
> $14.95 ONETIME Lifetime accounts with Privacy Features! 15GB disk! No bandwidth quotas!
> Commercial and Bulk Mail Options!
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ajdamico at gmail.com  Sun Sep 15 08:39:08 2013
From: ajdamico at gmail.com (Anthony Damico)
Date: Sun, 15 Sep 2013 02:39:08 -0400
Subject: [R] accumulate() function in R?
In-Reply-To: <20130914213623.9844702dgc370ug4@www.vfemail.net>
References: <20130914213623.9844702dgc370ug4@www.vfemail.net>
Message-ID: <CAOwvMDzQ55yvtk34wrzRT4CcdjSuU+G1tQ3nB4VnAsSBnPm9Lg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130915/bf4f9f24/attachment.pl>

From mdsumner at gmail.com  Sun Sep 15 09:24:15 2013
From: mdsumner at gmail.com (Michael Sumner)
Date: Sun, 15 Sep 2013 17:24:15 +1000
Subject: [R] Imputation for space-time satellite data
In-Reply-To: <CABaJH79rAZ9dw=XSSFhVEa6_7nZ+fV8db0HPVHm-HSjuXA3dfg@mail.gmail.com>
References: <CABaJH79rAZ9dw=XSSFhVEa6_7nZ+fV8db0HPVHm-HSjuXA3dfg@mail.gmail.com>
Message-ID: <CAAcGz9_R0u8fAs+K_jXc0btm4ujdNev1-woJT1U80wXmhJ8gVw@mail.gmail.com>

See packages raster, rgdal and spacetime. Also the mailing list
R-Sig-Geo which is more relevant for this topic.


On Wed, Sep 11, 2013 at 10:02 PM, Eddie Smith <eddieatr at gmail.com> wrote:
> Dear list,
>
> I am trying to do a space-time imputation for time series satellite
> imageries. Any recommendation for a good package to use. I am new to R.
>
> Thank you.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Michael Sumner
Hobart, Australia
e-mail: mdsumner at gmail.com


From f.harrell at Vanderbilt.Edu  Sun Sep 15 10:52:44 2013
From: f.harrell at Vanderbilt.Edu (Frank Harrell)
Date: Sun, 15 Sep 2013 03:52:44 -0500
Subject: [R] Regression model for predicting ranks of the dependent
	variable
Message-ID: <5235755C.3080604@vanderbilt.edu>

require(rms)
?orm            # ordinal regression model

For a case study see Handouts in 
http://biostat.mc.vanderbilt.edu/CourseBios330

Since you have lost the original values, one part of the case study will 
not apply: the use of Mean().

Frank
-------------
I have a dataset which has several predictor variables and a dependent 
variable, "score" (which is numeric). The score for each row is 
calculated using a formula which uses some of the predictor variables. 
But, the "score" figures are not explicitly given in the dataset. The 
scores are only arranged in ascending order, and the ranks of the 
numbers are given (like 1, 2, 3, 4, etc.; rank 1 means that the 
particular row had the highest score, 2 means it had the second highest 
score and so on). So, if the data has 100 rows, the output has ranks 
from 1 to 100.
I don't think it would be proper to treat the output column as a numeric 
one, since it is an ordinal variable, and the distance (difference in 
scores) between ranks 1 and 2 may not be the same as that between ranks 
2 and 3. However, most R regression models for ordinal regression are 
made for output such as (high, medium, low), where each level of the 
output does not necessarily correspond to a unique row. In my case, each 
output (rank) corresponds to a unique row.
So please suggest me what models I could use for this problem. Will 
treating the output as numeric instead of ordinal be a reasonable 
approximation? Or will the usual models for ordinal regression work on 
this dataset as well?


From hadassa.brunschwig at mail.huji.ac.il  Sun Sep 15 11:42:57 2013
From: hadassa.brunschwig at mail.huji.ac.il (Hadassa Brunschwig)
Date: Sun, 15 Sep 2013 10:42:57 +0100
Subject: [R] Executing a code until a new user input aborts it (readlines?)
Message-ID: <CAFn+=0SsCrO0+G74R85JnXi=jEfimTpSa999JtrdUL9mD8dARA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130915/d2c09ac8/attachment.pl>

From andreas at maunz.de  Sun Sep 15 12:02:17 2013
From: andreas at maunz.de (Andreas Maunz)
Date: Sun, 15 Sep 2013 12:02:17 +0200
Subject: [R] rgl snapshot on headless server
In-Reply-To: <52309822.5060403@gmail.com>
References: <CAJHOUEMjjYO98UYrkJ_SfSByC9xNqd2ydGVgkFoazbW21ccMvQ@mail.gmail.com>
	<522F4B07.4030004@gmail.com>
	<CAJHOUEM6VM=znCy=g1RaLZ2gMSJ8Wei3-aFKN4tw-BVvEHy8fQ@mail.gmail.com>
	<52309822.5060403@gmail.com>
Message-ID: <CAJHOUEOcdCp5D3dUGsvE_7w0+Zv+nU3YNmc5M1--uowKZ-_qfA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130915/36cec9a2/attachment.pl>

From murdoch.duncan at gmail.com  Sun Sep 15 13:18:52 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 15 Sep 2013 07:18:52 -0400
Subject: [R] rgl snapshot on headless server
In-Reply-To: <CAJHOUEOcdCp5D3dUGsvE_7w0+Zv+nU3YNmc5M1--uowKZ-_qfA@mail.gmail.com>
References: <CAJHOUEMjjYO98UYrkJ_SfSByC9xNqd2ydGVgkFoazbW21ccMvQ@mail.gmail.com>
	<522F4B07.4030004@gmail.com>
	<CAJHOUEM6VM=znCy=g1RaLZ2gMSJ8Wei3-aFKN4tw-BVvEHy8fQ@mail.gmail.com>
	<52309822.5060403@gmail.com>
	<CAJHOUEOcdCp5D3dUGsvE_7w0+Zv+nU3YNmc5M1--uowKZ-_qfA@mail.gmail.com>
Message-ID: <5235979C.1070503@gmail.com>

On 13-09-15 6:02 AM, Andreas Maunz wrote:
> The other write* options seem to limited to me. I am looking for a way
> to obtain a PS, or at least a PNG, since I develop a web application on
> a server that needs to grab the screenshot and create a written report
> with it. Starting my Xvfb like this:
>
> Xvfb :5 -screen 0 640x480x24 -ac +extension GLX +render -noreset -fbdir
> /tmp/foobar
>
> I can easily run glxgears and obtain nice snapshots of the gears via
> 'xwud -in /tmp/foobar/Xvfb_screen0'. However, it just won't work for
> rgl! Given my test.R script with (taken from the doc of bg()):

That does make it sound like an rgl problem.

>
> library('rgl')
> rgl.open()
> foo<-readline('Enter to cont')
> bg3d("white")
> foo<-readline('Enter to cont')
> rgl.bg <http://rgl.bg>(sphere=TRUE, color=c("black","green"), lit=FALSE,
> back="lines" )
> foo<-readline('Enter to cont')
> rgl.bg <http://rgl.bg>(sphere=TRUE,
> texture=system.file("textures/sunsleep.png", package="rgl"), back="filled" )
> foo<-readline('Enter to cont')
>
> I can skip through the steps and check at each with xwud, but it just
> manages to draw the white background. The two last steps fail
> completely, I only receive a black screen. Sane for plot3d(), for example.
>
> Please help, if you can, it would be quite important to have this
> functionality

I can't reproduce any of this, since I'm working on Windows, a system 
without Xvfb, and Mac OSX, where your Xvfb command fails with this error

_XSERVTransmkdir: ERROR: euid != 0,directory /tmp/.X11-unix will not be 
created.

(followed by a sequence of other errors).  So I'd like to fix this, but 
it just doesn't look feasible.  Perhaps you know some X11 expert who can 
tell you what rgl is doing wrong?

Duncan Murdoch

>
> Thanks
> Andreas
>
>
>
> On Wed, Sep 11, 2013 at 6:19 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>
>     On 11/09/2013 11:44 AM, Andreas Maunz wrote:
>
>         I am running Xvfb now with
>
>         -fbdir /some/path and
>         -extension RANDR
>
>         but rgl.snapshot is still not working.
>
>         Any other idea? Since I can display the webGL successfully in
>         firefox (so comes out correct), I assume there should be some
>         way of converting it on the server side to some (vector) graphic
>         file format?
>
>
>     The .html file that writeWebGL produces could be considered to be
>     that, but it's really mostly Javascript code, and I don't know
>     anything other than a browser that can display it.  If you look at
>     ?writeWebGL, you'll see links to various other ?write* files; they
>     are all vector formats, but are all more limited than writeWebGL in
>     what they can record.
>
>     Duncan Murdoch
>
>
>         Thanks
>         Andreas
>
>
>
>
>         On Tue, Sep 10, 2013 at 6:38 PM, Duncan Murdoch
>         <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>
>         <mailto:murdoch.duncan at gmail.__com
>         <mailto:murdoch.duncan at gmail.com>>> wrote:
>
>              On 10/09/2013 10:58 AM, Andreas Maunz wrote:
>
>                  Hi all,
>
>                  I have a shiny app, in which I want to use rgl's snapshot
>                  function. I am
>                  running Xvfb on my server so that rgl works. I start my
>         shiny
>                  app as
>                  follows:
>
>                  echo "Checking for Xvfb..."
>                  pgrep -U username Xvfb > /dev/null 2>&1
>
>                  if [ "$?" -gt 0 ]; then
>                     echo "Starting Xvfb..."
>                     Xvfb :7 -screen 0 1280x1024x24 &
>                     sleep 2
>                  fi
>
>                  echo "...starting shiny"
>                  export DISPLAY=":7"; R --no-save --no-restore -e
>                  "library('shiny');
>                  runApp('/path/to/app', port=8101)"
>
>                  In the app, I do plot3d(), generate webGL and send the
>         results
>                  to the
>                  browser. But the rgl.snapshot or rgl.postscript
>         functionality
>                  do not work,
>                  i.e. they produce black or empty images. I assume this
>         is due
>                  to Xvfb. Any
>                  chance I can create snapshots?
>
>
>              rgl.snapshot requires the X server to maintain a frame
>         buffer that
>              it can read.   It looks as though something is going wrong with
>              yours.  I don't use a system with Xvfb, so I can't really help,
>              but you could try Googling to see if that turns anything up.
>
>              rgl.postscript shouldn't need the X server, but it is
>         limited in
>              what it can display.
>
>              Duncan Murdoch
>
>
>
>


From ron_michael70 at yahoo.com  Sun Sep 15 14:21:39 2013
From: ron_michael70 at yahoo.com (Ron Michael)
Date: Sun, 15 Sep 2013 20:21:39 +0800 (SGT)
Subject: [R] Downloading data directly from internet
Message-ID: <1379247699.2324.YahooMailNeo@web190503.mail.sg3.yahoo.com>

Hi,
?
I need to download data from this site:
http://www.cmegroup.com/trading/agricultural/grain-and-oilseed/corn_quotes_globex.html
?
?
I tried with following set of codes:
?
?
library(RCurl) 
library(XML) 
?
aa <- getURL("http://www.cmegroup.com/trading/agricultural/grain-and-oilseed/corn_quotes_globex.html")
readHTMLTable(aa)
?
However not getting the required data.
?
Can someone please help me to point out how I can get that data?
?
Your help will be highly appreciated.
?
Thank you very much.


From rahmannorthampton at gmail.com  Sun Sep 15 11:15:09 2013
From: rahmannorthampton at gmail.com (Lutfor Rahman)
Date: Sun, 15 Sep 2013 10:15:09 +0100
Subject: [R] GLM result output..
In-Reply-To: <8974D68E-04B6-4EE8-93A0-47FA0690F6A4@comcast.net>
References: <CAP43mJ97ZFJFaZRLeaK6zVB01v8RMXQ8SHFBdrB55vBDDXRwEg@mail.gmail.com>
	<8974D68E-04B6-4EE8-93A0-47FA0690F6A4@comcast.net>
Message-ID: <CAP43mJ-Ui5AvjgJsEN9c77UTW=xnmca37rPnc4+V4EUOBZqwwA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130915/f92d7547/attachment.pl>

From yueyumeng at hotmail.com  Sun Sep 15 14:30:38 2013
From: yueyumeng at hotmail.com (Yumeng Yue)
Date: Sun, 15 Sep 2013 20:30:38 +0800
Subject: [R] Failed path analysis using sem package
Message-ID: <BLU170-W102BB420EBA053309C58FF0AB250@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130915/cfc271e8/attachment.pl>

From jfox at mcmaster.ca  Sun Sep 15 15:16:31 2013
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 15 Sep 2013 09:16:31 -0400
Subject: [R] DataEllipse versus Ellipse Function in R
In-Reply-To: <CALv--daCWy_mmGQkpeWFaDpzbukyXHnD4_aTo4xxje-+HPY+Sg@mail.gmail.com>
References: <CALv--daCWy_mmGQkpeWFaDpzbukyXHnD4_aTo4xxje-+HPY+Sg@mail.gmail.com>
Message-ID: <web-474050617@cgpsrv2.cis.mcmaster.ca>

Dear Anamika Chaudhuri,

On Sat, 14 Sep 2013 21:04:42 -0400
 Anamika Chaudhuri <canamika at gmail.com> wrote:
> Hi:
> 
> Does Ellipse and dataellipse function in R produce the same ellipse? I
> wanted to see how the radius for the Ellipse function in R calculated. Also
> what is the var-covariance matrix, if any, assumed for the dataellipse
> function? Heres an example of the code where I am generating Multivariate
> normal data and creating ellipse using the 2 functions:
> 
> 
> library(car)
>   library(mvtnorm)
> 
>   mu = c(0,0)
>   sigma = matrix(c(20,0,0,45),nrow=2)
> 
>   z = rmvnorm(10000,mu,sqrt(sigma))
> 
>   dataEllipse(z,levels=.95)
>   car::ellipse(mu, sigma*qchisq(.05,2), col="blue", radius=sqrt(2 *
> qf(.975, 2, 9998)) )
> 
> Any help is appreciated.
> Thanks
> Anamika

As explained in ?ellipse, the ellipse() function draws an ellipse, dataEllipse() draws data ellipses (i.e., estimated concentration ellipses assuming bivariate normality), and confidenceEllipse() draws confidence ellipses. 

The latter two functions call ellipse(), so yes, you can use either ellipse() or dataEllipse() to draw a data ellipse, but you made five mistakes:

(1) In generating the data, you probably intended to use sigma rather than sqrt(sigma) for the covariance matrix. If for some unusual reason you really wanted to take the square roots of each of the elements of sigma, then the "size" matrix supplied to ellipse() should also have used sqrt(sigma) for consistency.

(2)  The "size" doesn't involve a chisq quantile.

(3)  The quantile for the F distribution should be .95, not .975.

(4)  The denominator df are n - 1 not n - 2.

(5)  You used the population means and tried to use the population covariance matrix rather than the sample means and covariance matrix.

Thus, to get the 95% concentration ellipse for your unusually generated data, you could use

ellipse(colMeans(z), cov(z), col="blue", radius=sqrt(2 * qf(.95, 2, 9999)) )

Best,
 John


>
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

------------------------------------------------
John Fox
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/


From jfox at mcmaster.ca  Sun Sep 15 16:33:50 2013
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 15 Sep 2013 10:33:50 -0400
Subject: [R] Failed path analysis using sem package
In-Reply-To: <BLU170-W102BB420EBA053309C58FF0AB250@phx.gbl>
References: <BLU170-W102BB420EBA053309C58FF0AB250@phx.gbl>
Message-ID: <000401ceb220$98cafae0$ca60f0a0$@mcmaster.ca>

Dear Brad,

It's impossible to know from the information given whether the model is
identified or not. Including a reproducible example of your problem, as the
r-help posting guide asks, is a good idea.

Assuming that OCB is an observed variable, however, the model is identified,
but implausible. That is, you've specified that the three latent exogenous
variables, STA, SA, DA, are uncorrelated. That likely would produce
difficulties in maximizing the likelihood, which could explain the error you
encountered. Again, without a reproducible example, one can only guess.

Some other points:

(1) It's generally easier to use specifyEquations() in preference to
specifyModel() to define the model. See ?specifyEquations.

(2) Even if you use specifyModel(), you need not supply error-variance
parameters for endogenous variables; these will be added to the model by
default. If you look closely, you'll see that this was done for OCB, for
which you omitted the error-variance parameter. See ?specifyModel.

(3) You're better off letting sem() compute the observed-variable covariance
matrix rather than supplying it as an argument. Among other things, that
will allow you to compute robust coefficient standard errors and tests on
the fitted model. See ?sem and
<http://socserv.mcmaster.ca/jfox/Books/Companion/appendix/Appendix-SEMs.pdf>
.

I hope this helps,
 John

-----------------------------------------------
John Fox
McMaster University
Hamilton, Ontario, Canada
http://socserv.socsci.mcmaster.ca/jfox/


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Yumeng Yue
> Sent: Sunday, September 15, 2013 8:31 AM
> To: r-help at r-project.org
> Subject: [R] Failed path analysis using sem package
> 
> Dear R users:
> 
> I am trying to run a path analysis using sem package in R. But I have
> encountered one problem, below is my code:
> 
> SEMEX<-read.csv("D:/Documents and Settings/z3409964/Desktop/Hospital
> 1.csv")
> library(sem)
> cov.matrixSEMEX<-cov(na.omit(SEMEX))
> 
> SEMEX<-specifyModel()
> CWB->CWB13,NA,1
> CWB->CWB23,deviance1
> CWB->CWB33,deviance2
> CWB->CWB43,deviance3
> STA->STA13,NA,1
> STA->STA23,citizenship1
> STA->STA33,citizenship2
> STA->STA43,citizenship3
> STA->STA53,citizenship4
> SA->SA13,NA,1
> SA->SA23,surface1
> SA->SA33,surface2
> DA->DA13,NA,1
> DA->DA23,deep1
> DA->DA33,deep2
> NA->NA13,NA,1
> NA->NA23,negative1
> NA->NA33,negative2
> PA->PA13,NA,1
> PA->PA23,positive1
> PA->PA33,positive2
> CWB13<->CWB13,error1
> CWB23<->CWB23,error2
> CWB33<->CWB33,error3
> CWB43<->CWB43,error4
> STA13<->STA13,error5
> STA23<->STA23,error6
> STA33<->STA33,error7
> STA43<->STA43,error8
> STA53<->STA53,error9
> SA13<->SA13,error10
> SA23<->SA23,error11
> SA33<->SA33,error12
> DA13<->DA13,error13
> DA23<->DA23,error14
> DA33<->DA33,error15
> NA13<->NA13,error16
> NA23<->NA23,error17
> NA33<->NA33,error18
> PA13<->PA13,error19
> PA23<->PA23,error20
> PA33<->PA33,error21
> CWB<->CWB,var1
> STA<->STA,var2
> SA<->SA,var3
> DA<->DA,var4
> PA<->PA,var5
> NA<->NA,var6
> SA->NA,beta1
> NA->CWB,beta2
> DA->PA,beta3
> PA->OCB,beta4
> SA->PA,beta5
> DA->NA,beta6
> OCB<->CWB,cov2
> 
> SEMEX<-sem(SEMEX,cov.matrixSEMEX, nrow(SEMEX))
> summary(SEMEX,fit.indices=c("CFI","GFI","AGFI","RMSEA"))
> 
> Yet the output shows the following:
> 
> Error in summary.objectiveML(SEMEX, fit.indices = c("CFI", "GFI",
> "AGFI",  :
>   coefficient covariances cannot be computed
> In addition: Warning message:
> In vcov.sem(object, robust = robust, analytic = analytic.se) :
>    singular Hessian: model is probably underidentified.
> 
> Can you help figure out what is going on? Thank you very much
> 
> Brad
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Sun Sep 15 17:25:05 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 15 Sep 2013 08:25:05 -0700 (PDT)
Subject: [R] accumulate() function in R?
In-Reply-To: <20130914213623.9844702dgc370ug4@www.vfemail.net>
References: <20130914213623.9844702dgc370ug4@www.vfemail.net>
Message-ID: <1379258705.70364.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,


If you have a vector of values to compare:
thresh1<- c(30,4,12,65,5)
indx<-findInterval(thresh1-1,cumsum(X))
indx2<-ave(rep(indx,indx),rep(indx,indx),FUN=seq)
?X[indx2]
# [1]? 1? 3? 4? 5? 8? 1? 1? 3? 4? 1? 3? 4? 5? 8 15? 1? 3
#you can split this into a list

split(X[indx2],cumsum(c(TRUE,diff(indx2)<=0)))
#$`1`
#[1] 1 3 4 5 8
#
#$`2`
#[1] 1
#
#$`3`
#[1] 1 3 4
#
#$`4`
#[1]? 1? 3? 4? 5? 8 15
#
#$`5`
#[1] 1 3

A.K.



----- Original Message -----
From: "gildororonar at mail-on.us" <gildororonar at mail-on.us>
To: r-help at r-project.org
Cc: 
Sent: Saturday, September 14, 2013 10:36 PM
Subject: [R] accumulate() function in R?

I came from Python, newly learning R. is there something like? 
accumulate() in R?

Example:
accumulate([1,2,3,4,5]) --> 1 3 6 10 15

Or perhaps I should show the problem. The problem I am trying to? 
solve, is to select elements from X until it accumulate to 30. My? 
solution is:

> X = c(1,3,4,5,8,15,35,62,78,99)
> X[sapply(seq_len(length(X)), function(x) { sum(X[1:x])}) < 30]
[1] 1 3 4 5 8

Is this already the shortest/canonical way to do it in R?


-------------------------------------------------

VFEmail.net - http://www.vfemail.net
$14.95 ONETIME Lifetime accounts with Privacy Features!? 
15GB disk! No bandwidth quotas!
Commercial and Bulk Mail Options!

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From dwinsemius at comcast.net  Sun Sep 15 17:30:26 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 15 Sep 2013 08:30:26 -0700
Subject: [R] GLM result output..
In-Reply-To: <CAP43mJ-Ui5AvjgJsEN9c77UTW=xnmca37rPnc4+V4EUOBZqwwA@mail.gmail.com>
References: <CAP43mJ97ZFJFaZRLeaK6zVB01v8RMXQ8SHFBdrB55vBDDXRwEg@mail.gmail.com>
	<8974D68E-04B6-4EE8-93A0-47FA0690F6A4@comcast.net>
	<CAP43mJ-Ui5AvjgJsEN9c77UTW=xnmca37rPnc4+V4EUOBZqwwA@mail.gmail.com>
Message-ID: <0BC04C3D-F343-457C-83B3-DE37EEC379BA@comcast.net>


On Sep 15, 2013, at 2:15 AM, Lutfor Rahman wrote:

> Thanks for that. Still I am a bit confused. Please advice me. 
> Now, I have got minimal adequate model keeping all the those significant predictors in the model which is shown below:
> Coefficients:
>                                Estimate Std. Error z value Pr(>|z|)    
> (Intercept)                  5.846747   0.987461   5.921  3.2e-09 ***
> orgmatter                 -0.886985   0.235347  -3.769 0.000164 ***
> baresoil                    -0.935106   0.293838  -3.182 0.001461 ** 
> orgmatter:moistcont   0.009452   0.002759   3.426 0.000612 ***
> baresoil:moistcont     0.025640   0.009698   2.644 0.008194 ** 
> wood10:grass10        0.007433   0.003187   2.333 0.019667 *  
> grass10:rdnet10        0.004822   0.001563   3.085 0.002036 ** 
> wood10:rdnet10        -0.045485   0.016890  -2.693 0.007081 ** 
> 
> But when I do anova test of this minimal adequate model, only baresoil:moistcont, grass10:rdnet, wood10:rdnet10 were found significant. 
> 
>                     Df Deviance Resid. Df Resid. Dev Pr(>Chi)   
> NULL                                   17     36.167            
> orgmatter            1   2.4260        16     33.741 0.119334   
> baresoil             1   1.0871        15     32.654 0.297104   
> orgmatter:moistcont  1   2.5611        14     30.093 0.109526   
> baresoil:moistcont   1   8.2976        13     21.795 0.003970 **
> wood10:grass10       1   0.0184        12     21.777 0.892042   
> grass10:rdnet10      1   5.4520        11     16.325 0.019546 * 
> wood10:rdnet10       1   8.1565        10      8.168 0.004291 **
> 
> So, when I report the outcome of this model, should I show summary significance values or anova significance value (chi-square).

I don't think you should report anything. You need a consultation.  

Rhelp is established to offer technical advice about running R code.

From the Posting Guide:

"Questions about statistics: The R mailing lists are primarily intended for questions and discussion about the R software. However, questions about statistical methodology are sometimes posted. If the question is well-asked and of interest to someone on the list, it may elicit an informative up-to-date answer. See also the Usenet groups sci.stat.consult (applied statistics and consulting) and sci.stat.math (mathematical stat and probability).

Basic statistics and classroom homework: R-help is not intended for these."

-- 
David.
> 
> Regards
> Lutfor   
> 
> 
> 
> 
> 
> On Fri, Sep 13, 2013 at 7:42 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> On Sep 13, 2013, at 9:38 AM, Lutfor Rahman wrote:
> 
> Dear forum members,
> 
> Please help me understanding significance value when GLM done in r.
> 
> After doing minimal adequate model, I have found a number of independent
> values  which are significant. But doing their anova significant values are
> different. Please find my result following. Which significant values should
> I use.
> 
> 
> glm(formula = richness ~ moistcont + orgmatter + baresoil + grass10 +
>    wood10 + rdnet10 + moistcont:orgmatter + moistcont:baresoil +
>    grass10:wood10 + grass10:rdnet10 + wood10:rdnet10, family = poisson,
>    data = data)
> 
> Deviance Residuals:
>     Min        1Q    Median        3Q       Max
> -1.19112  -0.33682   0.09813   0.32808   0.70509
> 
> Coefficients:
>                     Estimate Std. Error z value Pr(>|z|)
> (Intercept)         11.384447   4.014170   2.836  0.00457 **
> moistcont           -0.095813   0.084995  -1.127  0.25962
> orgmatter           -1.810116   0.613688  -2.950  0.00318 **
> baresoil            -1.636707   0.559129  -2.927  0.00342 **
> grass10             -0.018979   0.065647  -0.289  0.77250
> wood10               0.150683   0.128386   1.174  0.24053
> rdnet10             -0.011448   0.068090  -0.168  0.86648
> moistcont:orgmatter  0.025698   0.011521   2.231  0.02571 *
> moistcont:baresoil   0.044110   0.015799   2.792  0.00524 **
> grass10:wood10       0.010740   0.006498   1.653  0.09838 .
> grass10:rdnet10      0.011013   0.004412   2.496  0.01255 *
> wood10:rdnet10      -0.088297   0.027120  -3.256  0.00113 **
> 
> The only p-value I would have expected to be the same would have been the last one in the avova output:
> 
>                    Df Deviance Resid. Df Resid. Dev Pr(>Chi)
> .....
> 
> wood10:rdnet10       1  10.7812         6      3.928 0.001025 **
> 
> And that particular p-value is not far off from the 0.00113 value reported in the model summary. The other p-values are not of the same sort. The p-values above are basically reporting the "significance" of removing single predictors or interactions from the full model. The anova reported below is perfoming sequential addition of terms to a NULL model as well as doing a different test:  LR tests instead of Wald statistics.
> 
> -- 
> David.
> 
> 
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> (Dispersion parameter for poisson family taken to be 1)
> 
>    Null deviance: 36.1673  on 17  degrees of freedom
> Residual deviance:  3.9276  on  6  degrees of freedom
> AIC: 97.893
> 
> Number of Fisher Scoring iterations: 4
> 
> anova(data1, test="Chisq")
> Analysis of Deviance Table
> 
> Model: poisson, link: log
> 
> Response: richness
> 
> Terms added sequentially (first to last)
> 
> 
>                    Df Deviance Resid. Df Resid. Dev Pr(>Chi)
> NULL                                   17     36.167
> moistcont            1   8.6322        16     27.535 0.003303 **
> orgmatter            1   2.1244        15     25.411 0.144966
> baresoil             1   0.0029        14     25.408 0.956986
> grass10              1   1.5251        13     23.883 0.216842
> wood10               1   3.6952        12     20.187 0.054570 .
> rdnet10              1   0.0001        11     20.187 0.990564
> moistcont:orgmatter  1   2.0482        10     18.139 0.152381
> moistcont:baresoil   1   2.8730         9     15.266 0.090076 .
> grass10:wood10       1   0.1431         8     15.123 0.705247
> grass10:rdnet10      1   0.4141         7     14.709 0.519883
> wood10:rdnet10       1  10.7812         6      3.928 0.001025 **
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius, MD
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From ankurseth82 at gmail.com  Sun Sep 15 17:37:39 2013
From: ankurseth82 at gmail.com (Ankur Seth)
Date: Sun, 15 Sep 2013 21:07:39 +0530
Subject: [R] Data labels in R
Message-ID: <CAK6WB8tqq+QmF3MEjYRfcSxLq_s1Fyh5okcwWZ+aO+b91yV+4g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130915/b94f2c2b/attachment.pl>

From jholtman at gmail.com  Sun Sep 15 17:46:10 2013
From: jholtman at gmail.com (jim holtman)
Date: Sun, 15 Sep 2013 11:46:10 -0400
Subject: [R] Data labels in R
In-Reply-To: <CAK6WB8tqq+QmF3MEjYRfcSxLq_s1Fyh5okcwWZ+aO+b91yV+4g@mail.gmail.com>
References: <CAK6WB8tqq+QmF3MEjYRfcSxLq_s1Fyh5okcwWZ+aO+b91yV+4g@mail.gmail.com>
Message-ID: <CAAxdm-5sy1L_F3Bcx8KENyj22uJE2B46cPhtY16Z0kmhWEaPqA@mail.gmail.com>

Read the help file on 'plot' and look at some of the examples to see
how to place labels in various places on a plot.  This is not
difficult if you have read any of the documentation.

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Sun, Sep 15, 2013 at 11:37 AM, Ankur Seth <ankurseth82 at gmail.com> wrote:
> I need to put labels in plot in R. Can someone please help? The labels are
> in the excel file and loaded into "lables"
>
> library(xlsx)
> library(zoo)
>
> fPTAnalysis<-"Input.xls"
> data<-read.xlsx(fPTAnalysis,9)
>
> lables<-subset(data, select=c(Labels))
> data<-subset(data, select=c(Date,col1, col2 ))
> data<-read.zoo(data)
>
>
>
> plot(data)
>
> --
> Regards,
> Ankur Seth
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ankurseth82 at gmail.com  Sun Sep 15 18:43:41 2013
From: ankurseth82 at gmail.com (Ankur Seth)
Date: Sun, 15 Sep 2013 22:13:41 +0530
Subject: [R] Data labels in R
In-Reply-To: <CAAxdm-5sy1L_F3Bcx8KENyj22uJE2B46cPhtY16Z0kmhWEaPqA@mail.gmail.com>
References: <CAK6WB8tqq+QmF3MEjYRfcSxLq_s1Fyh5okcwWZ+aO+b91yV+4g@mail.gmail.com>
	<CAAxdm-5sy1L_F3Bcx8KENyj22uJE2B46cPhtY16Z0kmhWEaPqA@mail.gmail.com>
Message-ID: <CAK6WB8sTsqf8O2_n+xuVBDzbs1YGKDWTcdy2PyCHSvrArbDkog@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130915/0922ffb4/attachment.pl>

From andrewcd at gmail.com  Sun Sep 15 18:51:45 2013
From: andrewcd at gmail.com (Andrew Crane-Droesch)
Date: Sun, 15 Sep 2013 09:51:45 -0700
Subject: [R] Instructions for upgrading R on ubuntu
Message-ID: <5235E5A1.7060307@gmail.com>

I am trying to upgrade to R 3.0.1, and I am working on ubuntu. 
Apparently, the new version is available in the following ppa: 
https://launchpad.net/~marutter/+archive/c2d4u.  I have added this ppa 
to my software sources.

I then run the typical sudo apt-get update && sudo apt-get dist-upgrade, 
and R fails to upgrade from 2.15.2 to 3.0.1.  I then manually try to 
sudo apt-get install r-base-dev, which does not recognize that a new 
version is available from the newly-installed ppa.

I have tried using the GUI Software Center as well -- it lists R as 
installed, and makes no mention of the new version.

Could someone be so kind as to post step-by-step instructions for 
actually installing R 3.0.1?  Given issues with graphics in R2.15.2 with 
Ubuntu 13.04, I am sure that this will be useful to people besides me.

Thanks,
Andrew


From jdnewmil at dcn.davis.CA.us  Sun Sep 15 19:11:15 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 15 Sep 2013 10:11:15 -0700
Subject: [R] Instructions for upgrading R on ubuntu
In-Reply-To: <5235E5A1.7060307@gmail.com>
References: <5235E5A1.7060307@gmail.com>
Message-ID: <57842ec6-b3dd-440f-8616-137269a0857d@email.android.com>

"Apparently"? How is this apparent? I don't see this mentioned at CRAN [1]. Why would you reference some perhaps well-intentioned but possibly untrustworthy person's website when you could be downloading from a vetted distribution source?

[1] http://cran.us.r-project.org/bin/linux/ubuntu/
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Andrew Crane-Droesch <andrewcd at gmail.com> wrote:
>I am trying to upgrade to R 3.0.1, and I am working on ubuntu. 
>Apparently, the new version is available in the following ppa: 
>https://launchpad.net/~marutter/+archive/c2d4u.  I have added this ppa 
>to my software sources.
>
>I then run the typical sudo apt-get update && sudo apt-get
>dist-upgrade, 
>and R fails to upgrade from 2.15.2 to 3.0.1.  I then manually try to 
>sudo apt-get install r-base-dev, which does not recognize that a new 
>version is available from the newly-installed ppa.
>
>I have tried using the GUI Software Center as well -- it lists R as 
>installed, and makes no mention of the new version.
>
>Could someone be so kind as to post step-by-step instructions for 
>actually installing R 3.0.1?  Given issues with graphics in R2.15.2
>with 
>Ubuntu 13.04, I am sure that this will be useful to people besides me.
>
>Thanks,
>Andrew
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From JSorkin at grecc.umaryland.edu  Sun Sep 15 19:22:22 2013
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Sun, 15 Sep 2013 13:22:22 -0400
Subject: [R] Instructions for upgrading R on ubuntu
In-Reply-To: <57842ec6-b3dd-440f-8616-137269a0857d@email.android.com>
References: <5235E5A1.7060307@gmail.com>
	<57842ec6-b3dd-440f-8616-137269a0857d@email.android.com>
Message-ID: <5235B48E020000CB000F0D1A@smtp.medicine.umaryland.edu>

Jeff, Andrew,
When you come up with a solution to the upgrade problem, please send it to me. I have a similiar problem under Mint, which is an Unbuntu fork.
Thank you,
John

 
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>>> Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 9/15/2013 1:11 PM >>>
"Apparently"? How is this apparent? I don't see this mentioned at CRAN [1]. Why would you reference some perhaps well-intentioned but possibly untrustworthy person's website when you could be downloading from a vetted distribution source?

[1] http://cran.us.r-project.org/bin/linux/ubuntu/
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------
Sent from my phone. Please excuse my brevity.

Andrew Crane-Droesch <andrewcd at gmail.com> wrote:
>I am trying to upgrade to R 3.0.1, and I am working on ubuntu. 
>Apparently, the new version is available in the following ppa: 
>https://launchpad.net/~marutter/+archive/c2d4u.  I have added this ppa 
>to my software sources.
>
>I then run the typical sudo apt-get update && sudo apt-get
>dist-upgrade, 
>and R fails to upgrade from 2.15.2 to 3.0.1.  I then manually try to 
>sudo apt-get install r-base-dev, which does not recognize that a new 
>version is available from the newly-installed ppa.
>
>I have tried using the GUI Software Center as well -- it lists R as 
>installed, and makes no mention of the new version.
>
>Could someone be so kind as to post step-by-step instructions for 
>actually installing R 3.0.1?  Given issues with graphics in R2.15.2
>with 
>Ubuntu 13.04, I am sure that this will be useful to people besides me.
>
>Thanks,
>Andrew
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information.  Any unauthorized use, disclosure or distribution is prohibited.  If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From bhh at xs4all.nl  Sun Sep 15 19:34:55 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 15 Sep 2013 19:34:55 +0200
Subject: [R] Instructions for upgrading R on ubuntu
In-Reply-To: <57842ec6-b3dd-440f-8616-137269a0857d@email.android.com>
References: <5235E5A1.7060307@gmail.com>
	<57842ec6-b3dd-440f-8616-137269a0857d@email.android.com>
Message-ID: <FFAB2167-804B-4B74-A9E5-8568C55E1F8A@xs4all.nl>


On 15-09-2013, at 19:11, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> "Apparently"? How is this apparent? I don't see this mentioned at CRAN [1]. Why would you reference some perhaps well-intentioned but possibly untrustworthy person's website when you could be downloading from a vetted distribution source?
> 

Well, M.A. Rutter builds the Ubuntu R packages. 
See http://www.personal.psu.edu/mar36/blogs/the_ubuntu_r_blog/installing-r.html

R 3.0.1 has been available for Ubuntu for quite some time.

I've had no problem in installing this R in a virtual Kubuntu Precise (and Ubuntu Lucid).
When following the instructions on CRAN.

Berend

> [1] http://cran.us.r-project.org/bin/linux/ubuntu/
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> Andrew Crane-Droesch <andrewcd at gmail.com> wrote:
>> I am trying to upgrade to R 3.0.1, and I am working on ubuntu. 
>> Apparently, the new version is available in the following ppa: 
>> https://launchpad.net/~marutter/+archive/c2d4u.  I have added this ppa 
>> to my software sources.
>> 
>> I then run the typical sudo apt-get update && sudo apt-get
>> dist-upgrade, 
>> and R fails to upgrade from 2.15.2 to 3.0.1.  I then manually try to 
>> sudo apt-get install r-base-dev, which does not recognize that a new 
>> version is available from the newly-installed ppa.
>> 
>> I have tried using the GUI Software Center as well -- it lists R as 
>> installed, and makes no mention of the new version.
>> 
>> Could someone be so kind as to post step-by-step instructions for 
>> actually installing R 3.0.1?  Given issues with graphics in R2.15.2
>> with 
>> Ubuntu 13.04, I am sure that this will be useful to people besides me.
>> 
>> Thanks,
>> Andrew
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Sun Sep 15 19:33:22 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 15 Sep 2013 10:33:22 -0700 (PDT)
Subject: [R] Data labels in R
In-Reply-To: <CAK6WB8sTsqf8O2_n+xuVBDzbs1YGKDWTcdy2PyCHSvrArbDkog@mail.gmail.com>
References: <CAK6WB8tqq+QmF3MEjYRfcSxLq_s1Fyh5okcwWZ+aO+b91yV+4g@mail.gmail.com>	<CAAxdm-5sy1L_F3Bcx8KENyj22uJE2B46cPhtY16Z0kmhWEaPqA@mail.gmail.com>
	<CAK6WB8sTsqf8O2_n+xuVBDzbs1YGKDWTcdy2PyCHSvrArbDkog@mail.gmail.com>
Message-ID: <1379266402.70862.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Try:
lab<- as.character(x[,3])
library(lattice)
xyplot(y~time(y),type="b",xlab="Date",ylab="Price",scales=list(x=list(at=time(y),labels=format(time(y),"%b-%d"))),
panel=function(x, y, ...) {
?????????????? panel.xyplot(x, y, ...);
?????????????? ltext(x=x, y=y, labels= lab, pos=1, offset=1, cex=0.8)})

A.K.




----- Original Message -----
From: Ankur Seth <ankurseth82 at gmail.com>
To: jim holtman <jholtman at gmail.com>
Cc: r-help <r-help at stat.math.ethz.ch>
Sent: Sunday, September 15, 2013 12:43 PM
Subject: Re: [R] Data labels in R

I want to put labels a,b,c,d on the data points

x<-data.frame(c(1,2,3,4),c(1,4,9,16),c("a","b","c","d"),
as.Date(c("01-10-2013", "02-10-2013","03-10-2013","04-10-2013"),
"%d-%m-%Y"))
colnames(x)<-c("x", "sq", "lables","dates")
y<-subset(x, select=c(dates,x,sq))
y<-read.zoo(y)
plot(y, plot.type="single", xlab="Date", ylab="Price")




On Sun, Sep 15, 2013 at 9:16 PM, jim holtman <jholtman at gmail.com> wrote:

> Read the help file on 'plot' and look at some of the examples to see
> how to place labels in various places on a plot.? This is not
> difficult if you have read any of the documentation.
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
>
> On Sun, Sep 15, 2013 at 11:37 AM, Ankur Seth <ankurseth82 at gmail.com>
> wrote:
> > I need to put labels in plot in R. Can someone please help? The labels
> are
> > in the excel file and loaded into "lables"
> >
> > library(xlsx)
> > library(zoo)
> >
> > fPTAnalysis<-"Input.xls"
> > data<-read.xlsx(fPTAnalysis,9)
> >
> > lables<-subset(data, select=c(Labels))
> > data<-subset(data, select=c(Date,col1, col2 ))
> > data<-read.zoo(data)
> >
> >
> >
> > plot(data)
> >
> > --
> > Regards,
> > Ankur Seth
> >
> >? ? ? ?  [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
Regards,
Ankur Seth

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jdnewmil at dcn.davis.CA.us  Sun Sep 15 20:03:36 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 15 Sep 2013 11:03:36 -0700
Subject: [R] Instructions for upgrading R on ubuntu
In-Reply-To: <FFAB2167-804B-4B74-A9E5-8568C55E1F8A@xs4all.nl>
References: <5235E5A1.7060307@gmail.com>
	<57842ec6-b3dd-440f-8616-137269a0857d@email.android.com>
	<FFAB2167-804B-4B74-A9E5-8568C55E1F8A@xs4all.nl>
Message-ID: <a89d5f4f-8250-4601-90ff-7a40e3fd3f7b@email.android.com>

Ah, my apologies to Mr. Rutter are due then, but a proper reference by the OP would have clarified this.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Berend Hasselman <bhh at xs4all.nl> wrote:
>
>On 15-09-2013, at 19:11, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> "Apparently"? How is this apparent? I don't see this mentioned at
>CRAN [1]. Why would you reference some perhaps well-intentioned but
>possibly untrustworthy person's website when you could be downloading
>from a vetted distribution source?
>> 
>
>Well, M.A. Rutter builds the Ubuntu R packages. 
>See
>http://www.personal.psu.edu/mar36/blogs/the_ubuntu_r_blog/installing-r.html
>
>R 3.0.1 has been available for Ubuntu for quite some time.
>
>I've had no problem in installing this R in a virtual Kubuntu Precise
>(and Ubuntu Lucid).
>When following the instructions on CRAN.
>
>Berend
>
>> [1] http://cran.us.r-project.org/bin/linux/ubuntu/
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                      Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>
>> Sent from my phone. Please excuse my brevity.
>> 
>> Andrew Crane-Droesch <andrewcd at gmail.com> wrote:
>>> I am trying to upgrade to R 3.0.1, and I am working on ubuntu. 
>>> Apparently, the new version is available in the following ppa: 
>>> https://launchpad.net/~marutter/+archive/c2d4u.  I have added this
>ppa 
>>> to my software sources.
>>> 
>>> I then run the typical sudo apt-get update && sudo apt-get
>>> dist-upgrade, 
>>> and R fails to upgrade from 2.15.2 to 3.0.1.  I then manually try to
>
>>> sudo apt-get install r-base-dev, which does not recognize that a new
>
>>> version is available from the newly-installed ppa.
>>> 
>>> I have tried using the GUI Software Center as well -- it lists R as 
>>> installed, and makes no mention of the new version.
>>> 
>>> Could someone be so kind as to post step-by-step instructions for 
>>> actually installing R 3.0.1?  Given issues with graphics in R2.15.2
>>> with 
>>> Ubuntu 13.04, I am sure that this will be useful to people besides
>me.
>>> 
>>> Thanks,
>>> Andrew
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Sun Sep 15 20:04:54 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 15 Sep 2013 11:04:54 -0700
Subject: [R] Instructions for upgrading R on ubuntu
In-Reply-To: <5235B48E020000CB000F0D1A@smtp.medicine.umaryland.edu>
References: <5235E5A1.7060307@gmail.com>
	<57842ec6-b3dd-440f-8616-137269a0857d@email.android.com>
	<5235B48E020000CB000F0D1A@smtp.medicine.umaryland.edu>
Message-ID: <e35016bd-733a-44e4-8295-63cd0d1a829e@email.android.com>

John, the instructions at CRAN have worked for me.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

John Sorkin <JSorkin at grecc.umaryland.edu> wrote:
>Jeff, Andrew,
>When you come up with a solution to the upgrade problem, please send it
>to me. I have a similiar problem under Mint, which is an Unbuntu fork.
>Thank you,
>John
>
> 
>John David Sorkin M.D., Ph.D.
>Professor of Medicine
>Chief, Biostatistics and Informatics
>University of Maryland School of Medicine Division of Gerontology and
>Geriatric Medicine
>Baltimore VA Medical Center
>10 North Greene Street
>GRECC (BT/18/GR)
>Baltimore, MD 21201-1524
>(Phone) 410-605-7119
>(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>>>> Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 9/15/2013 1:11 PM >>>
>"Apparently"? How is this apparent? I don't see this mentioned at CRAN
>[1]. Why would you reference some perhaps well-intentioned but possibly
>untrustworthy person's website when you could be downloading from a
>vetted distribution source?
>
>[1] http://cran.us.r-project.org/bin/linux/ubuntu/
>---------------------------------------------------------------------------
>Jeff Newmiller                        The     .....       .....  Go
>Live...
>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>                                     Live:   OO#.. Dead: OO#..  Playing
>Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>/Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>---------------------------------------------------------------------------
>
>Sent from my phone. Please excuse my brevity.
>
>Andrew Crane-Droesch <andrewcd at gmail.com> wrote:
>>I am trying to upgrade to R 3.0.1, and I am working on ubuntu. 
>>Apparently, the new version is available in the following ppa: 
>>https://launchpad.net/~marutter/+archive/c2d4u.  I have added this ppa
>
>>to my software sources.
>>
>>I then run the typical sudo apt-get update && sudo apt-get
>>dist-upgrade, 
>>and R fails to upgrade from 2.15.2 to 3.0.1.  I then manually try to 
>>sudo apt-get install r-base-dev, which does not recognize that a new 
>>version is available from the newly-installed ppa.
>>
>>I have tried using the GUI Software Center as well -- it lists R as 
>>installed, and makes no mention of the new version.
>>
>>Could someone be so kind as to post step-by-step instructions for 
>>actually installing R 3.0.1?  Given issues with graphics in R2.15.2
>>with 
>>Ubuntu 13.04, I am sure that this will be useful to people besides me.
>>
>>Thanks,
>>Andrew
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>
>Confidentiality Statement:
>This email message, including any attachments, is for t...{{dropped:6}}


From istazahn at gmail.com  Sun Sep 15 21:47:41 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Sun, 15 Sep 2013 15:47:41 -0400
Subject: [R] Downloading data directly from internet
In-Reply-To: <1379247699.2324.YahooMailNeo@web190503.mail.sg3.yahoo.com>
References: <1379247699.2324.YahooMailNeo@web190503.mail.sg3.yahoo.com>
Message-ID: <CA+vqiLGhP8UHUEk=zWHW-sXqSHB6ZZeE6kqRzRX4x5juSUGsPg@mail.gmail.com>

Hi Ron,

It looks like the data you want is generated by javascript; if so
Rcurl will not be able to retrieve it for you. See
http://stackoverflow.com/questions/14491598/how-do-i-download-the-source-code-for-a-webpage
and http://stackoverflow.com/questions/9778076/how-to-view-webpage-source-code-using-r?rq=1
for some ideas to get you started.

Best,
Ista

On Sun, Sep 15, 2013 at 8:21 AM, Ron Michael <ron_michael70 at yahoo.com> wrote:
> Hi,
>
> I need to download data from this site:
> http://www.cmegroup.com/trading/agricultural/grain-and-oilseed/corn_quotes_globex.html
>
>
> I tried with following set of codes:
>
>
> library(RCurl)
> library(XML)
>
> aa <- getURL("http://www.cmegroup.com/trading/agricultural/grain-and-oilseed/corn_quotes_globex.html")
> readHTMLTable(aa)
>
> However not getting the required data.
>
> Can someone please help me to point out how I can get that data?
>
> Your help will be highly appreciated.
>
> Thank you very much.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Sun Sep 15 22:50:37 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Sun, 15 Sep 2013 15:50:37 -0500
Subject: [R] Deterministic initialization for k-means
In-Reply-To: <CAJRSaT_iLo3WJt9Z1SrF65ooVKvk3zj=eOCd35fpmALrZDg+yQ@mail.gmail.com>
References: <CAJRSaT_iLo3WJt9Z1SrF65ooVKvk3zj=eOCd35fpmALrZDg+yQ@mail.gmail.com>
Message-ID: <00bd01ceb255$3b1af5f0$b150e1d0$@tamu.edu>

I am not aware of an implementation of the algorithm you
describe. If you are not locked to that particular approach,
function diana() in package cluster performs polythetic,
hierarchical partitioning which could be used to get your
starting cluster centers. 

Scanning over a paper by Su and Dy (you didn't give us a full
citation, this one was published in Intelligent Data Analysis
2007 (11): 319-338), they conclude:

"In case one cannot afford several random start runs, our
deterministic initialization methods provide reasonable
alternatives."

Unless your data is enormous, you can surely afford multiple
random starts. Just use the nstart= argument in the kmeans()
function. It will run that many kmeans analyses and pick the one
that produces the minimum within sum of squares.

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Safiye Celik
Sent: Thursday, September 12, 2013 7:37 PM
To: r-help at r-project.org
Subject: [R] Deterministic initialization for k-means

Hi,

I want to cluster my data points into K clusters using k-means
algorithm,
and I want to use a deterministic (non-random) initialization
scheme which
is also a "good" start. I found a paper by Ting Su and Jennifer
Dy named "A
Deterministic Method for Initializing K-means Clustering" and I
wonder if
there is a way in R to partition the points in the way that is
described in
this paper.

"Starting from an initial cluster that contains the entire data
set, the
method iteratively selects the cluster with the greatest SSE and
divides it
into two subclusters using a hyperplane that passes through the
cluster
centroid and is orthogonal to the principal eigenvector of the
cluster
covariance matrix. This procedure is repeated until K clusters
are
obtained."

If I get the final K centers from this partitioning, then I can
give those
centers to R's kmeans algorithm to let it converge.

Is there a built-in R function to get such an initial
partitioning?

Thanks!

-- 
-safiye

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From andrewcd at gmail.com  Mon Sep 16 00:19:38 2013
From: andrewcd at gmail.com (Andrew Crane-Droesch)
Date: Sun, 15 Sep 2013 15:19:38 -0700
Subject: [R] Instructions for upgrading R on ubuntu
In-Reply-To: <e35016bd-733a-44e4-8295-63cd0d1a829e@email.android.com>
References: <5235E5A1.7060307@gmail.com>
	<57842ec6-b3dd-440f-8616-137269a0857d@email.android.com>
	<5235B48E020000CB000F0D1A@smtp.medicine.umaryland.edu>
	<e35016bd-733a-44e4-8295-63cd0d1a829e@email.android.com>
Message-ID: <5236327A.1070906@gmail.com>

Indeed, the instructions at CRAN work (with the small addition that one 
needs to be a superuser to edit the software sources).  The confusion 
arose because the c2d4u PPA is the main search result when googling 
"upgrade R 3.0.1 ubuntu".

Andrew

On 09/15/2013 11:04 AM, Jeff Newmiller wrote:
> John, the instructions at CRAN have worked for me.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> John Sorkin <JSorkin at grecc.umaryland.edu> wrote:
>> Jeff, Andrew,
>> When you come up with a solution to the upgrade problem, please send it
>> to me. I have a similiar problem under Mint, which is an Unbuntu fork.
>> Thank you,
>> John
>>
>>
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and
>> Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>>>> Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 9/15/2013 1:11 PM >>>
>> "Apparently"? How is this apparent? I don't see this mentioned at CRAN
>> [1]. Why would you reference some perhaps well-intentioned but possibly
>> untrustworthy person's website when you could be downloading from a
>> vetted distribution source?
>>
>> [1] http://cran.us.r-project.org/bin/linux/ubuntu/
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                      Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>> ---------------------------------------------------------------------------
>>
>> Sent from my phone. Please excuse my brevity.
>>
>> Andrew Crane-Droesch <andrewcd at gmail.com> wrote:
>>> I am trying to upgrade to R 3.0.1, and I am working on ubuntu.
>>> Apparently, the new version is available in the following ppa:
>>> https://launchpad.net/~marutter/+archive/c2d4u.  I have added this ppa
>>> to my software sources.
>>>
>>> I then run the typical sudo apt-get update && sudo apt-get
>>> dist-upgrade,
>>> and R fails to upgrade from 2.15.2 to 3.0.1.  I then manually try to
>>> sudo apt-get install r-base-dev, which does not recognize that a new
>>> version is available from the newly-installed ppa.
>>>
>>> I have tried using the GUI Software Center as well -- it lists R as
>>> installed, and makes no mention of the new version.
>>>
>>> Could someone be so kind as to post step-by-step instructions for
>>> actually installing R 3.0.1?  Given issues with graphics in R2.15.2
>>> with
>>> Ubuntu 13.04, I am sure that this will be useful to people besides me.
>>>
>>> Thanks,
>>> Andrew
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> Confidentiality Statement:
>> This email message, including any attachments, is for the sole use of
>> the intended recipient(s) and may contain confidential and privileged
>> information.  Any unauthorized use, disclosure or distribution is
>> prohibited.  If you are not the intended recipient, please contact the
>> sender by reply email and destroy all copies of the original message.
>


From josheckman at hotmail.com  Sun Sep 15 23:33:28 2013
From: josheckman at hotmail.com (Joshua Eckman)
Date: Sun, 15 Sep 2013 15:33:28 -0600
Subject: [R] hclust/dendrogram merging
Message-ID: <BAY167-W1059032665F8387DD05CB26DE250@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130915/787ea054/attachment.pl>

From michel.arnaud at cirad.fr  Mon Sep 16 08:42:31 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Mon, 16 Sep 2013 08:42:31 +0200
Subject: [R] Change the color of the line inside of the function lines
Message-ID: <5236A857.9060903@cirad.fr>

Hi

I have the following problem :
I have 3 vectors xx, yy, zz :
xx <-  c(5479,  6209,  6940,  7670,  8766,  9496, 10227, 11048, 11778, 
12509, 13239, 13970,
14700, 15340, 15948)
yy <- c( 267, 275, 281, 287, 296, 306, 316, 325, 334, 351, 365, 377, 
389, 419, 419)
zz <- c( 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6)
I would like a line wich join the points (xx, yy) with stair steps (as 
type = "s")
plot(xx, yy, type="n")
lines(xx, yy, type ="s")
but I want to change the color according to the value of zz (exemple : 
col = 1 if zz =3 ; col =2 if zz= 4 ;  col =3 if zz= 5 ;  col =4 if zz= 6)
Thank you for your help

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From tcmuigai at gmail.com  Mon Sep 16 09:01:03 2013
From: tcmuigai at gmail.com (Charles Thuo)
Date: Mon, 16 Sep 2013 10:01:03 +0300
Subject: [R] is it possible to install R packages without admin rights on a
	work station
Message-ID: <CAAJc=rOsf9Q5PJfFhxXgLr-noyJC5yVph5Nbt61ee40bW2hkfQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130916/4ab96184/attachment.pl>

From tsjerkw at gmail.com  Mon Sep 16 09:01:39 2013
From: tsjerkw at gmail.com (Tsjerk Wassenaar)
Date: Mon, 16 Sep 2013 09:01:39 +0200
Subject: [R] Change the color of the line inside of the function lines
In-Reply-To: <5236A857.9060903@cirad.fr>
References: <5236A857.9060903@cirad.fr>
Message-ID: <CABzE1SimWT+DFm51KinJ7QydR69m=Qpb9qRKFtPzk=owBsDdcw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130916/7d7177d5/attachment.pl>

From michel.arnaud at cirad.fr  Mon Sep 16 09:20:40 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Mon, 16 Sep 2013 09:20:40 +0200
Subject: [R] Change the color of the line inside of the function lines
In-Reply-To: <CABzE1SimWT+DFm51KinJ7QydR69m=Qpb9qRKFtPzk=owBsDdcw@mail.gmail.com>
References: <5236A857.9060903@cirad.fr>
	<CABzE1SimWT+DFm51KinJ7QydR69m=Qpb9qRKFtPzk=owBsDdcw@mail.gmail.com>
Message-ID: <5236B148.2020601@cirad.fr>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
URL : <https://stat.ethz.ch/pipermail/r-help/attachments/20130916/93b19f57/attachment.pl>

From petr.pikal at precheza.cz  Mon Sep 16 09:27:39 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 16 Sep 2013 07:27:39 +0000
Subject: [R] Splitting data into two camps
In-Reply-To: <CAAomMNynA9UdQGJN7Va2XDLPtW1FZYav4KOc+OSUtwoTWOnorw@mail.gmail.com>
References: <CAAomMNynA9UdQGJN7Va2XDLPtW1FZYav4KOc+OSUtwoTWOnorw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B91F2C@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Evan Sticca
> Sent: Friday, September 13, 2013 6:48 PM
> To: r-help at r-project.org
> Subject: [R] Splitting data into two camps
> 
> Hello R-help,
> 
> I have recently generated some meta-data on SNP variation across whole
> exomes and I need to begin sorting it into two camps: one in which the
> alternate allele matches the derived form and one where the alternate
> allele matches the ancestral form. I have the data saved as a .txt file
> from its original VCF format. I am a novice at writing my own functions
> in R, so any help would greatly be appreciated.

See
?read.table
and other read functions.

And if you start to read help pages I strongly recommend to read also
1.	Posting guide
2.	R intro
3.	R data
or at least some parts of it. It prevents you from great frustration if you are used to Excel or other similar pieces of software and consider R as another one.

Regards
Petr



> 
> Thank you,
> Evan Sticca
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tsjerkw at gmail.com  Mon Sep 16 09:38:04 2013
From: tsjerkw at gmail.com (Tsjerk Wassenaar)
Date: Mon, 16 Sep 2013 09:38:04 +0200
Subject: [R] Change the color of the line inside of the function lines
In-Reply-To: <5236B148.2020601@cirad.fr>
References: <5236A857.9060903@cirad.fr>
	<CABzE1SimWT+DFm51KinJ7QydR69m=Qpb9qRKFtPzk=owBsDdcw@mail.gmail.com>
	<5236B148.2020601@cirad.fr>
Message-ID: <CABzE1Siz9vk-_8=n51Kji7BHyKCLba_uEGODKFZhSc1JWRDDmw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130916/10c6771f/attachment.pl>

From kridox at ymail.com  Mon Sep 16 09:42:57 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Mon, 16 Sep 2013 16:42:57 +0900
Subject: [R] Change the color of the line inside of the function lines
In-Reply-To: <5236A857.9060903@cirad.fr>
References: <5236A857.9060903@cirad.fr>
Message-ID: <5236B681.2030400@ymail.com>

Hi,

Maybe the following might help you:

 > s <- seq(length(xx)-1)
 > plot(xx, yy, type="n")
 > segments(xx[s], yy[s], xx[s+1], yy[s], col=zz, lwd=2)
 > segments(xx[s+1], yy[s], xx[s+1], yy[s+1], col='grey')

Regards,
Pascal


On 16/09/2013 15:42, Arnaud Michel wrote:
> Hi
>
> I have the following problem :
> I have 3 vectors xx, yy, zz :
> xx <-  c(5479,  6209,  6940,  7670,  8766,  9496, 10227, 11048, 11778,
> 12509, 13239, 13970,
> 14700, 15340, 15948)
> yy <- c( 267, 275, 281, 287, 296, 306, 316, 325, 334, 351, 365, 377,
> 389, 419, 419)
> zz <- c( 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6)
> I would like a line wich join the points (xx, yy) with stair steps (as
> type = "s")
> plot(xx, yy, type="n")
> lines(xx, yy, type ="s")
> but I want to change the color according to the value of zz (exemple :
> col = 1 if zz =3 ; col =2 if zz= 4 ;  col =3 if zz= 5 ;  col =4 if zz= 6)
> Thank you for your help
>

-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From michel.arnaud at cirad.fr  Mon Sep 16 10:10:15 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Mon, 16 Sep 2013 10:10:15 +0200
Subject: [R] Change the color of the line inside of the function lines
In-Reply-To: <5236B681.2030400@ymail.com>
References: <5236A857.9060903@cirad.fr> <5236B681.2030400@ymail.com>
Message-ID: <5236BCE7.2070201@cirad.fr>

Thanks Pascal and Tsjerk
Michel
Le 16/09/2013 09:42, Pascal Oettli a ?crit :
> Hi,
>
> Maybe the following might help you:
>
> > s <- seq(length(xx)-1)
> > plot(xx, yy, type="n")
> > segments(xx[s], yy[s], xx[s+1], yy[s], col=zz, lwd=2)
> > segments(xx[s+1], yy[s], xx[s+1], yy[s+1], col='grey')
>
> Regards,
> Pascal
>
>
> On 16/09/2013 15:42, Arnaud Michel wrote:
>> Hi
>>
>> I have the following problem :
>> I have 3 vectors xx, yy, zz :
>> xx <-  c(5479,  6209,  6940,  7670,  8766,  9496, 10227, 11048, 11778,
>> 12509, 13239, 13970,
>> 14700, 15340, 15948)
>> yy <- c( 267, 275, 281, 287, 296, 306, 316, 325, 334, 351, 365, 377,
>> 389, 419, 419)
>> zz <- c( 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6)
>> I would like a line wich join the points (xx, yy) with stair steps (as
>> type = "s")
>> plot(xx, yy, type="n")
>> lines(xx, yy, type ="s")
>> but I want to change the color according to the value of zz (exemple :
>> col = 1 if zz =3 ; col =2 if zz= 4 ;  col =3 if zz= 5 ;  col =4 if 
>> zz= 6)
>> Thank you for your help
>>
>

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From nalimilan at club.fr  Mon Sep 16 10:40:08 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Mon, 16 Sep 2013 10:40:08 +0200
Subject: [R] Non-ACSII characters in R on Windows
In-Reply-To: <CAGKs4siL8rasbtsCgEfX=haESyAD5=7BHZv1R9CqeABS560aSQ@mail.gmail.com>
References: <CAGKs4siL8rasbtsCgEfX=haESyAD5=7BHZv1R9CqeABS560aSQ@mail.gmail.com>
Message-ID: <1379320808.17743.59.camel@milan>

Le vendredi 13 septembre 2013 ? 23:38 +0400, Maxim Linchits a ?crit :
> This is a condensed version of the same question on stackexchange here:
> http://stackoverflow.com/questions/18789330/r-on-windows-character-encoding-hell
> If you've already stumbled upon it feel free to ignore.
> 
> My problem is that R on US Windows does not read *any* text file that
> contains *any* foreign characters. It simply reads the first consecutive n
> ASCII characters and then throws a warning once it reached a foreign
> character:
> 
> > test <- read.table("test.txt", sep=";", dec=",", quote="",
> fileEncoding="UTF-8")
> Warning messages:
> 1: In read.table("test.txt", sep = ";", dec = ",", quote = "", fileEncoding
> = "UTF-8") :
>   invalid input found on input connection 'test.txt'
> 2: In read.table("test.txt", sep = ";", dec = ",", quote = "", fileEncoding
> = "UTF-8") :
>   incomplete final line found by readTableHeader on 'test.txt'
> > print(test)
>        V1
> 1 english
> 
> > Sys.getlocale()
>    [1] "LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> States.1252;
>      LC_MONETARY=English_United
> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252"
> 
> 
> It is important to note that that R on linux will read UTF-8 as well as
> exotic character sets without a problem. I've tried it with the exact same
> files (one was UTF-8 and another was OEM866 Cyrillic).
> 
> If I do not include the fileEncoding parameter, read.table will read the
> whole CSV file. But naturally it will read it wrong because it does not
> know the encoding. So whenever I try to specify the fileEncoding, R will
> throw the warnings and stop once it reaches a foreign character. It's the
> same story with all international character encodings.
> Other users on stackexchange have reported exactly the same issue.
> 
> 
> Is anyone here who is on a US version of Windows able to import files with
> foreign characters? Please let me know.
A reproducible example would have helped, as requested by the posting
guide.

Though I am also experiencing the same problem after saving the data
below to a CSV file encoded in UTF-8 (you can do this using even the
Notepad):
"?","?"
1,10
2,20

This is on a Windows 7 box using French locale, but same codepage 1252
as yours. What is interesting is that reading the file using
readLines(file("myFile.csv", encoding="UTF-8"))
gives no invalid characters. So there must be a bug in read.table().


But I must note I do not experience issues with French accentuated
characters like "?" ("\Ue9"). On the contrary, reading Armenian
characters like "?" ("\U531") gives weird results: the character appears
as <U+0531> instead of ?.

Self-contained example, writing the file and reading it back from R:
tmpfile <- tempfile()
writeLines("\U531", file(tmpfile, "w", encoding="UTF-8"))
readLines(file(tmpfile, encoding="UTF-8"))
# "<U+0531>"

The same phenomenon happens when creating a data frame from this
character (as noted on StackExchange):
data.frame("\U531")

So my conclusion is that maybe Windows does not really support Unicode
characters that are not "relevant" for your current locale. And that may
have created bugs in the way R handles them in read.table(). R
developers can probably tell us more about it.


Regards


From rolf.turner at xtra.co.nz  Mon Sep 16 10:46:17 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Mon, 16 Sep 2013 20:46:17 +1200
Subject: [R] is it possible to install R packages without admin rights
 on a work station
In-Reply-To: <CAAJc=rOsf9Q5PJfFhxXgLr-noyJC5yVph5Nbt61ee40bW2hkfQ@mail.gmail.com>
References: <CAAJc=rOsf9Q5PJfFhxXgLr-noyJC5yVph5Nbt61ee40bW2hkfQ@mail.gmail.com>
Message-ID: <5236C559.5080403@xtra.co.nz>

On 09/16/13 19:01, Charles Thuo wrote:
>   How can a person in a controlled environment install additional R
> packages...

Use a "local library" in your user space.  Create a directory --- I 
called mine "Rlib",
and it is located in my home directory.  I.e. my local library is 
/home/rolf/Rlib.

Then when using install.packages() from within R I invoke the function with
the syntax

install.packages("<whatever>",lib="/home/rolf/Rlib",<other possible 
arguments>)

Installing from source, from the command line I do:

     R CMD INSTALL <whatever>.tar.gz -l /home/rolf/Rlib

To load a package from one's local library one can do things like:

     library(<whatever>,lib.loc="/home/rolf/Rlib")

Note that the argument specifying the local library is named "lib" in 
install.packages()
but is named "lib.loc" in library().  I can never remember which is 
which.  Psigh!

Or you can add your local library to your .libPaths(), as in:

     .libPaths("/home/rolf/Rlib")

You can put a line like this in your .Rprofile file so that it gets done 
automatically
when you start R.  Or you can set an environment variable R_LIBS:

     setenv R_LIBS /home/rolf/Rlib

(if using csh) or

     R_LIBS = /home/rolf/Rlib
     export R_LIBS

(if using bash).


HTH

     cheers,

     Rolf Turner


From daniel.hornung at ds.mpg.de  Mon Sep 16 10:55:23 2013
From: daniel.hornung at ds.mpg.de (Daniel Hornung)
Date: Mon, 16 Sep 2013 10:55:23 +0200
Subject: [R] is it possible to install R packages without admin rights
	on a work station
In-Reply-To: <CAAJc=rOsf9Q5PJfFhxXgLr-noyJC5yVph5Nbt61ee40bW2hkfQ@mail.gmail.com>
References: <CAAJc=rOsf9Q5PJfFhxXgLr-noyJC5yVph5Nbt61ee40bW2hkfQ@mail.gmail.com>
Message-ID: <201309161055.26617.daniel.hornung@ds.mpg.de>

On Monday, September 16, 2013 09:01:03 Charles Thuo wrote:
>  How can a person in a controlled environment install additional R
> packages..
> 
> Charles.

Hello Charles,

a slight variation of what Rolf wrote, this is my setup:

in my ~/.Rprofile (which is read at R's startup), I set the R_LIBS_USER 
variable like so:

R_LIBS_USER=~/.local/share/R/libs

Of course you may vary the exact path according to your liking.  Another 
helpful option I found is the follwoing, if you decide you like a specific 
repository best (to avoid the selection dialog): in your ~/.Rprofile, add this 
line:

options(repos=structure(c(CRAN="http://ftp5.gwdg.de/pub/misc/cran/")))

(Use the repo which is fastest for you).

HTH,
Daniel

-- 
Max-Planck-Institute for Dynamics and Self-Organization
Laboratory for Fluid Dynamics, Pattern Formation and Biocomplexity
Biomedical Physics Group

Am Fassberg 17
D-37077 Goettingen

(+49) 551 5176 373
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 836 bytes
Desc: This is a digitally signed message part.
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130916/41dc092e/attachment.bin>

From zhangweiwu at realss.com  Mon Sep 16 13:22:20 2013
From: zhangweiwu at realss.com (Zhang Weiwu)
Date: Mon, 16 Sep 2013 19:22:20 +0800 (CST)
Subject: [R] Instructions for upgrading R on ubuntu
In-Reply-To: <5236327A.1070906@gmail.com>
References: <5235E5A1.7060307@gmail.com>
	<57842ec6-b3dd-440f-8616-137269a0857d@email.android.com>
	<5235B48E020000CB000F0D1A@smtp.medicine.umaryland.edu>
	<e35016bd-733a-44e4-8295-63cd0d1a829e@email.android.com>
	<5236327A.1070906@gmail.com>
Message-ID: <alpine.DEB.2.00.1309161904540.5203@lyonesse>


On Sun, 15 Sep 2013, Andrew Crane-Droesch wrote:

> The c2d4u PPA is the main search result when googling "upgrade R 3.0.1 
> ubuntu".

And it should be, because it is more likely that a PPA re-distribution works 
better for Ubuntu than a general distribution, even if it is an exceptional 
case with this software this time.

You must be in bad need of 64-bit memory access or long vectors?, to do a 
manual upgrade just one month ahead of Ubuntu's own maintenance upgrade 
(13.10) with contains R-3.0.1.

? They are the major features offered by R-3, so I guess most users are 
unlikely argued into hurrying an upgrade from R-2.x
http://www.r-bloggers.com/r-3-0-0-is-released-whats-new-and-how-to-upgrade/

From thomas.parr at maine.edu  Mon Sep 16 15:47:54 2013
From: thomas.parr at maine.edu (Thomas Parr)
Date: Mon, 16 Sep 2013 09:47:54 -0400
Subject: [R] hclust/dendrogram merging
Message-ID: <CADUm0t4hFaJvsN933--RjKGZEvMXkh6bMJjm4Z_Ga-V2tJ+EjQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130916/f6dff260/attachment.pl>

From nalimilan at club.fr  Mon Sep 16 16:38:57 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Mon, 16 Sep 2013 16:38:57 +0200
Subject: [R] Non-ACSII characters in R on Windows
In-Reply-To: <1379320808.17743.59.camel@milan>
References: <CAGKs4siL8rasbtsCgEfX=haESyAD5=7BHZv1R9CqeABS560aSQ@mail.gmail.com>
	<1379320808.17743.59.camel@milan>
Message-ID: <1379342337.26458.13.camel@milan>

Le lundi 16 septembre 2013 ? 10:40 +0200, Milan Bouchet-Valat a ?crit :
> Le vendredi 13 septembre 2013 ? 23:38 +0400, Maxim Linchits a ?crit :
> > This is a condensed version of the same question on stackexchange here:
> > http://stackoverflow.com/questions/18789330/r-on-windows-character-encoding-hell
> > If you've already stumbled upon it feel free to ignore.
> > 
> > My problem is that R on US Windows does not read *any* text file that
> > contains *any* foreign characters. It simply reads the first consecutive n
> > ASCII characters and then throws a warning once it reached a foreign
> > character:
> > 
> > > test <- read.table("test.txt", sep=";", dec=",", quote="",
> > fileEncoding="UTF-8")
> > Warning messages:
> > 1: In read.table("test.txt", sep = ";", dec = ",", quote = "", fileEncoding
> > = "UTF-8") :
> >   invalid input found on input connection 'test.txt'
> > 2: In read.table("test.txt", sep = ";", dec = ",", quote = "", fileEncoding
> > = "UTF-8") :
> >   incomplete final line found by readTableHeader on 'test.txt'
> > > print(test)
> >        V1
> > 1 english
> > 
> > > Sys.getlocale()
> >    [1] "LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> > States.1252;
> >      LC_MONETARY=English_United
> > States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252"
> > 
> > 
> > It is important to note that that R on linux will read UTF-8 as well as
> > exotic character sets without a problem. I've tried it with the exact same
> > files (one was UTF-8 and another was OEM866 Cyrillic).
> > 
> > If I do not include the fileEncoding parameter, read.table will read the
> > whole CSV file. But naturally it will read it wrong because it does not
> > know the encoding. So whenever I try to specify the fileEncoding, R will
> > throw the warnings and stop once it reaches a foreign character. It's the
> > same story with all international character encodings.
> > Other users on stackexchange have reported exactly the same issue.
> > 
> > 
> > Is anyone here who is on a US version of Windows able to import files with
> > foreign characters? Please let me know.
> A reproducible example would have helped, as requested by the posting
> guide.
> 
> Though I am also experiencing the same problem after saving the data
> below to a CSV file encoded in UTF-8 (you can do this using even the
> Notepad):
> "?","?"
> 1,10
> 2,20
> 
> This is on a Windows 7 box using French locale, but same codepage 1252
> as yours. What is interesting is that reading the file using
> readLines(file("myFile.csv", encoding="UTF-8"))
> gives no invalid characters. So there must be a bug in read.table().
> 
> 
> But I must note I do not experience issues with French accentuated
> characters like "?" ("\Ue9"). On the contrary, reading Armenian
> characters like "?" ("\U531") gives weird results: the character appears
> as <U+0531> instead of ?.
> 
> Self-contained example, writing the file and reading it back from R:
> tmpfile <- tempfile()
> writeLines("\U531", file(tmpfile, "w", encoding="UTF-8"))
> readLines(file(tmpfile, encoding="UTF-8"))
> # "<U+0531>"
> 
> The same phenomenon happens when creating a data frame from this
> character (as noted on StackExchange):
> data.frame("\U531")
> 
> So my conclusion is that maybe Windows does not really support Unicode
> characters that are not "relevant" for your current locale. And that may
> have created bugs in the way R handles them in read.table(). R
> developers can probably tell us more about it.
After some more investigation, one part of the problem can be traced
back to scan() (with myFile.csv filled as described above):
scan("myFile.csv", encoding="UTF-8", sep=",", nlines=1)
# Read 2 items
# [1] "?" "?"

Equivalent, but nonsensical to me:
scan("myFile.csv", fileEncoding="CP1252", encoding="UTF-8", sep=",", nlines=1)
# Read 2 items
# [1] "?" "?"

scan("myFile.csv", fileEncoding="UTF-8", sep=",", nlines=1)
# Read 0 items
# character(0)
# Warning message:
# In scan(file, what, nmax, sep, dex, quote, skip, nlines, na.strings,  :
#  invalid input found on input connection 'myFile.csv'


So there seem to be one part of the issue in scan(), which for some
reason does not work when passed fileEncoding="UTF-8"; and another part
in read.table(), which transforms "?" ("\U531") into "X.U.0531.",
probably via make.names(), since:
make.names("\U531")
# "X.U.0531."


Does this make sense to R-core members?


Regards


From agoijman at cnia.inta.gov.ar  Mon Sep 16 17:09:21 2013
From: agoijman at cnia.inta.gov.ar (Andrea Goijman)
Date: Mon, 16 Sep 2013 11:09:21 -0400
Subject: [R] Aggregate rows with same fields, within factors
Message-ID: <CA+vCKnXKudUjeA0E_otpD70kevY_WJXk=DeadZ+1_6h-usTkUw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130916/7def43c9/attachment.pl>

From smartpink111 at yahoo.com  Mon Sep 16 17:22:22 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 16 Sep 2013 08:22:22 -0700 (PDT)
Subject: [R] Aggregate rows with same fields, within factors
In-Reply-To: <CA+vCKnXKudUjeA0E_otpD70kevY_WJXk=DeadZ+1_6h-usTkUw@mail.gmail.com>
References: <CA+vCKnXKudUjeA0E_otpD70kevY_WJXk=DeadZ+1_6h-usTkUw@mail.gmail.com>
Message-ID: <1379344942.80776.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Try:


?aggregate(IND~.,data=net1,sum)
?? CAMP LOTE HAB TRANS?????? ORDEN IND
1??? C1?? B1?? C??? C1?????????????? 0
2??? C1?? B1?? B??? B3?????? ACARI?? 3
3??? C1?? B1?? B??? B1???? ARANEAE?? 1
4??? C1?? B1?? B??? B3???? ARANEAE?? 2
5??? C1?? B1?? B??? B3? COLEOPTERA?? 2
6??? C1?? B1?? B??? B1???? DIPTERA? 27
7??? C1?? B1?? B??? B3???? DIPTERA? 11
8??? C1?? B1?? C??? C2???? DIPTERA?? 3
9??? C1?? B1?? B??? B1?? HEMIPTERA? 11
10?? C1?? B1?? B??? B3?? HEMIPTERA 231
11?? C1?? B1?? C??? C2?? HEMIPTERA 147
12?? C1?? B1?? B??? B1 HYMENOPTERA?? 8
13?? C1?? B1?? B??? B3 HYMENOPTERA?? 2
14?? C1?? B1?? C??? C2 HYMENOPTERA?? 1
15?? C1?? B1?? B??? B1 LEPIDOPTERA?? 1
16?? C1?? B1?? B??? B1? NEUROPTERA?? 1
17?? C1?? B1?? B??? B1? ORTHOPTERA?? 2
18?? C1?? B1?? B??? B3? ORTHOPTERA?? 1


A.K.

----- Original Message -----
From: Andrea Goijman <agoijman at cnia.inta.gov.ar>
To: R help <r-help at r-project.org>
Cc: 
Sent: Monday, September 16, 2013 11:09 AM
Subject: [R] Aggregate rows with same fields, within factors

Dear R list,

I want to aggregate the number of individuals 'IND' of the same ORDER,
within each site and season CAMP,TRANS... but I also want to keep record of
the habitat HAB and LOTE

For example I have this:

? ? ? ?  CAMP LOTE HAB TRANS IND? ? ?  ORDEN
1765?  C1?  B1?  B? ? B1?  7?  HEMIPTERA
1766?  C1?  B1?  B? ? B1?  7? ?  DIPTERA
1767?  C1?  B1?  B? ? B1?  1? ?  DIPTERA
1768?  C1?  B1?  B? ? B1?  1? NEUROPTERA
1769?  C1?  B1?  B? ? B1?  1?  HEMIPTERA
1770?  C1?  B1?  B? ? B1?  5? ?  DIPTERA
1771?  C1?  B1?  B? ? B1?  1? ?  DIPTERA

And I want this

? ? ? ? ? CAMP LOTE HAB TRANS IND? ? ?  ORDEN
1765?  C1?  B1?  B? ? B1?  8?  HEMIPTERA
1766?  C1?  B1?  B? ? B1?  14? ?  DIPTERA
1768?  C1?  B1?  B? ? B1?  1? NEUROPTERA


I'm using aggregate the way I show below, but it is not working, and I
cannot figure out why.

Thanks!

Andrea



net1<-structure(list(CAMP = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("C1",
"C2", "C3", "C4"), class = "factor"), LOTE = structure(c(1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L), .Label = c("B1", "B4", "B5", "F7", "G6", "G8", "R10", "W9",
"Z2", "Z3"), class = "factor"), HAB = structure(c(1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label =
c("B",
"C"), class = "factor"), TRANS = structure(c(1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L,
2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L), .Label = c("B1",
"B2", "B3", "C1", "C2", "C3"), class = "factor"), IND = c(2L,
6L, 7L, 1L, 1L, 7L, 7L, 1L, 1L, 1L, 5L, 1L, 1L, 1L, 4L, 1L, 2L,
1L, 1L, NA, NA, NA, NA, 28L, 4L, 2L, 1L, 3L, 193L, 1L, 2L, 7L,
2L, 1L, 5L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 62L, 1L, 1L, 1L, 80L,
1L, 1L, 4L), ORDEN = structure(c(9L, 10L, 8L, 8L, 15L, 9L, 8L,
8L, 12L, 9L, 8L, 8L, 11L, 3L, 8L, 8L, 10L, 9L, 15L, 1L, 1L, 1L,
1L, 9L, 8L, 8L, 5L, 2L, 9L, 10L, 3L, 9L, 9L, 9L, 8L, 10L, 5L,
15L, 1L, 1L, 1L, 1L, 9L, 8L, 10L, 9L, 9L, 8L, 8L, 9L), .Label = c("",
"ACARI", "ARANEAE", "CHILOGNATHA", "COLEOPTERA", "DERMAPTERA",
"DICTYOPTERA", "DIPTERA", "HEMIPTERA", "HYMENOPTERA", "LEPIDOPTERA",
"NEUROPTERA", "NN", "ODONATA", "ORTHOPTERA", "PSOCOPTERA", "STREPSIPTERA",
"THYSANOPTERA", "TRICHOPTERA"), class = "factor")), .Names = c("CAMP",
"LOTE", "HAB", "TRANS", "IND", "ORDEN"), row.names = c(1760L,
1761L, 1762L, 1763L, 1764L, 1765L, 1766L, 1767L, 1768L, 1769L,
1770L, 1771L, 1772L, 1773L, 1920L, 1921L, 1922L, 1923L, 1924L,
1774L, 1775L, 1776L, 1777L, 1778L, 1779L, 1780L, 1781L, 1782L,
1783L, 1784L, 1785L, 1786L, 1787L, 1788L, 1789L, 1790L, 1791L,
1925L, 1731L, 1732L, 1733L, 1734L, 1735L, 1736L, 1737L, 1738L,
1739L, 1740L, 1741L, 1742L), class = "data.frame")

#generate grouping list
b <- list(net1$CAMP, net1$LOTE, net1$HAB, net1$TRANS, net1$ORDEN)

#aggregate data
net2 <- aggregate(x = net1, by =(b), FUN = "sum")

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From agoijman at cnia.inta.gov.ar  Mon Sep 16 17:42:07 2013
From: agoijman at cnia.inta.gov.ar (Andrea Goijman)
Date: Mon, 16 Sep 2013 11:42:07 -0400
Subject: [R] Aggregate rows with same fields, within factors
In-Reply-To: <1379344942.80776.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <CA+vCKnXKudUjeA0E_otpD70kevY_WJXk=DeadZ+1_6h-usTkUw@mail.gmail.com>
	<1379344942.80776.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <CA+vCKnXekYBkfvcQYTxGwh1WGPxJM8YjO2YCPv7FKDszTvcn6Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130916/4ea28b88/attachment.pl>

From istazahn at gmail.com  Mon Sep 16 17:56:41 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 16 Sep 2013 11:56:41 -0400
Subject: [R] Non-ACSII characters in R on Windows
In-Reply-To: <1379342337.26458.13.camel@milan>
References: <CAGKs4siL8rasbtsCgEfX=haESyAD5=7BHZv1R9CqeABS560aSQ@mail.gmail.com>
	<1379320808.17743.59.camel@milan> <1379342337.26458.13.camel@milan>
Message-ID: <CA+vqiLERZUJOZ+xpCUY1AQ1-EQ6662hcH2tozspAmZK06f+u_Q@mail.gmail.com>

UTF-8 on windows is a huge pain, this bites me often. Usually I give
up and do the analysis on a Linux server. In previous struggles with
this I've found this blog post enlightening:
https://tomizonor.wordpress.com/2013/04/17/file-utf8-windows/

Best,
Ista

On Mon, Sep 16, 2013 at 10:38 AM, Milan Bouchet-Valat <nalimilan at club.fr> wrote:
> Le lundi 16 septembre 2013 ? 10:40 +0200, Milan Bouchet-Valat a ?crit :
>> Le vendredi 13 septembre 2013 ? 23:38 +0400, Maxim Linchits a ?crit :
>> > This is a condensed version of the same question on stackexchange here:
>> > http://stackoverflow.com/questions/18789330/r-on-windows-character-encoding-hell
>> > If you've already stumbled upon it feel free to ignore.
>> >
>> > My problem is that R on US Windows does not read *any* text file that
>> > contains *any* foreign characters. It simply reads the first consecutive n
>> > ASCII characters and then throws a warning once it reached a foreign
>> > character:
>> >
>> > > test <- read.table("test.txt", sep=";", dec=",", quote="",
>> > fileEncoding="UTF-8")
>> > Warning messages:
>> > 1: In read.table("test.txt", sep = ";", dec = ",", quote = "", fileEncoding
>> > = "UTF-8") :
>> >   invalid input found on input connection 'test.txt'
>> > 2: In read.table("test.txt", sep = ";", dec = ",", quote = "", fileEncoding
>> > = "UTF-8") :
>> >   incomplete final line found by readTableHeader on 'test.txt'
>> > > print(test)
>> >        V1
>> > 1 english
>> >
>> > > Sys.getlocale()
>> >    [1] "LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
>> > States.1252;
>> >      LC_MONETARY=English_United
>> > States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252"
>> >
>> >
>> > It is important to note that that R on linux will read UTF-8 as well as
>> > exotic character sets without a problem. I've tried it with the exact same
>> > files (one was UTF-8 and another was OEM866 Cyrillic).
>> >
>> > If I do not include the fileEncoding parameter, read.table will read the
>> > whole CSV file. But naturally it will read it wrong because it does not
>> > know the encoding. So whenever I try to specify the fileEncoding, R will
>> > throw the warnings and stop once it reaches a foreign character. It's the
>> > same story with all international character encodings.
>> > Other users on stackexchange have reported exactly the same issue.
>> >
>> >
>> > Is anyone here who is on a US version of Windows able to import files with
>> > foreign characters? Please let me know.
>> A reproducible example would have helped, as requested by the posting
>> guide.
>>
>> Though I am also experiencing the same problem after saving the data
>> below to a CSV file encoded in UTF-8 (you can do this using even the
>> Notepad):
>> "?","?"
>> 1,10
>> 2,20
>>
>> This is on a Windows 7 box using French locale, but same codepage 1252
>> as yours. What is interesting is that reading the file using
>> readLines(file("myFile.csv", encoding="UTF-8"))
>> gives no invalid characters. So there must be a bug in read.table().
>>
>>
>> But I must note I do not experience issues with French accentuated
>> characters like "?" ("\Ue9"). On the contrary, reading Armenian
>> characters like "?" ("\U531") gives weird results: the character appears
>> as <U+0531> instead of ?.
>>
>> Self-contained example, writing the file and reading it back from R:
>> tmpfile <- tempfile()
>> writeLines("\U531", file(tmpfile, "w", encoding="UTF-8"))
>> readLines(file(tmpfile, encoding="UTF-8"))
>> # "<U+0531>"
>>
>> The same phenomenon happens when creating a data frame from this
>> character (as noted on StackExchange):
>> data.frame("\U531")
>>
>> So my conclusion is that maybe Windows does not really support Unicode
>> characters that are not "relevant" for your current locale. And that may
>> have created bugs in the way R handles them in read.table(). R
>> developers can probably tell us more about it.
> After some more investigation, one part of the problem can be traced
> back to scan() (with myFile.csv filled as described above):
> scan("myFile.csv", encoding="UTF-8", sep=",", nlines=1)
> # Read 2 items
> # [1] "?" "?"
>
> Equivalent, but nonsensical to me:
> scan("myFile.csv", fileEncoding="CP1252", encoding="UTF-8", sep=",", nlines=1)
> # Read 2 items
> # [1] "?" "?"
>
> scan("myFile.csv", fileEncoding="UTF-8", sep=",", nlines=1)
> # Read 0 items
> # character(0)
> # Warning message:
> # In scan(file, what, nmax, sep, dex, quote, skip, nlines, na.strings,  :
> #  invalid input found on input connection 'myFile.csv'
>
>
> So there seem to be one part of the issue in scan(), which for some
> reason does not work when passed fileEncoding="UTF-8"; and another part
> in read.table(), which transforms "?" ("\U531") into "X.U.0531.",
> probably via make.names(), since:
> make.names("\U531")
> # "X.U.0531."
>
>
> Does this make sense to R-core members?
>
>
> Regards
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From noahsilverman at ucla.edu  Mon Sep 16 18:13:01 2013
From: noahsilverman at ucla.edu (Noah Silverman)
Date: Mon, 16 Sep 2013 09:13:01 -0700
Subject: [R] Console Output Formatting
In-Reply-To: <CAL9B2vetA=5X9=-gWYcqr3QvSAv=Hw0AAPUg4rWXOhwHWBahwQ@mail.gmail.com>
References: <C55AF251-862A-4967-BF6B-2D460C7D3449@ucla.edu>
	<5227AFB6.5050808@stats.ox.ac.uk>
	<CAL9B2vetA=5X9=-gWYcqr3QvSAv=Hw0AAPUg4rWXOhwHWBahwQ@mail.gmail.com>
Message-ID: <FA43D454-F4B0-434E-B8EE-1072AFBCA815@ucla.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130916/9b02c124/attachment.pl>

From 538280 at gmail.com  Mon Sep 16 18:20:08 2013
From: 538280 at gmail.com (Greg Snow)
Date: Mon, 16 Sep 2013 10:20:08 -0600
Subject: [R] Regression model for predicting ranks of the dependent
	variable
In-Reply-To: <BAY168-W133889764D7F2EA374101A497240@phx.gbl>
References: <BAY168-W133889764D7F2EA374101A497240@phx.gbl>
Message-ID: <CAFEqCdwTEi4r1qnWXiSCSQdOr8nT9xgX_2Skxyd12qro6QWGhA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130916/34b026ad/attachment.pl>

From cgenolin at u-paris10.fr  Mon Sep 16 14:11:45 2013
From: cgenolin at u-paris10.fr (Christophe Genolini)
Date: Mon, 16 Sep 2013 14:11:45 +0200
Subject: [R] microbenchmark
Message-ID: <5236F581.2020300@u-paris10.fr>

Hi the list,

I am using the function microbenchmark to measure the performance of some code. But I notice that 
the first execution of the code takes much longueur than the next executions.
I compare it to several executions of the code :

--- 8< ----------
A <- matrix(1:9,3)
nbReroll <- 1000
temps <- matrix(NA,1000,2)
temps[,1] <- microbenchmark(colMeans(A),times=nbReroll)$time

for(j in 1:nbReroll){
     temps[j,2] <- microbenchmark(colMeans(A),times=1)$time
}

--- 8< -----------
Here is a plot of the result I get.
  - In red, temps[,1], that is microbenchmarck(...,times=1000)
  - In blue temps[,2], that is for(i in 1:1000)microbenchmark(...times=1)


So why is there such a bid difference? What is the correct execution time for my instruction?

Christophe

-- 
Christophe Genolini
Ma?tre de conf?rences en bio-statistique
Vice pr?sident Communication interne et animation du campus
Universit? Paris Ouest Nanterre La D?fense


From a2_n2_k2 at yahoo.co.in  Mon Sep 16 14:45:22 2013
From: a2_n2_k2 at yahoo.co.in (amit khatri)
Date: Mon, 16 Sep 2013 20:45:22 +0800 (SGT)
Subject: [R] Help to run bootstrap in R
Message-ID: <1379335522.13105.YahooMailNeo@web194605.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130916/b5ce27df/attachment.pl>

From mlinchits at gmail.com  Mon Sep 16 18:04:46 2013
From: mlinchits at gmail.com (Maxim Linchits)
Date: Mon, 16 Sep 2013 20:04:46 +0400
Subject: [R] Non-ACSII characters in R on Windows
In-Reply-To: <1379342337.26458.13.camel@milan>
References: <CAGKs4siL8rasbtsCgEfX=haESyAD5=7BHZv1R9CqeABS560aSQ@mail.gmail.com>
	<1379320808.17743.59.camel@milan> <1379342337.26458.13.camel@milan>
Message-ID: <CAGKs4shYcB=eEON0cNXK9COs5yrNe7DkSZHOPnqU+6V_gaqbLQ@mail.gmail.com>

Here is that old post:
http://r.789695.n4.nabble.com/read-csv-and-FileEncoding-in-Windows-version-of-R-2-13-0-td3567177.html

A taste: "Again, the issue is that opening this UTF-8 encoded file
under R 2.13.0 yields an error, but opening it under R 2.12.2 works
without any issues. (...)"

On Mon, Sep 16, 2013 at 6:38 PM, Milan Bouchet-Valat <nalimilan at club.fr> wrote:
> Le lundi 16 septembre 2013 ? 10:40 +0200, Milan Bouchet-Valat a ?crit :
>> Le vendredi 13 septembre 2013 ? 23:38 +0400, Maxim Linchits a ?crit :
>> > This is a condensed version of the same question on stackexchange here:
>> > http://stackoverflow.com/questions/18789330/r-on-windows-character-encoding-hell
>> > If you've already stumbled upon it feel free to ignore.
>> >
>> > My problem is that R on US Windows does not read *any* text file that
>> > contains *any* foreign characters. It simply reads the first consecutive n
>> > ASCII characters and then throws a warning once it reached a foreign
>> > character:
>> >
>> > > test <- read.table("test.txt", sep=";", dec=",", quote="",
>> > fileEncoding="UTF-8")
>> > Warning messages:
>> > 1: In read.table("test.txt", sep = ";", dec = ",", quote = "", fileEncoding
>> > = "UTF-8") :
>> >   invalid input found on input connection 'test.txt'
>> > 2: In read.table("test.txt", sep = ";", dec = ",", quote = "", fileEncoding
>> > = "UTF-8") :
>> >   incomplete final line found by readTableHeader on 'test.txt'
>> > > print(test)
>> >        V1
>> > 1 english
>> >
>> > > Sys.getlocale()
>> >    [1] "LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
>> > States.1252;
>> >      LC_MONETARY=English_United
>> > States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252"
>> >
>> >
>> > It is important to note that that R on linux will read UTF-8 as well as
>> > exotic character sets without a problem. I've tried it with the exact same
>> > files (one was UTF-8 and another was OEM866 Cyrillic).
>> >
>> > If I do not include the fileEncoding parameter, read.table will read the
>> > whole CSV file. But naturally it will read it wrong because it does not
>> > know the encoding. So whenever I try to specify the fileEncoding, R will
>> > throw the warnings and stop once it reaches a foreign character. It's the
>> > same story with all international character encodings.
>> > Other users on stackexchange have reported exactly the same issue.
>> >
>> >
>> > Is anyone here who is on a US version of Windows able to import files with
>> > foreign characters? Please let me know.
>> A reproducible example would have helped, as requested by the posting
>> guide.
>>
>> Though I am also experiencing the same problem after saving the data
>> below to a CSV file encoded in UTF-8 (you can do this using even the
>> Notepad):
>> "?","?"
>> 1,10
>> 2,20
>>
>> This is on a Windows 7 box using French locale, but same codepage 1252
>> as yours. What is interesting is that reading the file using
>> readLines(file("myFile.csv", encoding="UTF-8"))
>> gives no invalid characters. So there must be a bug in read.table().
>>
>>
>> But I must note I do not experience issues with French accentuated
>> characters like "?" ("\Ue9"). On the contrary, reading Armenian
>> characters like "?" ("\U531") gives weird results: the character appears
>> as <U+0531> instead of ?.
>>
>> Self-contained example, writing the file and reading it back from R:
>> tmpfile <- tempfile()
>> writeLines("\U531", file(tmpfile, "w", encoding="UTF-8"))
>> readLines(file(tmpfile, encoding="UTF-8"))
>> # "<U+0531>"
>>
>> The same phenomenon happens when creating a data frame from this
>> character (as noted on StackExchange):
>> data.frame("\U531")
>>
>> So my conclusion is that maybe Windows does not really support Unicode
>> characters that are not "relevant" for your current locale. And that may
>> have created bugs in the way R handles them in read.table(). R
>> developers can probably tell us more about it.
> After some more investigation, one part of the problem can be traced
> back to scan() (with myFile.csv filled as described above):
> scan("myFile.csv", encoding="UTF-8", sep=",", nlines=1)
> # Read 2 items
> # [1] "?" "?"
>
> Equivalent, but nonsensical to me:
> scan("myFile.csv", fileEncoding="CP1252", encoding="UTF-8", sep=",", nlines=1)
> # Read 2 items
> # [1] "?" "?"
>
> scan("myFile.csv", fileEncoding="UTF-8", sep=",", nlines=1)
> # Read 0 items
> # character(0)
> # Warning message:
> # In scan(file, what, nmax, sep, dex, quote, skip, nlines, na.strings,  :
> #  invalid input found on input connection 'myFile.csv'
>
>
> So there seem to be one part of the issue in scan(), which for some
> reason does not work when passed fileEncoding="UTF-8"; and another part
> in read.table(), which transforms "?" ("\U531") into "X.U.0531.",
> probably via make.names(), since:
> make.names("\U531")
> # "X.U.0531."
>
>
> Does this make sense to R-core members?
>
>
> Regards


From jun.shen.ut at gmail.com  Mon Sep 16 18:26:58 2013
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Mon, 16 Sep 2013 12:26:58 -0400
Subject: [R] Draw two separate legends in xyplot
Message-ID: <CAMCXXmrHQ38fA-hLART6eyVi=RrOa8q-T9y5XO+GsB6tBnn3KQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130916/ed6b55de/attachment.pl>

From smartpink111 at yahoo.com  Mon Sep 16 18:25:21 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 16 Sep 2013 09:25:21 -0700 (PDT)
Subject: [R] Aggregate rows with same fields, within factors
In-Reply-To: <CA+vCKnXekYBkfvcQYTxGwh1WGPxJM8YjO2YCPv7FKDszTvcn6Q@mail.gmail.com>
References: <CA+vCKnXKudUjeA0E_otpD70kevY_WJXk=DeadZ+1_6h-usTkUw@mail.gmail.com>
	<1379344942.80776.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<CA+vCKnXekYBkfvcQYTxGwh1WGPxJM8YjO2YCPv7FKDszTvcn6Q@mail.gmail.com>
Message-ID: <1379348721.36771.YahooMailNeo@web142606.mail.bf1.yahoo.com>

HI,
Not sure how you wanted the results with the rows having NAs.

net1[,sapply(net1,is.factor)]<-lapply(net1[,sapply(net1,is.factor)],as.character)
?with(net1,aggregate(IND,list(CAMP,LOTE,HAB,TRANS,ORDEN),FUN=sum))
#or
with(net1,aggregate(IND,list(CAMP,LOTE,HAB,TRANS,ORDEN),FUN=sum,na.rm=TRUE))
A.K.


________________________________
From: Andrea Goijman <agoijman at cnia.inta.gov.ar>
To: arun <smartpink111 at yahoo.com> 
Cc: R help <r-help at r-project.org> 
Sent: Monday, September 16, 2013 11:42 AM
Subject: Re: [R] Aggregate rows with same fields, within factors



it works, but it eliminates the rows with NA

is there a way to keep those??



On Mon, Sep 16, 2013 at 11:22 AM, arun <smartpink111 at yahoo.com> wrote:

Hi,
>Try:
>
>
>?aggregate(IND~.,data=net1,sum)
>?? CAMP LOTE HAB TRANS?????? ORDEN IND
>1??? C1?? B1?? C??? C1?????????????? 0
>2??? C1?? B1?? B??? B3?????? ACARI?? 3
>3??? C1?? B1?? B??? B1???? ARANEAE?? 1
>4??? C1?? B1?? B??? B3???? ARANEAE?? 2
>5??? C1?? B1?? B??? B3? COLEOPTERA?? 2
>6??? C1?? B1?? B??? B1???? DIPTERA? 27
>7??? C1?? B1?? B??? B3???? DIPTERA? 11
>8??? C1?? B1?? C??? C2???? DIPTERA?? 3
>9??? C1?? B1?? B??? B1?? HEMIPTERA? 11
>10?? C1?? B1?? B??? B3?? HEMIPTERA 231
>11?? C1?? B1?? C??? C2?? HEMIPTERA 147
>12?? C1?? B1?? B??? B1 HYMENOPTERA?? 8
>13?? C1?? B1?? B??? B3 HYMENOPTERA?? 2
>14?? C1?? B1?? C??? C2 HYMENOPTERA?? 1
>15?? C1?? B1?? B??? B1 LEPIDOPTERA?? 1
>16?? C1?? B1?? B??? B1? NEUROPTERA?? 1
>17?? C1?? B1?? B??? B1? ORTHOPTERA?? 2
>18?? C1?? B1?? B??? B3? ORTHOPTERA?? 1
>
>
>A.K.
>
>
>----- Original Message -----
>From: Andrea Goijman <agoijman at cnia.inta.gov.ar>
>To: R help <r-help at r-project.org>
>Cc:
>Sent: Monday, September 16, 2013 11:09 AM
>Subject: [R] Aggregate rows with same fields, within factors
>
>Dear R list,
>
>I want to aggregate the number of individuals 'IND' of the same ORDER,
>within each site and season CAMP,TRANS... but I also want to keep record of
>the habitat HAB and LOTE
>
>For example I have this:
>
>? ? ? ? ?CAMP LOTE HAB TRANS IND? ? ? ?ORDEN
>1765? ?C1? ?B1? ?B? ? B1? ?7? ?HEMIPTERA
>1766? ?C1? ?B1? ?B? ? B1? ?7? ? ?DIPTERA
>1767? ?C1? ?B1? ?B? ? B1? ?1? ? ?DIPTERA
>1768? ?C1? ?B1? ?B? ? B1? ?1? NEUROPTERA
>1769? ?C1? ?B1? ?B? ? B1? ?1? ?HEMIPTERA
>1770? ?C1? ?B1? ?B? ? B1? ?5? ? ?DIPTERA
>1771? ?C1? ?B1? ?B? ? B1? ?1? ? ?DIPTERA
>
>And I want this
>
>? ? ? ? ? CAMP LOTE HAB TRANS IND? ? ? ?ORDEN
>1765? ?C1? ?B1? ?B? ? B1? ?8? ?HEMIPTERA
>1766? ?C1? ?B1? ?B? ? B1? ?14? ? ?DIPTERA
>1768? ?C1? ?B1? ?B? ? B1? ?1? NEUROPTERA
>
>
>I'm using aggregate the way I show below, but it is not working, and I
>cannot figure out why.
>
>Thanks!
>
>Andrea
>
>
>
>net1<-structure(list(CAMP = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("C1",
>"C2", "C3", "C4"), class = "factor"), LOTE = structure(c(1L,
>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>1L), .Label = c("B1", "B4", "B5", "F7", "G6", "G8", "R10", "W9",
>"Z2", "Z3"), class = "factor"), HAB = structure(c(1L, 1L, 1L,
>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label =
>c("B",
>"C"), class = "factor"), TRANS = structure(c(1L, 1L, 1L, 1L,
>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L,
>2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L), .Label = c("B1",
>"B2", "B3", "C1", "C2", "C3"), class = "factor"), IND = c(2L,
>6L, 7L, 1L, 1L, 7L, 7L, 1L, 1L, 1L, 5L, 1L, 1L, 1L, 4L, 1L, 2L,
>1L, 1L, NA, NA, NA, NA, 28L, 4L, 2L, 1L, 3L, 193L, 1L, 2L, 7L,
>2L, 1L, 5L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 62L, 1L, 1L, 1L, 80L,
>1L, 1L, 4L), ORDEN = structure(c(9L, 10L, 8L, 8L, 15L, 9L, 8L,
>8L, 12L, 9L, 8L, 8L, 11L, 3L, 8L, 8L, 10L, 9L, 15L, 1L, 1L, 1L,
>1L, 9L, 8L, 8L, 5L, 2L, 9L, 10L, 3L, 9L, 9L, 9L, 8L, 10L, 5L,
>15L, 1L, 1L, 1L, 1L, 9L, 8L, 10L, 9L, 9L, 8L, 8L, 9L), .Label = c("",
>"ACARI", "ARANEAE", "CHILOGNATHA", "COLEOPTERA", "DERMAPTERA",
>"DICTYOPTERA", "DIPTERA", "HEMIPTERA", "HYMENOPTERA", "LEPIDOPTERA",
>"NEUROPTERA", "NN", "ODONATA", "ORTHOPTERA", "PSOCOPTERA", "STREPSIPTERA",
>"THYSANOPTERA", "TRICHOPTERA"), class = "factor")), .Names = c("CAMP",
>"LOTE", "HAB", "TRANS", "IND", "ORDEN"), row.names = c(1760L,
>1761L, 1762L, 1763L, 1764L, 1765L, 1766L, 1767L, 1768L, 1769L,
>1770L, 1771L, 1772L, 1773L, 1920L, 1921L, 1922L, 1923L, 1924L,
>1774L, 1775L, 1776L, 1777L, 1778L, 1779L, 1780L, 1781L, 1782L,
>1783L, 1784L, 1785L, 1786L, 1787L, 1788L, 1789L, 1790L, 1791L,
>1925L, 1731L, 1732L, 1733L, 1734L, 1735L, 1736L, 1737L, 1738L,
>1739L, 1740L, 1741L, 1742L), class = "data.frame")
>
>#generate grouping list
>b <- list(net1$CAMP, net1$LOTE, net1$HAB, net1$TRANS, net1$ORDEN)
>
>#aggregate data
>net2 <- aggregate(x = net1, by =(b), FUN = "sum")
>
>??? [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>


-- 

-----Lic. Andrea Paula Goijman,?PhD Candidate
Grupo Ecolog?a, Biodiversidad y Gesti?n Ambiental en Agroecosistemas
Instituto de Recursos Biol?gicos
CIRN - INTA Castelar, Argentina
agoijman at cnia.inta.gov.arhttp://inta.gob.ar/personas/goijman.andrea/


D.B. Warnell School of Forestry and Natural Resources
USGS Georgia Cooperative Fish and Wildlife Research Unit

University of Georgia
Athens, GA 30602 USA
Tel. +706.206.4805
Skype: andrea.goijman
andreapg at uga.edu


From 538280 at gmail.com  Mon Sep 16 18:45:55 2013
From: 538280 at gmail.com (Greg Snow)
Date: Mon, 16 Sep 2013 10:45:55 -0600
Subject: [R] Executing a code until a new user input aborts it
	(readlines?)
In-Reply-To: <CAFn+=0SsCrO0+G74R85JnXi=jEfimTpSa999JtrdUL9mD8dARA@mail.gmail.com>
References: <CAFn+=0SsCrO0+G74R85JnXi=jEfimTpSa999JtrdUL9mD8dARA@mail.gmail.com>
Message-ID: <CAFEqCdwFF=9UkqfVBhXkxZpC7ObVzR7js9NhZ-aDLSo205KCsQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130916/1c7cda3f/attachment.pl>

From Markus.Gesmann at lloyds.com  Mon Sep 16 19:02:13 2013
From: Markus.Gesmann at lloyds.com (Gesmann, Markus)
Date: Mon, 16 Sep 2013 17:02:13 +0000
Subject: [R] Draw two separate legends in xyplot
In-Reply-To: <CAMCXXmrHQ38fA-hLART6eyVi=RrOa8q-T9y5XO+GsB6tBnn3KQ@mail.gmail.com>
References: <CAMCXXmrHQ38fA-hLART6eyVi=RrOa8q-T9y5XO+GsB6tBnn3KQ@mail.gmail.com>
Message-ID: <2D1AC19CDA3D5643B9D7AE596C377B280C0A67A8@GBS0039303.lloyds.net>

Here is an example using grid functions, based on an example from Deepayan (https://stat.ethz.ch/pipermail/r-help/2005-April/069459.html)
I hope this helps.

library(grid)
library(lattice)

ft <-
  grid.layout(nrow = 2, ncol = 4,
              heights = unit(rep(1, 2), "lines"),
              widths =
                unit(c(2, 1, 2, 1),
                     c("cm", "strwidth", "cm",
                       "strwidth", "cm", "strwidth"),
                     data = list(NULL, "John", NULL,
                                 "George")))

foo <- frameGrob(layout = ft)
foo <- placeGrob(foo,
                 pointsGrob(.5, .5, pch=19,
                            gp = gpar(col="red", cex=0.5)),
                 row = 1, col = 1)
foo <- placeGrob(foo,
                 linesGrob(c(0.2, 0.8), c(.5, .5),
                           gp = gpar(col="blue")),
                 row = 2, col = 1)
foo <- placeGrob(foo,
                 linesGrob(c(0.2, 0.8), c(.5, .5),
                           gp = gpar(col="green")), 
                 row = 1, col = 3)
foo <- placeGrob(foo,
                 linesGrob(c(0.2, 0.8), c(.5, .5),
                           gp = gpar(col="brown")), 
                 row = 2, col = 3)
foo <- placeGrob(foo,
                 textGrob(lab = "John"), 
                 row = 1, col = 2)
foo <- placeGrob(foo,
                 textGrob(lab = "Paul"), 
                 row = 2, col = 2)
foo <- placeGrob(foo,
                 textGrob(lab = "George"), 
                 row = 1, col = 4)
foo <- placeGrob(foo,
                 textGrob(lab = "Ringo"), 
                 row = 2, col = 4)
fb <-
  grid.layout(nrow = 1, ncol = 2,
              heights = unit(1, "lines"),
              widths =
                unit(c(2, 1),
                     c("cm", "strwidth"),
                     data = list(NULL, "The Beatles")))

boo <- frameGrob(layout = fb)
boo <- placeGrob(boo,
                 rectGrob(width = 0.6, 
                          gp = gpar(col="orange",
                                    fill = "orange")), 
                 row = 1, col = 1)

boo <- placeGrob(boo,
                 textGrob(lab = "The Beatles"), 
                 row = 1, col = 2)

xyplot(1 ~ 1, legend = list(top = list(fun = foo),
                            bottom = list(fun = boo)))


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Jun Shen
Sent: 16 September 2013 17:27
To: R-help
Subject: [R] Draw two separate legends in xyplot

Hi all,

I wonder if there is a way to draw two separate legends in xyplot as I would like to separate the legend for data and the legend for reference lines I add. I can use key argument to draw one legend with everything together. What I really want is to put one legend at the bottom and the other on the top. Thanks.

Jun

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://urldefense.proofpoint.com/v1/url?u=https://stat.ethz.ch/mailman/listinfo/r-help&k=VTIXiGvdT7U4yPSpeHcrHQ%3D%3D%0A&r=dUkLGPeM%2BYkyyiRRq50yGs%2BmEf8kG%2FyCNQPwZn%2FaQD0%3D%0A&m=GyDRn8AygWnkEHHpZi6XchB6xBiliVWVxVbKN7b8MsE%3D%0A&s=7806cd15bf1d4ce1282cd1e8b2b1328f73cb36ee69b3ecb8640a64bb2e457ce1
PLEASE do read the posting guide https://urldefense.proofpoint.com/v1/url?u=http://www.r-project.org/posting-guide.html&k=VTIXiGvdT7U4yPSpeHcrHQ%3D%3D%0A&r=dUkLGPeM%2BYkyyiRRq50yGs%2BmEf8kG%2FyCNQPwZn%2FaQD0%3D%0A&m=GyDRn8AygWnkEHHpZi6XchB6xBiliVWVxVbKN7b8MsE%3D%0A&s=35157497e0e6679cdcd3116ad32a43ca58adf3889ab0caa0d6a530b87001a008
and provide commented, minimal, self-contained, reproducible code.

----------------------------------------------------------------------
The information in this E-Mail and in any attachments is...{{dropped:19}}


From ruipbarradas at sapo.pt  Mon Sep 16 19:36:01 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 16 Sep 2013 18:36:01 +0100
Subject: [R] Help to run bootstrap in R
In-Reply-To: <1379335522.13105.YahooMailNeo@web194605.mail.sg3.yahoo.com>
References: <1379335522.13105.YahooMailNeo@web194605.mail.sg3.yahoo.com>
Message-ID: <52374181.7080609@sapo.pt>

Hello,

As for a general purpose bootstrap routine, at an R prompt type the 
following.

library(boot)
?boot


Manu other boot strap functions from other packages are available. Good 
luck searching.


Hope this helps,

Rui Barradas

Em 16-09-2013 13:45, amit khatri escreveu:
> Hello R Team,
>                               Thanks
> for this gigantic software Called R. I am new to R software. My name is Amit
> Khatri and currently  I am working as a Research Student in
> Department of Economics University of Mumbai, Mumbai, India. I need your suggestion
> on How to use bootstrapfor DEA Efficiency score. Also help me to locate Bootstrap
> in R which I have already  downloaded and
> installed.
>
> Thanks  A Lot,
> With Regards
> From: Amit Khatri
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch.duncan at gmail.com  Mon Sep 16 19:39:53 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 16 Sep 2013 13:39:53 -0400
Subject: [R] Non-ACSII characters in R on Windows
In-Reply-To: <CAGKs4shYcB=eEON0cNXK9COs5yrNe7DkSZHOPnqU+6V_gaqbLQ@mail.gmail.com>
References: <CAGKs4siL8rasbtsCgEfX=haESyAD5=7BHZv1R9CqeABS560aSQ@mail.gmail.com>
	<1379320808.17743.59.camel@milan> <1379342337.26458.13.camel@milan>
	<CAGKs4shYcB=eEON0cNXK9COs5yrNe7DkSZHOPnqU+6V_gaqbLQ@mail.gmail.com>
Message-ID: <52374269.70804@gmail.com>

On 16/09/2013 12:04 PM, Maxim Linchits wrote:
> Here is that old post:
> http://r.789695.n4.nabble.com/read-csv-and-FileEncoding-in-Windows-version-of-R-2-13-0-td3567177.html

In that post, you'll see I asked for a sample file.  I never received 
any reply; presumably some spam filter didn't like what Alexander sent 
me, and Nabble doesn't archive any attachment.

Similarly, the Stackoverflow thread contains no sample data.

Could someone who is having this problem please put a small sample 
online for download?  As I told Alexander last time, my experiments with 
files I constructed myself showed no errors.

Duncan Murdoch

>
> A taste: "Again, the issue is that opening this UTF-8 encoded file
> under R 2.13.0 yields an error, but opening it under R 2.12.2 works
> without any issues. (...)"
>
> On Mon, Sep 16, 2013 at 6:38 PM, Milan Bouchet-Valat <nalimilan at club.fr> wrote:
> > Le lundi 16 septembre 2013 ? 10:40 +0200, Milan Bouchet-Valat a ?crit :
> >> Le vendredi 13 septembre 2013 ? 23:38 +0400, Maxim Linchits a ?crit :
> >> > This is a condensed version of the same question on stackexchange here:
> >> > http://stackoverflow.com/questions/18789330/r-on-windows-character-encoding-hell
> >> > If you've already stumbled upon it feel free to ignore.
> >> >
> >> > My problem is that R on US Windows does not read *any* text file that
> >> > contains *any* foreign characters. It simply reads the first consecutive n
> >> > ASCII characters and then throws a warning once it reached a foreign
> >> > character:
> >> >
> >> > > test <- read.table("test.txt", sep=";", dec=",", quote="",
> >> > fileEncoding="UTF-8")
> >> > Warning messages:
> >> > 1: In read.table("test.txt", sep = ";", dec = ",", quote = "", fileEncoding
> >> > = "UTF-8") :
> >> >   invalid input found on input connection 'test.txt'
> >> > 2: In read.table("test.txt", sep = ";", dec = ",", quote = "", fileEncoding
> >> > = "UTF-8") :
> >> >   incomplete final line found by readTableHeader on 'test.txt'
> >> > > print(test)
> >> >        V1
> >> > 1 english
> >> >
> >> > > Sys.getlocale()
> >> >    [1] "LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> >> > States.1252;
> >> >      LC_MONETARY=English_United
> >> > States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252"
> >> >
> >> >
> >> > It is important to note that that R on linux will read UTF-8 as well as
> >> > exotic character sets without a problem. I've tried it with the exact same
> >> > files (one was UTF-8 and another was OEM866 Cyrillic).
> >> >
> >> > If I do not include the fileEncoding parameter, read.table will read the
> >> > whole CSV file. But naturally it will read it wrong because it does not
> >> > know the encoding. So whenever I try to specify the fileEncoding, R will
> >> > throw the warnings and stop once it reaches a foreign character. It's the
> >> > same story with all international character encodings.
> >> > Other users on stackexchange have reported exactly the same issue.
> >> >
> >> >
> >> > Is anyone here who is on a US version of Windows able to import files with
> >> > foreign characters? Please let me know.
> >> A reproducible example would have helped, as requested by the posting
> >> guide.
> >>
> >> Though I am also experiencing the same problem after saving the data
> >> below to a CSV file encoded in UTF-8 (you can do this using even the
> >> Notepad):
> >> "?","?"
> >> 1,10
> >> 2,20
> >>
> >> This is on a Windows 7 box using French locale, but same codepage 1252
> >> as yours. What is interesting is that reading the file using
> >> readLines(file("myFile.csv", encoding="UTF-8"))
> >> gives no invalid characters. So there must be a bug in read.table().
> >>
> >>
> >> But I must note I do not experience issues with French accentuated
> >> characters like "?" ("\Ue9"). On the contrary, reading Armenian
> >> characters like "?" ("\U531") gives weird results: the character appears
> >> as <U+0531> instead of ?.
> >>
> >> Self-contained example, writing the file and reading it back from R:
> >> tmpfile <- tempfile()
> >> writeLines("\U531", file(tmpfile, "w", encoding="UTF-8"))
> >> readLines(file(tmpfile, encoding="UTF-8"))
> >> # "<U+0531>"
> >>
> >> The same phenomenon happens when creating a data frame from this
> >> character (as noted on StackExchange):
> >> data.frame("\U531")
> >>
> >> So my conclusion is that maybe Windows does not really support Unicode
> >> characters that are not "relevant" for your current locale. And that may
> >> have created bugs in the way R handles them in read.table(). R
> >> developers can probably tell us more about it.
> > After some more investigation, one part of the problem can be traced
> > back to scan() (with myFile.csv filled as described above):
> > scan("myFile.csv", encoding="UTF-8", sep=",", nlines=1)
> > # Read 2 items
> > # [1] "?" "?"
> >
> > Equivalent, but nonsensical to me:
> > scan("myFile.csv", fileEncoding="CP1252", encoding="UTF-8", sep=",", nlines=1)
> > # Read 2 items
> > # [1] "?" "?"
> >
> > scan("myFile.csv", fileEncoding="UTF-8", sep=",", nlines=1)
> > # Read 0 items
> > # character(0)
> > # Warning message:
> > # In scan(file, what, nmax, sep, dex, quote, skip, nlines, na.strings,  :
> > #  invalid input found on input connection 'myFile.csv'
> >
> >
> > So there seem to be one part of the issue in scan(), which for some
> > reason does not work when passed fileEncoding="UTF-8"; and another part
> > in read.table(), which transforms "?" ("\U531") into "X.U.0531.",
> > probably via make.names(), since:
> > make.names("\U531")
> > # "X.U.0531."
> >
> >
> > Does this make sense to R-core members?
> >
> >
> > Regards
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From saumya.gupta at outlook.com  Mon Sep 16 19:53:47 2013
From: saumya.gupta at outlook.com (Saumya Gupta)
Date: Mon, 16 Sep 2013 23:23:47 +0530
Subject: [R] Regression model for predicting ranks of the dependent
 variable
In-Reply-To: <CAFEqCdwTEi4r1qnWXiSCSQdOr8nT9xgX_2Skxyd12qro6QWGhA@mail.gmail.com>
References: <BAY168-W133889764D7F2EA374101A497240@phx.gbl>,
	<CAFEqCdwTEi4r1qnWXiSCSQdOr8nT9xgX_2Skxyd12qro6QWGhA@mail.gmail.com>
Message-ID: <BAY168-W96BD4F95D46724CF91BC1297260@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130916/b0f383cf/attachment.pl>

From charliethebrown77 at gmail.com  Mon Sep 16 20:05:04 2013
From: charliethebrown77 at gmail.com (Charlie Brown)
Date: Mon, 16 Sep 2013 13:05:04 -0500
Subject: [R] MASS mve_fits mycov.rob
Message-ID: <CABnkourEqvm-JRUxmhG6hp8RYmAtVADV09ReRYNVWt2KVyQ0dg@mail.gmail.com>

Hello,
In R 3.0.1, I get the following warning that I do not get in R 2.15.3:

data(mtcars)
mycov.rob(mtcars[,1:3], method="mcd")
Error in .C("mve_fitlots", as.double(x), as.integer(n), as.integer(p),  :
  "mve_fitlots" not available for .C() for package "MASS"

It seems like there was a change in MASS?  Can someone please help me
determine how to to use mycov.rob(x, method="mcd") in R 3.0.1 (I am
guessing that this includes anything that uses mve_fitlots...

Thanks.


From macqueen1 at llnl.gov  Mon Sep 16 20:20:54 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 16 Sep 2013 18:20:54 +0000
Subject: [R] problem with grep under loop
In-Reply-To: <1379128636.42243.YahooMailNeo@web125003.mail.ne1.yahoo.com>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521910D4405C0@PRDEXMBX-08.the-lab.llnl.gov>

to understand the "argument is of length zero" message, study these
example:

> if (grep('a',c('a','b'))==1) 'a' else 'b'
[1] "a"

> if (grep('a',c('c','b'))==1) 'a' else 'b'
Error in if (grep("a", c("c", "b")) == 1) "a" else "b" :
  argument is of length zero
 
> grep('a',c('c','b'))
integer(0)

> grep('a',c('c','b'))==1
logical(0)

> length(grep('a',c('c','b')))
[1] 0

> length(grep('a',c('c','b'))==1)
[1] 0


The value inside the parentheses of if() has to have length=1.


And consider possibly using grepl() instead of grep(), for example:

> grepl('a',c('c','b'))
[1] FALSE FALSE

> any(grepl('a',c('c','b')))
[1] FALSE



-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 9/13/13 8:17 PM, "capricy gao" <capricyg at yahoo.com> wrote:

>Thanks a lot for all the responses!!
>
>I then first test my data:
>
>> dim(data)
>[1] 52086    13
>>  if(grep(data[3,4],data[3,12])==1) print("Y")
>[1] "Y"
>> for(i in 1:52086){if(grep(data[i,4],data[i,12])==1) print ("Y")}
>Error in if (grep(data[i, 4], data[i, 12]) == 1) print("Y") :
>  argument is of length zero
>
>
>What is this new error message? "argument is of length zero"
>
>Here is my data format:
>>head(data)
>
>           V1     V2         V3           V4       V5  V6       V7
>   V8
>1 ref_gene_id ref_id class_code cuff_gene_id  cuff_id FMI     FPKM
>FPKM_conf_lo
>2           -      -          u       C.3 C.3.1 100 1.000000     0.000000
>3           -      -          u       C.2 C.2.1 100 1.000000     0.000000
>4           -      -          u       C.4 C.4.1 100 1.000000     0.000000
>5           -      -          u       C.1 C.1.1 100 1.000000     0.000000
>6           -      -          u       C.5 C.5.1 100 1.000000     0.000000
>            V9      V10 V11          V12           V13
>1 FPKM_conf_hi      cov len major_iso_id ref_match_len
>2     0.000000 0.056682  96     C.3.1             -
>3     0.000000 0.058453  99     C.2.1             -
>4     0.000000 0.059634 101     C.4.1             -
>5     0.000000 0.059634 101     C.2.1             -
>6     0.000000 0.059634 101     C.5.1             -
>
>
>________________________________
> From: Jeff Newmiller <jdnewmil at dcn.davis.CA.us>
>
>help at r-project.org" <r-help at r-project.org>
>Sent: Friday, September 13, 2013 9:21 PM
>Subject: Re: [R] problem with grep under loop
>
>
>This is because you are not printing it (with the print or cat
>functions). Keep in mind that the visible result you get from calling a
>function or evaluating a variable interactively comes from the
>interactive R command line, not from R itself. Once you put such an
>expression inside a function (such as the "for" function) it is no longer
>directly being invoked by the command interpreter.
>
>You might want to read [1] and [2] (which says don't post using HTML).
>
>[1] 
>http://stackoverflow.com/questions/4716152/why-do-r-objects-not-print-in-a
>-function-or-a-for-loop
>[2] http://www.R-project.org/posting-guide.html
>--------------------------------------------------------------------------
>-
>Jeff Newmiller                        The     .....       .....  Go
>Live...
>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
>Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>/Software/Embedded Controllers)               .OO#.       .OO#.
>rocks...1k
>--------------------------------------------------------------------------
>-
>Sent from my phone. Please excuse my brevity.
>
>
>>
>>
>>I am just testing the possibility of using grep under for loop:
>>
>>>for(i in 1:10){grep("a",letters)}
>>
>>
>>nothing came out;
>>
>>when I ran: 
>>
>>
>>>grep("a",letters),
>>
>>
>>I got "1"
>>
>>so in my for loop, I expected to see ten "1"s, but I did not.
>>
>>Could anybody help me to figure out why? Thanks a lot for your help.
>>
>>Capricy
>>    [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>	[[alternative HTML version deleted]]
>


From macqueen1 at llnl.gov  Mon Sep 16 20:30:09 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 16 Sep 2013 18:30:09 +0000
Subject: [R] Data labels in R
In-Reply-To: <CAK6WB8sTsqf8O2_n+xuVBDzbs1YGKDWTcdy2PyCHSvrArbDkog@mail.gmail.com>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521910D44065F@PRDEXMBX-08.the-lab.llnl.gov>

Possibly the text() function.

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 9/15/13 9:43 AM, "Ankur Seth" <ankurseth82 at gmail.com> wrote:

>I want to put labels a,b,c,d on the data points
>
>x<-data.frame(c(1,2,3,4),c(1,4,9,16),c("a","b","c","d"),
>as.Date(c("01-10-2013", "02-10-2013","03-10-2013","04-10-2013"),
>"%d-%m-%Y"))
>colnames(x)<-c("x", "sq", "lables","dates")
>y<-subset(x, select=c(dates,x,sq))
>y<-read.zoo(y)
>plot(y, plot.type="single", xlab="Date", ylab="Price")
>
>
>
>
>On Sun, Sep 15, 2013 at 9:16 PM, jim holtman <jholtman at gmail.com> wrote:
>
>> Read the help file on 'plot' and look at some of the examples to see
>> how to place labels in various places on a plot.  This is not
>> difficult if you have read any of the documentation.
>>
>> Jim Holtman
>> Data Munger Guru
>>
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>>
>>
>> On Sun, Sep 15, 2013 at 11:37 AM, Ankur Seth <ankurseth82 at gmail.com>
>> wrote:
>> > I need to put labels in plot in R. Can someone please help? The labels
>> are
>> > in the excel file and loaded into "lables"
>> >
>> > library(xlsx)
>> > library(zoo)
>> >
>> > fPTAnalysis<-"Input.xls"
>> > data<-read.xlsx(fPTAnalysis,9)
>> >
>> > lables<-subset(data, select=c(Labels))
>> > data<-subset(data, select=c(Date,col1, col2 ))
>> > data<-read.zoo(data)
>> >
>> >
>> >
>> > plot(data)
>> >
>> > --
>> > Regards,
>> > Ankur Seth
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
>-- 
>Regards,
>Ankur Seth
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ankurseth82 at gmail.com  Mon Sep 16 20:32:52 2013
From: ankurseth82 at gmail.com (Ankur Seth)
Date: Tue, 17 Sep 2013 00:02:52 +0530
Subject: [R] Data labels in R
In-Reply-To: <5E1B812FAC2C4A49B3D99593B5A521910D44065F@PRDEXMBX-08.the-lab.llnl.gov>
References: <CAK6WB8sTsqf8O2_n+xuVBDzbs1YGKDWTcdy2PyCHSvrArbDkog@mail.gmail.com>
	<5E1B812FAC2C4A49B3D99593B5A521910D44065F@PRDEXMBX-08.the-lab.llnl.gov>
Message-ID: <CAK6WB8sk0sa7O3YGgSKjGuizu+ntXWVSsYExmEwK-5gybCRB=A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130917/fa26abd0/attachment.pl>

From mlinchits at gmail.com  Mon Sep 16 20:50:06 2013
From: mlinchits at gmail.com (Maxim Linchits)
Date: Mon, 16 Sep 2013 22:50:06 +0400
Subject: [R] Non-ACSII characters in R on Windows
In-Reply-To: <CA+vqiLERZUJOZ+xpCUY1AQ1-EQ6662hcH2tozspAmZK06f+u_Q@mail.gmail.com>
References: <CAGKs4siL8rasbtsCgEfX=haESyAD5=7BHZv1R9CqeABS560aSQ@mail.gmail.com>
	<1379320808.17743.59.camel@milan> <1379342337.26458.13.camel@milan>
	<CA+vqiLERZUJOZ+xpCUY1AQ1-EQ6662hcH2tozspAmZK06f+u_Q@mail.gmail.com>
Message-ID: <CAGKs4sg07kBM3JLx8_550msV6Cc32ZTWgO1tZ2W5x1Vpg_e0XQ@mail.gmail.com>

"There is a solution for this problem. Writing a binary file instead
of a text file solves this. All applications handling a UTF-8 file in
Windows are using the same trick."
No reason why R should fail to perform this very standard "trick";
apparently R forgot how it works in 2010.
Just tried the advertised script and it did read the foreign
characters. However,  the starting file, which looked like this:

1a; 1b
2a; 2b
3a; 3b
...

turns into this in the output: (some lines become "a;b","a;b" while
others remain "a;b")

"1a; 1b", "2a; 2b",
"3a;3b",
...

So it's not a smooth substitute for a working read.table() function.
Probably time to recode all the strings into integers and move along.



Best,
Max

On Mon, Sep 16, 2013 at 7:56 PM, Ista Zahn <istazahn at gmail.com> wrote:
> UTF-8 on windows is a huge pain, this bites me often. Usually I give
> up and do the analysis on a Linux server. In previous struggles with
> this I've found this blog post enlightening:
> https://tomizonor.wordpress.com/2013/04/17/file-utf8-windows/
>
> Best,
> Ista
>
> On Mon, Sep 16, 2013 at 10:38 AM, Milan Bouchet-Valat <nalimilan at club.fr> wrote:
>> Le lundi 16 septembre 2013 ? 10:40 +0200, Milan Bouchet-Valat a ?crit :
>>> Le vendredi 13 septembre 2013 ? 23:38 +0400, Maxim Linchits a ?crit :
>>> > This is a condensed version of the same question on stackexchange here:
>>> > http://stackoverflow.com/questions/18789330/r-on-windows-character-encoding-hell
>>> > If you've already stumbled upon it feel free to ignore.
>>> >
>>> > My problem is that R on US Windows does not read *any* text file that
>>> > contains *any* foreign characters. It simply reads the first consecutive n
>>> > ASCII characters and then throws a warning once it reached a foreign
>>> > character:
>>> >
>>> > > test <- read.table("test.txt", sep=";", dec=",", quote="",
>>> > fileEncoding="UTF-8")
>>> > Warning messages:
>>> > 1: In read.table("test.txt", sep = ";", dec = ",", quote = "", fileEncoding
>>> > = "UTF-8") :
>>> >   invalid input found on input connection 'test.txt'
>>> > 2: In read.table("test.txt", sep = ";", dec = ",", quote = "", fileEncoding
>>> > = "UTF-8") :
>>> >   incomplete final line found by readTableHeader on 'test.txt'
>>> > > print(test)
>>> >        V1
>>> > 1 english
>>> >
>>> > > Sys.getlocale()
>>> >    [1] "LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
>>> > States.1252;
>>> >      LC_MONETARY=English_United
>>> > States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252"
>>> >
>>> >
>>> > It is important to note that that R on linux will read UTF-8 as well as
>>> > exotic character sets without a problem. I've tried it with the exact same
>>> > files (one was UTF-8 and another was OEM866 Cyrillic).
>>> >
>>> > If I do not include the fileEncoding parameter, read.table will read the
>>> > whole CSV file. But naturally it will read it wrong because it does not
>>> > know the encoding. So whenever I try to specify the fileEncoding, R will
>>> > throw the warnings and stop once it reaches a foreign character. It's the
>>> > same story with all international character encodings.
>>> > Other users on stackexchange have reported exactly the same issue.
>>> >
>>> >
>>> > Is anyone here who is on a US version of Windows able to import files with
>>> > foreign characters? Please let me know.
>>> A reproducible example would have helped, as requested by the posting
>>> guide.
>>>
>>> Though I am also experiencing the same problem after saving the data
>>> below to a CSV file encoded in UTF-8 (you can do this using even the
>>> Notepad):
>>> "?","?"
>>> 1,10
>>> 2,20
>>>
>>> This is on a Windows 7 box using French locale, but same codepage 1252
>>> as yours. What is interesting is that reading the file using
>>> readLines(file("myFile.csv", encoding="UTF-8"))
>>> gives no invalid characters. So there must be a bug in read.table().
>>>
>>>
>>> But I must note I do not experience issues with French accentuated
>>> characters like "?" ("\Ue9"). On the contrary, reading Armenian
>>> characters like "?" ("\U531") gives weird results: the character appears
>>> as <U+0531> instead of ?.
>>>
>>> Self-contained example, writing the file and reading it back from R:
>>> tmpfile <- tempfile()
>>> writeLines("\U531", file(tmpfile, "w", encoding="UTF-8"))
>>> readLines(file(tmpfile, encoding="UTF-8"))
>>> # "<U+0531>"
>>>
>>> The same phenomenon happens when creating a data frame from this
>>> character (as noted on StackExchange):
>>> data.frame("\U531")
>>>
>>> So my conclusion is that maybe Windows does not really support Unicode
>>> characters that are not "relevant" for your current locale. And that may
>>> have created bugs in the way R handles them in read.table(). R
>>> developers can probably tell us more about it.
>> After some more investigation, one part of the problem can be traced
>> back to scan() (with myFile.csv filled as described above):
>> scan("myFile.csv", encoding="UTF-8", sep=",", nlines=1)
>> # Read 2 items
>> # [1] "?" "?"
>>
>> Equivalent, but nonsensical to me:
>> scan("myFile.csv", fileEncoding="CP1252", encoding="UTF-8", sep=",", nlines=1)
>> # Read 2 items
>> # [1] "?" "?"
>>
>> scan("myFile.csv", fileEncoding="UTF-8", sep=",", nlines=1)
>> # Read 0 items
>> # character(0)
>> # Warning message:
>> # In scan(file, what, nmax, sep, dex, quote, skip, nlines, na.strings,  :
>> #  invalid input found on input connection 'myFile.csv'
>>
>>
>> So there seem to be one part of the issue in scan(), which for some
>> reason does not work when passed fileEncoding="UTF-8"; and another part
>> in read.table(), which transforms "?" ("\U531") into "X.U.0531.",
>> probably via make.names(), since:
>> make.names("\U531")
>> # "X.U.0531."
>>
>>
>> Does this make sense to R-core members?
>>
>>
>> Regards
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Mon Sep 16 20:56:07 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 16 Sep 2013 11:56:07 -0700 (PDT)
Subject: [R] How do you do this in R?
Message-ID: <1379357767.78514.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
Try:
?sum(sapply(1:100,function(i) i^3+ 4*(i^2)))
#[1] 26855900
?169551560477066118158651749177/79632685831739040000 
#[1] 2129170437

sum(sapply(1:25,function(i) ((2^i)/i)+ ((3^i)/(i^2))))
#[1] 2129170437
A.K.



I have done this on myself using paper and I know the answer for A is 26,855,900 
B I got 169,551,560,477,066,118,158,651,749,177/79,632,685,831,739,040,000 

So sorry for the constant questions here.


From Hui.Du at dataventures.com  Mon Sep 16 21:05:59 2013
From: Hui.Du at dataventures.com (Hui Du)
Date: Mon, 16 Sep 2013 19:05:59 +0000
Subject: [R] set breakpoint in debug
Message-ID: <13A371591163EE48BD95F2D2B244AAF41C1AF87F@SNICKERS.dataventures.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130916/ab2c33ff/attachment.pl>

From smartpink111 at yahoo.com  Mon Sep 16 21:05:56 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 16 Sep 2013 12:05:56 -0700 (PDT)
Subject: [R] MASS mve_fits mycov.rob
In-Reply-To: <CABnkourEqvm-JRUxmhG6hp8RYmAtVADV09ReRYNVWt2KVyQ0dg@mail.gmail.com>
References: <CABnkourEqvm-JRUxmhG6hp8RYmAtVADV09ReRYNVWt2KVyQ0dg@mail.gmail.com>
Message-ID: <1379358356.84418.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
library(MASS)
Couldn't find the function ?mycov.rob()
?mycov.rob(mtcars[,1:3],method="mcd")
#Error: could not find function "mycov.rob"

??mycov.rob
No vignettes or demos or help files found with alias or concept or
title matching ?mycov.rob? using regular expression matching.


Though,
?cov.rob(mtcars[,1:3],method="mcd")
$center
?????? mpg??????? cyl?????? disp 
?18.528571?? 6.380952 225.295238 

$cov
???????????? mpg??????? cyl????? disp
mpg??? 10.676143? -4.901429 -248.3544
cyl??? -4.901429?? 2.647619? 127.3619
disp -248.354357 127.361905 7469.5075

$msg
[1] "106 singular samples of size 4 out of 2000"

$crit
[1] 7.701039

$best
?[1]? 1? 2? 3? 6? 7 10 11 12 13 14 21 22 23 24 29 30 31 32

$n.obs
[1] 32
?sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
?[1] LC_CTYPE=en_CA.UTF-8?????? LC_NUMERIC=C????????????? 
?[3] LC_TIME=en_CA.UTF-8??????? LC_COLLATE=en_CA.UTF-8??? 
?[5] LC_MONETARY=en_CA.UTF-8??? LC_MESSAGES=en_CA.UTF-8?? 
?[7] LC_PAPER=C???????????????? LC_NAME=C???????????????? 
?[9] LC_ADDRESS=C?????????????? LC_TELEPHONE=C??????????? 
[11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C?????? 

attached base packages:
[1] grid????? stats???? graphics? grDevices utils???? datasets? methods? 
[8] base???? 

other attached packages:
[1] zoo_1.7-10????? rlme_0.2??????? quantreg_5.02?? SparseM_1.03?? 
[5] MASS_7.3-28???? lattice_0.20-15 stringr_0.6.2?? reshape2_1.2.2 

loaded via a namespace (and not attached):
[1] magic_1.5-4?? Matrix_1.0-12 mgcv_1.7-24?? nlme_3.1-110? plyr_1.8???? 
[6] tcltk_3.0.1?? tools_3.0.1? 

A.K.






----- Original Message -----
From: Charlie Brown <charliethebrown77 at gmail.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Monday, September 16, 2013 2:05 PM
Subject: [R] MASS mve_fits mycov.rob

Hello,
In R 3.0.1, I get the following warning that I do not get in R 2.15.3:

data(mtcars)
mycov.rob(mtcars[,1:3], method="mcd")
Error in .C("mve_fitlots", as.double(x), as.integer(n), as.integer(p),? :
? "mve_fitlots" not available for .C() for package "MASS"

It seems like there was a change in MASS?? Can someone please help me
determine how to to use mycov.rob(x, method="mcd") in R 3.0.1 (I am
guessing that this includes anything that uses mve_fitlots...

Thanks.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From szehnder at uni-bonn.de  Mon Sep 16 21:14:13 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Mon, 16 Sep 2013 21:14:13 +0200
Subject: [R] set breakpoint in debug
In-Reply-To: <13A371591163EE48BD95F2D2B244AAF41C1AF87F@SNICKERS.dataventures.local>
References: <13A371591163EE48BD95F2D2B244AAF41C1AF87F@SNICKERS.dataventures.local>
Message-ID: <8A6ADECC-41EC-424D-AA85-10CB68B7D6F9@uni-bonn.de>

You could just use debug(f) and then when the Browser opens and the loop begins type 'c', that jumps over the loop to next line after the loop. 

Best

Simon

On Sep 16, 2013, at 9:05 PM, Hui Du <Hui.Du at dataventures.com> wrote:

> Hi All,
> 
> I need some help regarding how to set up a breakpoint in debug. For example, I have a very simple/na?ve function (a useless function just for demo)
> 
> f = function()
> {
>    x = 10;
>    len = 100;
> 
>    a = 1;
>    for(i in 1:len)
>    {
>        a = a * i;
>    }
> 
> y = x + a;
> y;
> }
> 
> 
> If I need to debug it, I can run debug(f). After I go into the debugger, if I want to skip the loop and stop in the statement y = y + a, directly, how to do that? I know R has a function named setBreakpoint but I have never used it correctly.
> 
> Your help is highly appreciated.
> 
> HXD
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Mon Sep 16 21:20:37 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 16 Sep 2013 15:20:37 -0400
Subject: [R] set breakpoint in debug
In-Reply-To: <13A371591163EE48BD95F2D2B244AAF41C1AF87F@SNICKERS.dataventures.local>
References: <13A371591163EE48BD95F2D2B244AAF41C1AF87F@SNICKERS.dataventures.local>
Message-ID: <52375A05.2090508@gmail.com>

On 16/09/2013 3:05 PM, Hui Du wrote:
> Hi All,
>
> I need some help regarding how to set up a breakpoint in debug. For example, I have a very simple/na?ve function (a useless function just for demo)
>
> f = function()
> {
>      x = 10;
>      len = 100;
>
>      a = 1;
>      for(i in 1:len)
>      {
>          a = a * i;
>      }
>
> y = x + a;
> y;
> }
>
>
> If I need to debug it, I can run debug(f). After I go into the debugger, if I want to skip the loop and stop in the statement y = y + a, directly, how to do that? I know R has a function named setBreakpoint but I have never used it correctly.

After you have gone into the debugger, it's too late.  setBreakpoint 
works by modifying the body of the function, and the evaluator has 
already retrieved the body of the function when you enter.

You can set a breakpoint in a function that is not executing from the 
top level or from the debugger, and it will stop there on the next 
invocation.   The syntax is something like:

setBreakpoint("filename.R#11")

assuming that the spot where you want to stop is line 11 in the source 
file filename.R where your function came from.  (In July at useR 2013 
the RStudio folks were demonstrating a GUI that did the same sort of thing.)

It has been requested that setBreakpoint should be able to work on the 
active function as well as inactive ones, and there is no fundamental 
reason why that would be impossible, but it is tricky to manipulate 
expressions in the middle of evaluating them, so that's not in place (yet?).

Duncan Murdoch
>
> Your help is highly appreciated.
>
> HXD
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Sep 16 21:33:31 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 16 Sep 2013 12:33:31 -0700
Subject: [R] Regression model for predicting ranks of the dependent
	variable
In-Reply-To: <BAY168-W96BD4F95D46724CF91BC1297260@phx.gbl>
References: <BAY168-W133889764D7F2EA374101A497240@phx.gbl>,
	<CAFEqCdwTEi4r1qnWXiSCSQdOr8nT9xgX_2Skxyd12qro6QWGhA@mail.gmail.com>
	<BAY168-W96BD4F95D46724CF91BC1297260@phx.gbl>
Message-ID: <792F7731-428C-4E53-A77E-3B7445409B49@comcast.net>


On Sep 16, 2013, at 10:53 AM, Saumya Gupta wrote:

> I have a training dataset which contains statistics of football players for the year 2009, and their ranks for the year 2010. For example:
> 

RHelp is not the place to ask for help on homework or Kaggle challenges.

Read:

> https://stat.ethz.ch/mailman/listinfo/r-help
> 
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

-- 
David Winsemius.

> 
>  Player
>  No. of goals
>  No. of matches
>  Age
>  Rank (in 2010)
> 
> 
>  A
>  5
>  1
>  35
>  1
> 
> 
> The above ranks have been calculated on the basis of a 'score' (which is unknown) given to each player, which is a function of the 3 variables. It could be something like:Score = (No. of goals/No. of matches) - Age^(1/2)After you arrange the scores in descending order, you get the ranks. The scores are not known and neither is the formula for calculating it. Only the ranks are given.
> Now, I have statistics for football players for the year 2013, and I have to predict their ranks for the year 2014, which should give the same result if the formula used in 2010 were used. Calculating their scores is not necessary and even finding out the formula is not the objective. The objective is just to predict their ranks. But, finding the exact formula for calculating scores will be a bonus.
> Date: Mon, 16 Sep 2013 10:20:08 -0600
> Subject: Re: [R] Regression model for predicting ranks of the dependent variable
> From: 538280 at gmail.com
> To: saumya.gupta at outlook.com
> CC: r-help at r-project.org
> 
> What question (or questions) are you trying to answer?  Any advice we may give will depend on what you are trying to accomplish.
> 
> On Sat, Sep 14, 2013 at 2:12 PM, Saumya Gupta <saumya.gupta at outlook.com> wrote:
> 
> I have a dataset which has several predictor variables and a dependent variable, "score" (which is numeric). The score for each row is calculated using a formula which uses some of the predictor variables. But, the "score" figures are not explicitly given in the dataset. The scores are only arranged in ascending order, and the ranks of the numbers are given (like 1, 2, 3, 4, etc.; rank 1 means that the particular row had the highest score, 2 means it had the second highest score and so on). So, if the data has 100 rows, the output has ranks from 1 to 100.
> 
> 
> I don't think it would be proper to treat the output column as a numeric one, since it is an ordinal variable, and the distance (difference in scores) between ranks 1 and 2 may not be the same as that between ranks 2 and 3. However, most R regression models for ordinal regression are made for output such as (high, medium, low), where each level of the output does not necessarily correspond to a unique row. In my case, each output (rank) corresponds to a unique row.
> 
> 
> So please suggest me what models I could use for this problem. Will treating the output as numeric instead of ordinal be a reasonable approximation? Or will the usual models for ordinal regression work on this dataset as well?
> 
> 
>        [[alternative HTML version deleted]]
> 

David Winsemius
Alameda, CA, USA


From peter.langfelder at gmail.com  Mon Sep 16 21:35:25 2013
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Mon, 16 Sep 2013 21:35:25 +0200
Subject: [R] hclust/dendrogram merging
In-Reply-To: <BAY167-W1059032665F8387DD05CB26DE250@phx.gbl>
References: <BAY167-W1059032665F8387DD05CB26DE250@phx.gbl>
Message-ID: <CA+hbrhU9otSFFzPZBGBmG4vhEa=63qMV6sUa9OSvZ8tDtYG4Hw@mail.gmail.com>

Joshua,

I'm not sure I understand your aim correctly, but if I do, here's my
advice: If you are able to find the clusters according to rows or
columns using clustering, you must be using some kind of a distance
matrix that encodes whether two antibodies should be in one bin for
rows, and a similar matrix for the columns. To get a clustering that
represents only bins that occur in both directions, you can
appropriately combine the two matrices into a single matrix. For
example, if the distance matrix is zero if the antibodies go together
and 1 otherwise, you can add the two matrices into a single matrix,
then cluster the antibodies using the combined matrix using hclust
(with complete linkage, if I understand it correctly), then use
cutree() with cut height equal say 0.5.

HTH,

Peter

On Sun, Sep 15, 2013 at 11:33 PM, Joshua Eckman <josheckman at hotmail.com> wrote:
> I am working with protein blocking assays and the end result is a 2D matrix describing which antibodies block the binding of other antibodies to the target antigen.I need to group the antibodies together into "bins" based on their combined profiles in both the row and column direction.I am able to group the blocking profiles of rows vs rows, or columns vs columns, using clustering.  The end results could look something like this:
>>col_bins         binAb1   1Ab2   2Ab3   2Ab4   2Ab5   3Ab6   4Ab7   5Ab8   5Ab9   6
> In this case the "bin" values are just to describe they have similar blocking profiles - so Ab2, Ab3, Ab4 have the same blocking profile, as do Ab7 and Ab8.
> Looking at the row profiles
>>row_bins       binAb1   1Ab2   2Ab3   3Ab4   3Ab5   4Ab6   5Ab7   5  Ab8   6Ab10  7
> The important end result, where I am stuck, is how to combine this with the row direction and only report those that are represented in both directions AND group together in both directions.  It is possible that some Abs will not be represented in both directions.  The "bin" values of row_bins and col_bins are also not important, just the relationship between Abs by name that belong in the same bin, in both directions.
> In other words, a combined bins report would look something like this:
>        binAb1  A Ab3  BAb4  BAb5  C
> I made this visually because it is clear that these are the only groupings that are maintained in both directions.  But real data sets are much bigger, so I need some form of automation.
> Any ideas on how do this with matrix, dendograms or clustering functions?
> Thank you,
> josh
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Mon Sep 16 21:35:35 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 16 Sep 2013 15:35:35 -0400
Subject: [R] Non-ACSII characters in R on Windows
In-Reply-To: <52374269.70804@gmail.com>
References: <CAGKs4siL8rasbtsCgEfX=haESyAD5=7BHZv1R9CqeABS560aSQ@mail.gmail.com>
	<1379320808.17743.59.camel@milan> <1379342337.26458.13.camel@milan>
	<CAGKs4shYcB=eEON0cNXK9COs5yrNe7DkSZHOPnqU+6V_gaqbLQ@mail.gmail.com>
	<52374269.70804@gmail.com>
Message-ID: <CA+vqiLHqb+1OjwkMDJan6Fr916pQxnvQ2jK9CFqR3jUuJh+s2g@mail.gmail.com>

Hi Duncan,

I've put an example file online at
https://docs.google.com/file/d/0B73Ve8vxnjR6QnRESXBQTHRUME0/edit?usp=sharing,
with a screenshot showing the expected contents of the file at
https://docs.google.com/file/d/0B73Ve8vxnjR6b1ZSQmtsRXdadVU/edit?usp=sharing

Hopefully you'll find this easy and the rest of us can feel dumb for
not having figured it out...

Thanks,
Ista

On Mon, Sep 16, 2013 at 1:39 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 16/09/2013 12:04 PM, Maxim Linchits wrote:
>>
>> Here is that old post:
>>
>> http://r.789695.n4.nabble.com/read-csv-and-FileEncoding-in-Windows-version-of-R-2-13-0-td3567177.html
>
>
> In that post, you'll see I asked for a sample file.  I never received any
> reply; presumably some spam filter didn't like what Alexander sent me, and
> Nabble doesn't archive any attachment.
>
> Similarly, the Stackoverflow thread contains no sample data.
>
> Could someone who is having this problem please put a small sample online
> for download?  As I told Alexander last time, my experiments with files I
> constructed myself showed no errors.
>
> Duncan Murdoch
>
>
>>
>> A taste: "Again, the issue is that opening this UTF-8 encoded file
>> under R 2.13.0 yields an error, but opening it under R 2.12.2 works
>> without any issues. (...)"
>>
>> On Mon, Sep 16, 2013 at 6:38 PM, Milan Bouchet-Valat <nalimilan at club.fr>
>> wrote:
>> > Le lundi 16 septembre 2013 ? 10:40 +0200, Milan Bouchet-Valat a ?crit :
>> >> Le vendredi 13 septembre 2013 ? 23:38 +0400, Maxim Linchits a ?crit :
>> >> > This is a condensed version of the same question on stackexchange
>> >> > here:
>> >> >
>> >> > http://stackoverflow.com/questions/18789330/r-on-windows-character-encoding-hell
>> >> > If you've already stumbled upon it feel free to ignore.
>> >> >
>> >> > My problem is that R on US Windows does not read *any* text file that
>> >> > contains *any* foreign characters. It simply reads the first
>> >> > consecutive n
>> >> > ASCII characters and then throws a warning once it reached a foreign
>> >> > character:
>> >> >
>> >> > > test <- read.table("test.txt", sep=";", dec=",", quote="",
>> >> > fileEncoding="UTF-8")
>> >> > Warning messages:
>> >> > 1: In read.table("test.txt", sep = ";", dec = ",", quote = "",
>> >> > fileEncoding
>> >> > = "UTF-8") :
>> >> >   invalid input found on input connection 'test.txt'
>> >> > 2: In read.table("test.txt", sep = ";", dec = ",", quote = "",
>> >> > fileEncoding
>> >> > = "UTF-8") :
>> >> >   incomplete final line found by readTableHeader on 'test.txt'
>> >> > > print(test)
>> >> >        V1
>> >> > 1 english
>> >> >
>> >> > > Sys.getlocale()
>> >> >    [1] "LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
>> >> > States.1252;
>> >> >      LC_MONETARY=English_United
>> >> > States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252"
>> >> >
>> >> >
>> >> > It is important to note that that R on linux will read UTF-8 as well
>> >> > as
>> >> > exotic character sets without a problem. I've tried it with the exact
>> >> > same
>> >> > files (one was UTF-8 and another was OEM866 Cyrillic).
>> >> >
>> >> > If I do not include the fileEncoding parameter, read.table will read
>> >> > the
>> >> > whole CSV file. But naturally it will read it wrong because it does
>> >> > not
>> >> > know the encoding. So whenever I try to specify the fileEncoding, R
>> >> > will
>> >> > throw the warnings and stop once it reaches a foreign character. It's
>> >> > the
>> >> > same story with all international character encodings.
>> >> > Other users on stackexchange have reported exactly the same issue.
>> >> >
>> >> >
>> >> > Is anyone here who is on a US version of Windows able to import files
>> >> > with
>> >> > foreign characters? Please let me know.
>> >> A reproducible example would have helped, as requested by the posting
>> >> guide.
>> >>
>> >> Though I am also experiencing the same problem after saving the data
>> >> below to a CSV file encoded in UTF-8 (you can do this using even the
>> >> Notepad):
>> >> "?","?"
>> >> 1,10
>> >> 2,20
>> >>
>> >> This is on a Windows 7 box using French locale, but same codepage 1252
>> >> as yours. What is interesting is that reading the file using
>> >> readLines(file("myFile.csv", encoding="UTF-8"))
>> >> gives no invalid characters. So there must be a bug in read.table().
>> >>
>> >>
>> >> But I must note I do not experience issues with French accentuated
>> >> characters like "?" ("\Ue9"). On the contrary, reading Armenian
>> >> characters like "?" ("\U531") gives weird results: the character
>> >> appears
>> >> as <U+0531> instead of ?.
>> >>
>> >> Self-contained example, writing the file and reading it back from R:
>> >> tmpfile <- tempfile()
>> >> writeLines("\U531", file(tmpfile, "w", encoding="UTF-8"))
>> >> readLines(file(tmpfile, encoding="UTF-8"))
>> >> # "<U+0531>"
>> >>
>> >> The same phenomenon happens when creating a data frame from this
>> >> character (as noted on StackExchange):
>> >> data.frame("\U531")
>> >>
>> >> So my conclusion is that maybe Windows does not really support Unicode
>> >> characters that are not "relevant" for your current locale. And that
>> >> may
>> >> have created bugs in the way R handles them in read.table(). R
>> >> developers can probably tell us more about it.
>> > After some more investigation, one part of the problem can be traced
>> > back to scan() (with myFile.csv filled as described above):
>> > scan("myFile.csv", encoding="UTF-8", sep=",", nlines=1)
>> > # Read 2 items
>> > # [1] "?" "?"
>> >
>> > Equivalent, but nonsensical to me:
>> > scan("myFile.csv", fileEncoding="CP1252", encoding="UTF-8", sep=",",
>> > nlines=1)
>> > # Read 2 items
>> > # [1] "?" "?"
>> >
>> > scan("myFile.csv", fileEncoding="UTF-8", sep=",", nlines=1)
>> > # Read 0 items
>> > # character(0)
>> > # Warning message:
>> > # In scan(file, what, nmax, sep, dex, quote, skip, nlines, na.strings,
>> > :
>> > #  invalid input found on input connection 'myFile.csv'
>> >
>> >
>> > So there seem to be one part of the issue in scan(), which for some
>> > reason does not work when passed fileEncoding="UTF-8"; and another part
>> > in read.table(), which transforms "?" ("\U531") into "X.U.0531.",
>> > probably via make.names(), since:
>> > make.names("\U531")
>> > # "X.U.0531."
>> >
>> >
>> > Does this make sense to R-core members?
>> >
>> >
>> > Regards
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From charliethebrown77 at gmail.com  Mon Sep 16 21:54:26 2013
From: charliethebrown77 at gmail.com (Charlie Brown)
Date: Mon, 16 Sep 2013 14:54:26 -0500
Subject: [R] MASS mve_fits mycov.rob
In-Reply-To: <1379358356.84418.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <CABnkourEqvm-JRUxmhG6hp8RYmAtVADV09ReRYNVWt2KVyQ0dg@mail.gmail.com>
	<1379358356.84418.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <CABnkouoz8qLU_o_-FgvFfgdCVAbmt-2+MWw2oWGgWCVzxosqPA@mail.gmail.com>

I missed that, thank you.
This is from a function someone else wrote, and they modified
cov.rob(); I will look through what they have done.
Thank you.

On Mon, Sep 16, 2013 at 2:05 PM, arun <smartpink111 at yahoo.com> wrote:
> Hi,
> library(MASS)
> Couldn't find the function ?mycov.rob()
>  mycov.rob(mtcars[,1:3],method="mcd")
> #Error: could not find function "mycov.rob"
>
> ??mycov.rob
> No vignettes or demos or help files found with alias or concept or
> title matching ?mycov.rob? using regular expression matching.
>
>
> Though,
>  cov.rob(mtcars[,1:3],method="mcd")
> $center
>        mpg        cyl       disp
>  18.528571   6.380952 225.295238
>
> $cov
>              mpg        cyl      disp
> mpg    10.676143  -4.901429 -248.3544
> cyl    -4.901429   2.647619  127.3619
> disp -248.354357 127.361905 7469.5075
>
> $msg
> [1] "106 singular samples of size 4 out of 2000"
>
> $crit
> [1] 7.701039
>
> $best
>  [1]  1  2  3  6  7 10 11 12 13 14 21 22 23 24 29 30 31 32
>
> $n.obs
> [1] 32
>  sessionInfo()
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>  [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
>  [7] LC_PAPER=C                 LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] grid      stats     graphics  grDevices utils     datasets  methods
> [8] base
>
> other attached packages:
> [1] zoo_1.7-10      rlme_0.2        quantreg_5.02   SparseM_1.03
> [5] MASS_7.3-28     lattice_0.20-15 stringr_0.6.2   reshape2_1.2.2
>
> loaded via a namespace (and not attached):
> [1] magic_1.5-4   Matrix_1.0-12 mgcv_1.7-24   nlme_3.1-110  plyr_1.8
> [6] tcltk_3.0.1   tools_3.0.1
>
> A.K.
>
>
>
>
>
>
> ----- Original Message -----
> From: Charlie Brown <charliethebrown77 at gmail.com>
> To: "r-help at r-project.org" <r-help at r-project.org>
> Cc:
> Sent: Monday, September 16, 2013 2:05 PM
> Subject: [R] MASS mve_fits mycov.rob
>
> Hello,
> In R 3.0.1, I get the following warning that I do not get in R 2.15.3:
>
> data(mtcars)
> mycov.rob(mtcars[,1:3], method="mcd")
> Error in .C("mve_fitlots", as.double(x), as.integer(n), as.integer(p),  :
>   "mve_fitlots" not available for .C() for package "MASS"
>
> It seems like there was a change in MASS?  Can someone please help me
> determine how to to use mycov.rob(x, method="mcd") in R 3.0.1 (I am
> guessing that this includes anything that uses mve_fitlots...
>
> Thanks.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From paulbernal07 at gmail.com  Mon Sep 16 21:55:44 2013
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Mon, 16 Sep 2013 14:55:44 -0500
Subject: [R] Is R able to fit and forecast arima models using daily time
	series?
Message-ID: <CAMOcQfMpYkbUfQPULbseqAwo-bjwiMtvu_f1Ex2SBoU0=EeU5g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130916/7fb8f4a5/attachment.pl>

From nalimilan at club.fr  Mon Sep 16 22:19:29 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Mon, 16 Sep 2013 22:19:29 +0200
Subject: [R] Non-ACSII characters in R on Windows
In-Reply-To: <52374269.70804@gmail.com>
References: <CAGKs4siL8rasbtsCgEfX=haESyAD5=7BHZv1R9CqeABS560aSQ@mail.gmail.com>
	<1379320808.17743.59.camel@milan> <1379342337.26458.13.camel@milan>
	<CAGKs4shYcB=eEON0cNXK9COs5yrNe7DkSZHOPnqU+6V_gaqbLQ@mail.gmail.com>
	<52374269.70804@gmail.com>
Message-ID: <1379362769.26458.20.camel@milan>

Le lundi 16 septembre 2013 ? 13:39 -0400, Duncan Murdoch a ?crit :
> On 16/09/2013 12:04 PM, Maxim Linchits wrote:
> > Here is that old post:
> > http://r.789695.n4.nabble.com/read-csv-and-FileEncoding-in-Windows-version-of-R-2-13-0-td3567177.html
> 
> In that post, you'll see I asked for a sample file.  I never received 
> any reply; presumably some spam filter didn't like what Alexander sent 
> me, and Nabble doesn't archive any attachment.
> 
> Similarly, the Stackoverflow thread contains no sample data.
> 
> Could someone who is having this problem please put a small sample 
> online for download?  As I told Alexander last time, my experiments with 
> files I constructed myself showed no errors.
Yes, this was my first reaction, and then I saw the link to a second
thread on StackOverflow with such an example. This is the one I took in
my previous posts in this thread. If you want to get the file directly
instead of pasting the contents it by hand, here is a version that
should be enough:
http://nalimilan.perso.neuf.fr/transfert/utf8.csv


Regards

> Duncan Murdoch
> 
> >
> > A taste: "Again, the issue is that opening this UTF-8 encoded file
> > under R 2.13.0 yields an error, but opening it under R 2.12.2 works
> > without any issues. (...)"
> >
> > On Mon, Sep 16, 2013 at 6:38 PM, Milan Bouchet-Valat <nalimilan at club.fr> wrote:
> > > Le lundi 16 septembre 2013 ? 10:40 +0200, Milan Bouchet-Valat a ?crit :
> > >> Le vendredi 13 septembre 2013 ? 23:38 +0400, Maxim Linchits a ?crit :
> > >> > This is a condensed version of the same question on stackexchange here:
> > >> > http://stackoverflow.com/questions/18789330/r-on-windows-character-encoding-hell
> > >> > If you've already stumbled upon it feel free to ignore.
> > >> >
> > >> > My problem is that R on US Windows does not read *any* text file that
> > >> > contains *any* foreign characters. It simply reads the first consecutive n
> > >> > ASCII characters and then throws a warning once it reached a foreign
> > >> > character:
> > >> >
> > >> > > test <- read.table("test.txt", sep=";", dec=",", quote="",
> > >> > fileEncoding="UTF-8")
> > >> > Warning messages:
> > >> > 1: In read.table("test.txt", sep = ";", dec = ",", quote = "", fileEncoding
> > >> > = "UTF-8") :
> > >> >   invalid input found on input connection 'test.txt'
> > >> > 2: In read.table("test.txt", sep = ";", dec = ",", quote = "", fileEncoding
> > >> > = "UTF-8") :
> > >> >   incomplete final line found by readTableHeader on 'test.txt'
> > >> > > print(test)
> > >> >        V1
> > >> > 1 english
> > >> >
> > >> > > Sys.getlocale()
> > >> >    [1] "LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> > >> > States.1252;
> > >> >      LC_MONETARY=English_United
> > >> > States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252"
> > >> >
> > >> >
> > >> > It is important to note that that R on linux will read UTF-8 as well as
> > >> > exotic character sets without a problem. I've tried it with the exact same
> > >> > files (one was UTF-8 and another was OEM866 Cyrillic).
> > >> >
> > >> > If I do not include the fileEncoding parameter, read.table will read the
> > >> > whole CSV file. But naturally it will read it wrong because it does not
> > >> > know the encoding. So whenever I try to specify the fileEncoding, R will
> > >> > throw the warnings and stop once it reaches a foreign character. It's the
> > >> > same story with all international character encodings.
> > >> > Other users on stackexchange have reported exactly the same issue.
> > >> >
> > >> >
> > >> > Is anyone here who is on a US version of Windows able to import files with
> > >> > foreign characters? Please let me know.
> > >> A reproducible example would have helped, as requested by the posting
> > >> guide.
> > >>
> > >> Though I am also experiencing the same problem after saving the data
> > >> below to a CSV file encoded in UTF-8 (you can do this using even the
> > >> Notepad):
> > >> "?","?"
> > >> 1,10
> > >> 2,20
> > >>
> > >> This is on a Windows 7 box using French locale, but same codepage 1252
> > >> as yours. What is interesting is that reading the file using
> > >> readLines(file("myFile.csv", encoding="UTF-8"))
> > >> gives no invalid characters. So there must be a bug in read.table().
> > >>
> > >>
> > >> But I must note I do not experience issues with French accentuated
> > >> characters like "?" ("\Ue9"). On the contrary, reading Armenian
> > >> characters like "?" ("\U531") gives weird results: the character appears
> > >> as <U+0531> instead of ?.
> > >>
> > >> Self-contained example, writing the file and reading it back from R:
> > >> tmpfile <- tempfile()
> > >> writeLines("\U531", file(tmpfile, "w", encoding="UTF-8"))
> > >> readLines(file(tmpfile, encoding="UTF-8"))
> > >> # "<U+0531>"
> > >>
> > >> The same phenomenon happens when creating a data frame from this
> > >> character (as noted on StackExchange):
> > >> data.frame("\U531")
> > >>
> > >> So my conclusion is that maybe Windows does not really support Unicode
> > >> characters that are not "relevant" for your current locale. And that may
> > >> have created bugs in the way R handles them in read.table(). R
> > >> developers can probably tell us more about it.
> > > After some more investigation, one part of the problem can be traced
> > > back to scan() (with myFile.csv filled as described above):
> > > scan("myFile.csv", encoding="UTF-8", sep=",", nlines=1)
> > > # Read 2 items
> > > # [1] "?" "?"
> > >
> > > Equivalent, but nonsensical to me:
> > > scan("myFile.csv", fileEncoding="CP1252", encoding="UTF-8", sep=",", nlines=1)
> > > # Read 2 items
> > > # [1] "?" "?"
> > >
> > > scan("myFile.csv", fileEncoding="UTF-8", sep=",", nlines=1)
> > > # Read 0 items
> > > # character(0)
> > > # Warning message:
> > > # In scan(file, what, nmax, sep, dex, quote, skip, nlines, na.strings,  :
> > > #  invalid input found on input connection 'myFile.csv'
> > >
> > >
> > > So there seem to be one part of the issue in scan(), which for some
> > > reason does not work when passed fileEncoding="UTF-8"; and another part
> > > in read.table(), which transforms "?" ("\U531") into "X.U.0531.",
> > > probably via make.names(), since:
> > > make.names("\U531")
> > > # "X.U.0531."
> > >
> > >
> > > Does this make sense to R-core members?
> > >
> > >
> > > Regards
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Mon Sep 16 22:30:05 2013
From: 538280 at gmail.com (Greg Snow)
Date: Mon, 16 Sep 2013 14:30:05 -0600
Subject: [R] Regression model for predicting ranks of the dependent
	variable
In-Reply-To: <BAY168-W96BD4F95D46724CF91BC1297260@phx.gbl>
References: <BAY168-W133889764D7F2EA374101A497240@phx.gbl>
	<CAFEqCdwTEi4r1qnWXiSCSQdOr8nT9xgX_2Skxyd12qro6QWGhA@mail.gmail.com>
	<BAY168-W96BD4F95D46724CF91BC1297260@phx.gbl>
Message-ID: <CAFEqCdyLFTbezJN2ewXxN9zpQBZUqPN1HCSuwhD0AtQXTJrSuA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130916/44459e67/attachment.pl>

From sreckojoksimovic at gmail.com  Mon Sep 16 23:57:28 2013
From: sreckojoksimovic at gmail.com (srecko joksimovic)
Date: Mon, 16 Sep 2013 14:57:28 -0700
Subject: [R] split on change occurence
Message-ID: <CAM8BP_=ypZkULEuFN_xVLaxag11Z2VhaBvZ4F72ebvuQdYmcXQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130916/b4c290d4/attachment.pl>

From ruipbarradas at sapo.pt  Tue Sep 17 00:44:00 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 16 Sep 2013 23:44:00 +0100
Subject: [R] split on change occurence
In-Reply-To: <CAM8BP_=ypZkULEuFN_xVLaxag11Z2VhaBvZ4F72ebvuQdYmcXQ@mail.gmail.com>
References: <CAM8BP_=ypZkULEuFN_xVLaxag11Z2VhaBvZ4F72ebvuQdYmcXQ@mail.gmail.com>
Message-ID: <523789B0.1050805@sapo.pt>

Hello,

That's an even simpler case for ?split.


dat <- read.table(text = "
id    user    IP
1      12      ip1
2      12      ip1
3      12      ip2
4      12      ip2
5      12      ip2
6      12      ip3
7      12      ip3
8      12      ip3
", header = TRUE)

split(dat, dat$IP)


Hope this helps,

Rui Barradas

Em 16-09-2013 22:57, srecko joksimovic escreveu:
> Hi,
>
> I had an example like this:
> id    user    action
> 1      12      login
> 2      12      view
> 3      12      view
> 4      12      view
> 5      12      login
> 6      12      view
> 7      12      view
> 8      12      login
> which I used to split using split(dat1,cumsum(dat1$action=="login")).
>
> If I had a similar example:
> id    user    IP
> 1      12      ip1
> 2      12      ip1
> 3      12      ip2
> 4      12      ip2
> 5      12      ip2
> 6      12      ip3
> 7      12      ip3
> 8      12      ip3
>
> how can I split data frame to obtain the following structure:
> #1
> 1      12      ip1
> 2      12      ip1
> #2
> 3      12      ip2
> 4      12      ip2
> 5      12      ip2
> #3
> 6      12      ip3
> 7      12      ip3
> 8      12      ip3
>
> thanks,
> Srecko
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From sreckojoksimovic at gmail.com  Tue Sep 17 00:44:59 2013
From: sreckojoksimovic at gmail.com (srecko joksimovic)
Date: Mon, 16 Sep 2013 15:44:59 -0700
Subject: [R] split on change occurence
In-Reply-To: <523789B0.1050805@sapo.pt>
References: <CAM8BP_=ypZkULEuFN_xVLaxag11Z2VhaBvZ4F72ebvuQdYmcXQ@mail.gmail.com>
	<523789B0.1050805@sapo.pt>
Message-ID: <CAM8BP_m62jugmhXi1At-M+sthft0gEOcAX_3BOYrN3EJC+So2A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130916/b499be7a/attachment.pl>

From smartpink111 at yahoo.com  Tue Sep 17 04:40:48 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 16 Sep 2013 19:40:48 -0700 (PDT)
Subject: [R] How do you do this in R?
In-Reply-To: <1379357767.78514.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1379357767.78514.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1379385648.65848.YahooMailNeo@web142603.mail.bf1.yahoo.com>



Hi,
No problem.
Please ?dput() your dataset.

dat<- read.table(text="
strategy region result
conservative desert 64.68427
moderate mountains 10.880242
moderate desert 48.72387
aggressive desert 34.37877
aggressive mountains 37.43783
moderate grassland 60.572490
aggressive forest 5.193187
aggressive grassland 15.527508",sep="",header=TRUE,stringsAsFactors=FALSE)

dat[with(dat,(result>mean(result)) & region!="grassland" ),]
#????? strategy??? region?? result
#1 conservative??? desert 64.68427
#3???? moderate??? desert 48.72387
#5?? aggressive mountains 37.43783


dat$result[dat$region=="grassland"]<- NA


A.K.


Thank you so much for your help throughout these weeks! You've been such
a great help to me. I just have one more question sorry. 


When I try to get the mean I get this error 


In number 8 should I use subset or replace()? 


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Monday, September 16, 2013 2:56 PM
Subject: Re: How do you do this in R?

Hi,
Try:
?sum(sapply(1:100,function(i) i^3+ 4*(i^2)))
#[1] 26855900
?169551560477066118158651749177/79632685831739040000 
#[1] 2129170437

sum(sapply(1:25,function(i) ((2^i)/i)+ ((3^i)/(i^2))))
#[1] 2129170437
A.K.



I have done this on myself using paper and I know the answer for A is 26,855,900 
B I got 169,551,560,477,066,118,158,651,749,177/79,632,685,831,739,040,000 

So sorry for the constant questions here.


From kridox at ymail.com  Tue Sep 17 05:05:02 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Tue, 17 Sep 2013 12:05:02 +0900
Subject: [R] Is R able to fit and forecast arima models using daily time
	series?
In-Reply-To: <CAMOcQfMpYkbUfQPULbseqAwo-bjwiMtvu_f1Ex2SBoU0=EeU5g@mail.gmail.com>
References: <CAMOcQfMpYkbUfQPULbseqAwo-bjwiMtvu_f1Ex2SBoU0=EeU5g@mail.gmail.com>
Message-ID: <CAAcyNCxw3PffYi7Jnzgjuss7MQLHoh+P-zdX9_Bstugz3+StTg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130917/e5aebdaa/attachment.pl>

From smartpink111 at yahoo.com  Tue Sep 17 05:06:58 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 16 Sep 2013 20:06:58 -0700 (PDT)
Subject: [R] A factor times a matrix
Message-ID: <1379387218.18129.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
?t(a*t(b))
#???? [,1] [,2]
#[1,]??? 1??? 8
#[2,]??? 2?? 10
#[3,]??? 3?? 12

A.K.


Hello eveybody, 

I have a vector a and a matrix b : 
> a 
[1] 1 2 
> b 
[,1] [,2] 
[1,] 1 4 
[2,] 2 5 
[3,] 3 6 

With simple multiplication I get : 
> a * b 
[,1] [,2] 
[1,] 1 8 
[2,] 4 5 
[3,] 3 12 

I would like to have that : 
[,1] [,2] 
[1,] 1 8 
[2,] 2 10 
[3,] 3 12 

Fo now I use replicate bu I would like to do this in a simple way. 

Do you have a solution ? 

Thank you in advance


From kridox at ymail.com  Tue Sep 17 05:38:09 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Tue, 17 Sep 2013 12:38:09 +0900
Subject: [R] A factor times a matrix
In-Reply-To: <1379387218.18129.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <1379387218.18129.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <CAAcyNCzpHkMKkGpem1bybZprKynepq63NE--MQ_78ybobppM3w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130917/90546fb4/attachment.pl>

From John.Gonzalez at gmx.fr  Mon Sep 16 23:14:55 2013
From: John.Gonzalez at gmx.fr (John Gonzalez)
Date: Mon, 16 Sep 2013 23:14:55 +0200
Subject: [R] Re :  Privacy rights of an old user of this list
Message-ID: <20130916211455.202290@gmx.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130916/0fb307af/attachment.pl>

From hardy.edouard at gmail.com  Tue Sep 17 08:47:43 2013
From: hardy.edouard at gmail.com (Edouard Hardy)
Date: Tue, 17 Sep 2013 08:47:43 +0200
Subject: [R] A factor times a matrix
In-Reply-To: <CAAcyNCzpHkMKkGpem1bybZprKynepq63NE--MQ_78ybobppM3w@mail.gmail.com>
References: <1379387218.18129.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<CAAcyNCzpHkMKkGpem1bybZprKynepq63NE--MQ_78ybobppM3w@mail.gmail.com>
Message-ID: <CAFsztN6keT4TZ=7C9fMQbH6H_ikzb2+ctWa3miCz7havYet4kQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130917/3cb23927/attachment.pl>

From andreas at maunz.de  Tue Sep 17 09:01:30 2013
From: andreas at maunz.de (Andreas Maunz)
Date: Tue, 17 Sep 2013 09:01:30 +0200
Subject: [R] rgl snapshot on headless server
In-Reply-To: <5235979C.1070503@gmail.com>
References: <CAJHOUEMjjYO98UYrkJ_SfSByC9xNqd2ydGVgkFoazbW21ccMvQ@mail.gmail.com>
	<522F4B07.4030004@gmail.com>
	<CAJHOUEM6VM=znCy=g1RaLZ2gMSJ8Wei3-aFKN4tw-BVvEHy8fQ@mail.gmail.com>
	<52309822.5060403@gmail.com>
	<CAJHOUEOcdCp5D3dUGsvE_7w0+Zv+nU3YNmc5M1--uowKZ-_qfA@mail.gmail.com>
	<5235979C.1070503@gmail.com>
Message-ID: <CAJHOUEPiWu-=G=JmYOi3c_hipLMwmgZmH0bqNmcR1AZrSDukrA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130917/553429d2/attachment.pl>

From mbmiller+l at gmail.com  Tue Sep 17 10:11:10 2013
From: mbmiller+l at gmail.com (Mike Miller)
Date: Tue, 17 Sep 2013 03:11:10 -0500
Subject: [R] automatic history file append with every command?
Message-ID: <alpine.DEB.2.00.1309170251480.9964@taxa.psych.umn.edu>

In the bash shell we can use PROMPT_COMMAND="history -a" to tell bash to 
always append the last command to the history file.  It will do this with 
every command so that if bash crashes or an ssh connection is lost, the 
command history will still be available in the history file.

With R, I see there is a savehistory() command (link below), but I have 
some questions:

(1) does savehistory() append to the current history file or overwrite it?

(2) if it appends, when savehistory() is evoked repeatedly, does it only 
append commands that haven't already been appended?  Or does it append the 
entire history to the file?

(3) Is there a way to evoke history saving automatically so that the file 
is always updated?


I have the impression that savehistory() only overwrites and cannot 
append.  If that's true, I might still get what I want, but I'd be doing a 
lot of unnecessary writing.  Luckily, my R history is usually quite short. 
So if I were to enter 100 commands, appending would write 100 lines, but 
overwriting would write 5050 lines.


savehistory:

http://stat.ethz.ch/R-manual/R-devel/library/utils/html/savehistory.html


Best,
Mike

--
Michael B. Miller, Ph.D.
Minnesota Center for Twin and Family Research
Department of Psychology
University of Minnesota


From hardy.edouard at gmail.com  Tue Sep 17 10:09:42 2013
From: hardy.edouard at gmail.com (Edouard Hardy)
Date: Tue, 17 Sep 2013 10:09:42 +0200
Subject: [R] A factor times a matrix
In-Reply-To: <CAFsztN6keT4TZ=7C9fMQbH6H_ikzb2+ctWa3miCz7havYet4kQ@mail.gmail.com>
References: <1379387218.18129.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<CAAcyNCzpHkMKkGpem1bybZprKynepq63NE--MQ_78ybobppM3w@mail.gmail.com>
	<CAFsztN6keT4TZ=7C9fMQbH6H_ikzb2+ctWa3miCz7havYet4kQ@mail.gmail.com>
Message-ID: <CAFsztN7LoxC49VvTShbwSE-_2cvw=wq+H-KMrUu2Z+F5S0Docg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130917/0a170239/attachment.pl>

From gildororonar at mail-on.us  Tue Sep 17 12:15:00 2013
From: gildororonar at mail-on.us (gildororonar at mail-on.us)
Date: Tue, 17 Sep 2013 05:15:00 -0500
Subject: [R] how to find interval?
Message-ID: <20130917051500.461877c1uxxz5n48@www.vfemail.net>

I can do this:

> 1:10 %in% c(3, 5, 6, 10)
  [1] FALSE FALSE  TRUE FALSE  TRUE  TRUE FALSE FALSE FALSE  TRUE

but what I wish to get is:

[1] 3 2 1 4

let me explain:

3 # [1:3] ends with TRUE, i.e. FALSE FALSE  TRUE
2 # [4:5] ends with TRUE, i.e. FALSE  TRUE
1 # [6:6] ends with TRUE, i.e. TRUE
4 # [7:10] ends with TRUE, i.e. FALSE FALSE FALSE TRUE

That is, %in% gave me a serial whether or not the element is in a set,  
the length is equal to the former, i.e. 1:10

But I wish to get a serial of intevals of occurance of the element in  
the set, the length is equal to the latter i.e. c(3, 5, 6, 10)

With ths task of finding the intervals, I found, with googling, a  
function called findInterval. I did read every line of that manual,  
and it seems to be for a completely different purpose.

Kindly help the poor newbie:)


From bhh at xs4all.nl  Tue Sep 17 12:41:31 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Tue, 17 Sep 2013 12:41:31 +0200
Subject: [R] how to find interval?
In-Reply-To: <20130917051500.461877c1uxxz5n48@www.vfemail.net>
References: <20130917051500.461877c1uxxz5n48@www.vfemail.net>
Message-ID: <6B69975D-11A9-4E76-A48C-C7AAD7264137@xs4all.nl>


On 17-09-2013, at 12:15, gildororonar at mail-on.us wrote:

> I can do this:
> 
>> 1:10 %in% c(3, 5, 6, 10)
> [1] FALSE FALSE  TRUE FALSE  TRUE  TRUE FALSE FALSE FALSE  TRUE
> 
> but what I wish to get is:
> 
> [1] 3 2 1 4
> 
> let me explain:
> 
> 3 # [1:3] ends with TRUE, i.e. FALSE FALSE  TRUE
> 2 # [4:5] ends with TRUE, i.e. FALSE  TRUE
> 1 # [6:6] ends with TRUE, i.e. TRUE
> 4 # [7:10] ends with TRUE, i.e. FALSE FALSE FALSE TRUE
> 
> That is, %in% gave me a serial whether or not the element is in a set, the length is equal to the former, i.e. 1:10
> 
> But I wish to get a serial of intevals of occurance of the element in the set, the length is equal to the latter i.e. c(3, 5, 6, 10)


One way is

> diff(c(0,which(1:10 %in% a)))
[1] 3 2 1 4


Berend


From pburns at pburns.seanet.com  Tue Sep 17 12:47:00 2013
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Tue, 17 Sep 2013 11:47:00 +0100
Subject: [R] how to find interval?
In-Reply-To: <20130917051500.461877c1uxxz5n48@www.vfemail.net>
References: <20130917051500.461877c1uxxz5n48@www.vfemail.net>
Message-ID: <52383324.3050108@pburns.seanet.com>

I believe you want to use 'diff' and 'which' as in:

 > diff(which(c(TRUE, 1:10 %in% c(3, 5, 6, 10) )))
[1] 3 2 1 4


Pat

On 17/09/2013 11:15, gildororonar at mail-on.us wrote:
> I can do this:
>
>> 1:10 %in% c(3, 5, 6, 10)
>   [1] FALSE FALSE  TRUE FALSE  TRUE  TRUE FALSE FALSE FALSE  TRUE
>
> but what I wish to get is:
>
> [1] 3 2 1 4
>
> let me explain:
>
> 3 # [1:3] ends with TRUE, i.e. FALSE FALSE  TRUE
> 2 # [4:5] ends with TRUE, i.e. FALSE  TRUE
> 1 # [6:6] ends with TRUE, i.e. TRUE
> 4 # [7:10] ends with TRUE, i.e. FALSE FALSE FALSE TRUE
>
> That is, %in% gave me a serial whether or not the element is in a set,
> the length is equal to the former, i.e. 1:10
>
> But I wish to get a serial of intevals of occurance of the element in
> the set, the length is equal to the latter i.e. c(3, 5, 6, 10)
>
> With ths task of finding the intervals, I found, with googling, a
> function called findInterval. I did read every line of that manual, and
> it seems to be for a completely different purpose.
>
> Kindly help the poor newbie:)
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @burnsstat @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of:
  'Impatient R'
  'The R Inferno'
  'Tao Te Programming')


From petr.pikal at precheza.cz  Tue Sep 17 12:54:40 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 17 Sep 2013 10:54:40 +0000
Subject: [R] how to find interval?
In-Reply-To: <20130917051500.461877c1uxxz5n48@www.vfemail.net>
References: <20130917051500.461877c1uxxz5n48@www.vfemail.net>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9243A@SRVEXCHMBX.precheza.cz>

Hi

I am not sure if my solution is general enough

diff(c(0,which(1:10 %in% c(3, 5, 6, 10))))
[1] 3 2 1 4

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of gildororonar at mail-on.us
> Sent: Tuesday, September 17, 2013 12:15 PM
> To: r-help at r-project.org
> Subject: [R] how to find interval?
> 
> I can do this:
> 
> > 1:10 %in% c(3, 5, 6, 10)
>   [1] FALSE FALSE  TRUE FALSE  TRUE  TRUE FALSE FALSE FALSE  TRUE
> 
> but what I wish to get is:
> 
> [1] 3 2 1 4
> 
> let me explain:
> 
> 3 # [1:3] ends with TRUE, i.e. FALSE FALSE  TRUE
> 2 # [4:5] ends with TRUE, i.e. FALSE  TRUE
> 1 # [6:6] ends with TRUE, i.e. TRUE
> 4 # [7:10] ends with TRUE, i.e. FALSE FALSE FALSE TRUE
> 
> That is, %in% gave me a serial whether or not the element is in a set,
> the length is equal to the former, i.e. 1:10
> 
> But I wish to get a serial of intevals of occurance of the element in
> the set, the length is equal to the latter i.e. c(3, 5, 6, 10)
> 
> With ths task of finding the intervals, I found, with googling, a
> function called findInterval. I did read every line of that manual, and
> it seems to be for a completely different purpose.
> 
> Kindly help the poor newbie:)
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gildororonar at mail-on.us  Tue Sep 17 12:58:19 2013
From: gildororonar at mail-on.us (gildororonar at mail-on.us)
Date: Tue, 17 Sep 2013 05:58:19 -0500
Subject: [R] how to find interval?
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9243A@SRVEXCHMBX.precheza.cz>
References: <20130917051500.461877c1uxxz5n48@www.vfemail.net>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9243A@SRVEXCHMBX.precheza.cz>
Message-ID: <20130917055819.205721u862dl3emj@www.vfemail.net>

Quoting "PIKAL Petr" <petr.pikal at precheza.cz>:
> diff(c(0,which(1:10 %in% c(3, 5, 6, 10))))
> [1] 3 2 1 4

That solves the problem! Thanks.


From bhh at xs4all.nl  Tue Sep 17 12:58:19 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Tue, 17 Sep 2013 12:58:19 +0200
Subject: [R] how to find interval?
In-Reply-To: <6B69975D-11A9-4E76-A48C-C7AAD7264137@xs4all.nl>
References: <20130917051500.461877c1uxxz5n48@www.vfemail.net>
	<6B69975D-11A9-4E76-A48C-C7AAD7264137@xs4all.nl>
Message-ID: <732D2A98-958D-46F1-BDDE-0A9BF73DA104@xs4all.nl>


On 17-09-2013, at 12:41, Berend Hasselman <bhh at xs4all.nl> wrote:

> 
> On 17-09-2013, at 12:15, gildororonar at mail-on.us wrote:
> 
>> I can do this:
>> 
>>> 1:10 %in% c(3, 5, 6, 10)
>> [1] FALSE FALSE  TRUE FALSE  TRUE  TRUE FALSE FALSE FALSE  TRUE
>> 
>> but what I wish to get is:
>> 
>> [1] 3 2 1 4
>> 
>> let me explain:
>> 
>> 3 # [1:3] ends with TRUE, i.e. FALSE FALSE  TRUE
>> 2 # [4:5] ends with TRUE, i.e. FALSE  TRUE
>> 1 # [6:6] ends with TRUE, i.e. TRUE
>> 4 # [7:10] ends with TRUE, i.e. FALSE FALSE FALSE TRUE
>> 
>> That is, %in% gave me a serial whether or not the element is in a set, the length is equal to the former, i.e. 1:10
>> 
>> But I wish to get a serial of intevals of occurance of the element in the set, the length is equal to the latter i.e. c(3, 5, 6, 10)
> 
> One way is
> 
>> diff(c(0,which(1:10 %in% a)))
> [1] 3 2 1 4
> 

and of course a equals c(3, 5, 6, 10) !

Berend


From nalimilan at club.fr  Tue Sep 17 14:15:36 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Tue, 17 Sep 2013 14:15:36 +0200
Subject: [R] Non-ACSII characters in R on Windows
In-Reply-To: <CAGKs4shYcB=eEON0cNXK9COs5yrNe7DkSZHOPnqU+6V_gaqbLQ@mail.gmail.com>
References: <CAGKs4siL8rasbtsCgEfX=haESyAD5=7BHZv1R9CqeABS560aSQ@mail.gmail.com>
	<1379320808.17743.59.camel@milan> <1379342337.26458.13.camel@milan>
	<CAGKs4shYcB=eEON0cNXK9COs5yrNe7DkSZHOPnqU+6V_gaqbLQ@mail.gmail.com>
Message-ID: <1379420136.26458.30.camel@milan>

Le lundi 16 septembre 2013 ? 20:04 +0400, Maxim Linchits a ?crit :
> Here is that old post:
> http://r.789695.n4.nabble.com/read-csv-and-FileEncoding-in-Windows-version-of-R-2-13-0-td3567177.html
> 
> A taste: "Again, the issue is that opening this UTF-8 encoded file
> under R 2.13.0 yields an error, but opening it under R 2.12.2 works
> without any issues. (...)"
I have tried with R 2.12.2 both 32 and 64 bit on Windows Server 2008
with the French (CP1252) locale, and I still experience an error with
the test case I provided in previous messages. So it does not sound like
it is the same issue.


Regards

> On Mon, Sep 16, 2013 at 6:38 PM, Milan Bouchet-Valat <nalimilan at club.fr> wrote:
> > Le lundi 16 septembre 2013 ? 10:40 +0200, Milan Bouchet-Valat a ?crit :
> >> Le vendredi 13 septembre 2013 ? 23:38 +0400, Maxim Linchits a ?crit :
> >> > This is a condensed version of the same question on stackexchange here:
> >> > http://stackoverflow.com/questions/18789330/r-on-windows-character-encoding-hell
> >> > If you've already stumbled upon it feel free to ignore.
> >> >
> >> > My problem is that R on US Windows does not read *any* text file that
> >> > contains *any* foreign characters. It simply reads the first consecutive n
> >> > ASCII characters and then throws a warning once it reached a foreign
> >> > character:
> >> >
> >> > > test <- read.table("test.txt", sep=";", dec=",", quote="",
> >> > fileEncoding="UTF-8")
> >> > Warning messages:
> >> > 1: In read.table("test.txt", sep = ";", dec = ",", quote = "", fileEncoding
> >> > = "UTF-8") :
> >> >   invalid input found on input connection 'test.txt'
> >> > 2: In read.table("test.txt", sep = ";", dec = ",", quote = "", fileEncoding
> >> > = "UTF-8") :
> >> >   incomplete final line found by readTableHeader on 'test.txt'
> >> > > print(test)
> >> >        V1
> >> > 1 english
> >> >
> >> > > Sys.getlocale()
> >> >    [1] "LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> >> > States.1252;
> >> >      LC_MONETARY=English_United
> >> > States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252"
> >> >
> >> >
> >> > It is important to note that that R on linux will read UTF-8 as well as
> >> > exotic character sets without a problem. I've tried it with the exact same
> >> > files (one was UTF-8 and another was OEM866 Cyrillic).
> >> >
> >> > If I do not include the fileEncoding parameter, read.table will read the
> >> > whole CSV file. But naturally it will read it wrong because it does not
> >> > know the encoding. So whenever I try to specify the fileEncoding, R will
> >> > throw the warnings and stop once it reaches a foreign character. It's the
> >> > same story with all international character encodings.
> >> > Other users on stackexchange have reported exactly the same issue.
> >> >
> >> >
> >> > Is anyone here who is on a US version of Windows able to import files with
> >> > foreign characters? Please let me know.
> >> A reproducible example would have helped, as requested by the posting
> >> guide.
> >>
> >> Though I am also experiencing the same problem after saving the data
> >> below to a CSV file encoded in UTF-8 (you can do this using even the
> >> Notepad):
> >> "?","?"
> >> 1,10
> >> 2,20
> >>
> >> This is on a Windows 7 box using French locale, but same codepage 1252
> >> as yours. What is interesting is that reading the file using
> >> readLines(file("myFile.csv", encoding="UTF-8"))
> >> gives no invalid characters. So there must be a bug in read.table().
> >>
> >>
> >> But I must note I do not experience issues with French accentuated
> >> characters like "?" ("\Ue9"). On the contrary, reading Armenian
> >> characters like "?" ("\U531") gives weird results: the character appears
> >> as <U+0531> instead of ?.
> >>
> >> Self-contained example, writing the file and reading it back from R:
> >> tmpfile <- tempfile()
> >> writeLines("\U531", file(tmpfile, "w", encoding="UTF-8"))
> >> readLines(file(tmpfile, encoding="UTF-8"))
> >> # "<U+0531>"
> >>
> >> The same phenomenon happens when creating a data frame from this
> >> character (as noted on StackExchange):
> >> data.frame("\U531")
> >>
> >> So my conclusion is that maybe Windows does not really support Unicode
> >> characters that are not "relevant" for your current locale. And that may
> >> have created bugs in the way R handles them in read.table(). R
> >> developers can probably tell us more about it.
> > After some more investigation, one part of the problem can be traced
> > back to scan() (with myFile.csv filled as described above):
> > scan("myFile.csv", encoding="UTF-8", sep=",", nlines=1)
> > # Read 2 items
> > # [1] "?" "?"
> >
> > Equivalent, but nonsensical to me:
> > scan("myFile.csv", fileEncoding="CP1252", encoding="UTF-8", sep=",", nlines=1)
> > # Read 2 items
> > # [1] "?" "?"
> >
> > scan("myFile.csv", fileEncoding="UTF-8", sep=",", nlines=1)
> > # Read 0 items
> > # character(0)
> > # Warning message:
> > # In scan(file, what, nmax, sep, dex, quote, skip, nlines, na.strings,  :
> > #  invalid input found on input connection 'myFile.csv'
> >
> >
> > So there seem to be one part of the issue in scan(), which for some
> > reason does not work when passed fileEncoding="UTF-8"; and another part
> > in read.table(), which transforms "?" ("\U531") into "X.U.0531.",
> > probably via make.names(), since:
> > make.names("\U531")
> > # "X.U.0531."
> >
> >
> > Does this make sense to R-core members?
> >
> >
> > Regards


From amartin2 at umd.edu  Tue Sep 17 13:29:43 2013
From: amartin2 at umd.edu (Adan Leobardo Martinez Cruz)
Date: Tue, 17 Sep 2013 11:29:43 +0000
Subject: [R] Re :  Privacy rights of an old user of this list
In-Reply-To: <20130916211455.202290@gmx.com>
References: <20130916211455.202290@gmx.com>
Message-ID: <4ED416630266664A939E00E497C1385A6AB4459F@OITMX1003.AD.UMD.EDU>

Dear all,

I will express my opinion without knowing the details of the posts John would like to be removed.

In the current state, people posting on this and other servers have no clear way to go when trying to remove their posts.
It is a likely event that the number of people attempting the removal of their past posts will increase. Their reasons will vary and may or not may be reasonable to us.
It seems that a discussion on how the R-server will handle this likely situation is needed (including the possibility of keeping the current policy, of course)
Once the decision has been taken, a warning note would be helpful for newcomers (something in big, black letters saying that whatever we post will not be removed or something like that).

Best regards to all,

adan



________________________________________
From: r-help-bounces at r-project.org [r-help-bounces at r-project.org] on behalf of John Gonzalez [John.Gonzalez at gmx.fr]
Sent: Monday, September 16, 2013 5:14 PM
To: David Winsemius; Albin Blaschka; Duncan Murdoch; Jeff Newmiller; S  Ellison; Jim Lemon
Cc: r-help at r-project.org
Subject: [R] Re :  Privacy rights of an old user of this list

I would like to thank David for letting me publish this and discuss it openly. I must acknowledge from the answers that I received to my post, that the administrators of this list are doing what seems to be fair to me: what most people demand or understand that is right.
However I don't share your views and I honestly think you are making a mistake which may hurt you just as much as it is hurting me now) in the long term. Let me develop my point.
First of all let me clarify for those who accuse me of being desinformed or innocent about my request, I'm not asking for your collaboration to remove what I published from the internet, its google records or any of the infinite copies that may be lying around. I'm asking for a very simple thing:
There are 7 messages (sorry it wasn't 3...) written by me and hosted at the server stat.ethz.ch https://stat.ethz.ch/pipermail/r-help/2009-March/190367.html  which I would like to have removed.
Now, Steve E makes a good point: "I am also of the opinion that the list owner was not showing disrespect by describing the state of affairs you agreed to on signing up, or by declining to act beyond the requirements of the conditions applicable to the list. " Steve
Fair enough. But that doesn't mean that those conditions are right and should never be modified. I'm probably something similar to an unhappy customer who has bought a product with no money-back policy but with an important distinction: I'm going to be wearing this product for the rest of my life. So that makes me, if anything, a "very unhappy customer".
Now let me explain why in this world I'm spending time on requesting the removal of these 7 messages in that server.
I have a MS in Computer Science and a 5 years long Telecommunications degree, I know quite well how the internet works. This is not the first time that I request this. I already requested it in another mailing list, where they were kind enough to aprove it after I verified my identity and they checked that they weren't removing anything critical. The result was that that piece information was obviously not erased from the entire internet but was not showing up in the first 12 pages of google when you would look up my name (when it was on the first page previously). It took me 5 requests to different servers but I managed. There is nothing impossible about it and it made a difference in my life.
So why is this important for me (something like not showing up on the first pages of google?). Well please understand that there is a difference between publishing an article and writing an email to a list. An article goes through several personal revisions and is examined by a professional reviewer before it is published. It only takes a click to send an email. It is extremely easy to make mistakes (particularly when you are young and you know little about life). Actually, people make lots of mistakes and banks may use it to deny you or give you credit, employers to give you an opportunity or not, a lover to have more or less reasons to meet you etc etc etc. Removing this information from servers that are more visited by the search bot crawlers makes a difference: your banker will have to spend more time or resources to refuse your credit request, your lover may be already calling you for a date, your employer may be already calling your for an interview.
Now, if you have a lifetime job, if you never want to change your career, if you will never need a credit, if you have a lovely, healthy and loyal wife, what I just wrote may sound meaningless but if anything happens to your life, you may end up remembering what I said and suffering like me.
Why? Because you it is not possible to remove 7 messages from a server? OK, this is surely extra work that may be difficult to handle but have you considered adding a small fee for those removal requests? I would be more than happy to pay for it.
"There are a quite a few of my postings to newsgroups that I wouldn't mind seeing disappear and even a few on the Rhelp archives. I just don't think that my errors in judgment or
knowledge deserve to be ignored. My hope is that I am judged on the balance of useful versus boneheaded." David
I hope that my point is clear by now. My original motivation was and continues to be that my name was associated with a company that I don't want to be associated with (may I keep my reasons private?). My knowledge or professionality is not at stake for what I said. I can actually prove to you that I abandonded my career in engineering and I'm working in things that have nothing to do with it.
Looking forward to hearing your opinions again.
Best regards,
John
----- Message d'origine -----
De : John Gonzalez
Envoy??s : 12.09.13 15:40
?? : r-help at r-project.org, r-help at r-project.org
Objet : [R] Privacy rights of an old user of this list

Dear subscribers of r-help, I would like to know your opinion about a privacy problem that I recently had after publishing to this list. Not a long time ago, I requested to the administrators of this list that they removed 2 or 3 old posts from mine. These posts were associating my name with an old company for which I worked a few years ago when you would look up my real name at google. I'm 100% aware that there are many mirrors of this list archive and that this is a hard work, however my point was to move their google references to later pages so that new people that look up my name would focus first on more recent work that I see as more relevant for what I would like to do in the future. This is the answer that I received from Mr. Winsemius: << Such a service is not available. Almost immediately rhelp postings are replicated in multiple websites around the world. The information that you could have (and should have) read at the time of signing up is here: https://stat.et!
 hz.ch/mailman/listinfo/r-help ... and the relevant sentence is: "Posters should be aware that the R lists are /public/ discussion lists and anything you post will be *archived and accessible* via several websites for many years." >> I followed up explaining that at that time I was too young to understand the consequences of what I was doing and that, honestly, I didn't pay attention to such a note. Mr. Winsemius didn't understand the reason of my request and therefore decided to ignore it, even after asking a representative from the company mentioned in my old posts to contact him to request the removal of such posts. At this point I feel completely powerless and disturbed that the administrators of the r-help list refuse to remove a text that I decided a long time ago to publish here. I don't think that they own the rights of what I wrote and I wonder what I have done wrong to be disrespected in such a way. Best regards, John Gonzalez (pseudonym) [[alternative HTML version!
  deleted]] ______________________________________________ R-help at r-pro

ject.org mailing list https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the posting guide http://www.R-project.org/posting-guide.html and provide commented, minimal, self-contained, reproducible code.

        [[alternative HTML version deleted]]



From lorenz at usgs.gov  Tue Sep 17 14:17:38 2013
From: lorenz at usgs.gov (Lorenz, David)
Date: Tue, 17 Sep 2013 07:17:38 -0500
Subject: [R] Aggregate rows with same fields, within factors
Message-ID: <CALxY2LdAknQWFZNeJ830foLWmLXTTEhAmkQ6kh7Nr0p46MLXnA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130917/dd5993cf/attachment.pl>

From andrew.beckerman at gmail.com  Tue Sep 17 13:36:27 2013
From: andrew.beckerman at gmail.com (Andrew Beckerman)
Date: Tue, 17 Sep 2013 12:36:27 +0100
Subject: [R] why does system() truncates stdout output from large files?
Message-ID: <E1F8EF42529A4C1FB7A205460E99D7EA@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130917/6de40497/attachment.pl>

From laomeng_3 at 163.com  Tue Sep 17 14:06:16 2013
From: laomeng_3 at 163.com (meng)
Date: Tue, 17 Sep 2013 20:06:16 +0800 (CST)
Subject: [R] question about "lines"
Message-ID: <2d78a066.e241.1412bd056d8.Coremail.laomeng_3@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130917/4fd388e6/attachment.pl>

From paladini at trustindata.de  Tue Sep 17 11:49:20 2013
From: paladini at trustindata.de (paladini at trustindata.de)
Date: Tue, 17 Sep 2013 11:49:20 +0200
Subject: [R] intensity plot
Message-ID: <20130917114920.Horde.HptBDBlnuv5nGNXF_iRhig1@webmail.df.eu>

Hello,
I have got a data frame looking like this:

Country ? ? ? ? ?Sector ? ?m-value

USA              Banks     38.5
USA              Media     17
USA              hospitals 2.3
Germany          Banks      56
Germany          real estate 1
Italy            Banks      34
Italy            Media      23
Italy            real estate 78
Italy            Beverage    23
....


I would like to have a graph, let's say country on the x-axis, sector  
at the y-axis,  and for
each compination of country and sector a square in blue. The shade of  
the color should depend on the
level of the m-value.(This graph should look more or less like the  
graph when you use corrgram() to display correlation)

I tried ggplot() but I didn't get far. So it would be really nice if  
somebody could help me.

Best regards

Claudia


From pkount at bgc-jena.mpg.de  Tue Sep 17 11:55:15 2013
From: pkount at bgc-jena.mpg.de (pakoun)
Date: Tue, 17 Sep 2013 02:55:15 -0700 (PDT)
Subject: [R] foreach returns null first object in the list
Message-ID: <1379411715267-4676303.post@n4.nabble.com>

Dear all,

I am sending you a copy of a demo that i am trying to make that work and
embedded in a more complicated structure. The problem is that i want to get
a list of 2 objects (matrices in specific, and thats why i am not specifing
a .combine argument if i am not wrong..), but the first element of the list
is just null. the second one is perfectly fine. Any idea?
Thank you in advance

 library(doMC)
 registerDoMC(2)

Xa<-matrix(1:100,ncol=10)
Sa<-matrix(101:200,ncol=10)
Ta<-matrix(1:100,ncol=10)
   get.Xp <- function(Xa,Sa){
             result <- Xa%*%Sa
             return(result)
   }
   get.Sa.post <- function(Xa,Ta){

             result <- Ta%*%Sa
             return(result)
   }

  func.list <- list(get.Xp,get.Sa.post)   

  post.ls <- foreach(i =1:2) %dopar% {

             fun <- func.list[[i]]
             if(i==1){fun(Xa,Sa)}
             if(i==2){fun(Ta,Sa)}

             }
 
post.ls
[[1]]
NULL

[[2]]
        [,1]   [,2]   [,3]   [,4]   [,5]   [,6]   [,7]   [,8]   [,9]  [,10]
 [1,] 154855 169455 184055 198655 213255 227855 242455 257055 271655 286255
 [2,] 155910 170610 185310 200010 214710 229410 244110 258810 273510 288210
 [3,] 156965 171765 186565 201365 216165 230965 245765 260565 275365 290165
 [4,] 158020 172920 187820 202720 217620 232520 247420 262320 277220 292120
 [5,] 159075 174075 189075 204075 219075 234075 249075 264075 279075 294075
 [6,] 160130 175230 190330 205430 220530 235630 250730 265830 280930 296030
 [7,] 161185 176385 191585 206785 221985 237185 252385 267585 282785 297985
 [8,] 162240 177540 192840 208140 223440 238740 254040 269340 284640 299940
 [9,] 163295 178695 194095 209495 224895 240295 255695 271095 286495 301895
[10,] 164350 179850 195350 210850 226350 241850 257350 272850 288350 303850



--
View this message in context: http://r.789695.n4.nabble.com/foreach-returns-null-first-object-in-the-list-tp4676303.html
Sent from the R help mailing list archive at Nabble.com.


From yueyun at 139.com  Tue Sep 17 11:09:37 2013
From: yueyun at 139.com (=?gb2312?B?1MDaUw==?=)
Date: Tue, 17 Sep 2013 17:09:37 +0800
Subject: [R] the values of predict( , type = "terms", )
Message-ID: <018f01ceb385$a2645630$e72d0290$@139.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130917/0ec6f2bc/attachment.pl>

From bretschr at xs4all.nl  Tue Sep 17 14:45:08 2013
From: bretschr at xs4all.nl (Bretschneider (R))
Date: Tue, 17 Sep 2013 14:45:08 +0200
Subject: [R] question about "lines"
In-Reply-To: <2d78a066.e241.1412bd056d8.Coremail.laomeng_3@163.com>
References: <2d78a066.e241.1412bd056d8.Coremail.laomeng_3@163.com>
Message-ID: <BBB42A47-4C94-4E34-9FAE-5745D9DDECEC@xs4all.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130917/34fcf0bc/attachment.pl>

From murdoch.duncan at gmail.com  Tue Sep 17 14:56:04 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 17 Sep 2013 08:56:04 -0400
Subject: [R] question about "lines"
In-Reply-To: <2d78a066.e241.1412bd056d8.Coremail.laomeng_3@163.com>
References: <2d78a066.e241.1412bd056d8.Coremail.laomeng_3@163.com>
Message-ID: <52385164.6030909@gmail.com>

On 13-09-17 8:06 AM, meng wrote:
> Hi all:
> I met a question about "lines".
>
>
> attach(cars)
>
>
> plot(dist ~ speed)
> #add the regression line to the plot
> lines(fitted(lm(dist~speed)) ~ speed)
>
>
> plot(dist ~ speed)
> #what kind of curve does the following command add to the plot?
> lines(fitted(lm(dist~speed)))
>
>
> My question is :
> what kind of curve does the last command add to the plot?

Look at the class of fitted(lm(...)).  It is "numeric".  So what you're 
seeing is the same as if you computed the fitted values, and then did

lines(values)

Since values is just a vector of numbers, that will plot them as y 
values against x values 1:length(values).  That's unlikely to be a 
useful thing to do.

Duncan Murdoch

>
>
> My guess:maybe the level of fitted values?
>> range(fitted(lm(dist~speed)))
> [1] -1.84946 80.73112
>
>
> But from the plot,I can see the range of the curve is about 10 to 40 more or less,which is different from(-1.84946, 80.73112).So the curve must not be the fitted values.What kind of curve does the last command add to the plot then?
>
>
>
>
> Many thanks for your help
>
>
> My best
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch.duncan at gmail.com  Tue Sep 17 15:01:47 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 17 Sep 2013 09:01:47 -0400
Subject: [R] Non-ACSII characters in R on Windows
In-Reply-To: <1379420136.26458.30.camel@milan>
References: <CAGKs4siL8rasbtsCgEfX=haESyAD5=7BHZv1R9CqeABS560aSQ@mail.gmail.com>
	<1379320808.17743.59.camel@milan> <1379342337.26458.13.camel@milan>
	<CAGKs4shYcB=eEON0cNXK9COs5yrNe7DkSZHOPnqU+6V_gaqbLQ@mail.gmail.com>
	<1379420136.26458.30.camel@milan>
Message-ID: <523852BB.20308@gmail.com>

On 13-09-17 8:15 AM, Milan Bouchet-Valat wrote:
> Le lundi 16 septembre 2013 ? 20:04 +0400, Maxim Linchits a ?crit :
>> Here is that old post:
>> http://r.789695.n4.nabble.com/read-csv-and-FileEncoding-in-Windows-version-of-R-2-13-0-td3567177.html
>>
>> A taste: "Again, the issue is that opening this UTF-8 encoded file
>> under R 2.13.0 yields an error, but opening it under R 2.12.2 works
>> without any issues. (...)"
> I have tried with R 2.12.2 both 32 and 64 bit on Windows Server 2008
> with the French (CP1252) locale, and I still experience an error with
> the test case I provided in previous messages. So it does not sound like
> it is the same issue.


I can reproduce the error with a file sent to me by Maxim.  From a quick 
look, I suspect that changes will be needed to read.table to handle 
this, and they'll be large enough that they won't make it into 3.0.2, 
but hopefully will go into R-patched after the release.

Duncan Murdoch


From szehnder at uni-bonn.de  Tue Sep 17 15:06:13 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Tue, 17 Sep 2013 15:06:13 +0200
Subject: [R] foreach returns null first object in the list
In-Reply-To: <1379411715267-4676303.post@n4.nabble.com>
References: <1379411715267-4676303.post@n4.nabble.com>
Message-ID: <0DDEE80D-2E16-4D5E-BDA8-9F595E61F5BE@uni-bonn.de>

Use an extra call to return:

post.ls <- foreach(i =1:2, .verbose = TRUE) %dopar% {

            fun <- func.list[[i]]
        	 if (i == 1) return(fun(Xa, Sa))
	 if (i == 2) return(fun(Ta, Sa))
            }

Best

Simon

On Sep 17, 2013, at 11:55 AM, pakoun <pkount at bgc-jena.mpg.de> wrote:

> Dear all,
> 
> I am sending you a copy of a demo that i am trying to make that work and
> embedded in a more complicated structure. The problem is that i want to get
> a list of 2 objects (matrices in specific, and thats why i am not specifing
> a .combine argument if i am not wrong..), but the first element of the list
> is just null. the second one is perfectly fine. Any idea?
> Thank you in advance
> 
> library(doMC)
> registerDoMC(2)
> 
> Xa<-matrix(1:100,ncol=10)
> Sa<-matrix(101:200,ncol=10)
> Ta<-matrix(1:100,ncol=10)
>   get.Xp <- function(Xa,Sa){
>             result <- Xa%*%Sa
>             return(result)
>   }
>   get.Sa.post <- function(Xa,Ta){
> 
>             result <- Ta%*%Sa
>             return(result)
>   }
> 
>  func.list <- list(get.Xp,get.Sa.post)   
> 
>  post.ls <- foreach(i =1:2) %dopar% {
> 
>             fun <- func.list[[i]]
>             if(i==1){fun(Xa,Sa)}
>             if(i==2){fun(Ta,Sa)}
> 
>             }
> 
> post.ls
> [[1]]
> NULL
> 
> [[2]]
>        [,1]   [,2]   [,3]   [,4]   [,5]   [,6]   [,7]   [,8]   [,9]  [,10]
> [1,] 154855 169455 184055 198655 213255 227855 242455 257055 271655 286255
> [2,] 155910 170610 185310 200010 214710 229410 244110 258810 273510 288210
> [3,] 156965 171765 186565 201365 216165 230965 245765 260565 275365 290165
> [4,] 158020 172920 187820 202720 217620 232520 247420 262320 277220 292120
> [5,] 159075 174075 189075 204075 219075 234075 249075 264075 279075 294075
> [6,] 160130 175230 190330 205430 220530 235630 250730 265830 280930 296030
> [7,] 161185 176385 191585 206785 221985 237185 252385 267585 282785 297985
> [8,] 162240 177540 192840 208140 223440 238740 254040 269340 284640 299940
> [9,] 163295 178695 194095 209495 224895 240295 255695 271095 286495 301895
> [10,] 164350 179850 195350 210850 226350 241850 257350 272850 288350 303850
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/foreach-returns-null-first-object-in-the-list-tp4676303.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Tue Sep 17 15:38:55 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 17 Sep 2013 06:38:55 -0700 (PDT)
Subject: [R] A factor times a matrix
In-Reply-To: <CAAcyNCzpHkMKkGpem1bybZprKynepq63NE--MQ_78ybobppM3w@mail.gmail.com>
References: <1379387218.18129.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<CAAcyNCzpHkMKkGpem1bybZprKynepq63NE--MQ_78ybobppM3w@mail.gmail.com>
Message-ID: <1379425135.5098.YahooMailNeo@web142605.mail.bf1.yahoo.com>



?sweep() would be a bit slower compared to other two methods.


b1<-do.call(rbind,replicate(1e6,b,simplify=FALSE))
?system.time(res1<- t(a*t(b1)))
#?? user? system elapsed 
#? 0.044?? 0.000?? 0.044 
?system.time(res2<- sweep(b1,2,a,"*"))
#?? user? system elapsed 
#?? 0.14??? 0.00??? 0.14 
?system.time(res3<- b1%*% diag(a))
#?? user? system elapsed 
#? 0.084?? 0.000?? 0.083 
?identical(res1,res2)
#[1] TRUE
?all.equal(res1,res3)
#[1] TRUE
A.K.


________________________________
From: Pascal Oettli <kridox at ymail.com>
To: Edouard Hardy <hardy.edouard at gmail.com> 
Cc: R help <r-help at r-project.org>; arun <smartpink111 at yahoo.com> 
Sent: Monday, September 16, 2013 11:38 PM
Subject: Re: [R] A factor times a matrix



Hello,

To complete Arun's response, you also have:

> sweep(b,2,a,'*')
? ? ?[,1] [,2]
[1,] ? ?1 ? ?8
[2,] ? ?2 ? 10
[3,] ? ?3 ? 12

or

> b %*% diag(a)
? ? ?[,1] [,2]
[1,] ? ?1 ? ?8
[2,] ? ?2 ? 10
[3,] ? ?3 ? 12

Regards,
Pascal


2013/9/17 arun <smartpink111 at yahoo.com>

Hi,
>?t(a*t(b))
>#???? [,1] [,2]
>#[1,]??? 1??? 8
>#[2,]??? 2?? 10
>#[3,]??? 3?? 12
>
>A.K.
>
>
>Hello eveybody,
>
>I have a vector a and a matrix b :
>> a
>[1] 1 2
>> b
>[,1] [,2]
>[1,] 1 4
>[2,] 2 5
>[3,] 3 6
>
>With simple multiplication I get :
>> a * b
>[,1] [,2]
>[1,] 1 8
>[2,] 4 5
>[3,] 3 12
>
>I would like to have that :
>[,1] [,2]
>[1,] 1 8
>[2,] 2 10
>[3,] 3 12
>
>Fo now I use replicate bu I would like to do this in a simple way.
>
>Do you have a solution ?
>
>Thank you in advance
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>


-- 

Pascal Oettli
Project Scientist
JAMSTEC

Yokohama, Japan


From jim at bitwrit.com.au  Tue Sep 17 15:40:02 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 17 Sep 2013 23:40:02 +1000
Subject: [R] intensity plot
In-Reply-To: <20130917114920.Horde.HptBDBlnuv5nGNXF_iRhig1@webmail.df.eu>
References: <20130917114920.Horde.HptBDBlnuv5nGNXF_iRhig1@webmail.df.eu>
Message-ID: <52385BB2.8090202@bitwrit.com.au>

On 09/17/2013 07:49 PM, paladini at trustindata.de wrote:
> Hello,
> I have got a data frame looking like this:
>
> Country          Sector    m-value
>
> USA Banks 38.5
> USA Media 17
> USA hospitals 2.3
> Germany Banks 56
> Germany real estate 1
> Italy Banks 34
> Italy Media 23
> Italy real estate 78
> Italy Beverage 23
> ....
>
>
> I would like to have a graph, let's say country on the x-axis, sector at
> the y-axis, and for
> each compination of country and sector a square in blue. The shade of
> the color should depend on the
> level of the m-value.(This graph should look more or less like the graph
> when you use corrgram() to display correlation)
>
Hi Claudia,
If you can fill in the missing values with NA as below, try this:

cpdat<-read.table(text="USA              Banks     38.5
USA              Media     17
USA              real_estate NA
USA              hospitals 2.3
USA              Beverage   NA
Germany          Banks      56
Germany          Media      NA
Germany          real_estate 1
Germany          hospitals   5
Germany          Beverage   NA
Italy            Banks      34
Italy            Media      23
Italy            real_estate 78
Italy            hospitals   NA
Italy            Beverage    23
Australia	 Banks	     15
Australia        Media      10
Australia        real_estate 42
Australia        hospitals   NA
Australia        Beverage    34")
# create a matrix
cpmat<-matrix(0,nrow=5,ncol=4)
# fill the matrix
for(i in 1:20)
  cpmat[as.numeric(cpdat$V2[i]),as.numeric(cpdat$V1[i])]<-cpdat$V3[i]
color2D.matplot(cpmat,extremes=c("blue","red"),axes=FALSE,
  main="Intensity plot")
axis(1,at=seq(0.5,3.5),labels=levels(cpdat$V1))
axis(2,at=seq(0.5,4.5),labels=levels(cpdat$V2))

Jim


From dulcalma at bigpond.com  Tue Sep 17 15:47:43 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Tue, 17 Sep 2013 23:47:43 +1000
Subject: [R] Draw two separate legends in xyplot
In-Reply-To: <CAMCXXmrHQ38fA-hLART6eyVi=RrOa8q-T9y5XO+GsB6tBnn3KQ@mail.gmail.com>
References: <CAMCXXmrHQ38fA-hLART6eyVi=RrOa8q-T9y5XO+GsB6tBnn3KQ@mail.gmail.com>
Message-ID: <001e01ceb3ac$7c4e5be0$74eb13a0$@bigpond.com>

Have a look at

?draw.key

I have not got any code at hand as it is too late

Regards

Duncan
Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Jun Shen
Sent: Tuesday, 17 September 2013 02:27
To: R-help
Subject: [R] Draw two separate legends in xyplot

Hi all,

I wonder if there is a way to draw two separate legends in xyplot as I would
like to separate the legend for data and the legend for reference lines I
add. I can use key argument to draw one legend with everything together.
What I really want is to put one legend at the bottom and the other on the
top. Thanks.

Jun

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From capricyg at yahoo.com  Tue Sep 17 16:08:10 2013
From: capricyg at yahoo.com (capricy gao)
Date: Tue, 17 Sep 2013 07:08:10 -0700 (PDT)
Subject: [R] problem with grep under loop
In-Reply-To: <1379134012.31325.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <1378295727096-4675348.post@n4.nabble.com>
	<1379122191.23805.YahooMailNeo@web125004.mail.ne1.yahoo.com>
	<1379134012.31325.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <1379426890.95954.YahooMailNeo@web125006.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130917/0491f8e4/attachment.pl>

From pkount at bgc-jena.mpg.de  Tue Sep 17 17:55:08 2013
From: pkount at bgc-jena.mpg.de (pakoun)
Date: Tue, 17 Sep 2013 08:55:08 -0700 (PDT)
Subject: [R] foreach returns null first object in the list
In-Reply-To: <0DDEE80D-2E16-4D5E-BDA8-9F595E61F5BE@uni-bonn.de>
References: <1379411715267-4676303.post@n4.nabble.com>
	<0DDEE80D-2E16-4D5E-BDA8-9F595E61F5BE@uni-bonn.de>
Message-ID: <1379433308715-4676329.post@n4.nabble.com>

This is the output with the debugging message. I don't really understand what
is the problem.

>   post.ls <- foreach(i =1:2, .verbose=T) %dopar% {
+
+              fun <- func.list[[i]]
+              if(i==1){fun(Xa,Sa)}
+              if(i==2){fun(Ta,Sa)}
+
+              }
numValues: 2, numResults: 0, stopped: TRUE
got results for task 1
numValues: 2, numResults: 1, stopped: TRUE
returning status FALSE
got results for task 2
numValues: 2, numResults: 2, stopped: TRUE
calling combine function
evaluating call object to combine results:
  fun(accum, result.1, result.2)
returning status TRUE




--
View this message in context: http://r.789695.n4.nabble.com/foreach-returns-null-first-object-in-the-list-tp4676303p4676329.html
Sent from the R help mailing list archive at Nabble.com.


From sreckojoksimovic at gmail.com  Tue Sep 17 18:03:30 2013
From: sreckojoksimovic at gmail.com (srecko joksimovic)
Date: Tue, 17 Sep 2013 09:03:30 -0700
Subject: [R] Unrecognized token
Message-ID: <CAM8BP_=uUy0hycVXg7DkGoMq7NybsEf=Ro8R2Md0BFtH6f=q2w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130917/9c415d4f/attachment.pl>

From bt_jannis at yahoo.de  Tue Sep 17 18:09:36 2013
From: bt_jannis at yahoo.de (Jannis)
Date: Tue, 17 Sep 2013 18:09:36 +0200
Subject: [R] big difference between ncdf and RNetCDF ?
Message-ID: <52387EC0.2080209@yahoo.de>

Dear package authors, dear r-help list,


are there any big differences between the ncdf and the RNetCDF package, 
especially with regards to the support of different netcdf versions, 
future maintenacne or speed? I have looked at both packages and their 
capabilities seem to be quiet identical (with regards to their 
functions). I ask because I will give some advice on ncdf and R to a 
group of people highlighting some of the (possible) differences.


Thanks a lot
Jannis


From szehnder at uni-bonn.de  Tue Sep 17 18:15:50 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Tue, 17 Sep 2013 18:15:50 +0200
Subject: [R] foreach returns null first object in the list
In-Reply-To: <1379433308715-4676329.post@n4.nabble.com>
References: <1379411715267-4676303.post@n4.nabble.com>
	<0DDEE80D-2E16-4D5E-BDA8-9F595E61F5BE@uni-bonn.de>
	<1379433308715-4676329.post@n4.nabble.com>
Message-ID: <1B9CE4F8-9BFF-4274-965A-017592B2A632@uni-bonn.de>

Use an extra call to 'return()' as posted below. 

On Sep 17, 2013, at 5:55 PM, pakoun <pkount at bgc-jena.mpg.de> wrote:

> This is the output with the debugging message. I don't really understand what
> is the problem.
> 
>>  post.ls <- foreach(i =1:2, .verbose=T) %dopar% {
> +
> +              fun <- func.list[[i]]
> +              if(i==1){fun(Xa,Sa)}
> +              if(i==2){fun(Ta,Sa)}
> +
> +              }
> numValues: 2, numResults: 0, stopped: TRUE
> got results for task 1
> numValues: 2, numResults: 1, stopped: TRUE
> returning status FALSE
> got results for task 2
> numValues: 2, numResults: 2, stopped: TRUE
> calling combine function
> evaluating call object to combine results:
>  fun(accum, result.1, result.2)
> returning status TRUE
> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/foreach-returns-null-first-object-in-the-list-tp4676303p4676329.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Tue Sep 17 18:16:47 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 17 Sep 2013 16:16:47 +0000
Subject: [R] Unrecognized token
In-Reply-To: <CAM8BP_=uUy0hycVXg7DkGoMq7NybsEf=Ro8R2Md0BFtH6f=q2w@mail.gmail.com>
References: <CAM8BP_=uUy0hycVXg7DkGoMq7NybsEf=Ro8R2Md0BFtH6f=q2w@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C343A88@PA-MBX01.na.tibco.com>

Look at the query strings your code produces:

> with(list(id=c("1234","abcd")), paste(paste("select * from tbl_user where student_id = ", id,
                  sep=""), " order by date_time", sep="")
  )
[1] "select * from tbl_user where student_id = 1234 order by date_time"
[2] "select * from tbl_user where student_id = abcd order by date_time"

I suspect that the abcd should have quotes around it.  If student_id is stored
as string data the 1234 should probably also have quotes around it.  Replace
   id
with
   "\"", id, "\""
and you may get a query that works.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of srecko joksimovic
> Sent: Tuesday, September 17, 2013 9:04 AM
> To: R help
> Subject: [R] Unrecognized token
> 
> Hi,
> 
> when I generate query using sqldf library, like this:
> query = paste(paste("select * from tbl_user where student_id = ", id,
>                 sep=""), " order by date_time", sep="")
> 
> student <- sqldf(query)
> 
> everything works fine in case the id is "21328", "82882", or something like
> that. But, when id is something like "78789D", there is an error:
> Error in sqliteExecStatement(con, statement, bind.data) :
>   RS-DBI driver: (error in statement: unrecognized token: "78789D")
> 
> I tried replacing single quotes with double, but it still doesn't work...
> 
> thanks,
> Srecko
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From szehnder at uni-bonn.de  Tue Sep 17 18:20:58 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Tue, 17 Sep 2013 18:20:58 +0200
Subject: [R] Unrecognized token
In-Reply-To: <CAM8BP_=uUy0hycVXg7DkGoMq7NybsEf=Ro8R2Md0BFtH6f=q2w@mail.gmail.com>
References: <CAM8BP_=uUy0hycVXg7DkGoMq7NybsEf=Ro8R2Md0BFtH6f=q2w@mail.gmail.com>
Message-ID: <9338BBB4-FBA6-45F4-9FF0-7973E33F0D35@uni-bonn.de>

Maybe you should escape the single quotes something like " ' " id " ' "?

On Sep 17, 2013, at 6:03 PM, srecko joksimovic <sreckojoksimovic at gmail.com> wrote:

> Hi,
> 
> when I generate query using sqldf library, like this:
> query = paste(paste("select * from tbl_user where student_id = ", id,
>                sep=""), " order by date_time", sep="")
> 
> student <- sqldf(query)
> 
> everything works fine in case the id is "21328", "82882", or something like
> that. But, when id is something like "78789D", there is an error:
> Error in sqliteExecStatement(con, statement, bind.data) :
>  RS-DBI driver: (error in statement: unrecognized token: "78789D")
> 
> I tried replacing single quotes with double, but it still doesn't work...
> 
> thanks,
> Srecko
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ahmedatia80 at gmail.com  Tue Sep 17 18:23:02 2013
From: ahmedatia80 at gmail.com (Ahmed Attia)
Date: Tue, 17 Sep 2013 11:23:02 -0500
Subject: [R] Fwd: axis lab font in r
In-Reply-To: <CAG6S0O=4dDj++VkSwMfYoQuZWu7WLTsLtZ31LNroPnB8BgqpzA@mail.gmail.com>
References: <CAG6S0O=4dDj++VkSwMfYoQuZWu7WLTsLtZ31LNroPnB8BgqpzA@mail.gmail.com>
Message-ID: <CAG6S0OmuupLmRfvkmVYa-+E45=c9=RbWk7wUhArRSUhvhygWNg@mail.gmail.com>

---------- Forwarded message ----------
From: Ahmed Attia <ahmedatia80 at gmail.com>
Date: Tue, Sep 17, 2013 at 11:17 AM
Subject: axis lab font in r
To: r-help-request at r-project.org



I have an a question about the axis lab font in r. I use font.lab, but
r changes the font of x axis lab only. How I can change the font of y
lab axis as well?

I have another problem; when I increase the size of y lab, the lab
goes out of the graph box.

I use R version 2.15.2 (32-bit)

Thank you
--
Ahmed M. Attia


Research Assistant
Dept. Of Soil&Crop Sciences
Texas A&M University
ahmed.attia at ag.tamu.edu
Cell phone: 001-979-248-5215




-- 
Ahmed M. Attia


Research Assistant
Dept. Of Soil&Crop Sciences
Texas A&M University
ahmed.attia at ag.tamu.edu
Cell phone: 001-979-248-5215

From dpierce at ucsd.edu  Tue Sep 17 18:32:38 2013
From: dpierce at ucsd.edu (David W. Pierce)
Date: Tue, 17 Sep 2013 09:32:38 -0700
Subject: [R] big difference between ncdf and RNetCDF ?
In-Reply-To: <52387EC0.2080209@yahoo.de>
References: <52387EC0.2080209@yahoo.de>
Message-ID: <CAL+Zad__DffY2U6e=RT1b4qaBVup53RHNQ+RKd7Hrfa6odJgrA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130917/7d09d144/attachment.pl>

From sreckojoksimovic at gmail.com  Tue Sep 17 18:35:49 2013
From: sreckojoksimovic at gmail.com (srecko joksimovic)
Date: Tue, 17 Sep 2013 09:35:49 -0700
Subject: [R] Unrecognized token
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C343A88@PA-MBX01.na.tibco.com>
References: <CAM8BP_=uUy0hycVXg7DkGoMq7NybsEf=Ro8R2Md0BFtH6f=q2w@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C343A88@PA-MBX01.na.tibco.com>
Message-ID: <CAM8BP_niHE81jnGYe0OsuguaBSMCJHtw_joM+t+xPnqCYasQCw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130917/9ab476cc/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Tue Sep 17 18:43:21 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 17 Sep 2013 09:43:21 -0700
Subject: [R] Unrecognized token
In-Reply-To: <CAM8BP_=uUy0hycVXg7DkGoMq7NybsEf=Ro8R2Md0BFtH6f=q2w@mail.gmail.com>
References: <CAM8BP_=uUy0hycVXg7DkGoMq7NybsEf=Ro8R2Md0BFtH6f=q2w@mail.gmail.com>
Message-ID: <d173c77d-0746-40e5-8f1a-172b99a085a5@email.android.com>

Why don't you print the 'query' variable with each id value and consider what the SQL syntax is for number and string literals. Then study the use of escaping in strings ("\\") to fix the query.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

srecko joksimovic <sreckojoksimovic at gmail.com> wrote:
>Hi,
>
>when I generate query using sqldf library, like this:
>query = paste(paste("select * from tbl_user where student_id = ", id,
>                sep=""), " order by date_time", sep="")
>
>student <- sqldf(query)
>
>everything works fine in case the id is "21328", "82882", or something
>like
>that. But, when id is something like "78789D", there is an error:
>Error in sqliteExecStatement(con, statement, bind.data) :
>  RS-DBI driver: (error in statement: unrecognized token: "78789D")
>
>I tried replacing single quotes with double, but it still doesn't
>work...
>
>thanks,
>Srecko
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From sreckojoksimovic at gmail.com  Tue Sep 17 18:47:37 2013
From: sreckojoksimovic at gmail.com (srecko joksimovic)
Date: Tue, 17 Sep 2013 09:47:37 -0700
Subject: [R] Unrecognized token
In-Reply-To: <d173c77d-0746-40e5-8f1a-172b99a085a5@email.android.com>
References: <CAM8BP_=uUy0hycVXg7DkGoMq7NybsEf=Ro8R2Md0BFtH6f=q2w@mail.gmail.com>
	<d173c77d-0746-40e5-8f1a-172b99a085a5@email.android.com>
Message-ID: <CAM8BP_mH7oHGMFvVnbQF7=_3ZriGKbP-DZOrhfDbxvFOWVdE0A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130917/7d9bc93b/attachment.pl>

From hnorpois at gmail.com  Tue Sep 17 18:11:18 2013
From: hnorpois at gmail.com (Hermann Norpois)
Date: Tue, 17 Sep 2013 18:11:18 +0200
Subject: [R] cov and huge matrix
Message-ID: <CAKyZeBurjcubYOV+v1JLkkxYvgLtuYQoR2MBo9rNwzLbLpnGTg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130917/c9187626/attachment.pl>

From shouli.li at utu.fi  Tue Sep 17 14:37:53 2013
From: shouli.li at utu.fi (Shouli Li)
Date: Tue, 17 Sep 2013 12:37:53 +0000
Subject: [R] lme4: How to specify nested factors, meaning of : and %in%
Message-ID: <26389D1F4F62BE4DBEB36F898B97D5011D045A5B@exch-mbx-02.utu.fi>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130917/c3ecd90e/attachment.pl>

From pkount at bgc-jena.mpg.de  Tue Sep 17 19:29:39 2013
From: pkount at bgc-jena.mpg.de (pakoun)
Date: Tue, 17 Sep 2013 10:29:39 -0700 (PDT)
Subject: [R] foreach returns null first object in the list
In-Reply-To: <1B9CE4F8-9BFF-4274-965A-017592B2A632@uni-bonn.de>
References: <1379411715267-4676303.post@n4.nabble.com>
	<0DDEE80D-2E16-4D5E-BDA8-9F595E61F5BE@uni-bonn.de>
	<1379433308715-4676329.post@n4.nabble.com>
	<1B9CE4F8-9BFF-4274-965A-017592B2A632@uni-bonn.de>
Message-ID: <1379438979415-4676344.post@n4.nabble.com>

OOhhh I am sorry I didnt notice the return before the function. Everything
works. 
Thank you :)
Best regards.



--
View this message in context: http://r.789695.n4.nabble.com/foreach-returns-null-first-object-in-the-list-tp4676303p4676344.html
Sent from the R help mailing list archive at Nabble.com.


From 538280 at gmail.com  Tue Sep 17 19:32:41 2013
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 17 Sep 2013 11:32:41 -0600
Subject: [R] automatic history file append with every command?
In-Reply-To: <alpine.DEB.2.00.1309170251480.9964@taxa.psych.umn.edu>
References: <alpine.DEB.2.00.1309170251480.9964@taxa.psych.umn.edu>
Message-ID: <CAFEqCdxeJ28wiAbLZLw659XiJbqaYnj2BG48XTx2dYyHxbsXNA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130917/3452d630/attachment.pl>

From miseno77 at hotmail.com  Tue Sep 17 19:35:19 2013
From: miseno77 at hotmail.com (Simone Santoro)
Date: Tue, 17 Sep 2013 19:35:19 +0200
Subject: [R] =?windows-1252?q?Very_high_Nagelkerke=92s_Pseudo-R2_values?=
Message-ID: <DUB108-W32100F044EEFA564AA9E7DDC270@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130917/a6bb3db5/attachment.pl>

From zd.gibbs at yahoo.com  Tue Sep 17 19:52:36 2013
From: zd.gibbs at yahoo.com (Zd Gibbs)
Date: Tue, 17 Sep 2013 10:52:36 -0700 (PDT)
Subject: [R] If-then with Dates in Date Ranges
Message-ID: <1379440356.86249.YahooMailNeo@web162302.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130917/6b271099/attachment.pl>

From sreckojoksimovic at gmail.com  Tue Sep 17 19:56:32 2013
From: sreckojoksimovic at gmail.com (srecko joksimovic)
Date: Tue, 17 Sep 2013 10:56:32 -0700
Subject: [R] Unrecognized token
In-Reply-To: <CAM8BP_mH7oHGMFvVnbQF7=_3ZriGKbP-DZOrhfDbxvFOWVdE0A@mail.gmail.com>
References: <CAM8BP_=uUy0hycVXg7DkGoMq7NybsEf=Ro8R2Md0BFtH6f=q2w@mail.gmail.com>
	<d173c77d-0746-40e5-8f1a-172b99a085a5@email.android.com>
	<CAM8BP_mH7oHGMFvVnbQF7=_3ZriGKbP-DZOrhfDbxvFOWVdE0A@mail.gmail.com>
Message-ID: <CAM8BP_kSKfuQZ+vum=hVG1bxnUwsorEvgadvsYRh5E7fXOhh4w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130917/da797f89/attachment.pl>

From michel.arnaud at cirad.fr  Tue Sep 17 20:14:52 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Tue, 17 Sep 2013 20:14:52 +0200
Subject: [R] delete some lines of a dataframe
Message-ID: <52389C1C.4050503@cirad.fr>

Hi

I have a dataframe Df1
dput(Df1)
structure(list(Mat = c(141, 141, 157, 157, 188, 188, 232, 232,
253, 253, 253, 254, 254, 254, 254, 256, 256, 264, 264), Prenom = 
c("Pierre",
"Pierre", "Jean-Claude", "Jean-Claude", "Jean-Louis", "Jean-Louis",
"Philippe", "Philippe", "Christophe", "Christophe", "Christophe",
"Dominique", "Dominique", "Dominique", "Dominique", "Pierre-Luc",
"Pierre-Luc", "Alain", "Alain"), Sexe = c("Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin"),
     DateNais = c("23/08/1946", "23/08/1946", "11/08/1945", "11/08/1945",
     "09/04/1948", "09/04/1948", "01/05/1946", "01/05/1946", "11/02/1951",
     "11/02/1951", "11/02/1951", "21/10/1949", "21/10/1949", "21/10/1949",
     "21/10/1949", "25/06/1946", "25/06/1946", "13/03/1949", "13/03/1949"
     )), .Names = c("Mat", "Prenom", "Sexe", "DateNais"), row.names = 
c("207",
"208", "232", "233", "288", "289", "373", "374", "412", "413",
"414", "415", "416", "417", "418", "420", "421", "436", "437"
), class = "data.frame")

I want to extract of Df1 2 other dataframes :
1) delete the first line for each values of Mat
        Mat      Prenom     Sexe   DateNais
208 141      Pierre Masculin 23/08/1946
233 157 Jean-Claude Masculin 11/08/1945
289 188  Jean-Louis Masculin 09/04/1948
374 232    Philippe Masculin 01/05/1946
413 253  Christophe Masculin 11/02/1951
414 253  Christophe Masculin 11/02/1951
416 254   Dominique Masculin 21/10/1949
417 254   Dominique Masculin 21/10/1949
418 254   Dominique Masculin 21/10/1949
421 256  Pierre-Luc Masculin 25/06/1946
437 264       Alain Masculin 13/03/1949

2) delete the last line for each values of Mat
     Mat      Prenom     Sexe   DateNais
207 141      Pierre Masculin 23/08/1946
232 157 Jean-Claude Masculin 11/08/1945
288 188  Jean-Louis Masculin 09/04/1948
373 232    Philippe Masculin 01/05/1946
412 253  Christophe Masculin 11/02/1951
413 253  Christophe Masculin 11/02/1951
415 254   Dominique Masculin 21/10/1949
416 254   Dominique Masculin 21/10/1949
417 254   Dominique Masculin 21/10/1949
420 256  Pierre-Luc Masculin 25/06/1946
436 264       Alain Masculin 13/03/1949

Any ideas ?


-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From jdnewmil at dcn.davis.ca.us  Tue Sep 17 20:22:11 2013
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 17 Sep 2013 11:22:11 -0700 (PDT)
Subject: [R] Unrecognized token
In-Reply-To: <CAM8BP_kSKfuQZ+vum=hVG1bxnUwsorEvgadvsYRh5E7fXOhh4w@mail.gmail.com>
References: <CAM8BP_=uUy0hycVXg7DkGoMq7NybsEf=Ro8R2Md0BFtH6f=q2w@mail.gmail.com>
	<d173c77d-0746-40e5-8f1a-172b99a085a5@email.android.com>
	<CAM8BP_mH7oHGMFvVnbQF7=_3ZriGKbP-DZOrhfDbxvFOWVdE0A@mail.gmail.com>
	<CAM8BP_kSKfuQZ+vum=hVG1bxnUwsorEvgadvsYRh5E7fXOhh4w@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1309171117280.23254@pedal.dcn.davis.ca.us>


> id <- c("21328","78789D")
> query <- paste(paste("select * from tbl_user where student_id = ", 
id,sep=""), " order by date_time", sep="")
> query
[1] "select * from tbl_user where student_id = 21328 order by date_time"
[2] "select * from tbl_user where student_id = 78789D order by date_time"

Now, does the second string look like valid SQL to you? In particular, the 
78789D is a problem. On the other hand...

> query <- paste(paste("select * from tbl_user where student_id = '", 
id,sep=""), "' order by date_time", sep="")
> query
[1] "select * from tbl_user where student_id = '21328' order by date_time"
[2] "select * from tbl_user where student_id = '78789D' order by 
date_time"

As others have pointed out, in this case escaping does not appear to be 
key to getting valid SQL syntax... but looking at the query before 
shipping it off to a database engine seems to me to be an obvious 
technique you should learn.

On Tue, 17 Sep 2013, srecko joksimovic wrote:

> There is no difference, the same query structure is in the both cases:"6683"
> "character"
> "character"
> "select * from?students?where student_id = 6683 order by date_time"
> "4738D"
> "character"
> "character"
> "select * from students where student_id = 4738D order by date_time"
> 
> and still is the same error
> 
> 
> On Tue, Sep 17, 2013 at 9:47 AM, srecko joksimovic
> <sreckojoksimovic at gmail.com> wrote:
>       thanks, Jeff,
> good point... I'll try that
> 
> 
> On Tue, Sep 17, 2013 at 9:43 AM, Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> wrote:
>       Why don't you print the 'query' variable with each id
>       value and consider what the SQL syntax is for number and
>       string literals. Then study the use of escaping in strings
>       ("\\") to fix the query.
> ---------------------------------------------------------------------------
>
>       Jeff Newmiller ? ? ? ? ? ? ? ? ? ? ? ?The ? ? ..... ? ? ?
>       ..... ?Go Live...
>       DCN:<jdnewmil at dcn.davis.ca.us> ? ? ? ?Basics: ##.#. ? ? ?
>       ##.#. ?Live Go...
>       ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Live: ? OO#.. Dead:
>       OO#.. ?Playing
>       Research Engineer (Solar/Batteries ? ? ? ? ? ?O.O#. ? ? ?
>       #.O#. ?with
>       /Software/Embedded Controllers) ? ? ? ? ? ? ? .OO#. ? ? ?
>       .OO#. ?rocks...1k
> ---------------------------------------------------------------------------
>
>       Sent from my phone. Please excuse my brevity.
>
>       srecko joksimovic <sreckojoksimovic at gmail.com> wrote:
>       >Hi,
>       >
>       >when I generate query using sqldf library, like this:
>       >query = paste(paste("select * from tbl_user where
>       student_id = ", id,
>       > ? ? ? ? ? ? ? ?sep=""), " order by date_time", sep="")
>       >
>       >student <- sqldf(query)
>       >
>       >everything works fine in case the id is "21328", "82882",
>       or something
>       >like
>       >that. But, when id is something like "78789D", there is
>       an error:
>       >Error in sqliteExecStatement(con, statement, bind.data) :
>       > ?RS-DBI driver: (error in statement: unrecognized token:
>       "78789D")
>       >
>       >I tried replacing single quotes with double, but it still
>       doesn't
>       >work...
>       >
>       >thanks,
>       >Srecko
>       >
> > ? ? ? [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible
> code.
> 
> 
> 
> 
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------

From sreckojoksimovic at gmail.com  Tue Sep 17 20:26:10 2013
From: sreckojoksimovic at gmail.com (srecko joksimovic)
Date: Tue, 17 Sep 2013 11:26:10 -0700
Subject: [R] Unrecognized token
In-Reply-To: <alpine.BSF.2.00.1309171117280.23254@pedal.dcn.davis.ca.us>
References: <CAM8BP_=uUy0hycVXg7DkGoMq7NybsEf=Ro8R2Md0BFtH6f=q2w@mail.gmail.com>
	<d173c77d-0746-40e5-8f1a-172b99a085a5@email.android.com>
	<CAM8BP_mH7oHGMFvVnbQF7=_3ZriGKbP-DZOrhfDbxvFOWVdE0A@mail.gmail.com>
	<CAM8BP_kSKfuQZ+vum=hVG1bxnUwsorEvgadvsYRh5E7fXOhh4w@mail.gmail.com>
	<alpine.BSF.2.00.1309171117280.23254@pedal.dcn.davis.ca.us>
Message-ID: <CAM8BP_=cYFvXBSV_jJt3a2uMEZM64__Z81BC3DjCPW68yEUr7Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130917/e7d71aeb/attachment.pl>

From jrkrideau at inbox.com  Tue Sep 17 20:42:00 2013
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 17 Sep 2013 10:42:00 -0800
Subject: [R] Fwd: axis lab font in r
In-Reply-To: <CAG6S0OmuupLmRfvkmVYa-+E45=c9=RbWk7wUhArRSUhvhygWNg@mail.gmail.com>
References: <cag6s0o=4ddj++vkswmfyoquzwu7wltsltz31lnropnb8bgqpza@mail.gmail.com>
Message-ID: <1A9ACA416F3.00000592jrkrideau@inbox.com>

 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

We need a bit of information and code about how you are using font.ab.

As far as I can see both x and y axes should be affected.

See this example from http://r.789695.n4.nabble.com/font-lab-and-font-axis-td3009882.html

x<-rnorm(100)
hist(x,axes=F,font.lab=12,font.main=9)
axis(1,font.axis=4)
axis(2,font.axis=3) 

John Kane
Kingston ON Canada

> -----Original Message-----
> From: ahmedatia80 at gmail.com
> Sent: Tue, 17 Sep 2013 11:23:02 -0500
> To: r-help at r-project.org
> Subject: [R] Fwd: axis lab font in r

> I have an a question about the axis lab font in r. I use font.lab, but
> r changes the font of x axis lab only. How I can change the font of y
> lab axis as well?
> 
> I have another problem; when I increase the size of y lab, the lab
> goes out of the graph box.
> 
> I use R version 2.15.2 (32-bit)
> 
> Thank you
> --
> Ahmed M. Attia
> 

> Research Assistant
> Dept. Of Soil&Crop Sciences
> Texas A&M University
> ahmed.attia at ag.tamu.edu
> Cell phone: 001-979-248-5215

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From smartpink111 at yahoo.com  Tue Sep 17 20:56:35 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 17 Sep 2013 11:56:35 -0700 (PDT)
Subject: [R] delete some lines of a dataframe
In-Reply-To: <52389C1C.4050503@cirad.fr>
References: <52389C1C.4050503@cirad.fr>
Message-ID: <1379444195.73052.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Try:
Df1[duplicated(Df1),]
?Df1[duplicated(Df1,fromLast=TRUE),]
A.K.



----- Original Message -----
From: Arnaud Michel <michel.arnaud at cirad.fr>
To: R help <r-help at r-project.org>
Cc: 
Sent: Tuesday, September 17, 2013 2:14 PM
Subject: [R] delete some lines of a dataframe

Hi

I have a dataframe Df1
dput(Df1)
structure(list(Mat = c(141, 141, 157, 157, 188, 188, 232, 232,
253, 253, 253, 254, 254, 254, 254, 256, 256, 264, 264), Prenom = c("Pierre",
"Pierre", "Jean-Claude", "Jean-Claude", "Jean-Louis", "Jean-Louis",
"Philippe", "Philippe", "Christophe", "Christophe", "Christophe",
"Dominique", "Dominique", "Dominique", "Dominique", "Pierre-Luc",
"Pierre-Luc", "Alain", "Alain"), Sexe = c("Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin"),
? ? DateNais = c("23/08/1946", "23/08/1946", "11/08/1945", "11/08/1945",
? ? "09/04/1948", "09/04/1948", "01/05/1946", "01/05/1946", "11/02/1951",
? ? "11/02/1951", "11/02/1951", "21/10/1949", "21/10/1949", "21/10/1949",
? ? "21/10/1949", "25/06/1946", "25/06/1946", "13/03/1949", "13/03/1949"
? ? )), .Names = c("Mat", "Prenom", "Sexe", "DateNais"), row.names = c("207",
"208", "232", "233", "288", "289", "373", "374", "412", "413",
"414", "415", "416", "417", "418", "420", "421", "436", "437"
), class = "data.frame")

I want to extract of Df1 2 other dataframes :
1) delete the first line for each values of Mat
? ? ?  Mat? ? ? Prenom? ?  Sexe?  DateNais
208 141? ? ? Pierre Masculin 23/08/1946
233 157 Jean-Claude Masculin 11/08/1945
289 188? Jean-Louis Masculin 09/04/1948
374 232? ? Philippe Masculin 01/05/1946
413 253? Christophe Masculin 11/02/1951
414 253? Christophe Masculin 11/02/1951
416 254?  Dominique Masculin 21/10/1949
417 254?  Dominique Masculin 21/10/1949
418 254?  Dominique Masculin 21/10/1949
421 256? Pierre-Luc Masculin 25/06/1946
437 264? ? ?  Alain Masculin 13/03/1949

2) delete the last line for each values of Mat
? ? Mat? ? ? Prenom? ?  Sexe?  DateNais
207 141? ? ? Pierre Masculin 23/08/1946
232 157 Jean-Claude Masculin 11/08/1945
288 188? Jean-Louis Masculin 09/04/1948
373 232? ? Philippe Masculin 01/05/1946
412 253? Christophe Masculin 11/02/1951
413 253? Christophe Masculin 11/02/1951
415 254?  Dominique Masculin 21/10/1949
416 254?  Dominique Masculin 21/10/1949
417 254?  Dominique Masculin 21/10/1949
420 256? Pierre-Luc Masculin 25/06/1946
436 264? ? ?  Alain Masculin 13/03/1949

Any ideas ?


-- Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ross at biostat.ucsf.edu  Tue Sep 17 21:06:15 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Tue, 17 Sep 2013 12:06:15 -0700
Subject: [R] save/load doubles memory
Message-ID: <1379444775.16341.261.camel@localhost>

Saving and loading data is roughly doubling memory use.  I'm trying to
understand and correct the problem.

R1 was an R process using just over 2G of memory.
I did save(r3b, r4, sflist, file="r4.rdata")
and then, in a new process R2,
load(file="r4.rdata")

R2 used just under 4G of memory, i.e., almost double the original
process.  The r4.rdata file was just under 2G, which seemed like very
little compression.

r4 was created by
r4 <- sflist2stanfit(sflist)

I presume that r4 and sflist shared most of their memory.
The save() apparently lost the information that the memory was shared,
doubling memory use.

R 2.15.1, 64 bit on linux.

First, does my diagnosis sound right?  The reports of memory use in R2
are quite a bit lower than the process footprint; is that normal?
> gc()  # after loading data
            used   (Mb) gc trigger   (Mb)  max used   (Mb)
Ncells   1988691  106.3    3094291  165.3   2432643  130.0
Vcells 266976864 2036.9  282174979 2152.9 268661172 2049.8
> rm("r4")
> gc()
            used   (Mb) gc trigger   (Mb)  max used   (Mb)
Ncells   1949626  104.2    3094291  165.3   2432643  130.0
Vcells 190689777 1454.9  282174979 2152.9 268661172 2049.8
> r4 <- sflist2stanfit(sflist)
> gc()
            used   (Mb) gc trigger   (Mb)  max used   (Mb)
Ncells   1970497  105.3    3094291  165.3   2432643  130.0
Vcells 228827252 1745.9  296363727 2261.1 268661172 2049.8
> 

Even weirder, R1 reports memory use well beyond the memory I show the
process using (2.2G)
> gc()
             used   (Mb) gc trigger   (Mb)  max used   (Mb)
 Ncells   3640941  194.5    5543382  296.1   5543382  296.1
 Vcells 418720281 3194.6  553125025 4220.1 526708090 4018.5


Second, what can I do to avoid the problem?

I guess in this case I could not save r4 and recreate it, but is there a
more general solution?

If I did myboth <- list(r4, sflist) and
save(myboth, file="myfile")
would that be enough to keep the objects together?  Judging from the
size of the file, it seems not.

Even if the myboth trick worked it seems like a kludge.

Ross Boylan


From ross at biostat.ucsf.edu  Tue Sep 17 21:19:50 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Tue, 17 Sep 2013 12:19:50 -0700
Subject: [R] save/load doubles memory [oops]
In-Reply-To: <1379444775.16341.261.camel@localhost>
References: <1379444775.16341.261.camel@localhost>
Message-ID: <1379445590.16341.268.camel@localhost>

On Tue, 2013-09-17 at 12:06 -0700, Ross Boylan wrote:
> Saving and loading data is roughly doubling memory use.  I'm trying to
> understand and correct the problem.
Apparently I had the process memories mixed up: R1 below was the one
with 4G and R2 with 2G.  So there's less of a mystery.  However...
> 
> R1 was an R process using just over 2G of memory.
> I did save(r3b, r4, sflist, file="r4.rdata")
> and then, in a new process R2,
> load(file="r4.rdata")
> 
> R2 used just under 4G of memory, i.e., almost double the original
> process.  The r4.rdata file was just under 2G, which seemed like very
> little compression.
> 
> r4 was created by
> r4 <- sflist2stanfit(sflist)
> 
> I presume that r4 and sflist shared most of their memory.
> The save() apparently lost the information that the memory was shared,
> doubling memory use.
Still wondering if this is going on.
> 
> R 2.15.1, 64 bit on linux.
> 
> First, does my diagnosis sound right?  The reports of memory use in R2
> are quite a bit lower than the process footprint; is that normal?
> > gc()  # after loading data
>             used   (Mb) gc trigger   (Mb)  max used   (Mb)
> Ncells   1988691  106.3    3094291  165.3   2432643  130.0
> Vcells 266976864 2036.9  282174979 2152.9 268661172 2049.8
> > rm("r4")
> > gc()
>             used   (Mb) gc trigger   (Mb)  max used   (Mb)
> Ncells   1949626  104.2    3094291  165.3   2432643  130.0
> Vcells 190689777 1454.9  282174979 2152.9 268661172 2049.8
> > r4 <- sflist2stanfit(sflist)
> > gc()
>             used   (Mb) gc trigger   (Mb)  max used   (Mb)
> Ncells   1970497  105.3    3094291  165.3   2432643  130.0
> Vcells 228827252 1745.9  296363727 2261.1 268661172 2049.8
> > 
It seems the recreated r4 used about 300M less memory than the one read
in from disk.  This suggests that some of the sharing was lost in the
save/load  process.

> 
> Even weirder, R1 reports memory use well beyond the memory I show the
> process using (2.2G)
Not a mystery after getting the right processes.  Actually, I'm a little
surprised the process memory is less than the max used memory; I thought
giving back memory was not possible on Linux.
> > gc()
>              used   (Mb) gc trigger   (Mb)  max used   (Mb)
>  Ncells   3640941  194.5    5543382  296.1   5543382  296.1
>  Vcells 418720281 3194.6  553125025 4220.1 526708090 4018.5
> 
> 
> Second, what can I do to avoid the problem?

Now a more modest problem, though still a problem.
> 
> I guess in this case I could not save r4 and recreate it, but is there a
> more general solution?
> 
> If I did myboth <- list(r4, sflist) and
> save(myboth, file="myfile")
> would that be enough to keep the objects together?  Judging from the
> size of the file, it seems not.
> 
> Even if the myboth trick worked it seems like a kludge.
> 
> Ross Boylan
>


From a.mosnier at gmail.com  Tue Sep 17 21:26:26 2013
From: a.mosnier at gmail.com (Arnaud Mosnier)
Date: Tue, 17 Sep 2013 15:26:26 -0400
Subject: [R] lowercase and uppercase greek letters
Message-ID: <CANkFkEckY1zN_Nm8fiMdr-i1OsJuEZTw8dJeQTuEosHmKmC1Nw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130917/990b6de3/attachment.pl>

From murdoch.duncan at gmail.com  Tue Sep 17 21:35:41 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 17 Sep 2013 15:35:41 -0400
Subject: [R] lowercase and uppercase greek letters
In-Reply-To: <CANkFkEckY1zN_Nm8fiMdr-i1OsJuEZTw8dJeQTuEosHmKmC1Nw@mail.gmail.com>
References: <CANkFkEckY1zN_Nm8fiMdr-i1OsJuEZTw8dJeQTuEosHmKmC1Nw@mail.gmail.com>
Message-ID: <5238AF0D.4080608@gmail.com>

On 17/09/2013 3:26 PM, Arnaud Mosnier wrote:
> Hi all,
>
> I want to present a figure including the uppercase and lowercase version of
> the greek letter phi.
>
> I know that I can use "expression" to have the symbol like in:
>
> plot(1~1, main = expression(phi))
>
> But, is there somewhere things like upper(phi) or lower(phi) ?

No functions for that.  You just need to give the letters in lowercase 
or uppercase:  lowercase is phi, uppercase is Phi.  Run
demo(plotmath) for more hints.

Duncan Murdoch


From luke-tierney at uiowa.edu  Tue Sep 17 21:39:04 2013
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Tue, 17 Sep 2013 14:39:04 -0500
Subject: [R] save/load doubles memory [oops]
In-Reply-To: <1379445590.16341.268.camel@localhost>
References: <1379444775.16341.261.camel@localhost>
	<1379445590.16341.268.camel@localhost>
Message-ID: <alpine.DEB.2.02.1309171435340.2134@luke-Latitude>

At this point R's serialization format only preserves sharing of
environments; any other sharing is lost. Changing this will require an
extensive rewrite of serialization. It would be useful to have this,
especially as we are trying to increase sharing/decrease copying, but
it isn't likely any time soon.

Best,

luke

On Tue, 17 Sep 2013, Ross Boylan wrote:

> On Tue, 2013-09-17 at 12:06 -0700, Ross Boylan wrote:
>> Saving and loading data is roughly doubling memory use.  I'm trying to
>> understand and correct the problem.
> Apparently I had the process memories mixed up: R1 below was the one
> with 4G and R2 with 2G.  So there's less of a mystery.  However...
>>
>> R1 was an R process using just over 2G of memory.
>> I did save(r3b, r4, sflist, file="r4.rdata")
>> and then, in a new process R2,
>> load(file="r4.rdata")
>>
>> R2 used just under 4G of memory, i.e., almost double the original
>> process.  The r4.rdata file was just under 2G, which seemed like very
>> little compression.
>>
>> r4 was created by
>> r4 <- sflist2stanfit(sflist)
>>
>> I presume that r4 and sflist shared most of their memory.
>> The save() apparently lost the information that the memory was shared,
>> doubling memory use.
> Still wondering if this is going on.
>>
>> R 2.15.1, 64 bit on linux.
>>
>> First, does my diagnosis sound right?  The reports of memory use in R2
>> are quite a bit lower than the process footprint; is that normal?
>>> gc()  # after loading data
>>             used   (Mb) gc trigger   (Mb)  max used   (Mb)
>> Ncells   1988691  106.3    3094291  165.3   2432643  130.0
>> Vcells 266976864 2036.9  282174979 2152.9 268661172 2049.8
>>> rm("r4")
>>> gc()
>>             used   (Mb) gc trigger   (Mb)  max used   (Mb)
>> Ncells   1949626  104.2    3094291  165.3   2432643  130.0
>> Vcells 190689777 1454.9  282174979 2152.9 268661172 2049.8
>>> r4 <- sflist2stanfit(sflist)
>>> gc()
>>             used   (Mb) gc trigger   (Mb)  max used   (Mb)
>> Ncells   1970497  105.3    3094291  165.3   2432643  130.0
>> Vcells 228827252 1745.9  296363727 2261.1 268661172 2049.8
>>>
> It seems the recreated r4 used about 300M less memory than the one read
> in from disk.  This suggests that some of the sharing was lost in the
> save/load  process.
>
>>
>> Even weirder, R1 reports memory use well beyond the memory I show the
>> process using (2.2G)
> Not a mystery after getting the right processes.  Actually, I'm a little
> surprised the process memory is less than the max used memory; I thought
> giving back memory was not possible on Linux.
>>> gc()
>>              used   (Mb) gc trigger   (Mb)  max used   (Mb)
>>  Ncells   3640941  194.5    5543382  296.1   5543382  296.1
>>  Vcells 418720281 3194.6  553125025 4220.1 526708090 4018.5
>>
>>
>> Second, what can I do to avoid the problem?
>
> Now a more modest problem, though still a problem.
>>
>> I guess in this case I could not save r4 and recreate it, but is there a
>> more general solution?
>>
>> If I did myboth <- list(r4, sflist) and
>> save(myboth, file="myfile")
>> would that be enough to keep the objects together?  Judging from the
>> size of the file, it seems not.
>>
>> Even if the myboth trick worked it seems like a kludge.
>>
>> Ross Boylan
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From ross at biostat.ucsf.edu  Tue Sep 17 21:51:04 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Tue, 17 Sep 2013 12:51:04 -0700
Subject: [R] save/load doubles memory [oops]
In-Reply-To: <alpine.DEB.2.02.1309171435340.2134@luke-Latitude>
References: <1379444775.16341.261.camel@localhost>
	<1379445590.16341.268.camel@localhost>
	<alpine.DEB.2.02.1309171435340.2134@luke-Latitude>
Message-ID: <1379447464.16341.275.camel@localhost>

On Tue, 2013-09-17 at 14:39 -0500, luke-tierney at uiowa.edu wrote:
> At this point R's serialization format only preserves sharing of
> environments; any other sharing is lost. Changing this will require an
> extensive rewrite of serialization. It would be useful to have this,
> especially as we are trying to increase sharing/decrease copying, but
> it isn't likely any time soon.
> 
> Best,
> 
> luke
Thanks for the info.

Does this apply save.image() as well, i.e., can simply saving a
workspace, quitting, starting and reloading result in more memory use?

While searching about this issue I came across saveRDS.  Does that
operate any differently with respect to sharing?

Ross


From michel.arnaud at cirad.fr  Tue Sep 17 22:00:13 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Tue, 17 Sep 2013 22:00:13 +0200
Subject: [R] delete some lines of a dataframe
In-Reply-To: <1379444195.73052.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <52389C1C.4050503@cirad.fr>
	<1379444195.73052.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <5238B4CD.8010104@cirad.fr>

Thank you Arun
but the values of other columns may be different !!!
Michel
Le 17/09/2013 20:56, arun a ?crit :
> Hi,
> Try:
> Df1[duplicated(Df1),]
>   Df1[duplicated(Df1,fromLast=TRUE),]
> A.K.
>
>
>
> ----- Original Message -----
> From: Arnaud Michel <michel.arnaud at cirad.fr>
> To: R help <r-help at r-project.org>
> Cc:
> Sent: Tuesday, September 17, 2013 2:14 PM
> Subject: [R] delete some lines of a dataframe
>
> Hi
>
> I have a dataframe Df1
> dput(Df1)
> structure(list(Mat = c(141, 141, 157, 157, 188, 188, 232, 232,
> 253, 253, 253, 254, 254, 254, 254, 256, 256, 264, 264), Prenom = c("Pierre",
> "Pierre", "Jean-Claude", "Jean-Claude", "Jean-Louis", "Jean-Louis",
> "Philippe", "Philippe", "Christophe", "Christophe", "Christophe",
> "Dominique", "Dominique", "Dominique", "Dominique", "Pierre-Luc",
> "Pierre-Luc", "Alain", "Alain"), Sexe = c("Masculin", "Masculin",
> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin"),
>      DateNais = c("23/08/1946", "23/08/1946", "11/08/1945", "11/08/1945",
>      "09/04/1948", "09/04/1948", "01/05/1946", "01/05/1946", "11/02/1951",
>      "11/02/1951", "11/02/1951", "21/10/1949", "21/10/1949", "21/10/1949",
>      "21/10/1949", "25/06/1946", "25/06/1946", "13/03/1949", "13/03/1949"
>      )), .Names = c("Mat", "Prenom", "Sexe", "DateNais"), row.names = c("207",
> "208", "232", "233", "288", "289", "373", "374", "412", "413",
> "414", "415", "416", "417", "418", "420", "421", "436", "437"
> ), class = "data.frame")
>
> I want to extract of Df1 2 other dataframes :
> 1) delete the first line for each values of Mat
>         Mat      Prenom     Sexe   DateNais
> 208 141      Pierre Masculin 23/08/1946
> 233 157 Jean-Claude Masculin 11/08/1945
> 289 188  Jean-Louis Masculin 09/04/1948
> 374 232    Philippe Masculin 01/05/1946
> 413 253  Christophe Masculin 11/02/1951
> 414 253  Christophe Masculin 11/02/1951
> 416 254   Dominique Masculin 21/10/1949
> 417 254   Dominique Masculin 21/10/1949
> 418 254   Dominique Masculin 21/10/1949
> 421 256  Pierre-Luc Masculin 25/06/1946
> 437 264       Alain Masculin 13/03/1949
>
> 2) delete the last line for each values of Mat
>      Mat      Prenom     Sexe   DateNais
> 207 141      Pierre Masculin 23/08/1946
> 232 157 Jean-Claude Masculin 11/08/1945
> 288 188  Jean-Louis Masculin 09/04/1948
> 373 232    Philippe Masculin 01/05/1946
> 412 253  Christophe Masculin 11/02/1951
> 413 253  Christophe Masculin 11/02/1951
> 415 254   Dominique Masculin 21/10/1949
> 416 254   Dominique Masculin 21/10/1949
> 417 254   Dominique Masculin 21/10/1949
> 420 256  Pierre-Luc Masculin 25/06/1946
> 436 264       Alain Masculin 13/03/1949
>
> Any ideas ?
>
>
> -- Michel ARNAUD
> Charg? de mission aupr?s du DRH
> DGDRD-Drh - TA 174/04
> Av Agropolis 34398 Montpellier cedex 5
> tel : 04.67.61.75.38
> fax : 04.67.61.57.87
> port: 06.47.43.55.31
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From smartpink111 at yahoo.com  Tue Sep 17 22:21:07 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 17 Sep 2013 13:21:07 -0700 (PDT)
Subject: [R] delete some lines of a dataframe
In-Reply-To: <5238B4CD.8010104@cirad.fr>
References: <52389C1C.4050503@cirad.fr>
	<1379444195.73052.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<5238B4CD.8010104@cirad.fr>
Message-ID: <1379449267.62114.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi Arnaud,

In that case:

Try:
Df1[duplicated(Df1$Mat),]
?Df1[duplicated(Df1$Mat,fromLast=TRUE),]

#or


A.K.


----- Original Message -----
From: Arnaud Michel <michel.arnaud at cirad.fr>
To: arun <smartpink111 at yahoo.com>
Cc: R help <r-help at r-project.org>
Sent: Tuesday, September 17, 2013 4:00 PM
Subject: Re: [R] delete some lines of a dataframe

Thank you Arun
but the values of other columns may be different !!!
Michel
Le 17/09/2013 20:56, arun a ?crit :
> Hi,
> Try:
> Df1[duplicated(Df1),]
>?  Df1[duplicated(Df1,fromLast=TRUE),]
> A.K.
>
>
>
> ----- Original Message -----
> From: Arnaud Michel <michel.arnaud at cirad.fr>
> To: R help <r-help at r-project.org>
> Cc:
> Sent: Tuesday, September 17, 2013 2:14 PM
> Subject: [R] delete some lines of a dataframe
>
> Hi
>
> I have a dataframe Df1
> dput(Df1)
> structure(list(Mat = c(141, 141, 157, 157, 188, 188, 232, 232,
> 253, 253, 253, 254, 254, 254, 254, 256, 256, 264, 264), Prenom = c("Pierre",
> "Pierre", "Jean-Claude", "Jean-Claude", "Jean-Louis", "Jean-Louis",
> "Philippe", "Philippe", "Christophe", "Christophe", "Christophe",
> "Dominique", "Dominique", "Dominique", "Dominique", "Pierre-Luc",
> "Pierre-Luc", "Alain", "Alain"), Sexe = c("Masculin", "Masculin",
> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin"),
>? ? ? DateNais = c("23/08/1946", "23/08/1946", "11/08/1945", "11/08/1945",
>? ? ? "09/04/1948", "09/04/1948", "01/05/1946", "01/05/1946", "11/02/1951",
>? ? ? "11/02/1951", "11/02/1951", "21/10/1949", "21/10/1949", "21/10/1949",
>? ? ? "21/10/1949", "25/06/1946", "25/06/1946", "13/03/1949", "13/03/1949"
>? ? ? )), .Names = c("Mat", "Prenom", "Sexe", "DateNais"), row.names = c("207",
> "208", "232", "233", "288", "289", "373", "374", "412", "413",
> "414", "415", "416", "417", "418", "420", "421", "436", "437"
> ), class = "data.frame")
>
> I want to extract of Df1 2 other dataframes :
> 1) delete the first line for each values of Mat
>? ? ? ?  Mat? ? ? Prenom? ?  Sexe?  DateNais
> 208 141? ? ? Pierre Masculin 23/08/1946
> 233 157 Jean-Claude Masculin 11/08/1945
> 289 188? Jean-Louis Masculin 09/04/1948
> 374 232? ? Philippe Masculin 01/05/1946
> 413 253? Christophe Masculin 11/02/1951
> 414 253? Christophe Masculin 11/02/1951
> 416 254?  Dominique Masculin 21/10/1949
> 417 254?  Dominique Masculin 21/10/1949
> 418 254?  Dominique Masculin 21/10/1949
> 421 256? Pierre-Luc Masculin 25/06/1946
> 437 264? ? ?  Alain Masculin 13/03/1949
>
> 2) delete the last line for each values of Mat
>? ? ? Mat? ? ? Prenom? ?  Sexe?  DateNais
> 207 141? ? ? Pierre Masculin 23/08/1946
> 232 157 Jean-Claude Masculin 11/08/1945
> 288 188? Jean-Louis Masculin 09/04/1948
> 373 232? ? Philippe Masculin 01/05/1946
> 412 253? Christophe Masculin 11/02/1951
> 413 253? Christophe Masculin 11/02/1951
> 415 254?  Dominique Masculin 21/10/1949
> 416 254?  Dominique Masculin 21/10/1949
> 417 254?  Dominique Masculin 21/10/1949
> 420 256? Pierre-Luc Masculin 25/06/1946
> 436 264? ? ?  Alain Masculin 13/03/1949
>
> Any ideas ?
>
>
> -- Michel ARNAUD
> Charg? de mission aupr?s du DRH
> DGDRD-Drh - TA 174/04
> Av Agropolis 34398 Montpellier cedex 5
> tel : 04.67.61.75.38
> fax : 04.67.61.57.87
> port: 06.47.43.55.31
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From rolf.turner at xtra.co.nz  Tue Sep 17 22:34:55 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Wed, 18 Sep 2013 08:34:55 +1200
Subject: [R] lowercase and uppercase greek letters
In-Reply-To: <CANkFkEckY1zN_Nm8fiMdr-i1OsJuEZTw8dJeQTuEosHmKmC1Nw@mail.gmail.com>
References: <CANkFkEckY1zN_Nm8fiMdr-i1OsJuEZTw8dJeQTuEosHmKmC1Nw@mail.gmail.com>
Message-ID: <5238BCEF.5050808@xtra.co.nz>

On 09/18/13 07:26, Arnaud Mosnier wrote:
> Hi all,
>
> I want to present a figure including the uppercase and lowercase version of
> the greek letter phi.
>
> I know that I can use "expression" to have the symbol like in:
>
> plot(1~1, main = expression(phi))
>
> But, is there somewhere things like upper(phi) or lower(phi) ?
>
> Thanks for your help !

RTFM.  From ?plotmath:

alpha -- omega     Greek symbols
Alpha -- Omega     uppercase Greek symbols

     cheers,

     Rolf Turner


From smartpink111 at yahoo.com  Tue Sep 17 22:41:02 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 17 Sep 2013 13:41:02 -0700 (PDT)
Subject: [R] delete some lines of a dataframe
In-Reply-To: <1379449267.62114.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <52389C1C.4050503@cirad.fr>
	<1379444195.73052.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<5238B4CD.8010104@cirad.fr>
	<1379449267.62114.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <1379450462.83455.YahooMailNeo@web142604.mail.bf1.yahoo.com>



Hi Arnaud,
You could also try:
indx<- Df1$Mat[-1]==Df1$Mat[-nrow(Df1)]
indx1<-c(indx,FALSE)
indx2<-c(FALSE,indx)

Df1[indx1,]
?Df1[indx2,]
A.K.



________________________________
From: arun <smartpink111 at yahoo.com>
To: Arnaud Michel <michel.arnaud at cirad.fr> 
Cc: R help <r-help at r-project.org> 
Sent: Tuesday, September 17, 2013 4:21 PM
Subject: Re: [R] delete some lines of a dataframe


Hi Arnaud,

In that case:

Try:
Df1[duplicated(Df1$Mat),]
?Df1[duplicated(Df1$Mat,fromLast=TRUE),]

#or


A.K.


----- Original Message -----
From: Arnaud Michel <michel.arnaud at cirad.fr>
To: arun <smartpink111 at yahoo.com>
Cc: R help <r-help at r-project.org>
Sent: Tuesday, September 17, 2013 4:00 PM
Subject: Re: [R] delete some lines of a dataframe

Thank you Arun
but the values of other columns may be different !!!
Michel
Le 17/09/2013 20:56, arun a ?crit :
> Hi,
> Try:
> Df1[duplicated(Df1),]
>?? Df1[duplicated(Df1,fromLast=TRUE),]
> A.K.
>
>
>
> ----- Original Message -----
> From: Arnaud Michel <michel.arnaud at cirad.fr>
> To: R help <r-help at r-project.org>
> Cc:
> Sent: Tuesday, September 17, 2013 2:14 PM
> Subject: [R] delete some lines of a dataframe
>
> Hi
>
> I have a dataframe Df1
> dput(Df1)
> structure(list(Mat = c(141, 141, 157, 157, 188, 188, 232, 232,
> 253, 253, 253, 254, 254, 254, 254, 256, 256, 264, 264), Prenom = c("Pierre",
> "Pierre", "Jean-Claude", "Jean-Claude", "Jean-Louis", "Jean-Louis",
> "Philippe", "Philippe", "Christophe", "Christophe", "Christophe",
> "Dominique", "Dominique", "Dominique", "Dominique", "Pierre-Luc",
> "Pierre-Luc", "Alain", "Alain"), Sexe = c("Masculin", "Masculin",
> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin"),
>? ? ? DateNais = c("23/08/1946", "23/08/1946", "11/08/1945", "11/08/1945",
>? ? ? "09/04/1948", "09/04/1948", "01/05/1946", "01/05/1946", "11/02/1951",
>? ? ? "11/02/1951", "11/02/1951", "21/10/1949", "21/10/1949", "21/10/1949",
>? ? ? "21/10/1949", "25/06/1946", "25/06/1946", "13/03/1949", "13/03/1949"
>? ? ? )), .Names = c("Mat", "Prenom", "Sexe", "DateNais"), row.names = c("207",
> "208", "232", "233", "288", "289", "373", "374", "412", "413",
> "414", "415", "416", "417", "418", "420", "421", "436", "437"
> ), class = "data.frame")
>
> I want to extract of Df1 2 other dataframes :
> 1) delete the first line for each values of Mat
>? ? ? ?? Mat? ? ? Prenom? ?? Sexe?? DateNais
> 208 141? ? ? Pierre Masculin 23/08/1946
> 233 157 Jean-Claude Masculin 11/08/1945
> 289 188? Jean-Louis Masculin 09/04/1948
> 374 232? ? Philippe Masculin 01/05/1946
> 413 253? Christophe Masculin 11/02/1951
> 414 253? Christophe Masculin 11/02/1951
> 416 254?? Dominique Masculin 21/10/1949
> 417 254?? Dominique Masculin 21/10/1949
> 418 254?? Dominique Masculin 21/10/1949
> 421 256? Pierre-Luc Masculin 25/06/1946
> 437 264? ? ?? Alain Masculin 13/03/1949
>
> 2) delete the last line for each values of Mat
>? ? ? Mat? ? ? Prenom? ?? Sexe?? DateNais
> 207 141? ? ? Pierre Masculin 23/08/1946
> 232 157 Jean-Claude Masculin 11/08/1945
> 288 188? Jean-Louis Masculin 09/04/1948
> 373 232? ? Philippe Masculin 01/05/1946
> 412 253? Christophe Masculin 11/02/1951
> 413 253? Christophe Masculin 11/02/1951
> 415 254?? Dominique Masculin 21/10/1949
> 416 254?? Dominique Masculin 21/10/1949
> 417 254?? Dominique Masculin 21/10/1949
> 420 256? Pierre-Luc Masculin 25/06/1946
> 436 264? ? ?? Alain Masculin 13/03/1949
>
> Any ideas ?
>
>
> -- Michel ARNAUD
> Charg? de mission aupr?s du DRH
> DGDRD-Drh - TA 174/04
> Av Agropolis 34398 Montpellier cedex 5
> tel : 04.67.61.75.38
> fax : 04.67.61.57.87
> port: 06.47.43.55.31
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From bbolker at gmail.com  Tue Sep 17 23:17:35 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 17 Sep 2013 21:17:35 +0000
Subject: [R] lme4: How to specify nested factors, meaning of : and %in%
References: <26389D1F4F62BE4DBEB36F898B97D5011D045A5B@exch-mbx-02.utu.fi>
Message-ID: <loom.20130917T231539-260@post.gmane.org>

Shouli Li <shouli.li <at> utu.fi> writes:

> 
> I have the same problem. I am wondering have you solved the problem already?
> 
> 	[[alternative HTML version deleted]]
> 
> 


  It's completely unclear from this message what the context is,
so it's unanswerable -- sorry.  (Perhaps there was a link to
the original question that got stripped -- I'm reading it on
gmane.comp.lang.r.general ...)

  Can you please repost this to r-sig-mixed-models at r-project.org,
referencing https://stat.ethz.ch/pipermail/r-help/2008-April/158761.html
(which I was able to find by doing some googling)?


From lorenzo.isella at gmail.com  Tue Sep 17 23:25:33 2013
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Tue, 17 Sep 2013 23:25:33 +0200
Subject: [R] Generation of a Markov Chain
Message-ID: <op.w3kq4vaczqkd1e@nirvana>

Dear All,
While looking for a way to generate a Markov chain given a transition  
matrix, I found this

http://bit.ly/1a1CFl8

but the example provided does not work on my machine

> y<-numeric(100)
> x=matrix(runif(16),4,4) for(i in 2:100) {
+  y[i]=which(rmultinom(1, size = 1, prob = x[y[i-1], ])==1) }
Error in rmultinom(1, size = 1, prob = x[y[i - 1], ]) :
   too few positive probabilities

Any idea about how to fix this?
Cheers

Lorenzo


From dwarnold45 at suddenlink.net  Tue Sep 17 23:33:32 2013
From: dwarnold45 at suddenlink.net (David Arnold)
Date: Tue, 17 Sep 2013 14:33:32 -0700 (PDT)
Subject: [R] "With" question
Message-ID: <1379453612818-4676379.post@n4.nabble.com>

All,

Trying to avoid using attach and detach while teaching class in Intro Stats.

data=read.delim("dataset1.dat",header=TRUE)
with(data,{
  sort(age)
  length(age)
  (age[10]+age[11])/2
})

However, this code only produces output for the last line between the curly
braces. Granted, as we type the lines in one at a time and execute the code,
we'll see each output. And, we can fix the problem by adding a print to each
line.

Wonder if there are any other suggestions?

David



--
View this message in context: http://r.789695.n4.nabble.com/With-question-tp4676379.html
Sent from the R help mailing list archive at Nabble.com.


From jdnewmil at dcn.davis.CA.us  Tue Sep 17 23:42:54 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 17 Sep 2013 14:42:54 -0700
Subject: [R] save/load doubles memory [oops]
In-Reply-To: <1379447464.16341.275.camel@localhost>
References: <1379444775.16341.261.camel@localhost>
	<1379445590.16341.268.camel@localhost>
	<alpine.DEB.2.02.1309171435340.2134@luke-Latitude>
	<1379447464.16341.275.camel@localhost>
Message-ID: <714121e2-fbad-4d88-8005-229402772980@email.android.com>

The alternatives you mention are all forms of serialization, so they are all subject to this limitation. As Luke said, it would be a lot of work to fix this, so if the answer were as easy as using a different function then they would already have done that.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Ross Boylan <ross at biostat.ucsf.edu> wrote:
>On Tue, 2013-09-17 at 14:39 -0500, luke-tierney at uiowa.edu wrote:
>> At this point R's serialization format only preserves sharing of
>> environments; any other sharing is lost. Changing this will require
>an
>> extensive rewrite of serialization. It would be useful to have this,
>> especially as we are trying to increase sharing/decrease copying, but
>> it isn't likely any time soon.
>> 
>> Best,
>> 
>> luke
>Thanks for the info.
>
>Does this apply save.image() as well, i.e., can simply saving a
>workspace, quitting, starting and reloading result in more memory use?
>
>While searching about this issue I came across saveRDS.  Does that
>operate any differently with respect to sharing?
>
>Ross
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From h.wickham at gmail.com  Tue Sep 17 23:47:25 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 17 Sep 2013 17:47:25 -0400
Subject: [R] microbenchmark
In-Reply-To: <5236F581.2020300@u-paris10.fr>
References: <5236F581.2020300@u-paris10.fr>
Message-ID: <CABdHhvHv7h7zRrFk0MaAUO3p8Skf4Jrevz9aCLMATrvDBAMnKA@mail.gmail.com>

I'm not sure why either, but here's a simpler (and much faster)
illustration of the problem:

library(microbenchmark)

A <- matrix(1:9,3)

replicate(10, microbenchmark(colMeans(A), times = 4)$time)
replicate(10, microbenchmark(A, times = 4)$time)

Hadley

On Mon, Sep 16, 2013 at 8:11 AM, Christophe Genolini
<cgenolin at u-paris10.fr> wrote:
> Hi the list,
>
> I am using the function microbenchmark to measure the performance of some
> code. But I notice that the first execution of the code takes much longueur
> than the next executions.
> I compare it to several executions of the code :
>
> --- 8< ----------
> A <- matrix(1:9,3)
> nbReroll <- 1000
> temps <- matrix(NA,1000,2)
> temps[,1] <- microbenchmark(colMeans(A),times=nbReroll)$time
>
> for(j in 1:nbReroll){
>     temps[j,2] <- microbenchmark(colMeans(A),times=1)$time
> }
>
> --- 8< -----------
> Here is a plot of the result I get.
>  - In red, temps[,1], that is microbenchmarck(...,times=1000)
>  - In blue temps[,2], that is for(i in 1:1000)microbenchmark(...times=1)
>
>
> So why is there such a bid difference? What is the correct execution time
> for my instruction?
>
> Christophe
>
> --
> Christophe Genolini
> Ma?tre de conf?rences en bio-statistique
> Vice pr?sident Communication interne et animation du campus
> Universit? Paris Ouest Nanterre La D?fense
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Chief Scientist, RStudio
http://had.co.nz/


From NordlDJ at dshs.wa.gov  Tue Sep 17 23:58:13 2013
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Tue, 17 Sep 2013 21:58:13 +0000
Subject: [R] Generation of a Markov Chain
In-Reply-To: <op.w3kq4vaczqkd1e@nirvana>
References: <op.w3kq4vaczqkd1e@nirvana>
Message-ID: <F7E6D18CC2877149AB5296CE54EA2766238F4AB6@WAXMXOLYMB025.WAX.wa.lcl>

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Lorenzo Isella
> Sent: Tuesday, September 17, 2013 2:26 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Generation of a Markov Chain
> 
> Dear All,
> While looking for a way to generate a Markov chain given a transition
> matrix, I found this
> 
> http://bit.ly/1a1CFl8
> 
> but the example provided does not work on my machine
> 
> > y<-numeric(100)
> > x=matrix(runif(16),4,4) for(i in 2:100) {
> +  y[i]=which(rmultinom(1, size = 1, prob = x[y[i-1], ])==1) }
> Error in rmultinom(1, size = 1, prob = x[y[i - 1], ]) :
>    too few positive probabilities
> 
> Any idea about how to fix this?
> Cheers
> 
> Lorenzo
> 

Seems to me that the code you point to requires you to set the initial state. So do something like this

y=numeric(100)
y[1]=1  # set initial state (to 1, 2, 3 or 4)

x=matrix(runif(16),4,4) 
 for(i in 2:100) { 
 y[i]=which(rmultinom(1, size = 1, prob = x[y[i-1], ])==1) 
 } 


Hope this is helpful,

Dan

Daniel J. Nordlund
Washington State Department of Social and Health Services
Planning, Performance, and Accountability
Research and Data Analysis Division
Olympia, WA 98504-5204



From kripa777 at hotmail.com  Wed Sep 18 00:13:13 2013
From: kripa777 at hotmail.com (Kripa R)
Date: Tue, 17 Sep 2013 22:13:13 +0000
Subject: [R] PAMR - adding additional labels
Message-ID: <BAY179-W29BCF1D00D6A6FC4D7B44799270@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130917/30778aa1/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Wed Sep 18 00:22:09 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 17 Sep 2013 15:22:09 -0700
Subject: [R] "With" question
In-Reply-To: <1379453612818-4676379.post@n4.nabble.com>
References: <1379453612818-4676379.post@n4.nabble.com>
Message-ID: <4a7d5306-1735-4d97-898d-27670426df15@email.android.com>

You seem to be applying the syntax for the within function to the with function. You should compare the documentation for them and choose your approach accordingly.
Also once inside a code block of any type, simply typing a variable name no longer prints it, so you need to use the appropriate function (print or cat).
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

David Arnold <dwarnold45 at suddenlink.net> wrote:
>All,
>
>Trying to avoid using attach and detach while teaching class in Intro
>Stats.
>
>data=read.delim("dataset1.dat",header=TRUE)
>with(data,{
>  sort(age)
>  length(age)
>  (age[10]+age[11])/2
>})
>
>However, this code only produces output for the last line between the
>curly
>braces. Granted, as we type the lines in one at a time and execute the
>code,
>we'll see each output. And, we can fix the problem by adding a print to
>each
>line.
>
>Wonder if there are any other suggestions?
>
>David
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/With-question-tp4676379.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jim at bitwrit.com.au  Wed Sep 18 00:22:27 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 18 Sep 2013 08:22:27 +1000
Subject: [R] Fwd: axis lab font in r
In-Reply-To: <CAG6S0OmuupLmRfvkmVYa-+E45=c9=RbWk7wUhArRSUhvhygWNg@mail.gmail.com>
References: <CAG6S0O=4dDj++VkSwMfYoQuZWu7WLTsLtZ31LNroPnB8BgqpzA@mail.gmail.com>
	<CAG6S0OmuupLmRfvkmVYa-+E45=c9=RbWk7wUhArRSUhvhygWNg@mail.gmail.com>
Message-ID: <5238D623.6020902@bitwrit.com.au>

On 09/18/2013 02:23 AM, Ahmed Attia wrote:
> ---------- Forwarded message ----------
> From: Ahmed Attia<ahmedatia80 at gmail.com>
> Date: Tue, Sep 17, 2013 at 11:17 AM
> Subject: axis lab font in r
> To: r-help-request at r-project.org
>
>
>
> I have an a question about the axis lab font in r. I use font.lab, but
> r changes the font of x axis lab only. How I can change the font of y
> lab axis as well?
>
> I have another problem; when I increase the size of y lab, the lab
> goes out of the graph box.
>
Hi Ahmed,
In the example below, font.lab appears to work for both axes:

plot(1:10)
# allow user to step through plots
par(ask=TRUE)
# change the font to bold
par(font.lab=2)
plot(1:10)
# double the size of the axis labels
par(cex.lab=2)
plot(1:10)
# add more space on the left
par(mar=c(5,6,4,2))
plot(1:10)
par(ask=FALSE)

Jim


From laomeng_3 at 163.com  Wed Sep 18 00:36:37 2013
From: laomeng_3 at 163.com (meng)
Date: Wed, 18 Sep 2013 06:36:37 +0800 (CST)
Subject: [R] question about "lines"
In-Reply-To: <52385164.6030909@gmail.com>
References: <2d78a066.e241.1412bd056d8.Coremail.laomeng_3@163.com>
	<52385164.6030909@gmail.com>
Message-ID: <8398c46.f99e.1412e117483.Coremail.laomeng_3@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130918/97785a4c/attachment.pl>

From pavel.michna at giub.unibe.ch  Tue Sep 17 23:10:56 2013
From: pavel.michna at giub.unibe.ch (pavel.michna at giub.unibe.ch)
Date: Tue, 17 Sep 2013 21:10:56 +0000
Subject: [R] big difference between ncdf and RNetCDF ?
In-Reply-To: <CAL+Zad__DffY2U6e=RT1b4qaBVup53RHNQ+RKd7Hrfa6odJgrA@mail.gmail.com>
References: <52387EC0.2080209@yahoo.de>
	<CAL+Zad__DffY2U6e=RT1b4qaBVup53RHNQ+RKd7Hrfa6odJgrA@mail.gmail.com>
Message-ID: <65474F74-5FF3-4A40-96EC-1DAFDFCFDCFE@giub.unibe.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130917/5383941a/attachment.pl>

From laomeng_3 at 163.com  Wed Sep 18 00:40:14 2013
From: laomeng_3 at 163.com (meng)
Date: Wed, 18 Sep 2013 06:40:14 +0800 (CST)
Subject: [R] question about "lines"
In-Reply-To: <BBB42A47-4C94-4E34-9FAE-5745D9DDECEC@xs4all.nl>
References: <2d78a066.e241.1412bd056d8.Coremail.laomeng_3@163.com>
	<BBB42A47-4C94-4E34-9FAE-5745D9DDECEC@xs4all.nl>
Message-ID: <409d4409.f9aa.1412e14c3a9.Coremail.laomeng_3@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130918/21363ba5/attachment.pl>

From murdoch.duncan at gmail.com  Wed Sep 18 02:49:51 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 17 Sep 2013 20:49:51 -0400
Subject: [R] question about "lines"
In-Reply-To: <8398c46.f99e.1412e117483.Coremail.laomeng_3@163.com>
References: <2d78a066.e241.1412bd056d8.Coremail.laomeng_3@163.com>
	<52385164.6030909@gmail.com>
	<8398c46.f99e.1412e117483.Coremail.laomeng_3@163.com>
Message-ID: <5238F8AF.20602@gmail.com>

On 13-09-17 6:36 PM, meng wrote:
> Thanks for your reply.
>
> Is "fitted(lm(...))" the same as "values" of lines(values)?
>
> If yes,then why the range of lines(values) is different from
> range(fitted(lm(...)))?

You are plotting against the wrong x axis, and you don't see all the values.

Duncan Murdoch

> If no, what "values" refers to?
>
>
>
> At 2013-09-17 20:56:04,"Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>>On 13-09-17 8:06 AM, meng wrote:
>>> Hi all:
>>> I met a question about "lines".
>>>
>>>
>>> attach(cars)
>>>
>>>
>>> plot(dist ~ speed)
>>> #add the regression line to the plot
>>> lines(fitted(lm(dist~speed)) ~ speed)
>>>
>>>
>>> plot(dist ~ speed)
>>> #what kind of curve does the following command add to the plot?
>>> lines(fitted(lm(dist~speed)))
>>>
>>>
>>> My question is :
>>> what kind of curve does the last command add to the plot?
>>
>>Look at the class of fitted(lm(...)).  It is "numeric".  So what you're
>>seeing is the same as if you computed the fitted values, and then did
>>
>>lines(values)
>>
>>Since values is just a vector of numbers, that will plot them as y
>>values against x values 1:length(values).  That's unlikely to be a
>>useful thing to do.
>>
>>Duncan Murdoch
>>
>>>
>>>
>>> My guess:maybe the level of fitted values?
>>>> range(fitted(lm(dist~speed)))
>>> [1] -1.84946 80.73112
>>>
>>>
>>> But from the plot,I can see the range of the curve is about 10 to 40 more or less,which is different from(-1.84946, 80.73112).So the curve must not be the fitted values.What kind of curve does the last command add to the plot then?
>>>
>>>
>>>
>>>
>>> Many thanks for your help
>>>
>>>
>>> My best
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>
>
>


From 538280 at gmail.com  Wed Sep 18 03:35:05 2013
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 17 Sep 2013 19:35:05 -0600
Subject: [R] how to find interval?
In-Reply-To: <20130917051500.461877c1uxxz5n48@www.vfemail.net>
References: <20130917051500.461877c1uxxz5n48@www.vfemail.net>
Message-ID: <CAFEqCdyDnbSMCfDt-GPRGWf=EEGz27ChaOMbrsBMRihEq5Xz1Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130917/408b836a/attachment.pl>

From gildororonar at mail-on.us  Wed Sep 18 04:09:32 2013
From: gildororonar at mail-on.us (gildororonar at mail-on.us)
Date: Tue, 17 Sep 2013 21:09:32 -0500
Subject: [R] on how to make a skip-table
In-Reply-To: <alpine.DEB.2.00.1309131159250.5637@lyonesse>
References: <alpine.DEB.2.00.1309130054380.20861@lyonesse>
	<alpine.DEB.2.00.1309131159250.5637@lyonesse>
Message-ID: <20130917210932.11724pn2yi3o5qww@www.vfemail.net>

Quoting "Zhang Weiwu" <zhangweiwu at realss.com>:

> Jim Holtman asked me to elaborate the problem:
>
>     It is a common problem in reading sparse variable-lenght record data
>     file.  Records are stored in file one next to another. The length of
>     each record is known in advance, but a lot of them records are invalid,
>     and should be skipped to make efficient use of memory.
>
>     Ideally the datafile-reading routine should receive a skip-table. Before
>     reading each wanted/valid record, it seeks forward for the distance
>     given in the skip-table. The problem is how to obtain such a skip table.


Ideally, in C, yes, you need to calculate the steps, because you use a  
pointer.

Jim Holtman asks what you intend to do, I guess because he sees the  
problem may a different solution in R.

What you need is not a skip-table, but a offset table, and you skip  
from the begining to the offset directly, not from the previous  
position.

e.g. instead of skip-1, skip-3, skip-5, skip-7
you should do: offset-1, offset-4, offset-9, offset-15

Consider the skip-table is about the reverse of cumsum, and is harder  
to achieve, you should start with offset-table.


-------------------------------------------------

VFEmail.net - http://www.vfemail.net
$24.95 ONETIME Lifetime accounts with Privacy Features!  
15GB disk! No bandwidth quotas!
Commercial and Bulk Mail Options!


From Tyler.Hallman at oregonstate.edu  Wed Sep 18 01:42:03 2013
From: Tyler.Hallman at oregonstate.edu (Hallman, Tyler)
Date: Tue, 17 Sep 2013 23:42:03 +0000
Subject: [R] clusterboot function in the fpc package in R
Message-ID: <C166DB602CA3824F931AA26E6A35785037D8A133@EX2.oregonstate.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130917/0fbde08d/attachment.pl>

From algaratti at gmail.com  Wed Sep 18 04:06:23 2013
From: algaratti at gmail.com (alexis garatti)
Date: Wed, 18 Sep 2013 10:06:23 +0800
Subject: [R] (no subject)
Message-ID: <CABSk1OGoo5yWejG1-YGzFbqdeGFMDOH8Fu=Hc-u5Lc7sWZgwWQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130918/00b56009/attachment.pl>

From guy.wachsmann at duke.edu  Wed Sep 18 04:48:12 2013
From: guy.wachsmann at duke.edu (Guy Wachsman)
Date: Wed, 18 Sep 2013 02:48:12 +0000
Subject: [R] can you explain the cov2cor function
Message-ID: <A90A0274487D124AB11C77E82ACD449602FB4FB8@ex-mbg-04.win.duke.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130918/268416e7/attachment.pl>

From kridox at ymail.com  Wed Sep 18 07:07:01 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Wed, 18 Sep 2013 14:07:01 +0900
Subject: [R] can you explain the cov2cor function
In-Reply-To: <A90A0274487D124AB11C77E82ACD449602FB4FB8@ex-mbg-04.win.duke.edu>
References: <A90A0274487D124AB11C77E82ACD449602FB4FB8@ex-mbg-04.win.duke.edu>
Message-ID: <CAAcyNCwhEnJBc4AgLXDCVqfXGud2ZwWeG6fDh3nk_vd7B7QJNw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130918/52719ae6/attachment.pl>

From kridox at ymail.com  Wed Sep 18 07:19:17 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Wed, 18 Sep 2013 14:19:17 +0900
Subject: [R] can you explain the cov2cor function
In-Reply-To: <CAAcyNCwhEnJBc4AgLXDCVqfXGud2ZwWeG6fDh3nk_vd7B7QJNw@mail.gmail.com>
References: <A90A0274487D124AB11C77E82ACD449602FB4FB8@ex-mbg-04.win.duke.edu>
	<CAAcyNCwhEnJBc4AgLXDCVqfXGud2ZwWeG6fDh3nk_vd7B7QJNw@mail.gmail.com>
Message-ID: <CAAcyNCyVH2Mwu0ireCdQVgp0w=0Ejgncj3c6SzbUabWdnMdm_w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130918/772c493e/attachment.pl>

From michel.arnaud at cirad.fr  Wed Sep 18 08:11:01 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Wed, 18 Sep 2013 08:11:01 +0200
Subject: [R] delete some lines of a dataframe
In-Reply-To: <1379450462.83455.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <52389C1C.4050503@cirad.fr>
	<1379444195.73052.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<5238B4CD.8010104@cirad.fr>
	<1379449267.62114.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1379450462.83455.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <523943F5.3040406@cirad.fr>

Merci Arun
Michel
Le 17/09/2013 22:41, arun a ?crit :
>
> Hi Arnaud,
> You could also try:
> indx<- Df1$Mat[-1]==Df1$Mat[-nrow(Df1)]
> indx1<-c(indx,FALSE)
> indx2<-c(FALSE,indx)
>
> Df1[indx1,]
>   Df1[indx2,]
> A.K.
>
>
>
> ________________________________
> From: arun <smartpink111 at yahoo.com>
> To: Arnaud Michel <michel.arnaud at cirad.fr>
> Cc: R help <r-help at r-project.org>
> Sent: Tuesday, September 17, 2013 4:21 PM
> Subject: Re: [R] delete some lines of a dataframe
>
>
> Hi Arnaud,
>
> In that case:
>
> Try:
> Df1[duplicated(Df1$Mat),]
>   Df1[duplicated(Df1$Mat,fromLast=TRUE),]
>
> #or
>
>
> A.K.
>
>
> ----- Original Message -----
> From: Arnaud Michel <michel.arnaud at cirad.fr>
> To: arun <smartpink111 at yahoo.com>
> Cc: R help <r-help at r-project.org>
> Sent: Tuesday, September 17, 2013 4:00 PM
> Subject: Re: [R] delete some lines of a dataframe
>
> Thank you Arun
> but the values of other columns may be different !!!
> Michel
> Le 17/09/2013 20:56, arun a ?crit :
>> Hi,
>> Try:
>> Df1[duplicated(Df1),]
>>     Df1[duplicated(Df1,fromLast=TRUE),]
>> A.K.
>>
>>
>>
>> ----- Original Message -----
>> From: Arnaud Michel <michel.arnaud at cirad.fr>
>> To: R help <r-help at r-project.org>
>> Cc:
>> Sent: Tuesday, September 17, 2013 2:14 PM
>> Subject: [R] delete some lines of a dataframe
>>
>> Hi
>>
>> I have a dataframe Df1
>> dput(Df1)
>> structure(list(Mat = c(141, 141, 157, 157, 188, 188, 232, 232,
>> 253, 253, 253, 254, 254, 254, 254, 256, 256, 264, 264), Prenom = c("Pierre",
>> "Pierre", "Jean-Claude", "Jean-Claude", "Jean-Louis", "Jean-Louis",
>> "Philippe", "Philippe", "Christophe", "Christophe", "Christophe",
>> "Dominique", "Dominique", "Dominique", "Dominique", "Pierre-Luc",
>> "Pierre-Luc", "Alain", "Alain"), Sexe = c("Masculin", "Masculin",
>> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
>> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
>> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin"),
>>        DateNais = c("23/08/1946", "23/08/1946", "11/08/1945", "11/08/1945",
>>        "09/04/1948", "09/04/1948", "01/05/1946", "01/05/1946", "11/02/1951",
>>        "11/02/1951", "11/02/1951", "21/10/1949", "21/10/1949", "21/10/1949",
>>        "21/10/1949", "25/06/1946", "25/06/1946", "13/03/1949", "13/03/1949"
>>        )), .Names = c("Mat", "Prenom", "Sexe", "DateNais"), row.names = c("207",
>> "208", "232", "233", "288", "289", "373", "374", "412", "413",
>> "414", "415", "416", "417", "418", "420", "421", "436", "437"
>> ), class = "data.frame")
>>
>> I want to extract of Df1 2 other dataframes :
>> 1) delete the first line for each values of Mat
>>           Mat      Prenom     Sexe   DateNais
>> 208 141      Pierre Masculin 23/08/1946
>> 233 157 Jean-Claude Masculin 11/08/1945
>> 289 188  Jean-Louis Masculin 09/04/1948
>> 374 232    Philippe Masculin 01/05/1946
>> 413 253  Christophe Masculin 11/02/1951
>> 414 253  Christophe Masculin 11/02/1951
>> 416 254   Dominique Masculin 21/10/1949
>> 417 254   Dominique Masculin 21/10/1949
>> 418 254   Dominique Masculin 21/10/1949
>> 421 256  Pierre-Luc Masculin 25/06/1946
>> 437 264       Alain Masculin 13/03/1949
>>
>> 2) delete the last line for each values of Mat
>>        Mat      Prenom     Sexe   DateNais
>> 207 141      Pierre Masculin 23/08/1946
>> 232 157 Jean-Claude Masculin 11/08/1945
>> 288 188  Jean-Louis Masculin 09/04/1948
>> 373 232    Philippe Masculin 01/05/1946
>> 412 253  Christophe Masculin 11/02/1951
>> 413 253  Christophe Masculin 11/02/1951
>> 415 254   Dominique Masculin 21/10/1949
>> 416 254   Dominique Masculin 21/10/1949
>> 417 254   Dominique Masculin 21/10/1949
>> 420 256  Pierre-Luc Masculin 25/06/1946
>> 436 264       Alain Masculin 13/03/1949
>>
>> Any ideas ?
>>
>>
>> -- Michel ARNAUD
>> Charg? de mission aupr?s du DRH
>> DGDRD-Drh - TA 174/04
>> Av Agropolis 34398 Montpellier cedex 5
>> tel : 04.67.61.75.38
>> fax : 04.67.61.57.87
>> port: 06.47.43.55.31
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From laomeng_3 at 163.com  Wed Sep 18 07:38:26 2013
From: laomeng_3 at 163.com (meng)
Date: Wed, 18 Sep 2013 13:38:26 +0800 (CST)
Subject: [R] question about "lines"
In-Reply-To: <5238F8AF.20602@gmail.com>
References: <2d78a066.e241.1412bd056d8.Coremail.laomeng_3@163.com>
	<52385164.6030909@gmail.com>
	<8398c46.f99e.1412e117483.Coremail.laomeng_3@163.com>
	<5238F8AF.20602@gmail.com>
Message-ID: <5658b215.16dd2.1412f93a1e8.Coremail.laomeng_3@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130918/2cdb071b/attachment.pl>

From anna.zakrisson at su.se  Wed Sep 18 07:52:33 2013
From: anna.zakrisson at su.se (Anna Zakrisson Braeunlich)
Date: Wed, 18 Sep 2013 05:52:33 +0000
Subject: [R] ggplot2: changing shapes facet_grid - special case.
Message-ID: <11019DCE9B47004F90B2D9C62FF15792025E72EB@ebox-prod-srv04.win.su.se>

Hi,

I want to change my geom.point shapes in facet grid. I have tried all sorts of solutions, but for some reason none seem to work. Something overrides the "normal" codes. I am stuck.
I have attached the data to the mail.
I want organism to have different shapes and then add a legend to the plot.
thank you for your help!

Code:

  Anaalldata <- read.table(file = "Annadata_2007_9_ISO_long.txt", header = TRUE, dec = ".")
  str(Anaalldata)
  names(Anaalldata)
  library(hexbin)
  library(grid)
  library(ggplot2)
  Anaalldata <- within(Anaalldata, fweek <- factor(week))
  Anaalldata <- within(Anaalldata, fyear <- factor(year))
  Anaalldata <- na.exclude(Anaalldata)
  names(Anaalldata)

  Summisodata11 <- ddply(Anaalldata, .(station, organism), summarise, mean = mean(deltancy),
                        sd = sd(deltancy))

  p <- ggplot(Anaalldata, aes(station, organism))+

    geom_errorbar(data = Summisodata11, aes(ymin = mean - sd, y = mean,
                                       ymax = mean + sd),
                  size = 1, width = 0.1, color = "black")+
    geom_point(data = Summisodata11, aes(y = mean))+
               scale_shape(solid = F)+
    theme_bw() +
    theme(strip.background = element_blank())+
    xlab("Station") +
    ylab(expression(paste("",delta^{15}, "N")))+
    scale_y_continuous(limits=c(-3, 14),    # Set y range
                       breaks=-4:15*2) +
    geom_hline(yintercept=0, linetype=3) + #draws dotted line at 0
    theme(strip.text.x = element_text(size = 20, colour="black", family="serif", angle=00)) +
    theme(strip.text.y = element_text(size = 20, colour="black", family="serif", angle=00)) +
    theme(axis.text.x = element_text(size = 20, colour="black", family="serif", angle=00)) +
    theme(axis.text.y = element_text(size = 17, colour="black", family="serif", angle=00)) +
    theme(axis.title.x = element_text(size=20, colour="black", family="serif", angle=00))+
    theme(axis.title.y = element_text(size=20, colour="black", family="serif", angle=90))+
    facet_wrap( ~ year)
p

Anna Zakrisson Braeunlich
PhD student

Department of Ecology, Environment and Plant Sciences
Stockholm University
Svante Arrheniusv. 21A
SE-106 91 Stockholm
Sweden/Sverige

Lives in Berlin.
For paper mail:
Katzbachstr. 21
D-10965, Berlin - Kreuzberg
Germany/Deutschland

E-mail: anna.zakrisson at su.se
Tel work: +49-(0)3091541281
Mobile: +49-(0)15777374888
LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b

><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?. .? `?. .><((((?>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Annadata_2007_9_ISO_long.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130918/df5256cf/attachment.txt>

From jason at troutnut.com  Wed Sep 18 08:58:01 2013
From: jason at troutnut.com (Carabiniero)
Date: Tue, 17 Sep 2013 23:58:01 -0700 (PDT)
Subject: [R] Stacked Bar Plot With Two Dependent Variables
Message-ID: <1379487481398-4676402.post@n4.nabble.com>

Hi All, 

I need to construct a stacked bar plot with two independent (x) variables,
where the stacking is x1 and the x-axis label is x2. Can someone help out
with the code for this or provide a reference/example?

Thank you,
J






--
View this message in context: http://r.789695.n4.nabble.com/Stacked-Bar-Plot-With-Two-Dependent-Variables-tp4676402.html
Sent from the R help mailing list archive at Nabble.com.


From Achim.Zeileis at uibk.ac.at  Wed Sep 18 09:42:41 2013
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Wed, 18 Sep 2013 09:42:41 +0200 (CEST)
Subject: [R] Stacked Bar Plot With Two Dependent Variables
In-Reply-To: <1379487481398-4676402.post@n4.nabble.com>
References: <1379487481398-4676402.post@n4.nabble.com>
Message-ID: <alpine.DEB.2.10.1309180931040.4164@paninaro.uibk.ac.at>

On Tue, 17 Sep 2013, Carabiniero wrote:

> Hi All,
>
> I need to construct a stacked bar plot with two independent (x) variables,
> where the stacking is x1 and the x-axis label is x2. Can someone help out
> with the code for this or provide a reference/example?

I'm not completely sure what exactly you are looking for but you might 
want to explore mosaic displays that generalize stacked barplot. For 
example you can do the following using the UCBAdmissions data. I treat 
"Admit" as the dependent and "Gender" and "Dept" as the explanatory 
variables:

## data and colors
ucb <- aperm(UCBAdmissions, 3:1)
gr <- gray.colors(2)[2:1]

## mosaic with alternating split direction
mosaicplot(ucb, col = gr, off = c(5, 3, 0))

## doubledecker style
mosaicplot(ucb, col = gr, dir = c("v", "v", "h"), off = c(6, 4, 0))

## or using vcd package
library("vcd")
mosaic(~ Dept + Gender + Admit, data = UCBAdmissions,
   gp = gpar(fill = gr), spacing = spacing_highlighting)
doubledecker(Admit ~ Dept + Gender, data = UCBAdmissions)

> Thank you,
> J
>
>
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Stacked-Bar-Plot-With-Two-Dependent-Variables-tp4676402.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From lebatsnok at gmail.com  Wed Sep 18 10:13:42 2013
From: lebatsnok at gmail.com (Kenn Konstabel)
Date: Wed, 18 Sep 2013 11:13:42 +0300
Subject: [R] can you explain the cov2cor function
In-Reply-To: <CAAcyNCyVH2Mwu0ireCdQVgp0w=0Ejgncj3c6SzbUabWdnMdm_w@mail.gmail.com>
References: <A90A0274487D124AB11C77E82ACD449602FB4FB8@ex-mbg-04.win.duke.edu>
	<CAAcyNCwhEnJBc4AgLXDCVqfXGud2ZwWeG6fDh3nk_vd7B7QJNw@mail.gmail.com>
	<CAAcyNCyVH2Mwu0ireCdQVgp0w=0Ejgncj3c6SzbUabWdnMdm_w@mail.gmail.com>
Message-ID: <CAH7sKSNHakmcZTsBjOfAuU80Dkbbeq51J3t6weRSO-bv=DTvYQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130918/aa39aaaa/attachment.pl>

From kridox at ymail.com  Wed Sep 18 11:02:28 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Wed, 18 Sep 2013 18:02:28 +0900
Subject: [R] can you explain the cov2cor function
In-Reply-To: <CAAcyNCyVH2Mwu0ireCdQVgp0w=0Ejgncj3c6SzbUabWdnMdm_w@mail.gmail.com>
References: <A90A0274487D124AB11C77E82ACD449602FB4FB8@ex-mbg-04.win.duke.edu>
	<CAAcyNCwhEnJBc4AgLXDCVqfXGud2ZwWeG6fDh3nk_vd7B7QJNw@mail.gmail.com>
	<CAAcyNCyVH2Mwu0ireCdQVgp0w=0Ejgncj3c6SzbUabWdnMdm_w@mail.gmail.com>
Message-ID: <CAAcyNCwZ0Kf0Hm3t96mQYvm04CDtMbD1KRZZ06V4zLzs75a6fw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130918/f0990ea3/attachment.pl>

From kridox at ymail.com  Wed Sep 18 11:14:40 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Wed, 18 Sep 2013 18:14:40 +0900
Subject: [R] can you explain the cov2cor function
In-Reply-To: <CAH7sKSNHakmcZTsBjOfAuU80Dkbbeq51J3t6weRSO-bv=DTvYQ@mail.gmail.com>
References: <A90A0274487D124AB11C77E82ACD449602FB4FB8@ex-mbg-04.win.duke.edu>
	<CAAcyNCwhEnJBc4AgLXDCVqfXGud2ZwWeG6fDh3nk_vd7B7QJNw@mail.gmail.com>
	<CAAcyNCyVH2Mwu0ireCdQVgp0w=0Ejgncj3c6SzbUabWdnMdm_w@mail.gmail.com>
	<CAH7sKSNHakmcZTsBjOfAuU80Dkbbeq51J3t6weRSO-bv=DTvYQ@mail.gmail.com>
Message-ID: <CAAcyNCyp7czBRhSHfermBMhNE_pgodjOfJMxXgRReUtoKvueEg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130918/78b96846/attachment.pl>

From pdalgd at gmail.com  Wed Sep 18 11:44:43 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 18 Sep 2013 11:44:43 +0200
Subject: [R] "With" question
In-Reply-To: <4a7d5306-1735-4d97-898d-27670426df15@email.android.com>
References: <1379453612818-4676379.post@n4.nabble.com>
	<4a7d5306-1735-4d97-898d-27670426df15@email.android.com>
Message-ID: <C3A833A5-CDF0-4106-9180-1BADC4BB453B@gmail.com>


On Sep 18, 2013, at 00:22 , Jeff Newmiller wrote:

> You seem to be applying the syntax for the within function to the with function. You should compare the documentation for them and choose your approach accordingly.

The syntax is fine, the difference in within() is that you can do assignments and that the return value is the modified data frame. 

However, the only way to print the value of each subexpression is to use explicit print(), or splitting it up as

with(data, sort(age))
with(data, length(age))
with(data, (age[10]+age[11])/2)

(This is why I'm a bit less dismissive towards attach() than some others are.) 

Of course, you can program your way out of anything in R (well almost anything), e.g.

> evalP <- function(e, ...) structure(lapply(e, eval,...), class="listofresults")
> print.listofresults <- function(x) for(i in x) print(i)
> dd <- data.frame(age=rbinom(20,100,.2))
> evalP(expression(sort(age), length(age), (age[10]+age[11])/2), dd)
 [1] 11 14 14 14 14 16 17 17 18 19 19 20 23 24 24 24 25 27 27 29
[1] 20
[1] 28

(which can be elaborated ad libitum)

-pd


> Also once inside a code block of any type, simply typing a variable name no longer prints it, so you need to use the appropriate function (print or cat).
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> David Arnold <dwarnold45 at suddenlink.net> wrote:
>> All,
>> 
>> Trying to avoid using attach and detach while teaching class in Intro
>> Stats.
>> 
>> data=read.delim("dataset1.dat",header=TRUE)
>> with(data,{
>> sort(age)
>> length(age)
>> (age[10]+age[11])/2
>> })
>> 
>> However, this code only produces output for the last line between the
>> curly
>> braces. Granted, as we type the lines in one at a time and execute the
>> code,
>> we'll see each output. And, we can fix the problem by adding a print to
>> each
>> line.
>> 
>> Wonder if there are any other suggestions?
>> 
>> David
>> 
>> 
>> 
>> --
>> View this message in context:
>> http://r.789695.n4.nabble.com/With-question-tp4676379.html
>> Sent from the R help mailing list archive at Nabble.com.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jrkrideau at inbox.com  Wed Sep 18 12:35:47 2013
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 18 Sep 2013 02:35:47 -0800
Subject: [R] (no subject)
In-Reply-To: <CABSk1OGoo5yWejG1-YGzFbqdeGFMDOH8Fu=Hc-u5Lc7sWZgwWQ@mail.gmail.com>
Message-ID: <22EEA9911CD.0000119Cjrkrideau@inbox.com>

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

John Kane
Kingston ON Canada


> -----Original Message-----
> From: algaratti at gmail.com
> Sent: Wed, 18 Sep 2013 10:06:23 +0800
> To: r-help at r-project.org
> Subject: [R] (no subject)
> 
> Good morning,
> 
> I am an economist. I try to build a strategic - tactical portfolio based
> on
> my forecasts on different assets. I would want to use the  BLCOP package.
> 
> The strategic portfolio would be based on one-year expectation on the
> return of each asset
> 
> The tactical portfolio, with a monthly re-balancing, would result from
> short-term views on the market.
> 
> Could you help me to combine these views in a COP framework. I have
> already
> built a portfolio. I only struggle to introduce my medium-term views.
> 
> Thank you very much for your help,
> 
> Best regards,
> 
> Alexis Garatti
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From jrkrideau at inbox.com  Wed Sep 18 13:05:10 2013
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 18 Sep 2013 03:05:10 -0800
Subject: [R] ggplot2: changing shapes facet_grid - special case.
In-Reply-To: <11019DCE9B47004F90B2D9C62FF15792025E72EB@ebox-prod-srv04.win.su.se>
Message-ID: <23305614E9F.0000121Cjrkrideau@inbox.com>

Does this questions help http://stackoverflow.com/questions/1478532/changing-shapes-used-for-scale-shape-in-ggplot2 ?

It looks like it does but I don't have time at the moment to work it out with your code.

Good luck

John Kane
Kingston ON Canada


> -----Original Message-----
> From: anna.zakrisson at su.se
> Sent: Wed, 18 Sep 2013 05:52:33 +0000
> To: r-help at r-project.org
> Subject: [R] ggplot2: changing shapes facet_grid - special case.
> 
> Hi,
> 
> I want to change my geom.point shapes in facet grid. I have tried all
> sorts of solutions, but for some reason none seem to work. Something
> overrides the "normal" codes. I am stuck.
> I have attached the data to the mail.
> I want organism to have different shapes and then add a legend to the
> plot.
> thank you for your help!
> 
> Code:
> 
>   Anaalldata <- read.table(file = "Annadata_2007_9_ISO_long.txt", header
> = TRUE, dec = ".")
>   str(Anaalldata)
>   names(Anaalldata)
>   library(hexbin)
>   library(grid)
>   library(ggplot2)
>   Anaalldata <- within(Anaalldata, fweek <- factor(week))
>   Anaalldata <- within(Anaalldata, fyear <- factor(year))
>   Anaalldata <- na.exclude(Anaalldata)
>   names(Anaalldata)
> 
>   Summisodata11 <- ddply(Anaalldata, .(station, organism), summarise,
> mean = mean(deltancy),
>                         sd = sd(deltancy))
> 
>   p <- ggplot(Anaalldata, aes(station, organism))+
> 
>     geom_errorbar(data = Summisodata11, aes(ymin = mean - sd, y = mean,
>                                        ymax = mean + sd),
>                   size = 1, width = 0.1, color = "black")+
>     geom_point(data = Summisodata11, aes(y = mean))+
>                scale_shape(solid = F)+
>     theme_bw() +
>     theme(strip.background = element_blank())+
>     xlab("Station") +
>     ylab(expression(paste("",delta^{15}, "N")))+
>     scale_y_continuous(limits=c(-3, 14),    # Set y range
>                        breaks=-4:15*2) +
>     geom_hline(yintercept=0, linetype=3) + #draws dotted line at 0
>     theme(strip.text.x = element_text(size = 20, colour="black",
> family="serif", angle=00)) +
>     theme(strip.text.y = element_text(size = 20, colour="black",
> family="serif", angle=00)) +
>     theme(axis.text.x = element_text(size = 20, colour="black",
> family="serif", angle=00)) +
>     theme(axis.text.y = element_text(size = 17, colour="black",
> family="serif", angle=00)) +
>     theme(axis.title.x = element_text(size=20, colour="black",
> family="serif", angle=00))+
>     theme(axis.title.y = element_text(size=20, colour="black",
> family="serif", angle=90))+
>     facet_wrap( ~ year)
> p
> 
> Anna Zakrisson Braeunlich
> PhD student
> 
> Department of Ecology, Environment and Plant Sciences
> Stockholm University
> Svante Arrheniusv. 21A
> SE-106 91 Stockholm
> Sweden/Sverige
> 
> Lives in Berlin.
> For paper mail:
> Katzbachstr. 21
> D-10965, Berlin - Kreuzberg
> Germany/Deutschland
> 
> E-mail: anna.zakrisson at su.se
> Tel work: +49-(0)3091541281
> Mobile: +49-(0)15777374888
> LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b
> 
> ><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ?
> `?. .? `?. .><((((?>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at http://www.inbox.com/smileys
Works with AIM?, MSN? Messenger, Yahoo!? Messenger, ICQ?, Google Talk? and most webmails


From murdoch.duncan at gmail.com  Wed Sep 18 13:20:26 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 18 Sep 2013 07:20:26 -0400
Subject: [R] question about "lines"
In-Reply-To: <5658b215.16dd2.1412f93a1e8.Coremail.laomeng_3@163.com>
References: <2d78a066.e241.1412bd056d8.Coremail.laomeng_3@163.com>
	<52385164.6030909@gmail.com>
	<8398c46.f99e.1412e117483.Coremail.laomeng_3@163.com>
	<5238F8AF.20602@gmail.com>
	<5658b215.16dd2.1412f93a1e8.Coremail.laomeng_3@163.com>
Message-ID: <52398C7A.7080405@gmail.com>

On 13-09-18 1:38 AM, meng wrote:
> Oh,yes, I found out this according to your reply.Thanks.
>
> As to time series analysis, in order to show the effect of smoothing or
> filtering,the common command is:
> plot(ts0);
> lines(fitted(...))
> But not "lines(fitted(...) ~ time(ts) )"
>
> How to understand this then?

lines() and plot() are "generic functions".  What it does depends on the 
class of the first argument.   To see what happens, you need to know the 
class of ts0, or fitted(...), or fitted(...) ~ time(ts).  I'd guess ts0 
has some time series class, fitted(...) probably has class "numeric" 
(though this would depend on the dots, since it is also generic), and 
the formula has class "formula".    "numeric" generally gets the default 
method (plot.default, lines.default); "formula" usually has its own 
methods (plot.formula, lines.formula), etc.  Read up on this in An 
Introduction to R for more details (sections 3.4 and 10.9).

Duncan Murdoch

>
> Many thanks.
>
> Best.
>
>
>
>
> At 2013-09-18 08:49:51,"Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>>On 13-09-17 6:36 PM, meng wrote:
>>> Thanks for your reply.
>>>
>>> Is "fitted(lm(...))" the same as "values" of lines(values)?
>>>
>>> If yes,then why the range of lines(values) is different from
>>> range(fitted(lm(...)))?
>>
>>You are plotting against the wrong x axis, and you don't see all the values.
>>
>>Duncan Murdoch
>>
>>> If no, what "values" refers to?
>>>
>>>
>>>
>>> At 2013-09-17 20:56:04,"Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>>>>On 13-09-17 8:06 AM, meng wrote:
>>>>> Hi all:
>>>>> I met a question about "lines".
>>>>>
>>>>>
>>>>> attach(cars)
>>>>>
>>>>>
>>>>> plot(dist ~ speed)
>>>>> #add the regression line to the plot
>>>>> lines(fitted(lm(dist~speed)) ~ speed)
>>>>>
>>>>>
>>>>> plot(dist ~ speed)
>>>>> #what kind of curve does the following command add to the plot?
>>>>> lines(fitted(lm(dist~speed)))
>>>>>
>>>>>
>>>>> My question is :
>>>>> what kind of curve does the last command add to the plot?
>>>>
>>>>Look at the class of fitted(lm(...)).  It is "numeric".  So what you're
>>>>seeing is the same as if you computed the fitted values, and then did
>>>>
>>>>lines(values)
>>>>
>>>>Since values is just a vector of numbers, that will plot them as y
>>>>values against x values 1:length(values).  That's unlikely to be a
>>>>useful thing to do.
>>>>
>>>>Duncan Murdoch
>>>>
>>>>>
>>>>>
>>>>> My guess:maybe the level of fitted values?
>>>>>> range(fitted(lm(dist~speed)))
>>>>> [1] -1.84946 80.73112
>>>>>
>>>>>
>>>>> But from the plot,I can see the range of the curve is about 10 to 40 more or less,which is different from(-1.84946, 80.73112).So the curve must not be the fitted values.What kind of curve does the last command add to the plot then?
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> Many thanks for your help
>>>>>
>>>>>
>>>>> My best
>>>>> 	[[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>
>>>
>>>
>>
>
>
>


From anna.zakrisson at su.se  Wed Sep 18 13:29:46 2013
From: anna.zakrisson at su.se (Anna Zakrisson Braeunlich)
Date: Wed, 18 Sep 2013 11:29:46 +0000
Subject: [R] ggplot2: changing strip text in facet_grid and a legend text
	problem
Message-ID: <11019DCE9B47004F90B2D9C62FF15792025E7561@ebox-prod-srv04.win.su.se>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130918/fb5d6c3d/attachment.pl>

From r.cristian.ramirez at gmail.com  Wed Sep 18 13:32:32 2013
From: r.cristian.ramirez at gmail.com (Ricardo Cristian Ramirez)
Date: Wed, 18 Sep 2013 14:32:32 +0300
Subject: [R] Multi multivariate feature selection problem
Message-ID: <CAMgR+PVWuNpNT72us1gC0y16Y+Ox3G5qM1eq5c6qaAdefKynPw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130918/ecffeeee/attachment.pl>

From reith_william at bah.com  Wed Sep 18 13:56:29 2013
From: reith_william at bah.com (wwreith)
Date: Wed, 18 Sep 2013 04:56:29 -0700 (PDT)
Subject: [R] R packages for CAT scans
Message-ID: <1379505389090-4676418.post@n4.nabble.com>

Does anyone know of a package that would allow data from a CT scan to be
loaded into R?

Thanks!



--
View this message in context: http://r.789695.n4.nabble.com/R-packages-for-CAT-scans-tp4676418.html
Sent from the R help mailing list archive at Nabble.com.


From batholdy at googlemail.com  Wed Sep 18 14:10:30 2013
From: batholdy at googlemail.com (Martin Batholdy)
Date: Wed, 18 Sep 2013 14:10:30 +0200
Subject: [R] convert string to date format
Message-ID: <509B0B39-0901-4AE9-B732-2DDD8B0D71E7@googlemail.com>

Hi,

I have a vector that looks like this;
(imported from another file)

dates <- c("Tue Sep 17 2013 16:25:17", "Wed Sep 18 2013 16:35:17", "Thu Sep 19 2013 16:55:17")


now I need a data frame with two columns;

date 			time
2013.09.17		16:25:17
2013.09.18		16:35:17
?


I first started with functions like strsplit to do string manipulations.
But since I have to do this for multiple files with different native date-formats, probably there is a more general way to deal with dates and time formats in R.

How can I make R recognize that the dates vector does not contain strings but a dates in a specific format?
And then how can use this to create the mentioned data-frame?


thanks for any suggestions!


From a.mosnier at gmail.com  Wed Sep 18 14:27:03 2013
From: a.mosnier at gmail.com (Arnaud Mosnier)
Date: Wed, 18 Sep 2013 08:27:03 -0400
Subject: [R] lowercase and uppercase greek letters
In-Reply-To: <5238BCEF.5050808@xtra.co.nz>
References: <CANkFkEckY1zN_Nm8fiMdr-i1OsJuEZTw8dJeQTuEosHmKmC1Nw@mail.gmail.com>
	<5238BCEF.5050808@xtra.co.nz>
Message-ID: <CANkFkEctGbCi7ucgyibjvMB25JonNksYraS7ATkhKvnUQidKwQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130918/ee84d33e/attachment.pl>

From a.mosnier at gmail.com  Wed Sep 18 14:29:21 2013
From: a.mosnier at gmail.com (Arnaud Mosnier)
Date: Wed, 18 Sep 2013 08:29:21 -0400
Subject: [R] lowercase and uppercase greek letters
In-Reply-To: <5238AF0D.4080608@gmail.com>
References: <CANkFkEckY1zN_Nm8fiMdr-i1OsJuEZTw8dJeQTuEosHmKmC1Nw@mail.gmail.com>
	<5238AF0D.4080608@gmail.com>
Message-ID: <CANkFkEf3gAFrpQVqoXSGXdV95gWrema66rdFXU6jbC0iy+tK-Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130918/073416ac/attachment.pl>

From smartpink111 at yahoo.com  Wed Sep 18 14:35:01 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 18 Sep 2013 05:35:01 -0700 (PDT)
Subject: [R] convert string to date format
In-Reply-To: <509B0B39-0901-4AE9-B732-2DDD8B0D71E7@googlemail.com>
References: <509B0B39-0901-4AE9-B732-2DDD8B0D71E7@googlemail.com>
Message-ID: <1379507701.74377.YahooMailNeo@web142602.mail.bf1.yahoo.com>

HI,
May be this helps:
vec1<-as.POSIXlt(strptime(gsub("^\\w+ ","",dates),"%b %d %Y %H:%M:%S"))

dat1<- data.frame(date= gsub("-",".",as.Date(vec1)), time= strftime(vec1,format="%H:%M:%S")
?,stringsAsFactors=FALSE)
?dat1
#??????? date???? time
#1 2013.09.17 16:25:17
#2 2013.09.18 16:35:17
#3 2013.09.19 16:55:17
A.K.



----- Original Message -----
From: Martin Batholdy <batholdy at googlemail.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Wednesday, September 18, 2013 8:10 AM
Subject: [R] convert string to date format

Hi,

I have a vector that looks like this;
(imported from another file)

dates <- c("Tue Sep 17 2013 16:25:17", "Wed Sep 18 2013 16:35:17", "Thu Sep 19 2013 16:55:17")


now I need a data frame with two columns;

date ??? ??? ??? time
2013.09.17??? ??? 16:25:17
2013.09.18??? ??? 16:35:17
?


I first started with functions like strsplit to do string manipulations.
But since I have to do this for multiple files with different native date-formats, probably there is a more general way to deal with dates and time formats in R.

How can I make R recognize that the dates vector does not contain strings but a dates in a specific format?
And then how can use this to create the mentioned data-frame?


thanks for any suggestions!

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ii54250 at msn.com  Wed Sep 18 14:43:23 2013
From: ii54250 at msn.com (ioanna ioannou)
Date: Wed, 18 Sep 2013 13:43:23 +0100
Subject: [R] Identifying the bin where a value is included.
Message-ID: <DUB104-DS11F75B91F61E1C9AF25E00F3200@phx.gbl>

Hello all, 

A very simple problem. 

Lets assume I  have an interval [0,1] and I split it in 6 bins having
thresholds:
pro= cbind(0, 0.3675509, 0.8618615, 0.9814291, 0.9975283, 0.9997789,
1.0000000,
           0, 0.3662881, 0.8609743, 0.9812032, 0.9974822, 0.9997738,
1.0000000)

dim(pro)<-c(7,2)

 I randomly generate a number and I want to identify which bin it belongs
to. How? What I provide below doesn't seem to be working. 
Any ideas?

for (i in 1:2){
    ids<-runif(1)
  for (j in 1:length(pro[,i])-1){
    if (ids < pro[j,i]) {
      ds[i]<-j
    }
    else {
      ds[i]<-6
    } 
  }
}

Best, 
IOanna


From hanson at depauw.edu  Wed Sep 18 15:04:09 2013
From: hanson at depauw.edu (Bryan Hanson)
Date: Wed, 18 Sep 2013 09:04:09 -0400
Subject: [R] R packages for CAT scans
In-Reply-To: <1379505389090-4676418.post@n4.nabble.com>
References: <1379505389090-4676418.post@n4.nabble.com>
Message-ID: <54D57BD6-DEAF-490C-A6B5-002ACBF1D4FE@depauw.edu>

Check here: http://cran.r-project.org/web/views/MedicalImaging.html

Bryan

On Sep 18, 2013, at 7:56 AM, wwreith <reith_william at bah.com> wrote:

> Does anyone know of a package that would allow data from a CT scan to be
> loaded into R?
> 
> Thanks!
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/R-packages-for-CAT-scans-tp4676418.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jim at bitwrit.com.au  Wed Sep 18 15:07:38 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 18 Sep 2013 23:07:38 +1000
Subject: [R] Identifying the bin where a value is included.
In-Reply-To: <DUB104-DS11F75B91F61E1C9AF25E00F3200@phx.gbl>
References: <DUB104-DS11F75B91F61E1C9AF25E00F3200@phx.gbl>
Message-ID: <5239A59A.6080208@bitwrit.com.au>

On 09/18/2013 10:43 PM, ioanna ioannou wrote:
> Hello all,
>
> A very simple problem.
>
> Lets assume I  have an interval [0,1] and I split it in 6 bins having
> thresholds:
> pro= cbind(0, 0.3675509, 0.8618615, 0.9814291, 0.9975283, 0.9997789,
> 1.0000000,
>             0, 0.3662881, 0.8609743, 0.9812032, 0.9974822, 0.9997738,
> 1.0000000)
>
> dim(pro)<-c(7,2)
>
>   I randomly generate a number and I want to identify which bin it belongs
> to. How? What I provide below doesn't seem to be working.
> Any ideas?
>
> for (i in 1:2){
>      ids<-runif(1)
>    for (j in 1:length(pro[,i])-1){
>      if (ids<  pro[j,i]) {
>        ds[i]<-j
>      }
>      else {
>        ds[i]<-6
>      }
>    }
> }
>
Hi Ioanna,
Does:

ids<-runif(1)
bin<-which(ids<pro)[1]-1

do what you want?

Jim


From bhh at xs4all.nl  Wed Sep 18 15:20:20 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 18 Sep 2013 15:20:20 +0200
Subject: [R] Identifying the bin where a value is included.
In-Reply-To: <DUB104-DS11F75B91F61E1C9AF25E00F3200@phx.gbl>
References: <DUB104-DS11F75B91F61E1C9AF25E00F3200@phx.gbl>
Message-ID: <B0855013-148F-4261-A136-593F9EC888B5@xs4all.nl>


On 18-09-2013, at 14:43, ioanna ioannou <ii54250 at msn.com> wrote:

> Hello all, 
> 
> A very simple problem. 
> 
> Lets assume I  have an interval [0,1] and I split it in 6 bins having
> thresholds:
> pro= cbind(0, 0.3675509, 0.8618615, 0.9814291, 0.9975283, 0.9997789,
> 1.0000000,
>           0, 0.3662881, 0.8609743, 0.9812032, 0.9974822, 0.9997738,
> 1.0000000)
> 
> dim(pro)<-c(7,2)
> 
> I randomly generate a number and I want to identify which bin it belongs
> to. How? What I provide below doesn't seem to be working. 

"Doesn't seem to be working" is pretty vague.
It either works or it doesn't.
What are you seeing? An error message (I got one)? Wrong result?

> Any ideas?
> 

Yes.
In the expression "j in 1:length(pro[,i])-1" the 1 is subtracted from the left and righthand side of :.
The expression should read: j in 1:(length(pro[,i])-1)


> for (i in 1:2){
>    ids<-runif(1)
>  for (j in 1:length(pro[,i])-1){
>    if (ids < pro[j,i]) {
>      ds[i]<-j

You need to break after this.
>    }
>    else {
>      ds[i]<-6
>    } 
>  }
> }
> 

Alternative to Jim's suggestion is: have a look at findInterval.

Berend

> Best, 
> IOanna
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Wed Sep 18 15:38:58 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 18 Sep 2013 09:38:58 -0400
Subject: [R] ggplot2: changing shapes facet_grid - special case.
In-Reply-To: <11019DCE9B47004F90B2D9C62FF15792025E72EB@ebox-prod-srv04.win.su.se>
References: <11019DCE9B47004F90B2D9C62FF15792025E72EB@ebox-prod-srv04.win.su.se>
Message-ID: <CA+vqiLHqHNaVWXQBba1rkBS4q6AQsqmT0srNBE5zvLSaVm1BZw@mail.gmail.com>

Hi Anna,

It's not clear to me what you are trying to do. If you want different
shapes for different organisms then you should map organism to shape,
e.g.,

    geom_point(data = Summisodata11, aes(y = mean, shape=organism))

Is that what you are looking for? If not please restate the question.

Best,
Ista

On Wed, Sep 18, 2013 at 1:52 AM, Anna Zakrisson Braeunlich
<anna.zakrisson at su.se> wrote:
> Hi,
>
> I want to change my geom.point shapes in facet grid. I have tried all sorts of solutions, but for some reason none seem to work. Something overrides the "normal" codes. I am stuck.
> I have attached the data to the mail.
> I want organism to have different shapes and then add a legend to the plot.
> thank you for your help!
>
> Code:
>
>   Anaalldata <- read.table(file = "Annadata_2007_9_ISO_long.txt", header = TRUE, dec = ".")
>   str(Anaalldata)
>   names(Anaalldata)
>   library(hexbin)
>   library(grid)
>   library(ggplot2)
>   Anaalldata <- within(Anaalldata, fweek <- factor(week))
>   Anaalldata <- within(Anaalldata, fyear <- factor(year))
>   Anaalldata <- na.exclude(Anaalldata)
>   names(Anaalldata)
>
>   Summisodata11 <- ddply(Anaalldata, .(station, organism), summarise, mean = mean(deltancy),
>                         sd = sd(deltancy))
>
>   p <- ggplot(Anaalldata, aes(station, organism))+
>
>     geom_errorbar(data = Summisodata11, aes(ymin = mean - sd, y = mean,
>                                        ymax = mean + sd),
>                   size = 1, width = 0.1, color = "black")+
>     geom_point(data = Summisodata11, aes(y = mean))+
>                scale_shape(solid = F)+
>     theme_bw() +
>     theme(strip.background = element_blank())+
>     xlab("Station") +
>     ylab(expression(paste("",delta^{15}, "N")))+
>     scale_y_continuous(limits=c(-3, 14),    # Set y range
>                        breaks=-4:15*2) +
>     geom_hline(yintercept=0, linetype=3) + #draws dotted line at 0
>     theme(strip.text.x = element_text(size = 20, colour="black", family="serif", angle=00)) +
>     theme(strip.text.y = element_text(size = 20, colour="black", family="serif", angle=00)) +
>     theme(axis.text.x = element_text(size = 20, colour="black", family="serif", angle=00)) +
>     theme(axis.text.y = element_text(size = 17, colour="black", family="serif", angle=00)) +
>     theme(axis.title.x = element_text(size=20, colour="black", family="serif", angle=00))+
>     theme(axis.title.y = element_text(size=20, colour="black", family="serif", angle=90))+
>     facet_wrap( ~ year)
> p
>
> Anna Zakrisson Braeunlich
> PhD student
>
> Department of Ecology, Environment and Plant Sciences
> Stockholm University
> Svante Arrheniusv. 21A
> SE-106 91 Stockholm
> Sweden/Sverige
>
> Lives in Berlin.
> For paper mail:
> Katzbachstr. 21
> D-10965, Berlin - Kreuzberg
> Germany/Deutschland
>
> E-mail: anna.zakrisson at su.se
> Tel work: +49-(0)3091541281
> Mobile: +49-(0)15777374888
> LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b
>
>><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?. .? `?. .><((((?>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From istazahn at gmail.com  Wed Sep 18 15:52:44 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 18 Sep 2013 09:52:44 -0400
Subject: [R] ggplot2: changing strip text in facet_grid and a legend
	text problem
In-Reply-To: <11019DCE9B47004F90B2D9C62FF15792025E7561@ebox-prod-srv04.win.su.se>
References: <11019DCE9B47004F90B2D9C62FF15792025E7561@ebox-prod-srv04.win.su.se>
Message-ID: <CA+vqiLEyhaegcppHv5=z+QF0AMVxtuv6BE=tehEP_iTA3X_dPw@mail.gmail.com>

Hi Anna,

See in line below.

On Wed, Sep 18, 2013 at 7:29 AM, Anna Zakrisson Braeunlich
<anna.zakrisson at su.se> wrote:
> Hi,
>
> Dummy data script and scripts are attached below.
>
> I would like to change the plot to look like this:
> https://www.google.se/search?q=facet_grid&bav=on.2,or.r_qf.&bvm=bv.52288139,d.Yms&biw=1454&bih=704&dpr=1&pdl=300&um=1&ie=UTF-8&hl=sv&tbm=isch&source=og&sa=N&tab=wi&ei=vY05Uu3vD8aHtAawsYDIBw#facrc=_&imgdii=_&imgrc=IyGjjRic2YJAsM%3A%3BzWmfhhY7LA1p2M%3Bhttps%253A%252F%252Fgithub-camo.global.ssl.fastly.net%252Fc18764797ada04cb8006a2bdaa962c65bfd9bf09%252F687474703a2f2f6661726d362e737461746963666c69636b722e636f6d2f353333332f373036363335373537335f336537313031326534655f6f2e706e67%3Bhttps%253A%252F%252Fgithub.com%252Fcboettig%252Fwrightscape%252Fblob%252Fmaster%252Finst%252Fexamples%252Flabrid_par_bootstrap.md%3B576%3B360
>
> i.e. I want the panes labelled on top and on the right side of the graph. I want however, the text horizontally on the right side.
>
> I do not understand why facet_grid plotted it this way for me. Why?

Because you did not use facet_grid. Change

  facet_wrap(year~ station) +

to

  facet_grid(year~ station) +

>
> I would also like to change the text in the legend of this plot.
> I have tried several solutions including:
>
> scale_fill_discrete(guide = guide_legend(), labels=c("cyanobacteria", "zooplankton"))
> scale_fill_discrete(name="organism",
>                         breaks=c("cyano", "seston"),
>                         labels=c("cyanobacteria", "seston"))
>
> for some reason nothing works. Ideas?

It doesn't work because you have not mapped anything to fill.
Presumably you want

    scale_shape_discrete(name="organism",
                        breaks=c("cyano", "seston"),
                        labels=c("cyanobacteria", "seston"),
                         solid=FALSE) +
    scale_linetype_discrete(name="organism",
                        breaks=c("cyano", "seston"),
                        labels=c("cyanobacteria", "seston"))

Best,
Ista

>
> mydata <- data.frame(
>   D15N = c(runif(100, min = -2), runif(100), runif(100, max = 2), runif(100)),
>   year = rep(c('2007', '2008'), each = 100),
>   organism = rep(c('cyano', 'seston'), each = 200),
>   station = sample(c('B1', 'H2', 'H3', 'H4'), 400, replace = TRUE),
>   week = sample(c('19', '21', '23', '25'), 400, replace = TRUE))
>
>
> names(mydata)
> head(mydata)
> str(mydata)
>
>
> Summdata <- ddply(mydata, .(week, organism, year, station), summarise, mean = mean(D15N),
>                        sd = sd(D15N))
>
> p <- ggplot(mydata, aes(x = week, y = D15N)) +
>   (mapping=aes(group=interaction(week, organism))) +
>   facet_wrap(year~ station) +
>   theme_bw() +
>   geom_errorbar(data = Summdata, aes(ymin = mean - sd, y = mean,
>                                           ymax = mean + sd),
>                 size = 1, width = 0.05, color = "black")+
>   theme(strip.background = element_blank())+
>   ylab(expression(paste("",delta^{15}, "N")))+
>   xlab("Week") +
>   geom_line(stat="summary", fun.y = "mean",
>             mapping=aes(linetype=organism, group=organism))+ #must add jitter if using this
>   geom_point(stat="summary", fun.y = "mean", size=2, mapping=aes(shape=organism))+
>   scale_shape(solid = FALSE) + #must be unfilled
>   geom_hline(yintercept=0, linetype=3) + #draws dotted line at 0
>   theme(strip.text.x = element_text(size = 16, colour="black", family="serif", angle=00)) +
>   theme(strip.text.y = element_text(size = 16, colour="black", family="serif", angle=00)) +
>   theme(axis.text.x = element_text(size = 16, colour="black", family="serif", angle=00)) +
>   theme(axis.text.y = element_text(size = 16, colour="black", family="serif", angle=00)) +
>   theme(axis.title.x = element_text(size=16, colour="black", family="serif", angle=00))+
>   theme(axis.title.y = element_text(size=16, colour="black", family="serif", angle=90)) +
>   scale_fill_discrete(guide = guide_legend(), labels=c("cyanobacteria", "zooplankton"))
>
> p
>
> with kind regards
>
>
> Anna Zakrisson Braeunlich
> PhD student
>
> Department of Ecology, Environment and Plant Sciences
> Stockholm University
> Svante Arrheniusv. 21A
> SE-106 91 Stockholm
> Sweden/Sverige
>
> Lives in Berlin.
> For paper mail:
> Katzbachstr. 21
> D-10965, Berlin - Kreuzberg
> Germany/Deutschland
>
> E-mail: anna.zakrisson at su.se
> Tel work: +49-(0)3091541281
> Mobile: +49-(0)15777374888
> LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b
>
>><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?. .? `?. .><((((?>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Wed Sep 18 16:31:41 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 18 Sep 2013 07:31:41 -0700 (PDT)
Subject: [R] binary symmetric matrix combination
In-Reply-To: <1378488581.72798.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <1378411770.83414.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1378413000.30677.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1378421659.27771.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1378488581.72798.YahooMailNeo@web142604.mail.bf1.yahoo.com> 
Message-ID: <1379514701.73325.YahooMailNeo@web142605.mail.bf1.yahoo.com>



Hi Elio,
Try this:
Assuming that there is a single blank row separating the matrices:

lines1<- readLines(textConnection("aa5 ??? aa10 ??? b253 ??? b254
aa5 ??? 0 ??? 1 ??? 1 ??? 1
aa10 ??? 1 ??? 0 ??? 1 ??? 1
b253 ??? 1 ??? 1 ??? 0 ??? 1
b254 ??? 1 ??? 1 ??? 1 ??? 0

??? aa5 ??? aa9 ??? b27 ??? b29
aa5 ??? 0 ??? 1 ??? 1 ??? 1
aa9 ??? 1 ??? 0 ??? 1 ??? 1
b27 ??? 1 ??? 1 ??? 0 ??? 1
b29 ??? 1 ??? 1 ??? 1 ??? 0??? 

??? a15 ??? b3 ??? g23 ??? i250
a15 ??? 0 ??? 1 ??? 1 ??? 1
b3 ??? 1 ??? 0 ??? 1 ??? 1
g23 ??? 1 ??? 1 ??? 0 ??? 1
i250 ??? 1 ??? 1 ??? 1 ??? 0??? 

??? a15 ??? a16 ??? q27 ??? v87
a15 ??? 0 ??? 1 ??? 1 ??? 1
a16 ??? 1 ??? 0 ??? 1 ??? 1
q27 ??? 1 ??? 1 ??? 0 ??? 1
v87 ??? 1 ??? 1 ??? 1 ??? 0"))
lst1<-lapply(split(lines1,cumsum(lines1=="")),function(x) as.matrix(read.table(text=x[x!=""],sep="",row.names=1)))
names(lst1)<- paste0("m",seq_along(lst1))
?lst1[1:2]
#$m1
#???? aa5 aa10 b253 b254
#aa5??? 0??? 1??? 1??? 1
#aa10?? 1??? 0??? 1??? 1
#b253?? 1??? 1??? 0??? 1
#b254?? 1??? 1??? 1??? 0
#
#$m2
#??? aa5 aa9 b27 b29
#aa5?? 0?? 1?? 1?? 1
#aa9?? 1?? 0?? 1?? 1
#b27?? 1?? 1?? 0?? 1
#b29?? 1?? 1?? 1?? 0

#Reading from file: The data you showed seems to be tab separated.? It could be different.
lines2<- gsub("\t","", readLines("Elio.txt"))
##In case it is just space:
#lines2<- readLines("Elio.txt")
lst2<-lapply(split(lines2,cumsum(lines2=="")),function(x) as.matrix(read.table(text=x[x!=""],sep="",row.names=1)))
names(lst2)<- paste0("m",seq_along(lst2))
?identical(lst1,lst2)
#[1] TRUE

A.K.




Hi,

I have another question 
related to the same problem. I have a text file with about 350 matrices 
each separated by a blank row. My question is how to make R believe each matrix is separate and has a specific name m1, m2,....m350. Below is an example:



aa5 aa10 b253 b254 
aa5 0 1 1 1 
aa10 1 0 1 1 
b253 1 1 0 1 
b254 1 1 1 0 






aa5 aa9 b27 b29 
aa5 0 1 1 1 
aa9 1 0 1 1 
b27 1 1 0 1 
b29 1 1 1 0 






a15 b3 g23 i250 
a15 0 1 1 1 
b3 1 0 1 1 
g23 1 1 0 1 
i250 1 1 1 0 






a15 a16 q27 v87 
a15 0 1 1 1 
a16 1 0 1 1 
q27 1 1 0 1 
v87 1 1 1 0 
This is what I get from R, how to make it believe each one is a matrix and name the matrix m1, m2, m3 and so on.

Thanks a lot!!


From smartpink111 at yahoo.com  Wed Sep 18 16:40:36 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 18 Sep 2013 07:40:36 -0700 (PDT)
Subject: [R] Save multiple plots of model output
Message-ID: <1379515236.65792.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Try:
lapply(paste0("m",1:2),function(x) {png(file=paste0("plot",x,".png")); plot(get(x),pages=1,shade=TRUE);dev.off()})


#change 1:2 accordingly

A.K.


I wanted to plot a gam object output ?and save the plots in a folder. I have several such objects in the workspace and wanted to automate the 
process. For a single object I would have used: 
? 
png(file='plotm1.png') 
plot(m1,pages=1, shade=TRUE) 
dev.off() 

I would like to save the plot as the name of the gam object for later identification 

Example data and code 

library(MASS) 
library(mgcv) 
library(car) 

data(Prestige) 

Prestige2<-na.omit(Prestige) 

m1<-gam(prestige~s(income)+s(education),data =Prestige2) 
m2<-gam(prestige~s(income),data =Prestige2) 

Thanks


From JPRIGOT at partners.org  Wed Sep 18 15:14:55 2013
From: JPRIGOT at partners.org (Prigot, Jonathan)
Date: Wed, 18 Sep 2013 13:14:55 +0000
Subject: [R] R-3.0.1 g77 errors
Message-ID: <D42D0BE74BCC6443A81E6E7F0438764B3451B325@PHSX10MB14.partners.org>

I am trying to build R-3.0.1 on our SPARC Solaris 10 system, but it
fails part way through with g77 errors. Has anyone run into this? Any
suggestions? For what it's worth, R-2.15.1 is the last one to build
error free for us.
===
Jon Prigot

R is now configured for sparc-sun-solaris2.10

  Source directory:          .
  Installation directory:    /usr/local

  C compiler:                gcc -std=gnu99  -g -O2
  Fortran 77 compiler:       g77  -g -O2

  C++ compiler:              g++  -g -O2
  Fortran 90/95 compiler:    gfortran 
  Obj-C compiler:             

  Interfaces supported:      X11, tcltk
  External libraries:        readline, ICU
  Additional capabilities:   PNG, JPEG, TIFF, NLS
  Options enabled:           shared BLAS, R profiling

  Recommended packages:      yes

make 
...

g77 -fPIC  -g -O2 -ffloat-store -c dlamch.f -o dlamch.o
dlamch.f: In function `dlamch':
dlamch.f:89: warning:
         INTRINSIC          DIGITS, EPSILON, HUGE, MAXEXPONENT,
                            ^
Reference to unimplemented intrinsic `DIGITS' at (^) (assumed EXTERNAL)
dlamch.f:89: 
         INTRINSIC          DIGITS, EPSILON, HUGE, MAXEXPONENT,
                            ^
Invalid declaration of or reference to symbol `digits' at (^) [initially
seen at (^)]
dlamch.f:89: warning:
         INTRINSIC          DIGITS, EPSILON, HUGE, MAXEXPONENT,
                                    ^
Reference to unimplemented intrinsic `EPSILON' at (^) (assumed EXTERNAL)

-- 
Jonathan M. Prigot <jprigot at partners.org>
Partners Healthcare Systems



The information in this e-mail is intended only for the person to whom it is
addressed. If you believe this e-mail was sent to you in error and the e-mail
contains patient information, please contact the Partners Compliance HelpLine at
http://www.partners.org/complianceline . If the e-mail was sent to you in error
but does not contain patient information, please contact the sender and properly
dispose of the e-mail.

From taraka at fripost.org  Wed Sep 18 15:18:49 2013
From: taraka at fripost.org (K. Taraka Rama)
Date: Wed, 18 Sep 2013 15:18:49 +0200
Subject: [R] Converting a asymmetric data frame to symmetric matrix
Message-ID: <5239A839.8080704@fripost.org>

Hi,

I have a pair-wise distance vector. FOr objects: a,b,c, it is: (a,b) :5, 
(b,c) :6, (a,c) : 7. I want to convert it into a symmetric matrix. I 
used cast function but the function does not fill the matrix like a 
triangular matrix. How do I get a symmetric matrix?

-- 
--Taraka


From selius at gmail.com  Wed Sep 18 15:36:33 2013
From: selius at gmail.com (supernovartis)
Date: Wed, 18 Sep 2013 06:36:33 -0700 (PDT)
Subject: [R] binary symmetric matrix combination
In-Reply-To: <1378636803382-4675624.post@n4.nabble.com>
References: <1378380710423-4675440.post@n4.nabble.com>
	<1378411770.83414.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1378413000.30677.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1378421659.27771.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1378488581.72798.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1378636803382-4675624.post@n4.nabble.com>
Message-ID: <CAEBi+_nJZKXsgydZpO_nSeH9O5ifnmjtwd0kgJCh6cfuWE8Ofw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130918/cb5beab1/attachment.pl>

From smartpink111 at yahoo.com  Wed Sep 18 15:26:24 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 18 Sep 2013 06:26:24 -0700 (PDT)
Subject: [R] Identifying the bin where a value is included.
In-Reply-To: <DUB104-DS11F75B91F61E1C9AF25E00F3200@phx.gbl>
References: <DUB104-DS11F75B91F61E1C9AF25E00F3200@phx.gbl>
Message-ID: <1379510784.3801.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Try:?set.seed(49)
?t(sapply(seq_len(ncol(pro)),function(i) {ids<- runif(1); x1<-cut(ids,breaks=pro[,i]); c(ids=ids,bin_location=x1)}))
#?????????? ids bin_location
#[1,] 0.3656991??????????? 1
#[2,] 0.4878542??????????? 2

A.K.




----- Original Message -----
From: ioanna ioannou <ii54250 at msn.com>
To: r-help at r-project.org
Cc: 
Sent: Wednesday, September 18, 2013 8:43 AM
Subject: Re: [R] Identifying the bin where a value is included.

Hello all, 

A very simple problem. 

Lets assume I? have an interval [0,1] and I split it in 6 bins having
thresholds:
pro= cbind(0, 0.3675509, 0.8618615, 0.9814291, 0.9975283, 0.9997789,
1.0000000,
? ? ? ? ?  0, 0.3662881, 0.8609743, 0.9812032, 0.9974822, 0.9997738,
1.0000000)

dim(pro)<-c(7,2)

I randomly generate a number and I want to identify which bin it belongs
to. How? What I provide below doesn't seem to be working. 
Any ideas?

for (i in 1:2){
? ? ids<-runif(1)
? for (j in 1:length(pro[,i])-1){
? ? if (ids < pro[j,i]) {
? ? ? ds[i]<-j
? ? }
? ? else {
? ? ? ds[i]<-6
? ? } 
? }
}

Best, 
IOanna

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From szehnder at uni-bonn.de  Wed Sep 18 17:20:13 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Wed, 18 Sep 2013 17:20:13 +0200
Subject: [R] R-3.0.1 g77 errors
In-Reply-To: <D42D0BE74BCC6443A81E6E7F0438764B3451B325@PHSX10MB14.partners.org>
References: <D42D0BE74BCC6443A81E6E7F0438764B3451B325@PHSX10MB14.partners.org>
Message-ID: <8BCD42E1-642F-4473-8B19-BFCDF6A5975B@uni-bonn.de>

On my systems Linux Scientific and Mac OS X I use as well for the F77 the gfortran compiler and this works. You could give it a trial.

Best

Simon

On Sep 18, 2013, at 3:14 PM, "Prigot, Jonathan" <JPRIGOT at partners.org> wrote:

> I am trying to build R-3.0.1 on our SPARC Solaris 10 system, but it
> fails part way through with g77 errors. Has anyone run into this? Any
> suggestions? For what it's worth, R-2.15.1 is the last one to build
> error free for us.
> ===
> Jon Prigot
> 
> R is now configured for sparc-sun-solaris2.10
> 
> Source directory:          .
> Installation directory:    /usr/local
> 
> C compiler:                gcc -std=gnu99  -g -O2
> Fortran 77 compiler:       g77  -g -O2
> 
> C++ compiler:              g++  -g -O2
> Fortran 90/95 compiler:    gfortran 
> Obj-C compiler:             
> 
> Interfaces supported:      X11, tcltk
> External libraries:        readline, ICU
> Additional capabilities:   PNG, JPEG, TIFF, NLS
> Options enabled:           shared BLAS, R profiling
> 
> Recommended packages:      yes
> 
> make 
> ...
> 
> g77 -fPIC  -g -O2 -ffloat-store -c dlamch.f -o dlamch.o
> dlamch.f: In function `dlamch':
> dlamch.f:89: warning:
>       INTRINSIC          DIGITS, EPSILON, HUGE, MAXEXPONENT,
>                          ^
> Reference to unimplemented intrinsic `DIGITS' at (^) (assumed EXTERNAL)
> dlamch.f:89: 
>       INTRINSIC          DIGITS, EPSILON, HUGE, MAXEXPONENT,
>                          ^
> Invalid declaration of or reference to symbol `digits' at (^) [initially
> seen at (^)]
> dlamch.f:89: warning:
>       INTRINSIC          DIGITS, EPSILON, HUGE, MAXEXPONENT,
>                                  ^
> Reference to unimplemented intrinsic `EPSILON' at (^) (assumed EXTERNAL)
> 
> -- 
> Jonathan M. Prigot <jprigot at partners.org>
> Partners Healthcare Systems
> 
> 
> 
> The information in this e-mail is intended only for th...{{dropped:18}}


From sds at gnu.org  Wed Sep 18 17:42:13 2013
From: sds at gnu.org (Sam Steingold)
Date: Wed, 18 Sep 2013 11:42:13 -0400
Subject: [R] strsplit with a vector split argument
Message-ID: <877geeb0h6.fsf@gnu.org>

Hi,
I find this behavior unexpected:
--8<---------------cut here---------------start------------->8---
> strsplit(c("a,b;c","d;e,f"),c(",",";"))
[[1]]
[1] "a"   "b;c"

[[2]]
[1] "d"   "e,f"
--8<---------------cut here---------------end--------------->8---
I thought that it should be identical to this:
--8<---------------cut here---------------start------------->8---
> strsplit(c("a,b;c","d;e,f"),"[,;]")
[[1]]
[1] "a" "b" "c"

[[2]]
[1] "d" "e" "f"
--8<---------------cut here---------------end--------------->8---
Is this a bug or did I misunderstand the docs?
Thanks!

-- 
Sam Steingold (http://sds.podval.org/) on Ubuntu 13.04 (raring) X 11.0.11303000
http://www.childpsy.net/ http://www.memritv.org http://truepeace.org
http://camera.org http://openvotingconsortium.org http://palestinefacts.org
Experience comes with debts.


From marc_schwartz at me.com  Wed Sep 18 17:49:43 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 18 Sep 2013 10:49:43 -0500
Subject: [R] strsplit with a vector split argument
In-Reply-To: <877geeb0h6.fsf@gnu.org>
References: <877geeb0h6.fsf@gnu.org>
Message-ID: <D8B9C0A4-4FFF-435E-94CB-B5A9E5F2EE65@me.com>

On Sep 18, 2013, at 10:42 AM, Sam Steingold <sds at gnu.org> wrote:

> Hi,
> I find this behavior unexpected:
> --8<---------------cut here---------------start------------->8---
>> strsplit(c("a,b;c","d;e,f"),c(",",";"))
> [[1]]
> [1] "a"   "b;c"
> 
> [[2]]
> [1] "d"   "e,f"
> --8<---------------cut here---------------end--------------->8---
> I thought that it should be identical to this:
> --8<---------------cut here---------------start------------->8---
>> strsplit(c("a,b;c","d;e,f"),"[,;]")
> [[1]]
> [1] "a" "b" "c"
> 
> [[2]]
> [1] "d" "e" "f"
> --8<---------------cut here---------------end--------------->8---
> Is this a bug or did I misunderstand the docs?
> Thanks!


The latter. From ?strplit in the description of 'split':

  If split has length greater than 1, it is re-cycled along x.

Thus, in the first example above, ',' is used for the first element of your vector and ';' is used for the second and so on.

Regards,

Marc Schwartz


From smartpink111 at yahoo.com  Wed Sep 18 17:56:36 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 18 Sep 2013 08:56:36 -0700 (PDT)
Subject: [R] Converting a asymmetric data frame to symmetric matrix
In-Reply-To: <5239A839.8080704@fripost.org>
References: <5239A839.8080704@fripost.org>
Message-ID: <1379519796.74164.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,

It is not clear whether it is a data frame or vector.? Please use ?dput() to show the example dataset.


vec1<- 5:7 
mat1<- matrix(0,3,3,dimnames=list(letters[1:3],letters[1:3]))
mat2<- mat1
?nm1<- c("ab","bc","ac")
?vec2<-paste0(colnames(mat1)[col(mat1)],rownames(mat1)[row(mat1)])
?mat1[match(nm1,vec2)]<- vec1
?mat1
#? a b c
#a 0 0 0
#b 5 0 0
#c 7 6 0

#or
?vec2<- c(5,7,6)
?mat2[upper.tri(mat2)]<- vec2
?mat2[lower.tri(mat2)]<- vec2
?mat2
#? a b c
#a 0 5 7
#b 5 0 6
#c 7 6 0
A.K.



----- Original Message -----
From: K. Taraka Rama <taraka at fripost.org>
To: r-help at r-project.org
Cc: 
Sent: Wednesday, September 18, 2013 9:18 AM
Subject: [R] Converting a asymmetric data frame to symmetric matrix

Hi,

I have a pair-wise distance vector. FOr objects: a,b,c, it is: (a,b) :5, 
(b,c) :6, (a,c) : 7. I want to convert it into a symmetric matrix. I 
used cast function but the function does not fill the matrix like a 
triangular matrix. How do I get a symmetric matrix?

-- 
--Taraka

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Wed Sep 18 18:04:45 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 18 Sep 2013 09:04:45 -0700 (PDT)
Subject: [R] strsplit with a vector split argument
In-Reply-To: <877geeb0h6.fsf@gnu.org>
References: <877geeb0h6.fsf@gnu.org>
Message-ID: <1379520285.49123.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
You could try:

strsplit(c("a,b;c","d;e,f"),",|;")
#[[1]]
#[1] "a" "b" "c"
#
#[[2]]
#[1] "d" "e" "f"
A.K.



----- Original Message -----
From: Sam Steingold <sds at gnu.org>
To: r-help at r-project.org
Cc: 
Sent: Wednesday, September 18, 2013 11:42 AM
Subject: [R] strsplit with a vector split argument

Hi,
I find this behavior unexpected:
--8<---------------cut here---------------start------------->8---
> strsplit(c("a,b;c","d;e,f"),c(",",";"))
[[1]]
[1] "a"?  "b;c"

[[2]]
[1] "d"?  "e,f"
--8<---------------cut here---------------end--------------->8---
I thought that it should be identical to this:
--8<---------------cut here---------------start------------->8---
> strsplit(c("a,b;c","d;e,f"),"[,;]")
[[1]]
[1] "a" "b" "c"

[[2]]
[1] "d" "e" "f"
--8<---------------cut here---------------end--------------->8---
Is this a bug or did I misunderstand the docs?
Thanks!

-- 
Sam Steingold (http://sds.podval.org/) on Ubuntu 13.04 (raring) X 11.0.11303000
http://www.childpsy.net/ http://www.memritv.org http://truepeace.org
http://camera.org http://openvotingconsortium.org http://palestinefacts.org
Experience comes with debts.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From 538280 at gmail.com  Wed Sep 18 18:19:53 2013
From: 538280 at gmail.com (Greg Snow)
Date: Wed, 18 Sep 2013 10:19:53 -0600
Subject: [R] the values of predict( , type = "terms", )
In-Reply-To: <018f01ceb385$a2645630$e72d0290$@139.com>
References: <018f01ceb385$a2645630$e72d0290$@139.com>
Message-ID: <CAFEqCdyO+19E1rCCL0M9YAj1BwgT9bf7is09DSUgFqAW0fFYRw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130918/7123ff0b/attachment.pl>

From hpages at fhcrc.org  Wed Sep 18 20:27:00 2013
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Wed, 18 Sep 2013 11:27:00 -0700
Subject: [R] strsplit with a vector split argument
In-Reply-To: <1379520285.49123.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <877geeb0h6.fsf@gnu.org>
	<1379520285.49123.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <5239F074.6040305@fhcrc.org>

On 09/18/2013 09:04 AM, arun wrote:
> Hi,
> You could try:
>
> strsplit(c("a,b;c","d;e,f"),",|;")

He did it with "[,;]" which is equivalent but slightly faster. The more
characters you have inside the square brackets, the more beneficial it
is to use [abcde] over a|b|c|d|e. It's also more compact and easier to
read.

H.

> #[[1]]
> #[1] "a" "b" "c"
> #
> #[[2]]
> #[1] "d" "e" "f"
> A.K.
>
>
>
> ----- Original Message -----
> From: Sam Steingold <sds at gnu.org>
> To: r-help at r-project.org
> Cc:
> Sent: Wednesday, September 18, 2013 11:42 AM
> Subject: [R] strsplit with a vector split argument
>
> Hi,
> I find this behavior unexpected:
> --8<---------------cut here---------------start------------->8---
>> strsplit(c("a,b;c","d;e,f"),c(",",";"))
> [[1]]
> [1] "a"   "b;c"
>
> [[2]]
> [1] "d"   "e,f"
> --8<---------------cut here---------------end--------------->8---
> I thought that it should be identical to this:
> --8<---------------cut here---------------start------------->8---
>> strsplit(c("a,b;c","d;e,f"),"[,;]")
> [[1]]
> [1] "a" "b" "c"
>
> [[2]]
> [1] "d" "e" "f"
> --8<---------------cut here---------------end--------------->8---
> Is this a bug or did I misunderstand the docs?
> Thanks!
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From jholtman at gmail.com  Wed Sep 18 21:33:15 2013
From: jholtman at gmail.com (jim holtman)
Date: Wed, 18 Sep 2013 15:33:15 -0400
Subject: [R] If-then with Dates in Date Ranges
In-Reply-To: <1379440356.86249.YahooMailNeo@web162302.mail.bf1.yahoo.com>
References: <1379440356.86249.YahooMailNeo@web162302.mail.bf1.yahoo.com>
Message-ID: <CAAxdm-59toSiRz_h4WvagW0n_p=u+o8C3cO5pD8+cBTiDV8P0A@mail.gmail.com>

You need to tell us what the objects are.  Are they vectors of some
type of data?  If so, what type, etc......

At least provide a subset of the data using 'dput' so we know what we
are looking at.

The 'if' statement will work fine is the objects are single valued;
you will need a different syntax if they are vectors of values and the
exact statement will depend on the data.

Please follow the posting guidelines.

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Tue, Sep 17, 2013 at 1:52 PM, Zd Gibbs <zd.gibbs at yahoo.com> wrote:
> Hello everyone.
>
> I am very much a beginner with R and I am trying to turn the following if-then statement into R code. More detail. I want to create a new variable: "inperiod" that will be a numeric code. So if a specific event start date (StartDate) is greater or equal to a testing date (Beg1Date) AND the event end date (EndDate) is less than or equal to the testing date (Beg1Date), I want the inperiod code to be 1. I will do this for a range of dates so that the code can be anywhere from 1-25.
>
> If StartDate >= Beg1Date & EndDate <= Beg1Date inperiod = 1.
>
> Thanks for any help.
>
> Zeda
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From macqueen1 at llnl.gov  Wed Sep 18 21:43:27 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 18 Sep 2013 19:43:27 +0000
Subject: [R] If-then with Dates in Date Ranges
In-Reply-To: <1379440356.86249.YahooMailNeo@web162302.mail.bf1.yahoo.com>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521910D4437D2@PRDEXMBX-08.the-lab.llnl.gov>

On possible way, if I understand the question correctly, is to use the
findInterval() function.
Otherwise, solutions depend on details you haven't included.

Here's an example from ?findInterval

  x <- 2:18
  v <- c(5, 10, 15) # create two bins [5,10) and [10,15)
  cbind(x, findInterval(x, v))
 
The cut() function might also work.

Based on the example from ?findInterval, try this:

>  bnds <- Sys.Date() + seq(0,15,5)
>  vals  <- Sys.Date() + 1:15
 
> cbind(vals, findInterval(vals,bnds))
       vals  
 [1,] 15967 1
 [2,] 15968 1
 [3,] 15969 1
 [4,] 15970 1
 [5,] 15971 2
 [6,] 15972 2
 [7,] 15973 2
 [8,] 15974 2
 [9,] 15975 2
[10,] 15976 3
[11,] 15977 3
[12,] 15978 3
[13,] 15979 3
[14,] 15980 3
[15,] 15981 4

> tmp <-  findInterval(vals,bnds)


> cbind(format(vals),tmp)                    tmp
 [1,] "2013-09-19" "1"
 [2,] "2013-09-20" "1"
 [3,] "2013-09-21" "1"
 [4,] "2013-09-22" "1"
 [5,] "2013-09-23" "2"
 [6,] "2013-09-24" "2"
 [7,] "2013-09-25" "2"
 [8,] "2013-09-26" "2"
 [9,] "2013-09-27" "2"
[10,] "2013-09-28" "3"
[11,] "2013-09-29" "3"
[12,] "2013-09-30" "3"
[13,] "2013-10-01" "3"
[14,] "2013-10-02" "3"
[15,] "2013-10-03" "4"



For your one-line fragment, the basic syntax would be

  if (StartDate >= Beg1Date & EndDate <= Beg1Date) inperiod <- 1 else
inperiod <- 0

but of course that handles only one time interval (bin).
A huge if, else if, else if, ... thing could be used, but R has a better
way!



-Don
 

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 9/17/13 10:52 AM, "Zd Gibbs" <zd.gibbs at yahoo.com> wrote:

>Hello everyone.
>
>I am very much a beginner with R and I am trying to turn the following
>if-then statement into R code. More detail. I want to create a new
>variable: "inperiod" that will be a numeric code. So if a specific event
>start date (StartDate) is greater or equal to a testing date (Beg1Date)
>AND the event end date (EndDate) is less than or equal to the testing
>date (Beg1Date), I want the inperiod code to be 1. I will do this for a
>range of dates so that the code can be anywhere from 1-25.
>
>If StartDate >= Beg1Date & EndDate <= Beg1Date inperiod = 1.
>
>Thanks for any help.
>
>Zeda
>	[[alternative HTML version deleted]]
>


From smartpink111 at yahoo.com  Wed Sep 18 22:00:55 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 18 Sep 2013 13:00:55 -0700 (PDT)
Subject: [R] How to find values that correspond to a given value (i.e.
	max)
Message-ID: <1379534455.7809.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
Try:
?all[which.max(all$income),c('names','age')]
#? names age
#2?? Jim? 25


A.K.


Hi everyone 
I'm new to R, so this is probably a stupid question, but I looked 
around for quite a while an couldn't find an answer. Basically I'm 
trying to print values that correspond to a found maximum. 

If I have this: 

"names" <- c("John", "Jim", "Mary", "Susan") 
"age" <- c(16, 25, 32, 56) 
"income" <- c(2000, 3000, 2500, 1500) 
"all"<- data.frame(names, age, income) 
max(all$income) 

I would like to print the name and age that correspond to the 
found maximum. I tried some if-statements, but they didn't work because 
my programming skills outside of SQL are basically non-existent. 

I'd be glad for any pointers, thanks


From friendly at yorku.ca  Wed Sep 18 22:06:26 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 18 Sep 2013 16:06:26 -0400
Subject: [R] ggplot: stat_smooth(method='glm', ...) - plot linear predictor?
Message-ID: <523A07C2.3080509@yorku.ca>

The code below uses ggplot with stat_smooth(method="glm", 
family=binomial, ...)
to plot the data on survival of passengers on the Titanic, with the 
logistic regression
curves for each sex on the scale of Pr(survived). This works (quite 
nicely!)  because
I've explicitly transformed the factor survived to 0/1 in the ggplot call.

Some questions:

- Is it possible, and if so, how, to plot the same data and fitted 
smooths on the logit
scale, i.e., the linear predictor for the binomial glm?

- the response, survived, is a factor.  Is it possible to avoid using 
as.numeric(survived)-1
in the call to ggplot()? This is cosmetic, but requires an extra bit of 
explanation to use
in teaching or writing.
i.e., glm() is quite happy to fit the model survived ~ age+sex
in the binomial family, and gives the same predicted probabilities and 
logits.

install.packages("vcdExtra")# data from the most recent version, 
vcdExtra_0.5-11
data(Titanicp, package="vcdExtra")
str(Titanicp)

'data.frame':   1309 obs. of  6 variables:
  $ pclass  : Factor w/ 3 levels "1st","2nd","3rd": 1 1 1 1 1 1 1 1 1 1 ...
  $ survived: Factor w/ 2 levels "died","survived": 2 2 1 1 1 2 2 1 2 1 ...
  $ sex     : Factor w/ 2 levels "female","male": 1 2 1 2 1 2 1 2 1 2 ...
  $ age     : num  29 0.917 2 30 25 ...
  $ sibsp   : num  0 1 1 1 1 0 1 0 2 0 ...
  $ parch   : num  0 2 2 2 2 0 0 0 0 0 ...
 >


require(ggplot2)
# remove missings on age
Titanicp <- Titanicp[!is.na(Titanicp$age),]

ggplot(Titanicp, aes(age, as.numeric(survived)-1, color=sex)) +
     stat_smooth(method="glm", family=binomial, formula=y~x, alpha=0.2, 
size=2, aes(fill=sex)) +
     geom_point(position=position_jitter(height=0.02, width=0), size=1.5)

# equivalent logistic regression model, survived as a factor
mod <- glm(survived ~ age+sex, family=binomial, data=Titanicp)
summary(mod)

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From tomdharray at gmail.com  Wed Sep 18 17:42:20 2013
From: tomdharray at gmail.com (Tom D. Harray)
Date: Wed, 18 Sep 2013 11:42:20 -0400
Subject: [R] Radius of Curvature Fit
Message-ID: <CAM9RCO8K7y9xnTvVnd1QCQdQwvBu2CU_OxdnGAmMrhCg+H7P4Q@mail.gmail.com>

Hi there,

I want to know the radius of curvature for a set of points, but cannot
figure out how to perform the fit in R.

I have a set of points P_i for which I want to calculate the radius of
curvature. The coordinates (x_i|y_i) of the points in a data.frame:

p <- data.frame(
    x = c(113, 143, 184, 229, 290, 342, 393, 456, 540, 618),
    y = c(392, 389, 386, 383, 379, 380, 380, 380, 383, 388)
    )

For the radius of curvature I now have to find the circle the which
describes best my points. This circle has an origin at r_x and r_y,
and the radius r. The equation I started with is:

   r^2 = (r_x - x_i)^2 + (r_y + y_i)^2

r^2, r_x, and r_y are constant. Expanding the quadratic terms and
subtracting r^2 leads to

   0 = x_i^2 + (-2*r_x)*x_i  +  y_i^2 + (-2*r_y)*y_i  + r_x^2 + r_y^2 - r^2

The last three terms add up to zero due to r^2 = r_x^2 + r_y^2:

   0 = x_i^2 + (-2*r_x)*x_i  +  y_i^2 + (-2*r_y)*y_i

Here I got stuck. I -- as a non-mathematician -- would describe it as
quadratic equation in two dimensions, but I didn't succeed searching
for these terms in the help, mailing list, and web.

My question is: How to estimate the r_x, and r_y from the set of
points p using R?


Thanks and regards,

Dirk


From Stephanie.Ross at phri.ca  Wed Sep 18 21:40:53 2013
From: Stephanie.Ross at phri.ca (Ross, Stephanie)
Date: Wed, 18 Sep 2013 19:40:53 +0000
Subject: [R] Dose-response relationship using metafor?
Message-ID: <62901AE6C429764C82AE0D998DFC8FF2140A20@RIEXMBXP1.DBRI.LOCAL>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130918/4f7b5cb5/attachment.pl>

From jacqueline.schweizer at wuestundpartner.com  Wed Sep 18 18:44:54 2013
From: jacqueline.schweizer at wuestundpartner.com (jas)
Date: Wed, 18 Sep 2013 09:44:54 -0700 (PDT)
Subject: [R] One-To-Many Spatial JOIN
Message-ID: <1379522694441-4676447.post@n4.nabble.com>



Hello all,

I am trying to do a one-to-many Spatial Join with PolyLines and Polygons. I
have about a couple of thousands of PolyLines (streets) and I want to assign
them all the Polyogons (regions) they cross or touch.

I know this is possible in ArcGIS, do you have any idea how this is possible
in R? the simple over-methods dont seem to cut it.

Thanks a bunch,

Jacqueline



--
View this message in context: http://r.789695.n4.nabble.com/One-To-Many-Spatial-JOIN-tp4676447.html
Sent from the R help mailing list archive at Nabble.com.


From s.tsiropoulou.1 at research.gla.ac.uk  Wed Sep 18 17:54:19 2013
From: s.tsiropoulou.1 at research.gla.ac.uk (SOPHIA TSIROPOULOU)
Date: Wed, 18 Sep 2013 16:54:19 +0100
Subject: [R] v3.0.1 issue
Message-ID: <5F46D59F8ABDE34BB68E87EADB758CA87EE76BBBE2@CMS07.campus.gla.ac.uk>

Hi there,

I have recently installed the latest R version 3.0.1, replacing the previous version 2.15.2.

Just as I am running R I get a few warnings about packages that I have previously used.

Below I attach the session info a long with the warnings I am getting.

What does these warnings mean? Is there something I could do to fix the issue?

Thanks a lot for your help.

Sophia



> sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United Kingdom.1252 
[2] LC_CTYPE=English_United Kingdom.1252   
[3] LC_MONETARY=English_United Kingdom.1252
[4] LC_NUMERIC=C                           
[5] LC_TIME=English_United Kingdom.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base




R version 3.0.1 (2013-05-16) -- "Good Sport"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: i386-w64-mingw32/i386 (32-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

Warning: namespace ?xcms? is not available and has been replaced
by .GlobalEnv when processing object ?.Last?
Warning: namespace ?XML? is not available and has been replaced
by .GlobalEnv when processing object ?.Last?
Warning: namespace ?rJava? is not available and has been replaced
by .GlobalEnv when processing object ?.Last?
[Previously saved workspace restored]

From Tim.Umbach at hufw.de  Wed Sep 18 21:42:36 2013
From: Tim.Umbach at hufw.de (Hal_V)
Date: Wed, 18 Sep 2013 12:42:36 -0700 (PDT)
Subject: [R] How to find values that correspond to a given value (i.e. max)
Message-ID: <1379533356055-4676456.post@n4.nabble.com>

Hi everyone
I'm new to R, so this is probably a stupid question, but I looked around for
quite a while an couldn't find an answer. Basically I'm trying to print
values that correspond to a found maximum.

If I have this:

"names" <- c("John", "Jim", "Mary", "Susan")
"age" <- c(16, 25, 32, 56)
"income" <- c(2000, 3000, 2500, 1500)
"all"<- data.frame(names, age, income)
max(all$income)

I would like to print the name and age that correspond to the found maximum.
I tried some if-statements, but they didn't work because my programming
skills outside of SQL are basically non-existent.

I'd be glad for any pointers, thanks



--
View this message in context: http://r.789695.n4.nabble.com/How-to-find-values-that-correspond-to-a-given-value-i-e-max-tp4676456.html
Sent from the R help mailing list archive at Nabble.com.


From gw57 at duke.edu  Wed Sep 18 19:28:39 2013
From: gw57 at duke.edu (wacguy)
Date: Wed, 18 Sep 2013 10:28:39 -0700 (PDT)
Subject: [R] cov2cor exp
In-Reply-To: <1379471415255-4676395.post@n4.nabble.com>
References: <1379471415255-4676395.post@n4.nabble.com>
Message-ID: <1379525319734-4676450.post@n4.nabble.com>

Ok, Thanks foe the answer, Ken:

*1L, 2L etc are integers. (That is, identical to as.integer(1) ,
as.integer(2) etc)

Using integers (instead of "numeric" type) is more efficient as here they're
used as indexes and would be converted to integer anyway.

Compare 
> is(1) 
... and 
> is(1L)

1L:p is the sequence 1, 2, 3, ..., p (just like 1:p)

Just for curiosity, what is findFn('cov2cor') ?

Regards,
Kenn*

I don't know what findFn('cov2cor') is, I'm a total newbie to R but I
created a new, simpler to my opinion function for some descriptive
statistics as matrix functions for a matrix called "x":

one1=c(rep(1, nrow(x)))
means <- t(one1)%*%x/3#row vector of means
M=one1%*%means#A ?? ? ?? matrix ?? where each column is filled with the mean
value for that column
D=x-M#deviation matrix
S=(t(D)%*%D)/(nrow(x)-1)#Covariance matrix

R=function(S){###R is a Correlation matrix###
  V=matrix(nrow=nrow(S),ncol=ncol(S))
  V1 <- sqrt(1/diag(S))
  diag(V)=V1
  V[is.na(V)]=0
  R=V%*%S%*%V
  return(R)
}
  R(S)



--
View this message in context: http://r.789695.n4.nabble.com/cov2cor-exp-tp4676395p4676450.html
Sent from the R help mailing list archive at Nabble.com.


From wdunlap at tibco.com  Wed Sep 18 23:51:02 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 18 Sep 2013 21:51:02 +0000
Subject: [R] How to find values that correspond to a given value (i.e.
 max)
In-Reply-To: <1379533356055-4676456.post@n4.nabble.com>
References: <1379533356055-4676456.post@n4.nabble.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C34401E@PA-MBX01.na.tibco.com>

> If I have this:
> 
> "names" <- c("John", "Jim", "Mary", "Susan")
> "age" <- c(16, 25, 32, 56)
> "income" <- c(2000, 3000, 2500, 1500)
> "all"<- data.frame(names, age, income)

First, things will be easier for you if you make that dataset as
   all <- data.frame(
                       names = c("John", "Jim", "Mary", "Susan"),
                       age = c(16, 25, 32, 56),
                       income = c(2000, 3000, 2500, 1500))
so you don't have two things called "names", etc., one in the data.frame
and one in the current environment.

You can select subsets in R using the "[" operator.  If it is given an integer
argument it gives you the items indexed by that that integer vector; if
given a logical argument it gives you the items corresponding to TRUE's
in that logical vector.  E.g., try
   x <- c(11,22,33,44)
   x[c(1,3)] # gives 11 and 33
   x[c(TRUE, FALSE, TRUE, FALSE)] # also gives 11 and 33

Make a logical vector of showing which items in 'income' are equal to
its maximum with
   atMaxIncome <- max(all$income) == all$income # gives, FALSE TRUE FALSE FALSE
and do the selection with
   all[ atMaxIncome, ]

> I tried some if-statements, but they didn't work because my programming
> skills outside of SQL are basically non-existent.

All of this is in Chapter 2 of "An Introduction to R" (about 4 pages into it), which comes with R.
Read it and do the examples and your R programming skills will improve.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Hal_V
> Sent: Wednesday, September 18, 2013 12:43 PM
> To: r-help at r-project.org
> Subject: [R] How to find values that correspond to a given value (i.e. max)
> 
> Hi everyone
> I'm new to R, so this is probably a stupid question, but I looked around for
> quite a while an couldn't find an answer. Basically I'm trying to print
> values that correspond to a found maximum.
> 
> If I have this:
> 
> "names" <- c("John", "Jim", "Mary", "Susan")
> "age" <- c(16, 25, 32, 56)
> "income" <- c(2000, 3000, 2500, 1500)
> "all"<- data.frame(names, age, income)
> max(all$income)
> 
> I would like to print the name and age that correspond to the found maximum.
> I tried some if-statements, but they didn't work because my programming
> skills outside of SQL are basically non-existent.
> 
> I'd be glad for any pointers, thanks
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/How-to-find-values-that-
> correspond-to-a-given-value-i-e-max-tp4676456.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Tim.Umbach at hufw.de  Thu Sep 19 00:23:22 2013
From: Tim.Umbach at hufw.de (Hal_V)
Date: Wed, 18 Sep 2013 15:23:22 -0700 (PDT)
Subject: [R] How to find values that correspond to a given value (i.e.
	max)
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C34401E@PA-MBX01.na.tibco.com>
References: <1379533356055-4676456.post@n4.nabble.com>
	<E66794E69CFDE04D9A70842786030B931C34401E@PA-MBX01.na.tibco.com>
Message-ID: <CA+iePb=YFKN-5BsVpZK1V+JvAQ_rtx+HEJwpGEpoz_Sfka7XVw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130918/da25678c/attachment.pl>

From saptarshi.guha at gmail.com  Thu Sep 19 00:56:36 2013
From: saptarshi.guha at gmail.com (Saptarshi Guha)
Date: Wed, 18 Sep 2013 15:56:36 -0700
Subject: [R] rbinlist for data.table and specifying the column class
Message-ID: <CAJDot1pMbbz9+h5FxNU4J=dgSD4RZJokOrV7b3Kf1ZzdKSvqXQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130918/1eff17c9/attachment.pl>

From macqueen1 at llnl.gov  Thu Sep 19 01:57:19 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 18 Sep 2013 23:57:19 +0000
Subject: [R] One-To-Many Spatial JOIN
In-Reply-To: <1379522694441-4676447.post@n4.nabble.com>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521910D444436@PRDEXMBX-08.the-lab.llnl.gov>

I'd suggest you ask this question on r-sig-geo
-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 9/18/13 9:44 AM, "jas" <jacqueline.schweizer at wuestundpartner.com> wrote:

>
>
>Hello all,
>
>I am trying to do a one-to-many Spatial Join with PolyLines and Polygons.
>I
>have about a couple of thousands of PolyLines (streets) and I want to
>assign
>them all the Polyogons (regions) they cross or touch.
>
>I know this is possible in ArcGIS, do you have any idea how this is
>possible
>in R? the simple over-methods dont seem to cut it.
>
>Thanks a bunch,
>
>Jacqueline
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/One-To-Many-Spatial-JOIN-tp4676447.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From kridox at ymail.com  Thu Sep 19 02:20:06 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 19 Sep 2013 09:20:06 +0900
Subject: [R] cov2cor exp
In-Reply-To: <1379525319734-4676450.post@n4.nabble.com>
References: <1379471415255-4676395.post@n4.nabble.com>
	<1379525319734-4676450.post@n4.nabble.com>
Message-ID: <CAAcyNCx1BcH6fnRiU=UJGff2vwjkOkCAWet-kWN=UJ+rAufr-w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130919/d775e7a7/attachment.pl>

From wdunlap at tibco.com  Thu Sep 19 02:22:02 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 19 Sep 2013 00:22:02 +0000
Subject: [R] How to find values that correspond to a given value
	(i.e.	max)
In-Reply-To: <CA+iePb=YFKN-5BsVpZK1V+JvAQ_rtx+HEJwpGEpoz_Sfka7XVw@mail.gmail.com>
References: <1379533356055-4676456.post@n4.nabble.com>
	<E66794E69CFDE04D9A70842786030B931C34401E@PA-MBX01.na.tibco.com>
	<CA+iePb=YFKN-5BsVpZK1V+JvAQ_rtx+HEJwpGEpoz_Sfka7XVw@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C34478A@PA-MBX01.na.tibco.com>

I would stay away from learning about 'while' and 'if' until you
understand using '[' to select subsets.  Subsetting is in chapter 2
of "An Introduction to R" and 'while' and 'if' are in chapter 9 for
good reason.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Hal_V
> Sent: Wednesday, September 18, 2013 3:23 PM
> To: r-help at r-project.org
> Subject: Re: [R] How to find values that correspond to a given value (i.e. max)
> 
> Thanks a lot to you both.
> Both solutions work great, and thanks to will for explaining how this
> works. I will have a look into while and if statements in R tomorrow...
> 
> 
> 2013/9/18 William Dunlap [via R] <ml-node+s789695n4676466h90 at n4.nabble.com>
> 
> > > If I have this:
> > >
> > > "names" <- c("John", "Jim", "Mary", "Susan")
> > > "age" <- c(16, 25, 32, 56)
> > > "income" <- c(2000, 3000, 2500, 1500)
> > > "all"<- data.frame(names, age, income)
> >
> > First, things will be easier for you if you make that dataset as
> >    all <- data.frame(
> >                        names = c("John", "Jim", "Mary", "Susan"),
> >                        age = c(16, 25, 32, 56),
> >                        income = c(2000, 3000, 2500, 1500))
> > so you don't have two things called "names", etc., one in the data.frame
> > and one in the current environment.
> >
> > You can select subsets in R using the "[" operator.  If it is given an
> > integer
> > argument it gives you the items indexed by that that integer vector; if
> > given a logical argument it gives you the items corresponding to TRUE's
> > in that logical vector.  E.g., try
> >    x <- c(11,22,33,44)
> >    x[c(1,3)] # gives 11 and 33
> >    x[c(TRUE, FALSE, TRUE, FALSE)] # also gives 11 and 33
> >
> > Make a logical vector of showing which items in 'income' are equal to
> > its maximum with
> >    atMaxIncome <- max(all$income) == all$income # gives, FALSE TRUE FALSE
> > FALSE
> > and do the selection with
> >    all[ atMaxIncome, ]
> >
> > > I tried some if-statements, but they didn't work because my programming
> > > skills outside of SQL are basically non-existent.
> >
> > All of this is in Chapter 2 of "An Introduction to R" (about 4 pages into
> > it), which comes with R.
> > Read it and do the examples and your R programming skills will improve.
> >
> > Bill Dunlap
> > Spotfire, TIBCO Software
> > wdunlap tibco.com
> >
> > > -----Original Message-----
> > > From: [hidden
> email]<http://user/SendEmail.jtp?type=node&node=4676466&i=0>[mailto:[hidden
> > email] <http://user/SendEmail.jtp?type=node&node=4676466&i=1>] On Behalf
> > > Of Hal_V
> > > Sent: Wednesday, September 18, 2013 12:43 PM
> > > To: [hidden email]<http://user/SendEmail.jtp?type=node&node=4676466&i=2>
> > > Subject: [R] How to find values that correspond to a given value (i.e.
> > max)
> > >
> > > Hi everyone
> > > I'm new to R, so this is probably a stupid question, but I looked around
> > for
> > > quite a while an couldn't find an answer. Basically I'm trying to print
> > > values that correspond to a found maximum.
> > >
> > > If I have this:
> > >
> > > "names" <- c("John", "Jim", "Mary", "Susan")
> > > "age" <- c(16, 25, 32, 56)
> > > "income" <- c(2000, 3000, 2500, 1500)
> > > "all"<- data.frame(names, age, income)
> > > max(all$income)
> > >
> > > I would like to print the name and age that correspond to the found
> > maximum.
> > > I tried some if-statements, but they didn't work because my programming
> > > skills outside of SQL are basically non-existent.
> > >
> > > I'd be glad for any pointers, thanks
> > >
> > >
> > >
> > > --
> > > View this message in context:
> > http://r.789695.n4.nabble.com/How-to-find-values-that-
> > > correspond-to-a-given-value-i-e-max-tp4676456.html
> > > Sent from the R help mailing list archive at Nabble.com.
> > >
> > > ______________________________________________
> > > [hidden email] <http://user/SendEmail.jtp?type=node&node=4676466&i=3>mailing
> list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > [hidden email] <http://user/SendEmail.jtp?type=node&node=4676466&i=4>mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> > ------------------------------
> >  If you reply to this email, your message will be added to the discussion
> > below:
> >
> > http://r.789695.n4.nabble.com/How-to-find-values-that-correspond-to-a-given-value-
> i-e-max-tp4676456p4676466.html
> >  To unsubscribe from How to find values that correspond to a given value
> > (i.e. max), click
> here<http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_
> code&node=4676456&code=VGltLlVtYmFjaEBodWZ3LmRlfDQ2NzY0NTZ8MTg1MTc5NTE
> yOQ==>
> > .
> >
> NAML<http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=macro_viewer
> &id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicName
> space-nabble.view.web.template.NabbleNamespace-
> nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabbl
> e%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-
> send_instant_email%21nabble%3Aemail.naml>
> >
> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/How-to-find-values-that-
> correspond-to-a-given-value-i-e-max-tp4676456p4676467.html
> Sent from the R help mailing list archive at Nabble.com.
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kridox at ymail.com  Thu Sep 19 02:39:34 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 19 Sep 2013 09:39:34 +0900
Subject: [R] Radius of Curvature Fit
In-Reply-To: <CAM9RCO8K7y9xnTvVnd1QCQdQwvBu2CU_OxdnGAmMrhCg+H7P4Q@mail.gmail.com>
References: <CAM9RCO8K7y9xnTvVnd1QCQdQwvBu2CU_OxdnGAmMrhCg+H7P4Q@mail.gmail.com>
Message-ID: <CAAcyNCzMGNAKOX2OBoQ-i2zkAAYZGhPEfkMdMG-C-WBYeyg50w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130919/6cf66f8f/attachment.pl>

From smartpink111 at yahoo.com  Thu Sep 19 02:44:06 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 18 Sep 2013 17:44:06 -0700 (PDT)
Subject: [R] rbinlist for data.table and specifying the column class
In-Reply-To: <CAJDot1pMbbz9+h5FxNU4J=dgSD4RZJokOrV7b3Kf1ZzdKSvqXQ@mail.gmail.com>
References: <CAJDot1pMbbz9+h5FxNU4J=dgSD4RZJokOrV7b3Kf1ZzdKSvqXQ@mail.gmail.com>
Message-ID: <1379551446.75958.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
Try:

rbindlist(list(list(a=NA_integer_,b=NA),list(a=20,b=FALSE)))
#??? a???? b
#1: NA??? NA
#2: 20 FALSE


A.K.

----- Original Message -----
From: Saptarshi Guha <saptarshi.guha at gmail.com>
To: "R-help at r-project.org" <R-help at r-project.org>
Cc: 
Sent: Wednesday, September 18, 2013 6:56 PM
Subject: [R] rbinlist for data.table and specifying the column class

hello,


This

rbindlist(list(list(a=NA,b=NA),list(a=20,b=FALSE)))

returns

? ? ? a? ?  b
1:?  NA? ? NA
2: TRUE FALSE

as per the documentation ?rbindlist

is there a way to specify the column class of 'a' to be numeric?
In actual usage, i wont be able to re-order the 2nd list entry to be the
first.

I did try

rbindlist(list(list(a=numeric(0),b=logical(0),list(a=NA,b=NA),list(a=20,b=FALSE)))

but got

? ? ? a? ?  b
1:?  NA? ? NA
2: TRUE FALSE

This worked

mu? =
rbindlist(list(list(a=numeric(1),b=logical(1),list(a=NA,b=NA),list(a=20,b=FALSE)))
mu = mu[-1,]

Is there a way to specify up front the classes rather than the last approach

Regards
Saptarshi

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From matloff at cs.ucdavis.edu  Thu Sep 19 04:22:51 2013
From: matloff at cs.ucdavis.edu (Norm Matloff)
Date: Wed, 18 Sep 2013 19:22:51 -0700
Subject: [R] novel graphics package
Message-ID: <20130919022251.GJ6584@laura>

I've developed a new graphics library, BDGraphs, designed for "big"
data, meaning any data large enough to cause major screen clutter and
overplotting if the points are plotted individually.

The library includes a novel approach to parallel coordinates, and some
methods I introduced in my JSM talk last month.

I'm posting this message because I'd like to get feedback from people
before I put the package on CRAN.  If you're interested, please go to 

http://heather.cs.ucdavis.edu/bdgraphs.html 

The package is there for downloading, and the Examples page shows
several examples with pictures.

Norm Matloff


From amoser1 at binghamton.edu  Thu Sep 19 06:04:16 2013
From: amoser1 at binghamton.edu (Alecia M Moser)
Date: Thu, 19 Sep 2013 00:04:16 -0400
Subject: [R] replace.df() function in R
Message-ID: <CAHHZM+06XaXqv-yuE6kaP94=iE1dCMSepteasjaiOg50PwzrHQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130919/24a7a704/attachment.pl>

From kridox at ymail.com  Thu Sep 19 06:19:42 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 19 Sep 2013 13:19:42 +0900
Subject: [R] replace.df() function in R
In-Reply-To: <CAHHZM+06XaXqv-yuE6kaP94=iE1dCMSepteasjaiOg50PwzrHQ@mail.gmail.com>
References: <CAHHZM+06XaXqv-yuE6kaP94=iE1dCMSepteasjaiOg50PwzrHQ@mail.gmail.com>
Message-ID: <CAAcyNCwOy075uKs98xCF3DiHVTUn-KutewB0rwWJKfSUmnquiA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130919/15c46a6f/attachment.pl>

From amoser1 at binghamton.edu  Thu Sep 19 07:01:06 2013
From: amoser1 at binghamton.edu (Alecia M Moser)
Date: Thu, 19 Sep 2013 01:01:06 -0400
Subject: [R] Replacement function using grouping variable
Message-ID: <CAHHZM+07ZgLxam-YXZp8uN8i1+Sd_2j1qEtEGpS-MR-CT4bOUA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130919/b5a248e6/attachment.pl>

From kennyxu1983 at hotmail.com  Thu Sep 19 04:21:17 2013
From: kennyxu1983 at hotmail.com (kenny xu)
Date: Thu, 19 Sep 2013 12:21:17 +1000
Subject: [R] glmer vs glmmadmb
Message-ID: <BLU169-W126E9B4CB282C9DCFC5791AB6210@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130919/fa994717/attachment.pl>

From james at crosb.ie  Wed Sep 18 23:43:25 2013
From: james at crosb.ie (jcrosbie)
Date: Wed, 18 Sep 2013 14:43:25 -0700 (PDT)
Subject: [R] Download data
In-Reply-To: <1369836315.62054.YahooMailNeo@web5806.biz.mail.ne1.yahoo.com>
References: <1369756934006-4668138.post@n4.nabble.com>
	<CAN5YmCGGosh=K7zmSH4231xzp2Zs0BcXJ8bi5Qp2WAt3uy4-AQ@mail.gmail.com>
	<1369836315.62054.YahooMailNeo@web5806.biz.mail.ne1.yahoo.com>
Message-ID: <1379540605812-4676465.post@n4.nabble.com>

Thank you for all your help. I'm still not able to figure out how automate
downloads from online websites.

This is a daily function to download the needed data. I would also like to
be able to do this on other websites such as: 

http://ets.aeso.ca/ets_web/docroot/Market/Reports/HistoricalReportsStart.html

and

http://www.ngx.com/?page_id=561




--
View this message in context: http://r.789695.n4.nabble.com/Download-data-tp4668138p4676465.html
Sent from the R help mailing list archive at Nabble.com.


From laomeng_3 at 163.com  Thu Sep 19 04:01:19 2013
From: laomeng_3 at 163.com (meng)
Date: Thu, 19 Sep 2013 10:01:19 +0800 (CST)
Subject: [R] question about "lines"
In-Reply-To: <52398C7A.7080405@gmail.com>
References: <2d78a066.e241.1412bd056d8.Coremail.laomeng_3@163.com>
	<52385164.6030909@gmail.com>
	<8398c46.f99e.1412e117483.Coremail.laomeng_3@163.com>
	<5238F8AF.20602@gmail.com>
	<5658b215.16dd2.1412f93a1e8.Coremail.laomeng_3@163.com>
	<52398C7A.7080405@gmail.com>
Message-ID: <294a84a2.dce.14133f33601.Coremail.laomeng_3@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130919/ee461119/attachment.pl>

From kridox at ymail.com  Thu Sep 19 04:59:06 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 19 Sep 2013 11:59:06 +0900
Subject: [R] cov2cor exp
In-Reply-To: <A90A0274487D124AB11C77E82ACD449602FBA0CB@ex-mbg-04.win.duke.edu>
References: <1379471415255-4676395.post@n4.nabble.com>
	<1379525319734-4676450.post@n4.nabble.com>
	<CAAcyNCx1BcH6fnRiU=UJGff2vwjkOkCAWet-kWN=UJ+rAufr-w@mail.gmail.com>
	<A90A0274487D124AB11C77E82ACD449602FBA0CB@ex-mbg-04.win.duke.edu>
Message-ID: <CAAcyNCwB3A4CpVKSk_iuEF+dVwMHQRiSfnuMU3SAOZEEfYHjNw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130919/998f2701/attachment.pl>

From jeff.n.marcus at gmail.com  Thu Sep 19 06:07:56 2013
From: jeff.n.marcus at gmail.com (Jeff Marcus)
Date: Thu, 19 Sep 2013 00:07:56 -0400
Subject: [R] =?windows-1252?q?How_do_I_ensure_that_the_polygon_in_spatstat?=
	=?windows-1252?q?=3A=3Aowin=28poly=3D=3Cpolygon=3E=29_does_not_hav?=
	=?windows-1252?q?e_=93negative_area=94?=
Message-ID: <CAHAP1TDsYaWfsh+hv2MYBmLnHkzy2QJ=f3H59ySNbs6Y_TKDdw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130919/dc9fb758/attachment.pl>

From jeff.n.marcus at gmail.com  Thu Sep 19 06:24:08 2013
From: jeff.n.marcus at gmail.com (Jeff Marcus)
Date: Thu, 19 Sep 2013 00:24:08 -0400
Subject: [R] =?windows-1252?q?How_do_I_ensure_that_the_polygon_in_spatstat?=
	=?windows-1252?q?=3A=3Aowin=28poly=3D=3Cpolygon=3E=29_does_not_hav?=
	=?windows-1252?q?e_=93negative_area=94?=
Message-ID: <CAHAP1TAKEb=FcDkRY1AUL7zXhNMOimsVV_MPVVYYSiPHYjzzuA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130919/3e6337ec/attachment.pl>

From anna.zakrisson at su.se  Thu Sep 19 07:38:01 2013
From: anna.zakrisson at su.se (Anna Zakrisson Braeunlich)
Date: Thu, 19 Sep 2013 05:38:01 +0000
Subject: [R] ggplot2: two y-axis - any change?
Message-ID: <11019DCE9B47004F90B2D9C62FF15792025E9CBC@ebox-prod-srv04.win.su.se>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130919/8d2ff862/attachment.pl>

From kien.kieu at jouy.inra.fr  Thu Sep 19 08:58:23 2013
From: kien.kieu at jouy.inra.fr (=?ISO-8859-1?Q?Ki=EAn_Ki=EAu?=)
Date: Thu, 19 Sep 2013 08:58:23 +0200
Subject: [R] callNextMethod with dots argument
Message-ID: <523AA08F.3000507@jouy.inra.fr>

Hi,

I met a problem when invoking callNextMethod within a method associated 
with a generic function taking ... as an argument.

Here is the code

setClass("Aparent",representation(x="numeric",y="numeric"))
setClass("Achild",contains="Aparent")

setGeneric("do",def=function(a,...) standardGeneric("do"))
setMethod("do",signature(a="Aparent"),
           function(a,msg) {
             print("do Aparent")
           })
setMethod("do",signature(a="Achild"),
           function(a,msg)  {
             print("do Achild")
             callNextMethod()
           })

myA <- new("Achild")
buf <- do(a=myA)               # works
buf <- do(a=myA,msg="bonjour") # error

The last call yields the following error message:

Error in callNextMethod() :
   in processing 'callNextMethod', found a '...' in the matched call, 
but no corresponding '...' argument

which I do not understand. Replacing "..." by "msg" in setGeneric makes 
it work. But I don't like this limitation so much (unless I understand it).

Regards.

Kien


From lebatsnok at gmail.com  Thu Sep 19 10:48:44 2013
From: lebatsnok at gmail.com (Kenn Konstabel)
Date: Thu, 19 Sep 2013 11:48:44 +0300
Subject: [R] can you explain the cov2cor function
In-Reply-To: <CAAcyNCyp7czBRhSHfermBMhNE_pgodjOfJMxXgRReUtoKvueEg@mail.gmail.com>
References: <A90A0274487D124AB11C77E82ACD449602FB4FB8@ex-mbg-04.win.duke.edu>
	<CAAcyNCwhEnJBc4AgLXDCVqfXGud2ZwWeG6fDh3nk_vd7B7QJNw@mail.gmail.com>
	<CAAcyNCyVH2Mwu0ireCdQVgp0w=0Ejgncj3c6SzbUabWdnMdm_w@mail.gmail.com>
	<CAH7sKSNHakmcZTsBjOfAuU80Dkbbeq51J3t6weRSO-bv=DTvYQ@mail.gmail.com>
	<CAAcyNCyp7czBRhSHfermBMhNE_pgodjOfJMxXgRReUtoKvueEg@mail.gmail.com>
Message-ID: <CAH7sKSOvr5uQhcU_R7o=4XCKoaX4X1Q6qG_E1aFOje2QKM-qrQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130919/c9d70ba7/attachment.pl>

From mlinchits at gmail.com  Thu Sep 19 11:06:01 2013
From: mlinchits at gmail.com (Maxim Linchits)
Date: Thu, 19 Sep 2013 13:06:01 +0400
Subject: [R] Non-ACSII characters in R on Windows
In-Reply-To: <523852BB.20308@gmail.com>
References: <CAGKs4siL8rasbtsCgEfX=haESyAD5=7BHZv1R9CqeABS560aSQ@mail.gmail.com>
	<1379320808.17743.59.camel@milan> <1379342337.26458.13.camel@milan>
	<CAGKs4shYcB=eEON0cNXK9COs5yrNe7DkSZHOPnqU+6V_gaqbLQ@mail.gmail.com>
	<1379420136.26458.30.camel@milan> <523852BB.20308@gmail.com>
Message-ID: <CAGKs4shyd+zwDfnyN0kNH2-ypkiwJ7rUvmRONS2bwVuw9=zO7g@mail.gmail.com>

Have any of the thread participants sent a bug report to R? If not,
let me know if you intend to so so. Otherwise, I'll send a report
myself.

thanks

On Tue, Sep 17, 2013 at 5:01 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 13-09-17 8:15 AM, Milan Bouchet-Valat wrote:
>>
>> Le lundi 16 septembre 2013 ? 20:04 +0400, Maxim Linchits a ?crit :
>>>
>>> Here is that old post:
>>>
>>> http://r.789695.n4.nabble.com/read-csv-and-FileEncoding-in-Windows-version-of-R-2-13-0-td3567177.html
>>>
>>> A taste: "Again, the issue is that opening this UTF-8 encoded file
>>> under R 2.13.0 yields an error, but opening it under R 2.12.2 works
>>> without any issues. (...)"
>>
>> I have tried with R 2.12.2 both 32 and 64 bit on Windows Server 2008
>> with the French (CP1252) locale, and I still experience an error with
>> the test case I provided in previous messages. So it does not sound like
>> it is the same issue.
>
>
>
> I can reproduce the error with a file sent to me by Maxim.  From a quick
> look, I suspect that changes will be needed to read.table to handle this,
> and they'll be large enough that they won't make it into 3.0.2, but
> hopefully will go into R-patched after the release.
>
> Duncan Murdoch


From bt_jannis at yahoo.de  Thu Sep 19 11:29:29 2013
From: bt_jannis at yahoo.de (Jannis)
Date: Thu, 19 Sep 2013 11:29:29 +0200
Subject: [R] v3.0.1 issue
In-Reply-To: <5F46D59F8ABDE34BB68E87EADB758CA87EE76BBBE2@CMS07.campus.gla.ac.uk>
References: <5F46D59F8ABDE34BB68E87EADB758CA87EE76BBBE2@CMS07.campus.gla.ac.uk>
Message-ID: <523AC3F9.2070009@yahoo.de>

I only guess, but this message may hint to the cause:

[Previously saved workspace restored]


R automatically starts some .RData files with images of the workspaces you used before. Try to start R with the

--no-restore

argument (R --no-restore in the command line or added to the properties of the symbol you click to start R in the Windows case).

Perhaps this solves the issue.


Jannis




On 18.09.2013 17:54, SOPHIA TSIROPOULOU wrote:
> [Previously saved workspace restored]


From szehnder at uni-bonn.de  Thu Sep 19 11:45:18 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Thu, 19 Sep 2013 11:45:18 +0200
Subject: [R] callNextMethod with dots argument
In-Reply-To: <523AA08F.3000507@jouy.inra.fr>
References: <523AA08F.3000507@jouy.inra.fr>
Message-ID: <30FF581A-EAF3-4AE1-B13B-E7BE80C6D6E0@uni-bonn.de>

Kien,

if you want to add variables in a function definition that is predefined by a Generic and calls CallNextMethod you have to add the '?' argument as well.

> setMethod("do",signature(a="Achild"),
>          function(a,msg,...)  {
>            print("do Achild")
>            callNextMethod()
>          })

Best

Simon

On Sep 19, 2013, at 8:58 AM, Ki?n Ki?u <kien.kieu at jouy.inra.fr> wrote:

> Hi,
> 
> I met a problem when invoking callNextMethod within a method associated with a generic function taking ... as an argument.
> 
> Here is the code
> 
> setClass("Aparent",representation(x="numeric",y="numeric"))
> setClass("Achild",contains="Aparent")
> 
> setGeneric("do",def=function(a,...) standardGeneric("do"))
> setMethod("do",signature(a="Aparent"),
>          function(a,msg) {
>            print("do Aparent")
>          })
> setMethod("do",signature(a="Achild"),
>          function(a,msg)  {
>            print("do Achild")
>            callNextMethod()
>          })
> 
> myA <- new("Achild")
> buf <- do(a=myA)               # works
> buf <- do(a=myA,msg="bonjour") # error
> 
> The last call yields the following error message:
> 
> Error in callNextMethod() :
>  in processing 'callNextMethod', found a '...' in the matched call, but no corresponding '...' argument
> 
> which I do not understand. Replacing "..." by "msg" in setGeneric makes it work. But I don't like this limitation so much (unless I understand it).
> 
> Regards.
> 
> Kien
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Thu Sep 19 12:45:38 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 19 Sep 2013 06:45:38 -0400
Subject: [R] Non-ACSII characters in R on Windows
In-Reply-To: <CAGKs4shyd+zwDfnyN0kNH2-ypkiwJ7rUvmRONS2bwVuw9=zO7g@mail.gmail.com>
References: <CAGKs4siL8rasbtsCgEfX=haESyAD5=7BHZv1R9CqeABS560aSQ@mail.gmail.com>
	<1379320808.17743.59.camel@milan> <1379342337.26458.13.camel@milan>
	<CAGKs4shYcB=eEON0cNXK9COs5yrNe7DkSZHOPnqU+6V_gaqbLQ@mail.gmail.com>
	<1379420136.26458.30.camel@milan> <523852BB.20308@gmail.com>
	<CAGKs4shyd+zwDfnyN0kNH2-ypkiwJ7rUvmRONS2bwVuw9=zO7g@mail.gmail.com>
Message-ID: <523AD5D2.6040305@gmail.com>

On 13-09-19 5:06 AM, Maxim Linchits wrote:
> Have any of the thread participants sent a bug report to R? If not,
> let me know if you intend to so so. Otherwise, I'll send a report
> myself.

There's no bug, as far as I know.  The issue is that various functions 
(by design) convert strings to the local encoding, and in the example 
you were trying, the local encoding can't represent all the characters, 
so they are shown using the hex codes, and things get messed up.

I'm currently looking into changing the design, so that there is more 
use of UTF-8 internally.  This is likely to have side effects, which 
need to be investigated carefully.

Duncan Murdoch

>
> thanks
>
> On Tue, Sep 17, 2013 at 5:01 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 13-09-17 8:15 AM, Milan Bouchet-Valat wrote:
>>>
>>> Le lundi 16 septembre 2013 ? 20:04 +0400, Maxim Linchits a ?crit :
>>>>
>>>> Here is that old post:
>>>>
>>>> http://r.789695.n4.nabble.com/read-csv-and-FileEncoding-in-Windows-version-of-R-2-13-0-td3567177.html
>>>>
>>>> A taste: "Again, the issue is that opening this UTF-8 encoded file
>>>> under R 2.13.0 yields an error, but opening it under R 2.12.2 works
>>>> without any issues. (...)"
>>>
>>> I have tried with R 2.12.2 both 32 and 64 bit on Windows Server 2008
>>> with the French (CP1252) locale, and I still experience an error with
>>> the test case I provided in previous messages. So it does not sound like
>>> it is the same issue.
>>
>>
>>
>> I can reproduce the error with a file sent to me by Maxim.  From a quick
>> look, I suspect that changes will be needed to read.table to handle this,
>> and they'll be large enough that they won't make it into 3.0.2, but
>> hopefully will go into R-patched after the release.
>>
>> Duncan Murdoch


From andrew.beckerman at gmail.com  Thu Sep 19 13:08:50 2013
From: andrew.beckerman at gmail.com (Andrew Beckerman)
Date: Thu, 19 Sep 2013 12:08:50 +0100
Subject: [R] why does system() truncates stdout output from large files?
 (SOLUTION)
In-Reply-To: <E1F8EF42529A4C1FB7A205460E99D7EA@gmail.com>
References: <E1F8EF42529A4C1FB7A205460E99D7EA@gmail.com>
Message-ID: <48D1BF7CEF024E4F8924F4B65C22539A@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130919/a2e26714/attachment.pl>

From petr.pikal at precheza.cz  Thu Sep 19 13:15:10 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 19 Sep 2013 11:15:10 +0000
Subject: [R] Replacement function using grouping variable
In-Reply-To: <CAHHZM+07ZgLxam-YXZp8uN8i1+Sd_2j1qEtEGpS-MR-CT4bOUA@mail.gmail.com>
References: <CAHHZM+07ZgLxam-YXZp8uN8i1+Sd_2j1qEtEGpS-MR-CT4bOUA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B929BB@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Alecia M Moser
> Sent: Thursday, September 19, 2013 7:01 AM
> To: r-help at r-project.org
> Subject: [R] Replacement function using grouping variable
> 
> Hello -
> 
> I am looking for a function that would allow me to replace specific
> columns in one data frame with columns in another data frame using a
> grouping variable.
> 
> df <- read.csv("data.csv", header=T)
> df1 <- aggregate(df[, c(8,9,10,11,12,27,28)], by=list(df$ID),
> FUN=function(x) sub("(.*):", "\\1.", x))
> 
> How do I replace columns (8,9,10,11,12,27,28) in df with those from df1
> using the ID column?

Maybe ?merge.

Petr

> 
> Thank you,
> 
> Alecia
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Thu Sep 19 13:17:28 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 19 Sep 2013 11:17:28 +0000
Subject: [R] v3.0.1 issue
In-Reply-To: <523AC3F9.2070009@yahoo.de>
References: <5F46D59F8ABDE34BB68E87EADB758CA87EE76BBBE2@CMS07.campus.gla.ac.uk>
	<523AC3F9.2070009@yahoo.de>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B929C9@SRVEXCHMBX.precheza.cz>

Hi

or install missing packages to new R version before starting R with workspace.

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Jannis
> Sent: Thursday, September 19, 2013 11:29 AM
> To: r-help at r-project.org
> Cc: s.tsiropoulou.1 at research.gla.ac.uk
> Subject: Re: [R] v3.0.1 issue
> 
> I only guess, but this message may hint to the cause:
> 
> [Previously saved workspace restored]
> 
> 
> R automatically starts some .RData files with images of the workspaces
> you used before. Try to start R with the
> 
> --no-restore
> 
> argument (R --no-restore in the command line or added to the properties
> of the symbol you click to start R in the Windows case).
> 
> Perhaps this solves the issue.
> 
> 
> Jannis
> 
> 
> 
> 
> On 18.09.2013 17:54, SOPHIA TSIROPOULOU wrote:
> > [Previously saved workspace restored]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bbolker at gmail.com  Thu Sep 19 14:56:38 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 19 Sep 2013 12:56:38 +0000
Subject: [R] glmer vs glmmadmb
References: <BLU169-W126E9B4CB282C9DCFC5791AB6210@phx.gbl>
Message-ID: <loom.20130919T145123-753@post.gmane.org>

kenny xu <kennyxu1983 <at> hotmail.com> writes:

> 
> Dear All
>
> I have fitted the following glmm:
> 
> cmai ~ time.f * intrv.f + (1 | nhome.f/Res_Code.f)
> 
> with poisson distribution, using both glmer and glmmadmb.
> 
> But the estimation for the fixed and random effects were different, i.e.

  This is a surprising set of differences.  I'm going to suggest
you send follow-ups to r-sig-mixed-models at r-project.org, which is
specialized for mixed models

> > summary(lmer.AGGREG.cmai.out3)
> 
> Call:
> glmmadmb(formula = cmai ~ time.f * intrv.f + (1 | nhome.f/Res_Code.f), 
>     data = beam.AGGREG.cmai.long, family = "poisson", link = "log", 
>     zeroInflation = F, admb.opts = admbControl(impSamp = 0, run = F), 
>     save.dir = "tmp")

   Is there a particular reason you're using 'run=FALSE'?  This specification
will tell glmmADMB not to run the model, but to collect the results of
a previous run from the working directory -- not necessarily wrong,
but very easy to make a mistake this way and pick up the results
from a model run with a *different* specification (which might???
be what happened here)  (Also, just as a matter of practice, it's
strongly advised to use FALSE instead of F, just in case someone
decided to assign a value to 'F' ...)

> AIC: 1032.2 
> 
> Coefficients:
>                  Estimate Std. Error z value Pr(>|z|)
> (Intercept)         0.542      3.105    0.17     0.86
> time.f2             0.104      5.177    0.02     0.98
> time.f3            -0.526      3.230   -0.16     0.87
> intrv.f1            0.929      2.712    0.34     0.73
> time.f2:intrv.f1   -0.416      5.302   -0.08     0.94
> time.f3:intrv.f1    0.177      3.261    0.05     0.96
> 
> Number of observations: total=1032, nhome.f=35, nhome.f:Res_Code.f=344 
> Random effect variance(s):
> Group=nhome.f
>             Variance StdDev
> (Intercept)   0.7118 0.8437
> Group=nhome.f:Res_Code.f
>             Variance StdDev
> (Intercept)    1.454  1.206
> Log-likelihood: -508.108 
> 
> > summary(lmer.AGGREG.cmai.out2)
> Generalized linear mixed model fit by the Laplace approximation 
> Formula: cmai ~ time.f * intrv.f + (1 | nhome.f/Res_Code.f) 
>    Data: beam.AGGREG.cmai.long 
>   AIC  BIC logLik deviance
>  1835 1874 -909.5     1819
> Random effects:
>  Groups             Name        Variance Std.Dev.
>  Res_Code.f:nhome.f (Intercept) 0.040125 0.20031 
>  nhome.f            (Intercept) 0.033702 0.18358 
> Number of obs: 1032, groups: Res_Code.f:nhome.f, 344; nhome.f, 35
> 
> Fixed effects:
>                  Estimate Std. Error z value Pr(>|z|)    
> (Intercept)       3.62040    0.04749   76.23   <2e-16 ***
> time.f2          -0.01964    0.01706   -1.15   0.2496    
> time.f3           0.01643    0.01691    0.97   0.3310    
> intrv.f1          0.07540    0.06819    1.11   0.2689    
> time.f2:intrv.f1  0.02148    0.02395    0.90   0.3698    
> time.f3:intrv.f1 -0.04835    0.02394   -2.02   0.0435 *  

  Otherwise I'm stumped.  The numbers of observations etc. etc.
seem consistent. It's hard to compare AIC/log-likelihood between
glmmADMB and glmer because (at present) they use different
additive offsets ...

   You could send me the data if it's not too sensitive.

  Ben Bolker


From friendly at yorku.ca  Thu Sep 19 15:19:01 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 19 Sep 2013 09:19:01 -0400
Subject: [R] ggplot: stat_smooth(method='glm',
	...) - plot linear predictor?
In-Reply-To: <CADv2QyGOKhFkJaAcUPJrZ+YtFZtxwZE3h0Esx+QsMuzhFegGEg@mail.gmail.com>
References: <523A07C2.3080509@yorku.ca>
	<CADv2QyGOKhFkJaAcUPJrZ+YtFZtxwZE3h0Esx+QsMuzhFegGEg@mail.gmail.com>
Message-ID: <523AF9C5.4060802@yorku.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130919/2b0c2c5c/attachment.pl>

From macqueen1 at llnl.gov  Thu Sep 19 15:30:36 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 19 Sep 2013 13:30:36 +0000
Subject: [R]
 =?iso-8859-1?q?How_do_I_ensure_that_the_polygon_in_spatstat?=
 =?iso-8859-1?q?=3A=3Aowin=28poly=3D=3Cpolygon=3E=29_does_not_have_=B3nega?=
 =?iso-8859-1?q?tive_area=B2?=
In-Reply-To: <CAHAP1TDsYaWfsh+hv2MYBmLnHkzy2QJ=f3H59ySNbs6Y_TKDdw@mail.gmail.com>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521910D4448C4@PRDEXMBX-08.the-lab.llnl.gov>

I suggest taking this question to r-sig-geo, if you haven't already.
-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 9/18/13 9:07 PM, "Jeff Marcus" <jeff.n.marcus at gmail.com> wrote:

>I am a new user of the R spatstat package and am having problems creating
>a
>polygonal observation window with owin(). Code follows:
>
>library("maps")
>library ("sp")`
>library("spatstat")
>mass.map <- map("state", "massachusetts:main", fill=T) # This returns
>a data frame includding x and y components that form a polygon of
>massachusetts mainland`
>
>mass.win <- owin(poly=data.frame(x=mass.map$x, y=mass.map$y)
>
> Error in if (w.area < 0) stop(paste("Area of polygon is negative -",
>"maybe traversed in >wrong direction?")) : missing value where TRUE/FALSE
>needed
>
>I tried things like reversing the order of the polygon and got same error.
>
> mass.win <- owin(poly=data.frame(x=rev(mass.map$x), y=rev(mass.map$y)))
>
> Polygon contains duplicated vertices
>
> Polygon is self-intersecting Error in owin(poly = data.frame(x =
>rev(mass.map$x), y = rev(mass.map$y))) : Polygon data contain duplicated
>vertices and self-intersection
>
>Then I figured that maybe the polygon returned by map() is not meant to be
>fed to owin(). So I tried loading a massachusetts shape file (I am totally
>taking guesses at this point).:
>
>x <- readShapePoly("../Geog/OUTLINE25K_POLY") ## The shape file for
>MASS, loaded from MassGIS website
>mass.poly <- x <- readShapePoly("../Geog/OUTLINE25K_POLY",
>force_ring=T, delete_null_obj=T) ## I got following error whether or
>not I used force_ring
>
> mass.owin <- as(mass.poly, "owin") Checking 1006 polygons...1, Polygon 1
>contains duplicated vertices [Checking polygon with 91844 edges...] 2, 3,
>.. [etd 1:21:52] ....10 [etd 36:12] ..... [etd 23:10] ....20 [etd 16:59]
>..... [etd 13:22] ....30 [etd 11:01] ..... [etd 9:21] ....40 [etd 8:06]
>..... [etd 7:09] ....50 [etd 6:23] ..... [etd 5:46] ....60 [etd 5:15]
>...[Checking polygon with 2449 edges...] .. [etd 4:49] ....70 [etd 4:27]
>..... [etd 4:07] ....80 [etd 3:50] ..... [etd 3:36] ....90 [etd 3:22]
>.....
>[etd 3:11] ....100 [ etc.
>
>I got messages complaining about intersecting vertices, etc. and it failed
>to build the polygon.
>
>Some context on problem: I am trying to use functions in spatstat for
>spatial relative risk calculations, i.e, the spatial ratio of denstity of
>cases vs. controls. For that I need an observation window and point plot
>within that window. I could cheat and make the observation window a
>rectangle around massachusetts but that would presumably distort values
>near the coast. In any case, I'd like to learn how to do this right for
>any
>future work I do with this package. Thanks for any help you can provide.
>
>Note: I cross-posted this to STack Overflow and then realized that r-help
>is probably a better forum.
>
>
> Jeff
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Thu Sep 19 15:36:57 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 19 Sep 2013 06:36:57 -0700 (PDT)
Subject: [R] binary symmetric matrix combination
In-Reply-To: <CAEBi+_m6ZT8hWkenzp-aa3+p0wAkmD__4Y2acLWKfsv7vDmrTA@mail.gmail.com>
References: <18616451.21640.1379526255404.JavaMail.nabble@joe.nabble.com>	<CAEBi+_=-Mcm20ChYz5ivC9OK0QrNx2tEKZfuqOMQ1f4WE1KJdA@mail.gmail.com>	<1379550935.95411.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<CAEBi+_m6ZT8hWkenzp-aa3+p0wAkmD__4Y2acLWKfsv7vDmrTA@mail.gmail.com>
Message-ID: <1379597817.72417.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi Elio,
Try this:
library(stringr)
?lines1<-str_trim(gsub("\t"," ",readLines("elio.txt")))
?lst1<-lapply(split(lines1,cumsum(lines2=="")),function(x) x[x!=""])

lst2<- lapply(lst1[lapply(lst1,length)>0],function(x) as.matrix(read.table(text=x,row.names=1)))
names(lst2)<- paste0("m",seq_along(lst2))

lst2[1:2]
#$m1
?# ?? aa5 aa10 b253 b254
#aa5??? 0??? 1??? 1??? 1
#aa10?? 1??? 0??? 1??? 1
#b253?? 1??? 1??? 0??? 1
#b254?? 1??? 1??? 1??? 0
#
#$m2
?# ? aa5 aa9 b27 b29
#aa5?? 0?? 1?? 1?? 1
#aa9?? 1?? 0?? 1?? 1
#b27?? 1?? 1?? 0?? 1
#b29?? 1?? 1?? 1?? 0


A.K.

________________________________
From: Elio Shijaku <selius at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Thursday, September 19, 2013 3:27 AM
Subject: Re: binary symmetric matrix combination



Hi Arun,

Please find attached the text file. Let me know if anything else is needed. Thanks a lot for your continuous help.

Best,

Elio


From ramzi.nahhas at wright.edu  Thu Sep 19 16:48:55 2013
From: ramzi.nahhas at wright.edu (rwnahhas)
Date: Thu, 19 Sep 2013 07:48:55 -0700 (PDT)
Subject: [R] Warning in gamlss function centiles.pred
Message-ID: <1379602120018-4676513.post@n4.nabble.com>

Hello,

I am getting a warning message in GAMLSS and have not been able to figure
out what the problem is, or if
 it is something I should be concerned about.

I fit the following 4 models and find that fit2.bcpe is the one with the
lowest AIC

fit1.bcpe  = gamlss(y~pb(x),                                                             
data=DAT, family=BCPE)
fit2.bcpe  = gamlss(y~pb(x), sigma.formula=~pb(x),                              
data=DAT, family=BCPE)
fit3.bcpe  = gamlss(y~pb(x), sigma.formula=~pb(x), nu.formula=~pb(x),   
data=DAT, family=BCPE)
fit4.bcpe  = gamlss(y~pb(x), sigma.formula=~pb(x), nu.formula=~pb(x),
tau.formula=~pb(x), data=DAT, family=BCPE)
AIC(fit1.bcpe,  fit2.bcpe,  fit3.bcpe,  fit4.bcpe)
#                       df        AIC
# fit2.bcpe 23.67571 15802.37
# fit3.bcpe 24.67868 15803.90
# fit4.bcpe 25.67313 15805.56
# fit1.bcpe 20.60762 15823.97

Then I use centiles.pred() to get predictions:

centiles.pred(fit2.bcpe, type=c("centiles"), xname="x", xvalues=18,
cent=c(3,15,50,85,97))

# new prediction 
# new prediction 
#     x          C3         C15       C50         C85        C97
# 1 18 100.3498 105.4568 111.4948 117.7682 123.4695
# Warning message:
#   In predict.gamlss(obj, what = "mu", newdata = newx, type = "response", 
:
#                       There is a discrepancy  between the original and the
re-fit 
#                     used to achieve 'safe' predictions 
                    
I thought perhaps that I am getting this error because of the use of the
pb() function. In the example
 below, using x+I(x^2)+I(x^3) instead of poly(x,3) solves the problem,
although the exact same 
predictions are produced making me wonder if the warning is something I can
just ignore.

data(aids)
a       = gamlss(y~poly(x,3), family=PO, data=aids)
newaids = data.frame(x=c(45,46,47))
centiles.pred(a, type=c("centiles"), xname="x", xvalues=c(45,46,47),
cent=c(3,15,50,85,97))
#    x  C3 C15 C50 C85 C97
# 1 45 420 438 460 483 501
# 2 46 442 461 483 506 525
# 3 47 468 487 510 533 553
# Warning message:
#   In predict.gamlss(obj, what = "mu", newdata = newx, type = "response", 
:
#                       There is a discrepancy  between the original and the
re-fit 
#                     used to achieve 'safe' predictions                     
a = gamlss(y~x+I(x^2)+I(x^3), family=PO, data=aids)
centiles.pred(a, type=c("centiles"), xname="x", xvalues=c(45,46,47),
cent=c(3,15,50,85,97))
#    x  C3 C15 C50 C85 C97
# 1 45 420 438 460 483 501
# 2 46 442 461 483 506 525
# 3 47 468 487 510 533 553
# No warning, but same predictions.    
                    
So I thought perhaps the problem was the use of pb(), but I do NOT get the
warning if I make predictions
 for any of the other 3 models:
                      
centiles.pred(fit1.bcpe, type=c("centiles"), xname="x", xvalues=18,
cent=c(3,15,50,85,97), plot=T)
#     x          C3         C15       C50         C85        C97
# 1 18 100.1979 105.4092 111.4645 117.7477 123.547
centiles.pred(fit3.bcpe, type=c("centiles"), xname="x", xvalues=18,
cent=c(3,15,50,85,97), plot=T)
#     x          C3         C15       C50         C85        C97
# 1 18 100.4709 105.4202 111.3888 117.729 123.6178
centiles.pred(fit4.bcpe, type=c("centiles"), xname="x", xvalues=18,
cent=c(3,15,50,85,97), plot=T)
#     x          C3         C15       C50         C85        C97
# 1 18 100.3045 105.3596 111.2794 117.5696 123.5994

(1) If the warning is not because of pb(), then what is causing it?
(2) Can I ignore the warning? At least in the poly() example, the
predictions are the same after I fix the 
problem causing the warning. And in my data, the predictions are similar
across the 4 models.

Thanks!
  
Ramzi



--
View this message in context: http://r.789695.n4.nabble.com/Warning-in-gamlss-function-centiles-pred-tp4676513.html
Sent from the R help mailing list archive at Nabble.com.


From ramzi.nahhas at wright.edu  Thu Sep 19 16:53:36 2013
From: ramzi.nahhas at wright.edu (rwnahhas)
Date: Thu, 19 Sep 2013 07:53:36 -0700 (PDT)
Subject: [R] Polynomial of Degree 4
In-Reply-To: <1379570430058-4676481.post@n4.nabble.com>
References: <1379570430058-4676481.post@n4.nabble.com>
Message-ID: <1379602416030-4676515.post@n4.nabble.com>

Try solve.polynomial in package polynom

Ramzi



--
View this message in context: http://r.789695.n4.nabble.com/Polynomial-of-Degree-4-tp4676481p4676515.html
Sent from the R help mailing list archive at Nabble.com.


From istazahn at gmail.com  Thu Sep 19 18:29:44 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 19 Sep 2013 12:29:44 -0400
Subject: [R] ggplot: stat_smooth(method='glm',
	...) - plot linear predictor?
In-Reply-To: <523AF9C5.4060802@yorku.ca>
References: <523A07C2.3080509@yorku.ca>
	<CADv2QyGOKhFkJaAcUPJrZ+YtFZtxwZE3h0Esx+QsMuzhFegGEg@mail.gmail.com>
	<523AF9C5.4060802@yorku.ca>
Message-ID: <CA+vqiLGeaQoWNJ7NhBzKrF3L7s-sWjikX_rtvZuTNKofKh-eiw@mail.gmail.com>

You need to map obs to the y axis:

p + geom_point(aes(y=obs), position=position_jitter(height=0.02, width=0))

Best,
Ista

On Thu, Sep 19, 2013 at 9:19 AM, Michael Friendly <friendly at yorku.ca> wrote:
> Thanks for the very helpful reply. Some comments inline.
>
> On 9/18/2013 8:53 PM, Dennis Murphy wrote:
>> Hi Michael:
>>
>
>> Some questions:
>>
>> - Is it possible, and if so, how, to plot the same data and fitted smooths
>> on the logit
>> scale, i.e., the linear predictor for the binomial glm?
>> Yes, but not through stat/geom_smooth directly - the geom only
>> provides a simple default mechanism. You can create a data frame using
>> predict.glm() with the default type, set se.fit = TRUE and then use
>> geom_line() and geom_ribbon() in ggplot2. See below.
>
> Hmm.  I thought that ggplot had the facility to apply a transformation,
> and found coord_trans,
> which I think does what I want, more or less (except that geom_point
> doesn't work).
>
> logit <- function(x) log(x)/log(1-x)
>
> ggplot(Titanicp, aes(age, as.numeric(survived)-1, color=sex)) +
>    stat_smooth(method="glm", family=binomial, formula=y~x,
>                alpha=0.2, size=2, aes(fill=sex)) +
> #  geom_point(position=position_jitter(height=0.02, width=0), size=1.5) +
>    coord_trans(y="logit") + labs(x = "Age", y = "Estimated logit")
>
>> . We first need to get the predicted logits with corresponding SE
>> estimates into a data frame along with age and sex, and we should be
>> ready to go:
>    ...
>
> With this setup, I'd be happy to plot the observations on the logit
> scale jittered around
> some reasonable values, say \pm 1.5.  However my attempt to do this
> doesn't work
> and I'm not sure why.
>
> mod <- glm(survived ~ age*sex, family=binomial, data=Titanicp)
> modp <- cbind(Titanicp[, c("survived", "sex", "age")],
>                predict(mod, se.fit = TRUE))
> modp$obs <- c(-1.5, 1.5)[modp$survived]
>
> # Plot predicted logits with corresponding Wald CIs
> p <- ggplot(modp, aes(x = age, y = fit, color = sex)) +
>    geom_line(size = 2) +
>    geom_ribbon(aes(ymin = fit - 1.96 * se.fit,
>                    ymax = fit + 1.96 * se.fit,
>                    fill = sex), alpha = 0.2,
>                color = "transparent") +
>    labs(x = "Age", y = "Estimated logit")
> p + geom_point(y=modp$obs, position=position_jitter(height=0.02, width=0))
>
>
>>p + geom_point(y=modp$obs, position=position_jitter(height=0.02, width=0))
> Error: position_jitter requires the following missing aesthetics: y
>
>>p + geom_point(y=modp$obs, position=position_jitter(y=modp$obs, height=0.02, width=0))
> Error in position_jitter(y = modp$obs, height = 0.02, width = 0) :
>    unused argument (y = modp$obs)
>
>>
>> Dennis
>>
>>> i.e., glm() is quite happy to fit the model survived ~ age+sex
>>> in the binomial family, and gives the same predicted probabilities and
>>> logits.
>>>
>>> install.packages("vcdExtra")# data from the most recent version,
>>> vcdExtra_0.5-11
>>> data(Titanicp, package="vcdExtra")
>>> str(Titanicp)
>>>
>>> 'data.frame':   1309 obs. of  6 variables:
>>>   $ pclass  : Factor w/ 3 levels "1st","2nd","3rd": 1 1 1 1 1 1 1 1 1 1 ...
>>>   $ survived: Factor w/ 2 levels "died","survived": 2 2 1 1 1 2 2 1 2 1 ...
>>>   $ sex     : Factor w/ 2 levels "female","male": 1 2 1 2 1 2 1 2 1 2 ...
>>>   $ age     : num  29 0.917 2 30 25 ...
>>>   $ sibsp   : num  0 1 1 1 1 0 1 0 2 0 ...
>>>   $ parch   : num  0 2 2 2 2 0 0 0 0 0 ...
>>>
>>> require(ggplot2)
>>> # remove missings on age
>>> Titanicp <- Titanicp[!is.na(Titanicp$age),]
>>>
>>> ggplot(Titanicp, aes(age, as.numeric(survived)-1, color=sex)) +
>>>      stat_smooth(method="glm", family=binomial, formula=y~x, alpha=0.2,
>>> size=2, aes(fill=sex)) +
>>>      geom_point(position=position_jitter(height=0.02, width=0), size=1.5)
>>>
>>> # equivalent logistic regression model, survived as a factor
>>> mod <- glm(survived ~ age+sex, family=binomial, data=Titanicp)
>>> summary(mod)
>>>
>
>
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:   http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Sep 19 20:14:15 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 19 Sep 2013 11:14:15 -0700
Subject: [R] can you explain the cov2cor function
In-Reply-To: <CAH7sKSOvr5uQhcU_R7o=4XCKoaX4X1Q6qG_E1aFOje2QKM-qrQ@mail.gmail.com>
References: <A90A0274487D124AB11C77E82ACD449602FB4FB8@ex-mbg-04.win.duke.edu>
	<CAAcyNCwhEnJBc4AgLXDCVqfXGud2ZwWeG6fDh3nk_vd7B7QJNw@mail.gmail.com>
	<CAAcyNCyVH2Mwu0ireCdQVgp0w=0Ejgncj3c6SzbUabWdnMdm_w@mail.gmail.com>
	<CAH7sKSNHakmcZTsBjOfAuU80Dkbbeq51J3t6weRSO-bv=DTvYQ@mail.gmail.com>
	<CAAcyNCyp7czBRhSHfermBMhNE_pgodjOfJMxXgRReUtoKvueEg@mail.gmail.com>
	<CAH7sKSOvr5uQhcU_R7o=4XCKoaX4X1Q6qG_E1aFOje2QKM-qrQ@mail.gmail.com>
Message-ID: <8CD2F256-8245-448F-90C2-E1E3724689E4@comcast.net>


On Sep 19, 2013, at 1:48 AM, Kenn Konstabel wrote:

> On Wed, Sep 18, 2013 at 12:14 PM, Pascal Oettli <kridox at ymail.com> wrote:
> 
>> It's a function of package "sos", quite useful to find functions in R.
>> 
>> 
>> It is interesting to note that neither RSiteSearch("cov2cor") nor
> findFn("cov2cor") seem to be able to find cov2cor (from the stats package!
> so it's there on every machine that has R installed) but find lots of other
> answeres (e.g., cor2cov). It is thus perhaps too simple-minded to assume
> that when I search for foobar, and if there is a function with exactly that
> name, it would appear as the first answer.  You can find cov2cor by
> searching for "Correlation, Variance and Covariance (Matrices)" (an
> unlikely search string:).

That's not exactly true.  does find the help page on which that function is described:

http://finzi.psych.upenn.edu/R/library/stats/html/cor.html

It just doesn't list it as the name of the page. And it's buried in a welter of other potential hits:

 findFn("cov2cor")
found 74 matches;  retrieving 4 pages
2 3 4 
Downloaded 65 links in 37 packages.

-- 
David Winsemius
Alameda, CA, USA


From wolfgang.viechtbauer at maastrichtuniversity.nl  Thu Sep 19 21:11:11 2013
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Thu, 19 Sep 2013 21:11:11 +0200
Subject: [R] Dose-response relationship using metafor?
In-Reply-To: <62901AE6C429764C82AE0D998DFC8FF2140A20@RIEXMBXP1.DBRI.LOCAL>
References: <62901AE6C429764C82AE0D998DFC8FF2140A20@RIEXMBXP1.DBRI.LOCAL>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730D89447440@UM-MAIL4112.unimaas.nl>

Can you provide a minimal and self-contained example showing/illustrating what you have done and would like to test? Based on the information provided, I could only make a vague suggestion along the lines of: You could include dose in an appropriate meta-regression model and then examine whether polynomial versions of the dose variable are significant (which would suggest a non-linear relationship).

Best,
Wolfgang

--   
Wolfgang Viechtbauer, Ph.D., Statistician   
Department of Psychiatry and Psychology   
School for Mental Health and Neuroscience   
Faculty of Health, Medicine, and Life Sciences   
Maastricht University, P.O. Box 616 (VIJV1)   
6200 MD Maastricht, The Netherlands   
+31 (43) 388-4170 | http://www.wvbauer.com   


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Ross, Stephanie
> Sent: Wednesday, September 18, 2013 21:41
> To: r-help at r-project.org
> Subject: [R] Dose-response relationship using metafor?
> 
> I am currently working a meta-analysis that is exploring the effect of a
> drug on plasma lipid levels. However, I am primarily interested in
> assessing the overall dose-response relationship with mean change in
> lipids. I have used the metafor package to conduct a meta-regression but
> is there a way to determine if this relationship is linear? Something like
> a p-value for trend?
> Thanks so much!
> 
> ________________________________
> PHRI DISCLAIMER This information is directed in confidence solely to the
> person named above and may not otherwise be distributed, copied or
> disclosed. Therefore, this information should be considered strictly
> confidential. If you have received this email in error, please notify the
> sender immediately via a return email for further direction. Thank you for
> your assistance.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cryan at binghamton.edu  Thu Sep 19 21:52:16 2013
From: cryan at binghamton.edu (Christopher W. Ryan)
Date: Thu, 19 Sep 2013 15:52:16 -0400
Subject: [R] making a wider, shorter, 4-column table instead of the narrower,
 longer, 2-column table I get with tm, Hmisc, and Sweave
Message-ID: <523B55F0.1060707@binghamton.edu>

I think my question sort of straddles two mailing lists, texhax and
r-help. Response so far on texhax has been scant.

Using the tm package, I am tabulating the frequencies of words used by
respondents to several survey questions. I use Sweave and the Hmisc
latex() command to produce the output report. running R 2.15.2, MikTeX
2.9, on WinXP.

Here is some Rnw code to replicate the problem:

\documentclass{article}
\usepackage[margin=1in]{geometry}
\usepackage{Sweave}

\begin{document}

<<options, echo=FALSE, results=hide>>=
options(SweaveSyntax="SweaveSyntaxNoweb")
library(tm)
library(Hmisc)
@

<<generatedocuments, echo=FALSE>>=
tags <- sample(1:40, 110, replace=TRUE)
words <- paste("word", tags, sep="")
words2 <- paste(words, tags, sep="")
n <- length(words)
words3 <- paste(words2[1:(n/2)], words2[(n/2 + 1):n], sep=" ")
docs <- data.frame(words3)
# the data.frame part isn't really needed for
# this minimal example, but I include it to
# mimic my operational code
@

<<makecorpora, echo=FALSE, results=hid>>=
docs2 <- Corpus(DataframeSource(docs))
@

<<maketdm, echo=FALSE, results=hide>>=
docs3 <- TermDocumentMatrix(docs2)
@

<<wordfrequencies, echo=FALSE, results=hide>>=
word.freq <- rowSums(inspect(docs3))
@

<<narrowtable, results=tex, echo=FALSE>>=
latex(sort(word.freq, decreasing=TRUE), file="", caption="Frequencies of
words", label="qol" )
@

\end{document}

The output consists, of course, of a very long two-column table, with
wide swaths of empty white space on either side. I'd like to use the
page width more efficiently, by making a shorter, wider table of 4
columns (2 pairs of columns), with the rows  "flowing" from the bottom
of the left-hand pair to the top of the right-hand pair.

I know I could modify the intermediate .tex file "by hand," after
R/Sweave/HMisc generates it, splitting it at some row roughly halfway
down. But is there a way to do this programmatically in the Rnw file?
All I can think of is using two separate chunks to generate two separate
tables, one for elements 1:(length(word.freq)/2) of word.freq and one
for the remaining elements. Is there a better way?

Thanks.

--Chris
-- 
Christopher W. Ryan, MD, MS
SUNY Upstate Medical University Clinical Campus at Binghamton
425 Robinson Street, Binghamton, NY  13904
cryanatbinghamtondotedu

"Once we recognize that we do not err out of laziness, stupidity, or
evil intent, we can liberate ourselves from the impossible burden of
trying to be permanently right. We can take seriously the proposition
that we could be in error, without deeming ourselves idiotic or
unworthy." [Karen Schulz, in Being Wrong: Adventures in the Margin of Error]


From anna.zakrisson at su.se  Thu Sep 19 12:20:31 2013
From: anna.zakrisson at su.se (Anna Zakrisson Braeunlich)
Date: Thu, 19 Sep 2013 10:20:31 +0000
Subject: [R] lattice: double y - problem changing axis color after
	doubleYScale
Message-ID: <11019DCE9B47004F90B2D9C62FF15792025E9E8D@ebox-prod-srv04.win.su.se>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130919/d01f5ced/attachment.pl>

From abhinav.akash999 at gmail.com  Thu Sep 19 14:04:40 2013
From: abhinav.akash999 at gmail.com (abhinav kashyap)
Date: Thu, 19 Sep 2013 17:34:40 +0530
Subject: [R]  CRAN mirror for R in India: new one at WBUT,
 how do we get listed in the CRAN website?
Message-ID: <CAD1Vk45oXqNHihaU6WibZBXSiD+ZBtt0DD1P1UvZQCxUAug=-w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130919/7bbc76fc/attachment.pl>

From bernd_lenzner at gmx.de  Thu Sep 19 16:03:11 2013
From: bernd_lenzner at gmx.de (Bernd Lenzner)
Date: Thu, 19 Sep 2013 17:03:11 +0300
Subject: [R] SAR: nonlinear and linear mixed model comparison using mmSAR -
 package
Message-ID: <523B041F.8060506@gmx.de>

Hello,
I have a problem trying to compare model-fit between linear and 
non-linear mixed models. I am using the mmSAR-package from Guilhaumon 
(Version 1.0) to fit different models (power, exponential, lomolino, 
weibull etc.) to my data. Besides that I am as well fitting a linear 
model to the data.
My dataset looks like this:

           a        s
1  21.28038 2.944439
2  21.22179 3.091042
3  22.09917 3.526361
4  21.66947 2.197225
5  21.66702 3.713572
6  21.58499 3.044522
7  22.03311 3.465736
8  22.03289 2.397895
9  22.16306 3.610918
.
.
.

with a = area estimate and s = species richness. Both variabels are log 
- transformed to reach normality and variance homogeneity.

Now I want to compare the model fit of the linear model with the fit of 
the non-linear models by using information theory. I use corrected AIC 
values to estimate model fit but when I use the "multiSAR" function from 
the mmSAR package to genereate non-linear model fit I obtain negative 
AICc values:

 >mod.selection <- multiSAR(MODELS,DATA)

 >mod.selection$filtOptimRes

                     p1 p2                       p3                    AICc
power         1.349178e-01      9.999853e-01     0.00000000 -55.64722
expo          -1.201421e+01    4.856363e+00    0.00000000 -56.93415
negexpo     1.063781e+08    1.268287e-09      0.00000000 -55.64728
logist          3.762325e+00    3.364975e-01      6.02467719 -54.79978
ratio          -2.427444e-02     8.295920e-02      -0.01806225 -54.56568
lomolino     3.925678e+00    5.436657e+02     18.23351785 -54.79876
weibull        3.550748e+00   2.352926e-06      4.39606412 -54.81074

on the other hand I get a positive AICc value for the linear model

 >lin <- lm(log(s) ~ log(a))
 >AICc(lin)

 > 181.50


How do I interpret these results? Visually inspecting the regressions 
shows that the exponential regression line is almost identical to the 
linear one so I would expect that the AICc value should be somewhere in 
the same range.

Thanks for the help or suggestions.


From JPRIGOT at partners.org  Thu Sep 19 16:28:25 2013
From: JPRIGOT at partners.org (Prigot, Jonathan)
Date: Thu, 19 Sep 2013 14:28:25 +0000
Subject: [R] R-3.0.1 g77 errors
In-Reply-To: <8BCD42E1-642F-4473-8B19-BFCDF6A5975B@uni-bonn.de>
References: <D42D0BE74BCC6443A81E6E7F0438764B3451B325@PHSX10MB14.partners.org>
	<8BCD42E1-642F-4473-8B19-BFCDF6A5975B@uni-bonn.de>
Message-ID: <D42D0BE74BCC6443A81E6E7F0438764B3451C0B7@PHSX10MB14.partners.org>

Sadly, I am limited to the Solaris 10 system. I wish that I could use
Linux, the world uses it.
-- 
Jonathan M. Prigot <jprigot at partners.org>
Partners Healthcare Systems

On Wed, 2013-09-18 at 17:20 +0200, Simon Zehnder wrote:
> On my systems Linux Scientific and Mac OS X I use as well for the F77 the gfortran compiler and this works. You could give it a trial.
> 
> Best
> 
> Simon
> 
> On Sep 18, 2013, at 3:14 PM, "Prigot, Jonathan" <JPRIGOT at partners.org> wrote:
> 
> > I am trying to build R-3.0.1 on our SPARC Solaris 10 system, but it
> > fails part way through with g77 errors. Has anyone run into this? Any
> > suggestions? For what it's worth, R-2.15.1 is the last one to build
> > error free for us.
> > ===
> > Jon Prigot
> > 
> > R is now configured for sparc-sun-solaris2.10
> > 
> > Source directory:          .
> > Installation directory:    /usr/local
> > 
> > C compiler:                gcc -std=gnu99  -g -O2
> > Fortran 77 compiler:       g77  -g -O2
> > 
> > C++ compiler:              g++  -g -O2
> > Fortran 90/95 compiler:    gfortran 
> > Obj-C compiler:             
> > 
> > Interfaces supported:      X11, tcltk
> > External libraries:        readline, ICU
> > Additional capabilities:   PNG, JPEG, TIFF, NLS
> > Options enabled:           shared BLAS, R profiling
> > 
> > Recommended packages:      yes
> > 
> > make 
> > ...
> > 
> > g77 -fPIC  -g -O2 -ffloat-store -c dlamch.f -o dlamch.o
> > dlamch.f: In function `dlamch':
> > dlamch.f:89: warning:
> >       INTRINSIC          DIGITS, EPSILON, HUGE, MAXEXPONENT,
> >                          ^
> > Reference to unimplemented intrinsic `DIGITS' at (^) (assumed EXTERNAL)
> > dlamch.f:89: 
> >       INTRINSIC          DIGITS, EPSILON, HUGE, MAXEXPONENT,
> >                          ^
> > Invalid declaration of or reference to symbol `digits' at (^) [initially
> > seen at (^)]
> > dlamch.f:89: warning:
> >       INTRINSIC          DIGITS, EPSILON, HUGE, MAXEXPONENT,
> >                                  ^
> > Reference to unimplemented intrinsic `EPSILON' at (^) (assumed EXTERNAL)
> > 
> > -- 
> > Jonathan M. Prigot <jprigot at partners.org>
> > Partners Healthcare Systems
> > 
> > 
> > 
> > The information in this e-mail is intended only for th...{{dropped:18}}
> 
> 


The information in this e-mail is intended only for the person to whom it is
addressed. If you believe this e-mail was sent to you in error and the e-mail
contains patient information, please contact the Partners Compliance HelpLine at
http://www.partners.org/complianceline . If the e-mail was sent to you in error
but does not contain patient information, please contact the sender and properly
dispose of the e-mail.

From e.h.blokkdal at kjemi.uio.no  Thu Sep 19 18:57:51 2013
From: e.h.blokkdal at kjemi.uio.no (Espen Hagen Blokkdal)
Date: Thu, 19 Sep 2013 18:57:51 +0200
Subject: [R] Fitting some data to a two-exponential expression
Message-ID: <CAG6=0J0X0cShNhk_pt9njOAuNg78Po+xs9k=yKN1Sq3-Pq-Shg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130919/b5674974/attachment.pl>

From selius at gmail.com  Thu Sep 19 22:30:31 2013
From: selius at gmail.com (supernovartis)
Date: Thu, 19 Sep 2013 13:30:31 -0700 (PDT)
Subject: [R] binary symmetric matrix combination
In-Reply-To: <1379597817.72417.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <1378380710423-4675440.post@n4.nabble.com>
	<1379597817.72417.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <CAEBi+_kP8fSTQD3sN1vfGgeJ_tEEYamr_yCFDEvKZpQSM4AUug@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130919/e74da2f3/attachment.pl>

From meddee1000 at gmail.com  Thu Sep 19 14:39:12 2013
From: meddee1000 at gmail.com (tony toca)
Date: Thu, 19 Sep 2013 14:39:12 +0200
Subject: [R] (no subject)
Message-ID: <CA+ugAwmwXxYFMXomoZ+XM85bLfqx+XBGA7bCK1qFTBYgR4GzyQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130919/ae2c2c8e/attachment.pl>

From smartpink111 at yahoo.com  Thu Sep 19 23:18:14 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 19 Sep 2013 14:18:14 -0700 (PDT)
Subject: [R] (no subject)
In-Reply-To: <CA+ugAwmwXxYFMXomoZ+XM85bLfqx+XBGA7bCK1qFTBYgR4GzyQ@mail.gmail.com>
References: <CA+ugAwmwXxYFMXomoZ+XM85bLfqx+XBGA7bCK1qFTBYgR4GzyQ@mail.gmail.com>
Message-ID: <1379625494.17569.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
You can either use:
A<-as.matrix(rbind(M,Fert))
dimnames(A)<- list(NULL,NULL)
?A
#???? [,1] [,2] [,3]
#[1,]? 0.3? 0.0??? 0
#[2,]? 0.0? 0.5??? 0
#[3,]? 0.0? 1.0??? 5


#or
matrix(rbind(M,Fert),3,3)
A.K.

?



----- Original Message -----
From: tony toca <meddee1000 at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Thursday, September 19, 2013 8:39 AM
Subject: [R] (no subject)

Dear R sages,

I used the function rbind to combine a matrix (M) and a vector (Fert) to
get a new matrix (A). This was fine.

The issue is however, that the new matrix A has as its row names the name
of the vector Fert, even though I set teh new vector A to have
dimnames=NULL. See short code below fyi.

*Fert<-c(0,1,5)
*
*M <- matrix(0, 2, 3)
diag(M) <- c(0.3,0.5)
*
*A<- as.matrix(rbind(Fert,M),dimnames=NULL)
A*


Any insights as to how to remove the row names from the new vector would be
greatly appreciated.

Many thanks,
Tony

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Thu Sep 19 23:24:04 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 19 Sep 2013 14:24:04 -0700 (PDT)
Subject: [R] (no subject)
In-Reply-To: <1379625494.17569.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <CA+ugAwmwXxYFMXomoZ+XM85bLfqx+XBGA7bCK1qFTBYgR4GzyQ@mail.gmail.com>
	<1379625494.17569.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <1379625844.30134.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
You don't even need as.matrix() in this case:
?A<- rbind(M,Fert)
is.matrix(A)
#[1] TRUE
?dimnames(A)<- list(NULL,NULL)
A.K.



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: tony toca <meddee1000 at gmail.com>
Cc: R help <r-help at r-project.org>
Sent: Thursday, September 19, 2013 5:18 PM
Subject: Re: [R] (no subject)

Hi,
You can either use:
A<-as.matrix(rbind(M,Fert))
dimnames(A)<- list(NULL,NULL)
?A
#???? [,1] [,2] [,3]
#[1,]? 0.3? 0.0??? 0
#[2,]? 0.0? 0.5??? 0
#[3,]? 0.0? 1.0??? 5


#or
matrix(rbind(M,Fert),3,3)
A.K.

?



----- Original Message -----
From: tony toca <meddee1000 at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Thursday, September 19, 2013 8:39 AM
Subject: [R] (no subject)

Dear R sages,

I used the function rbind to combine a matrix (M) and a vector (Fert) to
get a new matrix (A). This was fine.

The issue is however, that the new matrix A has as its row names the name
of the vector Fert, even though I set teh new vector A to have
dimnames=NULL. See short code below fyi.

*Fert<-c(0,1,5)
*
*M <- matrix(0, 2, 3)
diag(M) <- c(0.3,0.5)
*
*A<- as.matrix(rbind(Fert,M),dimnames=NULL)
A*


Any insights as to how to remove the row names from the new vector would be
greatly appreciated.

Many thanks,
Tony

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From rolf.turner at xtra.co.nz  Fri Sep 20 00:01:40 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Fri, 20 Sep 2013 10:01:40 +1200
Subject: [R]
 =?windows-1252?q?How_do_I_ensure_that_the_polygon_in_spatstat?=
 =?windows-1252?q?=3A=3Aowin=28poly=3D=3Cpolygon=3E=29_does_not_have_=93ne?=
 =?windows-1252?q?gative_area=94?=
In-Reply-To: <CAHAP1TDsYaWfsh+hv2MYBmLnHkzy2QJ=f3H59ySNbs6Y_TKDdw@mail.gmail.com>
References: <CAHAP1TDsYaWfsh+hv2MYBmLnHkzy2QJ=f3H59ySNbs6Y_TKDdw@mail.gmail.com>
Message-ID: <523B7444.8080205@xtra.co.nz>


You were nearly there.  No need to muck about with the shapefile 
business which
introduces a whole lot of sub-polygons (counties or townships I guess).

The polygon for the border of Massachusetts provided in "maps" has its 
vertices
in clockwise order and its first and last vertices identical to each 
other.  You need
to (a) reverse the direction (as you have done) and (b) remove the 
duplication.
Easiest to do (b) first:

mass.df <- with(mass.map,data.frame(x=rev(x),y=rev(y)))
mass.df <- unique(mass.df)
mass.win  <- owin(poly=mass.df)
plot(mass.win) # OMMMMMMMMM!

     cheers,

     Rolf Turner

P.S.  It is inadvisable to use "T" when you mean "TRUE".  Write out 
"TRUE" in
full.  (The name "T" can be over-written, leading to dangers. E.g. "T <- 
FALSE" !!!
The name "TRUE" cannot be over-written.)

     R. T.

On 09/19/13 16:07, Jeff Marcus wrote:
> I am a new user of the R spatstat package and am having problems creating a
> polygonal observation window with owin(). Code follows:
>
> library("maps")
> library ("sp")
> library("spatstat")
> mass.map <- map("state", "massachusetts:main", fill=T) # This returns
> a data frame includding x and y components that form a polygon of
> massachusetts mainland`
>
> mass.win <- owin(poly=data.frame(x=mass.map$x, y=mass.map$y)
>
>   Error in if (w.area < 0) stop(paste("Area of polygon is negative -",
> "maybe traversed in >wrong direction?")) : missing value where TRUE/FALSE
> needed
>
> I tried things like reversing the order of the polygon and got same error.
>
>   mass.win <- owin(poly=data.frame(x=rev(mass.map$x), y=rev(mass.map$y)))
>
>   Polygon contains duplicated vertices
>
>   Polygon is self-intersecting Error in owin(poly = data.frame(x =
> rev(mass.map$x), y = rev(mass.map$y))) : Polygon data contain duplicated
> vertices and self-intersection
>
> Then I figured that maybe the polygon returned by map() is not meant to be
> fed to owin(). So I tried loading a massachusetts shape file (I am totally
> taking guesses at this point).:
>
> x <- readShapePoly("../Geog/OUTLINE25K_POLY") ## The shape file for
> MASS, loaded from MassGIS website
> mass.poly <- x <- readShapePoly("../Geog/OUTLINE25K_POLY",
> force_ring=T, delete_null_obj=T) ## I got following error whether or
> not I used force_ring
>
>   mass.owin <- as(mass.poly, "owin") Checking 1006 polygons...1, Polygon 1
> contains duplicated vertices [Checking polygon with 91844 edges...] 2, 3,
> .. [etd 1:21:52] ....10 [etd 36:12] ..... [etd 23:10] ....20 [etd 16:59]
> ..... [etd 13:22] ....30 [etd 11:01] ..... [etd 9:21] ....40 [etd 8:06]
> ..... [etd 7:09] ....50 [etd 6:23] ..... [etd 5:46] ....60 [etd 5:15]
> ...[Checking polygon with 2449 edges...] .. [etd 4:49] ....70 [etd 4:27]
> ..... [etd 4:07] ....80 [etd 3:50] ..... [etd 3:36] ....90 [etd 3:22] .....
> [etd 3:11] ....100 [ etc.
>
> I got messages complaining about intersecting vertices, etc. and it failed
> to build the polygon.
>
> Some context on problem: I am trying to use functions in spatstat for
> spatial relative risk calculations, i.e, the spatial ratio of denstity of
> cases vs. controls. For that I need an observation window and point plot
> within that window. I could cheat and make the observation window a
> rectangle around massachusetts but that would presumably distort values
> near the coast. In any case, I'd like to learn how to do this right for any
> future work I do with this package. Thanks for any help you can provide.
>
> Note: I cross-posted this to STack Overflow and then realized that r-help
> is probably a better forum.


From robert.b.lynch at gmail.com  Fri Sep 20 01:44:22 2013
From: robert.b.lynch at gmail.com (Robert Lynch)
Date: Thu, 19 Sep 2013 16:44:22 -0700
Subject: [R] ggplot legend formatting
Message-ID: <CACYeG1hnRWsgz6Yebgc5W-MEP5pfhJbgATbhVie48ZejJCuQZg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130919/c8759428/attachment.pl>

From friendly at yorku.ca  Fri Sep 20 02:51:39 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 20 Sep 2013 02:51:39 +0200
Subject: [R] ggplot: stat_smooth(method='glm',
	...) - plot linear predictor?
In-Reply-To: <CA+vqiLGeaQoWNJ7NhBzKrF3L7s-sWjikX_rtvZuTNKofKh-eiw@mail.gmail.com>
References: <523A07C2.3080509@yorku.ca>
	<CADv2QyGOKhFkJaAcUPJrZ+YtFZtxwZE3h0Esx+QsMuzhFegGEg@mail.gmail.com>
	<523AF9C5.4060802@yorku.ca>
	<CA+vqiLGeaQoWNJ7NhBzKrF3L7s-sWjikX_rtvZuTNKofKh-eiw@mail.gmail.com>
Message-ID: <523B9C1B.6040903@yorku.ca>

On 19/09/2013 6:29 PM, Ista Zahn wrote:
> You need to map obs to the y axis:
>
> p + geom_point(aes(y=obs), position=position_jitter(height=0.02, width=0))
Great. that's the magic I was missing

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From abhinavk698 at gmail.com  Thu Sep 19 23:40:17 2013
From: abhinavk698 at gmail.com (Abhinav Kashyap)
Date: Fri, 20 Sep 2013 03:10:17 +0530
Subject: [R]  CRAN mirror for R in India: new one at WBUT,
 how do we get listed in the CRAN website?
Message-ID: <CACkB_X3xqwHEd62qiNS8Wy-pZZz=9z6ASeW2YxOtspx06HYRAQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130920/65789bf7/attachment.pl>

From richardkwock at gmail.com  Thu Sep 19 23:28:12 2013
From: richardkwock at gmail.com (Richard Kwock)
Date: Thu, 19 Sep 2013 14:28:12 -0700
Subject: [R] (no subject)
In-Reply-To: <CA+ugAwmwXxYFMXomoZ+XM85bLfqx+XBGA7bCK1qFTBYgR4GzyQ@mail.gmail.com>
References: <CA+ugAwmwXxYFMXomoZ+XM85bLfqx+XBGA7bCK1qFTBYgR4GzyQ@mail.gmail.com>
Message-ID: <CAJU8Py2nSnTknCvCVXDnZWpTewPFeM5jAkJEqiB6NYqh5NFa3A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130919/2de6576c/attachment.pl>

From ivanc010 at umn.edu  Fri Sep 20 00:59:46 2013
From: ivanc010 at umn.edu (ivanc010)
Date: Thu, 19 Sep 2013 15:59:46 -0700 (PDT)
Subject: [R] Need help to find out the name of my columns and rows in a data
 file
Message-ID: <1379631585915-4676534.post@n4.nabble.com>

I've been assigned homework to analyze a file. The R package is "car". The
specific data file is "Florida."

So, I did the usual stuff:
library(car)
data(Florida)
summary(Florida)

My specific assignment is to run a t-test between GORE and BUSH. (This file
has information on the 2000 election.) 

To run my t-test, my code must be something analogues to:

t.test(case0102$Salary[case0102$Sex=="Female"],case0102$Salary[case0102$Sex=="Male"])
  
Unfortunately, for my Florida data I can't find the analogues titles of the
rows and columns (i.e. Sex and Salary).

Please help.



--
View this message in context: http://r.789695.n4.nabble.com/Need-help-to-find-out-the-name-of-my-columns-and-rows-in-a-data-file-tp4676534.html
Sent from the R help mailing list archive at Nabble.com.


From meddee1000 at gmail.com  Fri Sep 20 00:39:09 2013
From: meddee1000 at gmail.com (tony toca)
Date: Fri, 20 Sep 2013 00:39:09 +0200
Subject: [R] (no subject)
In-Reply-To: <CAJU8Py2nSnTknCvCVXDnZWpTewPFeM5jAkJEqiB6NYqh5NFa3A@mail.gmail.com>
References: <CA+ugAwmwXxYFMXomoZ+XM85bLfqx+XBGA7bCK1qFTBYgR4GzyQ@mail.gmail.com>
	<CAJU8Py2nSnTknCvCVXDnZWpTewPFeM5jAkJEqiB6NYqh5NFa3A@mail.gmail.com>
Message-ID: <CA+ugAwkciNmSZN1pO=B1brPO-0Sg40yLUEHzTVV58KEGeeOgvg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130920/2a8e9c7f/attachment.pl>

From dwinsemius at comcast.net  Fri Sep 20 06:33:42 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 19 Sep 2013 21:33:42 -0700
Subject: [R] ggplot legend formatting
In-Reply-To: <CACYeG1hnRWsgz6Yebgc5W-MEP5pfhJbgATbhVie48ZejJCuQZg@mail.gmail.com>
References: <CACYeG1hnRWsgz6Yebgc5W-MEP5pfhJbgATbhVie48ZejJCuQZg@mail.gmail.com>
Message-ID: <113253CA-FF29-43FE-AD4A-22CFF939D6DB@comcast.net>


On Sep 19, 2013, at 4:44 PM, Robert Lynch wrote:

> I am having trouble getting my legend to format correctly in ggplot2. A
> full description and pictures are in the ggplot google
> group<https://groups.google.com/forum/?hl=en#!topic/ggplot2/LSarpgmSG8k>.
> but the short description is that in guides(fill = guide_legend(nrow =
> 3),bycol = TRUE) changing the call to have byrow=TRUE does not change the
> plot.
> 

So this is just a crossposting? You are asked not to crosspost on the R mailing lists.

-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Fri Sep 20 06:38:57 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 19 Sep 2013 21:38:57 -0700
Subject: [R] Need help to find out the name of my columns and rows in a
	data file
In-Reply-To: <1379631585915-4676534.post@n4.nabble.com>
References: <1379631585915-4676534.post@n4.nabble.com>
Message-ID: <CCC1844E-0176-4C18-ADF2-841CE235B654@comcast.net>


On Sep 19, 2013, at 3:59 PM, ivanc010 wrote:

> I've been assigned homework to analyze a file. The R package is "car". The
> specific data file is "Florida."
> 
> So, I did the usual stuff:
> library(car)
> data(Florida)
> summary(Florida)
> 
> My specific assignment is to run a t-test between GORE and BUSH. (This file
> has information on the 2000 election.) 
> 
> To run my t-test, my code must be something analogues to:
> 
> t.test(case0102$Salary[case0102$Sex=="Female"],case0102$Salary[case0102$Sex=="Male"])
> 
> Unfortunately, for my Florida data I can't find the analogues titles of the
> rows and columns (i.e. Sex and Salary).

Please read the Posting Guide. Many of the participants in R-Help are academics and they are asking _their_ students not to post howmework questions here. The Posting Guide lays out the reasoning. Please read it, ... and don't expect replies.

> --
> View this message in context: http://r.789695.n4.nabble.com/Need-help-to-find-out-the-name-of-my-columns-and-rows-in-a-data-file-tp4676534.html
> Sent from the R help mailing list archive at Nabble.com.
> 

Nabble is NOT the archive for R-help.

-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Fri Sep 20 06:54:26 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 19 Sep 2013 21:54:26 -0700
Subject: [R] CRAN mirror for R in India: new one at WBUT,
	how do we get listed in the CRAN website?
In-Reply-To: <CACkB_X3xqwHEd62qiNS8Wy-pZZz=9z6ASeW2YxOtspx06HYRAQ@mail.gmail.com>
References: <CACkB_X3xqwHEd62qiNS8Wy-pZZz=9z6ASeW2YxOtspx06HYRAQ@mail.gmail.com>
Message-ID: <A99E505F-A09C-46BB-B57D-77A0ABEDE2EB@comcast.net>



From the first hit on a google search for : cran mirrors:

(Which appears to be the listing to which you aspire...)

"If you want to host a new mirror at your institution, please have a look at the CRAN Mirror HOWTO."

There is a link in the webpage.

And please post in plain text to Rhelp.

On Sep 19, 2013, at 2:40 PM, Abhinav Kashyap wrote:

> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From mohan.radhakrishnan at polarisft.com  Fri Sep 20 07:10:56 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Fri, 20 Sep 2013 10:40:56 +0530
Subject: [R] Averate memory usage trend
Message-ID: <OF44A6E87C.6B066F6A-ON65257BEC.001BE681-65257BEC.001C7380@polarisft.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130920/030f2d24/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Fri Sep 20 07:44:58 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 19 Sep 2013 22:44:58 -0700
Subject: [R] Download data
In-Reply-To: <1379540605812-4676465.post@n4.nabble.com>
References: <1369756934006-4668138.post@n4.nabble.com>
	<CAN5YmCGGosh=K7zmSH4231xzp2Zs0BcXJ8bi5Qp2WAt3uy4-AQ@mail.gmail.com>
	<1369836315.62054.YahooMailNeo@web5806.biz.mail.ne1.yahoo.com>
	<1379540605812-4676465.post@n4.nabble.com>
Message-ID: <3cbabf36-bcb2-4a13-b9ea-89a2de43cc59@email.android.com>

I am sorry to hear that you are having difficulty, but your automation task is one that requires operating-system-specific knowledge that would be off-topic for this list, and web-scraping of forms really requires knowledge of web protocols and (in this case) Java and JavaScript that are also off-topic here. There exist packages in CRAN that may be helpful in your endeavor, but likely only if you study the appropriate subject areas outside of R first so that you know what you need to accomplish in detail. My quick estimation is that the aeso web site will be unusually difficult to extract data from, so you may need to pay a consultant to help you with this and/or ask the website developers if they support an automation mechanism that you can use.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

jcrosbie <james at crosb.ie> wrote:
>Thank you for all your help. I'm still not able to figure out how
>automate
>downloads from online websites.
>
>This is a daily function to download the needed data. I would also like
>to
>be able to do this on other websites such as: 
>
>http://ets.aeso.ca/ets_web/docroot/Market/Reports/HistoricalReportsStart.html
>
>and
>
>http://www.ngx.com/?page_id=561
>
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/Download-data-tp4668138p4676465.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From indrajitsg2013 at gmail.com  Fri Sep 20 08:05:59 2013
From: indrajitsg2013 at gmail.com (Indrajit Sengupta)
Date: Fri, 20 Sep 2013 11:35:59 +0530
Subject: [R] Factored ARMA models
Message-ID: <CA+Lnj2uGJvcCbhYD867gvmdfrhMmOoMMTcdUJYVu3ZDATRNqxg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130920/655f8240/attachment.pl>

From kridox at ymail.com  Fri Sep 20 08:40:13 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Fri, 20 Sep 2013 15:40:13 +0900
Subject: [R] Factored ARMA models
In-Reply-To: <CA+Lnj2uGJvcCbhYD867gvmdfrhMmOoMMTcdUJYVu3ZDATRNqxg@mail.gmail.com>
References: <CA+Lnj2uGJvcCbhYD867gvmdfrhMmOoMMTcdUJYVu3ZDATRNqxg@mail.gmail.com>
Message-ID: <CAAcyNCywP=GcLx20zZOZuU607bgPcy8mFz1JiB8aaaUMG-ez0g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130920/c40f2f8c/attachment.pl>

From ripley at stats.ox.ac.uk  Fri Sep 20 09:08:49 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 20 Sep 2013 08:08:49 +0100
Subject: [R] R-3.0.1 g77 errors
In-Reply-To: <D42D0BE74BCC6443A81E6E7F0438764B3451C0B7@PHSX10MB14.partners.org>
References: <D42D0BE74BCC6443A81E6E7F0438764B3451B325@PHSX10MB14.partners.org>
	<8BCD42E1-642F-4473-8B19-BFCDF6A5975B@uni-bonn.de>
	<D42D0BE74BCC6443A81E6E7F0438764B3451C0B7@PHSX10MB14.partners.org>
Message-ID: <523BF481.40102@stats.ox.ac.uk>

On 19/09/2013 15:28, Prigot, Jonathan wrote:
> Sadly, I am limited to the Solaris 10 system. I wish that I could use
> Linux, the world uses it.

What does that have to do with this?

The CRAN check farm uses gfortran 4.8 on a Solaris 10 system.  g77 is 
not the native compiler there, nor is that used for most binary software.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From i.visser at uva.nl  Thu Sep 19 11:32:46 2013
From: i.visser at uva.nl (Ingmar Visser)
Date: Thu, 19 Sep 2013 11:32:46 +0200
Subject: [R] [R-pkgs] depmixS4 version 1.3-0 on CRAN
Message-ID: <CABmqZHP-kW7Yg+TsKe_z_-mVDNEcN7BmZEUPqZaArT1M64NvNg@mail.gmail.com>

Package news (see below for general description of functionality)

depmixS4 version 1.3-0 has been released on CRAN. See the NEWS file
for an overview of all changes. The most important user-visible
changes are:

1) more compact pretty-printing of parameters in print/summary of
(dep)mix objects (following lm/glm style of presenting results)

2) some speed improvements in the EM algorithm, most notable in large
data/models

3) EM has an optional argument to use the classification likelihood
instead of the usual likelihood; this can be useful as a means of
starting value generation; use with caution as results are often
unstable.

Best, happy mixing, Ingmar & Maarten



Package general information

depmixS4 is a framework for specifying and fitting dependent mixture
models, otherwise known as hidden or latent Markov models.
Optimization is done with the EM algorithm or optionally with Rdonlp2
when (general linear (in-)equality) constraints on the parameters need
to be incorporated.  Models can be fitted on (multiple) sets of
observations.  The response densities for each state may be chosen
from the GLM family, or a multinomial.  User defined response
densities are easy to add; for the latter an example is given for the
ex-gauss distribution as well as the multivariate normal distribution.

Mixture or latent class (regression) models can also be fitted; these
are the limit case in which the length of observed time series is 1
for all cases.

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From petr.pikal at precheza.cz  Fri Sep 20 09:54:30 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 20 Sep 2013 07:54:30 +0000
Subject: [R] Need help to find out the name of my columns and rows in
	a	data file
In-Reply-To: <CCC1844E-0176-4C18-ADF2-841CE235B654@comcast.net>
References: <1379631585915-4676534.post@n4.nabble.com>
	<CCC1844E-0176-4C18-ADF2-841CE235B654@comcast.net>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B92B80@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of David Winsemius
> Sent: Friday, September 20, 2013 6:39 AM
> To: ivanc010
> Cc: r-help at r-project.org
> Subject: Re: [R] Need help to find out the name of my columns and rows
> in a data file
> 
> 
> On Sep 19, 2013, at 3:59 PM, ivanc010 wrote:
> 
> > I've been assigned homework to analyze a file. The R package is
> "car".
> > The specific data file is "Florida."
> >
> > So, I did the usual stuff:
> > library(car)
> > data(Florida)
> > summary(Florida)
> >
> > My specific assignment is to run a t-test between GORE and BUSH.
> (This
> > file has information on the 2000 election.)
> >
> > To run my t-test, my code must be something analogues to:
> >
> >
> t.test(case0102$Salary[case0102$Sex=="Female"],case0102$Salary[case010
> > 2$Sex=="Male"])
> >
> > Unfortunately, for my Florida data I can't find the analogues titles
> > of the rows and columns (i.e. Sex and Salary).

Well, can not resist. I believe both are Male.

see
?str

Regards
Petr

> 
> Please read the Posting Guide. Many of the participants in R-Help are
> academics and they are asking _their_ students not to post howmework
> questions here. The Posting Guide lays out the reasoning. Please read
> it, ... and don't expect replies.
> 
> > --
> > View this message in context:
> > http://r.789695.n4.nabble.com/Need-help-to-find-out-the-name-of-my-
> col
> > umns-and-rows-in-a-data-file-tp4676534.html
> > Sent from the R help mailing list archive at Nabble.com.
> >
> 
> Nabble is NOT the archive for R-help.
> 
> --
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From szehnder at uni-bonn.de  Fri Sep 20 12:08:29 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Fri, 20 Sep 2013 12:08:29 +0200
Subject: [R] Hope u have some time for 2 more questions
In-Reply-To: <28336814.52209.1379618678883.JavaMail.nabble@joe.nabble.com>
References: <28336814.52209.1379618678883.JavaMail.nabble@joe.nabble.com>
Message-ID: <A16EFAEA-3EDD-4D43-9637-84C695FA0E9F@uni-bonn.de>

Hi,

as far as I know, there is no limitation on data size in regard to foreach. You should reserve though enough memory for your application on the cluster (via ulimit -s unlimited and ulimit -v unlimited). 

Furthermore I would check the following: 
Check if there are two versions of R on the cluster/your home directory on the frontend (LSF loads this frontend environment and uses the R version installed there). If you have two R executables (R and R64) make sure you use the 64bit version.

Run R and call memory.limit() to see what are the limits of memory in your system. 

If this is limited to sizes below your needed sizes, increase it by calling R in the LSF script with the options --max-mem-size=YourSize and if you get errors of kind " cannot allocate vector of size" you should also use --max-vsize=YourVSize. 

Then, check if there is a memory leak in your application: If you compiled R with the --enable-memory-profiling you can use Rprof to do this otherwise you must rely on profiling instruments given by the cluster environment (I think you work there as well with modules, so type in the shell 'module avail' for listing available modules). 

If you detect a memory leak or if you see, that at certain points in your algorithms some objects are not used anymore call rm(ObjectName) and gc() for garbage collection. 


To your nested loop using foreach: That is a highly delicate issue in parallel computing and for the foreach syntax I refer to the must-read http://cran.r-project.org/web/packages/foreach/vignettes/nested.pdf. 

Using nested loops should be considered carefully in regard to organizing the nesting. In C++ you have the ability to determine how many cores should work on which loop. In the foreach environment using doMC this seems to me not possible. 


And, please keep the discussion to the r-help mailing list, so others can learn from it and researchers with more experience can also leave comments. 


Best

Simon


On Sep 19, 2013, at 9:24 PM, pkount at bgc-jena.mpg.de wrote:

> Hi again,
> 
> if you have some time I would like to bother you again with 2 more questions. After your response the parallel code is working perfect but when I implement that to the real case (big matrices) I get an error for not numeric dimension and i guess that again it returns NULL or something. Are you aware if foreach loop can handle only a certain size objects? the equation that I am using includes 3 objects with 2Gb size each. 
> 
> The second question has to deal with the cores that foreach uses. Although I am asking to our cluster (LSF) to give me certain number of cpus, and also i am specifing that with
> library(doMC)
> registerDoMC(n) 
> 
> it seems from the top command that I am using all the cores. I am using 2 foreach as nest  foreach(i in 1:16){
>         foreach(j in 1:10)  etc etc..
> maybe i should do something with this kind of nest? I am not aware about that.
> 
> I am sorry for the long text , and thank you for your nice solution
> 
> _____________________________________
> Sent from http://r.789695.n4.nabble.com
> 


From bogaso.christofer at gmail.com  Fri Sep 20 12:52:37 2013
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Fri, 20 Sep 2013 16:22:37 +0530
Subject: [R] Subcripting matrix
Message-ID: <CA+dpOJ=Z9h08i0xP2o8WBvepfK7Co1rfZ_wCSPVcGd_4oPxkRQ@mail.gmail.com>

Hello again,

I have one question on subscripting matrix. Let say I have following matrix:

> Mat <- matrix(1:9, 3)
> colnames(Mat) <- c("a", "b", "a")
> Mat
     a b a
[1,] 1 4 7
[2,] 2 5 8
[3,] 3 6 9


Now I want to fetch data for colnames 'a'.I did following:

> Mat[, "a"]
[1] 1 2 3


However it is not taking second 'a' colume. Basically I expected to
get 1st and 3rd columns

Can somebody tell me how to achieve that?

Thanks and regards,


From bhh at xs4all.nl  Fri Sep 20 13:12:43 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 20 Sep 2013 13:12:43 +0200
Subject: [R] Subcripting matrix
In-Reply-To: <CA+dpOJ=Z9h08i0xP2o8WBvepfK7Co1rfZ_wCSPVcGd_4oPxkRQ@mail.gmail.com>
References: <CA+dpOJ=Z9h08i0xP2o8WBvepfK7Co1rfZ_wCSPVcGd_4oPxkRQ@mail.gmail.com>
Message-ID: <BF6801D5-BD37-4D40-8ACA-13702906BD12@xs4all.nl>


On 20-09-2013, at 12:52, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:

> Hello again,
> 
> I have one question on subscripting matrix. Let say I have following matrix:
> 
>> Mat <- matrix(1:9, 3)
>> colnames(Mat) <- c("a", "b", "a")
>> Mat
>     a b a
> [1,] 1 4 7
> [2,] 2 5 8
> [3,] 3 6 9
> 
> 
> Now I want to fetch data for colnames 'a'.I did following:
> 
>> Mat[, "a"]
> [1] 1 2 3
> 
> 
> However it is not taking second 'a' colume. Basically I expected to
> get 1st and 3rd columns
> 
> Can somebody tell me how to achieve that?
> 

I think this is just silly.

How about

Mat[,which(colnames(Mat)=="a")]

Berend


From olivier.crouzet at univ-nantes.fr  Fri Sep 20 13:19:07 2013
From: olivier.crouzet at univ-nantes.fr (Olivier Crouzet)
Date: Fri, 20 Sep 2013 13:19:07 +0200
Subject: [R] Subcripting matrix
In-Reply-To: <CA+dpOJ=Z9h08i0xP2o8WBvepfK7Co1rfZ_wCSPVcGd_4oPxkRQ@mail.gmail.com>
References: <CA+dpOJ=Z9h08i0xP2o8WBvepfK7Co1rfZ_wCSPVcGd_4oPxkRQ@mail.gmail.com>
Message-ID: <20130920131907.30aaab18471b0e676a427ca0@univ-nantes.fr>

Hi,

it seems the following works as needed...

Mat[,colnames(Mat)=="a"]

Olivier.

On Fri, 20 Sep 2013 16:22:37 +0530
Christofer Bogaso <bogaso.christofer at gmail.com> wrote:

> Hello again,
> 
> I have one question on subscripting matrix. Let say I have following
> matrix:
> 
> > Mat <- matrix(1:9, 3)
> > colnames(Mat) <- c("a", "b", "a")
> > Mat
>      a b a
> [1,] 1 4 7
> [2,] 2 5 8
> [3,] 3 6 9
> 
> 
> Now I want to fetch data for colnames 'a'.I did following:
> 
> > Mat[, "a"]
> [1] 1 2 3
> 
> 
> However it is not taking second 'a' colume. Basically I expected to
> get 1st and 3rd columns
> 
> Can somebody tell me how to achieve that?
> 
> Thanks and regards,
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.


-- 
  Olivier Crouzet, PhD
  Laboratoire de Linguistique -- EA3827
  Universit? de Nantes
  Chemin de la Censive du Tertre - BP 81227
  44312 Nantes cedex 3
  France

     phone:        (+33) 02 40 14 14 05 (lab.)
                   (+33) 02 40 14 14 36 (office)
     fax:          (+33) 02 40 14 13 27
     e-mail:       olivier.crouzet at univ-nantes.fr
 		
  http://www.lling.univ-nantes.fr/


From indrajitsg2013 at gmail.com  Fri Sep 20 14:07:40 2013
From: indrajitsg2013 at gmail.com (Indrajit Sengupta)
Date: Fri, 20 Sep 2013 17:37:40 +0530
Subject: [R] Factored ARMA models
In-Reply-To: <CAAcyNCywP=GcLx20zZOZuU607bgPcy8mFz1JiB8aaaUMG-ez0g@mail.gmail.com>
References: <CA+Lnj2uGJvcCbhYD867gvmdfrhMmOoMMTcdUJYVu3ZDATRNqxg@mail.gmail.com>
	<CAAcyNCywP=GcLx20zZOZuU607bgPcy8mFz1JiB8aaaUMG-ez0g@mail.gmail.com>
Message-ID: <CA+Lnj2szoPkWmMk+PqCK6M-tOsqAxHjcrwwo2ekr7DpfOvgFvA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130920/eb5b2f49/attachment.pl>

From smartpink111 at yahoo.com  Fri Sep 20 14:59:03 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 20 Sep 2013 05:59:03 -0700 (PDT)
Subject: [R] binary symmetric matrix combination
In-Reply-To: <CAEBi+_kypgvfiF35jHVoJL40c-A9hRRReRuxU+cqubL0Y_UMqw@mail.gmail.com>
References: <18616451.21640.1379526255404.JavaMail.nabble@joe.nabble.com>	<CAEBi+_=-Mcm20ChYz5ivC9OK0QrNx2tEKZfuqOMQ1f4WE1KJdA@mail.gmail.com>	<1379550935.95411.YahooMailNeo@web142602.mail.bf1.yahoo.com>	<CAEBi+_m6ZT8hWkenzp-aa3+p0wAkmD__4Y2acLWKfsv7vDmrTA@mail.gmail.com>	<1379597817.72417.YahooMailNeo@web142604.mail.bf1.yahoo.com>	<1379598003.66715.YahooMailNeo@web142603.mail.bf1.yahoo.com>	<1379626408.11480.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CAEBi+_kypgvfiF35jHVoJL40c-A9hRRReRuxU+cqubL0Y_UMqw@mail.gmail.com>
Message-ID: <1379681943.80793.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi Elio,
Try this:

library(stringr)

lines1<-str_trim(gsub("\t"," ",readLines("elio.txt")))
?lst1<-lapply(split(lines1,cumsum(lines1=="")),function(x) x[x!=""])

lst2<- lapply(lst1[lapply(lst1,length)>0],function(x) as.matrix(read.table(text=x,row.names=1)))
names(lst2)<- paste0("m",seq_along(lst2))
dat<- do.call(rbind,lapply(names(lst2),function(x) {x1<- lst2[[x]]; cbind(expand.grid(rep(list(colnames(x1)),2),stringsAsFactors=FALSE),value=as.vector(x1))}))
library(reshape2)
res<- dcast(dat,Var1~Var2,value.var="value",sum)
?row.names(res)<- res[,1]
?res<- as.matrix(res[,-1])
?dim(res)
#[1] 14 14


A.K.



________________________________
From: Elio Shijaku <selius at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Friday, September 20, 2013 3:38 AM
Subject: Re: binary symmetric matrix combination



Hi Arun,

Let me explain my point. With your great help, I was able to create matrices such as m1, m2, etc. My initial objective was to combine the binary matrices and I succeeded in that again with your help. The only problem I have left is that since? I have about 350 matrices to combine for a single giant symmetric binary matrix of 470x470 size and I have to repeat this 22 times (got 22 giant matrices to build), I was hoping to not have to manually input each matrix but to use your list2 command to get them all from Excel. Now the problem is how to get the elements from list2 to then apply the commands:


Out1<-
as.matrix(read.table(text="y1 g24 c1 c2 l17 h4 s2 s30 e5
l15",sep="",header=TRUE))
names1<-unique(c(colnames(m1),colnames(m2),colnames(m3),colnames(m4),colnames(m5))) 
Out3<-matrix(0,length(names1),length(names1),dimnames=list(names1,names1)) 
vecOut<-paste0(colnames(Out3)[col(Out3)],rownames(Out3)[row(Out3)])?lst1<-sapply(paste0("m",1:5),function(x)
{x1<- get(x); x2<-paste0(colnames(x1)[col(x1)],rownames(x1)[row(x1)]);
match(x2,vecOut)}) 
lst2<- list(m1,m2,m3,m4,m5) 
N<- length(lst1) 

?fn1<- function(N,Out){ 
?i=1 
?while(i<=N){ 
?Out[lst1[[i]]]<-lst2[[i]] 
?i<-i+1 
?} 
Out 
?} 
fn1(N,Out3)

Thanks a lot!!

Best,

Elio


From mohan.radhakrishnan at polarisft.com  Fri Sep 20 15:15:04 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Fri, 20 Sep 2013 18:45:04 +0530
Subject: [R] Averate memory usage trend
In-Reply-To: <OF44A6E87C.6B066F6A-ON65257BEC.001BE681-65257BEC.001C7380@polarisft.com>
References: <OF44A6E87C.6B066F6A-ON65257BEC.001BE681-65257BEC.001C7380@polarisft.com>
Message-ID: <OFBC1FC516.4781D78C-ON65257BEC.004850D4-65257BEC.0048C655@polarisft.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130920/2851712c/attachment.pl>

From smartpink111 at yahoo.com  Fri Sep 20 15:30:04 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 20 Sep 2013 06:30:04 -0700 (PDT)
Subject: [R] Averate memory usage trend
In-Reply-To: <OFBC1FC516.4781D78C-ON65257BEC.004850D4-65257BEC.0048C655@polarisft.com>
References: <OF44A6E87C.6B066F6A-ON65257BEC.001BE681-65257BEC.001C7380@polarisft.com>
	<OFBC1FC516.4781D78C-ON65257BEC.004850D4-65257BEC.0048C655@polarisft.com>
Message-ID: <1379683804.68798.YahooMailNeo@web142604.mail.bf1.yahoo.com>

library(stringr)


read.table(text=gsub("[()]","",str_trim(input[input!=""])),sep="",header=FALSE,stringsAsFactors=FALSE)
#?? V1??? V2 V3
#1 6.2 httpd 18
#2 4.0 httpd 11
#3 4.0 httpd 11
#4 3.3 httpd? 9
#5 4.2 httpd 12
#6 4.2 httpd 12
#7 4.2 httpd 12
#8 4.2 httpd 12
#9 4.2 httpd 12
A.K. 




----- Original Message -----
From: "mohan.radhakrishnan at polarisft.com" <mohan.radhakrishnan at polarisft.com>
To: r-help at r-project.org
Cc: 
Sent: Friday, September 20, 2013 9:15 AM
Subject: Re: [R] Averate memory usage trend

Replying with some code.

input<- readLines(textConnection("
? 6.2?  httpd (18)
? 4.0?  httpd (11)
? 4.0?  httpd (11)
? 3.3?  httpd (9)
? 4.2?  httpd (12)
? 4.2? ? ? ? httpd (12)
? 4.2?  httpd (12)
? 4.2?  httpd (12)
? 4.2?  httpd (12)
"))

data<-input[input!=""]

> data
[1] "? 6.2 httpd (18)"?  "? 4.0 httpd (11)"?  "? 4.0 httpd (11)"?  "? 3.3 
httpd (9)" 
[5] "? 4.2 httpd (12)"?  "? 4.2?  httpd (12)" "? 4.2 httpd (12)"?  "? 4.2 
httpd (12)" 
[9] "? 4.2 httpd (12)" 

m <- t(sapply(1:1,function(x) unlist(strsplit(data," +"))))

?  [,1] [,2]? [,3]? ? [,4]?  [,5] [,6]? [,7]? ? [,8]?  [,9] [,10] [,11] 
[,12]? [,13] [,14]
[1,] ""?  "6.2" "httpd" "(18)" ""?  "4.0" "httpd" "(11)" ""?  "4.0" 
"httpd" "(11)" ""? ? "3.3"
? ?  [,15]?  [,16] [,17] [,18] [,19]?  [,20]? [,21] [,22] [,23]?  [,24] 
[,25] [,26] [,27] 
[1,] "httpd" "(9)" ""? ? "4.2" "httpd" "(12)" ""? ? "4.2" "httpd" "(12)" 
""? ? "4.2" "httpd"
? ?  [,28]? [,29] [,30] [,31]?  [,32]? [,33] [,34] [,35]?  [,36] 
[1,] "(12)" ""? ? "4.2" "httpd" "(12)" ""? ? "4.2" "httpd" "(12)"


What I want to do is this ?

? 6.2?  httpd? ? ?  18
? 4.0?  httpd? ? ?  11
? 4.0?  httpd? ? ?  11
? 3.3?  httpd? ? ? ? 9)
? 4.2?  httpd? ? ?  12
? 4.2? ? ? ? httpd? ? ? ? 12
? 4.2?  httpd? ? ?  12
? 4.2?  httpd? ? ?  12
? 4.2?  httpd? ? ?  12


Thanks,
Mohan



From:? mohan.radhakrishnan at polarisft.com
To:? ? r-help at r-project.org
Date:?  09/20/2013 10:44 AM
Subject:? ? ? ? [R] Averate memory usage trend
Sent by:? ? ? ? r-help-bounces at r-project.org



Hi,

? ? ? ? I would like to understand how to draw a graph to find out the 
average memory used by a single httpd process given these details 
collected over a period of
several days. I code R but this is about a method to find an average 
memory utilization. I believe I have enough data.

How should I statistically calculate this ? 

The figures inside braces are the total httpd processes at that time. Will 

there be an error? margin if I have combined totals like this ?

Sample data :

? Private? ?  Shared? ?  RAM used? ? ?  Program 
? 4.0 MiB? ? 3.3 MiB? ? ? ? 7.2 MiB? ?  httpd (11)
? 3.3 MiB? ? 3.0 MiB? ? ?  6.3 MiB? ? ? httpd (9)
? 4.2 MiB? ? 3.3 MiB? ? ? 7.5 MiB? ? ?  httpd (12)


Thanks,
Mohan



This e-Mail may contain proprietary and confidential information and is 
sent for the intended recipient(s) only.? If by an addressing or 
transmission error this mail has been misdirected to you, you are 
requested to delete this mail immediately. You are also hereby notified 
that any use, any form of reproduction, dissemination, copying, 
disclosure, modification, distribution and/or publication of this e-mail 
message, contents or its attachment other than by its intended recipient/s 
is strictly prohibited.

Visit us at http://www.polarisFT.com

? ? ? ? ? ? ? ?  [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




This e-Mail may contain proprietary and confidential information and is sent for the intended recipient(s) only.? If by an addressing or transmission error this mail has been misdirected to you, you are requested to delete this mail immediately. You are also hereby notified that any use, any form of reproduction, dissemination, copying, disclosure, modification, distribution and/or publication of this e-mail message, contents or its attachment other than by its intended recipient/s is strictly prohibited.

Visit us at http://www.polarisFT.com

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From lordpreetam at gmail.com  Fri Sep 20 16:10:23 2013
From: lordpreetam at gmail.com (Preetam Pal)
Date: Fri, 20 Sep 2013 19:40:23 +0530
Subject: [R] Renaming variables
Message-ID: <CAHVFrXE4=qrZWQneDVr+NVtJ4aBmKG3szfBrGn7qP_sPSObMaQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130920/45eab846/attachment.pl>

From clint at ecy.wa.gov  Fri Sep 20 16:24:26 2013
From: clint at ecy.wa.gov (Clint Bowman)
Date: Fri, 20 Sep 2013 07:24:26 -0700 (PDT)
Subject: [R] Need help to find out the name of my columns and rows in a
 data file
In-Reply-To: <1379631585915-4676534.post@n4.nabble.com>
References: <1379631585915-4676534.post@n4.nabble.com>
Message-ID: <alpine.LRH.2.03.1309200721570.12815@ecy.wa.gov>

You are close--think "names", not "titles", as in rownames or colnames (no 
reason to completely spell out column).  Summary already gave you the 
column names, so type "?rownames" to learn more.

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Thu, 19 Sep 2013, ivanc010 wrote:

> I've been assigned homework to analyze a file. The R package is "car". The
> specific data file is "Florida."
>
> So, I did the usual stuff:
> library(car)
> data(Florida)
> summary(Florida)
>
> My specific assignment is to run a t-test between GORE and BUSH. (This file
> has information on the 2000 election.)
>
> To run my t-test, my code must be something analogues to:
>
> t.test(case0102$Salary[case0102$Sex=="Female"],case0102$Salary[case0102$Sex=="Male"])
>
> Unfortunately, for my Florida data I can't find the analogues titles of the
> rows and columns (i.e. Sex and Salary).
>
> Please help.
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Need-help-to-find-out-the-name-of-my-columns-and-rows-in-a-data-file-tp4676534.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From szehnder at uni-bonn.de  Fri Sep 20 16:28:57 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Fri, 20 Sep 2013 16:28:57 +0200
Subject: [R] Renaming variables
In-Reply-To: <CAHVFrXE4=qrZWQneDVr+NVtJ4aBmKG3szfBrGn7qP_sPSObMaQ@mail.gmail.com>
References: <CAHVFrXE4=qrZWQneDVr+NVtJ4aBmKG3szfBrGn7qP_sPSObMaQ@mail.gmail.com>
Message-ID: <F6122D14-C720-4D0E-BD12-4EFEA4FE661E@uni-bonn.de>

You haven't said yet, what object your 'data file' is. If you mean a data.frame I would use colnames(dataName) <- c("Col1Name", "col2Name", ?.)

Best
Simon

On Sep 20, 2013, at 4:10 PM, Preetam Pal <lordpreetam at gmail.com> wrote:

> Hi,
> 
> I guess this is pretty basic.
> 
> I have 25 variables in the data file (name: score), i.e. X1,X2,.....,X25.
> 
> I dont want to use score$X1, score$X2 everytime I use these variables.
> 
> Is there a way I can rename all these variables as simply X1,X2,.....X25
> without writing 25 lines of code, one line for renaming each variable (eg:
>> X1=score.X1  >X2=score.X2  and so on) ?
> 
> Thanks for your help.
> 
> Regards,
> Preetam
> 
> -- 
> Preetam Pal
> (+91)-9432212774
> M-Stat 2nd Year,                                             Room No. N-114
> Statistics Division,                                           C.V.Raman
> Hall
> Indian Statistical Institute,                                 B.H.O.S.
> Kolkata.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From thiem at sipo.gess.ethz.ch  Fri Sep 20 16:54:51 2013
From: thiem at sipo.gess.ethz.ch (Thiem  Alrik)
Date: Fri, 20 Sep 2013 14:54:51 +0000
Subject: [R] Clustering of data set documentation files in package
	description
Message-ID: <11CF903D5D22CD42AF2157C898E05EB21D9750A0@MBX22.d.ethz.ch>

Dear R help list,

I was just wondering whether there is a way to cluster the documentation files of data sets in the package documentation index file, so that common prefixes such as "dat..." are not necessary.

Best wishes,
Alrik


********************************************************
Dr. Alrik Thiem
Post-Doctoral Researcher

Department of Humanities, Social and Political Sciences
Swiss Federal Institute of Technology Zurich (ETHZ)
Building IFW, Office C 29.2
Haldeneggsteig 4
CH-8092 Zurich

+41 44 63 20937 (landline)
+41 76 52 78083 (mobile)

http://www.alrik-thiem.net
http://www.compasss.org
********************************************************

********************************************************
Dr. Alrik Thiem
Post-Doctoral Researcher

Department of Humanities, Social and Political Sciences
Swiss Federal Institute of Technology Zurich (ETHZ)
Building IFW, Office C 29.2
Haldeneggsteig 4
CH-8092 Zurich

+41 44 63 20937 (landline)
+41 76 52 78083 (mobile)

http://www.alrik-thiem.net
http://www.compasss.org


From dwinsemius at comcast.net  Fri Sep 20 17:11:39 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 20 Sep 2013 08:11:39 -0700
Subject: [R] Creating dummy vars with contrasts - why does the returned
	identity matrix contain all levels (and not n-1 levels) ?
In-Reply-To: <DUB114-DS392E0830FFA2D67F34763CCA240@phx.gbl>
References: <DUB114-DS1481B35E35DF4AC29807F6CA3B0@phx.gbl>
	<FA5360B9-73E7-41A4-B577-77212FD4F25B@comcast.net>
	<DUB114-DS28C57F8A86245D07B7D278CA3B0@phx.gbl>
	<544106D3-0042-4ACF-A5A1-0F572A4F7D5B@comcast.net>
	<DUB114-DS392E0830FFA2D67F34763CCA240@phx.gbl>
Message-ID: <255AFEA9-DE51-4984-B308-6734B4C3B616@comcast.net>


On Sep 13, 2013, at 11:21 PM, E Joffe wrote:

> Hi David,
>
> First I ordered the levels of each factor in a descending order  
> based on
> frequency.
> Then, I used the following code to generate a matrix from the  
> dataframe with
> dummy variables and  subsequently run the glmnet (coxnet)
>
> ## tranform categorical variables into binary variables with dummy for
> trainSet
> predict_matrix <- model.matrix(~ ., data=trainSet,
>                              contrasts.arg = lapply
> (trainSet[,sapply(trainSet, is.factor)], contrasts))
>
> ## remove the status/time variables from the predictor matrix (x) for
> glmnet
> predict_matrix <- subset (predict_matrix, select=c(-time,-status))
>
> ## create a glmnet cox object using lasso regularization and cross
> validation
> glmnet.cv <- cv.glmnet (predict_matrix, surv_obj, family="cox")
>
>
> I hope I did not do anything wrong .....
>
> Can't thank you enough for your advice and interest.

Thank you for outlining the process that you used. It looks "from the  
outside" as though it respects the constraints on the first two  
argument imposed by the more constrained input requirements of  
cv.glmnet. I didn't realize that subset could accept a `-`sign as an  
operator inside a c() expression, but if you are getting success then  
I guess it must.

-- 
David.



> Erel
>
>
>
> -----Original Message-----
> From: David Winsemius [mailto:dwinsemius at comcast.net]
> Sent: Friday, September 13, 2013 8:51 PM
> To: E Joffe
> Cc: r-help at r-project.org
> Subject: Re: [R] Creating dummy vars with contrasts - why does the  
> returned
> identity matrix contain all levels (and not n-1 levels) ?
>
>
> On Sep 13, 2013, at 9:33 AM, E Joffe wrote:
>
>> Thank you so much for your answer  !
>> As far as I understand, glmnet doesn't accept categorical variables
>> only binary factors - so I had to create dummy variables for all
>> categorical variables.
>
> I was rather puzzled by your question. The conventions used by  
> glmnet should
> prevent constrasts from being pre-specified. Only matrices are  
> accepted as
> data objects and one cannot assign contrast attributes to matrix  
> columns.
>
>> It worked perfectly.
>> Erel
>>
>>
>> Erel Joffe MD MSc
>> School of Biomedical Informatics
>> University of Texas - Health Science Center in Houston
>> 832.287.0829 (c)
>>
>> -----Original Message-----
>> From: David Winsemius [mailto:dwinsemius at comcast.net]
>> Sent: Friday, September 13, 2013 3:05 PM
>> To: E Joffe
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Creating dummy vars with contrasts - why does the
>> returned identity matrix contain all levels (and not n-1 levels) ?
>>
>>
>> On Sep 13, 2013, at 4:15 AM, E Joffe wrote:
>>
>>> Hello,
>>>
>>>
>>>
>>> I have a problem with creating an identity matrix for glmnet by  
>>> using
>>> the contrasts function.
>>
>> Why do you want to do this?
>>
>>> I have a factor with 4 levels.
>>>
>>> When I create dummy variables I think there should be n-1 variables
>>> (in this case 3) - so that the contrasts would be against the
>>> baseline level.
>>>
>>> This is also what is written in the help file for 'contrasts'.
>>>
>>> The problem is that the function creates a matrix with n variables
>>> (i.e. the same as the number of levels) and not n-1 (where I would
>>> have a baseline level for comparison).
>>
>> Only if you specify contrasts=FALSE does it do so and this is
>> documented in that help file.
>>>
>>>
>>>
>>> My questions are:
>>>
>>> 1.       How can I create a matrix with n-1 dummy vars ?
>>
>> See below.
>>
>>> was I supposed to
>>> define explicitly that I want contr.treatment (contrasts) ?
>>
>> No need to do so.
>>
>>>
>>> 2.       If it is not possible, how should I interpret the hazard
>>> ratios in
>>> the Cox regression I am generating (I use glmnet for variable
>>> selection and
>>> then generate a Cox regression)  - That is, if I get an HR of 3 for
>>> the
>>> variable 300mg what does it mean ? the hazard is 3 times higher of
>>> what ?
>>>
>>
>> Relative hazards are generally referenced to the "baseline hazard",
>> i.e. the hazard for a group with the omitted level for treatment
>> constrasts and the mean value for any numeric predictors.
>>
>>> Here is some code to reproduce the issue:
>>>
>>> # Create a 4 level example factor
>>>
>>> trt <- factor( sample( c("PLACEBO", "300 MG", "600 MG", "1200 MG"),
>>>
>>>                  100, replace=TRUE ) )
>>
>> # If your intent is to use constrasts different than the defaults  
>> used
>> by
>> #  regression functions, these factor contrasts need to be assigned,
>> either
>> # within the construction of the factor or after the fact.
>>
>>> contrasts(trt)
>>     300 MG 600 MG PLACEBO
>> 1200 MG      0      0       0
>> 300 MG       1      0       0
>> 600 MG       0      1       0
>> PLACEBO      0      0       1
>>
>> # the default value for the contrasts parameter is TRUE and the
>> default type is treatement
>>
>> # That did not cause any change to the 'trt'-object:
>> trt
>>
>> #To make a change you need to use the `contrasts<-` function:
>>
>> contrasts (trt) <- contrasts(trt)
>> trt
>>
>>>
>>> # Use contrasts to get the identity matrix of dummy variables to be
>>> used in
>>> glmnet
>>>
>>> trt2 <- contrasts (trt,contrasts=FALSE)
>>>
>>> Results (as you can see all levels are represented in the identity
>>> matrix):
>>>
>>>> levels (trt)
>>> [1] "1200 MG" "300 MG"  "600 MG"  "PLACEBO"
>>>
>>>
>>>> print (trt2)
>>>
>>>   1200 MG 300 MG 600 MG PLACEBO
>>>
>>> 1200 MG       1      0      0       0
>>>
>>> 300 MG        0      1      0       0
>>>
>>> 600 MG        0      0      1       0
>>>
>>> PLACEBO       0      0      0       1
>>>
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>
>> Rhelp is a plain text mailing list.
>>
>> -- 
>> David Winsemius, MD
>> Alameda, CA, USA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius, MD
> Alameda, CA, USA
>
>

David Winsemius, MD
Alameda, CA, USA


From ajmackey at gmail.com  Fri Sep 20 17:22:46 2013
From: ajmackey at gmail.com (Aaron Mackey)
Date: Fri, 20 Sep 2013 11:22:46 -0400
Subject: [R] Renaming variables
In-Reply-To: <CAHVFrXE4=qrZWQneDVr+NVtJ4aBmKG3szfBrGn7qP_sPSObMaQ@mail.gmail.com>
References: <CAHVFrXE4=qrZWQneDVr+NVtJ4aBmKG3szfBrGn7qP_sPSObMaQ@mail.gmail.com>
Message-ID: <CAErFSoh2ZPs8o6pgOAw3heTnjzmj7NUDZ80k4h0D_uz7ZtqejA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130920/ca19e560/attachment.pl>

From clint at ecy.wa.gov  Fri Sep 20 17:33:36 2013
From: clint at ecy.wa.gov (Clint Bowman)
Date: Fri, 20 Sep 2013 08:33:36 -0700 (PDT)
Subject: [R] Renaming variables
In-Reply-To: <CAErFSoh2ZPs8o6pgOAw3heTnjzmj7NUDZ80k4h0D_uz7ZtqejA@mail.gmail.com>
References: <CAHVFrXE4=qrZWQneDVr+NVtJ4aBmKG3szfBrGn7qP_sPSObMaQ@mail.gmail.com>
	<CAErFSoh2ZPs8o6pgOAw3heTnjzmj7NUDZ80k4h0D_uz7ZtqejA@mail.gmail.com>
Message-ID: <alpine.LRH.2.03.1309200832550.12815@ecy.wa.gov>

or

with(score.plot(X1, X2))

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Fri, 20 Sep 2013, Aaron Mackey wrote:

> On Fri, Sep 20, 2013 at 10:10 AM, Preetam Pal <lordpreetam at gmail.com> wrote:
>
>> I have 25 variables in the data file (name: score), i.e. X1,X2,.....,X25.
>>
>> I dont want to use score$X1, score$X2 everytime I use these variables.
>>
>
> attach(score)
>
> plot(X1, X2) # etc. etc.
>
> -Aaron
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From tmrsg11 at gmail.com  Fri Sep 20 17:52:57 2013
From: tmrsg11 at gmail.com (C W)
Date: Fri, 20 Sep 2013 11:52:57 -0400
Subject: [R] Is there a way to change x and y axis tick mark inside plot()?
Message-ID: <CAE2FW2kKc4Y4-DZPwNjFR65tEzLTcgNDA_4NdJZUGw5wywHvxA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130920/72765895/attachment.pl>

From smartpink111 at yahoo.com  Fri Sep 20 18:11:02 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 20 Sep 2013 09:11:02 -0700 (PDT)
Subject: [R] Compare two subsequent rows based on specific values of a
	string
Message-ID: <1379693462.91217.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
May be this helps:
dat1<- read.table(text="x1??? x2??? x3?? x4? 
1???? xz?? ab??? cd??? ef
2???? ab?? fz??? cd??? ef
3???? ab?? cd?? dy??? dx",sep="",header=TRUE,stringsAsFactors=FALSE)
dat1$changes_to_row_above<- sapply(seq_len(nrow(dat1)),function(i) {x1<-dat1[,i]%in% dat1[,i-1];if(any(x1)) sum(x1,na.rm=TRUE) else NA})
?dat1
#? x1 x2 x3 x4 changes_to_row_above
#1 xz ab cd ef?????????????????? NA
#2 ab fz cd ef??????????????????? 1
#3 ab cd dy dx??????????????????? 2

A.K.



Dear all, 

I would like to compare two rows and check whether something 
changed. The only thing is, it is not always the same column that needs 
to be compared. It is rather a matrix of values. The outcome would be a 
number of changes in these, for instance: "of row 2, there are 3 exactly
 same values in row 3". I will make up an example: 

? ? ? x1 ? ?x2 ? ?x3 ? x4 ? changes_to_row_above 
1 ? ? xz ? ab ? ?cd ? ?ef ? NA 
2 ? ? ab ? fz ? ?cd ? ?ef ? 1 
3 ? ? ab ? cd ? dy ? ?dx ? 2 
and so forth... 

Do you think that would be possible? Is there an easy function 
to do so? It would be great help guys, thanks a lot in advance, sorry 
for my bad data manipulation knowledge... 

Tobi


From murdoch.duncan at gmail.com  Fri Sep 20 18:17:46 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 20 Sep 2013 12:17:46 -0400
Subject: [R] Is there a way to change x and y axis tick mark inside
	plot()?
In-Reply-To: <CAE2FW2kKc4Y4-DZPwNjFR65tEzLTcgNDA_4NdJZUGw5wywHvxA@mail.gmail.com>
References: <CAE2FW2kKc4Y4-DZPwNjFR65tEzLTcgNDA_4NdJZUGw5wywHvxA@mail.gmail.com>
Message-ID: <523C752A.50806@gmail.com>

On 20/09/2013 11:52 AM, C W wrote:
> Dear R community,
> I am having trouble changing the tick marks on y-axis to every 5 units?  I
> have the following:
>
> x <- c(12, 16, 6, 23, 27, 8, 5, 19, 23, 13, 16, 8)
>
> y <- c(29, 29, 23, 34, 38, 24, 22, 34, 36, 27, 33, 27)
>
> plot(x, y, pch=19)
>
> Should I change ylim=c(0,40), and then use axis()?

Don't use ylim, use yaxt="n", then use axis().
>
> I kept on thinking I can do everything inside plot(), but there is actually
> axis(), par(), ..., and so on.
> Could someone tell me why is there so many functions outside plot().  I'm
> sure there is a reason, but I don't seem to understand why.

R is designed to be flexible.  If you create giant functions that can do 
everything, you end up with a design like SAS, which is extremely 
inflexible.  It's good at what it can do, but it's very hard to get it 
to do something the designers didn't think of.

Duncan Murdoch


From gregd at gn.apc.org  Fri Sep 20 09:50:12 2013
From: gregd at gn.apc.org (Greg Dropkin)
Date: Fri, 20 Sep 2013 08:50:12 +0100 (BST)
Subject: [R] gam and optim
In-Reply-To: <1177.109.148.204.116.1371798164.squirrel@sqmail.gn.apc.org>
References: <1177.109.148.204.116.1371798164.squirrel@sqmail.gn.apc.org>
Message-ID: <1222.10.254.253.3.1379663412.squirrel@sqmail.gn.apc.org>

hi

probably a silly mistake, but I expected gam to minimise the penalised
deviance.

thanks

greg

set.seed(1)
library(mgcv)
x<-runif(100)
lp<-exp(-2*x)*sin(8*x)
y<-rpois(100,exp(lp))
plot(x,y)
m1<-gam(y~s(x),poisson)
points(x,exp(lp),pch=16,col="green3")
points(x,fitted(m1),pch=16,cex=0.5,col="blue")
W<-diag(fitted(m1))
X<-predict(m1,type="lpmatrix")
S<-m1$smooth[[1]]$S[[1]]
S<-rbind(0,cbind(0,S))
A<-X%*%solve(t(X)%*%W%*%X+m1$sp*S)%*%t(X)%*%W
sum(diag(A))
sum(m1$edf)
fit<-fitted(m1)
b<-m1$coef
range(exp(X%*%b)-fit)
z<-y/fit-1+X%*%b
range(A%*%z-X%*%b)

dv<-function(t)
{
f<-exp(X%*%t)
-2*sum(y*log(f)-f-ifelse(y==0,0,y*log(y))+y)+t%*%S%*%t
}
dv(b)
m1$dev+b%*%S%*%b

#so far, so good


t1<-optim(rep(0,10),dv)
t1$p
b

#different

dv(t1$p)
dv(b)

#different, and dv(t1$p) is lower!

fit1<-exp(X%*%t1$p)
points(x,fit1,pch=16,cex=0.5,col="red")

# different
# gam found b which does approximate the true curve, but does not minimise
the penalised deviance, by a long shot.


From gregd at gn.apc.org  Fri Sep 20 10:44:37 2013
From: gregd at gn.apc.org (Greg Dropkin)
Date: Fri, 20 Sep 2013 09:44:37 +0100 (BST)
Subject: [R] gam and optim
In-Reply-To: <1222.86.128.146.62.1379663412.squirrel@sqmail.gn.apc.org>
References: <1177.109.148.204.116.1371798164.squirrel@sqmail.gn.apc.org>
	<1222.86.128.146.62.1379663412.squirrel@sqmail.gn.apc.org>
Message-ID: <60363.10.254.253.3.1379666677.squirrel@sqmail.gn.apc.org>

please ignore this, I see the error.

greg

> hi
>
> probably a silly mistake, but I expected gam to minimise the penalised
> deviance.
>
> thanks
>
> greg
>
> set.seed(1)
> library(mgcv)
> x<-runif(100)
> lp<-exp(-2*x)*sin(8*x)
> y<-rpois(100,exp(lp))
> plot(x,y)
> m1<-gam(y~s(x),poisson)
> points(x,exp(lp),pch=16,col="green3")
> points(x,fitted(m1),pch=16,cex=0.5,col="blue")
> W<-diag(fitted(m1))
> X<-predict(m1,type="lpmatrix")
> S<-m1$smooth[[1]]$S[[1]]
> S<-rbind(0,cbind(0,S))
> A<-X%*%solve(t(X)%*%W%*%X+m1$sp*S)%*%t(X)%*%W
> sum(diag(A))
> sum(m1$edf)
> fit<-fitted(m1)
> b<-m1$coef
> range(exp(X%*%b)-fit)
> z<-y/fit-1+X%*%b
> range(A%*%z-X%*%b)
>
> dv<-function(t)
> {
> f<-exp(X%*%t)
> -2*sum(y*log(f)-f-ifelse(y==0,0,y*log(y))+y)+t%*%S%*%t
> }
> dv(b)
> m1$dev+b%*%S%*%b
>
> #so far, so good
>
>
> t1<-optim(rep(0,10),dv)
> t1$p
> b
>
> #different
>
> dv(t1$p)
> dv(b)
>
> #different, and dv(t1$p) is lower!
>
> fit1<-exp(X%*%t1$p)
> points(x,fit1,pch=16,cex=0.5,col="red")
>
> # different
> # gam found b which does approximate the true curve, but does not minimise
> the penalised deviance, by a long shot.
>
>


From anna.zakrisson at su.se  Fri Sep 20 12:55:03 2013
From: anna.zakrisson at su.se (Anna Zakrisson Braeunlich)
Date: Fri, 20 Sep 2013 10:55:03 +0000
Subject: [R] saving as TIFF - problem with compression
Message-ID: <11019DCE9B47004F90B2D9C62FF15792025EA602@ebox-prod-srv04.win.su.se>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130920/f0ffa2a2/attachment.pl>

From hollandlucas at gmail.com  Fri Sep 20 13:37:05 2013
From: hollandlucas at gmail.com (Lucas Holland)
Date: Fri, 20 Sep 2013 13:37:05 +0200
Subject: [R] Comparing two GAMs using anova (mgcv)
Message-ID: <78FD766E-0F9F-4FF5-AB5D-4E50B86789DE@gmail.com>

Hey all,

I've fitted two GAMs to some data using mgcv. The only difference between the two models is that one includes an additional smooth term (the smooth terms are s(x), s(y) and s(log(y)), the difference being that one model contains s(y) as additional term whereas the other one only contains s(x) and s(log(y)) - x and y being my explanatory variables). 

I'm now trying to decide between those two models. There's no difference in deviance explained or R^2 and the diagnostic plots returned by gam.check() look fairly similar although the one of the fuller model looks slightly more satisfactory as far as the histogram of the residuals is concerned. 

I'm wondering whether it is appropriate to conduct an approximate F test using the anova function. I'm not 100% clear I've understood the documentation on that completely. Is it appropriate to conduct such a test if the only difference between models is the inclusion/exclusion of a smooth term? 

Conducting the test, I get the result that there's no reason to reject the null hypothesis that the simpler model (without s(y)) is correct. 

Thanks!


From miss.d.smith at gmail.com  Fri Sep 20 16:16:04 2013
From: miss.d.smith at gmail.com (Danielle Smith)
Date: Fri, 20 Sep 2013 15:16:04 +0100
Subject: [R] Best way to specify a mixed ANCOVA in R?
Message-ID: <405A1550-511E-4482-9E56-E1BF25A3CD24@gmail.com>

I initially posted this question to one of the StackExchange sites, and they suggested that I repost my problem here.

After using ezANOVA as my primary way of specifying mixed ANOVAs, I've hit a stumbling block when it come to adding a covariate to the model. I am using an ANCOVA in order to determine if there is a developmental trajectory in my data; namely, I need to be able to see the F-statistic and p-values for interactions with the covariate (see p.466 onwards here [http://www.psyc.bbk.ac.uk/research/DNL/personalpages/annaz_etal_2009.pdf] if you want an example).

Using ezANOVA, I can include covariates but the output does not show the F-statistic and p-values for interactions with the covariate - the main effect of the covariate is also not tested using this method.

My ezANOVA model is as follows:

aov.model<-ezANOVA(
data=textureView.child.outliersRemoved
, dv=.(x)
, wid=.(ID)
, within=.(Texture,View)
, between=.(TNOGroup)
, between_covariates=.(Age)
, type=3
, return_aov=TRUE    
)

Another option is to use lm or Anova, but I don't know how to specify the error terms properly for either and I'm limited because I want to use Type-III sums of squares (drop1 doesn't work in the cases where I've tried to use the aov wrapper for lm; it fails while reporting 'Error in formula.default(object, env = baseenv()) : invalid formula').

Finally, I've heard about using the nlme package to specify my ANCOVA as a mixed model instead, but I don't know where to begin here (despite spending a while reading about it).

To give a summary, I'm trying to do a 2 (between; TNOGroup) x 2 (within, Texture) x2 (within, View) mixed ANCOVA, with age as a covariate. I want to use Type-III sums of squares, and see the F-statistic and p-values for interactions with the covariate, as well as for the main effect of the covariate.

Any advice on the best way to do this would be much appreciated.

Thanks,
Danielle

From carlisle.thacker at gmail.com  Fri Sep 20 17:02:52 2013
From: carlisle.thacker at gmail.com (carlisle thacker)
Date: Fri, 20 Sep 2013 11:02:52 -0400
Subject: [R] time zones from longitude, latitude, and date
Message-ID: <CAAZ8xcmpPMErsEYGdMbmA7LqxB7HDochipqUHtjHvAYUr+mQ4Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130920/c02adb75/attachment.pl>

From michelgomez at free.fr  Fri Sep 20 17:56:58 2013
From: michelgomez at free.fr (Michel)
Date: Fri, 20 Sep 2013 17:56:58 +0200
Subject: [R] Rmpfr question
Message-ID: <!&!AAAAAAAAAAAYAAAAAAAAAD+bP9Kay49OhKgiYwFy3LDCgAAAEAAAADLTCDxVQ7NOlQPBclfnJl0BAAAAAA==@free.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130920/d6791ad2/attachment.pl>

From sha at nokc.no  Fri Sep 20 11:43:44 2013
From: sha at nokc.no (sahar_nokc)
Date: Fri, 20 Sep 2013 02:43:44 -0700 (PDT)
Subject: [R] Access of odfWeave function to variables that are defined
 inside a function
Message-ID: <1379670224075-4676562.post@n4.nabble.com>

Hi everyone!

I have now been using odfWeave() for a while in order to make some word
document reports of my data. I have encountered a problem when I try to
organize my program script into some functions. It seems that if I use the
odfWeave() within a function, then odfWeave() is not able to access the
variables that are defined inside the body of the same function that runs
odfWeave(). Here is a simple example of what I mean:

report.year <- function(){
    year=2011
    odfWeave(sourcefile,outputfile)
}

report.year()

When I run report.year(), I get the error message: object 'year' not found

However, if I define the year out of the body of the function where I run
report.year(), then I don't get such error and I can produce my report.

I am wondering if this is something expected when using odfWeave due to its
nature of being able to only access the variables on the first level, or
should I somehow give access to the variables that are defined in the higher
levels (I mean within the body of my functions)?

I would actually like to report some of the variables that can only be
defined within this function, is there any way of doing it inside the body
of my report.year() function?

I appreciate it a lot if anyone can give me some hint about what I can do in
order to correct for this.

Best regards,
Sahar 




--
View this message in context: http://r.789695.n4.nabble.com/Access-of-odfWeave-function-to-variables-that-are-defined-inside-a-function-tp4676562.html
Sent from the R help mailing list archive at Nabble.com.


From jdnewmil at dcn.davis.CA.us  Fri Sep 20 19:13:23 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 20 Sep 2013 10:13:23 -0700
Subject: [R] time zones from longitude, latitude, and date
In-Reply-To: <CAAZ8xcmpPMErsEYGdMbmA7LqxB7HDochipqUHtjHvAYUr+mQ4Q@mail.gmail.com>
References: <CAAZ8xcmpPMErsEYGdMbmA7LqxB7HDochipqUHtjHvAYUr+mQ4Q@mail.gmail.com>
Message-ID: <0bd41626-7433-4381-ba28-df5636145247@email.android.com>

If you make no further assumptions then this question is not solvable. For example we use standard time in our data collection systems even though legal time here applies daylight savings offset in the summer. In some cases I have seen data collected from sites in multiple time zones recorded in one data base with a single time zone.
Even if you do assume local legal time applies in all cases, the boundaries of the time zones have changed over time. There exist time zone maps (e.g. http://efele.net/maps/tz/world/) that you could assume apply but I am not aware of any in CRAN. Someone on r-sig-geo might be able to help.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

carlisle thacker <carlisle.thacker at gmail.com> wrote:
>I have data that provide longitude, latitude, and local date and time
>but
>no information about the corresponding time zone.  How to identify the
>time
>zone so they can be converted to a common date/time?
>
>Thanks,
>
>Carlisle
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From tmrsg11 at gmail.com  Fri Sep 20 19:37:16 2013
From: tmrsg11 at gmail.com (C W)
Date: Fri, 20 Sep 2013 13:37:16 -0400
Subject: [R] Is there a way to change x and y axis tick mark inside
	plot()?
In-Reply-To: <523C752A.50806@gmail.com>
References: <CAE2FW2kKc4Y4-DZPwNjFR65tEzLTcgNDA_4NdJZUGw5wywHvxA@mail.gmail.com>
	<523C752A.50806@gmail.com>
Message-ID: <CAE2FW2ke682s34LKpwYgggJvi1wRY=9_y53f1pmPrHPu+zzPDQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130920/6bad9006/attachment.pl>

From marc_schwartz at me.com  Fri Sep 20 19:42:50 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 20 Sep 2013 12:42:50 -0500
Subject: [R] Is there a way to change x and y axis tick mark
	inside	plot()?
In-Reply-To: <523C752A.50806@gmail.com>
References: <CAE2FW2kKc4Y4-DZPwNjFR65tEzLTcgNDA_4NdJZUGw5wywHvxA@mail.gmail.com>
	<523C752A.50806@gmail.com>
Message-ID: <3C995C71-1198-4708-8487-C4E091862DD2@me.com>


On Sep 20, 2013, at 11:17 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 20/09/2013 11:52 AM, C W wrote:
>> Dear R community,
>> I am having trouble changing the tick marks on y-axis to every 5 units?  I
>> have the following:
>> 
>> x <- c(12, 16, 6, 23, 27, 8, 5, 19, 23, 13, 16, 8)
>> 
>> y <- c(29, 29, 23, 34, 38, 24, 22, 34, 36, 27, 33, 27)
>> 
>> plot(x, y, pch=19)
>> 
>> Should I change ylim=c(0,40), and then use axis()?
> 
> Don't use ylim, use yaxt="n", then use axis().
>> 
>> I kept on thinking I can do everything inside plot(), but there is actually
>> axis(), par(), ..., and so on.
>> Could someone tell me why is there so many functions outside plot().  I'm
>> sure there is a reason, but I don't seem to understand why.
> 


> R is designed to be flexible.  If you create giant functions that can do everything, you end up with a design like SAS, which is extremely inflexible.  It's good at what it can do, but it's very hard to get it to do something the designers didn't think of.
> 
> Duncan Murdoch


Fortune candidate, with cc: to Z.

Regards,

Marc Schwartz


From michelgomez at free.fr  Fri Sep 20 18:37:46 2013
From: michelgomez at free.fr (Michel)
Date: Fri, 20 Sep 2013 18:37:46 +0200
Subject: [R] Compare two subsequent rows based on specific values of
	a	string
In-Reply-To: <1379693462.91217.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1379693462.91217.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <!&!AAAAAAAAAAAYAAAAAAAAAD+bP9Kay49OhKgiYwFy3LDCgAAAEAAAAEyThL+9PH1MmlDI0k8ioW4BAAAAAA==@free.fr>

Thanks I'm lookin for yur example

-----Message d'origine-----
De?: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] De
la part de arun
Envoy??: vendredi 20 septembre 2013 18:11
??: R help
Objet?: Re: [R] Compare two subsequent rows based on specific values of a
string

Hi,
May be this helps:
dat1<- read.table(text="x1??? x2??? x3?? x4
1???? xz?? ab??? cd??? ef
2???? ab?? fz??? cd??? ef
3???? ab?? cd?? dy??? dx",sep="",header=TRUE,stringsAsFactors=FALSE)
dat1$changes_to_row_above<- sapply(seq_len(nrow(dat1)),function(i)
{x1<-dat1[,i]%in% dat1[,i-1];if(any(x1)) sum(x1,na.rm=TRUE) else NA})
?dat1
#? x1 x2 x3 x4 changes_to_row_above
#1 xz ab cd ef?????????????????? NA
#2 ab fz cd ef??????????????????? 1
#3 ab cd dy dx??????????????????? 2

A.K.



Dear all, 

I would like to compare two rows and check whether something changed. The
only thing is, it is not always the same column that needs to be compared.
It is rather a matrix of values. The outcome would be a number of changes in
these, for instance: "of row 2, there are 3 exactly  same values in row 3".
I will make up an example: 

? ? ? x1 ? ?x2 ? ?x3 ? x4 ? changes_to_row_above
1 ? ? xz ? ab ? ?cd ? ?ef ? NA
2 ? ? ab ? fz ? ?cd ? ?ef ? 1
3 ? ? ab ? cd ? dy ? ?dx ? 2
and so forth... 

Do you think that would be possible? Is there an easy function to do so? It
would be great help guys, thanks a lot in advance, sorry for my bad data
manipulation knowledge... 

Tobi

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From giuseppe.amatulli at gmail.com  Fri Sep 20 18:52:16 2013
From: giuseppe.amatulli at gmail.com (Giuseppe Amatulli)
Date: Fri, 20 Sep 2013 12:52:16 -0400
Subject: [R] SPATIO-TEMPORAL ANALYSIS AND BIG DATA PROCESSING USING FREE AND
 OPEN SOURCE SW
Message-ID: <CAKoiDH+24duNGjFDiDZiyUGbbEnH011Emk28ciu3PmXFEpFz0g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130920/da469c8d/attachment.pl>

From dwinsemius at comcast.net  Fri Sep 20 20:18:41 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 20 Sep 2013 11:18:41 -0700
Subject: [R] time zones from longitude, latitude, and date
In-Reply-To: <CAAZ8xcmpPMErsEYGdMbmA7LqxB7HDochipqUHtjHvAYUr+mQ4Q@mail.gmail.com>
References: <CAAZ8xcmpPMErsEYGdMbmA7LqxB7HDochipqUHtjHvAYUr+mQ4Q@mail.gmail.com>
Message-ID: <26133729-5DF6-4DF3-A14A-541E0D5781EC@comcast.net>


On Sep 20, 2013, at 8:02 AM, carlisle thacker wrote:

> I have data that provide longitude, latitude, and local date and  
> time but
> no information about the corresponding time zone.  How to identify  
> the time
> zone so they can be converted to a common date/time?

Perhaps as an approximation you could divide the longitude by 360/24,  
truncate and subtract to get an estimated GMT. It really depends on  
your purposes, the encoding of "local time", need for accuracy, and  
perhaps further details regarding the data collection methods, none of  
which you have provided.

-- 

David Winsemius, MD
Alameda, CA, USA


From maitra.mbox.ignored at inbox.com  Fri Sep 20 20:50:50 2013
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Fri, 20 Sep 2013 13:50:50 -0500
Subject: [R] saving as TIFF - problem with compression
In-Reply-To: <11019DCE9B47004F90B2D9C62FF15792025EA602@ebox-prod-srv04.win.su.se>
References: <11019DCE9B47004F90B2D9C62FF15792025EA602@ebox-prod-srv04.win.su.se>
Message-ID: <20130920135050.db0dfb6fedfa304295371ba3@inbox.com>

Hi,

Are you using Linux? If so, you may use ImageMagick and try your luck
using 

convert filename.whatever.format filename.tiff 

There are lots of options in ImageMagick. (Read the manual.)

I have done this in the past, and it has worked. However, your exact
situation may be different, so sorry if this information is not
particularly helpful.

Ranjan

On Fri, 20 Sep 2013 10:55:03 +0000 Anna Zakrisson Braeunlich
<anna.zakrisson at su.se> wrote:

> Hi,
> 
> I am struggling to save my figures as TIFF files (yes, the yournal only accept TIFF and not any other format).
> I can manage to save a simple plot as TIFF at the correct dpi (I need at least 600dpi) and compression works. Only not for my own plot. Everything looks distorted. I have read Stack Overflow and tried to change the point size to 6, but with no apparent effect. Why is this and what would be the solution? The TIFF-stuff is in the end of the script.
> thank you for your time!
> 
> Ndata <- data.frame(
>   Ncellpercent = rnorm(400, mean = rep(c(14, 18, 65), each = 40),
>                sd = rep(c(1, 3, 6), each = 40)),
>   fyear = rep(c('2007', '2008'), each = 100*2),
>   Station = sample(c('B1', 'H2', 'H3', 'H4'), 400, replace = TRUE),
>   Week = sample(c('19', '21', '23', '25'), 400, replace = TRUE))
> 
> Pdata <- data.frame(
>   Ppercentcell = rnorm(400, mean = rep(c(4, 17, 22), each = 40),
>                sd = rep(c(0.1, 0.2, 0.4), each = 40)),
>   fyear = rep(c('2007', '2008'), each = 100*2),
>   Station = sample(c('B1', 'H2', 'H3', 'H4'), 400, replace = TRUE),
>   Week = sample(c('19', '21', '23', '25'), 400, replace = TRUE))
> 
> SummNdata <- ddply(Ndata, .(Week, fyear, Station), summarise,
>                    mean = mean(Ncellpercent),
>                    sd = sd(Ncellpercent))
> names(Pdata)
> SummPdata <- ddply(Pdata, .(Week, fyear, Station), summarise,
>                    mean = mean(Ppercentcell),
>                    sd = sd(Ppercentcell))
> SummPdata
> library(lattice)
> library(latticeExtra)
> library(HH)
> 
> font.settings <- list( font = 1, cex = 1.2, fontfamily = "serif")
> 
> my.theme <- list(
>   par.xlab.text = font.settings,
>   par.ylab.text = font.settings,
>   axis.text = font.settings,
>   par.sub=font.settings)
> 
> plotN <- xyplot(mean ~ Week | Station*fyear,
>                 col="black",
>                 pch=1,
>                 cex=1.1,
>                 lty=1,
>                 strip = strip.custom(bg = 'white', style=1), # why can I not use fontfamily="serif" here ???
>                 key=list(text=list(c(""),
>                                    col=c("black")),
>                          points=list(pch=1, lty=1, cex=1.5,
>                                      col=c("black")),
>                          columns=1, border=F,
>                          x = 0.02, y = 0.55, corner = c(2, 2),
>                          title="", cex.title=1.3),
>                 ylab = ("Nc"),
>                 xlab="Week",
>                 data= SummNdata,type="o",
>                 par.settings = my.theme)
> 
> 
> plotP <- xyplot(mean ~ Week | Station*fyear,
>                 col="black",
>                 pch=2,
>                 cex=1.1,
>                 lty=2,
>                 strip = strip.custom(bg = 'white', style=1),
>                 key=list(text=list(c(""),
>                                    col=c("black")),
>                          points=list(pch=1, lty=1, cex=1.5,
>                                      col=c("black")),
>                          columns=1, border=F,
>                          x = 0.2, y = 0.2, corner = c(2, 2),
>                          title="", cex.title=1.3),
>                 ylab = ("Pc"),
>                 xlab="Week",
>                 data= SummPdata,type="o",
>                 par.settings = my.theme)
> 
> tiff(file="myplot.tiff", bg="white", res=800,
>      width=13.3, height=9.45, units="cm",  pointsize="6",
>      compression = "lzw")
> doubleYScale(plotN, plotP, add.ylab2 = TRUE)
> dev.off()
> 
> 
> this works:
> tiff(file="myplot8.tiff", bg="white", res=800,
>      width=13.3, height=9.45, units="cm",  pointsize="6",
>      compression = "lzw")
> plot(1:100)
> dev.off()
> 
> Anna Zakrisson Braeunlich
> PhD student
> 
> Department of Ecology, Environment and Plant Sciences
> Stockholm University
> Svante Arrheniusv. 21A
> SE-106 91 Stockholm
> Sweden/Sverige
> 
> Lives in Berlin.
> For paper mail:
> Katzbachstr. 21
> D-10965, Berlin - Kreuzberg
> Germany/Deutschland
> 
> E-mail: anna.zakrisson at su.se
> Tel work: +49-(0)3091541281
> Mobile: +49-(0)15777374888
> LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b
> 
> ><((((_>`_. . _ `_. ._ `_. . ><((((_>`_. . _ `_. ._ `_. .><((((_>`_. . _ `_. ._ `_. .><((((_>
> 
> 	[[alternative HTML version deleted]]
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be
deleted on receipt. Please respond to the mailing list if appropriate.
For those needing to send personal or professional e-mail, please use
appropriate addresses.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From elaine.kuo.tw at gmail.com  Sat Sep 21 01:14:38 2013
From: elaine.kuo.tw at gmail.com (Elaine Kuo)
Date: Sat, 21 Sep 2013 07:14:38 +0800
Subject: [R] search species with all absence in a presence-absence matrix
Message-ID: <CAGJhoDxjY95xvk5MsGHpSxCaB-O_4xLu7YdZteMD=Suz3EkBTA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130921/ab60f75e/attachment.pl>

From jrkrideau at inbox.com  Sat Sep 21 01:40:58 2013
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 20 Sep 2013 15:40:58 -0800
Subject: [R] search species with all absence in a presence-absence matrix
In-Reply-To: <CAGJhoDxjY95xvk5MsGHpSxCaB-O_4xLu7YdZteMD=Suz3EkBTA@mail.gmail.com>
Message-ID: <42EEFD24BD7.00000E94jrkrideau@inbox.com>

Once you learn to use dput() I am sure someone will be happy to help you.

 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

John Kane
Kingston ON Canada


> -----Original Message-----
> From: elaine.kuo.tw at gmail.com
> Sent: Sat, 21 Sep 2013 07:14:38 +0800
> To: r-help at r-project.org
> Subject: [R] search species with all absence in a presence-absence matrix
> 
> Dear list
> 
> 
> 
> I have a matrix composed of islandID as rows and speciesID as columns.
> 
> IslandID: Island A, B, C?.O (15 islands in total)
> 
> SpeciesID: D0001, D0002, D0003?.D0100 (100 species in total)
> 
> 
> 
> The cell of the matrix describes presence (1) or absence (0) of the
> species
> in an island.
> 
> 
> 
> Now I would like to search the species with absence (0)
> 
> in all the islands (Island A to Island O.)
> 
> 
> 
> Please kindly advise the R code for the search purpose.
> 
> Thank you.
> 
> 
> 
> Elaine
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From jrkrideau at inbox.com  Sat Sep 21 01:59:11 2013
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 20 Sep 2013 15:59:11 -0800
Subject: [R] Renaming variables
In-Reply-To: <CAHVFrXE4=qrZWQneDVr+NVtJ4aBmKG3szfBrGn7qP_sPSObMaQ@mail.gmail.com>
Message-ID: <4317B60E81B.00000EBFjrkrideau@inbox.com>

Depending on what your doing perhaps with()  could help?
Or assuming a data.frame or matrix, score[ , 25] will give you Score$X25

If you would supply a bit more information (and code) about what you are doing we probably can help more.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: lordpreetam at gmail.com
> Sent: Fri, 20 Sep 2013 19:40:23 +0530
> To: r-help at r-project.org
> Subject: [R] Renaming variables
> 
> Hi,
> 
> I guess this is pretty basic.
> 
> I have 25 variables in the data file (name: score), i.e. X1,X2,.....,X25.
> 
> I dont want to use score$X1, score$X2 everytime I use these variables.
> 
> Is there a way I can rename all these variables as simply X1,X2,.....X25
>  without writing 25 lines of code, one line for renaming each variable
> (eg:
>  > X1=score.X1  >X2=score.X2  and so on) ?
> 
> Thanks for your help.
> 
> Regards,
> Preetam
> 
> --
> Preetam Pal
> (+91)-9432212774
> M-Stat 2nd Year,                                             Room No.
> N-114
> Statistics Division,                                           C.V.Raman
> Hall
> Indian Statistical Institute,                                 B.H.O.S.
> Kolkata.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Receive Notifications of Incoming Messages
Easily monitor multiple email accounts & access them with a click.
Visit http://www.inbox.com/notifier and check it out!


From smartpink111 at yahoo.com  Sat Sep 21 02:57:37 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 20 Sep 2013 17:57:37 -0700 (PDT)
Subject: [R] search species with all absence in a presence-absence matrix
In-Reply-To: <CAGJhoDxjY95xvk5MsGHpSxCaB-O_4xLu7YdZteMD=Suz3EkBTA@mail.gmail.com>
References: <CAGJhoDxjY95xvk5MsGHpSxCaB-O_4xLu7YdZteMD=Suz3EkBTA@mail.gmail.com>
Message-ID: <1379725057.38724.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
Try this:

?set.seed(248)
?lst1<- lapply(1:1000,function(i) matrix( sample(0:1,15*100,replace=TRUE),ncol=100,dimnames=list(paste("Island",LETTERS[1:15]),? paste0("D",sprintf("%04d",1:100)))))
?lst2<-lst1[sapply(lst1,function(x) any(colSums(x)==0))]
##The above steps are just to create some matrices with zeros in all the "islands"
mat1<-lst2[[1]]
?mat1[,colSums(mat1)==0,drop=FALSE]
#???????? D0038
#Island A???? 0
#Island B???? 0
#Island C???? 0
#Island D???? 0
#Island E???? 0
#Island F???? 0
#Island G???? 0
#Island H???? 0
#Island I???? 0
#Island J???? 0
#Island K???? 0
#Island L???? 0
#Island M???? 0
#Island N???? 0
#Island O???? 0
colnames(mat1)[colSums(mat1)==0]
#[1] "D0038"
?mat2<-lst2[[3]]
?colnames(mat2)[colSums(mat2)==0]
#[1] "D0086"

A.K.




----- Original Message -----
From: Elaine Kuo <elaine.kuo.tw at gmail.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Friday, September 20, 2013 7:14 PM
Subject: [R] search species with all absence in a presence-absence matrix

Dear list



I have a matrix composed of islandID as rows and speciesID as columns.

IslandID: Island A, B, C?.O (15 islands in total)

SpeciesID: D0001, D0002, D0003?.D0100 (100 species in total)



The cell of the matrix describes presence (1) or absence (0) of the species
in an island.



Now I would like to search the species with absence (0)

in all the islands (Island A to Island O.)



Please kindly advise the R code for the search purpose.

Thank you.



Elaine

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From caciquesamurai at gmail.com  Sat Sep 21 06:47:52 2013
From: caciquesamurai at gmail.com (Raoni Rodrigues)
Date: Sat, 21 Sep 2013 01:47:52 -0300
Subject: [R] Grouping variables by a irregular time interval
Message-ID: <CAGtwFe21S8yXSbSojrjp6RkgRg9On=5hjXF6-gK-HyUwFSff7Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130921/2208890d/attachment.pl>

From selius at gmail.com  Fri Sep 20 20:27:33 2013
From: selius at gmail.com (supernovartis)
Date: Fri, 20 Sep 2013 11:27:33 -0700 (PDT)
Subject: [R] binary symmetric matrix combination
In-Reply-To: <1379681943.80793.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <1378380710423-4675440.post@n4.nabble.com>
	<1379597817.72417.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1379681943.80793.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <CAEBi+_kuVye=536aT4wd5LGNZ7DrY2j4DHTj_tdFFu24C1wN8w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130920/15d185d8/attachment.pl>

From carlisle.thacker at gmail.com  Fri Sep 20 22:31:25 2013
From: carlisle.thacker at gmail.com (carlisle thacker)
Date: Fri, 20 Sep 2013 16:31:25 -0400
Subject: [R] time zones from longitude, latitude, and date
In-Reply-To: <26133729-5DF6-4DF3-A14A-541E0D5781EC@comcast.net>
References: <CAAZ8xcmpPMErsEYGdMbmA7LqxB7HDochipqUHtjHvAYUr+mQ4Q@mail.gmail.com>
	<26133729-5DF6-4DF3-A14A-541E0D5781EC@comcast.net>
Message-ID: <CAAZ8xc=E9uiCNXv-vGfs3uD+xHc9_a8=bF-9U85ZNe+yhVCP3A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130920/7eb59eed/attachment.pl>

From joseph8472 at yahoo.com  Sat Sep 21 01:57:20 2013
From: joseph8472 at yahoo.com (jos)
Date: Fri, 20 Sep 2013 16:57:20 -0700 (PDT)
Subject: [R] raster package: OpenStreetMap broken on Ubuntu, works on Mac
Message-ID: <1379721440.74722.YahooMailNeo@web121103.mail.ne1.yahoo.com>

Hi,
I'm a novice in R and I was trying to play with OpenStreetMap package as in a few examples on the web. And the examples worked on my Mac but on Ubuntu (12.04) they fail to work. The simplest one is:

library(OpenStreetMap)
library(rgdal)
map <- openmap(c(70,-179), c(-70,179))
plot(map)

(OpenStreetMap, rgdal, rJava etc..) packages have to be installed first.

On the Mac - it worked without any problems from the first try (shows a picture of world map). On Ubuntu, I get:

'merge' is not an exported object from 'namespace:raster'

when I execute the "openmap" function.

Now, at first I thought that the problem was in different library versions and it was quite a pain to make ubuntu install everything I wanted (rgdal being the biggest - unless one knows exactly what to look for on the internet, instructions are vague and there is a lot of outdated versions out there). But even after that, when version numbers matched on both OSes in R console, it still failed to work on Ubuntu. So the versions are:



library(rgdal)
Loading required package: sp
rgdal: version: 0.8-11, (SVN revision 479M)
Geospatial Data Abstraction Library extensions to R successfully loaded
Loaded GDAL runtime: GDAL 1.9.2, released 2012/10/08
Path to GDAL shared files: /usr/local/share/gdal
Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 480]
Path to PROJ.4 shared files: (autodetected)



Still didn't work with identical output on both machines. Then I thought that the problem must be in "raster" library, but both have the same version number:


packageVersion("raster")
[1] ?2.1.49?

but after showing all the functions in "raster" package, although both have 235 elements:


basevals <- ls(pos="package:raster")
basevals


the Mac one has "merge" listed and Ubuntu - doesn't. Also on Mac, the array begins with "%in%" and on Ubuntu with "addLayer"... so there is more than one inconsistency and "merge" is actually breaking openmap().

My questions are:
*is this a bug?
*is there a workaround (eg. can I "export" merge from raster namespace myself by copying potentially the code from Mac)?


Thanks in advance,

J


From richardkwock at gmail.com  Sat Sep 21 01:57:46 2013
From: richardkwock at gmail.com (Richard Kwock)
Date: Fri, 20 Sep 2013 16:57:46 -0700
Subject: [R] search species with all absence in a presence-absence matrix
In-Reply-To: <42EEFD24BD7.00000E94jrkrideau@inbox.com>
References: <CAGJhoDxjY95xvk5MsGHpSxCaB-O_4xLu7YdZteMD=Suz3EkBTA@mail.gmail.com>
	<42EEFD24BD7.00000E94jrkrideau@inbox.com>
Message-ID: <CAJU8Py3v8E3jT6MmTg4czcWcYfucOEaS2xbx-yzzUEs9e87eJQ@mail.gmail.com>

Hi,

I believe the function you are looking for is:

which("yourdata" == 0, arr.ind = T)

The "arr.ind" parameter in the "which" function will return you a
matrix with row, column indices for where there are 0's in your
dataset.

set.seed(6584)
data <- matrix(sample(c(0,1), 36, replace = T), nc = 6, dimnames =
list(c(paste("c",1:6, sep = "")), paste("r", 1:6, sep = "")))
data
 #  r1 r2 r3 r4 r5 r6
#c1  1  1  0  1  0  1
#c2  1  0  0  0  1  0
#c3  1  0  1  0  0  1
#c4  1  1  0  0  0  1
#c5  0  0  0  1  0  1
#c6  0  0  1  1  1  0

array_indices <- which(data == 0, arr.ind = T)
array_indices

#   row col
#c5   5   1
#c6   6   1
#c2   2   2
#c3   3   2
#c5   5   2
#c6   6   2
#c1   1   3
#c2   2   3
#c4   4   3
#c5   5   3
#c2   2   4
#c3   3   4
#c4   4   4
#c1   1   5
#c3   3   5
#c4   4   5
#c5   5   5
#c2   2   6
#c6   6   6

cbind(row = rownames(data)[array_indices[,1]], col =
colnames(data)[array_indices[,2]])

The last command will get you rownames and colnames from your dataset.

Richard

On Fri, Sep 20, 2013 at 4:40 PM, John Kane <jrkrideau at inbox.com> wrote:
> Once you learn to use dput() I am sure someone will be happy to help you.
>
>  http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>
> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: elaine.kuo.tw at gmail.com
>> Sent: Sat, 21 Sep 2013 07:14:38 +0800
>> To: r-help at r-project.org
>> Subject: [R] search species with all absence in a presence-absence matrix
>>
>> Dear list
>>
>>
>>
>> I have a matrix composed of islandID as rows and speciesID as columns.
>>
>> IslandID: Island A, B, C?.O (15 islands in total)
>>
>> SpeciesID: D0001, D0002, D0003?.D0100 (100 species in total)
>>
>>
>>
>> The cell of the matrix describes presence (1) or absence (0) of the
>> species
>> in an island.
>>
>>
>>
>> Now I would like to search the species with absence (0)
>>
>> in all the islands (Island A to Island O.)
>>
>>
>>
>> Please kindly advise the R code for the search purpose.
>>
>> Thank you.
>>
>>
>>
>> Elaine
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Sat Sep 21 08:32:50 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 21 Sep 2013 07:32:50 +0100
Subject: [R] raster package: OpenStreetMap broken on Ubuntu, works on Mac
In-Reply-To: <1379721440.74722.YahooMailNeo@web121103.mail.ne1.yahoo.com>
References: <1379721440.74722.YahooMailNeo@web121103.mail.ne1.yahoo.com>
Message-ID: <523D3D92.10702@stats.ox.ac.uk>

What did the OpenStreetMap maintainer say (see the posting guide)?
Hint: he and the raster maintainer are aware of their problem, and a 
correction is way overdue.

The issue is not Ubuntu vs Mac but the order in which packages are 
installed (and for binary packages that is when they were installed to 
be packaged).

On 21/09/2013 00:57, jos wrote:
> Hi,
> I'm a novice in R and I was trying to play with OpenStreetMap package as in a few examples on the web. And the examples worked on my Mac but on Ubuntu (12.04) they fail to work. The simplest one is:
>
> library(OpenStreetMap)
> library(rgdal)
> map <- openmap(c(70,-179), c(-70,179))
> plot(map)
>
> (OpenStreetMap, rgdal, rJava etc..) packages have to be installed first.
>
> On the Mac - it worked without any problems from the first try (shows a picture of world map). On Ubuntu, I get:
>
> 'merge' is not an exported object from 'namespace:raster'
>
> when I execute the "openmap" function.
>
> Now, at first I thought that the problem was in different library versions and it was quite a pain to make ubuntu install everything I wanted (rgdal being the biggest - unless one knows exactly what to look for on the internet, instructions are vague and there is a lot of outdated versions out there). But even after that, when version numbers matched on both OSes in R console, it still failed to work on Ubuntu. So the versions are:
>
>
>
> library(rgdal)
> Loading required package: sp
> rgdal: version: 0.8-11, (SVN revision 479M)
> Geospatial Data Abstraction Library extensions to R successfully loaded
> Loaded GDAL runtime: GDAL 1.9.2, released 2012/10/08
> Path to GDAL shared files: /usr/local/share/gdal
> Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 480]
> Path to PROJ.4 shared files: (autodetected)
>
>
>
> Still didn't work with identical output on both machines. Then I thought that the problem must be in "raster" library, but both have the same version number:
>
>
> packageVersion("raster")
> [1] ?2.1.49?
>
> but after showing all the functions in "raster" package, although both have 235 elements:
>
>
> basevals <- ls(pos="package:raster")
> basevals
>
>
> the Mac one has "merge" listed and Ubuntu - doesn't. Also on Mac, the array begins with "%in%" and on Ubuntu with "addLayer"... so there is more than one inconsistency and "merge" is actually breaking openmap().
>
> My questions are:
> *is this a bug?
> *is there a workaround (eg. can I "export" merge from raster namespace myself by copying potentially the code from Mac)?
>
>
> Thanks in advance,
>
> J


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ggrothendieck at gmail.com  Sat Sep 21 09:17:56 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 21 Sep 2013 03:17:56 -0400
Subject: [R] time zones from longitude, latitude, and date
In-Reply-To: <CAAZ8xc=E9uiCNXv-vGfs3uD+xHc9_a8=bF-9U85ZNe+yhVCP3A@mail.gmail.com>
References: <CAAZ8xcmpPMErsEYGdMbmA7LqxB7HDochipqUHtjHvAYUr+mQ4Q@mail.gmail.com>
	<26133729-5DF6-4DF3-A14A-541E0D5781EC@comcast.net>
	<CAAZ8xc=E9uiCNXv-vGfs3uD+xHc9_a8=bF-9U85ZNe+yhVCP3A@mail.gmail.com>
Message-ID: <CAP01uRk_62Np3S-mDY1G=jJz-JMGRgVnJNtKFjExoZ3QCUXAEw@mail.gmail.com>

On Fri, Sep 20, 2013 at 4:31 PM, carlisle thacker
<carlisle.thacker at gmail.com> wrote:
> I was looking for something like shown on the map:
> http://upload.wikimedia.org/wikipedia/commons/8/88/World_Time_Zones_Map.png
>
> Information about local daylight savings times would also help.
>
> The data are from ships, supposedly in local time, but no time-zone info is
> given.  A function that would return time zone and whether or not daylight
> savings time applies at given date would would help.  I'm trying to track
> down more information about the data and whether they can be referenced to
> UTC.

The zone.tab file has this information.  See the Examples section at
the end of ?Sys.timezone for info on its whereabouts.


From ripley at stats.ox.ac.uk  Sat Sep 21 10:13:09 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 21 Sep 2013 09:13:09 +0100
Subject: [R] time zones from longitude, latitude, and date
In-Reply-To: <CAP01uRk_62Np3S-mDY1G=jJz-JMGRgVnJNtKFjExoZ3QCUXAEw@mail.gmail.com>
References: <CAAZ8xcmpPMErsEYGdMbmA7LqxB7HDochipqUHtjHvAYUr+mQ4Q@mail.gmail.com>
	<26133729-5DF6-4DF3-A14A-541E0D5781EC@comcast.net>
	<CAAZ8xc=E9uiCNXv-vGfs3uD+xHc9_a8=bF-9U85ZNe+yhVCP3A@mail.gmail.com>
	<CAP01uRk_62Np3S-mDY1G=jJz-JMGRgVnJNtKFjExoZ3QCUXAEw@mail.gmail.com>
Message-ID: <523D5515.803@stats.ox.ac.uk>

On 21/09/2013 08:17, Gabor Grothendieck wrote:
> On Fri, Sep 20, 2013 at 4:31 PM, carlisle thacker
> <carlisle.thacker at gmail.com> wrote:
>> I was looking for something like shown on the map:
>> http://upload.wikimedia.org/wikipedia/commons/8/88/World_Time_Zones_Map.png
>>
>> Information about local daylight savings times would also help.
>>
>> The data are from ships, supposedly in local time, but no time-zone info is
>> given.  A function that would return time zone and whether or not daylight
>> savings time applies at given date would would help.  I'm trying to track
>> down more information about the data and whether they can be referenced to
>> UTC.
>
> The zone.tab file has this information.  See the Examples section at
> the end of ?Sys.timezone for info on its whereabouts.

On some OSes only.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ligges at statistik.tu-dortmund.de  Sat Sep 21 10:20:12 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 21 Sep 2013 10:20:12 +0200
Subject: [R] CRAN mirror for R in India: new one at WBUT,
 how do we get listed in the CRAN website?
In-Reply-To: <CAD1Vk45oXqNHihaU6WibZBXSiD+ZBtt0DD1P1UvZQCxUAug=-w@mail.gmail.com>
References: <CAD1Vk45oXqNHihaU6WibZBXSiD+ZBtt0DD1P1UvZQCxUAug=-w@mail.gmail.com>
Message-ID: <523D56BC.1090707@statistik.tu-dortmund.de>

See
http://cran.r-project.org/mirror-howto.html

Uwe Ligges


On 19.09.2013 14:04, abhinav kashyap wrote:
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Sat Sep 21 10:22:57 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 21 Sep 2013 10:22:57 +0200
Subject: [R] cov and huge matrix
In-Reply-To: <CAKyZeBurjcubYOV+v1JLkkxYvgLtuYQoR2MBo9rNwzLbLpnGTg@mail.gmail.com>
References: <CAKyZeBurjcubYOV+v1JLkkxYvgLtuYQoR2MBo9rNwzLbLpnGTg@mail.gmail.com>
Message-ID: <523D5761.3060105@statistik.tu-dortmund.de>



On 17.09.2013 18:11, Hermann Norpois wrote:
> Hello,
>
> I tried to compute the covariance (between the columns) of a matrix with
>> 200000.
> This failed ...
>
> Error: cannot allocate vector of size 691.2 GB
>
> Ok, this is rather huge. But ... On the other hand ... Is there an
> alternative to cov?
>
> Maybe one could combine combn with cov - so it is rather doing it hand by
> hand (within a function).


OK, but you need hundreds of gigabytes just to store the results. I 
wonder how you could make use of it in the end.

Uwe Ligges


From ligges at statistik.tu-dortmund.de  Sat Sep 21 10:26:19 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 21 Sep 2013 10:26:19 +0200
Subject: [R] Re :  Privacy rights of an old user of this list
In-Reply-To: <4ED416630266664A939E00E497C1385A6AB4459F@OITMX1003.AD.UMD.EDU>
References: <20130916211455.202290@gmx.com>
	<4ED416630266664A939E00E497C1385A6AB4459F@OITMX1003.AD.UMD.EDU>
Message-ID: <523D582B.9080607@statistik.tu-dortmund.de>

The locations where the mailing list are archived are not even 
controlled by any member of R-core or the R foundation. Everybody, 
including John, could collect mails from the list and publish them.
This is a well known property of a public mailing list.

Uwe Ligges




On 17.09.2013 13:29, Adan Leobardo Martinez Cruz wrote:
> Dear all,
>
> I will express my opinion without knowing the details of the posts John would like to be removed.
>
> In the current state, people posting on this and other servers have no clear way to go when trying to remove their posts.
> It is a likely event that the number of people attempting the removal of their past posts will increase. Their reasons will vary and may or not may be reasonable to us.
> It seems that a discussion on how the R-server will handle this likely situation is needed (including the possibility of keeping the current policy, of course)
> Once the decision has been taken, a warning note would be helpful for newcomers (something in big, black letters saying that whatever we post will not be removed or something like that).
>
> Best regards to all,
>
> adan
>
>
>
> ________________________________________
> From: r-help-bounces at r-project.org [r-help-bounces at r-project.org] on behalf of John Gonzalez [John.Gonzalez at gmx.fr]
> Sent: Monday, September 16, 2013 5:14 PM
> To: David Winsemius; Albin Blaschka; Duncan Murdoch; Jeff Newmiller; S  Ellison; Jim Lemon
> Cc: r-help at r-project.org
> Subject: [R] Re :  Privacy rights of an old user of this list
>
> I would like to thank David for letting me publish this and discuss it openly. I must acknowledge from the answers that I received to my post, that the administrators of this list are doing what seems to be fair to me: what most people demand or understand that is right.
> However I don't share your views and I honestly think you are making a mistake which may hurt you just as much as it is hurting me now) in the long term. Let me develop my point.
> First of all let me clarify for those who accuse me of being desinformed or innocent about my request, I'm not asking for your collaboration to remove what I published from the internet, its google records or any of the infinite copies that may be lying around. I'm asking for a very simple thing:
> There are 7 messages (sorry it wasn't 3...) written by me and hosted at the server stat.ethz.ch https://stat.ethz.ch/pipermail/r-help/2009-March/190367.html  which I would like to have removed.
> Now, Steve E makes a good point: "I am also of the opinion that the list owner was not showing disrespect by describing the state of affairs you agreed to on signing up, or by declining to act beyond the requirements of the conditions applicable to the list. " Steve
> Fair enough. But that doesn't mean that those conditions are right and should never be modified. I'm probably something similar to an unhappy customer who has bought a product with no money-back policy but with an important distinction: I'm going to be wearing this product for the rest of my life. So that makes me, if anything, a "very unhappy customer".
> Now let me explain why in this world I'm spending time on requesting the removal of these 7 messages in that server.
> I have a MS in Computer Science and a 5 years long Telecommunications degree, I know quite well how the internet works. This is not the first time that I request this. I already requested it in another mailing list, where they were kind enough to aprove it after I verified my identity and they checked that they weren't removing anything critical. The result was that that piece information was obviously not erased from the entire internet but was not showing up in the first 12 pages of google when you would look up my name (when it was on the first page previously). It took me 5 requests to different servers but I managed. There is nothing impossible about it and it made a difference in my life.
> So why is this important for me (something like not showing up on the first pages of google?). Well please understand that there is a difference between publishing an article and writing an email to a list. An article goes through several personal revisions and is examined by a professional reviewer before it is published. It only takes a click to send an email. It is extremely easy to make mistakes (particularly when you are young and you know little about life). Actually, people make lots of mistakes and banks may use it to deny you or give you credit, employers to give you an opportunity or not, a lover to have more or less reasons to meet you etc etc etc. Removing this information from servers that are more visited by the search bot crawlers makes a difference: your banker will have to spend more time or resources to refuse your credit request, your lover may be already calling you for a date, your employer may be already calling your for an interview.
> Now, if you have a lifetime job, if you never want to change your career, if you will never need a credit, if you have a lovely, healthy and loyal wife, what I just wrote may sound meaningless but if anything happens to your life, you may end up remembering what I said and suffering like me.
> Why? Because you it is not possible to remove 7 messages from a server? OK, this is surely extra work that may be difficult to handle but have you considered adding a small fee for those removal requests? I would be more than happy to pay for it.
> "There are a quite a few of my postings to newsgroups that I wouldn't mind seeing disappear and even a few on the Rhelp archives. I just don't think that my errors in judgment or
> knowledge deserve to be ignored. My hope is that I am judged on the balance of useful versus boneheaded." David
> I hope that my point is clear by now. My original motivation was and continues to be that my name was associated with a company that I don't want to be associated with (may I keep my reasons private?). My knowledge or professionality is not at stake for what I said. I can actually prove to you that I abandonded my career in engineering and I'm working in things that have nothing to do with it.
> Looking forward to hearing your opinions again.
> Best regards,
> John
> ----- Message d'origine -----
> De : John Gonzalez
> Envoy??s : 12.09.13 15:40
> ?? : r-help at r-project.org, r-help at r-project.org
> Objet : [R] Privacy rights of an old user of this list
>
> Dear subscribers of r-help, I would like to know your opinion about a privacy problem that I recently had after publishing to this list. Not a long time ago, I requested to the administrators of this list that they removed 2 or 3 old posts from mine. These posts were associating my name with an old company for which I worked a few years ago when you would look up my real name at google. I'm 100% aware that there are many mirrors of this list archive and that this is a hard work, however my point was to move their google references to later pages so that new people that look up my name would focus first on more recent work that I see as more relevant for what I would like to do in the future. This is the answer that I received from Mr. Winsemius: << Such a service is not available. Almost immediately rhelp postings are replicated in multiple websites around the world. The information that you could have (and should have) read at the time of signing up is here: https://stat.!
 et!
>   hz.ch/mailman/listinfo/r-help ... and the relevant sentence is: "Posters should be aware that the R lists are /public/ discussion lists and anything you post will be *archived and accessible* via several websites for many years." >> I followed up explaining that at that time I was too young to understand the consequences of what I was doing and that, honestly, I didn't pay attention to such a note. Mr. Winsemius didn't understand the reason of my request and therefore decided to ignore it, even after asking a representative from the company mentioned in my old posts to contact him to request the removal of such posts. At this point I feel completely powerless and disturbed that the administrators of the r-help list refuse to remove a text that I decided a long time ago to publish here. I don't think that they own the rights of what I wrote and I wonder what I have done wrong to be disrespected in such a way. Best regards, John Gonzalez (pseudonym) [[alternative HTML vers!
 ion!
>    deleted]] ______________________________________________ R-help at r-pro
>
> ject.org mailing list https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the posting guide http://www.R-project.org/posting-guide.html and provide commented, minimal, self-contained, reproducible code.
>
>          [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Sat Sep 21 16:01:05 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 21 Sep 2013 09:01:05 -0500
Subject: [R] Error in library() call
In-Reply-To: <CAEBi+_kuVye=536aT4wd5LGNZ7DrY2j4DHTj_tdFFu24C1wN8w@mail.gmail.com>
References: <1378380710423-4675440.post@n4.nabble.com>
	<1379597817.72417.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1379681943.80793.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<CAEBi+_kuVye=536aT4wd5LGNZ7DrY2j4DHTj_tdFFu24C1wN8w@mail.gmail.com>
Message-ID: <24744024-74F4-454B-A0A8-3E80086704F1@comcast.net>


On Sep 20, 2013, at 1:27 PM, supernovartis wrote:

> Hi Arun,
>
> I get the following error when I enter the command:
>
> library(reshape2)
>
>
> Error in library(reshape2) : there is no package called ?reshape2?

Packages need to be installed before they are loaded.

You are also requested not to highjack threads or if your do at least  
modify the subject line line so that it is informative.

-- 
David.
> On Fri, Sep 20, 2013 at 3:09 PM, arun kirshna [via R] <
> ml-node+s789695n4676569h16 at n4.nabble.com> wrote:
>
>> Hi Elio,
>> Try this:
>>
>> library(stringr

snippedunrelated message text

>
> --
> View this message in context: http://r.789695.n4.nabble.com/binary-symmetric-matrix-combination-tp4675440p4676602.html
> Sent from the R help mailing list archive at Nabble.com.
> 	[[alternative HTML version deleted]]

Please read the Posing Guide, and if you must use Nabble at least  
learn how to post in plain text.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From dwinsemius at comcast.net  Sat Sep 21 16:25:20 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 21 Sep 2013 09:25:20 -0500
Subject: [R] time zones from longitude, latitude, and date
In-Reply-To: <523D5515.803@stats.ox.ac.uk>
References: <CAAZ8xcmpPMErsEYGdMbmA7LqxB7HDochipqUHtjHvAYUr+mQ4Q@mail.gmail.com>
	<26133729-5DF6-4DF3-A14A-541E0D5781EC@comcast.net>
	<CAAZ8xc=E9uiCNXv-vGfs3uD+xHc9_a8=bF-9U85ZNe+yhVCP3A@mail.gmail.com>
	<CAP01uRk_62Np3S-mDY1G=jJz-JMGRgVnJNtKFjExoZ3QCUXAEw@mail.gmail.com>
	<523D5515.803@stats.ox.ac.uk>
Message-ID: <A4A57CC9-B381-4AE1-B0AA-78370ACC6FAA@comcast.net>


On Sep 21, 2013, at 3:13 AM, Prof Brian Ripley wrote:

> On 21/09/2013 08:17, Gabor Grothendieck wrote:
>> On Fri, Sep 20, 2013 at 4:31 PM, carlisle thacker
>> <carlisle.thacker at gmail.com> wrote:
>>> I was looking for something like shown on the map:
>>> http://upload.wikimedia.org/wikipedia/commons/8/88/World_Time_Zones_Map.png
>>>
>>> Information about local daylight savings times would also help.
>>>
>>> The data are from ships, supposedly in local time, but no time- 
>>> zone info is
>>> given.  A function that would return time zone and whether or not  
>>> daylight
>>> savings time applies at given date would would help.  I'm trying  
>>> to track
>>> down more information about the data and whether they can be  
>>> referenced to
>>> UTC.
>>
>> The zone.tab file has this information.  See the Examples section at
>> the end of ?Sys.timezone for info on its whereabouts.
>
> On some OSes only.

This is a couple of snippets of that file from a Mac:
/usr/share/zoneinfo/zone.tab
#-------------
# This file contains a table with the following columns:
# 1.  ISO 3166 2-character country code.  See the file `iso3166.tab'.
# 2.  Latitude and longitude of the zone's principal location
#     in ISO 6709 sign-degrees-minutes-seconds format,
#     either +-DDMM+-DDDMM or +-DDMMSS+-DDDMMSS,
#     first latitude (+ is north), then longitude (+ is east).
# 3.  Zone name used in value of TZ environment variable.
# 4.  Comments; present if and only if the country has multiple rows.
#---------

US	+340308-1181434	America/Los_Angeles	Pacific Time
US	+611305-1495401	America/Anchorage	Alaska Time
US	+581807-1342511	America/Juneau	Alaska Time - Alaska panhandle
US	+593249-1394338	America/Yakutat	Alaska Time - Alaska panhandle neck
US	+643004-1652423	America/Nome	Alaska Time - west Alaska
US	+515248-1763929	America/Adak	Aleutian Islands
US	+211825-1575130	Pacific/Honolulu	Hawaii
UY	-3453-05611	America/Montevideo
UZ	+3940+06648	Asia/Samarkand	west Uzbekistan
UZ	+4120+06918	Asia/Tashkent	east Uzbekistan
VA	+415408+0122711	Europe/Vatican


After looking at it I'm not sure it will be of much additional value  
for the purposes outlined. It does not provide boundaries of time zones.

-- 

David Winsemius, MD
Alameda, CA, USA


From irasharenow100 at yahoo.com  Sat Sep 21 17:30:44 2013
From: irasharenow100 at yahoo.com (Ira Sharenow)
Date: Sat, 21 Sep 2013 08:30:44 -0700
Subject: [R] Obtaining data from a different row of data frame
Message-ID: <523DBBA4.7070301@yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130921/74021a7e/attachment.pl>

From smartpink111 at yahoo.com  Sat Sep 21 17:32:43 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 21 Sep 2013 08:32:43 -0700 (PDT)
Subject: [R] binary symmetric matrix combination
In-Reply-To: <1379681943.80793.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <18616451.21640.1379526255404.JavaMail.nabble@joe.nabble.com>	<CAEBi+_=-Mcm20ChYz5ivC9OK0QrNx2tEKZfuqOMQ1f4WE1KJdA@mail.gmail.com>	<1379550935.95411.YahooMailNeo@web142602.mail.bf1.yahoo.com>	<CAEBi+_m6ZT8hWkenzp-aa3+p0wAkmD__4Y2acLWKfsv7vDmrTA@mail.gmail.com>	<1379597817.72417.YahooMailNeo@web142604.mail.bf1.yahoo.com>	<1379598003.66715.YahooMailNeo@web142603.mail.bf1.yahoo.com>	<1379626408.11480.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CAEBi+_kypgvfiF35jHVoJL40c-A9hRRReRuxU+cqubL0Y_UMqw@mail.gmail.com>
	<1379681943.80793.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <1379777563.99968.YahooMailNeo@web142604.mail.bf1.yahoo.com>


Hi Elio,
Use ?write.table()
write.table(res,"Eliores.txt",quote=FALSE)

#and as read the file
mat1<- as.matrix(read.table("Eliores.txt",header=TRUE))
#or even this should work
mat1<-? as.matrix(read.table("Eliores.txt"))

#If you have very big matrix, you may try:
library(tseries)
write(res,"ElioresNew.txt",ncolumns=dim(res)[1]) #dimnames are not stored
write.table(dimnames(res)[[1]],"Eliodimnames.txt",quote=FALSE,row.names=FALSE)
mat2<- read.matrix("ElioresNew.txt")
?names1<-read.table("Eliodimnames.txt",header=TRUE,stringsAsFactors=FALSE)[,1]
dimnames(mat2)<- list(names1,names1)
all.equal(mat1,mat2)
#[1] TRUE

A.K.




________________________________
From: Elio Shijaku <selius at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Saturday, September 21, 2013 5:10 AM
Subject: Re: binary symmetric matrix combination



Hi Arun, 

That
 was real magic, thanks a lot, now I get the full matrix with no need to
 input the commands that you gave me before. One last question, how to 
export the res matrix as a text file so I can use it with other 
software?






On Sat, Sep 21, 2013 at 4:35 AM, arun <smartpink111 at yahoo.com> wrote:

HI Elio,
>It looks like you haven't installed reshape2 package. Or is there any problem in installing the package?
>install.packages("reshape2")
>
>
>
>
>Hi Arun,
>
>I get the following error when I enter the command:
>
>library(reshape2)
>
>
>Error in library(reshape2) : there is no package called ?reshape2?
>
>
>Any ideas?
>
>
>Thanks again.
>



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Friday, September 20, 2013 8:59 AM
Subject: Re: binary symmetric matrix combination

>Hi Elio,
>Try this:
>
>library(stringr)
>
>lines1<-str_trim(gsub("\t"," ",readLines("elio.txt")))
>lst1<-lapply(split(lines1,cumsum(lines1=="")),function(x) x[x!=""])
>
>lst2<- lapply(lst1[lapply(lst1,length)>0],function(x) as.matrix(read.table(text=x,row.names=1)))
>names(lst2)<- paste0("m",seq_along(lst2))
>dat<- do.call(rbind,lapply(names(lst2),function(x) {x1<- lst2[[x]]; cbind(expand.grid(rep(list(colnames(x1)),2),stringsAsFactors=FALSE),value=as.vector(x1))}))
>library(reshape2)
>res<- dcast(dat,Var1~Var2,value.var="value",sum)
> row.names(res)<- res[,1]
> res<- as.matrix(res[,-1])
>dim(res)
#[1] 14 14
>
>
>A.K.


From smartpink111 at yahoo.com  Sat Sep 21 17:51:11 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 21 Sep 2013 08:51:11 -0700 (PDT)
Subject: [R] search species with all absence in a presence-absence matrix
In-Reply-To: <CAGJhoDzwuRV-pNw4cmRz2K_Mv0LmjvSfGZQjcHW53UJ8fhnPEQ@mail.gmail.com>
References: <CAGJhoDxjY95xvk5MsGHpSxCaB-O_4xLu7YdZteMD=Suz3EkBTA@mail.gmail.com>	<1379725057.38724.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<CAGJhoDzwuRV-pNw4cmRz2K_Mv0LmjvSfGZQjcHW53UJ8fhnPEQ@mail.gmail.com>
Message-ID: <1379778671.36945.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi Elaine,
#You can either convert the .xls dataset to .csv and read it with ?read.csv() or use one of the packages to read excel dataset

library(XLConnect) 
wb<- loadWorkbook("is_matrix.xls")
dataRM<- readWorksheet(wb,sheet="is_matrix",rownames=1)
dim(dataRM)
#[1] 22 23
?mat1<- as.matrix(dataRM)
matSub<- mat1[,colSums(mat1)==0,drop=FALSE]
?head(matSub,3)
#???????? D0008 D0009 D0010 D0011 D0012 D3396
#Sakhalin???? 0???? 0???? 0???? 0???? 0???? 0
#Hokkaido???? 0???? 0???? 0???? 0???? 0???? 0
#Korea??????? 0???? 0???? 0???? 0???? 0???? 0
colnames(mat1)[colSums(mat1)==0]
#[1] "D0008" "D0009" "D0010" "D0011" "D0012" "D3396"


#I used lst1, lst2 etc just to create some data.
A.K.


________________________________
From: Elaine Kuo <elaine.kuo.tw at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Saturday, September 21, 2013 7:10 AM
Subject: Re: [R] search species with all absence in a presence-absence matrix



Hello Arun, 

Thanks for the code.
I replaced my file (dataRM) with lst2 but
an error showed up.
It said
Error in colSums(mat1): x must be at an
array or at least two dimensions

I am sure the x (dataRM) is two-dimension.

Please kindly advise any code modification.
Also, I attach part of my data in the
e-mail.
Thank you again.

Elaine
Code
load("f:/b_W_line/R_workspace/R_workspace_R_4874/R_workspace_RM/dataset_RM_3546.RData")
?dim(dataRM)
?str(dataRM)

?mat1<-dataRM[[1]]
?mat1[,colSums(mat1)==0,drop=FALSE](error)
?colnames(mat1)[colSums(mat1)==0]



On Sat, Sep 21, 2013 at 8:57 AM, arun <smartpink111 at yahoo.com> wrote:

Hi,
>Try this:
>
>?set.seed(248)
>?lst1<- lapply(1:1000,function(i) matrix( sample(0:1,15*100,replace=TRUE),ncol=100,dimnames=list(paste("Island",LETTERS[1:15]),? paste0("D",sprintf("%04d",1:100)))))
>?lst2<-lst1[sapply(lst1,function(x) any(colSums(x)==0))]
>##The above steps are just to create some matrices with zeros in all the "islands"
>mat1<-lst2[[1]]
>?mat1[,colSums(mat1)==0,drop=FALSE]
>#???????? D0038
>#Island A???? 0
>#Island B???? 0
>#Island C???? 0
>#Island D???? 0
>#Island E???? 0
>#Island F???? 0
>#Island G???? 0
>#Island H???? 0
>#Island I???? 0
>#Island J???? 0
>#Island K???? 0
>#Island L???? 0
>#Island M???? 0
>#Island N???? 0
>#Island O???? 0
>colnames(mat1)[colSums(mat1)==0]
>#[1] "D0038"
>?mat2<-lst2[[3]]
>?colnames(mat2)[colSums(mat2)==0]
>#[1] "D0086"
>
>A.K.
>
>
>
>
>
>----- Original Message -----
>From: Elaine Kuo <elaine.kuo.tw at gmail.com>
>To: "r-help at r-project.org" <r-help at r-project.org>
>Cc:
>Sent: Friday, September 20, 2013 7:14 PM
>Subject: [R] search species with all absence in a presence-absence matrix
>
>
>Dear list
>
>
>
>I have a matrix composed of islandID as rows and speciesID as columns.
>
>IslandID: Island A, B, C?.O (15 islands in total)
>
>SpeciesID: D0001, D0002, D0003?.D0100 (100 species in total)
>
>
>
>The cell of the matrix describes presence (1) or absence (0) of the species
>in an island.
>
>
>
>Now I would like to search the species with absence (0)
>
>in all the islands (Island A to Island O.)
>
>
>
>Please kindly advise the R code for the search purpose.
>
>Thank you.
>
>
>
>Elaine
>
>
>??? [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>?????


From smartpink111 at yahoo.com  Sat Sep 21 18:08:15 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 21 Sep 2013 09:08:15 -0700 (PDT)
Subject: [R] Filtering out data from list
Message-ID: <1379779695.21702.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
?list1<-lapply(c("",2:3),function(x) paste0("hi I am here!",x))
#or
list1<-? as.list(paste0("hi I am here!",c("",2:3)))


?str(list1)
#List of 3
# $ : chr "hi I am here!"
# $ : chr "hi I am here!2"
# $ : chr "hi I am here!3"


It is not a list within a list
?

list2<-list1[grepl("2",unlist(list1))]
?list2
#[[1]]
#[1] "hi I am here!2"



#list within a list
listNew<- list( as.list(paste0("hi I am here!",c("",2:3))))
str(listNew)
#List of 1
# $ :List of 3
?# ..$ : chr "hi I am here!"
? #..$ : chr "hi I am here!2"
? #..$ : chr "hi I am here!3"

listNew2<- lapply(1:3,function(x) as.list(paste0("hi I am here!",c("",2:3))))
?str(listNew2)
#List of 3
# $ :List of 3
?# ..$ : chr "hi I am here!"
? #..$ : chr "hi I am here!2"
? #..$ : chr "hi I am here!3"
?#$ :List of 3
?# ..$ : chr "hi I am here!"
?# ..$ : chr "hi I am here!2"
?# ..$ : chr "hi I am here!3"
# $ :List of 3
#? ..$ : chr "hi I am here!"
#? ..$ : chr "hi I am here!2"
#? ..$ : chr "hi I am here!3"


A.K.




Okay im pretty new in r... ? 
and im having trouble figuring how to filtering out data 
just say for example i have a list which prints out 

> list1 
[[1]] 
[1] "hi I am here!" 

[[2]] 
[1] "hi I am here!2" 

[[3]] 
[1] "hi I am here!3" 

.... 

1) okay first I need to confirm , is that a list within a list ? since its displaying 

[[1]] 
[1] ? ?<-- in this fashion 

2) and now just say i want to have list1 to only contain the list with the number 2 in it how do i do it? 
or any methods to suggest ?


From caciquesamurai at gmail.com  Sat Sep 21 18:16:26 2013
From: caciquesamurai at gmail.com (Raoni Rodrigues)
Date: Sat, 21 Sep 2013 13:16:26 -0300
Subject: [R] Grouping variables by a irregular time interval
Message-ID: <CAGtwFe3kR2vr6PAiH_HyFWG3eazdyV1CYw+DwppBhZbwWxgbKg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130921/cccc108f/attachment.pl>

From davideps at umich.edu  Sat Sep 21 18:43:17 2013
From: davideps at umich.edu (davideps)
Date: Sat, 21 Sep 2013 09:43:17 -0700 (PDT)
Subject: [R] Display all element names neatly in a Venn Diagram
Message-ID: <1379781797300-4676631.post@n4.nabble.com>

Hello,

I want to create a Venn diagram that displays all the elements of the sets
and overlap regions. The closest tool I've found for this is in Vennerable,
described here:

http://stackoverflow.com/questions/7029987/r-how-to-display-elements-instead-of-just-counts-within-each-circle-of-a-venn

However, this does not actually fit the elements within the regions but
instead makes a single long name for that region from the element names. At
the very least, I would like to reformat the name onto multiple lines. Any
suggestions?

-david



--
View this message in context: http://r.789695.n4.nabble.com/Display-all-element-names-neatly-in-a-Venn-Diagram-tp4676631.html
Sent from the R help mailing list archive at Nabble.com.


From johnatlanta12 at gmail.com  Sat Sep 21 18:31:11 2013
From: johnatlanta12 at gmail.com (John S.)
Date: Sat, 21 Sep 2013 12:31:11 -0400
Subject: [R] Psedocode in R
Message-ID: <CAPSJ6ynKoMXZFEXcpzC=DSRoGNV5y1xCHpHXnRGpkUZ8g2krkg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130921/cee70e1c/attachment.pl>

From bhh at xs4all.nl  Sat Sep 21 19:56:47 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sat, 21 Sep 2013 19:56:47 +0200
Subject: [R] Psedocode in R
In-Reply-To: <CAPSJ6ynKoMXZFEXcpzC=DSRoGNV5y1xCHpHXnRGpkUZ8g2krkg@mail.gmail.com>
References: <CAPSJ6ynKoMXZFEXcpzC=DSRoGNV5y1xCHpHXnRGpkUZ8g2krkg@mail.gmail.com>
Message-ID: <24A0974F-E296-43C5-BF02-D023A1B97749@xs4all.nl>


On 21-09-2013, at 18:31, "John S." <johnatlanta12 at gmail.com> wrote:

> I have never written my own function, psedocode, in R. Can anyone show me
> how to write a psedocode if I want to return, say, like mode or class...?
> Thanks
> 

What is psedocode?
Furthermore: this is incomprehensible.

> 	[[alternative HTML version deleted]]
> 

Please do not post in HTML.

Berend

> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Sat Sep 21 20:15:42 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 21 Sep 2013 19:15:42 +0100
Subject: [R] Display all element names neatly in a Venn Diagram
In-Reply-To: <1379781797300-4676631.post@n4.nabble.com>
References: <1379781797300-4676631.post@n4.nabble.com>
Message-ID: <523DE24E.1050803@sapo.pt>

Hello,

There's a package VennDiagram, I don't know if it is what you want, but 
it makes nice graphs.

Hope this helps,

Rui Barradas

Em 21-09-2013 17:43, davideps escreveu:
> Hello,
>
> I want to create a Venn diagram that displays all the elements of the sets
> and overlap regions. The closest tool I've found for this is in Vennerable,
> described here:
>
> http://stackoverflow.com/questions/7029987/r-how-to-display-elements-instead-of-just-counts-within-each-circle-of-a-venn
>
> However, this does not actually fit the elements within the regions but
> instead makes a single long name for that region from the element names. At
> the very least, I would like to reformat the name onto multiple lines. Any
> suggestions?
>
> -david
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Display-all-element-names-neatly-in-a-Venn-Diagram-tp4676631.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wdunlap at tibco.com  Sat Sep 21 20:26:57 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 21 Sep 2013 18:26:57 +0000
Subject: [R] Obtaining data from a different row of data frame
In-Reply-To: <523DBBA4.7070301@yahoo.com>
References: <523DBBA4.7070301@yahoo.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C34517A@PA-MBX01.na.tibco.com>

Note that your inner loop

> for(i in 1:10 ) {
>    rowNumber = i + df1[i,j-2]
>    df1[i,j] = df1[rowNumber, j-4]
> } # end i loop

is equivalent to the much quicker
      i <- 1:10
      rowNumbers <- i + df1[i, j-2]
      df1[i, j] <- df1[rowNumbers, j-4]

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Ira Sharenow
> Sent: Saturday, September 21, 2013 8:31 AM
> To: r-help at r-project.org
> Subject: [R] Obtaining data from a different row of data frame
> 
> I have a large data frame with 2,000 rows and 600 columns. I can write
> loops to solve a smaller problem, but I need a better strategy for this
> data frame.
> 
> Below is a simple example with just two stocks.
> 
> In the data frame, each row represents a trading day. The first column
> is dates. The next group of columns represents the prices of the stocks
> on the specified dates. The next group of columns represents how many
> trading days I wish to offset. So if the first trading day is 2006-01-03
> and OF1 == 3, then I need to go to row 1+3 and get the price in column
> P1. The result is placed in row 1 of column 6.
> 
> 
> df1 = data.frame(matrix(rep(NA, 10*7), nrow = 10))
> 
> Dates =as.Date(c("2006-01-03", "2006-01-04", "2006-01-05", "2006-01-06",
> "2006-01-09", "2006-01-10", "2006-01-11",
> 
> "2006-01-12", "2006-01-13", "2006-01-16"), format = "%Y-%m-%d")
> 
> P1 = 10:19
> 
> P2 = 100:109
> 
> OF1 = c(3,3,4,5,2,2,2,1,1,0)
> 
> OF2 = c(5,3,4,2,1,2,2,1,1,0)
> 
> df1 = data.frame(Dates = Dates, P1 = P1, P2 = P2, OF1 = OF1, OF2 = OF2)
> 
> df1$newPrice1 = rep(NA, 10)
> 
> df1$newPrice2 = rep(NA, 10)
> 
> for(j in 6:7) {
> 
> for(i in 1:10 ) {
> 
> rowNumber = i + df1[i,j-2]
> 
> #print(rowNumber)
> 
> df1[i,j] = df1[rowNumber, j-4]
> 
> } # end i loop
> 
> } # end j loop
> 
> df1
> 
> > df1
> 
> Dates P1P2 OF1 OF2 newPrice1 newPrice2
> 
> 1 2006-01-03 10 1003513105
> 
> 22006-01-04 11 1013314104
> 
> 32006-01-05 12 1024416106
> 
> 42006-01-06 13 1035218105
> 
> 52006-01-09 14 1042116105
> 
> 62006-01-10 15 1052217107
> 
> 72006-01-11 16 1062218108
> 
> 82006-01-12 17 1071118108
> 
> 92006-01-13 18 1081119109
> 
> 10 2006-01-16 19 1090019109
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Rainer at krugs.de  Sat Sep 21 15:51:43 2013
From: Rainer at krugs.de (Rainer M Krug)
Date: Sat, 21 Sep 2013 15:51:43 +0200
Subject: [R] Re :  Privacy rights of an old user of this list
References: <20130916211455.202290@gmx.com>
	<4ED416630266664A939E00E497C1385A6AB4459F@OITMX1003.AD.UMD.EDU>
Message-ID: <m2wqmanuz4.fsf@krugs.de>

If you say something inn public, it will be there and people may
remember it - you can't take back what you said.

So why is a mailing list different? it is just that we are typing
instead of talking - it goes into the public and there it stays. 

Ever heard of the Streisand effect
https://en.wikipedia.org/wiki/Streisand_effect?

I am really tempted to scan the mailing lists to find out how many
contributed three posts which fit the profile...

So live with what you said. 

Post a mail where you distance yourself from the posts, but don't expect
that the original ones will disappear.

Cheers,

Rainer

Adan Leobardo Martinez Cruz <amartin2 at umd.edu> writes:

> Dear all,
>
> I will express my opinion without knowing the details of the posts John would like to be removed.
>
> In the current state, people posting on this and other servers have no clear way to go when trying to remove their posts.
> It is a likely event that the number of people attempting the removal of their past posts will increase. Their reasons will vary and may or not may be reasonable to us.
> It seems that a discussion on how the R-server will handle this likely situation is needed (including the possibility of keeping the current policy, of course)
> Once the decision has been taken, a warning note would be helpful for newcomers (something in big, black letters saying that whatever we post will not be removed or something like that).
>
> Best regards to all,
>
> adan
>
>
>
> ________________________________________
> From: r-help-bounces at r-project.org [r-help-bounces at r-project.org] on behalf of John Gonzalez [John.Gonzalez at gmx.fr]
> Sent: Monday, September 16, 2013 5:14 PM
> To: David Winsemius; Albin Blaschka; Duncan Murdoch; Jeff Newmiller; S  Ellison; Jim Lemon
> Cc: r-help at r-project.org
> Subject: [R] Re :  Privacy rights of an old user of this list
>
> I would like to thank David for letting me publish this and discuss it openly. I must acknowledge from the answers that I received to my post, that the administrators of this list are doing what seems to be fair to me: what most people demand or understand that is right.
> However I don't share your views and I honestly think you are making a mistake which may hurt you just as much as it is hurting me now) in the long term. Let me develop my point.
> First of all let me clarify for those who accuse me of being desinformed or innocent about my request, I'm not asking for your collaboration to remove what I published from the internet, its google records or any of the infinite copies that may be lying around. I'm asking for a very simple thing:
> There are 7 messages (sorry it wasn't 3...) written by me and hosted at the server stat.ethz.ch https://stat.ethz.ch/pipermail/r-help/2009-March/190367.html  which I would like to have removed.
> Now, Steve E makes a good point: "I am also of the opinion that the list owner was not showing disrespect by describing the state of affairs you agreed to on signing up, or by declining to act beyond the requirements of the conditions applicable to the list. " Steve
> Fair enough. But that doesn't mean that those conditions are right and should never be modified. I'm probably something similar to an unhappy customer who has bought a product with no money-back policy but with an important distinction: I'm going to be wearing this product for the rest of my life. So that makes me, if anything, a "very unhappy customer".
> Now let me explain why in this world I'm spending time on requesting the removal of these 7 messages in that server.
> I have a MS in Computer Science and a 5 years long Telecommunications degree, I know quite well how the internet works. This is not the first time that I request this. I already requested it in another mailing list, where they were kind enough to aprove it after I verified my identity and they checked that they weren't removing anything critical. The result was that that piece information was obviously not erased from the entire internet but was not showing up in the first 12 pages of google when you would look up my name (when it was on the first page previously). It took me 5 requests to different servers but I managed. There is nothing impossible about it and it made a difference in my life.
> So why is this important for me (something like not showing up on the first pages of google?). Well please understand that there is a difference between publishing an article and writing an email to a list. An article goes through several personal revisions and is examined by a professional reviewer before it is published. It only takes a click to send an email. It is extremely easy to make mistakes (particularly when you are young and you know little about life). Actually, people make lots of mistakes and banks may use it to deny you or give you credit, employers to give you an opportunity or not, a lover to have more or less reasons to meet you etc etc etc. Removing this information from servers that are more visited by the search bot crawlers makes a difference: your banker will have to spend more time or resources to refuse your credit request, your lover may be already calling you for a date, your employer may be already calling your for an interview.
> Now, if you have a lifetime job, if you never want to change your career, if you will never need a credit, if you have a lovely, healthy and loyal wife, what I just wrote may sound meaningless but if anything happens to your life, you may end up remembering what I said and suffering like me.
> Why? Because you it is not possible to remove 7 messages from a server? OK, this is surely extra work that may be difficult to handle but have you considered adding a small fee for those removal requests? I would be more than happy to pay for it.
> "There are a quite a few of my postings to newsgroups that I wouldn't mind seeing disappear and even a few on the Rhelp archives. I just don't think that my errors in judgment or
> knowledge deserve to be ignored. My hope is that I am judged on the balance of useful versus boneheaded." David
> I hope that my point is clear by now. My original motivation was and continues to be that my name was associated with a company that I don't want to be associated with (may I keep my reasons private?). My knowledge or professionality is not at stake for what I said. I can actually prove to you that I abandonded my career in engineering and I'm working in things that have nothing to do with it.
> Looking forward to hearing your opinions again.
> Best regards,
> John
> ----- Message d'origine -----
> De : John Gonzalez
> Envoy??s : 12.09.13 15:40
> ?? : r-help at r-project.org, r-help at r-project.org
> Objet : [R] Privacy rights of an old user of this list
>
> Dear subscribers of r-help, I would like to know your opinion about a privacy problem that I recently had after publishing to this list. Not a long time ago, I requested to the administrators of this list that they removed 2 or 3 old posts from mine. These posts were associating my name with an old company for which I worked a few years ago when you would look up my real name at google. I'm 100% aware that there are many mirrors of this list archive and that this is a hard work, however my point was to move their google references to later pages so that new people that look up my name would focus first on more recent work that I see as more relevant for what I would like to do in the future. This is the answer that I received from Mr. Winsemius: << Such a service is not available. Almost immediately rhelp postings are replicated in multiple websites around the world. The information that you could have (and should have) read at the time of signing up is here: https://stat.et!
>  hz.ch/mailman/listinfo/r-help ... and the relevant sentence is: "Posters should be aware that the R lists are /public/ discussion lists and anything you post will be *archived and accessible* via several websites for many years." >> I followed up explaining that at that time I was too young to understand the consequences of what I was doing and that, honestly, I didn't pay attention to such a note. Mr. Winsemius didn't understand the reason of my request and therefore decided to ignore it, even after asking a representative from the company mentioned in my old posts to contact him to request the removal of such posts. At this point I feel completely powerless and disturbed that the administrators of the r-help list refuse to remove a text that I decided a long time ago to publish here. I don't think that they own the rights of what I wrote and I wonder what I have done wrong to be disrespected in such a way. Best regards, John Gonzalez (pseudonym) [[alternative HTML version!
>   deleted]] ______________________________________________ R-help at r-pro
>
> ject.org mailing list https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the posting guide http://www.R-project.org/posting-guide.html and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
>
<#secure method=pgpmime mode=sign>

-- 
Rainer M. Krug

email: RMKrug<at>gmail<dot>com


From smartpink111 at yahoo.com  Sun Sep 22 01:00:01 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 21 Sep 2013 16:00:01 -0700 (PDT)
Subject: [R] Obtaining data from a different row of data frame
In-Reply-To: <523E0AF3.8050904@yahoo.com>
References: <523DBBA4.7070301@yahoo.com>
	<1379795975.60563.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<523E0AF3.8050904@yahoo.com>
Message-ID: <1379804401.3645.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi Ira,

Some suggestions:
1. Not sure why you created a dataframe with NA's in the beginning.? It seemed to be not required here.
df1 = data.frame(matrix(rep(NA, 10*7), nrow = 10))

2. The below code:
df1 = data.frame(Dates = Dates, P1 = P1, P2 = P2, OF1 = OF1, OF2 = OF2)
can be simplifed as:
df1 = data.frame(Dates,P1,P2, P3, P4, OF1, OF2,OF3, OF4)
?head(df1,2)
#?????? Dates P1? P2 P3 P4 OF1 OF2 OF3 OF4
#1 2006-01-03 10 100 90 70?? 3?? 5?? 4?? 3
#2 2006-01-04 13 102 94 75?? 3?? 3?? 3?? 5


3.? If you have multiple columns of NA's to create

df1$newPrice1 = rep(NA, 10)
?df1$newPrice2 = rep(NA, 10)

This could be also done by:
df1[,6:7]<- NA
?colnames(df1)[6:7]<- paste0("newPrice",1:2)



#Regarding the question:
#Created another dataset with couple more columns:

?Dates =? as.Date(c("2006-01-03", "2006-01-04", "2006-01-05", "2006-01-06", "2006-01-09", "2006-01-10", "2006-01-11",
??????????????????? "2006-01-12", "2006-01-13", "2006-01-16"), format = "%Y-%m-%d")
?P1 = seq(from = 10, by = 3, length.out = 10)
?P2 = seq(from = 100, by = 2, length.out = 10)
P3= seq(from= 90, by=4,length.out=10)
?P4= seq(from=70,by=5,length.out=10)
?OF1 = c(3,3,4,5,2,2,2,1,1,0)
?OF2 = c(5,3,4,2,1,2,2,1,1,0)
?OF3 <- c(4,3,4,1,3,2,2,1,1,0)
?OF4<- c(3,5,4,2,3,1,2,1,1,0)
df1 = data.frame(Dates,P1,P2, P3, P4, OF1, OF2,OF3, OF4)
df2<- df1
?df2[,10:13]<- NA
colnames(df2)[10:13]<- paste0("newPrice",1:4)

##your code

for(j in 2:5) {
?df2[j+8] = df2[df2[,j+4] + row(df2)[,j], j]
?}


#modified code #didn't check the speed.
indx1<- unlist(df1[,grep("OF",colnames(df1))],use.names=FALSE)
val1<- unlist(df1[,grep("P",colnames(df1))],use.names=FALSE)
?df1[,10:13]<- val1[indx1+seq_along(indx1)]
?colnames(df1)[10:13]<- colnames(df2)[10:13]
?identical(df1,df2)
#[1] TRUE


The "average" part is not clear.
For ex:
df2$OF1
# [1] 3 3 4 5 2 2 2 1 1 0

df2$P1
# [1] 10 13 16 19 22 25 28 31 34 37


Could you explain it in terms of the above values?


A.K.



________________________________
From: Ira Sharenow <irasharenow100 at yahoo.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Saturday, September 21, 2013 5:09 PM
Subject: Re: [R] Obtaining data from a different row of data frame



Arun,

Thanks for helping me improve my question.

I made a slight change to the data, so that the coincidence will not occur.

Please note that eventually I will have to write a function for a user. Also after my rewrite, I have better code, but I do not know how to get rid of the loop. Also eventually I will need to generalize and take the average of r rows above and below the row that this algorithm is attempting to retrieve. For example if r = 5 and the row 1 offset gets me to row 100, I will eventually need the price in rows 95 through 105. Yes, I realize that I need to deal with a number of annoying details such as possibly winding up with row -3.


> df1 = data.frame(matrix(rep(NA, 10*7), nrow = 10))
> Dates =? as.Date(c("2006-01-03", "2006-01-04", "2006-01-05", "2006-01-06", "2006-01-09", "2006-01-10", "2006-01-11", 
+??????????????????? "2006-01-12", "2006-01-13", "2006-01-16"), format = "%Y-%m-%d")
> P1 = seq(from = 10, by = 3, length.out = 10)
> P2 = seq(from = 100, by = 2, length.out = 10)
> OF1 = c(3,3,4,5,2,2,2,1,1,0)
> OF2 = c(5,3,4,2,1,2,2,1,1,0)
> df1 = data.frame(Dates = Dates, P1 = P1, P2 = P2, OF1 = OF1, OF2 = OF2)
> df1$newPrice1 = rep(NA, 10)
> df1$newPrice2 = rep(NA, 10)
> 
> df1
??????? Dates P1? P2 OF1 OF2 newPrice1 newPrice2
1? 2006-01-03 10 100?? 3?? 5??????? NA??????? NA
2? 2006-01-04 13 102?? 3?? 3??????? NA??????? NA
3? 2006-01-05 16 104?? 4?? 4??????? NA??????? NA
4? 2006-01-06 19 106?? 5?? 2??????? NA??????? NA
5? 2006-01-09 22 108?? 2?? 1??????? NA???? ???NA
6? 2006-01-10 25 110?? 2?? 2??????? NA??????? NA
7? 2006-01-11 28 112?? 2?? 2??????? NA??????? NA
8? 2006-01-12 31 114?? 1?? 1??????? NA??????? NA
9? 2006-01-13 34 116?? 1?? 1??????? NA??????? NA
10 2006-01-16 37 118?? 0?? 0??????? NA??????? NA
> 
> for(j in 2:3) {
+ df1[j+4] = df1[df1[,j+2] + row(df1)[,j], j]
+ }
> df1
??????? Dates P1? P2 OF1 OF2 newPrice1 newPrice2
1? 2006-01-03 10 100?? 3?? 5??????? 19?????? 110
2? 2006-01-04 13 102?? 3?? 3??????? 22?????? 108
3? 2006-01-05 16 104?? 4?? 4?????? ?28?????? 112
4? 2006-01-06 19 106?? 5?? 2??????? 34?????? 110
5? 2006-01-09 22 108?? 2?? 1??????? 28?????? 110
6? 2006-01-10 25 110?? 2?? 2??????? 31?????? 114
7? 2006-01-11 28 112?? 2?? 2??????? 34?????? 116
8? 2006-01-12 31 114?? 1?? 1??????? 34?????? 116
9? 2006-01-13 34 116?? 1?? 1??????? 37?????? 118
10 2006-01-16 37 118?? 0?? 0??????? 37?????? 118
> ?


> # Better code. Produces exactly the same results as above.
> for(j in 2:3) {
+ df1[j+4] = df1[df1[,j+2] + row(df1)[,j], j]
+ }
> df1 
On 9/21/2013 1:39 PM, arun wrote:

Hi,
Your example dataset could be confusing as: with(df1,P1+OF1)
# [1] 13 14 16 18 16 17 18 18 19 19
?with(df1,P2+OF2)
# [1] 105 104 106 105 105 107 108 108 109 109 which is the same as:
?df1$newPrice1
# [1] 13 14 16 18 16 17 18 18 19 19
?df1$newPrice2
# [1] 105 104 106 105 105 107 108 108 109 109 ----- Original Message -----
From: Ira Sharenow <irasharenow100 at yahoo.com> To: r-help at r-project.org Cc: 
Sent: Saturday, September 21, 2013 11:30 AM
Subject: [R] Obtaining data from a different row of data frame I have a large data frame with 2,000 rows and 600 columns. I can write 
loops to solve a smaller problem, but I need a better strategy for this 
data frame. Below is a simple example with just two stocks. In the data frame, each row represents a trading day. The first column 
is dates. The next group of columns represents the prices of the stocks 
on the specified dates. The next group of columns represents how many 
trading days I wish to offset. So if the first trading day is 2006-01-03 
and OF1 == 3, then I need to go to row 1+3 and get the price in column 
P1. The result is placed in row 1 of column 6. df1 = data.frame(matrix(rep(NA, 10*7), nrow = 10)) Dates =as.Date(c("2006-01-03", "2006-01-04", "2006-01-05", "2006-01-06", 
"2006-01-09", "2006-01-10", "2006-01-11", "2006-01-12", "2006-01-13", "2006-01-16"), format = "%Y-%m-%d") P1 = 10:19 P2 = 100:109 OF1 = c(3,3,4,5,2,2,2,1,1,0) OF2 = c(5,3,4,2,1,2,2,1,1,0) df1 = data.frame(Dates = Dates, P1 = P1, P2 = P2, OF1 = OF1, OF2 = OF2) df1$newPrice1 = rep(NA, 10) df1$newPrice2 = rep(NA, 10) for(j in 6:7) { for(i in 1:10 ) { rowNumber = i + df1[i,j-2] #print(rowNumber) df1[i,j] = df1[rowNumber, j-4] } # end i loop } # end j loop df1 
>df1 
>Dates P1P2 OF1 OF2 newPrice1 newPrice2 1 2006-01-03 10 1003513105 22006-01-04 11 1013314104 32006-01-05 12 1024416106 42006-01-06 13 1035218105 52006-01-09 14 1042116105 62006-01-10 15 1052217107 72006-01-11 16 1062218108 82006-01-12 17 1071118108 92006-01-13 18 1081119109 10 2006-01-16 19 1090019109 ??? [[alternative HTML version deleted]] ______________________________________________ R-help at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the posting guide http://www.R-project.org/posting-guide.html and provide commented, minimal, self-contained, reproducible code. ???????


From spencer.graves at structuremonitoring.com  Sun Sep 22 03:09:02 2013
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Sat, 21 Sep 2013 18:09:02 -0700
Subject: [R] Read a Google Spreadsheet?
In-Reply-To: <CANz9Z_LL7UJeDAtubow+JFDpiPcRj8p-AxwwM1HTmFhxn_nnCA@mail.gmail.com>
References: <5227B050.1080502@structuremonitoring.com>
	<CA+vqiLEbZK_3-oGD3DjjVz3n9NsShMFUvTMP+-MqBHkzu8eNww@mail.gmail.com>
	<5227E020.4000401@structuremonitoring.com>
	<CANz9Z_LL7UJeDAtubow+JFDpiPcRj8p-AxwwM1HTmFhxn_nnCA@mail.gmail.com>
Message-ID: <523E432E.5000309@structuremonitoring.com>

Hi, Josh and Ista:


       Thanks very much for the replies.  I just downloaded and 
installed Java x64, and library(xlsx) worked with 64-bit R when it 
hadn't before.


       This gives me hope I can fix a problem with 
writeFindFn2xls{sos}.  It works with 32-bit R, and complains that 
"odbcConnectExcel is only usable with 32-bit Windows." (Problems with 
taking the wrong lesson:  I may have erroneously applied that 
contraindication for RODBC to Java.)


       Thanks again.
       Spencer


On 9/4/2013 6:50 PM, Joshua Wiley wrote:
> Hi Spencer,
>
> It really is not very hard, and I have never had issue with it:
>
> http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html
>
> Just download the x86 and x64 versions for your OS and install.  Worst
> case, you need to add the directory to the PATH variable in Windows.
>
> I do this regularly so I can use/test either version of R.
>
> Cheers,
>
> Josh
>
> P.S. Emacs + ESS allows for different versions of R and it is not too
> difficult to use the 64 or 32 bit version... M-x
> R-version-architecture
>
>
> On Wed, Sep 4, 2013 at 6:36 PM, Spencer Graves
> <spencer.graves at structuremonitoring.com> wrote:
>> On 9/4/2013 6:09 PM, Ista Zahn wrote:
>>> Hi Spencer,
>>>
>>> Why don't you want to install 64bit Java?
>>
>>
>>        That may be a reasonable approach.
>>
>>
>>        I may have Java confused with something else, but I remember hearing
>> that it was difficult or unwise to try to install both 32- and 64-bit
>> versions of something like Java or Java Script on the same Windows operating
>> system.  If I need to uninstall 32-bit Java to install 64-bit, who knows
>> what else I could break.  I'm a statistician, not an information
>> technologist:  If I spend more time playing with Java, I'll have less time
>> for other things I want to do.
>>
>>
>>        Thanks for the reply.
>>        Spencer
>>>
>>> On Wed, Sep 4, 2013 at 6:12 PM, Spencer Graves
>>> <spencer.graves at structuremonitoring.com> wrote:
>>>> Hello, All:
>>>>
>>>>
>>>> What do you recommend for reading a Google Spreadsheet into R? I didn't
>>>> find
>>>> anything useful using library(sos); findFn('google spreadsheet').
>>>>
>>>>
>>>> I can solve the problem by downloading the file either as *.ods or *.xlsx
>>>> format, then opening it and saving it as *.xls, then using
>>>> read.xls{gdata}.
>>>>
>>>>
>>>> Alternatives I haven't tried use read.xlsx{xlsx} and
>>>> readWorksheetFromFile{XLConnect} with 32-bit R. Neither of these work for
>>>> me
>>>> with 64-bit R, because they can't find an appropriate rJava on my
>>>> computer;
>>>> see below. (I've been using 64-bit R with Emacs, so switching to 32-bit R
>>>> is
>>>> not completely trivial.) Similarly, read.gnumeric.sheet{gnumeric}
>>>> requires
>>>> the "external program, ssconvert", which seems not to be available on my
>>>> computer or installed for 64-bit R.
>>>>
>>>>
>>>> What do you suggest? Avoid 64-bit R unless I really need it? That seems
>>>> to
>>>> be the message I'm getting from this. (The writeFindFn2xls{sos} also
>>>> works
>>>> in 32-bit R but fails in 64-bit apparently for the same reason.)
>>>>
>>>>
>>>> Thanks,
>>>> Spencer
>>>>
>>>>
>>>>> library(xlsx)
>>>> Loading required package: xlsxjars
>>>> Loading required package: rJava
>>>> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>>>> call: fun(libname, pkgname)
>>>> error: No CurrentVersion entry in Software/JavaSoft registry! Try
>>>> re-installing Java and make sure R and Java have matching architectures.
>>>> Error: package ?rJava? could not be loaded
>>>>> library(XLConnect)
>>>> Loading required package: rJava
>>>> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>>>> call: fun(libname, pkgname)
>>>> error: No CurrentVersion entry in Software/JavaSoft registry! Try
>>>> re-installing Java and make sure R and Java have matching architectures.
>>>> Error: package ?rJava? could not be loaded
>>>>> sessionInfo()
>>>> R version 3.0.1 (2013-05-16)
>>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>>
>>>> locale:
>>>> [1] LC_COLLATE=English_United States.1252
>>>> [2] LC_CTYPE=English_United States.1252
>>>> [3] LC_MONETARY=English_United States.1252
>>>> [4] LC_NUMERIC=C
>>>> [5] LC_TIME=English_United States.1252
>>>>
>>>> attached base packages:
>>>> [1] stats graphics grDevices utils datasets methods base
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Sun Sep 22 03:18:47 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 21 Sep 2013 18:18:47 -0700 (PDT)
Subject: [R] Obtaining data from a different row of data frame
In-Reply-To: <523E0AF3.8050904@yahoo.com>
References: <523DBBA4.7070301@yahoo.com>
	<1379795975.60563.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<523E0AF3.8050904@yahoo.com>
Message-ID: <1379812727.49785.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi Ira,

#Speed comparison 


set.seed(29)
?df2<- data.frame(Dates=seq(as.Date("2006-01-03"),length.out=2000,by="1 day"),cbind(matrix(sample(10:120,2000*300,replace=TRUE),ncol=300),matrix(sample(0:6,2000*300,replace=TRUE),ncol=300)))
?colnames(df2)[2:301]<- paste0("P",1:300)
?colnames(df2)[302:601]<- paste0("OF",1:300)
df2[2000,grep("OF",colnames(df2))]<-0
?df2[1995:1999,grep("OF",colnames(df2))]<-1

df3<- df2

df2[,602:901]<-NA
colnames(df2)[602:901]<- paste0("newPrice",1:300)
dim(df2)
#[1] 2000? 901

system.time({
for(j in grep("^P",colnames(df2))) {
?df2[j+600] = df2[df2[,j+300] + row(df2)[,j], j]
?}
})
#? user? system elapsed 
# 12.292?? 0.256? 12.576 
system.time({
indx1<- unlist(df3[,grep("OF",colnames(df3))],use.names=FALSE)
val1<- unlist(df3[,grep("P",colnames(df3))],use.names=FALSE)
?df3[,602:901]<- val1[indx1+seq_along(indx1)]
?colnames(df3)[602:901]<- colnames(df2)[602:901]
})
#? user? system elapsed 
#? 0.600?? 0.016?? 0.616 
identical(df2,df3)
#[1] TRUE

A.K.


________________________________
From: Ira Sharenow <irasharenow100 at yahoo.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Saturday, September 21, 2013 5:09 PM
Subject: Re: [R] Obtaining data from a different row of data frame



Arun,

Thanks for helping me improve my question.

I made a slight change to the data, so that the coincidence will not occur.

Please note that eventually I will have to write a function for a user. Also after my rewrite, I have better code, but I do not know how to get rid of the loop. Also eventually I will need to generalize and take the average of r rows above and below the row that this algorithm is attempting to retrieve. For example if r = 5 and the row 1 offset gets me to row 100, I will eventually need the price in rows 95 through 105. Yes, I realize that I need to deal with a number of annoying details such as possibly winding up with row -3.


> df1 = data.frame(matrix(rep(NA, 10*7), nrow = 10))
> Dates =? as.Date(c("2006-01-03", "2006-01-04", "2006-01-05", "2006-01-06", "2006-01-09", "2006-01-10", "2006-01-11", 
+??????????????????? "2006-01-12", "2006-01-13", "2006-01-16"), format = "%Y-%m-%d")
> P1 = seq(from = 10, by = 3, length.out = 10)
> P2 = seq(from = 100, by = 2, length.out = 10)
> OF1 = c(3,3,4,5,2,2,2,1,1,0)
> OF2 = c(5,3,4,2,1,2,2,1,1,0)
> df1 = data.frame(Dates = Dates, P1 = P1, P2 = P2, OF1 = OF1, OF2 = OF2)
> df1$newPrice1 = rep(NA, 10)
> df1$newPrice2 = rep(NA, 10)
> 
> df1
??????? Dates P1? P2 OF1 OF2 newPrice1 newPrice2
1? 2006-01-03 10 100?? 3?? 5??????? NA??????? NA
2? 2006-01-04 13 102?? 3?? 3??????? NA??????? NA
3? 2006-01-05 16 104?? 4?? 4??????? NA??????? NA
4? 2006-01-06 19 106?? 5?? 2??????? NA??????? NA
5? 2006-01-09 22 108?? 2?? 1??????? NA???? ???NA
6? 2006-01-10 25 110?? 2?? 2??????? NA??????? NA
7? 2006-01-11 28 112?? 2?? 2??????? NA??????? NA
8? 2006-01-12 31 114?? 1?? 1??????? NA??????? NA
9? 2006-01-13 34 116?? 1?? 1??????? NA??????? NA
10 2006-01-16 37 118?? 0?? 0??????? NA??????? NA
> 
> for(j in 2:3) {
+ df1[j+4] = df1[df1[,j+2] + row(df1)[,j], j]
+ }
> df1
??????? Dates P1? P2 OF1 OF2 newPrice1 newPrice2
1? 2006-01-03 10 100?? 3?? 5??????? 19?????? 110
2? 2006-01-04 13 102?? 3?? 3??????? 22?????? 108
3? 2006-01-05 16 104?? 4?? 4?????? ?28?????? 112
4? 2006-01-06 19 106?? 5?? 2??????? 34?????? 110
5? 2006-01-09 22 108?? 2?? 1??????? 28?????? 110
6? 2006-01-10 25 110?? 2?? 2??????? 31?????? 114
7? 2006-01-11 28 112?? 2?? 2??????? 34?????? 116
8? 2006-01-12 31 114?? 1?? 1??????? 34?????? 116
9? 2006-01-13 34 116?? 1?? 1??????? 37?????? 118
10 2006-01-16 37 118?? 0?? 0??????? 37?????? 118
> ?


> # Better code. Produces exactly the same results as above.
> for(j in 2:3) {
+ df1[j+4] = df1[df1[,j+2] + row(df1)[,j], j]
+ }
> df1 
On 9/21/2013 1:39 PM, arun wrote:

Hi,
Your example dataset could be confusing as: with(df1,P1+OF1)
# [1] 13 14 16 18 16 17 18 18 19 19
?with(df1,P2+OF2)
# [1] 105 104 106 105 105 107 108 108 109 109 which is the same as:
?df1$newPrice1
# [1] 13 14 16 18 16 17 18 18 19 19
?df1$newPrice2
# [1] 105 104 106 105 105 107 108 108 109 109 ----- Original Message -----
From: Ira Sharenow <irasharenow100 at yahoo.com> To: r-help at r-project.org Cc: 
Sent: Saturday, September 21, 2013 11:30 AM
Subject: [R] Obtaining data from a different row of data frame I have a large data frame with 2,000 rows and 600 columns. I can write 
loops to solve a smaller problem, but I need a better strategy for this 
data frame. Below is a simple example with just two stocks. In the data frame, each row represents a trading day. The first column 
is dates. The next group of columns represents the prices of the stocks 
on the specified dates. The next group of columns represents how many 
trading days I wish to offset. So if the first trading day is 2006-01-03 
and OF1 == 3, then I need to go to row 1+3 and get the price in column 
P1. The result is placed in row 1 of column 6. df1 = data.frame(matrix(rep(NA, 10*7), nrow = 10)) Dates =as.Date(c("2006-01-03", "2006-01-04", "2006-01-05", "2006-01-06", 
"2006-01-09", "2006-01-10", "2006-01-11", "2006-01-12", "2006-01-13", "2006-01-16"), format = "%Y-%m-%d") P1 = 10:19 P2 = 100:109 OF1 = c(3,3,4,5,2,2,2,1,1,0) OF2 = c(5,3,4,2,1,2,2,1,1,0) df1 = data.frame(Dates = Dates, P1 = P1, P2 = P2, OF1 = OF1, OF2 = OF2) df1$newPrice1 = rep(NA, 10) df1$newPrice2 = rep(NA, 10) for(j in 6:7) { for(i in 1:10 ) { rowNumber = i + df1[i,j-2] #print(rowNumber) df1[i,j] = df1[rowNumber, j-4] } # end i loop } # end j loop df1 
>df1 
>Dates P1P2 OF1 OF2 newPrice1 newPrice2 1 2006-01-03 10 1003513105 22006-01-04 11 1013314104 32006-01-05 12 1024416106 42006-01-06 13 1035218105 52006-01-09 14 1042116105 62006-01-10 15 1052217107 72006-01-11 16 1062218108 82006-01-12 17 1071118108 92006-01-13 18 1081119109 10 2006-01-16 19 1090019109 ??? [[alternative HTML version deleted]] ______________________________________________ R-help at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the posting guide http://www.R-project.org/posting-guide.html and provide commented, minimal, self-contained, reproducible code. ???????


From dulcalma at bigpond.com  Sun Sep 22 05:00:16 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Sun, 22 Sep 2013 13:00:16 +1000
Subject: [R] lattice: double y - problem changing axis color
	after	doubleYScale
In-Reply-To: <11019DCE9B47004F90B2D9C62FF15792025E9E8D@ebox-prod-srv04.win.su.se>
References: <11019DCE9B47004F90B2D9C62FF15792025E9E8D@ebox-prod-srv04.win.su.se>
Message-ID: <000001ceb73f$dd93b2b0$98bb1810$@bigpond.com>

Hi  Anna

I am not sure what you want but the following should get you part of the way

I prefer to keep all my parameters within the function rather than use
themes.

useOuterStrips(strip      = strip.custom(#factor.levels = ,
                                         par.strip.text =
list(fontfamily="serif" )),
               strip.left = strip.custom(#factor.levels = ,
                                         par.strip.text =
list(fontfamily="serif" )),
xyplot(mean ~ Week | Station*fyear, data= SummPdata,
                col="black",
                pch=2,
                cex=1.1,
                lty=2,
                par.settings = list(strip.background = list(col =
"transparent"),
                                    add.text = list(fontfamily = "serif"
)),
                #strip      = strip.custom(#factor.levels = ,
                #                         par.strip.text =
list(fontfamily="serif" )),
               scales = list(alternating = c(3,3),
                              fontfamily = "serif"),
                ylab = list(text = "Pc", fontfamily = "serif"),
                xlab=list(text = "Week", fontfamily = "serif"),
                key  = list(text = list(labels = c("P","N")),
                            points = list(pch = c(2,20)),
                            lines  = list(lty = c(1,2))),
                type = "o",
                ylim = c(0,70),
                subscripts = TRUE,
                panel = function(x,y, subscripts, ...){
                          panel.xyplot(x,y, ...)
                          # sd
                          # upper
                          panel.arrows(x0 = x, x1 = x,
                                       y0 = y, y1 = y+ SummPdata[subscripts,
"sd"]/2, angle = 90, length = 0.04)
                          # lower
                          panel.arrows(x0 = x, x1 = x,
                                       y0 = y, y1 = y- SummPdata[subscripts,
"sd"]/2, angle = 90, length = 0.04)

                          panel.xyplot(x+0.1, SummNdata[subscripts,"mean"],
type ="o",pch = 20, lty =1, col = "black")
                          # sd
                          # upper
                          panel.arrows(x0 = x+0.1, x1 = x+0.1,
                                      y0 = SummNdata[subscripts,"mean"], y1
= SummNdata[subscripts,"mean"] + SummNdata[subscripts, "sd"]/2, angle = 90,
length = 0.04)
                          # lower
                          panel.arrows(x0 = x+0.1, x1 = x+0.1,
                                       y0 = SummNdata[subscripts,"mean"], y1
= SummNdata[subscripts,"mean"]- SummNdata[subscripts, "sd"]/2, angle = 90,
length = 0.04)

                        }# panel
                )#
) ## useOuterStrips

Note that I offset the N data so that the error bars are more legible

For sd I just divided them by 2 so you will have to work out what you
require

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Anna Zakrisson Braeunlich
Sent: Thursday, 19 September 2013 20:21
To: r-help at r-project.org
Subject: [R] lattice: double y - problem changing axis color after
doubleYScale

Hi,

I have had some troubles using doubleYScale. No matter what I try, I cant
manage to change the color of the y-axis in the end. I have to produce a
black and white plot. There is also something I do not understand regarding
fontfamilyj="serif" when using it in:
strip=strip.custom()

Maybe someone has a better idea for defining which line and dots belong to
which y-axis when not using a colorcode than the one I had.

I have annotated my questions in the code below.

Thank you for your time!


Here is some dummy data:

Ndata <- data.frame(
  Ncellpercent = rnorm(400, mean = rep(c(14, 18, 65), each = 40),
               sd = rep(c(1, 3, 6), each = 40)),
  fyear = rep(c('2007', '2008'), each = 100*2),
  Station = sample(c('B1', 'H2', 'H3', 'H4'), 400, replace = TRUE),
  Week = sample(c('19', '21', '23', '25'), 400, replace = TRUE))

Pdata <- data.frame(
  Ppercentcell = rnorm(400, mean = rep(c(4, 17, 22), each = 40),
               sd = rep(c(0.1, 0.2, 0.4), each = 40)),
  fyear = rep(c('2007', '2008'), each = 100*2),
  Station = sample(c('B1', 'H2', 'H3', 'H4'), 400, replace = TRUE),
  Week = sample(c('19', '21', '23', '25'), 400, replace = TRUE))

SummNdata <- ddply(Ndata, .(Week, fyear, Station), summarise,
                   mean = mean(Ncellpercent),
                   sd = sd(Ncellpercent))
names(Pdata)
SummPdata <- ddply(Pdata, .(Week, fyear, Station), summarise,
                   mean = mean(Ppercentcell),
                   sd = sd(Ppercentcell))
library(lattice)
library(latticeExtra)
library(HH)

font.settings <- list( font = 1, cex = 1.2, fontfamily = "serif")

my.theme <- list(
  par.xlab.text = font.settings,
  par.ylab.text = font.settings,
  axis.text = font.settings,
  par.sub=font.settings)

plotN <- xyplot(mean ~ Week | Station*fyear,
                col="black",
                pch=1,
                cex=1.1,
                lty=1,
                strip = strip.custom(bg = 'white', style=1), # why can I not
use fontfamily="serif" here ???
                key=list(text=list(c(""),
                                   col=c("black")),
                         points=list(pch=1, lty=1, cex=1.5,
                                     col=c("black")),
                         columns=1, border=F,
                         x = 0.02, y = 0.55, corner = c(2, 2),
                         title="", cex.title=1.3),
                ylab = ("Nc"),
                xlab="Week",
                data= SummNdata,type="o",
                par.settings = my.theme) plotN # I would like to add the
standard deviations (sd) to the plot. I have tried some stuff, # but for
some reason, it does not seem to work. How would I go about this?


plotP <- xyplot(mean ~ Week | Station*fyear,
                col="black",
                pch=2,
                cex=1.1,
                lty=2,
                strip = strip.custom(bg = 'white', style=1), # why can I not
use fontfamily="serif" here ???
                key=list(text=list(c(""),
                                   col=c("black")),
                         points=list(pch=1, lty=1, cex=1.5,
                                     col=c("black")),
                         columns=1, border=F,
                         x = 0.2, y = 0.2, corner = c(2, 2),
                         title="", cex.title=1.3),
                ylab = ("Pc"),
                xlab="Week",
                data= SummPdata,type="o",
                par.settings = my.theme) plotP

doubleYScale(plotN, plotP, add.ylab2 = TRUE)  #Why can I not change the axis
color by adding to this argument?

# I want the y1 and y2 axes to be defined not by color, but by shape and
linetype.
# I have managed to draw the shapes (defined by Nc and Pc) by the y1 and y2
axes, but I do not manage to get the lines # though the shape - ideas?
# Alternative ways that are not based on color (I have to do this black and
white).
# Is there possible to add shapes to the axis text? such as:
# --O-- Nc  on the left y-axis (but with lty=1: I could not do a non-dotted
line on the keybord).

with kind regards

Anna Zakrisson Braeunlich
PhD student

Department of Ecology, Environment and Plant Sciences Stockholm University
Svante Arrheniusv. 21A
SE-106 91 Stockholm
Sweden/Sverige

Lives in Berlin.
For paper mail:
Katzbachstr. 21
D-10965, Berlin - Kreuzberg
Germany/Deutschland

E-mail: anna.zakrisson at su.se
Tel work: +49-(0)3091541281
Mobile: +49-(0)15777374888
LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b

><((((:>`. .  `. . `. . ><((((:>`. .  `. . `. .><((((:>`. .  
>`. . `. .><((((:>

	[[alternative HTML version deleted]]


From skiyoshi2001 at yahoo.com  Sun Sep 22 05:12:34 2013
From: skiyoshi2001 at yahoo.com (Kiyoshi Sasaki)
Date: Sat, 21 Sep 2013 20:12:34 -0700 (PDT)
Subject: [R] Conditioning plots (wth coplot function) with logistic
	regression curves
Message-ID: <1379819554.56426.YahooMailNeo@web142404.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130921/f0998a05/attachment.pl>

From caciquesamurai at gmail.com  Sun Sep 22 05:53:17 2013
From: caciquesamurai at gmail.com (Raoni Rodrigues)
Date: Sun, 22 Sep 2013 00:53:17 -0300
Subject: [R] Grouping variables by a irregular time interval
In-Reply-To: <CAGtwFe3kR2vr6PAiH_HyFWG3eazdyV1CYw+DwppBhZbwWxgbKg@mail.gmail.com>
References: <CAGtwFe3kR2vr6PAiH_HyFWG3eazdyV1CYw+DwppBhZbwWxgbKg@mail.gmail.com>
Message-ID: <CAGtwFe1Y8RNXqD5wuiW5ngF-3-uMWvGkYDS_zs_dLSU_=bfvBA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130922/7e6d42e6/attachment.pl>

From smartpink111 at yahoo.com  Sun Sep 22 06:07:47 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 21 Sep 2013 21:07:47 -0700 (PDT)
Subject: [R] Obtaining data from a different row of data frame
In-Reply-To: <523E65A7.9070707@yahoo.com>
References: <523DBBA4.7070301@yahoo.com>
	<1379795975.60563.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<523E0AF3.8050904@yahoo.com>
	<1379812727.49785.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<523E4DFD.3030502@yahoo.com>
	<1379815656.34841.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<523E561E.9060507@yahoo.com>
	<1379818041.24463.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<523E6307.8070705@yahoo.com>
	<1379820626.88190.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<523E65A7.9070707@yahoo.com>
Message-ID: <1379822867.75018.YahooMailNeo@web142601.mail.bf1.yahoo.com>



Hi,
May be you can try this:
Change the 

df1<- structure(list(Dates = structure(c(13151, 13152, 13153, 13154,
?13157, 13158, 13159, 13160, 13161, 13164), class = "Date"), P1 = c(10,
?13, 16, 19, 22, 25, 28, 31, 34, 37), P2 = c(100, 102, 104, 106,
?108, 110, 112, 114, 116, 118), P3 = c(90, 94, 98, 102, 106, 110,
?114, 118, 122, 126), P4 = c(70, 75, 80, 85, 90, 95, 100, 105,
?110, 115), OF1 = c(3, 3, 4, 5, 2, 2, 2, 1, 1, 5), OF2 = c(5,
?3, 4, 2, 1, 2, 2, 1, 1, 0), OF3 = c(4, 3, 4, 1, 3, 2, 2, 1, 1,
?0), OF4 = c(3, 5, 4, 2, 3, 1, 2, 1, 1, 0)), .Names = c("Dates",
?"P1", "P2", "P3", "P4", "OF1", "OF2", "OF3", "OF4"), row.names = c(NA,
?-10L), class = "data.frame")
df1$OF2[9]<-4

df2<- df1
?df2[,10:13]<- NA
colnames(df2)[10:13]<- paste0("newPrice",1:4)

##your code

for(j in 2:5) {
?df2[j+8] = df2[df2[,j+4] + row(df2)[,j], j]
?}
?vec1<- 5:1 ##change values according to the range of actual values in your rows
?vec2<- 6:10 ##change accordingly
df1[vec2,grep("OF",colnames(df1))]<- t(sapply(seq_along(vec1),function(i) {x1<-as.matrix(df1[vec2[i],grep("OF",colnames(df1))]); x1[x1>vec1[i]]<-NA; x1}))

indx1<- unlist(df1[,grep("OF",colnames(df1))],use.names=FALSE)
val1<- unlist(df1[,grep("P",colnames(df1))],use.names=FALSE)
?df1[,10:13]<- val1[indx1+seq_along(indx1)]
?colnames(df1)[10:13]<- colnames(df2)[10:13]
identical(df1[,10:13],df2[,10:13])
#[1] TRUE
A.K.

________________________________
From: Ira Sharenow <irasharenow100 at yahoo.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Saturday, September 21, 2013 11:36 PM
Subject: Re: [R] Obtaining data from a different row of data frame



Arun,

Yes, I definitely want NA, and I certainly do not want to pick off values from a different stock.

I set up the example the way I did because I was more concerned about finding the values than dealing with these bad cases. I figured I could work them out later and with my strategy I get the NA values.

I had not considered your approach.

Ira 
On 9/21/2013 8:30 PM, arun wrote:

Hi Ira, This info was not provided before.? In fact, I wanted to ask about this in cases where the last row entries are not 0.? So, you wanted the newPrices to be NA's for the corresponding rows, right?? ________________________________
From: Ira Sharenow <irasharenow100 at yahoo.com> To: arun <smartpink111 at yahoo.com> Sent: Saturday, September 21, 2013 11:24 PM
Subject: Re: [R] Obtaining data from a different row of data frame Arun, Thanks. I appreciate the details. I am learning a lot. But there may be a bug in your code. This information is gathered on an ongoing basis. So on September 1, 2013 a prediction for A1 stock may have been made and the prediction date is December 15, 2013, which has not yet occurred. My method produces NA. For example go to? OF4 and change the last entry from 0 to 6. Ira 
># change OF1[10] = 5 <------
df1<- structure(list(Dates = structure(c(13151, 13152, 
>????13153, 13154, 
+ 13157, 13158, 13159, 13160, 13161, 13164), class = "Date"), P1 =
????c(10, 
+ 13, 16, 19, 22, 25, 28, 31, 34, 37), P2 = c(100, 102, 104, 106, 
+ 108, 110, 112, 114, 116, 118), P3 = c(90, 94, 98, 102, 106, 110, 
+ 114, 118, 122, 126), P4 = c(70, 75, 80, 85, 90, 95, 100, 105, 
+ 110, 115), OF1 = c(3, 3, 4, 5, 2, 2, 2, 1, 1, 5), OF2 = c(5, 
+ 3, 4, 2, 1, 2, 2, 1, 1, 0), OF3 = c(4, 3, 4, 1, 3, 2, 2, 1, 1, 
+ 0), OF4 = c(3, 5, 4, 2, 3, 1, 2, 1, 1, 0)), .Names = c("Dates", 
+ "P1", "P2", "P3", "P4", "OF1", "OF2", "OF3", "OF4"), row.names =
????c(NA, 
+ -10L), class = "data.frame") 
>#Splitting the code grep("OF",colnames(df1)) #gives the column numbers? having "OF" 
>????as column names
[1] 6 7 8 9 
>[1] 6 7 8 9 
>Error: unexpected '[' in "[" 
>#Subset those columns ? df1[,grep("OF",colnames(df1))] 
>?? OF1 OF2 OF3 OF4
1??? 3?? 5?? 4?? 3
2??? 3?? 3?? 3?? 5
3??? 4?? 4?? 4?? 4
4??? 5?? 2?? 1?? 2
5??? 2?? 1?? 3?? 3
6??? 2?? 2?? 2?? 1
7??? 2?? 2?? 2?? 2
8??? 1?? 1?? 1?? 1
9??? 1?? 1?? 1?? 1
10??5?? 0?? 0?? 0 
>#unlist those columns to create a vector
? indx1<- 
>????unlist(df1[,grep("OF",colnames(df1))],use.names=FALSE) 
>indx1 
>?[1] 3 3 4 5 2 2 2 1 1 5 5 3 4 2 1 2 2 1 1 0 4 3 4 1 3 2 2 1 1 0 3 5
????4 2 3 1 2 1 1 0 
>#Same steps done with columns having names "P"
val1<- unlist(df1[,grep("P",colnames(df1))],use.names=FALSE)
val1 
>?[1]? 10? 13? 16? 19? 22? 25? 28? 31? 34? 37 100 102 104 106 108 110
????112 114 116 118? 90? 94? 98 102 106
[26] 110 114 118 122 126? 70? 75? 80? 85? 90? 95 100 105 110 115 
>? val1[indx1+seq_along(indx1)] 
>?[1]? 19? 22? 28? 34? 28? 31? 34? 34? 37 108 110 108 112 110 110 114
????116 116 118 118 106 106 114 106 118
[26] 118 122 122 126 126? 85 100 100? 95 105 100 110 110 115 115 
>df1[,10:13]<- val1[indx1+seq_along(indx1)]
? df1 
>??????? Dates P1? P2? P3? P4 OF1 OF2 OF3 OF4 V10 V11 V12 V13
1? 2006-01-03 10 100? 90? 70?? 3?? 5?? 4?? 3? 19 110 106? 85
2? 2006-01-04 13 102? 94? 75?? 3?? 3?? 3?? 5? 22 108 106 100
3? 2006-01-05 16 104? 98? 80?? 4?? 4?? 4?? 4? 28 112 114 100
4? 2006-01-06 19 106 102? 85?? 5?? 2?? 1?? 2? 34 110 106? 95
5? 2006-01-09 22 108 106? 90?? 2?? 1?? 3?? 3? 28 110 118 105
6? 2006-01-10 25 110 110? 95?? 2?? 2?? 2?? 1? 31 114 118 100
7? 2006-01-11 28 112 114 100?? 2?? 2?? 2?? 2? 34 116 122 110
8? 2006-01-12 31 114 118 105?? 1?? 1?? 1?? 1? 34 116 122 110
9? 2006-01-13 34 116 122 110?? 1?? 1?? 1?? 1? 37 118 126 115
10 2006-01-16 37 118 126 115?? 5?? 0?? 0?? 0 108 118 126 115 On 9/21/2013 7:47 PM, arun wrote: Hi Ira, The code I used was based on how you calculated the values from your previous explanation. Let us, take ##dput??df1<- structure(list(Dates = structure(c(13151, 13152, 13153, 13154, 
13157, 13158, 13159, 13160, 13161, 13164), class = "Date"), P1 = c(10, 
13, 16, 19, 22, 25, 28, 31, 34, 37), P2 = c(100, 102, 104, 106, 
108, 110, 112, 114, 116, 118), P3 = c(90, 94, 98, 102, 106, 110, 
114, 118, 122, 126), P4 = c(70, 75, 80, 85, 90, 95, 100, 105, 
110, 115), OF1 = c(3, 3, 4, 5, 2, 2, 2, 1, 1, 0), OF2 = c(5, 
3, 4, 2, 1, 2, 2, 1, 1, 0), OF3 = c(4, 3, 4, 1, 3, 2, 2, 1, 1, 
0), OF4 = c(3, 5, 4, 2, 3, 1, 2, 1, 1, 0)), .Names = c("Dates", 
"P1", "P2", "P3", "P4", "OF1", "OF2", "OF3", "OF4"), row.names = c(NA, 
-10L), class = "data.frame") #Splitting the code grep("OF",colnames(df1)) #gives the column numbers? having "OF" as column names
[1] 6 7 8 9 #Subset those columns ?df1[,grep("OF",colnames(df1))]
?? OF1 OF2 OF3 OF4
1??? 3?? 5?? 4?? 3
2??? 3?? 3?? 3?? 5
3??? 4?? 4?? 4?? 4
4??? 5?? 2?? 1?? 2
5??? 2?? 1?? 3?? 3
6??? 2?? 2?? 2?? 1
7??? 2?? 2?? 2?? 2
8??? 1?? 1?? 1?? 1
9??? 1?? 1?? 1?? 1
10?? 0?? 0?? 0?? 0 #unlist those columns to create a vector
?indx1<- unlist(df1[,grep("OF",colnames(df1))],use.names=FALSE)
indx1
# [1] 3 3 4 5 2 2 2 1 1 0 5 3 4 2 1 2 2 1 1 0 4 3 4 1 3 2 2 1 1 0 3 5 4 2 3 1 2 1
#[39] 1 0 #Same steps done with columns having names "P"
val1<- unlist(df1[,grep("P",colnames(df1))],use.names=FALSE)
val1
# [1]? 10? 13? 16? 19? 22? 25? 28? 31? 34? 37 100 102 104 106 108 110 112 114 116
#[20] 118? 90? 94? 98 102 106 110 114 118 122 126? 70? 75? 80? 85? 90? 95 100 105
#[39] 110 115
indx1+seq_along(indx1)? #get the index 
# [1]? 4? 5? 7? 9? 7? 8? 9? 9 10 10 16 15 17 16 16 18 19 19 20 20 25 25 27 25 28
#[26] 28 29 29 30 30 34 37 37 36 38 37 39 39 40 40
?val1[indx1+seq_along(indx1)]
# [1]? 19? 22? 28? 34? 28? 31? 34? 34? 37? 37 110 108 112 110 110 114 116 116 118
#[20] 118 106 106 114 106 118 118 122 122 126 126? 85 100 100? 95 105 100 110 110
#[39] 115 115 df1[,10:13]<- val1[indx1+seq_along(indx1)]
?df1
??????? Dates P1? P2? P3? P4 OF1 OF2 OF3 OF4 V10 V11 V12 V13
1? 2006-01-03 10 100? 90? 70?? 3?? 5?? 4?? 3? 19 110 106? 85
2? 2006-01-04 13 102? 94? 75?? 3?? 3?? 3?? 5? 22 108 106 100
3? 2006-01-05 16 104? 98? 80?? 4?? 4?? 4?? 4? 28 112 114 100
4? 2006-01-06 19 106 102? 85?? 5?? 2?? 1?? 2? 34 110 106? 95
5? 2006-01-09 22 108 106? 90?? 2?? 1?? 3?? 3? 28 110 118 105
6? 2006-01-10 25 110 110? 95?? 2?? 2?? 2?? 1? 31 114 118 100
7? 2006-01-11 28 112 114 100?? 2?? 2?? 2?? 2? 34 116 122 110
8? 2006-01-12 31 114 118 105?? 1?? 1?? 1?? 1? 34 116 122 110
9? 2006-01-13 34 116 122 110?? 1?? 1?? 1?? 1? 37 118 126 115
10 2006-01-16 37 118 126 115?? 0?? 0?? 0?? 0? 37 118 126 115 Hope it helps. A.K.????? ????


From lmramba at ufl.edu  Sun Sep 22 07:07:31 2013
From: lmramba at ufl.edu (Laz)
Date: Sun, 22 Sep 2013 01:07:31 -0400
Subject: [R] Creating rectangular plots with x and y coordinates and
 treatments from a matrix for a randomized block design
Message-ID: <523E7B13.1020705@ufl.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130922/3525640f/attachment.pl>

From lmramba at ufl.edu  Sun Sep 22 07:18:37 2013
From: lmramba at ufl.edu (Laz)
Date: Sun, 22 Sep 2013 01:18:37 -0400
Subject: [R] Creating rectangular plots with x and y coordinates and
 treatments from a matrix for a randomized block design
In-Reply-To: <523E7B13.1020705@ufl.edu>
References: <523E7B13.1020705@ufl.edu>
Message-ID: <523E7DAD.4090809@ufl.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130922/d90060be/attachment.pl>

From yueyun at 139.com  Sun Sep 22 07:53:07 2013
From: yueyun at 139.com (=?UTF-8?B?5bKz6LWf?=)
Date: Sun, 22 Sep 2013 13:53:07 +0800
Subject: [R] =?utf-8?b?562U5aSNOiAgdGhlIHZhbHVlcyBvZiBwcmVkaWN0KCAsIHR5?=
	=?utf-8?b?cGUgPSAidGVybXMiLCAp?=
In-Reply-To: <CAFEqCdyO+19E1rCCL0M9YAj1BwgT9bf7is09DSUgFqAW0fFYRw@mail.gmail.com>
References: <018f01ceb385$a2645630$e72d0290$@139.com>
	<CAFEqCdyO+19E1rCCL0M9YAj1BwgT9bf7is09DSUgFqAW0fFYRw@mail.gmail.com>
Message-ID: <020d01ceb758$038f6fa0$0aae4ee0$@139.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130922/58106061/attachment.pl>

From mikhailbeketov at googlemail.com  Sat Sep 21 21:30:31 2013
From: mikhailbeketov at googlemail.com (Mikhail Beketov)
Date: Sat, 21 Sep 2013 21:30:31 +0200
Subject: [R] Setting a new method for generic function to satisfy "R CMD
	check"
Message-ID: <CAFPVqzwXiOo9RugMFhuvMvQZMpTAJNK4ht=aGQk6ABhY8+yW8A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130921/b5bc0087/attachment.pl>

From John.Gonzalez at gmx.fr  Sat Sep 21 22:40:24 2013
From: John.Gonzalez at gmx.fr (John Gonzalez)
Date: Sat, 21 Sep 2013 22:40:24 +0200
Subject: [R] Re : Re:  Re :  Privacy rights of an old user of this list
Message-ID: <20130921204025.202300@gmx.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130921/8d3a23e9/attachment.pl>

From day01 at pitt.edu  Sat Sep 21 22:41:30 2013
From: day01 at pitt.edu (Day, Roger S)
Date: Sat, 21 Sep 2013 16:41:30 -0400
Subject: [R] problem with showMethods()
Message-ID: <DD025A53-2E24-40A4-A899-E1F90240B75F@pitt.edu>

This message could be useful for people fairly new to S4 classes.
Therefore r-help and not r-devel.

One use for showMethods(), important to me,
is to find all methods that use a particular class in their signatures.

This works:
	showMethods(class="Action", where="package:CTDesignExplorer")  
It finds the methods in the package.

This works:
	showMethods(class="Action", where=topenv(parent.frame())) 
in the sense that it finds nothing (looking in .GlobalEnv).
	"no applicable functions"

The default for "where" is where=topenv(parent.frame()),
so you'd think this would also give nothing.
	showMethods(class="Action") 
Instead, it prints names of hundreds of S4 generics,  reporting that they are not.
For example, 
	Function "xvcopy":
	 <not an S4 generic function>
that come from packages installed even though they are not loaded.
Since this was the first thing I tried,
getting to the bottom of it derailed me for hours.

The problem seems to be from this, in the definition of showMethod:
	  if (length(f) == 0L) {
	    f <- if (missing(.where))  ### This is the problem. It's missing, even though the default value is set.
	      getGenerics()
	    else getGenerics(.where)
	  }
I think better would be just
	    f <- getGenerics(.where)    
Then the default value would apply.
This would forestall a vast downpour of reports about generics claiming that they are not generics.
Or maybe someone can explain the thinking behind the if clause.

Thanks.

-Roger Day


> sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] CTDesignExplorer_1.3.9

loaded via a namespace (and not attached):
[1] BiocGenerics_0.6.0 Biostrings_2.28.0  grid_3.0.1         IRanges_1.18.1    
[5] lattice_0.20-15    parallel_3.0.1     stats4_3.0.1       tools_3.0.1  


From smartpink111 at yahoo.com  Sat Sep 21 22:43:36 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 21 Sep 2013 13:43:36 -0700 (PDT)
Subject: [R] Filtering out data from list
In-Reply-To: <1379779695.21702.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1379779695.21702.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1379796216.93442.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,

list1<-as.list(c("hi I am here!","my name is bob!", "I am mary!!", "bob likes mary!!"))
?list2<- list1[grepl("bob",unlist(list1))]
?list2
#[[1]]
#[1] "my name is bob!"
#
#[[2]]
#[1] "bob likes mary!!"
A.K.



Hm thanks :P 
but i was actually trying to say is like... 

if my list were more random like below and i'm trying to filter out this list which doesnt have the 
specific word such as bob. 

> list1 
[[1]] 
[1] "hi I am here!" 

[[2]] 
[1] "my name is bob!" 

[[3]] 
[1] "I am mary!!" 

[[4]] 
[1] "bob likes mary!!" 

will become 

> list1 

[[1]] 
[1] "my name is bob!" 

[[2]] 
[1] "bob likes mary!!" 


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Saturday, September 21, 2013 12:08 PM
Subject: Re: Filtering out data from list 

Hi,
?list1<-lapply(c("",2:3),function(x) paste0("hi I am here!",x))
#or
list1<-? as.list(paste0("hi I am here!",c("",2:3)))


?str(list1)
#List of 3
# $ : chr "hi I am here!"
# $ : chr "hi I am here!2"
# $ : chr "hi I am here!3"


It is not a list within a list
?

list2<-list1[grepl("2",unlist(list1))]
?list2
#[[1]]
#[1] "hi I am here!2"



#list within a list
listNew<- list( as.list(paste0("hi I am here!",c("",2:3))))
str(listNew)
#List of 1
# $ :List of 3
?# ..$ : chr "hi I am here!"
? #..$ : chr "hi I am here!2"
? #..$ : chr "hi I am here!3"

listNew2<- lapply(1:3,function(x) as.list(paste0("hi I am here!",c("",2:3))))
?str(listNew2)
#List of 3
# $ :List of 3
?# ..$ : chr "hi I am here!"
? #..$ : chr "hi I am here!2"
? #..$ : chr "hi I am here!3"
?#$ :List of 3
?# ..$ : chr "hi I am here!"
?# ..$ : chr "hi I am here!2"
?# ..$ : chr "hi I am here!3"
# $ :List of 3
#? ..$ : chr "hi I am here!"
#? ..$ : chr "hi I am here!2"
#? ..$ : chr "hi I am here!3"


A.K.




Okay im pretty new in r... ? 
and im having trouble figuring how to filtering out data 
just say for example i have a list which prints out 

> list1 
[[1]] 
[1] "hi I am here!" 

[[2]] 
[1] "hi I am here!2" 

[[3]] 
[1] "hi I am here!3" 

.... 

1) okay first I need to confirm , is that a list within a list ? since its displaying 

[[1]] 
[1] ? ?<-- in this fashion 

2) and now just say i want to have list1 to only contain the list with the number 2 in it how do i do it? 
or any methods to suggest ?


From ifatunji at gmail.com  Sun Sep 22 00:03:30 2013
From: ifatunji at gmail.com (Mosi Ifatunji)
Date: Sat, 21 Sep 2013 18:03:30 -0400
Subject: [R] Translating recoding syntax from SPSS to R
Message-ID: <0CD53644-5A19-4CF4-8A91-38F82673305A@gmail.com>

Colleagues,

I am in the process of learning R. I've been able to import my dataset (from Stata) and do some simple coding. I have now come to coding situation that requires some assistance. This is some code in SPSS that I would like to be able to execute in R:

if (race eq 1 and usborn=0) confused=1 .
if (race eq 2 and usborn=0) confused=1 .
if (race eq 1 and usborn=1) confused=0 .
if (race eq 2 and usborn=1) confused=0 .
if (race eq 3 and usborn=1) confused=0 .
if (race eq 3 and cohort=1) confused=0 .
if (race eq 3 and cohort=2) confused=0 .
variable labels confused "R claims to be both an African American and foriegn born" .
value labels confused
	1 "Both AfAm and Foreign"
	2 "Not" .
select if (confused eq 0) .

Any assistance would be greatly appreciated.

-- Mosi

From smartpink111 at yahoo.com  Sun Sep 22 08:27:41 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 21 Sep 2013 23:27:41 -0700 (PDT)
Subject: [R] Obtaining data from a different row of data frame
In-Reply-To: <1379827687.67121.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <523DBBA4.7070301@yahoo.com>
	<1379795975.60563.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<523E0AF3.8050904@yahoo.com>
	<1379812727.49785.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<523E4DFD.3030502@yahoo.com>
	<1379815656.34841.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<523E561E.9060507@yahoo.com>
	<1379818041.24463.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<523E6307.8070705@yahoo.com>
	<1379820626.88190.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<523E65A7.9070707@yahoo.com>
	<1379822867.75018.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1379827687.67121.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <1379831261.15127.YahooMailNeo@web142605.mail.bf1.yahoo.com>

HI,

A modified code to avoid the ?sapply()
df1<- structure(list(Dates = structure(c(13151, 13152, 13153, 13154,
?13157, 13158, 13159, 13160, 13161, 13164), class = "Date"), P1 = c(10,
?13, 16, 19, 22, 25, 28, 31, 34, 37), P2 = c(100, 102, 104, 106,
?108, 110, 112, 114, 116, 118), P3 = c(90, 94, 98, 102, 106, 110,
?114, 118, 122, 126), P4 = c(70, 75, 80, 85, 90, 95, 100, 105,
?110, 115), OF1 = c(3, 3, 4, 5, 2, 2, 2, 1, 1, 5), OF2 = c(5,
?3, 4, 2, 1, 2, 2, 1, 1, 0), OF3 = c(4, 3, 4, 1, 3, 2, 2, 1, 1,
?0), OF4 = c(3, 5, 4, 2, 3, 1, 2, 1, 1, 0)), .Names = c("Dates",
?"P1", "P2", "P3", "P4", "OF1", "OF2", "OF3", "OF4"), row.names = c(NA,
?-10L), class = "data.frame")
df1$OF2[9]<-4

df2<- df1
?df2[,10:13]<- NA
colnames(df2)[10:13]<- paste0("newPrice",1:4)

##your code

for(j in 2:5) {
?df2[j+8] = df2[df2[,j+4] + row(df2)[,j], j]
?}
indx1<- unlist(df1[,grep("OF",colnames(df1))],use.names=FALSE)
?indx1[rep(seq(nrow(df1)),4)%in% 6:10][indx1[rep(seq(nrow(df1)),4)%in% 6:10]- rep(5:1,4)>=0]<- NA

val1<- unlist(df1[,grep("P",colnames(df1))],use.names=FALSE)
?df1[,10:13]<- val1[indx1+seq_along(indx1)]
?colnames(df1)[10:13]<- colnames(df2)[10:13]
identical(df1[,10:13],df2[,10:13])
#[1] TRUE


###On a bigger dataset:
set.seed(29)
?df2<- data.frame(Dates=seq(as.Date("2006-01-03"),length.out=2000,by="1 day"),cbind(matrix(sample(10:120,2000*300,replace=TRUE),ncol=300),matrix(sample(0:6,2000*300,replace=TRUE),ncol=300)))
?colnames(df2)[2:301]<- paste0("P",1:300)
?colnames(df2)[302:601]<- paste0("OF",1:300)
?df3<- df2


df2[,602:901]<-NA
?colnames(df2)[602:901]<- paste0("newPrice",1:300)
?system.time({
?for(j in grep("^P",colnames(df2))) {
? df2[j+600] = df2[df2[,j+300] + row(df2)[,j], j]
? }
?})
#?? user? system elapsed
?#? 8.508?? 0.000?? 8.523 


colN_OF<- ncol(df3[,grep("OF",colnames(df3))])
system.time({
?indx1<- unlist(df3[,grep("OF",colnames(df3))],use.names=FALSE)
?indx1[rep(seq(nrow(df3)),colN_OF) %in% 1995:2000][indx1[rep(seq(nrow(df3)),colN_OF) %in% 1995:2000] - rep(6:1,colN_OF)>=0] <-NA
? val1<- unlist(df3[,grep("P",colnames(df3))],use.names=FALSE)
? df3[,602:901]<- val1[indx1+seq_along(indx1)]
? colnames(df3)[602:901]<- colnames(df2)[602:901]
?})
#? user? system elapsed 
#? 0.568?? 0.000?? 0.569 

?identical(df2,df3)
#[1] TRUE


A.K.





----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Ira Sharenow <irasharenow100 at yahoo.com>
Cc: 
Sent: Sunday, September 22, 2013 1:28 AM
Subject: Re: [R] Obtaining data from a different row of data frame

Ira,

I tried with a bigger dataset to look for any errors in the code:
set.seed(29)
?df2<- data.frame(Dates=seq(as.Date("2006-01-03"),length.out=2000,by="1 day"),cbind(matrix(sample(10:120,2000*300,replace=TRUE),ncol=300),matrix(sample(0:6,2000*300,replace=TRUE),ncol=300)))
?colnames(df2)[2:301]<- paste0("P",1:300)
?colnames(df2)[302:601]<- paste0("OF",1:300)
?df3<- df2

df2[,602:901]<-NA
?colnames(df2)[602:901]<- paste0("newPrice",1:300)
?system.time({
?for(j in grep("^P",colnames(df2))) {
? df2[j+600] = df2[df2[,j+300] + row(df2)[,j], j]
? }
?})
#?? user? system elapsed 
?# 9.584?? 0.000?? 9.601 



vec1<- 6:1 ##change values according to the range of actual values in your rows.
?vec2<- 1995:2000 ##change accordingly. If the maximum value is say 100, take 100 rows from the tail end.? Change the vec1 also so that both are of the same length


system.time({
?df3[vec2,grep("OF",colnames(df3))]<- t(sapply(seq_along(vec1),function(i) {x1<-as.matrix(df3[vec2[i],grep("OF",colnames(df3))]); x1[x1>=vec1[i]]<-NA; x1}))
?indx1<- unlist(df3[,grep("OF",colnames(df3))],use.names=FALSE)
?val1<- unlist(df3[,grep("P",colnames(df3))],use.names=FALSE)
? df3[,602:901]<- val1[indx1+seq_along(indx1)]
? colnames(df3)[602:901]<- colnames(df2)[602:901]
?})
#?? user? system elapsed 
?# 0.552?? 0.000?? 0.553 

identical(df2[,602:901],df3[,602:901])
#[1] TRUE


A.K.


From smartpink111 at yahoo.com  Sun Sep 22 08:47:02 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 21 Sep 2013 23:47:02 -0700 (PDT)
Subject: [R] Translating recoding syntax from SPSS to R
In-Reply-To: <0CD53644-5A19-4CF4-8A91-38F82673305A@gmail.com>
References: <0CD53644-5A19-4CF4-8A91-38F82673305A@gmail.com>
Message-ID: <1379832422.61839.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
Try:
set.seed(429)
dat1<- data.frame(race=sample(1:3,20,replace=TRUE),usborn=sample(0:2,20,replace=TRUE))
?dat1$confused<- 1*((dat1$race==1|dat1$race==2) & dat1$usborn==0)
head(dat1)
#? race usborn confused
#1??? 3????? 2??????? 0
#2??? 1????? 0??????? 1
#3??? 2????? 1??????? 0
#4??? 3????? 2??????? 0
#5??? 1????? 2??????? 0
#6??? 1????? 1??????? 0
A.K.



----- Original Message -----
From: Mosi Ifatunji <ifatunji at gmail.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Saturday, September 21, 2013 6:03 PM
Subject: [R] Translating recoding syntax from SPSS to R

Colleagues,

I am in the process of learning R. I've been able to import my dataset (from Stata) and do some simple coding. I have now come to coding situation that requires some assistance. This is some code in SPSS that I would like to be able to execute in R:

if (race eq 1 and usborn=0) confused=1 .
if (race eq 2 and usborn=0) confused=1 .
if (race eq 1 and usborn=1) confused=0 .
if (race eq 2 and usborn=1) confused=0 .
if (race eq 3 and usborn=1) confused=0 .
if (race eq 3 and cohort=1) confused=0 .
if (race eq 3 and cohort=2) confused=0 .
variable labels confused "R claims to be both an African American and foriegn born" .
value labels confused
??? 1 "Both AfAm and Foreign"
??? 2 "Not" .
select if (confused eq 0) .

Any assistance would be greatly appreciated.

-- Mosi
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jwiley.psych at gmail.com  Sun Sep 22 09:20:14 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sun, 22 Sep 2013 00:20:14 -0700
Subject: [R] Translating recoding syntax from SPSS to R
In-Reply-To: <1379832422.61839.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <0CD53644-5A19-4CF4-8A91-38F82673305A@gmail.com>
	<1379832422.61839.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <CANz9Z_LgiRSVdnYGznHw5_8wGc20YivL8YNSkURK3VhUi9Z7WQ@mail.gmail.com>

Just a slight addition to Arun's answer: within() saves typing and
makes life a bit easier

#####################################################
set.seed(429)
dat1 <- data.frame(
  race=sample(1:3,20,replace=TRUE),
  usborn=sample(0:2,20,replace=TRUE))

# within is a nice way to add variables
# and make modifications within a dataset
# saves typing lots of dat1$

dat1 <- within(dat1, {
 confused <- 1 * ((race==1 | race==2) & usborn==0)
})

head(dat1)

# only confused 0
dat1 <- subset(dat1, confused == 0)
#####################################################


On Sat, Sep 21, 2013 at 11:47 PM, arun <smartpink111 at yahoo.com> wrote:
> Hi,
> Try:
> set.seed(429)
> dat1<- data.frame(race=sample(1:3,20,replace=TRUE),usborn=sample(0:2,20,replace=TRUE))
>  dat1$confused<- 1*((dat1$race==1|dat1$race==2) & dat1$usborn==0)
> head(dat1)
> #  race usborn confused
> #1    3      2        0
> #2    1      0        1
> #3    2      1        0
> #4    3      2        0
> #5    1      2        0
> #6    1      1        0
> A.K.
>
>
>
> ----- Original Message -----
> From: Mosi Ifatunji <ifatunji at gmail.com>
> To: "r-help at r-project.org" <r-help at r-project.org>
> Cc:
> Sent: Saturday, September 21, 2013 6:03 PM
> Subject: [R] Translating recoding syntax from SPSS to R
>
> Colleagues,
>
> I am in the process of learning R. I've been able to import my dataset (from Stata) and do some simple coding. I have now come to coding situation that requires some assistance. This is some code in SPSS that I would like to be able to execute in R:
>
> if (race eq 1 and usborn=0) confused=1 .
> if (race eq 2 and usborn=0) confused=1 .
> if (race eq 1 and usborn=1) confused=0 .
> if (race eq 2 and usborn=1) confused=0 .
> if (race eq 3 and usborn=1) confused=0 .
> if (race eq 3 and cohort=1) confused=0 .
> if (race eq 3 and cohort=2) confused=0 .
> variable labels confused "R claims to be both an African American and foriegn born" .
> value labels confused
>     1 "Both AfAm and Foreign"
>     2 "Not" .
> select if (confused eq 0) .
>
> Any assistance would be greatly appreciated.
>
> -- Mosi
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://joshuawiley.com/
Senior Analyst - Elkhart Group Ltd.
http://elkhartgroup.com


From ligges at statistik.tu-dortmund.de  Sun Sep 22 10:55:16 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 22 Sep 2013 10:55:16 +0200
Subject: [R] Re : Re:  Re :  Privacy rights of an old user of this list
In-Reply-To: <20130921204025.202300@gmx.com>
References: <20130921204025.202300@gmx.com>
Message-ID: <523EB074.40200@statistik.tu-dortmund.de>

On 21.09.2013 22:40, John Gonzalez wrote:
> As I said previously, I'm only concerned about what was published in the
> archive of stat.ethz.ch.

And it is OK to habe your post on Nabble (and many others) after you 
removed it from stat.ethz.ch? Are the swiss that bad?


> I visited https://stat.ethz.ch/mailman/listinfo/r-help to find out where
> I had to send my request to remove those messages and I read:
>
> "R-help list run by maechler at stat.math.ethz.ch, bates at r-project.org"
>
> So I emailed these addresses and r-help-owner at r-project.org.


Right, Martin Maechler may be on vacations, and he will probably answer 
that he does not remove posts in general.



> Only David got back to me, denying my request, so this is why I'm
> discussing it here.
>
> If anybody could provide me a contact of who is controlling this
> archive, I would definitely appreciate it.
>
> Regards,
>
> John
>
>> ----- Message d'origine -----
>>
>> De : Uwe Ligges
>>
>> Envoy?s : 21.09.13 10:26
>>
>> ? : Adan Leobardo Martinez Cruz
>>
>> Objet : Re: [R] Re : Privacy rights of an old user of this list
>>
>> The locations where the mailing list are archived are not even
>> controlled by any member of R-core or the R foundation. Everybody,
>> including John, could collect mails from the list and publish them.
>> This is a well known property of a public mailing list.
>>
>> Uwe Ligges
>>
>>
>>
>>
>> On 17.09.2013 13:29, Adan Leobardo Martinez Cruz wrote:
>> > Dear all,
>> >
>> > I will express my opinion without knowing the details of the posts John would like to be removed.
>> >
>> > In the current state, people posting on this and other servers have no clear way to go when trying to remove their posts.
>> > It is a likely event that the number of people attempting the removal of their past posts will increase. Their reasons will vary and may or not may be reasonable to us.
>> > It seems that a discussion on how the R-server will handle this likely situation is needed (including the possibility of keeping the current policy, of course)
>> > Once the decision has been taken, a warning note would be helpful for newcomers (something in big, black letters saying that whatever we post will not be removed or something like that).
>> >
>> > Best regards to all,
>> >
>> > adan
>> >
>> >
>> >
>> > ________________________________________
>> > From: r-help-bounces at r-project.org [r-help-bounces at r-project.org] on behalf of John Gonzalez [John.Gonzalez at gmx.fr]
>> > Sent: Monday, September 16, 2013 5:14 PM
>> > To: David Winsemius; Albin Blaschka; Duncan Murdoch; Jeff Newmiller; S  Ellison; Jim Lemon
>> > Cc: r-help at r-project.org
>> > Subject: [R] Re :  Privacy rights of an old user of this list
>> >
>> > I would like to thank David for letting me publish this and discuss it openly. I must acknowledge from the answers that I received to my post, that the administrators of this list are doing what seems to be fair to me: what most people demand or understand that is right.
>> > However I don't share your views and I honestly think you are making a mistake which may hurt you just as much as it is hurting me now) in the long term. Let me develop my point.
>> > First of all let me clarify for those who accuse me of being desinformed or innocent about my request, I'm not asking for your collaboration to remove what I published from the internet, its google records or any of the infinite copies that may be lying around. I'm asking for a very simple thing:
>> > There are 7 messages (sorry it wasn't 3...) written by me and hosted at the server stat.ethz.ch https://stat.ethz.ch/pipermail/r-help/2009-March/190367.html  which I would like to have removed.
>> > Now, Steve E makes a good point: "I am also of the opinion that the list owner was not showing disrespect by describing the state of affairs you agreed to on signing up, or by declining to act beyond the requirements of the conditions applicable to the list. " Steve
>> > Fair enough. But that doesn't mean that those conditions are right and should never be modified. I'm probably something similar to an unhappy customer who has bought a product with no money-back policy but with an important distinction: I'm going to be wearing this product for the rest of my life. So that makes me, if anything, a "very unhappy customer".
>> > Now let me explain why in this world I'm spending time on requesting the removal of these 7 messages in that server.
>> > I have a MS in Computer Science and a 5 years long Telecommunications degree, I know quite well how the internet works. This is not the first time that I request this. I already requested it in another mailing list, where they were kind enough to aprove it after I verified my identity and they checked that they weren't removing anything critical. The result was that that piece information was obviously not erased from the entire internet but was not showing up in the first 12 pages of google when you would look up my name (when it was on the first page previously). It took me 5 requests to different servers but I managed. There is nothing impossible about it and it made a difference in my life.
>> > So why is this important for me (something like not showing up on the first pages of google?). Well please understand that there is a difference between publishing an article and writing an email to a list. An article goes through several personal revisions and is examined by a professional reviewer before it is published. It only takes a click to send an email. It is extremely easy to make mistakes (particularly when you are young and you know little about life). Actually, people make lots of mistakes and banks may use it to deny you or give you credit, employers to give you an opportunity or not, a lover to have more or less reasons to meet you etc etc etc. Removing this information from servers that are more visited by the search bot crawlers makes a difference: your banker will have to spend more time or resources to refuse your credit request, your lover may be already calling you for a date, your employer may be already calling your for an interview.
>> > Now, if you have a lifetime job, if you never want to change your career, if you will never need a credit, if you have a lovely, healthy and loyal wife, what I just wrote may sound meaningless but if anything happens to your life, you may end up remembering what I said and suffering like me.
>> > Why? Because you it is not possible to remove 7 messages from a server? OK, this is surely extra work that may be difficult to handle but have you considered adding a small fee for those removal requests? I would be more than happy to pay for it.
>> > "There are a quite a few of my postings to newsgroups that I wouldn't mind seeing disappear and even a few on the Rhelp archives. I just don't think that my errors in judgment or
>> > knowledge deserve to be ignored. My hope is that I am judged on the balance of useful versus boneheaded." David
>> > I hope that my point is clear by now. My original motivation was and continues to be that my name was associated with a company that I don't want to be associated with (may I keep my reasons private?). My knowledge or professionality is not at stake for what I said. I can actually prove to you that I abandonded my career in engineering and I'm working in things that have nothing to do with it.
>> > Looking forward to hearing your opinions again.
>> > Best regards,
>> > John
>> > ----- Message d'origine -----
>> > De : John Gonzalez
>> > Envoy??s : 12.09.13 15:40
>> > ?? : r-help at r-project.org, r-help at r-project.org
>> > Objet : [R] Privacy rights of an old user of this list
>> >
>> > Dear subscribers of r-help, I would like to know your opinion about a privacy problem that I recently had after publishing to this list. Not a long time ago, I requested to the administrators of this list that they removed 2 or 3 old posts from mine. These posts were associating my name with an old company for which I worked a few years ago when you would look up my real name at google. I'm 100% aware that there are many mirrors of this list archive and that this is a hard work, however my point was to move their google references to later pages so that new people that look up my name would focus first on more recent work that I see as more relevant for what I would like to do in the future. This is the answer that I received from Mr. Winsemius: << Such a service is not available. Almost immediately rhelp postings are replicated in multiple websites around the world. The information that you could have (and should have) read at the time of signing up is here: https://st!
 at.et!
>> >   hz.ch/mailman/listinfo/r-help ... and the relevant sentence is: "Posters should be aware that the R lists are /public/ discussion lists and anything you post will be *archived and accessible* via several websites for many years." >> I followed up explaining that at that time I was too young to understand the consequences of what I was doing and that, honestly, I didn't pay attention to such a note. Mr. Winsemius didn't understand the reason of my request and therefore decided to ignore it, even after asking a representative from the company mentioned in my old posts to contact him to request the removal of such posts. At this point I feel completely powerless and disturbed that the administrators of the r-help list refuse to remove a text that I decided a long time ago to publish here. I don't think that they own the rights of what I wrote and I wonder what I have done wrong to be disrespected in such a way. Best regards, John Gonzalez (pseudonym) [[alternative HTML v!
 ersion!
>> >    deleted]] ______________________________________________ R-help at r-pro
>> >
>> > ject.org mailing list https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the posting guide http://www.R-project.org/posting-guide.html and provide commented, minimal, self-contained, reproducible code.
>> >
>> >          [[alternative HTML version deleted]]
>> >
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>


From murdoch.duncan at gmail.com  Sun Sep 22 13:25:28 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 22 Sep 2013 07:25:28 -0400
Subject: [R] Setting a new method for generic function to satisfy "R CMD
 check"
In-Reply-To: <CAFPVqzwXiOo9RugMFhuvMvQZMpTAJNK4ht=aGQk6ABhY8+yW8A@mail.gmail.com>
References: <CAFPVqzwXiOo9RugMFhuvMvQZMpTAJNK4ht=aGQk6ABhY8+yW8A@mail.gmail.com>
Message-ID: <523ED3A8.6070404@gmail.com>

On 13-09-21 3:30 PM, Mikhail Beketov wrote:
> Dear All,
>
> Can somebody explain me how to correctly set a new class-specific method
> for generic functions (e.g. for "plot", "summary" and "print"). I simply
> programmed these functions with the class names and it works perfectly.
> E.g.:
>
> x<-2
> y<-3
> class(x)<-"newclass"
> class(y)<-"newclass"
> print.newclass<-function(x){ cat(x*10) }
> print(x)
> print(y)
>
> However, I need the new methods for a new package, and the "R CMD check"
> gives me warnings that my approach is not correct. I have to define
> "methods" and do not use full names as "print.newclass".
> I read the "Writing R Extensions" and it is not explained there (at least
> to such level that I could get it) and I didn't get anything understandable
> by googling.
>
> Maybe someone can help me?

You need to declare methods in the NAMESPACE file, and there is special 
markup for them in Rd files.

Duncan Murdoch


From ggrothendieck at gmail.com  Sun Sep 22 14:25:20 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 22 Sep 2013 08:25:20 -0400
Subject: [R] time zones from longitude, latitude, and date
In-Reply-To: <A4A57CC9-B381-4AE1-B0AA-78370ACC6FAA@comcast.net>
References: <CAAZ8xcmpPMErsEYGdMbmA7LqxB7HDochipqUHtjHvAYUr+mQ4Q@mail.gmail.com>
	<26133729-5DF6-4DF3-A14A-541E0D5781EC@comcast.net>
	<CAAZ8xc=E9uiCNXv-vGfs3uD+xHc9_a8=bF-9U85ZNe+yhVCP3A@mail.gmail.com>
	<CAP01uRk_62Np3S-mDY1G=jJz-JMGRgVnJNtKFjExoZ3QCUXAEw@mail.gmail.com>
	<523D5515.803@stats.ox.ac.uk>
	<A4A57CC9-B381-4AE1-B0AA-78370ACC6FAA@comcast.net>
Message-ID: <CAP01uRnzPuuXPwXHqkSSY4ig51HO9QinT6BTYBm9jpDkuQiVtQ@mail.gmail.com>

On Sat, Sep 21, 2013 at 10:25 AM, David Winsemius
<dwinsemius at comcast.net> wrote:
>
> On Sep 21, 2013, at 3:13 AM, Prof Brian Ripley wrote:
>
>> On 21/09/2013 08:17, Gabor Grothendieck wrote:
>>>
>>> On Fri, Sep 20, 2013 at 4:31 PM, carlisle thacker
>>> <carlisle.thacker at gmail.com> wrote:
>>>>
>>>> I was looking for something like shown on the map:
>>>>
>>>> http://upload.wikimedia.org/wikipedia/commons/8/88/World_Time_Zones_Map.png
>>>>
>>>> Information about local daylight savings times would also help.
>>>>
>>>> The data are from ships, supposedly in local time, but no time-zone info
>>>> is
>>>> given.  A function that would return time zone and whether or not
>>>> daylight
>>>> savings time applies at given date would would help.  I'm trying to
>>>> track
>>>> down more information about the data and whether they can be referenced
>>>> to
>>>> UTC.
>>>
>>>
>>> The zone.tab file has this information.  See the Examples section at
>>> the end of ?Sys.timezone for info on its whereabouts.
>>
>>
>> On some OSes only.
>
>
> This is a couple of snippets of that file from a Mac:
> /usr/share/zoneinfo/zone.tab
> #-------------
> # This file contains a table with the following columns:
> # 1.  ISO 3166 2-character country code.  See the file `iso3166.tab'.
> # 2.  Latitude and longitude of the zone's principal location
> #     in ISO 6709 sign-degrees-minutes-seconds format,
> #     either +-DDMM+-DDDMM or +-DDMMSS+-DDDMMSS,
> #     first latitude (+ is north), then longitude (+ is east).
> # 3.  Zone name used in value of TZ environment variable.
> # 4.  Comments; present if and only if the country has multiple rows.
> #---------
>
> US      +340308-1181434 America/Los_Angeles     Pacific Time
> US      +611305-1495401 America/Anchorage       Alaska Time
> US      +581807-1342511 America/Juneau  Alaska Time - Alaska panhandle
> US      +593249-1394338 America/Yakutat Alaska Time - Alaska panhandle neck
> US      +643004-1652423 America/Nome    Alaska Time - west Alaska
> US      +515248-1763929 America/Adak    Aleutian Islands
> US      +211825-1575130 Pacific/Honolulu        Hawaii
> UY      -3453-05611     America/Montevideo
> UZ      +3940+06648     Asia/Samarkand  west Uzbekistan
> UZ      +4120+06918     Asia/Tashkent   east Uzbekistan
> VA      +415408+0122711 Europe/Vatican
>
>
> After looking at it I'm not sure it will be of much additional value for the
> purposes outlined. It does not provide boundaries of time zones.

The idea is to take the nearest lat/long found. If the input data is
lat/longs of major cities then it would likely work exactly.  If not
then it would only be an approximation but that might be sufficient
depending on one's purpose.  The nice thing is that the time zones you
get out is precisely the ones that R can use.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From ifatunji at gmail.com  Sun Sep 22 17:04:49 2013
From: ifatunji at gmail.com (Mosi Ifatunji)
Date: Sun, 22 Sep 2013 11:04:49 -0400
Subject: [R] Translating recoding syntax from SPSS to R
In-Reply-To: <CANz9Z_LgiRSVdnYGznHw5_8wGc20YivL8YNSkURK3VhUi9Z7WQ@mail.gmail.com>
References: <0CD53644-5A19-4CF4-8A91-38F82673305A@gmail.com>
	<1379832422.61839.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CANz9Z_LgiRSVdnYGznHw5_8wGc20YivL8YNSkURK3VhUi9Z7WQ@mail.gmail.com>
Message-ID: <49BC1E98-24D6-4C03-A19D-2D9EEBA2A708@gmail.com>

Thanks!

This worked wonderfully!

Very exciting!

-- Mosi


On Sep 22, 2013, at 3:20 AM, Joshua Wiley <jwiley.psych at gmail.com> wrote:

Just a slight addition to Arun's answer: within() saves typing and
makes life a bit easier

#####################################################
set.seed(429)
dat1 <- data.frame(
 race=sample(1:3,20,replace=TRUE),
 usborn=sample(0:2,20,replace=TRUE))

# within is a nice way to add variables
# and make modifications within a dataset
# saves typing lots of dat1$

dat1 <- within(dat1, {
confused <- 1 * ((race==1 | race==2) & usborn==0)
})

head(dat1)

# only confused 0
dat1 <- subset(dat1, confused == 0)
#####################################################


On Sat, Sep 21, 2013 at 11:47 PM, arun <smartpink111 at yahoo.com> wrote:
> Hi,
> Try:
> set.seed(429)
> dat1<- data.frame(race=sample(1:3,20,replace=TRUE),usborn=sample(0:2,20,replace=TRUE))
> dat1$confused<- 1*((dat1$race==1|dat1$race==2) & dat1$usborn==0)
> head(dat1)
> #  race usborn confused
> #1    3      2        0
> #2    1      0        1
> #3    2      1        0
> #4    3      2        0
> #5    1      2        0
> #6    1      1        0
> A.K.
> 
> 
> 
> ----- Original Message -----
> From: Mosi Ifatunji <ifatunji at gmail.com>
> To: "r-help at r-project.org" <r-help at r-project.org>
> Cc:
> Sent: Saturday, September 21, 2013 6:03 PM
> Subject: [R] Translating recoding syntax from SPSS to R
> 
> Colleagues,
> 
> I am in the process of learning R. I've been able to import my dataset (from Stata) and do some simple coding. I have now come to coding situation that requires some assistance. This is some code in SPSS that I would like to be able to execute in R:
> 
> if (race eq 1 and usborn=0) confused=1 .
> if (race eq 2 and usborn=0) confused=1 .
> if (race eq 1 and usborn=1) confused=0 .
> if (race eq 2 and usborn=1) confused=0 .
> if (race eq 3 and usborn=1) confused=0 .
> if (race eq 3 and cohort=1) confused=0 .
> if (race eq 3 and cohort=2) confused=0 .
> variable labels confused "R claims to be both an African American and foriegn born" .
> value labels confused
>    1 "Both AfAm and Foreign"
>    2 "Not" .
> select if (confused eq 0) .
> 
> Any assistance would be greatly appreciated.
> 
> -- Mosi
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://joshuawiley.com/
Senior Analyst - Elkhart Group Ltd.
http://elkhartgroup.com


From jholtman at gmail.com  Sun Sep 22 17:10:41 2013
From: jholtman at gmail.com (jim holtman)
Date: Sun, 22 Sep 2013 11:10:41 -0400
Subject: [R] Creating rectangular plots with x and y coordinates and
 treatments from a matrix for a randomized block design
In-Reply-To: <523E7B13.1020705@ufl.edu>
References: <523E7B13.1020705@ufl.edu>
Message-ID: <CAAxdm-6RBhcMOTL2SCtjv=Pq+r89yiyowxm3RwdXeTUgTwXNCw@mail.gmail.com>

Is this what you were after:


> ## A function to generate a RCB design
>
> rcbd<-function(b,g,rb,cb,r,c)
+ {
+    # b =number of blocks
+    # g = a vector of treatments
+    # rb = number of rows per blocks
+    # cb =number of columns per block
+    # r = total rows
+    # c = total columns
+ library(foreach)
+ genotypes<-times(b) %do% sample(g,length(g))
+ block<-rep(1:b,each=length(g))
+ genotypes<-factor(genotypes)
+ block<-factor(block)
+ ### generate the base design
+ k<-c/cb # number of blocks on the x-axis
+ x<-rep(rep(1:r,each=cb),k)  # X-coordinate
+ l<-cb
+ p<-r/rb
+ m<-l+1
+ d<-l*b/p
+ y<-c(rep(1:l,r),rep(m:d,r)) # Y-coordinate
+ data.frame(x,y,block,genotypes)
+ }
> set.seed(100)
> ans <- rcbd(b=4,g=1:4,rb=2,cb=2,r=4,c=4)
>
> result <- matrix(nrow = max(ans$x), ncol = max(ans$y))
> result[cbind(ans$y, ans$x)] <- ans$genotypes
> result
     [,1] [,2] [,3] [,4]
[1,]    2    4    2    3
[2,]    1    3    4    1
[3,]    3    2    2    3
[4,]    1    4    4    1
>

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Sun, Sep 22, 2013 at 1:07 AM, Laz <lmramba at ufl.edu> wrote:
> Dear R users,
>
> I have a function I created to generate randomized block designs given
> below. Once  I generate the design, I would like to plot it in a
> rectangular form to mimic the excel style where the blocks are
> represented with the treatment values placed exactly where their
> appropriate X and Y coordinates are.
>
> ## A function to generate a RCB design
>
> rcbd<-function(b,g,rb,cb,r,c)
> {
>    # b =number of blocks
>    # g = a vector of treatments
>    # rb = number of rows per blocks
>    # cb =number of columns per block
>    # r = total rows
>    # c = total columns
> library(foreach)
> genotypes<-times(b) %do% sample(g,length(g))
> block<-rep(1:b,each=length(g))
> genotypes<-factor(genotypes)
> block<-factor(block)
> ### generate the base design
> k<-c/cb # number of blocks on the x-axis
> x<-rep(rep(1:r,each=cb),k)  # X-coordinate
> l<-cb
> p<-r/rb
> m<-l+1
> d<-l*b/p
> y<-c(rep(1:l,r),rep(m:d,r)) # Y-coordinate
> data.frame(x,y,block,genotypes)
> }
> set.seed(100)
> rcbd(b=4,g=1:4,rb=2,cb=2,r=4,c=4)
>
>     x y block genotypes
> 1  1 1     1         2
> 2  1 2     1         1
> 3  2 1     1         4
> 4  2 2     1         3
> 5  3 1     2         2
> 6  3 2     2         4
> 7  4 1     2         3
> 8  4 2     2         1
> 9  1 3     3         3
> 10 1 4     3         1
> 11 2 3     3         2
> 12 2 4     3         4
> 13 3 3     4         2
> 14 3 4     4         4
> 15 4 3     4         3
> 16 4 4     4         1
>
> How can I produce a diagram like this one below or a better one for any run of my function?
>
>
> 2       4       2       3
> 1       3       4       1
> 3       2       2       3
> 1       4       4       1
>
>
> Regards,
> Laz
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Sun Sep 22 17:15:39 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 22 Sep 2013 08:15:39 -0700 (PDT)
Subject: [R] Obtaining data from a different row of data frame
In-Reply-To: <523F037B.6070108@yahoo.com>
References: <523DBBA4.7070301@yahoo.com>
	<1379795975.60563.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<523E0AF3.8050904@yahoo.com>
	<1379812727.49785.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<523E4DFD.3030502@yahoo.com>
	<1379815656.34841.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<523E561E.9060507@yahoo.com>
	<1379818041.24463.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<523E6307.8070705@yahoo.com>
	<1379820626.88190.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<523E65A7.9070707@yahoo.com>
	<1379822867.75018.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1379827687.67121.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1379831261.15127.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<523F037B.6070108@yahoo.com>
Message-ID: <1379862939.76336.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Ira,
No problem.
If you change the ?for() loop to ?lapply, there should be increase in speed (Usually, it is not the case.? Here it is does, but still not as good in terms of speed as the method I showed).

df1<- structure(list(Dates = structure(c(13151, 13152, 13153, 13154,
?13157, 13158, 13159, 13160, 13161, 13164), class = "Date"), P1 = c(10,
?13, 16, 19, 22, 25, 28, 31, 34, 37), P2 = c(100, 102, 104, 106,
?108, 110, 112, 114, 116, 118), P3 = c(90, 94, 98, 102, 106, 110,
?114, 118, 122, 126), P4 = c(70, 75, 80, 85, 90, 95, 100, 105,
?110, 115), OF1 = c(3, 3, 4, 5, 2, 2, 2, 1, 1, 5), OF2 = c(5,
?3, 4, 2, 1, 2, 2, 1, 1, 0), OF3 = c(4, 3, 4, 1, 3, 2, 2, 1, 1,
?0), OF4 = c(3, 5, 4, 2, 3, 1, 2, 1, 1, 0)), .Names = c("Dates",
?"P1", "P2", "P3", "P4", "OF1", "OF2", "OF3", "OF4"), row.names = c(NA,
?-10L), class = "data.frame")
df1$OF2[9]<-4

df2<- df1
?df2[,10:13]<- NA
colnames(df2)[10:13]<- paste0("newPrice",1:4)

##your code

for(j in 2:5) {
?df2[j+8] = df2[df2[,j+4] + row(df2)[,j], j]
?}

#using ?lapply()
?df1[,10:13]<-lapply(2:5,function(j) {df1[df1[,j+4]+row(df2)[,j],j]})
colnames(df1)[10:13]<- colnames(df2)[10:13]
?identical(df1,df2)
#[1] TRUE

#######Speed check:
set.seed(29)
?df2<- data.frame(Dates=seq(as.Date("2006-01-03"),length.out=2000,by="1 day"),cbind(matrix(sample(10:120,2000*300,replace=TRUE),ncol=300),matrix(sample(0:6,2000*300,replace=TRUE),ncol=300)))
?colnames(df2)[2:301]<- paste0("P",1:300)
?colnames(df2)[302:601]<- paste0("OF",1:300)
?df3<- df2


df2[,602:901]<-NA
?colnames(df2)[602:901]<- paste0("newPrice",1:300)

system.time({
?for(j in grep("^P",colnames(df2))) {
? df2[j+600] = df2[df2[,j+300] + row(df2)[,j], j]
? }
?})
?# user? system elapsed 
?#11.652?? 0.148? 11.822 

system.time({df3[,602:901]<-lapply(2:301,function(j) {df3[df3[,j+300]+row(df3)[,j],j]}) })
#? user? system elapsed 
#? 2.960?? 0.000?? 2.962 
colnames(df3)[602:901]<- colnames(df2)[602:901]
?identical(df2,df3)
#[1] TRUE

A.K.
?






________________________________
From: Ira Sharenow <irasharenow100 at yahoo.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Sunday, September 22, 2013 10:49 AM
Subject: Re: [R] Obtaining data from a different row of data frame



Arun,

Thanks for the time you spent helping me.

I always learned to use the apply family (but maybe your strategies are faster), and now I think I am going to learn Hadley Wickham?s methods. Right now I need to do other parts of the project. In a few days I will take another look at your code to see if I can get more out of my code.

For my current project once I am finished my boss will use my code and possibly modify it, so speed is just one factor. Transparency and his future coding time is another consideration. I need to balance things off. 

I need tolerable speed and relatively easy to understand code. It is an interesting trade off.

Thank again for your help. I?ll get back to you when I take another look at the details of what you wrote.

Ira 
On 9/21/2013 11:27 PM, arun wrote:

HI, A modified code to avoid the ?sapply()
df1<- structure(list(Dates = structure(c(13151, 13152, 13153, 13154,
?13157, 13158, 13159, 13160, 13161, 13164), class = "Date"), P1 = c(10,
?13, 16, 19, 22, 25, 28, 31, 34, 37), P2 = c(100, 102, 104, 106,
?108, 110, 112, 114, 116, 118), P3 = c(90, 94, 98, 102, 106, 110,
?114, 118, 122, 126), P4 = c(70, 75, 80, 85, 90, 95, 100, 105,
?110, 115), OF1 = c(3, 3, 4, 5, 2, 2, 2, 1, 1, 5), OF2 = c(5,
?3, 4, 2, 1, 2, 2, 1, 1, 0), OF3 = c(4, 3, 4, 1, 3, 2, 2, 1, 1,
?0), OF4 = c(3, 5, 4, 2, 3, 1, 2, 1, 1, 0)), .Names = c("Dates",
?"P1", "P2", "P3", "P4", "OF1", "OF2", "OF3", "OF4"), row.names = c(NA,
?-10L), class = "data.frame")
df1$OF2[9]<-4 df2<- df1
?df2[,10:13]<- NA
colnames(df2)[10:13]<- paste0("newPrice",1:4) ##your code for(j in 2:5) {
?df2[j+8] = df2[df2[,j+4] + row(df2)[,j], j]
?}
indx1<- unlist(df1[,grep("OF",colnames(df1))],use.names=FALSE)
?indx1[rep(seq(nrow(df1)),4)%in% 6:10][indx1[rep(seq(nrow(df1)),4)%in% 6:10]- rep(5:1,4)>=0]<- NA val1<- unlist(df1[,grep("P",colnames(df1))],use.names=FALSE)
?df1[,10:13]<- val1[indx1+seq_along(indx1)]
?colnames(df1)[10:13]<- colnames(df2)[10:13]
identical(df1[,10:13],df2[,10:13])
#[1] TRUE ###On a bigger dataset:
set.seed(29)
?df2<- data.frame(Dates=seq(as.Date("2006-01-03"),length.out=2000,by="1 day"),cbind(matrix(sample(10:120,2000*300,replace=TRUE),ncol=300),matrix(sample(0:6,2000*300,replace=TRUE),ncol=300)))
?colnames(df2)[2:301]<- paste0("P",1:300)
?colnames(df2)[302:601]<- paste0("OF",1:300)
?df3<- df2 df2[,602:901]<-NA
?colnames(df2)[602:901]<- paste0("newPrice",1:300)
?system.time({
?for(j in grep("^P",colnames(df2))) {
? df2[j+600] = df2[df2[,j+300] + row(df2)[,j], j]
? }
?})
#?? user? system elapsed
?#? 8.508?? 0.000?? 8.523??colN_OF<- ncol(df3[,grep("OF",colnames(df3))])
system.time({
?indx1<- unlist(df3[,grep("OF",colnames(df3))],use.names=FALSE)
?indx1[rep(seq(nrow(df3)),colN_OF) %in% 1995:2000][indx1[rep(seq(nrow(df3)),colN_OF) %in% 1995:2000] - rep(6:1,colN_OF)>=0] <-NA
? val1<- unlist(df3[,grep("P",colnames(df3))],use.names=FALSE)
? df3[,602:901]<- val1[indx1+seq_along(indx1)]
? colnames(df3)[602:901]<- colnames(df2)[602:901]
?})
#? user? system elapsed 
#? 0.568?? 0.000?? 0.569???identical(df2,df3)
#[1] TRUE A.K. ----- Original Message -----
From: arun <smartpink111 at yahoo.com> To: Ira Sharenow <irasharenow100 at yahoo.com> Cc: 
Sent: Sunday, September 22, 2013 1:28 AM
Subject: Re: [R] Obtaining data from a different row of data frame Ira, I tried with a bigger dataset to look for any errors in the code:
set.seed(29)
?df2<- data.frame(Dates=seq(as.Date("2006-01-03"),length.out=2000,by="1 day"),cbind(matrix(sample(10:120,2000*300,replace=TRUE),ncol=300),matrix(sample(0:6,2000*300,replace=TRUE),ncol=300)))
?colnames(df2)[2:301]<- paste0("P",1:300)
?colnames(df2)[302:601]<- paste0("OF",1:300)
?df3<- df2 df2[,602:901]<-NA
?colnames(df2)[602:901]<- paste0("newPrice",1:300)
?system.time({
?for(j in grep("^P",colnames(df2))) {
? df2[j+600] = df2[df2[,j+300] + row(df2)[,j], j]
? }
?})
#?? user? system elapsed 
?# 9.584?? 0.000?? 9.601??vec1<- 6:1 ##change values according to the range of actual values in your rows.
?vec2<- 1995:2000 ##change accordingly. If the maximum value is say 100, take 100 rows from the tail end.? Change the vec1 also so that both are of the same length system.time({
?df3[vec2,grep("OF",colnames(df3))]<- t(sapply(seq_along(vec1),function(i) {x1<-as.matrix(df3[vec2[i],grep("OF",colnames(df3))]); x1[x1>=vec1[i]]<-NA; x1}))
?indx1<- unlist(df3[,grep("OF",colnames(df3))],use.names=FALSE)
?val1<- unlist(df3[,grep("P",colnames(df3))],use.names=FALSE)
? df3[,602:901]<- val1[indx1+seq_along(indx1)]
? colnames(df3)[602:901]<- colnames(df2)[602:901]
?})
#?? user? system elapsed 
?# 0.552?? 0.000?? 0.553??identical(df2[,602:901],df3[,602:901])
#[1] TRUE A.K. ??????


From vojta at trapa.cz  Sun Sep 22 17:53:32 2013
From: vojta at trapa.cz (=?UTF-8?Q?Vojt=C4=9Bch_Zeisek?=)
Date: Sun, 22 Sep 2013 08:53:32 -0700 (PDT)
Subject: [R] PCA
In-Reply-To: <1379840665915-4676674.post@n4.nabble.com>
References: <1379840665915-4676674.post@n4.nabble.com>
Message-ID: <1379865212315-4676691.post@n4.nabble.com>

Hi,
see tutorial for Adegenet, http://adegenet.r-forge.r-project.org/ |
Documents | adegenet-basics.pdf | section 6. It should help You.
Vojt?ch



-----
Vojt?ch Zeisek

Department of Botany, Faculty of Science, Charles Uni., Prague, CZ
Institute of Botany, Academy of Science, Czech Republic
Community of the openSUSE GNU/Linux

https://www.natur.cuni.cz/faculty-en?set_language=en
http://www.ibot.cas.cz/?p=index&amp;site=en
http://www.opensuse.org/
http://trapa.cz/
--
View this message in context: http://r.789695.n4.nabble.com/PCA-tp4676674p4676691.html
Sent from the R help mailing list archive at Nabble.com.


From ifatunji at gmail.com  Sun Sep 22 20:40:55 2013
From: ifatunji at gmail.com (Mosi Ifatunji)
Date: Sun, 22 Sep 2013 14:40:55 -0400
Subject: [R] Coding several dummy variables into a single categorical
	variable
Message-ID: <A5B37FF0-7BC4-44BA-BA37-CD532920AE25@gmail.com>

Colleagues,

I have generated several dummy variables:

n$native0 <- 1 * (n$re=="white" & n$usborn=="yes")
n$native1 <- 1 * (n$re=="afam" & n$usborn=="yes")
n$native2 <- 1 * (n$re=="carib" & n$usborn=="yes")
n$native3 <- 1 * (n$re=="carib" & n$usborn=="no")

I would now like to combine these into a single categorical variable where the new variable would be n$native.

And values of native would be 0 through 3, where n$native0 would be a 0 value on n$native, n$native1 would be a 1 value on n$native etc.

Any help would be greatly appreciated.

-- Mosi


From smartpink111 at yahoo.com  Sun Sep 22 21:25:16 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 22 Sep 2013 12:25:16 -0700 (PDT)
Subject: [R] Coding several dummy variables into a single
	categorical	variable
In-Reply-To: <A5B37FF0-7BC4-44BA-BA37-CD532920AE25@gmail.com>
References: <A5B37FF0-7BC4-44BA-BA37-CD532920AE25@gmail.com>
Message-ID: <1379877916.59842.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Try:


set.seed(385)
df<- data.frame(re= sample(c("white","afam","carib"),20,replace=TRUE), usborn= sample(c("yes","no"),20,replace=TRUE),stringsAsFactors=FALSE) 

df1<-within(df,{native3<- 1*(re=="carib" & usborn=="no"); native2<- 1*(re=="carib" & usborn=="yes"); native1<- 1*(re=="afam" & usborn=="yes"); native0<- 1*(re=="white" & usborn=="yes")})

library(reshape2)
df2<- melt(df1,id.vars=c("re","usborn"))[,-3]
colnames(df2)[3]<- "native"
df2

A.K.


----- Original Message -----
From: Mosi Ifatunji <ifatunji at gmail.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Sunday, September 22, 2013 2:40 PM
Subject: [R] Coding several dummy variables into a single categorical	variable

Colleagues,

I have generated several dummy variables:

n$native0 <- 1 * (n$re=="white" & n$usborn=="yes")
n$native1 <- 1 * (n$re=="afam" & n$usborn=="yes")
n$native2 <- 1 * (n$re=="carib" & n$usborn=="yes")
n$native3 <- 1 * (n$re=="carib" & n$usborn=="no")

I would now like to combine these into a single categorical variable where the new variable would be n$native.

And values of native would be 0 through 3, where n$native0 would be a 0 value on n$native, n$native1 would be a 1 value on n$native etc.

Any help would be greatly appreciated.

-- Mosi

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Sun Sep 22 21:34:35 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 22 Sep 2013 12:34:35 -0700 (PDT)
Subject: [R] Coding several dummy variables into a single
	categorical	variable
In-Reply-To: <1379877916.59842.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <A5B37FF0-7BC4-44BA-BA37-CD532920AE25@gmail.com>
	<1379877916.59842.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <1379878475.58736.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,

Not sure this is what you wanted.
df2<- melt(df1,id.vars=c("re","usborn"))
df2New<-df2[df2$value==1,-4]
?df2New$variable<-as.numeric(gsub("[[:alpha:]]","",df2New$variable))
colnames(df2New)[3]<- "native"
?row.names(df2New)<- 1:nrow(df2New)
df2New
#????? re usborn native
#1? white??? yes????? 0
#2? white??? yes????? 0
#3? white??? yes????? 0
#4? white??? yes????? 0
#5? white??? yes????? 0
#6?? afam??? yes????? 1
#7?? afam??? yes????? 1
#8?? afam??? yes????? 1
#9? carib??? yes????? 2
#10 carib??? yes????? 2
#11 carib??? yes????? 2
#12 carib??? yes????? 2
#13 carib??? yes????? 2
#14 carib???? no????? 3
#15 carib???? no????? 3
#16 carib???? no????? 3
#17 carib???? no????? 3
#18 carib???? no????? 3


A.K.



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Mosi Ifatunji <ifatunji at gmail.com>
Cc: R help <r-help at r-project.org>
Sent: Sunday, September 22, 2013 3:25 PM
Subject: Re: [R] Coding several dummy variables into a single categorical	variable

Hi,
Try:


set.seed(385)
df<- data.frame(re= sample(c("white","afam","carib"),20,replace=TRUE), usborn= sample(c("yes","no"),20,replace=TRUE),stringsAsFactors=FALSE) 

df1<-within(df,{native3<- 1*(re=="carib" & usborn=="no"); native2<- 1*(re=="carib" & usborn=="yes"); native1<- 1*(re=="afam" & usborn=="yes"); native0<- 1*(re=="white" & usborn=="yes")})

library(reshape2)
df2<- melt(df1,id.vars=c("re","usborn"))[,-3]
colnames(df2)[3]<- "native"



A.K.


----- Original Message -----
From: Mosi Ifatunji <ifatunji at gmail.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Sunday, September 22, 2013 2:40 PM
Subject: [R] Coding several dummy variables into a single categorical??? variable

Colleagues,

I have generated several dummy variables:

n$native0 <- 1 * (n$re=="white" & n$usborn=="yes")
n$native1 <- 1 * (n$re=="afam" & n$usborn=="yes")
n$native2 <- 1 * (n$re=="carib" & n$usborn=="yes")
n$native3 <- 1 * (n$re=="carib" & n$usborn=="no")

I would now like to combine these into a single categorical variable where the new variable would be n$native.

And values of native would be 0 through 3, where n$native0 would be a 0 value on n$native, n$native1 would be a 1 value on n$native etc.

Any help would be greatly appreciated.

-- Mosi

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Sun Sep 22 21:45:09 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 22 Sep 2013 12:45:09 -0700 (PDT)
Subject: [R] Coding several dummy variables into a single
	categorical	variable
In-Reply-To: <1379878475.58736.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <A5B37FF0-7BC4-44BA-BA37-CD532920AE25@gmail.com>
	<1379877916.59842.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1379878475.58736.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <1379879109.36971.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,

If you don't want to install any package:
colnames(df1)[grep("native",colnames(df1))]<- gsub("([[:alpha:]])(\\d+)","\\1_\\2",colnames(df1)[grep("native",colnames(df1))])
? df2<-reshape(df1,direction="long",varying=3:ncol(df1),sep="_")[,-5]
df3<-df2[as.logical(df2$native),-4]
colnames(df3)[3]<- "native"
?row.names(df3)<- 1:nrow(df3)
?identical(df2New,df3)
#[1] TRUE
A.K.



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Mosi Ifatunji <ifatunji at gmail.com>
Cc: R help <r-help at r-project.org>
Sent: Sunday, September 22, 2013 3:34 PM
Subject: Re: [R] Coding several dummy variables into a single categorical	variable

Hi,

Not sure this is what you wanted.
df2<- melt(df1,id.vars=c("re","usborn"))
df2New<-df2[df2$value==1,-4]
?df2New$variable<-as.numeric(gsub("[[:alpha:]]","",df2New$variable))
colnames(df2New)[3]<- "native"
?row.names(df2New)<- 1:nrow(df2New)
df2New
#????? re usborn native
#1? white??? yes????? 0
#2? white??? yes????? 0
#3? white??? yes????? 0
#4? white??? yes????? 0
#5? white??? yes????? 0
#6?? afam??? yes????? 1
#7?? afam??? yes????? 1
#8?? afam??? yes????? 1
#9? carib??? yes????? 2
#10 carib??? yes????? 2
#11 carib??? yes????? 2
#12 carib??? yes????? 2
#13 carib??? yes????? 2
#14 carib???? no????? 3
#15 carib???? no????? 3
#16 carib???? no????? 3
#17 carib???? no????? 3
#18 carib???? no????? 3


A.K.



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Mosi Ifatunji <ifatunji at gmail.com>
Cc: R help <r-help at r-project.org>
Sent: Sunday, September 22, 2013 3:25 PM
Subject: Re: [R] Coding several dummy variables into a single categorical??? variable

Hi,
Try:


set.seed(385)
df<- data.frame(re= sample(c("white","afam","carib"),20,replace=TRUE), usborn= sample(c("yes","no"),20,replace=TRUE),stringsAsFactors=FALSE) 

df1<-within(df,{native3<- 1*(re=="carib" & usborn=="no"); native2<- 1*(re=="carib" & usborn=="yes"); native1<- 1*(re=="afam" & usborn=="yes"); native0<- 1*(re=="white" & usborn=="yes")})

library(reshape2)
df2<- melt(df1,id.vars=c("re","usborn"))[,-3]
colnames(df2)[3]<- "native"



A.K.


----- Original Message -----
From: Mosi Ifatunji <ifatunji at gmail.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Sunday, September 22, 2013 2:40 PM
Subject: [R] Coding several dummy variables into a single categorical??? variable

Colleagues,

I have generated several dummy variables:

n$native0 <- 1 * (n$re=="white" & n$usborn=="yes")
n$native1 <- 1 * (n$re=="afam" & n$usborn=="yes")
n$native2 <- 1 * (n$re=="carib" & n$usborn=="yes")
n$native3 <- 1 * (n$re=="carib" & n$usborn=="no")

I would now like to combine these into a single categorical variable where the new variable would be n$native.

And values of native would be 0 through 3, where n$native0 would be a 0 value on n$native, n$native1 would be a 1 value on n$native etc.

Any help would be greatly appreciated.

-- Mosi

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From lmramba at ufl.edu  Sun Sep 22 21:52:10 2013
From: lmramba at ufl.edu (Laz)
Date: Sun, 22 Sep 2013 15:52:10 -0400
Subject: [R] Creating rectangular plots with x and y coordinates and
 treatments from a matrix for a randomized block design
In-Reply-To: <CAAxdm-6RBhcMOTL2SCtjv=Pq+r89yiyowxm3RwdXeTUgTwXNCw@mail.gmail.com>
References: <523E7B13.1020705@ufl.edu>
	<CAAxdm-6RBhcMOTL2SCtjv=Pq+r89yiyowxm3RwdXeTUgTwXNCw@mail.gmail.com>
Message-ID: <523F4A6A.4060204@ufl.edu>

Thanks Jim,
What you have done is very good.
I was wondering if we could draw some horizontal and vertical lines to 
separate the blocks. Is it possible using R?
Regards,
Laz

On 9/22/2013 11:10 AM, jim holtman wrote:
> Is this what you were after:
>
>
>> ## A function to generate a RCB design
>>
>> rcbd<-function(b,g,rb,cb,r,c)
> + {
> +    # b =number of blocks
> +    # g = a vector of treatments
> +    # rb = number of rows per blocks
> +    # cb =number of columns per block
> +    # r = total rows
> +    # c = total columns
> + library(foreach)
> + genotypes<-times(b) %do% sample(g,length(g))
> + block<-rep(1:b,each=length(g))
> + genotypes<-factor(genotypes)
> + block<-factor(block)
> + ### generate the base design
> + k<-c/cb # number of blocks on the x-axis
> + x<-rep(rep(1:r,each=cb),k)  # X-coordinate
> + l<-cb
> + p<-r/rb
> + m<-l+1
> + d<-l*b/p
> + y<-c(rep(1:l,r),rep(m:d,r)) # Y-coordinate
> + data.frame(x,y,block,genotypes)
> + }
>> set.seed(100)
>> ans <- rcbd(b=4,g=1:4,rb=2,cb=2,r=4,c=4)
>>
>> result <- matrix(nrow = max(ans$x), ncol = max(ans$y))
>> result[cbind(ans$y, ans$x)] <- ans$genotypes
>> result
>       [,1] [,2] [,3] [,4]
> [1,]    2    4    2    3
> [2,]    1    3    4    1
> [3,]    3    2    2    3
> [4,]    1    4    4    1
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
>
> On Sun, Sep 22, 2013 at 1:07 AM, Laz <lmramba at ufl.edu> wrote:
>> Dear R users,
>>
>> I have a function I created to generate randomized block designs given
>> below. Once  I generate the design, I would like to plot it in a
>> rectangular form to mimic the excel style where the blocks are
>> represented with the treatment values placed exactly where their
>> appropriate X and Y coordinates are.
>>
>> ## A function to generate a RCB design
>>
>> rcbd<-function(b,g,rb,cb,r,c)
>> {
>>     # b =number of blocks
>>     # g = a vector of treatments
>>     # rb = number of rows per blocks
>>     # cb =number of columns per block
>>     # r = total rows
>>     # c = total columns
>> library(foreach)
>> genotypes<-times(b) %do% sample(g,length(g))
>> block<-rep(1:b,each=length(g))
>> genotypes<-factor(genotypes)
>> block<-factor(block)
>> ### generate the base design
>> k<-c/cb # number of blocks on the x-axis
>> x<-rep(rep(1:r,each=cb),k)  # X-coordinate
>> l<-cb
>> p<-r/rb
>> m<-l+1
>> d<-l*b/p
>> y<-c(rep(1:l,r),rep(m:d,r)) # Y-coordinate
>> data.frame(x,y,block,genotypes)
>> }
>> set.seed(100)
>> rcbd(b=4,g=1:4,rb=2,cb=2,r=4,c=4)
>>
>>      x y block genotypes
>> 1  1 1     1         2
>> 2  1 2     1         1
>> 3  2 1     1         4
>> 4  2 2     1         3
>> 5  3 1     2         2
>> 6  3 2     2         4
>> 7  4 1     2         3
>> 8  4 2     2         1
>> 9  1 3     3         3
>> 10 1 4     3         1
>> 11 2 3     3         2
>> 12 2 4     3         4
>> 13 3 3     4         2
>> 14 3 4     4         4
>> 15 4 3     4         3
>> 16 4 4     4         1
>>
>> How can I produce a diagram like this one below or a better one for any run of my function?
>>
>>
>> 2       4       2       3
>> 1       3       4       1
>> 3       2       2       3
>> 1       4       4       1
>>
>>
>> Regards,
>> Laz
>>
>>
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From gregd at gn.apc.org  Sun Sep 22 21:27:26 2013
From: gregd at gn.apc.org (Greg Dropkin)
Date: Sun, 22 Sep 2013 20:27:26 +0100 (BST)
Subject: [R] gam and optim
In-Reply-To: <60363.80.194.242.12.1379666677.squirrel@sqmail.gn.apc.org>
References: <1177.109.148.204.116.1371798164.squirrel@sqmail.gn.apc.org>
	<1222.86.128.146.62.1379663412.squirrel@sqmail.gn.apc.org>
	<60363.80.194.242.12.1379666677.squirrel@sqmail.gn.apc.org>
Message-ID: <1284.10.254.253.3.1379878046.squirrel@sqmail.gn.apc.org>

just to clarify how I see the error, it was the mis-definition of the
penalty term in the function dv. The following code corrects this error.
What is actually being minimised at this step is the penalised deviance
conditional on the smoothing parameter. A second issue is that the optim
default ("Nelder-Mead") would have to be recycled several times to
approximate the minimum obtained by gam, however, in this example, "BFGS"
gets it straight away.

sorry for all the confusion!

greg

set.seed(1)
library(mgcv)
x<-runif(100)
lp<-exp(-2*x)*sin(8*x)
y<-rpois(100,exp(lp))
m1<-gam(y~s(x),poisson)
W<-diag(fitted(m1))
X<-predict(m1,type="lpmatrix")
S<-m1$smooth[[1]]$S[[1]]
S<-rbind(0,cbind(0,S))
A<-X%*%solve(t(X)%*%W%*%X+m1$sp*S)%*%t(X)%*%W
sum(diag(A))
sum(m1$edf)
fit<-fitted(m1)
b<-m1$coef
range(exp(X%*%b)-fit)
z<-y/fit-1+X%*%b
range(A%*%z-X%*%b)

s<-m1$sp
dv<-function(t)
{
f<-exp(X%*%t)
-2*sum(y*log(f)-f-ifelse(y==0,0,y*log(y))+y)+s*t%*%S%*%t
}
dv(b)
m1$dev+m1$sp*b%*%S%*%b

t1<-optim(rep(0,10),dv,method="BFGS")
t1$p
b

dv(t1$p)
dv(b)

fit1<-exp(X%*%t1$p)

plot(x,y)
points(x,exp(lp),pch=16,col="green3")
points(x,fitted(m1),pch=16,cex=0.5,col="blue")
points(x,fit1,cex=1.5,col="red")





> please ignore this, I see the error.
>
> greg
>
>> hi
>>
>> probably a silly mistake, but I expected gam to minimise the penalised
>> deviance.
>>
>> thanks
>>
>> greg
>>
>> set.seed(1)
>> library(mgcv)
>> x<-runif(100)
>> lp<-exp(-2*x)*sin(8*x)
>> y<-rpois(100,exp(lp))
>> plot(x,y)
>> m1<-gam(y~s(x),poisson)
>> points(x,exp(lp),pch=16,col="green3")
>> points(x,fitted(m1),pch=16,cex=0.5,col="blue")
>> W<-diag(fitted(m1))
>> X<-predict(m1,type="lpmatrix")
>> S<-m1$smooth[[1]]$S[[1]]
>> S<-rbind(0,cbind(0,S))
>> A<-X%*%solve(t(X)%*%W%*%X+m1$sp*S)%*%t(X)%*%W
>> sum(diag(A))
>> sum(m1$edf)
>> fit<-fitted(m1)
>> b<-m1$coef
>> range(exp(X%*%b)-fit)
>> z<-y/fit-1+X%*%b
>> range(A%*%z-X%*%b)
>>
>> dv<-function(t)
>> {
>> f<-exp(X%*%t)
>> -2*sum(y*log(f)-f-ifelse(y==0,0,y*log(y))+y)+t%*%S%*%t
>> }
>> dv(b)
>> m1$dev+b%*%S%*%b
>>
>> #so far, so good
>>
>>
>> t1<-optim(rep(0,10),dv)
>> t1$p
>> b
>>
>> #different
>>
>> dv(t1$p)
>> dv(b)
>>
>> #different, and dv(t1$p) is lower!
>>
>> fit1<-exp(X%*%t1$p)
>> points(x,fit1,pch=16,cex=0.5,col="red")
>>
>> # different
>> # gam found b which does approximate the true curve, but does not
>> minimise
>> the penalised deviance, by a long shot.
>>
>>
>
>


From rolf.turner at xtra.co.nz  Sun Sep 22 22:21:55 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Mon, 23 Sep 2013 08:21:55 +1200
Subject: [R] Creating rectangular plots with x and y coordinates and
 treatments from a matrix for a randomized block design
In-Reply-To: <523F4A6A.4060204@ufl.edu>
References: <523E7B13.1020705@ufl.edu>
	<CAAxdm-6RBhcMOTL2SCtjv=Pq+r89yiyowxm3RwdXeTUgTwXNCw@mail.gmail.com>
	<523F4A6A.4060204@ufl.edu>
Message-ID: <523F5163.20709@xtra.co.nz>

On 09/23/13 07:52, Laz wrote:

<SNIP>
> I was wondering if we could draw some horizontal and vertical lines to 
> separate the blocks. Is it possible using R?
<SNIP>

See fortune("Yoda"). :-)

     cheers,

     Rolf Turner


From lmramba at ufl.edu  Sun Sep 22 22:32:22 2013
From: lmramba at ufl.edu (Laz)
Date: Sun, 22 Sep 2013 16:32:22 -0400
Subject: [R] Creating rectangular plots with x and y coordinates and
 treatments from a matrix for a randomized block design
In-Reply-To: <523F5163.20709@xtra.co.nz>
References: <523E7B13.1020705@ufl.edu>
	<CAAxdm-6RBhcMOTL2SCtjv=Pq+r89yiyowxm3RwdXeTUgTwXNCw@mail.gmail.com>
	<523F4A6A.4060204@ufl.edu> <523F5163.20709@xtra.co.nz>
Message-ID: <523F53D6.4080009@ufl.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130922/43ab90ff/attachment.pl>

From ruipbarradas at sapo.pt  Sun Sep 22 22:38:31 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 22 Sep 2013 21:38:31 +0100
Subject: [R] Creating rectangular plots with x and y coordinates and
 treatments from a matrix for a randomized block design
In-Reply-To: <523F53D6.4080009@ufl.edu>
References: <523E7B13.1020705@ufl.edu>
	<CAAxdm-6RBhcMOTL2SCtjv=Pq+r89yiyowxm3RwdXeTUgTwXNCw@mail.gmail.com>
	<523F4A6A.4060204@ufl.edu> <523F5163.20709@xtra.co.nz>
	<523F53D6.4080009@ufl.edu>
Message-ID: <523F5547.5050002@sapo.pt>

Hello,

No, 'Yoda' is not a package, the package is 'fortunes':

library(fortunes)  # load it in the R session
fortune("Yoda")

Or, if you don't want to load the package,

fortunes::fortune("Yoda")


Rui Barradas

Em 22-09-2013 21:32, Laz escreveu:
> Is "Yoda" an R package? I tried:
>
> install.packages("Yoda")
> Warning in install.packages :
>     package 'Yoda' is not available (for R version 3.0.1)
> Warning in install.packages :
>     package 'Yoda' is not available (for R version 3.0.1)
>
>
> How do I proceed from here?
> Regards,
> Laz
>
>
> On 9/22/2013 4:21 PM, Rolf Turner wrote:
>> On 09/23/13 07:52, Laz wrote:
>>
>> <SNIP>
>>> I was wondering if we could draw some horizontal and vertical lines
>>> to separate the blocks. Is it possible using R?
>> <SNIP>
>>
>> See fortune("Yoda"). :-)
>>
>>      cheers,
>>
>>      Rolf Turner
>>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From lmramba at ufl.edu  Sun Sep 22 22:45:53 2013
From: lmramba at ufl.edu (Laz)
Date: Sun, 22 Sep 2013 16:45:53 -0400
Subject: [R] Creating rectangular plots with x and y coordinates and
 treatments from a matrix for a randomized block design
In-Reply-To: <523F5547.5050002@sapo.pt>
References: <523E7B13.1020705@ufl.edu>
	<CAAxdm-6RBhcMOTL2SCtjv=Pq+r89yiyowxm3RwdXeTUgTwXNCw@mail.gmail.com>
	<523F4A6A.4060204@ufl.edu> <523F5163.20709@xtra.co.nz>
	<523F53D6.4080009@ufl.edu> <523F5547.5050002@sapo.pt>
Message-ID: <523F5701.2010303@ufl.edu>

Hi,

fortune("Yoda") returns a quote of fortunes.

My problem was to draw horizontal and vertical lines to separate the 
blocks in my design. Each block has 4 elements. The first and second 
rows and columns are in block 1, 3rd  and 4th rows and 1st and 2nd 
columns are in 3 etc

     [,1] [,2] [,3] [,4]
[1,]    2    4    2    3
[2,]    1    3    4    1
[3,]    3    2    2    3
[4,]    1    4    4    1



On 9/22/2013 4:38 PM, Rui Barradas wrote:
> fortune("Yoda"). :-)


From istazahn at gmail.com  Mon Sep 23 00:12:43 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Sun, 22 Sep 2013 18:12:43 -0400
Subject: [R] Coding several dummy variables into a single categorical
	variable
In-Reply-To: <A5B37FF0-7BC4-44BA-BA37-CD532920AE25@gmail.com>
References: <A5B37FF0-7BC4-44BA-BA37-CD532920AE25@gmail.com>
Message-ID: <CA+vqiLFjYJhVK7zOU50Pvaku8AF5xwRwNySWu9oGCeRp8gtbbQ@mail.gmail.com>

Hi Mosi,

The easiest approach would be be generate native from re and usborn
directly, rather than generating dummy codes as an intermediate step:

n$native <- interaction(n[c("re", "usborn")])

This has the advantage of preserving the meanings of the levels of
native in the resulting factor, so that you don't have to remember
what 0,1,2,3 mean. If for some reason you prefer the numeric levels
you can then change them using the levels() function.

If for some reason you don't have the original variables (re and
usborn in your example), you can construct a factor from the dummy
codes as follows:

n$native <- factor(
    with(n, paste(native0, native1, native2, native3, sep = "")),
    levels = c("1000", "0100", "0010", "0001"),
    labels = c("0", "1", "2", "3"))


Best,
Ista

On Sun, Sep 22, 2013 at 2:40 PM, Mosi Ifatunji <ifatunji at gmail.com> wrote:
> Colleagues,
>
> I have generated several dummy variables:
>
> n$native0 <- 1 * (n$re=="white" & n$usborn=="yes")
> n$native1 <- 1 * (n$re=="afam" & n$usborn=="yes")
> n$native2 <- 1 * (n$re=="carib" & n$usborn=="yes")
> n$native3 <- 1 * (n$re=="carib" & n$usborn=="no")
>
> I would now like to combine these into a single categorical variable where the new variable would be n$native.
>
> And values of native would be 0 through 3, where n$native0 would be a 0 value on n$native, n$native1 would be a 1 value on n$native etc.
>
> Any help would be greatly appreciated.
>
> -- Mosi
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From friendly at yorku.ca  Mon Sep 23 01:46:04 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Sun, 22 Sep 2013 19:46:04 -0400
Subject: [R] Conditioning plots (wth coplot function) with logistic
 regression curves
In-Reply-To: <1379819554.56426.YahooMailNeo@web142404.mail.bf1.yahoo.com>
References: <1379819554.56426.YahooMailNeo@web142404.mail.bf1.yahoo.com>
Message-ID: <523F813C.1040301@yorku.ca>

On 9/21/2013 11:12 PM, Kiyoshi Sasaki wrote:
> I have been trying to produce a conditional plot using coplot function (http://stat.ethz.ch/R-manual/R-devel/library/graphics/html/coplot.html) for a binary response ("Presence" in my case) variable and one continuous variable ("Overstory") given a specific levels of the other continuous variable ("Ivy"). But, my codes produces an overlapping graph. Also, I want to use three equal intervals for "Ivy" (i.e.,33.3 each), but I could not figure out how. Here is my data and codes I used:
>

If you feel it hurts because you are banging your head into a wall 
trying to get coplot to do this, the answer is: Don't do that!

Instead, you might consider using ggplot2, which handles this case
nicely, as far as I can tell from your description.

But first a due diligence caveat:  Say you come to me for consulting
on this little plotting question. I look at your data frame, dat,
and I see there are a number of other variables that might explain
Presence, so maybe the marginal plot that ignores them could be
misleading, e.g., any of Moist, Leaf, Prey, ... could moderate
the relation between overstory and presence, but you won't see that
in a marginal plot.


Here are a couple of quick ggplot examples, plotting classes of Ivy in the
same plot frame, and on the probability scale.

library(ggplot2)
ggplot(dat, aes(Overstory, Presence), color=Ivy>50 ) +
   stat_smooth(method="glm", family=binomial, formula= y~x, alpha=0.3, 
aes(fill=Ivy>50))

dat$Ivy3 <- factor(cut(dat$Ivy,3))
plt <- ggplot(dat, aes(Overstory, Presence), color=Ivy3 ) +
   stat_smooth(method="glm", family=binomial, formula= y~x, alpha=0.3, 
aes(fill=Ivy3))
plt

If you want separate panels, try something like

plt + facet_grid(. ~ Ivy3)

For plots on the logit scale, try something like
logit <- function(p) log(p)/log(1-p), then

plt + coord_trans(y="logit")

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From peake.19 at osu.edu  Mon Sep 23 01:13:02 2013
From: peake.19 at osu.edu (peake)
Date: Sun, 22 Sep 2013 16:13:02 -0700 (PDT)
Subject: [R] Arcsine transformation
Message-ID: <1379891582470-4676706.post@n4.nabble.com>

I am tryin to perform an arcsine transformation on my data containig
percentages as the dep. variable. Does anyone have a code that I could use
to do that? I am relatively new to R. Thanks for your help!



--
View this message in context: http://r.789695.n4.nabble.com/Arcsine-transformation-tp4676706.html
Sent from the R help mailing list archive at Nabble.com.


From jholtman at gmail.com  Mon Sep 23 02:26:03 2013
From: jholtman at gmail.com (jim holtman)
Date: Sun, 22 Sep 2013 20:26:03 -0400
Subject: [R] Creating rectangular plots with x and y coordinates and
 treatments from a matrix for a randomized block design
In-Reply-To: <523F5701.2010303@ufl.edu>
References: <523E7B13.1020705@ufl.edu>
	<CAAxdm-6RBhcMOTL2SCtjv=Pq+r89yiyowxm3RwdXeTUgTwXNCw@mail.gmail.com>
	<523F4A6A.4060204@ufl.edu> <523F5163.20709@xtra.co.nz>
	<523F53D6.4080009@ufl.edu> <523F5547.5050002@sapo.pt>
	<523F5701.2010303@ufl.edu>
Message-ID: <CAAxdm-7RJRPNMrG+f8krgGXUe1R-sEcmpyoSyAWLhXc2T79XxQ@mail.gmail.com>

CHeck out the 'tables' package if you want to create pretty outputs of
your tables.  Exactly where do you plan to use them?  You can also use
Sweave/Latex to create such tables.

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Sun, Sep 22, 2013 at 4:45 PM, Laz <lmramba at ufl.edu> wrote:
> Hi,
>
> fortune("Yoda") returns a quote of fortunes.
>
> My problem was to draw horizontal and vertical lines to separate the blocks
> in my design. Each block has 4 elements. The first and second rows and
> columns are in block 1, 3rd  and 4th rows and 1st and 2nd columns are in 3
> etc
>
>
>     [,1] [,2] [,3] [,4]
> [1,]    2    4    2    3
> [2,]    1    3    4    1
> [3,]    3    2    2    3
> [4,]    1    4    4    1
>
>
>
> On 9/22/2013 4:38 PM, Rui Barradas wrote:
>>
>> fortune("Yoda"). :-)
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From skiyoshi2001 at yahoo.com  Mon Sep 23 02:48:49 2013
From: skiyoshi2001 at yahoo.com (Kiyoshi Sasaki)
Date: Sun, 22 Sep 2013 17:48:49 -0700 (PDT)
Subject: [R] Conditioning plots (wth coplot function) with logistic
	regression curves
In-Reply-To: <523F813C.1040301@yorku.ca>
References: <1379819554.56426.YahooMailNeo@web142404.mail.bf1.yahoo.com>
	<523F813C.1040301@yorku.ca>
Message-ID: <1379897329.55709.YahooMailNeo@web142406.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130922/e7c09558/attachment.pl>

From bbolker at gmail.com  Mon Sep 23 02:54:00 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 23 Sep 2013 00:54:00 +0000
Subject: [R] Arcsine transformation
References: <1379891582470-4676706.post@n4.nabble.com>
Message-ID: <loom.20130923T025056-812@post.gmane.org>

peake <peake.19 <at> osu.edu> writes:

> 
> I am tryin to perform an arcsine transformation on my data containig
> percentages as the dep. variable. Does anyone have a code that I could use
> to do that? I am relatively new to R. Thanks for your help!

asin(x/100)

? or

asin(x/100)*2/pi if you want the results rescaled to (0,1)

curve(asin(x/100)*2/pi,from=0,to=100)


From Peter.Alspach at plantandfood.co.nz  Mon Sep 23 03:25:09 2013
From: Peter.Alspach at plantandfood.co.nz (Peter Alspach)
Date: Mon, 23 Sep 2013 13:25:09 +1200
Subject: [R] Arcsine transformation
In-Reply-To: <loom.20130923T025056-812@post.gmane.org>
References: <1379891582470-4676706.post@n4.nabble.com>
	<loom.20130923T025056-812@post.gmane.org>
Message-ID: <ED8CD182D432434485C7D1787FB06DDC0CD74B1AE0@AKLEXM01.PFR.CO.NZ>

Tena koe

I think you'll find the arcsine transformation is asin(sqrt(x/100)) where ? is the percentage.  However, it might be better to ask whether the data wouldn't be better analysed using generalised models (e.g., glm).

HTH ....

Peter Alspach

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Ben Bolker
Sent: Monday, 23 September 2013 12:54 p.m.
To: r-help at stat.math.ethz.ch
Subject: Re: [R] Arcsine transformation

peake <peake.19 <at> osu.edu> writes:

> 
> I am tryin to perform an arcsine transformation on my data containig 
> percentages as the dep. variable. Does anyone have a code that I could 
> use to do that? I am relatively new to R. Thanks for your help!

asin(x/100)

? or

asin(x/100)*2/pi if you want the results rescaled to (0,1)

curve(asin(x/100)*2/pi,from=0,to=100)

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

The contents of this e-mail are confidential and may be ...{{dropped:14}}


From bbolker at gmail.com  Mon Sep 23 03:45:45 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 22 Sep 2013 21:45:45 -0400
Subject: [R] Arcsine transformation
In-Reply-To: <ED8CD182D432434485C7D1787FB06DDC0CD74B1AE0@AKLEXM01.PFR.CO.NZ>
References: <1379891582470-4676706.post@n4.nabble.com>
	<loom.20130923T025056-812@post.gmane.org>
	<ED8CD182D432434485C7D1787FB06DDC0CD74B1AE0@AKLEXM01.PFR.CO.NZ>
Message-ID: <523F9D49.2030208@gmail.com>

On 13-09-22 09:25 PM, Peter Alspach wrote:
> Tena koe
> 
> I think you'll find the arcsine transformation is asin(sqrt(x/100))
> where ? is the percentage.  However, it might be better to ask
> whether the data wouldn't be better analysed using generalised models
> (e.g., glm).
> 
> HTH ....
> 

  Good point about arcsine-sqrt, and about GLMs: specifically see

Warton, David I., and Francis K. C. Hui. 2011. ?The Arcsine Is Asinine:
The Analysis of Proportions in Ecology.? Ecology 92 (1) (January): 3?10.
doi:10.1890/10-0340.1.
http://www.esajournals.org/doi/full/10.1890/10-0340.1.

  I think the title is a little silly, but it's worth reading.

> Peter Alspach
> 
> -----Original Message----- From: r-help-bounces at r-project.org
> [mailto:r-help-bounces at r-project.org] On Behalf Of Ben Bolker Sent:
> Monday, 23 September 2013 12:54 p.m. To: r-help at stat.math.ethz.ch 
> Subject: Re: [R] Arcsine transformation
> 
> peake <peake.19 <at> osu.edu> writes:
> 
>> 
>> I am tryin to perform an arcsine transformation on my data
>> containig percentages as the dep. variable. Does anyone have a code
>> that I could use to do that? I am relatively new to R. Thanks for
>> your help!
> 
> asin(x/100)
> 
> ? or
> 
> asin(x/100)*2/pi if you want the results rescaled to (0,1)
> 
> curve(asin(x/100)*2/pi,from=0,to=100)
> 
> ______________________________________________ R-help at r-project.org
> mailing list https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do
> read the posting guide http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code.
> 
> The contents of this e-mail are confidential and may be subject to
> legal privilege. If you are not the intended recipient you must not
> use, disseminate, distribute or reproduce all or any part of this
> e-mail or attachments.  If you have received this e-mail in error,
> please notify the sender and delete all material pertaining to this 
> e-mail.  Any opinion or views expressed in this e-mail are those of
> the individual sender and may not represent those of The New Zealand
> Institute for Plant and Food Research Limited.
>


From peake.19 at osu.edu  Mon Sep 23 03:26:04 2013
From: peake.19 at osu.edu (peake)
Date: Sun, 22 Sep 2013 18:26:04 -0700 (PDT)
Subject: [R] Arcsine transformation
In-Reply-To: <1379894285612-4676708.post@n4.nabble.com>
References: <1379891582470-4676706.post@n4.nabble.com>
	<1379894285612-4676708.post@n4.nabble.com>
Message-ID: <CACYJ9FQNHU7RvEZViEpiQrr0fX6zm9OddO_3jAJC98zarsHqbg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130922/9dfd23f4/attachment.pl>

From bpschn01 at gmail.com  Mon Sep 23 03:43:31 2013
From: bpschn01 at gmail.com (Brad P)
Date: Sun, 22 Sep 2013 20:43:31 -0500
Subject: [R] PLS1 NIPALS question: error with chemometrics package?
Message-ID: <CAMAcwjwQXxgSjUpRj=ayAgDoo196D9gOuyN0wE-=TK4NyUPKog@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130922/d8e153a1/attachment.pl>

From dwarnold45 at suddenlink.net  Mon Sep 23 04:55:36 2013
From: dwarnold45 at suddenlink.net (David Arnold)
Date: Sun, 22 Sep 2013 19:55:36 -0700 (PDT)
Subject: [R] xlim with barplot
Message-ID: <1379904936803-4676717.post@n4.nabble.com>

Hi,

I want to compare to barplots with same horizontal axis limits.

x=c(55,56,57,58,59,60,60,60,61,62,63,64,65)
y=c(35,40,45,50,55,60,60,60,65,70,75,80,85)

par(mfrow=c(2,1))
barplot(table(x),xlim=c(35,85))
barplot(table(y),xlim=c(35,85))
par(mfrow=c(1,1))

But the bars disappear.

<http://r.789695.n4.nabble.com/file/n4676717/Rplot.png> 

Any suggestions?






--
View this message in context: http://r.789695.n4.nabble.com/xlim-with-barplot-tp4676717.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Mon Sep 23 05:05:34 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 22 Sep 2013 20:05:34 -0700 (PDT)
Subject: [R] Correlate rows of 2 matrices
In-Reply-To: <523FA005.3060109@yahoo.com>
References: <523FA005.3060109@yahoo.com>
Message-ID: <1379905534.25698.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
You may try:
set.seed(49)
m1 = matrix(rnorm(30), nrow = 3)
m2 = matrix(rnorm(30), nrow = 3)
?corsP<-vector()
? for(i in 1:3) corsP[i] =? cor(m1[i,], m2[i,])
?corsP
#[1]? 0.58411274 -0.02382329? 0.03760757

diag(cor(t(m1),t(m2)))
#[1]? 0.58411274 -0.02382329? 0.03760757

#or
mNew<- rbind(m1,m2)
?indx<-rep(seq(nrow(mNew)/2),2)
?sapply(split(seq_len(nrow(mNew)),indx),function(x) cor(t(mNew[x,]),t(mNew[x,]))[2])
?#???????? 1?????????? 2?????????? 3 
?#0.58411274 -0.02382329? 0.03760757 
#or
tapply(seq_along(indx),list(indx),FUN=function(x) cor(t(mNew[x,]),t(mNew[x,]))[2])
?#???????? 1?????????? 2?????????? 3 
?#0.58411274 -0.02382329? 0.03760757 
A.K.






________________________________
From: Ira Sharenow <irasharenow100 at yahoo.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Sunday, September 22, 2013 9:57 PM
Subject: Correlate rows of 2 matrices



Arun,

I have a new problem for you. 

I have two data frames (or matrices) and row by row I want to take the correlations.

So if I have a 3 row by 10 column matrix, I would produce 3 correlations.

Is there a way to merge the matrices and then use some sort of split?

Ideas/solutions much appreciated.

m1 = matrix(rnorm(30), nrow = 3)
m2 = matrix(rnorm(30), nrow = 3)

> set.seed(22)
> m1 = matrix(rnorm(30), nrow = 3)
> m2 = matrix(rnorm(30), nrow = 3)
> for(i in 1:3) corsP[i] =? cor(m1[i,], m2[i,])
> corsP
[1] -0.50865019 -0.27760046? 0.01423144

Thanks.

Ira ?????????


From jim at bitwrit.com.au  Mon Sep 23 05:43:02 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Mon, 23 Sep 2013 13:43:02 +1000
Subject: [R] xlim with barplot
In-Reply-To: <1379904936803-4676717.post@n4.nabble.com>
References: <1379904936803-4676717.post@n4.nabble.com>
Message-ID: <523FB8C6.3030501@bitwrit.com.au>

On 09/23/2013 12:55 PM, David Arnold wrote:
> Hi,
>
> I want to compare to barplots with same horizontal axis limits.
>
> x=c(55,56,57,58,59,60,60,60,61,62,63,64,65)
> y=c(35,40,45,50,55,60,60,60,65,70,75,80,85)
>
> par(mfrow=c(2,1))
> barplot(table(x),xlim=c(35,85))
> barplot(table(y),xlim=c(35,85))
> par(mfrow=c(1,1))
>
> But the bars disappear.
>
> <http://r.789695.n4.nabble.com/file/n4676717/Rplot.png>
>
> Any suggestions?
>
Hi David,
The first suggestion is:

  par("usr")
[1] -0.32 13.72 -0.03  3.00

Specifying the x limits as above means that the bars are floating 
somewhere off to the left of the plot and thus not visible. You are 
mistaking the labels of the bars for their position. Now, having 
admonished you like some grumpy old school teacher, I suppose I should 
do something useful:

barplot(tabulate(x,nbins=85)[35:85])
barplot(tabulate(y,nbins=85)[35:85])

This is an underhanded trick to line up the bars as I think you want 
them. I suppose you want x labels as well:

barpos<-barplot(tabulate(x,nbins=85)[35:85],names.arg=xylabels)
axis(1,at=barpos[c(6,16,26,36,46)],labels=c(40,50,60,70,80))
barplot(tabulate(y,nbins=85)[35:85],names.arg=xylabels)
axis(1,at=barpos[c(6,16,26,36,46)],labels=c(40,50,60,70,80))

Jim


From jszhao at yeah.net  Mon Sep 23 05:54:40 2013
From: jszhao at yeah.net (Jinsong Zhao)
Date: Mon, 23 Sep 2013 11:54:40 +0800
Subject: [R] legend for the plot with type = "b"
Message-ID: <523FBB80.9040909@yeah.net>

Hi there,

I plot a simple plot with the following code:

plot (rnorm(1:10), type = "b")
legend("top", "test", lty = 1, pch = 21)

The result is something wired for the line crosses the point in the 
legend while the line does not cross the point in the main plot.

Is there possibility to draw the legend that line does not cross the 
point, i.e., like the pattern in the main plot?

Any help is really appreciated.

Best regards,
Jinsong


From smartpink111 at yahoo.com  Mon Sep 23 05:56:29 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 22 Sep 2013 20:56:29 -0700 (PDT)
Subject: [R] xlim with barplot
In-Reply-To: <1379904936803-4676717.post@n4.nabble.com>
References: <1379904936803-4676717.post@n4.nabble.com>
Message-ID: <1379908589.89949.YahooMailNeo@web142604.mail.bf1.yahoo.com>

You could try ggplot() as well.
library(ggplot2)
library(gridExtra)
library(plyr)
x1<- count(x)
?y1<- count(y)
p1<-ggplot(x1,aes(x=x,y=freq))+geom_bar(stat="identity",colour="gray",fill="red")+xlim(c(35,85))+ theme_bw()+ theme(axis.line=element_line(colour="black"),
panel.grid.major=element_blank(), panel.grid.minor=element_blank(), panel.border=element_blank(),panel.background=element_blank())
?p2<-ggplot(y1,aes(x=x,y=freq))+geom_bar(stat="identity",colour="gray",fill="blue")+xlim(c(35,85)) +theme_bw()+ theme(axis.line=element_line(colour="black"),
panel.grid.major=element_blank(), panel.grid.minor=element_blank(), 
panel.border=element_blank(),panel.background=element_blank())
?grid.arrange(p1,p2,nrow=2)

A.K.



----- Original Message -----
From: David Arnold <dwarnold45 at suddenlink.net>
To: r-help at r-project.org
Cc: 
Sent: Sunday, September 22, 2013 10:55 PM
Subject: [R] xlim with barplot

Hi,

I want to compare to barplots with same horizontal axis limits.

x=c(55,56,57,58,59,60,60,60,61,62,63,64,65)
y=c(35,40,45,50,55,60,60,60,65,70,75,80,85)

par(mfrow=c(2,1))
barplot(table(x),xlim=c(35,85))
barplot(table(y),xlim=c(35,85))
par(mfrow=c(1,1))

But the bars disappear.

<http://r.789695.n4.nabble.com/file/n4676717/Rplot.png> 

Any suggestions?






--
View this message in context: http://r.789695.n4.nabble.com/xlim-with-barplot-tp4676717.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jim at bitwrit.com.au  Mon Sep 23 06:06:59 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Mon, 23 Sep 2013 14:06:59 +1000
Subject: [R] xlim with barplot
In-Reply-To: <1379908589.89949.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <1379904936803-4676717.post@n4.nabble.com>
	<1379908589.89949.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <523FBE63.1060209@bitwrit.com.au>

On 09/23/2013 01:56 PM, arun wrote:
> You could try ggplot() as well.
> library(ggplot2)
> library(gridExtra)
> library(plyr)
> x1<- count(x)
>   y1<- count(y)
> p1<-ggplot(x1,aes(x=x,y=freq))+geom_bar(stat="identity",colour="gray",fill="red")+xlim(c(35,85))+ theme_bw()+ theme(axis.line=element_line(colour="black"),
> panel.grid.major=element_blank(), panel.grid.minor=element_blank(), panel.border=element_blank(),panel.background=element_blank())
>   p2<-ggplot(y1,aes(x=x,y=freq))+geom_bar(stat="identity",colour="gray",fill="blue")+xlim(c(35,85)) +theme_bw()+ theme(axis.line=element_line(colour="black"),
> panel.grid.major=element_blank(), panel.grid.minor=element_blank(),
> panel.border=element_blank(),panel.background=element_blank())
>   grid.arrange(p1,p2,nrow=2)
>
> A.K.
>
Hi arun,
Okay, if we're allowed to use packages, challenge taken:

library(plotrix)
barp(tabulate(x,nbins=85)[35:85],names.arg=35:85)
barp(tabulate(y,nbins=85)[35:85],names.arg=35:85)

Jim


From smartpink111 at yahoo.com  Mon Sep 23 06:31:27 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 22 Sep 2013 21:31:27 -0700 (PDT)
Subject: [R] legend for the plot with type = "b"
In-Reply-To: <523FBB80.9040909@yeah.net>
References: <523FBB80.9040909@yeah.net>
Message-ID: <1379910687.75676.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
May be this helps.


set.seed(55)
?x<-rnorm(1:10)
?plot(x,type="n",xaxt="n",yaxt="n")
?legend1<- legend("top","test",lty=1,pch=21)
range1<- range(x)
?range1[2]<- 1.05* (range1[2]+ legend1$rect$h)
?plot(x,ylim=range1,type="b")
?legend1<- legend("top","test",lty=1,pch=21)

A.K.



----- Original Message -----
From: Jinsong Zhao <jszhao at yeah.net>
To: R help <r-help at r-project.org>
Cc: 
Sent: Sunday, September 22, 2013 11:54 PM
Subject: [R] legend for the plot with type = "b"

Hi there,

I plot a simple plot with the following code:

plot (rnorm(1:10), type = "b")
legend("top", "test", lty = 1, pch = 21)

The result is something wired for the line crosses the point in the 
legend while the line does not cross the point in the main plot.

Is there possibility to draw the legend that line does not cross the 
point, i.e., like the pattern in the main plot?

Any help is really appreciated.

Best regards,
Jinsong

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Mon Sep 23 06:40:22 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 22 Sep 2013 21:40:22 -0700 (PDT)
Subject: [R] basic matrix function
Message-ID: <1379911222.94592.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
Use `drop=FALSE`.
?b<- matrix(c(2,1,-1,-2),ncol=1)
?b[1:3,1]
#[1]? 2? 1 -1
?b[1:3,1,drop=FALSE]
#or
b[1:3,,drop=FALSE]
#???? [,1]
#[1,]??? 2
#[2,]??? 1
#[3,]?? -1


A.K.



hi all, 

i got a small question tonight. 
> matrix(b,4)[] 
? ? ?[,1] 
[1,] ? ?2 
[2,] ? ?1 
[3,] ? -1 
[4,] ? -2 
> dim(matrix(betan,4)) 
[1] 4 1 
As shown, b is a 4X1 matrix. 

> matrix(betan,4)[1:3,1] 
[1] ?2 ?1 -1 

However, I think the result should be 
? ? ?[,1] 
[1,] ? ?2 
[2,] ? ?1 
[3,] ? -1 

How could I get the result above? 
Many thanks,


From dwinsemius at comcast.net  Mon Sep 23 06:52:32 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 22 Sep 2013 23:52:32 -0500
Subject: [R] legend for the plot with type = "b"
In-Reply-To: <523FBB80.9040909@yeah.net>
References: <523FBB80.9040909@yeah.net>
Message-ID: <4773CD51-BEA8-41EE-9EF9-4B5638D66822@comcast.net>


On Sep 22, 2013, at 10:54 PM, Jinsong Zhao wrote:

> Hi there,
>
> I plot a simple plot with the following code:
>
> plot (rnorm(1:10), type = "b")
> legend("top", "test", lty = 1, pch = 21)

?par
plot (rnorm(1:10), type = "b")
legend("top", "test", lty = "69", pch = 21)

>
> The result is something wired for the line crosses the point in the  
> legend while the line does not cross the point in the main plot.
>
> Is there possibility to draw the legend that line does not cross the  
> point, i.e., like the pattern in the main plot?
>
> Any help is really appreciated.

-- 

David Winsemius, MD
Alameda, CA, USA


From pdalgd at gmail.com  Mon Sep 23 09:00:33 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 23 Sep 2013 09:00:33 +0200
Subject: [R] xlim with barplot
In-Reply-To: <523FB8C6.3030501@bitwrit.com.au>
References: <1379904936803-4676717.post@n4.nabble.com>
	<523FB8C6.3030501@bitwrit.com.au>
Message-ID: <70CBDAE0-BB03-40DD-9C98-400DB558F071@gmail.com>


On Sep 23, 2013, at 05:43 , Jim Lemon wrote:
> 
> barplot(tabulate(x,nbins=85)[35:85])
> barplot(tabulate(y,nbins=85)[35:85])
> 
> This is an underhanded trick to line up the bars as I think you want them.

Not all that underhanded! table() with numeric vectors _will_ skip values not present in data, which is usually not desirable if the magnitude of the values matters. It gets a bit awkward if there are nonpositive (or very large) values, though. A better solution could be table(factor(x, levels=35:85)).

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From s.wood at bath.ac.uk  Mon Sep 23 09:43:06 2013
From: s.wood at bath.ac.uk (Simon Wood)
Date: Mon, 23 Sep 2013 09:43:06 +0200
Subject: [R] Comparing two GAMs using anova (mgcv)
In-Reply-To: <78FD766E-0F9F-4FF5-AB5D-4E50B86789DE@gmail.com>
References: <78FD766E-0F9F-4FF5-AB5D-4E50B86789DE@gmail.com>
Message-ID: <523FF10A.3020206@bath.ac.uk>

It's ok to use an approximate F test here, provided you are careful with 
the interpretation. e.g. do look at the differences in EDF and not just 
the p-value (negative or very small EDF differences will render the 
p-value essentially meaningless). however...

Where-ever possible it is usually better to test using `summary' or 
`anova' with a single model argument. The approximations used by these 
are better founded than the approximate F-test. i.e. take a look at the 
p-values associated with the 's(y)' term in the larger model.

best,
Simon

On 20/09/13 13:37, Lucas Holland wrote:
> Hey all,
>
> I've fitted two GAMs to some data using mgcv. The only difference between the two models is that one includes an additional smooth term (the smooth terms are s(x), s(y) and s(log(y)), the difference being that one model contains s(y) as additional term whereas the other one only contains s(x) and s(log(y)) - x and y being my explanatory variables).
>
> I'm now trying to decide between those two models. There's no difference in deviance explained or R^2 and the diagnostic plots returned by gam.check() look fairly similar although the one of the fuller model looks slightly more satisfactory as far as the histogram of the residuals is concerned.
>
> I'm wondering whether it is appropriate to conduct an approximate F test using the anova function. I'm not 100% clear I've understood the documentation on that completely. Is it appropriate to conduct such a test if the only difference between models is the inclusion/exclusion of a smooth term?
>
> Conducting the test, I get the result that there's no reason to reject the null hypothesis that the simpler model (without s(y)) is correct.
>
> Thanks!
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
+44 (0)1225 386603               http://people.bath.ac.uk/sw283


From jim at bitwrit.com.au  Mon Sep 23 11:11:07 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Mon, 23 Sep 2013 19:11:07 +1000
Subject: [R] legend for the plot with type = "b"
In-Reply-To: <523FBB80.9040909@yeah.net>
References: <523FBB80.9040909@yeah.net>
Message-ID: <524005AB.3030106@bitwrit.com.au>

On 09/23/2013 01:54 PM, Jinsong Zhao wrote:
> Hi there,
>
> I plot a simple plot with the following code:
>
> plot (rnorm(1:10), type = "b")
> legend("top", "test", lty = 1, pch = 21)
>
> The result is something wired for the line crosses the point in the
> legend while the line does not cross the point in the main plot.
>
> Is there possibility to draw the legend that line does not cross the
> point, i.e., like the pattern in the main plot?
>
> Any help is really appreciated.
>
Hi Jinsong,
A bit messy, but doable:

plot (rnorm(1:10), type = "b")
library(plotrix)
legendg(x=sum(par("usr")[1:2])/2,y=par("usr")[4],
  legend="test",pch=list(c(45,1,45)),col=list(c(1,1,1)))

I plan to add the "top" etc. positions to the legendg function in the 
near future.

Jim


From axel.urbiz at gmail.com  Mon Sep 23 12:28:46 2013
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Mon, 23 Sep 2013 06:28:46 -0400
Subject: [R] Permutation Test on Interactions {coin}
Message-ID: <CAAyVsXJ7nzHZAm1-_btKHvv_eQbHfn1T0G+_1fN3ErW_uy+XzA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130923/82e96055/attachment.pl>

From chrisaa at med.umich.edu  Mon Sep 23 13:22:46 2013
From: chrisaa at med.umich.edu (Andrews, Chris)
Date: Mon, 23 Sep 2013 11:22:46 +0000
Subject: [R] PLS1 NIPALS question: error with chemometrics package?
In-Reply-To: <CAMAcwjwQXxgSjUpRj=ayAgDoo196D9gOuyN0wE-=TK4NyUPKog@mail.gmail.com>
References: <CAMAcwjwQXxgSjUpRj=ayAgDoo196D9gOuyN0wE-=TK4NyUPKog@mail.gmail.com>
Message-ID: <30411786F64EEF46856EFBA2CD9177992C1FB8DA@UHEXMBSPR03.umhs.med.umich.edu>

I think you need to divide by sqrt(sum(th^2)) rather than sum(th^2)

			ch <- as.numeric(t(yh) %*% th)/sqrt(sum(th^2))  # modified: / sqrt(SS)
			#ch <- as.numeric(t(yh) %*% th)/sum(th^2)  # modified: / SS
			# ch <- ch/as.vector(sqrt(t(th) %*% th))   # modified: removed normalization of ch

Chris

-----Original Message-----
From: Brad P [mailto:bpschn01 at gmail.com] 
Sent: Sunday, September 22, 2013 9:44 PM
To: r-help at r-project.org
Subject: [R] PLS1 NIPALS question: error with chemometrics package?

I am doing a self study, trying to understand PLS.
I have run across the following and hope that someone here can clarify as
to what is going on.

These are the data from Wold et al. (1984)

dat <- structure(list(t = 1:15, y = c(4.39, 4.42, 5, 5.85, 4.35, 4.51,
6.33, 6.37, 4.68, 5.04, 7.1, 5.04, 6, 5.48, 7.1), x1 = c(4.55,
4.74, 5.07, 5.77, 4.62, 4.41, 6.17, 6.17, 4.33, 4.62, 7.22, 4.64,
5.62, 6.19, 7.85), x2 = c(8.93, 8.93, 9.29, 9.9, 9.9, 9.93, 9.19,
9.19, 10.03, 10.29, 9.29, 10.22, 9.94, 9.77, 9.29), x3 = c(1.14,
1.14, 1.14, 1.14, 1.14, 1.14, 1.14, 1.14, 1.14, 1.14, 1.14, 1.14,
-0.07, -0.07, -0.07), x4 = c(0.7, 1.23, 0.19, 0.19, 1.23, 1.23,
0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19, 0.19), x5 = c(0.19,
0.19, 0.7, 1.64, 1.64, 2.35, 2.83, 2.56, 2.42, 3.36, 2.43, 2.95,
1.64, 1.64, 3.8), x6 = c(0.49, 0.49, 0, -0.1, -0.1, -0.2, -0.13,
-0.13, -0.08, -0.13, -0.3, -0.08, -0.19, -0.19, -0.3), x7 = c(1.24,
1.24, 0, -0.47, -0.47, -0.51, -0.93, -0.93, -0.38, -0.93, -1.6,
-0.38, -0.47, -0.47, -1.6), x8 = c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 0L, 0L, 1L, 0L, 1L, 1L, 1L)), .Names = c("t", "y", "x1",
"x2", "x3", "x4", "x5", "x6", "x7", "x8"), class = "data.frame", row.names
= c(NA,
-15L))
In Wold et al. (1984) (pg 741, Table 2) beta coefficients are given for PLS
(1) and PLS (2) where (1) and (2) correspond to the number of PLS
components retained. The coefficients are not the same as those when I run
the following:

library("chemometrics")

# retaining 1 component:
pls1_nipals(X=dat[,c(3:10)], y=dat[2], a=1, scale=TRUE)$b

# retaining 2 components:
pls1_nipals(X=dat[,c(3:10)], y=dat[2], a=2, scale=TRUE)$b



However, if I modify the source code like this:

 pls1_nipals_mod <- function(X, y, a, it = 50, tol = 1e-08, scale = FALSE)
    {
        Xh <- scale(X, center = TRUE, scale = scale)
        yh <- scale(y, center = TRUE, scale = scale)
        T <- NULL
        P <- NULL
        C <- NULL
        W <- NULL
        for (h in 1:a) {
            wh <- t(Xh) %*% yh/sum(yh^2)              # modified: / SS
            wh <- wh/as.vector(sqrt(t(wh) %*% wh))
            th <- Xh %*% wh
            ch <- as.numeric(t(yh) %*% th)/sum(th^2)  # modified: / SS
            # ch <- ch/as.vector(sqrt(t(th) %*% th))   # modified: removed
normalization of ch
            ph <- t(Xh) %*% th/as.vector(t(th) %*% th)
            Xh <- Xh - th %*% t(ph)
            yh <- yh - th * ch
            T <- cbind(T, th)
            P <- cbind(P, ph)
            C <- c(C, ch)
            W <- cbind(W, wh)
        }
        b <- W %*% solve(t(P) %*% W) %*% C
        list(P = P, T = T, W = W, C = C, b = b)
    }

pls1_nipals_mod(X=dat[,c(3:10)], y=dat[2], a=1, scale=TRUE)$b
pls1_nipals_mod(X=dat[,c(3:10)], y=dat[2], a=2, scale=TRUE)$b

These beta coefficients are exactly the same as in Wold et al. (1984)


Furthermore, if I do a leave-one-out CV, my modified version has a PRESS =
1.27, whereas the original pls1_nipals() function has a PRESS = 18.11!

That's not good, right? Here is my LOOCV code, 1:1 lines added in plots:

    ### LOOCV for original function
    out.j <- vector("list", length=nrow(dat))
    for(j in c(2:nrow(dat), 1)){
    b <- pls1_nipals(X=dat[-j,c(3:10)], y=dat[-j,2], a=2, scale=TRUE)$b
    dats <- scale(dat)
    y.est <- dats[j,c(3:10)] %*% b
    y.obs <- dats[j,2]
    out.j[[j]] <- data.frame(y.obs, y.est)
        }
    out <- do.call(rbind, out.j)
    sqrt(sum((out[,1]-out[,2])^2) )
    plot(out[,2]~ out[,1], ylab="pred", xlab="obs")
    abline(0,1, col="grey")

### LOOCV for modified function
    out.j <- vector("list", length=nrow(dat))
    for(j in c(2:nrow(dat), 1)){
    b <- pls1_nipals_mod(X=dat[-j,c(3:10)], y=dat[-j,2], a=2, scale=TRUE)$b
    dats <- scale(dat)
    y.est <- dats[j,c(3:10)] %*% b
    y.obs <- dats[j,2]
    out.j[[j]] <- data.frame(y.obs, y.est)
        }
    out <- do.call(rbind, out.j)
    sqrt(sum((out[,1]-out[,2])^2) )
    plot(out[,2]~ out[,1], ylab="pred", xlab="obs")
    abline(0,1, col="grey")


Is this an error with the chemometrics function; or am I simply
understanding something incorrectly?
Thank you.


Citation: Wold, S., A. Ruhe, H. Wold, W. Dunn. (1984) The collinearity
problem in linear regression. The partial least squares (PLS) approach to
generalized inverses*" SIAM J. Sci. Stat. Comput.

	[[alternative HTML version deleted]]


**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues 


From julian.bothe at elitepartner.de  Mon Sep 23 13:45:15 2013
From: julian.bothe at elitepartner.de (julian.bothe at elitepartner.de)
Date: Mon, 23 Sep 2013 13:45:15 +0200 (CEST)
Subject: [R] Bug in Survival - predict.coxph with collapse? (related to
	question "censor=FALSE and id options in survfit.coxph")
Message-ID: <a10662b9.00001314.00000007@FIW7PC12.ELITEMEDIANET>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130923/23246dfc/attachment.pl>

From friendly at yorku.ca  Mon Sep 23 14:53:11 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Mon, 23 Sep 2013 08:53:11 -0400
Subject: [R] Conditioning plots (wth coplot function) with logistic
 regression curves
In-Reply-To: <1379897329.55709.YahooMailNeo@web142406.mail.bf1.yahoo.com>
References: <1379819554.56426.YahooMailNeo@web142404.mail.bf1.yahoo.com>
	<523F813C.1040301@yorku.ca>
	<1379897329.55709.YahooMailNeo@web142406.mail.bf1.yahoo.com>
Message-ID: <524039B7.4050904@yorku.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130923/cb1ceef3/attachment.pl>

From olivier.eterradossi at mines-ales.fr  Mon Sep 23 14:47:03 2013
From: olivier.eterradossi at mines-ales.fr (Olivier Eterradossi)
Date: Mon, 23 Sep 2013 12:47:03 +0000
Subject: [R] time zones from longitude, latitude, and date
References: <CAAZ8xcmpPMErsEYGdMbmA7LqxB7HDochipqUHtjHvAYUr+mQ4Q@mail.gmail.com>
Message-ID: <loom.20130923T144334-585@post.gmane.org>

carlisle thacker <carlisle.thacker <at> gmail.com> writes:



> 

> I have data that provide longitude, latitude, and local date and time but

> no information about the corresponding time zone.  How to identify the 
time

> zone so they can be converted to a common date/time?

> 

> Thanks,

> 

> Carlisle

> 

> 	[[alternative HTML version deleted]]

> 

> 



Hi list,



maybe I didn't read the post carefully enough, but what about using the 
GNtimezone in Barry Rowlinson's "geonames" package ?



Olivier


From deter088 at umn.edu  Mon Sep 23 15:38:49 2013
From: deter088 at umn.edu (Charles Determan Jr)
Date: Mon, 23 Sep 2013 08:38:49 -0500
Subject: [R] Recycling other internal package functions
Message-ID: <CAOLJphmY+KF=HPOQuE_hVaW6BrT0tMo+sgUcjp=m_ZpAGJy-kA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130923/bbd49266/attachment.pl>

From smartpink111 at yahoo.com  Mon Sep 23 16:04:44 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 23 Sep 2013 07:04:44 -0700 (PDT)
Subject: [R] Date Comparing *Problem*
Message-ID: <1379945084.663.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Try:

set.seed(634)
dat<- data.frame(date=seq(as.Date("2012-11-15"),length.out=10,by="1 day"), value=rnorm(10))
subset(dat,"2012-11-19" < date)? 
#???????? date????? value
#6? 2012-11-20 -0.3290021
#7? 2012-11-21? 0.3106802
#8? 2012-11-22 -1.0782814
#9? 2012-11-23 -0.1333426
#10 2012-11-24? 0.8441754
A.K.



I have a problem with comparing dates. i tried it like "datesub = 
subset(data, 2012-11-19 < data$date)", but this doesn't work and i 
don't know why. 

Hope you can help me. 

here are my files: 
http://uploaded.net/file/n9sxdm0v


From jszhao at yeah.net  Mon Sep 23 17:00:57 2013
From: jszhao at yeah.net (Jinsong Zhao)
Date: Mon, 23 Sep 2013 23:00:57 +0800
Subject: [R] legend for the plot with type = "b"
In-Reply-To: <4773CD51-BEA8-41EE-9EF9-4B5638D66822@comcast.net>
References: <523FBB80.9040909@yeah.net>
	<4773CD51-BEA8-41EE-9EF9-4B5638D66822@comcast.net>
Message-ID: <524057A9.8010704@yeah.net>

On 2013/9/23 12:52, David Winsemius wrote:
>
> On Sep 22, 2013, at 10:54 PM, Jinsong Zhao wrote:
>
>> Hi there,
>>
>> I plot a simple plot with the following code:
>>
>> plot (rnorm(1:10), type = "b")
>> legend("top", "test", lty = 1, pch = 21)
>
> ?par
> plot (rnorm(1:10), type = "b")
> legend("top", "test", lty = "69", pch = 21)

Thank you very much, it works like a champ! I never know the line in 
legend can be draw like that.

Regards,
Jinsong

>
>>
>> The result is something wired for the line crosses the point in the
>> legend while the line does not cross the point in the main plot.
>>
>> Is there possibility to draw the legend that line does not cross the
>> point, i.e., like the pattern in the main plot?
>>
>> Any help is really appreciated.
>


From lmramba at ufl.edu  Mon Sep 23 17:01:13 2013
From: lmramba at ufl.edu (Laz)
Date: Mon, 23 Sep 2013 11:01:13 -0400
Subject: [R] Creating rectangular plots with x and y coordinates and
 treatments from a matrix for a randomized block design
In-Reply-To: <CAAxdm-7RJRPNMrG+f8krgGXUe1R-sEcmpyoSyAWLhXc2T79XxQ@mail.gmail.com>
References: <523E7B13.1020705@ufl.edu>
	<CAAxdm-6RBhcMOTL2SCtjv=Pq+r89yiyowxm3RwdXeTUgTwXNCw@mail.gmail.com>
	<523F4A6A.4060204@ufl.edu> <523F5163.20709@xtra.co.nz>
	<523F53D6.4080009@ufl.edu> <523F5547.5050002@sapo.pt>
	<523F5701.2010303@ufl.edu>
	<CAAxdm-7RJRPNMrG+f8krgGXUe1R-sEcmpyoSyAWLhXc2T79XxQ@mail.gmail.com>
Message-ID: <524057B9.8020506@ufl.edu>

Thanks. Sweave/Latex is done the job for me !

Regards,
Laz

On 9/22/2013 8:26 PM, jim holtman wrote:
> CHeck out the 'tables' package if you want to create pretty outputs of
> your tables.  Exactly where do you plan to use them?  You can also use
> Sweave/Latex to create such tables.
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
>
> On Sun, Sep 22, 2013 at 4:45 PM, Laz <lmramba at ufl.edu> wrote:
>> Hi,
>>
>> fortune("Yoda") returns a quote of fortunes.
>>
>> My problem was to draw horizontal and vertical lines to separate the blocks
>> in my design. Each block has 4 elements. The first and second rows and
>> columns are in block 1, 3rd  and 4th rows and 1st and 2nd columns are in 3
>> etc
>>
>>
>>      [,1] [,2] [,3] [,4]
>> [1,]    2    4    2    3
>> [2,]    1    3    4    1
>> [3,]    3    2    2    3
>> [4,]    1    4    4    1
>>
>>
>>
>> On 9/22/2013 4:38 PM, Rui Barradas wrote:
>>> fortune("Yoda"). :-)
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jszhao at yeah.net  Mon Sep 23 17:04:00 2013
From: jszhao at yeah.net (Jinsong Zhao)
Date: Mon, 23 Sep 2013 23:04:00 +0800
Subject: [R] legend for the plot with type = "b"
In-Reply-To: <524005AB.3030106@bitwrit.com.au>
References: <523FBB80.9040909@yeah.net> <524005AB.3030106@bitwrit.com.au>
Message-ID: <52405860.5@yeah.net>

On 2013/9/23 17:11, Jim Lemon wrote:
> On 09/23/2013 01:54 PM, Jinsong Zhao wrote:
>> Hi there,
>>
>> I plot a simple plot with the following code:
>>
>> plot (rnorm(1:10), type = "b")
>> legend("top", "test", lty = 1, pch = 21)
>>
>> The result is something wired for the line crosses the point in the
>> legend while the line does not cross the point in the main plot.
>>
>> Is there possibility to draw the legend that line does not cross the
>> point, i.e., like the pattern in the main plot?
>>
>> Any help is really appreciated.
>>
> Hi Jinsong,
> A bit messy, but doable:
>
> plot (rnorm(1:10), type = "b")
> library(plotrix)
> legendg(x=sum(par("usr")[1:2])/2,y=par("usr")[4],
>   legend="test",pch=list(c(45,1,45)),col=list(c(1,1,1)))
>
> I plan to add the "top" etc. positions to the legendg function in the
> near future.
>
> Jim
>

Hi Jim,

Thank you very much for pointing me to plotrix, which is a great package.

Regards,
Jinsong


From 538280 at gmail.com  Mon Sep 23 18:27:58 2013
From: 538280 at gmail.com (Greg Snow)
Date: Mon, 23 Sep 2013 10:27:58 -0600
Subject: [R]
	=?gb2312?b?tPC4tDogIHRoZSB2YWx1ZXMgb2YgcHJlZGljdCggLCB0eXBl?=
	=?gb2312?b?ID0gInRlcm1zIiwgKQ==?=
In-Reply-To: <020d01ceb758$038f6fa0$0aae4ee0$@139.com>
References: <018f01ceb385$a2645630$e72d0290$@139.com>
	<CAFEqCdyO+19E1rCCL0M9YAj1BwgT9bf7is09DSUgFqAW0fFYRw@mail.gmail.com>
	<020d01ceb758$038f6fa0$0aae4ee0$@139.com>
Message-ID: <CAFEqCdwgUffZ6v+vj1EDq2NqC6K3XCfiCMR_j2wZTvWvmgHocA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130923/206bd458/attachment.pl>

From wshadish at ucmerced.edu  Mon Sep 23 19:41:08 2013
From: wshadish at ucmerced.edu (William Shadish)
Date: Mon, 23 Sep 2013 10:41:08 -0700
Subject: [R] two questions about xyplot
Message-ID: <52407D34.9050405@ucmerced.edu>

Dear R helpers,

I am generating three artificial short interrupted time series datasets
(single-case designs; call them Case 1, Case 2, Case 3) and then plotting
them in xyplot. I will put the entire code below so you can reproduce. I
have been unable to figure out how to do two things.

1. Each time series has 24 time points divided into four phases. Call them
phases A, B, C, D for convenience. I have used running() to compute the
means of the observations in each of these four parts; and I saved these as
objects called mn1 (for Case 1), mn2 (Case 2) and mn3 (Case 3). So mn1
contains the four means for A, B, C, D phases for Case 1, etc. I want to
insert these means into the xyplot in the appropriate place. For instance,
insert the first mean from mn1 into phase A of Case 1, the second mean into
phase B of Case 1, and so forth until insert the fourth mean from mn3 into
phase D of Case 3. Ideally, it would insert something like "M = 49.02" or
"Xbar = 49.02" into phase A for Case 1.

2. The xyplot code I use creates a line connecting the data points, and that
line is continuous over the entire graph. I would like to have the lines be
discontinuous between phases. Phase changes are indicated by panel.abline()
in the code, and occur at time points 6.5, 12.5, and 18.5. So, for example,
I would like a line connecting the datapoints from 1 to 6, then 7-12, then
13-18, then 19-24 (but not including 6-7, 12-13, and 18-19).

I appreciate any help you might be able to offer.

Will Shadish

Here is the code:
#############################################################################
library(gtools)
library(lattice)
###g = .66
z <- rnorm(24, mean = 0, sd = 10)
w <- rnorm(24, mean = 0, sd = 10)
###change mean = to vary the effect size
tm <- rnorm(6, mean = 10, sd = 10)
b <- rep(0,6)
c <- rep(1,6)
tmt <- c(b,tm,b,tm)
for (t in 2:24) z[t] <- 0.25 * z[t - 1] + w[t]
dvy <- 50 + z + tmt
jid <- rep(1,24)
sid <- rep(1,24)
pid <- rep(1,24)
dvid <- rep(1,24)
desvar <- rep(1,24)
dvdir <- rep(0,24)
sessidx <- c(1:24)
m <- rep(1,6)
n <- rep(2,6)
o <- rep(3,6)
p <- rep(4,6)
numph <- c(m,n,o,p)
phasebtm <- c(b,c,b,c)
d1 <- cbind(jid,sid,pid,dvid,desvar,dvdir,dvy,sessidx,numph,phasebtm)
mn1 <- running(dvy, width=6, by=6)

#second dataset
z <- rnorm(24, mean = 0, sd = 10)
w <- rnorm(24, mean = 0, sd = 10)
tm <- rnorm(6, mean = 10, sd = 10)
b <- rep(0,6)
c <- rep(1,6)
tmt <- c(b,tm,b,tm)
for (t in 2:24) z[t] <- 0.25 * z[t - 1] + w[t]
dvy <- 50 + z + tmt
jid <- rep(1,24)
sid <- rep(1,24)
pid <- rep(2,24)
dvid <- rep(1,24)
desvar <- rep(1,24)
dvdir <- rep(0,24)
sessidx <- c(1:24)
m <- rep(1,6)
n <- rep(2,6)
o <- rep(3,6)
p <- rep(4,6)
numph <- c(m,n,o,p)
phasebtm <- c(b,c,b,c)
d2 <- cbind(jid,sid,pid,dvid,desvar,dvdir,dvy,sessidx,numph,phasebtm)
mn2 <- running(dvy, width=6, by=6)

#third dataset
z <- rnorm(24, mean = 0, sd = 10)
w <- rnorm(24, mean = 0, sd = 10)
tm <- rnorm(6, mean = 10, sd = 10)
b <- rep(0,6)
c <- rep(1,6)
tmt <- c(b,tm,b,tm)
for (t in 2:24) z[t] <- 0.25 * z[t - 1] + w[t]
dvy <- 50 + z + tmt
jid <- rep(1,24)
sid <- rep(1,24)
pid <- rep(3,24)
dvid <- rep(1,24)
desvar <- rep(1,24)
dvdir <- rep(0,24)
sessidx <- c(1:24)
m <- rep(1,6)
n <- rep(2,6)
o <- rep(3,6)
p <- rep(4,6)
numph <- c(m,n,o,p)
phasebtm <- c(b,c,b,c)
d3 <- cbind(jid,sid,pid,dvid,desvar,dvdir,dvy,sessidx,numph,phasebtm)
mn3 <- running(dvy, width=6, by=6)

#concatenate d1 d2 d3
d66 <- rbind(d1, d2, d3)
d66df <- as.data.frame(d66)
d66df$case <- ordered(d66df$pid,
levels = c(1,2,3),
labels = c("Case 3", "Case 2", "Case 1"))
p<-xyplot(dvy ~ sessidx | case, data=d66df,
     layout=c(1, 3), xlab= "Sessions",
     ylab = "Number of Seconds",
     type="l")
update(p, panel=function(...){
         panel.xyplot(...)
         panel.abline(v=6.5)
         panel.abline(v=12.5)
         panel.abline(v=18.5)
} )

-- 
William R. Shadish
Distinguished Professor
Founding Faculty

Mailing Address:
William R. Shadish
University of California
School of Social Sciences, Humanities and Arts
5200 North Lake Rd
Merced CA  95343

Physical/Delivery Address:
University of California Merced
ATTN: William Shadish
School of Social Sciences, Humanities and Arts
Facilities Services Building A
5200 North Lake Rd.
Merced, CA 95343

209-228-4372 voice
209-228-4007 fax (communal fax: be sure to include cover sheet)
wshadish at ucmerced.edu
http://faculty.ucmerced.edu/wshadish/index.htm
http://psychology.ucmerced.edu


From richardkwock at gmail.com  Mon Sep 23 20:23:25 2013
From: richardkwock at gmail.com (Richard Kwock)
Date: Mon, 23 Sep 2013 11:23:25 -0700
Subject: [R] two questions about xyplot
In-Reply-To: <52407D34.9050405@ucmerced.edu>
References: <52407D34.9050405@ucmerced.edu>
Message-ID: <CAJU8Py0EGJ-0R4tq5=qd74=T3Ln0SXg3-ZEf54QtmsrMXO=39A@mail.gmail.com>

Hi,

To answer your second question you can do something like this:

p<-xyplot(dvy ~ sessidx | case, group = numph, data=d66df, col = c(1:4),
    layout=c(1, 3), xlab= "Sessions",
    ylab = "Number of Seconds",
    type="l")

update(p, panel=function(...){
        panel.xyplot(...)
        panel.abline(v=6.5)
        panel.abline(v=12.5)
        panel.abline(v=18.5)
} )

By setting the "group" parameter in xyplot to be "numph",  xyplot will
plot different lines for each group of numph you have in each case.

For your first question, did you mean you want a text to display the
mean in each panel?

Richard


On Mon, Sep 23, 2013 at 10:41 AM, William Shadish <wshadish at ucmerced.edu> wrote:
> Dear R helpers,
>
> I am generating three artificial short interrupted time series datasets
> (single-case designs; call them Case 1, Case 2, Case 3) and then plotting
> them in xyplot. I will put the entire code below so you can reproduce. I
> have been unable to figure out how to do two things.
>
> 1. Each time series has 24 time points divided into four phases. Call them
> phases A, B, C, D for convenience. I have used running() to compute the
> means of the observations in each of these four parts; and I saved these as
> objects called mn1 (for Case 1), mn2 (Case 2) and mn3 (Case 3). So mn1
> contains the four means for A, B, C, D phases for Case 1, etc. I want to
> insert these means into the xyplot in the appropriate place. For instance,
> insert the first mean from mn1 into phase A of Case 1, the second mean into
> phase B of Case 1, and so forth until insert the fourth mean from mn3 into
> phase D of Case 3. Ideally, it would insert something like "M = 49.02" or
> "Xbar = 49.02" into phase A for Case 1.
>
> 2. The xyplot code I use creates a line connecting the data points, and that
> line is continuous over the entire graph. I would like to have the lines be
> discontinuous between phases. Phase changes are indicated by panel.abline()
> in the code, and occur at time points 6.5, 12.5, and 18.5. So, for example,
> I would like a line connecting the datapoints from 1 to 6, then 7-12, then
> 13-18, then 19-24 (but not including 6-7, 12-13, and 18-19).
>
> I appreciate any help you might be able to offer.
>
> Will Shadish
>
> Here is the code:
> #############################################################################
> library(gtools)
> library(lattice)
> ###g = .66
> z <- rnorm(24, mean = 0, sd = 10)
> w <- rnorm(24, mean = 0, sd = 10)
> ###change mean = to vary the effect size
> tm <- rnorm(6, mean = 10, sd = 10)
> b <- rep(0,6)
> c <- rep(1,6)
> tmt <- c(b,tm,b,tm)
> for (t in 2:24) z[t] <- 0.25 * z[t - 1] + w[t]
> dvy <- 50 + z + tmt
> jid <- rep(1,24)
> sid <- rep(1,24)
> pid <- rep(1,24)
> dvid <- rep(1,24)
> desvar <- rep(1,24)
> dvdir <- rep(0,24)
> sessidx <- c(1:24)
> m <- rep(1,6)
> n <- rep(2,6)
> o <- rep(3,6)
> p <- rep(4,6)
> numph <- c(m,n,o,p)
> phasebtm <- c(b,c,b,c)
> d1 <- cbind(jid,sid,pid,dvid,desvar,dvdir,dvy,sessidx,numph,phasebtm)
> mn1 <- running(dvy, width=6, by=6)
>
> #second dataset
> z <- rnorm(24, mean = 0, sd = 10)
> w <- rnorm(24, mean = 0, sd = 10)
> tm <- rnorm(6, mean = 10, sd = 10)
> b <- rep(0,6)
> c <- rep(1,6)
> tmt <- c(b,tm,b,tm)
> for (t in 2:24) z[t] <- 0.25 * z[t - 1] + w[t]
> dvy <- 50 + z + tmt
> jid <- rep(1,24)
> sid <- rep(1,24)
> pid <- rep(2,24)
> dvid <- rep(1,24)
> desvar <- rep(1,24)
> dvdir <- rep(0,24)
> sessidx <- c(1:24)
> m <- rep(1,6)
> n <- rep(2,6)
> o <- rep(3,6)
> p <- rep(4,6)
> numph <- c(m,n,o,p)
> phasebtm <- c(b,c,b,c)
> d2 <- cbind(jid,sid,pid,dvid,desvar,dvdir,dvy,sessidx,numph,phasebtm)
> mn2 <- running(dvy, width=6, by=6)
>
> #third dataset
> z <- rnorm(24, mean = 0, sd = 10)
> w <- rnorm(24, mean = 0, sd = 10)
> tm <- rnorm(6, mean = 10, sd = 10)
> b <- rep(0,6)
> c <- rep(1,6)
> tmt <- c(b,tm,b,tm)
> for (t in 2:24) z[t] <- 0.25 * z[t - 1] + w[t]
> dvy <- 50 + z + tmt
> jid <- rep(1,24)
> sid <- rep(1,24)
> pid <- rep(3,24)
> dvid <- rep(1,24)
> desvar <- rep(1,24)
> dvdir <- rep(0,24)
> sessidx <- c(1:24)
> m <- rep(1,6)
> n <- rep(2,6)
> o <- rep(3,6)
> p <- rep(4,6)
> numph <- c(m,n,o,p)
> phasebtm <- c(b,c,b,c)
> d3 <- cbind(jid,sid,pid,dvid,desvar,dvdir,dvy,sessidx,numph,phasebtm)
> mn3 <- running(dvy, width=6, by=6)
>
> #concatenate d1 d2 d3
> d66 <- rbind(d1, d2, d3)
> d66df <- as.data.frame(d66)
> d66df$case <- ordered(d66df$pid,
> levels = c(1,2,3),
> labels = c("Case 3", "Case 2", "Case 1"))
> p<-xyplot(dvy ~ sessidx | case, data=d66df,
>     layout=c(1, 3), xlab= "Sessions",
>     ylab = "Number of Seconds",
>     type="l")
> update(p, panel=function(...){
>         panel.xyplot(...)
>         panel.abline(v=6.5)
>         panel.abline(v=12.5)
>         panel.abline(v=18.5)
> } )
>
> --
> William R. Shadish
> Distinguished Professor
> Founding Faculty
>
> Mailing Address:
> William R. Shadish
> University of California
> School of Social Sciences, Humanities and Arts
> 5200 North Lake Rd
> Merced CA  95343
>
> Physical/Delivery Address:
> University of California Merced
> ATTN: William Shadish
> School of Social Sciences, Humanities and Arts
> Facilities Services Building A
> 5200 North Lake Rd.
> Merced, CA 95343
>
> 209-228-4372 voice
> 209-228-4007 fax (communal fax: be sure to include cover sheet)
> wshadish at ucmerced.edu
> http://faculty.ucmerced.edu/wshadish/index.htm
> http://psychology.ucmerced.edu
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wshadish at ucmerced.edu  Mon Sep 23 20:29:49 2013
From: wshadish at ucmerced.edu (William Shadish)
Date: Mon, 23 Sep 2013 11:29:49 -0700
Subject: [R] two questions about xyplot
In-Reply-To: <CAJU8Py0EGJ-0R4tq5=qd74=T3Ln0SXg3-ZEf54QtmsrMXO=39A@mail.gmail.com>
References: <52407D34.9050405@ucmerced.edu>
	<CAJU8Py0EGJ-0R4tq5=qd74=T3Ln0SXg3-ZEf54QtmsrMXO=39A@mail.gmail.com>
Message-ID: <5240889D.20806@ucmerced.edu>

Dear Richard, your solution to the second question worked like a charm. 
Thanks! So much to learn about this stuff, but at least it is fun.

On the first question, yes, I want a text to display the mean in each of 
the 12 panels.

Will

On 9/23/2013 11:23 AM, Richard Kwock wrote:
> Hi,
>
> To answer your second question you can do something like this:
>
> p<-xyplot(dvy ~ sessidx | case, group = numph, data=d66df, col = c(1:4),
>      layout=c(1, 3), xlab= "Sessions",
>      ylab = "Number of Seconds",
>      type="l")
>
> update(p, panel=function(...){
>          panel.xyplot(...)
>          panel.abline(v=6.5)
>          panel.abline(v=12.5)
>          panel.abline(v=18.5)
> } )
>
> By setting the "group" parameter in xyplot to be "numph",  xyplot will
> plot different lines for each group of numph you have in each case.
>
> For your first question, did you mean you want a text to display the
> mean in each panel?
>
> Richard
>
>
> On Mon, Sep 23, 2013 at 10:41 AM, William Shadish <wshadish at ucmerced.edu> wrote:
>> Dear R helpers,
>>
>> I am generating three artificial short interrupted time series datasets
>> (single-case designs; call them Case 1, Case 2, Case 3) and then plotting
>> them in xyplot. I will put the entire code below so you can reproduce. I
>> have been unable to figure out how to do two things.
>>
>> 1. Each time series has 24 time points divided into four phases. Call them
>> phases A, B, C, D for convenience. I have used running() to compute the
>> means of the observations in each of these four parts; and I saved these as
>> objects called mn1 (for Case 1), mn2 (Case 2) and mn3 (Case 3). So mn1
>> contains the four means for A, B, C, D phases for Case 1, etc. I want to
>> insert these means into the xyplot in the appropriate place. For instance,
>> insert the first mean from mn1 into phase A of Case 1, the second mean into
>> phase B of Case 1, and so forth until insert the fourth mean from mn3 into
>> phase D of Case 3. Ideally, it would insert something like "M = 49.02" or
>> "Xbar = 49.02" into phase A for Case 1.
>>
>> 2. The xyplot code I use creates a line connecting the data points, and that
>> line is continuous over the entire graph. I would like to have the lines be
>> discontinuous between phases. Phase changes are indicated by panel.abline()
>> in the code, and occur at time points 6.5, 12.5, and 18.5. So, for example,
>> I would like a line connecting the datapoints from 1 to 6, then 7-12, then
>> 13-18, then 19-24 (but not including 6-7, 12-13, and 18-19).
>>
>> I appreciate any help you might be able to offer.
>>
>> Will Shadish
>>
>> Here is the code:
>> #############################################################################
>> library(gtools)
>> library(lattice)
>> ###g = .66
>> z <- rnorm(24, mean = 0, sd = 10)
>> w <- rnorm(24, mean = 0, sd = 10)
>> ###change mean = to vary the effect size
>> tm <- rnorm(6, mean = 10, sd = 10)
>> b <- rep(0,6)
>> c <- rep(1,6)
>> tmt <- c(b,tm,b,tm)
>> for (t in 2:24) z[t] <- 0.25 * z[t - 1] + w[t]
>> dvy <- 50 + z + tmt
>> jid <- rep(1,24)
>> sid <- rep(1,24)
>> pid <- rep(1,24)
>> dvid <- rep(1,24)
>> desvar <- rep(1,24)
>> dvdir <- rep(0,24)
>> sessidx <- c(1:24)
>> m <- rep(1,6)
>> n <- rep(2,6)
>> o <- rep(3,6)
>> p <- rep(4,6)
>> numph <- c(m,n,o,p)
>> phasebtm <- c(b,c,b,c)
>> d1 <- cbind(jid,sid,pid,dvid,desvar,dvdir,dvy,sessidx,numph,phasebtm)
>> mn1 <- running(dvy, width=6, by=6)
>>
>> #second dataset
>> z <- rnorm(24, mean = 0, sd = 10)
>> w <- rnorm(24, mean = 0, sd = 10)
>> tm <- rnorm(6, mean = 10, sd = 10)
>> b <- rep(0,6)
>> c <- rep(1,6)
>> tmt <- c(b,tm,b,tm)
>> for (t in 2:24) z[t] <- 0.25 * z[t - 1] + w[t]
>> dvy <- 50 + z + tmt
>> jid <- rep(1,24)
>> sid <- rep(1,24)
>> pid <- rep(2,24)
>> dvid <- rep(1,24)
>> desvar <- rep(1,24)
>> dvdir <- rep(0,24)
>> sessidx <- c(1:24)
>> m <- rep(1,6)
>> n <- rep(2,6)
>> o <- rep(3,6)
>> p <- rep(4,6)
>> numph <- c(m,n,o,p)
>> phasebtm <- c(b,c,b,c)
>> d2 <- cbind(jid,sid,pid,dvid,desvar,dvdir,dvy,sessidx,numph,phasebtm)
>> mn2 <- running(dvy, width=6, by=6)
>>
>> #third dataset
>> z <- rnorm(24, mean = 0, sd = 10)
>> w <- rnorm(24, mean = 0, sd = 10)
>> tm <- rnorm(6, mean = 10, sd = 10)
>> b <- rep(0,6)
>> c <- rep(1,6)
>> tmt <- c(b,tm,b,tm)
>> for (t in 2:24) z[t] <- 0.25 * z[t - 1] + w[t]
>> dvy <- 50 + z + tmt
>> jid <- rep(1,24)
>> sid <- rep(1,24)
>> pid <- rep(3,24)
>> dvid <- rep(1,24)
>> desvar <- rep(1,24)
>> dvdir <- rep(0,24)
>> sessidx <- c(1:24)
>> m <- rep(1,6)
>> n <- rep(2,6)
>> o <- rep(3,6)
>> p <- rep(4,6)
>> numph <- c(m,n,o,p)
>> phasebtm <- c(b,c,b,c)
>> d3 <- cbind(jid,sid,pid,dvid,desvar,dvdir,dvy,sessidx,numph,phasebtm)
>> mn3 <- running(dvy, width=6, by=6)
>>
>> #concatenate d1 d2 d3
>> d66 <- rbind(d1, d2, d3)
>> d66df <- as.data.frame(d66)
>> d66df$case <- ordered(d66df$pid,
>> levels = c(1,2,3),
>> labels = c("Case 3", "Case 2", "Case 1"))
>> p<-xyplot(dvy ~ sessidx | case, data=d66df,
>>      layout=c(1, 3), xlab= "Sessions",
>>      ylab = "Number of Seconds",
>>      type="l")
>> update(p, panel=function(...){
>>          panel.xyplot(...)
>>          panel.abline(v=6.5)
>>          panel.abline(v=12.5)
>>          panel.abline(v=18.5)
>> } )
>>
>> --
>> William R. Shadish
>> Distinguished Professor
>> Founding Faculty
>>
>> Mailing Address:
>> William R. Shadish
>> University of California
>> School of Social Sciences, Humanities and Arts
>> 5200 North Lake Rd
>> Merced CA  95343
>>
>> Physical/Delivery Address:
>> University of California Merced
>> ATTN: William Shadish
>> School of Social Sciences, Humanities and Arts
>> Facilities Services Building A
>> 5200 North Lake Rd.
>> Merced, CA 95343
>>
>> 209-228-4372 voice
>> 209-228-4007 fax (communal fax: be sure to include cover sheet)
>> wshadish at ucmerced.edu
>> http://faculty.ucmerced.edu/wshadish/index.htm
>> http://psychology.ucmerced.edu
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>

-- 
William R. Shadish
Distinguished Professor
Founding Faculty

Mailing Address:
William R. Shadish
University of California
School of Social Sciences, Humanities and Arts
5200 North Lake Rd
Merced CA  95343

Physical/Delivery Address:
University of California Merced
ATTN: William Shadish
School of Social Sciences, Humanities and Arts
Facilities Services Building A
5200 North Lake Rd.
Merced, CA 95343

209-228-4372 voice
209-228-4007 fax (communal fax: be sure to include cover sheet)
wshadish at ucmerced.edu
http://faculty.ucmerced.edu/wshadish/index.htm
http://psychology.ucmerced.edu


From smartpink111 at yahoo.com  Mon Sep 23 20:36:45 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 23 Sep 2013 11:36:45 -0700 (PDT)
Subject: [R] Turning a string into a real vector
Message-ID: <1379961405.85039.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi

If I use your code:
grep ("ACC", input, FALSE, FALSE, TRUE)
#[1] "ACC,1.1,2.2,3.3,4.4\nACC,2.2,3,4,5\nADN,3.3,4,5\nACC,4.4,5.5,6.6,7.7\nADN,5.5,6,7\n"
Seems like you forgot one line of code: with ?strsplit()

vec1<- grep("ACC",strsplit(input,"\n")[[1]],FALSE,FALSE,TRUE)
vec1
#[1] "ACC,1.1,2.2,3.3,4.4" "ACC,2.2,3,4,5"?????? "ACC,4.4,5.5,6.6,7.7"

?vec2<- grep("ADN",strsplit(input,"\n")[[1]],FALSE,FALSE,TRUE)
vec2
#[1] "ADN,3.3,4,5" "ADN,5.5,6,7"
length(vec2)
#[1] 2


A.K.



I have the following string input: 

input <- "ACC,1.1,2.2,3.3,4.4\nACC,2.2,3,4,5\nADN,3.3,4,5\nACC,4.4,5.5,6.6,7.7\nADN,5.5,6,7\n" 

Note that \n is a real line feed in the data and the numbers are
 all made up and might be other values. The key is that the first number
 is a float, the ACC packets are all floats and the ADN the first value 
is a float and the rest are ints. 

I want to turn this string into a vector of packets. I tired 
using grep and regexpr without luck. I would also like to filter the 
packets so that I can get a vector of just the ACC packets and another 
vector of just the ADN packets. 

When I tried this: 

grep ("ACC", input, FALSE, FALSE, TRUE) 

What I ended up with was: 

[1] "ACC,1.1,2.2,3.3,4.4" ? ? ? ? ? ?"ACC,2.2,3,4,5" ? ? ? ? 
"ADN,3.3,4,5" ? ? ? ? ? ? ? ? ? ?"ACC,4.4,5.5,6.6,7.7" ? ? ? ? ? 
"ADN,5.5,6,7" 

What I wanted was: 

[1] "ACC,1.1,2.2,3.3,4.4" 
[2] "ACC,2.2,3,4,5" 
[3] "ACC,4.4,5.5,6.6,7.7" 

Then I wanted to put in grep ("ADN", input, FALSE, FALSE, TRUE) and get out: 

[1] "ADN,3.3,4,5" 
[2] "ADN,5.5,6,7" 

Can someone help me figure this out?


From joseclaudio.faria at gmail.com  Mon Sep 23 20:55:20 2013
From: joseclaudio.faria at gmail.com (Jose Claudio Faria)
Date: Mon, 23 Sep 2013 15:55:20 -0300
Subject: [R] Vector of char generated by Sys.getenv function is not
 available when the package is loaded
Message-ID: <CAN+Emd8yfGRz3KSBpDGUeZU1H07o1Ut2A=QYOOyix=_-gLYtsg@mail.gmail.com>

I have been developing a new package (TinnRcom) to avoid the necessity
of any script
(as below) in the Rprofile.site file related to the use of Tinn-R Editor and R:

#===============================================================
# Tinn-R: necessary packages and functions
# Tinn-R: >= 2.4.1.1 with TinnR package >= 1.0.3
#===============================================================
# Set the URL of the preferred repository, below some examples:
options(repos='http://cran.at.r-project.org/')     # Austria/Wien
#options(repos='http://cran-r.c3sl.ufpr.br/')       # Brazil/PR
#options(repos='http://cran.fiocruz.br/')           # Brazil/RJ
#options(repos='http://www.vps.fmvz.usp.br/CRAN/')  # Brazil/SP
#options(repos='http://brieger.esalq.usp.br/CRAN/') # Brazil/SP

library(utils)

# Check necessary packages
necessary <- c('TinnR',
               'svSocket',
               'formatR')

installed <- necessary %in% installed.packages()[, 'Package']
if (length(necessary[!installed]) >=1)
  install.packages(necessary[!installed])

# Load packages
library(TinnR)
library(svSocket)

# Uncoment the two lines below if you want Tinn-R to always start R at start-up
# (Observation: check the path of Tinn-R.exe)
options(IDE='C:/Tinn-R/bin/Tinn-R.exe')
trStartIDE()

# Short paths
.trPaths <- paste(paste(Sys.getenv('APPDATA'),
                        '\\Tinn-R\\tmp\\',
                        sep=''),
                  c('',
                    'search.txt',
                    'objects.txt',
                    'file.r',
                    'selection.r',
                    'block.r',
                    'lines.r',
                    'reformat-input.r',
                    'reformat-output.r'),
                  sep='')

library(Matrix)
library(cluster)
library(Hmisc)
#===============================================================

For this it is necessary to put the object trPaths in the new TinnRcom package.

I make this as follows in the folder TinnRcom/R/trPaths.R:

trPaths <- paste(paste(Sys.getenv('APPDATA'),
                       '\\Tinn-R\\tmp\\',
                       sep=''),
                 c('',
                   'search.txt',
                   'objects.txt',
                   'file.r',
                   'selection.r',
                   'block.r',
                   'lines.r',
                   'reformat-input.r',
                   'reformat-output.r'),
                 sep='')


The NAMESPACE file is as below:

import(utils, tcltk, Hmisc, R2HTML)
importFrom(formatR, tidy.source)
importFrom(svSocket, evalServer)

export(
  trArgs,
  trComplete,
  trCopy,
  trExport,
  trObjList,
  trObjSearch,
  trPaths,
  trStartIDE)

S3method(trExport, default)
S3method(trExport, data.frame)
S3method(trExport, matrix)


After to load the package

> library(TinnRcom)

the result is always:
> trPaths
[1] "\\Tinn-R\\tmp\\"                  "\\Tinn-R\\tmp\\search.txt"
[3] "\\Tinn-R\\tmp\\objects.txt"       "\\Tinn-R\\tmp\\file.r"
[5] "\\Tinn-R\\tmp\\selection.r"       "\\Tinn-R\\tmp\\block.r"
[7] "\\Tinn-R\\tmp\\lines.r"           "\\Tinn-R\\tmp\\reformat-input.r"
[9] "\\Tinn-R\\tmp\\reformat-output.r"

When should be:
> trPaths
[1] "C:\\Users\\jcfaria\\AppData\\Roaming\\Tinn-R\\tmp\\"
[2] "C:\\Users\\jcfaria\\AppData\\Roaming\\Tinn-R\\tmp\\search.txt"
[3] "C:\\Users\\jcfaria\\AppData\\Roaming\\Tinn-R\\tmp\\objects.txt"
[4] "C:\\Users\\jcfaria\\AppData\\Roaming\\Tinn-R\\tmp\\file.r"
[5] "C:\\Users\\jcfaria\\AppData\\Roaming\\Tinn-R\\tmp\\selection.r"
[6] "C:\\Users\\jcfaria\\AppData\\Roaming\\Tinn-R\\tmp\\block.r"
[7] "C:\\Users\\jcfaria\\AppData\\Roaming\\Tinn-R\\tmp\\lines.r"
[8] "C:\\Users\\jcfaria\\AppData\\Roaming\\Tinn-R\\tmp\\reformat-input.r"
[9] "C:\\Users\\jcfaria\\AppData\\Roaming\\Tinn-R\\tmp\\reformat-output.r"

What is wrong?
Why the Sys.getenv function is not making the job when in the package?

Anyone can help please?

P.S: The beta version of the TinnRcom package is available to download at:
http://nbcgib.uesc.br/lec/download/R/TinnRcom_1.0-09.zip
-- 
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
Jose Claudio Faria
Estatistica
UESC/DCET/Brasil
joseclaudio.faria at gmail.com
Telefones:
55(73)3680.5545 - UESC
55(73)9100.7351 - TIM
55(73)8817.6159 - OI
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\


From ggrothendieck at gmail.com  Mon Sep 23 21:14:21 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 23 Sep 2013 15:14:21 -0400
Subject: [R] Vector of char generated by Sys.getenv function is not
 available when the package is loaded
In-Reply-To: <CAN+Emd8yfGRz3KSBpDGUeZU1H07o1Ut2A=QYOOyix=_-gLYtsg@mail.gmail.com>
References: <CAN+Emd8yfGRz3KSBpDGUeZU1H07o1Ut2A=QYOOyix=_-gLYtsg@mail.gmail.com>
Message-ID: <CAP01uR=Act2q14XpunmPgpczo1Au2MsTmG5Fsen8QhgKowX7hw@mail.gmail.com>

On Mon, Sep 23, 2013 at 2:55 PM, Jose Claudio Faria
<joseclaudio.faria at gmail.com> wrote:
> trPaths <- paste(paste(Sys.getenv('APPDATA'),
>                        '\\Tinn-R\\tmp\\',
>                        sep=''),
>                  c('',
>                    'search.txt',
>                    'objects.txt',
>                    'file.r',
>                    'selection.r',
>                    'block.r',
>                    'lines.r',
>                    'reformat-input.r',
>                    'reformat-output.r'),
>                  sep='')
>

Try this:


trPaths <- file.path(
   Sys.getenv('APPDATA'),
   'Tinn-R',
    'tmp',
    c('',
                   'search.txt',
                   'objects.txt',
                   'file.r',
                   'selection.r',
                   'block.r',
                   'lines.r',
                   'reformat-input.r',
                   'reformat-output.r'),
   fsep = '\\')



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From dwinsemius at comcast.net  Mon Sep 23 21:26:04 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 23 Sep 2013 14:26:04 -0500
Subject: [R] time zones from longitude, latitude, and date
In-Reply-To: <CAAZ8xc=gwqasopz3zD=53AZ9-LCbExsKZ=SC=DSfyYepo2cHsQ@mail.gmail.com>
References: <CAAZ8xcmpPMErsEYGdMbmA7LqxB7HDochipqUHtjHvAYUr+mQ4Q@mail.gmail.com>
	<26133729-5DF6-4DF3-A14A-541E0D5781EC@comcast.net>
	<CAAZ8xc=E9uiCNXv-vGfs3uD+xHc9_a8=bF-9U85ZNe+yhVCP3A@mail.gmail.com>
	<CAP01uRk_62Np3S-mDY1G=jJz-JMGRgVnJNtKFjExoZ3QCUXAEw@mail.gmail.com>
	<CAAZ8xc=gwqasopz3zD=53AZ9-LCbExsKZ=SC=DSfyYepo2cHsQ@mail.gmail.com>
Message-ID: <14DD32CC-41E6-4197-8CF8-CC6307BE7E81@comcast.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130923/19576f66/attachment.pl>

From alamont082 at gmail.com  Mon Sep 23 15:17:03 2013
From: alamont082 at gmail.com (Andrea Lamont)
Date: Mon, 23 Sep 2013 09:17:03 -0400
Subject: [R] pulling out coefficients
Message-ID: <CALxSy06M2Es6E5a9eJX_TFDc0ZJdYpET=BoDrgPEjF+jAHPrPA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130923/050d7994/attachment.pl>

From carlisle.thacker at gmail.com  Mon Sep 23 16:05:34 2013
From: carlisle.thacker at gmail.com (carlisle thacker)
Date: Mon, 23 Sep 2013 10:05:34 -0400
Subject: [R] time zones from longitude, latitude, and date
In-Reply-To: <CAP01uRk_62Np3S-mDY1G=jJz-JMGRgVnJNtKFjExoZ3QCUXAEw@mail.gmail.com>
References: <CAAZ8xcmpPMErsEYGdMbmA7LqxB7HDochipqUHtjHvAYUr+mQ4Q@mail.gmail.com>
	<26133729-5DF6-4DF3-A14A-541E0D5781EC@comcast.net>
	<CAAZ8xc=E9uiCNXv-vGfs3uD+xHc9_a8=bF-9U85ZNe+yhVCP3A@mail.gmail.com>
	<CAP01uRk_62Np3S-mDY1G=jJz-JMGRgVnJNtKFjExoZ3QCUXAEw@mail.gmail.com>
Message-ID: <CAAZ8xc=gwqasopz3zD=53AZ9-LCbExsKZ=SC=DSfyYepo2cHsQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130923/ad412524/attachment.pl>

From Torsten.Hothorn at uzh.ch  Mon Sep 23 12:54:44 2013
From: Torsten.Hothorn at uzh.ch (Torsten Hothorn)
Date: Mon, 23 Sep 2013 12:54:44 +0200 (CEST)
Subject: [R] Permutation Test on Interactions {coin}
In-Reply-To: <CAAyVsXJ7nzHZAm1-_btKHvv_eQbHfn1T0G+_1fN3ErW_uy+XzA@mail.gmail.com>
References: <CAAyVsXJ7nzHZAm1-_btKHvv_eQbHfn1T0G+_1fN3ErW_uy+XzA@mail.gmail.com>
Message-ID: <alpine.DEB.2.02.1309231254150.10549@artemis>


Axel,

you need a model for such type of analyses and coin is completely 
model-free.

Torsten

On Mon, 23 Sep 2013, Axel Urbiz wrote:

> Dear List,
> I'm interested in performing a permutation test on the interaction between a binary treatment
> indicator and a covariate (either continuous or categorical). I'm interested in the p-value
> of the interaction effect from a permutation test, and I'm using the coin package for that
> purpose.?
> 
> As I haven't seen any examples like this in the package documentation (or anywhere else), I'm
> not sure how to specify the test in this case. For example, should I interpret the p-value in
> the example below as the pvalue of the interaction effect between group and the covariate x.?
> 
> set.seed(1)
> library("coin")
> data("rotarod", package = "coin")
> x <- rnorm(24)
> rotarod <- cbind(rotarod, x)
> pvalue(independence_test(time ~ group * x, data = rotarod))
> 
> 
> Your advice would be much appreciated.?
> 
> Regards,
> Axel. ??
> 
>

From rhymes at gmx.net  Mon Sep 23 13:48:33 2013
From: rhymes at gmx.net (Rhymes)
Date: Mon, 23 Sep 2013 04:48:33 -0700 (PDT)
Subject: [R] Date Comparing *Problem*
Message-ID: <1379936913489-4676739.post@n4.nabble.com>

I have a problem with comparing dates. i tried it like "datesub =
subset(data, 2012-11-19 < data$date)", but this doesn't work and i don't
know why.

Hope you can help me.

here are my files:
http://uploaded.net/file/n9sxdm0v <http://uploaded.net/file/n9sxdm0v>  



--
View this message in context: http://r.789695.n4.nabble.com/Date-Comparing-Problem-tp4676739.html
Sent from the R help mailing list archive at Nabble.com.


From tony at shatalmic.com  Mon Sep 23 18:49:53 2013
From: tony at shatalmic.com (tony at shatalmic.com)
Date: Mon, 23 Sep 2013 09:49:53 -0700 (PDT)
Subject: [R] Turning a string into a real vector
Message-ID: <1379954993904-4676751.post@n4.nabble.com>

I have the following string input:

input <-
"ACC,1.1,2.2,3.3,4.4\nACC,2.2,3,4,5\nADN,3.3,4,5\nACC,4.4,5.5,6.6,7.7\nADN,5.5,6,7\n"

Note that \n is a real line feed in the data and the numbers are all made up
and might be other values. The key is that the first number is a float, the
ACC packets are all floats and the ADN the first value is a float and the
rest are ints.

I want to turn this string into a vector of packets. I tired using grep and
regexpr without luck. I would also like to filter the packets so that I can
get a vector of just the ACC packets and another vector of just the ADN
packets.

When I tried this:

grep ("ACC", input, FALSE, FALSE, TRUE)

What I ended up with was:

[1] "ACC,1.1,2.2,3.3,4.4"            "ACC,2.2,3,4,5"         "ADN,3.3,4,5"                   
"ACC,4.4,5.5,6.6,7.7"           "ADN,5.5,6,7"

What I wanted was:

[1] "ACC,1.1,2.2,3.3,4.4"
[2] "ACC,2.2,3,4,5"
[3] "ACC,4.4,5.5,6.6,7.7"

Then I wanted to put in grep ("ADN", input, FALSE, FALSE, TRUE) and get out:

[1] "ADN,3.3,4,5"
[2] "ADN,5.5,6,7"

Can someone help me figure this out?



--
View this message in context: http://r.789695.n4.nabble.com/Turning-a-string-into-a-real-vector-tp4676751.html
Sent from the R help mailing list archive at Nabble.com.


From tony at shatalmic.com  Mon Sep 23 21:36:59 2013
From: tony at shatalmic.com (tony at shatalmic.com)
Date: Mon, 23 Sep 2013 12:36:59 -0700 (PDT)
Subject: [R] Turning a string into a real vector
In-Reply-To: <1379961405.85039.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1379954993904-4676751.post@n4.nabble.com>
	<1379961405.85039.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <1379965019555-4676762.post@n4.nabble.com>

Thank you. I was doing a strsplit and forgot to include it in my post. What
was confusing me is that the result doesn't look like a vector. I guess it
actually is. I will try writing it out and see if I get what I want from it.

Thanks!



--
View this message in context: http://r.789695.n4.nabble.com/Turning-a-string-into-a-real-vector-tp4676751p4676762.html
Sent from the R help mailing list archive at Nabble.com.


From joseclaudio.faria at gmail.com  Mon Sep 23 21:56:59 2013
From: joseclaudio.faria at gmail.com (Jose Claudio Faria)
Date: Mon, 23 Sep 2013 16:56:59 -0300
Subject: [R] Vector of char generated by Sys.getenv function is not
 available when the package is loaded
In-Reply-To: <CAP01uR=Act2q14XpunmPgpczo1Au2MsTmG5Fsen8QhgKowX7hw@mail.gmail.com>
References: <CAN+Emd8yfGRz3KSBpDGUeZU1H07o1Ut2A=QYOOyix=_-gLYtsg@mail.gmail.com>
	<CAP01uR=Act2q14XpunmPgpczo1Au2MsTmG5Fsen8QhgKowX7hw@mail.gmail.com>
Message-ID: <CAN+Emd_N4UcESa7nTr2f6E=3PwxK0z33pjZZnV+6d+k0VPJ14g@mail.gmail.com>

I appreciate your attention Gabor.
However, the result was the same. :(

Both only work when the trPath object is sent to a R session already running.
When inside the package the result was the same.

> remove.packages('TinnRcom')

> Install.packages('TinnRcom_1.0-09.zip', repos=NULL)  # New version

> library(TinnRcom)

> trPaths
[1] "\\Tinn-R\\tmp\\"                  "\\Tinn-R\\tmp\\search.txt"
[3] "\\Tinn-R\\tmp\\objects.txt"       "\\Tinn-R\\tmp\\file.r"
[5] "\\Tinn-R\\tmp\\selection.r"       "\\Tinn-R\\tmp\\block.r"
[7] "\\Tinn-R\\tmp\\lines.r"           "\\Tinn-R\\tmp\\reformat-input.r"
[9] "\\Tinn-R\\tmp\\reformat-output.r"

On Mon, Sep 23, 2013 at 4:14 PM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> On Mon, Sep 23, 2013 at 2:55 PM, Jose Claudio Faria
> <joseclaudio.faria at gmail.com> wrote:
>> trPaths <- paste(paste(Sys.getenv('APPDATA'),
>>                        '\\Tinn-R\\tmp\\',
>>                        sep=''),
>>                  c('',
>>                    'search.txt',
>>                    'objects.txt',
>>                    'file.r',
>>                    'selection.r',
>>                    'block.r',
>>                    'lines.r',
>>                    'reformat-input.r',
>>                    'reformat-output.r'),
>>                  sep='')
>>
>
> Try this:
>
>
> trPaths <- file.path(
>    Sys.getenv('APPDATA'),
>    'Tinn-R',
>     'tmp',
>     c('',
>                    'search.txt',
>                    'objects.txt',
>                    'file.r',
>                    'selection.r',
>                    'block.r',
>                    'lines.r',
>                    'reformat-input.r',
>                    'reformat-output.r'),
>    fsep = '\\')
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com



-- 
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
Jose Claudio Faria
Estatistica
UESC/DCET/Brasil
joseclaudio.faria at gmail.com
Telefones:
55(73)3680.5545 - UESC
55(73)9100.7351 - TIM
55(73)8817.6159 - OI
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\


From richardkwock at gmail.com  Mon Sep 23 22:08:08 2013
From: richardkwock at gmail.com (Richard Kwock)
Date: Mon, 23 Sep 2013 13:08:08 -0700
Subject: [R] two questions about xyplot
In-Reply-To: <CAJU8Py0EGJ-0R4tq5=qd74=T3Ln0SXg3-ZEf54QtmsrMXO=39A@mail.gmail.com>
References: <52407D34.9050405@ucmerced.edu>
	<CAJU8Py0EGJ-0R4tq5=qd74=T3Ln0SXg3-ZEf54QtmsrMXO=39A@mail.gmail.com>
Message-ID: <CAJU8Py3dZ_6W4soUq78eV3LX_pfYuVzkmD+tkQX_yZC5q5f9eQ@mail.gmail.com>

Hi,

Getting text to show on the panel plots is a bit trickier, but doable.

# append to the dataset the mean for each group and line
d66df_mns <- cbind(d66df, "Means" = c(rep(c(mn1, mn2, mn3), each = 6)))

# set the y_lim to extend a bit further above the graph to allow for
the means to be displayed
p<-xyplot(dvy ~ sessidx | case, group = numph, data=d66df_mns, col = c(1:4),
    layout=c(1, 3), xlab= "Sessions",
    ylab = "Number of Seconds", ylim = c(min(d66df_mns$dvy), 110),
    type="l")

# pass in the means as an argument to the panel function
update(p, panel=function(x, y, means = d66df_mns$Means, ... ){
        # print(list(...))

        # this will store the groups index by subscript into a variable
        grps <- list(...)$groups[list(...)$subscript]
        unique_indices <- !duplicated(grps)

        # this will get the mean for each panel and for each line
        mean_1 <- (means[list(...)$subscript][unique_indices])
        print(mean_1)
        print(x[unique_indices])

        panel.xyplot(x, y, ... )
        panel.abline(v=6.5)
        panel.abline(v=12.5)
        panel.abline(v=18.5)
        panel.abline(v=18.5)

       # print the mean values here.
       panel.text(x[unique_indices], 100, paste("M = " , round(mean_1,
2)), adj = c(0,0))
} )

If you are working in lattice a lot, print(list(...)) is a handy
function that will show you what parameters values you are passing in
as "..." in the panel function.

Hope that helps.

Richard

On Mon, Sep 23, 2013 at 11:23 AM, Richard Kwock <richardkwock at gmail.com> wrote:
> Hi,
>
> To answer your second question you can do something like this:
>
> p<-xyplot(dvy ~ sessidx | case, group = numph, data=d66df, col = c(1:4),
>     layout=c(1, 3), xlab= "Sessions",
>     ylab = "Number of Seconds",
>     type="l")
>
> update(p, panel=function(...){
>         panel.xyplot(...)
>         panel.abline(v=6.5)
>         panel.abline(v=12.5)
>         panel.abline(v=18.5)
> } )
>
> By setting the "group" parameter in xyplot to be "numph",  xyplot will
> plot different lines for each group of numph you have in each case.
>
> For your first question, did you mean you want a text to display the
> mean in each panel?
>
> Richard
>
>
> On Mon, Sep 23, 2013 at 10:41 AM, William Shadish <wshadish at ucmerced.edu> wrote:
>> Dear R helpers,
>>
>> I am generating three artificial short interrupted time series datasets
>> (single-case designs; call them Case 1, Case 2, Case 3) and then plotting
>> them in xyplot. I will put the entire code below so you can reproduce. I
>> have been unable to figure out how to do two things.
>>
>> 1. Each time series has 24 time points divided into four phases. Call them
>> phases A, B, C, D for convenience. I have used running() to compute the
>> means of the observations in each of these four parts; and I saved these as
>> objects called mn1 (for Case 1), mn2 (Case 2) and mn3 (Case 3). So mn1
>> contains the four means for A, B, C, D phases for Case 1, etc. I want to
>> insert these means into the xyplot in the appropriate place. For instance,
>> insert the first mean from mn1 into phase A of Case 1, the second mean into
>> phase B of Case 1, and so forth until insert the fourth mean from mn3 into
>> phase D of Case 3. Ideally, it would insert something like "M = 49.02" or
>> "Xbar = 49.02" into phase A for Case 1.
>>
>> 2. The xyplot code I use creates a line connecting the data points, and that
>> line is continuous over the entire graph. I would like to have the lines be
>> discontinuous between phases. Phase changes are indicated by panel.abline()
>> in the code, and occur at time points 6.5, 12.5, and 18.5. So, for example,
>> I would like a line connecting the datapoints from 1 to 6, then 7-12, then
>> 13-18, then 19-24 (but not including 6-7, 12-13, and 18-19).
>>
>> I appreciate any help you might be able to offer.
>>
>> Will Shadish
>>
>> Here is the code:
>> #############################################################################
>> library(gtools)
>> library(lattice)
>> ###g = .66
>> z <- rnorm(24, mean = 0, sd = 10)
>> w <- rnorm(24, mean = 0, sd = 10)
>> ###change mean = to vary the effect size
>> tm <- rnorm(6, mean = 10, sd = 10)
>> b <- rep(0,6)
>> c <- rep(1,6)
>> tmt <- c(b,tm,b,tm)
>> for (t in 2:24) z[t] <- 0.25 * z[t - 1] + w[t]
>> dvy <- 50 + z + tmt
>> jid <- rep(1,24)
>> sid <- rep(1,24)
>> pid <- rep(1,24)
>> dvid <- rep(1,24)
>> desvar <- rep(1,24)
>> dvdir <- rep(0,24)
>> sessidx <- c(1:24)
>> m <- rep(1,6)
>> n <- rep(2,6)
>> o <- rep(3,6)
>> p <- rep(4,6)
>> numph <- c(m,n,o,p)
>> phasebtm <- c(b,c,b,c)
>> d1 <- cbind(jid,sid,pid,dvid,desvar,dvdir,dvy,sessidx,numph,phasebtm)
>> mn1 <- running(dvy, width=6, by=6)
>>
>> #second dataset
>> z <- rnorm(24, mean = 0, sd = 10)
>> w <- rnorm(24, mean = 0, sd = 10)
>> tm <- rnorm(6, mean = 10, sd = 10)
>> b <- rep(0,6)
>> c <- rep(1,6)
>> tmt <- c(b,tm,b,tm)
>> for (t in 2:24) z[t] <- 0.25 * z[t - 1] + w[t]
>> dvy <- 50 + z + tmt
>> jid <- rep(1,24)
>> sid <- rep(1,24)
>> pid <- rep(2,24)
>> dvid <- rep(1,24)
>> desvar <- rep(1,24)
>> dvdir <- rep(0,24)
>> sessidx <- c(1:24)
>> m <- rep(1,6)
>> n <- rep(2,6)
>> o <- rep(3,6)
>> p <- rep(4,6)
>> numph <- c(m,n,o,p)
>> phasebtm <- c(b,c,b,c)
>> d2 <- cbind(jid,sid,pid,dvid,desvar,dvdir,dvy,sessidx,numph,phasebtm)
>> mn2 <- running(dvy, width=6, by=6)
>>
>> #third dataset
>> z <- rnorm(24, mean = 0, sd = 10)
>> w <- rnorm(24, mean = 0, sd = 10)
>> tm <- rnorm(6, mean = 10, sd = 10)
>> b <- rep(0,6)
>> c <- rep(1,6)
>> tmt <- c(b,tm,b,tm)
>> for (t in 2:24) z[t] <- 0.25 * z[t - 1] + w[t]
>> dvy <- 50 + z + tmt
>> jid <- rep(1,24)
>> sid <- rep(1,24)
>> pid <- rep(3,24)
>> dvid <- rep(1,24)
>> desvar <- rep(1,24)
>> dvdir <- rep(0,24)
>> sessidx <- c(1:24)
>> m <- rep(1,6)
>> n <- rep(2,6)
>> o <- rep(3,6)
>> p <- rep(4,6)
>> numph <- c(m,n,o,p)
>> phasebtm <- c(b,c,b,c)
>> d3 <- cbind(jid,sid,pid,dvid,desvar,dvdir,dvy,sessidx,numph,phasebtm)
>> mn3 <- running(dvy, width=6, by=6)
>>
>> #concatenate d1 d2 d3
>> d66 <- rbind(d1, d2, d3)
>> d66df <- as.data.frame(d66)
>> d66df$case <- ordered(d66df$pid,
>> levels = c(1,2,3),
>> labels = c("Case 3", "Case 2", "Case 1"))
>> p<-xyplot(dvy ~ sessidx | case, data=d66df,
>>     layout=c(1, 3), xlab= "Sessions",
>>     ylab = "Number of Seconds",
>>     type="l")
>> update(p, panel=function(...){
>>         panel.xyplot(...)
>>         panel.abline(v=6.5)
>>         panel.abline(v=12.5)
>>         panel.abline(v=18.5)
>> } )
>>
>> --
>> William R. Shadish
>> Distinguished Professor
>> Founding Faculty
>>
>> Mailing Address:
>> William R. Shadish
>> University of California
>> School of Social Sciences, Humanities and Arts
>> 5200 North Lake Rd
>> Merced CA  95343
>>
>> Physical/Delivery Address:
>> University of California Merced
>> ATTN: William Shadish
>> School of Social Sciences, Humanities and Arts
>> Facilities Services Building A
>> 5200 North Lake Rd.
>> Merced, CA 95343
>>
>> 209-228-4372 voice
>> 209-228-4007 fax (communal fax: be sure to include cover sheet)
>> wshadish at ucmerced.edu
>> http://faculty.ucmerced.edu/wshadish/index.htm
>> http://psychology.ucmerced.edu
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From igorjrr at gmail.com  Mon Sep 23 22:27:08 2013
From: igorjrr at gmail.com (Igor Ribeiro)
Date: Mon, 23 Sep 2013 16:27:08 -0400
Subject: [R] labcurve - size of symbol
Message-ID: <CALfhqnnb8N3s2B=_CfOWa+37H8pXa_PfN6Q1uANj5spKOxJOpg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130923/7508a819/attachment.pl>

From ruipbarradas at sapo.pt  Mon Sep 23 22:43:00 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 23 Sep 2013 21:43:00 +0100
Subject: [R] pulling out coefficients
In-Reply-To: <CALxSy06M2Es6E5a9eJX_TFDc0ZJdYpET=BoDrgPEjF+jAHPrPA@mail.gmail.com>
References: <CALxSy06M2Es6E5a9eJX_TFDc0ZJdYpET=BoDrgPEjF+jAHPrPA@mail.gmail.com>
Message-ID: <5240A7D4.5000906@sapo.pt>

Hello,

Maybe something like the following.


cf <- vector("list", 500)
for (i in 1:500){
	s <- paste0("Chain",i)
	cf[[i]] <- mi.txt.i at imp[[s]]$cont.y.obs at model$coefficients
}


Hope this helps,

Rui Barradas

Em 23-09-2013 14:17, Andrea Lamont escreveu:
> Hello:
>
> I am running a simulation in which need to pull out the coefficients of a
> multiply imputed object for each simulation.
>
> The coefficientscould be called using the following command:
> mi.txt.i at imp$Chain1$cont.y.obs at model$coefficients
>
> THis gives me the coefficients for the first imputation (Chain 1). What I
> would like to do, however, is pull out the coefficients for all Chains but
> cannot figure out how.In other words, I want the coefficients from
> Chain1-Chain500 saved in a matrix.
>
> mi.txt.i at imp$Chain1$cont.y.obs at model$coefficients
> mi.txt.i at imp$Chain2$cont.y.obs at model$coefficients
> mi.txt.i at imp$Chain3$cont.y.obs at model$coefficients
> ...
> mi.txt.i at imp$Chain500$cont.y.obs at model$coefficients
>
> I tried using paste:
>
> for (i in 1:500){
> s=paste("Chain",i)
> mi.txt.i at imp$s$cont.y.obs at model$coefficients
> ...}
>
> But that did not work.  I also tried other variations of this looping with
> no avail.
>
> Thoughts on how to use a loop to call coefficients?
>
> Thanks,
>


From macqueen1 at llnl.gov  Mon Sep 23 23:43:32 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 23 Sep 2013 21:43:32 +0000
Subject: [R] time zones from longitude, latitude, and date
In-Reply-To: <CAAZ8xc=gwqasopz3zD=53AZ9-LCbExsKZ=SC=DSfyYepo2cHsQ@mail.gmail.com>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521910D44CA33@PRDEXMBX-08.the-lab.llnl.gov>

The very first response, from Jeff Newmiller, included a link
   http://efele.net/maps/tz/world/
which says it has offers a shapefile of timezones of the world.

An outline of a solution, then it to

  download the shapefile
  load it into R
  input your lat/long data into R
  use the over() function in the sp package

Of course there are many details amongst those steps; I would suggest
r-sig-geo would be the place for help with those details.

It remains to be seen whether the way in which the timezones are
identified in that shapefile is compatible with how timezones are
identified in R POSIXt classes (R uses the OS for this). Daylight savings
time information is, I believe, provided by the OS for at least some time
zones, but I don't know if its provided for all of them.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 9/23/13 7:05 AM, "carlisle thacker" <carlisle.thacker at gmail.com> wrote:

>Gabor,
>
>Thanks for your tip about zone.tab.  It provides country codes and lat/lon
>of the zone's principal location, which while useful is not exactly what I
>need.  I would like to know the coordinates of time zone boundaries.
>Better still would be a function, which returns the name of the time zone
>in which given lat/lon is situated.
>
>For example, in which time zone is 22N,166W?  And at what times of year
>might daylight savings time be in effect?
>
>Regards,
>
>Carlisle
>
>
>On Sat, Sep 21, 2013 at 3:17 AM, Gabor Grothendieck
><ggrothendieck at gmail.com
>> wrote:
>
>> On Fri, Sep 20, 2013 at 4:31 PM, carlisle thacker
>> <carlisle.thacker at gmail.com> wrote:
>> > I was looking for something like shown on the map:
>> >
>> 
>>http://upload.wikimedia.org/wikipedia/commons/8/88/World_Time_Zones_Map.p
>>ng
>> >
>> > Information about local daylight savings times would also help.
>> >
>> > The data are from ships, supposedly in local time, but no time-zone
>>info
>> is
>> > given.  A function that would return time zone and whether or not
>> daylight
>> > savings time applies at given date would would help.  I'm trying to
>>track
>> > down more information about the data and whether they can be
>>referenced
>> to
>> > UTC.
>>
>> The zone.tab file has this information.  See the Examples section at
>> the end of ?Sys.timezone for info on its whereabouts.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Mon Sep 23 23:55:24 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 23 Sep 2013 14:55:24 -0700 (PDT)
Subject: [R] Correlate rows of 2 matrices
In-Reply-To: <5240B660.5040605@yahoo.com>
References: <523FA005.3060109@yahoo.com> <52408CCF.9060007@yahoo.com>
	<1379962450.84659.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<5240A7C7.8070706@yahoo.com>
	<1379970722.53036.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<5240B660.5040605@yahoo.com>
Message-ID: <1379973324.21411.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi Ira,

I tried the ?lapply().? Looks like it edges the ?for() loop.
For e.g.
?

set.seed(435)
m1 <- matrix(rnorm(2000*30), ncol=30)
m2 <-? matrix(rnorm(2000*30), ncol= 30)
?corsP<-vector()
? 
?system.time({for(i in 1:2000) corsP[i] =? cor(m1[i,], m2[i,])})
?# user? system elapsed 
?# 0.124?? 0.000?? 0.122 
system.time({corsP2<- unlist(lapply(1:2000,function(i) cor(m1[i,],m2[i,])))})
# user? system elapsed 
# 0.108?? 0.000?? 0.110 
identical(corsP,corsP2)
#[1] TRUE


system.time(corsP3<- diag(cor(t(m1),t(m2))))
#? user? system elapsed 
#? 0.272?? 0.004?? 0.276 



mNew<- rbind(m1,m2)
?indx<-rep(seq(nrow(mNew)/2),2)
system.time({corsP4<- tapply(seq_along(indx),list(indx),FUN=function(x) cor(t(mNew[x,]),t(mNew[x,]))[2])})
#?? user? system elapsed 
#? 0.156?? 0.000?? 0.160 
attr(corsP4,"dimnames")<- NULL
all.equal(corsP,as.vector(corsP4))
#[1] TRUE


A.K.


________________________________
From: Ira Sharenow <irasharenow100 at yahoo.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Monday, September 23, 2013 5:45 PM
Subject: Re: Correlate rows of 2 matrices



Arun,

What department are you in? Are you on LinkedIn?

The loop takes about a second. I do not know how to use lapply/sapply with more than one object and a function of two variables such as cor().

When there are 2,000 columns it cannot be right to compute 4,000,000 correlations in order to use the 2,000 that are along the diagonal.

Ira 
On 9/23/2013 2:12 PM, arun wrote:

Ira, I work as a postdoc at Wayne State Univ. in Detroit. I didn't check the speed of ?diag().? It could be a bit slower because it first computes the whole correlation and then take the diagonal elements.? In that respect, loop will save the time.? Would be worth checking whether ?lapply() improves the speed compared to ?for(). Arun???________________________________
From: Ira Sharenow <irasharenow100 at yahoo.com> To: arun <smartpink111 at yahoo.com> Sent: Monday, September 23, 2013 4:42 PM
Subject: Re: Correlate rows of 2 matrices Arun, On a contract, I work for this San Francisco firm. But I work from home. http://www.manifoldpartners.com/Home.html How about yourself? Where are you located? Incidentally for my large matrix in addition to computing the pearson correlation matrix with use = "pairwise.complete.obs" (85 seconds), I also have to do spearman calculations. The code ran for 27 minutes. I only need about 2000 correlations, but I am computing 2000* 2000 correlations. Using a loop reduced the time to about 1 second Please note that this initial data set is one of the smaller ones I will be working on. Ira 
On 9/23/2013 11:54 AM, arun wrote: Hi Ira,
Glad it worked for you. I would also choose the one you selected.? 
BTW, where do you work?
Regards,
Arun ________________________________
From: Ira Sharenow <irasharenow100 at yahoo.com> To: arun <smartpink111 at yahoo.com> Sent: Monday, September 23, 2013 2:47 PM
Subject: Re: Correlate rows of 2 matrices Arun, Thanks for your help. I am very impressed with your ability to string together functions in order to achieve a desired result. On the other hand I prefer simplicity and I will have to explain my code to my boss who might have to eventually modify my code after I?ve moved on. I decided to go with your first option. It worked quite well.
diag(cor(t(m1),t(m2))) Thanks again. Ira 
On 9/22/2013 6:57 PM, Ira Sharenow wrote: Arun, 
>? 
>I have a new problem for you.??I have two data frames (or matrices) and row by row I want to take the correlations. So if I have a 3 row by 10 column matrix, I would produce 3 correlations. Is there a way to merge the matrices and then use some sort of split? Ideas/solutions much appreciated. m1 = matrix(rnorm(30), nrow = 3)
m2 = matrix(rnorm(30), nrow = 3) 
>set.seed(22) 
>m1 = matrix(rnorm(30), nrow = 3)
m2 = matrix(rnorm(30), nrow = 3)
for(i in 1:3) corsP[i] =? cor(m1[i,], m2[i,])
corsP 
>[1] -0.50865019 -0.27760046? 0.01423144 
>Thanks. Ira ???? ??????????? ?? ????


From carlisle.thacker at gmail.com  Mon Sep 23 23:09:08 2013
From: carlisle.thacker at gmail.com (carlisle thacker)
Date: Mon, 23 Sep 2013 17:09:08 -0400
Subject: [R] time zones from longitude, latitude, and date
In-Reply-To: <14DD32CC-41E6-4197-8CF8-CC6307BE7E81@comcast.net>
References: <CAAZ8xcmpPMErsEYGdMbmA7LqxB7HDochipqUHtjHvAYUr+mQ4Q@mail.gmail.com>
	<26133729-5DF6-4DF3-A14A-541E0D5781EC@comcast.net>
	<CAAZ8xc=E9uiCNXv-vGfs3uD+xHc9_a8=bF-9U85ZNe+yhVCP3A@mail.gmail.com>
	<CAP01uRk_62Np3S-mDY1G=jJz-JMGRgVnJNtKFjExoZ3QCUXAEw@mail.gmail.com>
	<CAAZ8xc=gwqasopz3zD=53AZ9-LCbExsKZ=SC=DSfyYepo2cHsQ@mail.gmail.com>
	<14DD32CC-41E6-4197-8CF8-CC6307BE7E81@comcast.net>
Message-ID: <CAAZ8xcm5YoNzr4TfgH_BP_di_2YHJT9dU+PJKdfuCzBikc3+Zw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130923/76313ada/attachment.pl>

From wshadish at ucmerced.edu  Tue Sep 24 00:25:14 2013
From: wshadish at ucmerced.edu (William Shadish)
Date: Mon, 23 Sep 2013 15:25:14 -0700
Subject: [R] two questions about xyplot
In-Reply-To: <CAJU8Py3dZ_6W4soUq78eV3LX_pfYuVzkmD+tkQX_yZC5q5f9eQ@mail.gmail.com>
References: <52407D34.9050405@ucmerced.edu>
	<CAJU8Py0EGJ-0R4tq5=qd74=T3Ln0SXg3-ZEf54QtmsrMXO=39A@mail.gmail.com>
	<CAJU8Py3dZ_6W4soUq78eV3LX_pfYuVzkmD+tkQX_yZC5q5f9eQ@mail.gmail.com>
Message-ID: <5240BFCA.70507@ucmerced.edu>

Richard,

This worked perfectly (adding # before "update"). Thank you so much for 
your help. I've bought a couple of books on R Graphics so I can learn 
this stuff better.

Will

On 9/23/2013 1:08 PM, Richard Kwock wrote:
> Hi,
>
> Getting text to show on the panel plots is a bit trickier, but doable.
>
> # append to the dataset the mean for each group and line
> d66df_mns <- cbind(d66df, "Means" = c(rep(c(mn1, mn2, mn3), each = 6)))
>
> # set the y_lim to extend a bit further above the graph to allow for
> the means to be displayed
> p<-xyplot(dvy ~ sessidx | case, group = numph, data=d66df_mns, col = c(1:4),
>      layout=c(1, 3), xlab= "Sessions",
>      ylab = "Number of Seconds", ylim = c(min(d66df_mns$dvy), 110),
>      type="l")
>
> # pass in the means as an argument to the panel function
> update(p, panel=function(x, y, means = d66df_mns$Means, ... ){
>          # print(list(...))
>
>          # this will store the groups index by subscript into a variable
>          grps <- list(...)$groups[list(...)$subscript]
>          unique_indices <- !duplicated(grps)
>
>          # this will get the mean for each panel and for each line
>          mean_1 <- (means[list(...)$subscript][unique_indices])
>          print(mean_1)
>          print(x[unique_indices])
>
>          panel.xyplot(x, y, ... )
>          panel.abline(v=6.5)
>          panel.abline(v=12.5)
>          panel.abline(v=18.5)
>          panel.abline(v=18.5)
>
>         # print the mean values here.
>         panel.text(x[unique_indices], 100, paste("M = " , round(mean_1,
> 2)), adj = c(0,0))
> } )
>
> If you are working in lattice a lot, print(list(...)) is a handy
> function that will show you what parameters values you are passing in
> as "..." in the panel function.
>
> Hope that helps.
>
> Richard
>
> On Mon, Sep 23, 2013 at 11:23 AM, Richard Kwock <richardkwock at gmail.com> wrote:
>> Hi,
>>
>> To answer your second question you can do something like this:
>>
>> p<-xyplot(dvy ~ sessidx | case, group = numph, data=d66df, col = c(1:4),
>>      layout=c(1, 3), xlab= "Sessions",
>>      ylab = "Number of Seconds",
>>      type="l")
>>
>> update(p, panel=function(...){
>>          panel.xyplot(...)
>>          panel.abline(v=6.5)
>>          panel.abline(v=12.5)
>>          panel.abline(v=18.5)
>> } )
>>
>> By setting the "group" parameter in xyplot to be "numph",  xyplot will
>> plot different lines for each group of numph you have in each case.
>>
>> For your first question, did you mean you want a text to display the
>> mean in each panel?
>>
>> Richard
>>
>>
>> On Mon, Sep 23, 2013 at 10:41 AM, William Shadish <wshadish at ucmerced.edu> wrote:
>>> Dear R helpers,
>>>
>>> I am generating three artificial short interrupted time series datasets
>>> (single-case designs; call them Case 1, Case 2, Case 3) and then plotting
>>> them in xyplot. I will put the entire code below so you can reproduce. I
>>> have been unable to figure out how to do two things.
>>>
>>> 1. Each time series has 24 time points divided into four phases. Call them
>>> phases A, B, C, D for convenience. I have used running() to compute the
>>> means of the observations in each of these four parts; and I saved these as
>>> objects called mn1 (for Case 1), mn2 (Case 2) and mn3 (Case 3). So mn1
>>> contains the four means for A, B, C, D phases for Case 1, etc. I want to
>>> insert these means into the xyplot in the appropriate place. For instance,
>>> insert the first mean from mn1 into phase A of Case 1, the second mean into
>>> phase B of Case 1, and so forth until insert the fourth mean from mn3 into
>>> phase D of Case 3. Ideally, it would insert something like "M = 49.02" or
>>> "Xbar = 49.02" into phase A for Case 1.
>>>
>>> 2. The xyplot code I use creates a line connecting the data points, and that
>>> line is continuous over the entire graph. I would like to have the lines be
>>> discontinuous between phases. Phase changes are indicated by panel.abline()
>>> in the code, and occur at time points 6.5, 12.5, and 18.5. So, for example,
>>> I would like a line connecting the datapoints from 1 to 6, then 7-12, then
>>> 13-18, then 19-24 (but not including 6-7, 12-13, and 18-19).
>>>
>>> I appreciate any help you might be able to offer.
>>>
>>> Will Shadish
>>>
>>> Here is the code:
>>> #############################################################################
>>> library(gtools)
>>> library(lattice)
>>> ###g = .66
>>> z <- rnorm(24, mean = 0, sd = 10)
>>> w <- rnorm(24, mean = 0, sd = 10)
>>> ###change mean = to vary the effect size
>>> tm <- rnorm(6, mean = 10, sd = 10)
>>> b <- rep(0,6)
>>> c <- rep(1,6)
>>> tmt <- c(b,tm,b,tm)
>>> for (t in 2:24) z[t] <- 0.25 * z[t - 1] + w[t]
>>> dvy <- 50 + z + tmt
>>> jid <- rep(1,24)
>>> sid <- rep(1,24)
>>> pid <- rep(1,24)
>>> dvid <- rep(1,24)
>>> desvar <- rep(1,24)
>>> dvdir <- rep(0,24)
>>> sessidx <- c(1:24)
>>> m <- rep(1,6)
>>> n <- rep(2,6)
>>> o <- rep(3,6)
>>> p <- rep(4,6)
>>> numph <- c(m,n,o,p)
>>> phasebtm <- c(b,c,b,c)
>>> d1 <- cbind(jid,sid,pid,dvid,desvar,dvdir,dvy,sessidx,numph,phasebtm)
>>> mn1 <- running(dvy, width=6, by=6)
>>>
>>> #second dataset
>>> z <- rnorm(24, mean = 0, sd = 10)
>>> w <- rnorm(24, mean = 0, sd = 10)
>>> tm <- rnorm(6, mean = 10, sd = 10)
>>> b <- rep(0,6)
>>> c <- rep(1,6)
>>> tmt <- c(b,tm,b,tm)
>>> for (t in 2:24) z[t] <- 0.25 * z[t - 1] + w[t]
>>> dvy <- 50 + z + tmt
>>> jid <- rep(1,24)
>>> sid <- rep(1,24)
>>> pid <- rep(2,24)
>>> dvid <- rep(1,24)
>>> desvar <- rep(1,24)
>>> dvdir <- rep(0,24)
>>> sessidx <- c(1:24)
>>> m <- rep(1,6)
>>> n <- rep(2,6)
>>> o <- rep(3,6)
>>> p <- rep(4,6)
>>> numph <- c(m,n,o,p)
>>> phasebtm <- c(b,c,b,c)
>>> d2 <- cbind(jid,sid,pid,dvid,desvar,dvdir,dvy,sessidx,numph,phasebtm)
>>> mn2 <- running(dvy, width=6, by=6)
>>>
>>> #third dataset
>>> z <- rnorm(24, mean = 0, sd = 10)
>>> w <- rnorm(24, mean = 0, sd = 10)
>>> tm <- rnorm(6, mean = 10, sd = 10)
>>> b <- rep(0,6)
>>> c <- rep(1,6)
>>> tmt <- c(b,tm,b,tm)
>>> for (t in 2:24) z[t] <- 0.25 * z[t - 1] + w[t]
>>> dvy <- 50 + z + tmt
>>> jid <- rep(1,24)
>>> sid <- rep(1,24)
>>> pid <- rep(3,24)
>>> dvid <- rep(1,24)
>>> desvar <- rep(1,24)
>>> dvdir <- rep(0,24)
>>> sessidx <- c(1:24)
>>> m <- rep(1,6)
>>> n <- rep(2,6)
>>> o <- rep(3,6)
>>> p <- rep(4,6)
>>> numph <- c(m,n,o,p)
>>> phasebtm <- c(b,c,b,c)
>>> d3 <- cbind(jid,sid,pid,dvid,desvar,dvdir,dvy,sessidx,numph,phasebtm)
>>> mn3 <- running(dvy, width=6, by=6)
>>>
>>> #concatenate d1 d2 d3
>>> d66 <- rbind(d1, d2, d3)
>>> d66df <- as.data.frame(d66)
>>> d66df$case <- ordered(d66df$pid,
>>> levels = c(1,2,3),
>>> labels = c("Case 3", "Case 2", "Case 1"))
>>> p<-xyplot(dvy ~ sessidx | case, data=d66df,
>>>      layout=c(1, 3), xlab= "Sessions",
>>>      ylab = "Number of Seconds",
>>>      type="l")
>>> update(p, panel=function(...){
>>>          panel.xyplot(...)
>>>          panel.abline(v=6.5)
>>>          panel.abline(v=12.5)
>>>          panel.abline(v=18.5)
>>> } )
>>>
>>> --
>>> William R. Shadish
>>> Distinguished Professor
>>> Founding Faculty
>>>
>>> Mailing Address:
>>> William R. Shadish
>>> University of California
>>> School of Social Sciences, Humanities and Arts
>>> 5200 North Lake Rd
>>> Merced CA  95343
>>>
>>> Physical/Delivery Address:
>>> University of California Merced
>>> ATTN: William Shadish
>>> School of Social Sciences, Humanities and Arts
>>> Facilities Services Building A
>>> 5200 North Lake Rd.
>>> Merced, CA 95343
>>>
>>> 209-228-4372 voice
>>> 209-228-4007 fax (communal fax: be sure to include cover sheet)
>>> wshadish at ucmerced.edu
>>> http://faculty.ucmerced.edu/wshadish/index.htm
>>> http://psychology.ucmerced.edu
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>
>

-- 
William R. Shadish
Distinguished Professor
Founding Faculty

Mailing Address:
William R. Shadish
University of California
School of Social Sciences, Humanities and Arts
5200 North Lake Rd
Merced CA  95343

Physical/Delivery Address:
University of California Merced
ATTN: William Shadish
School of Social Sciences, Humanities and Arts
Facilities Services Building A
5200 North Lake Rd.
Merced, CA 95343

209-228-4372 voice
209-228-4007 fax (communal fax: be sure to include cover sheet)
wshadish at ucmerced.edu
http://faculty.ucmerced.edu/wshadish/index.htm
http://psychology.ucmerced.edu


From anika.masters at gmail.com  Tue Sep 24 00:36:25 2013
From: anika.masters at gmail.com (Anika Masters)
Date: Mon, 23 Sep 2013 15:36:25 -0700
Subject: [R] capturing warnings within loops,
 so I know the iterations where warnings occurred?
Message-ID: <CAOQRPaZ96-_o1wOpzqR2Kg5seAHPb_gfZhpfDzF+ygeP6UsuBQ@mail.gmail.com>

I am running a loop.  Warnings sometimes occur, and the lop continues
until the end.
For each iteration of the loop, I wish to capture and "save" any
warnings issued, so that I can tell on which iteration the warnings
were issued.
I tried this, but it does not work.

mylist <- list(NULL)
mylist_warns <- list(NULL)
old.warn <- options(warn=1)

x <- c(1:5)
for (i in 1:2) {
assign("last.warning", NULL, envir = baseenv())
mylist[[i]] = x[ (i:1): 5 ]
mylist_warns[[i]] = warnings()
}

mylist
mylist_warns


From richardkwock at gmail.com  Tue Sep 24 03:15:14 2013
From: richardkwock at gmail.com (Richard Kwock)
Date: Mon, 23 Sep 2013 18:15:14 -0700
Subject: [R] capturing warnings within loops,
 so I know the iterations where warnings occurred?
In-Reply-To: <CAOQRPaZ96-_o1wOpzqR2Kg5seAHPb_gfZhpfDzF+ygeP6UsuBQ@mail.gmail.com>
References: <CAOQRPaZ96-_o1wOpzqR2Kg5seAHPb_gfZhpfDzF+ygeP6UsuBQ@mail.gmail.com>
Message-ID: <CAJU8Py1ueiXR5MZ29D=Bf6U6vQj2Xd=TOm0deckh9Z2V+bON7A@mail.gmail.com>

Hi,

Check out:

https://stat.ethz.ch/pipermail/r-help/2010-December/262626.html

> demo(error.catching)
> tryCatch.W.E

mylist <- list(NULL)
mylist_warns <- list(NULL)
old.warn <- options(warn=1)

x <- c(1:5)
for (i in 1:2) {
  assign("last.warning", NULL, envir = baseenv())
  temp <- tryCatch.W.E(x[ (i:1): 5 ] )
  mylist[[i]] = temp$value
  mylist_warns[[i]] = temp$warning
}

mylist

#[[1]]
#[1] 1 2 3 4 5
#
#[[2]]
#[1] 2 3 4 5

mylist_warns

#[[1]]
#NULL
#
#[[2]]
#<simpleWarning in (i:1):5: numerical expression has 2 elements: only
the first used>


Richard

On Mon, Sep 23, 2013 at 3:36 PM, Anika Masters <anika.masters at gmail.com> wrote:
> I am running a loop.  Warnings sometimes occur, and the lop continues
> until the end.
> For each iteration of the loop, I wish to capture and "save" any
> warnings issued, so that I can tell on which iteration the warnings
> were issued.
> I tried this, but it does not work.
>
> mylist <- list(NULL)
> mylist_warns <- list(NULL)
> old.warn <- options(warn=1)
>
> x <- c(1:5)
> for (i in 1:2) {
> assign("last.warning", NULL, envir = baseenv())
> mylist[[i]] = x[ (i:1): 5 ]
> mylist_warns[[i]] = warnings()
> }
>
> mylist
> mylist_warns
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From scfriant at wisc.edu  Tue Sep 24 02:05:17 2013
From: scfriant at wisc.edu (Sagan Friant)
Date: Mon, 23 Sep 2013 19:05:17 -0500
Subject: [R] adjust scale of x-axis to unequal intervals
Message-ID: <CA+tD=u7HV5i_xzjvOPhtoLEBycM0S3=HYKSEyEogyJg+BXbLNQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130923/77256ccd/attachment.pl>

From joseclaudio.faria at gmail.com  Tue Sep 24 04:51:30 2013
From: joseclaudio.faria at gmail.com (Jose Claudio Faria)
Date: Mon, 23 Sep 2013 23:51:30 -0300
Subject: [R] Vector of char generated by Sys.getenv function is not
 available when the package is loaded
In-Reply-To: <CAN+Emd_N4UcESa7nTr2f6E=3PwxK0z33pjZZnV+6d+k0VPJ14g@mail.gmail.com>
References: <CAN+Emd8yfGRz3KSBpDGUeZU1H07o1Ut2A=QYOOyix=_-gLYtsg@mail.gmail.com>
	<CAP01uR=Act2q14XpunmPgpczo1Au2MsTmG5Fsen8QhgKowX7hw@mail.gmail.com>
	<CAN+Emd_N4UcESa7nTr2f6E=3PwxK0z33pjZZnV+6d+k0VPJ14g@mail.gmail.com>
Message-ID: <CAN+Emd8z53nKgC3Ok1meh=7s8s9W15SDnTNBCdWKhqwW4y6N1A@mail.gmail.com>

I think I found the main problem!

I am developing the package under Linux and after R CMD build,
manually compressing the folder TinnRcom inside of the folder
TinnRcom.RCheck and installing in Windows.

As the APPDATA environment variable does not exist in Linux, the
function Sys.getenv ("APPDATA") is returning an empty string.

I think the problem is it, now it is necessary to find a solution.
Does anyone have a clue?
-- 
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
Jose Claudio Faria
Estatistica
UESC/DCET/Brasil
joseclaudio.faria at gmail.com
Telefones:
55(73)3680.5545 - UESC
55(73)9100.7351 - TIM
55(73)8817.6159 - OI
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\


From smartpink111 at yahoo.com  Tue Sep 24 05:12:34 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 23 Sep 2013 20:12:34 -0700 (PDT)
Subject: [R] Problem with plotting against time(hh:mm)
Message-ID: <1379992354.61702.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,

testing<- read.table(text="0:00,0.88
0:05,
0:20,0.6
0:25,0.14
0:30,0.25
0:35,0.5
0:40,0.25
0:45,0.13",sep=",",header=FALSE,stringsAsFactors=TRUE)

# After reading the file using ?read.csv(), try:
?plot(as.numeric(testing$V1),testing$V2,xaxt="n",xlab="TimeStamp",ylab="IntSollrr")
axis(1,as.numeric(testing$V1),levels(testing$V1))


A.K.


Hi guys, 

I am trying to plot the attached .csv (located in my C:\R 
folder). The .csv has 2 columns, where the first 6 rows are headers and 
look something like this: 

CSV-Export, 
, 
,SENS0700 
,28728 
TimeStamp,IntSolIrr 
hh:mm,W/m^2 
0:00,0.88 
0:05, 
0:20,0.6 
0:25,0.14 
0:30,0.25 
0:35,0.5 
0:40,0.25 
0:45,0.13 

If I were to type this 

> setwd("C:/R") 
> testing=read.csv("testing.csv", skip=6, header = FALSE) 
> plot(testing$V2) 

I get a nice graph 

But when I try to plot the graph against time instead and type this 

> setwd("C:/R") 
> testing=read.csv("testing.csv", skip=6, header = FALSE) 
> plot(testing$V1,testing$V2) 

The time gets all screwed up and are no longer in order. 

Is there a way to solve this? I also tried reading the 
documentation on zoo, but I cannot find how to tell R to treat only the 
first column as time in hh:mm format (I get a warning instead using 
read.zoo) 

Thank you!


From jim at bitwrit.com.au  Tue Sep 24 05:41:55 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 24 Sep 2013 13:41:55 +1000
Subject: [R] adjust scale of x-axis to unequal intervals
In-Reply-To: <CA+tD=u7HV5i_xzjvOPhtoLEBycM0S3=HYKSEyEogyJg+BXbLNQ@mail.gmail.com>
References: <CA+tD=u7HV5i_xzjvOPhtoLEBycM0S3=HYKSEyEogyJg+BXbLNQ@mail.gmail.com>
Message-ID: <52410A03.8040204@bitwrit.com.au>

On 09/24/2013 10:05 AM, Sagan Friant wrote:
> Dear R community,
>
> Please help.  I am new(ish) to R and have spent too many hours trying to
> achieve what I believe should be a relatively simple task.  I have searched
> help forums, but have not been able to successfully apply responses to
> loosely related questions to my own.
>
> I am running some preliminary summary statistics.  I wish to create a
> boxplot graph that represents summaries of samples collected over a series
> of time points (0-18).  My sample collection intensity was highest early
> on, with samples collection decreasing in frequency over time.  I am trying
> to scale the the x-axis to unequal intervals.
>
> The code I used for a graph representing a subset of my sample (re-named)
> is below:
>
> Boxplot(ALL~sample, data=rich.small, id.method="n", las = 2, names =
> c("0","2","4","7","10","18"))
>
> There were 10days between samples 0&2 and 3 days between 2&4, 4&7, 7&10,
> and then 75days between 10&18
>
Hi Sagan,
I think what you want is to have the boxplots spaced out as the 
occasions of measurement:

rich.small<-data.frame(ALL=rnorm(240,5),
  sample=c(rep(0,60),rep(2,50),rep(4,40),
  rep(7,30),rep(10,30),rep(18,30)))
# this gives you the spacing with the occasion labels
boxplot(ALL~sample,rich.small,at=c(0,10,13,16,19,94),xaxt="n",
  xlab="Occasion")
library(plotrix)
staxlab(1,at=c(0,10,13,16,19,94),labels=c(0,2,4,7,10,18))
# and this gives you the days
boxplot(ALL~sample,rich.small,at=c(0,10,13,16,19,94),xaxt="n",
  xlab="Days")
staxlab(1,at=c(0,10,13,16,19,94))

Lots of space in the middle for something.

Jim


From tal.galili at gmail.com  Tue Sep 24 06:25:17 2013
From: tal.galili at gmail.com (Tal Galili)
Date: Tue, 24 Sep 2013 06:25:17 +0200
Subject: [R] raster package: OpenStreetMap broken on Ubuntu, works on Mac
In-Reply-To: <523D3D92.10702@stats.ox.ac.uk>
References: <1379721440.74722.YahooMailNeo@web121103.mail.ne1.yahoo.com>
	<523D3D92.10702@stats.ox.ac.uk>
Message-ID: <CANdJ3dV0=46La2TEtkjDz2mY6Y5YCDxVrvtb0FYVLctjw_fqgw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130924/6f9032b8/attachment.pl>

From dwarnold45 at suddenlink.net  Tue Sep 24 07:15:47 2013
From: dwarnold45 at suddenlink.net (David Arnold)
Date: Mon, 23 Sep 2013 22:15:47 -0700 (PDT)
Subject: [R] Installing R, R packages
Message-ID: <1379999747146-4676808.post@n4.nabble.com>

All,

Consider this attempt:
> install.packages("car")
trying URL
'http://cran.cnr.Berkeley.edu/bin/macosx/contrib/3.0/car_2.0-19.tgz'
Content type 'application/x-gzip' length 1326903 bytes (1.3 Mb)
opened URL
==========================================
downloaded 1.1 Mb

car/data/Rdata.rdb: Truncated tar archive
tar: Error exit delayed from previous errors.

The downloaded binary packages are in

/var/folders/qE/qEavkZWTFMmxjncuY+HnqE+++TI/-Tmp-//Rtmpnxi1hV/downloaded_packages
Warning messages:
1: In download.file(url, destfile, method, mode = "wb", ...) :
  downloaded length 1126960 != reported length 1326903
2: 'tar' returned non-zero exit code 1 
> 

This seems to be happening frequently at the cran berkeley site. I've also
had students try to install R from the Berkeley site and it just doesn't
work for them.

I had another student tell me today he tried all sorts of mirrors and could
not get R and knitr installed until he tried the Washington site.

Is there some sort of corruption going on at the CRAN mirrors?

D.



--
View this message in context: http://r.789695.n4.nabble.com/Installing-R-R-packages-tp4676808.html
Sent from the R help mailing list archive at Nabble.com.


From jdnewmil at dcn.davis.CA.us  Tue Sep 24 07:47:30 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 23 Sep 2013 22:47:30 -0700
Subject: [R] Installing R, R packages
In-Reply-To: <1379999747146-4676808.post@n4.nabble.com>
References: <1379999747146-4676808.post@n4.nabble.com>
Message-ID: <f3914067-0250-4ec9-8ee4-a4efa8177576@email.android.com>

I have stopped using the Berkeley mirror, and just automatically use UCLA due to missing packages. However, I feel no compulsion to extrapolate and say that there is "some sort of corruption going on at CRAN mirrors" because it is only one data point.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

David Arnold <dwarnold45 at suddenlink.net> wrote:
>All,
>
>Consider this attempt:
>> install.packages("car")
>trying URL
>'http://cran.cnr.Berkeley.edu/bin/macosx/contrib/3.0/car_2.0-19.tgz'
>Content type 'application/x-gzip' length 1326903 bytes (1.3 Mb)
>opened URL
>==========================================
>downloaded 1.1 Mb
>
>car/data/Rdata.rdb: Truncated tar archive
>tar: Error exit delayed from previous errors.
>
>The downloaded binary packages are in
>
>/var/folders/qE/qEavkZWTFMmxjncuY+HnqE+++TI/-Tmp-//Rtmpnxi1hV/downloaded_packages
>Warning messages:
>1: In download.file(url, destfile, method, mode = "wb", ...) :
>  downloaded length 1126960 != reported length 1326903
>2: 'tar' returned non-zero exit code 1 
>> 
>
>This seems to be happening frequently at the cran berkeley site. I've
>also
>had students try to install R from the Berkeley site and it just
>doesn't
>work for them.
>
>I had another student tell me today he tried all sorts of mirrors and
>could
>not get R and knitr installed until he tried the Washington site.
>
>Is there some sort of corruption going on at the CRAN mirrors?
>
>D.
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/Installing-R-R-packages-tp4676808.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From phgrosjean at sciviews.org  Tue Sep 24 08:16:22 2013
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Tue, 24 Sep 2013 08:16:22 +0200
Subject: [R] Vector of char generated by Sys.getenv function is not
	available when the package is loaded
In-Reply-To: <CAN+Emd8yfGRz3KSBpDGUeZU1H07o1Ut2A=QYOOyix=_-gLYtsg@mail.gmail.com>
References: <CAN+Emd8yfGRz3KSBpDGUeZU1H07o1Ut2A=QYOOyix=_-gLYtsg@mail.gmail.com>
Message-ID: <99A9A6DF-C68F-4931-A322-1E69DF79D304@sciviews.org>

Hi JCFaria,

You package is supposed to be used only under Windows, right? Then, use:

OS_type=windows

in the DESCRIPTION file? and, of course, use R CMD check/R CMD build/ R CMD INSTALL under Windows only.
Best,

Philippe

On 23 Sep 2013, at 20:55, Jose Claudio Faria <joseclaudio.faria at gmail.com> wrote:

> I have been developing a new package (TinnRcom) to avoid the necessity
> of any script
> (as below) in the Rprofile.site file related to the use of Tinn-R Editor and R:
> 
> #===============================================================
> # Tinn-R: necessary packages and functions
> # Tinn-R: >= 2.4.1.1 with TinnR package >= 1.0.3
> #===============================================================
> # Set the URL of the preferred repository, below some examples:
> options(repos='http://cran.at.r-project.org/')     # Austria/Wien
> #options(repos='http://cran-r.c3sl.ufpr.br/')       # Brazil/PR
> #options(repos='http://cran.fiocruz.br/')           # Brazil/RJ
> #options(repos='http://www.vps.fmvz.usp.br/CRAN/')  # Brazil/SP
> #options(repos='http://brieger.esalq.usp.br/CRAN/') # Brazil/SP
> 
> library(utils)
> 
> # Check necessary packages
> necessary <- c('TinnR',
>               'svSocket',
>               'formatR')
> 
> installed <- necessary %in% installed.packages()[, 'Package']
> if (length(necessary[!installed]) >=1)
>  install.packages(necessary[!installed])
> 
> # Load packages
> library(TinnR)
> library(svSocket)
> 
> # Uncoment the two lines below if you want Tinn-R to always start R at start-up
> # (Observation: check the path of Tinn-R.exe)
> options(IDE='C:/Tinn-R/bin/Tinn-R.exe')
> trStartIDE()
> 
> # Short paths
> .trPaths <- paste(paste(Sys.getenv('APPDATA'),
>                        '\\Tinn-R\\tmp\\',
>                        sep=''),
>                  c('',
>                    'search.txt',
>                    'objects.txt',
>                    'file.r',
>                    'selection.r',
>                    'block.r',
>                    'lines.r',
>                    'reformat-input.r',
>                    'reformat-output.r'),
>                  sep='')
> 
> library(Matrix)
> library(cluster)
> library(Hmisc)
> #===============================================================
> 
> For this it is necessary to put the object trPaths in the new TinnRcom package.
> 
> I make this as follows in the folder TinnRcom/R/trPaths.R:
> 
> trPaths <- paste(paste(Sys.getenv('APPDATA'),
>                       '\\Tinn-R\\tmp\\',
>                       sep=''),
>                 c('',
>                   'search.txt',
>                   'objects.txt',
>                   'file.r',
>                   'selection.r',
>                   'block.r',
>                   'lines.r',
>                   'reformat-input.r',
>                   'reformat-output.r'),
>                 sep='')
> 
> 
> The NAMESPACE file is as below:
> 
> import(utils, tcltk, Hmisc, R2HTML)
> importFrom(formatR, tidy.source)
> importFrom(svSocket, evalServer)
> 
> export(
>  trArgs,
>  trComplete,
>  trCopy,
>  trExport,
>  trObjList,
>  trObjSearch,
>  trPaths,
>  trStartIDE)
> 
> S3method(trExport, default)
> S3method(trExport, data.frame)
> S3method(trExport, matrix)
> 
> 
> After to load the package
> 
>> library(TinnRcom)
> 
> the result is always:
>> trPaths
> [1] "\\Tinn-R\\tmp\\"                  "\\Tinn-R\\tmp\\search.txt"
> [3] "\\Tinn-R\\tmp\\objects.txt"       "\\Tinn-R\\tmp\\file.r"
> [5] "\\Tinn-R\\tmp\\selection.r"       "\\Tinn-R\\tmp\\block.r"
> [7] "\\Tinn-R\\tmp\\lines.r"           "\\Tinn-R\\tmp\\reformat-input.r"
> [9] "\\Tinn-R\\tmp\\reformat-output.r"
> 
> When should be:
>> trPaths
> [1] "C:\\Users\\jcfaria\\AppData\\Roaming\\Tinn-R\\tmp\\"
> [2] "C:\\Users\\jcfaria\\AppData\\Roaming\\Tinn-R\\tmp\\search.txt"
> [3] "C:\\Users\\jcfaria\\AppData\\Roaming\\Tinn-R\\tmp\\objects.txt"
> [4] "C:\\Users\\jcfaria\\AppData\\Roaming\\Tinn-R\\tmp\\file.r"
> [5] "C:\\Users\\jcfaria\\AppData\\Roaming\\Tinn-R\\tmp\\selection.r"
> [6] "C:\\Users\\jcfaria\\AppData\\Roaming\\Tinn-R\\tmp\\block.r"
> [7] "C:\\Users\\jcfaria\\AppData\\Roaming\\Tinn-R\\tmp\\lines.r"
> [8] "C:\\Users\\jcfaria\\AppData\\Roaming\\Tinn-R\\tmp\\reformat-input.r"
> [9] "C:\\Users\\jcfaria\\AppData\\Roaming\\Tinn-R\\tmp\\reformat-output.r"
> 
> What is wrong?
> Why the Sys.getenv function is not making the job when in the package?
> 
> Anyone can help please?
> 
> P.S: The beta version of the TinnRcom package is available to download at:
> http://nbcgib.uesc.br/lec/download/R/TinnRcom_1.0-09.zip
> -- 
> ///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
> Jose Claudio Faria
> Estatistica
> UESC/DCET/Brasil
> joseclaudio.faria at gmail.com
> Telefones:
> 55(73)3680.5545 - UESC
> 55(73)9100.7351 - TIM
> 55(73)8817.6159 - OI
> ///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From ripley at stats.ox.ac.uk  Tue Sep 24 09:09:50 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 24 Sep 2013 08:09:50 +0100
Subject: [R] time zones from longitude, latitude, and date
In-Reply-To: <5E1B812FAC2C4A49B3D99593B5A521910D44CA33@PRDEXMBX-08.the-lab.llnl.gov>
References: <5E1B812FAC2C4A49B3D99593B5A521910D44CA33@PRDEXMBX-08.the-lab.llnl.gov>
Message-ID: <52413ABE.50709@stats.ox.ac.uk>

On 23/09/2013 22:43, MacQueen, Don wrote:
> The very first response, from Jeff Newmiller, included a link
>     http://efele.net/maps/tz/world/
> which says it has offers a shapefile of timezones of the world.
>
> An outline of a solution, then it to
>
>    download the shapefile
>    load it into R
>    input your lat/long data into R
>    use the over() function in the sp package
>
> Of course there are many details amongst those steps; I would suggest
> r-sig-geo would be the place for help with those details.
>
> It remains to be seen whether the way in which the timezones are
> identified in that shapefile is compatible with how timezones are
> identified in R POSIXt classes (R uses the OS for this). Daylight savings
> time information is, I believe, provided by the OS for at least some time
> zones, but I don't know if its provided for all of them.

It needs to be.  That is why the tzone databases are so large and 
complex and change several times a year.

Actually, the info is provided by the OS except on Windows where the 
Olsen/IANA database is used (as it is by almost all other current OSes). 
  So timezone names are fairly portable.

I thought I read in this thread that these were recordings at sea: see 
the caveats at that URL (it only applies on land ...).


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue Sep 24 09:18:51 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 24 Sep 2013 08:18:51 +0100
Subject: [R] Vector of char generated by Sys.getenv function is not
 available when the package is loaded
In-Reply-To: <CAN+Emd8z53nKgC3Ok1meh=7s8s9W15SDnTNBCdWKhqwW4y6N1A@mail.gmail.com>
References: <CAN+Emd8yfGRz3KSBpDGUeZU1H07o1Ut2A=QYOOyix=_-gLYtsg@mail.gmail.com>
	<CAP01uR=Act2q14XpunmPgpczo1Au2MsTmG5Fsen8QhgKowX7hw@mail.gmail.com>
	<CAN+Emd_N4UcESa7nTr2f6E=3PwxK0z33pjZZnV+6d+k0VPJ14g@mail.gmail.com>
	<CAN+Emd8z53nKgC3Ok1meh=7s8s9W15SDnTNBCdWKhqwW4y6N1A@mail.gmail.com>
Message-ID: <52413CDB.2050106@stats.ox.ac.uk>

On 24/09/2013 03:51, Jose Claudio Faria wrote:
> I think I found the main problem!
>
> I am developing the package under Linux and after R CMD build,
> manually compressing the folder TinnRcom inside of the folder
> TinnRcom.RCheck and installing in Windows.

And how on earth did you expect the helpers here to know that you were 
subverting the R installation procedures?

For a package without compiled code (as this must be for that to work) 
it really is very simple

R CMD build TinnRcom # on Linux
install.packages('TinnRcom_xx-x.tar.gz") # on Windows: no extra tools 
are needed.

> As the APPDATA environment variable does not exist in Linux, the
> function Sys.getenv ("APPDATA") is returning an empty string.
>
> I think the problem is it, now it is necessary to find a solution.
> Does anyone have a clue?

You really do not want to do this at install time (or the settings will 
be for the user who installs for source, Uwe Ligges for most Windows 
users).  Use .onLoad.

We write R manuals to explain this sort of thing:  fortunes::fortune(14) 
applies.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ejoffe at hotmail.com  Tue Sep 24 10:58:01 2013
From: ejoffe at hotmail.com (E Joffe)
Date: Tue, 24 Sep 2013 10:58:01 +0200
Subject: [R] Creating dummy vars with contrasts - why does the returned
	identity matrix contain all levels (and not n-1 levels) ?
In-Reply-To: <255AFEA9-DE51-4984-B308-6734B4C3B616@comcast.net>
References: <DUB114-DS1481B35E35DF4AC29807F6CA3B0@phx.gbl>
	<FA5360B9-73E7-41A4-B577-77212FD4F25B@comcast.net>
	<DUB114-DS28C57F8A86245D07B7D278CA3B0@phx.gbl>
	<544106D3-0042-4ACF-A5A1-0F572A4F7D5B@comcast.net>
	<DUB114-DS392E0830FFA2D67F34763CCA240@phx.gbl>
	<255AFEA9-DE51-4984-B308-6734B4C3B616@comcast.net>
Message-ID: <DUB114-DS1673B1E5E29E29171867B1CA2E0@phx.gbl>

Hi David,

Thank you for your interest and advice regarding this analysis.
I went to double check that the subset process worked properly with the
select=c(-time,-status) and I can confirm that it did.

Best,
Erel

-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: Friday, September 20, 2013 5:12 PM
To: E Joffe
Cc: r-help at r-project.org
Subject: Re: [R] Creating dummy vars with contrasts - why does the returned
identity matrix contain all levels (and not n-1 levels) ?


On Sep 13, 2013, at 11:21 PM, E Joffe wrote:

> Hi David,
>
> First I ordered the levels of each factor in a descending order based 
> on frequency.
> Then, I used the following code to generate a matrix from the 
> dataframe with dummy variables and  subsequently run the glmnet 
> (coxnet)
>
> ## tranform categorical variables into binary variables with dummy for 
> trainSet predict_matrix <- model.matrix(~ ., data=trainSet,
>                              contrasts.arg = lapply 
> (trainSet[,sapply(trainSet, is.factor)], contrasts))
>
> ## remove the status/time variables from the predictor matrix (x) for 
> glmnet predict_matrix <- subset (predict_matrix, 
> select=c(-time,-status))
>
> ## create a glmnet cox object using lasso regularization and cross 
> validation glmnet.cv <- cv.glmnet (predict_matrix, surv_obj, 
> family="cox")
>
>
> I hope I did not do anything wrong .....
>
> Can't thank you enough for your advice and interest.

Thank you for outlining the process that you used. It looks "from the
outside" as though it respects the constraints on the first two argument
imposed by the more constrained input requirements of cv.glmnet. I didn't
realize that subset could accept a `-`sign as an operator inside a c()
expression, but if you are getting success then I guess it must.

--
David.



> Erel
>
>
>
> -----Original Message-----
> From: David Winsemius [mailto:dwinsemius at comcast.net]
> Sent: Friday, September 13, 2013 8:51 PM
> To: E Joffe
> Cc: r-help at r-project.org
> Subject: Re: [R] Creating dummy vars with contrasts - why does the  
> returned
> identity matrix contain all levels (and not n-1 levels) ?
>
>
> On Sep 13, 2013, at 9:33 AM, E Joffe wrote:
>
>> Thank you so much for your answer  !
>> As far as I understand, glmnet doesn't accept categorical variables
>> only binary factors - so I had to create dummy variables for all
>> categorical variables.
>
> I was rather puzzled by your question. The conventions used by  
> glmnet should
> prevent constrasts from being pre-specified. Only matrices are  
> accepted as
> data objects and one cannot assign contrast attributes to matrix  
> columns.
>
>> It worked perfectly.
>> Erel
>>
>>
>> Erel Joffe MD MSc
>> School of Biomedical Informatics
>> University of Texas - Health Science Center in Houston
>> 832.287.0829 (c)
>>
>> -----Original Message-----
>> From: David Winsemius [mailto:dwinsemius at comcast.net]
>> Sent: Friday, September 13, 2013 3:05 PM
>> To: E Joffe
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Creating dummy vars with contrasts - why does the
>> returned identity matrix contain all levels (and not n-1 levels) ?
>>
>>
>> On Sep 13, 2013, at 4:15 AM, E Joffe wrote:
>>
>>> Hello,
>>>
>>>
>>>
>>> I have a problem with creating an identity matrix for glmnet by  
>>> using
>>> the contrasts function.
>>
>> Why do you want to do this?
>>
>>> I have a factor with 4 levels.
>>>
>>> When I create dummy variables I think there should be n-1 variables
>>> (in this case 3) - so that the contrasts would be against the
>>> baseline level.
>>>
>>> This is also what is written in the help file for 'contrasts'.
>>>
>>> The problem is that the function creates a matrix with n variables
>>> (i.e. the same as the number of levels) and not n-1 (where I would
>>> have a baseline level for comparison).
>>
>> Only if you specify contrasts=FALSE does it do so and this is
>> documented in that help file.
>>>
>>>
>>>
>>> My questions are:
>>>
>>> 1.       How can I create a matrix with n-1 dummy vars ?
>>
>> See below.
>>
>>> was I supposed to
>>> define explicitly that I want contr.treatment (contrasts) ?
>>
>> No need to do so.
>>
>>>
>>> 2.       If it is not possible, how should I interpret the hazard
>>> ratios in
>>> the Cox regression I am generating (I use glmnet for variable
>>> selection and
>>> then generate a Cox regression)  - That is, if I get an HR of 3 for
>>> the
>>> variable 300mg what does it mean ? the hazard is 3 times higher of
>>> what ?
>>>
>>
>> Relative hazards are generally referenced to the "baseline hazard",
>> i.e. the hazard for a group with the omitted level for treatment
>> constrasts and the mean value for any numeric predictors.
>>
>>> Here is some code to reproduce the issue:
>>>
>>> # Create a 4 level example factor
>>>
>>> trt <- factor( sample( c("PLACEBO", "300 MG", "600 MG", "1200 MG"),
>>>
>>>                  100, replace=TRUE ) )
>>
>> # If your intent is to use constrasts different than the defaults  
>> used
>> by
>> #  regression functions, these factor contrasts need to be assigned,
>> either
>> # within the construction of the factor or after the fact.
>>
>>> contrasts(trt)
>>     300 MG 600 MG PLACEBO
>> 1200 MG      0      0       0
>> 300 MG       1      0       0
>> 600 MG       0      1       0
>> PLACEBO      0      0       1
>>
>> # the default value for the contrasts parameter is TRUE and the
>> default type is treatement
>>
>> # That did not cause any change to the 'trt'-object:
>> trt
>>
>> #To make a change you need to use the `contrasts<-` function:
>>
>> contrasts (trt) <- contrasts(trt)
>> trt
>>
>>>
>>> # Use contrasts to get the identity matrix of dummy variables to be
>>> used in
>>> glmnet
>>>
>>> trt2 <- contrasts (trt,contrasts=FALSE)
>>>
>>> Results (as you can see all levels are represented in the identity
>>> matrix):
>>>
>>>> levels (trt)
>>> [1] "1200 MG" "300 MG"  "600 MG"  "PLACEBO"
>>>
>>>
>>>> print (trt2)
>>>
>>>   1200 MG 300 MG 600 MG PLACEBO
>>>
>>> 1200 MG       1      0      0       0
>>>
>>> 300 MG        0      1      0       0
>>>
>>> 600 MG        0      0      1       0
>>>
>>> PLACEBO       0      0      0       1
>>>
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>
>> Rhelp is a plain text mailing list.
>>
>> -- 
>> David Winsemius, MD
>> Alameda, CA, USA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius, MD
> Alameda, CA, USA
>
>

David Winsemius, MD
Alameda, CA, USA


From michelgomez at free.fr  Tue Sep 24 10:07:44 2013
From: michelgomez at free.fr (Michel)
Date: Tue, 24 Sep 2013 10:07:44 +0200
Subject: [R] no answer to the following question
Message-ID: <000301ceb8fd$27356350$75a029f0$@fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130924/2c684e46/attachment.pl>

From atta_ycc at yahoo.com  Tue Sep 24 08:44:52 2013
From: atta_ycc at yahoo.com (atta ahmad)
Date: Mon, 23 Sep 2013 23:44:52 -0700 (PDT)
Subject: [R] request for help in R
Message-ID: <1380005092.49621.YahooMailNeo@web162804.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130923/6bfaffce/attachment.pl>

From amen.alyaari at Bordeaux.inra.fr  Tue Sep 24 10:24:40 2013
From: amen.alyaari at Bordeaux.inra.fr (Jonsson)
Date: Tue, 24 Sep 2013 01:24:40 -0700 (PDT)
Subject: [R] how to add a box to map plotted by a levelplot?
Message-ID: <1380011079688-4676815.post@n4.nabble.com>

conne2 <- file("C:\\ome1440s.bin","rb")
         bioms<- readBin(conne2, integer(), size=1,  n=1440*720, signed=F)
        library(raster)
        library(rasterVis)
        data(wrld_simpl)
      library(maptools) ## needed for wrld_simpl
        r <- raster(nrow=720, ncol=1440)
        r[] <- bioms;    r <- ratify(r);    rat <- levels(r)[[1]];   
rat$soil <- LETTERS[1:13];     levels(r) <- rat
         myPal <- c('gray80','gray80','blanchedalmond'
,'chartreuse','yellow','navajowhite2','salmon','lightskyblue','brown4','orange','burlywood4','palegreen','forestgreen')
           
         levelplot(r, col.regions=myPal) +
            layer(sp.polygons(wrld_simpl, lwd=0.5))
 
I want to add a box representing this zone of latitude and longtitude:

             e6 <- extent( 2  , 8 , 45   , 51  )#erop
              plot( e6 , add = TRUE )
but I got this

         Error: invalid graphics state
        Error: invalid graphics state



--
View this message in context: http://r.789695.n4.nabble.com/how-to-add-a-box-to-map-plotted-by-a-levelplot-tp4676815.html
Sent from the R help mailing list archive at Nabble.com.


From kridox at ymail.com  Tue Sep 24 11:01:31 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Tue, 24 Sep 2013 18:01:31 +0900
Subject: [R] how to add a box to map plotted by a levelplot?
In-Reply-To: <1380011079688-4676815.post@n4.nabble.com>
References: <1380011079688-4676815.post@n4.nabble.com>
Message-ID: <CAAcyNCzyP9rpva-=9YN_cCAZdOCZVE3WZvjFJaxDy1djZfuZ0g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130924/8b9e5298/attachment.pl>

From info at aghmed.fsnet.co.uk  Tue Sep 24 11:21:56 2013
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Tue, 24 Sep 2013 10:21:56 +0100
Subject: [R] Arcsine transformation
In-Reply-To: <CACYJ9FQNHU7RvEZViEpiQrr0fX6zm9OddO_3jAJC98zarsHqbg@mail.g
	mail.com>
References: <1379891582470-4676706.post@n4.nabble.com>
	<1379894285612-4676708.post@n4.nabble.com>
	<CACYJ9FQNHU7RvEZViEpiQrr0fX6zm9OddO_3jAJC98zarsHqbg@mail.gmail.com>
Message-ID: <Zen-1VOOon-000Ehr-6v@smarthost01d.mail.zen.net.uk>

At 02:26 23/09/2013, peake wrote:
>Thanks for the advice. Like I said, I am still pretty new to R, and stats
>in general. I tried wading through the search results on google, but I
>didn't really find anything that I could understand. I am working with
>percentages as my dependent variable, and I am trying to get my
>distribution as close to normal as possible. Is an arcsine transformation
>even the correct choice for my data? Querying R for help usually leaves me
>even more confused, so I was hoping someone could help me out by walking me
>through the process.

Transforming proportions is something which people involved in 
meta-analysis of non-comparative studies often do. You might like to 
look in the manual for metafor (on CRAN) and the function escalc 
which has a range of options under non-comparative studies. You might 
also look at betareg (on CRAN).

I think you also need to find some local statistical support as your 
question is now less about R and more about statistics.



>On Sun, Sep 22, 2013 at 8:00 PM, chuck.01 [via R] <
>ml-node+s789695n4676708h93 at n4.nabble.com> wrote:
>
> > ?asin
> >
> > also, try "Googling" anything you might want to do in R... it is there
> >
> > also, google... "R cheatsheet"  you will find several helpful sheets of
> > useful functions.
> >
> >
> >
> > peake wrote
> > I am tryin to perform an arcsine transformation on my data containig
> > percentages as the dep. variable. Does anyone have a code that I could use
> > to do that? I am relatively new to R. Thanks for your help!
> >
> >
> >
> > ------------------------------
> >  If you reply to this email, your message will be added to the discussion
> > below:
> > http://r.789695.n4.nabble.com/Arcsine-transformation-tp4676706p4676708.html
> >  To unsubscribe from Arcsine transformation, click 
> here<http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=4676706&code=cGVha2UuMTlAb3N1LmVkdXw0Njc2NzA2fDE4MjEzMDk3MTU=>
> > .
> > 
> NAML<http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
> >
>
>
>
>
>--
>View this message in context: 
>http://r.789695.n4.nabble.com/Arcsine-transformation-tp4676706p4676712.html
>Sent from the R help mailing list archive at Nabble.com.
>         [[alternative HTML version deleted]]

Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html


From dulcalma at bigpond.com  Tue Sep 24 11:32:33 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Tue, 24 Sep 2013 19:32:33 +1000
Subject: [R] lattice: double y - problem changing axis color
	after	doubleYScale
In-Reply-To: <11019DCE9B47004F90B2D9C62FF15792025EC5A9@ebox-prod-srv04.win.su.se>
References: <11019DCE9B47004F90B2D9C62FF15792025E9E8D@ebox-prod-srv04.win.su.se>,
	<000001ceb73f$dd93b2b0$98bb1810$@bigpond.com>
	<11019DCE9B47004F90B2D9C62FF15792025EC5A9@ebox-prod-srv04.win.su.se>
Message-ID: <001801ceb909$002286b0$00679410$@bigpond.com>

Hi Anna

I have never used doubleYScale and I am not sure what you want but try this

You need to do this first if columns not correct saves doing later - I
forgot to mention it for Week but as you have given the order for the
factors do it as well

SummPdata[,1] <- as.numeric(SummPdata[,1])
SummNdata[,1] <- as.numeric(SummNdata[,1])
SummPdata[,3] <- factor(SummPdata[,3], levels = c('B1', 'H2', 'H3', 'H4'))
SummNdata[,3] <- factor(SummNdata[,3], levels = c('B1', 'H2', 'H3', 'H4'))

As the data has a similar structure combine data

summData = rbind(SummPdata, SummNdata)
summData$element <- rep(c("P","N"), each = 32)

Just quickly cut and pasted the colours etc

useOuterStrips(strip      = strip.custom(#factor.levels = ,
                                         par.strip.text =
list(fontfamily="serif" )),
               strip.left = strip.custom(#factor.levels = ,
                                         par.strip.text =
list(fontfamily="serif" )),
               xyplot(mean ~ Week | Station*interaction(element,fyear),
data= summData,
                cex=1.1,
                par.settings = list(strip.background = list(col =
"transparent"),
                                    add.text = list(fontfamily = "serif")),
                #strip      = strip.custom(#factor.levels = ,
                #                         par.strip.text =
list(fontfamily="serif" )),
               scales = list(alternating = c(3,3),
                              fontfamily = "serif"),
                ylab = list(text = "Pc", fontfamily = "serif"),
                xlab=list(text = "Week", fontfamily = "serif"),
                key  = list(text = list(labels = c("P","N")),
                            points = list(pch = c(2,20), col =
c("red","blue")),
                            lines  = list(lty = c(1,2)), col =
c("red","blue")),
                type = "o",
                ylim = c(0,70),
                subscripts = TRUE,
                panel = function(x,y, subscripts, ...){

                          pnl = panel.number()

                          panel.xyplot(x,y, type = "o", col =
c("red","blue")[ifelse(pnl <9, 1,2)], lty = c(1,2)[ifelse(pnl <9, 1,2)], pch
= c(2,20)[ifelse(pnl <9, 1,2)])
                          # sd
                          # upper
                          panel.arrows(x0 = x, x1 = x,
                                       y0 = y, y1 = y+ summData[subscripts,
"sd"]/2, angle = 90, length = 0.04, col = c("red","blue")[ifelse(pnl <9,
1,2)])
                          # lower
                          panel.arrows(x0 = x, x1 = x,
                                       y0 = y, y1 = y- summData[subscripts,
"sd"]/2, angle = 90, length = 0.04, col = c("red","blue")[ifelse(pnl <9,
1,2)])

                        }# panel
                )#
) ## useOuterStrips

You can fill in the LHS strip with a vector of names as required

If you want to amend the ylimits  see ?combineLimits  in the latticeExtra
package

Duncan


-----Original Message-----
From: Anna Zakrisson Braeunlich [mailto:anna.zakrisson at su.se] 
Sent: Tuesday, 24 September 2013 18:28
To: Duncan Mackay
Subject: RE: [R] lattice: double y - problem changing axis color after
doubleYScale

OK, now the code works - thank you. The error bars are added beautifully!

As I am using doubleYScale, I am having the problem that the first y-axis is
covered by the left hand strip - how can I solve this? I really much prefer
using outer.strip() and have one strip vertically on the plot. It saves plot
space.

I am still having the problem of colourful y-axis when using doubleYScale()
- how can I make them black?
I have the same problem with the error bars - they are also default colour
no matter what I tell them to be.
Is there a way around this except Adobe Photoshop?

Here is the working script with dummy data (you can just run the lot if you
have time). I really appreciate your code - thanks! ...and sorry for being a
bit daft and sending a reply before thinking it through properly.

Ndata <- data.frame(
  Ncellpercent = rnorm(400, mean = rep(c(14, 18, 65), each = 40),
                       sd = rep(c(1, 3, 6), each = 40)),
  fyear = rep(c('2007', '2008'), each = 100*2),
  Station = sample(c('B1', 'H2', 'H3', 'H4'), 400, replace = TRUE),
  Week = sample(c('19', '21', '23', '25'), 400, replace = TRUE))

Pdata <- data.frame(
  Ppercentcell = rnorm(400, mean = rep(c(4, 17, 22), each = 40),
                       sd = rep(c(0.1, 0.2, 0.4), each = 40)),
  fyear = rep(c('2007', '2008'), each = 100*2),
  Station = sample(c('B1', 'H2', 'H3', 'H4'), 400, replace = TRUE),
  Week = sample(c('19', '21', '23', '25'), 400, replace = TRUE))

SummNdata <- ddply(Ndata, .(Week, fyear, Station), summarise, 
                   mean = mean(Ncellpercent), 
                   sd = sd(Ncellpercent))
names(Pdata)
SummPdata <- ddply(Pdata, .(Week, fyear, Station), summarise, 
                   mean = mean(Ppercentcell), 
                   sd = sd(Ppercentcell)) SummPdata

plotNtest <- useOuterStrips(strip      = strip.custom(factor.levels =
c("B1", "H2", "H3", "H4"),
  par.strip.text =
    list(fontfamily="serif" )),
               strip.left = strip.custom(factor.levels = c("2007", "2008",
"2009"),
                 par.strip.text =
                   list(fontfamily="serif" )),
               xyplot(mean ~ Week | Station*fyear, data= SummNdata,
                      col="black",
                      pch=1,
                      cex=1.1,
                      lty=1,
                      par.settings = list(strip.background = list(col =
 
"transparent"),
                                          add.text = list(fontfamily =
"serif"
                                          )),
                      strip      = strip.custom(factor.levels = c("B1",
"H2", "H3", "H4"),
                                               par.strip.text =
                      list(fontfamily="serif" )),
               scales = list(alternating = c(3,3),
                             fontfamily = "serif"),
               ylab = list(text = "Nc", fontfamily = "serif"),
               xlab=list(text = "Week", fontfamily = "serif"),
               key  = list(text = list(labels = c("Pc","Nc")),
                           points = list(pch = c(1,2)),
                           lines  = list(lty = c(1,2))),
               type = "o",
               ylim = c(0,70),
               subscripts = TRUE,
               panel = function(x,y, subscripts, ...){
                 panel.xyplot(x,y, ...)
                 # sd
                 # upper
                 panel.arrows(x0 = x, x1 = x,
                              y0 = y, y1 = y+ SummNdata[subscripts,
                                                        "sd"]/2, angle = 90,
length = 0.04)
                 # lower
                 panel.arrows(x0 = x, x1 = x,
                              y0 = y, y1 = y- SummNdata[subscripts,
                                                        "sd"]/2, angle = 90,
length = 0.04)
                 
                 panel.xyplot(x+0.1, SummNdata[subscripts,"mean"],
                              type ="o",pch = 20, lty =1, col = "black")
                 # sd
                 # upper
                 panel.arrows(x0 = x+0.1, x1 = x+0.1,
                              y0 = SummNdata[subscripts,"mean"], y1
                              = SummNdata[subscripts,"mean"] +
SummNdata[subscripts, "sd"]/2, angle = 90,
                              length = 0.04)
                 # lower
                 panel.arrows(x0 = x+0.1, x1 = x+0.1,
                              y0 = SummNdata[subscripts,"mean"], y1
                              = SummNdata[subscripts,"mean"]-
SummNdata[subscripts, "sd"]/2, angle = 90,
                              length = 0.04)
                 
               }# panel
)#
) ## useOuterStrips

plotPtest <- useOuterStrips(strip      = strip.custom(factor.levels =
c("B1", "H2", "H3", "H4"),
                                                 par.strip.text =
                                                   list(fontfamily="serif"
)),
                       strip.left = strip.custom(factor.levels = c("2007",
"2008", "2009"),
                                                 par.strip.text =
                                                   list(fontfamily="serif"
)),
                       xyplot(mean ~ Week | Station*fyear, data= SummPdata,
                              col="black",
                              pch=2,
                              cex=1.1,
                              lty=2,
                              par.settings = list(strip.background =
list(col =
 
"transparent"),
                                                  add.text = list(fontfamily
= "serif"
                                                  )),
                              strip      = strip.custom(factor.levels =
c("B1", "H2", "H3", "H4"),
                                                        par.strip.text =
 
list(fontfamily="serif" )),
                              scales = list(alternating = c(3,3),
                                            fontfamily = "serif"),
                              ylab = list(text = "Pc", fontfamily =
"serif"),
                              xlab=list(text = "Week", fontfamily =
"serif"),
                              type = "o",
                              ylim = c(0,70),
                              subscripts = TRUE,
                              panel = function(x,y, subscripts, ...){
                                panel.xyplot(x,y, ...)
                                # sd
                                # upper
                                panel.arrows(x0 = x, x1 = x,
                                             y0 = y, y1 = y+
SummPdata[subscripts,
 
"sd"]/2, angle = 90, length = 0.04)
                                # lower
                                panel.arrows(x0 = x, x1 = x,
                                             y0 = y, y1 = y-
SummPdata[subscripts,
 
"sd"]/2, angle = 90, length = 0.04)
                                
                                panel.xyplot(x+0.1,
SummPdata[subscripts,"mean"],
                                             type ="o",pch = 20, lty =1, col
= "black")
                                # sd
                                # upper
                                panel.arrows(x0 = x+0.1, x1 = x+0.1,
                                             y0 =
SummPdata[subscripts,"mean"], y1
                                             = SummPdata[subscripts,"mean"]
+ SummPdata[subscripts, "sd"]/2, angle = 90,
                                             length = 0.04)
                                # lower
                                panel.arrows(x0 = x+0.1, x1 = x+0.1,
                                             y0 =
SummPdata[subscripts,"mean"], y1
                                             = SummPdata[subscripts,"mean"]-
SummPdata[subscripts, "sd"]/2, angle = 90,
                                             length = 0.04)
                                
                              }# panel
                       )#
) ## useOuterStrips


plotNtest
plotPtest
doubleYScale(plotNtest, plotPtest, add.ylab2 = TRUE)

Can I make the
Anna Zakrisson Braeunlich
PhD student

Department of Ecology, Environment and Plant Sciences Stockholm University
Svante Arrheniusv. 21A
SE-106 91 Stockholm
Sweden/Sverige

Lives in Berlin.
For paper mail:
Katzbachstr. 21
D-10965, Berlin - Kreuzberg
Germany/Deutschland

E-mail: anna.zakrisson at su.se
Tel work: +49-(0)3091541281
Mobile: +49-(0)15777374888
LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b

><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? 
>`?. .? `?. .><((((?>

________________________________________
From: Duncan Mackay [dulcalma at bigpond.com]
Sent: 22 September 2013 05:00
To: Anna Zakrisson Braeunlich
Cc: R
Subject: RE: [R] lattice: double y - problem changing axis color after
doubleYScale

Hi  Anna

I am not sure what you want but the following should get you part of the way

I prefer to keep all my parameters within the function rather than use
themes.

useOuterStrips(strip      = strip.custom(#factor.levels = ,
                                         par.strip.text =
list(fontfamily="serif" )),
               strip.left = strip.custom(#factor.levels = ,
                                         par.strip.text =
list(fontfamily="serif" )), xyplot(mean ~ Week | Station*fyear, data=
SummPdata,
                col="black",
                pch=2,
                cex=1.1,
                lty=2,
                par.settings = list(strip.background = list(col =
"transparent"),
                                    add.text = list(fontfamily = "serif"
)),
                #strip      = strip.custom(#factor.levels = ,
                #                         par.strip.text =
list(fontfamily="serif" )),
               scales = list(alternating = c(3,3),
                              fontfamily = "serif"),
                ylab = list(text = "Pc", fontfamily = "serif"),
                xlab=list(text = "Week", fontfamily = "serif"),
                key  = list(text = list(labels = c("P","N")),
                            points = list(pch = c(2,20)),
                            lines  = list(lty = c(1,2))),
                type = "o",
                ylim = c(0,70),
                subscripts = TRUE,
                panel = function(x,y, subscripts, ...){
                          panel.xyplot(x,y, ...)
                          # sd
                          # upper
                          panel.arrows(x0 = x, x1 = x,
                                       y0 = y, y1 = y+ SummPdata[subscripts,
"sd"]/2, angle = 90, length = 0.04)
                          # lower
                          panel.arrows(x0 = x, x1 = x,
                                       y0 = y, y1 = y- SummPdata[subscripts,
"sd"]/2, angle = 90, length = 0.04)

                          panel.xyplot(x+0.1, SummNdata[subscripts,"mean"],
type ="o",pch = 20, lty =1, col = "black")
                          # sd
                          # upper
                          panel.arrows(x0 = x+0.1, x1 = x+0.1,
                                      y0 = SummNdata[subscripts,"mean"], y1
= SummNdata[subscripts,"mean"] + SummNdata[subscripts, "sd"]/2, angle = 90,
length = 0.04)
                          # lower
                          panel.arrows(x0 = x+0.1, x1 = x+0.1,
                                       y0 = SummNdata[subscripts,"mean"], y1
= SummNdata[subscripts,"mean"]- SummNdata[subscripts, "sd"]/2, angle = 90,
length = 0.04)

                        }# panel
                )#
) ## useOuterStrips

Note that I offset the N data so that the error bars are more legible

For sd I just divided them by 2 so you will have to work out what you
require

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Anna Zakrisson Braeunlich
Sent: Thursday, 19 September 2013 20:21
To: r-help at r-project.org
Subject: [R] lattice: double y - problem changing axis color after
doubleYScale

Hi,

I have had some troubles using doubleYScale. No matter what I try, I cant
manage to change the color of the y-axis in the end. I have to produce a
black and white plot. There is also something I do not understand regarding
fontfamilyj="serif" when using it in:
strip=strip.custom()

Maybe someone has a better idea for defining which line and dots belong to
which y-axis when not using a colorcode than the one I had.

I have annotated my questions in the code below.

Thank you for your time!


Here is some dummy data:

Ndata <- data.frame(
  Ncellpercent = rnorm(400, mean = rep(c(14, 18, 65), each = 40),
               sd = rep(c(1, 3, 6), each = 40)),
  fyear = rep(c('2007', '2008'), each = 100*2),
  Station = sample(c('B1', 'H2', 'H3', 'H4'), 400, replace = TRUE),
  Week = sample(c('19', '21', '23', '25'), 400, replace = TRUE))

Pdata <- data.frame(
  Ppercentcell = rnorm(400, mean = rep(c(4, 17, 22), each = 40),
               sd = rep(c(0.1, 0.2, 0.4), each = 40)),
  fyear = rep(c('2007', '2008'), each = 100*2),
  Station = sample(c('B1', 'H2', 'H3', 'H4'), 400, replace = TRUE),
  Week = sample(c('19', '21', '23', '25'), 400, replace = TRUE))

SummNdata <- ddply(Ndata, .(Week, fyear, Station), summarise,
                   mean = mean(Ncellpercent),
                   sd = sd(Ncellpercent))
names(Pdata)
SummPdata <- ddply(Pdata, .(Week, fyear, Station), summarise,
                   mean = mean(Ppercentcell),
                   sd = sd(Ppercentcell))
library(lattice)
library(latticeExtra)
library(HH)

font.settings <- list( font = 1, cex = 1.2, fontfamily = "serif")

my.theme <- list(
  par.xlab.text = font.settings,
  par.ylab.text = font.settings,
  axis.text = font.settings,
  par.sub=font.settings)

plotN <- xyplot(mean ~ Week | Station*fyear,
                col="black",
                pch=1,
                cex=1.1,
                lty=1,
                strip = strip.custom(bg = 'white', style=1), # why can I not
use fontfamily="serif" here ???
                key=list(text=list(c(""),
                                   col=c("black")),
                         points=list(pch=1, lty=1, cex=1.5,
                                     col=c("black")),
                         columns=1, border=F,
                         x = 0.02, y = 0.55, corner = c(2, 2),
                         title="", cex.title=1.3),
                ylab = ("Nc"),
                xlab="Week",
                data= SummNdata,type="o",
                par.settings = my.theme) plotN # I would like to add the
standard deviations (sd) to the plot. I have tried some stuff, # but for
some reason, it does not seem to work. How would I go about this?


plotP <- xyplot(mean ~ Week | Station*fyear,
                col="black",
                pch=2,
                cex=1.1,
                lty=2,
                strip = strip.custom(bg = 'white', style=1), # why can I not
use fontfamily="serif" here ???
                key=list(text=list(c(""),
                                   col=c("black")),
                         points=list(pch=1, lty=1, cex=1.5,
                                     col=c("black")),
                         columns=1, border=F,
                         x = 0.2, y = 0.2, corner = c(2, 2),
                         title="", cex.title=1.3),
                ylab = ("Pc"),
                xlab="Week",
                data= SummPdata,type="o",
                par.settings = my.theme) plotP

doubleYScale(plotN, plotP, add.ylab2 = TRUE)  #Why can I not change the axis
color by adding to this argument?

# I want the y1 and y2 axes to be defined not by color, but by shape and
linetype.
# I have managed to draw the shapes (defined by Nc and Pc) by the y1 and y2
axes, but I do not manage to get the lines # though the shape - ideas?
# Alternative ways that are not based on color (I have to do this black and
white).
# Is there possible to add shapes to the axis text? such as:
# --O-- Nc  on the left y-axis (but with lty=1: I could not do a non-dotted
line on the keybord).

with kind regards

Anna Zakrisson Braeunlich
PhD student

Department of Ecology, Environment and Plant Sciences Stockholm University
Svante Arrheniusv. 21A
SE-106 91 Stockholm
Sweden/Sverige

Lives in Berlin.
For paper mail:
Katzbachstr. 21
D-10965, Berlin - Kreuzberg
Germany/Deutschland

E-mail: anna.zakrisson at su.se
Tel work: +49-(0)3091541281
Mobile: +49-(0)15777374888
LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b

><((((:>`?. . ? `?. .? `?. . ><((((:>`?. . ? `?. .? `?. .><((((:>`?. . ?
>`?. .? `?. .><((((:>

        [[alternative HTML version deleted]]


From andreas_wittmann at gmx.de  Tue Sep 24 11:34:00 2013
From: andreas_wittmann at gmx.de (Andreas Wittmann)
Date: Tue, 24 Sep 2013 11:34:00 +0200
Subject: [R] R function for censored linear regression
Message-ID: <52415C88.40602@gmx.de>

Dear R-useRs,

I'm looking for an R-function for censored linear regression. I have the 
following data

x1 <- rnorm(100)
x2 <- rnorm(100)
y <- x1 + 2*x2 + rnorm(100,0,0.5)
stat <- rep(1,100)
stat[50:100] <- 0
data <- data.frame(y,x1,x2,stat)

y is the dependent variable, x1 and x2 are the independent variables in 
a linear model. the variable y could be right-censored, this information 
is in the variable stat, where 1 denotes observed and 0 denotes 
censored. If stat is 0, then the value in y is the observed 
right-censored value and could be greater. Using the Tobit-model would 
not be the right thing here because the Tobit model assumes the same 
limit for all observations, in my data each value of y[50:100] could 
have a different limit.

If i use linear regression

lm1 <- lm(y ~ x1 + x2, data=data)
summary(lm1)

the censoring is not incorporated, so my idea is to use survreg from the 
survival package

library(survival)
s1 <- survreg(Surv(y, stat) ~ x1 + x2, data, dist='gaussian')
summary(s1)

my question is, is this the right approach for my aim? Is it right, that 
here each censored observations could have its own limit?

Thanks and best regards
Andreas


From maechler at lynne.ethz.ch  Tue Sep 24 11:55:29 2013
From: maechler at lynne.ethz.ch (Martin Maechler)
Date: Tue, 24 Sep 2013 11:55:29 +0200
Subject: [R] Rmpfr question
In-Reply-To: <!&!AAAAAAAAAAAYAAAAAAAAAD+bP9Kay49OhKgiYwFy3LDCgAAAEAAAADLTCDxVQ7NOlQPBclfnJl0BAAAAAA==@free.fr>
References: <!&!AAAAAAAAAAAYAAAAAAAAAD+bP9Kay49OhKgiYwFy3LDCgAAAEAAAADLTCDxVQ7NOlQPBclfnJl0BAAAAAA==@free.fr>
Message-ID: <21057.24977.237949.686614@gargle.gargle.HOWL>

>>>>> "M" == Michel  <michelgomez at free.fr>
>>>>>     on Fri, 20 Sep 2013 17:56:58 +0200 writes:

    > Hello everyone, R beginner, I am confronted with the need
    > to use Rmpf.
why ?

    > In my first scripts I made use of
    > X=read.table(file.choose(), header=FALSE, sep=",",dec=".")  
    > X=as.matrix(X)

well, the above is not at all reproducible {we don't see *nor*
have the file you chose with file.choose() !}
so that's maybe why nobody helped ...

Does the file have numbers in high precision, i.e. more than
about 15-16 digits?
I'm assuming "no" for the moment.
If "yes" was the answer, then you really need to read the data
quite differently.
In that case please, show us the first few lines  of your file.


    > to load into a matrix data from file before matrix use.

    > How can I do to load the same data in a "mpfrMatrix".

As you already have the regular numeric matrix X,
you can either use

    M <- as(X, "mpfr") # uses default precision of 128 bits
or
    M <- mpfr(X, precBits = 200)

where you choose the precision of the numbers via 'precBits'


    > Is it possible to use with "mpfrMatrix" the same as
    > operations

    > M1 %*% M2

yes, matrix multiplications all work ... though a bit slowly.
matrix factorizations (eigen, svd, qr, solve,..) all do not
(yet; patches are welcome; I'm currently working at an LU decomposition).

    >  scale(M1,TRUE,FALSE)

not directly, in the current version of Rmpfr.
But you can use the following trick:

    scale.mpfrMatrix <- scale.default
    environment(scale.mpfrMatrix) <- asNamespace("Rmpfr")

and then it will work.


    > Sorry but I'm a newbe

let's hope, not for too long ;-) ;-)

    > Thanks in advance
    > Michel

You're welcome,
Martin Maechler, ETH Zurich

(maintainer of the 'Rmpfr' package.
 Yes, I know you also sent the question to me privately, 
 but only several days *after* asking on R-help; it would have
 been nice, if you had mentioned that you also asked here and
 nobody helped you.  ...)


From michelgomez at free.fr  Tue Sep 24 12:22:10 2013
From: michelgomez at free.fr (Michel)
Date: Tue, 24 Sep 2013 12:22:10 +0200
Subject: [R] Rmpfr question
In-Reply-To: <21057.24977.237949.686614@gargle.gargle.HOWL>
References: <!&!AAAAAAAAAAAYAAAAAAAAAD+bP9Kay49OhKgiYwFy3LDCgAAAEAAAADLTCDxVQ7NOlQPBclfnJl0BAAAAAA==@free.fr>
	<21057.24977.237949.686614@gargle.gargle.HOWL>
Message-ID: <!&!AAAAAAAAAAAYAAAAAAAAAD+bP9Kay49OhKgiYwFy3LDCgAAAEAAAAARyIl+ueG1Ng/+/IIAPTdABAAAAAA==@free.fr>

Hello,
Thanks for your answer
The file does not contains numbers in high precision but all the calculation
applied to these data will be 

In attachment a text file containing some lines
And her few values:
11111.0054014388224326026488598,-68239.4114845811819662912967033,10053.18245
84878233990181684021
3.05363891777017837760380136736,-1.40443175474415104684797195311,1.367669608
77453817890022497172

Many thanks in advance
Michel

-----Message d'origine-----
De?: Martin Maechler [mailto:maechler at lynne.ethz.ch] 
Envoy??: mardi 24 septembre 2013 11:55
??: Michel
Cc?: r-help at r-project.org
Objet?: Re: [R] Rmpfr question

>>>>> "M" == Michel  <michelgomez at free.fr>
>>>>>     on Fri, 20 Sep 2013 17:56:58 +0200 writes:

    > Hello everyone, R beginner, I am confronted with the need
    > to use Rmpf.
why ?

    > In my first scripts I made use of
    > X=read.table(file.choose(), header=FALSE, sep=",",dec=".")  
    > X=as.matrix(X)

well, the above is not at all reproducible {we don't see *nor* have the file
you chose with file.choose() !} so that's maybe why nobody helped ...

Does the file have numbers in high precision, i.e. more than about 15-16
digits?
I'm assuming "no" for the moment.
If "yes" was the answer, then you really need to read the data quite
differently.
In that case please, show us the first few lines  of your file.


    > to load into a matrix data from file before matrix use.

    > How can I do to load the same data in a "mpfrMatrix".

As you already have the regular numeric matrix X, you can either use

    M <- as(X, "mpfr") # uses default precision of 128 bits or
    M <- mpfr(X, precBits = 200)

where you choose the precision of the numbers via 'precBits'


    > Is it possible to use with "mpfrMatrix" the same as
    > operations

    > M1 %*% M2

yes, matrix multiplications all work ... though a bit slowly.
matrix factorizations (eigen, svd, qr, solve,..) all do not (yet; patches
are welcome; I'm currently working at an LU decomposition).

    >  scale(M1,TRUE,FALSE)

not directly, in the current version of Rmpfr.
But you can use the following trick:

    scale.mpfrMatrix <- scale.default
    environment(scale.mpfrMatrix) <- asNamespace("Rmpfr")

and then it will work.


    > Sorry but I'm a newbe

let's hope, not for too long ;-) ;-)

    > Thanks in advance
    > Michel

You're welcome,
Martin Maechler, ETH Zurich

(maintainer of the 'Rmpfr' package.
 Yes, I know you also sent the question to me privately,  but only several
days *after* asking on R-help; it would have  been nice, if you had
mentioned that you also asked here and  nobody helped you.  ...)



 
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: sommelines.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130924/918b2aa5/attachment.txt>

From joseclaudio.faria at gmail.com  Tue Sep 24 12:50:16 2013
From: joseclaudio.faria at gmail.com (Jose Claudio Faria)
Date: Tue, 24 Sep 2013 07:50:16 -0300
Subject: [R] Vector of char generated by Sys.getenv function is not
 available when the package is loaded
In-Reply-To: <99A9A6DF-C68F-4931-A322-1E69DF79D304@sciviews.org>
References: <CAN+Emd8yfGRz3KSBpDGUeZU1H07o1Ut2A=QYOOyix=_-gLYtsg@mail.gmail.com>
	<99A9A6DF-C68F-4931-A322-1E69DF79D304@sciviews.org>
Message-ID: <CAN+Emd_D0RO7FwMJ1_2=xP7t7ah4fSvFY2ukFG5K9A=f8=Lo_A@mail.gmail.com>

Hi,

I prefer to build my packages on Linux!

I changed the object trPaths as below,
After R CMD build TinnRcom on Linux and did the installation
on Windows from the source code: It worked very well!

I thank all who contributed to the solution and apologize for my lack
of knowledge in this area.

trPaths <-
  file.path(ifelse(.Platform$OS.type == "windows",
                   Sys.getenv("APPDATA"),
                   Sys.getenv("HOME")),
            "Tinn-R",
            "tmp",
            c('',
              'search.txt',
              'objects.txt',
              'file.r',
              'selection.r',
              'block.r',
              'lines.r',
              'reformat-input.r',
              'reformat-output.r'),
            fsep='\\')

> install.packages('TinnRcom_1.0-09.tar.gz', repos=NULL, type='source')
* installing *source* package 'TinnRcom' ...
** R
** inst
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded
* DONE (TinnRcom)

> library(TinnRcom)
Loading required package: tcltk
Loading required package: Hmisc
Loading required package: survival
Loading required package: splines
Loading required package: Formula
Hmisc library by Frank E Harrell Jr

Type library(help='Hmisc'), ?Overview, or ?Hmisc.Overview')
to see overall documentation.


Attaching package: ?Hmisc?

The following object is masked from ?package:survival?:

    untangle.specials

The following objects are masked from ?package:base?:

    format.pval, round.POSIXt, trunc.POSIXt, units

Loading required package: R2HTML
Loading required package: svSocket
Loading required package: formatR

> trPaths
[1] "C:\\Users\\jcfaria\\AppData\\Roaming\\Tinn-R\\tmp\\"
[2] "C:\\Users\\jcfaria\\AppData\\Roaming\\Tinn-R\\tmp\\search.txt"
[3] "C:\\Users\\jcfaria\\AppData\\Roaming\\Tinn-R\\tmp\\objects.txt"
[4] "C:\\Users\\jcfaria\\AppData\\Roaming\\Tinn-R\\tmp\\file.r"
[5] "C:\\Users\\jcfaria\\AppData\\Roaming\\Tinn-R\\tmp\\selection.r"
[6] "C:\\Users\\jcfaria\\AppData\\Roaming\\Tinn-R\\tmp\\block.r"
[7] "C:\\Users\\jcfaria\\AppData\\Roaming\\Tinn-R\\tmp\\lines.r"
[8] "C:\\Users\\jcfaria\\AppData\\Roaming\\Tinn-R\\tmp\\reformat-input.r"
[9] "C:\\Users\\jcfaria\\AppData\\Roaming\\Tinn-R\\tmp\\reformat-output.r"

All the best,
-- 
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
Jose Claudio Faria
Estatistica
UESC/DCET/Brasil
joseclaudio.faria at gmail.com
Telefones:
55(73)3680.5545 - UESC
55(73)9100.7351 - TIM
55(73)8817.6159 - OI
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\


From babakbsn at gmail.com  Tue Sep 24 12:19:02 2013
From: babakbsn at gmail.com (Babak Bastan)
Date: Tue, 24 Sep 2013 03:19:02 -0700
Subject: [R] Invalid Z argument error in persp.default
Message-ID: <CAF-JZQu+ovWAxU6OBiMG_j4_xDAhG1Jnj61M_tBbc4D_BvH8JQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130924/84df8f0d/attachment.pl>

From alexis.boucharin at ki.se  Tue Sep 24 13:10:58 2013
From: alexis.boucharin at ki.se (AlexisB)
Date: Tue, 24 Sep 2013 04:10:58 -0700 (PDT)
Subject: [R] Issue with lmerTest and dopar
Message-ID: <1380021058047-4676831.post@n4.nabble.com>

Hi,

I have a problem with running a script in parallel with the foreach function
for computing linear models at every voxel of a set of 3D images. When I run
it using %do%, it runs fine and I get the correct output but when I run it
with %dopar% then my main output is not correct. The problem inside the
foreach loop seems to be in the function called "lmer" which is part of the
lmerTest package. It is used to compute linear models and the issue is that
lmer returns the p-values which are different for each test when using %do%
but they are all the same when using %dopar%, which is obviously incorrect.

Here is the foreach loop:

#To try with the first 5 voxels only, so that it works.
resultTest<-foreach (index=1:5, .combine=rbind, .packages='lmerTest',
.verbose=TRUE) %dopar% {  
	
	i1 <- inmask[index,1]
	i2 <- inmask[index,2]
	i3 <- inmask[index,3]
	y <- ydat[i1,i2,i3,]
	
	# create the datafile with current voxel, with the voxelvalues and
variables of 
	# interest
	long <- data.frame(cbind(xdat,y))
	  
	# do the model you want to do on the data
	fm1 <- lmer(y ~ 1 + time + (1|id), long)

	# extract what you care about and save in your created array, with the
index you are
	# currently running. Type fm1 to see your output, str(fm1) to see your
slots, so you 
	# can find where the data you want are (which place in the order, which can
depend on 
	# your model).
	p=fm1 at t.pval[2]
	p.time[i1,i2,i3] <- p
	
}

And here is the output p-values when running with %do%:

result.1 0.02976868
result.2 0.01706419
result.3 0.01509690
result.4 0.02078050
result.5 0.03950854

Output using %dopar% (I ran this one right after the %do%, you can see that
all the p-values here are the same as the last p-value ran with %do%)

result.1 0.03950854
result.2 0.03950854
result.3 0.03950854
result.4 0.03950854
result.5 0.03950854



Also, here is the lmer function (from the lmerTest package):

lmer <-function(formula, data, family = NULL, REML = TRUE,
             control = list(), start = NULL, verbose = FALSE, doFit = TRUE,
             subset, weights, na.action, offset, contrasts = NULL,
             model = TRUE, x = TRUE, ...)
    {
      mc<-match.call()
      mc[[1]] <- quote(lme4::lmer)
      model<-eval.parent(mc)
      model<-as(model,"merLmerTest")
      #tryCatch(  { result = glm( y~x , family = binomial( link = "logit" )
) } , error = function(e) { print("test") } )
      t.pval <- tryCatch( {totalAnovaRandLsmeans(model=model,
ddf="Satterthwaite", isTtest=TRUE)$ttest$tpvalue}, error = function(e) {
NULL })
      if(!is.null(t.pval))
      {
        model at t.pval <-t.pval
      }
      else
      {
        model<-as(model,"mer")
      }
      return(model)
    }


What I do not understand is that all the other data output by lmer is fine
and different for each voxel except for this p-value.

So if anyone has a hint on how I could solve this issue, I would greatly
appreciate.

Thank you in advance.

Best regards,

Alexis.



--
View this message in context: http://r.789695.n4.nabble.com/Issue-with-lmerTest-and-dopar-tp4676831.html
Sent from the R help mailing list archive at Nabble.com.


From amen.alyaari at Bordeaux.inra.fr  Tue Sep 24 11:21:33 2013
From: amen.alyaari at Bordeaux.inra.fr (Jonsson)
Date: Tue, 24 Sep 2013 02:21:33 -0700 (PDT)
Subject: [R] how to add a box to map plotted by a levelplot?
In-Reply-To: <CAAcyNCzyP9rpva-=9YN_cCAZdOCZVE3WZvjFJaxDy1djZfuZ0g@mail.gmail.com>
References: <1380011079688-4676815.post@n4.nabble.com>
	<CAAcyNCzyP9rpva-=9YN_cCAZdOCZVE3WZvjFJaxDy1djZfuZ0g@mail.gmail.com>
Message-ID: <1380014493920-4676820.post@n4.nabble.com>

That worked fine, thanks. But only worked when the values are positive but
when I added negative values, the box was wrong. May be the order I lat and
long should be different?any ideas



--
View this message in context: http://r.789695.n4.nabble.com/how-to-add-a-box-to-map-plotted-by-a-levelplot-tp4676815p4676820.html
Sent from the R help mailing list archive at Nabble.com.


From amen.alyaari at Bordeaux.inra.fr  Tue Sep 24 11:41:52 2013
From: amen.alyaari at Bordeaux.inra.fr (Jonsson)
Date: Tue, 24 Sep 2013 02:41:52 -0700 (PDT)
Subject: [R] how to add a box to map plotted by a levelplot?
In-Reply-To: <CAAcyNCzyP9rpva-=9YN_cCAZdOCZVE3WZvjFJaxDy1djZfuZ0g@mail.gmail.com>
References: <1380011079688-4676815.post@n4.nabble.com>
	<CAAcyNCzyP9rpva-=9YN_cCAZdOCZVE3WZvjFJaxDy1djZfuZ0g@mail.gmail.com>
Message-ID: <1380015712685-4676825.post@n4.nabble.com>

Thanks.That worked fine.Is there a way to print a number like 1 inside the
box plotted?



--
View this message in context: http://r.789695.n4.nabble.com/how-to-add-a-box-to-map-plotted-by-a-levelplot-tp4676815p4676825.html
Sent from the R help mailing list archive at Nabble.com.


From murdoch.duncan at gmail.com  Tue Sep 24 13:52:44 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 24 Sep 2013 07:52:44 -0400
Subject: [R] Invalid Z argument error in persp.default
In-Reply-To: <CAF-JZQu+ovWAxU6OBiMG_j4_xDAhG1Jnj61M_tBbc4D_BvH8JQ@mail.gmail.com>
References: <CAF-JZQu+ovWAxU6OBiMG_j4_xDAhG1Jnj61M_tBbc4D_BvH8JQ@mail.gmail.com>
Message-ID: <52417D0C.5010301@gmail.com>

On 13-09-24 6:19 AM, Babak Bastan wrote:
> I do the folloowing in order to get 3D Plot:
>
> y<-1:(point/2)
> x<-20:30
> z<-r[1:(point/2)]
> persp(x,y,z,theta = 135, phi = 30, col = "green3", scale = FALSE,
> ltheta = -120, shade = 0.75,
>        border = 1)
>
>
> y:
>
> [1] 1 2 3 4 5
>
> x:
>
> [1] 20 21 22 23 24 25
>
> z:
>
> [1] 4811.000000    3.593025    6.968666    4.908174    5.332700
>
> but i always get the error message Error in persp.default(x, y, z, theta =
> 135, phi = 30, col = "green3", :invalid 'z' argument
>
> How may I solve the issue?

See ?persp.  z should be a 5x5 matrix to match your x and y.

Duncan Murdoch


From ligges at statistik.tu-dortmund.de  Tue Sep 24 14:17:09 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 24 Sep 2013 14:17:09 +0200
Subject: [R] Rmpfr question; was: no answer to the following question
In-Reply-To: <000301ceb8fd$27356350$75a029f0$@fr>
References: <000301ceb8fd$27356350$75a029f0$@fr>
Message-ID: <524182C5.8040905@statistik.tu-dortmund.de>



On 24.09.2013 10:07, Michel wrote:
> I sent this message :
> 			Hello everyone,
> 			R beginner, I am confronted with the need to use
> Rmpf.

It helps to provide a sensible subject line and not to misspell package 
names:Rmpfr.


> 			In my first scripts I made use of
> 				X=read.table(file.choose(), header=FALSE,
> sep=",",dec=".")
> 				X=as.matrix(X)
> 			to load into a matrix data  from file before matrix
> use.
> 			How can I do to load the same data in a
> "mpfrMatrix".
> 			Is it possible to use with "mpfrMatrix" the same as
> operations

M1 <- mpfr(M1, precBits = ....)


> 				M1%*%M2

Should work out of the box for mpfr objects.


> 				scale(M1,TRUE,FALSE)

There is not scale function implemented in Rmpfr. HEnce you need to 
write it yourself based on the provided infrastructure from the Rmpfr 
package.

Best,
Uwe Ligges

> 			Sorry but I'm a newbe
>
> 			Thanks in advance
>
> 			Michel
>
> But no body ... may be my question appear too simple for r-help people
> I'll try alone using books
> Thank you anyway
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Tue Sep 24 14:18:21 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 24 Sep 2013 14:18:21 +0200
Subject: [R] Date Comparing *Problem*
In-Reply-To: <1379936913489-4676739.post@n4.nabble.com>
References: <1379936913489-4676739.post@n4.nabble.com>
Message-ID: <5241830D.6070909@statistik.tu-dortmund.de>



On 23.09.2013 13:48, Rhymes wrote:
> I have a problem with comparing dates. i tried it like "datesub =
> subset(data, 2012-11-19 < data$date)", but this doesn't work and i don't
> know why.

Errr, in R:
  2012-11-19 == 1982

You probably want to convert it to a Date object or Posix.. object, but 
since we do not know ehat data$date is.....

Best,
Uwe Ligges


>
> Hope you can help me.
>
> here are my files:
> http://uploaded.net/file/n9sxdm0v <http://uploaded.net/file/n9sxdm0v>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Date-Comparing-Problem-tp4676739.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From highstat at highstat.com  Tue Sep 24 14:23:35 2013
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Tue, 24 Sep 2013 13:23:35 +0100
Subject: [R] GAM & GAMM course
Message-ID: <52418447.30508@highstat.com>

We would like to announce the following statistics course:

Beginner's Guide to MCMC, GAM and GAMM

When: 10-14 March 2014
Where: Elche, Alicante, Spain

For details, see: http://www.highstat.com/statscourse.htm
Course flyer: http://www.highstat.com/Courses/Flyer2014_3ElcheV2.pdf


Kind regards,

Alain Zuur


-- 
Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007)
2. Mixed effects models and extensions in ecology with R (2009)
3. A Beginner's Guide to R (2009)
4. Zero Inflated Models and GLMM with R (2012)
5. A Beginner's Guide to GAM (2012)
6. A Beginner's Guide to GLM and GLMM (2013)

Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com


From mohan.radhakrishnan at polarisft.com  Tue Sep 24 14:46:36 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Tue, 24 Sep 2013 18:16:36 +0530
Subject: [R] Graph is without line
Message-ID: <OF77059D3A.6545B4E9-ON65257BF0.0045C758-65257BF0.00462B70@polarisft.com>

Hi,
        Sometimes I get a graph like the attached one. The data type could 
have something to do with it. This graph does not use the color and does 
not draw
a line. Earlier I used to convert the factors in the data frame to another 
data type and drew the correct graphs.

Any idea why this happens ?

Thanks,
Mohan

            Var1 Freq
1     10.1.17.10  205
2     10.1.17.15  216
3     10.1.17.17   79
4     10.1.17.23   76
5     10.1.17.24  209
6      10.1.17.5  244
7      10.1.17.6  178
8      10.1.17.7  165
9      10.1.17.8  146



#prints factor
print(class(data$Var1))

plot(data$Var1,data$Freq,ylim=c(0,700),col="green",type="o",ylab="",xlab="",las=2,lwd=2.5,xaxt="n")
title("Estimation of concurrent connections",cex.main=3)
library(plotrix)
staxlab(at=data$Var1,
  labels=as.character(data$Var1),nlines=3,srt=90)


This e-Mail may contain proprietary and confidential information and is sent for the intended recipient(s) only.  If by an addressing or transmission error this mail has been misdirected to you, you are requested to delete this mail immediately. You are also hereby notified that any use, any form of reproduction, dissemination, copying, disclosure, modification, distribution and/or publication of this e-mail message, contents or its attachment other than by its intended recipient/s is strictly prohibited.

Visit us at http://www.polarisFT.com

From smartpink111 at yahoo.com  Tue Sep 24 15:16:10 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 24 Sep 2013 06:16:10 -0700 (PDT)
Subject: [R] Graph is without line
In-Reply-To: <OF77059D3A.6545B4E9-ON65257BF0.0045C758-65257BF0.00462B70@polarisft.com>
References: <OF77059D3A.6545B4E9-ON65257BF0.0045C758-65257BF0.00462B70@polarisft.com>
Message-ID: <1380028570.45617.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Try:

plot(as.numeric(data$Var1),data$Freq,ylim=c(0,700),col="green",type="o",ylab="",xlab="",las=2,lwd=2.5,xaxt="n")

A.K.



----- Original Message -----
From: "mohan.radhakrishnan at polarisft.com" <mohan.radhakrishnan at polarisft.com>
To: r-help at r-project.org
Cc: 
Sent: Tuesday, September 24, 2013 8:46 AM
Subject: [R] Graph is without line

Hi,
? ? ? ? Sometimes I get a graph like the attached one. The data type could 
have something to do with it. This graph does not use the color and does 
not draw
a line. Earlier I used to convert the factors in the data frame to another 
data type and drew the correct graphs.

Any idea why this happens ?

Thanks,
Mohan

? ? ? ? ? ? Var1 Freq
1? ?  10.1.17.10? 205
2? ?  10.1.17.15? 216
3? ?  10.1.17.17?  79
4? ?  10.1.17.23?  76
5? ?  10.1.17.24? 209
6? ? ? 10.1.17.5? 244
7? ? ? 10.1.17.6? 178
8? ? ? 10.1.17.7? 165
9? ? ? 10.1.17.8? 146



#prints factor
print(class(data$Var1))

plot(data$Var1,data$Freq,ylim=c(0,700),col="green",type="o",ylab="",xlab="",las=2,lwd=2.5,xaxt="n")
title("Estimation of concurrent connections",cex.main=3)
library(plotrix)
staxlab(at=data$Var1,
? labels=as.character(data$Var1),nlines=3,srt=90)


This e-Mail may contain proprietary and confidential information and is sent for the intended recipient(s) only.? If by an addressing or transmission error this mail has been misdirected to you, you are requested to delete this mail immediately. You are also hereby notified that any use, any form of reproduction, dissemination, copying, disclosure, modification, distribution and/or publication of this e-mail message, contents or its attachment other than by its intended recipient/s is strictly prohibited.

Visit us at http://www.polarisFT.com

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From dulcalma at bigpond.com  Tue Sep 24 15:38:04 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Tue, 24 Sep 2013 23:38:04 +1000
Subject: [R] lattice: double y - problem changing axis color
	after	doubleYScale
Message-ID: <000601ceb92b$4d356400$e7a02c00$@bigpond.com>

Hi Anna

Have a look a ylab in my script - you will need to modify the label I was
going from memory on the exact label  argument name . I think it is text  =
"Np" or whatever you want.

The strip arguments are controlled by useOuterStrip see ?useOuterStrip
So you will need to modify as a custom scale there.

There is doubleYScale in latticeExtra as well . I do not know or use the HH
package

As an afterthought you might have a look at ?make.groups for joining
datasets

Duncan

-----Original Message-----
From: Anna Zakrisson Braeunlich [mailto:anna.zakrisson at su.se] 
Sent: Tuesday, 24 September 2013 22:43
To: Duncan Mackay
Subject: RE: [R] lattice: double y - problem changing axis color after
doubleYScale

Thank you!

The code works if one removes:  strip      = strip.custom(factor.levels =
c("B1", "H2", "H3", "H4")),
                                               par.strip.text =
                      list(fontfamily="serif" )),

it was doubled.

It is not quite what I want as I need Nc and Pc in the same plot panel. Just
a simple double y-axis plot factorized by station and year and with week on
the x-axis.

Maybe you know why ylab=() is overridden in the codes you have sent me?
ylab=() is defined as normal, but is not showing up in the plot. Am I
defining something in the useOuterStrips() command that I am not
understanding?

I have solved the doubleYScale colour problem:
doubleYScale(plotNtest, plotPtest, add.ylab=T, style1=0, style2=0) #makes
both axes black.

I have a funktioning plot with doubleYScale provided this is solved:
1. I still have the problem that the strip.left =() outer strip is ON TOP of
my y-axis. Any ideas on how to tweak the position of the strip and/or move
the entire y-axis, but then using doubleYScale (which I know you don't use,
but maybe some other person does)? 
2. I can add ylab=(). It is non-functional at this time.

thank's

with kind regards
Anna Zakrisson

Here is the full code for my doubleYScale plot:
Ndata <- data.frame(
  Ncellpercent = rnorm(400, mean = rep(c(14, 18, 65), each = 40),
                       sd = rep(c(1, 3, 6), each = 40)),
  fyear = rep(c('2007', '2008'), each = 100*2),
  Station = sample(c('B1', 'H2', 'H3', 'H4'), 400, replace = TRUE),
  Week = sample(c('19', '21', '23', '25'), 400, replace = TRUE))

Pdata <- data.frame(
  Ppercentcell = rnorm(400, mean = rep(c(4, 17, 22), each = 40),
                       sd = rep(c(0.1, 0.2, 0.4), each = 40)),
  fyear = rep(c('2007', '2008'), each = 100*2),
  Station = sample(c('B1', 'H2', 'H3', 'H4'), 400, replace = TRUE),
  Week = sample(c('19', '21', '23', '25'), 400, replace = TRUE))

SummNdata <- ddply(Ndata, .(Week, fyear, Station), summarise, 
                   mean = mean(Ncellpercent), 
                   sd = sd(Ncellpercent))
names(Pdata)
SummPdata <- ddply(Pdata, .(Week, fyear, Station), summarise, 
                   mean = mean(Ppercentcell), 
                   sd = sd(Ppercentcell)) SummPdata

plotNtest <- useOuterStrips(strip      = strip.custom(factor.levels =
c("B1", "H2", "H3", "H4"),
  par.strip.text =
    list(fontfamily="serif" )),
               strip.left = strip.custom(factor.levels = c("2007", "2008",
"2009"),
                 par.strip.text =
                   list(fontfamily="serif" )),
               xyplot(mean ~ Week | Station*fyear, data= SummNdata,
                      col="black",
                      pch=1,
                      cex=1.1,
                      lty=1,
                      par.settings = list(strip.background = list(col =
 
"transparent"),
                                          add.text = list(fontfamily =
"serif"
                                          )),
                      strip      = strip.custom(factor.levels = c("B1",
"H2", "H3", "H4"),
                                               par.strip.text =
                      list(fontfamily="serif" )),
               scales = list(alternating = c(3,3),
                             fontfamily = "serif"),
               ylab = list(text = "Nc", fontfamily = "serif"),
               xlab=list(text = "Week", fontfamily = "serif"),
               key  = list(text = list(labels = c("Pc","Nc")),
                           points = list(pch = c(1,2)),
                           lines  = list(lty = c(1,2))),
               type = "o",
               ylim = c(0,70),
               subscripts = TRUE,
               panel = function(x,y, subscripts, ...){
                 panel.xyplot(x,y, ...)
                 # sd
                 # upper
                 panel.arrows(x0 = x, x1 = x,
                              y0 = y, y1 = y+ SummNdata[subscripts,
                                                        "sd"]/2, angle = 90,
length = 0.04)
                 # lower
                 panel.arrows(x0 = x, x1 = x,
                              y0 = y, y1 = y- SummNdata[subscripts,
                                                        "sd"]/2, angle = 90,
length = 0.04)
                 
                 panel.xyplot(x+0.1, SummNdata[subscripts,"mean"],
                              type ="o",pch = 20, lty =1, col = "black")
                 # sd
                 # upper
                 panel.arrows(x0 = x+0.1, x1 = x+0.1,
                              y0 = SummNdata[subscripts,"mean"], y1
                              = SummNdata[subscripts,"mean"] +
SummNdata[subscripts, "sd"]/2, angle = 90,
                              length = 0.04)
                 # lower
                 panel.arrows(x0 = x+0.1, x1 = x+0.1,
                              y0 = SummNdata[subscripts,"mean"], y1
                              = SummNdata[subscripts,"mean"]-
SummNdata[subscripts, "sd"]/2, angle = 90,
                              length = 0.04)
                 
               }# panel
)#
) ## useOuterStrips
plotNtest

plotPtest <- useOuterStrips(strip      = strip.custom(factor.levels =
c("B1", "H2", "H3", "H4"),
                                                 par.strip.text =
                                                   list(fontfamily="serif"
)),
                       strip.left = strip.custom(factor.levels = c("2007",
"2008", "2009"),
                                                 par.strip.text =
                                                   list(fontfamily="serif"
)),
                       xyplot(mean ~ Week | Station*fyear, data= SummPdata,
                              col="black",
                              pch=2,
                              cex=1.1,
                              lty=2,
                              par.settings = list(strip.background =
list(col =
 
"transparent"),
                                                  add.text = list(fontfamily
= "serif"
                                                  )),
                              strip      = strip.custom(factor.levels =
c("B1", "H2", "H3", "H4"),
                                                        par.strip.text =
 
list(fontfamily="serif" )),
                              scales = list(alternating = c(3,3),
                                            fontfamily = "serif"),
                              ylab = list(text = "Pc", fontfamily =
"serif"),
                              xlab=list(text = "Week", fontfamily =
"serif"),
                              type = "o",
                              ylim = c(0,70),
                              subscripts = TRUE,
                              panel = function(x,y, subscripts, ...){
                                panel.xyplot(x,y, ...)
                                # sd
                                # upper
                                panel.arrows(x0 = x, x1 = x,
                                             y0 = y, y1 = y+
SummPdata[subscripts,
 
"sd"]/2, angle = 90, length = 0.04)
                                # lower
                                panel.arrows(x0 = x, x1 = x,
                                             y0 = y, y1 = y-
SummPdata[subscripts,
 
"sd"]/2, angle = 90, length = 0.04)
                                
                                panel.xyplot(x+0.1,
SummPdata[subscripts,"mean"],
                                             type ="o",pch = 20, lty =1, col
= "black")
                                # sd
                                # upper
                                panel.arrows(x0 = x+0.1, x1 = x+0.1,
                                             y0 =
SummPdata[subscripts,"mean"], y1
                                             = SummPdata[subscripts,"mean"]
+ SummPdata[subscripts, "sd"]/2, angle = 90,
                                             length = 0.04)
                                # lower
                                panel.arrows(x0 = x+0.1, x1 = x+0.1,
                                             y0 =
SummPdata[subscripts,"mean"], y1
                                             = SummPdata[subscripts,"mean"]-
SummPdata[subscripts, "sd"]/2, angle = 90,
                                             length = 0.04)
                                
                              }# panel
                       )#
) ## useOuterStrips

?doubleYScale
plotNtest
plotPtest
doubleYScale(plotNtest, plotPtest, add.ylab=T, style1=0, style2=0)


Anna Zakrisson Braeunlich
PhD student

Department of Ecology, Environment and Plant Sciences Stockholm University
Svante Arrheniusv. 21A
SE-106 91 Stockholm
Sweden/Sverige

Lives in Berlin.
For paper mail:
Katzbachstr. 21
D-10965, Berlin - Kreuzberg
Germany/Deutschland

E-mail: anna.zakrisson at su.se
Tel work: +49-(0)3091541281
Mobile: +49-(0)15777374888
LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b

><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? 
>`?. .? `?. .><((((?>

________________________________________
From: Duncan Mackay [dulcalma at bigpond.com]
Sent: 24 September 2013 11:32
To: Anna Zakrisson Braeunlich
Cc: R
Subject: RE: [R] lattice: double y - problem changing axis color after
doubleYScale

Hi Anna

I have never used doubleYScale and I am not sure what you want but try this

You need to do this first if columns not correct saves doing later - I
forgot to mention it for Week but as you have given the order for the
factors do it as well

SummPdata[,1] <- as.numeric(SummPdata[,1]) SummNdata[,1] <-
as.numeric(SummNdata[,1]) SummPdata[,3] <- factor(SummPdata[,3], levels =
c('B1', 'H2', 'H3', 'H4')) SummNdata[,3] <- factor(SummNdata[,3], levels =
c('B1', 'H2', 'H3', 'H4'))

As the data has a similar structure combine data

summData = rbind(SummPdata, SummNdata)
summData$element <- rep(c("P","N"), each = 32)

Just quickly cut and pasted the colours etc

useOuterStrips(strip      = strip.custom(#factor.levels = ,
                                         par.strip.text =
list(fontfamily="serif" )),
               strip.left = strip.custom(#factor.levels = ,
                                         par.strip.text =
list(fontfamily="serif" )),
               xyplot(mean ~ Week | Station*interaction(element,fyear),
data= summData,
                cex=1.1,
                par.settings = list(strip.background = list(col =
"transparent"),
                                    add.text = list(fontfamily = "serif")),
                #strip      = strip.custom(#factor.levels = ,
                #                         par.strip.text =
list(fontfamily="serif" )),
               scales = list(alternating = c(3,3),
                              fontfamily = "serif"),
                ylab = list(text = "Pc", fontfamily = "serif"),
                xlab=list(text = "Week", fontfamily = "serif"),
                key  = list(text = list(labels = c("P","N")),
                            points = list(pch = c(2,20), col =
c("red","blue")),
                            lines  = list(lty = c(1,2)), col =
c("red","blue")),
                type = "o",
                ylim = c(0,70),
                subscripts = TRUE,
                panel = function(x,y, subscripts, ...){

                          pnl = panel.number()

                          panel.xyplot(x,y, type = "o", col =
c("red","blue")[ifelse(pnl <9, 1,2)], lty = c(1,2)[ifelse(pnl <9, 1,2)], pch
= c(2,20)[ifelse(pnl <9, 1,2)])
                          # sd
                          # upper
                          panel.arrows(x0 = x, x1 = x,
                                       y0 = y, y1 = y+ summData[subscripts,
"sd"]/2, angle = 90, length = 0.04, col = c("red","blue")[ifelse(pnl <9,
1,2)])
                          # lower
                          panel.arrows(x0 = x, x1 = x,
                                       y0 = y, y1 = y- summData[subscripts,
"sd"]/2, angle = 90, length = 0.04, col = c("red","blue")[ifelse(pnl <9,
1,2)])

                        }# panel
                )#
) ## useOuterStrips

You can fill in the LHS strip with a vector of names as required

If you want to amend the ylimits  see ?combineLimits  in the latticeExtra
package

Duncan


-----Original Message-----
From: Anna Zakrisson Braeunlich [mailto:anna.zakrisson at su.se]
Sent: Tuesday, 24 September 2013 18:28
To: Duncan Mackay
Subject: RE: [R] lattice: double y - problem changing axis color after
doubleYScale

OK, now the code works - thank you. The error bars are added beautifully!

As I am using doubleYScale, I am having the problem that the first y-axis is
covered by the left hand strip - how can I solve this? I really much prefer
using outer.strip() and have one strip vertically on the plot. It saves plot
space.

I am still having the problem of colourful y-axis when using doubleYScale()
- how can I make them black?
I have the same problem with the error bars - they are also default colour
no matter what I tell them to be.
Is there a way around this except Adobe Photoshop?

Here is the working script with dummy data (you can just run the lot if you
have time). I really appreciate your code - thanks! ...and sorry for being a
bit daft and sending a reply before thinking it through properly.

Ndata <- data.frame(
  Ncellpercent = rnorm(400, mean = rep(c(14, 18, 65), each = 40),
                       sd = rep(c(1, 3, 6), each = 40)),
  fyear = rep(c('2007', '2008'), each = 100*2),
  Station = sample(c('B1', 'H2', 'H3', 'H4'), 400, replace = TRUE),
  Week = sample(c('19', '21', '23', '25'), 400, replace = TRUE))

Pdata <- data.frame(
  Ppercentcell = rnorm(400, mean = rep(c(4, 17, 22), each = 40),
                       sd = rep(c(0.1, 0.2, 0.4), each = 40)),
  fyear = rep(c('2007', '2008'), each = 100*2),
  Station = sample(c('B1', 'H2', 'H3', 'H4'), 400, replace = TRUE),
  Week = sample(c('19', '21', '23', '25'), 400, replace = TRUE))

SummNdata <- ddply(Ndata, .(Week, fyear, Station), summarise,
                   mean = mean(Ncellpercent),
                   sd = sd(Ncellpercent))
names(Pdata)
SummPdata <- ddply(Pdata, .(Week, fyear, Station), summarise,
                   mean = mean(Ppercentcell),
                   sd = sd(Ppercentcell)) SummPdata

plotNtest <- useOuterStrips(strip      = strip.custom(factor.levels =
c("B1", "H2", "H3", "H4"),
  par.strip.text =
    list(fontfamily="serif" )),
               strip.left = strip.custom(factor.levels = c("2007", "2008",
"2009"),
                 par.strip.text =
                   list(fontfamily="serif" )),
               xyplot(mean ~ Week | Station*fyear, data= SummNdata,
                      col="black",
                      pch=1,
                      cex=1.1,
                      lty=1,
                      par.settings = list(strip.background = list(col =

"transparent"),
                                          add.text = list(fontfamily =
"serif"
                                          )),
                      strip      = strip.custom(factor.levels = c("B1",
"H2", "H3", "H4"),
                                               par.strip.text =
                      list(fontfamily="serif" )),
               scales = list(alternating = c(3,3),
                             fontfamily = "serif"),
               ylab = list(text = "Nc", fontfamily = "serif"),
               xlab=list(text = "Week", fontfamily = "serif"),
               key  = list(text = list(labels = c("Pc","Nc")),
                           points = list(pch = c(1,2)),
                           lines  = list(lty = c(1,2))),
               type = "o",
               ylim = c(0,70),
               subscripts = TRUE,
               panel = function(x,y, subscripts, ...){
                 panel.xyplot(x,y, ...)
                 # sd
                 # upper
                 panel.arrows(x0 = x, x1 = x,
                              y0 = y, y1 = y+ SummNdata[subscripts,
                                                        "sd"]/2, angle = 90,
length = 0.04)
                 # lower
                 panel.arrows(x0 = x, x1 = x,
                              y0 = y, y1 = y- SummNdata[subscripts,
                                                        "sd"]/2, angle = 90,
length = 0.04)

                 panel.xyplot(x+0.1, SummNdata[subscripts,"mean"],
                              type ="o",pch = 20, lty =1, col = "black")
                 # sd
                 # upper
                 panel.arrows(x0 = x+0.1, x1 = x+0.1,
                              y0 = SummNdata[subscripts,"mean"], y1
                              = SummNdata[subscripts,"mean"] +
SummNdata[subscripts, "sd"]/2, angle = 90,
                              length = 0.04)
                 # lower
                 panel.arrows(x0 = x+0.1, x1 = x+0.1,
                              y0 = SummNdata[subscripts,"mean"], y1
                              = SummNdata[subscripts,"mean"]-
SummNdata[subscripts, "sd"]/2, angle = 90,
                              length = 0.04)

               }# panel
)#
) ## useOuterStrips

plotPtest <- useOuterStrips(strip      = strip.custom(factor.levels =
c("B1", "H2", "H3", "H4"),
                                                 par.strip.text =
                                                   list(fontfamily="serif"
)),
                       strip.left = strip.custom(factor.levels = c("2007",
"2008", "2009"),
                                                 par.strip.text =
                                                   list(fontfamily="serif"
)),
                       xyplot(mean ~ Week | Station*fyear, data= SummPdata,
                              col="black",
                              pch=2,
                              cex=1.1,
                              lty=2,
                              par.settings = list(strip.background =
list(col =

"transparent"),
                                                  add.text = list(fontfamily
= "serif"
                                                  )),
                              strip      = strip.custom(factor.levels =
c("B1", "H2", "H3", "H4"),
                                                        par.strip.text =

list(fontfamily="serif" )),
                              scales = list(alternating = c(3,3),
                                            fontfamily = "serif"),
                              ylab = list(text = "Pc", fontfamily =
"serif"),
                              xlab=list(text = "Week", fontfamily =
"serif"),
                              type = "o",
                              ylim = c(0,70),
                              subscripts = TRUE,
                              panel = function(x,y, subscripts, ...){
                                panel.xyplot(x,y, ...)
                                # sd
                                # upper
                                panel.arrows(x0 = x, x1 = x,
                                             y0 = y, y1 = y+
SummPdata[subscripts,

"sd"]/2, angle = 90, length = 0.04)
                                # lower
                                panel.arrows(x0 = x, x1 = x,
                                             y0 = y, y1 = y-
SummPdata[subscripts,

"sd"]/2, angle = 90, length = 0.04)

                                panel.xyplot(x+0.1,
SummPdata[subscripts,"mean"],
                                             type ="o",pch = 20, lty =1, col
= "black")
                                # sd
                                # upper
                                panel.arrows(x0 = x+0.1, x1 = x+0.1,
                                             y0 =
SummPdata[subscripts,"mean"], y1
                                             = SummPdata[subscripts,"mean"]
+ SummPdata[subscripts, "sd"]/2, angle = 90,
                                             length = 0.04)
                                # lower
                                panel.arrows(x0 = x+0.1, x1 = x+0.1,
                                             y0 =
SummPdata[subscripts,"mean"], y1
                                             = SummPdata[subscripts,"mean"]-
SummPdata[subscripts, "sd"]/2, angle = 90,
                                             length = 0.04)

                              }# panel
                       )#
) ## useOuterStrips


plotNtest
plotPtest
doubleYScale(plotNtest, plotPtest, add.ylab2 = TRUE)

Can I make the
Anna Zakrisson Braeunlich
PhD student

Department of Ecology, Environment and Plant Sciences Stockholm University
Svante Arrheniusv. 21A
SE-106 91 Stockholm
Sweden/Sverige

Lives in Berlin.
For paper mail:
Katzbachstr. 21
D-10965, Berlin - Kreuzberg
Germany/Deutschland

E-mail: anna.zakrisson at su.se
Tel work: +49-(0)3091541281
Mobile: +49-(0)15777374888
LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b

><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? 
>`?. .? `?. .><((((?>

________________________________________
From: Duncan Mackay [dulcalma at bigpond.com]
Sent: 22 September 2013 05:00
To: Anna Zakrisson Braeunlich
Cc: R
Subject: RE: [R] lattice: double y - problem changing axis color after
doubleYScale

Hi  Anna

I am not sure what you want but the following should get you part of the way

I prefer to keep all my parameters within the function rather than use
themes.

useOuterStrips(strip      = strip.custom(#factor.levels = ,
                                         par.strip.text =
list(fontfamily="serif" )),
               strip.left = strip.custom(#factor.levels = ,
                                         par.strip.text =
list(fontfamily="serif" )), xyplot(mean ~ Week | Station*fyear, data=
SummPdata,
                col="black",
                pch=2,
                cex=1.1,
                lty=2,
                par.settings = list(strip.background = list(col =
"transparent"),
                                    add.text = list(fontfamily = "serif"
)),
                #strip      = strip.custom(#factor.levels = ,
                #                         par.strip.text =
list(fontfamily="serif" )),
               scales = list(alternating = c(3,3),
                              fontfamily = "serif"),
                ylab = list(text = "Pc", fontfamily = "serif"),
                xlab=list(text = "Week", fontfamily = "serif"),
                key  = list(text = list(labels = c("P","N")),
                            points = list(pch = c(2,20)),
                            lines  = list(lty = c(1,2))),
                type = "o",
                ylim = c(0,70),
                subscripts = TRUE,
                panel = function(x,y, subscripts, ...){
                          panel.xyplot(x,y, ...)
                          # sd
                          # upper
                          panel.arrows(x0 = x, x1 = x,
                                       y0 = y, y1 = y+ SummPdata[subscripts,
"sd"]/2, angle = 90, length = 0.04)
                          # lower
                          panel.arrows(x0 = x, x1 = x,
                                       y0 = y, y1 = y- SummPdata[subscripts,
"sd"]/2, angle = 90, length = 0.04)

                          panel.xyplot(x+0.1, SummNdata[subscripts,"mean"],
type ="o",pch = 20, lty =1, col = "black")
                          # sd
                          # upper
                          panel.arrows(x0 = x+0.1, x1 = x+0.1,
                                      y0 = SummNdata[subscripts,"mean"], y1
= SummNdata[subscripts,"mean"] + SummNdata[subscripts, "sd"]/2, angle = 90,
length = 0.04)
                          # lower
                          panel.arrows(x0 = x+0.1, x1 = x+0.1,
                                       y0 = SummNdata[subscripts,"mean"], y1
= SummNdata[subscripts,"mean"]- SummNdata[subscripts, "sd"]/2, angle = 90,
length = 0.04)

                        }# panel
                )#
) ## useOuterStrips

Note that I offset the N data so that the error bars are more legible

For sd I just divided them by 2 so you will have to work out what you
require

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Anna Zakrisson Braeunlich
Sent: Thursday, 19 September 2013 20:21
To: r-help at r-project.org
Subject: [R] lattice: double y - problem changing axis color after
doubleYScale

Hi,

I have had some troubles using doubleYScale. No matter what I try, I cant
manage to change the color of the y-axis in the end. I have to produce a
black and white plot. There is also something I do not understand regarding
fontfamilyj="serif" when using it in:
strip=strip.custom()

Maybe someone has a better idea for defining which line and dots belong to
which y-axis when not using a colorcode than the one I had.

I have annotated my questions in the code below.

Thank you for your time!


Here is some dummy data:

Ndata <- data.frame(
  Ncellpercent = rnorm(400, mean = rep(c(14, 18, 65), each = 40),
               sd = rep(c(1, 3, 6), each = 40)),
  fyear = rep(c('2007', '2008'), each = 100*2),
  Station = sample(c('B1', 'H2', 'H3', 'H4'), 400, replace = TRUE),
  Week = sample(c('19', '21', '23', '25'), 400, replace = TRUE))

Pdata <- data.frame(
  Ppercentcell = rnorm(400, mean = rep(c(4, 17, 22), each = 40),
               sd = rep(c(0.1, 0.2, 0.4), each = 40)),
  fyear = rep(c('2007', '2008'), each = 100*2),
  Station = sample(c('B1', 'H2', 'H3', 'H4'), 400, replace = TRUE),
  Week = sample(c('19', '21', '23', '25'), 400, replace = TRUE))

SummNdata <- ddply(Ndata, .(Week, fyear, Station), summarise,
                   mean = mean(Ncellpercent),
                   sd = sd(Ncellpercent))
names(Pdata)
SummPdata <- ddply(Pdata, .(Week, fyear, Station), summarise,
                   mean = mean(Ppercentcell),
                   sd = sd(Ppercentcell))
library(lattice)
library(latticeExtra)
library(HH)

font.settings <- list( font = 1, cex = 1.2, fontfamily = "serif")

my.theme <- list(
  par.xlab.text = font.settings,
  par.ylab.text = font.settings,
  axis.text = font.settings,
  par.sub=font.settings)

plotN <- xyplot(mean ~ Week | Station*fyear,
                col="black",
                pch=1,
                cex=1.1,
                lty=1,
                strip = strip.custom(bg = 'white', style=1), # why can I not
use fontfamily="serif" here ???
                key=list(text=list(c(""),
                                   col=c("black")),
                         points=list(pch=1, lty=1, cex=1.5,
                                     col=c("black")),
                         columns=1, border=F,
                         x = 0.02, y = 0.55, corner = c(2, 2),
                         title="", cex.title=1.3),
                ylab = ("Nc"),
                xlab="Week",
                data= SummNdata,type="o",
                par.settings = my.theme) plotN # I would like to add the
standard deviations (sd) to the plot. I have tried some stuff, # but for
some reason, it does not seem to work. How would I go about this?


plotP <- xyplot(mean ~ Week | Station*fyear,
                col="black",
                pch=2,
                cex=1.1,
                lty=2,
                strip = strip.custom(bg = 'white', style=1), # why can I not
use fontfamily="serif" here ???
                key=list(text=list(c(""),
                                   col=c("black")),
                         points=list(pch=1, lty=1, cex=1.5,
                                     col=c("black")),
                         columns=1, border=F,
                         x = 0.2, y = 0.2, corner = c(2, 2),
                         title="", cex.title=1.3),
                ylab = ("Pc"),
                xlab="Week",
                data= SummPdata,type="o",
                par.settings = my.theme) plotP

doubleYScale(plotN, plotP, add.ylab2 = TRUE)  #Why can I not change the axis
color by adding to this argument?

# I want the y1 and y2 axes to be defined not by color, but by shape and
linetype.
# I have managed to draw the shapes (defined by Nc and Pc) by the y1 and y2
axes, but I do not manage to get the lines # though the shape - ideas?
# Alternative ways that are not based on color (I have to do this black and
white).
# Is there possible to add shapes to the axis text? such as:
# --O-- Nc  on the left y-axis (but with lty=1: I could not do a non-dotted
line on the keybord).

with kind regards

Anna Zakrisson Braeunlich
PhD student

Department of Ecology, Environment and Plant Sciences Stockholm University
Svante Arrheniusv. 21A
SE-106 91 Stockholm
Sweden/Sverige

Lives in Berlin.
For paper mail:
Katzbachstr. 21
D-10965, Berlin - Kreuzberg
Germany/Deutschland

E-mail: anna.zakrisson at su.se
Tel work: +49-(0)3091541281
Mobile: +49-(0)15777374888
LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b

><((((:>`?. . ? `?. .? `?. . ><((((:>`?. . ? `?. .? `?. .><((((:>`?. . ?
>`?. .? `?. .><((((:>

        [[alternative HTML version deleted]]


From zhyjiang2006 at hotmail.com  Tue Sep 24 16:07:33 2013
From: zhyjiang2006 at hotmail.com (JiangZhengyu)
Date: Tue, 24 Sep 2013 22:07:33 +0800
Subject: [R] Help: calculations based on three matrices
In-Reply-To: <SNT147-W39065DC2A2F3ECEB085110CB2D0@phx.gbl>
References: <SNT135-W683AAD0CA6F447A95A0D1CBF60@phx.gbl>,
	<SNT135-W7024C9C8CA4FC36286571CBF70@phx.gbl>,
	<SNT147-W39065DC2A2F3ECEB085110CB2D0@phx.gbl>
Message-ID: <SNT147-W58D3AAE2A08474025EEADACB2E0@phx.gbl>


 






Dear R experts,
 
I have 3 matrices - "Mx", "My" and "geno" that have the same exact dimensions (attached).  I want to calculate a expression matrix (ME) of the same dimension as well. It is a little complicated.
 
To calculate and for a specific cell in ME,  e.g. ME[2,2],
 
 if value of geno[2,2] is 0, ME[2,2]=Mx[2,2]+My[2,2];
 if value of geno[2,2] is 1, ME[2,2]=the larger number of Mx[2,2] and My[2,2]
 if value of geno[2,2] is NA, ME[2,2]=NA
 
I tried to make codes below, but did not work and got stuck. I was wondering if anyone could help with better coding.
 
Thanks in advance,
Zhengyu
 
-----------------------------------------------   
 
Mx <-  read.table("Mx.txt",header=TRUE, sep="\t", na.strings="NA", dec=".", strip.white=TRUE)
My <-  read.table("My.txt",header=TRUE, sep="\t", na.strings="NA", dec=".", strip.white=TRUE)
geno <-  read.table("geno.txt",header=TRUE, sep="\t", na.strings="NA", dec=".", strip.white=TRUE)
 
#Calculate Exp for geno==0
ind=which(geno==0,arr.ind=T)
het=Mx+My
ME=matrix(het,nrow=nrow(geno),ncol=ncol(geno))
ME[ind]=het[ind]
 
#Calculate Exp for geno==1
ind=which(geno==1,arr.ind=T)
hom=apply(M1,c(1:2),function(x)max(M1[],M2[]))# error
ME=matrix(hom,nrow=nrow(geno),ncol=ncol(geno))
ME[ind]=hom[ind]
 
# I think the first calculation (geno==0) will be replaced but I don't know how to keep them.
 
> head(Mx)
   X1cX X2cX  X3cX  X4cX X5cX X6cX X7cX X8cX
1 26383 6252 14319 16421 2225  480 2038 1164
2   636  310   351   341  218  656  412  267
3   301  299   752   236  239  309  283  195
4  1016 1046  1364   782  822  274  437  346
5  1261 1272  1076  1037  659  337 1143 1195
6   609  414   393   459  215  429  566  236

> dim(Mx)
[1] 20  8

> head(My)
   X1cY X2cY X3cY X4cY X5cY X6cY X7cY X8cY
1  1039  233  408  607  275 1837 1319  149
2  7146 1706 2248 2346 1596  544 2696  417
3   266  425 1186  214  325  369  377  215
4   260  282  238  240  264  265  317  203
5  1070 1052  746  613  384  447  456  683
6 13032 1708 2328 5998 2529  923 1068  145

> dim(My)
[1] 20  8

> head(geno)
  P1 P2 P3 P4 P5 P6 P7 P8
1 NA NA NA NA  1 NA NA NA
2  1  1  1  1  1  1  1  1
3  1  1  0  0  0  0  1  0
4  1  1  1  1  1  1  0  0
5  0  0  0  0  0  0  1  0
6 NA NA NA NA NA NA NA NA

> dim(geno)
[1] 20  8



 		 	   		   		 	   		  
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Mx.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130924/ea519894/attachment.txt>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: My.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130924/ea519894/attachment-0001.txt>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: geno.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130924/ea519894/attachment-0002.txt>

From gergely at snowl.net  Tue Sep 24 16:12:51 2013
From: gergely at snowl.net (=?ISO-8859-1?Q?Gergely_Dar=F3czi?=)
Date: Tue, 24 Sep 2013 16:12:51 +0200
Subject: [R] Hungarian R User's Group: Exploratory and interactive data
 analysis talks on Wednesday
Message-ID: <CAPvvxJW1bV2sG0Kx=_un-pe2K2Gkmg2B3Tua0BOjtpP+VyRFfA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130924/cc253330/attachment.pl>

From gunter.berton at gene.com  Tue Sep 24 16:15:16 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 24 Sep 2013 07:15:16 -0700
Subject: [R] no answer to the following question
In-Reply-To: <000301ceb8fd$27356350$75a029f0$@fr>
References: <000301ceb8fd$27356350$75a029f0$@fr>
Message-ID: <CACk-te25eDPNL93u9P4LQZneT3Ps0_sZv-ZyxR1-54rB28mK-g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130924/0fbf4d6f/attachment.pl>

From smartpink111 at yahoo.com  Tue Sep 24 16:34:42 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 24 Sep 2013 07:34:42 -0700 (PDT)
Subject: [R] Matrix operation
In-Reply-To: <BLU170-W2320199220C3B08FBE5D2E892E0@phx.gbl>
References: <BLU170-W2320199220C3B08FBE5D2E892E0@phx.gbl>
Message-ID: <1380033282.35790.YahooMailNeo@web142604.mail.bf1.yahoo.com>



Hi,
Try:

set.seed(49)
qcd<- matrix(sample(1:20,124*69,replace=TRUE),ncol=69)

set.seed(345)
listt<- matrix(sample(1:80,124*5,replace=TRUE),ncol=5)
lst1<-list(c(15,2),c(56,54),c(15,62),c(4,14))
?names(lst1)<- 2:5
S<- do.call(cbind,lapply(names(lst1),function(i) {ww<-listt[,as.numeric(i),drop=FALSE];indx<-lst1[[i]]; YY<- cbind(qcd[,indx[1]],qcd[,indx[2]]);M<- lm(ww~qcd[,indx[1]]+qcd[,indx[2]]); A1<- M$coef[2]; B1<- M$coef[3]; unlist(lapply(seq_len(nrow(YY)),function(i){Y<- YY[i,];A<- A1*Y[1]; B<- B1*Y[2]; Alp<- A+B} ),use.names=FALSE) }))
colnames(S)<- paste0("Alp",1:4)
?dim(S)
#[1] 124?? 4

#or just

S1<-do.call(cbind,lapply(names(lst1),function(i) {ww<-listt[,as.numeric(i),drop=FALSE];indx<-lst1[[i]]; YY<- cbind(qcd[,indx[1]],qcd[,indx[2]]);M<- lm(ww~qcd[,indx[1]]+qcd[,indx[2]]); A1<- M$coef[2]; B1<- M$coef[3]; A<- A1* YY[,1]; B<- B1*YY[,2] ; A+B}))
?colnames(S1)<- colnames(S)
?identical(S1,S)
#[1] TRUE




A.K.
________________________________
From: eliza botto <eliza_botto at hotmail.com>
To: "smartpink111 at yahoo.com" <smartpink111 at yahoo.com> 
Sent: Tuesday, September 24, 2013 8:04 AM
Subject: 




Dear Arun,
I have the following codes to perform a certain operation

where "listt" is a matrix of dimension 124 ROW ?and 5 COLUMN. "qcd" has 124 rows and 69 columns. YY?has 12 rows and 2 columns.?
What i want to do is to make a loop so that R automatically replaces "15" in Y<-YY[15,] with the numbers from 1 to 124, every where.?
So "Alp1","Alp2","Alp3" and?"Alp4" should each be of 124 rows and 1 column. similarly "S",in the end,should be of dimension 124*4.
How can i do that?
I hope i am clear but if there is anything that is needed to be cleared about question please do let me know.

ww<-matrix(listt[,2],ncol=1)
?YY<-cbind(qcd[,15],qcd[,2])
?Y<-YY[15,]
?M<-lm(ww~qcd[,15]+qcd[,2])
?A<-M$coefficients[2]*Y[1]
?B<-M$coefficients[3]*Y[2]
?Alp1<-A+B
?Alp1

?ww<-matrix(listt[,3],ncol=1)
?YY<-cbind(qcd[,56],qcd[,54])
?Y<-YY[15,]
?M<-lm(ww~qcd[,56]+qcd[,54])
?A<-M$coefficients[2]*Y[1]
?B<-M$coefficients[3]*Y[2]
?Alp2<-A+B
?Alp2

ww<-matrix(listt[,4],ncol=1)
?YY<-cbind(qcd[,15],qcd[,62])
?Y<-YY[15,]
?M<-lm(ww~qcd[,7]+qcd[,62])
?A<-M$coefficients[2]*Y[1]
?B<-M$coefficients[3]*Y[2]
?Alp3<-A+B
Alp3

ww<-matrix(listt[,5],ncol=1)
?YY<-cbind(qcd[,4],qcd[,14])
?Y<-YY[15,]
?M<-lm(ww~qcd[,4]+qcd[,14])
?A<-M$coefficients[2]*Y[1]
?B<-M$coefficients[3]*Y[2]
?Alp4<-A+B
Alp4

S<-cbind(Alp1,Alp2,Alp3,Alp4)

Thanks indeed in advance

Eliza?????


From smartpink111 at yahoo.com  Tue Sep 24 16:51:38 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 24 Sep 2013 07:51:38 -0700 (PDT)
Subject: [R] Help: calculations based on three matrices
In-Reply-To: <SNT147-W58D3AAE2A08474025EEADACB2E0@phx.gbl>
References: <SNT135-W683AAD0CA6F447A95A0D1CBF60@phx.gbl>,
	<SNT135-W7024C9C8CA4FC36286571CBF70@phx.gbl>,
	<SNT147-W39065DC2A2F3ECEB085110CB2D0@phx.gbl>
	<SNT147-W58D3AAE2A08474025EEADACB2E0@phx.gbl>
Message-ID: <1380034298.18710.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
Try:
ME<- matrix(NA,dim(geno[1]),dim(geno)[2])
indx0<- geno==0 & !is.na(geno)
ME[indx0]<- Mx[indx0]+My[indx0]
?indx1<- geno==1 & !is.na(geno)
ME[indx1]<- apply(cbind(Mx[indx1],My[indx1]),1,max)

ME
A.K.




----- Original Message -----
From: JiangZhengyu <zhyjiang2006 at hotmail.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Tuesday, September 24, 2013 10:07 AM
Subject: [R] Help: calculations based on three matrices









Dear R experts,

I have 3 matrices - "Mx", "My" and "geno" that have the same exact dimensions (attached).? I want to calculate a expression matrix (ME) of the same dimension as well. It is a little complicated.

To calculate and for a specific cell in ME,? e.g. ME[2,2],

if value of geno[2,2] is 0, ME[2,2]=Mx[2,2]+My[2,2];
if value of geno[2,2] is 1, ME[2,2]=the larger number of Mx[2,2] and My[2,2]
if value of geno[2,2] is NA, ME[2,2]=NA

I tried to make codes below, but did not work and got stuck. I was wondering if anyone could help with better coding.

Thanks in advance,
Zhengyu

-----------------------------------------------? 

Mx <-? read.table("Mx.txt",header=TRUE, sep="\t", na.strings="NA", dec=".", strip.white=TRUE)
My <-? read.table("My.txt",header=TRUE, sep="\t", na.strings="NA", dec=".", strip.white=TRUE)
geno <-? read.table("geno.txt",header=TRUE, sep="\t", na.strings="NA", dec=".", strip.white=TRUE)

#Calculate Exp for geno==0
ind=which(geno==0,arr.ind=T)
het=Mx+My
ME=matrix(het,nrow=nrow(geno),ncol=ncol(geno))
ME[ind]=het[ind]

#Calculate Exp for geno==1
ind=which(geno==1,arr.ind=T)
hom=apply(M1,c(1:2),function(x)max(M1[],M2[]))# error
ME=matrix(hom,nrow=nrow(geno),ncol=ncol(geno))
ME[ind]=hom[ind]

# I think the first calculation (geno==0) will be replaced but I don't know how to keep them.

> head(Mx)
?  X1cX X2cX? X3cX? X4cX X5cX X6cX X7cX X8cX
1 26383 6252 14319 16421 2225? 480 2038 1164
2?  636? 310?  351?  341? 218? 656? 412? 267
3?  301? 299?  752?  236? 239? 309? 283? 195
4? 1016 1046? 1364?  782? 822? 274? 437? 346
5? 1261 1272? 1076? 1037? 659? 337 1143 1195
6?  609? 414?  393?  459? 215? 429? 566? 236

> dim(Mx)
[1] 20? 8

> head(My)
?  X1cY X2cY X3cY X4cY X5cY X6cY X7cY X8cY
1? 1039? 233? 408? 607? 275 1837 1319? 149
2? 7146 1706 2248 2346 1596? 544 2696? 417
3?  266? 425 1186? 214? 325? 369? 377? 215
4?  260? 282? 238? 240? 264? 265? 317? 203
5? 1070 1052? 746? 613? 384? 447? 456? 683
6 13032 1708 2328 5998 2529? 923 1068? 145

> dim(My)
[1] 20? 8

> head(geno)
? P1 P2 P3 P4 P5 P6 P7 P8
1 NA NA NA NA? 1 NA NA NA
2? 1? 1? 1? 1? 1? 1? 1? 1
3? 1? 1? 0? 0? 0? 0? 1? 0
4? 1? 1? 1? 1? 1? 1? 0? 0
5? 0? 0? 0? 0? 0? 0? 1? 0
6 NA NA NA NA NA NA NA NA

> dim(geno)
[1] 20? 8



??? ???  ??? ?  ??? ??? ?  ??? ???  ??? ?  ??? ??? ? 
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From bhh at xs4all.nl  Tue Sep 24 17:15:31 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Tue, 24 Sep 2013 17:15:31 +0200
Subject: [R] Help: calculations based on three matrices
In-Reply-To: <1380034298.18710.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <SNT135-W683AAD0CA6F447A95A0D1CBF60@phx.gbl>,
	<SNT135-W7024C9C8CA4FC36286571CBF70@phx.gbl>,
	<SNT147-W39065DC2A2F3ECEB085110CB2D0@phx.gbl>
	<SNT147-W58D3AAE2A08474025EEADACB2E0@phx.gbl>
	<1380034298.18710.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <9EB89529-5888-418F-B489-1F818D8FDA4F@xs4all.nl>


On 24-09-2013, at 16:51, arun <smartpink111 at yahoo.com> wrote:

> Hi,
> Try:
> ME<- matrix(NA,dim(geno[1]),dim(geno)[2])
> indx0<- geno==0 & !is.na(geno)
> ME[indx0]<- Mx[indx0]+My[indx0]
>  indx1<- geno==1 & !is.na(geno)
> ME[indx1]<- apply(cbind(Mx[indx1],My[indx1]),1,max)
> 
I would do this to avoid the apply

ME[indx1]<- pmax(Mx[indx1],My[indx1]) 

Berend

> ME
> A.K.
> 
> 
> 
> 
> ----- Original Message -----
> From: JiangZhengyu <zhyjiang2006 at hotmail.com>
> To: "r-help at r-project.org" <r-help at r-project.org>
> Cc: 
> Sent: Tuesday, September 24, 2013 10:07 AM
> Subject: [R] Help: calculations based on three matrices
> 
> 
> 
> 
> 
> 
> 
> 
> 
> Dear R experts,
> 
> I have 3 matrices - "Mx", "My" and "geno" that have the same exact dimensions (attached).  I want to calculate a expression matrix (ME) of the same dimension as well. It is a little complicated.
> 
> To calculate and for a specific cell in ME,  e.g. ME[2,2],
> 
> if value of geno[2,2] is 0, ME[2,2]=Mx[2,2]+My[2,2];
> if value of geno[2,2] is 1, ME[2,2]=the larger number of Mx[2,2] and My[2,2]
> if value of geno[2,2] is NA, ME[2,2]=NA
> 
> I tried to make codes below, but did not work and got stuck. I was wondering if anyone could help with better coding.
> 
> Thanks in advance,
> Zhengyu
> 
> -----------------------------------------------  
> 
> Mx <-  read.table("Mx.txt",header=TRUE, sep="\t", na.strings="NA", dec=".", strip.white=TRUE)
> My <-  read.table("My.txt",header=TRUE, sep="\t", na.strings="NA", dec=".", strip.white=TRUE)
> geno <-  read.table("geno.txt",header=TRUE, sep="\t", na.strings="NA", dec=".", strip.white=TRUE)
> 
> #Calculate Exp for geno==0
> ind=which(geno==0,arr.ind=T)
> het=Mx+My
> ME=matrix(het,nrow=nrow(geno),ncol=ncol(geno))
> ME[ind]=het[ind]
> 
> #Calculate Exp for geno==1
> ind=which(geno==1,arr.ind=T)
> hom=apply(M1,c(1:2),function(x)max(M1[],M2[]))# error
> ME=matrix(hom,nrow=nrow(geno),ncol=ncol(geno))
> ME[ind]=hom[ind]
> 
> # I think the first calculation (geno==0) will be replaced but I don't know how to keep them.
> 
>> head(Mx)
>    X1cX X2cX  X3cX  X4cX X5cX X6cX X7cX X8cX
> 1 26383 6252 14319 16421 2225  480 2038 1164
> 2   636  310   351   341  218  656  412  267
> 3   301  299   752   236  239  309  283  195
> 4  1016 1046  1364   782  822  274  437  346
> 5  1261 1272  1076  1037  659  337 1143 1195
> 6   609  414   393   459  215  429  566  236
> 
>> dim(Mx)
> [1] 20  8
> 
>> head(My)
>    X1cY X2cY X3cY X4cY X5cY X6cY X7cY X8cY
> 1  1039  233  408  607  275 1837 1319  149
> 2  7146 1706 2248 2346 1596  544 2696  417
> 3   266  425 1186  214  325  369  377  215
> 4   260  282  238  240  264  265  317  203
> 5  1070 1052  746  613  384  447  456  683
> 6 13032 1708 2328 5998 2529  923 1068  145
> 
>> dim(My)
> [1] 20  8
> 
>> head(geno)
>   P1 P2 P3 P4 P5 P6 P7 P8
> 1 NA NA NA NA  1 NA NA NA
> 2  1  1  1  1  1  1  1  1
> 3  1  1  0  0  0  0  1  0
> 4  1  1  1  1  1  1  0  0
> 5  0  0  0  0  0  0  1  0
> 6 NA NA NA NA NA NA NA NA
> 
>> dim(geno)
> [1] 20  8
> 
> 
> 
>                                                      
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From juliet.hannah at gmail.com  Tue Sep 24 17:30:39 2013
From: juliet.hannah at gmail.com (Juliet Hannah)
Date: Tue, 24 Sep 2013 11:30:39 -0400
Subject: [R] [] and escaping in regular expressions
Message-ID: <CALzuZRQ4Wyuf-EGqe8Di1R4PEzTcYPZFVoYTDhPucPk3STFgoQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130924/18462f60/attachment.pl>

From gunter.berton at gene.com  Tue Sep 24 17:40:18 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 24 Sep 2013 08:40:18 -0700
Subject: [R] [] and escaping in regular expressions
In-Reply-To: <CALzuZRQ4Wyuf-EGqe8Di1R4PEzTcYPZFVoYTDhPucPk3STFgoQ@mail.gmail.com>
References: <CALzuZRQ4Wyuf-EGqe8Di1R4PEzTcYPZFVoYTDhPucPk3STFgoQ@mail.gmail.com>
Message-ID: <CACk-te1vp_TS9qaXCrB5WrSvRcdPmhu_0eeo1AZS2DTVxZSzzA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130924/1fc43d3a/attachment.pl>

From istazahn at gmail.com  Tue Sep 24 17:48:55 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 24 Sep 2013 11:48:55 -0400
Subject: [R] [] and escaping in regular expressions
In-Reply-To: <CACk-te1vp_TS9qaXCrB5WrSvRcdPmhu_0eeo1AZS2DTVxZSzzA@mail.gmail.com>
References: <CALzuZRQ4Wyuf-EGqe8Di1R4PEzTcYPZFVoYTDhPucPk3STFgoQ@mail.gmail.com>
	<CACk-te1vp_TS9qaXCrB5WrSvRcdPmhu_0eeo1AZS2DTVxZSzzA@mail.gmail.com>
Message-ID: <CA+vqiLF8xoyjHFUYHYry-xd8vqWN+WEbXPhZEi-zTRgLLhpCZA@mail.gmail.com>

On Tue, Sep 24, 2013 at 11:40 AM, Bert Gunter <gunter.berton at gene.com> wrote:
> Time to spend some time with the docs!
>
> ?egexp

Just to avoid any confusion: the documentation topic is ?regexp, not ?egexp

>
> tells you:
>
> ". (Only ^ - \ ] are special inside character classes.)"
>
> See also inline below.
>
> Cheers,
> Bert
>
>
> On Tue, Sep 24, 2013 at 8:30 AM, Juliet Hannah <juliet.hannah at gmail.com>wrote:
>
>> Is it correct that one does not need to escape special characters such as
>> "*" (are these
>> properly called metacharacters) inside []. If so, what is the logic to
>> this?
>>
>
> Huh?  Are you aware that regular expressions are actually a context free
> grammar IIRC (computer science gurus, please confirm or correct)?
>
>>
>> mytest <- "he*llo"
>> sub("[*]","",mytest)
>> sub("\\*","",mytest)
>>
>> [] is easier to read for me than \\. Is this what people tend to use?
>>
>
> That would require a survey to answer, would it not? Tastes vary, as they
> say.
>
>
>
>> Thanks.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
>
> Internal Contact Info:
> Phone: 467-7374
> Website:
> http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From scfriant at wisc.edu  Tue Sep 24 17:56:06 2013
From: scfriant at wisc.edu (Sagan Friant)
Date: Tue, 24 Sep 2013 10:56:06 -0500
Subject: [R] adjust scale of x-axis to unequal intervals
In-Reply-To: <52410A03.8040204@bitwrit.com.au>
References: <CA+tD=u7HV5i_xzjvOPhtoLEBycM0S3=HYKSEyEogyJg+BXbLNQ@mail.gmail.com>
	<52410A03.8040204@bitwrit.com.au>
Message-ID: <CA+tD=u7rCqE2o6VOGjwSUPG87BZHnWsgAFLKWbh_ygjH+0EB6A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130924/947598bd/attachment.pl>

From dwinsemius at comcast.net  Tue Sep 24 18:10:09 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 24 Sep 2013 11:10:09 -0500
Subject: [R] Installing R, R packages
In-Reply-To: <f3914067-0250-4ec9-8ee4-a4efa8177576@email.android.com>
References: <1379999747146-4676808.post@n4.nabble.com>
	<f3914067-0250-4ec9-8ee4-a4efa8177576@email.android.com>
Message-ID: <5B0FFC49-1DAF-48DA-B7E5-8B90577F6896@comcast.net>


On Sep 24, 2013, at 12:47 AM, Jeff Newmiller wrote:

> I have stopped using the Berkeley mirror, and just automatically use  
> UCLA due to missing packages. However, I feel no compulsion to  
> extrapolate and say that there is "some sort of corruption going on  
> at CRAN mirrors" because it is only one data point.

I have not been having this sort of difficulty with the Berkeley  
mirror. Never have seen this particular error. Occasionally see the  
mirror down on a weekend, but that happens with all mirrors. (I do use  
Berkeley as my standard mirror and I do download a relatively large  
number of packages especially at the point where I call  
`update.packages`.)


-- 
David.

> Sent from my phone. Please excuse my brevity.
>
> David Arnold <dwarnold45 at suddenlink.net> wrote:
>> All,
>>
>> Consider this attempt:
>>> install.packages("car")
>> trying URL
>> 'http://cran.cnr.Berkeley.edu/bin/macosx/contrib/3.0/car_2.0-19.tgz'
>> Content type 'application/x-gzip' length 1326903 bytes (1.3 Mb)
>> opened URL
>> ==========================================
>> downloaded 1.1 Mb
>>
>> car/data/Rdata.rdb: Truncated tar archive
>> tar: Error exit delayed from previous errors.
>>
>> The downloaded binary packages are in
>>
>> /var/folders/qE/qEavkZWTFMmxjncuY+HnqE+++TI/-Tmp-//Rtmpnxi1hV/ 
>> downloaded_packages
>> Warning messages:
>> 1: In download.file(url, destfile, method, mode = "wb", ...) :
>> downloaded length 1126960 != reported length 1326903
>> 2: 'tar' returned non-zero exit code 1
>>>
>>
>> This seems to be happening frequently at the cran berkeley site. I've
>> also
>> had students try to install R from the Berkeley site and it just
>> doesn't
>> work for them.
>>
>> I had another student tell me today he tried all sorts of mirrors and
>> could
>> not get R and knitr installed until he tried the Washington site.
>>
>> Is there some sort of corruption going on at the CRAN mirrors?
>>
>> D.
>>
>


David Winsemius, MD
Alameda, CA, USA


From szehnder at uni-bonn.de  Tue Sep 24 18:23:18 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Tue, 24 Sep 2013 18:23:18 +0200
Subject: [R] Installing R, R packages
In-Reply-To: <5B0FFC49-1DAF-48DA-B7E5-8B90577F6896@comcast.net>
References: <1379999747146-4676808.post@n4.nabble.com>
	<f3914067-0250-4ec9-8ee4-a4efa8177576@email.android.com>
	<5B0FFC49-1DAF-48DA-B7E5-8B90577F6896@comcast.net>
Message-ID: <6BE20D38-BBD8-4B8C-9373-6CEE642E34E6@uni-bonn.de>

Had yesterday something pretty similar on the 73 installing benchmark:

Error in untar2(tarfile, files, list, exdir, restore_times) :
  incomplete block on file

The downloaded source packages are in
	?/private/var/folders/n9/zxfxcd01557dc06bf3c1njy00000gn/T/RtmpkwQyuQ/downloaded_packages?
Warning messages:
1: In download.file(url, destfile, method, mode = "wb", ...) :
  downloaded length 247786 != reported length 474551
2: In download.file(url, destfile, method, mode = "wb", ...) :
  downloaded length 280942 != reported length 403808
3: In install.packages("benchmark") :
  installation of package ?relations? had non-zero exit status
4: In install.packages("benchmark") :
  installation of package ?benchmark? had non-zero exit status

Today doing the same worked perfectly.


On Sep 24, 2013, at 6:10 PM, David Winsemius <dwinsemius at comcast.net> wrote:

> 
> On Sep 24, 2013, at 12:47 AM, Jeff Newmiller wrote:
> 
>> I have stopped using the Berkeley mirror, and just automatically use UCLA due to missing packages. However, I feel no compulsion to extrapolate and say that there is "some sort of corruption going on at CRAN mirrors" because it is only one data point.
> 
> I have not been having this sort of difficulty with the Berkeley mirror. Never have seen this particular error. Occasionally see the mirror down on a weekend, but that happens with all mirrors. (I do use Berkeley as my standard mirror and I do download a relatively large number of packages especially at the point where I call `update.packages`.)
> 
> 
> -- 
> David.
> 
>> Sent from my phone. Please excuse my brevity.
>> 
>> David Arnold <dwarnold45 at suddenlink.net> wrote:
>>> All,
>>> 
>>> Consider this attempt:
>>>> install.packages("car")
>>> trying URL
>>> 'http://cran.cnr.Berkeley.edu/bin/macosx/contrib/3.0/car_2.0-19.tgz'
>>> Content type 'application/x-gzip' length 1326903 bytes (1.3 Mb)
>>> opened URL
>>> ==========================================
>>> downloaded 1.1 Mb
>>> 
>>> car/data/Rdata.rdb: Truncated tar archive
>>> tar: Error exit delayed from previous errors.
>>> 
>>> The downloaded binary packages are in
>>> 
>>> /var/folders/qE/qEavkZWTFMmxjncuY+HnqE+++TI/-Tmp-//Rtmpnxi1hV/downloaded_packages
>>> Warning messages:
>>> 1: In download.file(url, destfile, method, mode = "wb", ...) :
>>> downloaded length 1126960 != reported length 1326903
>>> 2: 'tar' returned non-zero exit code 1
>>>> 
>>> 
>>> This seems to be happening frequently at the cran berkeley site. I've
>>> also
>>> had students try to install R from the Berkeley site and it just
>>> doesn't
>>> work for them.
>>> 
>>> I had another student tell me today he tried all sorts of mirrors and
>>> could
>>> not get R and knitr installed until he tried the Washington site.
>>> 
>>> Is there some sort of corruption going on at the CRAN mirrors?
>>> 
>>> D.
>>> 
>> 
> 
> 
> David Winsemius, MD
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Tue Sep 24 19:02:13 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 24 Sep 2013 10:02:13 -0700
Subject: [R] [] and escaping in regular expressions
In-Reply-To: <CA+vqiLF8xoyjHFUYHYry-xd8vqWN+WEbXPhZEi-zTRgLLhpCZA@mail.gmail.com>
References: <CALzuZRQ4Wyuf-EGqe8Di1R4PEzTcYPZFVoYTDhPucPk3STFgoQ@mail.gmail.com>
	<CACk-te1vp_TS9qaXCrB5WrSvRcdPmhu_0eeo1AZS2DTVxZSzzA@mail.gmail.com>
	<CA+vqiLF8xoyjHFUYHYry-xd8vqWN+WEbXPhZEi-zTRgLLhpCZA@mail.gmail.com>
Message-ID: <CACk-te0t882AZ+pHEPjeQaWZcQFima2LMLV=Va7S0vMPdJEcDQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130924/4a88bd10/attachment.pl>

From rd023411 at ohio.edu  Tue Sep 24 18:44:20 2013
From: rd023411 at ohio.edu (steric)
Date: Tue, 24 Sep 2013 09:44:20 -0700 (PDT)
Subject: [R] Checking a large data set for normality
Message-ID: <1380041060625-4676858.post@n4.nabble.com>

Hello,

I have a large data set that includes many soil parameters (i.e. pH, calcium
levels, enzyme activity, etc) Does anyone have any input as to the easiest
way to check a large data set for normality? Is there an R function/package
that can do this all at once?

Thank you in advance,





--
View this message in context: http://r.789695.n4.nabble.com/Checking-a-large-data-set-for-normality-tp4676858.html
Sent from the R help mailing list archive at Nabble.com.


From szehnder at uni-bonn.de  Tue Sep 24 19:18:10 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Tue, 24 Sep 2013 19:18:10 +0200
Subject: [R] Checking a large data set for normality
In-Reply-To: <1380041060625-4676858.post@n4.nabble.com>
References: <1380041060625-4676858.post@n4.nabble.com>
Message-ID: <19A16B1B-8903-4141-8529-95617A86C173@uni-bonn.de>

Check the Jarque-Bera Test for univariate testing (http://hosho.ees.hokudai.ac.jp/~kubo/Rdoc/library/tseries/html/jarque.bera.test.html) and Mardia's test for multivariate testing (http://www.inside-r.org/packages/cran/MVN/docs/mardia.test).


On Sep 24, 2013, at 6:44 PM, steric <rd023411 at ohio.edu> wrote:

> Hello,
> 
> I have a large data set that includes many soil parameters (i.e. pH, calcium
> levels, enzyme activity, etc) Does anyone have any input as to the easiest
> way to check a large data set for normality? Is there an R function/package
> that can do this all at once?
> 
> Thank you in advance,
> 
> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Checking-a-large-data-set-for-normality-tp4676858.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From friendly at yorku.ca  Tue Sep 24 19:53:13 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Tue, 24 Sep 2013 13:53:13 -0400
Subject: [R] display recursive partitioning tree as a treemap?
Message-ID: <5241D189.6040403@yorku.ca>

The rpart and party packages, among others, calculate recursive 
partitioning trees
for regression and classification.  There are plot methods available for 
showing
various features as, well,  trees.

But trees can be displayed more compactly as treemaps, eg with the 
treemap packge,
giving a recursive partitioning of a unit rectangle.
I'm wondering if anyone has tried to map the output from rpart() or 
party::ctree() into
the form required as input for a treemap in R.

-Michael

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From john.bingham-hall.10 at ucl.ac.uk  Tue Sep 24 20:13:15 2013
From: john.bingham-hall.10 at ucl.ac.uk (Bingham-Hall, John)
Date: Tue, 24 Sep 2013 18:13:15 +0000
Subject: [R] TwitteR package
Message-ID: <D467216D-B400-466A-B6CD-F23D4F3EDB64@ucl.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130924/83876c9a/attachment.pl>

From hnorpois at gmail.com  Tue Sep 24 19:25:31 2013
From: hnorpois at gmail.com (Hermann Norpois)
Date: Tue, 24 Sep 2013 19:25:31 +0200
Subject: [R] plot - scaling axis
Message-ID: <CAKyZeBvFSqB+HiZNAcRsq+sEn+JKpVObGDeqsKKbw4U9ovVVaQ@mail.gmail.com>

Hello,

i attached an example with two plotted vectors, respectively. And you might
see that the y and x axis are not the same scale (e.g. the third and the
last plot).

I would prefer them to be the same scale.

A toy example:

a <- c (1,2,3,4,5,6,9,20)
> b <- c (0.2,0.4,0.6,1,0.5,1,1,0.1)
> plot (a,b)

I would like to a have a plot with the same scales for the y and x axis.

Could you please give me a hint how it works.
thanks
Hermann
-------------- next part --------------
A non-text attachment was scrubbed...
Name: qholt1prc_qholt0prc.png
Type: image/png
Size: 31304 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130924/d4d611ec/attachment.png>

From wdunlap at tibco.com  Tue Sep 24 22:46:57 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 24 Sep 2013 20:46:57 +0000
Subject: [R] plot - scaling axis
In-Reply-To: <CAKyZeBvFSqB+HiZNAcRsq+sEn+JKpVObGDeqsKKbw4U9ovVVaQ@mail.gmail.com>
References: <CAKyZeBvFSqB+HiZNAcRsq+sEn+JKpVObGDeqsKKbw4U9ovVVaQ@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C345A0D@PA-MBX01.na.tibco.com>

Use asp=1 in the plot command.  E.g.,

par(mar=c(3,1,1,1), fig=c(0,1,.5,1)) ; plot(1:10, 1:10, asp=1)
par(new=TRUE, fig=c(0,.3,0,.5)) ; plot(1:10, 1:10, asp=1)
par(new=TRUE, fig=c(0.3,1,0,.5)) ; plot(1:10, 1:10, asp=1)

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Hermann Norpois
> Sent: Tuesday, September 24, 2013 10:26 AM
> To: r-help
> Subject: [R] plot - scaling axis
> 
> Hello,
> 
> i attached an example with two plotted vectors, respectively. And you might
> see that the y and x axis are not the same scale (e.g. the third and the
> last plot).
> 
> I would prefer them to be the same scale.
> 
> A toy example:
> 
> a <- c (1,2,3,4,5,6,9,20)
> > b <- c (0.2,0.4,0.6,1,0.5,1,1,0.1)
> > plot (a,b)
> 
> I would like to a have a plot with the same scales for the y and x axis.
> 
> Could you please give me a hint how it works.
> thanks
> Hermann


From jim at bitwrit.com.au  Wed Sep 25 01:34:18 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 25 Sep 2013 09:34:18 +1000
Subject: [R] plot - scaling axis
In-Reply-To: <CAKyZeBvFSqB+HiZNAcRsq+sEn+JKpVObGDeqsKKbw4U9ovVVaQ@mail.gmail.com>
References: <CAKyZeBvFSqB+HiZNAcRsq+sEn+JKpVObGDeqsKKbw4U9ovVVaQ@mail.gmail.com>
Message-ID: <5242217A.4050809@bitwrit.com.au>

On 09/25/2013 03:25 AM, Hermann Norpois wrote:
> Hello,
>
> i attached an example with two plotted vectors, respectively. And you might
> see that the y and x axis are not the same scale (e.g. the third and the
> last plot).
>
> I would prefer them to be the same scale.
>
> A toy example:
>
> a<- c (1,2,3,4,5,6,9,20)
>> b<- c (0.2,0.4,0.6,1,0.5,1,1,0.1)
>> plot (a,b)
>
> I would like to a have a plot with the same scales for the y and x axis.
>
> Could you please give me a hint how it works.
> thanks
> Hermann
>
Hi Herman,
My guess is that you want the x and y scales to have the same length in 
user units and perhaps even to have the same tick positions and values. 
For the toy example:

a <- c (1,2,3,4,5,6,9,20)
b <- c (0.2,0.4,0.6,1,0.5,1,1,0.1)
plot (a,b,xlim=c(0,20),ylim=c(0,20))

Adding the solution that Bill provided:

plot (a,b,xlim=c(0,20),ylim=c(0,20),asp=1)

will ensure that the actual intervals on the x and y axes will be the same.

Jim


From dushoff at mcmaster.ca  Wed Sep 25 01:47:25 2013
From: dushoff at mcmaster.ca (Jonathan Dushoff)
Date: Tue, 24 Sep 2013 19:47:25 -0400
Subject: [R] Confusing behaviour in data.table: unexpectedly changing
	variable
Message-ID: <CALF-=EKbGh29Qy_PdJvJjE+Yhsf_nXcSLrt2n8fhFx5=c5HWBw@mail.gmail.com>

I got bitten badly when a variable I created for the purpose of
recording an old set of names changed when I didn't think I was going
near it.

I'm not sure if this is a desired behaviour, or documented, or warned
about.  I read the data.table intro and the FAQ, and also ?setnames.

Ben Bolker created a minimal reproducible example:

library(data.table)
DT = data.table(x=rep(c("a","b","c"),each=3), y=c(1,3,6), v=1:9)
names(DT)
## [1] "x" "y" "v"

oldnames <- names(DT)
print(oldnames)
## [1] "x" "y" "v"

setnames(DT, LETTERS[1:3])
print(oldnames)
## [1] "A" "B" "C"

-- 
McMaster University Department of Biology
http://lalashan.mcmaster.ca/theobio/DushoffLab/index.php/Main_Page
https://twitter.com/jd_mathbio


From jim at bitwrit.com.au  Wed Sep 25 02:24:24 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 25 Sep 2013 10:24:24 +1000
Subject: [R] Graph is without line
In-Reply-To: <OF77059D3A.6545B4E9-ON65257BF0.0045C758-65257BF0.00462B70@polarisft.com>
References: <OF77059D3A.6545B4E9-ON65257BF0.0045C758-65257BF0.00462B70@polarisft.com>
Message-ID: <52422D38.6050604@bitwrit.com.au>

On 09/24/2013 10:46 PM, mohan.radhakrishnan at polarisft.com wrote:
> Hi,
>          Sometimes I get a graph like the attached one. The data type could
> have something to do with it. This graph does not use the color and does
> not draw
> a line. Earlier I used to convert the factors in the data frame to another
> data type and drew the correct graphs.
>
> Any idea why this happens ?
>
> Thanks,
> Mohan
>
>              Var1 Freq
> 1     10.1.17.10  205
> 2     10.1.17.15  216
> 3     10.1.17.17   79
> 4     10.1.17.23   76
> 5     10.1.17.24  209
> 6      10.1.17.5  244
> 7      10.1.17.6  178
> 8      10.1.17.7  165
> 9      10.1.17.8  146
>
>
>
> #prints factor
> print(class(data$Var1))
>
> plot(data$Var1,data$Freq,ylim=c(0,700),col="green",type="o",ylab="",xlab="",las=2,lwd=2.5,xaxt="n")
> title("Estimation of concurrent connections",cex.main=3)
> library(plotrix)
> staxlab(at=data$Var1,
>    labels=as.character(data$Var1),nlines=3,srt=90)
>
Hi Mohan,
If you pass a factor as the "x" value to plot, it assumes that the 
values of the factor are nominal or at best ordinal and does not try to 
connect them into a metric scale. You can get a "line" with:

plot(as.numeric(data$Var1),data$Freq,ylim=c(0,700),col="green",type="o",
  ylab="",xlab="",las=2,lwd=2.5,xaxt="n")
...

but think carefully about whether this means anything sensible.

Jim


From kridox at ymail.com  Wed Sep 25 02:29:07 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Wed, 25 Sep 2013 09:29:07 +0900
Subject: [R] how to add a box to map plotted by a levelplot?
In-Reply-To: <1380015712685-4676825.post@n4.nabble.com>
References: <1380011079688-4676815.post@n4.nabble.com>
	<CAAcyNCzyP9rpva-=9YN_cCAZdOCZVE3WZvjFJaxDy1djZfuZ0g@mail.gmail.com>
	<1380015712685-4676825.post@n4.nabble.com>
Message-ID: <CAAcyNCwJuvMKYrSE=euNd1PL-YJcZYPF=AFDnkDy_3bK39tffw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130925/ca0c794b/attachment.pl>

From jim at bitwrit.com.au  Wed Sep 25 03:22:59 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 25 Sep 2013 11:22:59 +1000
Subject: [R] adjust scale of x-axis to unequal intervals
In-Reply-To: <CA+tD=u7rCqE2o6VOGjwSUPG87BZHnWsgAFLKWbh_ygjH+0EB6A@mail.gmail.com>
References: <CA+tD=u7HV5i_xzjvOPhtoLEBycM0S3=HYKSEyEogyJg+BXbLNQ@mail.gmail.com>	<52410A03.8040204@bitwrit.com.au>
	<CA+tD=u7rCqE2o6VOGjwSUPG87BZHnWsgAFLKWbh_ygjH+0EB6A@mail.gmail.com>
Message-ID: <52423AF3.6080203@bitwrit.com.au>

On 09/25/2013 01:56 AM, Sagan Friant wrote:
> Thank you!  This worked beautifully.  Can you help me adapt the code to
> do the same thing for a plot of means? The application is not a simple
> as I hoped...
>
> plotMeans(rich.small$ALL, rich.small$sample, error.bars="se")
>...

Hi Sagan,
Let's see, plotMeans is in the Rcmdr package. After installing it, I 
couldn't get it to plot, but upon exiting the Rcmdr window I worked out 
that the second argument (factor1) must obviously be a factor. After 
correcting this:

rich.small<-data.frame(ALL=rnorm(240,5),
  sample=factor(c(rep(0,60),rep(2,50),rep(4,40),
  rep(7,30),rep(10,30),rep(18,30))))

I get a plot, but I can see no way of adjusting the positions of the 
means displayed. I suggest:

plot(c(0,10,13,16,19,94),
  by(rich.small$ALL,rich.small$sample,FUN=mean),
  xaxt="n",ylim=c(4.7,5.4))
library(plotrix)
dispersion(c(0,10,13,16,19,94),
  by(rich.small$ALL,rich.small$sample,FUN=mean),
  by(rich.small$ALL,rich.small$sample,FUN=std.error))
staxlab(1,at=c(0,10,13,16,19,94),labels=c(0,2,4,7,10,18))

Jim


From shanxiao at umail.iu.edu  Tue Sep 24 22:33:52 2013
From: shanxiao at umail.iu.edu (shanxiao)
Date: Tue, 24 Sep 2013 16:33:52 -0400
Subject: [R] fit a time varying coefficient log linear model in r
Message-ID: <000001ceb965$64e185e0$2ea491a0$@iu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130924/ea9c4642/attachment.pl>

From paul at stat.auckland.ac.nz  Wed Sep 25 02:35:44 2013
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Wed, 25 Sep 2013 12:35:44 +1200
Subject: [R] failure to replayPlot() a recordedplot object saved in a
 previous session?
In-Reply-To: <5E1B812FAC2C4A49B3D99593B5A521910D43AB81@PRDEXMBX-08.the-lab.llnl.gov>
References: <5E1B812FAC2C4A49B3D99593B5A521910D43AB81@PRDEXMBX-08.the-lab.llnl.gov>
Message-ID: <52422FE0.7090302@stat.auckland.ac.nz>

Hi

Attempting to use a display list snapshot (as created by recordPlot()) 
between R sessions has always been strongly discouraged, but as of about 
R 3.0.0 it has become impossible (due to internal changes, which was 
part of the reason for strongly discouraging this in the first place).

Sorry to be the bearer of bad news.

Paul

On 09/13/13 10:54, MacQueen, Don wrote:
> I have the following experience.
>
> If I use, for example,
>     tmp <-  recordPlot()
> in a session, then immediately the saved plot replays successfully using
>     replayPlot()
> in the same session. But not in the next R session. See examples below,
> copy/pasted from my shell window.
>
> The first R session is brand new; no saved objects left over from a
> previous session.
>
> I also have the same experience with R 3.0.1 patched on a linux machine
> (RHEL).
>
>
> Is this a known or expected behavior?
>
> Thanks
> -Don
>
>
> #### R session #1
>
> mydir[42]% R
>
> R version 3.0.1 Patched (2013-08-13 r63562) -- "Good Sport"
> Copyright (C) 2013 The R Foundation for Statistical Computing
> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
>    Natural language support but running in an English locale
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
>
>>
>> x11()
>> plot(1:2)
>> tmp <- recordPlot()
>> replayPlot(tmp)
>> q()
> Save workspace image? [y/n/c]: y
>
>
>
>
> #### R session #2
>
>
> mydir[43]% R
>
> R version 3.0.1 Patched (2013-08-13 r63562) -- "Good Sport"
> Copyright (C) 2013 The R Foundation for Statistical Computing
> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
>    Natural language support but running in an English locale
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
>
> [Previously saved workspace restored]
>
>> ls()
> [1] "tmp"
>> class(tmp)
> [1] "recordedplot"
>> x11()
>> replayPlot(tmp)
> Error: NULL value passed as symbol address
>>
>> sessionInfo()
> R version 3.0.1 Patched (2013-08-13 r63562)
> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>
> locale:
> [1] C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>
>
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From exode00 at hotmail.com  Wed Sep 25 04:18:18 2013
From: exode00 at hotmail.com (Pierre Paradis)
Date: Wed, 25 Sep 2013 02:18:18 +0000
Subject: [R] object not found in a cca analysis with vegan package
Message-ID: <BAY176-W5216F6B96A94AD3822CA4BBC2F0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130925/5bff6552/attachment.pl>

From kridox at ymail.com  Wed Sep 25 06:04:08 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Wed, 25 Sep 2013 13:04:08 +0900
Subject: [R] object not found in a cca analysis with vegan package
In-Reply-To: <BAY176-W5216F6B96A94AD3822CA4BBC2F0@phx.gbl>
References: <BAY176-W5216F6B96A94AD3822CA4BBC2F0@phx.gbl>
Message-ID: <CAAcyNCymE8TznAMue327PGMdvOAD3ecYSpD6Aqpc8NQgEvCY=A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130925/7c939d3a/attachment.pl>

From dwinsemius at comcast.net  Wed Sep 25 06:10:29 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 24 Sep 2013 23:10:29 -0500
Subject: [R] Checking a large data set for normality
In-Reply-To: <1380041060625-4676858.post@n4.nabble.com>
References: <1380041060625-4676858.post@n4.nabble.com>
Message-ID: <7B38DB6E-A1C9-43B6-BEED-6836BF4796D2@comcast.net>


On Sep 24, 2013, at 11:44 AM, steric wrote:

> Hello,
>
> I have a large data set that includes many soil parameters (i.e. pH,  
> calcium
> levels, enzyme activity, etc) Does anyone have any input as to the  
> easiest
> way to check a large data set for normality? Is there an R function/ 
> package
> that can do this all at once?
>

This raises the question about why one should be doing this. There is  
quite a bit of misinformation about the "need for normality", some of  
it presented by Six Sigma "experts" or even by college professors who  
should know better. One might even say that if you don't know how to  
check for normality then there is a high likelihood that you should  
not be doing so.

-- 
David Winsemius, MD
Alameda, CA, USA


From mohan.radhakrishnan at polarisft.com  Wed Sep 25 06:13:18 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Wed, 25 Sep 2013 09:43:18 +0530
Subject: [R] Graph is without line
In-Reply-To: <52422D38.6050604@bitwrit.com.au>
References: <OF77059D3A.6545B4E9-ON65257BF0.0045C758-65257BF0.00462B70@polarisft.com>
	<52422D38.6050604@bitwrit.com.au>
Message-ID: <OF15166A00.B55C130E-ON65257BF1.0016FA35-65257BF1.00172CDF@polarisft.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130925/af4f7c6d/attachment.pl>

From dwinsemius at comcast.net  Wed Sep 25 06:25:47 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 24 Sep 2013 23:25:47 -0500
Subject: [R] fit a time varying coefficient log linear model in r
In-Reply-To: <000001ceb965$64e185e0$2ea491a0$@iu.edu>
References: <000001ceb965$64e185e0$2ea491a0$@iu.edu>
Message-ID: <FB898414-86A1-4772-84C8-9C6468F3E4A6@comcast.net>


On Sep 24, 2013, at 3:33 PM, shanxiao wrote:

> Hello, all,
>
>
>
> Does anyone know any package in r to fit a log linear model with time
> varying coefficients in R? I have googled but with no results. Your  
> help
> will be appreciated. J
>

Perhaps glm (in the default stats package)  with an offset of log(time)?

-- 

David Winsemius, MD
Alameda, CA, USA


From gergely at snowl.net  Wed Sep 25 08:15:22 2013
From: gergely at snowl.net (=?ISO-8859-1?Q?Gergely_Dar=F3czi?=)
Date: Wed, 25 Sep 2013 08:15:22 +0200
Subject: [R] failure to replayPlot() a recordedplot object saved in a
 previous session?
In-Reply-To: <52422FE0.7090302@stat.auckland.ac.nz>
References: <5E1B812FAC2C4A49B3D99593B5A521910D43AB81@PRDEXMBX-08.the-lab.llnl.gov>
	<52422FE0.7090302@stat.auckland.ac.nz>
Message-ID: <CAPvvxJWwJRWsNhDrVTF2wWhnb9DSX33Lw-88RKVuhpzhKCxO6A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130925/7b226cb5/attachment.pl>

From babakbsn at gmail.com  Wed Sep 25 08:41:33 2013
From: babakbsn at gmail.com (Babak Bastan)
Date: Tue, 24 Sep 2013 23:41:33 -0700
Subject: [R] How can I draw a 3D diagram (persp) with these Infos
Message-ID: <CAF-JZQtnvbxdKN2S0kDm_JiisbCuHP7i7fB5xgzchs82e3w8LA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130924/92891ad5/attachment.pl>

From kridox at ymail.com  Wed Sep 25 08:56:17 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Wed, 25 Sep 2013 15:56:17 +0900
Subject: [R] How can I draw a 3D diagram (persp) with these Infos
In-Reply-To: <CAF-JZQtnvbxdKN2S0kDm_JiisbCuHP7i7fB5xgzchs82e3w8LA@mail.gmail.com>
References: <CAF-JZQtnvbxdKN2S0kDm_JiisbCuHP7i7fB5xgzchs82e3w8LA@mail.gmail.com>
Message-ID: <CAAcyNCxKM6mRN4oWUROxiuSkJbVHQU81m7MP-MKffShBVbFY9Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130925/9030e1b0/attachment.pl>

From smartpink111 at yahoo.com  Wed Sep 25 09:08:57 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 25 Sep 2013 00:08:57 -0700 (PDT)
Subject: [R] Computing calculation among two vectors
Message-ID: <1380092937.65850.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
Try:
x<- 1:4
?y<- c("*","/","-","+")
res<-sapply(y,function(i) {x1<-expand.grid(x,x); unlist(lapply(paste0(x1[,1],i,x1[,2]),function(u) eval(parse(text=u))))})
row.names(res)<- as.character(interaction(expand.grid(x,x),sep="_"))

head(res)
#??? *?? /? - +
#1_1 1 1.0? 0 2
#2_1 2 2.0? 1 3
#3_1 3 3.0? 2 4
#4_1 4 4.0? 3 5
#1_2 2 0.5 -1 3
#2_2 4 1.0? 0 4


A.K.



I have two vectors one numeric and another with operand. 

Eg: x - 1,2,3,4 and y-"*", "/", "-", "+" 

I need to calculate all the possible two combinations in x with 
each of operand in y. As example, 1*2, 1/2, 1-2, 1+2, 1*3, 1/3.... 

Any help appreciated. 

Regards 
Hussain


From mohan.radhakrishnan at polarisft.com  Wed Sep 25 09:10:17 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Wed, 25 Sep 2013 12:40:17 +0530
Subject: [R] Space between x-axis ticks
Message-ID: <OF12E2BA7F.8DF555BB-ON65257BF1.002715ED-65257BF1.00275E28@polarisft.com>

Hi,

          I am trying to clearly show the values in the x-axis in the 
attached graph. The tick marks are too close and the labels are blurred. 


plot(as.numeric(data$Var1),data$Freq,ylim=c(0,700),col="green",type="o",ylab="Number 
of connections",las=2,lwd=2.5,xaxt="n",xlab="IP")

axis(1,at=data$Var1,labels=data$Var1,las = 2,cex.axis=0.7,las=2)
title("Estimation of concurrent connections",cex.main=1.8,line=1)



Thanks,
Mohan


This e-Mail may contain proprietary and confidential information and is sent for the intended recipient(s) only.  If by an addressing or transmission error this mail has been misdirected to you, you are requested to delete this mail immediately. You are also hereby notified that any use, any form of reproduction, dissemination, copying, disclosure, modification, distribution and/or publication of this e-mail message, contents or its attachment other than by its intended recipient/s is strictly prohibited.

Visit us at http://www.polarisFT.com

From petr.pikal at precheza.cz  Wed Sep 25 09:16:50 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 25 Sep 2013 07:16:50 +0000
Subject: [R] Graph is without line
In-Reply-To: <OF15166A00.B55C130E-ON65257BF1.0016FA35-65257BF1.00172CDF@polarisft.com>
References: <OF77059D3A.6545B4E9-ON65257BF0.0045C758-65257BF0.00462B70@polarisft.com>
	<52422D38.6050604@bitwrit.com.au>
	<OF15166A00.B55C130E-ON65257BF1.0016FA35-65257BF1.00172CDF@polarisft.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B936DA@SRVEXCHMBX.precheza.cz>

Hi

It is mostly question of personal preference. Factors have some nice features when manipulating with levels, sorting, and/or using numeric annotation. However when you want to add some new value to factor it is trickier than with plain string vectors. Maybe it is time to look into R-intro explanation of object differences. 

Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of mohan.radhakrishnan at polarisft.com
> Sent: Wednesday, September 25, 2013 6:13 AM
> To: Jim Lemon
> Cc: r-help at r-project.org
> Subject: Re: [R] Graph is without line
> 
> Hi,
>              Yes. It worked. Is 'stringAsFactors=FALSE' the switch to
> use when reading data into a frame ? All the values I use are either
> numbers or dates or strings. Sometimes while I manipulate the data by
> filtering, the values seem to become factors ?
> 
> Thanks,
> Mohan
> 
> 
> 
> From:   Jim Lemon <jim at bitwrit.com.au>
> To:     mohan.radhakrishnan at polarisft.com
> Cc:     r-help at r-project.org
> Date:   09/25/2013 05:56 AM
> Subject:        Re: [R] Graph is without line
> 
> 
> 
> On 09/24/2013 10:46 PM, mohan.radhakrishnan at polarisft.com wrote:
> > Hi,
> >          Sometimes I get a graph like the attached one. The data type
> could
> > have something to do with it. This graph does not use the color and
> > does not draw a line. Earlier I used to convert the factors in the
> > data frame to
> another
> > data type and drew the correct graphs.
> >
> > Any idea why this happens ?
> >
> > Thanks,
> > Mohan
> >
> >              Var1 Freq
> > 1     10.1.17.10  205
> > 2     10.1.17.15  216
> > 3     10.1.17.17   79
> > 4     10.1.17.23   76
> > 5     10.1.17.24  209
> > 6      10.1.17.5  244
> > 7      10.1.17.6  178
> > 8      10.1.17.7  165
> > 9      10.1.17.8  146
> >
> >
> >
> > #prints factor
> > print(class(data$Var1))
> >
> >
> plot(data$Var1,data$Freq,ylim=c(0,700),col="green",type="o",ylab="",xla
> b="",las=2,lwd=2.5,xaxt="n")
> > title("Estimation of concurrent connections",cex.main=3)
> > library(plotrix)
> > staxlab(at=data$Var1,
> >    labels=as.character(data$Var1),nlines=3,srt=90)
> >
> Hi Mohan,
> If you pass a factor as the "x" value to plot, it assumes that the
> values of the factor are nominal or at best ordinal and does not try to
> connect them into a metric scale. You can get a "line" with:
> 
> plot(as.numeric(data$Var1),data$Freq,ylim=c(0,700),col="green",type="o"
> ,
>   ylab="",xlab="",las=2,lwd=2.5,xaxt="n")
> ...
> 
> but think carefully about whether this means anything sensible.
> 
> Jim
> 
> 
> 
> 
> This e-Mail may contain proprietary and confidential information and is
> sent for the intended recipient(s) only.  If by an addressing or
> transmission error this mail has been misdirected to you, you are
> requested to delete this mail immediately. You are also hereby notified
> that any use, any form of reproduction, dissemination, copying,
> disclosure, modification, distribution and/or publication of this e-
> mail message, contents or its attachment other than by its intended
> recipient/s is strictly prohibited.
> 
> Visit us at http://www.polarisFT.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mdowle at mdowle.plus.com  Wed Sep 25 09:18:24 2013
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Wed, 25 Sep 2013 08:18:24 +0100
Subject: [R] Confusing behaviour in data.table: unexpectedly changing
	variable
In-Reply-To: <CALF-=EKbGh29Qy_PdJvJjE+Yhsf_nXcSLrt2n8fhFx5=c5HWBw@mail.gmail.com>
References: <CALF-=EKbGh29Qy_PdJvJjE+Yhsf_nXcSLrt2n8fhFx5=c5HWBw@mail.gmail.com>
Message-ID: <52428E40.60005@mdowle.plus.com>


Very sorry to hear this bit you.  If you need a copy of names before 
changing them by reference :

     oldnames <- copy(names(DT))

This will be documented and it's on the bug list to do so. copy is 
needed in other circumstances too, see ?copy.

More details here :

http://stackoverflow.com/questions/18662715/colnames-being-dropped-in-data-table-in-r
http://stackoverflow.com/questions/15913417/why-does-data-table-update-namesdt-by-reference-even-if-i-assign-to-another-v

Btw, the r-help posting guide says (last time I looked) you should only 
post to r-help about packages if you have tried the maintainer first but 
didn't hear from them; i.e., r-help isn't for support about packages.

I don't follow r-help, so please continue to cc me if you reply.

Matthew

On 25/09/13 00:47, Jonathan Dushoff wrote:
> I got bitten badly when a variable I created for the purpose of
> recording an old set of names changed when I didn't think I was going
> near it.
>
> I'm not sure if this is a desired behaviour, or documented, or warned
> about.  I read the data.table intro and the FAQ, and also ?setnames.
>
> Ben Bolker created a minimal reproducible example:
>
> library(data.table)
> DT = data.table(x=rep(c("a","b","c"),each=3), y=c(1,3,6), v=1:9)
> names(DT)
> ## [1] "x" "y" "v"
>
> oldnames <- names(DT)
> print(oldnames)
> ## [1] "x" "y" "v"
>
> setnames(DT, LETTERS[1:3])
> print(oldnames)
> ## [1] "A" "B" "C"
>


From maechler at lynne.ethz.ch  Wed Sep 25 11:08:07 2013
From: maechler at lynne.ethz.ch (Martin Maechler)
Date: Wed, 25 Sep 2013 11:08:07 +0200
Subject: [R] Rmpfr question
In-Reply-To: <!&!AAAAAAAAAAAYAAAAAAAAAD+bP9Kay49OhKgiYwFy3LDCgAAAEAAAAARyIl+ueG1Ng/+/IIAPTdABAAAAAA==@free.fr>
References: <!&!AAAAAAAAAAAYAAAAAAAAAD+bP9Kay49OhKgiYwFy3LDCgAAAEAAAADLTCDxVQ7NOlQPBclfnJl0BAAAAAA==@free.fr>
	<21057.24977.237949.686614@gargle.gargle.HOWL>
	<!&!AAAAAAAAAAAYAAAAAAAAAD+bP9Kay49OhKgiYwFy3LDCgAAAEAAAAARyIl+ueG1Ng/+/IIAPTdABAAAAAA==@free.fr>
Message-ID: <21058.42999.139919.809511@gargle.gargle.HOWL>

>>>>> Michel  <michelgomez at free.fr>
>>>>>     on Tue, 24 Sep 2013 12:22:10 +0200 writes:

    > Hello, Thanks for your answer The file does not contains
    > numbers in high precision but all the calculation applied
    > to these data will be

    > In attachment a text file containing some lines And her
    > few values:
    > 11111.0054014388224326026488598,-68239.4114845811819662912967033,10053.1824584878233990181684021
    > 3.05363891777017837760380136736,-1.40443175474415104684797195311,1.36766960877453817890022497172

(two lines, typically split by mail writers/readers)

Aha!  But these actually *ARE* of  'high precision', i.e.
you cannot store them as usual double precision numbers in full accuracy.

So, I've prepared the following -- 100% reproducible -- script
to show you how to get such numbers into an Rmpfr matrix :


## MM: Reproducible example
set.seed(17); x <- mpfr(matrix(rnorm(28), 7, 4), precBits=128)
x <- x^2
mfile <- tempfile()
write.table(array(format(x), dim=dim(x)), file = mfile,
	    row.names=FALSE, col.names=FALSE, sep=",")
## to check:
writeLines(readLines(mfile) [1:2])


## Now, let's assume mfile contains the "high precision" matrix we want to get as
## mpfrMatrix :
## 1) Assume you know the number of columns, then this is fastest :
m.ncol <- 4
chmat <- matrix(scan(mfile, "", sep=","), ncol = m.ncol )

## 2) Nothing is known, ... ok, why not make the detour via read.table():
chmat <- as.matrix(read.table(mfile, colClasses="character", sep=","))

## in both cases:

require(Rmpfr)# the package

M <- mpfr(chmat)#-> determines precision *from* the input, here  133 .. 143 bits

## or set the precision yourself, high enough:
M <- mpfr(chmat, precBits = 144)

## and e.g. this works:

crossprod(M) ## == M'M

-------

Hoping this helps,
Martin


From mohan.radhakrishnan at polarisft.com  Wed Sep 25 11:13:05 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Wed, 25 Sep 2013 14:43:05 +0530
Subject: [R] Space between x-axis ticks
In-Reply-To: <OF12E2BA7F.8DF555BB-ON65257BF1.002715ED-65257BF1.00275E28@polarisft.com>
References: <OF12E2BA7F.8DF555BB-ON65257BF1.002715ED-65257BF1.00275E28@polarisft.com>
Message-ID: <OF35D0CE7A.5D21238F-ON65257BF1.00328985-65257BF1.00329F25@polarisft.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130925/7f7e35fa/attachment.pl>

From maechler at lynne.ethz.ch  Wed Sep 25 11:26:20 2013
From: maechler at lynne.ethz.ch (Martin Maechler)
Date: Wed, 25 Sep 2013 11:26:20 +0200
Subject: [R] Rmpfr question
In-Reply-To: <21058.42999.139919.809511@gargle.gargle.HOWL>
References: <!&!AAAAAAAAAAAYAAAAAAAAAD+bP9Kay49OhKgiYwFy3LDCgAAAEAAAADLTCDxVQ7NOlQPBclfnJl0BAAAAAA==@free.fr>
	<21057.24977.237949.686614@gargle.gargle.HOWL>
	<!&!AAAAAAAAAAAYAAAAAAAAAD+bP9Kay49OhKgiYwFy3LDCgAAAEAAAAARyIl+ueG1Ng/+/IIAPTdABAAAAAA==@free.fr>
	<21058.42999.139919.809511@gargle.gargle.HOWL>
Message-ID: <21058.44092.695238.125579@gargle.gargle.HOWL>

>>>>> Martin Maechler <maechler at lynne.ethz.ch>
>>>>>     on Wed, 25 Sep 2013 11:08:07 +0200 writes:

>>>>> Michel  <michelgomez at free.fr>
>>>>>     on Tue, 24 Sep 2013 12:22:10 +0200 writes:

    >> Hello, Thanks for your answer The file does not contains
    >> numbers in high precision but all the calculation applied
    >> to these data will be

    >> In attachment a text file containing some lines And her
    >> few values:
    >> 11111.0054014388224326026488598,-68239.4114845811819662912967033,10053.1824584878233990181684021
    >> 3.05363891777017837760380136736,-1.40443175474415104684797195311,1.36766960877453817890022497172

    > (two lines, typically split by mail writers/readers)

    > Aha!  But these actually *ARE* of  'high precision', i.e.
    > you cannot store them as usual double precision numbers in full accuracy.

    > So, I've prepared the following -- 100% reproducible -- script
    > to show you how to get such numbers into an Rmpfr matrix :


    > ## MM: Reproducible example
    > set.seed(17); x <- mpfr(matrix(rnorm(28), 7, 4), precBits=128)
    > x <- x^2
    > mfile <- tempfile()
    > write.table(array(format(x), dim=dim(x)), file = mfile,
    > row.names=FALSE, col.names=FALSE, sep=",")
    > ## to check:
    > writeLines(readLines(mfile) [1:2])


    > ## Now, let's assume mfile contains the "high precision" matrix we want to get as
    > ## mpfrMatrix :
    > ## 1) Assume you know the number of columns, then this is fastest :
    > m.ncol <- 4
    > chmat <- matrix(scan(mfile, "", sep=","), ncol = m.ncol )

and -- oops! -  the above was missing the ominous 'byrow = TRUE' 
i.e. the above needs to be

    chmat <- matrix(scan(mfile, "", sep=","), ncol = m.ncol, byrow = TRUE)

... which makes the detour via read.table() even more attractive ...

    > ## 2) Nothing is known, ... ok, why not make the detour via read.table():
    > chmat <- as.matrix(read.table(mfile, colClasses="character", sep=","))

    > ## in both cases:

    > require(Rmpfr)# the package

    > M <- mpfr(chmat)#-> determines precision *from* the input, here  133 .. 143 bits

    > ## or set the precision yourself, high enough:
    > M <- mpfr(chmat, precBits = 144)

    > ## and e.g. this works:

    > crossprod(M) ## == M'M

    > -------

    > Hoping this helps,
    > Martin


From petr.pikal at precheza.cz  Wed Sep 25 11:30:24 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 25 Sep 2013 09:30:24 +0000
Subject: [R] Space between x-axis ticks
In-Reply-To: <OF35D0CE7A.5D21238F-ON65257BF1.00328985-65257BF1.00329F25@polarisft.com>
References: <OF12E2BA7F.8DF555BB-ON65257BF1.002715ED-65257BF1.00275E28@polarisft.com>
	<OF35D0CE7A.5D21238F-ON65257BF1.00328985-65257BF1.00329F25@polarisft.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B937CF@SRVEXCHMBX.precheza.cz>

Hi

If you did
PLEASE do read the posting guide http://www.R-project.org/posting-
guide.html

you could find
No binary attachments except for PS, PDF, and some image and archive formats (others are automatically stripped off because they can contain malicious software). Files in other formats and larger ones should rather be put on the web and have only their URLs posted. This way a reader has the option to download them or not.

So the best way is to post some data preferably by

?dput

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of mohan.radhakrishnan at polarisft.com
> Sent: Wednesday, September 25, 2013 11:13 AM
> To: r-help at r-project.org
> Subject: Re: [R] Space between x-axis ticks
> 
> Looks like graph cannot be attached.
> 
> Mohan
> 
> 
> 
> From:   mohan.radhakrishnan at polarisft.com
> To:     r-help at r-project.org
> Date:   09/25/2013 12:41 PM
> Subject:        [R] Space between x-axis ticks
> Sent by:        r-help-bounces at r-project.org
> 
> 
> 
> Hi,
> 
>           I am trying to clearly show the values in the x-axis in the
> attached graph. The tick marks are too close and the labels are
> blurred.
> 
> 
> plot(as.numeric(data$Var1),data$Freq,ylim=c(0,700),col="green",type="o"
> ,ylab="Number
> 
> of connections",las=2,lwd=2.5,xaxt="n",xlab="IP")
> 
> axis(1,at=data$Var1,labels=data$Var1,las = 2,cex.axis=0.7,las=2)
> title("Estimation of concurrent connections",cex.main=1.8,line=1)
> 
> 
> 
> Thanks,
> Mohan
> 
> 
> This e-Mail may contain proprietary and confidential information and is
> sent for the intended recipient(s) only.  If by an addressing or
> transmission error this mail has been misdirected to you, you are
> requested to delete this mail immediately. You are also hereby notified
> that any use, any form of reproduction, dissemination, copying,
> disclosure, modification, distribution and/or publication of this e-
> mail
> message, contents or its attachment other than by its intended
> recipient/s
> is strictly prohibited.
> 
> Visit us at http://www.polarisFT.com
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> 
> This e-Mail may contain proprietary and confidential information and is
> sent for the intended recipient(s) only.  If by an addressing or
> transmission error this mail has been misdirected to you, you are
> requested to delete this mail immediately. You are also hereby notified
> that any use, any form of reproduction, dissemination, copying,
> disclosure, modification, distribution and/or publication of this e-
> mail message, contents or its attachment other than by its intended
> recipient/s is strictly prohibited.
> 
> Visit us at http://www.polarisFT.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pd.mes at cbs.dk  Wed Sep 25 13:16:24 2013
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Wed, 25 Sep 2013 13:16:24 +0200
Subject: [R] R 3.0.2 is released
Message-ID: <C81B1E54-41D7-447A-8F07-8843ACD68976@cbs.dk>

The build system rolled up R-3.0.2.tar.gz (codename "Frisbee Sailing") this morning.

The list below details the changes in this release.

You can get the source code from

http://cran.r-project.org/src/base/R-3/R-3.0.2.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team

Peter Dalgaard


These are the md5sums for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = cbf6da8f886ccd8d0dda0cc7ffd1b8ec
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 77da68a9d0abfa9121d54f6ff0bced33
MD5 (INSTALL) = 3964b9119adeaab9ceb633773fc94aac
MD5 (NEWS) = e01b5a01aade71ccef967d39f3738e0a
MD5 (NEWS.html) = 1925b57c75bd51373adb33a04e2c18f8
MD5 (R-latest.tar.gz) = f9a8374736e7650e4848f33e2e3bbee3
MD5 (README) = e259ae5dd943b8547f0b7719664e815b
MD5 (RESOURCES) = c7cb32499ebbf85deb064aab282f93a4
MD5 (THANKS) = d4b45e302b7cad0fc4bb50d2cfe69649
MD5 (R-3/R-3.0.2.tar.gz) = f9a8374736e7650e4848f33e2e3bbee3


This is the relevant part of the NEWS file

CHANGES IN R 3.0.2:

  NEW FEATURES:

    * The NEWS files have been re-organized.

      This file contains news for R >= 3.0.0: news for the 0.x.y, 1.x.y
      and 2.x.y releases is in files NEWS.0, NEWS.1 and NEWS.2.  The
      latter files are now installed when R is installed.  An HTML
      version of news from 2.10.0 to 2.15.3 is available as
      doc/html/NEWS.2.html.

    * sum() for integer arguments now uses an integer accumulator of at
      least 64 bits and so will be more accurate in the very rare case
      that a cumulative sum exceeds 2^53 (necessarily summing more than
      4 million elements).

    * The example() and tools::Rd2ex() functions now have parameters to
      allow them to ignore \dontrun markup in examples.  (Suggested by
      Peter Solymos.)

    * str(x) is considerably faster for very large lists, or factors
      with 100,000 levels, the latter as in PR#15337.

    * col2rgb() now converts factors to character strings not integer
      codes (suggested by Bryan Hanson).

    * tail(warnings()) now works, via the new `[` method.

    * There is now support for the LaTeX style file zi4.sty which has
      in some distributions replaced inconsolata.sty.

    * unlist(x) now typically returns all non-list xs unchanged, not
      just the "vector" ones.  Consequently, format(lst) now also works
      when the list lst has non-vector elements.

    * The tools::getVignetteInfo() function has been added to give
      information about installed vignettes.

    * New assertCondition(), etc. utilities in tools, useful for
      testing.

    * Profiling now records non-inlined calls from byte-compiled code
      to BUILTIN functions.

    * Various functions in stats and elsewhere that use non-standard
      evaluation are now more careful to follow the namespace scoping
      rules.  E.g. stats::lm() can now find stats::model.frame() even
      if stats is not on the search path or if some package defines a
      function of that name.

    * If an invalid/corrupt .Random.seed object is encountered in the
      workspace it is ignored with a warning rather than giving an
      error.  (This allows R itself to rely on a working RNG, e.g. to
      choose a random port.)

    * seq() and seq.int() give more explicit error messages if called
      with invalid (e.g. NaN) inputs.

    * When parse() finds a syntax error, it now makes partial parse
      information available up to the location of the error.  (Request
      of Reijo Sund.)

    * Methods invoked by NextMethod() had a different dynamic parent to
      the generic. This was causing trouble where S3 methods invoked
      via lazy evaluation could lose track of their generic.
      (PR#15267)

    * Code for the negative binomial distribution now treats the case
      size == 0 as a one-point distribution at zero.

    * abbreviate() handles without warning non-ASCII input strings
      which require no abbreviation.

    * read.dcf() no longer has a limit of 8191 bytes per line. (Wish of
      PR#15250.)

    * formatC(x) no longer copies the class of x to the result, to
      avoid misuse creating invalid objects as in PR#15303.  A warning
      is given if a class is discarded.

    * Dataset npk has been copied from MASS to allow more tests to be
      run without recommended packages being installed.

    * The initialization of the regression coefficients for
      non-degenerate differenced models in arima() has been changed and
      in some examples avoids a local maximum.  (PR#15396)

    * termplot() now has an argument transform.x to control the display
      of individual terms in the plot.  (PR#15329)

    * format() now supports digits = 0, to display nsmall decimal
      places.

    * There is a new read-only par() parameter called "page", which
      returns a logical value indicating whether the next plot.new()
      call will start a new page.

    * Processing Sweave and Rd documents to PDF now renders backticks
      and single quotes better in several instances, including in \code
      and \samp expressions.

    * utils::modifyList() gets a new argument keep.null allowing NULL
      components in the replacement to be retained, instead of causing
      corresponding components to be deleted.

    * tools::pkgVignettes() gains argument check; if set to TRUE, it
      will warn when it appears a vignette requests a non-existent
      vignette engine.

  UTILITIES:

    * R CMD check --as-cran checks the line widths in usage and
      examples sections of the package Rd files.

    * R CMD check --as-cran now implies --timings.

    * R CMD check looks for command gfile if a suitable file is not
      found.  (Although file is not from GNU, OpenCSW on Solaris
      installs it as gfile.)

    * R CMD build (with the internal tar) checks the permissions of
      configure and cleanup files and adds execute permission to the
      recorded permissions for these files if needed, with a warning.
      This is useful on OSes and file systems which do not support
      execute permissions (notably, on Windows).

    * R CMD build now weaves and tangles all vignettes, so suggested
      packages are not required during package installation if the
      source tarball was prepared with current R CMD build.

    * checkFF() (used by R CMD check) does a better job of detecting
      calls from other packages, including not reporting those where a
      function has been copied from another namespace (e.g. as a
      default method).  It now reports calls where .NAME is a symbol
      registered in another package.

    * On Unix-alike systems, R CMD INSTALL now installs packages group
      writably whenever the library (lib.loc) is group writable.
      Hence, update.packages() works for other group members (suggested
      originally and from a patch by Dirk Eddelbuettel).

    * R CMD javareconf now supports the use of symbolic links for
      JAVA_HOME on platforms which have realpath.  So it is now
      possible to use

      R CMD javareconf JAVA_HOME=/usr/lib/jvm/java-1.7.0

      on a Linux system and record that value rather than the
      frequently-changing full path such as
      /usr/lib/jvm/java-1.7.0-openjdk-1.7.0.25.x86_64.

    * (Windows only.) Rscript -e requires a non-empty argument for
      consistency with Unix versions of R.  (Also Rterm -e and R -e.)

    * R CMD check does more thorough checking of declared packages and
      namespaces.  It reports

        * packages declared in more than one of the Depends, Imports,
          Suggests and Enhances fields of the DESCRIPTION file.

        * namespaces declared in Imports but not imported from, neither
          in the NAMESPACE file nor using the :: nor ::: operators.

        * packages which are used in library() or requires() calls in
          the R code but were already put on the search path _via_
          Depends.

        * packages declared in Depends not imported _via_ the NAMESPACE
          file (except the standard packages).  Objects used from
          Depends packages should be imported to avoid conflicts and to
          allow correct operation when the namespace is loaded but not
          attached.

        * objects imported _via_ ::: calls where :: would do.

        * objects imported by :: which are not exported.

        * objects imported by ::: calls which do not exist.

      See 'Writing R Extensions' for good practice.

    * R CMD check optionally checks for non-standard top-level files
      and directories (which are often mistakes): this is enabled for
      --as-cran.

    * LaTeX style file upquote.sty is no longer included (the version
      was several years old): it is no longer used in R.  A much later
      version is commonly included in LaTeX distributions but does not
      play well with the ae fonts which are the default for Sweave
      vignettes.

    * R CMD build makes more use of the build sub-directory of package
      sources, for example to record information about the vignettes.

  INSTALLATION and INCLUDED SOFTWARE:

    * The macros used for the texinfo manuals have been changed to work
      better with the incompatible changes made in texinfo 5.x.

    * The minimum version for a system xz library is now 5.0.3 (was
      4.999).  This is in part to avoid 5.0.2, which can compress in
      ways other versions cannot decompress.

    * The included version of PCRE has been updated to 8.33.

    * The included version of zlib has been updated to 1.2.8, a bug-fix
      release.

    * The included version of xz utils's liblzma has been updated to
      5.0.5.

    * Since javareconf (see above) is used when R is installed, a
      stable link for JAVA_HOME can be supplied then.

    * Configuring with --disable-byte-compilation will override the
      DESCRIPTION files of recommended packages, which typically
      require byte-compilation.

    * More of the installation and checking process will work even when
      TMPDIR is set to a path containing spaces, but this is not
      recommended and external software (such as texi2dvi) may fail.

  PACKAGE INSTALLATION:

    * Installation is aborted immediately if a LinkingTo package is not
      installed.

    * R CMD INSTALL has a new option --no-byte-compile which will
      override a ByteCompile field in the package's DESCRIPTION file.

    * License BSD is deprecated: use BSD_3_clause or BSD_2_clause
      instead.

      License X11 is deprecated: use MIT or BSD_2_clause instead.

    * Version requirements for LinkingTo packages are now recognized:
      they are checked at installation.  (Fields with version
      requirements were previously silently ignored.)

    * The limit of 500 S3method entries in a NAMESPACE file has been
      removed.

    * The default 'version' of Bioconductor for its packages has been
      changed to the upcoming 2.13, but this can be set by the
      environment variable R_BIOC_VERSION, e.g.  in file Renviron.site.

  C-LEVEL FACILITIES:

    * Rdefines.h has been tweaked so it can be included in C++ code
      after R_ext/Boolean.h (which is included by R.h).

      Note that Rdefines.h is not kept up-to-date, and Rinternals.h is
      preferred for new code.

    * eval and applyClosure are now protected against package code
      supplying an invalid rho.

  DEPRECATED AND DEFUNCT:

    * The unused namespace argument to package.skeleton() is now
      formally deprecated and will be removed in R 3.1.0.

    * plclust() is deprecated: use the plot() method for class "hclust"
      instead.

    * Functions readNEWS() and checkNEWS() in package tools are
      deprecated (and they have not worked with current NEWS files for
      a long time).

  DOCUMENTATION:

    * 'An Introduction to R' has a new chapter on using R as a
      scripting language including interacting with the OS.

  BUG FIXES:

    * help.request() could not determine the current version of R on
      CRAN.  (PR#15241)

    * On Windows, file.info() failed on root directories unless the
      path was terminated with an explicit ".".  (PR#15302)

    * The regmatches<-() replacement function mishandled results coming
      from regexpr().  (PR#15311)

    * The help for setClass() and representation() still suggested the
      deprecated argument representation=. (PR#15312)

    * R CMD config failed in an installed build of R 3.0.1 (only) when
      a sub-architecture was used.  (Reported by Berwin Turlach.)

    * On Windows, the installer modified the etc/Rconsole and
      etc/Rprofile.site files even when default options were chosen, so
      the MD5 sums did not refer to the installed versions.  (Reported
      by Tal Galili.)

    * plot(hclust(), cex =) respects cex again (and possibly others
      similarly).  (Reported by Peter Langfelder.)

    * If multiple packages were checked by R CMD check, and one was
      written for a different OS, it would set --no-install for all
      following packages as well as itself.

    * qr.coef() and related functions did not properly coerce real
      vectors to complex when necessary.  (PR#15332)

    * ftable(a) now fixes up empty dimnames such that the result is
      printable.

    * package.skeleton() was not starting its search for function
      objects in the correct place if environment was supplied.
      (Reported by Karl Forner.)

    * Parsing code was changing the length field of vectors and
      confusing the memory manager.  (PR#15345)

    * The Fortran routine ZHER2K in the reference BLAS had a
      comment-out bug in two places.  This caused trouble with eigen()
      for Hermitian matrices.  (PR#15345 and report from Robin Hankin)

    * vignette() and browseVignettes() did not display non-Sweave
      vignettes properly.

    * Two warning/error messages have been corrected: the (optional)
      warning produced by a partial name match with a pairlist, the
      error message from a zero-length argument to the : operator.
      (Found by Radford Neal; PR#15358, PR#15356)

    * svd() returned NULL rather than omitting components as
      documented.  (Found by Radford Neal; PR#15360)

    * mclapply() and mcparallel() with silent = TRUE could break a
      process that uses stdout output unguarded against broken pipes
      (e.g., zip will fail silently). To work around such issues, they
      now replace stdout with a descriptor pointed to /dev/null
      instead. For this purpose, internal closeStdout and closeStderr
      functions have gained the to.null flag.

    * log(), signif() and round() now raise an error if a single named
      argument is not named x.  (PR#15361)

    * deparse() now deparses raw vectors in a form that is
      syntactically correct. (PR#15369)

    * The jpeg driver in Sweave created a JPEG file, but gave it a .png
      extension. (PR#15370)

    * Deparsing of infix operators with named arguments is improved.
      (PR#15350)

    * mget(), seq.int() and numericDeriv() did not duplicate arguments
      properly. (PR#15352, PR#15353, PR#15354)

    * kmeans(algorithm = "Hartigan-Wong") now always stops iterating in
      the QTran stage. (PR#15364).

    * read.dcf() re-allocated incorrectly and so could segfault when
      called on a file with lines of more than 100 bytes.

    * On systems where mktime() does not set errno, the last second
      before the epoch could not be converted from POSIXlt to POSIXct.
      (Reported by Bill Dunlap.)

    * add1.glm() miscalculated F-statistics when df > 1. (Bill Dunlap,
      PR#15386).

    * stem() now discards infinite inputs rather than hanging.
      (PR#15376)

    * The parser now enforces C99 syntax for floating point hexadecimal
      constants (e.g. 0x1.1p0), rather than returning unintended values
      for malformed constants. (PR#15234)

    * model.matrix() now works with very long LHS names (more than 500
      bytes).  (PR#15377)

    * integrate() reverts to the pre-2.12.0 behaviour: from 2.12.0 to
      3.0.1 it sometimes failed to achieve the requested tolerance and
      reported error estimates that were exceeded.  (PR#15219)

    * strptime() now handles %W fields with value 0. (PR#15915)

    * R is now better protected against people trying to interact with
      the console in startup code.  (PR#15325)

    * Subsetting 1D arrays often lost dimnames (PR#15301).

    * Unary + on a logical vector did not coerce to integer, although
      unary - did.

    * na.omit() and na.exclude() added a row to a zero-row data frame.
      (PR#15399)

    * All the (where necessary cut-down) vignettes are installed if R
      was configured with --without-recommended-packages.

    * source() did not display filenames when reporting syntax errors.

    * Syntax error reports misplaced the caret pointing out the bad
      token.

    * (Windows only) Starting R with R (instead of Rterm or Rgui) would
      lose any zero-length strings from the command line arguments.
      (PR#15406)

    * Errors in the encoding specified on the command line via
      --encoding=foo were not handled properly.  (PR#15405)

    * If x is a symbol, is.vector(x, "name") now returns TRUE, since
      "name" and "symbol" should be synonyms.  (Reported by Herv'e
      Pag`es.)

    * R CMD rtags works on platforms (such as OS X) with a
      XSI-conformant shell command echo. (PR#15231)

    * is.unsorted(NA) returns false as documented (rather than NA).

    * R CMD LINK did not know about sub-architectures.

    * system() and system2() are better protected against users who
      misguidedly have spaces in the temporary directory path.

    * file.show() and edit() are now more likely to work on file paths
      containing spaces.  (Where external utilities are used, not the
      norm on Windows nor in R.app which should previously have
      worked.)

    * Packages using the methods package are more likely to work when
      they import it but it is not attached.  (Several parts of its C
      code were looking for its R functions on the search path rather
      than in its namespace.)

    * lgamma(-x) is no longer NaN for very small x.

    * (Windows) system2() now respects specifying stdout and stderr as
      files if called from Rgui. (PR#15393)

    * Closing an x11() device whilst locator() or identify() is in
      progress no longer hangs R.  (PR#15253)

    * list.dirs(full.names = FALSE) was not implemented.  (PR#15170)

    * format() sometimes added unnecessary spaces.  (PR#15411)

    * all.equal(check.names = FALSE) would ignore the request to ignore
      the names and would check them as attributes.

    * The symbol set by tools::Rd2txt_options(itemBullet=) was not
      respected in some locales. (PR#15435)

    * mcMap() was not exported by package parallel. (PR#15439)

    * plot() for TukeyHSD objects did not balance dev.hold() and
      dev.flush() calls on multi-page plots.  (PR#15449)

--
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From babakbsn at gmail.com  Wed Sep 25 14:22:18 2013
From: babakbsn at gmail.com (Babak Bastan)
Date: Wed, 25 Sep 2013 05:22:18 -0700
Subject: [R] Cosine window in r
Message-ID: <CAF-JZQtaWwaORg2t4NC8_TErnozAoq1t4sH+gVtuqX3wES1cDg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130925/d9e604bb/attachment.pl>

From smartpink111 at yahoo.com  Wed Sep 25 14:47:54 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 25 Sep 2013 05:47:54 -0700 (PDT)
Subject: [R] Creating a new column to a data frame using a formula from
	another variable
Message-ID: <1380113274.39827.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,

Change:
aa$z<-? eval(parse(text=bb))

?aa
#? x y? z
#1 2 3? 3
#2 4 5? 7
#3 6 7 11
A.K.

I want to create a new column to a data frame using a formula from another variable: 
Example: 
I have a data set "aa" is; 
x ? ?y 
2 ? ?3 
4 ? ?5 
6 ? ?7 

My R code is; 
>bb <- "x+y-2" 
>attach(aa) 
>aa$z<- bb 
>detach(aa) 

the result is; 
x ?y ?z 
2 ?3 ?x+y-2 
4 ?5 ?x+y-2 
6 ?7 ?x+y-2 

but I want like; 
x ?y ?z 
2 ?3 ?3 
4 ?5 ?7 
6 ?7 ?11 

Could you please help me..


From smartpink111 at yahoo.com  Wed Sep 25 14:52:23 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 25 Sep 2013 05:52:23 -0700 (PDT)
Subject: [R] Creating a new column to a data frame using a formula from
	another variable
In-Reply-To: <1380113274.39827.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <1380113274.39827.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <1380113543.33680.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Also, Instead of ?attach, you could try ?with or ?within
aa$z<- with(aa,eval(parse(text=bb)))
aa$z

#[1]? 3? 7 11

aa<- within(aa,z<- eval(parse(text=bb)))
aa
#? x y? z
#1 2 3? 3
#2 4 5? 7
#3 6 7 11
A.K.



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Wednesday, September 25, 2013 8:47 AM
Subject: Re: Re: Creating a new column to a data frame using a formula from another variable

Hi,

Change:
aa$z<-? eval(parse(text=bb))

?aa
#? x y? z
#1 2 3? 3
#2 4 5? 7
#3 6 7 11
A.K.

I want to create a new column to a data frame using a formula from another variable: 
Example: 
I have a data set "aa" is; 
x ? ?y 
2 ? ?3 
4 ? ?5 
6 ? ?7 

My R code is; 
>bb <- "x+y-2" 
>attach(aa) 
>aa$z<- bb 
>detach(aa) 

the result is; 
x ?y ?z 
2 ?3 ?x+y-2 
4 ?5 ?x+y-2 
6 ?7 ?x+y-2 

but I want like; 
x ?y ?z 
2 ?3 ?3 
4 ?5 ?7 
6 ?7 ?11 

Could you please help me..


From dushoff at mcmaster.ca  Wed Sep 25 15:10:35 2013
From: dushoff at mcmaster.ca (Jonathan Dushoff)
Date: Wed, 25 Sep 2013 09:10:35 -0400
Subject: [R] Confusing behaviour in data.table: unexpectedly changing
	variable
In-Reply-To: <11991_1380093596_r8P7JP5h014299_52428E40.60005@mdowle.plus.com>
References: <CALF-=EKbGh29Qy_PdJvJjE+Yhsf_nXcSLrt2n8fhFx5=c5HWBw@mail.gmail.com>
	<11991_1380093596_r8P7JP5h014299_52428E40.60005@mdowle.plus.com>
Message-ID: <CALF-=E+DESqicU587bkjV123r6vQnaL8u5FbmpmpaQKPBHeNBA@mail.gmail.com>

Thanks for your help, and sorry for mis-posting.

JD

On Wed, Sep 25, 2013 at 3:18 AM, Matthew Dowle <mdowle at mdowle.plus.com> wrote:

> Very sorry to hear this bit you.  If you need a copy of names before
> changing them by reference :

>     oldnames <- copy(names(DT))

> This will be documented and it's on the bug list to do so. copy is needed in
> other circumstances too, see ?copy.

> More details here :

> http://stackoverflow.com/questions/18662715/colnames-being-dropped-in-data-table-in-r
> http://stackoverflow.com/questions/15913417/why-does-data-table-update-namesdt-by-reference-even-if-i-assign-to-another-v


From flipjribeiro at hotmail.com  Wed Sep 25 14:23:04 2013
From: flipjribeiro at hotmail.com (Filipe Ribeiro)
Date: Wed, 25 Sep 2013 14:23:04 +0200
Subject: [R] MaxLik estimation issues
Message-ID: <BLU0-SMTP6815963BC2241F40F0D22BDE2F0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130925/1fd20266/attachment.pl>

From rd023411 at ohio.edu  Wed Sep 25 12:55:43 2013
From: rd023411 at ohio.edu (steric)
Date: Wed, 25 Sep 2013 03:55:43 -0700 (PDT)
Subject: [R] Checking a large data set for normality
In-Reply-To: <7B38DB6E-A1C9-43B6-BEED-6836BF4796D2@comcast.net>
References: <1380041060625-4676858.post@n4.nabble.com>
	<7B38DB6E-A1C9-43B6-BEED-6836BF4796D2@comcast.net>
Message-ID: <1380106543656-4676917.post@n4.nabble.com>

It was just a question to see if it was possible on a large data set. I
wasn't looking for a flame war. New strategy is simply new strategy. Half of
my time spent on R is trying to find a better way.



--
View this message in context: http://r.789695.n4.nabble.com/Checking-a-large-data-set-for-normality-tp4676858p4676917.html
Sent from the R help mailing list archive at Nabble.com.


From jpalves at isec.pt  Wed Sep 25 15:00:25 2013
From: jpalves at isec.pt (=?ISO-8859-1?Q?Jo=E3o_Pedro_Alves?=)
Date: Wed, 25 Sep 2013 14:00:25 +0100
Subject: [R] Cosine window in r
In-Reply-To: <CAF-JZQtaWwaORg2t4NC8_TErnozAoq1t4sH+gVtuqX3wES1cDg@mail.gmail.com>
References: <CAF-JZQtaWwaORg2t4NC8_TErnozAoq1t4sH+gVtuqX3wES1cDg@mail.gmail.com>
Message-ID: <5242DE69.60000@isec.pt>

x<-seq(0,2*pi,by=0.01)
y<-cos(x)
plot(x,y,type='l')

On 25-09-2013 13:22, Babak Bastan wrote:
> Hi experts
>
> Can some one tell me, how can I implement Cosine window in r? Is there a
> function for that?
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Haiko.Lietz at gesis.org  Wed Sep 25 15:10:40 2013
From: Haiko.Lietz at gesis.org (Lietz, Haiko)
Date: Wed, 25 Sep 2013 13:10:40 +0000
Subject: [R] Multiple vector elements into one character element
Message-ID: <D57FB3A7BE5E14479A21F7832D5F1B341EB60988@svboexc02.gesis.intra>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130925/7fa76ddf/attachment.pl>

From Frederick.Mills at fda.hhs.gov  Wed Sep 25 15:47:41 2013
From: Frederick.Mills at fda.hhs.gov (Mills, Frederick)
Date: Wed, 25 Sep 2013 13:47:41 +0000
Subject: [R] grImport problems in Windows
Message-ID: <CE6861DC.DE7C%frederick.mills@fda.hhs.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130925/3c04eba4/attachment.pl>

From gunter.berton at gene.com  Wed Sep 25 16:31:00 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 25 Sep 2013 07:31:00 -0700
Subject: [R] Creating a new column to a data frame using a formula from
 another variable
In-Reply-To: <1380113543.33680.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1380113274.39827.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1380113543.33680.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <CACk-te1hJgqr1eRi02rienuhUWQMbkgd6fL_LcHYzZCyg_PNuQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130925/04631428/attachment.pl>

From gunter.berton at gene.com  Wed Sep 25 16:36:04 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 25 Sep 2013 07:36:04 -0700
Subject: [R] Multiple vector elements into one character element
In-Reply-To: <D57FB3A7BE5E14479A21F7832D5F1B341EB60988@svboexc02.gesis.intra>
References: <D57FB3A7BE5E14479A21F7832D5F1B341EB60988@svboexc02.gesis.intra>
Message-ID: <CACk-te0xhwHh08r2Tg3bQEgrsF55G8NfjGAo3iwnBy7S=txQZw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130925/f7c5171a/attachment.pl>

From smartpink111 at yahoo.com  Wed Sep 25 16:57:11 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 25 Sep 2013 07:57:11 -0700 (PDT)
Subject: [R] Multiple vector elements into one character element
In-Reply-To: <D57FB3A7BE5E14479A21F7832D5F1B341EB60988@svboexc02.gesis.intra>
References: <D57FB3A7BE5E14479A21F7832D5F1B341EB60988@svboexc02.gesis.intra>
Message-ID: <1380121031.50890.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,

May be this helps:
y<- aggregate(Day~Month,data=x,paste,collapse=",")
write.table(y,"file.txt",quote=FALSE)


A.K.



----- Original Message -----
From: "Lietz, Haiko" <Haiko.Lietz at gesis.org>
To: "'r-help at r-project.org'" <r-help at r-project.org>
Cc: 
Sent: Wednesday, September 25, 2013 9:10 AM
Subject: [R] Multiple vector elements into one character element

Hi all,

I want to collapse multiple elements of a vector into a single comma-separated character element. I only know how to create a list of the original elements, but I have not managed to write this into a text file, which is necessary.

To illustrate, let's use the airquality dataset and extract the Month and Day columns:

library(datasets)
x <- data.frame(Month = airquality$Month, Day = as.character(airquality$Day))

Using the aggregate function

y <- aggregate(x$Day ~ x$Month, data = x, paste)

only seemingly creates what I want because the list can't be written to a file.

"1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31" for the first row should actually be a character element.

I've tried it but sapply, ascii, write.matrix don't seem get me there.

Can someone please point me towards the function I need?

Best wishes

Haiko


Haiko Lietz
GESIS - Leibniz Institute for the Social Sciences
Unter Sachsenhausen 6-8, D-50667 K?ln
Tel: + 49 (0) 221 / 476 94 -223
eMail: haiko.lietz at gesis.org<mailto:haiko.lietz at gesis.org>
Web: http://www.gesis.org


??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Wed Sep 25 17:34:03 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 25 Sep 2013 08:34:03 -0700 (PDT)
Subject: [R] Computing calculation among two vectors
In-Reply-To: <1380092937.65850.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <1380092937.65850.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <1380123243.29602.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
You could also try:
res1<-sapply(y,function(i) {x1<- expand.grid(x,x);fun1<- function(a,op,b){ f1<- match.fun(FUN=op); f1(a,b)};fun1(x1[,1],i,x1[,2])})
row.names(res1)<- row.names(res)
?identical(res1,res)
#[1] TRUE
A.K.




----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Wednesday, September 25, 2013 3:08 AM
Subject: Re: Computing calculation among two vectors

Hi,
Try:
x<- 1:4
?y<- c("*","/","-","+")
res<-sapply(y,function(i) {x1<-expand.grid(x,x); unlist(lapply(paste0(x1[,1],i,x1[,2]),function(u) eval(parse(text=u))))})
row.names(res)<- as.character(interaction(expand.grid(x,x),sep="_"))

head(res)
#??? *?? /? - +
#1_1 1 1.0? 0 2
#2_1 2 2.0? 1 3
#3_1 3 3.0? 2 4
#4_1 4 4.0? 3 5
#1_2 2 0.5 -1 3
#2_2 4 1.0? 0 4


A.K.



I have two vectors one numeric and another with operand. 

Eg: x - 1,2,3,4 and y-"*", "/", "-", "+" 

I need to calculate all the possible two combinations in x with 
each of operand in y. As example, 1*2, 1/2, 1-2, 1+2, 1*3, 1/3.... 

Any help appreciated. 

Regards 
Hussain


From gunter.berton at gene.com  Wed Sep 25 17:46:49 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 25 Sep 2013 08:46:49 -0700
Subject: [R] Computing calculation among two vectors
In-Reply-To: <1380123243.29602.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <1380092937.65850.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1380123243.29602.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <CACk-te0buGd2Q3BbkcHkNNgeosz-Tq9aj8q9Lcyg9-S06dqo1A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130925/658b6d9e/attachment.pl>

From bartjoosen at hotmail.com  Wed Sep 25 18:30:02 2013
From: bartjoosen at hotmail.com (Bart Joosen)
Date: Wed, 25 Sep 2013 16:30:02 +0000
Subject: [R] animate dataframe
Message-ID: <SNT145-W79A7FD62888351B98DE99D82F0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130925/e5df9494/attachment.pl>

From bartjoosen at hotmail.com  Wed Sep 25 18:32:41 2013
From: bartjoosen at hotmail.com (Bart Joosen)
Date: Wed, 25 Sep 2013 16:32:41 +0000
Subject: [R] Animate dataframe
Message-ID: <SNT145-W241E7FB0263EDEAADAE73ED82F0@phx.gbl>

Hi,
 
sorry for the double posting, but it seems my text was gone...

I'm running a code which does some alignment between data.
Now I want to follow the alignment while looping over the data.
 
I'm aware of the animation package, and saw the (easy) example where a plot
is animated by calling 100 times plot.
 
Is it possible to use this trick also for printing a dataframe to the
graphics device?
I tried already addtable2plot, but the table doesn't fit in the graphics
device (or I'm doing something wrong).
 
Here a simplified example of how the data looks and how it is filled:
 
dat <- data.frame(rows=rep(1:10, 15), columns=rep(1:15, each=10), result=NA)
dat$result <- NA
i = 0
while (!all(!is.na(dat$result))) {
	i = i + 1
	if (i==100) break
	dat$result[sample(1:nrow(dat),1)] <- rnorm(1)
}
 
in each loop should be something like:
print(as.data.frame(tapply(dat$result,list(rows=dat$rows,columns=dat$columns),
function(x) paste(x[x!=""],collapse="/"))))
 
Thanks
 
Bart
PS: I know that I can use a for loop instead of the while and if (i==100)
break construction, but hey, its an example, right? ;-) 		 	   		  

From smartpink111 at yahoo.com  Wed Sep 25 18:55:29 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 25 Sep 2013 09:55:29 -0700 (PDT)
Subject: [R] Computing calculation among two vectors
In-Reply-To: <CACk-te0buGd2Q3BbkcHkNNgeosz-Tq9aj8q9Lcyg9-S06dqo1A@mail.gmail.com>
References: <1380092937.65850.YahooMailNeo@web142606.mail.bf1.yahoo.com>	<1380123243.29602.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CACk-te0buGd2Q3BbkcHkNNgeosz-Tq9aj8q9Lcyg9-S06dqo1A@mail.gmail.com>
Message-ID: <1380128129.34111.YahooMailNeo@web142603.mail.bf1.yahoo.com>

I guess you meant something like:
res2<- sapply(y,function(i) outer(x,x,i))
row.names(res2)<- row.names(res)
?identical(res2,res)
#[1] TRUE
#or is there any shorter way?

A.K.



________________________________
From: Bert Gunter <gunter.berton at gene.com>
To: arun <smartpink111 at yahoo.com> 
Cc: R help <r-help at r-project.org> 
Sent: Wednesday, September 25, 2013 11:46 AM
Subject: Re: [R] Computing calculation among two vectors



A cute problem. Is it homework?

Hint: ?outer

(will provide a much simpler solution than those given below)


-- Bert



On Wed, Sep 25, 2013 at 8:34 AM, arun <smartpink111 at yahoo.com> wrote:

Hi,
>You could also try:
>res1<-sapply(y,function(i) {x1<- expand.grid(x,x);fun1<- function(a,op,b){ f1<- match.fun(FUN=op); f1(a,b)};fun1(x1[,1],i,x1[,2])})
>row.names(res1)<- row.names(res)
>?identical(res1,res)
>#[1] TRUE
>A.K.
>
>
>
>
>----- Original Message -----
>From: arun <smartpink111 at yahoo.com>
>To: R help <r-help at r-project.org>
>Cc:
>Sent: Wednesday, September 25, 2013 3:08 AM
>Subject: Re: Computing calculation among two vectors
>
>Hi,
>Try:
>x<- 1:4
>?y<- c("*","/","-","+")
>res<-sapply(y,function(i) {x1<-expand.grid(x,x); unlist(lapply(paste0(x1[,1],i,x1[,2]),function(u) eval(parse(text=u))))})
>row.names(res)<- as.character(interaction(expand.grid(x,x),sep="_"))
>
>head(res)
>#??? *?? /? - +
>#1_1 1 1.0? 0 2
>#2_1 2 2.0? 1 3
>#3_1 3 3.0? 2 4
>#4_1 4 4.0? 3 5
>#1_2 2 0.5 -1 3
>#2_2 4 1.0? 0 4
>
>
>A.K.
>
>
>
>I have two vectors one numeric and another with operand.
>
>Eg: x - 1,2,3,4 and y-"*", "/", "-", "+"
>
>I need to calculate all the possible two combinations in x with
>each of operand in y. As example, 1*2, 1/2, 1-2, 1+2, 1*3, 1/3....
>
>Any help appreciated.
>
>Regards
>Hussain
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>


-- 


Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:

http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From andrewhaddonkemp at gmail.com  Wed Sep 25 16:29:35 2013
From: andrewhaddonkemp at gmail.com (Andrew Kemp)
Date: Wed, 25 Sep 2013 11:29:35 -0300
Subject: [R] error when using ps() function on categorical variables - re
 propensity score matching
In-Reply-To: <CE6876D8.1C2F4%andrewhaddonkemp@gmail.com>
Message-ID: <CE687828.1C2F6%andrewhaddonkemp@gmail.com>


Dear List,

I am having difficulty running the ps() function when variables are stored
as factors and was hoping someone could provide some advice on how to
proceed.

I am running propensity score matching as outlined in:

	Greg Ridgeway, Dan McCarey, Andrew Morral, Lane Burgette and Beth Ann
Grin (May 3, 2013) Toolkit for Weighting and Analysis of Nonequivalent
Groups: A tutorial for the twang package

and have a question about using unordered categorical variables as a
covariates. The tutorial indicates that:

 "There is no need to ? create indicator, or dummy coded, variables to
represent categorical covariates, provided the categorical variables are
stored as a factor  or as ordered? "

However, when I run the ps() function after converting categorical
variables to factors using the factor() function, I return the following
warning:

 "Warning in model.matrix(glm.object) * resid(glm.object, "working") :
longer object length is not a multiple of shorter object length"

and followed by an error:

 "Error in x$fpc$sampsize[i, , drop = FALSE] :  (subscript) logical
subscript too long"

Interestingly, the code runs without warning or error when variables are
not converted to factors.

Thanks in advance!


ANDREW H. KEMP, PhD
Invited International Visiting Professor, University of S?o Paulo
Associate Professor, University of Sydney


From sahnerolle at gmx.net  Wed Sep 25 16:43:42 2013
From: sahnerolle at gmx.net (sahnerolle)
Date: Wed, 25 Sep 2013 07:43:42 -0700 (PDT)
Subject: [R] drc - package
Message-ID: <1380120222373-4676924.post@n4.nabble.com>

Hi,

my english is not the best, i hope its comprehensible. Can i ask here in
german too?

my problem:
I have plottet a curve with weibull1.4. I want to define a value on the
y-axis and get the value of the x-axis for the plotted curve.

This is my command:

library(drc)
effect<-c(0,22.84,40.74,54.63,62.04,59.26)
conc<-c(0,90,150,260,440,750)
drm(effect~conc,fct=W1.4())
model<-drm(effect~conc,fct=W1.4())
summary(model)
plot(model)
ED(model,c(50),interval='delta')

With: "ED(model,c(50),interval='delta')" i get a value, but it is not on the
fitted curve. What to do?

Thanks
Fabian



--
View this message in context: http://r.789695.n4.nabble.com/drc-package-tp4676924.html
Sent from the R help mailing list archive at Nabble.com.


From jerrelharlanmast at gmail.com  Wed Sep 25 17:39:19 2013
From: jerrelharlanmast at gmail.com (Rui Wang)
Date: Wed, 25 Sep 2013 10:39:19 -0500
Subject: [R] How to fix col.regions mapping in multiple spplot?
Message-ID: <CAEgan+-L9mJ+7coqr-ALGx31Rt8HskUviO+bN6T9XM5rd+cmxQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130925/92cc182a/attachment.pl>

From Haiko.Lietz at gesis.org  Wed Sep 25 20:03:37 2013
From: Haiko.Lietz at gesis.org (Lietz, Haiko)
Date: Wed, 25 Sep 2013 18:03:37 +0000
Subject: [R]  Re: Multiple vector elements into one character element
Message-ID: <D57FB3A7BE5E14479A21F7832D5F1B341EB60A18@svboexc02.gesis.intra>

Hi A.K.,

This is exactly what I needed:

x <- data.frame(Month = airquality$Month, Day = as.character(airquality$Day))
y <- aggregate(x$Day ~ x$Month, data = x, paste, collapse = ", ")
write.table(y, "y.txt", row.names = FALSE, quote = FALSE, sep = '\t')

The trick is to use collapse in the aggregate function.

Many thanks

Haiko

P.S.: Bert, dput writes R code so that's not what I needed. But many thanks also!


________________________________________
Von: r-help-bounces at r-project.org [r-help-bounces at r-project.org]&quot; im Auftrag von &quot;arun [smartpink111 at yahoo.com]
Gesendet: Mittwoch, 25. September 2013 16:57
An: R help
Betreff: Re: [R] Multiple vector elements into one character element

Hi,

May be this helps:
y<- aggregate(Day~Month,data=x,paste,collapse=",")
write.table(y,"file.txt",quote=FALSE)


A.K.



----- Original Message -----
From: "Lietz, Haiko" <Haiko.Lietz at gesis.org>
To: "'r-help at r-project.org'" <r-help at r-project.org>
Cc:
Sent: Wednesday, September 25, 2013 9:10 AM
Subject: [R] Multiple vector elements into one character element

Hi all,

I want to collapse multiple elements of a vector into a single comma-separated character element. I only know how to create a list of the original elements, but I have not managed to write this into a text file, which is necessary.

To illustrate, let's use the airquality dataset and extract the Month and Day columns:

library(datasets)
x <- data.frame(Month = airquality$Month, Day = as.character(airquality$Day))

Using the aggregate function

y <- aggregate(x$Day ~ x$Month, data = x, paste)

only seemingly creates what I want because the list can't be written to a file.

"1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31" for the first row should actually be a character element.

I've tried it but sapply, ascii, write.matrix don't seem get me there.

Can someone please point me towards the function I need?

Best wishes

Haiko


Haiko Lietz
GESIS - Leibniz Institute for the Social Sciences
Unter Sachsenhausen 6-8, D-50667 K?ln
Tel: + 49 (0) 221 / 476 94 -223
eMail: haiko.lietz at gesis.org<mailto:haiko.lietz at gesis.org>
Web: http://www.gesis.org


    [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From erich.neuwirth at univie.ac.at  Wed Sep 25 21:46:47 2013
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Wed, 25 Sep 2013 21:46:47 +0200
Subject: [R] Slight misinformation in OSX version of R
Message-ID: <4FF4F895-AC55-4F9A-B402-A9F9C7C9D1D4@univie.ac.at>

I just installed R on a Mac without any traces of earlier versions.
It exhibited a well know problem:

WARNING: You're using a non-UTF8 locale, therefore only ASCII characters will work.
Please read R for Mac OS X FAQ (see Help) section 9 and adjust your system preferences accordingly.

The information needed is in section 7, not in section 9.


From smartpink111 at yahoo.com  Wed Sep 25 22:24:57 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 25 Sep 2013 13:24:57 -0700 (PDT)
Subject: [R] Best and worst values for each date
In-Reply-To: <52431566.8030700@yahoo.com>
References: <52431566.8030700@yahoo.com>
Message-ID: <1380140697.89069.YahooMailNeo@web142606.mail.bf1.yahoo.com>



Hi,
May be you can try this:

obj_name<- load("arun.RData")
Pred1<- get(obj_name[1])
Actual1<- get(obj_name[2])
library(reshape2)
dat<-cbind(melt(Pred1,id.vars="S1"),value2=melt(Actual1,id.vars="S1")[,3])? # to reshape to long form
colnames(dat)[3:4]<- c("Predict","Actual")
dat$variable<- as.character(dat$variable) #not that needed
dat1<-? dat[!(is.na(dat$Predict)|is.na(dat$Actual)),] # removes the NA values in columns "Predict" and "Actual"


res<- do.call(rbind,lapply(split(dat1,dat1$S1),function(x){x1<-x[order(x$Predict),]

??? ??? ??? ??? ??? ??? ????????????? xlow<-if(sum(x1$Predict<0) <5){? #in cases where you don't have 5 negative numbers

???????????????????????????????????????????????? x1[x1$Predict<0,]
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? }
???????????????????????????????????????????? else? {
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? x1[x1$Predict<0,][1:5,]? # select first five rows?? ? 

? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ?}
??? ??? ??? ??? ??? ??? ??? ??? ??? ? ? ?? xhigh<- if(sum(x1$Predict>0) <5){ #not having 5 postive numbers

??????????????????????????????????????????????? ? x1[x1$Predict>0,]}
????????????????????????????????????????????????? else {
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? tail(x1[x1$Predict>0,],5)

? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?? } ? 

? ? ? ? ? ? ? ? ?????rbind(xhigh[rev(order(xhigh$Predict)),],xlow)}))? ##reverse the order of high values 
?dim(res)
#[1] 480?? 4



A.K.

________________________________
From: Ira Sharenow <irasharenow100 at yahoo.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Wednesday, September 25, 2013 12:55 PM
Subject: Best and worst values for each date



Arun,

I hope you have been doing well.

I have a new problem.

I have two data frames, one for predictions and one for the actual returns.

Each day I act on the returns that have the 5 highest values and the five lowest values. I then want to compare to the actual values. So I need to subset my two original data frames so that the stocks and their prices that remain after each day are the ones I want. At the end of filtering there will be one data frame for predictions and one data frame for actual values.

Now for an enhancement. NA values cannot be part of the reduced data frames but will occur in great proportion in the original data frames. Each day I need to check that the top five are positive; otherwise I need to reduce that number as needed. Similarly I need for the bottom five are negative. At the end of 50 days each original data frame will have 5 * 2 * 50 = 500 rows, but this step may reduce that number.

I attached a smallish file with the two data frames. The real ones have hundreds of columns and over 1,000 rows.

Please aim for simplicity. If the solution is complex, please explain.


Do you want me to use a different email address?


Thanks.

Ira

Example. But the stocks are not set up this way.

The highlighted stocks are in the first data frames.



Predict Actual 
1/3/2006 S1 3 -1.943 
1/3/2006 S20 4 10.376 
1/3/2006 S3 2 8.611 
1/3/2006 S4 1 7.465 
1/3/2006 S5 0 1.648 
1/3/2006 S6 -1 5.36 
1/3/2006 S7 -2 4.36 
1/3/2006 S8 -3 3.574 
1/3/2006 S9 -4 2.748 
1/3/2006 S10 -5 1.933 
1/3/2006 S11 -6 0.548 
1/3/2006 S12 -7 -0.66 
1/3/2006 S13 -8 -1.793 
1/3/2006 S14 -9 -2.163 
1/3/2006 S15 -10 -3.077 
1/3/2006 S16 -11 -4.723 
1/3/2006 S17 -12 -5.919 
1/3/2006 S18 -13 -6.529 
1/3/2006 S19 -14 -7.979 
1/3/2006 S20 -15 -8.064 


After making sure only positives are in for top 5 predictions and only negatives for the bottom 5 predictions
1/3/2006 S1 3 -1.943 
1/3/2006 S20 4 10.376 
1/3/2006 S3 2 8.611 
1/3/2006 S4 1 7.465 
1/3/2006 S16 -11 -4.723 
1/3/2006 S17 -12 -5.919 
1/3/2006 S18 -13 -6.529 
1/3/2006 S19 -14 -7.979 
1/3/2006 S20 -15 -8.064 

Note that the next day different stocks may be selected. Also there cannot any NA in either the Predict or Actual columns.?????????? ???????


From davies.trevor at gmail.com  Wed Sep 25 23:11:44 2013
From: davies.trevor at gmail.com (Trevor Davies)
Date: Wed, 25 Sep 2013 14:11:44 -0700
Subject: [R] weighting in glmmadmb(family='nbinom') with RE
Message-ID: <CAJhyqVj8QhxCN1W4rC3+xqoqnaLbNsQj74FOUX7VrxrtCnY6EA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130925/31cad964/attachment.pl>

From bbolker at gmail.com  Wed Sep 25 23:29:42 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 25 Sep 2013 21:29:42 +0000
Subject: [R] Slight misinformation in OSX version of R
References: <4FF4F895-AC55-4F9A-B402-A9F9C7C9D1D4@univie.ac.at>
Message-ID: <loom.20130925T232852-570@post.gmane.org>

Erich Neuwirth <erich.neuwirth <at> univie.ac.at> writes:

> 
> I just installed R on a Mac without any traces of earlier versions.
> It exhibited a well know problem:
> 
> WARNING: You're using a non-UTF8 locale, therefore only ASCII
>  characters will work.
> Please read R for Mac OS X FAQ (see Help) section 9 and 
> adjust your system preferences accordingly.
> 
> The information needed is in section 7, not in section 9.
> 

  You should probably post this to r-devel, where it is slightly
more likely that an R-core member will see it and fix the docs.
(Small fixes like this are apparently preferred on R-devel to
in the R bug tracker .)


From ripley at stats.ox.ac.uk  Wed Sep 25 23:47:13 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 25 Sep 2013 22:47:13 +0100
Subject: [R] Slight misinformation in OSX version of R
In-Reply-To: <loom.20130925T232852-570@post.gmane.org>
References: <4FF4F895-AC55-4F9A-B402-A9F9C7C9D1D4@univie.ac.at>
	<loom.20130925T232852-570@post.gmane.org>
Message-ID: <524359E1.305@stats.ox.ac.uk>

On 25/09/2013 22:29, Ben Bolker wrote:
> Erich Neuwirth <erich.neuwirth <at> univie.ac.at> writes:
>
>>
>> I just installed R on a Mac without any traces of earlier versions.
>> It exhibited a well know problem:

Not 'well known' (sic) at all: most of us do not break our OS X.  We 
don't have reproduction instructions (see the posting guide), but I bet 
this is from R.app and not R (see below).  R.app is a separate project 
with separate maintainers.

>> WARNING: You're using a non-UTF8 locale, therefore only ASCII
>>   characters will work.
>> Please read R for Mac OS X FAQ (see Help) section 9 and
>> adjust your system preferences accordingly.
>>
>> The information needed is in section 7, not in section 9.
>>
>
>    You should probably post this to r-devel, where it is slightly
> more likely that an R-core member will see it and fix the docs.
> (Small fixes like this are apparently preferred on R-devel to
> in the R bug tracker .)

But actually R-sig-mac for issues with R.app: see the posting guide.  (I 
don't think it is the docs which need fixing, but R.app itself. And that 
string is translated, so the translations need changing too.)


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rolf.turner at xtra.co.nz  Thu Sep 26 00:21:44 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Thu, 26 Sep 2013 10:21:44 +1200
Subject: [R] Checking a large data set for normality
In-Reply-To: <7B38DB6E-A1C9-43B6-BEED-6836BF4796D2@comcast.net>
References: <1380041060625-4676858.post@n4.nabble.com>
	<7B38DB6E-A1C9-43B6-BEED-6836BF4796D2@comcast.net>
Message-ID: <524361F8.1080004@xtra.co.nz>

On 09/25/13 16:10, David Winsemius wrote:

<SNIP>

> There is quite a bit of misinformation about the "need for normality", 
> some of it presented by Six Sigma "experts" or even by college 
> professors who should know better. One might even say that if you 
> don't know how to check for normality then there is a high likelihood 
> that you should not be doing so.
>

Fortune nomination!

     cheers,

     Rolf


From rolf.turner at xtra.co.nz  Thu Sep 26 00:27:51 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Thu, 26 Sep 2013 10:27:51 +1200
Subject: [R] Cosine window in r
In-Reply-To: <5242DE69.60000@isec.pt>
References: <CAF-JZQtaWwaORg2t4NC8_TErnozAoq1t4sH+gVtuqX3wES1cDg@mail.gmail.com>
	<5242DE69.60000@isec.pt>
Message-ID: <52436367.5070308@xtra.co.nz>



I'm pretty sure that your answer has nothing to do with what the OP was 
asking about.

OTOH it's up to the OP to make it clear what he ***is*** asking and he 
did not do that.

     cheers,

     Rolf Turner

On 09/26/13 01:00, Jo?o Pedro Alves wrote:
> x<-seq(0,2*pi,by=0.01)
> y<-cos(x)
> plot(x,y,type='l')
>
> On 25-09-2013 13:22, Babak Bastan wrote:
>> Hi experts
>>
>> Can some one tell me, how can I implement Cosine window in r? Is there a
>> function for that?


From smartpink111 at yahoo.com  Thu Sep 26 00:35:51 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 25 Sep 2013 15:35:51 -0700 (PDT)
Subject: [R] Best and worst values for each date
In-Reply-To: <1380140697.89069.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <52431566.8030700@yahoo.com>
	<1380140697.89069.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <1380148551.59941.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Ira,

You may try also with ?ddply()

dat2<- data.frame(S1=rep(Pred1[,1],ncol(Pred1)-1),variable=rep(colnames(Pred1)[-1],each=nrow(Pred1)),Predict=unlist(Pred1[,-1],use.names=FALSE),Actual=unlist(Actual1[,-1],use.names=FALSE),stringsAsFactors=FALSE)
?identical(dat,dat2)
#[1] TRUE
dat2New<- dat2[!(is.na(dat2$Predict)|is.na(dat2$Actual)),]
?dat3<- dat2New[order(dat2New$S1,dat2New$Predict),]
library(plyr)
?res2<- ddply(dat3,.(S1),summarize, cbind(c(head(rev(Predict),5),head(Predict,5)),c(head(rev(Actual),5),head(Actual,5)))) #in the example data this works
res2New<- data.frame(S1=res2[,1],Predict=res2[,2][,1],Actual=res2[,2][,2])
?res3<- res2New[res2New$Predict!=0,] 
row.names(res3)<- 1:nrow(res3)
?identical(res3,res[,-2])
#[1] TRUE

But, if you have fewer number of positive or negative values, then the loop method or trying individually with ?ddply would be appropriate.
A.K.





----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Ira Sharenow <irasharenow100 at yahoo.com>
Cc: R help <r-help at r-project.org>
Sent: Wednesday, September 25, 2013 4:24 PM
Subject: Re: Best and worst values for each date



Hi,
May be you can try this:

obj_name<- load("arun.RData")
Pred1<- get(obj_name[1])
Actual1<- get(obj_name[2])
library(reshape2)
dat<-cbind(melt(Pred1,id.vars="S1"),value2=melt(Actual1,id.vars="S1")[,3])? # to reshape to long form
colnames(dat)[3:4]<- c("Predict","Actual")
dat$variable<- as.character(dat$variable) #not that needed
dat1<-? dat[!(is.na(dat$Predict)|is.na(dat$Actual)),] # removes the NA values in columns "Predict" and "Actual"


res<- do.call(rbind,lapply(split(dat1,dat1$S1),function(x){x1<-x[order(x$Predict),]

??? ??? ??? ??? ??? ??? ????????????? xlow<-if(sum(x1$Predict<0) <5){? #in cases where you don't have 5 negative numbers

???????????????????????????????????????????????? x1[x1$Predict<0,]
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? }
???????????????????????????????????????????? else? {
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? x1[x1$Predict<0,][1:5,]? # select first five rows?? ? 

? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ?}
??? ??? ??? ??? ??? ??? ??? ??? ??? ? ? ?? xhigh<- if(sum(x1$Predict>0) <5){ #not having 5 postive numbers

??????????????????????????????????????????????? ? x1[x1$Predict>0,]}
????????????????????????????????????????????????? else {
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? tail(x1[x1$Predict>0,],5)

? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?? } ? 

? ? ? ? ? ? ? ? ?????rbind(xhigh[rev(order(xhigh$Predict)),],xlow)}))? ##reverse the order of high values 
?dim(res)
#[1] 480?? 4



A.K.

________________________________
From: Ira Sharenow <irasharenow100 at yahoo.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Wednesday, September 25, 2013 12:55 PM
Subject: Best and worst values for each date



Arun,

I hope you have been doing well.

I have a new problem.

I have two data frames, one for predictions and one for the actual returns.

Each day I act on the returns that have the 5 highest values and the five lowest values. I then want to compare to the actual values. So I need to subset my two original data frames so that the stocks and their prices that remain after each day are the ones I want. At the end of filtering there will be one data frame for predictions and one data frame for actual values.

Now for an enhancement. NA values cannot be part of the reduced data frames but will occur in great proportion in the original data frames. Each day I need to check that the top five are positive; otherwise I need to reduce that number as needed. Similarly I need for the bottom five are negative. At the end of 50 days each original data frame will have 5 * 2 * 50 = 500 rows, but this step may reduce that number.

I attached a smallish file with the two data frames. The real ones have hundreds of columns and over 1,000 rows.

Please aim for simplicity. If the solution is complex, please explain.


Do you want me to use a different email address?


Thanks.

Ira

Example. But the stocks are not set up this way.

The highlighted stocks are in the first data frames.



Predict Actual 
1/3/2006 S1 3 -1.943 
1/3/2006 S20 4 10.376 
1/3/2006 S3 2 8.611 
1/3/2006 S4 1 7.465 
1/3/2006 S5 0 1.648 
1/3/2006 S6 -1 5.36 
1/3/2006 S7 -2 4.36 
1/3/2006 S8 -3 3.574 
1/3/2006 S9 -4 2.748 
1/3/2006 S10 -5 1.933 
1/3/2006 S11 -6 0.548 
1/3/2006 S12 -7 -0.66 
1/3/2006 S13 -8 -1.793 
1/3/2006 S14 -9 -2.163 
1/3/2006 S15 -10 -3.077 
1/3/2006 S16 -11 -4.723 
1/3/2006 S17 -12 -5.919 
1/3/2006 S18 -13 -6.529 
1/3/2006 S19 -14 -7.979 
1/3/2006 S20 -15 -8.064 


After making sure only positives are in for top 5 predictions and only negatives for the bottom 5 predictions
1/3/2006 S1 3 -1.943 
1/3/2006 S20 4 10.376 
1/3/2006 S3 2 8.611 
1/3/2006 S4 1 7.465 
1/3/2006 S16 -11 -4.723 
1/3/2006 S17 -12 -5.919 
1/3/2006 S18 -13 -6.529 
1/3/2006 S19 -14 -7.979 
1/3/2006 S20 -15 -8.064 

Note that the next day different stocks may be selected. Also there cannot any NA in either the Predict or Actual columns.?????????? ???????


From dwinsemius at comcast.net  Thu Sep 26 01:08:40 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 25 Sep 2013 18:08:40 -0500
Subject: [R] Checking a large data set for normality
In-Reply-To: <1380106543656-4676917.post@n4.nabble.com>
References: <1380041060625-4676858.post@n4.nabble.com>
	<7B38DB6E-A1C9-43B6-BEED-6836BF4796D2@comcast.net>
	<1380106543656-4676917.post@n4.nabble.com>
Message-ID: <798CB04C-322E-4C65-8B0D-7210B547B5B6@comcast.net>


On Sep 25, 2013, at 5:55 AM, steric wrote:

> It was just a question to see if it was possible on a large data  
> set. I
> wasn't looking for a flame war. New strategy is simply new strategy.  
> Half of
> my time spent on R is trying to find a better way.
>
If you say why you want to do a global test with such a function and  
what function you had in mind for a single vector, then perhaps:

lapply( dfrm[sapply(dfrm, is.numeric)],  
your_preferred_normaility_check_fun)


If you specify the statistical issues, then there might be a more  
specific response. There is a long history of people coming to Rhelp  
asking for tests of normality and being given similar advice as I  
gave. There are also many people who mistakenly believe that you need  
normality of predictor variables to do regression.

There is en entire Task View on robust methods. There is also:

install.packages(TeachingDemos)
library(TeachingDemos)
?SnowsPenultimateNormalityTest

You are asked in the Posting Guide to do some searching of the  
archives. I use Markmail for my searches but others use the Newcastle  
search site or Rseek.

-- 
David Winsemius, MD
Alameda, CA, USA


From simen.gaure at frisch.uio.no  Wed Sep 25 21:43:50 2013
From: simen.gaure at frisch.uio.no (sgaure)
Date: Wed, 25 Sep 2013 12:43:50 -0700 (PDT)
Subject: [R] Missing value handling for felm function in lfe package
In-Reply-To: <CAKHhH04=1nswApqtrmpF0xG=MX8eBB5tFc4TR5J88AV9iHEfQA@mail.gmail.com>
References: <CAKHhH04=1nswApqtrmpF0xG=MX8eBB5tFc4TR5J88AV9iHEfQA@mail.gmail.com>
Message-ID: <1380138229991-4676941.post@n4.nabble.com>

megha patnaik wrote
> Dear All,
> 
> I am trying to use the felm function in the lfe package. However it does
> not seem to deal with missing values the way the lm function does. I wish
> to tell it na.omit or na.action = na.omit but it does not recognize this.
> I
> need to allow for missing values as I have different specifications and
> don't want to remove observations for all. Help on this will be greatly
> appreciated!

As the author of the lfe-package I will put this on my todo list. 

--
Simen Gaure



--
View this message in context: http://r.789695.n4.nabble.com/Missing-value-handling-for-felm-function-in-lfe-package-tp4674948p4676941.html
Sent from the R help mailing list archive at Nabble.com.


From marco.bee at unitn.it  Wed Sep 25 22:35:08 2013
From: marco.bee at unitn.it (Marco Bee)
Date: Wed, 25 Sep 2013 22:35:08 +0200
Subject: [R] Besag endive data
Message-ID: <524348FC.2020101@unitn.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130925/b0e3b3cc/attachment.pl>

From msamtani at gmail.com  Thu Sep 26 04:18:41 2013
From: msamtani at gmail.com (mahesh samtani)
Date: Wed, 25 Sep 2013 22:18:41 -0400
Subject: [R] Less than equal to symbol in ggplot2 legend text
Message-ID: <CAHB+C45dkR+o8ND9rzkFL=W_Yks1J1_9nfqB+AECxunY5s1DHg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130925/5504a249/attachment.pl>

From kridox at ymail.com  Thu Sep 26 04:43:21 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 26 Sep 2013 11:43:21 +0900
Subject: [R] Less than equal to symbol in ggplot2 legend text
In-Reply-To: <CAHB+C45dkR+o8ND9rzkFL=W_Yks1J1_9nfqB+AECxunY5s1DHg@mail.gmail.com>
References: <CAHB+C45dkR+o8ND9rzkFL=W_Yks1J1_9nfqB+AECxunY5s1DHg@mail.gmail.com>
Message-ID: <CAAcyNCxfE8pgEwnJWZkLGKsdg-i7-4V1Z1L_=-4HxaSeO5fgXQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/df5078d4/attachment.pl>

From harb at student.unimelb.edu.au  Thu Sep 26 05:38:27 2013
From: harb at student.unimelb.edu.au (Ben Harrison)
Date: Thu, 26 Sep 2013 13:38:27 +1000
Subject: [R] table of contents link style in R's PDF docs
Message-ID: <l20a7b$rsi$1@ger.gmane.org>

Hello,
I am mildly annoyed each time I use a PDF doc of an R package that the 
table of contents hyperlinks are *only* on the page numbers. To activate 
a hyperlink, one must carefully scan sideways from the text item wanted 
to the far right of the page and click on a tiny box. Multiply that mild 
annoyance by the large number of times I need to look up package help 
docs, and I find myself here writing this message.

 From my understanding (albeit poor), all of the R docs for packages are 
to be written in Rd format. From that they are converted by the 
functions in the tools package as required (to latex and PDF, or HTML, 
etc). So the only thing that controls in the PDF docs the hyperlinks one 
way or another is the latex style file used - in this case I believe it 
is Rd.sty (/usr/share/R/share/texmf/tex/latex/Rd.sty on my system).

Line 303 of that file contains the single setting of the \hypersetup{} 
command for whether or not the text in the table of contents is 
hyperlinked, or the page number:

     linktocpage,%

which causes it to implicitly be set to True. Setting it to false (or 
just commenting out that line I suppose as false is the default) would 
mean the *text* in the TOC is hyperlinked.

So, is the desired behaviour intended to be that only the page numbers 
are hyperlinked (and therefore to annoy me), or has no-one really 
bothered themselves with it that much, or something else?

Can I recreate all the documentation on my system after I make a change 
to Rd.sty?


From arne.henningsen at gmail.com  Thu Sep 26 06:28:06 2013
From: arne.henningsen at gmail.com (Arne Henningsen)
Date: Thu, 26 Sep 2013 06:28:06 +0200
Subject: [R] MaxLik estimation issues
In-Reply-To: <BLU0-SMTP6815963BC2241F40F0D22BDE2F0@phx.gbl>
References: <BLU0-SMTP6815963BC2241F40F0D22BDE2F0@phx.gbl>
Message-ID: <CAMTWbJiVL1yP2A7Mt+dykC+Bm8-6=C9n4cbEDwJ5mdA=YebBXQ@mail.gmail.com>

Dear Filipe

On 25 September 2013 14:23, Filipe Ribeiro <flipjribeiro at hotmail.com> wrote:
> Hello everybody!
>
> I'm having some trouble to compute maximum likelihood
> estimations using maxLik package and I hope that you
> could give me a hint.
> The main problem is that I'm not able to get a result not
> even close to the ones given by glm() directly, and the
> second one is: "Error in maxNRCompute(fn = logLikAttr,
> fnOrig = fn, gradOrig = grad, hessOrig = hess, : NA in
> gradient".
>
> The codes:
> loglike.GGompiMaxLik <- function(theta,age,deaths,exposures) {
>  alpha <- exp(theta[1])
>  beta <- exp(theta[2])
>  gamma <- exp(theta[3])
>  first <- alpha*exp(beta*age)
>  second <- 1+(((alpha*gamma)/beta)*(exp(beta*age)-1))
>  mu <- first/second
>  llk <- -sum((deaths * log(mu)) + (- mu*exposures))
>  return(llk)
> }
>
>
> fit1 <- maxLik(loglike.GGompiMaxLik,
>               age=0:6,
>               deaths=c(15545, 21278, 32444, 36201, 30360, 14201, 5198),
>               exposures=c(935023.67, 819392.00, 724568.17, 470947.00,
> 231951.64, 69502.65, 15798.72),
>               start=c(-4.1402817, -0.6375773, -1.6945914))
>
> Do you know how I can solve this problem?

You did not write which model specification you want to estimate but I
am pretty sure that something in your log-likelihood function is
incorrect. The log-likelihood value at the starting values of the
parameters is so large that R even cannot calculate the likelihood
value:

> a <- loglike.GGompiMaxLik(c(-4.1402817, -0.6375773, -1.6945914), age=0:6,
+     deaths=c(15545, 21278, 32444, 36201, 30360, 14201, 5198),
+     exposures=c(935023.67, 819392.00, 724568.17, 470947.00,
+      231951.64, 69502.65, 15798.72))
> a
[1] 580365.2
> exp(a)
[1] Inf

In the second iteration, the first parameter gets so small (large in
absolute terms, -5e+10) that the log-likelihood value become extremely
(numerically infinitely) large and the gradients cannot be computed
(by the finite-difference method):

> fit1 <- maxLik(loglike.GGompiMaxLik,
+     age=0:6,
+     deaths=c(15545, 21278, 32444, 36201, 30360, 14201, 5198),
+     exposures=c(935023.67, 819392.00, 724568.17, 470947.00,
+         231951.64, 69502.65, 15798.72),
+     start=c(-4.1402817, -0.6375773, -1.6945914))
Iteration 2
Parameter:
[1] -5.174233e+10 -3.839076e+02  5.988668e+00
Gradient:
     [,1] [,2] [,3]
[1,]  NaN  NaN  NaN
Error in maxNRCompute(fn = logLikAttr, fnOrig = fn, gradOrig = grad,
hessOrig = hess,  :
  NA in gradient

> b <- loglike.GGompiMaxLik(c(-5.174233e+10, -3.839076e+02, 5.988668e+00), age=0:6,
+     deaths=c(15545, 21278, 32444, 36201, 30360, 14201, 5198),
+     exposures=c(935023.67, 819392.00, 724568.17, 470947.00,
+         231951.64, 69502.65, 15798.72))
> b
[1] Inf

Please note that you can also find hints and ask questions about the
maxLik package in the forums at maxLik's R-Forge site:

https://r-forge.r-project.org/projects/maxlik/

...and please do not forget to cite the maxLik package in your publications:

http://cran.r-project.org/web/packages/maxLik/citation.html

Best wishes,
Arne

-- 
Arne Henningsen
http://www.arne-henningsen.name


From jacquomo.monk at deakin.edu.au  Thu Sep 26 03:13:52 2013
From: jacquomo.monk at deakin.edu.au (Jacquomo Monk)
Date: Wed, 25 Sep 2013 18:13:52 -0700 (PDT)
Subject: [R] Importing,
	renaming columns and exporting mulitple csv files in R
Message-ID: <1380158031711-4676951.post@n4.nabble.com>

Hi All,

I have 1029 *.csv files that I would like read individually into R, delete
some columns and rename others, and then export individually using the
original file names. 

I have written some script to do this for an individual file (script below),
but cannot get it to loop through all the files in the directory. 

> name1<-read.table(file="FID-AW1775_DV0228012H_
> 20080518.csv",sep=",",header=TRUE)
 
> names(name1)[23]<-"Reef % cover" ######### renames column 23
> names(name1)[19]<-"Redundant" ######### renames column 19
 
> data <- subset(name1, select=-c(31:38)) ######### deletes column 31-38
> names(data)[31]<-"Comments" ######### renames column 31
> names(data)[11]<-"Confidence" ######### renames column 11
> names(data)[1]<-"" ######### renames column 1
> names(data)[22]<-"" ######### renames column 22
  
> names(data) ##### check correct columns have been deleted and renamed
  
> write.csv(data,file = "FID-AW1775_DV0228012H_
> 20080518_v2.csv",sep=",",col.names=TRUE,row.names=FALSE, na="")


I have tried looping using > For (i in 1:length(files)){... but it seams to
read all the files into one massive file rather than process them
individually. 

Any ideas on how to get this to loop on individual files and write them out
again would be appreciated.

Chrs,

Jac



--
View this message in context: http://r.789695.n4.nabble.com/Importing-renaming-columns-and-exporting-mulitple-csv-files-in-R-tp4676951.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Thu Sep 26 06:52:16 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 25 Sep 2013 21:52:16 -0700 (PDT)
Subject: [R] Importing,
	renaming columns and exporting mulitple csv files in R
In-Reply-To: <1380158031711-4676951.post@n4.nabble.com>
References: <1380158031711-4676951.post@n4.nabble.com>
Message-ID: <1380171136.46598.YahooMailNeo@web142602.mail.bf1.yahoo.com>



Hi,
Try:
If the files are all in the same working directory, 
#for example
list.files() # 3 files in my WD
#[1] "file1.csv" "file2.csv" "file3.csv"


?lapply(list.files(),function(x) {names1<-read.csv(x,header=TRUE); names(names1)[c(19,23)]<- c("Redundant","Reef % cover"); dat1<- subset(names1,select=-c(31:38)); names(dat1)[c(1,11,22,31)]<- c("","Confidence","","Comments"); names(dat1);write.csv(dat1,paste0("Modified_",x),row.names=FALSE,na="") })

A.K.



----- Original Message -----
From: Jacquomo Monk <jacquomo.monk at deakin.edu.au>
To: r-help at r-project.org
Cc: 
Sent: Wednesday, September 25, 2013 9:13 PM
Subject: [R] Importing,	renaming columns and exporting mulitple csv files in R

Hi All,

I have 1029 *.csv files that I would like read individually into R, delete
some columns and rename others, and then export individually using the
original file names. 

I have written some script to do this for an individual file (script below),
but cannot get it to loop through all the files in the directory. 

> name1<-read.table(file="FID-AW1775_DV0228012H_
> 20080518.csv",sep=",",header=TRUE)

> names(name1)[23]<-"Reef % cover" ######### renames column 23
> names(name1)[19]<-"Redundant" ######### renames column 19

> data <- subset(name1, select=-c(31:38)) ######### deletes column 31-38
> names(data)[31]<-"Comments" ######### renames column 31
> names(data)[11]<-"Confidence" ######### renames column 11
> names(data)[1]<-"" ######### renames column 1
> names(data)[22]<-"" ######### renames column 22
? 
> names(data) ##### check correct columns have been deleted and renamed
? 
> write.csv(data,file = "FID-AW1775_DV0228012H_
> 20080518_v2.csv",sep=",",col.names=TRUE,row.names=FALSE, na="")


I have tried looping using > For (i in 1:length(files)){... but it seams to
read all the files into one massive file rather than process them
individually. 

Any ideas on how to get this to loop on individual files and write them out
again would be appreciated.

Chrs,

Jac



--
View this message in context: http://r.789695.n4.nabble.com/Importing-renaming-columns-and-exporting-mulitple-csv-files-in-R-tp4676951.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jacquomo.monk at deakin.edu.au  Thu Sep 26 07:08:59 2013
From: jacquomo.monk at deakin.edu.au (Jacquomo Monk)
Date: Wed, 25 Sep 2013 22:08:59 -0700 (PDT)
Subject: [R] Importing,
 renaming columns and exporting mulitple csv files in R
In-Reply-To: <1380171136.46598.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1380158031711-4676951.post@n4.nabble.com>
	<1380171136.46598.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1380172139591-4676959.post@n4.nabble.com>

A.K.

Thanks for the reply. Will give it a try...

Jac



--
View this message in context: http://r.789695.n4.nabble.com/Importing-renaming-columns-and-exporting-mulitple-csv-files-in-R-tp4676951p4676959.html
Sent from the R help mailing list archive at Nabble.com.


From babakbsn at gmail.com  Thu Sep 26 09:31:06 2013
From: babakbsn at gmail.com (Babak Bastan)
Date: Thu, 26 Sep 2013 00:31:06 -0700
Subject: [R] Why does sin(pi) not return 0?
Message-ID: <CAF-JZQvkxziAxKrAUi_pAqZujB6VqzMW25oPvHYdfPoeyH-Kag@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/de891bfd/attachment.pl>

From kridox at ymail.com  Thu Sep 26 09:50:15 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 26 Sep 2013 16:50:15 +0900
Subject: [R] Why does sin(pi) not return 0?
In-Reply-To: <CAF-JZQvkxziAxKrAUi_pAqZujB6VqzMW25oPvHYdfPoeyH-Kag@mail.gmail.com>
References: <CAF-JZQvkxziAxKrAUi_pAqZujB6VqzMW25oPvHYdfPoeyH-Kag@mail.gmail.com>
Message-ID: <CAAcyNCy-N9FMUj8QbbZR+y8gSsvkHHPoHBetUmAvn7hzpgFRfw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/d548bcd7/attachment.pl>

From rolf.turner at xtra.co.nz  Thu Sep 26 09:55:38 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Thu, 26 Sep 2013 19:55:38 +1200
Subject: [R] Why does sin(pi) not return 0?
In-Reply-To: <CAF-JZQvkxziAxKrAUi_pAqZujB6VqzMW25oPvHYdfPoeyH-Kag@mail.gmail.com>
References: <CAF-JZQvkxziAxKrAUi_pAqZujB6VqzMW25oPvHYdfPoeyH-Kag@mail.gmail.com>
Message-ID: <5243E87A.8060604@xtra.co.nz>

On 09/26/13 19:31, Babak Bastan wrote:
> Hi experts,
>
> If I test sin(pi) in r, it returns me 1.224606e-16
>
> Why doesn't return me 0?

If you think that 1.224606e-16 is different from 0, you should probably not
be using computers.  See FAQ 7.31 (which is in a way about the inverse of
your question, but it should provide the necessary insight).

     cheers,

     Rolf Turner


From spyqqqdia at yahoo.com  Thu Sep 26 09:57:10 2013
From: spyqqqdia at yahoo.com (Michael Meyer)
Date: Thu, 26 Sep 2013 15:57:10 +0800 (SGT)
Subject: [R] error handling
Message-ID: <1380182230.5229.YahooMailNeo@web193405.mail.sg3.yahoo.com>

Greetings,
?
Error handling does not seem to work as expected.
When a handler for general conditions is provided in?first?position in?the handler list it will be called 
regardless of what condition has been signalled.
?
See sample code, move? "condition = function(c){...}" to first position in handler list.
This indicates that the determination of which condition handler is appropriate does not work like
virtual function dispatch.
?
I also would like to know what happens if some handlers are not provided.
For example if a warning handler is not provided and a warning is signalled does this invoke a
default handler and how does this handler know which value to return from the tryCatch block.
?
Thanks,
?
Michael
?
?
?
# Function signals various conditions
#
prejudiced <- function(x){
?
??? cl <- call("prejudiced",x)

??? # throw various conditions with message and information about function call
??? if(x==0) signalCondition( simpleCondition("x=0 encountered",call=cl) )
??? if(x==1) signalCondition( simpleMessage("Do not like 1",call=cl) )
??? if(x==2) signalCondition( simpleWarning("Hate 2",call=cl) )
??? if(x==3) signalCondition( simpleError("Cannot tolerate 3",call=cl) )
??? return(x)
}
tryCatchTest <- function(x){
??? 
actual <- tryCatch({
??????????????? # expressions evaluated until condition signalled:
??????????????? -1
??????????????? prejudiced(x)
??????????????? 4? # returned if no condition is signalled
??????????? },
??????????? # condition handlers return new value as result of tryCatch:
??????????? message = function(m){ print(m); 6},
??????????? warning = function(w){ print(w); 7},
??????????? error?? = function(e){ print(e); 8},
??????????? # must be put last otherwise it is called for any condition
??????????? condition = function(c){ print(c); 5},
??????????? finally = { cat("\nCleaned up.") }
??? )
??? # result of tryCatch:
??? expected <- 4
??? if(x==0) expected <- 5
??? if(x==1) expected <- 6
??? if(x==2) expected <- 7
??? if(x==3) expected <- 8
??? cat("\nResult of tryCatch should be ",expected," and is: ",actual)
}



From Ted.Harding at wlandres.net  Thu Sep 26 10:13:37 2013
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Thu, 26 Sep 2013 09:13:37 +0100 (BST)
Subject: [R] Why does sin(pi) not return 0?
In-Reply-To: <5243E87A.8060604@xtra.co.nz>
Message-ID: <XFMail.20130926091337.Ted.Harding@wlandres.net>

On 26-Sep-2013 07:55:38 Rolf Turner wrote:
> On 09/26/13 19:31, Babak Bastan wrote:
>> Hi experts,
>>
>> If I test sin(pi) in r, it returns me 1.224606e-16
>>
>> Why doesn't return me 0?
> 
> If you think that 1.224606e-16 is different from 0, you should probably not
> be using computers.

Is that a Fortune? And, if so, should R be using computers?

  sin(pi)
  # [1] 1.224606e-16
  sin(pi)==0
  # [1] FALSE

> See FAQ 7.31 (which is in a way about the inverse of
> your question, but it should provide the necessary insight).
> 
>      cheers,
>      Rolf Turner

Though, mind you, FAQ 3.71 does also offer some consolation to R:

  all.equal(0,sin(pi))
  # [1] TRUE

So it depends on what you mean by "different from". Computers
have their own fuzzy concept of this ... Babak has too fussy
a concept.

Ted.

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 26-Sep-2013  Time: 09:13:33
This message was sent by XFMail


From Rainer at krugs.de  Thu Sep 26 11:30:27 2013
From: Rainer at krugs.de (Rainer M Krug)
Date: Thu, 26 Sep 2013 11:30:27 +0200
Subject: [R] Why does sin(pi) not return 0?
References: <5243E87A.8060604@xtra.co.nz>
	<XFMail.20130926091337.Ted.Harding@wlandres.net>
Message-ID: <m2pprw6ibw.fsf@krugs.de>

(Ted Harding) <Ted.Harding at wlandres.net> writes:

> On 26-Sep-2013 07:55:38 Rolf Turner wrote:
>> On 09/26/13 19:31, Babak Bastan wrote:
>>> Hi experts,
>>>
>>> If I test sin(pi) in r, it returns me 1.224606e-16
>>>
>>> Why doesn't return me 0?
>> 

I think this should be a Fortune:
,----
| >> If you think that 1.224606e-16 is different from 0, you should probably not
| >> be using computers.
| >
| > Is that a Fortune? And, if so, should R be using computers?
| >
| >   sin(pi)
| >   # [1] 1.224606e-16
| >   sin(pi)==0
| >   # [1] FALSE
`----

Cheers,

Rainer

>
>> See FAQ 7.31 (which is in a way about the inverse of
>> your question, but it should provide the necessary insight).
>> 
>>      cheers,
>>      Rolf Turner
>
> Though, mind you, FAQ 3.71 does also offer some consolation to R:
>
>   all.equal(0,sin(pi))
>   # [1] TRUE
>
> So it depends on what you mean by "different from". Computers
> have their own fuzzy concept of this ... Babak has too fussy
> a concept.
>
> Ted.
>
> -------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
> Date: 26-Sep-2013  Time: 09:13:33
> This message was sent by XFMail
>
<#secure method=pgpmime mode=sign>

-- 
Rainer M. Krug

email: RMKrug<at>gmail<dot>com


From bretschr at xs4all.nl  Thu Sep 26 11:32:34 2013
From: bretschr at xs4all.nl (Bretschneider (R))
Date: Thu, 26 Sep 2013 11:32:34 +0200
Subject: [R]  Cosine window in r
Message-ID: <9090A534-A97B-4537-80D0-937F307F1A5A@xs4all.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/bb47cd8a/attachment.pl>

From mzoelck at hotmail.com  Thu Sep 26 12:37:47 2013
From: mzoelck at hotmail.com (Melanie Zoelck)
Date: Thu, 26 Sep 2013 10:37:47 +0000
Subject: [R] Override default colour scheme of an effects plot
Message-ID: <DUB111-W1351F28B8B42E09E88F9337B6280@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/5efc0f4d/attachment.pl>

From jrkrideau at inbox.com  Thu Sep 26 13:21:05 2013
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 26 Sep 2013 03:21:05 -0800
Subject: [R] Why does sin(pi) not return 0?
In-Reply-To: <m2pprw6ibw.fsf@krugs.de>
References: <5243e87a.8060604@xtra.co.nz>
	<xfmail.20130926091337.ted.harding@wlandres.net>
Message-ID: <87E91A901D3.00000A39jrkrideau@inbox.com>

Definitely a Fortune.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: rainer at krugs.de
> Sent: Thu, 26 Sep 2013 11:30:27 +0200
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] Why does sin(pi) not return 0?
> 
> (Ted Harding) <Ted.Harding at wlandres.net> writes:
> 
>> On 26-Sep-2013 07:55:38 Rolf Turner wrote:
>>> On 09/26/13 19:31, Babak Bastan wrote:
>>>> Hi experts,
>>>> 
>>>> If I test sin(pi) in r, it returns me 1.224606e-16
>>>> 
>>>> Why doesn't return me 0?
>>> 
> 
> I think this should be a Fortune:
> ,----
> | >> If you think that 1.224606e-16 is different from 0, you should
> probably not
> | >> be using computers.
> | >
> | > Is that a Fortune? And, if so, should R be using computers?
> | >
> | >   sin(pi)
> | >   # [1] 1.224606e-16
> | >   sin(pi)==0
> | >   # [1] FALSE
> `----
> 
> Cheers,
> 
> Rainer
> 
>> 
>>> See FAQ 7.31 (which is in a way about the inverse of
>>> your question, but it should provide the necessary insight).
>>> 
>>>      cheers,
>>>      Rolf Turner
>> 
>> Though, mind you, FAQ 3.71 does also offer some consolation to R:
>> 
>>   all.equal(0,sin(pi))
>>   # [1] TRUE
>> 
>> So it depends on what you mean by "different from". Computers
>> have their own fuzzy concept of this ... Babak has too fussy
>> a concept.
>> 
>> Ted.
>> 
>> -------------------------------------------------
>> E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
>> Date: 26-Sep-2013  Time: 09:13:33
>> This message was sent by XFMail
>> 
> <#secure method=pgpmime mode=sign>
> 
> --
> Rainer M. Krug
> 
> email: RMKrug<at>gmail<dot>com
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From jrkrideau at inbox.com  Thu Sep 26 13:25:35 2013
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 26 Sep 2013 03:25:35 -0800
Subject: [R] request for help in R
In-Reply-To: <1380176208.26658.YahooMailNeo@web162806.mail.bf1.yahoo.com>
References: <1380005092.49621.yahoomailneo@web162804.mail.bf1.yahoo.com>
	<7d5be2a9d21.00001051jrkrideau@inbox.com>
Message-ID: <87F331154C1.00000A41jrkrideau@inbox.com>

John Kane
Kingston ON Canada

-----Original Message-----
From: atta_ycc at yahoo.com
Sent: Wed, 25 Sep 2013 23:16:48 -0700 (PDT)
To: jrkrideau at inbox.com
Subject: Re: [R] request for help in R

hi,

i have data for 15 gauging stations of different rivers and for monthly maxmimum flows data, i want to make analysis of that using lmomRFA package of R , and in these analysis relative bias and absolute bias is needed?

Data? Code?  Please carefully read the links below and give us some information in terms of R code or at least supply is with some sample data.  See ?dput as a way to supply data.

  From: John Kane <jrkrideau at inbox.com>
 To: atta ahmad <atta_ycc at yahoo.com> 
 Sent: Wednesday, September 25, 2013 8:12 PM
 Subject: RE: [R] request for help in R

We need much more information about what you are doing before we likely can help.

Have a look at these links for some suggestions on how to create a good question.

https://github.com/hadley/devtools/wiki/Reproducibility [https://github.com/hadley/devtools/wiki/Reproducibility]
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example [http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example]

At a guess we need some idea of what your data looks like (see ?dput) and what code you have attempted to use.

Sorry not to be of more help.

John Kane
Kingston ON Canada

> -----Original Message-----
> From: atta_ycc at yahoo.com
> Sent: Mon, 23 Sep 2013 23:44:52 -0700 (PDT)
> To: r-help at stat.math.ethz.ch, r-help at r-project.org, bsaf at pau.edu.tr
> Subject: [R] request for help in R
> 
> respectd sir,
> i am working on regional frequency analysis of flood flow data and want
> to use packages lmomRFA, lmom, imomco,etc andby using these i want to
> find RMSE , errorbounds and absolute biase but could not make it clear to
> use, please help
> regards
> atta muhammad asif
> assistant professor
> atta_ycc at yahoo.com
> ??? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html [http://www.r-project.org/posting-guide.html]
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at http://www.inbox.com/smileys [http://www.inbox.com/smileys]
Works with AIM?, MSN? Messenger, Yahoo!? Messenger, ICQ?, Google Talk? and most webmails

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From msuzen at gmail.com  Thu Sep 26 14:48:52 2013
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Thu, 26 Sep 2013 14:48:52 +0200
Subject: [R] Why does sin(pi) not return 0?
In-Reply-To: <m2pprw6ibw.fsf@krugs.de>
References: <5243E87A.8060604@xtra.co.nz>
	<XFMail.20130926091337.Ted.Harding@wlandres.net>
	<m2pprw6ibw.fsf@krugs.de>
Message-ID: <CAPtbhHwgqS9jFXy5D9qb5hPH9i+_gGRS=HqCxUSWAHWvNeeFLg@mail.gmail.com>

On 26 September 2013 11:30, Rainer M Krug <Rainer at krugs.de> wrote:
>>>> Why doesn't return me 0?

It isn't R question at all. You might want to read about representing
real numbers in a computer using floating point
http://en.wikipedia.org/wiki/Floating_point

If you want more precision for some reason, you may want to use Rmpfr
package from CRAN, for example
> require(Rmpfr)
> pii <- mpfr(pi, 1200)
> sin(pii)
1 'mpfr' number of precision  1200   bits
[1] 1.22464679914735317722606593227499799708305390129979194948825771626086960997325810377509325527569013655456428540074414189136673810003656057935764118217436637676835016019778833613838580470703060741630570066750947925902443295873487819032259435513861185501796412843027607796970259523768923503206248925733373776859085615900203929142965774524665617260404787862664073939e-16


> | > Is that a Fortune? And, if so, should R be using computers?

Don't blame R for real numbers.


From pbruneau at gmail.com  Thu Sep 26 15:06:34 2013
From: pbruneau at gmail.com (Pierrick Bruneau)
Date: Thu, 26 Sep 2013 15:06:34 +0200
Subject: [R] Why does sin(pi) not return 0?
In-Reply-To: <CAPtbhHwgqS9jFXy5D9qb5hPH9i+_gGRS=HqCxUSWAHWvNeeFLg@mail.gmail.com>
References: <5243E87A.8060604@xtra.co.nz>
	<XFMail.20130926091337.Ted.Harding@wlandres.net>
	<m2pprw6ibw.fsf@krugs.de>
	<CAPtbhHwgqS9jFXy5D9qb5hPH9i+_gGRS=HqCxUSWAHWvNeeFLg@mail.gmail.com>
Message-ID: <CAF_q7hVVTfdKwi=Oe-FFWKtd622gv52heN_mL760gbgxSj7Avg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/81f94455/attachment.pl>

From babakbsn at gmail.com  Thu Sep 26 15:30:49 2013
From: babakbsn at gmail.com (Babak Bastan)
Date: Thu, 26 Sep 2013 06:30:49 -0700
Subject: [R] moving a window over a matrix column
Message-ID: <CAF-JZQvQQDthtdM4mTiz_=h3hVQ9paiUgRuJGpQhpupceeiQTQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/b4491f84/attachment.pl>

From dwinsemius at comcast.net  Thu Sep 26 15:53:55 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 26 Sep 2013 08:53:55 -0500
Subject: [R] Why does sin(pi) not return 0?
In-Reply-To: <CAF_q7hVVTfdKwi=Oe-FFWKtd622gv52heN_mL760gbgxSj7Avg@mail.gmail.com>
References: <5243E87A.8060604@xtra.co.nz>
	<XFMail.20130926091337.Ted.Harding@wlandres.net>
	<m2pprw6ibw.fsf@krugs.de>
	<CAPtbhHwgqS9jFXy5D9qb5hPH9i+_gGRS=HqCxUSWAHWvNeeFLg@mail.gmail.com>
	<CAF_q7hVVTfdKwi=Oe-FFWKtd622gv52heN_mL760gbgxSj7Avg@mail.gmail.com>
Message-ID: <8342B8BA-032D-4407-9BD0-346C8113A1AB@comcast.net>


On Sep 26, 2013, at 8:06 AM, Pierrick Bruneau wrote:

> Just to add a small note,
> sin(pi) is below machine precision :
>
>> .Machine$double.eps
> [1] 2.220446e-16
>
> (see ?.Machine for exact definition)
>
> -> if myval is bounded to be positive, one safe way of testing  
> equality to
> 0 would then be "myval < .Machine$double.eps"

That is a more stringent condition than is applied by `all.equal`  
which instead uses .Machine$double.eps^0.5.

-- 
David.
>
>
>
> On Thu, Sep 26, 2013 at 2:48 PM, Suzen, Mehmet <msuzen at gmail.com>  
> wrote:
>
>> On 26 September 2013 11:30, Rainer M Krug <Rainer at krugs.de> wrote:
>>>>>> Why doesn't return me 0?
>>
>> It isn't R question at all. You might want to read about representing
>> real numbers in a computer using floating point
>> http://en.wikipedia.org/wiki/Floating_point
>>
>> If you want more precision for some reason, you may want to use Rmpfr
>> package from CRAN, for example
>>> require(Rmpfr)
>>> pii <- mpfr(pi, 1200)
>>> sin(pii)
>> 1 'mpfr' number of precision  1200   bits
>> [1]
>> 1.22464679914735317722606593227499799708305390129979194948825771626086960997325810377509325527569013655456428540074414189136673810003656057935764118217436637676835016019778833613838580470703060741630570066750947925902443295873487819032259435513861185501796412843027607796970259523768923503206248925733373776859085615900203929142965774524665617260404787862664073939e-16
>>
>>
>>> | > Is that a Fortune? And, if so, should R be using computers?
>>
>> Don't blame R for real numbers.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From gunter.berton at gene.com  Thu Sep 26 15:57:27 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 26 Sep 2013 06:57:27 -0700
Subject: [R] moving a window over a matrix column
In-Reply-To: <CAF-JZQvQQDthtdM4mTiz_=h3hVQ9paiUgRuJGpQhpupceeiQTQ@mail.gmail.com>
References: <CAF-JZQvQQDthtdM4mTiz_=h3hVQ9paiUgRuJGpQhpupceeiQTQ@mail.gmail.com>
Message-ID: <CACk-te05Z6u_fehs59XywRSAEsYPH64eH0wdF9ad9ekqFXGHwg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/2e4a7c69/attachment.pl>

From istazahn at gmail.com  Thu Sep 26 16:03:18 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 26 Sep 2013 10:03:18 -0400
Subject: [R] table of contents link style in R's PDF docs
In-Reply-To: <l20a7b$rsi$1@ger.gmane.org>
References: <l20a7b$rsi$1@ger.gmane.org>
Message-ID: <CA+vqiLHLFRXpFvM5m=y7i-uCXv2hC49_A+nru1WWc-aub85M1Q@mail.gmail.com>

Hi Ben,



On Wed, Sep 25, 2013 at 11:38 PM, Ben Harrison
<harb at student.unimelb.edu.au> wrote:
> Hello,
> I am mildly annoyed each time I use a PDF doc of an R package that the table
> of contents hyperlinks are *only* on the page numbers. To activate a
> hyperlink, one must carefully scan sideways from the text item wanted to the
> far right of the page and click on a tiny box. Multiply that mild annoyance
> by the large number of times I need to look up package help docs, and I find
> myself here writing this message.

I agree that it would be nicer to have the whole TOC entry
hyperlinked. But out of curiosity, why are you using the pdf
documentation? I find the html much nicer.

Best,
Ista

>
> From my understanding (albeit poor), all of the R docs for packages are to
> be written in Rd format. From that they are converted by the functions in
> the tools package as required (to latex and PDF, or HTML, etc). So the only
> thing that controls in the PDF docs the hyperlinks one way or another is the
> latex style file used - in this case I believe it is Rd.sty
> (/usr/share/R/share/texmf/tex/latex/Rd.sty on my system).
>
> Line 303 of that file contains the single setting of the \hypersetup{}
> command for whether or not the text in the table of contents is hyperlinked,
> or the page number:
>
>     linktocpage,%
>
> which causes it to implicitly be set to True. Setting it to false (or just
> commenting out that line I suppose as false is the default) would mean the
> *text* in the TOC is hyperlinked.
>
> So, is the desired behaviour intended to be that only the page numbers are
> hyperlinked (and therefore to annoy me), or has no-one really bothered
> themselves with it that much, or something else?
>
> Can I recreate all the documentation on my system after I make a change to
> Rd.sty?
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Sep 26 16:08:23 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 26 Sep 2013 09:08:23 -0500
Subject: [R] moving a window over a matrix column
In-Reply-To: <CAF-JZQvQQDthtdM4mTiz_=h3hVQ9paiUgRuJGpQhpupceeiQTQ@mail.gmail.com>
References: <CAF-JZQvQQDthtdM4mTiz_=h3hVQ9paiUgRuJGpQhpupceeiQTQ@mail.gmail.com>
Message-ID: <59DC4983-92F3-4A28-AB5C-0E48356B662D@comcast.net>


On Sep 26, 2013, at 8:30 AM, Babak Bastan wrote:

> Greeting
>
> I want to move a window over a column in a Matrix. For example. I  
> have a
> 8X1 Matrix and I want to read the data from 1 until 5, for the  
> second time
> 2 until 6, third time 3 till 7 and... and do something on this  
> values and
> show them in a diagramm:

I tried looking at the code below but could not tell what was failing  
because you did not say what you meant by "did not work". If you got  
an error you should have posted it. I am guessing the "it" you wanted  
plotted were just the values against an index.

The embed function will construct a matrix something like I imagine  
you want, albeit with columns in reverse order:

 > M <- 1:8
 > embed(M, 3)
      [,1] [,2] [,3]
[1,]    3    2    1
[2,]    4    3    2
[3,]    5    4    3
[4,]    6    5    4
[5,]    7    6    5
[6,]    8    7    6

 > layout(c(1:3))
 > for(i in 3:1) plot( embed(M,3)[ , i])

-- 
David.

>
> I wrote this code:
>
> #here I make an nX1 Matrix
>
> df<-matrix(unlist(datalist,use.names=FALSE),ncol=1,byrow=TRUE)#window:
> the length of the window and Step:wenn this value 1 is, then for the
> second time it begins from 2while(n+window<=length(df)){
>  k<-matrix(df[n:n+window-1,1])
>  #plot(k) I want to do something over k and show it in a plot
>  n<-n+step}
>
> but my code doesn't work
>
>   - I can't show a plot inside of for loop
>   - I cant show the value of K inside of for loop
>   - If I show k outside of the loop I can only see one integer value
> and not a matrix
>
> if df:
>
> 12 13 14 15 16 17 18 8 19
>
> then k outside of the loop contain only 18.
>
> Could you please inform me how can I solve my problem?
>
> 	
-- 

David Winsemius, MD
Alameda, CA, USA


From davide.luciani at marionegri.it  Thu Sep 26 10:06:56 2013
From: davide.luciani at marionegri.it (Davide Luciani)
Date: Thu, 26 Sep 2013 10:06:56 +0200 (CEST)
Subject: [R] Installing Rcplex
Message-ID: <1017655785.1102848.1380182816928.JavaMail.root@marionegri.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/9423eb8f/attachment.pl>

From neep_hazarika at hotmail.com  Thu Sep 26 10:03:58 2013
From: neep_hazarika at hotmail.com (Neep Hazarika)
Date: Thu, 26 Sep 2013 09:03:58 +0100
Subject: [R] R hangs at NGramTokenizer
Message-ID: <DUB110-W13766F40486619073B2E7258D280@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/55735a9b/attachment.pl>

From rodrigo.silva at ipplan.org.br  Thu Sep 26 16:10:10 2013
From: rodrigo.silva at ipplan.org.br (=?iso-8859-1?Q?Rodrigo_C=E9sar_da_Silva?=)
Date: Thu, 26 Sep 2013 14:10:10 +0000
Subject: [R] Boxplot from statistics of original data
Message-ID: <c5911c76256e48e89d2ec238797327d2@GRXPR80MB064.lamprd80.prod.outlook.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/547efb65/attachment.pl>

From maechler at lynne.ethz.ch  Thu Sep 26 16:17:39 2013
From: maechler at lynne.ethz.ch (Martin Maechler)
Date: Thu, 26 Sep 2013 16:17:39 +0200
Subject: [R] Why does sin(pi) not return 0?
In-Reply-To: <CAPtbhHwgqS9jFXy5D9qb5hPH9i+_gGRS=HqCxUSWAHWvNeeFLg@mail.gmail.com>
References: <5243E87A.8060604@xtra.co.nz>
	<XFMail.20130926091337.Ted.Harding@wlandres.net>
	<m2pprw6ibw.fsf@krugs.de>
	<CAPtbhHwgqS9jFXy5D9qb5hPH9i+_gGRS=HqCxUSWAHWvNeeFLg@mail.gmail.com>
Message-ID: <21060.16899.77909.919070@gargle.gargle.HOWL>

>>>>> Suzen, Mehmet <msuzen at gmail.com>
>>>>>     on Thu, 26 Sep 2013 14:48:52 +0200 writes:

    > On 26 September 2013 11:30, Rainer M Krug <Rainer at krugs.de> wrote:
    >>>>> Why doesn't return me 0?

    > It isn't R question at all. You might want to read about representing
    > real numbers in a computer using floating point
    > http://en.wikipedia.org/wiki/Floating_point

    > If you want more precision for some reason, you may want to use Rmpfr
    > package from CRAN, for example
    >> require(Rmpfr)
    >> pii <- mpfr(pi, 1200)
    >> sin(pii)
    > 1 'mpfr' number of precision  1200   bits
    > [1] 1.22464679914735317722606593227499799708305390129979194948825771626086960997325810377509325527569013655456428540074414189136673810003656057935764118217436637676835016019778833613838580470703060741630570066750947925902443295873487819032259435513861185501796412843027607796970259523768923503206248925733373776859085615900203929142965774524665617260404787862664073939e-16

Thank you, Suzen, for mentioning Rmpfr.
In that case, I think you should also show how to get a more
accurate approximation of 0:

The most convenient way with Rmpfr is to use the builtin pi, in
the following :

> pii <- Const("pi") #  default precision of 120 bits
> sin(pii)
1 'mpfr' number of precision  120   bits 
[1] -5.5059930380881434362856026294599943387e-37
> ## or
> pii <- Const("pi", prec = 240)
> pii
1 'mpfr' number of precision  240   bits 
[1] 3.1415926535897932384626433832795028841971693993751058209749445923078164072
## and indeed the above is pi accurate to about 74 decimal digits
> sin(pii)
1 'mpfr' number of precision  240   bits 
[1] -8.9200160854418520294613808989866371392121893805952954481681649396960358864e-73
> asNumeric(sin(pii))
[1] -8.920016e-73
> 

So you see, the more accurate the approximation  pii  for the true
\pi, the more accurate is the result  of  sin(pii) 


Martin Maechler, ETH Zurich
(and author of Rmpfr)


From murdoch.duncan at gmail.com  Thu Sep 26 16:33:47 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 26 Sep 2013 10:33:47 -0400
Subject: [R] table of contents link style in R's PDF docs
In-Reply-To: <l20a7b$rsi$1@ger.gmane.org>
References: <l20a7b$rsi$1@ger.gmane.org>
Message-ID: <524445CB.8010205@gmail.com>

On 25/09/2013 11:38 PM, Ben Harrison wrote:
> Hello,
> I am mildly annoyed each time I use a PDF doc of an R package that the
> table of contents hyperlinks are *only* on the page numbers. To activate
> a hyperlink, one must carefully scan sideways from the text item wanted
> to the far right of the page and click on a tiny box. Multiply that mild
> annoyance by the large number of times I need to look up package help
> docs, and I find myself here writing this message.
>
>   From my understanding (albeit poor), all of the R docs for packages are
> to be written in Rd format. From that they are converted by the
> functions in the tools package as required (to latex and PDF, or HTML,
> etc). So the only thing that controls in the PDF docs the hyperlinks one
> way or another is the latex style file used - in this case I believe it
> is Rd.sty (/usr/share/R/share/texmf/tex/latex/Rd.sty on my system).
>
> Line 303 of that file contains the single setting of the \hypersetup{}
> command for whether or not the text in the table of contents is
> hyperlinked, or the page number:
>
>       linktocpage,%
>
> which causes it to implicitly be set to True. Setting it to false (or
> just commenting out that line I suppose as false is the default) would
> mean the *text* in the TOC is hyperlinked.
>
> So, is the desired behaviour intended to be that only the page numbers
> are hyperlinked (and therefore to annoy me), or has no-one really
> bothered themselves with it that much, or something else?

It's been the way it is for about 14 years, and I don't recall anyone 
else complaining, so I'd conclude it must have been set that way with 
you in mind.

More seriously, I prefer having the page number clickable to having just 
the text clickable.  Having both would be fine for both of us. There's a 
partially documented option "linktoc=all" that does that; it was added 
to the hyperref package in 2008, so you can hardly blame R for not using 
it back in 1999.  The only problem I can see with using it now is that 
some users might not have a sufficiently up-to-date LaTeX installation 
to use it; if their hyperref package doesn't know about linktoc, they 
won't be able to build anything at all.

>
> Can I recreate all the documentation on my system after I make a change
> to Rd.sty?

Easiest would be to just do a rebuild of R, but you could also do the 
PDF manuals one at a time using

R CMD Rd2pdf  <pkg>

from the directory where the package is installed, or where its source 
lives.

Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bhh at xs4all.nl  Thu Sep 26 16:48:23 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 26 Sep 2013 16:48:23 +0200
Subject: [R] moving a window over a matrix column
In-Reply-To: <CAF-JZQvQQDthtdM4mTiz_=h3hVQ9paiUgRuJGpQhpupceeiQTQ@mail.gmail.com>
References: <CAF-JZQvQQDthtdM4mTiz_=h3hVQ9paiUgRuJGpQhpupceeiQTQ@mail.gmail.com>
Message-ID: <11B3439B-DF0B-4379-9CE0-C03CFE9E3E5E@xs4all.nl>


On 26-09-2013, at 15:30, Babak Bastan <babakbsn at gmail.com> wrote:

> Greeting
> 
> I want to move a window over a column in a Matrix. For example. I have a
> 8X1 Matrix and I want to read the data from 1 until 5, for the second time
> 2 until 6, third time 3 till 7 and... and do something on this values and
> show them in a diagramm:
> 
> I wrote this code:
> 
> #here I make an nX1 Matrix
> 
> df<-matrix(unlist(datalist,use.names=FALSE),ncol=1,byrow=TRUE)#window:
> the length of the window and Step:wenn this value 1 is, then for the
> second time it begins from 2while(n+window<=length(df)){
>  k<-matrix(df[n:n+window-1,1])
>  #plot(k) I want to do something over k and show it in a plot
>  n<-n+step}
> 
> but my code doesn't work
> 
>   - I can't show a plot inside of for loop
>   - I cant show the value of K inside of for loop
>   - If I show k outside of the loop I can only see one integer value
> and not a matrix
> 
> if df:
> 
> 12 13 14 15 16 17 18 8 19
> 
> then k outside of the loop contain only 18.
> 
> Could you please inform me how can I solve my problem?
> 

It is impossible to give you proper advice since your code has been messed up by posting in HTML.
And you have not given a reproducible example.

Other have already made some suggestions.
I guessing that the expression

 k<-matrix(df[n:n+window-1,1])

is not doing what you expect. You likely want rows n upto and including n+window-1.
If so use () around the part after the : like this

k<-matrix(df[n:(n+window-1),1])

Read the "An Introduction to R" manual especially section 2.3 Generating regular sequences (R-3.0.2)

Berend

> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From zulutime.net at gmail.com  Thu Sep 26 17:07:16 2013
From: zulutime.net at gmail.com (Magnus Thor Torfason)
Date: Thu, 26 Sep 2013 15:07:16 +0000
Subject: [R] min(NA,"bla") != min("bla", NA)
Message-ID: <52444DA4.3050409@gmail.com>

Just ran these two statements:

 > min(NA,"bla")
[1] NA

 > min("bla", NA)
[1] "bla"

And then reran with explicit na.rm=FALSE

 > min(NA,"bla", na.rm=FALSE)
[1] NA

 > min("bla", NA, na.rm=FALSE)
[1] "bla"


That seems wrong. Would this be considered a bug or is there a way to 
explain these results in a different way?

Best,
Magnus

ps. Tested on R 3.0.1, 32 bit for Windows (as well as some older versions)


From smartpink111 at yahoo.com  Thu Sep 26 17:22:37 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 26 Sep 2013 08:22:37 -0700 (PDT)
Subject: [R] min(NA,"bla") != min("bla", NA)
In-Reply-To: <52444DA4.3050409@gmail.com>
References: <52444DA4.3050409@gmail.com>
Message-ID: <1380208957.16150.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
?min(5,1)
#[1] 1


?min(c(1,5))
#[1] 1
?min(c(1,5))==min(c(5,1))
#[1] TRUE



? min(c(NA,"bla"))
#[1] NA
?min(c("bla",NA))
#[1] NA
?min(c("bla",NA),na.rm=FALSE)
#[1] NA
?min(c("bla",NA),na.rm=TRUE)
#[1] "bla"

A.K.



----- Original Message -----
From: Magnus Thor Torfason <zulutime.net at gmail.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Thursday, September 26, 2013 11:07 AM
Subject: [R] min(NA,"bla") != min("bla", NA)

Just ran these two statements:

> min(NA,"bla")
[1] NA

> min("bla", NA)
[1] "bla"

And then reran with explicit na.rm=FALSE

> min(NA,"bla", na.rm=FALSE)
[1] NA

> min("bla", NA, na.rm=FALSE)
[1] "bla"


That seems wrong. Would this be considered a bug or is there a way to 
explain these results in a different way?

Best,
Magnus

ps. Tested on R 3.0.1, 32 bit for Windows (as well as some older versions)

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From istazahn at gmail.com  Thu Sep 26 17:36:26 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 26 Sep 2013 11:36:26 -0400
Subject: [R] min(NA,"bla") != min("bla", NA)
In-Reply-To: <1380208957.16150.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <52444DA4.3050409@gmail.com>
	<1380208957.16150.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <CA+vqiLEymrE65eYj4z-KkfAzHbJRfidccaJ8Y-DC0594Uwy4zg@mail.gmail.com>

Hi A.K.,

On Thu, Sep 26, 2013 at 11:22 AM, arun <smartpink111 at yahoo.com> wrote:
> Hi,
>  min(5,1)
> #[1] 1
>
>
>  min(c(1,5))
> #[1] 1
>  min(c(1,5))==min(c(5,1))
> #[1] TRUE
>
>
>
>   min(c(NA,"bla"))
> #[1] NA
>  min(c("bla",NA))
> #[1] NA
>  min(c("bla",NA),na.rm=FALSE)
> #[1] NA
>  min(c("bla",NA),na.rm=TRUE)
> #[1] "bla"

What is the point of this example? The OP's point was (I hope I am not
putting words in his mouth) that the documentation for ?min says

"     If ?na.rm? is ?FALSE? an ?NA? value in any of the arguments will
     cause a value of ?NA? to be returned, otherwise ?NA? values are
     ignored."

but that appears not to be true:

min("bla", NA)
[1] "bla"

It's not clear to me how your example is relevant.

Best,
Ista

>
> A.K.
>
>
>
> ----- Original Message -----
> From: Magnus Thor Torfason <zulutime.net at gmail.com>
> To: "r-help at r-project.org" <r-help at r-project.org>
> Cc:
> Sent: Thursday, September 26, 2013 11:07 AM
> Subject: [R] min(NA,"bla") != min("bla", NA)
>
> Just ran these two statements:
>
>> min(NA,"bla")
> [1] NA
>
>> min("bla", NA)
> [1] "bla"
>
> And then reran with explicit na.rm=FALSE
>
>> min(NA,"bla", na.rm=FALSE)
> [1] NA
>
>> min("bla", NA, na.rm=FALSE)
> [1] "bla"
>
>
> That seems wrong. Would this be considered a bug or is there a way to
> explain these results in a different way?
>
> Best,
> Magnus
>
> ps. Tested on R 3.0.1, 32 bit for Windows (as well as some older versions)
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Thu Sep 26 17:42:16 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 26 Sep 2013 08:42:16 -0700
Subject: [R] min(NA,"bla") != min("bla", NA)
In-Reply-To: <52444DA4.3050409@gmail.com>
References: <52444DA4.3050409@gmail.com>
Message-ID: <CACk-te2=gnnb1_KYemhhHJFSs9Af7Bcs65ADprKbD+DR9DV9CQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/fb40484c/attachment.pl>

From smartpink111 at yahoo.com  Thu Sep 26 17:40:45 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 26 Sep 2013 08:40:45 -0700 (PDT)
Subject: [R] min(NA,"bla") != min("bla", NA)
In-Reply-To: <CA+vqiLEymrE65eYj4z-KkfAzHbJRfidccaJ8Y-DC0594Uwy4zg@mail.gmail.com>
References: <52444DA4.3050409@gmail.com>
	<1380208957.16150.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<CA+vqiLEymrE65eYj4z-KkfAzHbJRfidccaJ8Y-DC0594Uwy4zg@mail.gmail.com>
Message-ID: <1380210045.53981.YahooMailNeo@web142603.mail.bf1.yahoo.com>

min(c(NA,"bla"),na.rm=FALSE)
[1] NA
> min(c("bla",NA),na.rm=FALSE)
[1] NA
A.K.



----- Original Message -----
From: Ista Zahn <istazahn at gmail.com>
To: arun <smartpink111 at yahoo.com>
Cc: Magnus Thor Torfason <zulutime.net at gmail.com>; R help <r-help at r-project.org>
Sent: Thursday, September 26, 2013 11:36 AM
Subject: Re: [R] min(NA,"bla") != min("bla", NA)

Hi A.K.,

On Thu, Sep 26, 2013 at 11:22 AM, arun <smartpink111 at yahoo.com> wrote:
> Hi,
>? min(5,1)
> #[1] 1
>
>
>? min(c(1,5))
> #[1] 1
>? min(c(1,5))==min(c(5,1))
> #[1] TRUE
>
>
>
>?  min(c(NA,"bla"))
> #[1] NA
>? min(c("bla",NA))
> #[1] NA
>? min(c("bla",NA),na.rm=FALSE)
> #[1] NA
>? min(c("bla",NA),na.rm=TRUE)
> #[1] "bla"

What is the point of this example? The OP's point was (I hope I am not
putting words in his mouth) that the documentation for ?min says

"? ?  If ?na.rm? is ?FALSE? an ?NA? value in any of the arguments will
? ?  cause a value of ?NA? to be returned, otherwise ?NA? values are
? ?  ignored."

but that appears not to be true:

min("bla", NA)
[1] "bla"

It's not clear to me how your example is relevant.

Best,
Ista

>
> A.K.
>
>
>
> ----- Original Message -----
> From: Magnus Thor Torfason <zulutime.net at gmail.com>
> To: "r-help at r-project.org" <r-help at r-project.org>
> Cc:
> Sent: Thursday, September 26, 2013 11:07 AM
> Subject: [R] min(NA,"bla") != min("bla", NA)
>
> Just ran these two statements:
>
>> min(NA,"bla")
> [1] NA
>
>> min("bla", NA)
> [1] "bla"
>
> And then reran with explicit na.rm=FALSE
>
>> min(NA,"bla", na.rm=FALSE)
> [1] NA
>
>> min("bla", NA, na.rm=FALSE)
> [1] "bla"
>
>
> That seems wrong. Would this be considered a bug or is there a way to
> explain these results in a different way?
>
> Best,
> Magnus
>
> ps. Tested on R 3.0.1, 32 bit for Windows (as well as some older versions)
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Thu Sep 26 17:45:10 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 26 Sep 2013 08:45:10 -0700
Subject: [R] min(NA,"bla") != min("bla", NA)
In-Reply-To: <52444DA4.3050409@gmail.com>
References: <52444DA4.3050409@gmail.com>
Message-ID: <CACk-te2-afuMJwUKV1=P_ZYqO2fKOR504XcbCzpeLY1hgMXWRw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/6b7f1cf8/attachment.pl>

From spyqqqdia at yahoo.com  Thu Sep 26 17:49:30 2013
From: spyqqqdia at yahoo.com (Michael Meyer)
Date: Thu, 26 Sep 2013 23:49:30 +0800 (SGT)
Subject: [R] How to catch errors regarding the hessian in 'optim'
Message-ID: <1380210570.54294.YahooMailNeo@web193403.mail.sg3.yahoo.com>

I am weighing in even though I know nothing.

in tryCatch define an error handler

error = function(e){

????text <- print(e)??????? # surely there must be better ways
????
????# parse text for substring 'optim' or more strongly characteristic substrings 
????# you have already seen to emerge from optim
????# do what you have to do if such is detected
}


Sorry if this answer seems trivial.

Michael Meyer


From wdunlap at tibco.com  Thu Sep 26 17:56:38 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 26 Sep 2013 15:56:38 +0000
Subject: [R] min(NA,"bla") != min("bla", NA)
In-Reply-To: <52444DA4.3050409@gmail.com>
References: <52444DA4.3050409@gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C3461F3@PA-MBX01.na.tibco.com>

I'd say that is a bug.  Furthermore, min(NA, "bla") returns an integer instead
of a character and the results depend on whether the NA is of class "logical"
or "character".
  > str(min(as.logical(NA), "bla")) # expect character NA
   int NA
  > str(min("bla", as.logical(NA))) # expect character NA
   chr "bla"
  > str(min(as.character(NA), "bla")) # expect character NA
   chr "bla"
  > str(min("bla", as.character(NA))) # expect character NA
   chr "bla"

max(NA,"bla") returns the integer NA but does the na.rm=FALSE correctly.

range() seems to get it all right.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Magnus Thor Torfason
> Sent: Thursday, September 26, 2013 8:07 AM
> To: r-help at r-project.org
> Subject: [R] min(NA,"bla") != min("bla", NA)
> 
> Just ran these two statements:
> 
>  > min(NA,"bla")
> [1] NA
> 
>  > min("bla", NA)
> [1] "bla"
> 
> And then reran with explicit na.rm=FALSE
> 
>  > min(NA,"bla", na.rm=FALSE)
> [1] NA
> 
>  > min("bla", NA, na.rm=FALSE)
> [1] "bla"
> 
> 
> That seems wrong. Would this be considered a bug or is there a way to
> explain these results in a different way?
> 
> Best,
> Magnus
> 
> ps. Tested on R 3.0.1, 32 bit for Windows (as well as some older versions)
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Thu Sep 26 18:07:43 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 26 Sep 2013 17:07:43 +0100
Subject: [R] Installing Rcplex
In-Reply-To: <1017655785.1102848.1380182816928.JavaMail.root@marionegri.it>
References: <1017655785.1102848.1380182816928.JavaMail.root@marionegri.it>
Message-ID: <52445BCF.3060308@stats.ox.ac.uk>

On 26/09/2013 09:06, Davide Luciani wrote:
>
> Hi,
>
> I have tried to install the R package Rcplex on windows xp without success. I have only cplex_studio124.win-x86-32 version.
> I have modified the makevars.win file as indicated in the installation guide ( http://cran.r-project.org/web/packages/Rcplex/INSTALL ), then I zipped the whole folder to order an installation from a zipped file (utils :menuInstallLocal())
> The message I had is
>
> file ???src/Makevars.win??? has the wrong MD5 checksum
>
> Plese let me know if you have any help!

That is a message not an error: as you altered the package it will be 
wrong. Simply remove the MD5 file, or use R CMD build to make a new tarball.

>
> Best regards
> Davide
>
>
> ------------------------------------------------------------
>
> Davide Luciani
> Unit?  di Ingegneria della Conoscenza Clinica
> Laboratorio di Epidemiologia Clinica
> Istituto di Ricerche Farmacologiche "Mario Negri"
> Via Giuseppe La Masa, 19
> 20156 Milano
> e-mail: luciani at marionegri.it
> Tel: +39 02 3901 4271
> Fax: +39 02 39014267
> ------------------------------------------------------------
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From wdunlap at tibco.com  Thu Sep 26 18:12:09 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 26 Sep 2013 16:12:09 +0000
Subject: [R] How to catch errors regarding the hessian in 'optim'
In-Reply-To: <1380210570.54294.YahooMailNeo@web193403.mail.sg3.yahoo.com>
References: <1380210570.54294.YahooMailNeo@web193403.mail.sg3.yahoo.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C346221@PA-MBX01.na.tibco.com>

> in tryCatch define an error handler
> 
> error = function(e){
> 
>     text <- print(e)        # surely there must be better ways
> 
>     # parse text for substring 'optim' or more strongly characteristic substrings

Note that print() should aways return its 'x' argument, so 'text' and 'e' will
be identical here.  conditionMessage(e) will give the error message (a character
string) and conditionCall(e) will give the call (a language object) to the function
which threw the error.  You probably want to use grep on conditionMessage(e).

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Michael Meyer
> Sent: Thursday, September 26, 2013 8:50 AM
> To: r-help at r-project.org
> Subject: [R] How to catch errors regarding the hessian in 'optim'
> 
> I am weighing in even though I know nothing.
> 
> in tryCatch define an error handler
> 
> error = function(e){
> 
> ????text <- print(e)??????? # surely there must be better ways
> 
> ????# parse text for substring 'optim' or more strongly characteristic substrings
> ????# you have already seen to emerge from optim
> ????# do what you have to do if such is detected
> }
> 
> 
> Sorry if this answer seems trivial.
> 
> Michael Meyer
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Thu Sep 26 18:15:12 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 26 Sep 2013 11:15:12 -0500
Subject: [R] min(NA,"bla") != min("bla", NA)
In-Reply-To: <1380210045.53981.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <52444DA4.3050409@gmail.com>
	<1380208957.16150.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<CA+vqiLEymrE65eYj4z-KkfAzHbJRfidccaJ8Y-DC0594Uwy4zg@mail.gmail.com>
	<1380210045.53981.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <FC571E8D-7E40-47A4-909B-A347C57D6B46@me.com>

Arun,

This additional example is still irrelevant.

The difference occurs when the two values are passed as the "..." argument to min(), which is a list and is what Magnus was using, versus your examples, where the two values are passed as a single vector, which is coerced to character:

> str(c(NA, "bla"))
 chr [1:2] NA "bla"

as compared to:

> str(list(NA, "bla"))
List of 2
 $ : logi NA
 $ : chr "bla"


Unless there is something in the internal C code, since min() is a .Primitive, where the lexical ordering of the two values NA and "bla" are relevant to the processing of the values and the returned value (eg. a collating sequence issue or a hierarchy of coercion issue), this appears to be a possible bug.

NOTE:

# Returns a int
> str(min(NA, "bla"))
 int NA

# Returns a character
> str(min("bla", NA))
 chr "bla"


However:

# Both return characters
> str(min(as.character(NA), "bla"))
 chr "bla"

> str(min("bla", as.character(NA)))
 chr "bla"


It would appear that in Magnus' example, that NA is passed as a logical in the argument list may be relevant here.

BTW, I can reproduce Magnus' example on 3.0.2 on OSX (10.8.5).

Regards,

Marc Schwartz


On Sep 26, 2013, at 10:40 AM, arun <smartpink111 at yahoo.com> wrote:

> min(c(NA,"bla"),na.rm=FALSE)
> [1] NA
>> min(c("bla",NA),na.rm=FALSE)
> [1] NA
> A.K.
> 
> 
> 
> ----- Original Message -----
> From: Ista Zahn <istazahn at gmail.com>
> To: arun <smartpink111 at yahoo.com>
> Cc: Magnus Thor Torfason <zulutime.net at gmail.com>; R help <r-help at r-project.org>
> Sent: Thursday, September 26, 2013 11:36 AM
> Subject: Re: [R] min(NA,"bla") != min("bla", NA)
> 
> Hi A.K.,
> 
> On Thu, Sep 26, 2013 at 11:22 AM, arun <smartpink111 at yahoo.com> wrote:
>> Hi,
>>   min(5,1)
>> #[1] 1
>> 
>> 
>>   min(c(1,5))
>> #[1] 1
>>   min(c(1,5))==min(c(5,1))
>> #[1] TRUE
>> 
>> 
>> 
>>    min(c(NA,"bla"))
>> #[1] NA
>>   min(c("bla",NA))
>> #[1] NA
>>   min(c("bla",NA),na.rm=FALSE)
>> #[1] NA
>>   min(c("bla",NA),na.rm=TRUE)
>> #[1] "bla"
> 
> What is the point of this example? The OP's point was (I hope I am not
> putting words in his mouth) that the documentation for ?min says
> 
> "     If ?na.rm? is ?FALSE? an ?NA? value in any of the arguments will
>      cause a value of ?NA? to be returned, otherwise ?NA? values are
>      ignored."
> 
> but that appears not to be true:
> 
> min("bla", NA)
> [1] "bla"
> 
> It's not clear to me how your example is relevant.
> 
> Best,
> Ista
> 
>> 
>> A.K.
>> 
>> 
>> 
>> ----- Original Message -----
>> From: Magnus Thor Torfason <zulutime.net at gmail.com>
>> To: "r-help at r-project.org" <r-help at r-project.org>
>> Cc:
>> Sent: Thursday, September 26, 2013 11:07 AM
>> Subject: [R] min(NA,"bla") != min("bla", NA)
>> 
>> Just ran these two statements:
>> 
>>> min(NA,"bla")
>> [1] NA
>> 
>>> min("bla", NA)
>> [1] "bla"
>> 
>> And then reran with explicit na.rm=FALSE
>> 
>>> min(NA,"bla", na.rm=FALSE)
>> [1] NA
>> 
>>> min("bla", NA, na.rm=FALSE)
>> [1] "bla"
>> 
>> 
>> That seems wrong. Would this be considered a bug or is there a way to
>> explain these results in a different way?
>> 
>> Best,
>> Magnus
>> 
>> ps. Tested on R 3.0.1, 32 bit for Windows (as well as some older versions)


From charliethebrown77 at gmail.com  Thu Sep 26 18:24:28 2013
From: charliethebrown77 at gmail.com (Charlie Brown)
Date: Thu, 26 Sep 2013 11:24:28 -0500
Subject: [R] help generalizing the following non-symmetric "identity"-like
	matrix
Message-ID: <CABnkoupW+O7Np=1aBejfCSya-1qjFjgY=1rGPCGedS9fzzRu8Q@mail.gmail.com>

Hi,
I need help generalizing the following non-symmetric "identity"-like matrix
In this case:

p = 5
k=3

and I want this:

I.kp <- cbind(diag(3), c(0, 0, 0), c(0, 0, 0))

How can I generalize this so that I don't have to add/subtract c(0, 0,
... , 0) when p and k changes?

Hopefully that makes sense.
Thanks.
Chuck


From wdunlap at tibco.com  Thu Sep 26 18:31:34 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 26 Sep 2013 16:31:34 +0000
Subject: [R] help generalizing the following non-symmetric
 "identity"-like	matrix
In-Reply-To: <CABnkoupW+O7Np=1aBejfCSya-1qjFjgY=1rGPCGedS9fzzRu8Q@mail.gmail.com>
References: <CABnkoupW+O7Np=1aBejfCSya-1qjFjgY=1rGPCGedS9fzzRu8Q@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C34624C@PA-MBX01.na.tibco.com>

> p <- 5
> k <- 3
> identical(cbind(diag(3), c(0, 0, 0), c(0, 0, 0)), diag(nrow=k, ncol=p))
[1] TRUE

Look at help(diag).

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Charlie Brown
> Sent: Thursday, September 26, 2013 9:24 AM
> To: R-help
> Subject: [R] help generalizing the following non-symmetric "identity"-like matrix
> 
> Hi,
> I need help generalizing the following non-symmetric "identity"-like matrix
> In this case:
> 
> p = 5
> k=3
> 
> and I want this:
> 
> I.kp <- cbind(diag(3), c(0, 0, 0), c(0, 0, 0))
> 
> How can I generalize this so that I don't have to add/subtract c(0, 0,
> ... , 0) when p and k changes?
> 
> Hopefully that makes sense.
> Thanks.
> Chuck
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From msingh59 at ml.com  Thu Sep 26 18:15:36 2013
From: msingh59 at ml.com (Singh, Mandeep - 2)
Date: Thu, 26 Sep 2013 16:15:36 +0000
Subject: [R] RODBC Package help ----binding issue
Message-ID: <5080E6A6ABC683418318A99AD0C3D22DBC269C@smtp_mail.bankofamerica.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/32f03b18/attachment.pl>

From murdoch.duncan at gmail.com  Thu Sep 26 18:45:54 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 26 Sep 2013 12:45:54 -0400
Subject: [R] min(NA,"bla") != min("bla", NA)
In-Reply-To: <52444DA4.3050409@gmail.com>
References: <52444DA4.3050409@gmail.com>
Message-ID: <524464C2.9090007@gmail.com>

On 26/09/2013 11:07 AM, Magnus Thor Torfason wrote:
> Just ran these two statements:
>
>   > min(NA,"bla")
> [1] NA
>
>   > min("bla", NA)
> [1] "bla"
>
> And then reran with explicit na.rm=FALSE
>
>   > min(NA,"bla", na.rm=FALSE)
> [1] NA
>
>   > min("bla", NA, na.rm=FALSE)
> [1] "bla"
>
>
> That seems wrong. Would this be considered a bug or is there a way to
> explain these results in a different way?

I'd call it a bug.  The internal code does a lot of tricky things with 
NA values and type coercion, and it looks as though this particular 
combination got messed up.  I wonder if there are other cases, too?  
I'll take a look.

Duncan Murdoch


From Hui.Du at dataventures.com  Thu Sep 26 18:47:59 2013
From: Hui.Du at dataventures.com (Hui Du)
Date: Thu, 26 Sep 2013 16:47:59 +0000
Subject: [R] plot multiple graphs in one graph and in multiple windows
Message-ID: <13A371591163EE48BD95F2D2B244AAF41C1B18F0@SNICKERS.dataventures.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/3147e2b0/attachment.pl>

From murdoch.duncan at gmail.com  Thu Sep 26 19:55:27 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 26 Sep 2013 13:55:27 -0400
Subject: [R] min(NA,"bla") != min("bla", NA)
In-Reply-To: <52444DA4.3050409@gmail.com>
References: <52444DA4.3050409@gmail.com>
Message-ID: <5244750F.5030502@gmail.com>

On 26/09/2013 11:07 AM, Magnus Thor Torfason wrote:
> Just ran these two statements:
>
>   > min(NA,"bla")
> [1] NA
>
>   > min("bla", NA)
> [1] "bla"
>
> And then reran with explicit na.rm=FALSE
>
>   > min(NA,"bla", na.rm=FALSE)
> [1] NA
>
>   > min("bla", NA, na.rm=FALSE)
> [1] "bla"

This should be all fixed now (at least for min and max; it's possible 
some of the other summary functions still have oddities). It's in 
R-devel, soon r-patched.  All of the above examples should now give a 
character NA.

Duncan Murdoch


From careyshan at gmail.com  Thu Sep 26 19:56:03 2013
From: careyshan at gmail.com (Shane Carey)
Date: Thu, 26 Sep 2013 18:56:03 +0100
Subject: [R] R not ploting lines in the correct order
Message-ID: <CA+jRDxDGO3kmPhiWZKyFG32txEn_f4Mipn7z=Vbe2Lb9EnAH6w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/018a974b/attachment.pl>

From residuo.solow at gmail.com  Thu Sep 26 20:02:50 2013
From: residuo.solow at gmail.com (Sebastian Kruk)
Date: Thu, 26 Sep 2013 15:02:50 -0300
Subject: [R] Help with list
Message-ID: <CAMn86NfENB3ORKZ71-s_LX=agRGNTBAwtW38HT7bnbd6-unFmw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: no disponible
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/634a99e5/attachment.pl>

From sarah.goslee at gmail.com  Thu Sep 26 20:23:41 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 26 Sep 2013 14:23:41 -0400
Subject: [R] R not ploting lines in the correct order
In-Reply-To: <CA+jRDxDGO3kmPhiWZKyFG32txEn_f4Mipn7z=Vbe2Lb9EnAH6w@mail.gmail.com>
References: <CA+jRDxDGO3kmPhiWZKyFG32txEn_f4Mipn7z=Vbe2Lb9EnAH6w@mail.gmail.com>
Message-ID: <CAM_vjunV66rVTk645BNnrVZJUXxu_toBe4+wGhwmHd2JC0QsUQ@mail.gmail.com>

Hi Shane,

Please use dput() to provide your data, rather than pasting it in so
that we can work from the same R object you are. Please also provide
the code you're using to make the graph.

Sarah

On Thu, Sep 26, 2013 at 1:56 PM, Shane Carey <careyshan at gmail.com> wrote:
> Hi,
>
> I have a set of x, y points where x represents dates and y actual values. I
> am trying to plot a line graph of the data with points on top, but R is
> connecting the wrong points with lines. Does anyone know how I can rectify
> this. Please see sample below:
>
> x=
>  24/09/2009 09:13  16/10/2009 11:17  24/10/2009 21:43  11/09/2009
> 18:34  22/08/2009
> 15:45  10/08/2009 00:30  14/08/2009 14:52  24/09/2009 12:19
> 25/10/2009 12:45  07/11/2009 14:07  17/10/2009 10:51  07/11/2009 15:54
> 01/11/2009 19:21  01/11/2009 12:23  02/10/2009 21:25  30/11/2009 11:40
> 26/10/2009 13:21  23/08/2009 13:28  19/12/2009 10:54  09/08/2009 22:45
>  12/09/2009
> 09:39  11/10/2009 11:28  13/08/2009 16:15  10/09/2009 11:01  21/08/2009
> 10:55  30/11/2009 10:03  26/10/2009 17:08  03/10/2009 12:45
>
> y=
>  4.2537264  4.397792  4.5570224  4.284056  3.9959248  4.2992208  4.2916384
> 4.4053744  4.2992208  4.1399904  4.4053744  4.4432864  4.321968  4.0414192
> 4.5418576  4.321968  4.5949344  4.1475728  4.8679008  4.587352  4.1627376
> 4.132408  4.1551552  4.2537264  4.5191104  4.0717488  4.3750448  4.4053744
> Thanks
> --
> Shane
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From ggrothendieck at gmail.com  Thu Sep 26 20:34:22 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 26 Sep 2013 14:34:22 -0400
Subject: [R] Help with list
In-Reply-To: <CAMn86NfENB3ORKZ71-s_LX=agRGNTBAwtW38HT7bnbd6-unFmw@mail.gmail.com>
References: <CAMn86NfENB3ORKZ71-s_LX=agRGNTBAwtW38HT7bnbd6-unFmw@mail.gmail.com>
Message-ID: <CAP01uRnJLGACAgBvi08iHY9S_YPyU4d_GyNRuT5dzKm3jAoU5w@mail.gmail.com>

On Thu, Sep 26, 2013 at 2:02 PM, Sebastian Kruk <residuo.solow at gmail.com> wrote:
> I have a list that gives me the number of occurrences of numbers 1, 2, 3 and
>  4.
>
>
> Sometimes a single in a casa just appears 0 and 1, in others only 2, and every
> combination you can think of.
>
>
> Eg
>
>
>> Caso [1:2]
> $ `9`
>
>
> 0 1
> 2 10
>
>
> $ `13`
>
>
> 0 2
> 2 4
>
>
> Can I turn it into a matrix consisting of 4 columns in which I put the
> number of occurrences of the previous numbers, and for cases where it does
> not appear any of those values put 0?

When creating Caso make the components factors with levels 0:4.

dat <- list("9" = c(0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1), "13" = c(0,
0, 4, 4, 4, 4))
Caso <- lapply(dat, factor, levels = 0:4)
do.call(rbind, lapply(Caso, table))

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From smartpink111 at yahoo.com  Thu Sep 26 20:51:18 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 26 Sep 2013 11:51:18 -0700 (PDT)
Subject: [R] Help with list
In-Reply-To: <CAMn86NfENB3ORKZ71-s_LX=agRGNTBAwtW38HT7bnbd6-unFmw@mail.gmail.com>
References: <CAMn86NfENB3ORKZ71-s_LX=agRGNTBAwtW38HT7bnbd6-unFmw@mail.gmail.com>
Message-ID: <1380221478.48905.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
May be this help:
Please dput() the example dataset:
Caso<- structure(list(`9` = structure(c(2, 10), .Names = c("0", "1")), 
??? `13` = structure(c(2, 4), .Names = c("0", "2"))), .Names = c("9", 
"13"))


nm<-unique(unlist(lapply(Caso,names)))
?vec1<- numeric(length(nm))
names(vec1)<- nm
?do.call(rbind,lapply(Caso,function(x){ indx<- names(vec1)%in% names(x); vec1[indx]<-x;vec1 }))
?#? 0? 1 2
#9? 2 10 0
#13 2? 0 4
A.K.



----- Original Message -----
From: Sebastian Kruk <residuo.solow at gmail.com>
To: R-help <r-help at r-project.org>
Cc: 
Sent: Thursday, September 26, 2013 2:02 PM
Subject: [R] Help with list

I have a list that gives me the number of occurrences of numbers 1, 2, 3 and
4.


Sometimes a single in a casa just appears 0 and 1, in others only 2, and every
combination you can think of.


Eg


> Caso [1:2]
$ `9`


0 1
2 10


$ `13`


0 2
2 4


Can I turn it into a matrix consisting of 4 columns in which I put the
number of occurrences of the previous numbers, and for cases where it does
not appear any of those values put 0?


Regards,


Sebastian.

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From bioprogrammer at gmail.com  Thu Sep 26 22:45:15 2013
From: bioprogrammer at gmail.com (Caitlin)
Date: Thu, 26 Sep 2013 13:45:15 -0700
Subject: [R] Constructing a graph with ggplot2.
Message-ID: <CABDKo+xThR_MwZt3STXkRmK_Yf087pd-awWOx7DNk23-HbyDSA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/18b13ff8/attachment.pl>

From santosh2005 at gmail.com  Thu Sep 26 22:54:57 2013
From: santosh2005 at gmail.com (Santosh)
Date: Thu, 26 Sep 2013 13:54:57 -0700
Subject: [R] Read shortcuts of MS Excel files through R
Message-ID: <CAN_e6XucEQQHSMiZbz3uUwayM80HBCCFuTrBsQA8rKwuT=w5gQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/b6634e96/attachment.pl>

From jluo.rhelp at gmail.com  Thu Sep 26 23:02:58 2013
From: jluo.rhelp at gmail.com (Jack Luo)
Date: Thu, 26 Sep 2013 17:02:58 -0400
Subject: [R] question regarding cast function in reshape package with
 mixture of numeric and character
Message-ID: <CAD-E8+7AoRsMe9asx2iZpjKTMk_n4q6NjLvWA_+-a19O=j4FUA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/978449f0/attachment.pl>

From smartpink111 at yahoo.com  Thu Sep 26 23:15:14 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 26 Sep 2013 14:15:14 -0700 (PDT)
Subject: [R] Grouping Matrix by Columns; OHLC Data
Message-ID: <1380230114.87236.YahooMailNeo@web142603.mail.bf1.yahoo.com>

HI,
May be this helps:

set.seed(24)
?mat1<- matrix(sample(1:60,30*24,replace=TRUE),ncol=24)
colnames(mat1)<- rep(c("O","H","L","C"),6)
indx<-seq_along(colnames(mat1))
n<- length(unique(colnames(mat1)))
?res<- lapply(split(indx,(indx-1)%%n+1),function(i) mat1[,i])
lapply(res,head,2)
#$`1`
#????? O? O? O? O? O? O
#[1,] 18 56 51 24 24 52
#[2,] 14 31 60 12 43 34
#
#$`2`
#????? H? H? H? H? H? H
#[1,] 20? 6? 4 23 10? 2
#[2,] 15 37 22 52 30 42
#
#$`3`
#????? L? L? L? L? L? L
#[1,] 30 25 29? 1 57 16
#[2,] 15 23 15 10 44 60
#
#$`4`
#????? C? C? C? C? C? C
#[1,] 20 13? 8 44? 5 13
#[2,] 45 17 35? 8 25 12

A.K.



Motivation: 

Bring in data containing a number of columns divisable by 4. 
This data contains several different assets and the columns correspond 
to Open,High,Low,Close, ....Open,High,Low,Close, ?etc (thus divisible by
 4). From where I am getting this data, the header is not labled as 
Open,High,Low,Close, but rather just has the asset symbol. 

The end goal is to have each Open,High,Low,Close, ?as its own 
OHLC object, to be run through different volatility functions (via 
QuantMod ) 

I believe i am best served by first grouping the original data 
so that each asset is its own object, with 4 columns. Then i can rename 
the columns to be: 
colnames(function$asset) <-c("Open", "High","Low", "Close") 

I've attempted to use split, but am having trouble with split along the columns. 

Obviously I could manipulate the indexing, with something like 
data[i:i+4] and use a loop. Maybe this indexing approach would work with
 use of apply(). 


Previously, I've been using Mathematica for most of my data 
manipulation, and there I would partition the entire data set i.e. 
Matrix, into ? column# / 4 separate objects. ?So, in that case I have a 3
 dimensional object. I'd then call the object by its 3rd dimension index
 # [][#]. 

I'm having trouble doing that here. Any thoughts, or at the least ?helping me to group the data by column. 

For the sake of possible examples, lets say the dimensions of my data is n.rows = 30, n.col = 24 



From rolf.turner at xtra.co.nz  Thu Sep 26 23:32:23 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Fri, 27 Sep 2013 09:32:23 +1200
Subject: [R] min(NA,"bla") != min("bla", NA)
In-Reply-To: <5244750F.5030502@gmail.com>
References: <52444DA4.3050409@gmail.com> <5244750F.5030502@gmail.com>
Message-ID: <5244A7E7.4060607@xtra.co.nz>


Just to add to the confusion, on my system I get NA --- which I 
understand to be
the correct value --- from all of min(NA,"bla"), min("bla",NA), 
min(c(NA,"bla")), and
min(c("bla",NA)).  When I append the argument na.rm=TRUE to each of the 
calls,
I get "bla" from each.

So, no bug in my system.

> sessionInfo()
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
> [1] C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
>
> other attached packages:
> [1] misc_0.0-15
>
> loaded via a namespace (and not attached):
> [1] tools_3.0.1

Are the rest of youse guys using Windoze?  No wonder ....

     cheers,

     Rolf

On 09/27/13 05:55, Duncan Murdoch wrote:
> On 26/09/2013 11:07 AM, Magnus Thor Torfason wrote:
>> Just ran these two statements:
>>
>>   > min(NA,"bla")
>> [1] NA
>>
>>   > min("bla", NA)
>> [1] "bla"
>>
>> And then reran with explicit na.rm=FALSE
>>
>>   > min(NA,"bla", na.rm=FALSE)
>> [1] NA
>>
>>   > min("bla", NA, na.rm=FALSE)
>> [1] "bla"
>
> This should be all fixed now (at least for min and max; it's possible 
> some of the other summary functions still have oddities). It's in 
> R-devel, soon r-patched.  All of the above examples should now give a 
> character NA.
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From diggsb at ohsu.edu  Thu Sep 26 23:37:39 2013
From: diggsb at ohsu.edu (Brian Diggs)
Date: Thu, 26 Sep 2013 21:37:39 +0000
Subject: [R] Constructing a graph with ggplot2.
References: <CABDKo+xThR_MwZt3STXkRmK_Yf087pd-awWOx7DNk23-HbyDSA@mail.gmail.com>
Message-ID: <49F59CE1FDF43441BE9EE55EB76C4544012ADB@EXMB06.ohsu.edu>

On 9/26/2013 1:45 PM, Caitlin wrote:
> Hi all.
>
> I am attempting to graph data from three lab teams with milligrams of
> maltose shown on the y-axis and 5 pH values (5 to 9) on the x-axis as
> labels. Unfortunately, I can't seem to construct the graph in this manner
> using the following code:
>
> ph1 = c(5, 6, 7, 8, 9)
>   ph2 = ph3 = ph1
>
> e1 = c(0.191, 0.154, 0.179, 0.073, 0.009)
> e2 = c(0, 0.029, 0.054, 0.055, 0.024)
> e3 = c(0.019, 0.027, 0.063, 0.029, 0.039)
> set.seed(1)
> df1 <- data.frame(e1 = sort(runif(5, 0.05, 0.25)),
>                     e2 = sort(runif(5, 0.05, 0.25)),
>                     e3 = sort(runif(5, 0.05, 0.25)),
>                     ph1 = sort(runif(5, 1, 100)),
>                     ph2 = sort(runif(5, 1, 100)),
>                     ph3 = sort(runif(5, 1, 100))
>                     )### reshape this to give a column indicating group
>   df2 <- with(df1,
>           as.data.frame(cbind( c(ph1, ph2, ph3),
>                               c(e1, e2, e3),
>                               rep(seq(3), each=5) )
>                         ))
>   colnames(df2) <- c("ph","maltose_in_mg","team")
>   df2$team <- as.factor(df2$team)
>   library(ggplot2)
>   ggplot(df2, aes(x=ph, y=maltose_in_mg, col=team)) + geom_line()
>
> Since I am still learning both R and ggplot2, I don't know how to proceed
> beyond what I have included here.

It's good form to mention that this was cross posted on StackOverflow: 
http://stackoverflow.com/q/19037565/892313

The comments there indicated that what you were trying to do (and what 
was not working) was not clear, and it has not been made any clearer in 
this duplicate. I gave a stab in the dark that you were looking for 
scale_x_continuous(limits=c(5, 9)), but that is a wild guess.

> Thanks,
>
> ~Caitlin
>
> 	[[alternative HTML version deleted]]
>

-- 
Brian S. Diggs, PhD
Senior Research Associate, Department of Surgery
Oregon Health & Science University


From jdnewmil at dcn.davis.CA.us  Thu Sep 26 23:39:11 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 26 Sep 2013 14:39:11 -0700
Subject: [R] question regarding cast function in reshape package with
	mixture of numeric and character
In-Reply-To: <CAD-E8+7AoRsMe9asx2iZpjKTMk_n4q6NjLvWA_+-a19O=j4FUA@mail.gmail.com>
References: <CAD-E8+7AoRsMe9asx2iZpjKTMk_n4q6NjLvWA_+-a19O=j4FUA@mail.gmail.com>
Message-ID: <0b3ad890-3c2d-4c24-bcd1-1d2265b139f4@email.android.com>

I am baffled. Just what do you want it to do? In melted form the data are all in one column and so are necessarily of one type... there are no mixed types to cast.

As usual, assistance here will be more useful when you follow the Posting Guide and post plain text only and give reproducible examples including dput input data and references to all packages used.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Jack Luo <jluo.rhelp at gmail.com> wrote:
>Hi,
>
>I am trying to process some data frame with cast function to unwind the
>stacked variables. I have no problem using cast when the values are all
>numeric based on the following format:
>
>cast(df,subject~v1+v2+v3....,value = "value",fun.aggregate = mean, fill
>=
>"NA")
>
>However, I am getting some trouble when the "value" variable has a
>mixture
>of numeric and character.
>
>I played around dropping off the fun.aggregate = mean option, but it
>use
>the default: which is the length and not what I want.
>
>I am wondering if there is anyway of doing this?
>
>Many thanks,
>
>-Jack
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From tobebryant at me.com  Thu Sep 26 23:51:10 2013
From: tobebryant at me.com (tobias schlager)
Date: Thu, 26 Sep 2013 23:51:10 +0200
Subject: [R] Sums based on values of other matrix
Message-ID: <F239F22E-A96B-4AAE-BA33-28581378DBE4@me.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/81e9f594/attachment.pl>

From 538280 at gmail.com  Thu Sep 26 23:51:35 2013
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 26 Sep 2013 15:51:35 -0600
Subject: [R] Boxplot from statistics of original data
In-Reply-To: <c5911c76256e48e89d2ec238797327d2@GRXPR80MB064.lamprd80.prod.outlook.com>
References: <c5911c76256e48e89d2ec238797327d2@GRXPR80MB064.lamprd80.prod.outlook.com>
Message-ID: <CAFEqCdwwYpZ2y3MaBMxYX8Sdg=HD63U6UrkbEpL9nBaSO_ojqw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/7a2a9efd/attachment.pl>

From sarah.goslee at gmail.com  Fri Sep 27 00:01:03 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 26 Sep 2013 18:01:03 -0400
Subject: [R] Sums based on values of other matrix
In-Reply-To: <F239F22E-A96B-4AAE-BA33-28581378DBE4@me.com>
References: <F239F22E-A96B-4AAE-BA33-28581378DBE4@me.com>
Message-ID: <CAM_vju=Rn7w8oJUNQq_7NVBj9hi_iN-fj1jj3HLYpmNENb6CPA@mail.gmail.com>

Hi,

You don't say what you want to do with the output, or whether you want
to do it with more than one value, but here's one of the many possible
ways to get your example:

R> A <- matrix(c(1,1,2,2,2,2,1,1), nrow=2, byrow=TRUE)
R> B <- matrix(c(3,4,2,1,1,1,2,2), nrow=2, byrow=TRUE)
R> A
     [,1] [,2] [,3] [,4]
[1,]    1    1    2    2
[2,]    2    2    1    1
R> B
     [,1] [,2] [,3] [,4]
[1,]    3    4    2    1
[2,]    1    1    2    2
R> ifelse(A == 1, B, 0)
     [,1] [,2] [,3] [,4]
[1,]    3    4    0    0
[2,]    0    0    2    2
R> rowSums(ifelse(A == 1, B, 0))
[1] 7 4

Sarah


On Thu, Sep 26, 2013 at 5:51 PM, tobias schlager <tobebryant at me.com> wrote:
> Dear all,
>
> I have a big problem:
> - I got two matrices, A and B
> - A shows identifies the value of B, however the values of B must be summed
> - For instance,
> 1 1 2 2
> 2 2 1 1
> gives matrix a
> 3 4 2 1
> 1 1 2 2
> gives matrix b
>
> Now the result for the value 1 would be
> 7
> 4
> which are the rowsums of the values of matrix B given that matrix A has the value 1.
>
>
> How can I do this automatically? I am really puzzled here. Thanks for your help guys,
> Tobi


-- 
Sarah Goslee
http://www.functionaldiversity.org


From sarah.goslee at gmail.com  Fri Sep 27 00:03:48 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 26 Sep 2013 18:03:48 -0400
Subject: [R] min(NA,"bla") != min("bla", NA)
In-Reply-To: <5244A7E7.4060607@xtra.co.nz>
References: <52444DA4.3050409@gmail.com> <5244750F.5030502@gmail.com>
	<5244A7E7.4060607@xtra.co.nz>
Message-ID: <CAM_vju=oQMrnFBiS=OKdXGP6ovHV6YWznhcwBTL1Zsp7QqGnfQ@mail.gmail.com>

Sorry Rolf, but it's not just Windows (though I completely understand
the urge to blame it):

R> sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-redhat-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=C                 LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] cairoDevice_2.19


R> min(NA,"bla")
[1] NA
R> min("bla",NA)
[1] "bla"
R> min(c(NA,"bla"))
[1] NA
R> min(c("bla",NA))
[1] NA

Sarah

On Thu, Sep 26, 2013 at 5:32 PM, Rolf Turner <rolf.turner at xtra.co.nz> wrote:
>
> Just to add to the confusion, on my system I get NA --- which I understand
> to be
> the correct value --- from all of min(NA,"bla"), min("bla",NA),
> min(c(NA,"bla")), and
> min(c("bla",NA)).  When I append the argument na.rm=TRUE to each of the
> calls,
> I get "bla" from each.
>
> So, no bug in my system.
>
>> sessionInfo()
>> R version 3.0.1 (2013-05-16)
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>
>> locale:
>> [1] C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods base
>>
>> other attached packages:
>> [1] misc_0.0-15
>>
>> loaded via a namespace (and not attached):
>> [1] tools_3.0.1
>
>
> Are the rest of youse guys using Windoze?  No wonder ....
>
>     cheers,
>
>     Rolf
>
> On 09/27/13 05:55, Duncan Murdoch wrote:
>>
>> On 26/09/2013 11:07 AM, Magnus Thor Torfason wrote:
>>>
>>> Just ran these two statements:
>>>
>>>   > min(NA,"bla")
>>> [1] NA
>>>
>>>   > min("bla", NA)
>>> [1] "bla"
>>>
>>> And then reran with explicit na.rm=FALSE
>>>
>>>   > min(NA,"bla", na.rm=FALSE)
>>> [1] NA
>>>
>>>   > min("bla", NA, na.rm=FALSE)
>>> [1] "bla"
>>
>>
>> This should be all fixed now (at least for min and max; it's possible some
>> of the other summary functions still have oddities). It's in R-devel, soon
>> r-patched.  All of the above examples should now give a character NA.
>>
>> Duncan Murdoch
>>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From sarah.goslee at gmail.com  Fri Sep 27 00:05:38 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 26 Sep 2013 18:05:38 -0400
Subject: [R] Read shortcuts of MS Excel files through R
In-Reply-To: <CAN_e6XucEQQHSMiZbz3uUwayM80HBCCFuTrBsQA8rKwuT=w5gQ@mail.gmail.com>
References: <CAN_e6XucEQQHSMiZbz3uUwayM80HBCCFuTrBsQA8rKwuT=w5gQ@mail.gmail.com>
Message-ID: <CAM_vjumcPma_zdVV4z4o59b6Hp7WTB_V8K_s5G6oUcDsN3TBBQ@mail.gmail.com>

Hi,

On Thu, Sep 26, 2013 at 4:54 PM, Santosh <santosh2005 at gmail.com> wrote:
> Dear Rxperts,
>
> Through Windows OS, I created shortcuts (paste as shortcut) to excel
> spreadsheets ( with "xlsx" as the file extension). I wasn't able to read
> the shortcuts through R and using "read" functions of "xlsx" package.

A shortcut isn't an Excel file: it's the operating system that figures
that out. The shortcut itself is just a note to Windows with a file
reference in it. I wouldn't expect R to be able to parse that
reference.

Sarah


> exf <- "a1.xlsx.lnk"
>
>> read.xlsx(exf,1)
> Error in .jcall("RJavaTools", "Ljava/lang/Object;", "invokeMethod", cl,  :
>   java.lang.IllegalArgumentException: Your InputStream was neither an OLE2
> stream, nor an OOXML stream
>> read.xlsx2(exf,1)
> Error in .jcall("RJavaTools", "Ljava/lang/Object;", "invokeMethod", cl,  :
>   java.lang.IllegalArgumentException: Your InputStream was neither an OLE2
> stream, nor an OOXML stream
>
>
> Would truly appreciate your suggestions.
>
> Regards,
> Santosh
>


-- 
Sarah Goslee
http://www.functionaldiversity.org


From dmck at u.washington.edu  Fri Sep 27 00:07:29 2013
From: dmck at u.washington.edu (Don McKenzie)
Date: Thu, 26 Sep 2013 15:07:29 -0700
Subject: [R] min(NA,"bla") != min("bla", NA)
In-Reply-To: <CAM_vju=oQMrnFBiS=OKdXGP6ovHV6YWznhcwBTL1Zsp7QqGnfQ@mail.gmail.com>
References: <52444DA4.3050409@gmail.com> <5244750F.5030502@gmail.com>
	<5244A7E7.4060607@xtra.co.nz>
	<CAM_vju=oQMrnFBiS=OKdXGP6ovHV6YWznhcwBTL1Zsp7QqGnfQ@mail.gmail.com>
Message-ID: <332CE87E-23AF-4ADD-8286-0304A5728BB9@u.washington.edu>

I had the same outcome as Sarah on mac OSX 10.8. R 3.0.1

On Sep 26, 2013, at 3:03 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:

> Sorry Rolf, but it's not just Windows (though I completely understand
> the urge to blame it):
> 
> R> sessionInfo()
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-redhat-linux-gnu (64-bit)
> 
> locale:
> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> [7] LC_PAPER=C                 LC_NAME=C
> [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] cairoDevice_2.19
> 
> 
> R> min(NA,"bla")
> [1] NA
> R> min("bla",NA)
> [1] "bla"
> R> min(c(NA,"bla"))
> [1] NA
> R> min(c("bla",NA))
> [1] NA
> 
> Sarah
> 
> On Thu, Sep 26, 2013 at 5:32 PM, Rolf Turner <rolf.turner at xtra.co.nz> wrote:
>> 
>> Just to add to the confusion, on my system I get NA --- which I understand
>> to be
>> the correct value --- from all of min(NA,"bla"), min("bla",NA),
>> min(c(NA,"bla")), and
>> min(c("bla",NA)).  When I append the argument na.rm=TRUE to each of the
>> calls,
>> I get "bla" from each.
>> 
>> So, no bug in my system.
>> 
>>> sessionInfo()
>>> R version 3.0.1 (2013-05-16)
>>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>> 
>>> locale:
>>> [1] C
>>> 
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods base
>>> 
>>> other attached packages:
>>> [1] misc_0.0-15
>>> 
>>> loaded via a namespace (and not attached):
>>> [1] tools_3.0.1
>> 
>> 
>> Are the rest of youse guys using Windoze?  No wonder ....
>> 
>>    cheers,
>> 
>>    Rolf
>> 
>> On 09/27/13 05:55, Duncan Murdoch wrote:
>>> 
>>> On 26/09/2013 11:07 AM, Magnus Thor Torfason wrote:
>>>> 
>>>> Just ran these two statements:
>>>> 
>>>>> min(NA,"bla")
>>>> [1] NA
>>>> 
>>>>> min("bla", NA)
>>>> [1] "bla"
>>>> 
>>>> And then reran with explicit na.rm=FALSE
>>>> 
>>>>> min(NA,"bla", na.rm=FALSE)
>>>> [1] NA
>>>> 
>>>>> min("bla", NA, na.rm=FALSE)
>>>> [1] "bla"
>>> 
>>> 
>>> This should be all fixed now (at least for min and max; it's possible some
>>> of the other summary functions still have oddities). It's in R-devel, soon
>>> r-patched.  All of the above examples should now give a character NA.
>>> 
>>> Duncan Murdoch
>>> 
> 
> -- 
> Sarah Goslee
> http://www.functionaldiversity.org
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Don McKenzie
Research Ecologist 
Pacific Wildland Fire Sciences Lab 
US Forest Service 
 

Affiliate Professor 
School of Environmental and Forest Sciences 
University of Washington 
 

phone: 206-732-7824 
dmck at uw.edu


From betti_la at hotmail.com  Thu Sep 26 20:25:08 2013
From: betti_la at hotmail.com (Bettina Lado Lindner)
Date: Thu, 26 Sep 2013 15:25:08 -0300
Subject: [R]  Is it possible with two random effects in lme()?
In-Reply-To: a81140100802010530o2c89fe83x6df29f77fbffed1b@mail.gmail.com
Message-ID: <BLU175-DS1276B43694D9CB5E16191EF3280@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/150022cf/attachment.pl>

From alan_randolph at hotmail.com  Thu Sep 26 21:35:46 2013
From: alan_randolph at hotmail.com (Alan Randolph)
Date: Thu, 26 Sep 2013 14:35:46 -0500
Subject: [R] Unexpected input error
In-Reply-To: <COL129-W5422694173A4C357282EFF90280@phx.gbl>
References: <BLU0-SMTP7699C4E37276C4898A6AFA902F0@phx.gbl>,
	<DCE81E14EB74504B971DAD4D2DB0356B0CB926E0D2@crcmail4.BCCRC.CA>,
	<COL129-W5422694173A4C357282EFF90280@phx.gbl>
Message-ID: <COL129-W263BF92222DA9CA2CE086290280@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/fdde6705/attachment.pl>

From John.Gonzalez at gmx.fr  Thu Sep 26 21:47:43 2013
From: John.Gonzalez at gmx.fr (John Gonzalez)
Date: Thu, 26 Sep 2013 21:47:43 +0200
Subject: [R] Re : Re: Re : Re: Re : Privacy rights of an old user of this
	list
Message-ID: <20130926194744.265170@gmx.com>

Dear Uwe,

----- Message d'origine -----
De : Uwe Ligges
Envoy?s : 22.09.13 10:55
? : John Gonzalez
Objet : Re: Re : Re: [R] Re : Privacy rights of an old user of this list

>> On 21.09.2013 22:40, John Gonzalez wrote:
>> As I said previously, I'm only concerned about what was published in the
>> archive of stat.ethz.ch.

>And it is OK to habe your post on Nabble (and many others) after you 
>removed it from stat.ethz.ch? Are the swiss that bad?

Lovely comment. I think I already mentioned that this is not the only server where I sent this request (I had messages removed from other servers already)...

>> I visited https://stat.ethz.ch/mailman/listinfo/r-help to find out where
>> I had to send my request to remove those messages and I read:
>>
>> "R-help list run by maechler at stat.math.ethz.ch, bates at r-project.org"
>>
>> So I emailed these addresses and r-help-owner at r-project.org.s

>Right, Martin Maechler may be on vacations, and he will probably answer 
that he does not remove posts in general.

Thank you. I would definitely prefer to ask him directly. I just saw recently posts from him on the list so I will write him again now.

Sincerely,
John


From munjalpatel85 at gmail.com  Thu Sep 26 22:47:57 2013
From: munjalpatel85 at gmail.com (Munjal Patel)
Date: Thu, 26 Sep 2013 16:47:57 -0400
Subject: [R] ConstrOptim Function (Related to Constraint Matrix/ui/ci
	error)
Message-ID: <CAOWjiK84RVmYOctbSCRrN95yxhBi2ZVRGAaZ=2W_4S6yQ0UC6g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/08f49fef/attachment.pl>

From munjalpatel85 at gmail.com  Thu Sep 26 23:30:21 2013
From: munjalpatel85 at gmail.com (Munjal Patel)
Date: Thu, 26 Sep 2013 17:30:21 -0400
Subject: [R] ConstrOptim function Error
Message-ID: <CAOWjiK_1cyZB7YVMWhmqjGSitiZiEpY_t=STSeK26egrkZNJLA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/fee73bbf/attachment.pl>

From 538280 at gmail.com  Fri Sep 27 00:31:29 2013
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 26 Sep 2013 16:31:29 -0600
Subject: [R] plot multiple graphs in one graph and in multiple windows
In-Reply-To: <13A371591163EE48BD95F2D2B244AAF41C1B18F0@SNICKERS.dataventures.local>
References: <13A371591163EE48BD95F2D2B244AAF41C1B18F0@SNICKERS.dataventures.local>
Message-ID: <CAFEqCdzHLMFEh2TOEh8g24Cysr6BrKPiBr2Giwx4YQvb8v9AZA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/2127ef2a/attachment.pl>

From murdoch.duncan at gmail.com  Fri Sep 27 00:34:18 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 26 Sep 2013 18:34:18 -0400
Subject: [R] min(NA,"bla") != min("bla", NA)
In-Reply-To: <5244A7E7.4060607@xtra.co.nz>
References: <52444DA4.3050409@gmail.com> <5244750F.5030502@gmail.com>
	<5244A7E7.4060607@xtra.co.nz>
Message-ID: <5244B66A.2050206@gmail.com>

On 13-09-26 5:32 PM, Rolf Turner wrote:
>
> Just to add to the confusion, on my system I get NA --- which I
> understand to be
> the correct value --- from all of min(NA,"bla"), min("bla",NA),
> min(c(NA,"bla")), and
> min(c("bla",NA)).  When I append the argument na.rm=TRUE to each of the
> calls,
> I get "bla" from each.
>
> So, no bug in my system.

Very strange.  I suspect it's the fact that you're upside-down :-).

Duncan Murdoch

>
>> sessionInfo()
>> R version 3.0.1 (2013-05-16)
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>
>> locale:
>> [1] C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods base
>>
>> other attached packages:
>> [1] misc_0.0-15
>>
>> loaded via a namespace (and not attached):
>> [1] tools_3.0.1
>
> Are the rest of youse guys using Windoze?  No wonder ....
>
>       cheers,
>
>       Rolf
>
> On 09/27/13 05:55, Duncan Murdoch wrote:
>> On 26/09/2013 11:07 AM, Magnus Thor Torfason wrote:
>>> Just ran these two statements:
>>>
>>>    > min(NA,"bla")
>>> [1] NA
>>>
>>>    > min("bla", NA)
>>> [1] "bla"
>>>
>>> And then reran with explicit na.rm=FALSE
>>>
>>>    > min(NA,"bla", na.rm=FALSE)
>>> [1] NA
>>>
>>>    > min("bla", NA, na.rm=FALSE)
>>> [1] "bla"
>>
>> This should be all fixed now (at least for min and max; it's possible
>> some of the other summary functions still have oddities). It's in
>> R-devel, soon r-patched.  All of the above examples should now give a
>> character NA.
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From smartpink111 at yahoo.com  Fri Sep 27 00:34:27 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 26 Sep 2013 15:34:27 -0700 (PDT)
Subject: [R] Sums based on values of other matrix
In-Reply-To: <F239F22E-A96B-4AAE-BA33-28581378DBE4@me.com>
References: <F239F22E-A96B-4AAE-BA33-28581378DBE4@me.com>
Message-ID: <1380234867.21009.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
Try:
A<- structure(c(1, 2, 1, 2, 2, 1, 2, 1), .Dim = c(2L, 4L))
B<- structure(c(3, 1, 4, 1, 2, 2, 1, 2), .Dim = c(2L, 4L))
?B1<- matrix(0,nrow(B),ncol(B))
B1[A==1]<-B[A==1]
?rowSums(B1)
#[1] 7 4
A.K.




----- Original Message -----
From: tobias schlager <tobebryant at me.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Thursday, September 26, 2013 5:51 PM
Subject: [R] Sums based on values of other matrix

Dear all, 

I have a big problem: 
- I got two matrices, A and B 
- A shows identifies the value of B, however the values of B must be summed 
- For instance, 
1 1 2 2 
2 2 1 1 
gives matrix a 
3 4 2 1 
1 1 2 2 
gives matrix b 

Now the result for the value 1 would be 
7 
4 
which are the rowsums of the values of matrix B given that matrix A has the value 1. 


How can I do this automatically? I am really puzzled here. Thanks for your help guys, 
Tobi
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Fri Sep 27 00:52:11 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 26 Sep 2013 15:52:11 -0700 (PDT)
Subject: [R] Grouping Matrix by Columns; OHLC Data
In-Reply-To: <1380230114.87236.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1380230114.87236.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <1380235931.37231.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi Jake.

Sorry, I misunderstood about what you wanted.
Instead of this:

lapply(split(indx,(indx-1)%%n+1),function(i) mat1[,i])

If I use:
res1<- lapply(split(indx,(indx-1)%/%n+1),function(i) mat1[,i])

#or
lapply(split(indx, as.numeric(gl(ncol(mat1),n,ncol(mat1)))),function(i) mat1[,i])



?lapply(res1,head,2)[1:2]
#$`1`
?# ??? O? H? L? C
#[1,] 18 20 30 20
#[2,] 14 15 15 45
#
#$`2`
?# ??? O? H? L? C
#[1,] 56? 6 25 13
#[2,] 31 37 23 17

A.K.




So, i got it worked out. Thanks for your input. I see that you used a 
mod, which worked well for the application which you solved, and an 
application that will likely come up again. Anyways, here is the 
solution I was lookin for: 


set.seed(24) 
?mat1<- matrix(sample(1:60,30*24,replace=TRUE),ncol=24) 
colnames(mat1)<- rep(c("O","H","L","C"),6) 
indx<-seq_along(colnames(mat1)) 
n<- length(unique(colnames(mat1))) 


res <-lapply(split(indx,rep(1:6,each = 4, times = 1)),function(i) mat1[,i]) 
##rep(1:6,each = 4, times = 1) 
## [1] 1 1 1 1 2 2 2 2 3 3 3 3 4 4 4 4 5 5 5 5 6 6 6 6 

lapply(res,head,2) 


$`1` 
? ? ? O ?H ?L ?C 
[1,] 18 20 30 20 
[2,] 14 15 15 45 

$`2` 
? ? ? O ?H ?L ?C 
[1,] 56 ?6 25 13 
[2,] 31 37 23 17 

$`3` 
? ? ? O ?H ?L ?C 
[1,] 51 ?4 29 ?8 
[2,] 60 22 15 35 

$`4` 
? ? ? O ?H ?L ?C 
[1,] 24 23 ?1 44 
[2,] 12 52 10 ?8 

$`5` 
? ? ? O ?H ?L ?C 
[1,] 24 10 57 ?5 
[2,] 43 30 44 25 

$`6` 
? ? ? O ?H ?L ?C 
[1,] 52 ?2 16 13 
[2,] 34 42 60 12 

Thanks again 


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Thursday, September 26, 2013 5:15 PM
Subject: Re: Grouping Matrix by Columns; OHLC Data

HI,
May be this helps:

set.seed(24)
?mat1<- matrix(sample(1:60,30*24,replace=TRUE),ncol=24)
colnames(mat1)<- rep(c("O","H","L","C"),6)
indx<-seq_along(colnames(mat1))
n<- length(unique(colnames(mat1)))
?res<- lapply(split(indx,(indx-1)%%n+1),function(i) mat1[,i])
lapply(res,head,2)
#$`1`
#????? O? O? O? O? O? O
#[1,] 18 56 51 24 24 52
#[2,] 14 31 60 12 43 34
#
#$`2`
#????? H? H? H? H? H? H
#[1,] 20? 6? 4 23 10? 2
#[2,] 15 37 22 52 30 42
#
#$`3`
#????? L? L? L? L? L? L
#[1,] 30 25 29? 1 57 16
#[2,] 15 23 15 10 44 60
#
#$`4`
#????? C? C? C? C? C? C
#[1,] 20 13? 8 44? 5 13
#[2,] 45 17 35? 8 25 12

A.K.



Motivation: 

Bring in data containing a number of columns divisable by 4. 
This data contains several different assets and the columns correspond 
to Open,High,Low,Close, ....Open,High,Low,Close, ?etc (thus divisible by
4). From where I am getting this data, the header is not labled as 
Open,High,Low,Close, but rather just has the asset symbol. 

The end goal is to have each Open,High,Low,Close, ?as its own 
OHLC object, to be run through different volatility functions (via 
QuantMod ) 

I believe i am best served by first grouping the original data 
so that each asset is its own object, with 4 columns. Then i can rename 
the columns to be: 
colnames(function$asset) <-c("Open", "High","Low", "Close") 

I've attempted to use split, but am having trouble with split along the columns. 

Obviously I could manipulate the indexing, with something like 
data[i:i+4] and use a loop. Maybe this indexing approach would work with
use of apply(). 


Previously, I've been using Mathematica for most of my data 
manipulation, and there I would partition the entire data set i.e. 
Matrix, into ? column# / 4 separate objects. ?So, in that case I have a 3
dimensional object. I'd then call the object by its 3rd dimension index
# [][#]. 

I'm having trouble doing that here. Any thoughts, or at the least ?helping me to group the data by column. 

For the sake of possible examples, lets say the dimensions of my data is n.rows = 30, n.col = 24 



From murdoch.duncan at gmail.com  Fri Sep 27 01:07:41 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 26 Sep 2013 19:07:41 -0400
Subject: [R] min(NA,"bla") != min("bla", NA)
In-Reply-To: <5244A7E7.4060607@xtra.co.nz>
References: <52444DA4.3050409@gmail.com> <5244750F.5030502@gmail.com>
	<5244A7E7.4060607@xtra.co.nz>
Message-ID: <5244BE3D.2010300@gmail.com>

On 13-09-26 5:32 PM, Rolf Turner wrote:
>
> Just to add to the confusion, on my system I get NA --- which I
> understand to be
> the correct value --- from all of min(NA,"bla"), min("bla",NA),
> min(c(NA,"bla")), and
> min(c("bla",NA)).  When I append the argument na.rm=TRUE to each of the
> calls,
> I get "bla" from each.
>
> So, no bug in my system.

I've just built a 3.0.1 version, and I definitely see the bug there. 
What do you get from these expressions?

str(min(NA, "bla"))
str(min("bla", NA))
str(min(NA_character_, "bla"))

I get

 > str(min(NA, "bla"))
  int NA
 > str(min("bla", NA))
  chr "bla"
 > str(min(NA_character_, "bla"))
  chr "bla"

on both Windows and OSX R 3.0.1.  After today's patch, I get

  chr NA

for all three.

Duncan Murdoch



>
>> sessionInfo()
>> R version 3.0.1 (2013-05-16)
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>
>> locale:
>> [1] C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods base
>>
>> other attached packages:
>> [1] misc_0.0-15
>>
>> loaded via a namespace (and not attached):
>> [1] tools_3.0.1
>
> Are the rest of youse guys using Windoze?  No wonder ....
>
>       cheers,
>
>       Rolf
>
> On 09/27/13 05:55, Duncan Murdoch wrote:
>> On 26/09/2013 11:07 AM, Magnus Thor Torfason wrote:
>>> Just ran these two statements:
>>>
>>>    > min(NA,"bla")
>>> [1] NA
>>>
>>>    > min("bla", NA)
>>> [1] "bla"
>>>
>>> And then reran with explicit na.rm=FALSE
>>>
>>>    > min(NA,"bla", na.rm=FALSE)
>>> [1] NA
>>>
>>>    > min("bla", NA, na.rm=FALSE)
>>> [1] "bla"
>>
>> This should be all fixed now (at least for min and max; it's possible
>> some of the other summary functions still have oddities). It's in
>> R-devel, soon r-patched.  All of the above examples should now give a
>> character NA.
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From rolf.turner at xtra.co.nz  Fri Sep 27 01:05:26 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Fri, 27 Sep 2013 11:05:26 +1200
Subject: [R] min(NA,"bla") != min("bla", NA)
In-Reply-To: <5244B66A.2050206@gmail.com>
References: <52444DA4.3050409@gmail.com> <5244750F.5030502@gmail.com>
	<5244A7E7.4060607@xtra.co.nz> <5244B66A.2050206@gmail.com>
Message-ID: <5244BDB6.9060906@xtra.co.nz>

On 09/27/13 10:34, Duncan Murdoch wrote:
> On 13-09-26 5:32 PM, Rolf Turner wrote:
>>
>> Just to add to the confusion, on my system I get NA --- which I
>> understand to be
>> the correct value --- from all of min(NA,"bla"), min("bla",NA),
>> min(c(NA,"bla")), and
>> min(c("bla",NA)).  When I append the argument na.rm=TRUE to each of the
>> calls,
>> I get "bla" from each.
>>
>> So, no bug in my system.
>
> Very strange.  I suspect it's the fact that you're upside-down :-).

Ah, but we are actually the right way up!!!

Hmm.  I got an email from arun saying that he was using Linux and R 
3.0.2 --- so I
conjecture for a while that perhaps the bug had been introduced in going 
from 3.0.1
to 3.0.2.  (So maybe everybody should downgrade.) But then I got 
messages from
Sarah Goslee and from Don McKenzie saying that they were using Linux and 
R 3.0.1
as well, and the bug showed up for them.   So it is all very mysterious.

Good luck in tracking down the problem.

     cheers,

     Rolf


From bbolker at gmail.com  Fri Sep 27 01:05:22 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 26 Sep 2013 23:05:22 +0000
Subject: [R] Is it possible with two random effects in lme()?
References: <BLU175-DS1276B43694D9CB5E16191EF3280@phx.gbl>
Message-ID: <loom.20130927T010403-738@post.gmane.org>

Bettina Lado Lindner <betti_la <at> hotmail.com> writes:


> Hello, 
> I want two random effect in R. One is BLOQUE nested in REP 
> and the other is TRAT. I don???t know how put TRAT
> independant of the other random effect.

[snip]

> I know that in lmer is easier but I use error correlation 
> so I need use lme.
> Bettina

  This (crossed random effects) is possible but not that easy: 
you should (1) study the
later chapters of Pinheiro and Bates 2000 and (2) re-post this
question to r-sig-mixed-models at r-project.org.

  good luck,
   Ben Bolker


From gunter.berton at gene.com  Fri Sep 27 01:07:32 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 26 Sep 2013 16:07:32 -0700
Subject: [R] Is it possible with two random effects in lme()?
In-Reply-To: <BLU175-DS1276B43694D9CB5E16191EF3280@phx.gbl>
References: <BLU175-DS1276B43694D9CB5E16191EF3280@phx.gbl>
Message-ID: <CACk-te1oPWtYKaRCSUbN4ApbBtJA2njO_DRH5iJWk2ACh3Hm+A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/e8363d20/attachment.pl>

From smartpink111 at yahoo.com  Fri Sep 27 01:15:29 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 26 Sep 2013 16:15:29 -0700 (PDT)
Subject: [R] Sums based on values of other matrix
In-Reply-To: <1380234867.21009.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <F239F22E-A96B-4AAE-BA33-28581378DBE4@me.com>
	<1380234867.21009.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1380237329.51395.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
If you have missing values:
?set.seed(125)
?A<- matrix(sample(c(NA,0:9),10*10,replace=TRUE),10,10)
?set.seed(49)
?B<- matrix(sample(c(NA,1:25),10*10,replace=TRUE),10,10)
B1<- matrix(0,nrow=nrow(B),ncol=ncol(B))
?B1[A==1 & !is.na(A)]<- B[A==1 & !is.na(A)]
?rowSums(B1)
?#[1]? 0? 0 38? 7 16? 0? 0? 1? 6 18


#Speed comparison

set.seed(485)
Anew<- matrix(sample(c(NA,0:9),3e5*70,replace=TRUE),3e5,70)
set.seed(944)
Bnew<- matrix(sample(c(NA,1:25),3e5*70,replace=TRUE),3e5,70)
B2<- Bnew
B3<- matrix(0,nrow=nrow(Bnew),ncol=ncol(Bnew))

system.time({
?B3[Anew==1 & !is.na(Anew)]<- Bnew[Anew==1 & !is.na(Anew)]
res1<- rowSums(B3)
})
# user? system elapsed 
#? 2.916?? 0.308?? 3.232 

system.time({
vec1<-ifelse(Anew == 1 & !is.na(Anew), B2, 0)
res2<- rowSums(vec1)
})
# user? system elapsed 
#? 7.012?? 0.744?? 7.775 
?identical(res1,res2)
#[1] TRUE


A.K.



Dear Sarah, 

this works very well! If fulfills what I need, however, there is
 a small performance problem: I have 300.000 rows and 70 columns. With 
missing values. 
Besides that you directly hit the key. 

Thanks, 
Tobias 


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: tobias schlager <tobebryant at me.com>
Cc: R help <r-help at r-project.org>
Sent: Thursday, September 26, 2013 6:34 PM
Subject: Re: [R] Sums based on values of other matrix

Hi,
Try:
A<- structure(c(1, 2, 1, 2, 2, 1, 2, 1), .Dim = c(2L, 4L))
B<- structure(c(3, 1, 4, 1, 2, 2, 1, 2), .Dim = c(2L, 4L))
?B1<- matrix(0,nrow(B),ncol(B))
B1[A==1]<-B[A==1]
?rowSums(B1)
#[1] 7 4
A.K.




----- Original Message -----
From: tobias schlager <tobebryant at me.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Thursday, September 26, 2013 5:51 PM
Subject: [R] Sums based on values of other matrix

Dear all, 

I have a big problem: 
- I got two matrices, A and B 
- A shows identifies the value of B, however the values of B must be summed 
- For instance, 
1 1 2 2 
2 2 1 1 
gives matrix a 
3 4 2 1 
1 1 2 2 
gives matrix b 

Now the result for the value 1 would be 
7 
4 
which are the rowsums of the values of matrix B given that matrix A has the value 1. 


How can I do this automatically? I am really puzzled here. Thanks for your help guys, 
Tobi
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Fri Sep 27 01:23:03 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 26 Sep 2013 16:23:03 -0700 (PDT)
Subject: [R] Sums based on values of other matrix
In-Reply-To: <1380237329.51395.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <F239F22E-A96B-4AAE-BA33-28581378DBE4@me.com>
	<1380234867.21009.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1380237329.51395.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1380237783.89132.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Just to add:

If you had missing values in both matrices, then some values in B matrix that are NA's could also replace the values in A that are 1.

So, it is better to use:
rowSums(B1,na.rm=TRUE)
A.K.




----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: tobias schlager <tobebryant at me.com>
Cc: R help <r-help at r-project.org>
Sent: Thursday, September 26, 2013 7:15 PM
Subject: Re: [R] Sums based on values of other matrix

Hi,
If you have missing values:
?set.seed(125)
?A<- matrix(sample(c(NA,0:9),10*10,replace=TRUE),10,10)
?set.seed(49)
?B<- matrix(sample(c(NA,1:25),10*10,replace=TRUE),10,10)
B1<- matrix(0,nrow=nrow(B),ncol=ncol(B))
?B1[A==1 & !is.na(A)]<- B[A==1 & !is.na(A)]
?rowSums(B1)
?#[1]? 0? 0 38? 7 16? 0? 0? 1? 6 18


#Speed comparison

set.seed(485)
Anew<- matrix(sample(c(NA,0:9),3e5*70,replace=TRUE),3e5,70)
set.seed(944)
Bnew<- matrix(sample(c(NA,1:25),3e5*70,replace=TRUE),3e5,70)
B2<- Bnew
B3<- matrix(0,nrow=nrow(Bnew),ncol=ncol(Bnew))

system.time({
?B3[Anew==1 & !is.na(Anew)]<- Bnew[Anew==1 & !is.na(Anew)]
res1<- rowSums(B3)
})
# user? system elapsed 
#? 2.916?? 0.308?? 3.232 

system.time({
vec1<-ifelse(Anew == 1 & !is.na(Anew), B2, 0)
res2<- rowSums(vec1)
})
# user? system elapsed 
#? 7.012?? 0.744?? 7.775 
?identical(res1,res2)
#[1] TRUE


A.K.



Dear Sarah, 

this works very well! If fulfills what I need, however, there is
a small performance problem: I have 300.000 rows and 70 columns. With 
missing values. 
Besides that you directly hit the key. 

Thanks, 
Tobias 


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: tobias schlager <tobebryant at me.com>
Cc: R help <r-help at r-project.org>
Sent: Thursday, September 26, 2013 6:34 PM
Subject: Re: [R] Sums based on values of other matrix

Hi,
Try:
A<- structure(c(1, 2, 1, 2, 2, 1, 2, 1), .Dim = c(2L, 4L))
B<- structure(c(3, 1, 4, 1, 2, 2, 1, 2), .Dim = c(2L, 4L))
?B1<- matrix(0,nrow(B),ncol(B))
B1[A==1]<-B[A==1]
?rowSums(B1)
#[1] 7 4
A.K.




----- Original Message -----
From: tobias schlager <tobebryant at me.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Thursday, September 26, 2013 5:51 PM
Subject: [R] Sums based on values of other matrix

Dear all, 

I have a big problem: 
- I got two matrices, A and B 
- A shows identifies the value of B, however the values of B must be summed 
- For instance, 
1 1 2 2 
2 2 1 1 
gives matrix a 
3 4 2 1 
1 1 2 2 
gives matrix b 

Now the result for the value 1 would be 
7 
4 
which are the rowsums of the values of matrix B given that matrix A has the value 1. 


How can I do this automatically? I am really puzzled here. Thanks for your help guys, 
Tobi
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From marc_schwartz at me.com  Fri Sep 27 02:43:16 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 26 Sep 2013 19:43:16 -0500
Subject: [R] Read shortcuts of MS Excel files through R
In-Reply-To: <CAM_vjumcPma_zdVV4z4o59b6Hp7WTB_V8K_s5G6oUcDsN3TBBQ@mail.gmail.com>
References: <CAN_e6XucEQQHSMiZbz3uUwayM80HBCCFuTrBsQA8rKwuT=w5gQ@mail.gmail.com>
	<CAM_vjumcPma_zdVV4z4o59b6Hp7WTB_V8K_s5G6oUcDsN3TBBQ@mail.gmail.com>
Message-ID: <4AA532C1-A156-4D31-B59D-1BE25979E229@me.com>

Hi,

I am not on Windows so cannot test this, but a search reveals that in the R.utils CRAN package by Henrik Bengtsson, there is the readWindowsShortcut() function which may provide some assistance in getting the path to the actual file.

Thus:
   
  install.package("R.utils", dependencies = TRUE) # depends upon 'R.oo'
  require(R.utils)
  ?readWindowsShortcut


Regards,

Marc Schwartz


On Sep 26, 2013, at 5:05 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:

> Hi,
> 
> On Thu, Sep 26, 2013 at 4:54 PM, Santosh <santosh2005 at gmail.com> wrote:
>> Dear Rxperts,
>> 
>> Through Windows OS, I created shortcuts (paste as shortcut) to excel
>> spreadsheets ( with "xlsx" as the file extension). I wasn't able to read
>> the shortcuts through R and using "read" functions of "xlsx" package.
> 
> A shortcut isn't an Excel file: it's the operating system that figures
> that out. The shortcut itself is just a note to Windows with a file
> reference in it. I wouldn't expect R to be able to parse that
> reference.
> 
> Sarah
> 
> 
>> exf <- "a1.xlsx.lnk"
>> 
>>> read.xlsx(exf,1)
>> Error in .jcall("RJavaTools", "Ljava/lang/Object;", "invokeMethod", cl,  :
>>  java.lang.IllegalArgumentException: Your InputStream was neither an OLE2
>> stream, nor an OOXML stream
>>> read.xlsx2(exf,1)
>> Error in .jcall("RJavaTools", "Ljava/lang/Object;", "invokeMethod", cl,  :
>>  java.lang.IllegalArgumentException: Your InputStream was neither an OLE2
>> stream, nor an OOXML stream
>> 
>> 
>> Would truly appreciate your suggestions.
>> 
>> Regards,
>> Santosh
>> 
> 
> 
> -- 
> Sarah Goslee
> http://www.functionaldiversity.org
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jim at bitwrit.com.au  Fri Sep 27 03:06:52 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 27 Sep 2013 11:06:52 +1000
Subject: [R] Boxplot from statistics of original data
In-Reply-To: <c5911c76256e48e89d2ec238797327d2@GRXPR80MB064.lamprd80.prod.outlook.com>
References: <c5911c76256e48e89d2ec238797327d2@GRXPR80MB064.lamprd80.prod.outlook.com>
Message-ID: <5244DA2C.1020206@bitwrit.com.au>

On 09/27/2013 12:10 AM, Rodrigo C?sar da Silva wrote:
>
> Hi, I have a data set that contains a set of universities and a number of statistics about the performance of students on an exam.  A sample of the table follows:
>
> Institutions_Name
>
> Mean
>
> Median
>
> Minimum
>
> Maximum
>
> 1Quartile
>
> 3Quartile
>
> CENTRO UNIVERSIT?RIO LUTERANO DE MANAUS
>
> 58,5
>
> 57,5
>
> 0
>
> 98
>
> 27,6%
>
> 13,8%
> ...

Hi Rodrigo,
I was about to answer this post last night when I noticed that you seem 
to have different measures for the last two values in each set. Unless I 
am sadly mistaken, the first and third quartile should bracket the 
median. I would check what these two figures mean before trying to build 
a boxplot.

Jim


From rolf.turner at xtra.co.nz  Fri Sep 27 03:10:01 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Fri, 27 Sep 2013 13:10:01 +1200
Subject: [R] min(NA,"bla") != min("bla", NA)
In-Reply-To: <5244BE3D.2010300@gmail.com>
References: <52444DA4.3050409@gmail.com> <5244750F.5030502@gmail.com>
	<5244A7E7.4060607@xtra.co.nz> <5244BE3D.2010300@gmail.com>
Message-ID: <5244DAE9.3040804@xtra.co.nz>

On 09/27/13 11:07, Duncan Murdoch wrote:
> On 13-09-26 5:32 PM, Rolf Turner wrote:
>>
>> Just to add to the confusion, on my system I get NA --- which I
>> understand to be
>> the correct value --- from all of min(NA,"bla"), min("bla",NA),
>> min(c(NA,"bla")), and
>> min(c("bla",NA)).  When I append the argument na.rm=TRUE to each of the
>> calls,
>> I get "bla" from each.
>>
>> So, no bug in my system.
>
> I've just built a 3.0.1 version, and I definitely see the bug there. 
> What do you get from these expressions?
>
> str(min(NA, "bla"))
> str(min("bla", NA))
> str(min(NA_character_, "bla"))
>
> I get
>
> > str(min(NA, "bla"))
>  int NA
> > str(min("bla", NA))
>  chr "bla"
> > str(min(NA_character_, "bla"))
>  chr "bla"
>
> on both Windows and OSX R 3.0.1.  After today's patch, I get
>
>  chr NA
>
> for all three.

I get:

 > str(min(NA, "bla"))
  int NA
  > str(min("bla", NA))
  chr NA
 > str(min(NA_character_, "bla"))
  chr NA

Which looks to me to be as it should be.  How come my system's so good
compared to others? :-)

     cheers,

     Rolf


From istazahn at gmail.com  Fri Sep 27 03:26:09 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 26 Sep 2013 21:26:09 -0400
Subject: [R] min(NA,"bla") != min("bla", NA)
In-Reply-To: <5244DAE9.3040804@xtra.co.nz>
References: <52444DA4.3050409@gmail.com> <5244750F.5030502@gmail.com>
	<5244A7E7.4060607@xtra.co.nz> <5244BE3D.2010300@gmail.com>
	<5244DAE9.3040804@xtra.co.nz>
Message-ID: <CA+vqiLHGhN92k0khBADxxB0BY+cdBGeM3MpvRCWGMhYC_vDb7g@mail.gmail.com>

On Thu, Sep 26, 2013 at 9:10 PM, Rolf Turner <rolf.turner at xtra.co.nz> wrote:
> On 09/27/13 11:07, Duncan Murdoch wrote:
>>
>> On 13-09-26 5:32 PM, Rolf Turner wrote:
>>>
>>>
>>> Just to add to the confusion, on my system I get NA --- which I
>>> understand to be
>>> the correct value --- from all of min(NA,"bla"), min("bla",NA),
>>> min(c(NA,"bla")), and
>>> min(c("bla",NA)).  When I append the argument na.rm=TRUE to each of the
>>> calls,
>>> I get "bla" from each.
>>>
>>> So, no bug in my system.
>>
>>
>> I've just built a 3.0.1 version, and I definitely see the bug there. What
>> do you get from these expressions?
>>
>> str(min(NA, "bla"))
>> str(min("bla", NA))
>> str(min(NA_character_, "bla"))
>>
>> I get
>>
>> > str(min(NA, "bla"))
>>  int NA
>> > str(min("bla", NA))
>>  chr "bla"
>> > str(min(NA_character_, "bla"))
>>  chr "bla"
>>
>> on both Windows and OSX R 3.0.1.  After today's patch, I get
>>
>>  chr NA
>>
>> for all three.
>
>
> I get:
>
>> str(min(NA, "bla"))
>  int NA
>  > str(min("bla", NA))
>  chr NA
>> str(min(NA_character_, "bla"))
>  chr NA
>
> Which looks to me to be as it should be.  How come my system's so good
> compared to others? :-)

It's not; you just have your locale set differently;

> Sys.getlocale()
[1] "LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=en_US.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C"
> for(l in letters) print(min(l, NA))
[1] "a"
[1] "b"
[1] "c"
[1] "d"
[1] "e"
[1] "f"
[1] "g"
[1] "h"
[1] "i"
[1] "j"
[1] "k"
[1] "l"
[1] "m"
[1] "n"
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
> Sys.setlocale("LC_ALL", "C")
[1] "LC_CTYPE=C;LC_NUMERIC=C;LC_TIME=C;LC_COLLATE=C;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C"
> for(l in letters) print(min(l, NA))
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
[1] NA
> sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=C                 LC_NUMERIC=C
 [3] LC_TIME=C                  LC_COLLATE=C
 [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=C                 LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

Best,
Ista

>
>     cheers,
>
>     Rolf
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Fri Sep 27 03:38:11 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 26 Sep 2013 21:38:11 -0400
Subject: [R] min(NA,"bla") != min("bla", NA)
In-Reply-To: <CA+vqiLHGhN92k0khBADxxB0BY+cdBGeM3MpvRCWGMhYC_vDb7g@mail.gmail.com>
References: <52444DA4.3050409@gmail.com> <5244750F.5030502@gmail.com>
	<5244A7E7.4060607@xtra.co.nz> <5244BE3D.2010300@gmail.com>
	<5244DAE9.3040804@xtra.co.nz>
	<CA+vqiLHGhN92k0khBADxxB0BY+cdBGeM3MpvRCWGMhYC_vDb7g@mail.gmail.com>
Message-ID: <5244E183.50105@gmail.com>

On 13-09-26 9:26 PM, Ista Zahn wrote:
> On Thu, Sep 26, 2013 at 9:10 PM, Rolf Turner <rolf.turner at xtra.co.nz> wrote:
>> On 09/27/13 11:07, Duncan Murdoch wrote:
>>>
>>> On 13-09-26 5:32 PM, Rolf Turner wrote:
>>>>
>>>>
>>>> Just to add to the confusion, on my system I get NA --- which I
>>>> understand to be
>>>> the correct value --- from all of min(NA,"bla"), min("bla",NA),
>>>> min(c(NA,"bla")), and
>>>> min(c("bla",NA)).  When I append the argument na.rm=TRUE to each of the
>>>> calls,
>>>> I get "bla" from each.
>>>>
>>>> So, no bug in my system.
>>>
>>>
>>> I've just built a 3.0.1 version, and I definitely see the bug there. What
>>> do you get from these expressions?
>>>
>>> str(min(NA, "bla"))
>>> str(min("bla", NA))
>>> str(min(NA_character_, "bla"))
>>>
>>> I get
>>>
>>>> str(min(NA, "bla"))
>>>   int NA
>>>> str(min("bla", NA))
>>>   chr "bla"
>>>> str(min(NA_character_, "bla"))
>>>   chr "bla"
>>>
>>> on both Windows and OSX R 3.0.1.  After today's patch, I get
>>>
>>>   chr NA
>>>
>>> for all three.
>>
>>
>> I get:
>>
>>> str(min(NA, "bla"))
>>   int NA
>>   > str(min("bla", NA))
>>   chr NA
>>> str(min(NA_character_, "bla"))
>>   chr NA
>>
>> Which looks to me to be as it should be.  How come my system's so good
>> compared to others? :-)
>
> It's not; you just have your locale set differently;

Nice catch.  The good news is that min() works in the C locale; the bad 
news is that max() doesn't.  But both work after today's patch.

Duncan Murdoch

>
>> Sys.getlocale()
> [1] "LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=en_US.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C"
>> for(l in letters) print(min(l, NA))
> [1] "a"
> [1] "b"
> [1] "c"
> [1] "d"
> [1] "e"
> [1] "f"
> [1] "g"
> [1] "h"
> [1] "i"
> [1] "j"
> [1] "k"
> [1] "l"
> [1] "m"
> [1] "n"
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
>> Sys.setlocale("LC_ALL", "C")
> [1] "LC_CTYPE=C;LC_NUMERIC=C;LC_TIME=C;LC_COLLATE=C;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C"
>> for(l in letters) print(min(l, NA))
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
> [1] NA
>> sessionInfo()
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>   [1] LC_CTYPE=C                 LC_NUMERIC=C
>   [3] LC_TIME=C                  LC_COLLATE=C
>   [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=C                 LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> Best,
> Ista
>
>>
>>      cheers,
>>
>>      Rolf
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From ross at biostat.ucsf.edu  Fri Sep 27 05:36:26 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu, 26 Sep 2013 20:36:26 -0700
Subject: [R] somewhat ineffective suppressing intercepts
Message-ID: <1380252986.5913.37.camel@localhost>

Suppressing the intercept and contr.sum coding are not quite working as
I expect:
> mf <- data.frame(A=C(factor(c("a", "b", "c")), contr.sum))
> mm <- model.matrix(~0+A, data=mf)
> mm
  Aa Ab Ac
1  1  0  0
2  0  1  0
3  0  0  1

What I expect (and want) is
   A1  A2
1  1    0
2  0    1
3  1    1

When I do more complicated models every term except the first one is
coded as expected.  That includes A itself if interacted with other
variables.

It seems R has decided the model really needs an intercept and is
throwing in an extra level for the first factor to assure that I get it,
even though I said with the "0" that I didn't want it.

BTW, ~A produces an intercept and the two columns expected above.  But I
don't want the intercept; the model matrix is going into a multinomial
model for which the intercept is not identified (since all intercepts
produce the same predicted probabilities).

What's going on here?

R 2.15.1


P.S. I think the above stripped down example illustrates the problem,
but here's a more expanded model:

> mf <- expand.grid(C(factor(c("a", "b", "c")), contr.sum),
+                   C(factor(c("f", "t")), contr.sum))
> colnames(mf) <- c("A", "H")
> mf$x <- seq(6)
> mf
  A H x
1 a f 1
2 b f 2
3 c f 3
4 a t 4
5 b t 5
6 c t 6
> myformula <- ~0+A*H*x
> mm <- model.matrix(myformula, data=mf)
> mm
  Aa Ab Ac H1 x A1:H1 A2:H1 A1:x A2:x H1:x A1:H1:x A2:H1:x
1  1  0  0  1 1     1     0    1    0    1       1       0
2  0  1  0  1 2     0     1    0    2    2       0       2
3  0  0  1  1 3    -1    -1   -3   -3    3      -3      -3
4  1  0  0 -1 4    -1     0    4    0   -4      -4       0
5  0  1  0 -1 5     0    -1    0    5   -5       0      -5
6  0  0  1 -1 6     1     1   -6   -6   -6       6       6


From jeffrey.flint at gmail.com  Fri Sep 27 03:26:19 2013
From: jeffrey.flint at gmail.com (Jeffrey Flint)
Date: Thu, 26 Sep 2013 18:26:19 -0700
Subject: [R] snow::makeCluster on Windows hangs
Message-ID: <CALbUM4O60G0CJrWckm=_4rL0MBkZO4M3zZkgZE+T7Ubc6Q1zSA@mail.gmail.com>

The command which hangs:
I'm hoping there is a simple explanation, but I searched on-line and
nothing jumped out.

> cl <- makeCluster(type="SOCK",c("localhost"),manual=TRUE)
Manually start worker on localhost with
     C:/PROGRA~1/R/R-214~1.2/bin/Rscript.exe "C:/Program
Files/R/R-2.14.2/library/snow/RSOCKnode.R" MASTER=localhost PORT=11944
OUT=/dev/null SNOWLIB=C:/Program Files/R/R-2.14.2/library
[HANGS]
> cl <- makeCluster(type="SOCK",c("localhost","localhost"),manual=TRUE)
Manually start worker on localhost with
     C:/PROGRA~1/R/R-214~1.2/bin/Rscript.exe "C:/Program
Files/R/R-2.14.2/library/snow/RSOCKnode.R" MASTER=localhost PORT=11944
OUT=/dev/null SNOWLIB=C:/Program Files/R/R-2.14.2/library
[HANGS]

The computer:

Dell Inspiron I6400
with T2300 Dual Core processor


The OS:

> version
               _
platform       i386-pc-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status
major          2
minor          14.2
year           2012
month          02
day            29
svn rev        58522
language       R
version.string R version 2.14.2 (2012-02-29)


From debasish08 at gmail.com  Fri Sep 27 06:26:05 2013
From: debasish08 at gmail.com (Debasish Sahu)
Date: Fri, 27 Sep 2013 09:56:05 +0530
Subject: [R] Calculating euclidean distance in R
Message-ID: <CAOzfnO5Wxub4HwnMVmULy3CrsGn9syQ5me0qWxT6kt0dq57Jvw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130927/4d4706fc/attachment.pl>

From gunter.berton at gene.com  Fri Sep 27 07:12:46 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 26 Sep 2013 22:12:46 -0700
Subject: [R] Calculating euclidean distance in R
In-Reply-To: <CAOzfnO5Wxub4HwnMVmULy3CrsGn9syQ5me0qWxT6kt0dq57Jvw@mail.gmail.com>
References: <CAOzfnO5Wxub4HwnMVmULy3CrsGn9syQ5me0qWxT6kt0dq57Jvw@mail.gmail.com>
Message-ID: <CACk-te3RXgRa=eiFLTc_3+D9y9c-R58CWBtY1GEE-7xUhYOFZQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/c407477e/attachment.pl>

From ripley at stats.ox.ac.uk  Fri Sep 27 07:31:44 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 27 Sep 2013 06:31:44 +0100
Subject: [R] snow::makeCluster on Windows hangs
In-Reply-To: <CALbUM4O60G0CJrWckm=_4rL0MBkZO4M3zZkgZE+T7Ubc6Q1zSA@mail.gmail.com>
References: <CALbUM4O60G0CJrWckm=_4rL0MBkZO4M3zZkgZE+T7Ubc6Q1zSA@mail.gmail.com>
Message-ID: <52451840.3070204@stats.ox.ac.uk>

You failed to mention this about contributed package 'snow' (and a long 
obsolete version of R: see the postin guide).  That version of R has 
package 'parallel' which would be preferred.   But it looks like you did 
not manually start the workers (and I am not sure why you would want to 
do that).

On 27/09/2013 02:26, Jeffrey Flint wrote:
> The command which hangs:
> I'm hoping there is a simple explanation, but I searched on-line and
> nothing jumped out.
>
>> cl <- makeCluster(type="SOCK",c("localhost"),manual=TRUE)
> Manually start worker on localhost with
>       C:/PROGRA~1/R/R-214~1.2/bin/Rscript.exe "C:/Program
> Files/R/R-2.14.2/library/snow/RSOCKnode.R" MASTER=localhost PORT=11944
> OUT=/dev/null SNOWLIB=C:/Program Files/R/R-2.14.2/library
> [HANGS]
>> cl <- makeCluster(type="SOCK",c("localhost","localhost"),manual=TRUE)
> Manually start worker on localhost with
>       C:/PROGRA~1/R/R-214~1.2/bin/Rscript.exe "C:/Program
> Files/R/R-2.14.2/library/snow/RSOCKnode.R" MASTER=localhost PORT=11944
> OUT=/dev/null SNOWLIB=C:/Program Files/R/R-2.14.2/library
> [HANGS]
>
> The computer:
>
> Dell Inspiron I6400
> with T2300 Dual Core processor
>
>
> The OS:
>
>> version
>                 _
> platform       i386-pc-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
> status
> major          2
> minor          14.2
> year           2012
> month          02
> day            29
> svn rev        58522
> language       R
> version.string R version 2.14.2 (2012-02-29)
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From harb at student.unimelb.edu.au  Fri Sep 27 07:54:30 2013
From: harb at student.unimelb.edu.au (Ben Harrison)
Date: Fri, 27 Sep 2013 15:54:30 +1000
Subject: [R] table of contents link style in R's PDF docs
In-Reply-To: <CA+vqiLHLFRXpFvM5m=y7i-uCXv2hC49_A+nru1WWc-aub85M1Q@mail.gmail.com>
References: <l20a7b$rsi$1@ger.gmane.org>
	<CA+vqiLHLFRXpFvM5m=y7i-uCXv2hC49_A+nru1WWc-aub85M1Q@mail.gmail.com>
Message-ID: <52451D96.1030900@student.unimelb.edu.au>

On 27/09/13 00:03, Ista Zahn wrote:
> Hi Ben,
>
>
>
> On Wed, Sep 25, 2013 at 11:38 PM, Ben Harrison
> <harb at student.unimelb.edu.au> wrote:
>> Hello,
>
> I agree that it would be nicer to have the whole TOC entry
> hyperlinked. But out of curiosity, why are you using the pdf
> documentation? I find the html much nicer.
>
> Best,
> Ista
>

It's just my ad-hoc workflow at the moment. I use RStudio, and the 
4-pane view. Help leads to the html within RStudio, but whenever I want 
to have a detailed read of a package, I seem to either search cran for 
the docs, or click a link inside RStudio's help pane, both of which tend 
to lead to PDFs. My second monitor for example seems to have a bunch of 
docs open at any one time (mind like a sieve) in both my browser and PDF 
viewer.


From harb at student.unimelb.edu.au  Fri Sep 27 07:54:30 2013
From: harb at student.unimelb.edu.au (Ben Harrison)
Date: Fri, 27 Sep 2013 15:54:30 +1000
Subject: [R] table of contents link style in R's PDF docs
In-Reply-To: <CA+vqiLHLFRXpFvM5m=y7i-uCXv2hC49_A+nru1WWc-aub85M1Q@mail.gmail.com>
References: <l20a7b$rsi$1@ger.gmane.org>
	<CA+vqiLHLFRXpFvM5m=y7i-uCXv2hC49_A+nru1WWc-aub85M1Q@mail.gmail.com>
Message-ID: <52451D96.1030900@student.unimelb.edu.au>

On 27/09/13 00:03, Ista Zahn wrote:
> Hi Ben,
>
>
>
> On Wed, Sep 25, 2013 at 11:38 PM, Ben Harrison
> <harb at student.unimelb.edu.au> wrote:
>> Hello,
>
> I agree that it would be nicer to have the whole TOC entry
> hyperlinked. But out of curiosity, why are you using the pdf
> documentation? I find the html much nicer.
>
> Best,
> Ista
>

It's just my ad-hoc workflow at the moment. I use RStudio, and the 
4-pane view. Help leads to the html within RStudio, but whenever I want 
to have a detailed read of a package, I seem to either search cran for 
the docs, or click a link inside RStudio's help pane, both of which tend 
to lead to PDFs. My second monitor for example seems to have a bunch of 
docs open at any one time (mind like a sieve) in both my browser and PDF 
viewer.


From harb at student.unimelb.edu.au  Fri Sep 27 08:10:09 2013
From: harb at student.unimelb.edu.au (Ben Harrison)
Date: Fri, 27 Sep 2013 16:10:09 +1000
Subject: [R] table of contents link style in R's PDF docs
In-Reply-To: <524445CB.8010205@gmail.com>
References: <l20a7b$rsi$1@ger.gmane.org> <524445CB.8010205@gmail.com>
Message-ID: <52452141.7000205@student.unimelb.edu.au>

On 27/09/13 00:33, Duncan Murdoch wrote:
> On 25/09/2013 11:38 PM, Ben Harrison wrote:
>> Hello,

> It's been the way it is for about 14 years, and I don't recall anyone
> else complaining, so I'd conclude it must have been set that way with
> you in mind.

Ah-hah, I knew it! I *am* special.


> More seriously, I prefer having the page number clickable to having just
> the text clickable.  Having both would be fine for both of us. There's a
> partially documented option "linktoc=all" that does that; it was added
> to the hyperref package in 2008, so you can hardly blame R for not using
> it back in 1999.

(Just to be clear, I didn't. I only heard of R last year. One reason I 
make so much use of the docs :) )

The only problem I can see with using it now is that
> some users might not have a sufficiently up-to-date LaTeX installation
> to use it; if their hyperref package doesn't know about linktoc, they
> won't be able to build anything at all.

(Easy, tell them to upgrade!)

>
>>
>> Can I recreate all the documentation on my system after I make a change
>> to Rd.sty?
>
> Easiest would be to just do a rebuild of R, but you could also do the
> PDF manuals one at a time using
>
> R CMD Rd2pdf  <pkg>
>
> from the directory where the package is installed, or where its source
> lives.
>
> Duncan Murdoch


When you say 'easiest would be to just do a rebuild of R' I have no idea 
if we are using the same language. Easy to me is like scratching my 
beard (but only with my right hand), or looking out the window, or 
staying in bed when the alarm goes off.

I've made the change in Rd.sty, so at least all packages I install from 
now on will have the text links (I guess). Thanks for the response Duncan.

Ben.


From harb at student.unimelb.edu.au  Fri Sep 27 08:10:09 2013
From: harb at student.unimelb.edu.au (Ben Harrison)
Date: Fri, 27 Sep 2013 16:10:09 +1000
Subject: [R] table of contents link style in R's PDF docs
In-Reply-To: <524445CB.8010205@gmail.com>
References: <l20a7b$rsi$1@ger.gmane.org> <524445CB.8010205@gmail.com>
Message-ID: <52452141.7000205@student.unimelb.edu.au>

On 27/09/13 00:33, Duncan Murdoch wrote:
> On 25/09/2013 11:38 PM, Ben Harrison wrote:
>> Hello,

> It's been the way it is for about 14 years, and I don't recall anyone
> else complaining, so I'd conclude it must have been set that way with
> you in mind.

Ah-hah, I knew it! I *am* special.


> More seriously, I prefer having the page number clickable to having just
> the text clickable.  Having both would be fine for both of us. There's a
> partially documented option "linktoc=all" that does that; it was added
> to the hyperref package in 2008, so you can hardly blame R for not using
> it back in 1999.

(Just to be clear, I didn't. I only heard of R last year. One reason I 
make so much use of the docs :) )

The only problem I can see with using it now is that
> some users might not have a sufficiently up-to-date LaTeX installation
> to use it; if their hyperref package doesn't know about linktoc, they
> won't be able to build anything at all.

(Easy, tell them to upgrade!)

>
>>
>> Can I recreate all the documentation on my system after I make a change
>> to Rd.sty?
>
> Easiest would be to just do a rebuild of R, but you could also do the
> PDF manuals one at a time using
>
> R CMD Rd2pdf  <pkg>
>
> from the directory where the package is installed, or where its source
> lives.
>
> Duncan Murdoch


When you say 'easiest would be to just do a rebuild of R' I have no idea 
if we are using the same language. Easy to me is like scratching my 
beard (but only with my right hand), or looking out the window, or 
staying in bed when the alarm goes off.

I've made the change in Rd.sty, so at least all packages I install from 
now on will have the text links (I guess). Thanks for the response Duncan.

Ben.


From mlamias at yahoo.com  Fri Sep 27 07:38:51 2013
From: mlamias at yahoo.com (Mark Lamias)
Date: Thu, 26 Sep 2013 22:38:51 -0700 (PDT)
Subject: [R] Read shortcuts of MS Excel files through R
In-Reply-To: <CAN_e6XucEQQHSMiZbz3uUwayM80HBCCFuTrBsQA8rKwuT=w5gQ@mail.gmail.com>
References: <CAN_e6XucEQQHSMiZbz3uUwayM80HBCCFuTrBsQA8rKwuT=w5gQ@mail.gmail.com>
Message-ID: <1380260331.60945.YahooMailNeo@web141204.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130926/2ad01ce8/attachment.pl>

From mohan.radhakrishnan at polarisft.com  Fri Sep 27 09:12:59 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Fri, 27 Sep 2013 12:42:59 +0530
Subject: [R] Locating inefficient code
Message-ID: <OF0982A977.A44D48C6-ON65257BF3.00271871-65257BF3.00279FA9@polarisft.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130927/02de227f/attachment.pl>

From mohan.radhakrishnan at polarisft.com  Fri Sep 27 09:15:51 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Fri, 27 Sep 2013 12:45:51 +0530
Subject: [R] Space between x-axis ticks
In-Reply-To: <OF12E2BA7F.8DF555BB-ON65257BF1.002715ED-65257BF1.00275E28@polarisft.com>
References: <OF12E2BA7F.8DF555BB-ON65257BF1.002715ED-65257BF1.00275E28@polarisft.com>
Message-ID: <OFABAE71F9.7818EEBD-ON65257BF3.0027D282-65257BF3.0027DEF6@polarisft.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130927/c1517d49/attachment.pl>

From jim at bitwrit.com.au  Fri Sep 27 10:05:20 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 27 Sep 2013 18:05:20 +1000
Subject: [R] Space between x-axis ticks
In-Reply-To: <OFABAE71F9.7818EEBD-ON65257BF3.0027D282-65257BF3.0027DEF6@polarisft.com>
References: <OF12E2BA7F.8DF555BB-ON65257BF1.002715ED-65257BF1.00275E28@polarisft.com>
	<OFABAE71F9.7818EEBD-ON65257BF3.0027D282-65257BF3.0027DEF6@polarisft.com>
Message-ID: <52453C40.2080605@bitwrit.com.au>

On 09/27/2013 05:15 PM, mohan.radhakrishnan at polarisft.com wrote:
> ...
>            I am trying to clearly show the values in the x-axis in the
> attached graph. The tick marks are too close and the labels are blurred.
>...

Hi Mohan,
If the tick marks are too close together, you can increase the width of 
the graphic device.

If the labels are blurred, use a larger font (cex=), stagger them 
(staxlab) or try a graphic device like postscript or pdf.

Jim


From mohan.radhakrishnan at polarisft.com  Fri Sep 27 10:13:50 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Fri, 27 Sep 2013 13:43:50 +0530
Subject: [R] Space between x-axis ticks
In-Reply-To: <52453C40.2080605@bitwrit.com.au>
References: <OF12E2BA7F.8DF555BB-ON65257BF1.002715ED-65257BF1.00275E28@polarisft.com>
	<OFABAE71F9.7818EEBD-ON65257BF3.0027D282-65257BF3.0027DEF6@polarisft.com>
	<52453C40.2080605@bitwrit.com.au>
Message-ID: <OF23B4F782.7A70EFE5-ON65257BF3.002CC39F-65257BF3.002D2E0E@polarisft.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130927/f1ae18a8/attachment.pl>

From jholtman at gmail.com  Fri Sep 27 10:27:46 2013
From: jholtman at gmail.com (jim holtman)
Date: Fri, 27 Sep 2013 04:27:46 -0400
Subject: [R] Locating inefficient code
In-Reply-To: <OF0982A977.A44D48C6-ON65257BF3.00271871-65257BF3.00279FA9@polarisft.com>
References: <OF0982A977.A44D48C6-ON65257BF3.00271871-65257BF3.00279FA9@polarisft.com>
Message-ID: <CAAxdm-6YV7jyNOW9cgKNSyWTssaFi+vun=yhncX80yP8Wvtkqw@mail.gmail.com>

Is this what you want?  Please use dput when providing data.  Should
be faster using regular expressions:

> x <-  read.table(text = "Proto Recv-Q Send-Q Local-Address               Foreign-Address  State
+  tcp        0            0                    172.20.100.2:60255
172.20.100.3:8209           ESTABLISHED
+  tcp        0         0                    172.20.100.2:60247
172.20.100.3:8209           ESTABLISHED
+  tcp        0         0                     ::ffff:172.20.100.2:80
::ffff:10.1.5.7:3185        TIME_WAIT
+  tcp        0        0                    ::ffff:172.20.100.2:80
::ffff:10.5.1.3:3189        TIME_WAIT
+  tcp        0        0                     ::ffff:172.20.100.2:80
::ffff:10.5.5.7:3445        TIME_WAIT
+  tcp        0        0                    ::ffff:172.20.100.2:80
::ffff:10.3.29.3:2671       TIME_WAIT"
+ , as.is = TRUE
+ , header = TRUE
+ , check.names = FALSE
+ )
> x  # before
  Proto Recv-Q Send-Q          Local-Address       Foreign-Address       State
1   tcp      0      0     172.20.100.2:60255     172.20.100.3:8209 ESTABLISHED
2   tcp      0      0     172.20.100.2:60247     172.20.100.3:8209 ESTABLISHED
3   tcp      0      0 ::ffff:172.20.100.2:80  ::ffff:10.1.5.7:3185   TIME_WAIT
4   tcp      0      0 ::ffff:172.20.100.2:80  ::ffff:10.5.1.3:3189   TIME_WAIT
5   tcp      0      0 ::ffff:172.20.100.2:80  ::ffff:10.5.5.7:3445   TIME_WAIT
6   tcp      0      0 ::ffff:172.20.100.2:80 ::ffff:10.3.29.3:2671   TIME_WAIT
> for (i in c("Local-Address", "Foreign-Address")){
+ x[[i]] <- sub("[^0-9]*(.*)", "\\1", x[[i]])  # ignore upto first digit
+ }
> x  # after
  Proto Recv-Q Send-Q      Local-Address   Foreign-Address       State
1   tcp      0      0 172.20.100.2:60255 172.20.100.3:8209 ESTABLISHED
2   tcp      0      0 172.20.100.2:60247 172.20.100.3:8209 ESTABLISHED
3   tcp      0      0    172.20.100.2:80     10.1.5.7:3185   TIME_WAIT
4   tcp      0      0    172.20.100.2:80     10.5.1.3:3189   TIME_WAIT
5   tcp      0      0    172.20.100.2:80     10.5.5.7:3445   TIME_WAIT
6   tcp      0      0    172.20.100.2:80    10.3.29.3:2671   TIME_WAIT
>

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Fri, Sep 27, 2013 at 3:12 AM,  <mohan.radhakrishnan at polarisft.com> wrote:
> Hi,
>
>           I have been using R for a few months and I have this working
> code. Don't seen any problem but this takes a long time. So if I have
> about 30000 rows it takes a few minutes. If I have 100000 it does not seem
> to complete.
>
> Original Data:
>
> Proto Recv-Q Send-Q Local-Address               Foreign-Address  State
> tcp        0            0                    172.20.100.2:60255
> 172.20.100.3:8209           ESTABLISHED
> tcp        0         0                    172.20.100.2:60247
> 172.20.100.3:8209           ESTABLISHED
> tcp        0         0                     ::ffff:172.20.100.2:80
> ::ffff:10.1.5.7:3185        TIME_WAIT
> tcp        0        0                    ::ffff:172.20.100.2:80
> ::ffff:10.5.1.3:3189        TIME_WAIT
> tcp        0        0                     ::ffff:172.20.100.2:80
> ::ffff:10.5.5.7:3445        TIME_WAIT
> tcp        0        0                    ::ffff:172.20.100.2:80
> ::ffff:10.3.29.3:2671       TIME_WAIT
>
> Parsed Data:
>
> tcp        0            0                    172.20.100.2:60255
> 172.20.100.3:8209           ESTABLISHED
> tcp        0         0                    172.20.100.2:60247
> 172.20.100.3:8209           ESTABLISHED
>
> Here I am just splitting at colons and getting IP's and ports. That is
> all. Can this code improved ?
>
> data <- read.table("D:\\Log
> Analysis\\26-9-2013\\concurrentusage-node1",sep="",header=T,stringsAsFactors=FALSE,
> fill=TRUE)
> var <- c("Foreign.Address")
> data[,var] <- sapply(data[,var],function(x)
> ifelse(length(unlist(str_split(x,":")))==5,unlist(str_split(x,":"))[4],unlist(str_split(x,":"))[1]))
> var <- c("Local.Address")
> data[,var] <- sapply(data[,var],function(x)
> ifelse(length(unlist(str_split(x,":")))==5,paste(unlist(str_split(x,":"))[4],":",unlist(str_split(x,":"))[5]),
>  paste(unlist(str_split(x,":"))[1],":",unlist(str_split(x,":"))[2])))
>
> Thanks,
> Mohan
>
>
> This e-Mail may contain proprietary and confidential information and is sent for the intended recipient(s) only.  If by an addressing or transmission error this mail has been misdirected to you, you are requested to delete this mail immediately. You are also hereby notified that any use, any form of reproduction, dissemination, copying, disclosure, modification, distribution and/or publication of this e-mail message, contents or its attachment other than by its intended recipient/s is strictly prohibited.
>
> Visit us at http://www.polarisFT.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jim at bitwrit.com.au  Fri Sep 27 11:37:44 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 27 Sep 2013 19:37:44 +1000
Subject: [R] Space between x-axis ticks
In-Reply-To: <OF23B4F782.7A70EFE5-ON65257BF3.002CC39F-65257BF3.002D2E0E@polarisft.com>
References: <OF12E2BA7F.8DF555BB-ON65257BF1.002715ED-65257BF1.00275E28@polarisft.com>
	<OFABAE71F9.7818EEBD-ON65257BF3.0027D282-65257BF3.0027DEF6@polarisft.com>
	<52453C40.2080605@bitwrit.com.au>
	<OF23B4F782.7A70EFE5-ON65257BF3.002CC39F-65257BF3.002D2E0E@polarisft.com>
Message-ID: <524551E8.1020807@bitwrit.com.au>

On 09/27/2013 06:13 PM, mohan.radhakrishnan at polarisft.com wrote:
> Hi Jim
> 1. I use a bigger font using 'cex' but that worsens because tick marks
> are close
> 2. A wider png is also insufficient.
>
> The first tick is slightly away from the origin. I should be able to
> move it closer and then stagger the ticks. What is the 'staxlab' line
> that will help ? I used to look at the help page of 'staxlab' but
> there are less examples. Are there better references ?
>
Odd. If you do what I told you, you get the attached plot. It works the 
same for a PNG image.

Jim

-------------- next part --------------
A non-text attachment was scrubbed...
Name: mk.pdf
Type: application/pdf
Size: 5063 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130927/b6122f77/attachment.pdf>

From zulutime.net at gmail.com  Fri Sep 27 12:00:11 2013
From: zulutime.net at gmail.com (Magnus Thor Torfason)
Date: Fri, 27 Sep 2013 10:00:11 +0000
Subject: [R] min(NA,"bla") != min("bla", NA)
In-Reply-To: <5244E183.50105@gmail.com>
References: <52444DA4.3050409@gmail.com> <5244750F.5030502@gmail.com>
	<5244A7E7.4060607@xtra.co.nz> <5244BE3D.2010300@gmail.com>
	<5244DAE9.3040804@xtra.co.nz>
	<CA+vqiLHGhN92k0khBADxxB0BY+cdBGeM3MpvRCWGMhYC_vDb7g@mail.gmail.com>
	<5244E183.50105@gmail.com>
Message-ID: <5245572B.2060209@gmail.com>

Thanks for putting together such a quick fix! Unfortunately the policy 
for the system that I'm working on doesn't allow unreleased versions, so 
I'll have to work around this for a little bit longer. But I'll ask my 
sysadmins to install 3.0.3 as soon as it gets released.

Best,
Magnus

On 9/27/2013 1:38 AM, Duncan Murdoch wrote:
> Nice catch.  The good news is that min() works in the C locale; the bad
> news is that max() doesn't.  But both work after today's patch.
>
> Duncan Murdoch


From elaine.kuo.tw at gmail.com  Fri Sep 27 12:48:38 2013
From: elaine.kuo.tw at gmail.com (Elaine Kuo)
Date: Fri, 27 Sep 2013 18:48:38 +0800
Subject: [R] Compare species presence and absence between sites
Message-ID: <CAGJhoDzGTvNvFhzbyeGy2vVSfDHOMrAoM8nH+CUEtgzn03zc9Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130927/4a49dacd/attachment.pl>

From murdoch.duncan at gmail.com  Fri Sep 27 13:03:44 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 27 Sep 2013 07:03:44 -0400
Subject: [R] min(NA,"bla") != min("bla", NA)
In-Reply-To: <5245572B.2060209@gmail.com>
References: <52444DA4.3050409@gmail.com> <5244750F.5030502@gmail.com>
	<5244A7E7.4060607@xtra.co.nz> <5244BE3D.2010300@gmail.com>
	<5244DAE9.3040804@xtra.co.nz>
	<CA+vqiLHGhN92k0khBADxxB0BY+cdBGeM3MpvRCWGMhYC_vDb7g@mail.gmail.com>
	<5244E183.50105@gmail.com> <5245572B.2060209@gmail.com>
Message-ID: <52456610.8000004@gmail.com>

On 13-09-27 6:00 AM, Magnus Thor Torfason wrote:
> Thanks for putting together such a quick fix! Unfortunately the policy
> for the system that I'm working on doesn't allow unreleased versions, so
> I'll have to work around this for a little bit longer. But I'll ask my
> sysadmins to install 3.0.3 as soon as it gets released.


As a workaround, it looked to me as though it would always be safe to 
use the single argument version, i.e. the fact that min(c("bla", NA)) 
got it right was not just a fluke.  It's a little bit less efficient 
than using two arguments, but probably not to the extent that you'd notice.

Duncan Murdoch


>
> Best,
> Magnus
>
> On 9/27/2013 1:38 AM, Duncan Murdoch wrote:
>> Nice catch.  The good news is that min() works in the C locale; the bad
>> news is that max() doesn't.  But both work after today's patch.
>>
>> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mohan.radhakrishnan at polarisft.com  Fri Sep 27 13:22:57 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Fri, 27 Sep 2013 16:52:57 +0530
Subject: [R] Space between x-axis ticks
In-Reply-To: <524551E8.1020807@bitwrit.com.au>
References: <OF12E2BA7F.8DF555BB-ON65257BF1.002715ED-65257BF1.00275E28@polarisft.com>
	<OFABAE71F9.7818EEBD-ON65257BF3.0027D282-65257BF3.0027DEF6@polarisft.com>
	<52453C40.2080605@bitwrit.com.au>
	<OF23B4F782.7A70EFE5-ON65257BF3.002CC39F-65257BF3.002D2E0E@polarisft.com>
	<524551E8.1020807@bitwrit.com.au>
Message-ID: <OFE42D383A.21F513C9-ON65257BF3.003E500E-65257BF3.003E7EB5@polarisft.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130927/fa3d9740/attachment.pl>

From ruipbarradas at sapo.pt  Fri Sep 27 13:39:21 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 27 Sep 2013 12:39:21 +0100
Subject: [R] Compare species presence and absence between sites
In-Reply-To: <CAGJhoDzGTvNvFhzbyeGy2vVSfDHOMrAoM8nH+CUEtgzn03zc9Q@mail.gmail.com>
References: <CAGJhoDzGTvNvFhzbyeGy2vVSfDHOMrAoM8nH+CUEtgzn03zc9Q@mail.gmail.com>
Message-ID: <52456E69.1080005@sapo.pt>

Hello,

Something like this?


different <- function(x, y) x == 1 & y == 0

set.seed(7054)
mat <- matrix(sample(0:1, 500, TRUE), nrow = 5)
rownames(mat) <- LETTERS[1:5]
colnames(mat) <- sprintf("D%03d", 1:100)

different(mat["B",], mat["E",])



Hope this helps,

Rui Barradas

Em 27-09-2013 11:48, Elaine Kuo escreveu:
> Dear List,
>
>
>
> I want to compare the presence and absence of bird species based on the
> sites in a matrix.
>
> The matrix has 5 rows for Island A, B, C, D, and E.
>
> It has 100 columns for bird species D001-D100.
>
> In each cell of the matrix,
>
> the presence-absence of bird species will be recorded as 1 or 0.
>
> (For example, if species D001 is found on Island D,
>
> the matrix cell of species D001 and Island D will be 1.)
>
>
>
> Now I want to know the different bird species between Island B and E.
>
> In other words, I would like to find out bird species present (1) on Island
> B but absent (0)on island E, and vice versa (absent (0) on Island B but
> present (1)on island E).
>
>
>
> Please kindly advise how to code the purpose above.
>
> Thank you in advance.
>
>
>
> Elaine
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From careyshan at gmail.com  Fri Sep 27 14:13:32 2013
From: careyshan at gmail.com (Shane Carey)
Date: Fri, 27 Sep 2013 13:13:32 +0100
Subject: [R] R not ploting lines in the correct order
In-Reply-To: <CAM_vjunV66rVTk645BNnrVZJUXxu_toBe4+wGhwmHd2JC0QsUQ@mail.gmail.com>
References: <CA+jRDxDGO3kmPhiWZKyFG32txEn_f4Mipn7z=Vbe2Lb9EnAH6w@mail.gmail.com>
	<CAM_vjunV66rVTk645BNnrVZJUXxu_toBe4+wGhwmHd2JC0QsUQ@mail.gmail.com>
Message-ID: <CA+jRDxBqiWASkj7qn1Y0mpe03ttKsvBx_m3_0-WCMwvQyv3vgg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130927/0a1761d7/attachment.pl>

From jim at bitwrit.com.au  Fri Sep 27 14:14:11 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 27 Sep 2013 22:14:11 +1000
Subject: [R] Space between x-axis ticks
In-Reply-To: <OFE42D383A.21F513C9-ON65257BF3.003E500E-65257BF3.003E7EB5@polarisft.com>
References: <OF12E2BA7F.8DF555BB-ON65257BF1.002715ED-65257BF1.00275E28@polarisft.com>
	<OFABAE71F9.7818EEBD-ON65257BF3.0027D282-65257BF3.0027DEF6@polarisft.com>
	<52453C40.2080605@bitwrit.com.au>
	<OF23B4F782.7A70EFE5-ON65257BF3.002CC39F-65257BF3.002D2E0E@polarisft.com>
	<524551E8.1020807@bitwrit.com.au>
	<OFE42D383A.21F513C9-ON65257BF3.003E500E-65257BF3.003E7EB5@polarisft.com>
Message-ID: <52457693.1060508@bitwrit.com.au>

On 09/27/2013 09:22 PM, mohan.radhakrishnan at polarisft.com wrote:
> Hi Jim,
>
> Yes. The attached graph has less values. When there are more the values
> are too close even though after the beginning and ending tick there is
> enough space to evenly distribute the ticks.
> Is there a parameter to specifcy the space between the ticks. I used
> 'space' in boxplots.
>
>
Hi Mohan,
The space between the ticks is determined by the number of ticks and the 
length of the x axis:

<space between ticks> = <length of x axis>/<number of ticks>

So, if you make the x axis longer by increasing the width of the plot, 
there will be more space for more tick labels. You can increase the 
number of lines that "staxlab" will use to display labels, but more than 
three lines is usually too difficult to read. you can also try rotating 
the labels (see the "srt" argument in staxlab) rather than staggering them.

Jim


From smartpink111 at yahoo.com  Fri Sep 27 15:03:55 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 27 Sep 2013 06:03:55 -0700 (PDT)
Subject: [R] Locating inefficient code
In-Reply-To: <OF0982A977.A44D48C6-ON65257BF3.00271871-65257BF3.00279FA9@polarisft.com>
References: <OF0982A977.A44D48C6-ON65257BF3.00271871-65257BF3.00279FA9@polarisft.com>
Message-ID: <1380287035.32197.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
Please use ?dput()
dat1<- structure(list(Proto = c("tcp", "tcp", "tcp", "tcp", "tcp", "tcp"
), `Recv-Q` = c(0L, 0L, 0L, 0L, 0L, 0L), `Send-Q` = c(0L, 0L, 
0L, 0L, 0L, 0L), `Local-Address` = c("172.20.100.2:60255", "172.20.100.2:60247", 
"::ffff:172.20.100.2:80", "::ffff:172.20.100.2:80", "::ffff:172.20.100.2:80", 
"::ffff:172.20.100.2:80"), `Foreign-Address` = c("172.20.100.3:8209", 
"172.20.100.3:8209", "::ffff:10.1.5.7:3185", "::ffff:10.5.1.3:3189", 
"::ffff:10.5.5.7:3445", "::ffff:10.3.29.3:2671"), State = c("ESTABLISHED", 
"ESTABLISHED", "TIME_WAIT", "TIME_WAIT", "TIME_WAIT", "TIME_WAIT"
)), .Names = c("Proto", "Recv-Q", "Send-Q", "Local-Address", 
"Foreign-Address", "State"), class = "data.frame", row.names = c(NA, 
-6L))

library(stringr)
dat1[,4:5]<-lapply(dat1[,4:5],function(x) str_replace(x,"^\\D+",""))
dat1
#? Proto Recv-Q Send-Q????? Local-Address?? Foreign-Address?????? State
#1?? tcp????? 0????? 0 172.20.100.2:60255 172.20.100.3:8209 ESTABLISHED
#2?? tcp????? 0????? 0 172.20.100.2:60247 172.20.100.3:8209 ESTABLISHED
##3?? tcp????? 0????? 0??? 172.20.100.2:80???? 10.1.5.7:3185?? TIME_WAIT
#4?? tcp????? 0????? 0??? 172.20.100.2:80???? 10.5.1.3:3189?? TIME_WAIT
#5?? tcp????? 0????? 0??? 172.20.100.2:80???? 10.5.5.7:3445?? TIME_WAIT
#6?? tcp????? 0????? 0??? 172.20.100.2:80??? 10.3.29.3:2671?? TIME_WAIT

A.K.




----- Original Message -----
From: "mohan.radhakrishnan at polarisft.com" <mohan.radhakrishnan at polarisft.com>
To: r-help at r-project.org
Cc: 
Sent: Friday, September 27, 2013 3:42 AM
Subject: [R] Locating inefficient code

Hi,

? ? ? ? ? I have been using R for a few months and I have this working 
code. Don't seen any problem but this takes a long time. So if I have 
about 30000 rows it takes a few minutes. If I have 100000 it does not seem 
to complete.

Original Data:

Proto Recv-Q Send-Q Local-Address? ? ? ? ? ? ?  Foreign-Address? State? 
tcp? ? ? ? 0? ? ? ? ? ? 0? ? ? ? ? ? ? ? ? ? 172.20.100.2:60255 
172.20.100.3:8209? ? ? ? ?  ESTABLISHED 
tcp? ? ? ? 0? ? ? ?  0? ? ? ? ? ? ? ? ? ? 172.20.100.2:60247 
172.20.100.3:8209? ? ? ? ?  ESTABLISHED 
tcp? ? ? ? 0? ? ? ?  0? ? ? ? ? ? ? ? ? ?  ::ffff:172.20.100.2:80 
::ffff:10.1.5.7:3185? ? ? ? TIME_WAIT 
tcp? ? ? ? 0? ? ? ? 0? ? ? ? ? ? ? ? ? ? ::ffff:172.20.100.2:80 
::ffff:10.5.1.3:3189? ? ? ? TIME_WAIT 
tcp? ? ? ? 0? ? ? ? 0? ? ? ? ? ? ? ? ? ?  ::ffff:172.20.100.2:80 
::ffff:10.5.5.7:3445? ? ? ? TIME_WAIT 
tcp? ? ? ? 0? ? ? ? 0? ? ? ? ? ? ? ? ? ? ::ffff:172.20.100.2:80 
::ffff:10.3.29.3:2671? ? ?  TIME_WAIT 

Parsed Data:

tcp? ? ? ? 0? ? ? ? ? ? 0? ? ? ? ? ? ? ? ? ? 172.20.100.2:60255 
172.20.100.3:8209? ? ? ? ?  ESTABLISHED 
tcp? ? ? ? 0? ? ? ?  0? ? ? ? ? ? ? ? ? ? 172.20.100.2:60247 
172.20.100.3:8209? ? ? ? ?  ESTABLISHED 

Here I am just splitting at colons and getting IP's and ports. That is 
all. Can this code improved ?

data <- read.table("D:\\Log 
Analysis\\26-9-2013\\concurrentusage-node1",sep="",header=T,stringsAsFactors=FALSE, 
fill=TRUE)
var <- c("Foreign.Address")
data[,var] <- sapply(data[,var],function(x) 
ifelse(length(unlist(str_split(x,":")))==5,unlist(str_split(x,":"))[4],unlist(str_split(x,":"))[1]))
var <- c("Local.Address")
data[,var] <- sapply(data[,var],function(x) 
ifelse(length(unlist(str_split(x,":")))==5,paste(unlist(str_split(x,":"))[4],":",unlist(str_split(x,":"))[5]),
paste(unlist(str_split(x,":"))[1],":",unlist(str_split(x,":"))[2])))

Thanks,
Mohan


This e-Mail may contain proprietary and confidential information and is sent for the intended recipient(s) only.? If by an addressing or transmission error this mail has been misdirected to you, you are requested to delete this mail immediately. You are also hereby notified that any use, any form of reproduction, dissemination, copying, disclosure, modification, distribution and/or publication of this e-mail message, contents or its attachment other than by its intended recipient/s is strictly prohibited.

Visit us at http://www.polarisFT.com

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Fri Sep 27 15:31:57 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 27 Sep 2013 06:31:57 -0700 (PDT)
Subject: [R] Compare species presence and absence between sites
In-Reply-To: <52456E69.1080005@sapo.pt>
References: <CAGJhoDzGTvNvFhzbyeGy2vVSfDHOMrAoM8nH+CUEtgzn03zc9Q@mail.gmail.com>
	<52456E69.1080005@sapo.pt>
Message-ID: <1380288717.26695.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Just to add:

If you wanted the difference of every combination of rows:
set.seed(248)
?mat1<- matrix(sample(0:1,5*100,replace=TRUE),ncol=100,dimnames=list(LETTERS[1:5],paste0("D",sprintf("%03d",1:100))) )
?dat<-expand.grid(LETTERS[1:5],LETTERS[1:5],stringsAsFactors=FALSE)
dat1<-dat[!paste0(dat[,1],dat[,2]) %in% paste0(LETTERS[1:5],LETTERS[1:5]),]
?lst1<- lapply(seq_len(nrow(dat1)),function(i) {x<-mat1[unlist(dat1[i,]),]; which(different(x[1,],x[2,]))}) #using Rui's function
names(lst1)<- paste(dat1[,1],dat1[,2],sep="_")


A.K.



----- Original Message -----
From: Rui Barradas <ruipbarradas at sapo.pt>
To: Elaine Kuo <elaine.kuo.tw at gmail.com>
Cc: "r-help at r-project.org" <r-help at r-project.org>
Sent: Friday, September 27, 2013 7:39 AM
Subject: Re: [R] Compare species presence and absence between sites

Hello,

Something like this?


different <- function(x, y) x == 1 & y == 0

set.seed(7054)
mat <- matrix(sample(0:1, 500, TRUE), nrow = 5)
rownames(mat) <- LETTERS[1:5]
colnames(mat) <- sprintf("D%03d", 1:100)

different(mat["B",], mat["E",])



Hope this helps,

Rui Barradas

Em 27-09-2013 11:48, Elaine Kuo escreveu:
> Dear List,
>
>
>
> I want to compare the presence and absence of bird species based on the
> sites in a matrix.
>
> The matrix has 5 rows for Island A, B, C, D, and E.
>
> It has 100 columns for bird species D001-D100.
>
> In each cell of the matrix,
>
> the presence-absence of bird species will be recorded as 1 or 0.
>
> (For example, if species D001 is found on Island D,
>
> the matrix cell of species D001 and Island D will be 1.)
>
>
>
> Now I want to know the different bird species between Island B and E.
>
> In other words, I would like to find out bird species present (1) on Island
> B but absent (0)on island E, and vice versa (absent (0) on Island B but
> present (1)on island E).
>
>
>
> Please kindly advise how to code the purpose above.
>
> Thank you in advance.
>
>
>
> Elaine
>
> ??? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From sarah.goslee at gmail.com  Fri Sep 27 15:36:02 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 27 Sep 2013 09:36:02 -0400
Subject: [R] R not ploting lines in the correct order
In-Reply-To: <CA+jRDxBqiWASkj7qn1Y0mpe03ttKsvBx_m3_0-WCMwvQyv3vgg@mail.gmail.com>
References: <CA+jRDxDGO3kmPhiWZKyFG32txEn_f4Mipn7z=Vbe2Lb9EnAH6w@mail.gmail.com>
	<CAM_vjunV66rVTk645BNnrVZJUXxu_toBe4+wGhwmHd2JC0QsUQ@mail.gmail.com>
	<CA+jRDxBqiWASkj7qn1Y0mpe03ttKsvBx_m3_0-WCMwvQyv3vgg@mail.gmail.com>
Message-ID: <CAM_vju=yG9_DQ01EUCo32o5p9Fu6_H25zLFj0jJ-O8XxJn1+vw@mail.gmail.com>

If you use dput() correctly, those of us following along via email can
create an exact duplicate of your R object. All you need to do is:
dput(X)
and paste the resulting output into email.

You see, if I look at your object as you pasted it in, I can't tell if
your Date column is a date format, or character, or factor, or who
knows what, and that may matter for answering your question.

Also, what are "the wrong points"? What points do you expect to be connected?

Sarah


On Fri, Sep 27, 2013 at 8:13 AM, Shane Carey <careyshan at gmail.com> wrote:
> Hi Sarah,
>
> thanks for your reply. Im not sure how to use dput? If I create an object of
> my data, does that mean you can read it in from your side or something?
>
> Here is my code:
> X
> Data         Date
> 5.61 24/09/2012 09:13
> 5.80 16/10/2012 11:17
> 6.01 24/10/2012 21:43
> 5.65 11/09/2012 18:34
> 5.27 22/08/2012 15:45
> 5.67 10/08/2012 00:30
> 5.66 14/08/2012 14:52
> 5.81 24/09/2012 12:19
> 5.67 25/10/2012 12:45
> 5.46 07/11/2012 14:07
> 5.81 17/10/2012 10:51
> 5.86 07/11/2012 15:54
> 5.70 01/11/2012 19:21
> 5.33 01/11/2012 12:23
> 5.99 02/10/2012 21:25
> 5.70 30/11/2012 11:40
> 6.06 26/10/2012 13:21
> 5.47 23/08/2012 13:28
> 6.42 19/12/2012 10:54
> 6.05 09/08/2012 22:45
> 5.49 12/09/2012 09:39
> 5.45 11/10/2012 11:28
> 5.48 13/08/2012 16:15
> 5.61 10/09/2012 11:01
> 5.96 21/08/2012 10:55
> 5.37 30/11/2012 10:03
> 5.77 26/10/2012 17:08
> 5.81 03/10/2012 12:45
> dput(X, "X")
> plot(X$Data,Y$Date,yaxt="n", xaxt="n",type="o")
> lines(X$Data,Y$Date,pch=21, col="blue",type="o")
>
>
> Thanks again
>
>
> On Thu, Sep 26, 2013 at 7:23 PM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
>>
>> Hi Shane,
>>
>> Please use dput() to provide your data, rather than pasting it in so
>> that we can work from the same R object you are. Please also provide
>> the code you're using to make the graph.
>>
>> Sarah
>>
>> On Thu, Sep 26, 2013 at 1:56 PM, Shane Carey <careyshan at gmail.com> wrote:
>> > Hi,
>> >
>> > I have a set of x, y points where x represents dates and y actual
>> > values. I
>> > am trying to plot a line graph of the data with points on top, but R is
>> > connecting the wrong points with lines. Does anyone know how I can
>> > rectify
>> > this. Please see sample below:
>> >
>> > x=
>> >  24/09/2009 09:13  16/10/2009 11:17  24/10/2009 21:43  11/09/2009
>> > 18:34  22/08/2009
>> > 15:45  10/08/2009 00:30  14/08/2009 14:52  24/09/2009 12:19
>> > 25/10/2009 12:45  07/11/2009 14:07  17/10/2009 10:51  07/11/2009 15:54
>> > 01/11/2009 19:21  01/11/2009 12:23  02/10/2009 21:25  30/11/2009 11:40
>> > 26/10/2009 13:21  23/08/2009 13:28  19/12/2009 10:54  09/08/2009 22:45
>> >  12/09/2009
>> > 09:39  11/10/2009 11:28  13/08/2009 16:15  10/09/2009 11:01  21/08/2009
>> > 10:55  30/11/2009 10:03  26/10/2009 17:08  03/10/2009 12:45
>> >
>> > y=
>> >  4.2537264  4.397792  4.5570224  4.284056  3.9959248  4.2992208
>> > 4.2916384
>> > 4.4053744  4.2992208  4.1399904  4.4053744  4.4432864  4.321968
>> > 4.0414192
>> > 4.5418576  4.321968  4.5949344  4.1475728  4.8679008  4.587352
>> > 4.1627376
>> > 4.132408  4.1551552  4.2537264  4.5191104  4.0717488  4.3750448
>> > 4.4053744
>> > Thanks
>> > --
>> > Shane
>> >
>>
>> --
>> Sarah Goslee
>> http://www.functionaldiversity.org
>
>
>
>
> --
> Shane


From petr.pikal at precheza.cz  Fri Sep 27 15:36:01 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 27 Sep 2013 13:36:01 +0000
Subject: [R] R not ploting lines in the correct order
In-Reply-To: <CA+jRDxBqiWASkj7qn1Y0mpe03ttKsvBx_m3_0-WCMwvQyv3vgg@mail.gmail.com>
References: <CA+jRDxDGO3kmPhiWZKyFG32txEn_f4Mipn7z=Vbe2Lb9EnAH6w@mail.gmail.com>
	<CAM_vjunV66rVTk645BNnrVZJUXxu_toBe4+wGhwmHd2JC0QsUQ@mail.gmail.com>
	<CA+jRDxBqiWASkj7qn1Y0mpe03ttKsvBx_m3_0-WCMwvQyv3vgg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B93F3E@SRVEXCHMBX.precheza.cz>

Hm

It seems to me that you want to plot some values from two objects X and Y.

you shall at least show us output of

str(X) and str(Y)

but posting result of

dput(X) and dput(Y)

gives us an opportunity to test what objects you have and what you actually do with them.

Just a guess. You think that your x values are dates but they actually are not, they only pretend to be.

Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Shane Carey
> Sent: Friday, September 27, 2013 2:14 PM
> To: Sarah Goslee
> Cc: r-help at r-project.org
> Subject: Re: [R] R not ploting lines in the correct order
> 
> Hi Sarah,
> 
> thanks for your reply. Im not sure how to use dput? If I create an
> object
> of my data, does that mean you can read it in from your side or
> something?
> 
> Here is my code:
> X
> Data         Date
> 5.61 24/09/2012 09:13
> 5.80 16/10/2012 11:17
> 6.01 24/10/2012 21:43
> 5.65 11/09/2012 18:34
> 5.27 22/08/2012 15:45
> 5.67 10/08/2012 00:30
> 5.66 14/08/2012 14:52
> 5.81 24/09/2012 12:19
> 5.67 25/10/2012 12:45
> 5.46 07/11/2012 14:07
> 5.81 17/10/2012 10:51
> 5.86 07/11/2012 15:54
> 5.70 01/11/2012 19:21
> 5.33 01/11/2012 12:23
> 5.99 02/10/2012 21:25
> 5.70 30/11/2012 11:40
> 6.06 26/10/2012 13:21
> 5.47 23/08/2012 13:28
> 6.42 19/12/2012 10:54
> 6.05 09/08/2012 22:45
> 5.49 12/09/2012 09:39
> 5.45 11/10/2012 11:28
> 5.48 13/08/2012 16:15
> 5.61 10/09/2012 11:01
> 5.96 21/08/2012 10:55
> 5.37 30/11/2012 10:03
> 5.77 26/10/2012 17:08
> 5.81 03/10/2012 12:45
> dput(X, "X")
> plot(X$Data,Y$Date,yaxt="n", xaxt="n",type="o")
> lines(X$Data,Y$Date,pch=21, col="blue",type="o")
> 
> 
> Thanks again
> 
> 
> On Thu, Sep 26, 2013 at 7:23 PM, Sarah Goslee
> <sarah.goslee at gmail.com>wrote:
> 
> > Hi Shane,
> >
> > Please use dput() to provide your data, rather than pasting it in so
> > that we can work from the same R object you are. Please also provide
> > the code you're using to make the graph.
> >
> > Sarah
> >
> > On Thu, Sep 26, 2013 at 1:56 PM, Shane Carey <careyshan at gmail.com>
> wrote:
> > > Hi,
> > >
> > > I have a set of x, y points where x represents dates and y actual
> > values. I
> > > am trying to plot a line graph of the data with points on top, but
> R is
> > > connecting the wrong points with lines. Does anyone know how I can
> > rectify
> > > this. Please see sample below:
> > >
> > > x=
> > >  24/09/2009 09:13  16/10/2009 11:17  24/10/2009 21:43  11/09/2009
> > > 18:34  22/08/2009
> > > 15:45  10/08/2009 00:30  14/08/2009 14:52  24/09/2009 12:19
> > > 25/10/2009 12:45  07/11/2009 14:07  17/10/2009 10:51  07/11/2009
> 15:54
> > > 01/11/2009 19:21  01/11/2009 12:23  02/10/2009 21:25  30/11/2009
> 11:40
> > > 26/10/2009 13:21  23/08/2009 13:28  19/12/2009 10:54  09/08/2009
> 22:45
> > >  12/09/2009
> > > 09:39  11/10/2009 11:28  13/08/2009 16:15  10/09/2009 11:01
> 21/08/2009
> > > 10:55  30/11/2009 10:03  26/10/2009 17:08  03/10/2009 12:45
> > >
> > > y=
> > >  4.2537264  4.397792  4.5570224  4.284056  3.9959248  4.2992208
> >  4.2916384
> > > 4.4053744  4.2992208  4.1399904  4.4053744  4.4432864  4.321968
> >  4.0414192
> > > 4.5418576  4.321968  4.5949344  4.1475728  4.8679008  4.587352
> 4.1627376
> > > 4.132408  4.1551552  4.2537264  4.5191104  4.0717488  4.3750448
> >  4.4053744
> > > Thanks
> > > --
> > > Shane
> > >
> >
> > --
> > Sarah Goslee
> > http://www.functionaldiversity.org
> >
> 
> 
> 
> --
> Shane
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Fri Sep 27 15:37:38 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 27 Sep 2013 06:37:38 -0700 (PDT)
Subject: [R] Best and Worst values
In-Reply-To: <1380256248.30438.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <5244DD1D.4060708@yahoo.com>
	<1380246887.85418.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<5244E839.3070205@yahoo.com>
	<1380248260.99226.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<5244F9EC.40301@yahoo.com>
	<1380256248.30438.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <1380289058.15354.YahooMailNeo@web142603.mail.bf1.yahoo.com>






Ira,
obj_name<- load("arun.RData")
Pred1<- get(obj_name[1])
Actual1<- get(obj_name[2])

dat2<- data.frame(S1=rep(Pred1[,1],ncol(Pred1)-1),variable=rep(colnames(Pred1)[-1],each=nrow(Pred1)),Predict=unlist(Pred1[,-1],use.names=FALSE),Actual=unlist(Actual1[,-1],use.names=FALSE),stringsAsFactors=FALSE)

dat2New<- dat2[!(is.na(dat2$Predict)|is.na(dat2$Actual)),]
?dat3<- dat2New[order(dat2New$S1,dat2New$Predict),]

library(plyr)

resLow<-ddply(dat3,.(S1),summarize, cbind(head(Predict,5),head(Actual,5)))
resHigh<-ddply(dat3,.(S1),summarize, cbind(head(rev(Predict),5),head(rev(Actual),5)))
?resLow1<-data.frame(Date=resLow[,1],Predict=resLow[,2][,1],Actual=resLow[,2][,2])
?resHigh1<-data.frame(Date=resHigh[,1],Predict=resHigh[,2][,1],Actual=resHigh[,2][,2])
?resHigh1$id<- 1:nrow(resHigh1)
?resLow1$id<- 1:nrow(resLow1)
resLow2<-resLow1[!resLow1[,2]>=0,]
resHigh2<- resHigh1[resHigh1[,2]>0,]
resFinal<- merge(resLow2,resHigh2,by=c("Date","id"),all=TRUE) 


resNew<- as.data.frame(matrix(0,nrow(resFinal)*2,3))
resNew[,1]<-rep(resFinal$Date,each=2)

###indexing is not that important here.? You can just ?melt() or ?reshape() from wide to long format and when you try ddply(), it will automatically arrange the data #accordingly. 


indx<-cbind(rep(seq_len(nrow(resFinal)),2),rep(c(5,3),each=250))? ## 5,3 represents the column numbers Predict in resFinal
indx2<-c(rep(seq(1,100,by=2),each=5),rep(seq(2,100,by=2),each=5))
indx3<- indx[order(indx2),]
resNew[,2]<-as.numeric(resFinal[indx3])

indx1<-cbind(rep(seq_len(nrow(resFinal)),2),rep(c(6,4),each=250)) #6,4 represent the columns Actual in resFinal
indx4<- indx1[order(indx2),]
resNew[,3]<-as.numeric(resFinal[indx4])
colnames(resNew)<- c("Date","Predict","Actual")


CorRes<-ddply(resNew,.(Date),summarize,Correl=cor(Predict,Actual,use="complete.obs"))

?head(CorRes)
#??????? Date??? Correl
#1 2006-01-03 0.7079585
#2 2006-01-04 0.6537652
#3 2006-01-05 0.6397637
#4 2006-01-06 0.7448979
#5 2006-01-09 0.7325796
#6 2006-01-10 0.6283132




Arun

________________________________
From: Ira Sharenow <irasharenow100 at yahoo.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Thursday, September 26, 2013 11:22 PM
Subject: Re: Update, September 26, 2013



Arun,


I may want to separate the longs and do a correlation and separate the shorts and do a correlation, but the more likely scenario is to have the (possibly) 10 pairs of values per day all as part of a single correlation.

Thanks.

Ira


From careyshan at gmail.com  Fri Sep 27 16:06:16 2013
From: careyshan at gmail.com (Shane Carey)
Date: Fri, 27 Sep 2013 15:06:16 +0100
Subject: [R] R not ploting lines in the correct order
In-Reply-To: <CAM_vju=yG9_DQ01EUCo32o5p9Fu6_H25zLFj0jJ-O8XxJn1+vw@mail.gmail.com>
References: <CA+jRDxDGO3kmPhiWZKyFG32txEn_f4Mipn7z=Vbe2Lb9EnAH6w@mail.gmail.com>
	<CAM_vjunV66rVTk645BNnrVZJUXxu_toBe4+wGhwmHd2JC0QsUQ@mail.gmail.com>
	<CA+jRDxBqiWASkj7qn1Y0mpe03ttKsvBx_m3_0-WCMwvQyv3vgg@mail.gmail.com>
	<CAM_vju=yG9_DQ01EUCo32o5p9Fu6_H25zLFj0jJ-O8XxJn1+vw@mail.gmail.com>
Message-ID: <CA+jRDxBkEm-SL+A+LAkAZkJdyHit_WSE5-R3CBUX4+tkwGZ_zw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130927/21b8a188/attachment.pl>

From smartpink111 at yahoo.com  Fri Sep 27 16:11:38 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 27 Sep 2013 07:11:38 -0700 (PDT)
Subject: [R] Some issues with operations
In-Reply-To: <CAFkF=gFTMQAbCDW2sNa5WmPez5CO3sPBUoxQSKH4vK+s8o-p_w@mail.gmail.com>
References: <CAFkF=gFTMQAbCDW2sNa5WmPez5CO3sPBUoxQSKH4vK+s8o-p_w@mail.gmail.com>
Message-ID: <1380291098.80037.YahooMailNeo@web142605.mail.bf1.yahoo.com>

HI Vivek,

I think there is only one row in the whole dataset which fulfills the condition.? If you need the dimension intact, use 'drop=FALSE'


?which(rowSums(mat1>0)==ncol(mat1))
#CXCL14 
?# 2349?


#Simplied some codes:

dat1<- read.table("FPKM_RZvsRP_expmat2_v3.txt",sep="\t",header=TRUE,stringsAsFactors=FALSE)

dat2<- dat1

dat2[,13:22]<-lapply(list(c(2,3),c(4,7),c(4,8),c(5,7),c(5,8),c(6,7),c(6,8),c(9,12),c(10,12),c(11,12)),function(x) {dat2[,x[1]] - dat2[,x[2]]} )
?colnames(dat2)[13:22]<-gsub("__","_",paste(c("p118",paste(rep("p132",6),c("",1:5),sep="_"),paste(rep("p91",3),c("",1:2),sep="_")),"diff",sep="_"))
mat1<- as.matrix(dat2[,13:22])
row.names(mat1)<- dat2[,1]
?res<-mat1[rowSums(mat1>0)==ncol(mat1),,drop=FALSE]

res
#?????? p118_diff p132_diff p132_1_diff p132_2_diff p132_3_diff p132_4_diff
#CXCL14? 3.606171? 1.241455??? 2.023101??? 1.413141??? 2.194787?? 0.5763301
?# ???? p132_5_diff p91_diff p91_1_diff p91_2_diff
#CXCL14??? 1.357977 3.485148?? 8.938696??? 6.29492
dim(res)
#[1]? 1 10


A.K.

________________________________
From: Vivek Das <vd4mmind at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Friday, September 27, 2013 5:36 AM
Subject: Some issues with operations



HI Arun,
I am facing some issues with the matrix operation in R. I am having a matrix ?with some genes and their corresponding expression values between samples. I am trying to see the the difference in expression values of the columns. Then making a matrix which will contain the whole data and its corresponding differences. Then am extracting only the difference of the columns I computed in a matrix and trying to separate the positive and the negative differences. I have worked with this earlier and I have not faced any issue. I have also applied it to other samples and they work perfectly fine. But I donot know this time its failing. I tried with other matrix I performed earlier and still they work. Somewhere here it does not. Can you please let me know where I am getting wrong ? I am sending you the code snippet and the matrix so that it makes sense to you.

Code:

##### to check the transition from RZ to RP - 91 rz,118rz, 132rz1,132rz2 Vs 91rp1, 91rp3, 91rp4, 118rp3,132rp1, 132rp3, 132rp4

data<-read.table("",sep='\t', header=T)

#calculate differences

p118_diff<-c(as.numeric(data[,2])-as.numeric(data[,3]))
p132_diff<-c(as.numeric(data[,4])-as.numeric(data[,7]))
p132_1_diff<-c(as.numeric(data[,4])-as.numeric(data[,8]))
p132_2_diff<-c(as.numeric(data[,5])-as.numeric(data[,7]))
p132_3_diff<-c(as.numeric(data[,5])-as.numeric(data[,8]))
p132_4_diff<-c(as.numeric(data[,6])-as.numeric(data[,7]))
p132_5_diff<-c(as.numeric(data[,6])-as.numeric(data[,8]))
p91_diff<-c(as.numeric(data[,9])-as.numeric(data[,12]))
p91_1_diff<-c(as.numeric(data[,10])-as.numeric(data[,12]))
p91_2_diff<-c(as.numeric(data[,11])-as.numeric(data[,12]))

diff_m<-cbind(data,p118_diff,p132_diff,p132_1_diff,p132_2_diff,p132_3_diff,p132_4_diff,p132_5_diff,p91_diff,p91_1_diff,p91_2_diff)

##select all the positive differences

mat1<- as.matrix(diff_m[,13:22])
row.names(mat1)<- diff_m[,1]

res1<-mat1[rowSums(mat1>0)==ncol(mat1),]
head(res1)

In the above rest computation it is failing. as it cant give correct dimension for res1. I only get one row with 1 columns which should not be the idea case. I should get all the positive differences across all samples from the mat1 matrix. Can you please guide me where I am getting wrong? I am also attaching the matrix so that it works for you and you can understand where I am getting wrong.


----------------------------------------------------------

Vivek Das
PhD Student in Computational Biology
Giuseppe Testa's Lab
European School of Molecular Medicine
IFOM-IEO Campus
Via Adamello, 16
Milan, Italy

emails:?vivek.das at ieo.eu
??? ??? ??? vchris_05 at yahoo.co.in
??? ??? ??? vd4mmind at gmail.com


From petr.pikal at precheza.cz  Fri Sep 27 16:26:22 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 27 Sep 2013 14:26:22 +0000
Subject: [R] R not ploting lines in the correct order
In-Reply-To: <CA+jRDxBkEm-SL+A+LAkAZkJdyHit_WSE5-R3CBUX4+tkwGZ_zw@mail.gmail.com>
References: <CA+jRDxDGO3kmPhiWZKyFG32txEn_f4Mipn7z=Vbe2Lb9EnAH6w@mail.gmail.com>
	<CAM_vjunV66rVTk645BNnrVZJUXxu_toBe4+wGhwmHd2JC0QsUQ@mail.gmail.com>
	<CA+jRDxBqiWASkj7qn1Y0mpe03ttKsvBx_m3_0-WCMwvQyv3vgg@mail.gmail.com>
	<CAM_vju=yG9_DQ01EUCo32o5p9Fu6_H25zLFj0jJ-O8XxJn1+vw@mail.gmail.com>
	<CA+jRDxBkEm-SL+A+LAkAZkJdyHit_WSE5-R3CBUX4+tkwGZ_zw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B94012@SRVEXCHMBX.precheza.cz>

OK

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Shane Carey
> Sent: Friday, September 27, 2013 4:06 PM
> To: Sarah Goslee
> Cc: r-help at r-project.org
> Subject: Re: [R] R not ploting lines in the correct order
> 
> Ah ok, Here we go:
> 
> structure(list(DATE = structure(c(1348477980, 1350386220, 1351114980,
> 1347388440, 1345650300, 1344558600, 1344955920, 1348489140, 1351169100,
> 1352297220, 1350471060, 1352303640, 1351797660, 1351772580, 1349213100,
> 1354275600, 1351257660, 1345728480, 1355914440, 1344552300, 1347442740,
> 1349954880, 1344874500, 1347274860, 1345546500, 1354269780, 1351271280,
> 1349268300), class = c("POSIXct", "POSIXt"), tzone = "GMT"),
>     DATA = c(5.61, 5.8, 6.01, 5.65, 5.27, 5.67, 5.66, 5.81, 5.67,
>     5.46, 5.81, 5.86, 5.7, 5.33, 5.99, 5.7, 6.06, 5.47, 6.42,
>     6.05, 5.49, 5.45, 5.48, 5.61, 5.96, 5.37, 5.77, 5.81)), .Names =
> c("DATE",
> "DATA"), row.names = c(NA, -28L), class = "data.frame")
> 
> The wrong points are being joined by lines. If I use qplot from the
> ggplot2
> library it plots fine, but I want to use plot as it is easier to
> customise.

Well, it is a matter of taste, ggplots are maybe more complicated but they allow you to do fairly broader customisation quite easily if you find how.

Now you shall tell us what is your plotting command.

this can not work as you are plotting X and Y objects
> > > plot(X$Data,Y$Date,yaxt="n", xaxt="n",type="o")
> > > lines(X$Data,Y$Date,pch=21, col="blue",type="o")

If I name your data frame to data and change plotting commands to 

plot(data$DATA,data$DATE,yaxt="n", xaxt="n",type="o")
lines(data$DATA,data$DATE,pch=21, col="blue",type="o")

I get some mess due to the fact that DATE is not sorted (and I believe that your intention is to have date values on x axis).

so making your data.frame ordered

ooo<-order(data$DATE)
data.o<-data[ooo,]
plot(data.o$DATE,data.o$DATA,yaxt="n", xaxt="n",type="o")
lines(data.o$DATE,data.o$DATA,pch=21, col="blue",type="o")

gives me quite reasonable result.

Regards
Petr


> 
> Thanks again.
> 
> 
> On Fri, Sep 27, 2013 at 2:36 PM, Sarah Goslee
> <sarah.goslee at gmail.com>wrote:
> 
> > If you use dput() correctly, those of us following along via email
> can
> > create an exact duplicate of your R object. All you need to do is:
> > dput(X)
> > and paste the resulting output into email.
> >
> > You see, if I look at your object as you pasted it in, I can't tell
> if
> > your Date column is a date format, or character, or factor, or who
> > knows what, and that may matter for answering your question.
> >
> > Also, what are "the wrong points"? What points do you expect to be
> > connected?
> >
> > Sarah
> >
> >
> > On Fri, Sep 27, 2013 at 8:13 AM, Shane Carey <careyshan at gmail.com>
> wrote:
> > > Hi Sarah,
> > >
> > > thanks for your reply. Im not sure how to use dput? If I create an
> > object of
> > > my data, does that mean you can read it in from your side or
> something?
> > >
> > > Here is my code:
> > > X
> > > Data         Date
> > > 5.61 24/09/2012 09:13
> > > 5.80 16/10/2012 11:17
> > > 6.01 24/10/2012 21:43
> > > 5.65 11/09/2012 18:34
> > > 5.27 22/08/2012 15:45
> > > 5.67 10/08/2012 00:30
> > > 5.66 14/08/2012 14:52
> > > 5.81 24/09/2012 12:19
> > > 5.67 25/10/2012 12:45
> > > 5.46 07/11/2012 14:07
> > > 5.81 17/10/2012 10:51
> > > 5.86 07/11/2012 15:54
> > > 5.70 01/11/2012 19:21
> > > 5.33 01/11/2012 12:23
> > > 5.99 02/10/2012 21:25
> > > 5.70 30/11/2012 11:40
> > > 6.06 26/10/2012 13:21
> > > 5.47 23/08/2012 13:28
> > > 6.42 19/12/2012 10:54
> > > 6.05 09/08/2012 22:45
> > > 5.49 12/09/2012 09:39
> > > 5.45 11/10/2012 11:28
> > > 5.48 13/08/2012 16:15
> > > 5.61 10/09/2012 11:01
> > > 5.96 21/08/2012 10:55
> > > 5.37 30/11/2012 10:03
> > > 5.77 26/10/2012 17:08
> > > 5.81 03/10/2012 12:45
> > > dput(X, "X")
> > > plot(X$Data,Y$Date,yaxt="n", xaxt="n",type="o")
> > > lines(X$Data,Y$Date,pch=21, col="blue",type="o")
> > >
> > >
> > > Thanks again
> > >
> > >
> > > On Thu, Sep 26, 2013 at 7:23 PM, Sarah Goslee
> <sarah.goslee at gmail.com>
> > > wrote:
> > >>
> > >> Hi Shane,
> > >>
> > >> Please use dput() to provide your data, rather than pasting it in
> so
> > >> that we can work from the same R object you are. Please also
> provide
> > >> the code you're using to make the graph.
> > >>
> > >> Sarah
> > >>
> > >> On Thu, Sep 26, 2013 at 1:56 PM, Shane Carey <careyshan at gmail.com>
> > wrote:
> > >> > Hi,
> > >> >
> > >> > I have a set of x, y points where x represents dates and y
> actual
> > >> > values. I
> > >> > am trying to plot a line graph of the data with points on top,
> but R
> > is
> > >> > connecting the wrong points with lines. Does anyone know how I
> can
> > >> > rectify
> > >> > this. Please see sample below:
> > >> >
> > >> > x=
> > >> >  24/09/2009 09:13  16/10/2009 11:17  24/10/2009 21:43
> 11/09/2009
> > >> > 18:34  22/08/2009
> > >> > 15:45  10/08/2009 00:30  14/08/2009 14:52  24/09/2009 12:19
> > >> > 25/10/2009 12:45  07/11/2009 14:07  17/10/2009 10:51  07/11/2009
> 15:54
> > >> > 01/11/2009 19:21  01/11/2009 12:23  02/10/2009 21:25  30/11/2009
> 11:40
> > >> > 26/10/2009 13:21  23/08/2009 13:28  19/12/2009 10:54  09/08/2009
> 22:45
> > >> >  12/09/2009
> > >> > 09:39  11/10/2009 11:28  13/08/2009 16:15  10/09/2009 11:01
> >  21/08/2009
> > >> > 10:55  30/11/2009 10:03  26/10/2009 17:08  03/10/2009 12:45
> > >> >
> > >> > y=
> > >> >  4.2537264  4.397792  4.5570224  4.284056  3.9959248  4.2992208
> > >> > 4.2916384
> > >> > 4.4053744  4.2992208  4.1399904  4.4053744  4.4432864  4.321968
> > >> > 4.0414192
> > >> > 4.5418576  4.321968  4.5949344  4.1475728  4.8679008  4.587352
> > >> > 4.1627376
> > >> > 4.132408  4.1551552  4.2537264  4.5191104  4.0717488  4.3750448
> > >> > 4.4053744
> > >> > Thanks
> > >> > --
> > >> > Shane
> > >> >
> > >>
> > >> --
> > >> Sarah Goslee
> > >> http://www.functionaldiversity.org
> > >
> > >
> > >
> > >
> > > --
> > > Shane
> >
> 
> 
> 
> --
> Shane
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From careyshan at gmail.com  Fri Sep 27 16:31:46 2013
From: careyshan at gmail.com (Shane Carey)
Date: Fri, 27 Sep 2013 15:31:46 +0100
Subject: [R] R not ploting lines in the correct order
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B94012@SRVEXCHMBX.precheza.cz>
References: <CA+jRDxDGO3kmPhiWZKyFG32txEn_f4Mipn7z=Vbe2Lb9EnAH6w@mail.gmail.com>
	<CAM_vjunV66rVTk645BNnrVZJUXxu_toBe4+wGhwmHd2JC0QsUQ@mail.gmail.com>
	<CA+jRDxBqiWASkj7qn1Y0mpe03ttKsvBx_m3_0-WCMwvQyv3vgg@mail.gmail.com>
	<CAM_vju=yG9_DQ01EUCo32o5p9Fu6_H25zLFj0jJ-O8XxJn1+vw@mail.gmail.com>
	<CA+jRDxBkEm-SL+A+LAkAZkJdyHit_WSE5-R3CBUX4+tkwGZ_zw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B94012@SRVEXCHMBX.precheza.cz>
Message-ID: <CA+jRDxAsefNWLOwfLOnX-4fDQ8H1tCP_kqx6fUpJvwrC0zp=RQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130927/f69cc533/attachment.pl>

From smartpink111 at yahoo.com  Fri Sep 27 16:35:10 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 27 Sep 2013 07:35:10 -0700 (PDT)
Subject: [R] R not ploting lines in the correct order
In-Reply-To: <CA+jRDxBkEm-SL+A+LAkAZkJdyHit_WSE5-R3CBUX4+tkwGZ_zw@mail.gmail.com>
References: <CA+jRDxDGO3kmPhiWZKyFG32txEn_f4Mipn7z=Vbe2Lb9EnAH6w@mail.gmail.com>	<CAM_vjunV66rVTk645BNnrVZJUXxu_toBe4+wGhwmHd2JC0QsUQ@mail.gmail.com>	<CA+jRDxBqiWASkj7qn1Y0mpe03ttKsvBx_m3_0-WCMwvQyv3vgg@mail.gmail.com>	<CAM_vju=yG9_DQ01EUCo32o5p9Fu6_H25zLFj0jJ-O8XxJn1+vw@mail.gmail.com>
	<CA+jRDxBkEm-SL+A+LAkAZkJdyHit_WSE5-R3CBUX4+tkwGZ_zw@mail.gmail.com>
Message-ID: <1380292510.88394.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Not sure if this helps, but you can try ?xts
library(xts)
X<- structure(....
xt1<- xts(X[,2],order.by=X[,1])
plot(xt1,type="o")
A.K.





----- Original Message -----
From: Shane Carey <careyshan at gmail.com>
To: Sarah Goslee <sarah.goslee at gmail.com>
Cc: "r-help at r-project.org" <r-help at r-project.org>
Sent: Friday, September 27, 2013 10:06 AM
Subject: Re: [R] R not ploting lines in the correct order

Ah ok, Here we go:

structure(list(DATE = structure(c(1348477980, 1350386220, 1351114980,
1347388440, 1345650300, 1344558600, 1344955920, 1348489140, 1351169100,
1352297220, 1350471060, 1352303640, 1351797660, 1351772580, 1349213100,
1354275600, 1351257660, 1345728480, 1355914440, 1344552300, 1347442740,
1349954880, 1344874500, 1347274860, 1345546500, 1354269780, 1351271280,
1349268300), class = c("POSIXct", "POSIXt"), tzone = "GMT"),
? ? DATA = c(5.61, 5.8, 6.01, 5.65, 5.27, 5.67, 5.66, 5.81, 5.67,
? ? 5.46, 5.81, 5.86, 5.7, 5.33, 5.99, 5.7, 6.06, 5.47, 6.42,
? ? 6.05, 5.49, 5.45, 5.48, 5.61, 5.96, 5.37, 5.77, 5.81)), .Names =
c("DATE",
"DATA"), row.names = c(NA, -28L), class = "data.frame")

The wrong points are being joined by lines. If I use qplot from the ggplot2
library it plots fine, but I want to use plot as it is easier to customise.

Thanks again.


On Fri, Sep 27, 2013 at 2:36 PM, Sarah Goslee <sarah.goslee at gmail.com>wrote:

> If you use dput() correctly, those of us following along via email can
> create an exact duplicate of your R object. All you need to do is:
> dput(X)
> and paste the resulting output into email.
>
> You see, if I look at your object as you pasted it in, I can't tell if
> your Date column is a date format, or character, or factor, or who
> knows what, and that may matter for answering your question.
>
> Also, what are "the wrong points"? What points do you expect to be
> connected?
>
> Sarah
>
>
> On Fri, Sep 27, 2013 at 8:13 AM, Shane Carey <careyshan at gmail.com> wrote:
> > Hi Sarah,
> >
> > thanks for your reply. Im not sure how to use dput? If I create an
> object of
> > my data, does that mean you can read it in from your side or something?
> >
> > Here is my code:
> > X
> > Data? ? ? ?  Date
> > 5.61 24/09/2012 09:13
> > 5.80 16/10/2012 11:17
> > 6.01 24/10/2012 21:43
> > 5.65 11/09/2012 18:34
> > 5.27 22/08/2012 15:45
> > 5.67 10/08/2012 00:30
> > 5.66 14/08/2012 14:52
> > 5.81 24/09/2012 12:19
> > 5.67 25/10/2012 12:45
> > 5.46 07/11/2012 14:07
> > 5.81 17/10/2012 10:51
> > 5.86 07/11/2012 15:54
> > 5.70 01/11/2012 19:21
> > 5.33 01/11/2012 12:23
> > 5.99 02/10/2012 21:25
> > 5.70 30/11/2012 11:40
> > 6.06 26/10/2012 13:21
> > 5.47 23/08/2012 13:28
> > 6.42 19/12/2012 10:54
> > 6.05 09/08/2012 22:45
> > 5.49 12/09/2012 09:39
> > 5.45 11/10/2012 11:28
> > 5.48 13/08/2012 16:15
> > 5.61 10/09/2012 11:01
> > 5.96 21/08/2012 10:55
> > 5.37 30/11/2012 10:03
> > 5.77 26/10/2012 17:08
> > 5.81 03/10/2012 12:45
> > dput(X, "X")
> > plot(X$Data,Y$Date,yaxt="n", xaxt="n",type="o")
> > lines(X$Data,Y$Date,pch=21, col="blue",type="o")
> >
> >
> > Thanks again
> >
> >
> > On Thu, Sep 26, 2013 at 7:23 PM, Sarah Goslee <sarah.goslee at gmail.com>
> > wrote:
> >>
> >> Hi Shane,
> >>
> >> Please use dput() to provide your data, rather than pasting it in so
> >> that we can work from the same R object you are. Please also provide
> >> the code you're using to make the graph.
> >>
> >> Sarah
> >>
> >> On Thu, Sep 26, 2013 at 1:56 PM, Shane Carey <careyshan at gmail.com>
> wrote:
> >> > Hi,
> >> >
> >> > I have a set of x, y points where x represents dates and y actual
> >> > values. I
> >> > am trying to plot a line graph of the data with points on top, but R
> is
> >> > connecting the wrong points with lines. Does anyone know how I can
> >> > rectify
> >> > this. Please see sample below:
> >> >
> >> > x=
> >> >? 24/09/2009 09:13? 16/10/2009 11:17? 24/10/2009 21:43? 11/09/2009
> >> > 18:34? 22/08/2009
> >> > 15:45? 10/08/2009 00:30? 14/08/2009 14:52? 24/09/2009 12:19
> >> > 25/10/2009 12:45? 07/11/2009 14:07? 17/10/2009 10:51? 07/11/2009 15:54
> >> > 01/11/2009 19:21? 01/11/2009 12:23? 02/10/2009 21:25? 30/11/2009 11:40
> >> > 26/10/2009 13:21? 23/08/2009 13:28? 19/12/2009 10:54? 09/08/2009 22:45
> >> >? 12/09/2009
> >> > 09:39? 11/10/2009 11:28? 13/08/2009 16:15? 10/09/2009 11:01
>? 21/08/2009
> >> > 10:55? 30/11/2009 10:03? 26/10/2009 17:08? 03/10/2009 12:45
> >> >
> >> > y=
> >> >? 4.2537264? 4.397792? 4.5570224? 4.284056? 3.9959248? 4.2992208
> >> > 4.2916384
> >> > 4.4053744? 4.2992208? 4.1399904? 4.4053744? 4.4432864? 4.321968
> >> > 4.0414192
> >> > 4.5418576? 4.321968? 4.5949344? 4.1475728? 4.8679008? 4.587352
> >> > 4.1627376
> >> > 4.132408? 4.1551552? 4.2537264? 4.5191104? 4.0717488? 4.3750448
> >> > 4.4053744
> >> > Thanks
> >> > --
> >> > Shane
> >> >
> >>
> >> --
> >> Sarah Goslee
> >> http://www.functionaldiversity.org
> >
> >
> >
> >
> > --
> > Shane
>



-- 
Shane

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From scupton at nps.edu  Fri Sep 27 16:51:51 2013
From: scupton at nps.edu (Upton, Stephen (Steve) (CIV))
Date: Fri, 27 Sep 2013 14:51:51 +0000
Subject: [R] Calculating euclidean distance in R
In-Reply-To: <CAOzfnO5Wxub4HwnMVmULy3CrsGn9syQ5me0qWxT6kt0dq57Jvw@mail.gmail.com>
References: <CAOzfnO5Wxub4HwnMVmULy3CrsGn9syQ5me0qWxT6kt0dq57Jvw@mail.gmail.com>
Message-ID: <C750A9148B73B84EB6293187A5F7DA756E8FD72B@GROWLER.ern.nps.edu>

?read.csv 
to read your data in,

then
?dist

to calculate distances.

steve

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Debasish Sahu
Sent: Friday, September 27, 2013 12:26 AM
To: r-help at r-project.org
Subject: [R] Calculating euclidean distance in R

Hello,
I am quite new to R.(in fact for the first time I am using) So forgive me if
I have asked a silly question.

I have a table in.csv format with data for location of samples in X, Y, Z
(column)format.
Now I want to calculate the Euclidean distance for the total sample dataset.

Can you please help me how to get the Euclidean distance of dataset .

Thanks & regards,
Debasish

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From klebyn at yahoo.com.br  Fri Sep 27 16:38:06 2013
From: klebyn at yahoo.com.br (Cleber N.Borges)
Date: Fri, 27 Sep 2013 11:38:06 -0300
Subject: [R] exchange of  axis labels in qqnorm function
Message-ID: <5245984E.1010504@yahoo.com.br>

Hello all,

Are there a reason for this behaviour in qqnorm function?
(the exchange of axis labels )

 >
 > x <- rnorm(1000)
 > par( mfcol=c(1,2) )
 > qqnorm(x, xlab='X Axis', ylab='Y  Axis', datax=FALSE ) #Default
 > qqnorm(x, xlab='X Axis', ylab='Y  Axis', datax=TRUE )
 >
 >
Thanks for any explanation.

cleber


From vincent.guyader at allstat.fr  Fri Sep 27 17:27:15 2013
From: vincent.guyader at allstat.fr (Vincent Guyader)
Date: Fri, 27 Sep 2013 17:27:15 +0200
Subject: [R] An Apply function question about changing type of variable
Message-ID: <CANCN_HQR0zFzvhs7dbTC1y9VdUKOHSL_AZQhCSOhDbQFCqG8dg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130927/be3e5799/attachment.pl>

From jeffrey.flint at gmail.com  Fri Sep 27 18:05:31 2013
From: jeffrey.flint at gmail.com (Jeffrey Flint)
Date: Fri, 27 Sep 2013 09:05:31 -0700
Subject: [R] snow::makeCluster on Windows hangs
In-Reply-To: <52451840.3070204@stats.ox.ac.uk>
References: <CALbUM4O60G0CJrWckm=_4rL0MBkZO4M3zZkgZE+T7Ubc6Q1zSA@mail.gmail.com>
	<52451840.3070204@stats.ox.ac.uk>
Message-ID: <CALbUM4Nea-6BPUmpXkNyNYLwDi8Zrod5btmzw+ARmezpoyv08w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130927/4295f0fd/attachment.pl>

From btupper at bigelow.org  Fri Sep 27 19:42:59 2013
From: btupper at bigelow.org (Ben Tupper)
Date: Fri, 27 Sep 2013 13:42:59 -0400
Subject: [R] An Apply function question about changing type of variable
In-Reply-To: <CANCN_HQR0zFzvhs7dbTC1y9VdUKOHSL_AZQhCSOhDbQFCqG8dg@mail.gmail.com>
References: <CANCN_HQR0zFzvhs7dbTC1y9VdUKOHSL_AZQhCSOhDbQFCqG8dg@mail.gmail.com>
Message-ID: <2DAD0B55-182A-4DEE-988A-3DEC1F681D80@bigelow.org>

Hi,

On Sep 27, 2013, at 11:27 AM, Vincent Guyader wrote:

> Hi everyone,
> 
> plese can you look at this few lines :
> 
> data(iris)
> res<-apply(iris,MARGIN=2,is)
> res[1,]
> 
> the result is :
> Sepal.Length  Sepal.Width Petal.Length  Petal.Width      Species
> "character"  "character"  "character"  "character"  "character"
> 
> How can I conserve the type off each colum? apply seems to convert it into
> "character" adn it could be a problem for me.
> 

Did you intend to use lapply() instead of apply()?  

> res<-lapply(iris,is)
> str(res)
List of 5
 $ Sepal.Length: chr [1:2] "numeric" "vector"
 $ Sepal.Width : chr [1:2] "numeric" "vector"
 $ Petal.Length: chr [1:2] "numeric" "vector"
 $ Petal.Width : chr [1:2] "numeric" "vector"
 $ Species     : chr [1:5] "factor" "integer" "oldClass" "numeric" ...

apply() expects an array input, so it will coerce non-array inputs to be so with as.matrix() or as.array(). That coercion will change the data type if needed, in your case changing all to character to accommodate the factor column.

> iris2 <- as.matrix(iris)
> str(iris2)
 chr [1:150, 1:5] "5.1" "4.9" "4.7" "4.6" "5.0" "5.4" "4.6" "5.0" "4.4" ...
 - attr(*, "dimnames")=List of 2
  ..$ : NULL
  ..$ : chr [1:5] "Sepal.Length" "Sepal.Width" "Petal.Length" "Petal.Width" ...

Cheers,
Ben



> 
> Regards
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From morgandetoi at hotmail.com  Fri Sep 27 20:20:19 2013
From: morgandetoi at hotmail.com (Mariki Zietsman)
Date: Fri, 27 Sep 2013 19:20:19 +0100
Subject: [R] Logical indexing not working
Message-ID: <DUB120-W40301B8B1FAAE99ED5A749A4290@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130927/f0986ae7/attachment.pl>

From wdunlap at tibco.com  Fri Sep 27 20:45:21 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 27 Sep 2013 18:45:21 +0000
Subject: [R] Logical indexing not working
In-Reply-To: <DUB120-W40301B8B1FAAE99ED5A749A4290@phx.gbl>
References: <DUB120-W40301B8B1FAAE99ED5A749A4290@phx.gbl>
Message-ID: <E66794E69CFDE04D9A70842786030B931C346702@PA-MBX01.na.tibco.com>

> where ... birds are 1,23,24 or 29 ...
> birds==c(1,23,24,29)

Use
   is.element(birds, c(1,23,24,29))
or
   (birds %in% c(1,23,24,29))
if you prefer typing percent signs.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Mariki Zietsman
> Sent: Friday, September 27, 2013 11:20 AM
> To: r-help at r-project.org
> Subject: [R] Logical indexing not working
> 
> I have a data frame frugivore.abundance.S1 where some columns are factors and others
> are numbers.For example these are my independent variables and "density" is my
> dependent variable. census<-c(1:70)sites<-c(1:5)birds<-c(1:45)
> 
> I want to select the data where sites is 1 and birds are 1,23,24 or 29
> So I write:fa1<-frugivore.abundance.S1attach(fa1)(abund.frug.RN1<-fa1[sites==1 &
> birds==c(1,23,24,29),])
> This code doesn't print all the data it should for some reason. It seems to not print rows
> where "density" has the same value as another row with the same criteria.
> i.e. if in the original data we have the following then only rows 1 and 3 will be printed,
> not all of them:
> census   sites   birds   density1                 1         1         0.0032                 1         1         0.0033
> 1         1         0.001
> Can anyone help me out with this please?
> RegardsMariki
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Fri Sep 27 20:49:00 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 27 Sep 2013 19:49:00 +0100
Subject: [R] Logical indexing not working
In-Reply-To: <DUB120-W40301B8B1FAAE99ED5A749A4290@phx.gbl>
References: <DUB120-W40301B8B1FAAE99ED5A749A4290@phx.gbl>
Message-ID: <5245D31C.4030704@sapo.pt>

Hello,

Please don't post in HTML, it messes up the code and data.
And please use ?dput to post your data:

dput(fa1)  # post the output of this.


As for your problem, maybe if you try ?%in%

fa1[sites==1 & birds %in% c(1,23,24,29),]


Hope this helps,

Rui Barradas

Em 27-09-2013 19:20, Mariki Zietsman escreveu:
> I have a data frame frugivore.abundance.S1 where some columns are factors and others are numbers.For example these are my independent variables and "density" is my dependent variable. census<-c(1:70)sites<-c(1:5)birds<-c(1:45)
>
> I want to select the data where sites is 1 and birds are 1,23,24 or 29
> So I write:fa1<-frugivore.abundance.S1attach(fa1)(abund.frug.RN1<-fa1[sites==1 & birds==c(1,23,24,29),])
> This code doesn't print all the data it should for some reason. It seems to not print rows where "density" has the same value as another row with the same criteria.
> i.e. if in the original data we have the following then only rows 1 and 3 will be printed, not all of them:
> census   sites   birds   density1                 1         1         0.0032                 1         1         0.0033                 1         1         0.001
> Can anyone help me out with this please?
> RegardsMariki
>   		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From sarah.goslee at gmail.com  Fri Sep 27 20:49:46 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 27 Sep 2013 14:49:46 -0400
Subject: [R] Logical indexing not working
In-Reply-To: <DUB120-W40301B8B1FAAE99ED5A749A4290@phx.gbl>
References: <DUB120-W40301B8B1FAAE99ED5A749A4290@phx.gbl>
Message-ID: <CAM_vju=5GGLigwL0GF+Y89=WVfOEmvFDx1SOoT9ZMvf234ZUow@mail.gmail.com>

Your post demonstrates why we ask people to NOT post in HTML.
Attempting to decode it, I think the problem might be

birds==c(1,23,24,29)

Look at this:

birds <- c(2, 4, 1, 23, 8, 24)
birds <- data.frame(birds)
birds[birds[,1] == c(1,23,24,29),]

And compare
birds[birds[,1] %in% c(1,23,24,29),]

You might also benefit from reading ?subset and the Introduction to R
that came with your installation.

Sarah

On Fri, Sep 27, 2013 at 2:20 PM, Mariki Zietsman
<morgandetoi at hotmail.com> wrote:
> I have a data frame frugivore.abundance.S1 where some columns are factors and others are numbers.For example these are my independent variables and "density" is my dependent variable. census<-c(1:70)sites<-c(1:5)birds<-c(1:45)
>
> I want to select the data where sites is 1 and birds are 1,23,24 or 29
> So I write:fa1<-frugivore.abundance.S1attach(fa1)(abund.frug.RN1<-fa1[sites==1 & birds==c(1,23,24,29),])
> This code doesn't print all the data it should for some reason. It seems to not print rows where "density" has the same value as another row with the same criteria.
> i.e. if in the original data we have the following then only rows 1 and 3 will be printed, not all of them:
> census   sites   birds   density1                 1         1         0.0032                 1         1         0.0033                 1         1         0.001
> Can anyone help me out with this please?
> RegardsMariki
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From jgrn at illinois.edu  Fri Sep 27 21:13:27 2013
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Fri, 27 Sep 2013 14:13:27 -0500
Subject: [R] Error: C stack usage is too close to the limit when using
	list.files()
Message-ID: <CABG0rftp4J29ETAtx2phZS587CmKv7xDsgz=aM6Z74E+NOBf3w@mail.gmail.com>

R-helpers:

I'm running a file search on my entire drive (Mac OS X) using:

files_found <- list.files(dir="/",pattern=somepattern,recursive=TRUE,full.names=TRUE)
where somepattern is a search pattern (which I have confirmed via a
unix "find / -name somepattern" only returns ~ 3 results).

I keep getting an error:

Error: C stack usage is too close to the limit

when running this command.  Any ideas on 1) how to fix this or 2) if
there is an alternative to using list.files() to accomplish this
search without resorting to an external package?

Cheers!

--jonathan


-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
259 Computing Applications Building, MC-150
605 East Springfield Avenue
Champaign, IL  61820-6371
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From murdoch.duncan at gmail.com  Fri Sep 27 21:21:40 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 27 Sep 2013 15:21:40 -0400
Subject: [R] table of contents link style in R's PDF docs
In-Reply-To: <524445CB.8010205@gmail.com>
References: <l20a7b$rsi$1@ger.gmane.org> <524445CB.8010205@gmail.com>
Message-ID: <5245DAC4.3080102@gmail.com>

On 26/09/2013 10:33 AM, Duncan Murdoch wrote:
> On 25/09/2013 11:38 PM, Ben Harrison wrote:
> > Hello,
> > I am mildly annoyed each time I use a PDF doc of an R package that the
> > table of contents hyperlinks are *only* on the page numbers. To activate
> > a hyperlink, one must carefully scan sideways from the text item wanted
> > to the far right of the page and click on a tiny box. Multiply that mild
> > annoyance by the large number of times I need to look up package help
> > docs, and I find myself here writing this message.
> >
> >   From my understanding (albeit poor), all of the R docs for packages are
> > to be written in Rd format. From that they are converted by the
> > functions in the tools package as required (to latex and PDF, or HTML,
> > etc). So the only thing that controls in the PDF docs the hyperlinks one
> > way or another is the latex style file used - in this case I believe it
> > is Rd.sty (/usr/share/R/share/texmf/tex/latex/Rd.sty on my system).
> >
> > Line 303 of that file contains the single setting of the \hypersetup{}
> > command for whether or not the text in the table of contents is
> > hyperlinked, or the page number:
> >
> >       linktocpage,%
> >
> > which causes it to implicitly be set to True. Setting it to false (or
> > just commenting out that line I suppose as false is the default) would
> > mean the *text* in the TOC is hyperlinked.
> >
> > So, is the desired behaviour intended to be that only the page numbers
> > are hyperlinked (and therefore to annoy me), or has no-one really
> > bothered themselves with it that much, or something else?
>
> It's been the way it is for about 14 years, and I don't recall anyone
> else complaining, so I'd conclude it must have been set that way with
> you in mind.
>
> More seriously, I prefer having the page number clickable to having just
> the text clickable.  Having both would be fine for both of us. There's a
> partially documented option "linktoc=all" that does that; it was added
> to the hyperref package in 2008, so you can hardly blame R for not using
> it back in 1999.  The only problem I can see with using it now is that
> some users might not have a sufficiently up-to-date LaTeX installation
> to use it; if their hyperref package doesn't know about linktoc, they
> won't be able to build anything at all.
>
> >
> > Can I recreate all the documentation on my system after I make a change
> > to Rd.sty?
>
> Easiest would be to just do a rebuild of R, but you could also do the
> PDF manuals one at a time using
>
> R CMD Rd2pdf  <pkg>
>
> from the directory where the package is installed, or where its source
> lives.

I took a look at changing this, and decided against it:  we've had 
trouble with varying versions
of hyperref in the past.  However, anyone who wants to control the 
hyperlinking can follow
the instructions in the Installation and Administration file and create 
an Rd.cfg file (and put it on the Latex path, e.g. in 
R_HOME/share/texmf/tex/latex) to configure their own installation. 
Putting the line

\ifthenelse{\boolean{Rd at use@hyper}}{\hypersetup{linktoc=all}}{}

into that file works to give hyperlinks on both the text and page 
number, provided you have a compatible version of
hyperref.  (This will be described in newer versions of the manual.)

Duncan Murdoch


From miolmor at gmail.com  Fri Sep 27 20:56:45 2013
From: miolmor at gmail.com (Conor Ryan)
Date: Fri, 27 Sep 2013 19:56:45 +0100
Subject: [R] Plot lines whose angle and length depict vector quantities
Message-ID: <CA+PRwqFwhRbWh-nS7fK3VkuuoQAs=8YRdWbNGppUHwP=RWzHqg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130927/4a872d8c/attachment.pl>

From bbolker at gmail.com  Fri Sep 27 21:36:57 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 27 Sep 2013 19:36:57 +0000
Subject: [R]
	=?utf-8?q?Error=3A_C_stack_usage_is_too_close_to_the_limit_wh?=
	=?utf-8?b?ZW4gdXNpbmcJbGlzdC5maWxlcygp?=
References: <CABG0rftp4J29ETAtx2phZS587CmKv7xDsgz=aM6Z74E+NOBf3w@mail.gmail.com>
Message-ID: <loom.20130927T213542-421@post.gmane.org>

Jonathan Greenberg <jgrn <at> illinois.edu> writes:

> 
> R-helpers:
> 
> I'm running a file search on my entire drive (Mac OS X) using:
> 
> files_found <-
list.files(dir="/",pattern=somepattern,recursive=TRUE,full.names=TRUE)
> where somepattern is a search pattern (which I have confirmed via a
> unix "find / -name somepattern" only returns ~ 3 results).
> 
> I keep getting an error:
> 
> Error: C stack usage is too close to the limit
> 
> when running this command.  Any ideas on 1) how to fix this or 2) if
> there is an alternative to using list.files() to accomplish this
> search without resorting to an external package?

  I assuming that using

system("find / -name somepattern")

(possibly with intern=TRUE) isn't allowed?  (I don't know what you're
trying to do, but if you don't need it to work on Windows-without-cygwin,
this should work across most Unix variants (although a "-print" might
be required)


From sarah.goslee at gmail.com  Fri Sep 27 21:44:53 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 27 Sep 2013 15:44:53 -0400
Subject: [R] Plot lines whose angle and length depict vector quantities
In-Reply-To: <CA+PRwqFwhRbWh-nS7fK3VkuuoQAs=8YRdWbNGppUHwP=RWzHqg@mail.gmail.com>
References: <CA+PRwqFwhRbWh-nS7fK3VkuuoQAs=8YRdWbNGppUHwP=RWzHqg@mail.gmail.com>
Message-ID: <CAM_vjukYFGFCK5ms6DOdzgoM-kyVdDfQo_i3tkVx84Z4ZiwkzQ@mail.gmail.com>

It's a straightforward trigonometry problem, isn't it?

On Fri, Sep 27, 2013 at 2:56 PM, Conor Ryan <miolmor at gmail.com> wrote:
> I am trying to plot points on a map for each ship locations (lat/long),
> where
> each point is a line whose angle (degrees) denotes ships heading and whose
> line length denotes it's speed. Unfortunately arrows(); p.arrows (sfsmisc)
> and ms.arrows (TeachingDemos) require start and end coordinates but I only
> have a single coordinate and an angle to work with. Can you suggest any
> other packages or commands that might allow me to plot this? Alternatively,
> can anyone suggest a method of making 'angle' a vector quantity when using
> the arrows function? Any advice would be much appreciated!
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From jgrn at illinois.edu  Fri Sep 27 21:50:33 2013
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Fri, 27 Sep 2013 14:50:33 -0500
Subject: [R] Error: C stack usage is too close to the limit when using
	list.files()
In-Reply-To: <loom.20130927T213542-421@post.gmane.org>
References: <CABG0rftp4J29ETAtx2phZS587CmKv7xDsgz=aM6Z74E+NOBf3w@mail.gmail.com>
	<loom.20130927T213542-421@post.gmane.org>
Message-ID: <CABG0rfuE+_2SR=H_eeUydOyzyW83wsmXaoJ1CEYqJ=wbhYeUNQ@mail.gmail.com>

Ben:

I'd like to avoid using that (previous version of my code solved it in
that way) -- I would like cross-platform compatibility and I am pretty
sure, along with Windows, vanilla Macs don't come with "find" either
unless XCode has been installed.

Is the list.files() code itself recursive when using recursive=TRUE
(so it has one recursion per bottom-folder)?

--j

P.S. I recognized that in my initial post I indicated using "dir" as
the parameter -- it should have been "path" (the error occurred
through the correct usage of list.files(path="/",...)   That'll teach
me not to copy/paste from my code...

On Fri, Sep 27, 2013 at 2:36 PM, Ben Bolker <bbolker at gmail.com> wrote:
> Jonathan Greenberg <jgrn <at> illinois.edu> writes:
>
>>
>> R-helpers:
>>
>> I'm running a file search on my entire drive (Mac OS X) using:
>>
>> files_found <-
> list.files(dir="/",pattern=somepattern,recursive=TRUE,full.names=TRUE)
>> where somepattern is a search pattern (which I have confirmed via a
>> unix "find / -name somepattern" only returns ~ 3 results).
>>
>> I keep getting an error:
>>
>> Error: C stack usage is too close to the limit
>>
>> when running this command.  Any ideas on 1) how to fix this or 2) if
>> there is an alternative to using list.files() to accomplish this
>> search without resorting to an external package?
>
>   I assuming that using
>
> system("find / -name somepattern")
>
> (possibly with intern=TRUE) isn't allowed?  (I don't know what you're
> trying to do, but if you don't need it to work on Windows-without-cygwin,
> this should work across most Unix variants (although a "-print" might
> be required)
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
259 Computing Applications Building, MC-150
605 East Springfield Avenue
Champaign, IL  61820-6371
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From wdunlap at tibco.com  Fri Sep 27 21:56:13 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 27 Sep 2013 19:56:13 +0000
Subject: [R] Error: C stack usage is too close to the limit when
	using	list.files()
In-Reply-To: <CABG0rftp4J29ETAtx2phZS587CmKv7xDsgz=aM6Z74E+NOBf3w@mail.gmail.com>
References: <CABG0rftp4J29ETAtx2phZS587CmKv7xDsgz=aM6Z74E+NOBf3w@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C346757@PA-MBX01.na.tibco.com>

Do you have some symbolic links that make loops in your file system?
list.files() has problems with such loops and find does not.  E.g.,  on a Linux box:

% cd /tmp
% mkdir dir dir/subdir
% cd dir/subdir
% ln -s ../../dir linkToUpperDir
% cd /tmp
% R --quiet
> list.files("dir", recursive=TRUE, full=TRUE)
[1] "dir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir"
> system("find dir")
dir
dir/subdir
dir/subdir/linkToUpperDir

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Jonathan Greenberg
> Sent: Friday, September 27, 2013 12:13 PM
> To: r-help
> Subject: [R] Error: C stack usage is too close to the limit when using list.files()
> 
> R-helpers:
> 
> I'm running a file search on my entire drive (Mac OS X) using:
> 
> files_found <- list.files(dir="/",pattern=somepattern,recursive=TRUE,full.names=TRUE)
> where somepattern is a search pattern (which I have confirmed via a
> unix "find / -name somepattern" only returns ~ 3 results).
> 
> I keep getting an error:
> 
> Error: C stack usage is too close to the limit
> 
> when running this command.  Any ideas on 1) how to fix this or 2) if
> there is an alternative to using list.files() to accomplish this
> search without resorting to an external package?
> 
> Cheers!
> 
> --jonathan
> 
> 
> --
> Jonathan A. Greenberg, PhD
> Assistant Professor
> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
> Department of Geography and Geographic Information Science
> University of Illinois at Urbana-Champaign
> 259 Computing Applications Building, MC-150
> 605 East Springfield Avenue
> Champaign, IL  61820-6371
> Phone: 217-300-1924
> http://www.geog.illinois.edu/~jgrn/
> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bhh at xs4all.nl  Fri Sep 27 21:59:54 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 27 Sep 2013 21:59:54 +0200
Subject: [R] Error: C stack usage is too close to the limit when using
	list.files()
In-Reply-To: <CABG0rfuE+_2SR=H_eeUydOyzyW83wsmXaoJ1CEYqJ=wbhYeUNQ@mail.gmail.com>
References: <CABG0rftp4J29ETAtx2phZS587CmKv7xDsgz=aM6Z74E+NOBf3w@mail.gmail.com>
	<loom.20130927T213542-421@post.gmane.org>
	<CABG0rfuE+_2SR=H_eeUydOyzyW83wsmXaoJ1CEYqJ=wbhYeUNQ@mail.gmail.com>
Message-ID: <335F6BB1-7E72-4F6D-9BB1-C7AF2571FAB4@xs4all.nl>


On 27-09-2013, at 21:50, Jonathan Greenberg <jgrn at illinois.edu> wrote:

> Ben:
> 
> I'd like to avoid using that (previous version of my code solved it in
> that way) -- I would like cross-platform compatibility and I am pretty
> sure, along with Windows, vanilla Macs don't come with "find" either
> unless XCode has been installed.
> 

As far as I can tell Mac OS X provides a find utility (the Unix version). It is not part of Xcode.

Berend

> Is the list.files() code itself recursive when using recursive=TRUE
> (so it has one recursion per bottom-folder)?
> 
> --j
> 
> P.S. I recognized that in my initial post I indicated using "dir" as
> the parameter -- it should have been "path" (the error occurred
> through the correct usage of list.files(path="/",...)   That'll teach
> me not to copy/paste from my code...
> 
> On Fri, Sep 27, 2013 at 2:36 PM, Ben Bolker <bbolker at gmail.com> wrote:
>> Jonathan Greenberg <jgrn <at> illinois.edu> writes:
>> 
>>> 
>>> R-helpers:
>>> 
>>> I'm running a file search on my entire drive (Mac OS X) using:
>>> 
>>> files_found <-
>> list.files(dir="/",pattern=somepattern,recursive=TRUE,full.names=TRUE)
>>> where somepattern is a search pattern (which I have confirmed via a
>>> unix "find / -name somepattern" only returns ~ 3 results).
>>> 
>>> I keep getting an error:
>>> 
>>> Error: C stack usage is too close to the limit
>>> 
>>> when running this command.  Any ideas on 1) how to fix this or 2) if
>>> there is an alternative to using list.files() to accomplish this
>>> search without resorting to an external package?
>> 
>>  I assuming that using
>> 
>> system("find / -name somepattern")
>> 
>> (possibly with intern=TRUE) isn't allowed?  (I don't know what you're
>> trying to do, but if you don't need it to work on Windows-without-cygwin,
>> this should work across most Unix variants (although a "-print" might
>> be required)
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> Jonathan A. Greenberg, PhD
> Assistant Professor
> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
> Department of Geography and Geographic Information Science
> University of Illinois at Urbana-Champaign
> 259 Computing Applications Building, MC-150
> 605 East Springfield Avenue
> Champaign, IL  61820-6371
> Phone: 217-300-1924
> http://www.geog.illinois.edu/~jgrn/
> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Fri Sep 27 22:01:41 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 27 Sep 2013 13:01:41 -0700
Subject: [R] Plot lines whose angle and length depict vector quantities
In-Reply-To: <CAM_vjukYFGFCK5ms6DOdzgoM-kyVdDfQo_i3tkVx84Z4ZiwkzQ@mail.gmail.com>
References: <CA+PRwqFwhRbWh-nS7fK3VkuuoQAs=8YRdWbNGppUHwP=RWzHqg@mail.gmail.com>
	<CAM_vjukYFGFCK5ms6DOdzgoM-kyVdDfQo_i3tkVx84Z4ZiwkzQ@mail.gmail.com>
Message-ID: <CACk-te1wDV0HO6vax6JLsEqGs0a817m3sZJpiK2d910NwYSSEQ@mail.gmail.com>

On Fri, Sep 27, 2013 at 12:44 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> It's a straightforward trigonometry problem, isn't it?

Indeed! (  (r,theta) to (x,y) coordinates  ) . So I wonder if this is
a homework problem. If so, the OP should note that we try not to do
homework here.

Cheers,
Bert
>
> On Fri, Sep 27, 2013 at 2:56 PM, Conor Ryan <miolmor at gmail.com> wrote:
>> I am trying to plot points on a map for each ship locations (lat/long),
>> where
>> each point is a line whose angle (degrees) denotes ships heading and whose
>> line length denotes it's speed. Unfortunately arrows(); p.arrows (sfsmisc)
>> and ms.arrows (TeachingDemos) require start and end coordinates but I only
>> have a single coordinate and an angle to work with. Can you suggest any
>> other packages or commands that might allow me to plot this? Alternatively,
>> can anyone suggest a method of making 'angle' a vector quantity when using
>> the arrows function? Any advice would be much appreciated!
>>
>
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From wdunlap at tibco.com  Fri Sep 27 22:08:43 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 27 Sep 2013 20:08:43 +0000
Subject: [R] Error: C stack usage is too close to the limit
	when	using	list.files()
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C346757@PA-MBX01.na.tibco.com>
References: <CABG0rftp4J29ETAtx2phZS587CmKv7xDsgz=aM6Z74E+NOBf3w@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C346757@PA-MBX01.na.tibco.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C34677F@PA-MBX01.na.tibco.com>

Toss a couple of extra files in there and you will see the output grow exponentially.

% touch dir/IMPORTANT_1 dir/subdir/IMPORTANT_2

and in R those two new files cause 82 more strings to appear in list.file's output:

> nchar(list.files("dir", recursive=TRUE))
 [1]  11  18  33  40  55  62  77  84  99 106 121 128 143 150 165 172 187 194 209
[20] 216 231 238 253 260 275 282 297 304 319 326 341 348 363 370 385 392 407 414
[39] 429 436 451 458 473 480 495 502 517 524 539 546 561 568 583 590 605 612 627
[58] 634 649 656 671 678 693 700 715 722 737 744 759 766 781 788 803 810 825 832
[77] 847 854 869 876 891 898 901

'find', by default, does not following symbolic links.

% find dir
dir
dir/subdir
dir/subdir/IMPORTANT_2
dir/subdir/linkToUpperDir
dir/IMPORTANT_1

The -L option makes it follow them, but it won't follow loops:

% find -L dir
dir
dir/subdir
dir/subdir/IMPORTANT_2
find: File system loop detected; `dir/subdir/linkToUpperDir' is part of the same file system loop as `dir'.
dir/IMPORTANT_1

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of William Dunlap
> Sent: Friday, September 27, 2013 12:56 PM
> To: Jonathan Greenberg; r-help
> Subject: Re: [R] Error: C stack usage is too close to the limit when using list.files()
> 
> Do you have some symbolic links that make loops in your file system?
> list.files() has problems with such loops and find does not.  E.g.,  on a Linux box:
> 
> % cd /tmp
> % mkdir dir dir/subdir
> % cd dir/subdir
> % ln -s ../../dir linkToUpperDir
> % cd /tmp
> % R --quiet
> > list.files("dir", recursive=TRUE, full=TRUE)
> [1]
> "dir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToU
> pperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkT
> oUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/li
> nkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdi
> r/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/su
> bdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir
> /subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpper
> Dir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUp
> perDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkTo
> UpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/lin
> kToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir"
> > system("find dir")
> dir
> dir/subdir
> dir/subdir/linkToUpperDir
> 
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
> 
> 
> > -----Original Message-----
> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> > Of Jonathan Greenberg
> > Sent: Friday, September 27, 2013 12:13 PM
> > To: r-help
> > Subject: [R] Error: C stack usage is too close to the limit when using list.files()
> >
> > R-helpers:
> >
> > I'm running a file search on my entire drive (Mac OS X) using:
> >
> > files_found <- list.files(dir="/",pattern=somepattern,recursive=TRUE,full.names=TRUE)
> > where somepattern is a search pattern (which I have confirmed via a
> > unix "find / -name somepattern" only returns ~ 3 results).
> >
> > I keep getting an error:
> >
> > Error: C stack usage is too close to the limit
> >
> > when running this command.  Any ideas on 1) how to fix this or 2) if
> > there is an alternative to using list.files() to accomplish this
> > search without resorting to an external package?
> >
> > Cheers!
> >
> > --jonathan
> >
> >
> > --
> > Jonathan A. Greenberg, PhD
> > Assistant Professor
> > Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
> > Department of Geography and Geographic Information Science
> > University of Illinois at Urbana-Champaign
> > 259 Computing Applications Building, MC-150
> > 605 East Springfield Avenue
> > Champaign, IL  61820-6371
> > Phone: 217-300-1924
> > http://www.geog.illinois.edu/~jgrn/
> > AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ana.arjona at northwestern.edu  Fri Sep 27 21:53:24 2013
From: ana.arjona at northwestern.edu (Ana Arjona)
Date: Fri, 27 Sep 2013 19:53:24 +0000
Subject: [R] Help with nested and non-nested factors
Message-ID: <CE6B4C62.2E238%ana.arjona@northwestern.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130927/92388ca1/attachment.pl>

From pkount at bgc-jena.mpg.de  Fri Sep 27 22:48:57 2013
From: pkount at bgc-jena.mpg.de (pakoun)
Date: Fri, 27 Sep 2013 13:48:57 -0700 (PDT)
Subject: [R] Memory distribution using foreach
Message-ID: <1380314937400-4677133.post@n4.nabble.com>

Dear R users,
I am struggling with memory issues and try to understand a few things. I am
using an LSF cluster with PGI compiler and parallel mpi2 computing (whatever
does that means..) and i submit a job like:

bsub -R "rusage[mem=30000]" -q queue -n 24 R CMD BATCH <arguments..> 
myjob.r ..log

According to that I am asking for 24 cores and 30GB RAM. 

Then I am using 
library(doMC)
registerDoMC(24) 

and a foreach loop either simple or nested with the %dopar% command. 

 1.  this 30 GB will be distributed among the 24 jobs or each will take 30?
 2. If i dont ask the -n 24 argument still the foreach loop will run in
parallel as i check with TOP command. What is the purpose of using it? Just
to "reserve" the nodes from other users?

Thank you



--
View this message in context: http://r.789695.n4.nabble.com/Memory-distribution-using-foreach-tp4677133.html
Sent from the R help mailing list archive at Nabble.com.


From ruipbarradas at sapo.pt  Fri Sep 27 22:56:08 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 27 Sep 2013 21:56:08 +0100
Subject: [R] exchange of  axis labels in qqnorm function
In-Reply-To: <5245984E.1010504@yahoo.com.br>
References: <5245984E.1010504@yahoo.com.br>
Message-ID: <5245F0E8.90201@sapo.pt>

Hello,

That's documented behavior. From the help page for ?qqnorm:

datax: logical. Should data values be on the x-axis?

(Try it without renaming the axis and it makes more sense.)


Hope this helps,

Rui Barradas

Em 27-09-2013 15:38, Cleber N.Borges escreveu:
> Hello all,
>
> Are there a reason for this behaviour in qqnorm function?
> (the exchange of axis labels )
>
>  >
>  > x <- rnorm(1000)
>  > par( mfcol=c(1,2) )
>  > qqnorm(x, xlab='X Axis', ylab='Y  Axis', datax=FALSE ) #Default
>  > qqnorm(x, xlab='X Axis', ylab='Y  Axis', datax=TRUE )
>  >
>  >
> Thanks for any explanation.
>
> cleber
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Fri Sep 27 23:07:41 2013
From: 538280 at gmail.com (Greg Snow)
Date: Fri, 27 Sep 2013 15:07:41 -0600
Subject: [R] Plot lines whose angle and length depict vector quantities
In-Reply-To: <CA+PRwqFwhRbWh-nS7fK3VkuuoQAs=8YRdWbNGppUHwP=RWzHqg@mail.gmail.com>
References: <CA+PRwqFwhRbWh-nS7fK3VkuuoQAs=8YRdWbNGppUHwP=RWzHqg@mail.gmail.com>
Message-ID: <CAFEqCdyU9_mh1xneZSe+73HDj8PyZNMUdELVve6mfoge4g11TA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130927/283058fe/attachment.pl>

From szehnder at uni-bonn.de  Sat Sep 28 00:05:27 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Sat, 28 Sep 2013 00:05:27 +0200
Subject: [R] Memory distribution using foreach
In-Reply-To: <1380314937400-4677133.post@n4.nabble.com>
References: <1380314937400-4677133.post@n4.nabble.com>
Message-ID: <F7877266-E41A-4E72-BA3C-E1931D477589@uni-bonn.de>

First of all LSF is a batch scheduling software. It usually expects an .lsf script. Usually the compilers on a cluster are interchangeable via the 'module switch <unload module> <load module>' and MPI-2 is the message passing interface standard. This is also rather an topic for the high-performance R list. 

Next, doMC is a multicore package registering cores on one machine - AFAIK, i.e. you have to work on one machine with the 24 cores (inform yourself on the hardware on your cluster - there should also be introduction presentations online! To know what hardware you use and what architecture it has is the first step! Try 'bhosts' on your shell to see what hosts are available). If you want to use several machines, your backend for foreach should be doMPI and not doMC (see http://cran.r-project.org/web/packages/doMPI/vignettes/doMPI.pdf). 

If you found your host, you have to write an lsf-script like the one following (for OpenMP on ONE machine - using 24 cores, in most cases this suffices. Further, it is faster as you do not have to wait that long because you have to use just ONE machine. If you have BULL clusters - take these. A lot of cores 32/64? and a lot of memory)

So in your case, write a script with extension .lsf containing:

### using the zsh shell
#!/usr/bin/env zsh 

### Job name
#BSUB -J OpenMP

### File/path where output will be written, the %J is the job ID
#BSUB -o OpenMP.%J

### (OFF) Different file for STDERR, if not to be merged with STDOUT
# #BSUB -e OpenM.e%J

### Request the time you need for execution in minutes 
### The format for the parameter is: [hour:]minute,
### that means for 80 minutes you could also use this: 1:20
#BSUB -W 3:00

### Request virtual memory you need for your job in MB (per process)
#BSUB -M 1024

### Request higher amount of stack site (per process)
#BSUB -S 1024
 
### Request the number of compute slots you want to use
#BSUB -n 24

### Specify your mail address 
#BSUB pkount at bgc-jena.mpg.de

### Send a mail when job is done
#BSUB -N

### Use esub for OpenMP 
#BSUB -a openmp

### (OFF) As R is usually compiled via gcc I would load the gcc module on your cluster 
# module switch pgi gcc/4.6

### (OFF) load another OpenMP (check which one is usually loaded!! should be now OpenMP 4.0) version than the default one
# module switch openmp openmp/3.0

### Set stack and address limits
ulimit -s unlimited
ulimit -v unlimited 

### Change to the work directory 
cd /home/your_username/

### Execute your application (make sure, that R can be loaded via 'R' on the shell!!!) 
R --no-restore --no-save --quiet --slave < your_R_script.R

------------------------

In your R script file, load the packages

library(doMC)
library(foreach)

 
registerDoMC(24)  ## now, foreach knows the backend.

forach(...) %dopar% ?..

## save your stuff to your work- or home directory (csv or database)

quit()

-----------------------

Then you send the script to LSF via 

bsub <- my_LSF_script.lsf

Look via 'bjobs' if it is is send and what's its status (PEND or RUN). If the status is RUN you can look via 'bpeek your_job_ID' what the output looks like, while it runs.

Best

Simon



On Sep 27, 2013, at 10:48 PM, pakoun <pkount at bgc-jena.mpg.de> wrote:

> Dear R users,
> I am struggling with memory issues and try to understand a few things. I am
> using an LSF cluster with PGI compiler and parallel mpi2 computing (whatever
> does that means..) and i submit a job like:
> 
> bsub -R "rusage[mem=30000]" -q queue -n 24 R CMD BATCH <arguments..> 
> myjob.r ..log
> 
> According to that I am asking for 24 cores and 30GB RAM. 
> 
> Then I am using 
> library(doMC)
> registerDoMC(24) 
> 
> and a foreach loop either simple or nested with the %dopar% command. 
> 
> 1.  this 30 GB will be distributed among the 24 jobs or each will take 30?
> 2. If i dont ask the -n 24 argument still the foreach loop will run in
> parallel as i check with TOP command. What is the purpose of using it? Just
> to "reserve" the nodes from other users?
> 
> Thank you
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Memory-distribution-using-foreach-tp4677133.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From elaine.kuo.tw at gmail.com  Sat Sep 28 00:11:20 2013
From: elaine.kuo.tw at gmail.com (Elaine Kuo)
Date: Sat, 28 Sep 2013 06:11:20 +0800
Subject: [R] Compare species presence and absence between sites
In-Reply-To: <1380288717.26695.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <CAGJhoDzGTvNvFhzbyeGy2vVSfDHOMrAoM8nH+CUEtgzn03zc9Q@mail.gmail.com>
	<52456E69.1080005@sapo.pt>
	<1380288717.26695.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <CAGJhoDzrs9uVhrt8F2ErncuP7jFFGZN-qawsjzz_-f-gu8WYWA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130928/a2a1594e/attachment.pl>

From michael.weylandt at gmail.com  Sat Sep 28 00:19:01 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt <michael.weylandt@gmail.com>)
Date: Fri, 27 Sep 2013 18:19:01 -0400
Subject: [R] An Apply function question about changing type of variable
In-Reply-To: <CANCN_HQR0zFzvhs7dbTC1y9VdUKOHSL_AZQhCSOhDbQFCqG8dg@mail.gmail.com>
References: <CANCN_HQR0zFzvhs7dbTC1y9VdUKOHSL_AZQhCSOhDbQFCqG8dg@mail.gmail.com>
Message-ID: <D34E2EFE-5BEA-462D-BD2E-E665B5A355FB@gmail.com>



On Sep 27, 2013, at 11:27, Vincent Guyader <vincent.guyader at allstat.fr> wrote:

> Hi everyone,
> 
> plese can you look at this few lines :
> 
> data(iris)
> res<-apply(iris,MARGIN=2,is)
> res[1,]
> 
> the result is :
> Sepal.Length  Sepal.Width Petal.Length  Petal.Width      Species
> "character"  "character"  "character"  "character"  "character"
> 
> How can I conserve the type off each colum? apply seems to convert it into
> "character" adn it could be a problem for me.
> 

lapply(iris, is)

apply() coerces to a matrix before doing its thing, here the lowest common denominator was character so that's what you got. 

M

> 
> Regards
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Sat Sep 28 00:21:07 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 27 Sep 2013 23:21:07 +0100
Subject: [R] Compare species presence and absence between sites
In-Reply-To: <CAGJhoDzrs9uVhrt8F2ErncuP7jFFGZN-qawsjzz_-f-gu8WYWA@mail.gmail.com>
References: <CAGJhoDzGTvNvFhzbyeGy2vVSfDHOMrAoM8nH+CUEtgzn03zc9Q@mail.gmail.com>
	<52456E69.1080005@sapo.pt>
	<1380288717.26695.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CAGJhoDzrs9uVhrt8F2ErncuP7jFFGZN-qawsjzz_-f-gu8WYWA@mail.gmail.com>
Message-ID: <524604D3.6040204@sapo.pt>

Hello,

Maybe something like the following.

res <- different(mat["B",], mat["E",])
res[res]


Rui Barradas

Em 27-09-2013 23:11, Elaine Kuo escreveu:
> Thanks Rui and Arun.
> Both worked well.
>
> One more question, what shall I add for Rui's code if only the comparison
> of TRUE (no FALSE) to be shown in the result?
>
> Elaine
>
> code
> different <- function(x, y) x == 1 & y == 0
>
> set.seed(7054)
> mat <- matrix(sample(0:1, 500, TRUE), nrow = 5)
> rownames(mat) <- LETTERS[1:5]
> colnames(mat) <- sprintf("D%03d", 1:100)
>
> different(mat["B",], mat["E",])
>
>
> On Fri, Sep 27, 2013 at 9:31 PM, arun <smartpink111 at yahoo.com> wrote:
>
>> Just to add:
>>
>> If you wanted the difference of every combination of rows:
>> set.seed(248)
>>   mat1<-
>> matrix(sample(0:1,5*100,replace=TRUE),ncol=100,dimnames=list(LETTERS[1:5],paste0("D",sprintf("%03d",1:100)))
>> )
>>   dat<-expand.grid(LETTERS[1:5],LETTERS[1:5],stringsAsFactors=FALSE)
>> dat1<-dat[!paste0(dat[,1],dat[,2]) %in% paste0(LETTERS[1:5],LETTERS[1:5]),]
>>   lst1<- lapply(seq_len(nrow(dat1)),function(i)
>> {x<-mat1[unlist(dat1[i,]),]; which(different(x[1,],x[2,]))}) #using Rui's
>> function
>> names(lst1)<- paste(dat1[,1],dat1[,2],sep="_")
>>
>>
>> A.K.
>>
>>
>>
>> ----- Original Message -----
>> From: Rui Barradas <ruipbarradas at sapo.pt>
>> To: Elaine Kuo <elaine.kuo.tw at gmail.com>
>> Cc: "r-help at r-project.org" <r-help at r-project.org>
>> Sent: Friday, September 27, 2013 7:39 AM
>> Subject: Re: [R] Compare species presence and absence between sites
>>
>> Hello,
>>
>> Something like this?
>>
>>
>> different <- function(x, y) x == 1 & y == 0
>>
>> set.seed(7054)
>> mat <- matrix(sample(0:1, 500, TRUE), nrow = 5)
>> rownames(mat) <- LETTERS[1:5]
>> colnames(mat) <- sprintf("D%03d", 1:100)
>>
>> different(mat["B",], mat["E",])
>>
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> Em 27-09-2013 11:48, Elaine Kuo escreveu:
>>> Dear List,
>>>
>>>
>>>
>>> I want to compare the presence and absence of bird species based on the
>>> sites in a matrix.
>>>
>>> The matrix has 5 rows for Island A, B, C, D, and E.
>>>
>>> It has 100 columns for bird species D001-D100.
>>>
>>> In each cell of the matrix,
>>>
>>> the presence-absence of bird species will be recorded as 1 or 0.
>>>
>>> (For example, if species D001 is found on Island D,
>>>
>>> the matrix cell of species D001 and Island D will be 1.)
>>>
>>>
>>>
>>> Now I want to know the different bird species between Island B and E.
>>>
>>> In other words, I would like to find out bird species present (1) on
>> Island
>>> B but absent (0)on island E, and vice versa (absent (0) on Island B but
>>> present (1)on island E).
>>>
>>>
>>>
>>> Please kindly advise how to code the purpose above.
>>>
>>> Thank you in advance.
>>>
>>>
>>>
>>> Elaine
>>>
>>>      [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>


From smartpink111 at yahoo.com  Sat Sep 28 01:39:17 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 27 Sep 2013 16:39:17 -0700 (PDT)
Subject: [R] Compare species presence and absence between sites
In-Reply-To: <CAGJhoDxqoGrKHyJjVhxELcM4N8KZbGQpNd0ZoaKmY=di+GJc1g@mail.gmail.com>
References: <CAGJhoDzGTvNvFhzbyeGy2vVSfDHOMrAoM8nH+CUEtgzn03zc9Q@mail.gmail.com>	<52456E69.1080005@sapo.pt>	<1380288717.26695.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CAGJhoDxqoGrKHyJjVhxELcM4N8KZbGQpNd0ZoaKmY=di+GJc1g@mail.gmail.com>
Message-ID: <1380325157.26836.YahooMailNeo@web142601.mail.bf1.yahoo.com>



Elaine,
Try:
set.seed(248)
?mat1<- matrix(sample(0:1,5*100,replace=TRUE),ncol=100,dimnames=list( c("Hokkaido","Honshu","Shikoku","Kyushu","Amami")
,paste0("D",sprintf("%03d",1:100))) )
##to change
?dat<- expand.grid(rownames(mat1),rownames(mat1),stringsAsFactors=FALSE)
dat1<- dat[!paste0(dat[,1],dat[,2])%in% paste0(rownames(mat1),rownames(mat1)),]

#same code:
lst1<- lapply(seq_len(nrow(dat1)),function(i) {x<-mat1[unlist(dat1[i,]),]; which(different(x[1,],x[2,]))}) #using Rui's function
?names(lst1)<- paste(dat1[,1],dat1[,2],sep="_")
A.K.

________________________________
From: Elaine Kuo <elaine.kuo.tw at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Friday, September 27, 2013 6:17 PM
Subject: Re: [R] Compare species presence and absence between sites



Hello Arun,?

Thanks for the code, but I have problem replacing Island A-D with real names.
Please kindly indicate where to change in the code.
The real names include Hokkaido, Honshu, Shikoku, Kyushu, and Amami.
Thanks again.

Elaine



On Fri, Sep 27, 2013 at 9:31 PM, arun <smartpink111 at yahoo.com> wrote:

Just to add:
>
>If you wanted the difference of every combination of rows:
>set.seed(248)
>?mat1<- matrix(sample(0:1,5*100,replace=TRUE),ncol=100,dimnames=list(LETTERS[1:5],paste0("D",sprintf("%03d",1:100))) )
>?dat<-expand.grid(LETTERS[1:5],LETTERS[1:5],stringsAsFactors=FALSE)
>dat1<-dat[!paste0(dat[,1],dat[,2]) %in% paste0(LETTERS[1:5],LETTERS[1:5]),]
>?lst1<- lapply(seq_len(nrow(dat1)),function(i) {x<-mat1[unlist(dat1[i,]),]; which(different(x[1,],x[2,]))}) #using Rui's function
>names(lst1)<- paste(dat1[,1],dat1[,2],sep="_")
>
>
>A.K.
>
>
>
>
>----- Original Message -----
>From: Rui Barradas <ruipbarradas at sapo.pt>
>To: Elaine Kuo <elaine.kuo.tw at gmail.com>
>Cc: "r-help at r-project.org" <r-help at r-project.org>
>Sent: Friday, September 27, 2013 7:39 AM
>Subject: Re: [R] Compare species presence and absence between sites
>
>Hello,
>
>Something like this?
>
>
>different <- function(x, y) x == 1 & y == 0
>
>set.seed(7054)
>mat <- matrix(sample(0:1, 500, TRUE), nrow = 5)
>rownames(mat) <- LETTERS[1:5]
>colnames(mat) <- sprintf("D%03d", 1:100)
>
>different(mat["B",], mat["E",])
>
>
>
>Hope this helps,
>
>Rui Barradas
>
>Em 27-09-2013 11:48, Elaine Kuo escreveu:
>> Dear List,
>>
>>
>>
>> I want to compare the presence and absence of bird species based on the
>> sites in a matrix.
>>
>> The matrix has 5 rows for Island A, B, C, D, and E.
>>
>> It has 100 columns for bird species D001-D100.
>>
>> In each cell of the matrix,
>>
>> the presence-absence of bird species will be recorded as 1 or 0.
>>
>> (For example, if species D001 is found on Island D,
>>
>> the matrix cell of species D001 and Island D will be 1.)
>>
>>
>>
>> Now I want to know the different bird species between Island B and E.
>>
>> In other words, I would like to find out bird species present (1) on Island
>> B but absent (0)on island E, and vice versa (absent (0) on Island B but
>> present (1)on island E).
>>
>>
>>
>> Please kindly advise how to code the purpose above.
>>
>> Thank you in advance.
>>
>>
>>
>> Elaine
>>
>> ??? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>


From gabrielagcc at gmail.com  Sat Sep 28 02:09:09 2013
From: gabrielagcc at gmail.com (gabriela bucini)
Date: Fri, 27 Sep 2013 20:09:09 -0400
Subject: [R] netCDF to raster and projection to UTM: output NA
Message-ID: <CABce+Y17jK2e3KPrvohUzMPM-GcDo3cXDUB1mAH0Axcg8=cv1w@mail.gmail.com>

Dear R colleagues,

I'm facing a problem with the projection of a netCDF file.
My original netCDF file is in lat/lon coordinates and I want to
project it in UTM.
I use the raster package with the function"raster" to open the file
and then "projectRaster" to change projection (I want to maintain a
similar cell resolution as the input netCDF). I obtain a raster of two
cells with NA values. Even if I change the resolution for the
projected output, I always obtain a raster of NA values.

Can anybody help me figuring out where I'm making a mistake?

Thank you very much for your help!

Gabriela

This is my code:
nc2r <- raster("./../Data/BCCA_daily_original/CMIP5/access1-0.1.rcp45/bcca5/Extraction_pr.nc",
varname = "pr", level=1)
# netCDF info
print(nc2r)
# raster info
nc2r
summary(nc2r)
#define the new projection (UTM)
newproj <- "+proj=utm +zone=18 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
# change the projection maintaining a similar resolution to input image
pr2 <- projectRaster(nc2r, crs=newproj, res=90000)
pr2
summary(pr2)


OUTPUTS:

> print(nc2r)
[1] "File C:\\Users\\GB\\Dropbox\\Downscaling\\Data\\BCCA_daily_original\\CMIP5\\access1-0.1.rcp45\\bcca5\\Extraction_pr.nc
(NC_FORMAT_CLASSIC):"
[1] ""
[1] "     1 variables (excluding dimension variables):"
[1] "        float pr[longitude,latitude,time,projection]   "
[1] "            typeConversion_op_ncl: double converted to float"
[1] "            _FillValue: 1.00000002004088e+20"
[1] "            associated_files: baseURL:
http://cmip-pcmdi.llnl.gov/CMIP5/dataLocation gridspecFile:
gridspec_atmos_fx_ACCESS1-0_historical_r0i0p0.nc areacella:
areacella_fx_ACCESS1-0_historical_r0i0p0.nc"
[1] "            missing_value: 1.00000002004088e+20"
[1] "            history: 2012-01-17T12:34:12Z altered by CMOR:
replaced missing value flag (-1.07374e+09) with standard missing value
(1e+20)."
[1] "            cell_measures: area: areacella"
[1] "            cell_methods: time: mean"
[1] "            units: mm/d"
[1] "            comment: at surface; includes both liquid and solid
phases from all types of clouds (both large-scale and convective)"
[1] "            long_name: Precipitation"
[1] "            standard_name: precipitation_flux"
[1] "            time: 0.5"
[1] ""
[1] "     4 dimensions:"
[1] "        latitude  Size:13"
[1] "            valid_max: 52.875"
[1] "            long_name: Latitude"
[1] "            valid_min: 25.125"
[1] "            units: degrees_north"
[1] "            axis: Y"
[1] "        longitude  Size:10"
[1] "            long_name: Longitude"
[1] "            axis: X"
[1] "            units: degrees_east"
[1] "            modulo: 360"
[1] "            topology: circular"
[1] "        time  Size:54787"
[1] "            calendar: standard"
[1] "            units: days since 1950-01-01 00:00:00"
[1] "            standard_name: time"
[1] "            long_name: time"
[1] "            axis: T"
[1] "        projection  Size:1   *** is unlimited ***"
[1] ""
[1] "    15 global attributes:"
[1] "        institution: CSIRO (Commonwealth Scientific and
Industrial Research Organisation, Australia), and BOM (Bureau of
Meteorology, Australia)"
[1] "        institute_id: CSIRO-BOM"
[1] "        model_id: ACCESS1-0"
[1] "        frequency: day"
[1] "        experiment: historical"
[1] "        experiment_id: historical"
[1] "        parent_experiment: pre-industrial control"
[1] "        parent_experiment_id: piControl"
[1] "        parent_experiment_rip: r1i1p1"
[1] "        creation_date: Fri Sep 14 14:51:45 PDT 2012"
[1] "        references: Daily BC method: modified version of Maurer
EP, Hidalgo HG, Das T, Dettinger MD, Cayan DR, 2010, Hydrol Earth Syst
Sci 14:1125-1138\nCA method: Hidalgo HG, Dettinger MD, Cayan DR, 2008,
California Energy Commission technical report
CEC-500-2007-123\nReference period obs: updated version of Maurer EP,
Wood AW, Adam JC, Lettenmaier DP, Nijssen B, 2002, J Climate
15(22):3237???3251, \nprovided via
http://www.engr.scu.edu/~emaurer/gridded_obs/index_gridded_obs.html"
[1] "        contacts: Bridget Thrasher:
bridget at climateanalyticsgroup.org or Ed Maurer: emaurer at scu.edu"
[1] "        documentation: http://gdo-dcp.ucllnl.org"
[1] "        NCO: 4.0.8"
[1] "        Projections: access1-0.1.rcp45, "


# raster info

> nc2r
class       : RasterLayer
dimensions  : 13, 10, 130  (nrow, ncol, ncell)
resolution  : 0.125, 0.125  (x, y)
extent      : 286.625, 287.875, 43.875, 45.5  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
data source : C:\Users\Gabriela
Bucini\Dropbox\Downscaling\Data\BCCA_daily_original\CMIP5\access1-0.1.rcp45\bcca5\Extraction_pr.nc
names       : Precipitation
z-value     : 1
zvar        : pr
level       : 1


class       : RasterLayer
dimensions  : 13, 10, 130  (nrow, ncol, ncell)
resolution  : 0.125, 0.125  (x, y)
extent      : 286.625, 287.875, 43.875, 45.5  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
data source : C:\Users\Gabriela
Bucini\Dropbox\Downscaling\Data\BCCA_daily_original\CMIP5\access1-0.1.rcp45\bcca5\Extraction_pr.nc
names       : Precipitation
z-value     : 1
zvar        : pr
level       : 1



> summary(values(nc2r))
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's
 0.5352  1.2530  1.6820  1.7590  2.2790  3.4180       6

#define the new projection
newproj <- "+proj=utm +zone=18 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
# change the projection maintaining a similar resolution to input image
pr2 <- projectRaster(nc2r, crs=newproj, res= 90000)

> pr2
class       : RasterLayer
dimensions  : 2, 1, 2  (nrow, ncol, ncell)
resolution  : 90000, 90000  (x, y)
extent      : 626955.8, 716955.8, 4862518, 5042518  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=utm +zone=18 +ellps=WGS84 +datum=WGS84 +units=m
+no_defs +towgs84=0,0,0
data source : in memory
names       : Precipitation
values      : NA, NA  (min, max)

> summary(pr2)
        Precipitation
Min.               NA
1st Qu.            NA
Median             NA
3rd Qu.            NA
Max.               NA
NA's                2


From pkount at bgc-jena.mpg.de  Sat Sep 28 02:18:15 2013
From: pkount at bgc-jena.mpg.de (pakoun)
Date: Fri, 27 Sep 2013 17:18:15 -0700 (PDT)
Subject: [R] Memory distribution using foreach
In-Reply-To: <F7877266-E41A-4E72-BA3C-E1931D477589@uni-bonn.de>
References: <1380314937400-4677133.post@n4.nabble.com>
	<F7877266-E41A-4E72-BA3C-E1931D477589@uni-bonn.de>
Message-ID: <1380327495150-4677149.post@n4.nabble.com>

Thank you Simon for your quick response. Now I understand a lot of things,
and how to use them. Well they should offer some lessons my department how
to work with the cluster but unfortunately they didnt and I am trying to
find alone everything. Thanks again for the great advise

Best wishes
Panos



--
View this message in context: http://r.789695.n4.nabble.com/Memory-distribution-using-foreach-tp4677133p4677149.html
Sent from the R help mailing list archive at Nabble.com.


From jim at bitwrit.com.au  Sat Sep 28 02:57:05 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sat, 28 Sep 2013 10:57:05 +1000
Subject: [R] Plot lines whose angle and length depict vector quantities
In-Reply-To: <CA+PRwqFwhRbWh-nS7fK3VkuuoQAs=8YRdWbNGppUHwP=RWzHqg@mail.gmail.com>
References: <CA+PRwqFwhRbWh-nS7fK3VkuuoQAs=8YRdWbNGppUHwP=RWzHqg@mail.gmail.com>
Message-ID: <52462961.9030703@bitwrit.com.au>

On 09/28/2013 04:56 AM, Conor Ryan wrote:
> I am trying to plot points on a map for each ship locations (lat/long),
> where
> each point is a line whose angle (degrees) denotes ships heading and whose
> line length denotes it's speed. Unfortunately arrows(); p.arrows (sfsmisc)
> and ms.arrows (TeachingDemos) require start and end coordinates but I only
> have a single coordinate and an angle to work with. Can you suggest any
> other packages or commands that might allow me to plot this? Alternatively,
> can anyone suggest a method of making 'angle' a vector quantity when using
> the arrows function? Any advice would be much appreciated!
>
Hi Conor,
Try the vector.field function (plotrix).

Jim


From jeffrey.flint at gmail.com  Sat Sep 28 03:20:32 2013
From: jeffrey.flint at gmail.com (Jeffrey Flint)
Date: Fri, 27 Sep 2013 18:20:32 -0700
Subject: [R] makeCluster help needed
Message-ID: <CALbUM4MVAXRUGn0gJ8ziRe+HjDC0aRRPE1R9UE4OLnAkVSoDdQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130927/dab1d46d/attachment.pl>

From xiaofang1990 at gmail.com  Sat Sep 28 02:21:32 2013
From: xiaofang1990 at gmail.com (Xiao Fang)
Date: Fri, 27 Sep 2013 20:21:32 -0400
Subject: [R] How to make LN(x) transformation in R?
Message-ID: <CAK-sm3E0-YTvgpCHOBR1SRGEFonjJyt1Jto2N5QgEao1-tJ4HQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130927/143056a6/attachment.pl>

From bhh at xs4all.nl  Sat Sep 28 07:11:34 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sat, 28 Sep 2013 07:11:34 +0200
Subject: [R] How to make LN(x) transformation in R?
In-Reply-To: <CAK-sm3E0-YTvgpCHOBR1SRGEFonjJyt1Jto2N5QgEao1-tJ4HQ@mail.gmail.com>
References: <CAK-sm3E0-YTvgpCHOBR1SRGEFonjJyt1Jto2N5QgEao1-tJ4HQ@mail.gmail.com>
Message-ID: <D5E92612-FD68-42BB-881F-3415E071D7C0@xs4all.nl>


On 28-09-2013, at 02:21, Xiao Fang <xiaofang1990 at gmail.com> wrote:

> Dear R colleagues,
> 
> I am a newbie to R. I can not figure out how to compute Ln(x) value in R.
> 
> My question may be so easy for you but I will really appreciate if you can
> help me. Thanks so much for your time!
> 

Assuming you mean natural logarithm,  use log and read the help page of log.

Berend

> Kathy
> 
> 	[[alternative HTML version deleted]]

Please don't post in HTML.
Read the posting  guide.


> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pburns at pburns.seanet.com  Sat Sep 28 12:39:02 2013
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Sat, 28 Sep 2013 11:39:02 +0100
Subject: [R] Plot lines whose angle and length depict vector quantities
In-Reply-To: <CACk-te1wDV0HO6vax6JLsEqGs0a817m3sZJpiK2d910NwYSSEQ@mail.gmail.com>
References: <CA+PRwqFwhRbWh-nS7fK3VkuuoQAs=8YRdWbNGppUHwP=RWzHqg@mail.gmail.com>
	<CAM_vjukYFGFCK5ms6DOdzgoM-kyVdDfQo_i3tkVx84Z4ZiwkzQ@mail.gmail.com>
	<CACk-te1wDV0HO6vax6JLsEqGs0a817m3sZJpiK2d910NwYSSEQ@mail.gmail.com>
Message-ID: <5246B1C6.8060905@pburns.seanet.com>

On 27/09/2013 21:01, Bert Gunter wrote:
> On Fri, Sep 27, 2013 at 12:44 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>> It's a straightforward trigonometry problem, isn't it?
>
> Indeed! (  (r,theta) to (x,y) coordinates  ) . So I wonder if this is
> a homework problem. If so, the OP should note that we try not to do
> homework here.

So that would make it unanimous that everyone here is trying
not to do homework.

Pat

>
> Cheers,
> Bert
>>
>> On Fri, Sep 27, 2013 at 2:56 PM, Conor Ryan <miolmor at gmail.com> wrote:
>>> I am trying to plot points on a map for each ship locations (lat/long),
>>> where
>>> each point is a line whose angle (degrees) denotes ships heading and whose
>>> line length denotes it's speed. Unfortunately arrows(); p.arrows (sfsmisc)
>>> and ms.arrows (TeachingDemos) require start and end coordinates but I only
>>> have a single coordinate and an angle to work with. Can you suggest any
>>> other packages or commands that might allow me to plot this? Alternatively,
>>> can anyone suggest a method of making 'angle' a vector quantity when using
>>> the arrows function? Any advice would be much appreciated!
>>>
>>
>> --
>> Sarah Goslee
>> http://www.functionaldiversity.org
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>

-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @burnsstat @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of:
  'Impatient R'
  'The R Inferno'
  'Tao Te Programming')


From pburns at pburns.seanet.com  Sat Sep 28 12:45:38 2013
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Sat, 28 Sep 2013 11:45:38 +0100
Subject: [R] Logical indexing not working
In-Reply-To: <DUB120-W40301B8B1FAAE99ED5A749A4290@phx.gbl>
References: <DUB120-W40301B8B1FAAE99ED5A749A4290@phx.gbl>
Message-ID: <5246B352.3090107@pburns.seanet.com>

This is Circle 8.1.6 of 'The R Inferno'.

http://www.burns-stat.com/documents/books/the-r-inferno/

Pat


On 27/09/2013 19:20, Mariki Zietsman wrote:
> I have a data frame frugivore.abundance.S1 where some columns are factors and others are numbers.For example these are my independent variables and "density" is my dependent variable. census<-c(1:70)sites<-c(1:5)birds<-c(1:45)
>
> I want to select the data where sites is 1 and birds are 1,23,24 or 29
> So I write:fa1<-frugivore.abundance.S1attach(fa1)(abund.frug.RN1<-fa1[sites==1 & birds==c(1,23,24,29),])
> This code doesn't print all the data it should for some reason. It seems to not print rows where "density" has the same value as another row with the same criteria.
> i.e. if in the original data we have the following then only rows 1 and 3 will be printed, not all of them:
> census   sites   birds   density1                 1         1         0.0032                 1         1         0.0033                 1         1         0.001
> Can anyone help me out with this please?
> RegardsMariki
>   		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @burnsstat @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of:
  'Impatient R'
  'The R Inferno'
  'Tao Te Programming')


From ejoffe at hotmail.com  Sat Sep 28 11:39:44 2013
From: ejoffe at hotmail.com (E Joffe)
Date: Sat, 28 Sep 2013 11:39:44 +0200
Subject: [R] Interperting results of glmnet and coxph plot,
	Brier score and Harrel's C-Index - am I doing something wrong ???
Message-ID: <DUB114-DS8BCB78F26CC24B7DF2E17CA2A0@phx.gbl>

Hi all,

I am using COX LASSO (glmnet / coxnet) regression to analyze a dataset of
394 obs. / 268 vars.
I use the following procedure:
1.	Construct a coxnet on the entire dataset (by cv.glmnet) 
2.	Pick the significant features by selecting the non-zero coefficient
under the best lambda selected by the model 
3.	Build a coxph model with bi-directional stepwise feature selection
limited to the coxnet selected features.
	
To validate the model I use both Brier score (library=peperr) and Harrel's
C-Index (library=Hmisc) with a bootstrap of 50 iterations.


MY QUESTION :  I am getting fairly good C-Index (0.76) and Brier (0.07)
values for the models however per the coxnet the %Dev explained by the model
is at best 0.27 and when I plot the survfit of the coxph the plotted
confidence interval is very large. 
What am I missing here ?

%DEV=27%
 


Brier score - 0.07  ($ipec.coxglmnet -> [1] 7.24)
C-Index - 0.76 ($cIndex -> [1] 0.763)



DATA: [Private Health Information - can't publish] 394 obs./268 vars.

CODE (need to define a dataset with 'time' and 'status' variables):

library("survival")
library ("glmnet")
library ("c060")
library ("peperr")
library ("Hmisc")

    #creat Y (survival matrix) for glmnet
    surv_obj <- Surv(dataset$time,dataset$status) 
    
      
    ## tranform categorical variables into binary variables with dummy for
dataset
    predict_matrix <- model.matrix(~ ., data=dataset, 
                                   contrasts.arg = lapply
(dataset[,sapply(dataset, is.factor)], contrasts))
    
    ## remove the statu/time variables from the predictor matrix (x) for
glmnet
    predict_matrix <- subset (predict_matrix, select=c(-time,-status))
    
    ## create a glmnet cox object using lasso regularization and cross
validation
    glmnet.cv <- cv.glmnet (predict_matrix, surv_obj, family="cox")
    
    ## get the glmnet model on the full dataset
    glmnet.obj <- glmnet.cv$glmnet.fit
    
    # find lambda index for the models with least partial likelihood
deviance (by cv.glmnet) 
    optimal.lambda <- glmnet.cv$lambda.min    # For a more parsimoneous
model use lambda.1se     
    lambda.index <- which(glmnet.obj$lambda==optimal.lambda) 
    
    
    # take beta for optimal lambda 
    optimal.beta  <- glmnet.obj$beta[,lambda.index] 
    
    # find non zero beta coef 
    nonzero.coef <- abs(optimal.beta)>0 
    selectedBeta <- optimal.beta[nonzero.coef] 
    
    # take only covariates for which beta is not zero 
    selectedVar   <- predict_matrix[,nonzero.coef] 
    
    # create a dataframe for trainSet with time, status and selected
variables in binary representation for evaluation in pec
    reformat_dataSet <- as.data.frame(cbind(surv_obj,selectedVar))
    
    # glmnet.cox only with meaningful features selected by stepwise
bidirectional AIC feature selection 
    glmnet.cox.meaningful <- step(coxph(Surv(time,status) ~
.,data=reformat_dataSet),direction="both")
    
         
  
 
##--------------------------------------------------------------------------
-----------------------------
    ##                                    MODEL PERFORMANCE
 
##--------------------------------------------------------------------------
-----------------------------
    ## 
    
  
    ## Calculate the Brier score - pec does its own bootstrap so this
function runs on i=51 (i.e., whole trainset)                         

        ## Brier score calculation to cox-glmnet
        peperr.coxglmnet <- peperr(response=surv_obj, x=selectedVarCox,
                                fit.fun=fit.coxph, load.all=TRUE,
                                indices=resample.indices(n=nrow(surv_obj),
method="boot", sample.n=50))
        
        # Get error predictions from peperr
        prederr.coxglmnet <- perr(peperr.coxglmnet)
        
        # Integrated prediction error Brier score calculation
        ipec.coxglmnet<-ipec(prederr.coxglmnet,
eval.times=peperr.coxglmnet$attribute, response=surv_obj)

    
  ## C-Index calculation 50 iter bootstrapping
  
  for (i in 1:50){
        print (paste("Iteration:",i))
        train <- sample(1:nrow(dataset), nrow(dataset), replace = TRUE) ##
random sampling with replacement
        # create a dataframe for trainSet with time, status and selected
variables in binary representation for evaluation in pec
        reformat_trainSet <- reformat_dataSet [train,]
        
        
        # glmnet.cox only with meaningful features selected by stepwise
bidirectional AIC feature selection 
        glmnet.cox.meaningful.test <- step(coxph(Surv(time,status) ~
.,data=reformat_dataSet),direction="both")
        
        selectedVarCox   <-
predict_matrix[,attr(glmnet.cox.meaningful.test$terms,"term.labels")] 
        reformat_testSet <- as.data.frame(cbind(surv_obj,selectedVarCox))
        reformat_testSet <- reformat_dataSet [-train,]
      
        
#     compute c-index (Harrell's) for cox-glmnet models
        if (is.null(glmnet.cox.meaningful)){
          cIndexCoxglmnet <- c(cIndexCoxglmnet,NULL)
        }else{
          cIndexCoxglmnet <- c(cIndexCoxglmnet,
1-rcorr.cens(predict(glmnet.cox.meaningful,
reformat_testSet),Surv(reformat_testSet$time,reformat_testSet$status))[1])
        }
  }
  
  #Get average C-Index
  cIndex<- mean (unlist(cIndexCoxglmnet),rm.na=TRUE)
  
  #create a list of all the objects generated
 
assign(name,c(eval(parse(text=name)),glmnet.cv=list(glmnet.cv),glmnet.obj=li
st(glmnet.obj),
 
selectedVar=list(colnames(selectedVar)),glmnet.cox=list(glmnet.cox),
 
glmnet.cox.meaningful=list(glmnet.cox.meaningful),ipec.coxglmnet=list(ipec.c
oxglmnet),
                cIndex=cIndex))
    
  # save image of the workspace after each iteration
    save.image("final_subgroup_analysissubgroup_analysis.RData")
    


From miolmor at gmail.com  Sat Sep 28 11:23:18 2013
From: miolmor at gmail.com (Conor Ryan)
Date: Sat, 28 Sep 2013 10:23:18 +0100
Subject: [R] Plot lines whose angle and length depict vector quantities
In-Reply-To: <52462961.9030703@bitwrit.com.au>
References: <CA+PRwqFwhRbWh-nS7fK3VkuuoQAs=8YRdWbNGppUHwP=RWzHqg@mail.gmail.com>
	<52462961.9030703@bitwrit.com.au>
Message-ID: <CA+PRwqHooBB321KXXQVLqXELLXguDhzhhG7R7cnDU8gJp5CMmw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130928/b69c5123/attachment.pl>

From miolmor at gmail.com  Sat Sep 28 11:26:32 2013
From: miolmor at gmail.com (Conor Ryan)
Date: Sat, 28 Sep 2013 10:26:32 +0100
Subject: [R] Plot lines whose angle and length depict vector quantities
In-Reply-To: <CAFEqCdyU9_mh1xneZSe+73HDj8PyZNMUdELVve6mfoge4g11TA@mail.gmail.com>
References: <CA+PRwqFwhRbWh-nS7fK3VkuuoQAs=8YRdWbNGppUHwP=RWzHqg@mail.gmail.com>
	<CAFEqCdyU9_mh1xneZSe+73HDj8PyZNMUdELVve6mfoge4g11TA@mail.gmail.com>
Message-ID: <CA+PRwqH0ZY=Y0AbVP0e4sVVE3=gSaQzbPGP8-P4JOeDUL+Bu6w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130928/d1b2286b/attachment.pl>

From miolmor at gmail.com  Sat Sep 28 13:31:57 2013
From: miolmor at gmail.com (Conor Ryan)
Date: Sat, 28 Sep 2013 12:31:57 +0100
Subject: [R] Plot lines whose angle and length depict vector quantities
In-Reply-To: <5246B1C6.8060905@pburns.seanet.com>
References: <CA+PRwqFwhRbWh-nS7fK3VkuuoQAs=8YRdWbNGppUHwP=RWzHqg@mail.gmail.com>
	<CAM_vjukYFGFCK5ms6DOdzgoM-kyVdDfQo_i3tkVx84Z4ZiwkzQ@mail.gmail.com>
	<CACk-te1wDV0HO6vax6JLsEqGs0a817m3sZJpiK2d910NwYSSEQ@mail.gmail.com>
	<5246B1C6.8060905@pburns.seanet.com>
Message-ID: <CA+PRwqFMWjRnOu4yCr2_ZLx6f9+FhnB8=MqJ_qvbwyGU2JsGVw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130928/abf85eae/attachment.pl>

From gunter.berton at gene.com  Sat Sep 28 16:28:40 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 28 Sep 2013 07:28:40 -0700
Subject: [R] Interperting results of glmnet and coxph plot,
 Brier score and Harrel's C-Index - am I doing something wrong ???
In-Reply-To: <DUB114-DS8BCB78F26CC24B7DF2E17CA2A0@phx.gbl>
References: <DUB114-DS8BCB78F26CC24B7DF2E17CA2A0@phx.gbl>
Message-ID: <CACk-te3mQ5-ibYGVN1ywJD-x-6V1nnsQ0_Hqqgd3azA0bSmPtA@mail.gmail.com>

This appears to be a statistics, not an R-help question, so should
probably be asked on a statistics list, not here (e.g.
stats.stackexchange.com).

But if I understand your issue correctly, perhaps the heart f the
matter is: why do you think a stable fit must explain a lot of the
variation?  Feel free to ignore if I I'm wrong or discuss further on
the statistics list.

Cheers,
Bert

On Sat, Sep 28, 2013 at 2:39 AM, E Joffe <ejoffe at hotmail.com> wrote:
> Hi all,
>
> I am using COX LASSO (glmnet / coxnet) regression to analyze a dataset of
> 394 obs. / 268 vars.
> I use the following procedure:
> 1.      Construct a coxnet on the entire dataset (by cv.glmnet)
> 2.      Pick the significant features by selecting the non-zero coefficient
> under the best lambda selected by the model
> 3.      Build a coxph model with bi-directional stepwise feature selection
> limited to the coxnet selected features.
>
> To validate the model I use both Brier score (library=peperr) and Harrel's
> C-Index (library=Hmisc) with a bootstrap of 50 iterations.
>
>
> MY QUESTION :  I am getting fairly good C-Index (0.76) and Brier (0.07)
> values for the models however per the coxnet the %Dev explained by the model
> is at best 0.27 and when I plot the survfit of the coxph the plotted
> confidence interval is very large.
> What am I missing here ?
>
> %DEV=27%
>
>
>
> Brier score - 0.07  ($ipec.coxglmnet -> [1] 7.24)
> C-Index - 0.76 ($cIndex -> [1] 0.763)
>
>
>
> DATA: [Private Health Information - can't publish] 394 obs./268 vars.
>
> CODE (need to define a dataset with 'time' and 'status' variables):
>
> library("survival")
> library ("glmnet")
> library ("c060")
> library ("peperr")
> library ("Hmisc")
>
>     #creat Y (survival matrix) for glmnet
>     surv_obj <- Surv(dataset$time,dataset$status)
>
>
>     ## tranform categorical variables into binary variables with dummy for
> dataset
>     predict_matrix <- model.matrix(~ ., data=dataset,
>                                    contrasts.arg = lapply
> (dataset[,sapply(dataset, is.factor)], contrasts))
>
>     ## remove the statu/time variables from the predictor matrix (x) for
> glmnet
>     predict_matrix <- subset (predict_matrix, select=c(-time,-status))
>
>     ## create a glmnet cox object using lasso regularization and cross
> validation
>     glmnet.cv <- cv.glmnet (predict_matrix, surv_obj, family="cox")
>
>     ## get the glmnet model on the full dataset
>     glmnet.obj <- glmnet.cv$glmnet.fit
>
>     # find lambda index for the models with least partial likelihood
> deviance (by cv.glmnet)
>     optimal.lambda <- glmnet.cv$lambda.min    # For a more parsimoneous
> model use lambda.1se
>     lambda.index <- which(glmnet.obj$lambda==optimal.lambda)
>
>
>     # take beta for optimal lambda
>     optimal.beta  <- glmnet.obj$beta[,lambda.index]
>
>     # find non zero beta coef
>     nonzero.coef <- abs(optimal.beta)>0
>     selectedBeta <- optimal.beta[nonzero.coef]
>
>     # take only covariates for which beta is not zero
>     selectedVar   <- predict_matrix[,nonzero.coef]
>
>     # create a dataframe for trainSet with time, status and selected
> variables in binary representation for evaluation in pec
>     reformat_dataSet <- as.data.frame(cbind(surv_obj,selectedVar))
>
>     # glmnet.cox only with meaningful features selected by stepwise
> bidirectional AIC feature selection
>     glmnet.cox.meaningful <- step(coxph(Surv(time,status) ~
> .,data=reformat_dataSet),direction="both")
>
>
>
>
> ##--------------------------------------------------------------------------
> -----------------------------
>     ##                                    MODEL PERFORMANCE
>
> ##--------------------------------------------------------------------------
> -----------------------------
>     ##
>
>
>     ## Calculate the Brier score - pec does its own bootstrap so this
> function runs on i=51 (i.e., whole trainset)
>
>         ## Brier score calculation to cox-glmnet
>         peperr.coxglmnet <- peperr(response=surv_obj, x=selectedVarCox,
>                                 fit.fun=fit.coxph, load.all=TRUE,
>                                 indices=resample.indices(n=nrow(surv_obj),
> method="boot", sample.n=50))
>
>         # Get error predictions from peperr
>         prederr.coxglmnet <- perr(peperr.coxglmnet)
>
>         # Integrated prediction error Brier score calculation
>         ipec.coxglmnet<-ipec(prederr.coxglmnet,
> eval.times=peperr.coxglmnet$attribute, response=surv_obj)
>
>
>   ## C-Index calculation 50 iter bootstrapping
>
>   for (i in 1:50){
>         print (paste("Iteration:",i))
>         train <- sample(1:nrow(dataset), nrow(dataset), replace = TRUE) ##
> random sampling with replacement
>         # create a dataframe for trainSet with time, status and selected
> variables in binary representation for evaluation in pec
>         reformat_trainSet <- reformat_dataSet [train,]
>
>
>         # glmnet.cox only with meaningful features selected by stepwise
> bidirectional AIC feature selection
>         glmnet.cox.meaningful.test <- step(coxph(Surv(time,status) ~
> .,data=reformat_dataSet),direction="both")
>
>         selectedVarCox   <-
> predict_matrix[,attr(glmnet.cox.meaningful.test$terms,"term.labels")]
>         reformat_testSet <- as.data.frame(cbind(surv_obj,selectedVarCox))
>         reformat_testSet <- reformat_dataSet [-train,]
>
>
> #     compute c-index (Harrell's) for cox-glmnet models
>         if (is.null(glmnet.cox.meaningful)){
>           cIndexCoxglmnet <- c(cIndexCoxglmnet,NULL)
>         }else{
>           cIndexCoxglmnet <- c(cIndexCoxglmnet,
> 1-rcorr.cens(predict(glmnet.cox.meaningful,
> reformat_testSet),Surv(reformat_testSet$time,reformat_testSet$status))[1])
>         }
>   }
>
>   #Get average C-Index
>   cIndex<- mean (unlist(cIndexCoxglmnet),rm.na=TRUE)
>
>   #create a list of all the objects generated
>
> assign(name,c(eval(parse(text=name)),glmnet.cv=list(glmnet.cv),glmnet.obj=li
> st(glmnet.obj),
>
> selectedVar=list(colnames(selectedVar)),glmnet.cox=list(glmnet.cox),
>
> glmnet.cox.meaningful=list(glmnet.cox.meaningful),ipec.coxglmnet=list(ipec.c
> oxglmnet),
>                 cIndex=cIndex))
>
>   # save image of the workspace after each iteration
>     save.image("final_subgroup_analysissubgroup_analysis.RData")
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From smartpink111 at yahoo.com  Sat Sep 28 16:31:58 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 28 Sep 2013 07:31:58 -0700 (PDT)
Subject: [R] Compare species presence and absence between sites
In-Reply-To: <CAGJhoDwvDXWGwD4fFzH-qO7A2ZZ1fOEM5cKB25zYO3zx=8Fhag@mail.gmail.com>
References: <CAGJhoDzGTvNvFhzbyeGy2vVSfDHOMrAoM8nH+CUEtgzn03zc9Q@mail.gmail.com>	<52456E69.1080005@sapo.pt>	<1380288717.26695.YahooMailNeo@web142603.mail.bf1.yahoo.com>	<CAGJhoDxqoGrKHyJjVhxELcM4N8KZbGQpNd0ZoaKmY=di+GJc1g@mail.gmail.com>	<1380325157.26836.YahooMailNeo@web142601.mail.bf1.yahoo.com>	<CAGJhoDyeseRuDCCyC-dcZcH=rx9M+PaTRXWBe9tJZTGXaOZsbg@mail.gmail.com>	<CAGJhoDzWbsqNxo1GkzAAatsJ0J5_U82aCVq+eLKJR053icENHw@mail.gmail.com>	<1380337292.35874.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CAGJhoDwvDXWGwD4fFzH-qO7A2ZZ1fOEM5cKB25zYO3zx=8Fhag@mail.gmail.com>
Message-ID: <1380378718.50724.YahooMailNeo@web142604.mail.bf1.yahoo.com>



I couldn't get the number you showed below each column number.? How did you get that one?

library(XLConnect)
wb<- loadWorkbook("is_matrix1.xls")
dataRM<- readWorksheet(wb,sheet="is_matrix",rownames=1)
mat1<- as.matrix(dataRM)
different <- function(x, y) x == 1 & y == 0

dat<- expand.grid(rownames(mat1),rownames(mat1),stringsAsFactors=FALSE)
dat1<- dat[!paste0(dat[,1],dat[,2])%in% paste0(rownames(mat1),rownames(mat1)),]
lst1<- lapply(seq_len(nrow(dat1)),function(i) {x<-mat1[unlist(dat1[i,]),]; which(different(x[1,],x[2,]))}) 
names(lst1)<- paste(dat1[,1],dat1[,2],sep="_")
? tail(lst1,1)
#$New_Guinea_Australia
#D2781 D2782 D2784 D2785 D2786 D2787 D2796 D0005 D0006 
?# ? 1???? 2???? 4???? 5???? 6???? 7???? 8???? 9??? 10??? #indicates the column index


#compare that with:

?tail(lapply(seq_len(nrow(dat1)),function(i) {x<-mat1[unlist(dat1[i,]),];x}),1)
[[1]]
?????????? D2781 D2782 D2783 D2784 D2785 D2786 D2787 D2796 D0005 D0006 D0008
New_Guinea???? 1???? 1???? 0???? 1???? 1???? 1???? 1???? 1???? 1???? 1???? 0
Australia????? 0???? 0???? 0???? 0???? 0???? 0???? 0???? 0???? 0???? 0???? 0
?????????? D0009 D0010 D0011 D0012 D3394 D3395 D3396 D3397 D3398 D3399 D3400
New_Guinea???? 0???? 0???? 0???? 0???? 0???? 0???? 0???? 0???? 0???? 0???? 0
Australia????? 0???? 0???? 0???? 0???? 0???? 0???? 0???? 0???? 0???? 0???? 0
?????????? D3401
New_Guinea???? 0
Australia????? 0



#If you wanted the actual columns that satify the condition:
lst2<- lapply(seq_len(nrow(dat1)),function(i) {x<-mat1[unlist(dat1[i,]),]; indx<- different(x[1,],x[2,]);x[,indx,drop=FALSE]})
?tail(lst2,1)
#[[1]]
?# ???????? D2781 D2782 D2784 D2785 D2786 D2787 D2796 D0005 D0006
#New_Guinea???? 1???? 1???? 1???? 1???? 1???? 1???? 1???? 1???? 1
#Australia????? 0???? 0???? 0???? 0???? 0???? 0???? 0???? 0???? 0

A.K.






________________________________
From: Elaine Kuo <elaine.kuo.tw at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Saturday, September 28, 2013 12:23 AM
Subject: Re: [R] Compare species presence and absence between sites



Hello Arun,?

Thanks for the immediate response.
Please kindly find the attached file.
For example, under D2202, it is 3402, not 2202.
Please kindly advise if this is a misunderstanding.

Thanks

Elaine



On Sat, Sep 28, 2013 at 11:01 AM, arun <smartpink111 at yahoo.com> wrote:


>
>
>Hi,
>I didn't understand the problem.? Could you please specify what you meant by the "species ID number and the number"?
>Tx
>
>________________________________
>From: Elaine Kuo <elaine.kuo.tw at gmail.com>
>To: arun <smartpink111 at yahoo.com>
>Sent: Friday, September 27, 2013 10:51 PM
>
>Subject: Re: [R] Compare species presence and absence between sites
>
>
>
>
>sorry,?
>I meant that the species ID number and the number are not the same.
>Need more sleep :P
>
>Elaine?
>
>
>
>On Sat, Sep 28, 2013 at 10:50 AM, Elaine Kuo <elaine.kuo.tw at gmail.com> wrote:
>
>Dear arun,?
>>
>>
>>Thanks for the code.
>>
>>
>>However, the number below each species ID is not identical.
>>Please kindly find attached file (I sent you once.) for test help.
>>Thanks again.
>>
>>
>>Elaine
>>
>>
>>
>>
>>Code
>>
>>
>>Try:
>>set.seed(248)
>>?mat1<- matrix(sample(0:1,5*100,replace=TRUE),ncol=100,dimnames=list( c("Hokkaido","Honshu","Shikoku","Kyushu","Amami")
>>
>>,paste0("D",sprintf("%03d",1:100))) )
>>##to change
>>?dat<- expand.grid(rownames(mat1),rownames(mat1),stringsAsFactors=FALSE)
>>dat1<- dat[!paste0(dat[,1],dat[,2])%in% paste0(rownames(mat1),rownames(mat1)),]
>>
>>#same code:
>>
>>
>
>>lst1<- lapply(seq_len(nrow(dat1)),function(i) {x<-mat1[unlist(dat1[i,]),]; which(different(x[1,],x[2,]))}) #using Rui's function
>>?names(lst1)<- paste(dat1[,1],dat1[,2],sep="_")
>>A.K.
>>
>>
>>
>>On Sat, Sep 28, 2013 at 7:39 AM, arun <smartpink111 at yahoo.com> wrote:
>>
>>
>>>
>>>Elaine,
>>>Try:
>>>set.seed(248)
>>>?mat1<- matrix(sample(0:1,5*100,replace=TRUE),ncol=100,dimnames=list( c("Hokkaido","Honshu","Shikoku","Kyushu","Amami")
>>>
>>>,paste0("D",sprintf("%03d",1:100))) )
>>>##to change
>>>?dat<- expand.grid(rownames(mat1),rownames(mat1),stringsAsFactors=FALSE)
>>>dat1<- dat[!paste0(dat[,1],dat[,2])%in% paste0(rownames(mat1),rownames(mat1)),]
>>>
>>>#same code:
>>>
>>>lst1<- lapply(seq_len(nrow(dat1)),function(i) {x<-mat1[unlist(dat1[i,]),]; which(different(x[1,],x[2,]))}) #using Rui's function
>>>?names(lst1)<- paste(dat1[,1],dat1[,2],sep="_")
>>>A.K.
>>>
>>>
>>>________________________________
>>>From: Elaine Kuo <elaine.kuo.tw at gmail.com>
>>>To: arun <smartpink111 at yahoo.com>
>>>Sent: Friday, September 27, 2013 6:17 PM
>>>
>>>Subject: Re: [R] Compare species presence and absence between sites
>>>
>>>
>>>
>>>Hello Arun,?
>>>
>>>Thanks for the code, but I have problem replacing Island A-D with real names.
>>>Please kindly indicate where to change in the code.
>>>The real names include Hokkaido, Honshu, Shikoku, Kyushu, and Amami.
>>>Thanks again.
>>>
>>>Elaine
>>>
>>>
>>>
>>>On Fri, Sep 27, 2013 at 9:31 PM, arun <smartpink111 at yahoo.com> wrote:
>>>
>>>Just to add:
>>>>
>>>>If you wanted the difference of every combination of rows:
>>>>set.seed(248)
>>>>?mat1<- matrix(sample(0:1,5*100,replace=TRUE),ncol=100,dimnames=list(LETTERS[1:5],paste0("D",sprintf("%03d",1:100))) )
>>>>?dat<-expand.grid(LETTERS[1:5],LETTERS[1:5],stringsAsFactors=FALSE)
>>>>dat1<-dat[!paste0(dat[,1],dat[,2]) %in% paste0(LETTERS[1:5],LETTERS[1:5]),]
>>>>?lst1<- lapply(seq_len(nrow(dat1)),function(i) {x<-mat1[unlist(dat1[i,]),]; which(different(x[1,],x[2,]))}) #using Rui's function
>>>>names(lst1)<- paste(dat1[,1],dat1[,2],sep="_")
>>>>
>>>>
>>>>A.K.
>>>>
>>>>
>>>>
>>>>
>>>>----- Original Message -----
>>>>From: Rui Barradas <ruipbarradas at sapo.pt>
>>>>To: Elaine Kuo <elaine.kuo.tw at gmail.com>
>>>>Cc: "r-help at r-project.org" <r-help at r-project.org>
>>>>Sent: Friday, September 27, 2013 7:39 AM
>>>>Subject: Re: [R] Compare species presence and absence between sites
>>>>
>>>>Hello,
>>>>
>>>>Something like this?
>>>>
>>>>
>>>>different <- function(x, y) x == 1 & y == 0
>>>>
>>>>set.seed(7054)
>>>>mat <- matrix(sample(0:1, 500, TRUE), nrow = 5)
>>>>rownames(mat) <- LETTERS[1:5]
>>>>colnames(mat) <- sprintf("D%03d", 1:100)
>>>>
>>>>different(mat["B",], mat["E",])
>>>>
>>>>
>>>>
>>>>Hope this helps,
>>>>
>>>>Rui Barradas
>>>>
>>>>Em 27-09-2013 11:48, Elaine Kuo escreveu:
>>>>> Dear List,
>>>>>
>>>>>
>>>>>
>>>>> I want to compare the presence and absence of bird species based on the
>>>>> sites in a matrix.
>>>>>
>>>>> The matrix has 5 rows for Island A, B, C, D, and E.
>>>>>
>>>>> It has 100 columns for bird species D001-D100.
>>>>>
>>>>> In each cell of the matrix,
>>>>>
>>>>> the presence-absence of bird species will be recorded as 1 or 0.
>>>>>
>>>>> (For example, if species D001 is found on Island D,
>>>>>
>>>>> the matrix cell of species D001 and Island D will be 1.)
>>>>>
>>>>>
>>>>>
>>>>> Now I want to know the different bird species between Island B and E.
>>>>>
>>>>> In other words, I would like to find out bird species present (1) on Island
>>>>> B but absent (0)on island E, and vice versa (absent (0) on Island B but
>>>>> present (1)on island E).
>>>>>
>>>>>
>>>>>
>>>>> Please kindly advise how to code the purpose above.
>>>>>
>>>>> Thank you in advance.
>>>>>
>>>>>
>>>>>
>>>>> Elaine
>>>>>
>>>>> ??? [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>______________________________________________
>>>>R-help at r-project.org mailing list
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>
>>
>


From ejoffe at hotmail.com  Sat Sep 28 17:14:58 2013
From: ejoffe at hotmail.com (E Joffe)
Date: Sat, 28 Sep 2013 17:14:58 +0200
Subject: [R] What is a "good fit"  Brier score and Harrel's C Index
Message-ID: <DUB114-DS43E3584350FBF616E9FC67CA2A0@phx.gbl>


Hi all, 

I am evaluating survival models using Brier score ("peperr") and Harrel's
C-Index ("Hmisc").
I am wondering:

1. What would be considered a "good fit" according to these scores (like the
heuristic levels we have for R square in linear regressions) ?

2. Are there any papers to cite on the matter (I couldn't find any) ?

3. Is there any paper to cite that discusses the limitation of using
traditional reporting for model fit in survival analysis as opposed to these
measures  ?

Thanks,
Erel


From dwinsemius at comcast.net  Sat Sep 28 16:40:49 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 28 Sep 2013 07:40:49 -0700
Subject: [R] Interperting results of glmnet and coxph plot,
	Brier score and Harrel's C-Index - am I doing something wrong ???
In-Reply-To: <DUB114-DS8BCB78F26CC24B7DF2E17CA2A0@phx.gbl>
References: <DUB114-DS8BCB78F26CC24B7DF2E17CA2A0@phx.gbl>
Message-ID: <36473A82-B759-4D34-A960-842FA41D2BC3@comcast.net>


On Sep 28, 2013, at 2:39 AM, E Joffe wrote:

> Hi all,
>
> I am using COX LASSO (glmnet / coxnet) regression to analyze a  
> dataset of
> 394 obs. / 268 vars.
> I use the following procedure:
> 1.	Construct a coxnet on the entire dataset (by cv.glmnet)
> 2.	Pick the significant features by selecting the non-zero coefficient
> under the best lambda selected by the model
> 3.	Build a coxph model with bi-directional stepwise feature selection
> limited to the coxnet selected features.

I was a bit puzzled by the third step. Once you had a reduced model  
from glmnet, what was the statistical basis for further elimination of  
variables?

(Quite apart from the statistical issues, I was rather surprised that  
this procedure even produced results since the 'step' function is not  
described in the 'stats' package as applying to 'coxph' model objects.)

> 	
> To validate the model I use both Brier score (library=peperr) and  
> Harrel's [Harrell]
> C-Index (library=Hmisc) with a bootstrap of 50 iterations.
>
>
> MY QUESTION :  I am getting fairly good C-Index (0.76) and Brier  
> (0.07)
> values for the models however per the coxnet the %Dev explained by  
> the model
> is at best 0.27 and when I plot the survfit of the coxph the plotted
> confidence interval is very large.

How many events did you have?  (The width of CI's is most importantly  
dependent on event counts and not particularly improved by a high case  
count. The power considerations are very similar to those of a  
binomial test.)


> What am I missing here ?

Perhaps sufficient events? (You also seem to be missing a description  
of the study goals.)


-- 
David.

>
> %DEV=27%
>
>
>
> Brier score - 0.07  ($ipec.coxglmnet -> [1] 7.24)
> C-Index - 0.76 ($cIndex -> [1] 0.763)
>
>
>
> DATA: [Private Health Information - can't publish] 394 obs./268 vars.
>
> CODE (need to define a dataset with 'time' and 'status' variables):
>
> library("survival")
> library ("glmnet")
> library ("c060")
> library ("peperr")
> library ("Hmisc")
>
>    #creat Y (survival matrix) for glmnet
>    surv_obj <- Surv(dataset$time,dataset$status)
>
>
>    ## tranform categorical variables into binary variables with  
> dummy for
> dataset
>    predict_matrix <- model.matrix(~ ., data=dataset,
>                                   contrasts.arg = lapply
> (dataset[,sapply(dataset, is.factor)], contrasts))
>
>    ## remove the statu/time variables from the predictor matrix (x)  
> for
> glmnet
>    predict_matrix <- subset (predict_matrix, select=c(-time,-status))
>
>    ## create a glmnet cox object using lasso regularization and cross
> validation
>    glmnet.cv <- cv.glmnet (predict_matrix, surv_obj, family="cox")
>
>    ## get the glmnet model on the full dataset
>    glmnet.obj <- glmnet.cv$glmnet.fit
>
>    # find lambda index for the models with least partial likelihood
> deviance (by cv.glmnet)
>    optimal.lambda <- glmnet.cv$lambda.min    # For a more parsimoneous
> model use lambda.1se
>    lambda.index <- which(glmnet.obj$lambda==optimal.lambda)
>
>
>    # take beta for optimal lambda
>    optimal.beta  <- glmnet.obj$beta[,lambda.index]
>
>    # find non zero beta coef
>    nonzero.coef <- abs(optimal.beta)>0
>    selectedBeta <- optimal.beta[nonzero.coef]
>
>    # take only covariates for which beta is not zero
>    selectedVar   <- predict_matrix[,nonzero.coef]
>
>    # create a dataframe for trainSet with time, status and selected
> variables in binary representation for evaluation in pec
>    reformat_dataSet <- as.data.frame(cbind(surv_obj,selectedVar))
>
>    # glmnet.cox only with meaningful features selected by stepwise
> bidirectional AIC feature selection
>    glmnet.cox.meaningful <- step(coxph(Surv(time,status) ~
> .,data=reformat_dataSet),direction="both")
>
>
>
>
> ##--------------------------------------------------------------------------
> -----------------------------
>    ##                                    MODEL PERFORMANCE
>
> ##--------------------------------------------------------------------------
> -----------------------------
>    ##
>
>
>    ## Calculate the Brier score - pec does its own bootstrap so this
> function runs on i=51 (i.e., whole trainset)
>
>        ## Brier score calculation to cox-glmnet
>        peperr.coxglmnet <- peperr(response=surv_obj, x=selectedVarCox,
>                                fit.fun=fit.coxph, load.all=TRUE,
>                                 
> indices=resample.indices(n=nrow(surv_obj),
> method="boot", sample.n=50))
>
>        # Get error predictions from peperr
>        prederr.coxglmnet <- perr(peperr.coxglmnet)
>
>        # Integrated prediction error Brier score calculation
>        ipec.coxglmnet<-ipec(prederr.coxglmnet,
> eval.times=peperr.coxglmnet$attribute, response=surv_obj)
>
>
>  ## C-Index calculation 50 iter bootstrapping
>
>  for (i in 1:50){
>        print (paste("Iteration:",i))
>        train <- sample(1:nrow(dataset), nrow(dataset), replace =  
> TRUE) ##
> random sampling with replacement
>        # create a dataframe for trainSet with time, status and  
> selected
> variables in binary representation for evaluation in pec
>        reformat_trainSet <- reformat_dataSet [train,]
>
>
>        # glmnet.cox only with meaningful features selected by stepwise
> bidirectional AIC feature selection
>        glmnet.cox.meaningful.test <- step(coxph(Surv(time,status) ~
> .,data=reformat_dataSet),direction="both")
>
>        selectedVarCox   <-
> predict_matrix[,attr(glmnet.cox.meaningful.test$terms,"term.labels")]
>        reformat_testSet <-  
> as.data.frame(cbind(surv_obj,selectedVarCox))
>        reformat_testSet <- reformat_dataSet [-train,]
>
>
> #     compute c-index (Harrell's) for cox-glmnet models
>        if (is.null(glmnet.cox.meaningful)){
>          cIndexCoxglmnet <- c(cIndexCoxglmnet,NULL)
>        }else{
>          cIndexCoxglmnet <- c(cIndexCoxglmnet,
> 1-rcorr.cens(predict(glmnet.cox.meaningful,
> reformat_testSet),Surv(reformat_testSet$time,reformat_testSet 
> $status))[1])
>        }
>  }
>
>  #Get average C-Index
>  cIndex<- mean (unlist(cIndexCoxglmnet),rm.na=TRUE)
>
>  #create a list of all the objects generated
>
> assign 
> (name,c(eval(parse(text=name)),glmnet.cv=list(glmnet.cv),glmnet.obj=li
> st(glmnet.obj),
>
> selectedVar=list(colnames(selectedVar)),glmnet.cox=list(glmnet.cox),
>
> glmnet 
> .cox.meaningful=list(glmnet.cox.meaningful),ipec.coxglmnet=list(ipec.c
> oxglmnet),
>                cIndex=cIndex))
>
>  # save image of the workspace after each iteration
>    save.image("final_subgroup_analysissubgroup_analysis.RData")
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From f.harrell at vanderbilt.edu  Sat Sep 28 16:48:38 2013
From: f.harrell at vanderbilt.edu (Frank Harrell)
Date: Sat, 28 Sep 2013 07:48:38 -0700 (PDT)
Subject: [R] Interperting results of glmnet and coxph plot,
 Brier score and Harrel's C-Index - am I doing something wrong ???
In-Reply-To: <36473A82-B759-4D34-A960-842FA41D2BC3@comcast.net>
References: <DUB114-DS8BCB78F26CC24B7DF2E17CA2A0@phx.gbl>
	<36473A82-B759-4D34-A960-842FA41D2BC3@comcast.net>
Message-ID: <1380379718878-4677175.post@n4.nabble.com>

This entire procedure is not valid.  You cannot use a penalized method for
selecting variables then use an unpenalized procedure on those selected.

Frank

David Winsemius wrote
> On Sep 28, 2013, at 2:39 AM, E Joffe wrote:
> 
>> Hi all,
>>
>> I am using COX LASSO (glmnet / coxnet) regression to analyze a  
>> dataset of
>> 394 obs. / 268 vars.
>> I use the following procedure:
>> 1.	Construct a coxnet on the entire dataset (by cv.glmnet)
>> 2.	Pick the significant features by selecting the non-zero coefficient
>> under the best lambda selected by the model
>> 3.	Build a coxph model with bi-directional stepwise feature selection
>> limited to the coxnet selected features.
> 
> I was a bit puzzled by the third step. Once you had a reduced model  
> from glmnet, what was the statistical basis for further elimination of  
> variables?
> 
> (Quite apart from the statistical issues, I was rather surprised that  
> this procedure even produced results since the 'step' function is not  
> described in the 'stats' package as applying to 'coxph' model objects.)
> 
>> 	
>> To validate the model I use both Brier score (library=peperr) and  
>> Harrel's [Harrell]
>> C-Index (library=Hmisc) with a bootstrap of 50 iterations.
>>
>>
>> MY QUESTION :  I am getting fairly good C-Index (0.76) and Brier  
>> (0.07)
>> values for the models however per the coxnet the %Dev explained by  
>> the model
>> is at best 0.27 and when I plot the survfit of the coxph the plotted
>> confidence interval is very large.
> 
> How many events did you have?  (The width of CI's is most importantly  
> dependent on event counts and not particularly improved by a high case  
> count. The power considerations are very similar to those of a  
> binomial test.)
> 
> 
>> What am I missing here ?
> 
> Perhaps sufficient events? (You also seem to be missing a description  
> of the study goals.)
> 
> 
> -- 
> David.
> 
>>
>> %DEV=27%
>>
>>
>>
>> Brier score - 0.07  ($ipec.coxglmnet -> [1] 7.24)
>> C-Index - 0.76 ($cIndex -> [1] 0.763)
>>
>>
>>
>> DATA: [Private Health Information - can't publish] 394 obs./268 vars.
>>
>> CODE (need to define a dataset with 'time' and 'status' variables):
>>
>> library("survival")
>> library ("glmnet")
>> library ("c060")
>> library ("peperr")
>> library ("Hmisc")
>>
>>    #creat Y (survival matrix) for glmnet
>>    surv_obj <- Surv(dataset$time,dataset$status)
>>
>>
>>    ## tranform categorical variables into binary variables with  
>> dummy for
>> dataset
>>    predict_matrix <- model.matrix(~ ., data=dataset,
>>                                   contrasts.arg = lapply
>> (dataset[,sapply(dataset, is.factor)], contrasts))
>>
>>    ## remove the statu/time variables from the predictor matrix (x)  
>> for
>> glmnet
>>    predict_matrix <- subset (predict_matrix, select=c(-time,-status))
>>
>>    ## create a glmnet cox object using lasso regularization and cross
>> validation
>>    glmnet.cv <- cv.glmnet (predict_matrix, surv_obj, family="cox")
>>
>>    ## get the glmnet model on the full dataset
>>    glmnet.obj <- glmnet.cv$glmnet.fit
>>
>>    # find lambda index for the models with least partial likelihood
>> deviance (by cv.glmnet)
>>    optimal.lambda <- glmnet.cv$lambda.min    # For a more parsimoneous
>> model use lambda.1se
>>    lambda.index <- which(glmnet.obj$lambda==optimal.lambda)
>>
>>
>>    # take beta for optimal lambda
>>    optimal.beta  <- glmnet.obj$beta[,lambda.index]
>>
>>    # find non zero beta coef
>>    nonzero.coef <- abs(optimal.beta)>0
>>    selectedBeta <- optimal.beta[nonzero.coef]
>>
>>    # take only covariates for which beta is not zero
>>    selectedVar   <- predict_matrix[,nonzero.coef]
>>
>>    # create a dataframe for trainSet with time, status and selected
>> variables in binary representation for evaluation in pec
>>    reformat_dataSet <- as.data.frame(cbind(surv_obj,selectedVar))
>>
>>    # glmnet.cox only with meaningful features selected by stepwise
>> bidirectional AIC feature selection
>>    glmnet.cox.meaningful <- step(coxph(Surv(time,status) ~
>> .,data=reformat_dataSet),direction="both")
>>
>>
>>
>>
>> ##--------------------------------------------------------------------------
>> -----------------------------
>>    ##                                    MODEL PERFORMANCE
>>
>> ##--------------------------------------------------------------------------
>> -----------------------------
>>    ##
>>
>>
>>    ## Calculate the Brier score - pec does its own bootstrap so this
>> function runs on i=51 (i.e., whole trainset)
>>
>>        ## Brier score calculation to cox-glmnet
>>        peperr.coxglmnet <- peperr(response=surv_obj, x=selectedVarCox,
>>                                fit.fun=fit.coxph, load.all=TRUE,
>>                                 
>> indices=resample.indices(n=nrow(surv_obj),
>> method="boot", sample.n=50))
>>
>>        # Get error predictions from peperr
>>        prederr.coxglmnet <- perr(peperr.coxglmnet)
>>
>>        # Integrated prediction error Brier score calculation
>>        ipec.coxglmnet<-ipec(prederr.coxglmnet,
>> eval.times=peperr.coxglmnet$attribute, response=surv_obj)
>>
>>
>>  ## C-Index calculation 50 iter bootstrapping
>>
>>  for (i in 1:50){
>>        print (paste("Iteration:",i))
>>        train <- sample(1:nrow(dataset), nrow(dataset), replace =  
>> TRUE) ##
>> random sampling with replacement
>>        # create a dataframe for trainSet with time, status and  
>> selected
>> variables in binary representation for evaluation in pec
>>        reformat_trainSet <- reformat_dataSet [train,]
>>
>>
>>        # glmnet.cox only with meaningful features selected by stepwise
>> bidirectional AIC feature selection
>>        glmnet.cox.meaningful.test <- step(coxph(Surv(time,status) ~
>> .,data=reformat_dataSet),direction="both")
>>
>>        selectedVarCox   <-
>> predict_matrix[,attr(glmnet.cox.meaningful.test$terms,"term.labels")]
>>        reformat_testSet <-  
>> as.data.frame(cbind(surv_obj,selectedVarCox))
>>        reformat_testSet <- reformat_dataSet [-train,]
>>
>>
>> #     compute c-index (Harrell's) for cox-glmnet models
>>        if (is.null(glmnet.cox.meaningful)){
>>          cIndexCoxglmnet <- c(cIndexCoxglmnet,NULL)
>>        }else{
>>          cIndexCoxglmnet <- c(cIndexCoxglmnet,
>> 1-rcorr.cens(predict(glmnet.cox.meaningful,
>> reformat_testSet),Surv(reformat_testSet$time,reformat_testSet 
>> $status))[1])
>>        }
>>  }
>>
>>  #Get average C-Index
>>  cIndex<- mean (unlist(cIndexCoxglmnet),rm.na=TRUE)
>>
>>  #create a list of all the objects generated
>>
>> assign 
>> (name,c(eval(parse(text=name)),glmnet.cv=list(glmnet.cv),glmnet.obj=li
>> st(glmnet.obj),
>>
>> selectedVar=list(colnames(selectedVar)),glmnet.cox=list(glmnet.cox),
>>
>> glmnet 
>> .cox.meaningful=list(glmnet.cox.meaningful),ipec.coxglmnet=list(ipec.c
>> oxglmnet),
>>                cIndex=cIndex))
>>
>>  # save image of the workspace after each iteration
>>    save.image("final_subgroup_analysissubgroup_analysis.RData")
>>
>>
>> ______________________________________________
>> 

> R-help@

>  mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius, MD
> Alameda, CA, USA
> 
> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.





-----
Frank Harrell
Department of Biostatistics, Vanderbilt University
--
View this message in context: http://r.789695.n4.nabble.com/Interperting-results-of-glmnet-and-coxph-plot-Brier-score-and-Harrel-s-C-Index-am-I-doing-something--tp4677166p4677175.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Sat Sep 28 17:04:19 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 28 Sep 2013 08:04:19 -0700
Subject: [R] What is a "good fit"  Brier score and Harrel's C Index
In-Reply-To: <DUB114-DS43E3584350FBF616E9FC67CA2A0@phx.gbl>
References: <DUB114-DS43E3584350FBF616E9FC67CA2A0@phx.gbl>
Message-ID: <B500B857-498F-496F-A95D-AAC3C7499534@comcast.net>


On Sep 28, 2013, at 8:14 AM, E Joffe wrote:

>
> Hi all,
>
> I am evaluating survival models using Brier score ("peperr") and  
> Harrel's
> C-Index ("Hmisc").

It's spelled 'Harrell'.

> I am wondering:
>
> 1. What would be considered a "good fit" according to these scores  
> (like the
> heuristic levels we have for R square in linear regressions) ?
>
> 2. Are there any papers to cite on the matter (I couldn't find any) ?

Frank Harrell's excellent text "Regression Modeling Strategies" has an  
extensive discussion of "goodness of fit" and the principles of model  
comparison. It's both too involved as well as off-topic for Rhelp. The  
other text to consult is Steyerberg's "Clinical Prediction Models".

>
> 3. Is there any paper to cite that discusses the limitation of using
> traditional reporting for model fit in survival analysis as opposed  
> to these
> measures  ?

I predict that the RMS bibliography would be an excellent place to  
start your search.

Despite getting his name attached to what he calls the 'c-index', I  
don't think one could call Frank Harrell a proponent of that measure  
or any of the "competitors". It's really just a dressed up/transformed  
AUC. The message I have taken from reading his book and listening to  
presentations is that one should apply biologic tests of sensibility  
as well as careful investigation of the functional relationships  
between candidate predictors and the outcomes of interest. He speaks  
very disparagingly about automatic procedures.

-- 

David Winsemius, MD
Alameda, CA, USA


From canamika at gmail.com  Sat Sep 28 17:13:04 2013
From: canamika at gmail.com (Anamika Chaudhuri)
Date: Sat, 28 Sep 2013 11:13:04 -0400
Subject: [R] Help with automation of WinBUGS from R
Message-ID: <CALv--dZiG1OhgSUQ344Lb7Hv0C4okkrxfVX1wCF0Ze7JwsSMuw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130928/acbef444/attachment.pl>

From ligges at statistik.tu-dortmund.de  Sat Sep 28 19:15:22 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 28 Sep 2013 19:15:22 +0200
Subject: [R] makeCluster help needed
In-Reply-To: <CALbUM4MVAXRUGn0gJ8ziRe+HjDC0aRRPE1R9UE4OLnAkVSoDdQ@mail.gmail.com>
References: <CALbUM4MVAXRUGn0gJ8ziRe+HjDC0aRRPE1R9UE4OLnAkVSoDdQ@mail.gmail.com>
Message-ID: <52470EAA.7090003@statistik.tu-dortmund.de>

Can you please upgrade R to R-3.0.2 and use the parallel package?
And can you please explain why you want to start the workers manually? 
I'd be happy to look into the details if you can reproduce the problem 
with a recent version of R and the parallel package.

Best,
Uwe Ligges





On 28.09.2013 03:20, Jeffrey Flint wrote:
> This is in regards to the SNOW library.
>
> I'm using Windows.  The problem is that makeSOCKcluster hangs in R as well
> as the DOS command line.  Below I've shown that it completes the Rscript
> until it reaches the line "slaveLoop(master)" , at which point it hangs.
>
> =============================
>
> In R:
>
>> cl <-
> makeSOCKcluster(names=c("localhost","localhost"),manual=T,outfile="jeff.log")
> Manually start worker on localhost with
>       C:/PROGRA~1/R/R-214~1.2/bin/Rscript.exe "C:/Program
> Files/R/R-2.14.2/library/snow/RSOCKnode.R" MASTER=localhost PORT=11590
> OUT=jeff.log SNOWLIB=C:/Program Files/R/R-2.14.2/library
> [HANGS]
> ================================
>
> On the DOS Command Line:
>
> C:\Documents and Settings\Jeff>C:/PROGRA~1/R/R-214~1.2/bin/Rscript.exe
> "C:/Program Files/R/R-2.14.2/library/snow/RSOCKno
> de.R" MASTER=localhost PORT=11590 OUT=jeff.log SNOWLIB=C:/Program
> Files/R/R-2.14.2/library
> [HANGS]
> ^C
> C:\Documents and Settings\Jeff>type jeff.log
> starting worker for localhost:11590
>
> ====================================
>
>
> In the file RSOCKnode.R, stalls after last line, after executing
> "slaveLoop(master)".
>
>
>
>
> local({
>      master <- "localhost"
>      port <- "8765"
>      snowlib <- Sys.getenv("R_SNOW_LIB")
>      outfile <- Sys.getenv("R_SNOW_OUTFILE")
>
>      args <- commandArgs()
>      pos <- match("--args", args)
>      args <- args[-(1 : pos)]
>      for (a in args) {
>          pos <- regexpr("=", a)
>          name <- substr(a, 1, pos - 1)
>          value <- substr(a,pos + 1, nchar(a))
>          switch(name,
>                 MASTER = master <- value,
>                 PORT = port <- value,
>                 SNOWLIB = snowlib <- value,
>                 OUT = outfile <- value,
>                 RANK = rank <- value,
>                 TMPWS = tmpWsName <- value)
>      }
>      ##**** these should be passed as arguments to makeNWSmaster
>      Sys.setenv(MASTER = master)
>      Sys.setenv(PORT = port)
>      Sys.setenv(RANK = rank)
>      Sys.setenv(TMPWS = tmpWsName)
>
>      if (! (snowlib %in% .libPaths()))
>          .libPaths(c(snowlib, .libPaths()))
>      library(methods) ## because Rscript as of R 2.7.0 doesn't load methods
>      library(nws)
>      library(snow)
>
>      sinkWorkerOutput(outfile)
>      master <- makeNWSmaster()
>      sendData(master, "ping")
>      cat("starting NWS worker\n")
>      slaveLoop(master)
> })
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jgrn at illinois.edu  Sat Sep 28 19:51:25 2013
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Sat, 28 Sep 2013 12:51:25 -0500
Subject: [R] Error: C stack usage is too close to the limit when using
	list.files()
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C34677F@PA-MBX01.na.tibco.com>
References: <CABG0rftp4J29ETAtx2phZS587CmKv7xDsgz=aM6Z74E+NOBf3w@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C346757@PA-MBX01.na.tibco.com>
	<E66794E69CFDE04D9A70842786030B931C34677F@PA-MBX01.na.tibco.com>
Message-ID: <CABG0rfuzFa6-6fEX5Ckmd_cGEyndeff7+2Ug5+BWJzVG8ewJiw@mail.gmail.com>

Thanks all -- ok, so the symbolic link issue is a distinct
possibility, but fundamentally doesn't solve the issue since most
users will have symbolic links on their machines SOMEPLACE, so a full
drive scan will run into these issues --  is list.files calling find,
or is it using a different algorithm?  This seems like a shortcoming
in the list.files algorithm -- is there a better solution (short of a
System call, which I'm still not sure will work on Macs without Xcode
-- a colleague of mine did NOT have Xcode, and reported not being able
to run find from the command line) -- perhaps a different package?

--j

On Fri, Sep 27, 2013 at 3:08 PM, William Dunlap <wdunlap at tibco.com> wrote:
> Toss a couple of extra files in there and you will see the output grow exponentially.
>
> % touch dir/IMPORTANT_1 dir/subdir/IMPORTANT_2
>
> and in R those two new files cause 82 more strings to appear in list.file's output:
>
>> nchar(list.files("dir", recursive=TRUE))
>  [1]  11  18  33  40  55  62  77  84  99 106 121 128 143 150 165 172 187 194 209
> [20] 216 231 238 253 260 275 282 297 304 319 326 341 348 363 370 385 392 407 414
> [39] 429 436 451 458 473 480 495 502 517 524 539 546 561 568 583 590 605 612 627
> [58] 634 649 656 671 678 693 700 715 722 737 744 759 766 781 788 803 810 825 832
> [77] 847 854 869 876 891 898 901
>
> 'find', by default, does not following symbolic links.
>
> % find dir
> dir
> dir/subdir
> dir/subdir/IMPORTANT_2
> dir/subdir/linkToUpperDir
> dir/IMPORTANT_1
>
> The -L option makes it follow them, but it won't follow loops:
>
> % find -L dir
> dir
> dir/subdir
> dir/subdir/IMPORTANT_2
> find: File system loop detected; `dir/subdir/linkToUpperDir' is part of the same file system loop as `dir'.
> dir/IMPORTANT_1
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
>> Of William Dunlap
>> Sent: Friday, September 27, 2013 12:56 PM
>> To: Jonathan Greenberg; r-help
>> Subject: Re: [R] Error: C stack usage is too close to the limit when using list.files()
>>
>> Do you have some symbolic links that make loops in your file system?
>> list.files() has problems with such loops and find does not.  E.g.,  on a Linux box:
>>
>> % cd /tmp
>> % mkdir dir dir/subdir
>> % cd dir/subdir
>> % ln -s ../../dir linkToUpperDir
>> % cd /tmp
>> % R --quiet
>> > list.files("dir", recursive=TRUE, full=TRUE)
>> [1]
>> "dir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToU
>> pperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkT
>> oUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/li
>> nkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdi
>> r/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/su
>> bdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir
>> /subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpper
>> Dir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUp
>> perDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkTo
>> UpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/lin
>> kToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir"
>> > system("find dir")
>> dir
>> dir/subdir
>> dir/subdir/linkToUpperDir
>>
>> Bill Dunlap
>> Spotfire, TIBCO Software
>> wdunlap tibco.com
>>
>>
>> > -----Original Message-----
>> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
>> > Of Jonathan Greenberg
>> > Sent: Friday, September 27, 2013 12:13 PM
>> > To: r-help
>> > Subject: [R] Error: C stack usage is too close to the limit when using list.files()
>> >
>> > R-helpers:
>> >
>> > I'm running a file search on my entire drive (Mac OS X) using:
>> >
>> > files_found <- list.files(dir="/",pattern=somepattern,recursive=TRUE,full.names=TRUE)
>> > where somepattern is a search pattern (which I have confirmed via a
>> > unix "find / -name somepattern" only returns ~ 3 results).
>> >
>> > I keep getting an error:
>> >
>> > Error: C stack usage is too close to the limit
>> >
>> > when running this command.  Any ideas on 1) how to fix this or 2) if
>> > there is an alternative to using list.files() to accomplish this
>> > search without resorting to an external package?
>> >
>> > Cheers!
>> >
>> > --jonathan
>> >
>> >
>> > --
>> > Jonathan A. Greenberg, PhD
>> > Assistant Professor
>> > Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
>> > Department of Geography and Geographic Information Science
>> > University of Illinois at Urbana-Champaign
>> > 259 Computing Applications Building, MC-150
>> > 605 East Springfield Avenue
>> > Champaign, IL  61820-6371
>> > Phone: 217-300-1924
>> > http://www.geog.illinois.edu/~jgrn/
>> > AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
259 Computing Applications Building, MC-150
605 East Springfield Avenue
Champaign, IL  61820-6371
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From bhh at xs4all.nl  Sat Sep 28 20:40:48 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sat, 28 Sep 2013 20:40:48 +0200
Subject: [R] Error: C stack usage is too close to the limit when using
	list.files()
In-Reply-To: <CABG0rfuzFa6-6fEX5Ckmd_cGEyndeff7+2Ug5+BWJzVG8ewJiw@mail.gmail.com>
References: <CABG0rftp4J29ETAtx2phZS587CmKv7xDsgz=aM6Z74E+NOBf3w@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C346757@PA-MBX01.na.tibco.com>
	<E66794E69CFDE04D9A70842786030B931C34677F@PA-MBX01.na.tibco.com>
	<CABG0rfuzFa6-6fEX5Ckmd_cGEyndeff7+2Ug5+BWJzVG8ewJiw@mail.gmail.com>
Message-ID: <7E2B9613-0DE0-4531-AF38-125D267EE092@xs4all.nl>


On 28-09-2013, at 19:51, Jonathan Greenberg <jgrn at illinois.edu> wrote:

> Thanks all -- ok, so the symbolic link issue is a distinct
> possibility, but fundamentally doesn't solve the issue since most
> users will have symbolic links on their machines SOMEPLACE, so a full
> drive scan will run into these issues --  is list.files calling find,
> or is it using a different algorithm?  This seems like a shortcoming
> in the list.files algorithm -- is there a better solution (short of a
> System call, which I'm still not sure will work on Macs without Xcode
> -- a colleague of mine did NOT have Xcode, and reported not being able
> to run find from the command line) -- perhaps a different package?
> 

Since Mac OS X Tiger at least  there is a find utility.
By doing a search here http://www.opensource.apple.com you can see that there is a find utility since 10.0
(to be found here http://www.opensource.apple.com/source/shell_cmds/shell_cmds-17.1/ ).
 
There must be something wrong with your colleague's setup.

Berend


From rafael.7 at poczta.fm  Sat Sep 28 17:18:12 2013
From: rafael.7 at poczta.fm (rafael.7 at poczta.fm)
Date: Sat, 28 Sep 2013 17:18:12 +0200
Subject: [R] Strange result from single [] extract operator
Message-ID: <ecilsjagsiqisxtnlwdb@qfbe>

Hi All,

I am using Rx64 3.0.1 on Windows 7 x64, and wanted to get two last rows from dataset. First, I tried
 library(datasets)
> data<-airquality
> data[nrow(data)-1:nrow(data),]

and received 152 rows sorted desc. Could you explain why it worked this way? I changed the extract line to:
data[(nrow(data)-1):nrow(data),]

and then I received what I wanted but still am curious about the performance of my previous code.

Yours faithfully,
Rafa? 


From srinivas.sridhara at gmail.com  Sat Sep 28 17:18:33 2013
From: srinivas.sridhara at gmail.com (Srinivas Sridhara)
Date: Sat, 28 Sep 2013 11:18:33 -0400
Subject: [R] Help about a R command
Message-ID: <CABMjXGent1MyvyR0VhWRqKb22BOVW9btjx1d=4k9CM_KepW8fw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130928/8fd59c77/attachment.pl>

From leopoldocatania at gmail.com  Sat Sep 28 17:27:38 2013
From: leopoldocatania at gmail.com (Leopoldo Catania)
Date: Sat, 28 Sep 2013 17:27:38 +0200
Subject: [R] Help with simple as.POSIXlt or strptime
Message-ID: <CAA6B8QcYUCm1nSKnfNkEZEHD_tVETEAyiFn_CsS5Us7V-McpFg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130928/df69f2dd/attachment.pl>

From rtomek at outlook.com  Sat Sep 28 21:36:31 2013
From: rtomek at outlook.com (Tomek R)
Date: Sat, 28 Sep 2013 15:36:31 -0400
Subject: [R] Command line r
Message-ID: <BAY175-W1085BD329837B744D0F339D62A0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130928/bdd24bf7/attachment.pl>

From wdunlap at tibco.com  Sun Sep 29 02:02:36 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 29 Sep 2013 00:02:36 +0000
Subject: [R] Strange result from single [] extract operator
In-Reply-To: <ecilsjagsiqisxtnlwdb@qfbe>
References: <ecilsjagsiqisxtnlwdb@qfbe>
Message-ID: <E66794E69CFDE04D9A70842786030B931C3469C0@PA-MBX01.na.tibco.com>

> First, I tried
>  library(datasets)
> > data<-airquality
> > data[nrow(data)-1:nrow(data),]
> 
> and received 152 rows sorted desc. Could you explain why it worked this way? I changed
> the extract line to:
> data[(nrow(data)-1):nrow(data),]
> 
> and then I received what I wanted but still am curious about the performance of my
> previous code.

Back up a little and compare
    nrow(data)-1:nrow(data)
to
    (nrow(data)-1):nrow(data)
or compare
   3-1:3
to
   (3-1):3

Then look at the help file for "Syntax".

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of rafael.7 at poczta.fm
> Sent: Saturday, September 28, 2013 8:18 AM
> To: r-help at r-project.org
> Subject: [R] Strange result from single [] extract operator
> 
> Hi All,
> 
> I am using Rx64 3.0.1 on Windows 7 x64, and wanted to get two last rows from dataset.
> First, I tried
>  library(datasets)
> > data<-airquality
> > data[nrow(data)-1:nrow(data),]
> 
> and received 152 rows sorted desc. Could you explain why it worked this way? I changed
> the extract line to:
> data[(nrow(data)-1):nrow(data),]
> 
> and then I received what I wanted but still am curious about the performance of my
> previous code.
> 
> Yours faithfully,
> Rafa?
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From wdunlap at tibco.com  Sun Sep 29 02:06:27 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 29 Sep 2013 00:06:27 +0000
Subject: [R] Error: C stack usage is too close to the limit when using
 list.files()
In-Reply-To: <CABG0rfuzFa6-6fEX5Ckmd_cGEyndeff7+2Ug5+BWJzVG8ewJiw@mail.gmail.com>
References: <CABG0rftp4J29ETAtx2phZS587CmKv7xDsgz=aM6Z74E+NOBf3w@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C346757@PA-MBX01.na.tibco.com>
	<E66794E69CFDE04D9A70842786030B931C34677F@PA-MBX01.na.tibco.com>
	<CABG0rfuzFa6-6fEX5Ckmd_cGEyndeff7+2Ug5+BWJzVG8ewJiw@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C3469D5@PA-MBX01.na.tibco.com>

The issue is not symbolic links per se, but ones that form loops.
Note that you can detect such loops by running 'find -L ...' and 
looking for the error messages.  (find by default does not follow
any symbolic links, which can be a problem also.)

It is a shortcoming of the current version of list.files().

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: jgrn307 at gmail.com [mailto:jgrn307 at gmail.com] On Behalf Of Jonathan
> Greenberg
> Sent: Saturday, September 28, 2013 10:51 AM
> To: William Dunlap
> Cc: r-help
> Subject: Re: [R] Error: C stack usage is too close to the limit when using list.files()
> 
> Thanks all -- ok, so the symbolic link issue is a distinct
> possibility, but fundamentally doesn't solve the issue since most
> users will have symbolic links on their machines SOMEPLACE, so a full
> drive scan will run into these issues --  is list.files calling find,
> or is it using a different algorithm?  This seems like a shortcoming
> in the list.files algorithm -- is there a better solution (short of a
> System call, which I'm still not sure will work on Macs without Xcode
> -- a colleague of mine did NOT have Xcode, and reported not being able
> to run find from the command line) -- perhaps a different package?
> 
> --j
> 
> On Fri, Sep 27, 2013 at 3:08 PM, William Dunlap <wdunlap at tibco.com> wrote:
> > Toss a couple of extra files in there and you will see the output grow exponentially.
> >
> > % touch dir/IMPORTANT_1 dir/subdir/IMPORTANT_2
> >
> > and in R those two new files cause 82 more strings to appear in list.file's output:
> >
> >> nchar(list.files("dir", recursive=TRUE))
> >  [1]  11  18  33  40  55  62  77  84  99 106 121 128 143 150 165 172 187 194 209
> > [20] 216 231 238 253 260 275 282 297 304 319 326 341 348 363 370 385 392 407 414
> > [39] 429 436 451 458 473 480 495 502 517 524 539 546 561 568 583 590 605 612 627
> > [58] 634 649 656 671 678 693 700 715 722 737 744 759 766 781 788 803 810 825 832
> > [77] 847 854 869 876 891 898 901
> >
> > 'find', by default, does not following symbolic links.
> >
> > % find dir
> > dir
> > dir/subdir
> > dir/subdir/IMPORTANT_2
> > dir/subdir/linkToUpperDir
> > dir/IMPORTANT_1
> >
> > The -L option makes it follow them, but it won't follow loops:
> >
> > % find -L dir
> > dir
> > dir/subdir
> > dir/subdir/IMPORTANT_2
> > find: File system loop detected; `dir/subdir/linkToUpperDir' is part of the same file
> system loop as `dir'.
> > dir/IMPORTANT_1
> >
> > Bill Dunlap
> > Spotfire, TIBCO Software
> > wdunlap tibco.com
> >
> >
> >> -----Original Message-----
> >> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
> Behalf
> >> Of William Dunlap
> >> Sent: Friday, September 27, 2013 12:56 PM
> >> To: Jonathan Greenberg; r-help
> >> Subject: Re: [R] Error: C stack usage is too close to the limit when using list.files()
> >>
> >> Do you have some symbolic links that make loops in your file system?
> >> list.files() has problems with such loops and find does not.  E.g.,  on a Linux box:
> >>
> >> % cd /tmp
> >> % mkdir dir dir/subdir
> >> % cd dir/subdir
> >> % ln -s ../../dir linkToUpperDir
> >> % cd /tmp
> >> % R --quiet
> >> > list.files("dir", recursive=TRUE, full=TRUE)
> >> [1]
> >>
> "dir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToU
> >>
> pperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkT
> >>
> oUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/li
> >>
> nkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdi
> >>
> r/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/su
> >>
> bdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir
> >>
> /subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpper
> >>
> Dir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUp
> >>
> perDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkTo
> >>
> UpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir/subdir/lin
> >> kToUpperDir/subdir/linkToUpperDir/subdir/linkToUpperDir"
> >> > system("find dir")
> >> dir
> >> dir/subdir
> >> dir/subdir/linkToUpperDir
> >>
> >> Bill Dunlap
> >> Spotfire, TIBCO Software
> >> wdunlap tibco.com
> >>
> >>
> >> > -----Original Message-----
> >> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
> Behalf
> >> > Of Jonathan Greenberg
> >> > Sent: Friday, September 27, 2013 12:13 PM
> >> > To: r-help
> >> > Subject: [R] Error: C stack usage is too close to the limit when using list.files()
> >> >
> >> > R-helpers:
> >> >
> >> > I'm running a file search on my entire drive (Mac OS X) using:
> >> >
> >> > files_found <-
> list.files(dir="/",pattern=somepattern,recursive=TRUE,full.names=TRUE)
> >> > where somepattern is a search pattern (which I have confirmed via a
> >> > unix "find / -name somepattern" only returns ~ 3 results).
> >> >
> >> > I keep getting an error:
> >> >
> >> > Error: C stack usage is too close to the limit
> >> >
> >> > when running this command.  Any ideas on 1) how to fix this or 2) if
> >> > there is an alternative to using list.files() to accomplish this
> >> > search without resorting to an external package?
> >> >
> >> > Cheers!
> >> >
> >> > --jonathan
> >> >
> >> >
> >> > --
> >> > Jonathan A. Greenberg, PhD
> >> > Assistant Professor
> >> > Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
> >> > Department of Geography and Geographic Information Science
> >> > University of Illinois at Urbana-Champaign
> >> > 259 Computing Applications Building, MC-150
> >> > 605 East Springfield Avenue
> >> > Champaign, IL  61820-6371
> >> > Phone: 217-300-1924
> >> > http://www.geog.illinois.edu/~jgrn/
> >> > AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> --
> Jonathan A. Greenberg, PhD
> Assistant Professor
> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
> Department of Geography and Geographic Information Science
> University of Illinois at Urbana-Champaign
> 259 Computing Applications Building, MC-150
> 605 East Springfield Avenue
> Champaign, IL  61820-6371
> Phone: 217-300-1924
> http://www.geog.illinois.edu/~jgrn/
> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From murdoch.duncan at gmail.com  Sun Sep 29 02:45:21 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 28 Sep 2013 20:45:21 -0400
Subject: [R] Help about a R command
In-Reply-To: <CABMjXGent1MyvyR0VhWRqKb22BOVW9btjx1d=4k9CM_KepW8fw@mail.gmail.com>
References: <CABMjXGent1MyvyR0VhWRqKb22BOVW9btjx1d=4k9CM_KepW8fw@mail.gmail.com>
Message-ID: <52477821.1040701@gmail.com>

On 13-09-28 11:18 AM, Srinivas Sridhara wrote:
> Hi,
>
> I was trying to get an answer to this issue:
>
> bookRatingData <- read.table(file.choose(),header=TRUE,nrows=1048570)
>
> Warning message:
> In read.table(file.choose(), header = TRUE, nrows = 1048570) :
>    incomplete final line found by readTableHeader on
> 'C:\Users\srinivas\Downloads\BX-Book-Ratings (2).xlsx'
>
>
>
> I tried opening the data file (BX-Book-Ratings (2).xlsx) and added a new
> line and then saved it. However, that didn't fix the incomplete final line
> issue. I still have the same problem. Any suggestions?

That's just a warning.  It says that the last line in your file doesn't 
have a line ending (LF, or CR/LF).  On Unix that often signals a 
problem.  On Windows it's pretty common.

Duncan Murdoch

>
> Thanks,
> Srinivas
>


From jim at bitwrit.com.au  Sun Sep 29 04:12:28 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sun, 29 Sep 2013 12:12:28 +1000
Subject: [R] Help with simple as.POSIXlt or strptime
In-Reply-To: <CAA6B8QcYUCm1nSKnfNkEZEHD_tVETEAyiFn_CsS5Us7V-McpFg@mail.gmail.com>
References: <CAA6B8QcYUCm1nSKnfNkEZEHD_tVETEAyiFn_CsS5Us7V-McpFg@mail.gmail.com>
Message-ID: <52478C8C.6050505@bitwrit.com.au>

On 09/29/2013 01:27 AM, Leopoldo Catania wrote:
> Hi,
> I really don't know what is wrong with my code, I have a character object
> and I need to have a POSIXlt object; my code is:
>> date="Mon, 23 Sep 2013 06:45:05 GMT"
>> as.POSIXlt(date,format="%a, %d %b %Y %H:%M:%S %Z")
> [1] NA
> even with
>> strptime(date,"%a, %d %b %Y %H:%M:%S %Z")
> [1] NA
> Also if I remove "Mon," and "GMT"
>> date2="23 Sep 2013 06:45:05"
>> as.POSIXlt(date2,format="%d %b %Y %H:%M:%S")
> [1] NA
>> strptime(date2,format="%d %b %Y %H:%M:%S")
> [1] NA
> If I try to run the last code line in ?strptime the result is:
> ## An RFC 822 header (Eastern Canada, during DST)
> strptime("Tue, 23 Mar 2010 14:36:38 -0400",  "%a, %d %b %Y %H:%M:%S %z")
> [1] NA
>
Hi Leopoldo,
The %Z is only included in the format string for output. Try these:

strptime(date,"%a, %d %b %Y %H:%M:%S")
[1] "2013-09-23 06:45:05"
strptime(date,"%a, %d %b %Y %H:%M:%S",tz="GMT")
[1] "2013-09-23 06:45:05 GMT"

Jim


From pburns at pburns.seanet.com  Sun Sep 29 10:47:09 2013
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Sun, 29 Sep 2013 09:47:09 +0100
Subject: [R] Strange result from single [] extract operator
In-Reply-To: <ecilsjagsiqisxtnlwdb@qfbe>
References: <ecilsjagsiqisxtnlwdb@qfbe>
Message-ID: <5247E90D.90901@pburns.seanet.com>

See Circle 8.1.3 of 'The R Inferno'.

http://www.burns-stat.com/documents/books/the-r-inferno/

Pat

On 28/09/2013 16:18, rafael.7 at poczta.fm wrote:
> Hi All,
>
> I am using Rx64 3.0.1 on Windows 7 x64, and wanted to get two last rows from dataset. First, I tried
>   library(datasets)
>> data<-airquality
>> data[nrow(data)-1:nrow(data),]
>
> and received 152 rows sorted desc. Could you explain why it worked this way? I changed the extract line to:
> data[(nrow(data)-1):nrow(data),]
>
> and then I received what I wanted but still am curious about the performance of my previous code.
>
> Yours faithfully,
> Rafa?
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @burnsstat @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of:
  'Impatient R'
  'The R Inferno'
  'Tao Te Programming')


From guy.wachsmann at duke.edu  Sun Sep 29 02:06:42 2013
From: guy.wachsmann at duke.edu (Guy Wachsman)
Date: Sun, 29 Sep 2013 00:06:42 +0000
Subject: [R] Error for atomic vectors and integers issue
Message-ID: <A90A0274487D124AB11C77E82ACD449602FBCCEF@ex-mbg-04.win.duke.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130929/e756d7ed/attachment.pl>

From ripley at stats.ox.ac.uk  Sun Sep 29 11:43:48 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 29 Sep 2013 10:43:48 +0100
Subject: [R] Error for atomic vectors and integers issue
In-Reply-To: <A90A0274487D124AB11C77E82ACD449602FBCCEF@ex-mbg-04.win.duke.edu>
References: <A90A0274487D124AB11C77E82ACD449602FBCCEF@ex-mbg-04.win.duke.edu>
Message-ID: <5247F654.6030807@stats.ox.ac.uk>

Please do read the help for cbind().  'iris' is a data frame, and you 
created a matrix.  Most likely you intended

iris.bind <- data.frame(x = iris.sub.pca$x, Species = iris$Species)


On 29/09/2013 01:06, Guy Wachsman wrote:
> Hi all,
>
> I was doing a PCA o the iris data set but when trying to rbind the "Species" column back from the original data set, it turned into 1:3 integers instead of the original ones. I noticed that the original names of the species are of type "integer", but I don't understand why, and how to put them back with the name. That might be important if you have more than 3 species. Then when I plotted I got an error message, here are the codes:
>
> works, but the species name has changed into 1,2,3:
>
> clrs <- c('red','green','blue')
> iris.sub=subset(iris, select=-Species)
> iris.sub.pca <- prcomp(iris.sub, center=T, retx=T)
> iris.bind=cbind(iris.sub.pca$x, iris$Species)
> plot(data=iris.bind, PC2~PC1, asp=1, pch=16, xlab='PC1',
> ylab='PC2',xlim=c(-5,5),ylim=c(-5,5), col = clrs[iris$Species] )
>
> If I plot like this:
>
> plot(iris.bind$x[,1], iris.bind$x[,2],asp=1,pch=16, xlab='PC1', ylab='PC2',xlim=c
>       (-5,5),ylim=c(-5,5), col = clrs[iris$Species] )
>
> I get this error message
>
> Error in iris.bind$x : $ operator is invalid for atomic vectors
>
> Thanks a lot,
> Guy
>
>
>
>
>
>
>
> --
> Guy Wachsman
> Benfey lab, FFSC #4131, Duke
> 130 Science Drive
> 27708, Durham, NC
> email: gw57 at duke.edu
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pdalgd at gmail.com  Sun Sep 29 11:51:38 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 29 Sep 2013 11:51:38 +0200
Subject: [R] Error for atomic vectors and integers issue
In-Reply-To: <A90A0274487D124AB11C77E82ACD449602FBCCEF@ex-mbg-04.win.duke.edu>
References: <A90A0274487D124AB11C77E82ACD449602FBCCEF@ex-mbg-04.win.duke.edu>
Message-ID: <5D7B8BED-57AB-4FED-A6F5-937B214C8D4F@gmail.com>


On Sep 29, 2013, at 02:06 , Guy Wachsman wrote:

> Hi all,
> 
> I was doing a PCA o the iris data set but when trying to rbind the "Species" column back from the original data set, it turned into 1:3 integers instead of the original ones. I noticed that the original names of the species are of type "integer", but I don't understand why, and how to put them back with the name. That might be important if you have more than 3 species. Then when I plotted I got an error message, here are the codes:
> 
> works, but the species name has changed into 1,2,3:
> 
> clrs <- c('red','green','blue')
> iris.sub=subset(iris, select=-Species)
> iris.sub.pca <- prcomp(iris.sub, center=T, retx=T)
> iris.bind=cbind(iris.sub.pca$x, iris$Species)
> plot(data=iris.bind, PC2~PC1, asp=1, pch=16, xlab='PC1',
> ylab='PC2',xlim=c(-5,5),ylim=c(-5,5), col = clrs[iris$Species] )
> 
> If I plot like this:
> 
> plot(iris.bind$x[,1], iris.bind$x[,2],asp=1,pch=16, xlab='PC1', ylab='PC2',xlim=c
>     (-5,5),ylim=c(-5,5), col = clrs[iris$Species] )
> 
> I get this error message
> 
> Error in iris.bind$x : $ operator is invalid for atomic vectors

So iris.bind does not accept $-operations. Apparently, you think it is a data frame, but try str(iris.bind) and see what it really is (a matrix, I'd expect). You might want to try

iris.bind <- data.frame(iris.sub.pca$x, iris$Species)

or maybe

iris.bind <- data.frame(I(iris.sub.pca$x), iris$Species)

Again, check with str() to see what data structure is produced, which names, etc.


> Thanks a lot,
> Guy
> 
> 
> 
> 
> 
> 
> 
> --
> Guy Wachsman
> Benfey lab, FFSC #4131, Duke
> 130 Science Drive
> 27708, Durham, NC
> email: gw57 at duke.edu
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From brucepetrovics at gmail.com  Sun Sep 29 04:46:04 2013
From: brucepetrovics at gmail.com (Bruce Petrovics)
Date: Sat, 28 Sep 2013 20:46:04 -0600
Subject: [R] How to avoid "$ operator is invalid for atomic vectors" Thu Nov
 6 19:04:49 CET 2008
Message-ID: <CA+CTnc0cf=QviwF_ka_+avX01bxEaJOBX+CPwnjQjSvxEUZtzw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130928/e538622c/attachment.pl>

From wojdanrafal at gmail.com  Sun Sep 29 12:47:45 2013
From: wojdanrafal at gmail.com (=?ISO-8859-2?Q?Rafa=B3_Wojdan?=)
Date: Sun, 29 Sep 2013 12:47:45 +0200
Subject: [R] Strange result from single [] extract operator
In-Reply-To: <5247E90D.90901@pburns.seanet.com>
References: <ecilsjagsiqisxtnlwdb@qfbe>
	<5247E90D.90901@pburns.seanet.com>
Message-ID: <CAFAxAVDhzwZBexajTQDcHbfxp1XcUCSwj8qZGQMouKtPw8Ahww@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130929/b406d727/attachment.pl>

From chee.chen at yahoo.com  Sun Sep 29 19:22:24 2013
From: chee.chen at yahoo.com (Chee Chen)
Date: Sun, 29 Sep 2013 13:22:24 -0400
Subject: [R] Help: concurrent R sessions for different settings of
	simulations
Message-ID: <A129CB4655F04D2AB768BA83ECBB33DF@princeton.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130929/df09b710/attachment.pl>

From Ted.Harding at wlandres.net  Sun Sep 29 20:31:33 2013
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Sun, 29 Sep 2013 19:31:33 +0100 (BST)
Subject: [R] Help: concurrent R sessions for different settings of
	simulations
In-Reply-To: <A129CB4655F04D2AB768BA83ECBB33DF@princeton.edu>
Message-ID: <XFMail.20130929193133.Ted.Harding@wlandres.net>

[See at end]
On 29-Sep-2013 17:22:24 Chee Chen wrote:
> Dear All, 
> I have spent almost 2 days but did not succeed yet.
> 
> Problem description:  I have 3 parameters, p1, p2 and p3, for which
> p1 take 1 of 5 possible distributions (e.g., normal, laplace),
> p2 takes 1 of 3 possible distributions, and p3 takes 1 of 5 possible
> distribution. These 3 parameters create 75 settings, and these 3
> parameters are arguments of a function F; and F is part of simulation
> codes. To summarize: different value of the ordered triple (p1,p2,p3)
> means different setting and this is the only difference in the
> simulation codes. 
> 
> Target to achieve: instead of loop through each of the 75 settings
> one after another, I would like to concurrently run all 75 settings
> on the cluster.
> 
> My attempts: via loops, I used Perl to create 75 files, each for a
> different triple (p1,p2,p3), and Perl uses "system(R ..)" to execute
> this setting once it is created. The Perl codes are submitted to
> cluster correctly. But when I looked into the log file, the cluster
> still executes it one setting after another setting. 
> 
> Request: any help is appreciated!  It is because of the loops of Perl
> that executes a setting once it is created?
> 
> Have a nice day!
> Chee

Just a simple comment (which does not cionsider the technicalities
of using Perl, using a cluster, etc.).

>From your description, it looks as though the system waits for one
item in the loop to finish before it starts the next one.

If that is the case, and *if* you are using UNIX/Linux (or other
UNIX-like OS), then you could try appending " &" to each submitted
command. An outline exemplar:

  for( s in settings ){
    system("R <something depending on s> &")
  }

The " &" has the effect, in a UNIX command line, of detaching the
command from the executing program. So the program can continue to
run (and take as long as it likes) while the system command-shell
is immediately freed up for the next command.

Therefore, with the above exemplar, is there were say 75 settings,
then that loop would complete in a very short time, after which
you would have 75 copies of R executing simulations, and your
original R command-line would be available.

Just a suggestion (which may have missed the essential point of
your query, but worth a try ... ).

I have no idea how to achieve a similar effect in Windows ...

Ted.

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 29-Sep-2013  Time: 19:31:29
This message was sent by XFMail


From aanas at feps.edu.eg  Sun Sep 29 19:17:35 2013
From: aanas at feps.edu.eg (Aya Anas)
Date: Sun, 29 Sep 2013 20:17:35 +0300
Subject: [R] DEoptim inconsistent output
Message-ID: <CAB=y=yM-vF8pU6zBY77BhWpvL+VXyYkNHAT5bwmqof9x_g=imA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130929/4b92914f/attachment.pl>

From szehnder at uni-bonn.de  Sun Sep 29 20:47:55 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Sun, 29 Sep 2013 20:47:55 +0200
Subject: [R] DEoptim inconsistent output
In-Reply-To: <CAB=y=yM-vF8pU6zBY77BhWpvL+VXyYkNHAT5bwmqof9x_g=imA@mail.gmail.com>
References: <CAB=y=yM-vF8pU6zBY77BhWpvL+VXyYkNHAT5bwmqof9x_g=imA@mail.gmail.com>
Message-ID: <ED6DA22F-0672-43B8-8B59-7082A8ADAF9B@uni-bonn.de>

It's always a good thing to trace the optimization. There can be a lot of reasons:

Is the function correctly implemented?

Is it defined for all values? If not, is it defined for all values in the constrained parameter space? Is it defined for the constraint? If it is not defined for the constrained (e.g. for zero, take the lower bound to be 1e-10; approximately zero)

How do the numerical gradients behave? They rely on difference methods, could be undefined for some values. 

So, as long as we have no error messages or more precise information, we cannot help you.


Best

Simon

On Sep 29, 2013, at 7:17 PM, Aya Anas <aanas at feps.edu.eg> wrote:

> Dear all,
> 
> 
> 
> I wrote an R optimization code using the DEoptim package that is used to
> minimize a numerical integration subject to a single constraint. I noticed
> that the code takes a long time to give an output. The resulting output
> doesn't make sense at all. I got parameters that don't satisfy the
> constraint. In addition, when i substituted with the resulting parameters
> in the objective function, I didn't obtain the resulting optimal objective
> function value. What might be the reason behind this?
> 
> .
> 
> Thanks,
> 
> Aya
> 
> 
> -- 
> Best Regards
> 
> Faculty of Economics & Political Science
> Cairo University
> Tel:(202)35728055-(202)35728116-(202)35736608-(202)35736605
> Fax:(202)35711020
> Follow us on twitter:https://twitter.com/fepsnews
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hb at biostat.ucsf.edu  Sun Sep 29 20:51:22 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sun, 29 Sep 2013 11:51:22 -0700
Subject: [R] Help: concurrent R sessions for different settings of
	simulations
In-Reply-To: <A129CB4655F04D2AB768BA83ECBB33DF@princeton.edu>
References: <A129CB4655F04D2AB768BA83ECBB33DF@princeton.edu>
Message-ID: <CAFDcVCTev1dtgFyYLhXCPaAKiYmi+w+pC54YHe218ouPsQUPRw@mail.gmail.com>

I strongly suggest to use the BatchJobs package
[http://cran.r-project.org/web/packages/BatchJobs] for this.  It is
easy to install and cross platform and does not rely on external
software such as perl.  It allows you develop your script running
sequentially/interactively on your local machine/laptop, the via *a
single configuration file* (./.BatchJobs.R) you can use the exact same
script to distribute the jobs to separate R sessions either on
multiple cores on the same machine or on a cluster (most common
cluster types are supported).  The learning curve is not that step -
as with most parallel computations you have to move away from using
for loops to using lapply() and then you're almost done.

/Henrik

On Sun, Sep 29, 2013 at 10:22 AM, Chee Chen <chee.chen at yahoo.com> wrote:
> Dear All,
> I have spent almost 2 days but did not succeed yet.
>
> Problem description:  I have 3 parameters, p1, p2 and p3, for which p1 take 1 of 5 possible distributions (e.g., normal, laplace), p2 takes 1 of 3 possible distributions, and p3 takes 1 of 5 possible distribution. These 3 parameters create 75 settings, and these 3 parameters are arguments of a function F; and  F is part of simulation codes.  To summarize: different value of the ordered triple (p1,p2,p3) means different setting and this is the only difference in the simulation codes.
>
> Target to achieve: instead of loop through each of the 75 settings one after another, I would like to concurrently run all 75 settings on the cluster.
>
> My attempts: via loops, I used Perl to create 75 files, each for a different triple (p1,p2,p3), and Perl uses "system(R ..)" to execute this setting once it is created. The Perl codes are submitted to cluster correctly. But when I looked into the log file, the cluster still executes it one setting after another setting.
>
> Request: any help is appreciated!  It is because of the loops of Perl that executes a setting once it is created?
>
> Have a nice day!
> Chee
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mrwansweedan at yahoo.com  Sun Sep 29 20:57:51 2013
From: mrwansweedan at yahoo.com (Mrwan Sweedan)
Date: Sun, 29 Sep 2013 11:57:51 -0700 (PDT)
Subject: [R] explination
Message-ID: <1380481071.50344.YahooMailNeo@web125002.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130929/3882d328/attachment.pl>

From dwinsemius at comcast.net  Sun Sep 29 21:42:26 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 29 Sep 2013 12:42:26 -0700
Subject: [R] explination
In-Reply-To: <1380481071.50344.YahooMailNeo@web125002.mail.ne1.yahoo.com>
References: <1380481071.50344.YahooMailNeo@web125002.mail.ne1.yahoo.com>
Message-ID: <5360C8F6-0A6D-4093-89CA-730AC8B856B9@comcast.net>


On Sep 29, 2013, at 11:57 AM, Mrwan Sweedan wrote:

> Hi,
> i downloaded R version 2.15.0 (2012-03-30) Platform: i386-pc-mingw32/i386 (32-bit) + Deducer + R studio.

That appears to be someone's effort at bundling package and the RStudio IDE. RStudio has its own help forum.



> I am facing few problem :
> 1- I don't know where to find the manual you talked about so i can read it and get help from it.

Who is "you"? We are about 20,00 readers of R help and most of us do not have RStudio. The "manual" might be "The Introduction to R" (TITR) or it might be something else. On my R64.app GUI I just click on "R Help" item in the Help-menu and I get a browser page that has a variety of Manuals including TITR.

> 2- what is console and where I can find it to use it?

It's what you are looking at when R is running in interactive mode.

> 3- what is the directory? and where i can find it? the reason for that question is i downloaded the table that you gave on the assignment on my desktop under the name "test" but when i try to open it with R they way you did in the video by using read.table it gave me Error type like below: 
>> data<- read.table("test.txt")
> 
> Error in file(file, "rt") : cannot open the connection
> In addition: Warning message:
> In file(file, "rt") :
>   cannot open file 'test.txt': No such file or directory
> 
> i went to discussion board

Where?

> try to use it I couldn't because there is no "new post" button or any similar thing

This?

http://support.rstudio.org/


> 4- you talk about the material as if we know the orders all ready, i don't think every one know that , example i went to a friend he is an IT asking him about the orders how we printed he gave me different things that the one you use in videos and he does not have any ideas about what are you talking about. so is there any book i can be refered to have the orders and what it means.

I'm thinking there may be a language difficulty. I cannot figure out what is "orders" means in this context.

> by the way the navigation in the coarse is not easy at all. you need a video to explain where and how to use this website.
>     
> i spend the entire week looking for such things and i had to print the questions in google to find answers other wise i will miss the first quiz , plus i literally counted things manually in the assignment you gave. 
> 
> 
> MARWAN SWEEDAN 
> 369-B 3rd st., #528
> San Rafael, CA 94901
> (408)310-0096
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ruipbarradas at sapo.pt  Sun Sep 29 21:43:35 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 29 Sep 2013 20:43:35 +0100
Subject: [R] explination
In-Reply-To: <1380481071.50344.YahooMailNeo@web125002.mail.ne1.yahoo.com>
References: <1380481071.50344.YahooMailNeo@web125002.mail.ne1.yahoo.com>
Message-ID: <524882E7.2070205@sapo.pt>

Hello,

You've posted in the wrong mailing list.

1. You've downloaded R version 2.15.0 but the current version is 3.0.2. 
You should update to the current version.
2. As for the manual, in your directory of R, probably C:\PROGRA~1\R you 
will find a folder named 'doc\manual'. The manual you are looking for is 
the PDF file R-intro.pdf.

As for the other questions they should be asked to your teacher, not to 
R-Help. But the error message you got means R (RGui ?) cannot find the 
file test.txt is the current directory. To see the current directory and 
the files there, at the R prompt type

getwd()
list.files()  # all files
list.files(pattern = "*.txt")


If it's RGui that you are using, in the File menu, there's an option 
Change dir. Use it to navigate to the directory where test.txt is. 
(Assuming you have that file on disk, which I don't really believe you do.)

Hope this helps,

Rui Barradas

Em 29-09-2013 19:57, Mrwan Sweedan escreveu:
> Hi,
> i downloaded R version 2.15.0 (2012-03-30) Platform: i386-pc-mingw32/i386 (32-bit) + Deducer + R studio.
> I am facing few problem :
> 1- I don't know where to find the manual you talked about so i can read it and get help from it.
> 2- what is console and where I can find it to use it?
> 3- what is the directory? and where i can find it? the reason for that question is i downloaded the table that you gave on the assignment on my desktop under the name "test" but when i try to open it with R they way you did in the video by using read.table it gave me Error type like below:
>> data<- read.table("test.txt")
>
> Error in file(file, "rt") : cannot open the connection
> In addition: Warning message:
> In file(file, "rt") :
>    cannot open file 'test.txt': No such file or directory
>
> i went to discussion board try to use it I couldn't because there is no "new post" button or any similar thing
> 4- you talk about the material as if we know the orders all ready, i don't think every one know that , example i went to a friend he is an IT asking him about the orders how we printed he gave me different things that the one you use in videos and he does not have any ideas about what are you talking about. so is there any book i can be refered to have the orders and what it means.
> by the way the navigation in the coarse is not easy at all. you need a video to explain where and how to use this website.
>
> i spend the entire week looking for such things and i had to print the questions in google to find answers other wise i will miss the first quiz , plus i literally counted things manually in the assignment you gave.
>
>
> MARWAN SWEEDAN
> 369-B 3rd st., #528
> San Rafael, CA 94901
> (408)310-0096
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ruipbarradas at sapo.pt  Sun Sep 29 21:50:50 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 29 Sep 2013 20:50:50 +0100
Subject: [R] explination
In-Reply-To: <524882E7.2070205@sapo.pt>
References: <1380481071.50344.YahooMailNeo@web125002.mail.ne1.yahoo.com>
	<524882E7.2070205@sapo.pt>
Message-ID: <5248849A.2010305@sapo.pt>

Hello,

Sorry, after reading David's answer I realized you are using RStudio. 
Forget what I've said about RGui, then. Anyway, the manual should be the 
one I've mentioned.

Rui Barradas

Em 29-09-2013 20:43, Rui Barradas escreveu:
> Hello,
>
> You've posted in the wrong mailing list.
>
> 1. You've downloaded R version 2.15.0 but the current version is 3.0.2.
> You should update to the current version.
> 2. As for the manual, in your directory of R, probably C:\PROGRA~1\R you
> will find a folder named 'doc\manual'. The manual you are looking for is
> the PDF file R-intro.pdf.
>
> As for the other questions they should be asked to your teacher, not to
> R-Help. But the error message you got means R (RGui ?) cannot find the
> file test.txt is the current directory. To see the current directory and
> the files there, at the R prompt type
>
> getwd()
> list.files()  # all files
> list.files(pattern = "*.txt")
>
>
> If it's RGui that you are using, in the File menu, there's an option
> Change dir. Use it to navigate to the directory where test.txt is.
> (Assuming you have that file on disk, which I don't really believe you do.)
>
> Hope this helps,
>
> Rui Barradas
>
> Em 29-09-2013 19:57, Mrwan Sweedan escreveu:
>> Hi,
>> i downloaded R version 2.15.0 (2012-03-30) Platform:
>> i386-pc-mingw32/i386 (32-bit) + Deducer + R studio.
>> I am facing few problem :
>> 1- I don't know where to find the manual you talked about so i can
>> read it and get help from it.
>> 2- what is console and where I can find it to use it?
>> 3- what is the directory? and where i can find it? the reason for that
>> question is i downloaded the table that you gave on the assignment on
>> my desktop under the name "test" but when i try to open it with R they
>> way you did in the video by using read.table it gave me Error type
>> like below:
>>> data<- read.table("test.txt")
>>
>> Error in file(file, "rt") : cannot open the connection
>> In addition: Warning message:
>> In file(file, "rt") :
>>    cannot open file 'test.txt': No such file or directory
>>
>> i went to discussion board try to use it I couldn't because there is
>> no "new post" button or any similar thing
>> 4- you talk about the material as if we know the orders all ready, i
>> don't think every one know that , example i went to a friend he is an
>> IT asking him about the orders how we printed he gave me different
>> things that the one you use in videos and he does not have any ideas
>> about what are you talking about. so is there any book i can be
>> refered to have the orders and what it means.
>> by the way the navigation in the coarse is not easy at all. you need a
>> video to explain where and how to use this website.
>>
>> i spend the entire week looking for such things and i had to print the
>> questions in google to find answers other wise i will miss the first
>> quiz , plus i literally counted things manually in the assignment you
>> gave.
>>
>>
>> MARWAN SWEEDAN
>> 369-B 3rd st., #528
>> San Rafael, CA 94901
>> (408)310-0096
>>     [[alternative HTML version deleted]]
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ejoffe at hotmail.com  Sun Sep 29 22:57:40 2013
From: ejoffe at hotmail.com (E Joffe)
Date: Sun, 29 Sep 2013 22:57:40 +0200
Subject: [R] What is a "good fit"  Brier score and Harrel's C Index
In-Reply-To: <B500B857-498F-496F-A95D-AAC3C7499534@comcast.net>
References: <DUB114-DS43E3584350FBF616E9FC67CA2A0@phx.gbl>
	<B500B857-498F-496F-A95D-AAC3C7499534@comcast.net>
Message-ID: <DUB114-DS20D5AF6A8A1167883E6743CA2B0@phx.gbl>

Thank you so much for this answer.
Per your comment I have moved the discussion (including your answer) to
StackExchange
At
http://stats.stackexchange.com/questions/71417/what-is-a-good-fit-brier-scor
e-and-harrels-c-index 

Many thanks !
Erel

-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: Saturday, September 28, 2013 5:04 PM
To: E Joffe
Cc: r-help at r-project.org
Subject: Re: [R] What is a "good fit" Brier score and Harrel's C Index


On Sep 28, 2013, at 8:14 AM, E Joffe wrote:

>
> Hi all,
>
> I am evaluating survival models using Brier score ("peperr") and 
> Harrel's C-Index ("Hmisc").

It's spelled 'Harrell'.

> I am wondering:
>
> 1. What would be considered a "good fit" according to these scores 
> (like the heuristic levels we have for R square in linear regressions) 
> ?
>
> 2. Are there any papers to cite on the matter (I couldn't find any) ?

Frank Harrell's excellent text "Regression Modeling Strategies" has an
extensive discussion of "goodness of fit" and the principles of model
comparison. It's both too involved as well as off-topic for Rhelp. The other
text to consult is Steyerberg's "Clinical Prediction Models".

>
> 3. Is there any paper to cite that discusses the limitation of using 
> traditional reporting for model fit in survival analysis as opposed to 
> these measures  ?

I predict that the RMS bibliography would be an excellent place to start
your search.

Despite getting his name attached to what he calls the 'c-index', I don't
think one could call Frank Harrell a proponent of that measure or any of the
"competitors". It's really just a dressed up/transformed AUC. The message I
have taken from reading his book and listening to presentations is that one
should apply biologic tests of sensibility as well as careful investigation
of the functional relationships between candidate predictors and the
outcomes of interest. He speaks very disparagingly about automatic
procedures.

-- 

David Winsemius, MD
Alameda, CA, USA


From ejoffe at hotmail.com  Sun Sep 29 23:16:52 2013
From: ejoffe at hotmail.com (E Joffe)
Date: Sun, 29 Sep 2013 23:16:52 +0200
Subject: [R] Interperting results of glmnet and coxph plot,
	Brier score and Harrel's C-Index - am I doing something wrong ???
In-Reply-To: <36473A82-B759-4D34-A960-842FA41D2BC3@comcast.net>
References: <DUB114-DS8BCB78F26CC24B7DF2E17CA2A0@phx.gbl>
	<36473A82-B759-4D34-A960-842FA41D2BC3@comcast.net>
Message-ID: <DUB114-DS248291526BFF97A678A070CA2B0@phx.gbl>

HI,

Thank you for your answer.
There were 301 events out of 394 observations.

Study goals: Identify proteins with prognostic power in patients with AML.
There were 232 proteins studied.
Traditional models won't converge.
I wanted to do a multivariate survival analysis that would allow me to
identify prognostic proteins and get an estimation of their hazard ratio.
LASSO allowed me to model the data but in order to get the HRs I needed to
run it a second time throw coxph - this was done based on a discussion on
stackexchange
http://r.789695.n4.nabble.com/estimating-survival-times-with-glmnet-and-coxp
h-td4614225.html  which I tweaked a bit.


The features selected by LASSO are not necessarily all significant when
constructing a coxph model in particular due to the lack of penalization.
This was commented on by Dr. Hastie in one of his papers (or in the video
lecture he gave - I need to find the exact source).
I understand that by doing this procedure I might be reducing the accuracy
of the model which is why I used a bootstrap evaluation.
Interestingly, the coxph models following stepwise feature selection had
marginally better performance in the evaluation compared with the LASSO
models (maybe the LASSO over-fit the data a bit ? - don't know)

What I still don't understand is why with a C-Index of 0.76 and a Brier
score of 0.07 when I look at the plot of the coxph object the confidence
intervals are so far ?
Further, I am wondering whether there is a sanity check I could perform to
make sure there is no error in the Brier/C-Index evaluation.

Thanks again for all you advice on this project,
Erel



-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: Saturday, September 28, 2013 4:41 PM
To: E Joffe
Cc: r-help at r-project.org
Subject: Re: [R] Interperting results of glmnet and coxph plot, Brier score
and Harrel's C-Index - am I doing something wrong ???


On Sep 28, 2013, at 2:39 AM, E Joffe wrote:

> Hi all,
>
> I am using COX LASSO (glmnet / coxnet) regression to analyze a dataset 
> of
> 394 obs. / 268 vars.
> I use the following procedure:
> 1.	Construct a coxnet on the entire dataset (by cv.glmnet)
> 2.	Pick the significant features by selecting the non-zero coefficient
> under the best lambda selected by the model
> 3.	Build a coxph model with bi-directional stepwise feature selection
> limited to the coxnet selected features.

I was a bit puzzled by the third step. Once you had a reduced model from
glmnet, what was the statistical basis for further elimination of variables?

(Quite apart from the statistical issues, I was rather surprised that this
procedure even produced results since the 'step' function is not described
in the 'stats' package as applying to 'coxph' model objects.)

> 	
> To validate the model I use both Brier score (library=peperr) and  
> Harrel's [Harrell]
> C-Index (library=Hmisc) with a bootstrap of 50 iterations.
>
>
> MY QUESTION :  I am getting fairly good C-Index (0.76) and Brier  
> (0.07)
> values for the models however per the coxnet the %Dev explained by  
> the model
> is at best 0.27 and when I plot the survfit of the coxph the plotted
> confidence interval is very large.

How many events did you have?  (The width of CI's is most importantly  
dependent on event counts and not particularly improved by a high case  
count. The power considerations are very similar to those of a  
binomial test.)


> What am I missing here ?

Perhaps sufficient events? (You also seem to be missing a description  
of the study goals.)


-- 
David.

>
> %DEV=27%
>
>
>
> Brier score - 0.07  ($ipec.coxglmnet -> [1] 7.24)
> C-Index - 0.76 ($cIndex -> [1] 0.763)
>
>
>
> DATA: [Private Health Information - can't publish] 394 obs./268 vars.
>
> CODE (need to define a dataset with 'time' and 'status' variables):
>
> library("survival")
> library ("glmnet")
> library ("c060")
> library ("peperr")
> library ("Hmisc")
>
>    #creat Y (survival matrix) for glmnet
>    surv_obj <- Surv(dataset$time,dataset$status)
>
>
>    ## tranform categorical variables into binary variables with  
> dummy for
> dataset
>    predict_matrix <- model.matrix(~ ., data=dataset,
>                                   contrasts.arg = lapply
> (dataset[,sapply(dataset, is.factor)], contrasts))
>
>    ## remove the statu/time variables from the predictor matrix (x)  
> for
> glmnet
>    predict_matrix <- subset (predict_matrix, select=c(-time,-status))
>
>    ## create a glmnet cox object using lasso regularization and cross
> validation
>    glmnet.cv <- cv.glmnet (predict_matrix, surv_obj, family="cox")
>
>    ## get the glmnet model on the full dataset
>    glmnet.obj <- glmnet.cv$glmnet.fit
>
>    # find lambda index for the models with least partial likelihood
> deviance (by cv.glmnet)
>    optimal.lambda <- glmnet.cv$lambda.min    # For a more parsimoneous
> model use lambda.1se
>    lambda.index <- which(glmnet.obj$lambda==optimal.lambda)
>
>
>    # take beta for optimal lambda
>    optimal.beta  <- glmnet.obj$beta[,lambda.index]
>
>    # find non zero beta coef
>    nonzero.coef <- abs(optimal.beta)>0
>    selectedBeta <- optimal.beta[nonzero.coef]
>
>    # take only covariates for which beta is not zero
>    selectedVar   <- predict_matrix[,nonzero.coef]
>
>    # create a dataframe for trainSet with time, status and selected
> variables in binary representation for evaluation in pec
>    reformat_dataSet <- as.data.frame(cbind(surv_obj,selectedVar))
>
>    # glmnet.cox only with meaningful features selected by stepwise
> bidirectional AIC feature selection
>    glmnet.cox.meaningful <- step(coxph(Surv(time,status) ~
> .,data=reformat_dataSet),direction="both")
>
>
>
>
>
##--------------------------------------------------------------------------
> -----------------------------
>    ##                                    MODEL PERFORMANCE
>
>
##--------------------------------------------------------------------------
> -----------------------------
>    ##
>
>
>    ## Calculate the Brier score - pec does its own bootstrap so this
> function runs on i=51 (i.e., whole trainset)
>
>        ## Brier score calculation to cox-glmnet
>        peperr.coxglmnet <- peperr(response=surv_obj, x=selectedVarCox,
>                                fit.fun=fit.coxph, load.all=TRUE,
>                                 
> indices=resample.indices(n=nrow(surv_obj),
> method="boot", sample.n=50))
>
>        # Get error predictions from peperr
>        prederr.coxglmnet <- perr(peperr.coxglmnet)
>
>        # Integrated prediction error Brier score calculation
>        ipec.coxglmnet<-ipec(prederr.coxglmnet,
> eval.times=peperr.coxglmnet$attribute, response=surv_obj)
>
>
>  ## C-Index calculation 50 iter bootstrapping
>
>  for (i in 1:50){
>        print (paste("Iteration:",i))
>        train <- sample(1:nrow(dataset), nrow(dataset), replace =  
> TRUE) ##
> random sampling with replacement
>        # create a dataframe for trainSet with time, status and  
> selected
> variables in binary representation for evaluation in pec
>        reformat_trainSet <- reformat_dataSet [train,]
>
>
>        # glmnet.cox only with meaningful features selected by stepwise
> bidirectional AIC feature selection
>        glmnet.cox.meaningful.test <- step(coxph(Surv(time,status) ~
> .,data=reformat_dataSet),direction="both")
>
>        selectedVarCox   <-
> predict_matrix[,attr(glmnet.cox.meaningful.test$terms,"term.labels")]
>        reformat_testSet <-  
> as.data.frame(cbind(surv_obj,selectedVarCox))
>        reformat_testSet <- reformat_dataSet [-train,]
>
>
> #     compute c-index (Harrell's) for cox-glmnet models
>        if (is.null(glmnet.cox.meaningful)){
>          cIndexCoxglmnet <- c(cIndexCoxglmnet,NULL)
>        }else{
>          cIndexCoxglmnet <- c(cIndexCoxglmnet,
> 1-rcorr.cens(predict(glmnet.cox.meaningful,
> reformat_testSet),Surv(reformat_testSet$time,reformat_testSet 
> $status))[1])
>        }
>  }
>
>  #Get average C-Index
>  cIndex<- mean (unlist(cIndexCoxglmnet),rm.na=TRUE)
>
>  #create a list of all the objects generated
>
> assign 
> (name,c(eval(parse(text=name)),glmnet.cv=list(glmnet.cv),glmnet.obj=li
> st(glmnet.obj),
>
> selectedVar=list(colnames(selectedVar)),glmnet.cox=list(glmnet.cox),
>
> glmnet 
> .cox.meaningful=list(glmnet.cox.meaningful),ipec.coxglmnet=list(ipec.c
> oxglmnet),
>                cIndex=cIndex))
>
>  # save image of the workspace after each iteration
>    save.image("final_subgroup_analysissubgroup_analysis.RData")
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From mrwansweedan at yahoo.com  Sun Sep 29 22:21:22 2013
From: mrwansweedan at yahoo.com (Mrwan Sweedan)
Date: Sun, 29 Sep 2013 13:21:22 -0700 (PDT)
Subject: [R] explination
In-Reply-To: <5248849A.2010305@sapo.pt>
References: <1380481071.50344.YahooMailNeo@web125002.mail.ne1.yahoo.com>
	<524882E7.2070205@sapo.pt> <5248849A.2010305@sapo.pt>
Message-ID: <1380486082.97872.YahooMailNeo@web125002.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130929/6a33c56b/attachment.pl>

From katharine.mullen at stat.ucla.edu  Sun Sep 29 22:48:48 2013
From: katharine.mullen at stat.ucla.edu (Mullen, Katharine)
Date: Sun, 29 Sep 2013 20:48:48 +0000
Subject: [R] useR! 2014: call for tutorial proposals
Message-ID: <C1996F44F7E53647862683EDC8C1D455410E4DAF@EM3C.ad.ucla.edu>

We are pleased to announce that the R user conference

   useR! 2014

is scheduled for July 1-3, 2014, and will take place at the
University of California, Los Angeles. 

As for the predecessor conferences, the program will consist of two
parts: invited lectures and user-contributed sessions (abstract
submission will be available in due course). Prior to the
conference, there will be tutorials on R (proposals for tutorials should
be sent before January 5, 2014, as described below).

CONFIRMED INVITED SPEAKERS

   John Chambers, David Diez, Dirk Eddelbuettel, Jan de Leeuw, Martin
   M?chler, Karline Soetaert

USER-CONTRIBUTED SESSIONS

The conference will feature both talks and posters illustrating the use
of R in practice. Contributions are welcome that introduce recent
developments in the R Project (including CRAN packages), demonstrate
applications of R in areas of current interest, or otherwise engage and
inspire participants in their use of R.

PRE-CONFERENCE TUTORIALS

Before the official program, half-day tutorials will be offered on
Monday, June 30.  

We invite R users to submit proposals for three hour tutorials on
special topics regarding R. The proposals should give a brief
description of the tutorial, including goals, detailed outline,
justification of why the tutorial is important, background knowledge
required and potential attendees. The proposals should be sent before
January 5, 2014 to useR-2014_at_R-project.org.

A web page offering more information on the `useR!' conference is
available at

   http://www.R-project.org/useR-2014

We hope to see you in Los Angeles!  

The organizing committee:

   Yunyun Dai, Phil Ender, Jan de Leeuw, David McArthur, 
   Amelia McNamara, Sanjog Misra, Katharine Mullen, Jeroen Ooms, 
   Szilard Pafka, Tim Triche, Joshua Wiley


From anon.r.user at gmail.com  Sun Sep 29 23:48:34 2013
From: anon.r.user at gmail.com (john doe)
Date: Sun, 29 Sep 2013 14:48:34 -0700
Subject: [R] Understanding classes in R
Message-ID: <CAFWa_VtawQSfo-eW7HdNYj9YB=Kv2Syc+7+1NqRc7M+YkcC1YA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130929/f17e4e14/attachment.pl>

From gunter.berton at gene.com  Mon Sep 30 01:10:28 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 29 Sep 2013 16:10:28 -0700
Subject: [R] Understanding classes in R
In-Reply-To: <CAFWa_VtawQSfo-eW7HdNYj9YB=Kv2Syc+7+1NqRc7M+YkcC1YA@mail.gmail.com>
References: <CAFWa_VtawQSfo-eW7HdNYj9YB=Kv2Syc+7+1NqRc7M+YkcC1YA@mail.gmail.com>
Message-ID: <CACk-te3=5TDCQS9U3PWWGmqmMp4kqP2-Y9qLGhtp_qFhUZ4S-w@mail.gmail.com>

R-help is not the place for an extended tutorial the R class systems
(there are in fact at least two, S3 and S4, neither of which is like
C++ classes). Read the "R Language Definition" Manual that ships with
R, John Chambers's books (probably the latest for S4), or search the
web for tutorials (there are many).

Online Help is terse, but perhaps useful:

?UseMethod ## S3 classes

?setMethod
?Methods   ## for S4 classes

Cheers,
Bert

On Sun, Sep 29, 2013 at 2:48 PM, john doe <anon.r.user at gmail.com> wrote:
> I am having trouble understanding how classes in R work.  Here is a small
> reproducable example:
>
>> x=1
>> class(x)
> [1] "numeric"
>
> OK.  When a variable is a number, its class is "numeric".  Does R have
> multiple types for numbers, like C++ (eg integer, float, double).  If so,
> where can I see a list, and how does "numeric" fit into this system?
>
>> x=1:100
>> class(x)
> [1] "integer"
>
> Wait - I thought that I assigned x to be an array/vector of 100 integers
> (numerics).  Why is the class not "array" or "vector".  How is "integer"
> different than "numeric"?  Is there a "vector" or "array" class in R?  If
> so, why is this not that?
>
>> class(x[1])
> [1] "integer"
>
> This is even more confusing to me.  Because x[1] is 1.  And the class of
> that was "numeric" in my first example.  Why is it integer now?
>
>> x=1.5:100.5
>> class(x)
> [1] "numeric"
>
> Why is this class "numeric" when the class of 1:100 was integer?
>
> Thanks for your help.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From dwinsemius at comcast.net  Mon Sep 30 01:39:33 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 29 Sep 2013 16:39:33 -0700
Subject: [R] Understanding classes in R
In-Reply-To: <CAFWa_VtawQSfo-eW7HdNYj9YB=Kv2Syc+7+1NqRc7M+YkcC1YA@mail.gmail.com>
References: <CAFWa_VtawQSfo-eW7HdNYj9YB=Kv2Syc+7+1NqRc7M+YkcC1YA@mail.gmail.com>
Message-ID: <EAC873A6-C083-4F3D-9CFC-A61D1A9682AF@comcast.net>


On Sep 29, 2013, at 2:48 PM, john doe wrote:

> I am having trouble understanding how classes in R work.  Here is a small
> reproducable example:
> 
>> x=1
>> class(x)
> [1] "numeric"
> 
> OK.  When a variable is a number, its class is "numeric".  Does R have
> multiple types for numbers, like C++ (eg integer, float, double).  If so,
> where can I see a list, and how does "numeric" fit into this system?
> 
>> x=1:100
>> class(x)
> [1] "integer"
> 
> Wait - I thought that I assigned x to be an array/vector of 100 integers
> (numerics).  Why is the class not "array" or "vector".

Well, it is a vector. But it's not an array because it has no 'dim' attribute. The ":" operator returns integer sequences.

?":"

>  How is "integer"
> different than "numeric"?  Is there a "vector" or "array" class in R?

Yes.

?array
?vector
?is.vector

>  If
> so, why is this not that?
> 
>> class(x[1])
> [1] "integer"
> 
> This is even more confusing to me.  Because x[1] is 1.

Look at:

x=1L
class(x)

>  And the class of
> that was "numeric" in my first example.  Why is it integer now?
> 
>> x=1.5:100.5
>> class(x)
> [1] "numeric"
> 
> Why is this class "numeric" when the class of 1:100 was integer?
> 

Intergers are stored as 4-byte per item with a bit of overhead, which numerics or doubles are stored with 8 bytes:

>  object.size(1:100000)
400040 bytes
> object.size( (1:100000)+.5 )
800040 bytes

As you can see it is very easy to corce an integer to numeric.

> Thanks for your help.
> 
> 	[[alternative HTML version deleted]]

And do learn to post in plain text.

> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
David Winsemius
Alameda, CA, USA


From istazahn at gmail.com  Mon Sep 30 02:28:14 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Sun, 29 Sep 2013 20:28:14 -0400
Subject: [R] Understanding classes in R
In-Reply-To: <CAFWa_VtawQSfo-eW7HdNYj9YB=Kv2Syc+7+1NqRc7M+YkcC1YA@mail.gmail.com>
References: <CAFWa_VtawQSfo-eW7HdNYj9YB=Kv2Syc+7+1NqRc7M+YkcC1YA@mail.gmail.com>
Message-ID: <CA+vqiLGFKyoP36h99o4-QcKW9cuTPf623Aq1kz-Btvcz89AvcQ@mail.gmail.com>

Hi JD,

On Sun, Sep 29, 2013 at 5:48 PM, john doe <anon.r.user at gmail.com> wrote:
> I am having trouble understanding how classes in R work.  Here is a small
> reproducable example:
>
>> x=1
>> class(x)
> [1] "numeric"
>
> OK.  When a variable is a number, its class is "numeric".  Does R have
> multiple types for numbers, like C++ (eg integer, float, double).

Yes, but the class is not the type:

> x <- 1:10
> class(x)
[1] "integer"
> typeof(x)
[1] "integer"
> class(x) <- "foo"
> class(x)
[1] "foo"
> typeof(x)
[1] "integer"

  If so,
> where can I see a list, and how does "numeric" fit into this system?

A list of what? For a list of storage modes see ?typof. For classes
there cannot be any such list, as you can create a new class as easily
as

class(x) <- "aNewClassThatNeverExistedBefore"


>
>> x=1:100
>> class(x)
> [1] "integer"
>
> Wait - I thought that I assigned x to be an array/vector of 100 integers
> (numerics).  Why is the class not "array" or "vector".  How is "integer"
> different than "numeric"?  Is there a "vector" or "array" class in R?  If
> so, why is this not that?

See http://cran.r-project.org/doc/manuals/r-release/R-intro.html#Objects
(And while you are there it wouldn't be a bad idea to read the rest of
manual as well).

>
>> class(x[1])
> [1] "integer"
>
> This is even more confusing to me.  Because x[1] is 1.  And the class of
> that was "numeric" in my first example.  Why is it integer now?

Presumably because '[' turned it into one. help("[") says that the
return value is "typically an array-like R object of a similar class
as ?x?."

>
>> x=1.5:100.5
>> class(x)
> [1] "numeric"
>
> Why is this class "numeric" when the class of 1:100 was integer?

Because 1.5 is not an integer. See the Value section of help(":")


>
> Thanks for your help.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From agrimasrivastava1 at gmail.com  Mon Sep 30 07:15:47 2013
From: agrimasrivastava1 at gmail.com (agrima srivastava)
Date: Mon, 30 Sep 2013 10:45:47 +0530
Subject: [R] str_count counts the substring
Message-ID: <CACV9Ukphe+YV7NkgEQoCfOoPvzJG1kTnOuUQE3xu3tvB20JkZA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130930/6771e617/attachment.pl>

From b.rowlingson at lancaster.ac.uk  Mon Sep 30 08:42:49 2013
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 30 Sep 2013 07:42:49 +0100
Subject: [R] Understanding classes in R
In-Reply-To: <1e60753163cd48f9bf82ca92af41fac9@EX-0-HT0.lancs.local>
References: <1e60753163cd48f9bf82ca92af41fac9@EX-0-HT0.lancs.local>
Message-ID: <CANVKczOxUFFkH3mBCjWiBcqA1iMjZKfA291eJrmS44nxdxJjkw@mail.gmail.com>

On Sun, Sep 29, 2013 at 10:48 PM, john doe <anon.r.user at gmail.com> wrote:
> I am having trouble understanding how classes in R work.  Here is a small
> reproducable example:
>
>> x=1
>> class(x)
> [1] "numeric"
>
> OK.  When a variable is a number, its class is "numeric".  Does R have
> multiple types for numbers, like C++ (eg integer, float, double).  If so,
> where can I see a list, and how does "numeric" fit into this system?
>
>> x=1:100
>> class(x)
> [1] "integer"
>
> Wait - I thought that I assigned x to be an array/vector of 100 integers
> (numerics).  Why is the class not "array" or "vector".  How is "integer"
> different than "numeric"?  Is there a "vector" or "array" class in R?  If
> so, why is this not that?

In most programming languages scalars and vectors (aka 1-d arrays) are
completely different things. However in R a scalar is the same thing
as a length-1 vector. Don't think of x=1 and x=1:100 as the first
creating a scalar and the second creating a vector containing 100
scalar values. The first creates a vector containing 1 scalar value,
and the second creates a vector conatining 100 scalar values. You
can't really get scalar values, they'll always effectively be in a
vector of length 1.

So the return value of class here is actually short for 'vector of
numeric' or 'vector of integer' - even when the length is 1 - and you
can think of those as the basic numeric classes. There is no 'scalar
numeric' class, all is vectors. is.vector(1) is TRUE. There isn't even
an is.scalar function.

None of that is true for 2-d arrays, aka matrices, where class(m) is
always "matrix" whether its a matrix of characters or numbers. You
have to look at the mode(m) or typeof(m) (or storage.mode(m)) to
figure out what kind of thing a matrix 'm' contains.

A 'list' is a bit more like some of the generic container classes that
you find in other programming langages. Its elements can be anything
but its class is always 'list'. Use it when you want a vector (in the
general sense of 'vector') of non-scalar values, eg L =
list(c(1,2,3),1,c(99,120),c("foo","bar","baz"))

Confused? Well, just forget everything you learned about classes in
your Comp Sci lessons and get ready to learn R's two incompatible
OO-programming systems (S3 and S4 classes), or four if you want to
look at even more OO systems people have implemented as add-on
packages....

Barry


From dwinsemius at comcast.net  Mon Sep 30 09:19:20 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 30 Sep 2013 00:19:20 -0700
Subject: [R] Understanding classes in R
In-Reply-To: <CA+vqiLGFKyoP36h99o4-QcKW9cuTPf623Aq1kz-Btvcz89AvcQ@mail.gmail.com>
References: <CAFWa_VtawQSfo-eW7HdNYj9YB=Kv2Syc+7+1NqRc7M+YkcC1YA@mail.gmail.com>
	<CA+vqiLGFKyoP36h99o4-QcKW9cuTPf623Aq1kz-Btvcz89AvcQ@mail.gmail.com>
Message-ID: <7B7EB799-57C9-407B-9BF7-57C8D305F6D1@comcast.net>


On Sep 29, 2013, at 5:28 PM, Ista Zahn wrote:

> Hi JD,
> 
> On Sun, Sep 29, 2013 at 5:48 PM, john doe <anon.r.user at gmail.com> wrote:
>> I am having trouble understanding how classes in R work.  Here is a small
>> reproducable example:
>> 
>>> x=1
>>> class(x)
>> [1] "numeric"
>> 
>> OK.  When a variable is a number, its class is "numeric".  Does R have
>> multiple types for numbers, like C++ (eg integer, float, double).
> 
> Yes, but the class is not the type:
> 
>> x <- 1:10
>> class(x)
> [1] "integer"
>> typeof(x)
> [1] "integer"
>> class(x) <- "foo"
>> class(x)
> [1] "foo"
>> typeof(x)
> [1] "integer"
> 
>  If so,
>> where can I see a list, and how does "numeric" fit into this system?
> 
> A list of what? For a list of storage modes see ?typof. For classes
> there cannot be any such list, as you can create a new class as easily
> as
> 
> class(x) <- "aNewClassThatNeverExistedBefore"
> 
> 
>> 
>>> x=1:100
>>> class(x)
>> [1] "integer"
>> 
>> Wait - I thought that I assigned x to be an array/vector of 100 integers
>> (numerics).  Why is the class not "array" or "vector".  How is "integer"
>> different than "numeric"?  Is there a "vector" or "array" class in R?  If
>> so, why is this not that?
> 
> See http://cran.r-project.org/doc/manuals/r-release/R-intro.html#Objects
> (And while you are there it wouldn't be a bad idea to read the rest of
> manual as well).
> 
>> 
>>> class(x[1])
>> [1] "integer"
>> 
>> This is even more confusing to me.  Because x[1] is 1.  And the class of
>> that was "numeric" in my first example.  Why is it integer now?
> 
> Presumably because '[' turned it into one. help("[") says that the
> return value is "typically an array-like R object of a similar class
> as ?x?."

If you just type:

x <- 1 # the mode is "double" and the class is "numeric"

If you type:

x <- 1L  # mode and class are "integer"

x[1] does not coerce an "integer" to "numeric"

-- 

David Winsemius
Alameda, CA, USA


From jhernandezcabrera at gmail.com  Mon Sep 30 11:47:55 2013
From: jhernandezcabrera at gmail.com (Juan Andres Hernandez)
Date: Mon, 30 Sep 2013 10:47:55 +0100
Subject: [R] barplot to the right side
Message-ID: <CAL79i+QywYuD1LA3-EszcAJVJj9ueLeDGSkRWon722PQ16F0MQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: no disponible
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130930/65ca6102/attachment.pl>

From jenny.williams at kew.org  Mon Sep 30 12:25:53 2013
From: jenny.williams at kew.org (Jenny Williams)
Date: Mon, 30 Sep 2013 11:25:53 +0100
Subject: [R] climstats
Message-ID: <DEF541F3CB545B4A8BC9A811132359C003697191EFE2@KEXCH00.ad.kew.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130930/6faaefcf/attachment.pl>

From jim at bitwrit.com.au  Mon Sep 30 12:36:01 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Mon, 30 Sep 2013 20:36:01 +1000
Subject: [R] barplot to the right side
In-Reply-To: <CAL79i+QywYuD1LA3-EszcAJVJj9ueLeDGSkRWon722PQ16F0MQ@mail.gmail.com>
References: <CAL79i+QywYuD1LA3-EszcAJVJj9ueLeDGSkRWon722PQ16F0MQ@mail.gmail.com>
Message-ID: <52495411.8060404@bitwrit.com.au>

On 09/30/2013 07:47 PM, Juan Andres Hernandez wrote:
> Hi, does anybody know how to get a barplot with the x axis starting in the
> right side and the y axis in the right side too?
> An example:
>
> dat=c(2,4,0,6,5)
> names(dat)=paste('dpt.',1:5,sep='')
> barplot(dat, horiz=T)
> box()
>
> I need this barplot in mirror, with the zero value to 6 starting in the
> right side of x axes and the horizontal bars starting in the right side too.
>
Hi Juan,
Try this:

par(mar=c(5,2,4,4))
barpos<-barplot(-dat,names.arg=rep("",5),axes=FALSE,horiz=TRUE)
axis(1,at=(-6):0,labels=6:0)
mtext(names(dat),side=4,at=barpos,line=1)

Jim


From smartpink111 at yahoo.com  Mon Sep 30 12:56:33 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 30 Sep 2013 03:56:33 -0700 (PDT)
Subject: [R] str_count counts the substring
In-Reply-To: <CACV9Ukphe+YV7NkgEQoCfOoPvzJG1kTnOuUQE3xu3tvB20JkZA@mail.gmail.com>
References: <CACV9Ukphe+YV7NkgEQoCfOoPvzJG1kTnOuUQE3xu3tvB20JkZA@mail.gmail.com>
Message-ID: <1380538593.85653.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,

May be this helps:
str1<- "Brazil is the world's leading orange producer, with an output almost as high as that of the next three countries combined (the United States, India, and China). Orange groves are located mainly in the state of S?o Paulo, in the southeastern region of Brazil. Oranges, whose flavour may vary from sweet to sour, are commonly peeled and eaten fresh or squeezed for juice ora"

regmatches(str1,gregexpr("\\borange\\b",tolower(str1),perl=TRUE))[[1]]
#[1] "orange" "Orange"


?length(regmatches(str1,gregexpr("\\borange\\b",tolower(str1),perl=TRUE))[[1]])
#[1] 2
A.K.







----- Original Message -----
From: agrima srivastava <agrimasrivastava1 at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Monday, September 30, 2013 1:45 AM
Subject: [R] str_count counts the substring

I am trying to count the number of times a word occurs in a string.
and using str_count function from the package stringr. This function counts
the substrings as well.
Is there a way in which I can exclude the substring count and just take the
exact match.
Thanks in advance.



-- 
Thanks and Regards
Agrima Srivastava
-------------------------------------------------------------------------------
Research Scholar
Computer Science & Information Systems Department
BITS Pilani Hyderabad Campus

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From therneau at mayo.edu  Mon Sep 30 16:30:01 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 30 Sep 2013 09:30:01 -0500
Subject: [R] Interperting results of glmnet and coxph plot,
 Brier score and Harrel's C-Index - am I doing something wrong ???
Message-ID: <52498AE9.9050906@mayo.edu>

To elaborate on Frank's response, the analysis plan of
   1. Look at the data and select "important" variables
   2. Put that truncated list into your favorite statistic procedure
   3. Ask - are the p-values (c-statistic, coefficients, .....) reliable?

is a very old plan.  The answer to the last question is always "NO".
The traditional step 1 involved graphs and t-tests, but replacing it by something modern 
does not change the overall outcome.

Terry T


From amandali at uchicago.edu  Mon Sep 30 16:55:31 2013
From: amandali at uchicago.edu (Amanda Li)
Date: Mon, 30 Sep 2013 22:55:31 +0800
Subject: [R] Apply function to do pairwise calculation
Message-ID: <CALwvZ4Vzeex8+=W4j6D6+8GAAuOvbBXZ2X0ahPhFsDsSwENuhA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130930/d0b20d1d/attachment.pl>

From chuan.cheng09 at imperial.ac.uk  Mon Sep 30 12:30:24 2013
From: chuan.cheng09 at imperial.ac.uk (Cheng, Chuan)
Date: Mon, 30 Sep 2013 10:30:24 +0000
Subject: [R] Split type in the RandomForest package
Message-ID: <69DCF4799E57F541A264D05A8468CC8954E9B230@icexch-m1.ic.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130930/68b441f4/attachment.pl>

From yveslaessig at web.de  Mon Sep 30 11:31:06 2013
From: yveslaessig at web.de (ZuckerRahmen)
Date: Mon, 30 Sep 2013 02:31:06 -0700 (PDT)
Subject: [R] Residuals in garch (tseries)
Message-ID: <1380533465485-4677241.post@n4.nabble.com>

Hello,

i'm currently working with the 'garch' function provided by the 'tseries'
package in R.

If you want to fit a time series you can call the function this way
fit = garch(data, order=c(1,1)).

A GARCH model delivers you a vector of sd's sigma and therefore confidence
intervals for your data. You can get them from the function output by
calling fit$fitted.values. 

You can also get some kind of residuals with fit$residuals and here is my
question: does anybody know how they are computed?

Normally some would say residuals = data - model, but for GARCH modelling
there is no exact model for the data but the confidence interval mentioned
above.

To compare the residuals I got here from the GARCH modelling to other models
I really need to know how they are computed, but the R documentary doesn't
provide an answer.

Anyone got a clue?

Thanks for any help in advance.



--
View this message in context: http://r.789695.n4.nabble.com/Residuals-in-garch-tseries-tp4677241.html
Sent from the R help mailing list archive at Nabble.com.


From dcarov at gmail.com  Mon Sep 30 11:42:04 2013
From: dcarov at gmail.com (Daniel Caro)
Date: Mon, 30 Sep 2013 10:42:04 +0100
Subject: [R] change specific factor level values to NA in data frame
Message-ID: <CAMeQTh3qUD_d0Obeyww9bcZaLNAk=z7EdDcDLSRRp9dDH2hMiQ@mail.gmail.com>

Dear R-users

I am trying to replace specific factor level values in a data frame
with NAs. The data frame includes different kind of variables (e.g,
characters, numbers, and factors). I'd like to replace all 'Not
applicable', 'Invalid', 'and Missing' for NA.

For example:

f.level <- c('Yes', 'No', 'Not applicable', 'Invalid', 'Missing')
df <- data.frame(x1=runif(100), x2=sample(f.level, 100, replace=T),
x3=sample(f.level, 100, replace=T))

I try changing the values by
df[df %in% c('Not applicable', 'Invalid', 'Missing'), ] <- NA

but nothing seems to change
summary(df)

My data frame has many more factors. Any advice?

Thank you,
Daniel


From saira8898 at gmail.com  Mon Sep 30 13:13:41 2013
From: saira8898 at gmail.com (saira khalid)
Date: Mon, 30 Sep 2013 04:13:41 -0700
Subject: [R] how to compare two different models with different dependent
	variables
Message-ID: <CAEj0iuZsdO24hEbBo5Kitn4dikWM6CiXPBkb8PMosAsNFQjVzA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130930/09c1125c/attachment.pl>

From tobi_gebetsberger at gmx.at  Mon Sep 30 15:05:09 2013
From: tobi_gebetsberger at gmx.at (happyR)
Date: Mon, 30 Sep 2013 06:05:09 -0700 (PDT)
Subject: [R] barplot - easy for experienced, difficult for me
Message-ID: <1380546308922-4677251.post@n4.nabble.com>

hey guys,

I wanna make a simple barplot, looking like this excel graph: 
<http://r.789695.n4.nabble.com/file/n4677251/barplot_invertebrates.jpg> 

my data set includes 9 groups of invertebrates (x-axes) and total number
(y-axes) from two different parks (1 and 2).

my data-set looks like that:

<http://r.789695.n4.nabble.com/file/n4677251/barplot_invertebrates.jpg> 

I'm a bloody beginner and happy for your help.

ps: if you know what other graph could be interesting to make out of this
very simple data, go ahead and let me know!









--
View this message in context: http://r.789695.n4.nabble.com/barplot-easy-for-experienced-difficult-for-me-tp4677251.html
Sent from the R help mailing list archive at Nabble.com.


From stan.aggerwal at gmail.com  Mon Sep 30 16:46:02 2013
From: stan.aggerwal at gmail.com (Stanislav Aggerwal)
Date: Mon, 30 Sep 2013 15:46:02 +0100
Subject: [R] get mouse position without waiting for a click
Message-ID: <CAOZp1on9k9L-_xvN8uVci9oAXuMG0RQGNH3Jc1h=9DqV_KSNKg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130930/ac02a647/attachment.pl>

From gunter.berton at gene.com  Mon Sep 30 17:46:55 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 30 Sep 2013 08:46:55 -0700
Subject: [R] get mouse position without waiting for a click
In-Reply-To: <CAOZp1on9k9L-_xvN8uVci9oAXuMG0RQGNH3Jc1h=9DqV_KSNKg@mail.gmail.com>
References: <CAOZp1on9k9L-_xvN8uVci9oAXuMG0RQGNH3Jc1h=9DqV_KSNKg@mail.gmail.com>
Message-ID: <CACk-te1_vLqhBGSjR36B_OoYOZaYfykLOuus-JG=X-Fm+fTdhA@mail.gmail.com>

On Windows or X11, (others ???)

?getGraphicsEvent

Cheers,
Bert

On Mon, Sep 30, 2013 at 7:46 AM, Stanislav Aggerwal
<stan.aggerwal at gmail.com> wrote:
> Consider the following:
>
> par(mar=c(0,0,0,0),xaxs = 'i',yaxs='i')
> plot.new()
> for(i in 1:20)
>   {
>   z <- matrix(runif(256*256), ncol=256)
>   dev.hold()
>   image(z, col=grey(0:255/255),zlim=c(0,1),useRaster=TRUE)
>   dev.flush()
>   Sys.sleep(.1)
>   }
>
> I would like to continuously display the animation until a mouse click
> happens. Obviously, locator() can't be used for this, because it will halt
> the animation while waiting for the mouse click. So something like this
> won't work:
>
> while((r<-locator(n=1)) == NULL)
>   {
>   z <- matrix(runif(256*256), ncol=256)
>   dev.hold()
>   image(z, col=grey(0:255/255),zlim=c(0,1),useRaster=TRUE)
>   dev.flush()
>   Sys.sleep(.1)
>   }
>
> Can somebody suggest a way to get user input while displaying the
> animation? I am willing to use a keypress if not the mouse. Essentially, I
> need an input routine that does not wait for a response but just checks at
> one instant (like kbhit in C).
>
> Thanks very much for any help.
>
> Stan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From gunter.berton at gene.com  Mon Sep 30 17:50:44 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 30 Sep 2013 08:50:44 -0700
Subject: [R] how to compare two different models with different
	dependent variables
In-Reply-To: <CAEj0iuZsdO24hEbBo5Kitn4dikWM6CiXPBkb8PMosAsNFQjVzA@mail.gmail.com>
References: <CAEj0iuZsdO24hEbBo5Kitn4dikWM6CiXPBkb8PMosAsNFQjVzA@mail.gmail.com>
Message-ID: <CACk-te1pfF-E4-46LASpyox93B=fWDmukGXOsMOYWzo4CwCNKg@mail.gmail.com>

1. This is an r-help list, not a statistics or econometrics list. So
you need to post elsewhere.

2. However, having said that, you might find that the CRAN
Econometrics task view may be useful.
http://cran.r-project.org/web/views/Econometrics.html

Cheers,
Bert

On Mon, Sep 30, 2013 at 4:13 AM, saira khalid <saira8898 at gmail.com> wrote:
> i want to compare two exchange rate models namely balassa samuelson model n
> monetary model of exchange rate.but i don't know how??because both models
> are different n dependent variables are also different from each
> other...plz help me in my research work n tell me which econometric
> technique is usefull in this context?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From msuzen at gmail.com  Mon Sep 30 18:13:08 2013
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Mon, 30 Sep 2013 18:13:08 +0200
Subject: [R] DEoptim inconsistent output
In-Reply-To: <CAB=y=yM-vF8pU6zBY77BhWpvL+VXyYkNHAT5bwmqof9x_g=imA@mail.gmail.com>
References: <CAB=y=yM-vF8pU6zBY77BhWpvL+VXyYkNHAT5bwmqof9x_g=imA@mail.gmail.com>
Message-ID: <CAPtbhHxPs5dwXmemMr8c3z8e5F037xJERdw8m7j4LwhyjeSHGg@mail.gmail.com>

On 29 September 2013 19:17, Aya Anas <aanas at feps.edu.eg> wrote:
> doesn't make sense at all. I got parameters that don't satisfy the
> constraint. In addition, when i substituted with the resulting parameters


Maybe you have issues with your interpretation of the usage of the package and
expected output. So, Can you provide reproducible code? Verbal descriptions may
not be efficient to explain issues with mathematical software...


From ruipbarradas at sapo.pt  Mon Sep 30 18:52:10 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 30 Sep 2013 17:52:10 +0100
Subject: [R] change specific factor level values to NA in data frame
In-Reply-To: <CAMeQTh3qUD_d0Obeyww9bcZaLNAk=z7EdDcDLSRRp9dDH2hMiQ@mail.gmail.com>
References: <CAMeQTh3qUD_d0Obeyww9bcZaLNAk=z7EdDcDLSRRp9dDH2hMiQ@mail.gmail.com>
Message-ID: <5249AC3A.9060500@sapo.pt>

Hello,

A possibility is the following.



icol <- sapply(df, is.factor)
df[icol] <- lapply(df[icol], function(x){
	x[as.character(x)  %in% c('Not applicable', 'Invalid', 'Missing')] <- NA
	x})


Hope this helps,

Rui Barradas

Em 30-09-2013 10:42, Daniel Caro escreveu:
> Dear R-users
>
> I am trying to replace specific factor level values in a data frame
> with NAs. The data frame includes different kind of variables (e.g,
> characters, numbers, and factors). I'd like to replace all 'Not
> applicable', 'Invalid', 'and Missing' for NA.
>
> For example:
>
> f.level <- c('Yes', 'No', 'Not applicable', 'Invalid', 'Missing')
> df <- data.frame(x1=runif(100), x2=sample(f.level, 100, replace=T),
> x3=sample(f.level, 100, replace=T))
>
> I try changing the values by
> df[df %in% c('Not applicable', 'Invalid', 'Missing'), ] <- NA
>
> but nothing seems to change
> summary(df)
>
> My data frame has many more factors. Any advice?
>
> Thank you,
> Daniel
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ruipbarradas at sapo.pt  Mon Sep 30 18:58:27 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 30 Sep 2013 17:58:27 +0100
Subject: [R] Residuals in garch (tseries)
In-Reply-To: <1380533465485-4677241.post@n4.nabble.com>
References: <1380533465485-4677241.post@n4.nabble.com>
Message-ID: <5249ADB3.4010204@sapo.pt>

Hello,

To know how something in R is computed, download the sources and read 
the respective function code.
That's one of the benefits of open source software, you can know exactly 
what is going on.


Hope this helps,

Rui Barradas

Em 30-09-2013 10:31, ZuckerRahmen escreveu:
> Hello,
>
> i'm currently working with the 'garch' function provided by the 'tseries'
> package in R.
>
> If you want to fit a time series you can call the function this way
> fit = garch(data, order=c(1,1)).
>
> A GARCH model delivers you a vector of sd's sigma and therefore confidence
> intervals for your data. You can get them from the function output by
> calling fit$fitted.values.
>
> You can also get some kind of residuals with fit$residuals and here is my
> question: does anybody know how they are computed?
>
> Normally some would say residuals = data - model, but for GARCH modelling
> there is no exact model for the data but the confidence interval mentioned
> above.
>
> To compare the residuals I got here from the GARCH modelling to other models
> I really need to know how they are computed, but the R documentary doesn't
> provide an answer.
>
> Anyone got a clue?
>
> Thanks for any help in advance.
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Residuals-in-garch-tseries-tp4677241.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From gunter.berton at gene.com  Mon Sep 30 19:16:57 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 30 Sep 2013 10:16:57 -0700
Subject: [R] change specific factor level values to NA in data frame
In-Reply-To: <5249AC3A.9060500@sapo.pt>
References: <CAMeQTh3qUD_d0Obeyww9bcZaLNAk=z7EdDcDLSRRp9dDH2hMiQ@mail.gmail.com>
	<5249AC3A.9060500@sapo.pt>
Message-ID: <CACk-te0s0e+z_qVoiwaNpjiC3KvwW=ZwLM34_Cu__gaHjdbKgg@mail.gmail.com>

Well, maybe or maybe not. The problem is that the old factor levels
remain. Here's a tiny example that illustrates the issue:

> z <- factor(c("a","b","c"))
> z[as.character(z)=="c"] <- NA
> z
[1] a    b    <NA>
Levels: a b c

Whether or  how you wish to change this depends on what you are doing
with the data.

Cheers,
Bert


On Mon, Sep 30, 2013 at 9:52 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> A possibility is the following.
>
>
>
> icol <- sapply(df, is.factor)
> df[icol] <- lapply(df[icol], function(x){
>         x[as.character(x)  %in% c('Not applicable', 'Invalid', 'Missing')]
> <- NA
>         x})
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 30-09-2013 10:42, Daniel Caro escreveu:
>>
>> Dear R-users
>>
>> I am trying to replace specific factor level values in a data frame
>> with NAs. The data frame includes different kind of variables (e.g,
>> characters, numbers, and factors). I'd like to replace all 'Not
>> applicable', 'Invalid', 'and Missing' for NA.
>>
>> For example:
>>
>> f.level <- c('Yes', 'No', 'Not applicable', 'Invalid', 'Missing')
>> df <- data.frame(x1=runif(100), x2=sample(f.level, 100, replace=T),
>> x3=sample(f.level, 100, replace=T))
>>
>> I try changing the values by
>> df[df %in% c('Not applicable', 'Invalid', 'Missing'), ] <- NA
>>
>> but nothing seems to change
>> summary(df)
>>
>> My data frame has many more factors. Any advice?
>>
>> Thank you,
>> Daniel
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From dwinsemius at comcast.net  Mon Sep 30 19:19:52 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 30 Sep 2013 10:19:52 -0700
Subject: [R] climstats
In-Reply-To: <DEF541F3CB545B4A8BC9A811132359C003697191EFE2@KEXCH00.ad.kew.org>
References: <DEF541F3CB545B4A8BC9A811132359C003697191EFE2@KEXCH00.ad.kew.org>
Message-ID: <1FB1E28E-2A6E-4474-950A-95C378442109@comcast.net>


On Sep 30, 2013, at 3:25 AM, Jenny Williams wrote:

> I have been trying to download the climstats package:
> https://r-forge.r-project.org/R/?group_id=861
> 
> but it doesn't seem to run on R 3.0.2 or 3.0.1

What makes you say this? What errors are reprorted? ("Doesn't seems to run" is a bit vague.)

> and the zipfile is empty.

I was able to install version 1.0 from sources with:

install.packages("climstats", repos="http://R-Forge.R-project.org", type="source")

(I agree that the zipfile for Windows was not found.)

R version 3.0.1 Patched (2013-07-23 r63392) Running Mac OS 10.7.5. It appears to require a fair number of external package, so you would need to check the Depends in the description file. 

Depends: R (>= 2.13), raster, rgdal, chron, zoo, sp, ncdf, R.utils

It did not appear to do any C or Fortran compiling, so I think that means you do not need to have RTools installed on Windows.

But since it requires rgdal, you would need to have GDAL installed if you were to get it to load.


> 
> Does anyone know the status of this package or where I can download it.
> 
> Thanks
> 
> ******************
> Jenny Williams
> Spatial Information Scientist, GIS Unit
> Herbarium, Library, Art & Archives Directorate
> Royal Botanic Gardens, Kew
> Richmond, TW9 3AB, UK
> 
> Tel: +44 (0)208 332 5277
> email: jenny.williams at kew.org<mailto:jenny.williams at kew.org>
> ******************
> 
> Film: The Forgotten Home of Coffee - Beyond the Gardens<http://www.youtube.com/watch?v=-uDtytKMKpA&sns=tw>
> Stories: Coffee Expedition - Ethiopia<http://storify.com/KewGIS/coffee-expedition-ethiopia>
>             Blog: Discovering Coffee in Ethiopia    <http://www.kew.org/news/kew-blogs/incrEdibles-food-blog/discovering-coffee.htm>
>             Kew in Harapan Rainforest Sumatra<http://storify.com/KewGIS/kew-in-harapan-rainforest>
> Articles: Seeing the wood for the trees<http://www.kew.org/ucm/groups/public/documents/document/kppcont_060602.pdf>
> How Kew's GIS team and South East Asia botanists are working to help conserve and restore a rainforest in Sumatra. Download a pdf of this article here.<http://www.kew.org/ucm/groups/public/documents/document/kppcont_060602.pdf>
> 
> 
> ________________________________
> The Royal Botanic Gardens, Kew is a non-departmental public body with exempt charitable status, whose principal place of business is at Royal Botanic Gardens, Kew, Richmond, Surrey TW9 3AB, United Kingdom.
> 
> The information contained in this email and any attachments is intended solely for the addressee(s) and may contain confidential or legally privileged information. If you have received this message in error, please return it immediately and permanently delete it. Do not use, copy or disclose the information contained in this email or in any attachment.
> 
> Any views expressed in this email do not necessarily reflect the opinions of RBG Kew.
> 
> Any files attached to this email have been inspected with virus detection software by RBG Kew before transmission, however you should carry out your own virus checks before opening any attachments. RBG Kew accepts no liability for any loss or damage which may be caused by software viruses.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Mon Sep 30 19:53:44 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 30 Sep 2013 10:53:44 -0700
Subject: [R] Interperting results of glmnet and coxph plot,
	Brier score and Harrel's C-Index - am I doing something wrong ???
In-Reply-To: <DUB114-DS248291526BFF97A678A070CA2B0@phx.gbl>
References: <DUB114-DS8BCB78F26CC24B7DF2E17CA2A0@phx.gbl>
	<36473A82-B759-4D34-A960-842FA41D2BC3@comcast.net>
	<DUB114-DS248291526BFF97A678A070CA2B0@phx.gbl>
Message-ID: <1596828E-C919-43E7-8232-EE82CAEFC7A0@comcast.net>


On Sep 29, 2013, at 2:16 PM, E Joffe wrote:

> HI,
> 
> Thank you for your answer.
> There were 301 events out of 394 observations.
> 
> Study goals: Identify proteins with prognostic power in patients with AML.
> There were 232 proteins studied.
> Traditional models won't converge.
> I wanted to do a multivariate survival analysis that would allow me to
> identify prognostic proteins and get an estimation of their hazard ratio.
> LASSO allowed me to model the data but in order to get the HRs I needed to
> run it a second time throw coxph - this was done based on a discussion on
> stackexchange

http://r.789695.n4.nabble.com/estimating-survival-times-with-glmnet-and-coxph-td4614225.html

>  which I tweaked a bit.
> 
> 
> The features selected by LASSO are not necessarily all significant when
> constructing a coxph model in particular due to the lack of penalization.
> This was commented on by Dr. Hastie in one of his papers (or in the video
> lecture he gave - I need to find the exact source).
> I understand that by doing this procedure I might be reducing the accuracy
> of the model which is why I used a bootstrap evaluation.
> Interestingly, the coxph models following stepwise feature selection had
> marginally better performance in the evaluation compared with the LASSO
> models (maybe the LASSO over-fit the data a bit ? - don't know)
> 
> What I still don't understand is why with a C-Index of 0.76 and a Brier
> score of 0.07 when I look at the plot of the coxph object the confidence
> intervals are so far ?

The item you referenced was not on stackexchange but rather on Nabble. The archived copy in R-help is here:

[R] Estimating survival times with glmnet and coxph 

https://stat.ethz.ch/pipermail/r-help/2012-May/312029.html
https://stat.ethz.ch/pipermail/r-help/2012-May/312038.html

The response from Terry Therneau at that time explained why the CI's were wide. I think this implies that even without the additional (faulty) step of stepwise reduction in covariates you still would not be able to use the CI's coxphfrom such a fit.


-- 
David.
> Further, I am wondering whether there is a sanity check I could perform to
> make sure there is no error in the Brier/C-Index evaluation.
> 
> Thanks again for all you advice on this project,
> Erel
> 
> 
> 
> -----Original Message-----
> From: David Winsemius [mailto:dwinsemius at comcast.net] 
> Sent: Saturday, September 28, 2013 4:41 PM
> To: E Joffe
> Cc: r-help at r-project.org
> Subject: Re: [R] Interperting results of glmnet and coxph plot, Brier score
> and Harrel's C-Index - am I doing something wrong ???
> 
> 
> On Sep 28, 2013, at 2:39 AM, E Joffe wrote:
> 
>> Hi all,
>> 
>> I am using COX LASSO (glmnet / coxnet) regression to analyze a dataset 
>> of
>> 394 obs. / 268 vars.
>> I use the following procedure:
>> 1.	Construct a coxnet on the entire dataset (by cv.glmnet)
>> 2.	Pick the significant features by selecting the non-zero coefficient
>> under the best lambda selected by the model
>> 3.	Build a coxph model with bi-directional stepwise feature selection
>> limited to the coxnet selected features.
> 
> I was a bit puzzled by the third step. Once you had a reduced model from
> glmnet, what was the statistical basis for further elimination of variables?
> 
> (Quite apart from the statistical issues, I was rather surprised that this
> procedure even produced results since the 'step' function is not described
> in the 'stats' package as applying to 'coxph' model objects.)
> 
>> 	
>> To validate the model I use both Brier score (library=peperr) and  
>> Harrel's [Harrell]
>> C-Index (library=Hmisc) with a bootstrap of 50 iterations.
>> 
>> 
>> MY QUESTION :  I am getting fairly good C-Index (0.76) and Brier  
>> (0.07)
>> values for the models however per the coxnet the %Dev explained by  
>> the model
>> is at best 0.27 and when I plot the survfit of the coxph the plotted
>> confidence interval is very large.
> 
> How many events did you have?  (The width of CI's is most importantly  
> dependent on event counts and not particularly improved by a high case  
> count. The power considerations are very similar to those of a  
> binomial test.)
> 
> 
>> What am I missing here ?
> 
> Perhaps sufficient events? (You also seem to be missing a description  
> of the study goals.)
> 
> 
> -- 
> David.
> 
>> 
>> %DEV=27%
>> 
>> 
>> 
>> Brier score - 0.07  ($ipec.coxglmnet -> [1] 7.24)
>> C-Index - 0.76 ($cIndex -> [1] 0.763)
>> 
>> 
>> 
>> DATA: [Private Health Information - can't publish] 394 obs./268 vars.
>> 
>> CODE (need to define a dataset with 'time' and 'status' variables):
>> 
>> library("survival")
>> library ("glmnet")
>> library ("c060")
>> library ("peperr")
>> library ("Hmisc")
>> 
>>   #creat Y (survival matrix) for glmnet
>>   surv_obj <- Surv(dataset$time,dataset$status)
>> 
>> 
>>   ## tranform categorical variables into binary variables with  
>> dummy for
>> dataset
>>   predict_matrix <- model.matrix(~ ., data=dataset,
>>                                  contrasts.arg = lapply
>> (dataset[,sapply(dataset, is.factor)], contrasts))
>> 
>>   ## remove the statu/time variables from the predictor matrix (x)  
>> for
>> glmnet
>>   predict_matrix <- subset (predict_matrix, select=c(-time,-status))
>> 
>>   ## create a glmnet cox object using lasso regularization and cross
>> validation
>>   glmnet.cv <- cv.glmnet (predict_matrix, surv_obj, family="cox")
>> 
>>   ## get the glmnet model on the full dataset
>>   glmnet.obj <- glmnet.cv$glmnet.fit
>> 
>>   # find lambda index for the models with least partial likelihood
>> deviance (by cv.glmnet)
>>   optimal.lambda <- glmnet.cv$lambda.min    # For a more parsimoneous
>> model use lambda.1se
>>   lambda.index <- which(glmnet.obj$lambda==optimal.lambda)
>> 
>> 
>>   # take beta for optimal lambda
>>   optimal.beta  <- glmnet.obj$beta[,lambda.index]
>> 
>>   # find non zero beta coef
>>   nonzero.coef <- abs(optimal.beta)>0
>>   selectedBeta <- optimal.beta[nonzero.coef]
>> 
>>   # take only covariates for which beta is not zero
>>   selectedVar   <- predict_matrix[,nonzero.coef]
>> 
>>   # create a dataframe for trainSet with time, status and selected
>> variables in binary representation for evaluation in pec
>>   reformat_dataSet <- as.data.frame(cbind(surv_obj,selectedVar))
>> 
>>   # glmnet.cox only with meaningful features selected by stepwise
>> bidirectional AIC feature selection
>>   glmnet.cox.meaningful <- step(coxph(Surv(time,status) ~
>> .,data=reformat_dataSet),direction="both")
>> 
>> 
>> 
>> 
>> 
> ##--------------------------------------------------------------------------
>> -----------------------------
>>   ##                                    MODEL PERFORMANCE
>> 
>> 
> ##--------------------------------------------------------------------------
>> -----------------------------
>>   ##
>> 
>> 
>>   ## Calculate the Brier score - pec does its own bootstrap so this
>> function runs on i=51 (i.e., whole trainset)
>> 
>>       ## Brier score calculation to cox-glmnet
>>       peperr.coxglmnet <- peperr(response=surv_obj, x=selectedVarCox,
>>                               fit.fun=fit.coxph, load.all=TRUE,
>> 
>> indices=resample.indices(n=nrow(surv_obj),
>> method="boot", sample.n=50))
>> 
>>       # Get error predictions from peperr
>>       prederr.coxglmnet <- perr(peperr.coxglmnet)
>> 
>>       # Integrated prediction error Brier score calculation
>>       ipec.coxglmnet<-ipec(prederr.coxglmnet,
>> eval.times=peperr.coxglmnet$attribute, response=surv_obj)
>> 
>> 
>> ## C-Index calculation 50 iter bootstrapping
>> 
>> for (i in 1:50){
>>       print (paste("Iteration:",i))
>>       train <- sample(1:nrow(dataset), nrow(dataset), replace =  
>> TRUE) ##
>> random sampling with replacement
>>       # create a dataframe for trainSet with time, status and  
>> selected
>> variables in binary representation for evaluation in pec
>>       reformat_trainSet <- reformat_dataSet [train,]
>> 
>> 
>>       # glmnet.cox only with meaningful features selected by stepwise
>> bidirectional AIC feature selection
>>       glmnet.cox.meaningful.test <- step(coxph(Surv(time,status) ~
>> .,data=reformat_dataSet),direction="both")
>> 
>>       selectedVarCox   <-
>> predict_matrix[,attr(glmnet.cox.meaningful.test$terms,"term.labels")]
>>       reformat_testSet <-  
>> as.data.frame(cbind(surv_obj,selectedVarCox))
>>       reformat_testSet <- reformat_dataSet [-train,]
>> 
>> 
>> #     compute c-index (Harrell's) for cox-glmnet models
>>       if (is.null(glmnet.cox.meaningful)){
>>         cIndexCoxglmnet <- c(cIndexCoxglmnet,NULL)
>>       }else{
>>         cIndexCoxglmnet <- c(cIndexCoxglmnet,
>> 1-rcorr.cens(predict(glmnet.cox.meaningful,
>> reformat_testSet),Surv(reformat_testSet$time,reformat_testSet 
>> $status))[1])
>>       }
>> }
>> 
>> #Get average C-Index
>> cIndex<- mean (unlist(cIndexCoxglmnet),rm.na=TRUE)
>> 
>> #create a list of all the objects generated
>> 
>> assign 
>> (name,c(eval(parse(text=name)),glmnet.cv=list(glmnet.cv),glmnet.obj=li
>> st(glmnet.obj),
>> 
>> selectedVar=list(colnames(selectedVar)),glmnet.cox=list(glmnet.cox),
>> 
>> glmnet 
>> .cox.meaningful=list(glmnet.cox.meaningful),ipec.coxglmnet=list(ipec.c
>> oxglmnet),
>>               cIndex=cIndex))
>> 
>> # save image of the workspace after each iteration
>>   save.image("final_subgroup_analysissubgroup_analysis.RData")
>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius, MD
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From girit at comcast.net  Mon Sep 30 20:12:57 2013
From: girit at comcast.net ( Cem Girit)
Date: Mon, 30 Sep 2013 14:12:57 -0400
Subject: [R] FW: Library update from version
Message-ID: <005901cebe08$b64a46e0$22ded4a0$@comcast.net>

Hello,

 

                I recently installed version 3.0.1 of R on to a computer. I
have a working installation for a Statconn application using R version
2.15.0 on another computer. I have many libraries under this old
installation. Can I just copy them into the new library from the old, or do
I install each one of them under the new R? Also how can I get a list of
differences in two libraries so that I can use this list to update the new
one? 

 

                Thank you.

 

Cem

 

 


From 538280 at gmail.com  Mon Sep 30 20:36:31 2013
From: 538280 at gmail.com (Greg Snow)
Date: Mon, 30 Sep 2013 12:36:31 -0600
Subject: [R] get mouse position without waiting for a click
In-Reply-To: <CAOZp1on9k9L-_xvN8uVci9oAXuMG0RQGNH3Jc1h=9DqV_KSNKg@mail.gmail.com>
References: <CAOZp1on9k9L-_xvN8uVci9oAXuMG0RQGNH3Jc1h=9DqV_KSNKg@mail.gmail.com>
Message-ID: <CAFEqCdzOX7+n7E6K+x-TNHj3Og2+8PWU=8d9tgZcm9kxmDjsWQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130930/403adf02/attachment.pl>

From lianoglou.steve at gene.com  Mon Sep 30 20:49:53 2013
From: lianoglou.steve at gene.com (Steve Lianoglou)
Date: Mon, 30 Sep 2013 11:49:53 -0700
Subject: [R] FW: Library update from version
In-Reply-To: <005901cebe08$b64a46e0$22ded4a0$@comcast.net>
References: <005901cebe08$b64a46e0$22ded4a0$@comcast.net>
Message-ID: <CAHA9McN5_zc79qNb_dcTKo6miwbBRFMhauZiRwLt0BF20oycFQ@mail.gmail.com>

Hi,

On Mon, Sep 30, 2013 at 11:12 AM, Cem Girit <girit at comcast.net> wrote:
> Hello,
>
>
>
>                 I recently installed version 3.0.1 of R on to a computer. I
> have a working installation for a Statconn application using R version
> 2.15.0 on another computer. I have many libraries under this old
> installation. Can I just copy them into the new library from the old, or do
> I install each one of them under the new R?

No, you shouldn't do that.

> Also how can I get a list of
> differences in two libraries so that I can use this list to update the new
> one?

A bit of googling could have provided several answers.

This post in particular has a few answers from some people who know
what they're doing w/ R, so probably a good place to start:

http://stackoverflow.com/questions/1401904/painless-way-to-install-a-new-version-of-r-on-windows

HTH,
-steve

-- 
Steve Lianoglou
Computational Biologist
Bioinformatics and Computational Biology
Genentech


From stan.aggerwal at gmail.com  Mon Sep 30 17:49:06 2013
From: stan.aggerwal at gmail.com (Stanislav Aggerwal)
Date: Mon, 30 Sep 2013 16:49:06 +0100
Subject: [R] get mouse position without waiting for a click
In-Reply-To: <CACk-te1_vLqhBGSjR36B_OoYOZaYfykLOuus-JG=X-Fm+fTdhA@mail.gmail.com>
References: <CAOZp1on9k9L-_xvN8uVci9oAXuMG0RQGNH3Jc1h=9DqV_KSNKg@mail.gmail.com>
	<CACk-te1_vLqhBGSjR36B_OoYOZaYfykLOuus-JG=X-Fm+fTdhA@mail.gmail.com>
Message-ID: <CAOZp1o=Y7sPL4RpaZrn+Fi5jaLdOBqksGBA-jgMnUmrwT4ymEw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130930/6b18f172/attachment.pl>

From sitterlyb at techemail.com  Mon Sep 30 19:39:23 2013
From: sitterlyb at techemail.com (sitterlyb)
Date: Mon, 30 Sep 2013 10:39:23 -0700 (PDT)
Subject: [R] ks.test or other Kolmogorov-Smirnov code
Message-ID: <1380562763272-4677290.post@n4.nabble.com>

Can any of the tools available provide where the supremum happens?

So classically D = sup|F1 - F2| or something to that affect, and then we use
D to figure out significance.  

If the ecdf is to be read as y=Pr(x<x_i), for each x_i , well at which x_i
does D occur?

Sorry for the repetition just trying to give all the context of what I'm
asking.

Thanks in advance.



--
View this message in context: http://r.789695.n4.nabble.com/ks-test-or-other-Kolmogorov-Smirnov-code-tp4677290.html
Sent from the R help mailing list archive at Nabble.com.


From wdunlap at tibco.com  Mon Sep 30 21:35:45 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 30 Sep 2013 19:35:45 +0000
Subject: [R] ks.test or other Kolmogorov-Smirnov code
In-Reply-To: <1380562763272-4677290.post@n4.nabble.com>
References: <1380562763272-4677290.post@n4.nabble.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C34793B@PA-MBX01.na.tibco.com>

> If the ecdf is to be read as y=Pr(x<x_i), for each x_i , well at which x_i
> does D occur?

The definition is Pr(x <= x_i), but that doesn't matter much here.

You know the maximum occurs at one of the points in union(x, y) so
you can find it by comparing the ecdf's at each of those points:
     f <- function(x, y) {
         xy <- union(x, y)
         d <- abs(ecdf(x)(xy) - ecdf(y)(xy))
         xy[ d == max(d) ]
    }

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of sitterlyb
> Sent: Monday, September 30, 2013 10:39 AM
> To: r-help at r-project.org
> Subject: [R] ks.test or other Kolmogorov-Smirnov code
> 
> Can any of the tools available provide where the supremum happens?
> 
> So classically D = sup|F1 - F2| or something to that affect, and then we use
> D to figure out significance.
> 
> If the ecdf is to be read as y=Pr(x<x_i), for each x_i , well at which x_i
> does D occur?
> 
> Sorry for the repetition just trying to give all the context of what I'm
> asking.
> 
> Thanks in advance.
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/ks-test-or-other-
> Kolmogorov-Smirnov-code-tp4677290.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From stan.aggerwal at gmail.com  Mon Sep 30 21:42:42 2013
From: stan.aggerwal at gmail.com (Stanislav Aggerwal)
Date: Mon, 30 Sep 2013 20:42:42 +0100
Subject: [R] get mouse position without waiting for a click
In-Reply-To: <CAFEqCdzOX7+n7E6K+x-TNHj3Og2+8PWU=8d9tgZcm9kxmDjsWQ@mail.gmail.com>
References: <CAOZp1on9k9L-_xvN8uVci9oAXuMG0RQGNH3Jc1h=9DqV_KSNKg@mail.gmail.com>
	<CAFEqCdzOX7+n7E6K+x-TNHj3Og2+8PWU=8d9tgZcm9kxmDjsWQ@mail.gmail.com>
Message-ID: <CAOZp1om6bqWe2Lw3MSmyLmMn2ERNUeeATSJmKs4KJ9YJidkTRA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130930/3cb5f424/attachment.pl>

From djmuser at gmail.com  Mon Sep 30 21:43:34 2013
From: djmuser at gmail.com (Dennis Murphy)
Date: Mon, 30 Sep 2013 12:43:34 -0700
Subject: [R] FW: Library update from version
In-Reply-To: <CAHA9McN5_zc79qNb_dcTKo6miwbBRFMhauZiRwLt0BF20oycFQ@mail.gmail.com>
References: <005901cebe08$b64a46e0$22ded4a0$@comcast.net>
	<CAHA9McN5_zc79qNb_dcTKo6miwbBRFMhauZiRwLt0BF20oycFQ@mail.gmail.com>
Message-ID: <CADv2QyEBWwCe_nvVZXMGLhXAiFFXB+ddDttw7-eVJPPXfcAEXA@mail.gmail.com>

In this case the OP probably does need to reinstall contributed
packages since going from 2.15.x to 3.0.y entails a major version
change in R.

Dennis

On Mon, Sep 30, 2013 at 11:49 AM, Steve Lianoglou
<lianoglou.steve at gene.com> wrote:
> Hi,
>
> On Mon, Sep 30, 2013 at 11:12 AM, Cem Girit <girit at comcast.net> wrote:
>> Hello,
>>
>>
>>
>>                 I recently installed version 3.0.1 of R on to a computer. I
>> have a working installation for a Statconn application using R version
>> 2.15.0 on another computer. I have many libraries under this old
>> installation. Can I just copy them into the new library from the old, or do
>> I install each one of them under the new R?
>
> No, you shouldn't do that.
>
>> Also how can I get a list of
>> differences in two libraries so that I can use this list to update the new
>> one?
>
> A bit of googling could have provided several answers.
>
> This post in particular has a few answers from some people who know
> what they're doing w/ R, so probably a good place to start:
>
> http://stackoverflow.com/questions/1401904/painless-way-to-install-a-new-version-of-r-on-windows
>
> HTH,
> -steve
>
> --
> Steve Lianoglou
> Computational Biologist
> Bioinformatics and Computational Biology
> Genentech
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Mon Sep 30 21:44:59 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 30 Sep 2013 15:44:59 -0400
Subject: [R] FW: Library update from version
In-Reply-To: <CAHA9McN5_zc79qNb_dcTKo6miwbBRFMhauZiRwLt0BF20oycFQ@mail.gmail.com>
References: <005901cebe08$b64a46e0$22ded4a0$@comcast.net>
	<CAHA9McN5_zc79qNb_dcTKo6miwbBRFMhauZiRwLt0BF20oycFQ@mail.gmail.com>
Message-ID: <CA+vqiLFveUmigu2OHhB_aUnxzniV+RDW7CYXOp1-VLEG6_Upmg@mail.gmail.com>

On Mon, Sep 30, 2013 at 2:49 PM, Steve Lianoglou
<lianoglou.steve at gene.com> wrote:
> Hi,
>
> On Mon, Sep 30, 2013 at 11:12 AM, Cem Girit <girit at comcast.net> wrote:
>> Hello,
>>
>>
>>
>>                 I recently installed version 3.0.1 of R on to a computer. I
>> have a working installation for a Statconn application using R version
>> 2.15.0 on another computer. I have many libraries under this old
>> installation. Can I just copy them into the new library from the old, or do
>> I install each one of them under the new R?
>
> No, you shouldn't do that.

Really? Why not? Note that the Windows upgrade FAQ
(http://cran.r-project.org/bin/windows/base/rw-FAQ.html#What_0027s-the-best-way-to-upgrade_003f)
says to do exactly that.

Best,
Ista
>
>> Also how can I get a list of
>> differences in two libraries so that I can use this list to update the new
>> one?
>
> A bit of googling could have provided several answers.
>
> This post in particular has a few answers from some people who know
> what they're doing w/ R, so probably a good place to start:
>
> http://stackoverflow.com/questions/1401904/painless-way-to-install-a-new-version-of-r-on-windows
>
> HTH,
> -steve
>
> --
> Steve Lianoglou
> Computational Biologist
> Bioinformatics and Computational Biology
> Genentech
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sitterlyb at techemail.com  Mon Sep 30 21:50:16 2013
From: sitterlyb at techemail.com (sitterlyb)
Date: Mon, 30 Sep 2013 12:50:16 -0700 (PDT)
Subject: [R] ks.test or other Kolmogorov-Smirnov code
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C34793B@PA-MBX01.na.tibco.com>
References: <1380562763272-4677290.post@n4.nabble.com>
	<E66794E69CFDE04D9A70842786030B931C34793B@PA-MBX01.na.tibco.com>
Message-ID: <1380570616050-4677306.post@n4.nabble.com>

sweet, I didn't know ecdf could be use like that!

Thanks!



--
View this message in context: http://r.789695.n4.nabble.com/ks-test-or-other-Kolmogorov-Smirnov-code-tp4677290p4677306.html
Sent from the R help mailing list archive at Nabble.com.


From jvadams at usgs.gov  Mon Sep 30 23:21:33 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 30 Sep 2013 16:21:33 -0500
Subject: [R] barplot - easy for experienced, difficult for me
In-Reply-To: <1380546308922-4677251.post@n4.nabble.com>
References: <1380546308922-4677251.post@n4.nabble.com>
Message-ID: <CAN5YmCHtTOUjZim6HnsKJtd96Hg6uityGnJX-dv_wOqZkGiS_A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130930/fc66c302/attachment.pl>

From jvadams at usgs.gov  Mon Sep 30 23:38:01 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 30 Sep 2013 16:38:01 -0500
Subject: [R] Apply function to do pairwise calculation
In-Reply-To: <CALwvZ4Vzeex8+=W4j6D6+8GAAuOvbBXZ2X0ahPhFsDsSwENuhA@mail.gmail.com>
References: <CALwvZ4Vzeex8+=W4j6D6+8GAAuOvbBXZ2X0ahPhFsDsSwENuhA@mail.gmail.com>
Message-ID: <CAN5YmCEidLw6LEhYiQ=NiJxE9MLptrXPAp8r-9Cg3NbVza7mJQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130930/76c8162c/attachment.pl>

From sreckojoksimovic at gmail.com  Mon Sep 30 23:50:13 2013
From: sreckojoksimovic at gmail.com (srecko joksimovic)
Date: Mon, 30 Sep 2013 14:50:13 -0700
Subject: [R] multilevel analysis
Message-ID: <CAM8BP_mZ5qoLL9kLtQV3K8RojsLxXdfYK=Jsf83hGcOayrKGWQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130930/304c1965/attachment.pl>

From lianoglou.steve at gene.com  Mon Sep 30 23:53:51 2013
From: lianoglou.steve at gene.com (Steve Lianoglou)
Date: Mon, 30 Sep 2013 14:53:51 -0700
Subject: [R] FW: Library update from version
In-Reply-To: <CA+vqiLFveUmigu2OHhB_aUnxzniV+RDW7CYXOp1-VLEG6_Upmg@mail.gmail.com>
References: <005901cebe08$b64a46e0$22ded4a0$@comcast.net>
	<CAHA9McN5_zc79qNb_dcTKo6miwbBRFMhauZiRwLt0BF20oycFQ@mail.gmail.com>
	<CA+vqiLFveUmigu2OHhB_aUnxzniV+RDW7CYXOp1-VLEG6_Upmg@mail.gmail.com>
Message-ID: <CAHA9McP5OtK9FVwNoA_OTBytYXmszzyt=b53+YFViQs5e7X7Lg@mail.gmail.com>

Hi,

On Mon, Sep 30, 2013 at 12:44 PM, Ista Zahn <istazahn at gmail.com> wrote:
> On Mon, Sep 30, 2013 at 2:49 PM, Steve Lianoglou
> <lianoglou.steve at gene.com> wrote:
>> Hi,
>>
>> On Mon, Sep 30, 2013 at 11:12 AM, Cem Girit <girit at comcast.net> wrote:
>>> Hello,
>>>
>>>
>>>
>>>                 I recently installed version 3.0.1 of R on to a computer. I
>>> have a working installation for a Statconn application using R version
>>> 2.15.0 on another computer. I have many libraries under this old
>>> installation. Can I just copy them into the new library from the old, or do
>>> I install each one of them under the new R?
>>
>> No, you shouldn't do that.
>
> Really? Why not?

Because it has been my experience that people *just* do that (ie. the
*just* copy the libraries, as the OP asked).

But as you correctly point out:

> Note that the Windows upgrade FAQ
> (http://cran.r-project.org/bin/windows/base/rw-FAQ.html#What_0027s-the-best-way-to-upgrade_003f)
> says to do exactly that.

There is a way to copy the old package and then ensure that they are
updated to the versions that build correctly on the newest version of
R.


-steve

-- 
Steve Lianoglou
Computational Biologist
Bioinformatics and Computational Biology
Genentech


